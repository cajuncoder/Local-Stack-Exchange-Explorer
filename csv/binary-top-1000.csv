title,viewcount,title,body,body,acceptedanswerid
"Reading binary file and looping over each byte","486753","","<p>In Python, how do I read in a binary file and loop over each byte of that file?</p>
","<pre><code>f = open(""myfile"", ""rb"")
try:
    byte = f.read(1)
    while byte != """":
        # Do stuff with byte.
        byte = f.read(1)
finally:
    f.close()
</code></pre>

<p>By suggestion of chrispy:</p>

<pre><code>with open(""myfile"", ""rb"") as f:
    byte = f.read(1)
    while byte != """":
        # Do stuff with byte.
        byte = f.read(1)
</code></pre>

<p>Note that the with statement is not available in versions of Python below 2.5. To use it in v 2.5 you'll need to import it:</p>

<pre><code>from __future__ import with_statement
</code></pre>

<p>In 2.6 this is not needed.</p>

<p>In Python 3, it's a bit different. We will no longer get raw characters from the stream in byte mode but byte objects, thus we need to alter the condition:</p>

<pre><code>with open(""myfile"", ""rb"") as f:
    byte = f.read(1)
    while byte != b"""":
        # Do stuff with byte.
        byte = f.read(1)
</code></pre>

<p>Or as benhoyt says, skip the not equal and take advantage of the fact that <code>b""""</code> evaluates to false. This makes the code compatible between 2.6 and 3.x without any changes. It would also save you from changing the condition if you go from byte mode to text or the reverse.</p>

<pre><code>with open(""myfile"", ""rb"") as f:
    byte = f.read(1)
    while byte:
        # Do stuff with byte.
        byte = f.read(1)
</code></pre>
","1035360"
"How to count the number of set bits in a 32-bit integer?","448755","","<p>8 bits representing the number 7 look like this:</p>

<pre><code>00000111
</code></pre>

<p>Three bits are set.   </p>

<p>What are algorithms to determine the number of set bits in a 32-bit integer?</p>
","<p>This is known as the '<a href=""https://en.wikipedia.org/wiki/Hamming_weight"" rel=""noreferrer"">Hamming Weight</a>', 'popcount' or 'sideways addition'.</p>

<p>The 'best' algorithm really depends on which CPU you are on and what your usage pattern is.</p>

<p>Some CPUs have a single built-in instruction to do it and others have parallel instructions which act on bit vectors. The parallel instructions (like x86's <code>popcnt</code>, on CPUs where it's supported) will almost certainly be fastest.  Some other architectures may have a slow instruction implemented with a microcoded loop that tests a bit per cycle (<em>citation needed</em>).</p>

<p>A pre-populated table lookup method can be very fast if your CPU has a large cache and/or you are doing lots of these instructions in a tight loop. However it can suffer because of the expense of a 'cache miss', where the CPU has to fetch some of the table from main memory.</p>

<p>If you know that your bytes will be mostly 0's or mostly 1's then there are very efficient algorithms for these scenarios.</p>

<p>I believe a very good general purpose algorithm is the following, known as 'parallel' or 'variable-precision SWAR algorithm'. I have expressed this in a C-like pseudo language, you may need to adjust it to work for a particular language (e.g. using uint32_t for C++ and >>> in Java):</p>

<pre class=""lang-c prettyprint-override""><code>int numberOfSetBits(int i)
{
     // Java: use &gt;&gt;&gt; instead of &gt;&gt;
     // C or C++: use uint32_t
     i = i - ((i &gt;&gt; 1) &amp; 0x55555555);
     i = (i &amp; 0x33333333) + ((i &gt;&gt; 2) &amp; 0x33333333);
     return (((i + (i &gt;&gt; 4)) &amp; 0x0F0F0F0F) * 0x01010101) &gt;&gt; 24;
}
</code></pre>

<p>This has the best worst-case behaviour of any of the algorithms discussed, so will efficiently deal with any usage pattern or values you throw at it.</p>

<hr>

<p>This bitwise-SWAR algorithm could parallelize to be done in multiple vector elements at once, instead of in a single integer register, for a speedup on CPUs with SIMD but no usable popcount instruction.  (e.g. x86-64 code that has to run on any CPU, not just Nehalem or later.)</p>

<p>However, the best way to use vector instructions for popcount is usually by using a variable-shuffle to do a table-lookup for 4 bits at a time of each byte in parallel.  (The 4 bits index a 16 entry table held in a vector register).</p>

<p>On Intel CPUs, the hardware 64bit popcnt instruction can outperform an <a href=""http://wm.ite.pl/articles/sse-popcount.html"" rel=""noreferrer"">SSSE3 <code>PSHUFB</code> bit-parallel implementation</a> by about a factor of 2, but only <a href=""http://danluu.com/assembly-intrinsics/"" rel=""noreferrer"">if your compiler gets it just right</a>.  Otherwise SSE can come out significantly ahead.  Newer compiler versions are aware of the <a href=""https://stackoverflow.com/a/25089720/224132"">popcnt false dependency</a> <a href=""https://gcc.gnu.org/bugzilla/show_bug.cgi?id=62011"" rel=""noreferrer"">problem on Intel</a>.</p>

<p>References:</p>

<p><a href=""https://graphics.stanford.edu/~seander/bithacks.html#CountBitsSetParallel"" rel=""noreferrer"">https://graphics.stanford.edu/~seander/bithacks.html</a></p>

<p><a href=""https://en.wikipedia.org/wiki/Hamming_weight"" rel=""noreferrer"">https://en.wikipedia.org/wiki/Hamming_weight</a></p>

<p><a href=""http://gurmeet.net/puzzles/fast-bit-counting-routines/"" rel=""noreferrer"">http://gurmeet.net/puzzles/fast-bit-counting-routines/</a></p>

<p><a href=""http://aggregate.ee.engr.uky.edu/MAGIC/#Population%20Count%20(Ones%20Count)"" rel=""noreferrer"">http://aggregate.ee.engr.uky.edu/MAGIC/#Population%20Count%20(Ones%20Count)</a></p>
","109025"
"What is “2's Complement”?","312373","","<p>I'm in a computer systems course and have been <em>struggling</em>, in part, with <a href=""http://en.wikipedia.org/wiki/Two%27s_complement"" rel=""noreferrer"">Two's Complement</a>. I want to understand it but everything I've read hasn't brought the picture together for me. I've read the <a href=""http://en.wikipedia.org/wiki/Two%27s_complement"" rel=""noreferrer"">wikipedia article</a> and various other articles, including <a href=""http://rads.stackoverflow.com/amzn/click/013034074X"" rel=""noreferrer"">my text book</a>.</p>

<p>Hence, I wanted to start this <strong>community wiki</strong> post to define what Two's Complement is, how to use it and how it can affect numbers during operations like casts (from signed to unsigned and vice versa), bit-wise operations and bit-shift operations.</p>

<p>What I'm hoping for is <strong>a clear and concise definition</strong> that is easily understood by a programmer.</p>
","<p>Two's complement is a clever way of storing integers so that common math problems are very simple to implement.</p>

<p>To understand, you have to think of the numbers in binary.</p>

<p>It basically says,</p>

<ul>
<li>for zero, use all 0's.</li>
<li>for positive integers, start counting up, with a maximum of 2<sup>(number of bits - 1)</sup>-1.</li>
<li>for negative integers, do exactly the same thing, but switch the role of 0's and 1's (so instead of starting with 0000, start with 1111 - that's the ""complement"" part).</li>
</ul>

<p>Let's try it with a mini-byte of 4 bits (we'll call it a <a href=""http://en.wikipedia.org/wiki/Nibble"" rel=""noreferrer"">nibble</a> - 1/2 a byte).</p>

<ul>
<li><code>0000</code> - zero</li>
<li><code>0001</code> - one</li>
<li><code>0010</code> - two</li>
<li><code>0011</code> - three</li>
<li><code>0100</code> to <code>0111</code> - four to seven</li>
</ul>

<p>That's as far as we can go in positives. 2<sup>3</sup>-1 = 7.</p>

<p>For negatives:</p>

<ul>
<li><code>1111</code> - negative one</li>
<li><code>1110</code> - negative two</li>
<li><code>1101</code> - negative three</li>
<li><code>1100</code> to <code>1000</code> - negative four to negative eight</li>
</ul>

<p>Note that you get one extra value for negatives (<code>1000</code> = -8) that you don't for positives. This is because <code>0000</code> is used for zero. This can be consider as <a href=""https://en.wikipedia.org/wiki/Number_line"" rel=""noreferrer"">Number Line</a> of computers.</p>

<p><strong>Distinguishing between positive and negative numbers</strong></p>

<p>Doing this, the first bit gets the role of the ""sign"" bit, as it can be used to distinguish between positive and negative decimal values. If the most significant bit is <code>1</code>, then the binary can be said to be negative, where as if the most significant bit (the leftmost) is <code>0</code>, you can say discern the decimal value is positive.</p>
","1049774"
"Can I use a binary literal in C or C++?","282309","","<p>I need to work with a binary number.</p>

<p>I tried writing:</p>

<pre><code>const x = 00010000;
</code></pre>

<p>But it didn't work.</p>

<p>I know that I can use an hexadecimal number that has the same value as <code>00010000</code>, but I want to know if there is a type in C++ for binary numbers and if there isn't, is there another solution for my problem?</p>
","<p>You can <a href=""http://www.boost.org/doc/libs/1_42_0/libs/utility/utility.htm#BOOST_BINARY"" rel=""nofollow noreferrer"">use <strong><code>BOOST_BINARY</code></strong></a> while waiting for C++0x. :)  <code>BOOST_BINARY</code> arguably has an advantage over template implementation insofar as it <strong>can be used in C programs as well</strong> (it is 100% preprocessor-driven.)</p>

<h3>UPDATE</h3>

<p>To do the converse (i.e. print out a number in binary form), you can use the non-portable <a href=""http://www.cplusplus.com/reference/clibrary/cstdlib/itoa/"" rel=""nofollow noreferrer""><code>itoa</code> function</a>, or <a href=""http://www.jb.man.ac.uk/~slowe/cpp/itoa.html"" rel=""nofollow noreferrer"">implement your own</a>.</p>

<p>Unfortunately you cannot do base 2 formatting with STL streams (since <a href=""http://en.cppreference.com/w/cpp/io/manip/setbase"" rel=""nofollow noreferrer""><code>setbase</code></a> will only honour bases 8, 10 and 16), but you <em>can</em> use either a <code>std::string</code> version of <code>itoa</code>, or (the more concise, yet marginally less efficient) <code>std::bitset</code>.</p>

<p><em>(Thank you <a href=""https://stackoverflow.com/users/54262/roger-pate"">Roger</a> for the <code>bitset</code> tip!)</em></p>

<pre><code>#include &lt;boost/utility/binary.hpp&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;bitset&gt;
#include &lt;iostream&gt;
#include &lt;iomanip&gt;

using namespace std;

int main() {
  unsigned short b = BOOST_BINARY( 10010 );
  char buf[sizeof(b)*8+1];
  printf(""hex: %04x, dec: %u, oct: %06o, bin: %16s\n"", b, b, b, itoa(b, buf, 2));
  cout &lt;&lt; setfill('0') &lt;&lt;
    ""hex: "" &lt;&lt; hex &lt;&lt; setw(4) &lt;&lt; b &lt;&lt; "", "" &lt;&lt;
    ""dec: "" &lt;&lt; dec &lt;&lt; b &lt;&lt; "", "" &lt;&lt;
    ""oct: "" &lt;&lt; oct &lt;&lt; setw(6) &lt;&lt; b &lt;&lt; "", "" &lt;&lt;
    ""bin: "" &lt;&lt; bitset&lt; 16 &gt;(b) &lt;&lt; endl;
  return 0;
}
</code></pre>

<p>produces:</p>

<pre><code>hex: 0012, dec: 18, oct: 000022, bin:            10010
hex: 0012, dec: 18, oct: 000022, bin: 0000000000010010
</code></pre>

<p>Also read Herb Sutter's <em><a href=""http://www.gotw.ca/publications/mill19.htm"" rel=""nofollow noreferrer"">The String Formatters of Manor Farm</a></em> for an interesting discussion.</p>
","2611883"
"How to view files in binary in the terminal?","229729","","<p>First things first, I'm on a Mac ssh'ing into a Linux machine via Terminal.</p>

<p>I would like to view the contents of a file in the current directory, but in binary. Is there a binary mode for any text editors like VI or Nano or the like?</p>
","<p>xxd does both binary and hexadecimal</p>

<p>bin:</p>

<pre><code>xxd -b file
</code></pre>

<p>hex:</p>

<pre><code>xxd file
</code></pre>
","20305782"
"What does the 'b' character do in front of a string literal?","211424","","<p>Apparently, the following is valid syntax</p>

<pre><code>my_string = b'The string'
</code></pre>

<p>I would like to know:</p>

<ol>
<li>What does this <code>b</code> character in front of the string mean?</li>
<li>What are the effects of using it?</li>
<li>What are appropriate situations to use it?</li>
</ol>

<p>I found a <a href=""https://stackoverflow.com/q/4749442/346561"">related question</a> right here on SO, but that question is about PHP though, and it states the <code>b</code> is used to indicate the string is binary, as opposed to Unicode, which was needed for code to be compatible from version of PHP &lt; 6, when migrating to PHP 6. I don't think this applies to Python.</p>

<p>I did find <a href=""http://docs.python.org/tutorial/introduction.html#unicode-strings"" rel=""nofollow noreferrer"">this documentation</a> on the Python site about using a <code>u</code> character in the same syntax to specify a string as Unicode. Unfortunately, it doesn't mention the <strong>b</strong> character anywhere in that document.</p>

<p>Also, just out of curiosity, are there more symbols than the <code>b</code> and <code>u</code> that do other things?</p>
","<p>To quote <a href=""https://docs.python.org/2/reference/lexical_analysis.html#string-literals"">the Python 2.x documentation</a>:</p>

<blockquote>
  <p>A prefix of 'b' or 'B' is ignored in
  Python 2; it indicates that the
  literal should become a bytes literal
  in Python 3 (e.g. when code is
  automatically converted with 2to3). A
  'u' or 'b' prefix may be followed by
  an 'r' prefix.</p>
</blockquote>

<p>The <a href=""https://docs.python.org/3.3/reference/lexical_analysis.html#string-literals"">Python 3.3 documentation</a> states:</p>

<blockquote>
  <p>Bytes literals are always prefixed with 'b' or 'B'; they produce an instance of the bytes type instead of the str type. They may only contain ASCII characters; bytes with a numeric value of 128 or greater must be expressed with escapes.</p>
</blockquote>
","6269785"
"Tool for comparing 2 binary files in Windows","205705","","<p>I need a tool for comparing 2 binary files. The files are quite big. Some freeware or trial tools I found on internet are not convenient to use for big files. Can you recommend me any tools?</p>
","<p>A few possibilities:</p>

<ul>
<li><a href=""http://www.cjmweb.net/vbindiff/"" rel=""nofollow noreferrer"">VBinDiff</a> (binary diff, designed for large files)</li>
<li><a href=""http://en.wikipedia.org/wiki/WinDiff"" rel=""nofollow noreferrer"">WinDiff</a></li>
<li><a href=""http://www.daemonology.net/bsdiff/"" rel=""nofollow noreferrer"">bsdiff</a></li>
</ul>

<p>See also: <a href=""https://stackoverflow.com/questions/688504/binary-diff-tool-for-very-large-files"">Binary diff tool for very large files?</a></p>
","8166748"
"How to print binary number via printf","194008","","<blockquote>
  <p><strong>Possible Duplicate:</strong> <br/>
  <a href=""https://stackoverflow.com/questions/111928/is-there-a-printf-converter-to-print-in-binary-format"">Is there a printf converter to print in binary format?</a></p>
</blockquote>



<p>Here is my program</p>

<pre><code>#include&lt;stdio.h&gt;
int main ()
{
    int i,a=2;
    i=~a;
    printf(""a=%d\ni=%d\n"",a,i);

    return 0;
}
</code></pre>

<p>The output is</p>

<pre><code>a=2
i=-3
</code></pre>

<p>I want this to print in binary. There are %x, %o, and %d which are for hexadecimal, octal, and decimal number, but what is for printing binary in printf?</p>
","<p>printf() doesn't directly support that. Instead you have to make your own function.</p>

<p>Something like:</p>

<pre><code>while (n) {
    if (n &amp; 1)
        printf(""1"");
    else
        printf(""0"");

    n &gt;&gt;= 1;
}
printf(""\n"");
</code></pre>
","6373240"
"Converting an int to a binary string representation in Java?","185608","","<p>What would be the best way (ideally, simplest) to convert an int to a binary string representation in Java?</p>

<p>For example, say the int is 156. The binary string representation of this would be ""10011100"".</p>
","<pre><code>Integer.toBinaryString(int i)
</code></pre>
","2406441"
"Are the shift operators (<<, >>) arithmetic or logical in C?","182889","","<p>In C, are the shift operators (<code>&lt;&lt;</code>, <code>&gt;&gt;</code>) arithmetic or logical?</p>
","<p>According to <a href=""http://rads.stackoverflow.com/amzn/click/0131103628"" rel=""noreferrer"">K&amp;R 2nd edition</a> the results are implementation-dependent for right shifts of signed values.</p>

<p><a href=""http://en.wikipedia.org/wiki/Arithmetic_shift"" rel=""noreferrer"">Wikipedia</a> says that C/C++ 'usually' implements an arithmetic shift on signed values.</p>

<p>Basically you need to either test your compiler or not rely on it. My VS2008 help for the current MS C++ compiler says that their compiler does an arithmetic shift.</p>
","7636"
"Converting Decimal to Binary Java","175684","","<p>I am trying to convert decimal to binary numbers from the user's input using Java. </p>

<p>I'm getting errors.</p>

<pre><code>package reversedBinary;
import java.util.Scanner;

public class ReversedBinary {


public static void main(String[] args) {
    int number; 

    Scanner in = new Scanner(System.in);

    System.out.println(""Enter a positive integer"");
    number=in.nextInt();

    if (number &lt;0)
        System.out.println(""Error: Not a positive integer"");
    else { 

        System.out.print(""Convert to binary is:"");
        System.out.print(binaryform(number));
}

}

private static Object binaryform(int number) {
    int remainder;

    if (number &lt;=1) {
        System.out.print(number);

    }

    remainder= number %2; 
    binaryform(number &gt;&gt;1);
    System.out.print(remainder);

    { 
    return null;
} } }
</code></pre>

<p>How do I convert Decimal to Binary in Java?</p>
","<p>Your <code>binaryForm</code> method is getting caught in an infinite recursion, you need to return if <code>number &lt;= 1</code>:</p>

<pre><code>import java.util.Scanner;

public class ReversedBinary {

    public static void main(String[] args) {
        int number; 

        Scanner in = new Scanner(System.in);

        System.out.println(""Enter a positive integer"");
        number = in.nextInt();

        if (number &lt; 0) {
            System.out.println(""Error: Not a positive integer"");
        } else { 

            System.out.print(""Convert to binary is:"");
            //System.out.print(binaryform(number));
            printBinaryform(number);
        }
    }

    private static void printBinaryform(int number) {
        int remainder;

        if (number &lt;= 1) {
            System.out.print(number);
            return;   // KICK OUT OF THE RECURSION
        }

        remainder = number %2; 
        printBinaryform(number &gt;&gt; 1);
        System.out.print(remainder);
    }
}
</code></pre>
","14784683"
"How many values can be represented with n bits?","173067","","<p>For example, if <code>n=9</code>, then how many different values can be represented in 9 binary digits (bits)?</p>

<p>My thinking is that if I set each of those 9 bits to 1, I will make the highest number possible that those 9 digits are able to represent. Therefore, the highest value is <code>1 1111 1111</code> which equals <code>511</code> in decimal. I conclude that, therefore, 9 digits of binary can represent 511 different values.</p>

<p>Is my thought process correct? If not, could someone kindly explain what I'm missing? How can I generalize it to <code>n</code> bits?</p>
","<p>2<sup>9</sup> = 512 values, because that's how many combinations of zeroes and ones you can have.</p>

<hr>

<p>What those values represent however will depend on the system you are using. If it's an unsigned integer, you will have:</p>

<pre><code>000000000 = 0 (min)
000000001 = 1
...
111111110 = 510
111111111 = 511 (max)
</code></pre>

<p>In <a href=""http://en.wikipedia.org/wiki/Two%27s_complement"" rel=""noreferrer"">two's complement</a>, which is commonly used to represent integers in binary, you'll have:</p>

<pre><code>000000000 = 0
000000001 = 1
...
011111110 = 254
011111111 = 255 (max)
100000000 = -256 (min) &lt;- yay integer overflow
100000001 = -255
...
111111110 = -2
111111111 = -1
</code></pre>

<p>In general, with <em>k</em> bits you can represent 2<sup>k</sup> values. Their range will depend on the system you are using:</p>

<blockquote>
  <p>Unsigned: 0 to 2<sup>k</sup>-1<br>
  Signed: -2<sup>k-1</sup> to 2<sup>k-1</sup>-1</p>
</blockquote>
","3809058"
"How to print (using cout) the way a number is stored in memory?","164661","","<p>I'm following a college course about operating systems and we're learning how to convert from binary to hexadecimal, decimal to hexadecimal, etc. and today we just learned how signed/unsigned numbers are stored in memory using the two's complement (~number + 1).</p>

<p>We have a couple of exercises to do on paper and I would like to be able to verify my answers before submitting my work to the teacher. I wrote a C++ program for the first few exercises but now I'm stuck as to how I could verify my answer with the following problem:</p>

<pre><code>char a, b;

short c;
a = -58;
c = -315;

b = a &gt;&gt; 3;
</code></pre>

<p>and we need to show the binary representation <em>in memory</em> of <code>a</code>, <code>b</code> and <code>c</code>.</p>

<p>I've done it on paper and it gives me the following results (all the binary representations in memory of the numbers after the two's complement):</p>

<blockquote>
  <p>a = 00111010 (it's a char, so 1 byte)</p>
  
  <p>b = 00001000 (it's a char, so 1 byte)</p>
  
  <p>c = 11111110 11000101 (it's a short, so 2 bytes)</p>
</blockquote>

<p>Is there a way to verify my answer? Is there a standard way in C++ to show the binary representation in memory of a number, or do I have to code each step myself (calculate the two's complement and then convert to binary)? I know the latter wouldn't take so long but I'm curious as to if there is a standard way to do so.</p>
","<p>The easiest way is probably to create an <a href=""http://en.cppreference.com/w/cpp/utility/bitset"" rel=""noreferrer""><code>std::bitset</code></a> representing the value, then stream that to <code>cout</code>.</p>

<pre><code>#include &lt;bitset&gt;
...

char a = -58;    
std::bitset&lt;8&gt; x(a);
std::cout &lt;&lt; x;

short c = -315;
std::bitset&lt;16&gt; y(c);
std::cout &lt;&lt; y;
</code></pre>
","7349767"
"How do you express binary literals in Python?","155047","","<p>How do you express an integer as a binary number with Python literals?</p>

<p>I was easily able to find the answer for hex:</p>

<pre><code>&gt;&gt;&gt; 0x12AF
4783
&gt;&gt;&gt; 0x100
256
</code></pre>

<p>and octal:</p>

<pre><code>&gt;&gt;&gt; 01267
695
&gt;&gt;&gt; 0100
64
</code></pre>

<p><strong>How do you use literals to express binary in Python?</strong></p>

<hr>

<p><strong><em>Summary of Answers</em></strong></p>

<ul>
<li>Python 2.5 and earlier: can express binary using <code>int('01010101111',2)</code> but not with a literal.</li>
<li>Python 2.5 and earlier: there is <em>no way</em> to express binary literals.</li>
<li>Python 2.6 beta: You can do like so: <code>0b1100111</code> or <code>0B1100111</code>.</li>
<li>Python 2.6 beta: will also allow <code>0o27</code> or <code>0O27</code> (second character is the letter O) to represent an octal.</li>
<li>Python 3.0 beta: Same as 2.6, but will no longer allow the older <code>027</code> syntax for octals.</li>
</ul>
","<p>For reference&mdash;<em>future</em> Python possibilities:<br>
Starting with Python 2.6 you can express binary literals using the prefix <strong>0b</strong> or <strong>0B</strong>:</p>

<pre><code>&gt;&gt;&gt; 0b101111
47
</code></pre>

<p>You can also use the new <strong>bin</strong> function to get the binary representation of a number:</p>

<pre><code>&gt;&gt;&gt; bin(173)
'0b10101101'
</code></pre>

<p>Development version of the documentation: <a href=""http://docs.python.org/dev/whatsnew/2.6.html#pep-3127-integer-literal-support-and-syntax"" rel=""noreferrer"">What's New in Python 2.6</a></p>
","13107"
"Reading and writing binary file","152086","","<p>I'm trying to write code to read a binary file into a buffer, then write the buffer to another file.  I have the following code, but the buffer only stores a couple of ASCII characters from the first line in the file and nothing else.</p>

<pre><code>int length;
char * buffer;

ifstream is;
is.open (""C:\\Final.gif"", ios::binary );
// get length of file:
is.seekg (0, ios::end);
length = is.tellg();
is.seekg (0, ios::beg);
// allocate memory:
buffer = new char [length];
// read data as a block:
is.read (buffer,length);
is.close();

FILE *pFile;
pFile = fopen (""C:\\myfile.gif"", ""w"");
fwrite (buffer , 1 , sizeof(buffer) , pFile );
</code></pre>
","<p>If you want to do this the C++ way, do it like this:</p>

<pre><code>#include &lt;fstream&gt;
#include &lt;iterator&gt;
#include &lt;algorithm&gt;

int main()
{
    std::ifstream input( ""C:\\Final.gif"", std::ios::binary );
    std::ofstream output( ""C:\\myfile.gif"", std::ios::binary );

    std::copy( 
        std::istreambuf_iterator&lt;char&gt;(input), 
        std::istreambuf_iterator&lt;char&gt;( ),
        std::ostreambuf_iterator&lt;char&gt;(output));
}
</code></pre>

<p>If you need that data in a buffer to modify it or something, do this:</p>

<pre><code>#include &lt;fstream&gt;
#include &lt;iterator&gt;
#include &lt;vector&gt;

int main()
{
    std::ifstream input( ""C:\\Final.gif"", std::ios::binary );
    // copies all data into buffer
    std::vector&lt;char&gt; buffer((
            std::istreambuf_iterator&lt;char&gt;(input)), 
            (std::istreambuf_iterator&lt;char&gt;()));
}
</code></pre>
","5420568"
"Convert string to binary in python","139249","","<p>I am in need of a way to get the binary representation of a string in python. e.g. </p>

<pre><code>st = ""hello world""
toBinary(st)
</code></pre>

<p>Is there a module of some neat way of doing this?</p>
","<p>Something like this?</p>

<pre><code>&gt;&gt;&gt; st = ""hello world""
&gt;&gt;&gt; ' '.join(format(ord(x), 'b') for x in st)
'1101000 1100101 1101100 1101100 1101111 100000 1110111 1101111 1110010 1101100 1100100'

#using `bytearray`
&gt;&gt;&gt; ' '.join(format(x, 'b') for x in bytearray(st))
'1101000 1100101 1101100 1101100 1101111 100000 1110111 1101111 1110010 1101100 1100100'
</code></pre>
","18815890"
"Converting integer to binary in python","138457","","<p>In order to convert an integer to a binary, i have used this code :</p>

<pre><code>&gt;&gt;&gt; bin(6)  
'0b110'
</code></pre>

<p>and when to erase the '0b', i use this :</p>

<pre><code>&gt;&gt;&gt; bin(6)[2:]  
'110'
</code></pre>

<p>What can i do if i want to show <code>6</code> as <code>00000110</code> instead of <code>110</code>?</p>
","<pre><code>&gt;&gt;&gt; '{0:08b}'.format(6)
'00000110'
</code></pre>

<p>Just to explain the parts of the formatting string:</p>

<ul>
<li><code>{}</code> places a variable into a string</li>
<li><code>0</code> takes the variable at argument position 0</li>
<li><code>:</code> adds formatting options for this variable (otherwise it would represent decimal <code>6</code>)</li>
<li><code>08</code> formats the number to eight digits zero-padded on the left</li>
<li><code>b</code> converts the number to its binary representation</li>
</ul>
","10411108"
"Convert binary to ASCII and vice versa","132501","","<p>Using this code to take a string and convert it to binary:</p>

<pre><code>bin(reduce(lambda x, y: 256*x+y, (ord(c) for c in 'hello'), 0))
</code></pre>

<p>this outputs:</p>

<pre><code>0b110100001100101011011000110110001101111
</code></pre>

<p>Which, if I put it into <a href=""http://www.roubaixinteractive.com/PlayGround/Binary_Conversion/Binary_To_Text.asp"" rel=""noreferrer"">this site</a> (on the right hand site) I get my message of <code>hello</code> back. I'm wondering what method it uses. I know I could splice apart the string of binary into 8's and then match it to the corresponding value to <code>bin(ord(character))</code> or some other way. Really looking for something simpler.</p>
","<p>For ASCII characters in the range <code>[ -~]</code> on Python 2:</p>

<pre><code>&gt;&gt;&gt; import binascii
&gt;&gt;&gt; bin(int(binascii.hexlify('hello'), 16))
'0b110100001100101011011000110110001101111'
</code></pre>

<p>In reverse:</p>

<pre><code>&gt;&gt;&gt; n = int('0b110100001100101011011000110110001101111', 2)
&gt;&gt;&gt; binascii.unhexlify('%x' % n)
'hello'
</code></pre>

<hr>

<p>In Python 3.2+:</p>

<pre><code>&gt;&gt;&gt; bin(int.from_bytes('hello'.encode(), 'big'))
'0b110100001100101011011000110110001101111'
</code></pre>

<p>In reverse:</p>

<pre><code>&gt;&gt;&gt; n = int('0b110100001100101011011000110110001101111', 2)
&gt;&gt;&gt; n.to_bytes((n.bit_length() + 7) // 8, 'big').decode()
'hello'
</code></pre>

<hr>

<h3>To support all Unicode characters in Python 3:</h3>

<pre><code>def text_to_bits(text, encoding='utf-8', errors='surrogatepass'):
    bits = bin(int.from_bytes(text.encode(encoding, errors), 'big'))[2:]
    return bits.zfill(8 * ((len(bits) + 7) // 8))

def text_from_bits(bits, encoding='utf-8', errors='surrogatepass'):
    n = int(bits, 2)
    return n.to_bytes((n.bit_length() + 7) // 8, 'big').decode(encoding, errors) or '\0'
</code></pre>

<h3>Here's  single-source Python 2/3 compatible version:</h3>

<pre><code>import binascii

def text_to_bits(text, encoding='utf-8', errors='surrogatepass'):
    bits = bin(int(binascii.hexlify(text.encode(encoding, errors)), 16))[2:]
    return bits.zfill(8 * ((len(bits) + 7) // 8))

def text_from_bits(bits, encoding='utf-8', errors='surrogatepass'):
    n = int(bits, 2)
    return int2bytes(n).decode(encoding, errors)

def int2bytes(i):
    hex_string = '%x' % i
    n = len(hex_string)
    return binascii.unhexlify(hex_string.zfill(n + (n &amp; 1)))
</code></pre>

<h3>Example</h3>

<pre><code>&gt;&gt;&gt; text_to_bits('hello')
'0110100001100101011011000110110001101111'
&gt;&gt;&gt; text_from_bits('110100001100101011011000110110001101111') == u'hello'
True
</code></pre>
","7397689"
"Count number of 1's in binary representation","115827","","<p>Efficient way to count number of 1s in the binary representation of a number in O(1) if you have enough memory to play with. This is an interview question I found on an online forum, but it had no answer. Can somebody suggest something, I cant think of a way to do it in O(1) time?</p>
","<p>That's the <a href=""http://en.wikipedia.org/wiki/Hamming_weight"">Hamming weight</a> problem, a.k.a. population count. The link mentions efficient implementations. Quoting:</p>

<blockquote>
  <p>With unlimited memory, we could simply create a large lookup table of the Hamming weight of every 64 bit integer</p>
</blockquote>
","8871279"
"How to convert a byte to its binary string representation","114530","","<p>For example, the bits in a byte <code>B</code> are <code>10000010</code>, how can I assign the bits to the string <code>str</code> literally, that is, <code>str = ""10000010""</code>. </p>

<p><strong>Edit</strong></p>

<p>I read the byte from a binary file, and stored in the byte array <code>B</code>. I use <code>System.out.println(Integer.toBinaryString(B[i]))</code>.  the problem is </p>

<p>(a) when the bits begin with (leftmost) 1, the output is not correct because it converts <code>B[i]</code> to a negative int value. </p>

<p>(b) if the bits begin with <code>0</code>, the output ignore <code>0</code>, for example, assume <code>B[0]</code> has 00000001, the output is <code>1</code> instead of <code>00000001</code></p>
","<p>Use <a href=""http://docs.oracle.com/javase/7/docs/api/java/lang/Integer.html#toBinaryString%28int%29""><code>Integer#toBinaryString()</code></a>:</p>

<pre><code>byte b1 = (byte) 129;
String s1 = String.format(""%8s"", Integer.toBinaryString(b1 &amp; 0xFF)).replace(' ', '0');
System.out.println(s1); // 10000001

byte b2 = (byte) 2;
String s2 = String.format(""%8s"", Integer.toBinaryString(b2 &amp; 0xFF)).replace(' ', '0');
System.out.println(s2); // 00000010
</code></pre>

<p><strong><a href=""http://ideone.com/xHojh"">DEMO</a></strong>.</p>
","12310078"
"Reading a binary file with python","113914","","<p>I find particularly difficult reading binary file with Python. Can you give me a hand?
I need to read this file, which in Fortran 90 is easily read by</p>

<pre><code>int*4 n_particles, n_groups
real*4 group_id(n_particles)
read (*) n_particles, n_groups
read (*) (group_id(j),j=1,n_particles)
</code></pre>

<p>In detail, the file format is:</p>

<pre><code>Bytes 1-4 -- The integer 8.
Bytes 5-8 -- The number of particles, N.
Bytes 9-12 -- The number of groups.
Bytes 13-16 -- The integer 8.
Bytes 17-20 -- The integer 4*N.
Next many bytes -- The group ID numbers for all the particles.
Last 4 bytes -- The integer 4*N. 
</code></pre>

<p>How can I read this with Python? I tried everything but it never worked. Is there any chance I might use a f90 program in python, reading this binary file and then save the data that I need to use?</p>
","<p>Read the binary file content like this:</p>

<pre><code>with open(fileName, mode='rb') as file: # b is important -&gt; binary
    fileContent = file.read()
</code></pre>

<p>then ""unpack"" binary data using <a href=""http://docs.python.org/library/struct.html#struct.unpack"">struct.unpack</a>:</p>

<p>The start bytes: <code>struct.unpack(""iiiii"", fileContent[:20])</code></p>

<p>The body: ignore the heading bytes and the trailing byte (= 24); The remaining part forms the body, to know the number of bytes in the body do an integer division by 4; The obtained quotient is multiplied by the string <code>'i'</code> to create the correct format for the unpack method:</p>

<pre><code>struct.unpack(""i"" * ((len(fileContent) -24) // 4), fileContent[20:-4])
</code></pre>

<p>The end byte: <code>struct.unpack(""i"", fileContent[-4:])</code></p>
","8711061"
"How to convert a Binary String to a base 10 integer in Java","113839","","<p>I have an array of Strings that represent Binary numbers (without leading zeroes) that I want to convert to their corresponding base 10 numbers. Consider:</p>

<pre><code>binary 1011 becomes integer 11
binary 1001 becomes integer 9
binary   11 becomes integer 3   etc. 
</code></pre>

<p>What's the best way to proceed? I've been exploring java.lang.number.* without finding a direct conversion method. <code>Integer.parseInt(b)</code> yields an integer EQUAL to the String...e.g., 1001 becomes 1,001 instead of 9...and does not seem to include a parameter for an output base. <code>toBinaryString</code> does the conversion the wrong direction. I suspect I'll need to do a multistep conversion, but can't seem to find the right combination of methods or subclasses. I'm also not sure the extent to which leading zeros or lack thereof will be an issue. Anyone have any good directions to point me?</p>
","<p>You need to <a href=""http://docs.oracle.com/javase/7/docs/api/java/lang/Integer.html#parseInt%28java.lang.String,%20int%29"">specify the radix</a>. There's an overload of <code>Integer#parseInt()</code> which allows you to.</p>

<pre><code>int foo = Integer.parseInt(""1001"", 2);
</code></pre>
","10179008"
"How to read file binary in C#?","111144","","<p>I want to make a method that takes any file and reads it as an array of 0s and 1s, i.e. its binary code. I want to save that binary code as a text file. Can you help me? Thanks. </p>
","<p>Quick and dirty version:</p>

<pre><code>byte[] fileBytes = File.ReadAllBytes(inputFilename);
StringBuilder sb = new StringBuilder();

foreach(byte b in fileBytes)
{
    sb.Append(Convert.ToString(b, 2).PadLeft(8, '0'));  
}

File.WriteAllText(outputFilename, sb.ToString());
</code></pre>
","2426395"
"How exactly does binary code get converted into letters?","104329","","<p>Out of curiosity, how exactly does binary code get converted into letters? I know there are sites that automatically convert binary to words for you but I wanna understand the specific, intermediary steps that binary code goes through before being converted into letters.</p>
","<p>Assuming that by ""binary code"" you mean just plain old data (sequences of bits, or bytes), and that by ""letters"" you mean characters, the answer is in two steps.  But first, some background.</p>

<ul>
<li>A character is just a named symbol, like ""LATIN CAPITAL LETTER A"" or ""GREEK SMALL LETTER PI"" or ""BLACK CHESS KNIGHT"".  Do not confuse a character (abstract symbol) with a <em>glyph</em> (a picture of a character).</li>
<li>A <em>character set</em> is a particular set of characters, each of which is associated with a special number, called its codepoint.  To see the codepoint mappings in the Unicode character set, see <a href=""http://www.unicode.org/Public/UNIDATA/UnicodeData.txt"">http://www.unicode.org/Public/UNIDATA/UnicodeData.txt</a>.</li>
</ul>

<p>Okay now here are the two steps:</p>

<ol>
<li><p>The data, if it is textual, must be accompanied somehow by a <em>character encoding</em>, something like UTF-8, Latin-1, US-ASCII, etc.  Each character encoding scheme specifies in great detail how  byte sequences are interpreted as codepoints (and conversely how codepoints are encoded as byte sequences).</p></li>
<li><p>Once the byte sequences are interpreted as codepoints, you have your characters, because each character has a specific codepoint.</p></li>
</ol>

<p>A couple notes:</p>

<ul>
<li>In some encodings, certain byte sequences correspond to no codepoints at all, so you can have character decoding errors.</li>
<li>In some character sets, there are codepoints that are unused, that is, they correspond to no character at all.</li>
</ul>

<p>In other words, not every byte sequence means something as text.</p>
","6826662"
"Binary numbers in Python","101879","","<p>How can I add, subtract, and compare binary numbers in Python without converting to decimal?</p>
","<p>You can convert between a string representation of the binary using bin() and int()</p>

<pre><code>&gt;&gt;&gt; bin(88)
'0b1011000'
&gt;&gt;&gt; int('0b1011000', 2)
88
&gt;&gt;&gt; 

&gt;&gt;&gt; a=int('01100000', 2)
&gt;&gt;&gt; b=int('00100110', 2)
&gt;&gt;&gt; bin(a &amp; b)
'0b100000'
&gt;&gt;&gt; bin(a | b)
'0b1100110'
&gt;&gt;&gt; bin(a ^ b)
'0b1000110'
</code></pre>
","1523581"
"Display the binary representation of a number in C?","99925","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/111928/is-there-a-printf-converter-to-print-in-binary-format"">Is there a printf converter to print in binary format?</a>  </p>
</blockquote>



<p>Still learning C and I was wondering: </p>

<p>Given a number, is it possible to do something like the following?</p>

<pre><code>char a = 5;
printf(""binary representation of a = %b"",a);
&gt; 101
</code></pre>

<p>Or would i have to write my own method to do the transformation to binary?</p>
","<p>Yes (write your own), something like the following complete function.</p>

<pre><code>#include &lt;stdio.h&gt; /* only needed for the printf() in main(). */
#include &lt;string.h&gt;

/* Create a string of binary digits based on the input value.
   Input:
       val:  value to convert.
       buff: buffer to write to must be &gt;= sz+1 chars.
       sz:   size of buffer.
   Returns address of string or NULL if not enough space provided.
*/
static char *binrep (unsigned int val, char *buff, int sz) {
    char *pbuff = buff;

    /* Must be able to store one character at least. */
    if (sz &lt; 1) return NULL;

    /* Special case for zero to ensure some output. */
    if (val == 0) {
        *pbuff++ = '0';
        *pbuff = '\0';
        return buff;
    }

    /* Work from the end of the buffer back. */
    pbuff += sz;
    *pbuff-- = '\0';

    /* For each bit (going backwards) store character. */
    while (val != 0) {
        if (sz-- == 0) return NULL;
        *pbuff-- = ((val &amp; 1) == 1) ? '1' : '0';

        /* Get next bit. */
        val &gt;&gt;= 1;
    }
    return pbuff+1;
}
</code></pre>

<p>Add this main to the end of it to see it in operation:</p>

<pre><code>#define SZ 32
int main(int argc, char *argv[]) {
    int i;
    int n;
    char buff[SZ+1];

    /* Process all arguments, outputting their binary. */
    for (i = 1; i &lt; argc; i++) {
        n = atoi (argv[i]);
        printf(""[%3d] %9d -&gt; %s (from '%s')\n"", i, n,
            binrep(n,buff,SZ), argv[i]);
    }

    return 0;
}
</code></pre>

<p>Run it with <code>""progname 0 7 12 52 123""</code> to get:</p>

<pre><code>[  1]         0 -&gt; 0 (from '0')
[  2]         7 -&gt; 111 (from '7')
[  3]        12 -&gt; 1100 (from '12')
[  4]        52 -&gt; 110100 (from '52')
[  5]       123 -&gt; 1111011 (from '123')
</code></pre>
","700018"
"How to compare binary files to check if they are the same?","98302","","<p>What is the easiest way (using a graphical tool or command line on Ubuntu Linux) to know if two binary files are the same or not (except for the time stamps)? I do not need to actually extract the difference. I just need to know whether they are the same or not.</p>
","<p>The standard unix <code>diff</code> will show if the files are the same or not:</p>

<pre><code>[me@host ~]$ diff 1.bin 2.bin
Binary files 1.bin and 2.bin differ
</code></pre>

<p>If there is no output from the command, it means that the files have no differences.</p>
","12118413"
"C# binary literals","97981","","<p>Is there a way to write binary literals in C#, like prefixing hexadecimal with 0x? 0b doesn't work.</p>

<p>If not, what is an easy way to do it? Some kind of string conversion?</p>
","<p>C# <a href=""https://github.com/dotnet/roslyn/issues/2136"" rel=""noreferrer"">7.0</a> supports <a href=""https://github.com/dotnet/roslyn/issues/215"" rel=""noreferrer"">binary literals</a> (and optional digit separators via underscore characters).</p>

<p>An example:</p>

<pre><code>int myValue = 0b0010_0110_0000_0011;
</code></pre>

<p>You can also find more information on the <a href=""https://github.com/dotnet/roslyn"" rel=""noreferrer"">Roslyn GitHub page</a>.</p>
","23546326"
"Bitwise operation and usage","97837","","<p>Consider this code:</p>

<pre><code>x = 1        # 0001
x &lt;&lt; 2       # Shift left 2 bits: 0100
# Result: 4

x | 2        # Bitwise OR: 0011
# Result: 3

x &amp; 1        # Bitwise AND: 0001
# Result: 1
</code></pre>

<p>I can understand the arithmetic operators in Python (and other languages), but I never understood 'bitwise' operators quite well. In the above example (from a Python book), I understand the left-shift but not the other two.</p>

<p>Also, what are bitwise operators actually used for? I'd appreciate some examples.</p>
","<p>Bitwise operators are operators that work on multi-bit values, but conceptually one bit at a time.</p>

<ul>
<li><code>AND</code> is 1 only if <em>both</em> of its inputs are 1, otherwise it's 0.</li>
<li><code>OR</code> is 1 if <em>one or both</em> of its inputs are 1, otherwise it's 0.</li>
<li><code>XOR</code> is 1 only if <em>exactly one</em> of its inputs are 1, otherwise it's 0.</li>
<li><code>NOT</code> is 1 only if its input is 0, otherwise it's 0.</li>
</ul>

<p>These can often be best shown as truth tables.  Input possibilities are on the top and left, the resultant bit is one of the four (two in the case of NOT since it only has one input) values shown at the intersection of the inputs.</p>

<pre><code>AND | 0 1     OR | 0 1     XOR | 0 1    NOT | 0 1
----+-----    ---+----     ----+----    ----+----
 0  | 0 0      0 | 0 1       0 | 0 1        | 1 0
 1  | 0 1      1 | 1 1       1 | 1 0
</code></pre>

<p>One example is if you only want the lower 4 bits of an integer, you AND it with 15 (binary 1111) so:</p>

<pre><code>    201: 1100 1001
AND  15: 0000 1111
------------------
 IS   9  0000 1001
</code></pre>

<p>The zero bits in 15 in that case effectively act as a filter, forcing the bits in the result to be zero as well.</p>

<p>In addition, <code>&gt;&gt;</code> and <code>&lt;&lt;</code> are often included as bitwise operators, and they ""shift"" a value respectively right and left by a certain number of bits, throwing away bits that roll of the end you're shifting towards, and feeding in zero bits at the other end.</p>

<p>So, for example:</p>

<pre><code>1001 0101 &gt;&gt; 2 gives 0010 0101
1111 1111 &lt;&lt; 4 gives 1111 0000
</code></pre>

<p>Note that the left shift in Python is unusual in that it's not using a fixed width where bits are discarded - while many languages use a fixed width based on the data type, Python simply expands the width to cater for extra bits. In order to get the discarding behaviour in Python, you can follow a left shift with a bitwise <code>and</code> such as in an 8-bit value shifting left four bits:</p>

<pre><code>bits8 = (bits8 &lt;&lt; 4) &amp; 255
</code></pre>

<p>With that in mind, another example of bitwise operators is if you have two 4-bit values that you want to pack into an 8-bit one, you can use all three of your operators (<code>left-shift</code>, <code>and</code> and <code>or</code>):</p>

<pre><code>packed_val = ((val1 &amp; 15) &lt;&lt; 4) | (val2 &amp; 15)
</code></pre>

<ul>
<li>The <code>&amp; 15</code> operation will make sure that both values only have the lower 4 bits.</li>
<li>The <code>&lt;&lt; 4</code> is a 4-bit shift left to move <code>val1</code> into the top 4 bits of an 8-bit value.</li>
<li>The <code>|</code> simply combines these two together.</li>
</ul>

<p>If <code>val1</code> is 7 and <code>val2</code> is 4:</p>

<pre><code>                val1            val2
                ====            ====
 &amp; 15 (and)   xxxx-0111       xxxx-0100  &amp; 15
 &lt;&lt; 4 (left)  0111-0000           |
                  |               |
                  +-------+-------+
                          |
| (or)                0111-0100
</code></pre>
","1746642"
"How to convert 'binary string' to normal string in Python3?","96257","","<p>For example, I have a string like this(return value of <code>subprocess.check_output</code>):</p>

<pre><code>&gt;&gt;&gt; b'a string'
b'a string'
</code></pre>

<p>Whatever I did to it, it is always printed with the annoying <code>b'</code> before the string:</p>

<pre><code>&gt;&gt;&gt; print(b'a string')
b'a string'
&gt;&gt;&gt; print(str(b'a string'))
b'a string'
</code></pre>

<p>Does anyone have any ideas about how to use it as a normal string or convert it into a normal string? </p>
","<p>Decode it.</p>

<pre><code>&gt;&gt;&gt; b'a string'.decode('ascii')
'a string'
</code></pre>

<p>To get bytes from string, encode it.</p>

<pre><code>&gt;&gt;&gt; 'a string'.encode('ascii')
b'a string'
</code></pre>
","17615424"
"How to get 0-padded binary representation of an integer in java?","89601","","<p>for example, for <code>1, 2, 128, 256</code> the output can be (16 digits):</p>

<pre><code>0000000000000001
0000000000000010
0000000010000000
0000000100000000
</code></pre>

<p>I tried</p>

<pre><code>String.format(""%16s"", Integer.toBinaryString(1));
</code></pre>

<p>it puts spaces for left-padding:</p>

<pre><code>`               1'
</code></pre>

<p>How to put <code>0</code>s for padding. I couldn't find it in <a href=""http://download.oracle.com/javase/1.5.0/docs/api/java/util/Formatter.html#syntax"" rel=""noreferrer"">Formatter</a>. Is there another way to do it?</p>

<p>Thanks in advance.</p>

<p>P.S. <a href=""https://stackoverflow.com/questions/473282/left-padding-integers-with-zeros-in-java"">this post</a> describes how to format integers with left 0-padding, but it is not for the binary representation.</p>
","<p>I think this is a suboptimal solution, but you could do</p>

<pre><code>String.format(""%16s"", Integer.toBinaryString(1)).replace(' ', '0')
</code></pre>
","4421438"
"Reading integers from binary file in Python","88669","","<p>I'm trying to read a <a href=""http://en.wikipedia.org/wiki/BMP_file_format"" rel=""noreferrer"">BMP</a> file in Python. I know the first two bytes 
indicate the BMP firm. The next 4 bytes are the file size. When I excecute:</p>

<pre><code>fin = open(""hi.bmp"", ""rb"")
firm = fin.read(2)  
file_size = int(fin.read(4))  
</code></pre>

<p>I get </p>

<blockquote>
  <p>ValueError: invalid literal for int() with base 10: 'F#\x13'</p>
</blockquote>

<p>What I want to do is reading those four bytes as an integer... It seems Python is reading them as characters and returning a string, which cannot be converted to an integer. How can I do this correctly?  </p>
","<p>The <code>read</code> method returns a sequence of bytes as a string. To convert from a string byte-sequence to binary data, use the built-in <code>struct</code> module: <a href=""http://docs.python.org/library/struct.html"" rel=""noreferrer"">http://docs.python.org/library/struct.html</a>. </p>

<pre><code>import struct

print(struct.unpack('i', fin.read(4)))
</code></pre>

<p>Note that <code>unpack</code> always returns a tuple, so <code>struct.unpack('i', fin.read(4))[0]</code> gives the integer value that you are after.</p>

<p>You should probably use the format string <code>'&lt;i'</code> (&lt; is a modifier that indicates little-endian byte-order and standard size and alignment - the default is to use the platform's byte ordering, size and alignment). According to the BMP format spec, the bytes should be written in Intel/little-endian byte order.</p>
","1163508"
"Binary diff tool for very large files?","88052","","<p>I need a utility to diff two binary files. The files are large (6-50 GB).</p>

<blockquote>
  <p><strong>Note:</strong> It needs to be specifically pointed out here: most diff programs work by mapping the file into their virtual address space. On 32-bit Windows, this limits the sizes of files that can be compared to under 1 GB each. (1.5 GB if Windows is run with the /3GB switch, and the program has advertised that it is 3 GB aware; /LARGEADDRESSAWARE).
  If a program insists on the technique of mapping the file entirely into its address space, then it <em>must</em> be recompiled as a 64-bit application, which has an address space of 8 TB (which meets my requirements)</p>
</blockquote>

<p><a href=""http://en.wikipedia.org/wiki/Beyond_Compare"" rel=""noreferrer"">Beyond Compare</a> is my favorite diff tool, and I own it, but it cannot handle binary files over what can fit in the process's address space.</p>

<p>HexDiff 3.0 seemed interesting, except the trial version doesn't do diff's. </p>

<ul>
<li><p>the tool should be free, since I'm not paying money to figure out that it doesn't work.</p></li>
<li><p>the tool should be a Windows application.</p></li>
<li><p>the tool should not be console based (that is, a Windows application)</p></li>
<li><p>the tool should be graphical (that is, a Windows application)</p></li>
</ul>
","<p>You are looking for <a href=""http://mh-nexus.de/en/hxd/"" rel=""noreferrer"">HxD</a> the best and free Hex-Editor for Windows, no changes needed since April 3, 2009, as it is free of error, just perfect.</p>

<p>Its ""File compare (simple)"" (<kbd>Ctrl</kbd>+<kbd>K</kbd>) does it visual for any binary files.</p>

<ul>
<li>Instant opening regardless of file-size (Up to 8EB) 8 ExaByte are 8 million TeraByte.</li>
</ul>
","21405173"
"Compare two Byte Arrays? (Java)","87162","","<p>I have a byte array with a ~known binary sequence in it. I need to confirm that the binary sequence is what it's supposed to be. I have tried <code>.equals</code> in addition to <code>==</code>, but neither worked. </p>

<pre><code>byte[] array = new BigInteger(""1111000011110001"", 2).toByteArray();
if (new BigInteger(""1111000011110001"", 2).toByteArray() == array){
    System.out.println(""the same"");
} else {
    System.out.println(""different'"");
}
</code></pre>
","<p>In your example, you have:</p>

<pre><code>if (new BigInteger(""1111000011110001"", 2).toByteArray() == array)
</code></pre>

<p>When dealing with objects, <code>==</code> in java compares <em>reference values</em>. You're checking to see if the reference to the array returned by <code>toByteArray()</code> is the same as the reference held in <code>array</code>, which of course can never be true. In addition, array classes don't override <code>.equals()</code> so the behavior is that of <code>Object.equals()</code> which also only compares the reference values. </p>

<p>To compare the <em>contents</em> of two arrays, static array comparison methods are provided by the <a href=""http://docs.oracle.com/javase/7/docs/api/java/util/Arrays.html"" rel=""noreferrer"">Arrays class</a></p>

<pre><code>byte[] array = new BigInteger(""1111000011110001"", 2).toByteArray();
byte[] secondArray = new BigInteger(""1111000011110001"", 2).toByteArray();
if (Arrays.equals(array, secondArray))
{
    System.out.println(""Yup, they're the same!"");
}
</code></pre>
","5440060"
"How to convert float number to Binary?","86075","","<p>Can anyone please tell me how can I convert this float number: 12.25 to binary?
I know how to convert the ""12"" but not the 0.25</p>

<p>Any help is much appreciated.
Thanks</p>
","<p>Keep multiplying the number after decimal by 2 till it becomes 1.0:</p>

<pre><code>0.25*2 = 0.50
0.50*2 = 1.00
</code></pre>

<p>and the result is in reverse order being .01</p>
","3954640"
"How do you embed binary data in XML?","85658","","<p>I have two applications written in Java that communicate with each other using XML messages over the network.  I'm using a SAX parser at the receiving end to get the data back out of the messages.  One of the requirements is to embed binary data in an XML message, but SAX doesn't like this.  Does anyone know how to do this?</p>

<p>UPDATE:  I got this working with the <a href=""http://commons.apache.org/codec/apidocs/org/apache/commons/codec/binary/Base64.html"" rel=""noreferrer"">Base64</a> class from the <a href=""http://commons.apache.org/codec/"" rel=""noreferrer"">apache commons codec library</a>, in case anyone else is trying something similar.</p>
","<p>You could encode the binary data using base64 and put it into a Base64 element; the below article is a pretty good one on the subject.</p>

<p><a href=""http://www.xml.com/pub/a/98/07/binary/binary.html"" rel=""noreferrer"">Handling Binary Data in XML Documents</a></p>
","19904"
"How do you convert a fraction to binary?","79604","","<p><code>1/10(decimal) = 0.0001100110011... (binary)</code></p>

<p>How do I do that? Am I supposed to convert to binary and then divide? Could someone show me?</p>
","<p>In university I learned it this way:</p>

<ol>
<li>Multiply by two</li>
<li>take decimal as the digit</li>
<li>take the fraction as the starting point for the next step</li>
<li>repeat until you either get to 0 or a periodic number</li>
<li>read the number starting from the top - the first result is the first digit after the comma</li>
</ol>

<p>Example:</p>

<pre><code>0.1 * 2 = 0.2 -&gt; 0
0.2 * 2 = 0.4 -&gt; 0
0.4 * 2 = 0.8 -&gt; 0
0.8 * 2 = 1.6 -&gt; 1
0.6 * 2 = 1.2 -&gt; 1
0.2 * 2 = 0.4 -&gt; 0
0.4 * 2 = 0.8 -&gt; 0
0.8 * 2 = 1.6 -&gt; 1
0.6 * 2 = 1.2 -&gt; 1
Result: 0.00011(0011) periodic.
</code></pre>
","4987217"
"Print an int in binary representation using C","77657","","<p>I'm looking for a function to allow me to print the binary representation of an int. What I have so far is;</p>

<pre><code>char *int2bin(int a)
{
 char *str,*tmp;
 int cnt = 31;
 str = (char *) malloc(33); /*32 + 1 , because its a 32 bit bin number*/
 tmp = str;
 while ( cnt &gt; -1 ){
      str[cnt]= '0';
      cnt --;
 }
 cnt = 31;
 while (a &gt; 0){
       if (a%2==1){
           str[cnt] = '1';
        }
      cnt--;
        a = a/2 ;
 }
 return tmp;

}
</code></pre>

<p>But when I call</p>

<pre><code>printf(""a %s"",int2bin(aMask)) // aMask = 0xFF000000
</code></pre>

<p>I get output like;</p>

<blockquote>
  <p>0000000000000000000000000000000000xtpYy (And a bunch of unknown characters.</p>
</blockquote>

<p>Is it a flaw in the function or am I printing the address of the character array or something? Sorry, I just can't see where I'm going wrong.</p>

<p>NB The code is from <a href=""http://en.allexperts.com/q/C-1587/printing-binary.htm"" rel=""noreferrer"">here</a></p>

<p>EDIT: It's not homework FYI, I'm trying to debug someone else's image manipulation routines in an unfamiliar language. If however it's been tagged as homework because it's an elementary concept then fair play.</p>
","<p>Here's another option that is more optimized where you pass in your allocated buffer.  Make sure it's the correct size.</p>

<pre><code>// buffer must have length &gt;= sizeof(int) + 1
// Write to the buffer backwards so that the binary representation
// is in the correct order i.e.  the LSB is on the far right
// instead of the far left of the printed string
char *int2bin(int a, char *buffer, int buf_size) {
    buffer += (buf_size - 1);

    for (int i = 31; i &gt;= 0; i--) {
        *buffer-- = (a &amp; 1) + '0';

        a &gt;&gt;= 1;
    }

    return buffer;
}

#define BUF_SIZE 33

int main() {
    char buffer[BUF_SIZE];
    buffer[BUF_SIZE - 1] = '\0';

    int2bin(0xFF000000, buffer, BUF_SIZE - 1);

    printf(""a = %s"", buffer);
}
</code></pre>
","1024414"
"How do I convert from a decimal number to IEEE 754 single-precision floating-point format?","76689","","<p>How would I go about manually changing a decimal (base 10) number into IEEE 754 single-precision floating-point format? I understand that there is three parts to it, a sign, an exponent, and a mantissa. I just don't completely understand what the last two parts actually represent. </p>
","<p>Find the largest power of 2 which is smaller than your number, e.g if you start with x = 10.0 then 2<sup>3</sup> = 8, so the exponent is 3. The exponent is biased by 127 so this means the exponent will be represented as 127 + 3 = 130. The mantissa is then 10.0/8 = 1.25. The 1 is implicit so we just need to represent 0.25, which is 010 0000 0000 0000 0000 0000 when expressed as a 23 bit unsigned fractional quantity. The sign bit is 0 for positive. So we have:</p>

<pre><code>s | exp [130]  | mantissa [(1).25]            |

0 | 100 0001 0 | 010 0000 0000 0000 0000 0000 |

0x41200000
</code></pre>

<p>You can test the representation with a simple C program, e.g.</p>

<pre><code>#include &lt;stdio.h&gt;

typedef union
{
    int i;
    float f;
} U;

int main(void)
{
    U u;

    u.f = 10.0;

    printf(""%g = %#x\n"", u.f, u.i);

    return 0;
}
</code></pre>
","2405005"
"Difference between Binary release and source release?","74479","","<p>i have been seeing the words <strong>binary</strong> and <strong>source</strong> release in many websites download sections. What they actually mean? And i have seen this in <a href=""http://groovy.codehaus.org/Download"" rel=""noreferrer"">Groovy</a> download page. My question is how they differ? Both tend to install groovy! But whats the main difference? </p>
","<p>A source release will be compiled on your own machine while a binary release must match your operating system.</p>

<p>source releases are more common on linux systems because linux systems can dramatically vary in cpu, installed library versions, kernelversions and nearly every linux system has a compiler installed.</p>

<p>binary releases are common on ms-windows systems. most windows machines do not have a compiler installed.</p>
","5280925"
"String to Binary in C#","72003","","<p>I have a function to convert string to hex as this,</p>

<pre><code>public static string ConvertToHex(string asciiString)
{
    string hex = """";
    foreach (char c in asciiString)
    {
         int tmp = c;
         hex += String.Format(""{0:x2}"", (uint)System.Convert.ToUInt32(tmp.ToString()));
    }
    return hex;
}
</code></pre>

<p>Could you please help me write another string to Binary function based on my sample function? </p>

<pre><code>public static string ConvertToBin(string asciiString)
{
    string bin = """";
    foreach (char c in asciiString)
    {
        int tmp = c;
        bin += String.Format(""{0:x2}"", (uint)System.Convert.????(tmp.ToString()));
    }
    return bin;
}
</code></pre>
","<p>Here you go:</p>

<pre><code>public static byte[] ConvertToByteArray(string str, Encoding encoding)
{
    return encoding.GetBytes(str);
}

public static String ToBinary(Byte[] data)
{
    return string.Join("" "", data.Select(byt =&gt; Convert.ToString(byt, 2).PadLeft(8, '0')));
}

// Use any sort of encoding you like. 
var binaryString = ToBinary(ConvertToByteArray(""Welcome, World!"", Encoding.ASCII));
</code></pre>
","5664400"
"Bitwise operator for simply flipping all bits in an integer?","69341","","<p>I have to flip all bits in a binary representation of an integer. Given:</p>

<pre><code>10101
</code></pre>

<p>The output should be </p>

<pre><code>01010
</code></pre>

<p>What is the bitwise operator to accomplish this when used with an integer? For example, if I were writing a method like <code>int flipBits(int n);</code>, what would go in the body? I need to flip only what's already present in the number, not all 32 bits in the integer.</p>
","<p>The <code>~</code> unary operator is bitwise negation. If you need fewer bits than what fits in an <code>int</code> then you'll need to mask it with <code>&amp;</code> after the fact.</p>
","6351380"
"Convert to binary and keep leading zeros in Python","68713","","<p>I'm trying to convert an integer to binary using the bin() function in Python. However, it always removes the leading zeros, which I actually need, such that the result is always 8-bit:</p>

<p>Example:</p>

<pre><code>bin(1) -&gt; 0b1

# What I would like:
bin(1) -&gt; 0b00000001
</code></pre>

<p>Is there a way of doing this?</p>
","<p>Use the <a href=""http://docs.python.org/2/library/functions.html#format""><code>format()</code> function</a>:</p>

<pre><code>&gt;&gt;&gt; format(14, '#010b')
'0b00001110'
</code></pre>

<p>The <code>format()</code> function simply formats the input following the <a href=""http://docs.python.org/2/library/string.html#format-specification-mini-language"">Format Specification mini language</a>. The <code>#</code> makes the format include the <code>0b</code> prefix, and the <code>010</code> size formats the output to fit in 10 characters width, with <code>0</code> padding; 2 characters for the <code>0b</code> prefix, the other 8 for the binary digits.</p>

<p>This is the most compact and direct option.</p>

<p>If you are putting the result in a larger string, use <a href=""https://docs.python.org/2/library/stdtypes.html#str.format""><code>str.format()</code></a> and put the second argument for the <code>format()</code> function after the colon of the placeholder <code>{:..}</code>:</p>

<pre><code>&gt;&gt;&gt; 'The produced output, in binary, is: {:#010b}'.format(14)
'The produced output, in binary, is: 0b00001110'
</code></pre>

<p>If you did not want the <code>0b</code> prefix, simply drop the <code>#</code> and adjust the length of the field:</p>

<pre><code>&gt;&gt;&gt; format(14, '08b')
'00001110'
</code></pre>
","16926357"
"Convert hexadecimal string (hex) to a binary string","68569","","<p>I found the following way hex to binary conversion:</p>

<pre><code>String binAddr = Integer.toBinaryString(Integer.parseInt(hexAddr, 16)); 
</code></pre>

<p>While this approach works for small hex numbers, a hex number such as the following</p>

<pre><code>A14AA1DBDB818F9759
</code></pre>

<p>Throws a <code>NumberFormatException.</code> </p>

<p>I therefore wrote the following method that seems to work:</p>

<pre><code>private String hexToBin(String hex){
    String bin = """";
    String binFragment = """";
    int iHex;
    hex = hex.trim();
    hex = hex.replaceFirst(""0x"", """");

    for(int i = 0; i &lt; hex.length(); i++){
        iHex = Integer.parseInt(""""+hex.charAt(i),16);
        binFragment = Integer.toBinaryString(iHex);

        while(binFragment.length() &lt; 4){
            binFragment = ""0"" + binFragment;
        }
        bin += binFragment;
    }
    return bin;
}
</code></pre>

<p>The above method basically takes each character in the Hex string and converts it to its binary equivalent pads it with zeros if necessary then joins it to the return value. 
Is this a proper way of performing a conversion? Or am I overlooking something that may cause my approach to fail?</p>

<p>Thanks in advance for any assistance.</p>
","<p><a href=""http://docs.oracle.com/javase/7/docs/api/java/math/BigInteger.html#toString%28int%29"" rel=""noreferrer""><code>BigInteger.toString(radix)</code></a> will do what you want.  Just pass in a radix of 2.</p>

<pre><code>static String hexToBin(String s) {
  return new BigInteger(s, 16).toString(2);
}
</code></pre>
","9246349"
"Save and retrieve image (binary) from SQL Server using Entity Framework 6","68418","","<p>I am trying to save a bitmap image to database </p>

<pre><code>Bitmap map = new Bitmap(pictureBoxMetroMap.Size.Width, pictureBoxMetroMap.Size.Height);
</code></pre>

<p>I created a column <code>imgcontent</code> in the database with datatype <code>binary</code> but my problem is how can I convert this <code>bitmap</code> (map) to binary data?</p>

<p>And how can I retrieve data from database?</p>

<p>I googled it and I found something like this but it didn't work:</p>

<pre><code>byte[] arr;
ImageConverter converter = new ImageConverter();
arr = (byte[])converter.ConvertTo(map, typeof(byte[]));
</code></pre>
","<p>Convert the image to a <code>byte[]</code> and store that in the database.</p>

<hr>

<p>Add this column to your model:</p>

<pre><code>public byte[] Content { get; set; }
</code></pre>

<p>Then convert your image to a byte array and store that like you would any other data:</p>

<pre><code>public byte[] imageToByteArray(System.Drawing.Image imageIn)
{
    MemoryStream ms = new MemoryStream();
    imageIn.Save(ms, System.Drawing.Imaging.ImageFormat.Gif);
    return ms.ToArray();
}

public Image byteArrayToImage(byte[] byteArrayIn)
{
     MemoryStream ms = new MemoryStream(byteArrayIn);
     Image returnImage = Image.FromStream(ms);
     return returnImage;
}
</code></pre>

<p>Source: <a href=""https://stackoverflow.com/questions/17352061/fastest-way-to-convert-image-to-byte-array"">Fastest way to convert Image to Byte array</a></p>

<pre><code>var image = new ImageEntity(){
   Content = imageToByteArray(image)
}
_Context.Images.Add(image);
_Context.SaveChanges();
</code></pre>

<p>When you want to get the image back, get the byte array from the database and use the <code>byteArrayToImage</code> and do what you wish with the <code>Image</code></p>

<p>This stops working when the <code>byte[]</code> gets to big. It will work for files under 100Mb</p>
","25400976"
"Conversion of Char to Binary in C","67818","","<p>I am trying to convert a character to its binary representation (so character --> ascii hex --> binary).</p>

<p>I know to do that I need to shift and <code>AND</code>. However, my code is not working for some reason.</p>

<p>Here is what I have. <code>*temp</code> points to an index in a C string.</p>

<pre><code>char c;
int j;
for (j = i-1; j &gt;= ptrPos; j--) {
    char x = *temp;
    c = (x &gt;&gt; i) &amp; 1;
    printf(""%d\n"", c);
    temp--;
}
</code></pre>
","<p>We show up two functions that prints a SINGLE character to binary.</p>

<pre><code>void printbinchar(char character)
{
    char output[9];
    itoa(character, output, 2);
    printf(""%s\n"", output);
}
</code></pre>

<p>printbinchar(10) will write into the console</p>

<pre><code>    1010
</code></pre>

<p>itoa is a library function that converts a single integer value to a string with the specified base.
For example... itoa(1341, output, 10) will write in output string ""1341"".
And of course itoa(9, output, 2) will write in the output string ""1001"".</p>

<p>The next function will print into the standard output the full binary representation of a character, that is, it will print all 8 bits, also if the higher bits are zero.</p>

<pre><code>void printbincharpad(char c)
{
    for (int i = 7; i &gt;= 0; --i)
    {
        putchar( (c &amp; (1 &lt;&lt; i)) ? '1' : '0' );
    }
    putchar('\n');
}
</code></pre>

<p>printbincharpad(10) will write into the console</p>

<pre><code>    00001010
</code></pre>

<p>Now i present a function that prints out an entire string (without last null character).</p>

<pre><code>void printstringasbinary(char* s)
{
    // A small 9 characters buffer we use to perform the conversion
    char output[9];

    // Until the first character pointed by s is not a null character
    // that indicates end of string...
    while (*s)
    {
        // Convert the first character of the string to binary using itoa.
        // Characters in c are just 8 bit integers, at least, in noawdays computers.
        itoa(*s, output, 2);

        // print out our string and let's write a new line.
        puts(output);

        // we advance our string by one character,
        // If our original string was ""ABC"" now we are pointing at ""BC"".
        ++s;
    }
}
</code></pre>

<p>Consider however that itoa don't adds padding zeroes, so printstringasbinary(""AB1"") will print something like:</p>

<pre><code>1000001
1000010
110001
</code></pre>
","7863524"
"How to compile a linux shell script to be a standalone executable *binary* (i.e. not just e.g. chmod 755)?","67810","","<p>I'm looking for a free open source tool-set that will compile various ""classic"" scripting languages, e.g. Korn Shell, ksh, csh, bash etc. as an executable -- and if the script calls other programs or executables, for them to be included in the single executable.</p>

<p>Reasons:</p>

<ol>
<li><p>To obfuscate the code for delivery to a customer so as not to reveal our Intellectual Property - for delivery onto a <em>customer's</em> own machine/systems for which I have no control over what permissions I can set regarding access, so the program file has to be binary whereby the workings cannot be easily seen by viewing in a text editor or <code>hexdump</code> viewer.</p></li>
<li><p>To make a single, simply deployed program for the customer without/or a minimal amount of any external dependencies.</p></li>
</ol>

<p>I would prefer something simple without the need for package manager since:</p>

<ol>
<li><p>I can't rely on the customer's knowledge to carry out (un) packaging instructions and</p></li>
<li><p>I can't rely on the policies governing their machines regarding installing packages (and indeed from third parties). </p></li>
</ol>

<p>The simplest preferred approach is to be able to compile to proper machine code a single executable that will run out of the box without any dependencies.</p>
","<p>The solution that fully meets my needs would be SHC - a free tool, or CCsh a commercial tool. Both compile shell scripts to C, which then can be compiled using a C compiler.</p>

<p>Links about SHC:</p>

<ul>
<li><a href=""https://github.com/neurobin/shc"" rel=""nofollow noreferrer"">https://github.com/neurobin/shc</a></li>
<li><a href=""http://www.datsi.fi.upm.es/~frosal/"" rel=""nofollow noreferrer"">http://www.datsi.fi.upm.es/~frosal/</a></li>
<li><a href=""http://www.downloadplex.com/Linux/System-Utilities/Shell-Tools/Download-shc_70414.html"" rel=""nofollow noreferrer"">http://www.downloadplex.com/Linux/System-Utilities/Shell-Tools/Download-shc_70414.html</a></li>
</ul>

<p>Links about CCsh:</p>

<ul>
<li><a href=""http://www.comeaucomputing.com/faqs/ccshlit.html"" rel=""nofollow noreferrer"">http://www.comeaucomputing.com/faqs/ccshlit.html</a></li>
</ul>
","6438272"
"bad operand types for binary operator ""&"" java","65632","","<p>The error shows this line </p>

<pre><code> if ((a[0] &amp; 1 == 0) &amp;&amp; (a[1] &amp; 1== 0) &amp;&amp; (a[2] &amp; 1== 0)){
</code></pre>

<p>This is the whole code: </p>

<pre><code>public class Ex4 {

  public static void main(String[] args) {
  int [] a = new int [3];
  if(args.length == 3)
  {
      try{
        for(int i = 0; i &lt; args.length; i++)
        {
        a[i] = Integer.parseInt(args[i]);
        }
        }
        catch(NumberFormatException e){
            System.out.println(""Wrong Argument"");
       }
      if ((a[0] &amp; 1 == 0) &amp;&amp; (a[1] &amp; 1== 0) &amp;&amp; (a[2] &amp; 1== 0)){
        System.out.println(""yes"");
      }
    else {
        System.out.println(""no"");
    }
  }
  else{
      System.out.println(""Error"");
    }
}
}
</code></pre>

<p>I've fixed the code: </p>

<pre><code>if ((a[0] &amp; 1) == 0 &amp;&amp; (a[1] &amp; 1) == 0 &amp;&amp; (a[2] &amp; 1) == 0){
</code></pre>

<p>Was an issue with the brackets, updated for anyone in the future.</p>
","<p><code>==</code> has higher priority than <code>&amp;</code>. You might want to wrap your operations in <code>()</code> to specify your own priority.</p>

<pre><code>((a[0] &amp; 1) == 0)
</code></pre>

<p>Similarly for all parts of the <code>if</code> condition.</p>
","23095032"
"Python writing binary","65069","","<p>I use python 3
I tried to write binary to file I use r+b.</p>

<pre><code>for bit in binary:
    fileout.write(bit)
</code></pre>

<p>where binary is a list that contain numbers.
How do I write this to file in binary?</p>

<p>The end file have to look like 
b' x07\x08\x07\</p>

<p>Thanks</p>
","<p>When you open a file in binary mode, then you are essentially working with the <a href=""http://docs.python.org/3/library/stdtypes.html#bytes""><code>bytes</code></a> type. So when you write to the file, you need to pass a <code>bytes</code> object, and when you read from it, you get a <code>bytes</code> object. In contrast, when opening the file in text mode, you are working with <code>str</code> objects.</p>

<p>So, writing “binary” is really writing a bytes string:</p>

<pre><code>with open(fileName, 'br+') as f:
    f.write(b'\x07\x08\x07')
</code></pre>

<p>If you have actual integers you want to write as binary, you can use the <code>bytes</code> function to convert a sequence of integers into a bytes object:</p>

<pre><code>&gt;&gt;&gt; lst = [7, 8, 7]
&gt;&gt;&gt; bytes(lst)
b'\x07\x08\x07'
</code></pre>

<p>Combining this, you can write a sequence of integers as a bytes object into a file opened in binary mode.</p>

<hr>

<p>As Hyperboreus pointed out in the comments, <code>bytes</code> will only accept a sequence of numbers that actually fit in a byte, i.e. numbers between 0 and 255. If you want to store arbitrary (positive) integers in the way they are, without having to bother about knowing their exact size (which is required for struct), then you can easily write a helper function which splits those numbers up into separate bytes:</p>

<pre><code>def splitNumber (num):
    lst = []
    while num &gt; 0:
        lst.append(num &amp; 0xFF)
        num &gt;&gt;= 8
    return lst[::-1]

bytes(splitNumber(12345678901234567890))
# b'\xabT\xa9\x8c\xeb\x1f\n\xd2'
</code></pre>

<p>So if you have a list of numbers, you can easily iterate over them and write each into the file; if you want to extract the numbers individually later you probably want to add something that keeps track of which individual bytes belong to which numbers.</p>

<pre><code>with open(fileName, 'br+') as f:
    for number in numbers:
        f.write(bytes(splitNumber(number)))
</code></pre>
","20955678"
"In Java, can I define an integer constant in binary format?","64883","","<p>Similar to how you can define an integer constant in hexadecimal or octal, can I do it in binary?</p>

<p>I admit this is a really easy (and stupid) question.  My google searches are coming up empty.</p>
","<p>So, with the release of Java SE 7, binary notation comes standard out of the box. The syntax is quite straight forward and obvious if you have a decent understanding of binary:</p>

<pre><code>byte fourTimesThree = 0b1100;
byte data = 0b0000110011;
short number = 0b111111111111111; 
int overflow = 0b10101010101010101010101010101011;
long bow = 0b101010101010101010101010101010111L;
</code></pre>

<p>And specifically on the point of declaring class level variables as binaries, there's absolutely no problem initializing a static variable using binary notation either:</p>

<pre><code>public static final int thingy = 0b0101;
</code></pre>

<p>Just be careful not to overflow the numbers with too much data, or else you'll get a compiler error:</p>

<pre><code>byte data = 0b1100110011; // Type mismatch: cannot convert from int to byte
</code></pre>

<p>Now, if you really want to get fancy, you can combine that other neat new feature in Java 7 known as numeric literals with underscores. Take a look at these fancy examples of binary notation with literal underscores:</p>

<pre><code>int overflow = 0b1010_1010_1010_1010_1010_1010_1010_1011;
long bow = 0b1__01010101__01010101__01010101__01010111L;
</code></pre>

<p>Now isn't that nice and clean, not to mention highly readable?</p>

<p>I pulled these code snippets from a little article I wrote about the topic over at TheServerSide. Feel free to check it out for more details:</p>

<p><a href=""http://www.theserverside.com/tutorial/Java-7-and-Binary-Notation"">Java 7 and Binary Notation: Mastering the OCP Java Programmer (OCPJP) Exam</a></p>
","8569929"
"Why prefer two's complement over sign-and-magnitude for signed numbers?","64441","","<p>I'm just curious if there's a reason why in order to represent -1 in binary, two's complement is used: flipping the bits and adding 1?</p>

<p>-1 is represented by 11111111 (two's complement) rather than (to me more intuitive) 10000001 which is binary 1 with first bit as negative flag.</p>

<p>Disclaimer: I don't rely on binary arithmetic for my job!</p>
","<p>It's done so that addition doesn't need to have any special logic for dealing with negative numbers. Check out <a href=""http://en.wikipedia.org/wiki/Two&#39;s_complement"" rel=""noreferrer"">the article on Wikipedia</a>.</p>

<p>Say you have two numbers, 2 and -1. In your ""intuitive"" way of representing numbers, they would be <code>0010</code> and <code>1001</code>, respectively (I'm sticking to 4 bits for size). In the two's complement way, they are <code>0010</code> and <code>1111</code>. Now, let's say I want to add them.</p>

<p>Two's complement addition is very simple. You add numbers normally and any carry bit at the end is discarded. So they're added as follows:</p>

<pre><code>  0010
+ 1111
=10001
= 0001 (discard the carry)
</code></pre>

<p><code>0001</code> is 1, which is the expected result of ""2+(-1)"" to be.</p>

<p>But in your ""intuitive"" method, adding is more complicated:</p>

<pre><code>  0010
+ 1001
= 1011
</code></pre>

<p>Which is -3, right? Simple addition doesn't work in this case. You need to note that one of the numbers is negative and use a different algorithm if that's the case.</p>

<p>For this ""intuitive"" storage method, subtraction is a different operation than addition, requiring additional checks on the numbers before they can be added. Since you want the most basic operations (addition, subtraction, etc) to be as fast as possible, you need to store numbers in a way that lets you use the simplest algorithms possible.</p>

<p>Additionally, in the ""intuitive"" storage method, there are two zeroes:</p>

<pre><code>0000  ""zero""
1000  ""negative zero""
</code></pre>

<p>Which are intuitively the same number but have two different values when stored. Every application will need to take extra steps to make sure that non-zero values are also not negative zero.</p>

<p>There's another bonus with storing ints this way, and that's when you need to extend the width of the register the value is being stored in. With two's complement, storing a 4-bit number in an 8-bit register is a matter of repeating its most significant bit:</p>

<pre><code>    0001 (one, in four bits)
00000001 (one, in eight bits)
    1110 (negative two, in four bits)
11111110 (negative two, in eight bits)
</code></pre>

<p>It's just a matter of looking at the sign bit of the smaller word and repeating it until it pads the width of the bigger word.</p>

<p>With your method you would need to clear the existing bit, which is an extra operation in addition to padding:</p>

<pre><code>    0001 (one, in four bits)
00000001 (one, in eight bits)
    1010 (negative two, in four bits)
10000010 (negative two, in eight bits)
</code></pre>

<p>You still need to set those extra 4 bits in both cases, but in the ""intuitive"" case you need to clear the 5th bit as well. It's one tiny extra step in one of the most fundamental and common operations present in every application.</p>
","1125317"
"Converting an integer to binary in C","61908","","<p>I'm trying to convert an integer 10 into the binary number 1010. </p>

<p>This code attempts it, but I get a segfault on the strcat():</p>

<pre><code>int int_to_bin(int k)
{
   char *bin;

   bin = (char *)malloc(sizeof(char));
   while(k&gt;0) {
      strcat(bin, k%2);
      k = k/2;
      bin = (char *)realloc(bin, sizeof(char) * (sizeof(bin)+1));
   }
   bin[sizeof(bin)-1] = '\0';

   return atoi(bin);
}
</code></pre>

<p>How do I convert an integer to binary in C?</p>
","<p>If you want to transform a number into another number (not number to string of characters), and you can do with a small range (0 to 1023 for implementations with 32-bit integers), you don't need to add <code>char*</code> to the solution</p>

<pre><code>unsigned int_to_int(unsigned k) {
    if (k == 0) return 0;
    if (k == 1) return 1;                       /* optional */
    return (k % 2) + 10 * int_to_int(k / 2);
}
</code></pre>

<p><a href=""https://stackoverflow.com/users/3543287/halosghost"">HalosGhost</a> suggested to compact the code into a single line</p>

<pre><code>unsigned int int_to_int(unsigned int k) {
    return (k == 0 || k == 1 ? k : ((k % 2) + 10 * int_to_int(k / 2)));
}
</code></pre>
","5488546"
"Convert from BitArray to Byte","59686","","<p>I have a <a href=""https://msdn.microsoft.com/en-us/library/system.collections.bitarray(v=vs.110).aspx"" rel=""noreferrer""><code>BitArray</code></a> with the length of 8, and I need a function to convert it to a <code>byte</code>. How to do it?</p>

<p>Specifically, I need a correct function of <code>ConvertToByte</code>:</p>

<pre><code>BitArray bit = new BitArray(new bool[]
{
    false, false, false, false,
    false, false, false, true
});

//How to write ConvertToByte
byte myByte = ConvertToByte(bit);
var recoveredBit = new BitArray(new[] { myByte });
Assert.AreEqual(bit, recoveredBit);
</code></pre>
","<p>This should work:</p>

<pre><code>byte ConvertToByte(BitArray bits)
{
    if (bits.Count != 8)
    {
        throw new ArgumentException(""bits"");
    }
    byte[] bytes = new byte[1];
    bits.CopyTo(bytes, 0);
    return bytes[0];
}
</code></pre>
","560131"
"What is an application binary interface (ABI)?","58214","","<p>I never clearly understood what an ABI is. Please don't point me to a Wikipedia article. If I could understand it, I wouldn't be here posting such a lengthy post.</p>

<p>This is my mindset about different interfaces:</p>

<p>A TV remote is an interface between the user and the TV. It is an existing entity, but useless (doesn't provide any functionality) by itself. All the functionality for each of those buttons on the remote is implemented in the television set.</p>

<blockquote>
  <p><strong>Interface:</strong> It is an ""existing entity"" layer between the
  <code>functionality</code> and <code>consumer</code> of that
  functionality. An interface by itself
  is doesn't do anything. It just
  invokes the functionality lying
  behind.</p>
  
  <p>Now depending on who the user is there
  are different type of interfaces.</p>
  
  <p><strong>Command Line Interface (CLI)</strong> commands are the existing entities,
  the consumer is the user and functionality
  lies behind.</p>
  
  <p><code>functionality:</code> my software
  functionality which solves some
  purpose to which we are describing
  this interface.</p>
  
  <p><code>existing entities:</code> commands</p>
  
  <p><code>consumer:</code> user</p>
  
  <p><strong>Graphical User Interface(GUI)</strong> window, buttons, etc. are the existing
  entities, and again the consumer is the user
  and functionality lies behind.</p>
  
  <p><code>functionality:</code> my software
  functionality which solves some
  purpose to which we are describing
  this interface.</p>
  
  <p><code>existing entities:</code> window,buttons
  etc..</p>
  
  <p><code>consumer:</code> user</p>
  
  <p><strong>Application Programming Interface(API)</strong> functions or to be
  more correct, interfaces (in
  interfaced based programming) are the
  existing entities, consumer here is
  another program not a user, and again
  functionality lies behind this layer.</p>
  
  <p><code>functionality:</code> my software
  functionality which solves some
  purpose to which we are describing
  this interface.</p>
  
  <p><code>existing entities:</code> functions,
  Interfaces(array of functions).</p>
  
  <p><code>consumer:</code> another
  program/application.</p>
  
  <p><strong>Application Binary Interface (ABI)</strong> Here is where my problem starts.</p>
  
  <p><code>functionality:</code> ???</p>
  
  <p><code>existing entities:</code> ???</p>
  
  <p><code>consumer:</code> ???</p>
</blockquote>

<ul>
<li>I've written software in different languages and provided different kind of interfaces (CLI, GUI, and API), but I'm not sure, if I ever, provided any ABI.</li>
</ul>

<p><a href=""http://en.wikipedia.org/wiki/Application_binary_interface"" rel=""noreferrer"">Wikipedia says:</a></p>

<blockquote>
  <p>ABIs cover details such as</p>
  
  <ul>
  <li>data type, size, and alignment;</li>
  <li>the calling convention, which controls how functions' arguments are
  passed and return values retrieved;</li>
  <li>the system call numbers and how an application should make system calls
  to the operating system;</li>
  </ul>
  
  <p>Other ABIs standardize details such as</p>
  
  <ul>
  <li>the C++ name mangling,</li>
  <li>exception propagation, and</li>
  <li>calling convention between compilers on the same platform, but do
  not require cross-platform
  compatibility.</li>
  </ul>
</blockquote>

<ul>
<li><p>Who needs these details? Please don't say the OS. I know assembly programming. I know how linking &amp; loading works. I know what exactly happens inside.</p></li>
<li><p>Why did C++ name mangling come in? I thought we are talking at the binary level. Why do languages come in?</p></li>
</ul>

<p>Anyway, I've downloaded the <a href=""http://www.sco.com/developers/devspecs/gabi41.pdf"" rel=""noreferrer"">[PDF] System V Application Binary Interface <em>Edition 4.1 (1997-03-18)</em></a> to see what exactly it contains. Well, most of it didn't make any sense.</p>

<ul>
<li><p>Why does it contain two chapters (4th &amp; 5th) to describe the <a href=""http://en.wikipedia.org/wiki/Executable_and_Linkable_Format"" rel=""noreferrer"">ELF</a> file format? In fact, these are the only two significant chapters of that specification. The rest of the chapters are ""processor specific"". Anyway, I thought that it is a completely different topic. Please don't say that ELF file format specifications <em>are</em> the ABI. It doesn't qualify to be an <em>interface</em> according to the definition.</p></li>
<li><p>I know, since we are talking at such a low level it must be very specific. But I'm not sure how is it ""instruction set architecture (ISA)"" specific?</p></li>
<li><p>Where can I find Microsoft Windows' ABI?</p></li>
</ul>

<p>So, these are the major queries that are bugging me.</p>
","<p>One easy way to understand ""ABI"" is to compare it to ""API"".</p>

<p>You are already familiar with the concept of an API.  If you want to use the features of, say, some library or your OS, you will use an API.  The API consists of data types/structures, constants, functions, etc that you can use in your code to access the functionality of that external component.</p>

<p>An ABI is very similar.  Think of it as the compiled version of an API (or as an API on the machine-language level).  When you write source code, you access the library though an API.  Once the code is compiled, your application accesses the binary data in the library through the ABI.  The ABI defines the structures and methods that your compiled application will use to access the external library (just like the API did), only on a lower level.</p>

<p>ABIs are important when it comes to applications that use external libraries.  If a program is built to use a particular library and that library is later updated, you don't want to have to re-compile that application (and from the end-user's standpoint, you may not have the source).  If the updated library uses the same ABI, then your program will not need to change.  The interface to the library (which is all your program really cares about) is the same even though the internal workings may have changed.  Two versions of a library that have the same ABI are sometimes called ""binary-compatible"" since they have the same low-level interface (you should be able to replace the old version with the new one and not have any major problems).</p>

<p>Sometimes, ABI changes are unavoidable.  When this happens, any programs that use that library will not work unless they are re-compiled to use the new version of the library.  If the ABI changes but the API does not, then the old and new library versions are sometimes called ""source compatible"".  This implies that while a program compiled for one library version will not work with the other, source code written for one will work for the other if re-compiled.</p>

<p>For this reason, library writers tend to try to keep their ABI stable (to minimize disruption).  Keeping an ABI stable means not changing function interfaces (return type and number, types, and order of arguments), definitions of data types or data structures, defined constants, etc.  New functions and data types can be added, but existing ones must stay the same.  If you expand, say, a 16-bit data structure field into a 32-bit field, then already-compiled code that uses that data structure will not be accessing that field (or any following it) correctly.  Accessing data structure members gets converted into memory addresses and offsets during compilation and if the data structure changes, then these offsets will not point to what the code is expecting them to point to and the results are unpredictable at best.</p>

<p>An ABI isn't necessarily something you will explicitly provide unless you are expecting people to interface with your code using assembly.  It isn't language-specific either, since (for example) a C application and a Pascal application will use the same ABI after they are compiled.</p>

<p><strong>Edit:</strong> Regarding your question about the chapters regarding the ELF file format in the SysV ABI docs:  The reason this information is included is because the ELF format defines the interface between operating system and application.  When you tell the OS to run a program, it expects the program to be formatted in a certain way and (for example) expects the first section of the binary to be an ELF header containing certain information at specific memory offsets.  This is how the application communicates important information about itself to the operating system.  If you build a program in a non-ELF binary format (such as a.out or PE), then an OS that expects ELF-formatted applications will not be able to interpret the binary file or run the application.  This is one big reason why Windows apps cannot be run directly on a Linux machine (or vice versa) without being either re-compiled or run inside some type of emulation layer that can translate from one binary format to another.</p>

<p>IIRC, Windows currently uses the <a href=""http://en.wikipedia.org/wiki/Portable_Executable"" rel=""noreferrer"">Portable Executable</a> (or, PE) format.  There are links in the ""external links"" section of that Wikipedia page with more information about the PE format.</p>

<p>Also, regarding your note about C++ name mangling:  The ABI can define a ""standardized"" way for a C++ compiler to do name mangling for the purpose of compatibility.  That is, if I create a library and you develop a program that uses the library, you should be able to use a different compiler than I did and not have to worry about the resulting binaries being incompatible due to different name mangling schemes.  This is really only of use if you are defining a new binary file format or writing a compiler or linker.</p>
","2456882"
"How to convert text to binary code in JavaScript?","57160","","<h1>Text to Binary Code</h1>

<p><strong>I want JavaScript to translate text in a textarea into binary code.</strong></p>

<p>For example, if a user types in ""<code>TEST</code>"" into the textarea, the value ""<code>01010100 01000101 01010011 01010100</code>"" should be returned.</p>

<p>I would like to avoid using a switch statement to assign each character a binary code value (e.g. <code>case ""T"": return ""01010100</code>) or any other similar technique. </p>

<p>Here's a <a href=""http://jsfiddle.net/fA24Y/"">JSFiddle</a> to show what I mean. Is this possible in native JavaScript?</p>
","<p>What you should do is convert every char using <code>charCodeAt</code> function to get the Ascii Code in decimal. Then you can convert it to Binary value using <code>toString(2)</code>:</p>

<p>HTML:</p>

<pre><code>&lt;input id=""ti1"" value =""TEST""/&gt;
&lt;input id=""ti2""/&gt;
&lt;button onClick=""convert();""&gt;Convert!&lt;/button&gt;
</code></pre>

<p>JS:</p>

<pre><code>function convert() {
  var output = document.getElementById(""ti2"");
  var input = document.getElementById(""ti1"").value;
  output.value = """";
  for (var i = 0; i &lt; input.length; i++) {
      output.value += input[i].charCodeAt(0).toString(2) + "" "";
  }
}
</code></pre>

<p>And here's a fiddle: <a href=""http://jsfiddle.net/fA24Y/1/"" rel=""noreferrer"">http://jsfiddle.net/fA24Y/1/</a></p>
","14430733"
"Decimal to Binary","57057","","<p>I have a number that I would like to convert to binary (from decimal) in C.</p>

<p>I would like my binary to always be in 5 bits (the decimal will never exceed 31). I already have a function that does it manually by dividing but that is hard to pad it to 5 bits.</p>

<p>Is there any easier way? Perhaps using bitwise shift?</p>

<p>I would also like the binary to be represented in a <code>char *</code></p>
","<p>Here's an elegant solution:</p>

<pre><code>void getBin(int num, char *str)
{
  *(str+5) = '\0';
  int mask = 0x10 &lt;&lt; 1;
  while(mask &gt;&gt;= 1)
    *str++ = !!(mask &amp; num) + '0';
}
</code></pre>

<p>Here, we start by making sure the string ends in a null character.  Then, we create a mask with a single one in it (its the mask you would expect, shifted to the left once to account for the shift in the first run of the while conditional).  Each time through the loop, the mask is shifted one place to the right, and then the corresponding character is set to either a '1' or a '0' (the <code>!!</code> ensure that we are adding either a 0 or a 1 to <code>'0'</code>).  Finally, when the 1 in the mask is shifted out of the number, the while loop ends.</p>

<p>To test it, use the following:</p>

<pre><code>int main()
{
  char str[6];
  getBin(10, str);
  printf(""%s\n"", str);
  return 0;
}
</code></pre>
","7911777"
"Advantage of 2's complement over 1's complement?","55456","","<p>What is the advantage of 2's complement over 1's compliment in negative number representation in binary number system? How does it affect the range of values stored in a certain bit representation of number in binary system?</p>
","<p>The primary advantage of two's complement over one's complement is that two's complement only has one value for zero. One's complement has a ""positive"" zero and a ""negative"" zero.</p>

<p>Next, to add numbers using one's complement you have to first do binary addition, then add in an end-around carry value.</p>

<p>Two's complement has only one value for zero, and doesn't require carry values.</p>

<p>You also asked how the range of values stored are affected. Consider an eight-bit integer value, the following are your minimum and maximum values:</p>

<pre><code>Notation     Min   Max
==========  ====  ====
Unsigned:      0   255
One's Comp: -127  +127
Two's Comp: -128  +127
</code></pre>

<p>References:</p>

<ul>
<li><a href=""http://en.wikipedia.org/wiki/Signed_number_representations"" rel=""noreferrer"">http://en.wikipedia.org/wiki/Signed_number_representations</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Ones%27_complement"" rel=""noreferrer"">http://en.wikipedia.org/wiki/Ones%27_complement</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Two%27s_complement"" rel=""noreferrer"">http://en.wikipedia.org/wiki/Two%27s_complement</a></li>
</ul>
","11054367"
"How to append binary data to a buffer in node.js","54930","","<p><strong>LAST UPDATE</strong></p>

<p>Use <a href=""http://nodejs.org/api/buffer.html#buffer_class_method_buffer_concat_list_totallength"" rel=""noreferrer"">concat</a>.</p>

<p><strong>EDIT</strong></p>

<p>I've written a <a href=""https://github.com/Gagle/Node-BufferedWriter"" rel=""noreferrer"">BufferedWriter</a> that writes bytes to a file using internal buffers. Same as <a href=""https://github.com/Gagle/Node-BufferedReader"" rel=""noreferrer"">BufferedReader</a> but for writing.</p>

<p>A quick example:</p>

<pre><code>//The BufferedWriter truncates the file because append == false
new BufferedWriter (""file"")
    .on (""error"", function (error){
        console.log (error);
    })

    //From the beginning of the file:
    .write ([0x00, 0x01, 0x02], 0, 3) //Writes 0x00, 0x01, 0x02
    .write (new Buffer ([0x03, 0x04]), 1, 1) //Writes 0x04
    .write (0x05) //Writes 0x05
    .close (); //Closes the writer. A flush is implicitly done.

//The BufferedWriter appends content to the end of the file because append == true
new BufferedWriter (""file"", true)
    .on (""error"", function (error){
        console.log (error);
    })

    //From the end of the file:
    .write (0xFF) //Writes 0xFF
    .close (); //Closes the writer. A flush is implicitly done.

//The file contains: 0x00, 0x01, 0x02, 0x04, 0x05, 0xFF
</code></pre>

<hr>

<p><strong>ORIGINAL QUESTION</strong></p>

<p>I have a buffer with some binary data:</p>

<pre><code>var b = new Buffer ([0x00, 0x01, 0x02]);
</code></pre>

<p>and I want to append <code>0x03</code>.</p>

<p>How can I append more binary data? I'm searching in the documentation but for appending data it must be a string, if not, an error occurs (<em>TypeError: Argument must be a string</em>):</p>

<pre><code>var b = new Buffer (256);
b.write (""hola"");
console.log (b.toString (""utf8"", 0, 4)); //hola
b.write ("", adios"", 4);
console.log (b.toString (""utf8"", 0, 11)); //hola, adios
</code></pre>

<p>Then, the only solution I can see here is to create a new buffer for every appended binary data and copy it to the major buffer with the correct offset:</p>

<pre><code>var b = new Buffer (4); //4 for having a nice printed buffer, but the size will be 16KB
new Buffer ([0x00, 0x01, 0x02]).copy (b);
console.log (b); //&lt;Buffer 00 01 02 00&gt;
new Buffer ([0x03]).copy (b, 3);
console.log (b); //&lt;Buffer 00 01 02 03&gt;
</code></pre>

<p>But this seems a bit inefficient because I have to instantiate a new buffer for every append.</p>

<p>Do you know a better way for appending binary data?</p>
","<h2>Updated Answer for Node.js ~>0.8</h2>

<p>Node is able to <a href=""http://nodejs.org/api/buffer.html#buffer_class_method_buffer_concat_list_totallength"" rel=""noreferrer"">concatenate buffers</a> on its own now.</p>

<pre><code>var newBuffer = Buffer.concat([buffer1, buffer2]);
</code></pre>

<h2>Old Answer for Node.js ~0.6</h2>

<p>I use a module to add a <code>.concat</code> function, among others:</p>

<p><a href=""https://github.com/coolaj86/node-bufferjs"" rel=""noreferrer"">https://github.com/coolaj86/node-bufferjs</a></p>

<p>I know it isn't a ""pure"" solution, but it works very well for my purposes.</p>
","10356183"
"Read and write from/to a binary file in Matlab","54368","","<p>My knowledge of matlab is merely on a need to know basis, so this is probably an elementary question. Nevertheless here it comes:</p>

<p>I have got a file containing data (16-bit integers) stored in binary format. How do I read it into a vector /an array in matlab? How do I write this data to a file in matlab? Is there any smart tweak to increase the performance speed when reading/writing a huge amount of data (gigabytes)?</p>
","<p>As <a href=""https://stackoverflow.com/questions/205735/read-and-write-fromto-a-binary-file-in-matlab#205819"">Bill the Lizard</a> wrote you can use fread to load the data into a vector.  I just want to expand a little on his answer.  </p>

<h3>Reading Data</h3>

<pre><code>&gt;&gt; fid=fopen('data.bin','rb') % opens the file for reading
&gt;&gt; A = fread(fid, count, 'int16') % reads _count_ elements and stores them in A.
</code></pre>

<p>The commands <em>fopen</em> and <em>fread</em> default to Little-endian[1] encoding for the integers.  If your file is Big-endian encoded you will need to change the <em>fread</em> to</p>

<pre><code>&gt;&gt; A = fread(fid, count, 'int16', 'ieee-be');
</code></pre>

<p>Also, if you want to read the whole file set </p>

<pre><code>&gt;&gt; count=inf;
</code></pre>

<p>and if you want to read the data into matrix with <em>n</em> columns use</p>

<pre><code>&gt;&gt; count=[n inf];
</code></pre>

<h3>Writing Data</h3>

<p>As for witting the data to a file.  The command, <em>fwrite</em>, in <a href=""https://stackoverflow.com/questions/205735/read-and-write-fromto-a-binary-file-in-matlab#205819"">Bill's</a> answer will write to a binary file.  If you want to write the data to a text file you can use <em>dlmwrite</em></p>

<pre><code>&gt;&gt; dlmwrite('data.csv',A,',');
</code></pre>

<h3>References</h3>

<p>[1] <a href=""http://en.wikipedia.org/wiki/Endianness"" rel=""nofollow noreferrer"">http://en.wikipedia.org/wiki/Endianness</a></p>

<h3>Update</h3>

<ol>
<li><p>The machine format (IE, <em>ieee-be</em>,
<em>ieee-le</em>, <em>vaxd</em> etc.) of the binary data can be specified in either the
<em>fopen</em> or the <em>fread</em> commands in Matlab.  Details of the supported
machine format can be found in
Matlab's documentation of <em>fopen</em>.  </p></li>
<li><p><a href=""https://stackoverflow.com/users/4928/scott-french"">Scott French's</a> comment to <a href=""https://stackoverflow.com/questions/205735/read-and-write-fromto-a-binary-file-in-matlab#205819"">Bill's
answer</a>
suggests reading the data into an
int16 variable.  To do this use</p>

<pre><code>&gt;&gt; A = int16(fread(fid,count,precision,machineFormat));
</code></pre>

<p>where <em>count</em> is the size/shape of
the data to be read, <em>precision</em> is
the data format, and <em>machineformat</em>
is the encoding of each byte.</p></li>
<li><p>See commands <em>fseek</em> to move around the file.  For example, </p>

<pre><code>&gt;&gt; fseek(fid,0,'bof');
</code></pre>

<p>will rewind the file to the beginning where <em>bof</em> stands for <em>beginning of file</em>.</p></li>
</ol>
","206199"
"How are integers internally represented at a bit level in Java?","54056","","<p>I am trying to understand how Java stores integer internally. I know all java primitive integers are signed, (except short?). That means one less bit available in a byte for the number.</p>

<p>My question is, are all integers (positive and negative) stored as two's complement or are only negative numbers in two's complement?</p>

<p>I see that the specs says <code>x bit two's complement number</code>. But I often get confused.</p>

<p>For instance:</p>

<pre><code>  int x = 15; // Stored as binary as is?  00000000 00000000 00000000 00001111?
  int y = -22; // Stored as two complemented value? 11111111 11111111 11111111 11101010
</code></pre>

<p><strong>Edit</strong></p>

<p>To be clear, <code>x = 15</code> </p>

<pre><code>   In binary as is: `00000000 00000000 00000000 00001111'
  Two's complement: `11111111 11111111 11111111 11110001`
</code></pre>

<p>So if your answer is  <code>all</code> numbers are stored as two's complement then:</p>

<pre><code>  int x = 15; // 11111111 11111111 11111111 11110001
  int y = -22 // 11111111 11111111 11111111 11101010
</code></pre>

<p>The confusion here again is the sign says, both are negative numbers. May be I am misreading / misunderstanding it?</p>

<p><strong>Edit</strong>
Not sure my question is confusing. Forced to isolate the question:</p>

<p><strong>My question precisely: Are positive numbers stored in <code>binary as is</code> while negative numbers are stored as <code>two's complement</code>?</strong></p>

<p>Some said all are stored in two's complement and one answer says only negative numbers are stored as two's complement.</p>
","<p>Lets start by summarizing Java primitive data types:</p>

<p><strong>byte</strong>: Byte data type is a 8-bit signed <strong>two's complement integer</strong>.</p>

<p><strong>Short</strong>: Short data type is a 16-bit signed <strong>two's complement integer</strong>.</p>

<p><strong>int:</strong> Int data type is a 32-bit signed <strong>two's complement integer</strong>.</p>

<p><strong>long:</strong> Long data type is a 64-bit signed <strong>two's complement integer</strong>.</p>

<p><strong>float:</strong> Float data type is a single-precision <strong>32-bit IEEE 754 floating point</strong>.</p>

<p><strong>double</strong>: double data type is a double-precision <strong>64-bit IEEE 754 floating point</strong>.</p>

<p><strong>boolean:</strong> boolean data type represents <strong>one bit of information</strong>.</p>

<p><strong>char:</strong> char data type is a <strong>single 16-bit Unicode character</strong>.</p>

<p><a href=""http://www.tutorialspoint.com/java/java_basic_datatypes.htm"" rel=""noreferrer"">Source</a></p>

<p><strong>Two's complement</strong></p>

<p>""The good example is  from <a href=""http://en.wikipedia.org/wiki/Two%27s_complement"" rel=""noreferrer"">wiki</a> that the relationship to two's complement is realized by noting that 256 = 255 + 1, and (255 − x) is the ones' complement of x</p>

<p>0000 0111=7 two's complement is 1111 1001= -7</p>

<p>the way it works is  the msb(most significant bit) receives a negative value so in the case above</p>

<blockquote>
  <p>-7 = 1001= -8 + 0+ 0+ 1 </p>
</blockquote>

<p>Positive integers are generally stored as simple binary numbers (1 is 1, 10 is 2, 11 is 3 and so on). </p>

<p>Negative integers are stored as the two's complement of their absolute value. The two's complement of a positive number is, when using this notation, a negative number.</p>

<p><a href=""https://stackoverflow.com/questions/794062/is-twos-complement-notation-of-a-positive-number-the-same-number"">Source</a></p>

<p>Since I received a few points for this answer, I decided to add it more information.</p>

<h2><strong>A more detailed answer:</strong></h2>

<p>Among other there are four main approaches to represent positive and negative numbers in binary, namely:</p>

<ol>
<li>Signed Magnitude</li>
<li>One's Complement</li>
<li>Two's Complement</li>
<li>Bias</li>
</ol>

<p><strong>1. Signed Magnitude</strong></p>

<p>Uses the most significant bit to represent the sign, the remaining bits are used to represent the absolute value. Where <strong>0</strong> represents a <strong>positive number</strong> and <strong>1</strong> represents a <strong>negative number</strong>, example:</p>

<pre><code>1011 = -3
0011 = +3
</code></pre>

<p>This representation is simpler. However, you cannot add binary numbers in the same way that you add decimal numbers, making it harder to be implemented at the hardware level. Moreover, this approach uses two binary patterns to represent the 0, 100...0 and 0....0.   </p>

<p><strong>2. One's Complement</strong></p>

<p>In this representation, we invert all the bits of a given number to find out its complementary. For exemple:</p>

<pre><code>010 = 2, so -2 = 101 (inverting all bits).
</code></pre>

<p>The problem of this representation is that there still exist two bits patterns to represent the 0 (00..0 and 11..1)</p>

<p><strong>3. Two's Complement</strong></p>

<p>To find the negative of a number, in this representation, we invert all the bits and then add one bit. Adding one bit solves the problem of having two bits patterns representing 0. In this representation we only have one (00...0). </p>

<p>For exemple, we want to find the binary negative representation of 4 (decimal) using 4 bits. First we convert 4 to binary:</p>

<pre><code>4 = 0100
</code></pre>

<p>then we invert all the bits</p>

<pre><code>0100 -&gt; 1011
</code></pre>

<p>finally we add one bit</p>

<pre><code>1011 + 1 = 1100.
</code></pre>

<p>So 1100 is equivalent to -4 in decimal, if we are using a Two's Complement binary representation with 4 bits.</p>

<p>A faster way of find the complementary is by fixing the first bit that as value 1 and inverting the remaining bits. In the above example it would be something like:</p>

<pre><code>0100 -&gt; 1100
^^ 
||-(fixing this value)
|--(inverting this one)
</code></pre>

<p>Two's Complement representation, besides having only one representation for 0, it also adds two binary values in the same way that in decimal, even numbers with different signs. Nevertheless, it is necessary to check for overflow cases.</p>

<p><strong>4. Bias</strong></p>

<p>This representation is used to represent the exponent in the IEEE 754 norm for floating points. It has the advantage that the binary value with all bits to zero represents the smallest value. And the binary value with all bits to 1 represents the biggest value. As the name indicates, the value is encoded (positive or negative) in binary with n bits with a bias (normally 2^(n-1) or 2^(n-1)-1).</p>

<p>So if we are using 8 bits, the value 1 in decimal is represented in binary using a bias of 2^(n-1), by the value: </p>

<pre><code>+1 + bias = +1 + 2^(8-1) = 1 + 128 = 129
converting to binary
1000 0001
</code></pre>
","13422442"
"How to Base64 encode a Java object using org.apache.commons.codec.binary.base64?","53826","","<p>I've been trying to do an object serialization and Base64 encode the result. It works with Sun's lib:</p>

<pre><code>Bean01 bean01 = new Bean01();
bean01.setDefaultValues();
ByteArrayOutputStream baos = new ByteArrayOutputStream();
new ObjectOutputStream( baos ).writeObject( bean01 );
System.out.println(Base64.encode(baos.toByteArray()));
</code></pre>

<p>This works fine. However, I would like to do the same using org.apache.commons.codec.binary.base64, but this does not return the same string:</p>

<p><code>System.out.println(org.apache.commons.codec.binary.Base64.encodeBase64(baos.toByteArray()));</code></p>

<p>What would be the correct way to achieve the correct Base64 encoding of a byteArray using Apache's encoder?</p>
","<p>Actually the <code>commons-codec</code> version and specific Sun internal version you are using <strong>do</strong> give the same results.  I think you thought they were giving different versions because you are implicitly calling <code>toString()</code> on an array when you do:</p>

<pre><code>System.out.println(org.apache.commons.codec.binary.Base64.encodeBase64(baos.toByteArray()));
</code></pre>

<p>which is definitely does not print out the array contents.  Instead, that will only print out the address of the array reference.</p>

<p>I've written the following program to test the encoders against each other.  You'll see from the output below that the give the same results:</p>

<pre><code>import java.util.Random;

public class Base64Stuff
{
    public static void main(String[] args) {
        Random random = new Random();
        byte[] randomBytes = new byte[32];
        random.nextBytes(randomBytes);

        String internalVersion = com.sun.org.apache.xerces.internal.impl.dv.util.Base64.encode(randomBytes);
        byte[] apacheBytes =  org.apache.commons.codec.binary.Base64.encodeBase64(randomBytes);
        String fromApacheBytes = new String(apacheBytes);

        System.out.println(""Internal length = "" + internalVersion.length());
        System.out.println(""Apache bytes len= "" + fromApacheBytes.length());
        System.out.println(""Internal version = |"" + internalVersion + ""|"");
        System.out.println(""Apache bytes     = |"" + fromApacheBytes + ""|"");
        System.out.println(""internal equal apache bytes?: "" + internalVersion.equals(fromApacheBytes));
    }
}
</code></pre>

<p>And here's the output from a run of it:</p>

<pre><code>Internal length = 44
Apache bytes len= 44
Internal version = |Kf0JBpbxCfXutxjveYs8CXMsFpQYgkllcHHzJJsz9+g=|
Apache bytes     = |Kf0JBpbxCfXutxjveYs8CXMsFpQYgkllcHHzJJsz9+g=|
internal equal apache bytes?: true
</code></pre>
","10747284"
"Converting a byte to a binary string in c#","53013","","<p>In c# I am converting a <code>byte</code> to <code>binary</code>, the actual answer is <code>00111111</code> but the result being given is <code>111111</code>. Now I really need to display even the 2 0s in front. Can anyone tell me how to do this?</p>

<p>I am using:</p>

<pre><code>Convert.ToString(byteArray[20],2)
</code></pre>

<p>and the byte value is 63</p>
","<p>Just change your code to:</p>

<pre><code>string yourByteString = Convert.ToString(byteArray[20], 2).PadLeft(8, '0');
// produces ""00111111""
</code></pre>
","3581798"
"Converting SQL Server varBinary data into string C#","52502","","<p>I need help figuring out how to convert data that comes in from a <strong>SQL Server</strong> table column that is set as <strong>varBinary(max)</strong> into a string in order to display it in a label.</p>

<p>This is in <strong>C#</strong> and I'm using a <strong>DataReader</strong>.</p>

<p>I can pull the data in using:</p>

<pre><code>var BinaryString = reader[1];
</code></pre>

<p>i know that this column holds text that was previously convert to binary.</p>
","<p>It really depends on which encoding was used when you originally converted from string to binary:</p>

<pre><code> byte[] binaryString = (byte[])reader[1];

 // if the original encoding was ASCII
 string x = Encoding.ASCII.GetString(binaryString);

 // if the original encoding was UTF-8
 string y = Encoding.UTF8.GetString(binaryString);

 // if the original encoding was UTF-16
 string z = Encoding.Unicode.GetString(binaryString);

 // etc
</code></pre>
","4959269"
"Is there a function that returns the ASCII value of a character? (C++)","52408","","<p>I need a function that returns the ASCII value of a character, including spaces, tabs, newlines, etc...</p>

<p>On a similar note, what is the function that converts between hexadecimal, decimal, and binary numbers?</p>
","<pre><code>char c;
int ascii = (int) c;
s2.data[j]=(char)count;
</code></pre>

<p>A char <strong>is</strong> an integer, no need for conversion functions.</p>

<p>Maybe you are looking for functions that display integers as a string - using hex, binary or decimal representations?</p>
","845713"
"Why does Git treat this text file as a binary file?","52060","","<p>I wonder why git tells me this:?</p>

<pre><code>$ git diff MyFile.txt
diff --git a/MyFile.txt b/MyFile.txt
index d41a4f3..15dcfa2 100644
Binary files a/MyFile.txt and b/MyFile.txt differ
</code></pre>

<p>Aren't they text files?</p>

<p>I have checked the .gitattributes and it is empty. Why I am getting this message? I cannot get diffs as I use to anymore</p>

<p><strong>ADDED:</strong></p>

<p>I've noticed there is an <code>@</code> in the file permissions, what is this? Could this be the reason?</p>

<pre><code>$ls -all
drwxr-xr-x   5 nacho4d  staff    170 28 Jul 17:07 .
drwxr-xr-x  16 nacho4d  staff    544 28 Jul 16:39 ..
-rw-r--r--@  1 nacho4d  staff   6148 28 Jul 16:15 .DS_Store
-rw-r--r--@  1 nacho4d  staff    746 28 Jul 17:07 MyFile.txt
-rw-r--r--   1 nacho4d  staff  22538  5 Apr 16:18 OtherFile.txt
</code></pre>
","<p>It simply means that when git inspects the actual content of the file (it doesn't <em>know</em> that any given extension is not a binary file - you can use the attributes file if you want to tell it explicitly - see the man pages).</p>

<p>Having inspected the file's contents it has seen stuff that isn't in basic ascii characters. Being UTF16 I expect that it will have 'funny' characters so it thinks it's binary.</p>

<p>There are ways of telling git if you have internationalisation (i18n) or extended character formats for the file. I'm not sufficiently up on the exact method for setting that - you may need to RT[Full]M ;-) </p>

<p>Edit: a quick search of SO found <a href=""https://stackoverflow.com/questions/777949/can-i-make-git-recognize-a-utf-16-file-as-text"">can-i-make-git-recognize-a-utf-16-file-as-text</a> which should give you a few clues. </p>
","6856566"
"Convert Byte to binary in Java","50353","","<p>I am trying to convert a byte value to binary for data transfer. Basically, I am sending a value like ""AC"" in binary (""10101100"") in a byte array where ""10101100"" is a single byte. I want to be able to receive this byte and convert it back into ""10101100."" As of now I have no success at all dont really know where to begin. Any help would be great.</p>

<p><strong>edit</strong>: sorry for all the confusion I didnt realize that I forgot to add specific details.</p>

<p>Basically I need to use a byte array to send binary values over a socket connection. I can do that but I dont know how to convert the values and make them appear correctly. Here is an example:</p>

<p>I need to send the hex values ACDE48 and be able to interpret it back. According to documentation, I must convert it to binary in the following way: byte [] b={10101100,11011110,01001000}, where each place in the array can hold 2 values. I then need to convert these values back after they are sent and received. I am not sure how to go about doing this.</p>
","<pre><code>String toBinary( byte[] bytes )
{
    StringBuilder sb = new StringBuilder(bytes.length * Byte.SIZE);
    for( int i = 0; i &lt; Byte.SIZE * bytes.length; i++ )
        sb.append((bytes[i / Byte.SIZE] &lt;&lt; i % Byte.SIZE &amp; 0x80) == 0 ? '0' : '1');
    return sb.toString();
}

byte[] fromBinary( String s )
{
    int sLen = s.length();
    byte[] toReturn = new byte[(sLen + Byte.SIZE - 1) / Byte.SIZE];
    char c;
    for( int i = 0; i &lt; sLen; i++ )
        if( (c = s.charAt(i)) == '1' )
            toReturn[i / Byte.SIZE] = (byte) (toReturn[i / Byte.SIZE] | (0x80 &gt;&gt;&gt; (i % Byte.SIZE)));
        else if ( c != '0' )
            throw new IllegalArgumentException();
    return toReturn;
}
</code></pre>

<p>There are some simpler ways to handle this also (assumes big endian).</p>

<pre><code>Integer.parseInt(hex, 16);
Integer.parseInt(binary, 2);
</code></pre>

<p>and</p>

<pre><code>Integer.toHexString(byte).subString((Integer.SIZE - Byte.SIZE) / 4);
Integer.toBinaryString(byte).substring(Integer.SIZE - Byte.SIZE);
</code></pre>
","11529308"
"Binary Subtraction with 2's Complement","49131","","<p>I need help subtracting with binary using 2's representation and using 5 bits for each number:</p>

<p>1) -9 -7 = ? Is there overflow?</p>

<p>-9 = 01001 (2's complement = 10111) and -7 = 00111 (2's complement = 11001)</p>

<p>Now we need to add because we're using 2's complement</p>

<p>10111
+11001
= 100000 But this answer doesn't make sense. Also, I'm assuming there's overflow because there are more than 5 bits in the answer.</p>

<p>2)  6 - 10, same process as before. Negative binary numbers don't make sense to me</p>
","<p><strong>1) -9 - 7</strong></p>

<p>-9 - 7 = -9 + -7</p>

<p>9 (binary) = 01001<br>
-9 (2's complement) = 10111<br>
7 (binary) = 00111<br>
-7 (2's complement) = 11001</p>

<pre><code> 10111 +
 11001 =
110000
</code></pre>

<p>This doesn't fit into 5 bits. Removing the overflow we get 10000, which is -16 (binary).</p>

<p><strong>2) 6 - 10</strong></p>

<p>6 - 10 = 6 + -10</p>

<p>6 (binary) = 00110<br>
10 (binary) = 01010<br>
-10 (2's complement) = 10110</p>

<pre><code> 00110 +
 10110 =
 11100
</code></pre>

<p>This fits into 5 bits and is -4 (binary).</p>
","14429899"
"Why do we use Base64?","49003","","<p><a href=""http://en.wikipedia.org/wiki/Base64"" rel=""noreferrer"">Wikipedia</a> says</p>

<blockquote>
  <p>Base64 encoding schemes are commonly used when there is a need to encode binary data that needs be stored and transferred over media that are designed to deal with textual data. This is to ensure that the data remains intact without modification during transport.</p>
</blockquote>

<p>But is it not that data is always stored/transmitted in binary because the memory that our machines have store binary and it just depends how you interpret it? So, whether you encode the bit pattern <code>010011010110000101101110</code> as <code>Man</code> in ASCII or as <code>TWFu</code> in Base64, you are eventually going to store the same bit pattern.</p>

<p><strong>If the ultimate encoding is in terms of zeros and ones and every machine and media can deal with them, how does it matter if the data is represented as ASCII or Base64?</strong></p>

<p>What does it mean ""media that are designed to deal with textual data""? They can deal with binary => they can deal with anything.</p>

<hr>

<p>Thanks everyone, I think I understand now.</p>

<p>When we send over data, we cannot be sure that the data would be interpreted in the same format as we intended it to be. So, we send over data coded in some format (like Base64) that both parties understand. That way even if sender and receiver interpret same things differently, but because they agree on the coded format, the data will not get interpreted wrongly.</p>

<p>From <a href=""https://stackoverflow.com/questions/3538021/why-do-we-use-base64/3538079#3538079"">Mark Byers example</a></p>

<p>If I want to send </p>

<pre><code>Hello
world!
</code></pre>

<p>One way is to send it in ASCII like </p>

<pre><code>72 101 108 108 111 10 119 111 114 108 100 33
</code></pre>

<p>But byte 10 might not be interpreted correctly as a newline at the other end. So, we use a subset of ASCII to encode it like this</p>

<pre><code>83 71 86 115 98 71 56 115 67 110 100 118 99 109 120 107 73 61 61
</code></pre>

<p>which at the cost of more data transferred for the same amount of information ensures that the receiver can decode the data in the intended way, even if the receiver happens to have different interpretations for the rest of the character set.</p>
","<p>Your first mistake is thinking that ASCII encoding and Base64 encoding are interchangeable. They are not. They are used for different purposes.</p>

<ul>
<li>When you encode text in ASCII, you start with a text string and convert it to a sequence of bytes.</li>
<li>When you encode data in Base64, you start with a sequence of bytes and convert it to a text string. </li>
</ul>

<p>To understand why Base64 was necessary in the first place we need a little history of computing.</p>

<hr>

<p>Computers communicate in binary - 0s and 1s - but people typically want to communicate with more rich forms data such as text or images. In order to transfer this data between computers it first has to be encoded into 0s and 1s, sent, then decoded again. To take text as an example - there are many different ways to perform this encoding. It would be much simpler if we could all agree on a single encoding, but sadly this is not the case.</p>

<p>Originally a lot of different encodings were created (e.g. <a href=""http://en.wikipedia.org/wiki/Baudot_code"" rel=""noreferrer"">Baudot code</a>) which used a different number of bits per character until eventually ASCII became a standard with 7 bits per character. However most computers store binary data in bytes consisting of 8 bits each so <a href=""http://en.wikipedia.org/wiki/ASCII"" rel=""noreferrer"">ASCII</a> is unsuitable for tranferring this type of data. Some systems would even wipe the most significant bit. Furthermore the difference in line ending encodings across systems mean that the ASCII character 10 and 13 were also sometimes modified.</p>

<p>To solve these problems <a href=""http://en.wikipedia.org/wiki/Base64"" rel=""noreferrer"">Base64</a> encoding was introduced. This allows you to encode aribtrary bytes to bytes which are known to be safe to send without getting corrupted (ASCII alphanumeric characters and a couple of symbols). The disadvantage is that encoding the message using Base64 increases its length - every 3 bytes of data is encoded to 4 ASCII characters.</p>

<p>To send text reliably you can <strong>first</strong> encode to bytes using a text encoding of your choice (for example UTF-8) and then <strong>afterwards</strong> Base64 encode the resulting binary data into a text string that is safe to send encoded as ASCII. The receiver will have to reverse this process to recover the original message. This of course requires that the receiver knows which encodings were used, and this information often needs to be sent separately.</p>

<p>Historically it has been used to encode binary data in email messages where the email server might modify line-endings. A more modern example is the use of Base64 encoding to <a href=""http://www.sweeting.org/mark/blog/2005/07/12/base64-encoded-images-embedded-in-html"" rel=""noreferrer"">embed image data directly in HTML source code</a>. Here it is necessary to encode the data to avoid characters like '&lt;' and '>' being interpreted as tags.</p>

<hr>

<p>Here is a worked example:</p>

<p>I wish to send a text message with two lines</p>

<pre>
Hello
world!
</pre>

<p>If I send it as ASCII (or UTF-8) it will look like this:</p>

<pre><code>72 101 108 108 111 10 119 111 114 108 100 33
</code></pre>

<p>The byte 10 is corrupted in some systems so we can base 64 encode these bytes as a Base64 string:</p>

<pre>SGVsbG8sCndvcmxkIQ==</pre>

<p>Which when encoded using ASCII looks like this:</p>

<pre><code>83 71 86 115 98 71 56 115 67 110 100 118 99 109 120 107 73 61 61
</code></pre>

<p>All the bytes here are known safe bytes, so there is very little chance that any system will corrupt this message. I can send this instead of my original message and let the receiver reverse the process to recover the original message.</p>
","3538079"
"Is it possible to program in binary?","48571","","<p>The title really says it all. A friend of mine told me he knows someone who can program in binary. I've never heard of someone programming in binary and a few quick Google searches didn't return anything useful. So I figured I'd turn to the SO community. Does anyone have any info on programming in binary and if possible maybe a quick Hello World example. Thanks in advance.</p>
","<p>Of course.  It's more commonly called <a href=""http://en.wikipedia.org/wiki/Machine_code"" rel=""noreferrer"">machine code</a>.  It's basically <a href=""http://en.wikipedia.org/wiki/Assembly_language"" rel=""noreferrer"">assembly language</a> without the mnemonic devices.  Someone who knows assembly very well could program in machine code with additional effort, referring to opcode listings (e.g. <a href=""http://ref.x86asm.net/"" rel=""noreferrer"">x86</a>) as needed.</p>

<p>Would I do it?  No.  Even assembly is only useful in rare circumstances, and there's no reason (beside demonstrating your skills) to reject the <a href=""http://en.wikipedia.org/wiki/Assemblers#Assembler"" rel=""noreferrer"">assembler</a>'s help.</p>

<p>Since you asked about hello world, you should check out <a href=""http://timelessname.com/elfbin/"" rel=""noreferrer"">this article</a>.  He shows how he wrote, then optimized, an x86 ELF program to output it.  It was originally written in <a href=""http://en.wikipedia.org/wiki/Netwide_Assembler"" rel=""noreferrer"">nasm</a> then modified in a hex editor.</p>
","4964977"
"Decimal to binary (and vice-versa)","48410","","<p>Can anybody give an example of c++ code that can easily convert a decimal value to binary and a binary value to decimal please?</p>
","<p>Well, your question is really vague, so this answer is the same.</p>

<pre><code>string DecToBin(int number)
{
    if ( number == 0 ) return ""0"";
    if ( number == 1 ) return ""1"";

    if ( number % 2 == 0 )
        return DecToBin(number / 2) + ""0"";
    else
        return DecToBin(number / 2) + ""1"";
}

int BinToDec(string number)
{
    int result = 0, pow = 1;
    for ( int i = number.length() - 1; i &gt;= 0; --i, pow &lt;&lt;= 1 )
        result += (number[i] - '0') * pow;

    return result;
}
</code></pre>

<p>You should check for overflow and do input validation of course.</p>

<p><code>x &lt;&lt; 1 == x * 2</code></p>

<p>Here's a way to convert to binary that uses a more ""programming-like"" approach rather than a ""math-like"" approach, for lack of a better description (the two are actually identical though, since this one just replaces divisions by right shifts, modulo by a bitwise and, recursion with a loop. It's kind of another way of thinking about it though, since this makes it obvious you are extracting the individual bits).</p>

<pre><code>string DecToBin2(int number)
{
    string result = """";

    do
    {
        if ( (number &amp; 1) == 0 )
            result += ""0"";
        else
            result += ""1"";

        number &gt;&gt;= 1;
    } while ( number );

    reverse(result.begin(), result.end());
    return result;
}
</code></pre>

<p>And here is how to do the conversion on paper:</p>

<ol>
<li><a href=""http://www.wikihow.com/Convert-from-Decimal-to-Binary"" rel=""noreferrer"">Decimal to binary</a></li>
<li><a href=""http://www.wikihow.com/Convert-from-Binary-to-Decimal"" rel=""noreferrer"">Binary to decimal</a></li>
</ol>
","2548374"
"Convert a String to binary sequence in C#","48408","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/736533/how-do-you-convert-a-string-to-ascii-to-binary-in-c"">How do you convert a string to ascii to binary in C#?</a>  </p>
</blockquote>



<p>How to convert <strong>string</strong> such as <code>""Hello""</code> to <strong>Binary</strong> sequence as <code>1011010</code> ?</p>
","<p>Try this:</p>

<pre><code>string str = ""Hello""; 
byte []arr = System.Text.Encoding.ASCII.GetBytes(str);
</code></pre>
","5990290"
"Adding binary numbers","48311","","<p>Does anyone know how to add 2 binary numbers, entered as binary, in Java?</p>

<p>For example, <code>1010 + 10 = 1100</code>.</p>
","<p>Yes, I know how.</p>

<p>Use <a href=""http://docs.oracle.com/javase/7/docs/api/java/lang/Integer.html#parseInt%28java.lang.String,%20int%29"" rel=""noreferrer""><code>Integer.parseInt(String, int radix)</code></a>.</p>

<pre><code>// The two input Strings, containing the binary representation of the two values:
String input0 = ""1010"";
String input1 = ""10"";

// Use as radix 2 because it's binary    
int number0 = Integer.parseInt(input0, 2);
int number1 = Integer.parseInt(input1, 2);

int sum = number0 + number1;
</code></pre>
","8548599"
"Changing integer to binary string of digits","47559","","<p>I'm currently working on a simulation of the MIPS processor in C++ for a comp architecture class and having some problems converting from decimal numbers to binary (signed numbers both ways). Everything's working fine until the very last bit because my current algorithm falls into out of bounds areas for int on 1&lt;&lt;=31. Just need a nudge in the right direction to get it up and running. Thanks!</p>

<pre><code>//Assume 32 bit decimal number
string DecimalToBinaryString(int a)
{
    string binary = """";
    int mask = 1;
    for(int i = 0; i &lt; 31; i++)
    {
        if((mask&amp;a) &gt;= 1)
            binary = ""1""+binary;
        else
            binary = ""0""+binary;
        mask&lt;&lt;=1;
    }
    cout&lt;&lt;binary&lt;&lt;endl;
    return binary;
}
</code></pre>

<p>I'm also including my other algorithm for completeness. I apologize for the lack of comments, but it's fairly straight forward.</p>

<pre><code>int BinaryStringToDecimal(string a)
{
    int num = 0;
    bool neg = false;
    if(a.at(0) == '1')
    {
        neg = true;
        for(int x = a.length()-1; x &gt;= 0; x--)
        {
            if(a.at(x) == '1')
                a.at(x) = '0';
            else a.at(x) = '1';
        }
        a.at(a.length()-1) += 1;
        for(int x = a.length()-1; x &gt;= 0; x--)
        {
            if(a.at(x) == '2')
            {
                if(x-1 &gt;= 0)
                {
                    if(a.at(x-1) == '1')
                        a.at(x-1) = '2';
                    if(a.at(x-1) == '0')
                        a.at(x-1) = '1';
                    a.at(x) = '0';
                }
            }
            else if(a.at(x) == '3')
            {
                if(x-1 &gt;= 0)
                    a.at(x-1) += '2';
                a.at(x) = '1';
            }
        }
        if(a.at(0) == '2')
            a.at(0) = '0';
        else if(a.at(0) == '3')
            a.at(0) = '1';
    }
    for(int x = a.length()-1; x &gt;= 0; x--)
    {
        if(a.at(x) == '1')
            num += pow(2.0, a.length()-x-1);
    }
    if(neg)
        num = num*-1;   
    return num;
 }
</code></pre>

<p>Also if anyone knows any good ways to go about writing these more efficiently I'd love to hear it. I've only had the two introductory programming classes but have been playing with different techniques to see how well I like their style.</p>
","<p>There are actually standard one-liners for these.</p>

<pre><code>#include &lt;bitset&gt;

std::string s = std::bitset&lt; 64 &gt;( 12345 ).to_string(); // string conversion

std::cout &lt;&lt; std::bitset&lt; 64 &gt;( 54321 ) &lt;&lt; ' '; // direct output

std::bitset&lt; 64 &gt; input;
std::cin &gt;&gt; input;
unsigned long ul = input.to_ulong();
</code></pre>

<p><a href=""http://ideone.com/kMYOJ"" rel=""noreferrer"">See this run as a demo</a>.</p>
","8224393"
"Fast way of counting non-zero bits in positive integer","47200","","<p>I need a fast way to count the number of bits in an integer in python.
My current solutions is </p>

<pre><code>bin(n).count(""1"")
</code></pre>

<p>but I am wondering if there is any faster way of doing this?</p>

<p>PS: (i am representing a big 2D binary array as a singe list of numbers and doing bitwise operations, and that brings the time down from hours to minutes. and now i would like to get rid of those extra minutes.</p>

<p>Edit: 
1. it has to be in python 2.7 or 2.6</p>

<p>and optimizing for small numbers does not matter that much since that would not be a clear bottle neck, but I do have numbers with 10 000 + bits at some places</p>

<p>for example this is a 2000 bit case:</p>

<pre><code>12448057941136394342297748548545082997815840357634948550739612798732309975923280685245876950055614362283769710705811182976142803324242407017104841062064840113262840137625582646683068904149296501029754654149991842951570880471230098259905004533869130509989042199261339990315125973721454059973605358766253998615919997174542922163484086066438120268185904663422979603026066685824578356173882166747093246377302371176167843247359636030248569148734824287739046916641832890744168385253915508446422276378715722482359321205673933317512861336054835392844676749610712462818600179225635467147870208L
</code></pre>
","<p>For arbitrary-length integers, <code>bin(n).count(""1"")</code> is the fastest I could find in pure Python.</p>

<p>I tried adapting Óscar's and Adam's solutions to process the integer in 64-bit and 32-bit chunks, respectively. Both were at least ten times slower than <code>bin(n).count(""1"")</code> (the 32-bit version took about half again as much time).</p>

<p>On the other hand, <a href=""http://code.google.com/p/gmpy/"">gmpy</a> <code>popcount()</code> took about 1/20th of the time of <code>bin(n).count(""1"")</code>. So if you can install gmpy, use that.</p>
","9831671"
"Sending and receiving binary data in Servlets","47111","","<p>I'm attempting to write a Java Servlet to receive binary data requests and reply to them, using <code>HttpServletRequest.getOutputStream()</code> and <code>HttpServletResponse.getInputStream()</code>. This is for a project which involves having a request sent by a Silverlight client to which this servlet responds to through an HTTP POST connection. For the time being, to test the Servlet I'm implementing a client in Java which I'm more familiar with than Silverlight.</p>

<p>The problem is that in my test project I send the data from a Servlet client as a byte array and expect to receive a byte array with the same length -- only it doesn't, and instead I'm getting a single byte. Therefore I'm posting here the relevant code snippets in the hopes that you might point me where I'm doing wrong and hopefully provide relevant bibliography to help me further.</p>

<p>So here goes.</p>

<p>The <strong>client</strong> servlet handles POST requests from a very simple HTML page with a form which I use as front-end. I'm not too worried about using JSP etc, instead I'm focused on making the inter-Servlet communication <em>work</em>.</p>

<pre><code>// client HttpServlet invokes this method from doPost(request,response)
private void process(HttpServletRequest request, HttpServletResponse response) 
throws ServletException, IOException {
  String firstName = (String) request.getParameter(""firstname"");
  String lastName = (String) request.getParameter(""lastname"");
  String xmlRequest = ""&lt;MyRequest&gt;&lt;Person&gt;&lt;Name Firstname=\""""+firstName+""\"" Lastname=\""""+lastName+""\"" /&gt;&lt;/Person&gt;&lt;/MyRequest&gt;"";

  OutputStream writer = null;
  InputStream reader = null;
  try {
    URL url = new URL(""http://localhost:8080/project/Server"");
    URLConnection conn = url.openConnection();
    conn.setDoInput(true);
    conn.setDoOutput(true);

    writer = conn.getOutputStream();
    byte[] baXml = xmlRequest.getBytes(""UTF-8"");
    writer.write(baXml, 0,baXml.length);
    writer.flush();
    // perhaps I should be waiting here? how?

    reader = conn.getInputStream();
    int available = reader.available();
    byte[] data = new byte[available];
    reader.read(data,0,available);
    String xmlResponse = new String(data,""UTF-8"");

    PrintWriter print = response.getWriter();
    print.write(""&lt;html&gt;&lt;body&gt;Response:&lt;br/&gt;&lt;pre&gt;"");
    print.write(xmlResponse);
    print.write(""&lt;/pre&gt;&lt;/body&gt;&lt;/html&gt;"");
    print.close();

  } finally {
    if(writer!=null)
      writer.close();
    if(reader!=null)
      reader.close();
  }
}
</code></pre>

<p>The <strong>server</strong> servlet handles HTTP POST requests. This is done by receiving requests the requests from a client Servlet for testing purposes above, but in the future I intend to use it for clients in other languages (specifically, Silverlight).</p>

<pre><code>// server HttpServlet invokes this method from doPost(request,response)
private void process(HttpServletRequest request, HttpServetResponse response)
throws ServletException, IOException {
  ServletInputStream sis = null;
  try {
    sis = request.getInputStream();
    // maybe I should be using a BufferedInputStream 
    // instead of the InputStream directly?
    int available = sis.available();
    byte[] input = new byte[available];
    int readBytes = sis.read(input,0,available);
    if(readBytes!=available) {
      throw new ServletException(""Oops! readBytes!=availableBytes"");
    }

    // I ONLY GET 1 BYTE OF DATA !!! 
    // It's the first byte of the client message, a '&lt;'.
    String msg = ""Read ""+readBytes+"" bytes of ""
                 +available+"" available from request InputStream."";
    System.err.println(""Server.process(HttpServletRequest,HttpServletResponse): ""+msg);
    String xmlReply = ""&lt;Reply&gt;&lt;Message&gt;""+msg+""&lt;/Message&gt;&lt;/Reply&gt;"";
    byte[] data = xmlReply.getBytes(""UTF-8"");
    ServletOutputStream sos = response.getOutputStream();
    sos.write(data, 0,data.length);
    sos.flush();
    sos.close();

  } finally {
    if(sis!=null)
      sis.close();
  }
}
</code></pre>

<p>I have been sticking to byte arrays instead of using <code>BufferInputStream</code>s so far because I've not decided yet if I'll be using e.g. Base64-encoded strings to transmit data or if I'll be sending binary data as-is.</p>

<p>Thank you in advance. </p>
","<p>The one thing I can think of is that you are reading only <code>request.getInputStream().available()</code> bytes, then deciding that you have had everything. According to the <a href=""http://download.oracle.com/javase/6/docs/api/java/io/InputStream.html#available%28%29"" rel=""nofollow"">documentation</a>, <code>available()</code> will return the number of bytes that can be read without blocking, but I don't see any mention of whether this is actually guaranteed to be the entire content of the input stream, so am inclined to assume that no such guarantees are made.</p>

<p>I'm not sure how to best find out when there is no more data (maybe <code>Content-Length</code> in the request can help?) without risking blocking indefinitely at EOF, but I would try looping until having read all the data from the input stream. To test that theory, you could always scan the input for a known pattern that occurs further into the stream, maybe a <code>&gt;</code> matching the initial <code>&lt;</code> that you are getting.</p>
","5180560"
"Really 1 KB (KiloByte) equals 1024 bytes?","47054","","<p>Until now I believed that 1024 bytes equals 1 KB (kilobyte) but I was reading on the internet about decimal and binary system.</p>

<p><img src=""https://i.stack.imgur.com/sR9WU.png"" alt=""enter image description here""></p>

<p>So, actually 1024 bytes = 1 KB would be the correct way to define or simply there is a general confusion? 
Sorry if my question is too silly. </p>

<p>Thanks in advance.</p>
","<p>What you are seeing is a marketing stunt.
Since non-technical people don't know the difference between Metric Meg, Gig, etc. against the binary Meg, Gig, etc. marketers for storage will use the Metric calculation, thus 1000 Bytes == 1 KiloByte.  </p>

<p>This can cause issues with development or highly technical people so you get the idea of a binary Meg, Gig, etc. which is designated with a bi instead of the standard combination (ex. Mebibyte vs Megabyte, or Gibibyte vs Gigabyte)</p>
","19819872"
"packing and unpacking variable length array/string using the struct module in python","46087","","<p>I am trying to get a grip around the packing and unpacking of binary data in Python 3. Its actually not that hard to understand, except one problem:</p>

<p>what if I have a variable length textstring and want to pack and unpack this in the most elegant manner?</p>

<p>As far as I can tell from the manual I can only unpack fixed size strings directly? In that case, are there any elegant way of getting around this limitation without padding lots and lots of unnecessary zeroes?</p>
","<p>The <code>struct</code> module does only support fixed-length structures.  For variable-length strings, your options are either:</p>

<ul>
<li><p>Dynamically construct your format string (a <code>str</code> will have to be converted to a <code>bytes</code> before passing it to <code>pack()</code>):  </p>

<pre><code>s = bytes(s, 'utf-8')    # Or other appropriate encoding
struct.pack(""I%ds"" % (len(s),), len(s), s)
</code></pre></li>
<li><p>Skip <code>struct</code> and just use normal string methods to add the string to your <code>pack()</code>-ed output: <code>struct.pack(""I"", len(s)) + s</code></p></li>
</ul>

<p>For unpacking, you just have to unpack a bit at a time:</p>

<pre><code>(i,), data = struct.unpack(""I"", data[:4]), data[4:]
s, data = data[:i], data[i:]
</code></pre>

<p>If you're doing a lot of this, you can always add a helper function which uses <code>calcsize</code> to do the string slicing:</p>

<pre><code>def unpack_helper(fmt, data):
    size = struct.calcsize(fmt)
    return struct.unpack(fmt, data[:size]), data[size:]
</code></pre>
","3753685"
"Sending binary data in javascript over HTTP","45546","","<p>I'm trying to send a HTTP POST to a device on my network.  I want to send four specific bytes of data to the device unfortunately I only seem to be able to send strings to the device.  Is there anyway to send raw binary using javascript?  </p>

<p>Here's the script I'm using to do the POST, it currently doesn't run unless I put a string in the data field.  Any ideas?</p>

<pre><code>(function ($) {
   $.ajax({
      url: '&lt;IP of Address&gt;',
      type: 'POST',
      contentType: 'application/octet-stream',

      //data:'253,0,128,1',
      data:0xFD008001,

      crossDomain: true
   });
})(jQuery);
</code></pre>
","<p>By default, jQuery serializes the data (passed in <code>data</code> property) - and it means <code>0xFD008001</code> <em>number</em> gets passed to the server as '4244668417' <em>string</em> (10 bytes, not 4), that's why the server treats it not as expected. </p>

<p>It's necessary to prevent such behaviour by setting <code>$.ajax</code> property <code>processData</code> to <code>false</code>:</p>

<blockquote>
  <p>By default, data passed in to the data option as an object
  (technically, anything other than a string) will be processed and
  transformed into a query string, fitting to the default content-type
  ""application/x-www-form-urlencoded"". If you want to send a
  DOMDocument, or other non-processed data, set this option to false.</p>
</blockquote>

<p>... but that's only part of the whole story: <code>XMLHttpRequest.send</code> implementation has its own <a href=""https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest#Browser_Compatibility"">restrictions</a>. That's why your best bet, I suppose, is to make your own serializer using <a href=""https://developer.mozilla.org/en-US/docs/Web/JavaScript/Typed_arrays""><strong>TypedArrays</strong></a>:</p>

<pre><code>// Since we deal with Firefox and Chrome only 
var bytesToSend = [253, 0, 128, 1],
    bytesArray = new Uint8Array(bytesToSend);

$.ajax({
   url: '%your_service_url%',
   type: 'POST',
   contentType: 'application/octet-stream',  
   data: bytesArray,
   processData: false
});
</code></pre>

<p>Or without using jQuery at all:</p>

<pre><code>var bytesToSend = [253, 0, 128, 1],
    bytesArray = new Uint8Array(bytesToSend);

var xhr = new XMLHttpRequest();
xhr.open('POST', '%your_service_url%');
xhr.setRequestHeader('Content-Type', 'application/octet-stream');
xhr.send(bytesArray);
</code></pre>
","19959244"
"Fastest way to Convert String to Binary?","45516","","<p>I want to convert a string, using the string class - to Binary. What is the fast way to do this character by character. Loop? Or is there some function out there that will convert for me? 1's and 0's binary.</p>

<p>A string being:</p>

<pre><code>#include &lt;string&gt;
using namespace std;
int main(){
  myString = ""Hello World"";
}
</code></pre>
","<p>Using <code>std::bitset</code> would work:</p>

<pre><code>#include &lt;string&gt;
#include &lt;bitset&gt;
#include &lt;iostream&gt;
using namespace std;
int main(){
  string myString = ""Hello World"";
  for (std::size_t i = 0; i &lt; myString.size(); ++i)
  {
      cout &lt;&lt; bitset&lt;8&gt;(myString.c_str()[i]) &lt;&lt; endl;
  }
}
</code></pre>

<p>Output:</p>

<pre><code>01001000
01100101
01101100
01101100
01101111
00100000
01010111
01101111
01110010
01101100
01100100
</code></pre>
","10184269"
"Why unsigned int 0xFFFFFFFF is equal to int -1?","45126","","<p>In C or C++ it is said that the maximum number a size_t (an unsigned int data type) can hold is the same as casting -1 to that data type. for example see <a href=""https://stackoverflow.com/questions/1420982/invalid-value-for-sizet"">Invalid Value for size_t</a></p>

<p>Why? </p>

<p>I mean, (talking about 32 bit ints) AFAIK the most significant bit holds the sign in a signed data type (that is, bit 0x80000000 to form a negative number). then, 1 is 0x00000001.. 0x7FFFFFFFF is the greatest positive number a int data type can hold.</p>

<p>Then, AFAIK the binary representation of -1 int should be 0x80000001 (perhaps I'm wrong). why/how this binary value is converted to anything completely different (0xFFFFFFFF) when casting ints to unsigned?? or.. how is it possible to form a binary -1 out of 0xFFFFFFFF?</p>

<p>I have no doubt that in C: ((unsigned int)-1) == 0xFFFFFFFF or ((int)0xFFFFFFFF) == -1 is equally true than 1 + 1 == 2, I'm just wondering why.</p>
","<p>C and C++ can run on many different architectures, and machine types.  Consequently, they can have different representations of numbers: Two's complement, and Ones' complement being the most common.  In general you should not rely on a particular representation in your program.</p>

<p>For unsigned integer types (<code>size_t</code> being one of those), the C standard (and the C++ standard too, I think) specifies precise overflow rules.  In short, if <code>SIZE_MAX</code> is the maximum value of the type <code>size_t</code>, then the expression</p>

<p><code>(size_t) (SIZE_MAX + 1)</code></p>

<p>is guaranteed to be <code>0</code>, and therefore, you can be sure that <code>(size_t) -1</code> is equal to <code>SIZE_MAX</code>.  The same holds true for other unsigned types.</p>

<p>Note that the above holds true:</p>

<ul>
<li>for all unsigned types,</li>
<li><em>even if the underlying machine doesn't represent numbers in Two's complement</em>.  In this case, the compiler has to make sure the identity holds true.</li>
</ul>

<p>Also, the above means that you can't rely on specific representations for <em>signed</em> types.</p>

<p><em>Edit</em>: In order to answer some of the comments:</p>

<p>Let's say we have a code snippet like:</p>

<pre><code>int i = -1;
long j = i;
</code></pre>

<p>There is a type conversion in the assignment to <code>j</code>.  Assuming that <code>int</code> and <code>long</code> have different sizes (most [all?] 64-bit systems), the bit-patterns at memory locations for <code>i</code> and <code>j</code> are going to be different, because they have different sizes.  The compiler makes sure that the <em>values</em> of <code>i</code> and <code>j</code> are <code>-1</code>.</p>

<p>Similarly, when we do:</p>

<pre><code>size_t s = (size_t) -1
</code></pre>

<p>There is a type conversion going on.  The <code>-1</code> is of type <code>int</code>.  It has a bit-pattern, but that is irrelevant for this example because when the conversion to <code>size_t</code> takes place due to the cast, the compiler will translate the <em>value</em> according to the rules for the type (<code>size_t</code> in this case).  Thus, even if <code>int</code> and <code>size_t</code> have different sizes, the standard guarantees that the value stored in <code>s</code> above will be the maximum value that <code>size_t</code> can take.</p>

<p>If we do:</p>

<pre><code>long j = LONG_MAX;
int i = j;
</code></pre>

<p>If <code>LONG_MAX</code> is greater than <code>INT_MAX</code>, then the value in <code>i</code> is implementation-defined (C89, section 3.2.1.2).</p>
","1863219"
"how to convert a char to binary?","44985","","<p>is there a simple way to convert a character to its binary representation?</p>

<p>Im trying to send a message to another process, a single bit at a time. 
So if the message is ""Hello"", i need to first turn 'H' into binary, and then send the bits in order.</p>

<p>Storing in an array would be preferred. </p>

<p>Thanks for any feedback, either pseudo code or actual code would be the most helpful.</p>

<p>I think I should mention this is for a school assignment to learn about signals... it's just an interesting way to learn about them. SIGUSR1 is used as 0, SIGUSR2 is used as 1, and the point is to send a message from one process to another, pretending the environment is locking down other methods of communication. </p>
","<p>You have only to loop for each bit do a shift and do an logic <code>AND</code> to get the bit.</p>

<pre><code>for (int i = 0; i &lt; 8; ++i) {
    send((mychar &gt;&gt; i) &amp; 1);
}
</code></pre>

<p>For example:</p>

<pre><code>unsigned char mychar = 0xA5; // 10100101

(mychar &gt;&gt; 0)    10100101
&amp; 1            &amp; 00000001
=============    00000001 (bit 1)

(mychar &gt;&gt; 1)    01010010
&amp; 1            &amp; 00000001
=============    00000000 (bit 0)
</code></pre>

<p>and so on...</p>
","4892655"
"How to GET data from an URL and save it into a file in binary in C#.NET without the encoding mess?","44678","","<p>In C#.NET, I want to fetch data from an URL and save it to a file in binary.</p>

<p>Using HttpWebRequest/Streamreader to read into a string and saving using StreamWriter works fine with ASCII, but non-ASCII characters get mangled because the Systems thinks it has to worry about Encodings, encode to Unicode or from or whatever. </p>

<p>What is the easiest way to GET data from an URL and saving it to a file, binary, as-is?</p>

<pre><code>// This code works, but for ASCII only
String url = ""url..."";
HttpWebRequest  request  = (HttpWebRequest)
WebRequest.Create(url);

// execute the request
HttpWebResponse response = (HttpWebResponse)
request.GetResponse();

// we will read data via the response stream
Stream ReceiveStream = response.GetResponseStream();
StreamReader readStream = new StreamReader( ReceiveStream );
string contents = readStream.ReadToEnd();

string filename = @""..."";

// create a writer and open the file
TextWriter tw = new StreamWriter(filename);
tw.Write(contents.Substring(5));
tw.Close();
</code></pre>
","<p>Minimalist answer:</p>

<pre><code>using (WebClient client = new WebClient()) {
    client.DownloadFile(url, filePath);
}
</code></pre>

<p>Or in PowerShell (suggested in an anonymous edit):</p>

<pre><code>[System.Net.WebClient]::WebClient
$client = New-Object System.Net.WebClient
$client.DownloadFile(URL, Filename)
</code></pre>
","992525"
"Binary buffer in Python","44368","","<p>In Python you can use <a href=""https://docs.python.org/library/struct.html"" rel=""noreferrer"">StringIO</a> for a file-like buffer for character data. <a href=""https://docs.python.org/library/mmap.html"" rel=""noreferrer"">Memory-mapped file</a> basically does similar thing for binary data, but it requires a file that is used as the basis. Does Python have a file object that is intended for binary data and is memory only, equivalent to Java's <a href=""http://java.sun.com/javase/6/docs/api/java/io/ByteArrayOutputStream.html"" rel=""noreferrer"">ByteArrayOutputStream</a>?</p>

<p>The use-case I have is I want to create a ZIP file in memory, and <a href=""https://docs.python.org/library/zipfile.html"" rel=""noreferrer"">ZipFile</a> requires a file-like object.</p>
","<p>You are probably looking for <a href=""http://docs.python.org/release/3.1.3/library/io.html#binary-i-o"">io.BytesIO</a> class. It works exactly like StringIO except that it supports binary data:</p>

<pre><code>from io import BytesIO
bio = BytesIO(b""some initial binary data: \x00\x01"")
</code></pre>

<p>StringIO will throw TypeError:</p>

<pre><code>from io import StringIO
sio = StringIO(b""some initial binary data: \x00\x01"")
</code></pre>
","7357938"
"Locking binary files using git version control system","43843","","<p>For one and a half years, I have been keeping my eyes on the git community in hopes of making the switch away from SVN.  One particular issue holding me back is the inability to lock binary files. Throughout the past year I have yet to see developments on this issue.  I understand that locking files goes against the fundamental principles of distributed source control, but I don't see how a web development company can take advantage of git to track source code and image file changes when there is the potential for binary file conflicts.</p>

<p>To achieve the effects of locking, a ""central"" repository must be identified.  Regardless of the distributed nature of git, most companies will have a ""central"" repository for a software project.  We should be able to mark a file as requiring a lock from the governing git repository at a specified address.  Perhaps this is made difficult because git tracks file contents not files?</p>

<p>Do any of you have experience in dealing with git and binary files that should be locked before modification?</p>

<p>NOTE: It looks like Source Gear's new open source distributed version control project, Veracity, has locking as one of its goals.</p>
","<p><a href=""https://github.com/blog/2328-git-lfs-2-0-0-released"" rel=""nofollow noreferrer"">Git LFS 2.0</a> has added support for file locking.</p>

<blockquote>
  <p>With Git LFS 2.0.0 you can now lock files that you're actively working on, preventing others from pushing to the Git LFS server until you unlock the files again.</p>
  
  <p>This will prevent merge conflicts as well as lost work on non-mergeable files at the filesystem level. While it may seem to contradict the distributed and parallel nature of Git, file locking is an important part of many software development workflows—particularly for larger teams working with binary assets.</p>
</blockquote>
","43624294"
"C represent int in base 2","42446","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/2611764/can-i-use-a-binary-literal-in-c-or-c"">Can I use a binary literal in C or C++?</a>  </p>
</blockquote>



<p>I am learning C and i recently found out that we can represent integers in different ways, like that:</p>

<p>(Assuming <code>i</code> has ""human-readable"" value of <strong>512</strong>.) Here are the representations:</p>

<h2>Decimal:</h2>

<pre class=""lang-c prettyprint-override""><code>int i = 512; 
</code></pre>

<h2>Octal:</h2>

<pre class=""lang-c prettyprint-override""><code>int i = 01000;
</code></pre>

<h2>Hexadecimal:</h2>

<pre class=""lang-c prettyprint-override""><code>int i = 0x200;
</code></pre>

<h2>In base 2 (or binary representation) <strong>512</strong> is <strong>1000000000</strong>. How to write this in C?</h2>

<p>Something like <code>int i = 1000000000b</code>? This is funny but unfortunately no C compiler accepts that value.</p>
","<p>In C (and I believe C++) there is no binary representation for numbers. However, for the simple number you show, you can use a shortcut</p>

<pre><code>int i = 1 &lt;&lt; 9; /* binary 1 followed by 9 binary 0's */
</code></pre>
","6414004"
"How do I create binary patches?","41705","","<p>What's the best way to go about making a patch for a binary file? I want it to be simple for users to apply(a simple <code>patch</code> application would be nice). Running diff on the file just gives <code>Binary files [...] differ</code></p>
","<p>If using something else than the standard <code>patch</code> is an option for you, you might want to check out <code>bsdiff</code> and <code>bspatch</code>:</p>

<p><a href=""http://www.daemonology.net/bsdiff/"" rel=""noreferrer"">http://www.daemonology.net/bsdiff/</a></p>

<blockquote>
  <p>bsdiff and bspatch are tools for building and applying patches to binary files. [...]</p>
</blockquote>
","1945095"
"How do I read binary data to a byte array in Javascript?","41518","","<p>I want to read a binary file in JavaScript that would be gotten through XMLHttpRequest and be able to manipulate that data. From my researching I discovered this method of reading a binary file data into an array</p>

<pre><code>var xhr = new XMLHttpRequest();
xhr.open('GET', '/binary_And_Ascii_File.obj', true);

xhr.responseType = 'arraybuffer';

xhr.onload = function(e) {
  var uInt8Array = new Uint8Array(this.response);
};
</code></pre>

<p>How do I convert this binary data array to a human-readable-string? </p>
","<p>I'm sure you will find this helpful: <a href=""http://jsdo.it/tsmallfield/uint8array"" rel=""noreferrer"">http://jsdo.it/tsmallfield/uint8array</a>.</p>

<p>Click on <code>javascript</code> tab.
 There will appear the code to convert the Uint8Array in a string. The author shows 2 method:</p>

<ul>
<li>The first is about creating a view.</li>
<li>The second offsetting bytes.</li>
</ul>

<p><strong>EDIT:</strong>  report the code for completeness</p>

<pre><code>var buffer = new ArrayBuffer( res.length ), // res is this.response in your case
    view   = new Uint8Array( buffer ),
    len    = view.length,
    fromCharCode = String.fromCharCode,
    i, s, str;    

/**
 *  1) 8bitの配列に入れて上位ビットけずる
 */
str = """";

for ( i = len; i--; ) {
  view[i] = res[i].charCodeAt(0);
}

for ( i = 0; i &lt; len; ++i ) {
  str += fromCharCode( view[i] );
}    

/**
 *  2) &amp; 0xff で上位ビットけずる
 */
str = """";

for ( i = 0; i &lt; len; ++i ) {
  str += fromCharCode( res[i].charCodeAt(0) &amp; 0xff );
}
</code></pre>
","6995242"
"Is two's complement notation of a positive number the same number?","41314","","<p>Is two's complement notation of a positive number is same as its binary representation?</p>
","<blockquote>
  <p>Is two's complement notation of a positive number the same number?</p>
</blockquote>

<p>The good example is  from <a href=""http://en.wikipedia.org/wiki/Two%27s_complement"" rel=""nofollow noreferrer"">wiki</a> that the relationship to two's complement is realized by noting that 256 = 255 + 1, and (255 − x) is the ones' complement of x</p>

<p>0000 0111=7 two's complement is 1111 1001= -7</p>

<p>the way it works is  the msb(most significant bit) receives a negative value so in the case above</p>

<blockquote>
  <p>-7 = 1001= -8 + 0+ 0+ 1 </p>
</blockquote>

<p><strong>Edit-</strong> A positive number written in two's-complement notation is the same as the number written in unsigned notation (although the most significant bit must be zero). A negative number can be written in two's complement notation by inverting all of the bits of its absolute value, then adding one to the result. <a href=""http://74.125.93.132/search?q=cache:ld9pBnc4_QcJ:cnx.org/content/m10808/latest/+two+complement+notation&amp;cd=2&amp;hl=en&amp;ct=clnk&amp;gl=us&amp;client=firefox-a"" rel=""nofollow noreferrer"">Two's-complement notation</a></p>

<p>The maximum number that can be represented with a k-bit two's-complement notation is 2^(k-1)−1</p>
","794104"
"How to analyze binary file?","40387","","<p>I have a binary file. I don't know how it's formatted, I only know it comes from a delphi code. </p>

<p>Does it exist any way to analyze a binary file? </p>

<p>Does it exist any ""pattern"" to analyze and deserialize the binary content of a file with unknown format?</p>
","<p>Try these:</p>

<ol>
<li><strong>Deserialize data</strong>: analyze how it's compiled your exe (try <a href=""http://vnet.times.lv/exe/fa.rar"" rel=""noreferrer"">File Analyzer</a>). Try to deserialize the binary data with the language discovered. Then serialize it in a xml format (language-indipendent) that every programming language can understand</li>
<li><strong>Analyze the binary data</strong>: try to save various versions of the file with little variation and use a diff program to analyze the meaning of every bit with an hex editor. Use it in conjunction with binary hacking techniques (like <a href=""http://www.iwriteiam.nl/Ha_HTCABFF.html"" rel=""noreferrer"">How to crack a Binary File Format by Frans Faase</a>)</li>
<li><strong>Reverse Engineer the application</strong>: try getting code using reverse engineering tools for the programming language used for build the app (found with <a href=""http://vnet.times.lv/exe/fa.rar"" rel=""noreferrer"">File Analyzer</a>). Otherwise use disassembler analysis tool like <a href=""http://www.hex-rays.com/idapro/overview.htm"" rel=""noreferrer"">IDA Pro Disassembler</a></li>
</ol>
","1027437"
"Adding and subtracting two's complement","40133","","<p>Using six-bit one's and two's complement representation I am trying to solve the following problem:</p>

<pre><code>12 - 7 
</code></pre>

<p>Now, i take 12 in binary and 7 in binary first.</p>

<pre><code>12 = 001100 - 6 bit 
7 =  000111 - 6 bit
</code></pre>

<p>Then, would I then flip the bit for two's complement and add one?</p>

<pre><code>12 = 110011 ones complement 
     +    1
    -------
     001101

7  = 111000 ones complement 
    +     1
   ---------
      111001
</code></pre>

<p>then, add those two complement together</p>

<pre><code> 001101
+111001
-------
1000110 = overflow? discard the last digit?  If so I get 5
</code></pre>

<p>Now, if I have a number like</p>

<pre><code>-15 + 2
</code></pre>

<p>I would then add a sign magnitude on the MSB if it's a zero?</p>

<p>like:</p>

<pre><code>-15 = 001111 6 bit
</code></pre>

<p>Would I add a 1 at the end here before I flip the bits?</p>

<pre><code>  = 101111
</code></pre>
","<p>Using two's complement to represent negative values has the benefit that subtraction and addition are the same. In your case, you can think of <code>12 - 7</code> as <code>12 + (-7)</code>. Hence you only need to find the two's complement representation of -7 and add it to +12:</p>

<pre><code>12  001100
-7  111001   -- to get this, invert all bits of 7 (000111) and add 1
----------
 5 1000101
</code></pre>

<p>Then discard the carry (indicates overflow), and you have your result: <code>000101</code> which equals to 5 as expected.</p>

<p>For your example of <code>-15 + 2</code>, simply follow the same procedure to get the two's complement representation of -15:</p>

<pre><code>15  001111
    110000   -- inverted bits
    110001   -- add 1
</code></pre>

<p>Now do the addition as usual:</p>

<pre><code>-15  110001
  2  000010
-----------
res  110011
</code></pre>

<p>To see that <code>res</code> indeed equals -13, you can see that it is negative (MSB set). For the magnitude, convert to positive (invert bits, add 1):</p>

<pre><code>res  110011
     001100  -- inverted bits
     001101  -- add 1
</code></pre>

<p>Hence the magnitude is 13 as expected.</p>
","3878135"
"How can I copy several binary files into one file on a Linux system?","40082","","<p>I need to copy the content of a folder which contains binary files to one binary file in another directory. </p>

<p>In Windows I can just use:</p>

<pre><code>copy file1 + file2 targetfile /B 
</code></pre>

<p>I couldn't find something similar for Linux (I saw an approach with <code>cat</code>, but I'm unsure if this really works for binary files).</p>
","<p>Unix has no distinction between text and binary files, which is why you can just <code>cat</code> them together:</p>

<pre><code>cat file1 file2 &gt; target_file
</code></pre>
","10347303"
"Convert a binary string representation to a byte array","39866","","<p>How do you convert a string such as ""01110100011001010111001101110100"" to a byte array then used File.WriteAllBytes such that the exact binary string is the binary of the file. In this case it would be the the text ""test"".</p>
","<p>In case you don't have this LINQ fetish, so common lately, you can try the normal way</p>

<pre><code>string input ....
int numOfBytes = input.Length / 8;
byte[] bytes = new byte[numOfBytes];
for(int i = 0; i &lt; numOfBytes; ++i)
{
    bytes[i] = Convert.ToByte(input.Substring(8 * i, 8), 2);
}
File.WriteAllBytes(fileName, bytes);
</code></pre>

<p>LINQ is great but there must be some limits.</p>
","3436456"
"Binary file reading/writing in C","38845","","<p>So I have an input.bin file which contains the following</p>

<pre><code>IK-SZH;jdl72u;John Doe;2013-03-28 11:05
IK-GRR;kat91n;Jane Doe;2013-03-21 15:41
IK-GRR;oat62f;Jane Doe;2013-03-24 08:08
</code></pre>

<p>What I am doing is to read it into a struct. Doing some stuff with the data. Add/Delete lines.
Then i would like to write the content of the structure back to the input.bin file in the same format as above.</p>

<p>But instead of appearing as it is above. It's like this (no spaces):</p>

<pre><code>IK-SZH NUL jdl72u NUL John Doe NUL NUL NUL NUL NUL 2013-03-28 NUL NUL NUL IK-GRR NUL kat91n NUL Jane Doe NUL NUL NUL NUL ...
</code></pre>

<p>When I re-read the file (with the NULs) It only puts the 1st line into the struct</p>

<p>My code</p>

<pre><code>typedef struct foo {
    char kid[7];    
    char jid[7];    
    char name[21];  
    char time[20];  

} Foo;

Foo foo[200];
FILE* fp;
int size;
</code></pre>

<p>------- File reader</p>

<pre><code>void read(char* filename){
    fp = fopen(filename, ""rb""); 
    int i = 0;

    while (!feof(fp)) {

        if (fp==NULL){perror(""File opening error\n""); exit(1);}

        fscanf(fp,""%[^;]; %[^;]; %20[^\;]; %s\n"", foo[i].kid, foo[i].jid,
                foo[i].name, foo[i].time);
        i++;
    }

    size = i;

    print();

    fclose(fp);
}


void print(){
    int i;
    for (i = 0; i &lt; size; ++i){
        printf(""%s\t %s\t %s\t %s\n"", foo[i].kid, foo[i].jid,
               foo[i].name, foo[i].time);
    }
}
</code></pre>

<p>----- Writer</p>

<pre><code>void write(){
    char str[1000];

    FILE* f = fopen(""input.bin"", ""wb"");
    fseek(f, 0, SEEK_SET);
    int i;
    for (i = 0; i &lt; jel_size; i++)
            fwrite(&amp;foo[i], sizeof(struct foo), 1, f);
    fclose(f);

}
</code></pre>

<p>Tried this, but this didn't write anything to the file:</p>

<pre><code>    char str[1000];
    sprintf(str,""%s;%s;%s;%s\n"", jelent[i].kazon,
                    jelent[i].jazon,jelent[i].nev,  jelent[i].ido );

        write(f,&amp;str,sizeof(str))!=sizeof(str);
</code></pre>
","<p>Your structure definition is:</p>

<pre><code>typedef struct foo
{
    char kid[7];    
    char jid[7];    
    char name[21];  
    char time[20];  
} Foo;
</code></pre>

<p>The code that writes the structures to the file is in <code>write()</code>:</p>

<pre><code>for (i = 0; i &lt; jel_size; i++)
    fwrite(&amp;foo[i], sizeof(struct foo), 1, f);
</code></pre>

<p>If the structures are intialized with all bytes zero, then for the first row of data you mention:</p>

<pre><code>IK-SZH;jdl72u;John Doe;2013-03-28 11:05
</code></pre>

<p>we can infer that the structure contains:</p>

<pre><code>IK-SZH\0
jdl72u\0
John Doe\0\0\0\0\0\0\0\0\0\0\0\0\0
2013-03-28 11:05\0\0\0\0
</code></pre>

<p>which more or less agrees with what you say the file contains:</p>

<pre><code>IK-SZH NUL jdl72u NUL John Doe NUL NUL NUL NUL NUL 2013-03-28 NUL NUL NUL 
</code></pre>

<p>By my reckoning, you're missing a few NULs after the name and the time and one NUL after the date.</p>

<p>If you want text output, you will have to format the data in <code>write()</code> using <code>fprintf()</code> analogous to the <code>fscanf()</code> statement you have in the <code>read()</code> function.  You should probably return a status from the function to indicate whether it was successful.  You can argue for checking that <code>fclose()</code> was successful, too.</p>

<pre><code>void write(void)
{
    FILE *fp = fopen(""input.bin"", ""w"");
    if (fp != 0)
    {
        for (int i = 0; i &lt; jel_size; i++)
            fprintf(fp, ""%s;%s;%s;%s\n"", foo[i].kid, foo[i].jid, foo[i].name, foo[i].time);
        fclose(fp);
    }
}
</code></pre>

<p>If you want binary output, you should use binary input in <code>read()</code>.  Again, you should consider returning an indication of success or failure; avoiding global variables is good, too.</p>

<pre><code>void read(const char *filename)
{
    FILE *fp = fopen(filename, ""rb""); 
    if (fp != 0)
    {
        for (i = 0; fread(&amp;foo[i], sizeof(foo[i]), 1, fp) == 1; i++)
            ;
        fclose(fp);
        size = i;
    }
}
</code></pre>

<p>Either technique will work; trying to use one on output and the other on input is going to lead to chaos and confusion.</p>

<p>Note that functions <code>read()</code> and <code>write()</code> are used by POSIX with a different interface.  While you stick with Standard C, the names are fair for you to use, but you'd probably be better off with alternative names, such as <code>reader()</code> and <code>writer()</code> or <code>foo_read()</code> and <code>foo_write()</code>.</p>
","15754508"
"How can I detect if a file is binary (non-text) in python?","38744","","<p>How can I tell if a file is binary (non-text) in python? I am searching through a large set of files in python, and keep getting matches in binary files. This makes the output look incredibly messy.</p>

<p>I know I could use grep -I, but I am doing more with the data than what grep allows for.</p>

<p>In the past I would have just searched for characters greater than 0x7f, but utf8 and the like make that impossible on modern systems. Ideally the solution would be fast, but any solution will do.</p>
","<p>You can also use the <a href=""https://docs.python.org/3.6/library/mimetypes.html"" rel=""nofollow noreferrer"">mimetypes</a> module:</p>

<pre><code>import mimetypes
...
mime = mimetypes.guess_type(file)
</code></pre>

<p>It's fairly easy to compile a list of binary mime types. For example Apache distributes with a mime.types file that you could parse into a set of lists, binary and text and then check to see if the mime is in your text or binary list.</p>
","898723"
"How do I add an attachment to an email using System.Net.Mail?","37909","","<p>I have an excel document represented as a byte[] and I'm wanting to send it as an attachment in an email.</p>

<p>I'm having a bit of trouble constructing the attachment.</p>

<p>I can create an Attachment which has the following constructors:</p>

<pre><code>(Stream contentStream, ContentType contentType)
(Stream contentStream, string name)
(Stream contentStream, string name, string mediaType)
</code></pre>

<p>My idea at the moment is to create a MemoryStream from the byte[] and pass it to the method which creates the attachment.</p>

<p>Unfortunately I can't see a way to obtain the intended filename and content type from the MemoryStream and I also can't see how to supply the correct content type. There are options for plain text, Pdf, Rtf etc but none that I can see that immediately jump out at me as the one I should use for an Excel document. </p>

<p>The closest I can find is <a href=""http://msdn.microsoft.com/en-us/library/system.net.mime.mediatypenames.application.octet.aspx"" rel=""noreferrer"">MediaTypeNames.Application.Octet</a> which states: </p>

<blockquote>
  <p>The Octet member designates that the
  attachment contains generic binary
  data.</p>
</blockquote>

<p>However, even if this is the one to use, unless it can be passed as a property of the Stream then my method for sending emails will only be able to send a byte[] as an Excel document...</p>

<p>Is there perhaps some other sort of Stream I could use? Or will I have to create my own type of Stream that has the details I need.</p>

<p>Surely someone out there has done this thing before and surely Microsoft would have thought this through to this level....</p>

<p>Any help would be much appreciated.</p>

<p><strong>Update:</strong>
Please don't vote for any answers that use the constructors that take the filename as a string. I'm really needing help using the ones that take a Stream...I want to avoid having to write the file to disk, email it, and then immediately delete it. Since there is a method that allows me to do that I'd like to use that one if at all possible.</p>

<p><strong>Solution Update</strong></p>

<p>Conrad managed to find what I was looking for! Thanks heaps man!</p>

<p>I'll just document the suggested solution just in case something happens to the content at the supplied link.</p>

<p>Credit for this solution goes to <a href=""http://www.systemnetmail.com/faq/3.4.2.aspx"" rel=""noreferrer"">www.systemnetmail.com</a></p>

<pre><code>static void AttachmentFromStream()
{

//create the mail message
MailMessage mail = new MailMessage();

//set the addresses
mail.From = new MailAddress(""me@mycompany.com"");
mail.To.Add(""you@yourcompany.com"");

//set the content
mail.Subject = ""This is an email"";
mail.Body = ""this content is in the body"";

//Get some binary data
byte[] data = GetData();

//save the data to a memory stream
MemoryStream ms = new MemoryStream(data);

//create the attachment from a stream. Be sure to name the data 
//with a file and 
//media type that is respective of the data
mail.Attachments.Add( new Attachment( ms, ""example.txt"", ""text/plain"" ));

SmtpClient smtp = new SmtpClient(""127.0.0.1"");
smtp.Send(mail);
}
</code></pre>

<p>In my case, it just means I'll have to change my method to take the filename and fileformat as strings. I'll try using the Octet one...but failing that I'll just pass in the official MIME type.</p>

<p>All things considered, this is a pretty obvious solution...but I do appreciate the help in solving it...and the good thing is this solution will be documented for future programmers who have the same problem.</p>

<p>Thanks again everyone for you help!</p>
","<p>The attachment constructor does indeed have a constructor that does what you need. I'm assuming you're using the System.Net.MailMessage class from .NET Framework 2. If so <a href=""http://www.systemnetmail.com/faq/3.4.2.aspx"" rel=""noreferrer"">read this link</a> for some sample code of what you need</p>
","527309"
"how to output an int in binary?","37840","","<pre><code>int x = 5;
cout&lt;&lt;(char)x;
</code></pre>

<p>the code above outputs an int x in raw binary, but only 1 byte. what I need it to do is output the x as 4-bytes in binary, because in my code, x can be anywhere between 0 and 2^32-1, since</p>

<pre><code>cout&lt;&lt;(int)x;
</code></pre>

<p>doesn't do the trick, how would I do it?</p>
","<p>You can use the <code>std::ostream::write()</code> member function:</p>

<pre><code>std::cout.write(reinterpret_cast&lt;const char*&gt;(&amp;x), sizeof x);
</code></pre>

<p>Note that you would usually want to do this with a stream that has been opened in binary mode.</p>
","3269780"
"How to convert a hexadecimal string to a binary string in C","37674","","<p>I have a text file with hexadecimal values. Now I need to convert the hexadecimal value to binary and need to save it on another file.
But I don't know how to convert the hexadecimal value to a binary string!
Please help...</p>
","<pre><code>const char input[] = ""...""; // the value to be converted
char res[9]; // the length of the output string has to be n+1 where n is the number of binary digits to show, in this case 8
res[8] = '\0';
int t = 128; // set this to s^(n-1) where n is the number of binary digits to show, in this case 8
int v = strtol(input, 0, 16); // convert the hex value to a number

while(t) // loop till we're done
{
    strcat(res, t &lt; v ? ""1"" : ""0"");
    if(t &lt; v)
        v -= t;
    t /= 2;
}
// res now contains the binary representation of the number
</code></pre>

<p>As an alternative (this assumes there's no prefix like in <code>""0x3A""</code>):</p>

<pre><code>const char binary[16][5] = {""0000"", ""0001"", ""0010"", ""0011"", ""0100"", ...};
const char digits = ""0123456789abcdef"";

const char input[] = ""..."" // input value
char res[1024];
res[0] = '\0';
int p = 0;

while(input[p])
{
    const char *v = strchr(digits, tolower(input[p++]));
    if (v)
        strcat(res, binary[v - digits]);
}
// res now contains the binary representation of the number
</code></pre>
","8551475"
"Reading and interpreting data from a binary file in Python","37498","","<p>I want to read a file byte by byte and check if the last bit of each byte is set:</p>

<pre><code>#!/usr/bin/python

def main():
    fh = open('/tmp/test.txt', 'rb')
    try:
        byte = fh.read(1)
        while byte != """":
            if (int(byte,16) &amp; 0x01) is 0x01:
                print 1
            else:
                print 0
            byte = fh.read(1)
    finally:
        fh.close

    fh.close()

if __name__ == ""__main__"":
        main()
</code></pre>

<p>The error I get is:</p>

<pre><code>Traceback (most recent call last):
  File ""./mini_01.py"", line 21, in &lt;module&gt;
    main()
  File ""./mini_01.py"", line 10, in main
    if (int(byte,16) &amp; 0x01) is 0x01:
ValueError: invalid literal for int() with base 16: '\xaf'
</code></pre>

<p>Anyone an idea? I didn't succeed using the struct and the binascii modules.</p>
","<p>You want to use <code>ord</code> instead of <code>int</code>:</p>

<pre><code>if (ord(byte) &amp; 0x01) == 0x01:
</code></pre>
","3943174"
"Why does a byte only have 0 to 255?","37262","","<p>Why does a byte only range from 0 to 255?</p>
","<p>Strictly speaking, the term ""byte"" can actually refer to a unit with other than 256 values. It's just that that's the <em>almost universal</em> size. From <a href=""http://en.wikipedia.org/wiki/Byte"">Wikipedia</a>:</p>

<blockquote>
  <p>Historically, a byte was the number of
  bits used to encode a single character
  of text in a computer and it is for
  this reason the basic addressable
  element in many computer
  architectures.</p>
  
  <p>The size of the byte has historically
  been hardware dependent and no
  definitive standards exist that
  mandate the size. The de facto
  standard of eight bits is a convenient
  power of two permitting the values 0
  through 255 for one byte. Many types
  of applications use variables
  representable in eight or fewer bits,
  and processor designers optimize for
  this common usage. The popularity of
  major commercial computing
  architectures have aided in the
  ubiquitous acceptance of the 8-bit
  size. The term octet was defined to
  explicitly denote a sequence of 8 bits
  because of the ambiguity associated
  with the term byte.</p>
</blockquote>

<p>Ironically, these days the size of ""a single character"" is no longer consider a single byte in most cases... most commonly, the idea of a ""character"" is associated with Unicode, where characters can be represented in a number of different formats, but are typically either 16 bits or 32.</p>

<p>It would be amusing for a system which used UCS-4/UTF-32 (the direct 32-bit representation of Unicode) to designate 32 bits as a byte. The confusion caused would be spectacular.</p>

<p>However, assuming we take ""byte"" as synonymous with ""octet"", there are eight independent <a href=""http://en.wikipedia.org/wiki/Bit""><em>bits</em></a>, each of which can be either on or off, true or false, 1 or 0, however you wish to think of it. That leads to 256 possible values, which are typically numbered 0 to 255. (That's not always the case though. For example, the designers of Java unfortunately decided to treat bytes as <em>signed</em> integers in the range -128 to 127.)</p>
","4986506"
"Converting very simple ARM instructions to binary/hex","36634","","<p>I've been trying to use <strong><a href=""http://www.nyx.net/~troddis/ARM.html"" rel=""noreferrer"">this page</a></strong> as well as various other guides to figure out how to express very simple ARM instructions as binary and hex. It seems like it should be a straightforward process to me, but I still don't understand. Here's a few examples.</p>

<p>Basic NOP:</p>

<pre><code>       what goes here?          what goes here?
             _↓_                  _____↓____
            |   |                |          |
mov r0, r0 ; ????00?1101?????????????????????
                         |__||__|
                          ↑    ↑
                 how do I express registers?
</code></pre>

<p>Same basic question for others.</p>

<p>Comparing two registers:</p>

<pre><code>cmp r1, r0
</code></pre>

<p>Adding immediate to register value:</p>

<pre><code>add r0, #0x1a
</code></pre>

<p>All of these tutorials online are excellent at describing how to use instructions like these, but none I have been able to find actually walk through how to convert an ARM instruction in to the binary/hex/machine code into which it gets assembled.</p>

<p>Thanks in advance for your help.</p>
","<p>Here is how data processing instructions are coded:</p>

<p><img src=""https://i.stack.imgur.com/0cPOx.png"" alt=""ARM data processing instructions""></p>

<p>You have condition codes table in that page of yours. Registers are coded <code>0000</code> through <code>1111</code>.</p>

<p>All your examples fall under the same category. The picture is extracted from some document on my HDD, but I also managed to find it by <a href=""http://www.ic.unicamp.br/~ranido/mc404/arm/arm-instructionset.pdf"">google</a>. Coding those instructions is a tedious job.</p>

<p>So, <code>mov r0, r0</code> should go like this:</p>

<pre><code>1110 00 0 0 1101 0000 0000 00000000
</code></pre>

<p>I put Rn to 0, because it is not actually applicable to <code>MOV</code>. In case of <code>CMP</code>, I believe, <code>S</code> is always 1. </p>
","11786481"
"Converting long string of binary to hex c#","36379","","<p>I'm looking for a way to convert a long string of binary to a hex string.</p>

<p>the binary string looks something like this <code>""0110011010010111001001110101011100110100001101101000011001010110001101101011""</code></p>

<p>I've tried using </p>

<pre><code>hex = String.Format(""{0:X2}"", Convert.ToUInt64(hex, 2));
</code></pre>

<p>but that only works if the binary string fits into a Uint64 which if the string is long enough it won't.</p>

<p>is there another way to convert a string of binary into hex?</p>

<p>Thanks</p>
","<p>I just knocked this up. Maybe you can use as a starting point...</p>

<pre><code>public static string BinaryStringToHexString(string binary)
{
    StringBuilder result = new StringBuilder(binary.Length / 8 + 1);

    // TODO: check all 1's or 0's... Will throw otherwise

    int mod4Len = binary.Length % 8;
    if (mod4Len != 0)
    {
        // pad to length multiple of 8
        binary = binary.PadLeft(((binary.Length / 8) + 1) * 8, '0');
    }

    for (int i = 0; i &lt; binary.Length; i += 8)
    {
        string eightBits = binary.Substring(i, 8);
        result.AppendFormat(""{0:X2}"", Convert.ToByte(eightBits, 2));
    }

    return result.ToString();
}
</code></pre>
","5612479"
"How to get only the first ten bytes of a binary file","35371","","<p>I am writing a bash script that needs to get the header (first 10 bytes) of a file and then in another section get everything except the first 10 bytes.  These are binary files and will likely have <code>\0</code>'s and <code>\n</code>'s throughout the first 10 bytes.  It seems like most utilities work with ASCII files.  What is a good way to achieve this task?</p>
","<p>To get the first 10 bytes, as noted already:</p>

<pre><code>head -c 10
</code></pre>

<p>To get all but the first 10 bytes (at least with GNU <code>tail</code>):</p>

<pre><code>tail -c+11
</code></pre>
","4411216"
"Binary String to Integer","35312","","<p>I have a binary string, entered by the user, which I need to convert to an integer.</p>

<p>At first I naivly used this simple line:</p>

<pre><code>Convert.ToInt32(""11011"",2);
</code></pre>

<p>Unfortunately this throws an exception if the user enters the integer directly.</p>

<pre><code>Convert.ToInt32(""123"",2); // throws Exception
</code></pre>

<p>How can I make sure that the string entered by the user actually is a binary string? </p>

<ul>
<li>try..catch....but that's just too ugly.</li>
<li>something like 'Int32.TryParse' maybe.</li>
</ul>

<p>Thanks</p>
","<p>You could use a <code>Regex</code> to check that it is ""^[01]+$"" (or better, ""^[01]{1,32}$""), and <em>then</em> use <code>Convert</code>?</p>

<p>of course, exceptions are <em>unlikely</em> to be a huge problem anyway! Inelegant? maybe. But they work.</p>

<p>Example (formatted for vertical space):</p>

<pre><code>static readonly Regex binary = new Regex(""^[01]{1,32}$"", RegexOptions.Compiled);
static void Main() {
    Test("""");
    Test(""01101"");
    Test(""123"");
    Test(""0110101101010110101010101010001010100011010100101010"");
}
static void Test(string s) {
    if (binary.IsMatch(s)) {
        Console.WriteLine(Convert.ToInt32(s, 2));
    } else {
        Console.WriteLine(""invalid: "" + s);
    }
}
</code></pre>
","1271571"
"Binary representation in Java","35280","","<p>I am finding it difficult to understand and work with this binary representation in java:</p>

<p>With the help of the user Jon Skeet, I understood that binary representation should be built this way.</p>

<p>Here's a code sample:</p>

<pre><code>public class chack {

public static void main(String[] args) {
    int num2=2;
    int num3=3;
    int num4=4;
    int num1=1;
    int nirbinary = (num1 &lt;&lt; 24) | (num2 &lt;&lt; 16) | (num3 &lt;&lt; 8) | num4;
    System.out.println(nirbinary);
    String nir=  Integer.toBinaryString(nirbinary);
    System.out.println(nir);
    }
}
</code></pre>

<p>Couple of question:</p>

<ol>
<li>How does one get num1 (for example) back from an int who is already in this binary</li>
<li>why do I get <code>16909060</code> when I print <code>nirbinary</code>- what does it stands for?
How does one get num1 (for example) back from an int who is already in this binary 
representation?</li>
</ol>

<p>Thank you</p>
","<p><code>16909060</code> stands for the number 16909060.</p>

<p>It is <a href=""http://www.google.com/search?q=1%2A2%5E24%2B2%2A2%5E16%2B3%2A2%5E8%2B4"" rel=""noreferrer"">(1 * 2<sup>24</sup>) + (2 * 2<sup>16</sup>) + (3 * 2<sup>8</sup>) + 4</a>.</p>

<p>To get <code>num1</code> back out, just right-shift the result the same amount you left-shifted and mask out the other bytes (not always necessary for <code>num1</code><sup>(*)</sup>, but for the others):</p>

<pre><code>int num1 = nirbinary &gt;&gt; 24 &amp; 0xFF;
int num2 = nirbinary &gt;&gt; 16 &amp; 0xFF;
int num3 = nirbinary &gt;&gt; 8 &amp; 0xFF;
int num4 = nirbinary &amp; 0xFF;
</code></pre>

<p>Note that <code>nirbinary</code> is not ""a binary representation"". Or more precisely: it's no more or less binary than <code>num1</code>, <code>num2</code>, <code>num3</code> and <code>num4</code>: internally all numbers (and characters, and booleans, ...) are stored in binary.</p>

<p>(*) note that if <code>num1</code> is > 127, then you <em>either</em> need to use <code>&gt;&gt;&gt;</code> to do the right-shift <em>or</em> use the <code>&amp; 0xFF</code> in order to ensure that the correct value is restored. The difference between <code>&gt;&gt;</code> and <code>&gt;&gt;&gt;</code> are the ""new"" bits inserted on the ""left"" side of the value: With <code>&gt;&gt;</code> they will depend on the highest-value bit (known as sign-extension) and with <code>&gt;&gt;&gt;</code> they will always be 0.</p>
","5593495"
"writing integer to binary file (C++)","35104","","<p>I have a very simple question, which happens to be hard for me since this is the first time I tried working with binary files, and I don't quite understand them. All I want to do is write an integer to a binary file.</p>

<p>Here is how I did it:</p>

<pre><code>#include &lt;fstream&gt;
using namespace std;
int main () {
    int num=162;
    ofstream file (""file.bin"", ios::binary);
    file.write ((char *)&amp;num, sizeof(num));
    file.close (); 
    return 0;
}
</code></pre>

<p>Could you please tell me if I did something wrong, and what?</p>

<p>The part that is giving me trouble is line with file.write, I don't understand it.</p>

<p>Thank you in advance.</p>
","<blockquote>
  <p>The part that is giving me trouble is line with file.write, I don't
  understand it.</p>
</blockquote>

<p>If you read the documentation of <code>ofstream.write()</code> method, you'll see that it requests two arguments:</p>

<ol>
<li><p>a <strong>pointer to a block of data</strong> with the content to be written;</p></li>
<li><p>an integer value representing the <strong>size, in bytes, of this block</strong>.</p></li>
</ol>

<p>This statement just gives these two pieces of information to <code>ofstream.write()</code>:</p>

<pre><code>file.write(reinterpret_cast&lt;const char *&gt;(&amp;num), sizeof(num));
</code></pre>

<p><code>&amp;num</code> is the address of the block of data (in this case just an integer variable), <code>sizeof(num)</code> is the size of this block (e.g. 4 bytes on Windows platforms).</p>
","9244948"
"Generate all binary strings of length n with k bits set","35049","","<p>What's the best algorithm to find all binary strings of length n that contain k bits set?  For example, if n=4 and k=3, there are...</p>

<pre><code>0111
1011
1101
1110
</code></pre>

<p>I need a good way to generate these given any n and any k so I'd prefer it to be done with strings.</p>
","<p>This method will generate all integers with exactly N '1' bits.</p>

<p>From <a href=""https://graphics.stanford.edu/~seander/bithacks.html#NextBitPermutation"" rel=""noreferrer"">https://graphics.stanford.edu/~seander/bithacks.html#NextBitPermutation</a></p>

<blockquote>
  <h3>Compute the lexicographically next bit permutation</h3>
  
  <p>Suppose we have a pattern of N bits set to 1 in an integer and we want
  the next permutation of N 1 bits in a lexicographical sense. For
  example, if N is 3 and the bit pattern is <code>00010011</code>, the next patterns
  would be <code>00010101</code>, <code>00010110</code>, <code>00011001</code>, <code>00011010</code>, <code>00011100</code>, <code>00100011</code>,
  and so forth. The following is a fast way to compute the next
  permutation.</p>

<pre><code>unsigned int v; // current permutation of bits
unsigned int w; // next permutation of bits

unsigned int t = v | (v - 1); // t gets v's least significant 0 bits set to 1
// Next set to 1 the most significant bit to change,
// set to 0 the least significant ones, and add the necessary 1 bits.
w = (t + 1) | (((~t &amp; -~t) - 1) &gt;&gt; (__builtin_ctz(v) + 1));
</code></pre>
  
  <p>The <code>__builtin_ctz(v)</code> GNU C compiler intrinsic for x86 CPUs returns the number of trailing zeros. If you are using Microsoft compilers for
  x86, the intrinsic is <code>_BitScanForward</code>. These both emit a <code>bsf</code>
  instruction, but equivalents may be available for other architectures.
  If not, then consider using one of the methods for counting the
  consecutive zero bits mentioned earlier. Here is another version that
  tends to be slower because of its division operator, but it does not
  require counting the trailing zeros.</p>

<pre><code>unsigned int t = (v | (v - 1)) + 1;
w = t | ((((t &amp; -t) / (v &amp; -v)) &gt;&gt; 1) - 1);
</code></pre>
  
  <p>Thanks to Dario Sneidermanis of Argentina, who provided this on November 28, 2009.</p>
</blockquote>
","2075867"
"How can I convert hexadecimal numbers to binary in C++?","34998","","<p>I am taking a beginning C++ class, and would like to convert letters between hex representations and binary. I can manage to print out the hex numbers using:</p>

<pre><code>for(char c = 'a'; c &lt;= 'z'; c++){
    cout &lt;&lt; hex &lt;&lt; (int)c;
}
</code></pre>

<p>But I can't do the same for binary. There is no <code>std::bin</code> that I can use to convert the decimal numbers to binary. </p>
","<p>Like so:</p>

<pre><code>for(char c = 'a'; c &lt;= 'z'; c++){
        std::bitset&lt;sizeof(char) * CHAR_BIT&gt; binary(c); //sizeof() returns bytes, not bits!
        std::cout &lt;&lt; ""Letter: "" &lt;&lt; c &lt;&lt; ""\t"";
        std::cout &lt;&lt; ""Hex: "" &lt;&lt; std::hex &lt;&lt; (int)c &lt;&lt; ""\t"";
        std::cout &lt;&lt; ""Binary: "" &lt;&lt; binary &lt;&lt; std::endl;
    }
</code></pre>
","483653"
"Adding binary numbers in C++","34976","","<p>How would I add two binary numbers in C++? What is the correct logic?</p>

<p>Here is my effort, but it doesn't seem to be correct:</p>

<pre><code>#include &lt;iostream&gt;
using namespace std;
int main()
{
    int a[3];
    int b[3];
    int carry = 0;
    int result[7];

    a[0] = 1;
    a[1] = 0;
    a[2] = 0;
    a[3] = 1;

    b[0] = 1;
    b[1] = 1;
    b[2] = 1;
    b[3] = 1;

    for(int i = 0; i &lt;= 3; i++)
    {
        if(a[i] + b[i] + carry == 0)
        {
            result[i] = 0;
            carry = 0;
        }

        if(a[i] + b[i] + carry == 1)
        {
            result[i] = 0;
            carry = 0;
        }

        if(a[i] + b[i] + carry == 2)
        {
            result[i] = 0;
            carry = 1;
        }

        if(a[i] + b[i] + carry &gt; 2)
        {
            result[i] = 1;
            carry = 1;
        }
    }
    for(int j = 0; j &lt;= 7; j++)
    {
        cout&lt;&lt;result[j]&lt;&lt;"" "";
    }
    system(""pause"");
}
</code></pre>
","<p>Well, it is a pretty trivial problem. </p>

<blockquote>
  <p><em>How to add two binary numbers in c++. what is the logic of it.</em></p>
</blockquote>

<p>For adding two binary numbers, a and b. You can use the following equations to do so.</p>

<blockquote>
  <p>sum = a xor b</p>
  
  <p>carry = ab</p>
</blockquote>

<p>This is the equation for a <a href=""http://en.wikipedia.org/wiki/Adder_%28electronics%29#Half_adder"">Half Adder</a>.</p>

<p>Now to implement this, you may need to understand how a <a href=""http://en.wikipedia.org/wiki/Adder_%28electronics%29#Full_adder"">Full Adder</a> works.</p>

<blockquote>
  <p>sum = a xor b xor c</p>
  
  <p>carry = ab+bc+ca</p>
</blockquote>

<p>Since you store your binary numbers in int array, you might want to understand <a href=""http://en.wikipedia.org/wiki/Bitwise_operation"">bitwise operation</a>.
You can use ^ for XOR,| operator for OR, &amp; operator for AND.</p>

<p>Here is a sample code to calculate the sum.</p>

<pre><code>for(i = 0; i &lt; 8 ; i++){
   sum[i] = ((a[i] ^ b[i]) ^ c); // c is carry
   c = ((a[i] &amp; b[i]) | (a[i] &amp; c)) | (b[i] &amp; c); 
}
</code></pre>
","13283126"
"Where is my application binary in XCode?","34451","","<p>I've built an app for the iTunes store.  However, being a noob to the platform, I can't figure out how to submit the app.</p>

<p>Where is the actual binary that I need to submit to the iTunes store?  What folder does it get built in?</p>
","<p>By default, you'll see a build directory inside the directory containing your project.<br>
In that build directory:</p>

<p><code>&lt;Project Name&gt;</code>.build` contains all the object files created during compilation</p>

<p>and a series of folders with the following naming scheme:</p>

<pre><code>&lt;build setting&gt;-&lt;platform&gt;
</code></pre>

<p>You're likely looking for something like ""Release-iphoneos"".  In that folder you should find the .app package to submit.</p>
","1460601"
"Is there any graphical Binary Diff tool for Mac OS X?","34359","","<p>Are there any Binary Diff tools for Mac OS X with a GUI? There are a gazillion text-based diff tools, but I need to compare two binary files. Essentially two Hex Editors with Dec/Hex View next to each other (the binary files are a custom file format, so not images or anything that has a more specialized diff tool)</p>
","<p>there is Ellié Computing Merge (<a href=""http://www.elliecomputing.com"" rel=""noreferrer"">http://www.elliecomputing.com</a>) (NB: I work for ECMerge).
it can compare arbitrarily large files with usual Hex+ASCII views and side by side visual diff.
it works on mac and linux/windows as well</p>
","7913180"
"Why don't people use base128?","34303","","<p>Why is everybody using base 64 to transmit binary data on the web? I ask that because the ASCII character set has 128 characters which in theory could represent base 128...</p>
","<p>The problem is that at least 32 characters of the ASCII character set are 'control characters' which may be interpreted by the receiving terminal. E.g., there's the BEL (bell) character that makes the receiving terminal chime. There's the SOT (Start Of Transmission) and EOT (End Of Transmission) characters which performs exactly what their names imply. And don't forget the characters CR and LF, which <em>may</em> have special meanings in how data structures are serialized/flattened into a stream.</p>

<p>Adobe created <a href=""http://en.wikipedia.org/wiki/Ascii85"" rel=""noreferrer"">the Base85 encoding</a> to use more characters in the ASCII character set, but AFAIK it's protected by patents.</p>
","6008744"
"Floating Point Modulo Operation","34191","","<p>I am trying to implement the range reduction operation for trigonometry.  But instead I think it might be better to just perform a modulo pi/2 operation on incoming data. I was wondering what algorithms exist and are efficient for this operation for 32-bit IEEE 754 floating-point?</p>

<p>I have to implement this in assembly, so fmod, division, multiplication, etc. aren't available to me with just one instruction. My processor uses 16-bit words and I have implemented 32-bit floating point addition, subtraction, multiplication, division, square root, cosine, and sine. I just need range reduction (modulus) for inputting values to cosine and sine. </p>
","<p>I think standard library's <code>fmod()</code> will be the best choice in most cases. Here's a <a href=""http://www.codeguru.com/forum/showthread.php?t=438110"" rel=""noreferrer"">link</a> to a discussion of several simple algorithms.</p>

<p>On my machine, <code>fmod()</code> uses optimized inline assembly code (<code>/usr/include/bits/mathinline.h</code>):</p>

<pre><code>#if defined __FAST_MATH__ &amp;&amp; !__GNUC_PREREQ (3, 5)
__inline_mathcodeNP2 (fmod, __x, __y, \
  register long double __value;                           \
  __asm __volatile__                                  \
    (""1:    fprem\n\t""                            \
     ""fnstsw    %%ax\n\t""                             \
     ""sahf\n\t""                                   \
     ""jp    1b""                               \
     : ""=t"" (__value) : ""0"" (__x), ""u"" (__y) : ""ax"", ""cc"");           \
  return __value)
#endif
</code></pre>

<p>So it actually uses a dedicated CPU instruction (fprem) for the calculation.</p>
","9505761"
"Convert hex to float","33531","","<p>How to convert the following hex string to float (single precision 32-bit) in Python?</p>

<pre><code>""41973333"" -&gt; 1.88999996185302734375E1

""41995C29"" -&gt; 1.91700000762939453125E1

""470FC614"" -&gt; 3.6806078125E4
</code></pre>
","<pre><code>&gt;&gt;&gt; import struct
&gt;&gt;&gt; struct.unpack('!f', '41973333'.decode('hex'))[0]
18.899999618530273
&gt;&gt;&gt; struct.unpack('!f', '41995C29'.decode('hex'))[0]
19.170000076293945
&gt;&gt;&gt; struct.unpack('!f', '470FC614'.decode('hex'))[0]
36806.078125
</code></pre>

<p>Update: see comment on how to do this in Python 3.</p>
","1592362"
"Convert Hex to Binary in C","33390","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/8197838/convert-a-long-hex-string-in-to-int-array-with-sscanf"">Convert a long hex string in to int array with sscanf</a>  </p>
</blockquote>



<p>I have seen some topics on this before, but most solutions are in Python (curse you for being so easy!).</p>

<p>Is there an easy way to do this in C? This is what my solution needs to be in. I know it's not complicated conceptually, but I am horrendous with C string manipulation and address handling.</p>

<p>Thanks for the help, guys!</p>

<p>----------EDIT-------------</p>

<p>Okay, so I solved that problem, and I have another question (I didn't want to open up a new thread!). Below is my modification to the given code, with the function call and the output.</p>

<pre><code>void htoi(const char *ptr, char *binAddr) {
char value[32] = """";
char ch = *ptr;
int i;
const char* quads[] = {""0000"", ""0001"", ""0010"", ""0011"", ""0100"", ""0101"",
                     ""0110"", ""0111"", ""1000"", ""1001"", ""1010"", ""1011"",
                     ""1100"", ""1101"", ""1110"", ""1111""};

while (ch == ' ' || ch == '\t')
    ch = *(++ptr);

for (i = 0; i &lt; 8; i++) {
    if (ch &gt;= '0' &amp;&amp; ch &lt;= '9')
        strncat(value, quads[ch - '0'], 4);
    if (ch &gt;= 'A' &amp;&amp; ch &lt;= 'F')
        strncat(value, quads[10 + ch - 'A'], 4);
    if (ch &gt;= 'a' &amp;&amp; ch &lt;= 'f')
        strncat(value, quads[10 + ch - 'a'], 4);

    ch = *(++ptr);
    printf(""%s\n"", value);
}

*binAddr = *value;
}
</code></pre>

<p>Here is my function call:</p>

<pre><code>char line[11], hexAddr[8], binAddr[32];
htoi(hexAddr, binAddr);
printf(""%s\n"", binAddr);
</code></pre>

<p>Here is the output (when input with 001133c0):</p>

<p>0000</p>

<p>00000000</p>

<p>000000000001</p>

<p>0000000000010001</p>

<p>00000000000100010011</p>

<p>000000000001000100110011</p>

<p>0000000000010001001100111100</p>

<p>00000000000100010011001111000000</p>

<p>0���</p>

<p>The last line (with the special characters) is the printf(binAddr) in the main function above. It is clear from the printf statements inside the function that the binary code is being constructed correctly.</p>

<p>Once again, this comes down to me not being worth anything with address manipulation. What am I doing wrong?</p>
","<p>It's fairly easy with a lookup table:</p>

<pre><code>const char * const quads = { ""0000"", ""0001"", ""0010"", .... };

const char * hex_to_bin_quad(unsigned char c)
{
  if (c &gt;= '0' &amp;&amp; c &lt;= '9') return quads[     c - '0'];
  if (c &gt;= 'A' &amp;&amp; c &lt;= 'F') return quads[10 + c - 'A'];
  if (c &gt;= 'a' &amp;&amp; c &lt;= 'f') return quads[10 + c - 'a'];
  return -1;
}
</code></pre>

<p>Now iterate over your string and append <code>hex_to_bin_quad(c)</code> for each character (e.g. using <code>strncat</code>). You already know that you'll need a target string of length <code>4 * strlen(src) + 1</code>, so allocate, iterate and concatenate.</p>
","8205319"
"Binary to Decimal Conversion - Formula?","31758","","<p>I've been searching a while and haven't gotten anything too useful yet, I'm working on a subnet calculator, and well I have used the decimal to binary which I found here, though, I haven't found a good way to convert binary to decimal.</p>

<p>Note: Remember its FROM binary TO decimal, anyways, im in need of the formula or something like that (meaning calculating it, not the automated one).</p>

<p>What I've understood by reading some other posts that you can somehow get the result by dividing by 10, but I didn't really understand it, so if anyone could point me in the right direction, I'd be glad.</p>

<p>Any and all help is very much appreciated guys! :)</p>
","<p>Doing it without LINQ:</p>

<pre><code>var s = ""101011"";    // my binary ""number"" as a string
var dec = 0;
for( int i=0; i&lt;s.Length; i++ ) {
  // we start with the least significant digit, and work our way to the left
  if( s[s.Length-i-1] == '0' ) continue;
  dec += (int)Math.Pow( 2, i );
}
</code></pre>

<p>A number in any base can be thought of as the sum of its digits multiplied by their place value.  For example, the decimal number 3906 can be written as:</p>

<pre><code>3*1000 + 9*100 + 0*10 + 6*1
</code></pre>

<p>The place values are simply powers of ten:</p>

<pre><code>3*10^3 + 9*10^2 + 0*10^1 + 6*10^0
</code></pre>

<p>(Remember that any number taken to the power of zero is 1.)</p>

<p>Binary works exactly the same way, except the base is 2, not 10.  For example, the binary number 101011 can be written as:</p>

<pre><code>1*2^5 + 0*2^4 + 1*2^3 + 0*2^2 + 1*2^1 + 1*2^0
</code></pre>

<p>I hope that gives you a better understanding of binary numbers and how to convert them.</p>

<p>On a practical note, the best solution is Matt Grande's; it's always preferable to use a library method instead of rolling your own (unless you have a very good reason to do so).</p>
","9743037"
"gcc compiled binaries give ""cannot execute binary file""","31360","","<p>I compile this program:</p>

<pre><code>#include &lt;stdio.h&gt;

int main()
{
    printf(""Hello World!"");
    return 0;
}
</code></pre>

<p>With this command: </p>

<pre><code>  gcc -c ""hello.c"" -o hello
</code></pre>

<p>And when I try to execute hello, I get </p>

<pre><code>bash: ./hello: Permission denied
</code></pre>

<p>Because the permissions are </p>

<pre><code>-rw-r--r-- 1 nathan nathan   856 2010-09-17 23:49 hello
</code></pre>

<p>For some reason?? </p>

<p>But whatever... after changing the permissions and trying to execute again, I get</p>

<pre><code>bash: ./hello: cannot execute binary file
</code></pre>

<p>I'm using gcc (Ubuntu 4.4.3-4ubuntu5) 4.4.3</p>

<p>What am I doing wrong here? It's gotta be obvious... it's just too late for me to keep using my tired eyes to try and figure out this simple problem.... </p>

<p>P.S. I do (sometimes) work on programs more sophisticated than Hello World, but gcc is doing this across the board... </p>
","<p>Take the <code>-c</code> out. That's for making object files, not executables.</p>
","3740328"
"Convert binary string into integer","31337","","<p>I would like to convert a binary number writen in a String into its integer value. </p>

<p>For example: </p>

<pre><code>string input = ""0101"";
int output = convert(input);
</code></pre>

<p><code>output</code> should be equal to <code>5</code> </p>
","<p><a href=""http://msdn.microsoft.com/en-us/library/1k20k614.aspx"" rel=""noreferrer"">Convert.ToInt32(String, Int32)</a> lets you specify the base:</p>

<pre><code>int output = Convert.ToInt32(input, 2);
</code></pre>
","9149738"
"Bash shell Decimal to Binary conversion","31284","","<p>I'm looking for an easy way in Bash to convert a decimal number into a binary number.  I have variables that need to be converted:</p>

<pre><code>$ip1 $ip2 $ip3 $ip4
</code></pre>

<p>Is there a simple method to do this without looking at every individual number?</p>

<p>I would prefer not to have to write a lot of code.</p>
","<p>You can use <code>bc</code> as:</p>

<pre><code>echo ""obase=2;$ip1"" | bc
</code></pre>

<p><a href=""http://ideone.com/BtD9i"" rel=""noreferrer""><strong>See it</strong></a></p>
","10278539"
"Convert string to hexadecimal in Ruby","31000","","<p>I'm trying to convert a Binary file to Hexadecimal using Ruby.</p>

<p>At the moment I have the following:</p>

<pre><code>File.open(out_name, 'w') do |f|
  f.puts ""const unsigned int modFileSize = #{data.length};""
  f.puts ""const char modFile[] = {""
  first_line = true
  data.bytes.each_slice(15) do |a|
    line = a.map { |b| "",#{b}"" }.join
    if first_line
      f.puts line[1..-1]
    else
      f.puts line
    end
    first_line = false
  end
  f.puts ""};""
end
</code></pre>

<p>This is what the following code is generating:</p>

<pre><code>const unsigned int modFileSize = 82946;
const char modFile[] = {
 116, 114, 97, 98, 97, 108, 97, 115, 104, 0, 0, 0, 0, 0, 0
, 0, 0, 0, 0, 0, 62, 62, 62, 110, 117, 107, 101, 32, 111, 102
, 32, 97, 110, 97, 114, 99, 104, 121, 60, 60, 60, 8, 8, 130, 0
};
</code></pre>

<p>What I need is the following:</p>

<pre><code>const unsigned int modFileSize = 82946;
const char modFile[] = {
 0x74, 0x72, etc, etc
};
</code></pre>

<p>So I need to be able to convert a string to its hexadecimal value.</p>

<p><code>""116"" =&gt; ""0x74""</code>, etc</p>

<p>Thanks in advance.</p>
","<p>Change this line:</p>

<pre><code>line = a.map { |b| "", #{b}"" }.join
</code></pre>

<p>to this:</p>

<pre><code>line = a.map { |b| sprintf("", 0x%02X"",b) }.join
</code></pre>

<p>(Change to <code>%02x</code> if necessary, it's unclear from the example whether the hex digits should be capitalized.)</p>
","8350209"
"How to explicity tell SVN to treat a file as text, not binary","30447","","<p>I have a number of files that I checked into SVN without having set up their Mime types correctly.  SVN initially classified them as binary.</p>

<p>I've since set their Mime type in SVN via propset to ""text/plain; charset=UTF-8"" and I'vc made sure that all the files are UTF-8 signed.  When I do 'svn blame filename', svn says that the file is binary and does not give me explicit blame-type output.</p>

<p>Any suggestions on how to persuade SVN that these are truly text files? </p>
","<p>Setting the svn:mime-type property to just ""text/plain"" helps:</p>

<pre><code>svn propset svn:mime-type text/plain build.xml
svn commit build.xml
</code></pre>

<p>Also, you can force Subversion to treat a file as text when blaming:</p>

<pre><code>svn blame file/to/blame --force
</code></pre>
","458761"
"How can I determine if a file is binary or text in c#?","30332","","<p>I need to determine in 80% if a file is binary or text, is there any way to do it even quick and dirty/ugly in c#?</p>
","<p>I would probably look for an abundance of control characters which would typically be present in a binary file but rarely in an text file.  Binary files tend to use 0 enough that just testing for many 0 bytes would probably be sufficient to catch most files.  If you care about localization you'd need to test multi-byte patterns as well.</p>

<p>As stated though, you can always be unlucky and get a binary file that looks like text or vice versa.  </p>
","910927"
"Converting binary string to a hexadecimal string JAVA","30034","","<p>I want to convert my binary(which is in string) to hexadecimal string also, this is just a program fragment since this program is just a part of another bigger program:</p>

<pre><code>//the variable name of the binary string is: ""binary""
int digitNumber = 1;
    int sum = 0;
    int test = binary.length()%4;
    if(test!=0) {
        binary = padLeft(binary, test);
    }
    for(int i = 0; i &lt; binary.length(); i++){
        if(digitNumber == 1)
            sum+=Integer.parseInt(binary.charAt(i) + """")*8;
        else if(digitNumber == 2)
            sum+=Integer.parseInt(binary.charAt(i) + """")*4;
        else if(digitNumber == 3)
            sum+=Integer.parseInt(binary.charAt(i) + """")*2;
        else if(digitNumber == 4 || i &lt; binary.length()+1){
            sum+=Integer.parseInt(binary.charAt(i) + """")*1;
            digitNumber = 0;
            if(sum &lt; 10)
                System.out.print(sum);
            else if(sum == 10)
                System.out.print(""A"");
            else if(sum == 11)
                System.out.print(""B"");
            else if(sum == 12)
                System.out.print(""C"");
            else if(sum == 13)
                System.out.print(""D"");
            else if(sum == 14)
                System.out.print(""E"");
            else if(sum == 15)
                System.out.print(""F"");
            sum=0;
        }
        digitNumber++;  
    }
    public static String padLeft(String s, int n) {
        return String.format(""%0$""+n+""s"", s);
    }//i added this for padding
</code></pre>

<p>the problem is that i dont know if the padding works but i am sure that this program return a wrong hexadecimal conversion of the binary string I am trying to do this: </p>

<p><a href=""http://www.wikihow.com/Convert-Binary-to-Hexadecimal"">http://www.wikihow.com/Convert-Binary-to-Hexadecimal</a></p>

<p><strong>PS: I need to implement it(not using any built-in function)</strong></p>
","<p>If you don't have to implement that conversion yourself, you can use existing code :</p>

<pre><code>int decimal = Integer.parseInt(binaryStr,2);
String hexStr = Integer.toString(decimal,16);
</code></pre>

<p>If you must implement it yourself, there are several problems in your code :</p>

<ol>
<li>The loop should iterate from 0 to binary.length()-1 (assuming the first character of the String represents the most significant bit).</li>
<li>You implicitly assume that your binary String has 4*x charcters for some integer x. If that's not true, your algorithm breaks. You should left pad your String with zeroes to get a String of such length.</li>
<li><code>sum</code> must be reset to 0 after each hex digit you output.</li>
<li><code>System.out.print(digitNumber);</code> - here you should print <code>sum</code>, not <code>digitNumber</code>.</li>
</ol>

<p>Here's how the mostly fixed code looks :</p>

<pre><code>    int digitNumber = 1;
    int sum = 0;
    String binary = ""011110101010"";
    for(int i = 0; i &lt; binary.length(); i++){
        if(digitNumber == 1)
            sum+=Integer.parseInt(binary.charAt(i) + """")*8;
        else if(digitNumber == 2)
            sum+=Integer.parseInt(binary.charAt(i) + """")*4;
        else if(digitNumber == 3)
            sum+=Integer.parseInt(binary.charAt(i) + """")*2;
        else if(digitNumber == 4 || i &lt; binary.length()+1){
            sum+=Integer.parseInt(binary.charAt(i) + """")*1;
            digitNumber = 0;
            if(sum &lt; 10)
                System.out.print(sum);
            else if(sum == 10)
                System.out.print(""A"");
            else if(sum == 11)
                System.out.print(""B"");
            else if(sum == 12)
                System.out.print(""C"");
            else if(sum == 13)
                System.out.print(""D"");
            else if(sum == 14)
                System.out.print(""E"");
            else if(sum == 15)
                System.out.print(""F"");
            sum=0;
        }
        digitNumber++;  
    }
</code></pre>

<p>Output :</p>

<p><code>7AA</code></p>

<p>This will work only if the number of binary digits is divisable by 4, so you must add left <code>0</code> padding as a preliminray step.</p>
","25592110"
"How can I convert BitArray to single int?","29879","","<p>How can I convert <a href=""https://msdn.microsoft.com/en-us/library/system.collections.bitarray(v=vs.110).aspx"" rel=""noreferrer""><code>BitArray</code></a> to a single <code>int</code>? The fastest way pls...</p>
","<pre><code>private int getIntFromBitArray(BitArray bitArray)
{

    if (bitArray.Length &gt; 32)
        throw new ArgumentException(""Argument length shall be at most 32 bits."");

    int[] array = new int[1];
    bitArray.CopyTo(array, 0);
    return array[0];

}
</code></pre>
","5283199"
"Varbinary vs Blob in MySQL","29465","","<p>I have about 2k of raw binary data that I need to store in a table, but don't know whether to choose the Varbinary or Blob type.  I have read through the descriptions in the MySQL docs but didn't find any contract and compare descriptions.  I also read that varbinary only supports up to 255 characters, but I successfully created a varbinary(2048) field, so I'm a bit confused.</p>

<p>The binary data does not need to be indexed, nor will I need to query on it.  Is there an advantage to using one type over the other from PHP?</p>

<p>Thanks!</p>
","<p><code>VARBINARY</code> is bound to 255 bytes on MySQL 5.0.2 and below, to 65kB on 5.0.3 and above.</p>

<p><code>BLOB</code> is bound to 65kB.</p>

<p>Ultimately, <code>VARBINARY</code> is virtually the same as <code>BLOB</code> (from the perspective of what can be stored in it), unless you want to preserve compatibility with ""old"" versions of MySQL. The <a href=""http://dev.mysql.com/doc/refman/5.0/en/blob.html"" rel=""noreferrer"">MySQL Documentation</a> says:</p>

<blockquote>
  <p>In most respects, you can regard a <code>BLOB</code> column as a <code>VARBINARY</code> column that can be as large as you like.</p>
</blockquote>
","8477055"
"Can I write a program in binary directly ? How can I get the computer to execute it?","29459","","<p>I know that may seem weird and looking for troubles but I think experiencing what the ancient programmers experienced before is something interesting. So how can I execute a program written only in binary? (Suppose that I know what I am doing and not using assembly of course.)</p>

<p>I just want to write a series of bits like <code>111010111010101010101</code> and execute that. So how can I do that?</p>
","<p>Use a hex editor. You'll need to find out the relevant executable format for your operating system, of course - assuming you want to <em>use</em> an operating system... I suppose you could always write your own bootloader and just run the code directly that way, if you want to get all hardcore.</p>

<p>I don't think you'll <em>really</em> be experiencing what programmers experienced back then though - for one thing, you won't be using punch cards, paper tape etc. For another, your context is completely different - you know what computers are like <em>now</em>, so it'll feel painfully primitive to you... whereas back then, it would have been bleeding edge and exciting just on those grounds.</p>
","4197073"
"Convert integer to binary and store it in an integer array of specified size:c++","29349","","<p>I want to convert an integer to binary string and then store each bit of the integer string to an element of a integer array of a given size. I am sure that the input integer's binary expression won't exceed the size of the array specified. How to do this in c++?</p>
","<p>Pseudo code:</p>

<pre><code>int value = ????  // assuming a 32 bit int
int i;

for (i = 0; i &lt; 32; ++i) {
    array[i] = (value &gt;&gt; i) &amp; 1;
}
</code></pre>
","14104263"
"how to do two complement multiplication and division of integers?","29347","","<p>I have read this <a href=""https://stackoverflow.com/questions/3899401/binary-multiplication-2s-complement"">post</a> on binary multiplication using two complement. but it is not very clear to me. Even I have difficulty understanding the <a href=""http://en.wikipedia.org/wiki/Two%27s_complement#Multiplication"" rel=""nofollow noreferrer"">wiki</a> article on this. I want to know how to go about calculating multiplications of negative numbers:</p>

<pre><code>eg: -1 with -7 should give 7.
A 4-bit, 2's complement of -1 is : 1111
A 4-bit, 2's complement of -7 is : 1001
</code></pre>

<p>some step-wise way of calculating the multiplication will be helpful. No article I came across talks about division. How to approach this?</p>
","<p>step 1: <code>sign extend</code> both integers to twice as many bits. This is safe to do, though may not always be necessary.</p>

<pre><code>for 4-bit --&gt; 1111, you would extend as 1111 1111
for 4-bit --&gt; 0111,you would extend as 0000 0111
</code></pre>

<p>step 2: do elementary multiplication</p>

<p>sep 3: take the correct number of result bits from the least significant portion of the result.</p>

<p>eg: after multiplication, you end up with something such as <code>0010011110</code>take the last 8 bits i.e <code>10011110</code></p>

<p>Let me illustrate with the example you provided: <code>-1 X -7</code> in 4-bit representation</p>

<pre><code>         1111 1111        -1
       x 1111 1001     x  -7
      ----------------    ------
          11111111         7
         00000000
        00000000
       11111111
      11111111
     11111111
    11111111
   11111111
   ----------------
1  00000000111       ---&gt;  7 (notice the Most significant bit is zer``o)
      --------  (last 8-bits needed) 
</code></pre>

<p>you could get more details <a href=""http://pages.cs.wisc.edu/~cs354-1/beyond354/int.mult.html"">here</a>;</p>

<p>for division: convert to positive and after the calculation adjust the sign. I will leave this as exercise but you could refer this <a href=""http://www.cs.utah.edu/~rajeev/cs3810/slides/3810-08.pdf"">page</a>.</p>
","20793834"
"How to print integer literals in binary or hex in haskell?","29308","","<p>How to print integer literals in binary or hex in haskell?</p>

<pre><code>printBinary 5 =&gt; ""0101""

printHex 5 =&gt; ""05""
</code></pre>

<p>Which libraries/functions allow this?</p>

<p>I came across the Numeric module and its showIntAtBase function but have been unable to use it correctly.</p>

<pre><code>&gt; :t showIntAtBase 

showIntAtBase :: (Integral a) =&gt; a -&gt; (Int -&gt; Char) -&gt; a -&gt; String -&gt; String
</code></pre>
","<p>The Numeric module includes several <a href=""https://hackage.haskell.org/package/base-4.7.0.2/docs/Numeric.html"" rel=""noreferrer"">functions for showing an Integral type</a> at various bases, including <code>showIntAtBase</code>. Here are some examples of use:</p>

<pre><code>import Numeric (showHex, showIntAtBase)
import Data.Char (intToDigit)

putStrLn $ showHex 12 """" -- prints ""c""
putStrLn $ showIntAtBase 2 intToDigit 12 """" -- prints ""1100""
</code></pre>
","1959789"
"Grabbing n bits from a byte","29095","","<p>I'm having a little trouble grabbing n bits from a byte.</p>

<p>I have an unsigned integer. Let's say our number in hex is 0x2A, which is 42 in decimal. In binary it looks like this: 0010 1010. How would I grab the first 5 bits which are 00101 and the next 3 bits which are 010, and place them into separate integers? </p>

<p>If anyone could help me that would be great! I know how to extract from one byte which is to simply do </p>

<pre><code>int x = (number &gt;&gt; (8*n)) &amp; 0xff // n being the # byte
</code></pre>

<p>which I saw on another post on stack overflow, but I wasn't sure on how to get separate bits out of the byte. If anyone could help me out, that'd be great! Thanks!</p>
","<p>Integers are represented inside a machine as a sequence of bits; fortunately for us humans, programming languages provide a mechanism to show us these numbers in decimal (or hexadecimal), but that does not alter their internal representation.</p>

<p>You should revise the bitwise operators <code>&amp;</code>, <code>|</code>, <code>^</code> and <code>~</code> as well as the shift operators <code>&lt;&lt;</code> and <code>&gt;&gt;</code>, which will help you understand how to solve problems like this.</p>

<p>The last 3 bits of the integer are:</p>

<pre><code>x &amp; 0x7
</code></pre>

<p>The five bits starting from the eight-last bit are:</p>

<pre><code>x &gt;&gt; 3    // all but the last three bits
  &amp;  0x1F // the last five bits.
</code></pre>
","15255821"
"How to find non-printable character in text file","29081","","<p>I have a text file that is processed by a third party. They told me the file is invalid because it contains a non-printable character. What's the best way to find the non-printable character as my normal text editors won't display it. I would prefer a windows, dos, or powershell based solution.</p>
","<h3>Option #1 - Show All Characters</h3>

<p>You can download <a href=""http://notepad-plus-plus.org/"" rel=""noreferrer"">Notepad++</a> and open the file there. Then, go to the menu and select <code>View-&gt;Show Symbol-&gt;Show All Characters</code>. All characters will become visible, but you will have to scroll through the whole file to see which character needs to be removed.</p>

<p>Unfortunately, <a href=""http://notepad-plus-plus.org/"" rel=""noreferrer"">Notepad++</a> will automatically convert line endings according to your <code>Edit-&gt;EOL Conversion</code> selection, so it won't help if your non-printable characters are CR or LF.</p>

<h3>Option #2 - TextFX Zap Non-printable Chars</h3>

<p>Alternatively, you could install the TextFX plugin from SourceForge, and use <code>TextFX-&gt;TextFX Characters-&gt;Zap all non-printable characters to #</code>. This will replace some non-printable characters with a pound sign, but not CR or LF.</p>

<h3>Option #3 - Remove BOM Encoding</h3>

<p>Lastly, you could use Notepad++, and use <code>Encoding-&gt;Convert to UTF8 without BOM</code>. This will remove non-printable characters which occasionally causes issues with certain renderers (<a href=""http://visualstudio.com"" rel=""noreferrer"">VSO</a>).</p>
","8523118"
"Binary grep on Linux?","28913","","<p>Say I have generated the following binary file:</p>

<pre><code># generate file:
python -c 'import sys;[sys.stdout.write(chr(i)) for i in (0,0,0,0,2,4,6,8,0,1,3,0,5,20)]' &gt; mydata.bin

# get file size in bytes
stat -c '%s' mydata.bin

# 14
</code></pre>

<p>And say, I want to find the locations of all zeroes (<code>0x00</code>), using a grep-like syntax.</p>

<p>&nbsp;</p>

<p>The best I can do so far is:</p>

<pre><code>$ hexdump -v -e ""1/1 \"" %02x\n\"""" mydata.bin | grep -n '00'

1: 00
2: 00
3: 00
4: 00
9: 00
12: 00
</code></pre>

<p>However, this implicitly converts each byte in the original binary file into a multi-byte ASCII representation, on which <code>grep</code> operates; not exactly the prime example of optimization :)</p>

<p>Is there something like a binary <code>grep</code> for Linux? Possibly, also, something that would support a regular expression-like syntax, but also for byte ""characters"" - that is, I could write something like '<code>a(\x00*)b</code>' and match 'zero or more' occurrences of byte 0 between bytes 'a' (97) and 'b' (98)?</p>

<p>EDIT: The context is that I'm working on a driver, where I capture 8-bit data; something goes wrong in the data, which can be kilobytes up to megabytes, and I'd like to check for particular signatures and where they occur. (<em>so far, I'm working with kilobyte snippets, so optimization is not that important - but if I start getting some errors in megabyte long captures, and I need to analyze those, my guess is I would like something more optimized :) . And especially, I'd like something where I can ""grep"" for a byte as a character - <code>hexdump</code> forces me to search strings per byte</em>)</p>

<p>EDIT2: same question, different forum :) <a href=""http://www.linuxquestions.org/questions/linux-software-2/grepping-through-a-binary-file-for-a-sequence-of-bytes-717503/"" rel=""noreferrer"">grepping through a binary file for a sequence of bytes</a></p>

<p>EDIT3: Thanks to the answer by @tchrist, here is also an example with 'grepping' and matching, and displaying results (<em>although not quite the same question as OP</em>):</p>

<pre><code>$ perl -ln0777e 'print unpack(""H*"",$1), ""\n"", pos() while /(.....\0\0\0\xCC\0\0\0.....)/g' /path/to/myfile.bin

ca000000cb000000cc000000cd000000ce     # Matched data (hex)
66357                                  # Offset (dec)
</code></pre>

<p>To have the matched data be grouped as one byte (two hex characters) each, then ""H2 H2 H2 ..."" needs to be specified for as many bytes are there in the matched string; as my match '<code>.....\0\0\0\xCC\0\0\0.....</code>' covers 17 bytes, I can write '<code>""H2""x17</code>' in Perl. Each of these ""H2"" will return a separate variable (as in a list), so <code>join</code> also needs to be used to add spaces between them - eventually:</p>

<pre><code>$ perl -ln0777e 'print join("" "", unpack(""H2 ""x17,$1)), ""\n"", pos() while /(.....\0\0\0\xCC\0\0\0.....)/g' /path/to/myfile.bin

ca 00 00 00 cb 00 00 00 cc 00 00 00 cd 00 00 00 ce
66357
</code></pre>

<p>Well.. indeed Perl is very nice 'binary grepping' facility, I must admit :) As long as one learns the syntax properly :)</p>
","<h2>One-Liner Input</h2>

<p>Here’s the shorter one-liner version:</p>

<pre><code>% perl -ln0e 'print tell' &lt; inputfile
</code></pre>

<p>And here's a slightly longer one-liner:</p>

<pre><code>% perl -e '($/,$\) = (""\0"",""\n""); print tell while &lt;STDIN&gt;' &lt; inputfile
</code></pre>

<p>The way to connect those two one-liners is by uncompiling the first one’s program:</p>

<pre><code>% perl -MO=Deparse,-p -ln0e 'print tell'
BEGIN { $/ = ""\000""; $\ = ""\n""; }
LINE: while (defined(($_ = &lt;ARGV&gt;))) {
    chomp($_);
    print(tell);
}
</code></pre>

<h2>Programmed Input</h2>

<p>If you want to put that in a file instead of a calling it from the command line, here’s a somewhat  more explicit version:</p>

<pre><code>#!/usr/bin/env perl

use English qw[ -no_match_vars ];

$RS  = ""\0"";    # input  separator for readline, chomp
$ORS = ""\n"";    # output separator for print

while (&lt;STDIN&gt;) {
    print tell();
}
</code></pre>

<p>And here’s the really long version:</p>

<pre><code>#!/usr/bin/env perl

use strict;
use autodie;  # for perl5.10 or better
use warnings qw[ FATAL all  ];

use IO::Handle;

IO::Handle-&gt;input_record_separator(""\0"");
IO::Handle-&gt;output_record_separator(""\n"");

binmode(STDIN);   # just in case

while (my $null_terminated = readline(STDIN)) {
    # this just *past* the null we just read:
    my $seek_offset = tell(STDIN);
    print STDOUT $seek_offset;  

}

close(STDIN);
close(STDOUT);
</code></pre>

<h2>One-Liner Output</h2>

<p>BTW, to create the test input file, I didn’t use your big, long   Python script; I just used this simple  Perl one-liner:</p>

<pre><code>% perl -e 'print 0.0.0.0.2.4.6.8.0.1.3.0.5.20' &gt; inputfile
</code></pre>

<p>You’ll find that Perl often winds up being 2-3 times shorter than Python to do the same job.  And you don’t have to compromise on clarity; what could be simpler that the one-liner above?</p>

<h2>Programmed Output</h2>

<p>I know, I know.  If you don’t already know the language, this might be clearer:</p>

<pre><code>#!/usr/bin/env perl
@values = (
    0,  0,  0,  0,  2,
    4,  6,  8,  0,  1,
    3,  0,  5, 20,
);
print pack(""C*"", @values);
</code></pre>

<p>although this works, too:</p>

<pre><code>print chr for @values;
</code></pre>

<p>as does </p>

<pre><code>print map { chr } @values;
</code></pre>

<p>Although for those who like everything all rigorous and careful and all, this might be more what you would see:</p>

<pre><code>#!/usr/bin/env perl

use strict;
use warnings qw[ FATAL all ];
use autodie;

binmode(STDOUT);

my @octet_list = (
    0,  0,  0,  0,  2,
    4,  6,  8,  0,  1,
    3,  0,  5, 20,
);

my $binary = pack(""C*"", @octet_list);
print STDOUT $binary;

close(STDOUT); 
</code></pre>

<h2>TMTOWTDI</h2>

<p>Perl supports more than one way to do things so that you can pick the one that you’re most comfortable with.  If this were something I planned to check in as school or work project, I would certainly select the longer, more careful versions — or at least put a comment in the shell script if I were using the one-liners.</p>

<p>You can find documentation for Perl on your own system.  Just type</p>

<pre><code>% man perl
% man perlrun
% man perlvar
% man perlfunc
</code></pre>

<p>etc at your shell prompt.  If you want pretty-ish versions on the web instead, get the manpages for <a href=""http://perldoc.perl.org/perl.html"">perl</a>, <a href=""http://perldoc.perl.org/perlrun.html"">perlrun</a>, <a href=""http://perldoc.perl.org/perlvar.html"">perlvar</a>, and <a href=""http://perldoc.perl.org/index-functions.html"">perlfunc</a> from <a href=""http://perldoc.perl.org"">http://perldoc.perl.org</a>.</p>
","4180531"
"converting a wire value to an integer in verilog","28876","","<p>I want to convert the data in a wire to an integer. For example:</p>

<pre><code>wire [2:0] w = 3'b101;
</code></pre>

<p>I want a method that converts this to '5' and stores it in an integer. How can I do that in a better way than this:</p>

<pre><code>j=1;
for(i=0; i&lt;=2; i=i+1)
begin
  a=a+(w[i]*j);   
  j=j*2;
end
</code></pre>

<p>Also, how do I convert it back to binary once I have the value in an integer? This seems a clumsy way. Thank you.</p>
","<p>Easy! Conversion is automatic in verilog if you assign to an integer. In verilog, all the data types are just collection on bits.</p>

<pre><code>integer my_int;
always @( w )
    my_int = w;
</code></pre>
","5666551"
"How can I create a binary file in Perl?","28870","","<p>For example, I want to create a file called <code>sample.bin</code> and put a number, like 255, so that 255 is saved in the file as little-endian, FF 00. Or 3826 to F2 0E.</p>

<p>I tried using binmode, as the perldoc said.</p>
","<p>The perl <a href=""http://perldoc.perl.org/functions/pack.html"" rel=""noreferrer"">pack</a> function will return ""binary"" data according to a template.</p>

<pre><code>open(my $out, '&gt;:raw', 'sample.bin') or die ""Unable to open: $!"";
print $out pack('s&lt;',255) ;
close($out);
</code></pre>

<p>In the above example, the <code>'s'</code> tells it to output a <code>short</code> (16 bits), and the <code>'&lt;'</code> forces it to little-endian mode.</p>

<p>In addition, <code>':raw'</code> in the call to <code>open</code> tells it to put the filehandle into binary mode on platforms where that matters (it is equivalent to using <code>binmode</code>). The <a href=""http://perldoc.perl.org/PerlIO.html"" rel=""noreferrer"">PerlIO</a> manual page has a little more information on doing I/O in different formats.</p>
","1464222"
"Saving a Base64 string to disk as a binary using PHP","28807","","<p>As a ""look under the covers"" tutorial for myself I am building a PHP script to gather emails from a POP3 mailbox.  While attempting to make use of binary attachments I am stuck trying to figure out what to do with the attachment information.</p>

<p>Given a string that would be gathered from an email:</p>

<blockquote>
  <p>------=_Part_16735_17392833.1229653992102
  Content-Type: image/jpeg; name=trans2.jpg
  Content-Transfer-Encoding: base64
  X-Attachment-Id: f_fow87t5j0
  Content-Disposition: attachment; filename=trans2.jpg</p>
  
  <p>/9j/4AAQSkZJRgABAgEASABIAAD/4QxrRXhpZgAATU0AKgAAAAgABwESAAMAAAABAAEAAAEaAAUA
  AAABAAAAYgEbAAUAAAABAAAAagEoAAMAAAABAAIAAAExAAIAAAAUAAAAcgEyAAIAAAAUAAAAhodp</p>
  
  <p>(...)</p>
  
  <p>EAgEAgEAgEAgEAg8IBQRL/Lbe/tJrScHqZ2lkmE4XUP2XcSDZZ2VvZ28dtbsDIYmhkbRxAIJCAQC
  AQCAQf/ScyAQCAQCAQCAQCAQCAQCAQCAQCAQCAQf/9k=
  ------=_Part_16735_17392833.1229653992102--</p>
</blockquote>

<p>Is there a way to save off the data to disk so that it would be in a usable format?</p>
","<p>Pass the data to <a href=""http://php.net/base64_decode"" rel=""noreferrer"">base64_decode()</a> to get the binary data, write it out to a file with <a href=""http://php.net/file_put_contents"" rel=""noreferrer"">file_put_contents()</a></p>
","380971"
"Is it safe to use -1 to set all bits to true?","28719","","<p>I've seen this pattern used a lot in C &amp; C++.</p>

<pre><code>unsigned int flags = -1;  // all bits are true
</code></pre>

<p>Is this a good portable way to accomplish this?  Or is using <code>0xffffffff</code> or <code>~0</code> better?</p>
","<p>I recommend you to do it exactly as you have shown, since it is the most straight forward one. Initialize to <code>-1</code> which will work <em>always</em>, independent of the actual sign representation, while <code>~</code> will sometimes have surprising behavior because you will have to have the right operand type. Only then you will get the most high value of an <code>unsigned</code> type. </p>

<p>For an example of a possible surprise, consider this one:</p>

<pre><code>unsigned long a = ~0u;
</code></pre>

<p>It won't necessarily store a pattern with all bits 1 into <code>a</code>. But it will first create a pattern with all bits 1 in an <code>unsigned int</code>, and then assign it to <code>a</code>. What happens when <code>unsigned long</code> has more bits is that not all of those are 1.</p>

<p>And consider this one, which will fail on a non-two's complement representation:</p>

<pre><code>unsigned int a = ~0; // Should have done ~0u !
</code></pre>

<p>The reason for that is that <code>~0</code> has to invert all bits. Inverting that will yield <code>-1</code> on a two's complement machine (which is the value we need!), but will <em>not</em> yield <code>-1</code> on another representation. On a one's complement machine, it yields zero. Thus, on a one's complement machine, the above will initialize <code>a</code> to zero. </p>

<p>The thing you should understand is that it's all about values - not bits. The variable is initialized with a <em>value</em>. If in the initializer you modify the bits of the variable used for initialization, the value will be generated according to those bits. The value you need, to initialize <code>a</code> to the highest possible value, is <code>-1</code> or <code>UINT_MAX</code>. The second will depend on the type of <code>a</code> - you will need to use <code>ULONG_MAX</code> for an <code>unsigned long</code>. However, the first will not depend on its type, and it's a nice way of getting the most highest value.</p>

<p><strong>We are <em>not</em> talking about whether <code>-1</code> has all bits one (it doesn't always have). And we're <em>not</em> talking about whether <code>~0</code> has all bits one (it has, of course).</strong></p>

<p>But what we are talking about is what the result of the initialized <code>flags</code> variable is. And for it, <strong>only <code>-1</code></strong> will work with every type and machine. </p>
","809341"
"How can I invert a binary image in MATLAB?","28677","","<p>I have a binary image and need to convert all of the black pixels to white pixels and vice versa. Then I need to save the new image to a file. Is there a way to do this without simply looping over every pixel and flipping its value?</p>
","<p>If you have a binary image <code>binImage</code> with just zeroes and ones, there are a number of simple ways to invert it:</p>

<pre><code>binImage = ~binImage;
binImage = 1-binImage;
binImage = (binImage == 0);
</code></pre>

<p>Then just save the inverted image using the function <a href=""http://www.mathworks.com/help/techdoc/ref/imwrite.html"" rel=""noreferrer"">IMWRITE</a>.</p>
","5277209"
"Convert Decimal to Binary","28549","","<p>I would like to convert a decimal number to binary. I want to create a method that converts the decimal number to binary and then call that method from Main to print the result, but I am having some trouble. This is the code I have so far. toBin method is not working properly and i cant seem to figure out what i am doing wrong.</p>

<p>I am trying to learn java on my own so any help would be appreciated including explanations if necessary. I am learning JAVA through <a href=""http://knowledgeblackbelt.com"" rel=""nofollow"">http://knowledgeblackbelt.com</a> and this is one of the exercises. Like I said I do not need the answer more than I want an example and explanation of the process since I do not seem to  figure it out. Thanks to the people who are really helping.</p>

<pre><code>public class DecToBin {


public static void main(String[] args) {

    System.out.println(toBin(2));

}


public static int toBin(int Number){


    int result = 0;
    while(Number &gt; 0){


        int mod = Number % 2;
        result = result * 1 + mod;

        Number /= 2;
    }

    return result;

}
</code></pre>

<p>}</p>
","<p>Hope this helps:</p>

<pre><code>/**
 * 
 * @author X
 *
 */
public class ConvertDecimal {

    public void convert(int decimal , int base)
    {
        int result = 0;
        int multiplier = 1;

          while(decimal &gt; 0)
            {
              int residue = decimal % base;
              decimal     = decimal / base;
              result      = result + residue * multiplier;
              multiplier  = multiplier * 10;
            }

            System.out.println (""binary....."" + result);
    }



    public static void main(String args[])
    {
        ConvertDecimal conv = new ConvertDecimal();
        conv.convert(128, 2);
    }

}
</code></pre>
","13147496"
"Easiest way to compare two Excel files in Java?","28360","","<p>I'm writing a JUnit test for some code that produces an Excel file (which is binary). I have another Excel file that contains my expected output. What's the easiest way to compare the actual file to the expected file?</p>

<p>Sure I could write the code myself, but I was wondering if there's an existing method in a trusted third-party library (e.g. Spring or Apache Commons) that already does this.</p>
","<p>Here's what I ended up doing (with the heavy lifting being done by <a href=""http://dbunit.sourceforge.net/"" rel=""noreferrer"">DBUnit</a>):</p>

<pre><code>/**
 * Compares the data in the two Excel files represented by the given input
 * streams, closing them on completion
 * 
 * @param expected can't be &lt;code&gt;null&lt;/code&gt;
 * @param actual can't be &lt;code&gt;null&lt;/code&gt;
 * @throws Exception
 */
private void compareExcelFiles(InputStream expected, InputStream actual)
  throws Exception
{
  try {
    Assertion.assertEquals(new XlsDataSet(expected), new XlsDataSet(actual));
  }
  finally {
    IOUtils.closeQuietly(expected);
    IOUtils.closeQuietly(actual);
  }
}
</code></pre>

<p>This compares the data in the two files, with no risk of false negatives from any irrelevant metadata that might be different. Hope this helps someone.</p>
","867390"
"Read/Parse Binary files with Powershell","28155","","<p>I'm trying to parse a binary file, and I need some help on where to go. I've looking online for ""parsing binary files"", ""reading binary files"", ""reading text inside binaries"", etc. and I haven't had any luck.</p>

<p>For example, how would I read this text out of this binary file? Any help would be MUCH appreciated. I am using powershell.</p>

<p><img src=""https://i.stack.imgur.com/Ry1lG.png"" alt=""enter image description here""></p>
","<p>It seems that you have a binary file with text on a fixed or otherwise deducible position. <a href=""http://technet.microsoft.com/en-us/library/ee176843"" rel=""noreferrer""><code>Get-Content</code></a> might help you but... It'll try to parse the entire file to an array of strings and thus creating an array of ""garbage"". Also, you wouldn't know from what file position a particular ""rope of characters"" was.</p>

<p>You can try .NET classes <a href=""http://msdn.microsoft.com/en-us/library/system.io.file.aspx"" rel=""noreferrer""><code>File</code></a> to read and <a href=""http://msdn.microsoft.com/en-us/library/system.text.encoding.aspx"" rel=""noreferrer""><code>Encoding</code></a> to decode. It's just a line for each call:</p>

<pre><code># Read the entire file to an array of bytes.
$bytes = [System.IO.File]::ReadAllBytes(""path_to_the_file"")
# Decode first 12 bytes to a text assuming ASCII encoding.
$text = [System.Text.Encoding]::ASCII.GetString($bytes, 0, 12)
</code></pre>

<p>In your real case you'd probably go through the array of bytes in a loop finding the start and end of a particular string sequence and using those indices to specify the range of bytes you want to extract the text from by the <a href=""http://msdn.microsoft.com/en-us/library/05cts4c3.aspx"" rel=""noreferrer""><code>GetString</code></a>.</p>

<p>The .NET methods I mentioned are available in .NET Framework 2.0 or higher. If you installed PowerShell 2.0 you already have it.</p>
","10672303"
"Convert 2 bytes to a number","28134","","<p>I have a control that has a byte array in it.</p>

<p>Every now and then there are two bytes that tell me some info about number of future items in the array.</p>

<p>So as an example I could have:</p>

<pre>
...
...
Item [4] = 7
Item [5] = 0
...
...</pre>

<p>The value of this is clearly 7.</p>

<p>But what about this?</p>

<pre>
...
...
Item [4] = 0
Item [5] = 7
...
...</pre>

<p>Any idea on what that equates to (as an normal int)?</p>

<p>I went to binary and thought it may be 11100000000 which equals 1792.  But I don't know if that is how it really works (ie does it use the whole 8 items for the byte).</p>

<p>Is there any way to know this with out testing?</p>

<p>Note: I am using C# 3.0 and visual studio 2008</p>
","<p><code>BitConverter</code> can easily convert the two bytes in a two-byte integer value:</p>

<pre><code>// assumes byte[] Item = someObject.GetBytes():
short num = BitConverter.ToInt16(Item, 4); // makes a short 
    // out of Item[4] and Item[5]
</code></pre>
","2660664"
"Efficiently convert between Hex, Binary, and Decimal in C/C++","28112","","<p>I have 3 base representations for positive integer numbers:</p>

<ol>
<li>Decimal, in unsigned long variable (e.g. <em>unsigned long int NumDec = 200</em>).</li>
<li>Hex, in string variable (e.g. <em>string NumHex = ""C8""</em>)</li>
<li>Binary, in string variable (e.g. <em>string NumBin = ""11001000""</em>)</li>
</ol>

<p>I want to be able to convert between numbers in all 3 representations in the most efficient way. I.e. to implement the following 6 functions:</p>

<pre><code>unsigned long int Binary2Dec(const string &amp; Bin) {}
unsigned long int Hex2Dec(const string &amp; Hex) {}
string Dec2Hex(unsigned long int Dec) {}
string Binary2Hex(const string &amp; Bin) {}
string Dec2Binary(unsigned long int Dec) {}
string Hex2Binary(const string &amp; Hex) {}
</code></pre>

<p>What is the most efficient approach for each of them? I can use C and C++, but not boost. </p>

<p>Edit: By ""efficiency"" I mean time efficiency: Shortest execution time.</p>
","<p>As others have pointed out, I would start with <a href=""http://en.cppreference.com/w/cpp/io/c/fscanf"" rel=""nofollow noreferrer""><code>sscanf()</code></a>, <a href=""http://en.cppreference.com/w/cpp/io/c/fprintf"" rel=""nofollow noreferrer""><code>printf()</code></a> and/or <a href=""http://en.cppreference.com/w/cpp/string/byte/strtoul"" rel=""nofollow noreferrer""><code>strtoul()</code></a>.  They are fast enough for most applications, and they are less likely to have bugs.  I will say, however, that these functions are more generic than you might expect, as they have to deal with non-ASCII character sets, with numbers represented in any base and so forth.  For some domains it is possible to beat the library functions.</p>

<p>So, measure first, and if the performance of these conversion is really an issue, then:</p>

<p>1) In some applications / domains certain numbers appear very often, for example zero, 100, 200, 19.95, may be so common that it makes sense to optimize your functions to convert such numbers with a bunch of if() statements, and then fall back to the generic library functions.
2) Use a table lookup if the most common 100 numbers, and then fall back on a library function.  Remember that large tables may not fit in your cache and may require multiple indirections for shared libraries, so measure these things carefully to make sure you are not decreasing performance.</p>

<p>You may also want to look at boost lexical_cast functions, though in my experience the latter are relatively compared to the good old C functions.</p>

<p>Tough many have said it, it is worth repeating over and over:  do not optimize these conversions until you have evidence that they are a problem.  If you do optimize, measure your new implementation to make sure it is faster <em>and</em> make sure you have a ton of unit tests for your own version, because you will introduce bugs :-(</p>
","822128"
"java: convert binary string to int","28017","","<p>I'm trying to convert a couple of binary strings back to int. However it doesn't convert all my binary strings, leaving me a <strong>java.lang.NumberFormatException</strong> exception.
Here is my test code with 3 binary string:</p>

<pre><code>public class Bin {

    public static void main(String argvs[]) {
            String binaryString ;
            binaryString = Integer.toBinaryString(~0);
            //binaryString = Integer.toBinaryString(~1);
            //binaryString = ""1010"" ;
            int base = 2;
            int decimal = Integer.parseInt(binaryString, base);
            System.out.println(""INPUT="" + binaryString + "" decimal="" + decimal) ;
    }
}
</code></pre>

<p>If I convert the ""1010"" it works great, but when I try to convert one of the other two I get the exception. Can someone explain to me why this is ?</p>

<p>Cheers</p>
","<p>From <a href=""http://docs.oracle.com/javase/1.5.0/docs/api/java/lang/Integer.html#toBinaryString(int)"" rel=""nofollow"">http://docs.oracle.com/javase/1.5.0/docs/api/java/lang/Integer.html#toBinaryString(int)</a> : the <code>toBinaryString()</code> method converts its input into the binary representation of the ""<em>unsigned integer value is the argument plus 2<sup>32</sup> if the argument is negative</em>"".</p>

<p>From <a href=""http://docs.oracle.com/javase/1.5.0/docs/api/java/lang/Integer.html#parseInt(java.lang.String,%20int)"" rel=""nofollow"">http://docs.oracle.com/javase/1.5.0/docs/api/java/lang/Integer.html#parseInt(java.lang.String,%20int)</a> : the <code>parseInt()</code> method throws <code>NumberFormatException</code> if ""<em>The value represented by the string is not a value of type <code>int</code></em>"".</p>

<p>Note that both <code>~0</code> and <code>~1</code> are negative (-1 and -2 respectively), so will be converted to the binary representations of 2<sup>32</sup>-1 and 2<sup>32</sup>-2 respectively, neither of which can be represented in a value of type <code>int</code>, so causing the <code>NumberFormatException</code> that you are seeing.</p>
","14883571"
"How are negative numbers represented in 32-bit signed integer?","27974","","<p>How are negative number represented in 32-bit signed integer?
Is it two's or one's complement? or the last bit on the left is like a flag?
For example: (-10)</p>
","<p>Most computers these days use <a href=""http://en.wikipedia.org/wiki/Two&#39;s_complement"" rel=""nofollow noreferrer"">two's complement</a> for signed integers, but it can vary by hardware architecture, programming language, or other platform-specific issues.</p>

<p>For a two's-complement representation, the most-significant (""leftmost"") bit is referred to as the <em>sign bit</em>, and it will be set for a negative integer and clear for a non-negative integer.  However, it is more than just a ""flag"".  See the <a href=""http://en.wikipedia.org/wiki/Two&#39;s_complement"" rel=""nofollow noreferrer"">Wikipedia article</a> for more information.</p>
","2931646"
"How to detect type of compression used on the file? (if no file extension is specified)","27833","","<p>How can one detect the type of compression used on the file? (assuming that .zip, .gz, .xz or any other extension is not specified).</p>

<p>Is this information stored somewhere in the header of that file?</p>
","<p>You can determine that it is <em>likely</em> to be one of those formats by looking at the first few bytes.  You should then test to see if it really <em>is</em> one of those, using an integrity check from the associated utility for that format, or by actually proceeding to decompress.</p>

<p>You can find the header formats in the descriptions:</p>

<ul>
<li><a href=""http://www.pkware.com/documents/casestudies/APPNOTE.TXT"">Zip (.zip) format description</a>, starts with 0x50, 0x4b, 0x03, 0x04 (unless empty — then the last two are 0x05, 0x06 or 0x06, 0x06)</li>
<li><a href=""http://www.ietf.org/rfc/rfc1952.txt"">Gzip (.gz) format description</a>, starts with 0x1f, 0x8b, 0x08</li>
<li><a href=""http://tukaani.org/xz/xz-file-format-1.0.4.txt"">xz (.xz) format description</a>, starts with 0xfd, 0x37, 0x7a, 0x58, 0x5a, 0x00</li>
</ul>

<p>Others:</p>

<ul>
<li><a href=""http://www.ietf.org/rfc/rfc1950.txt"">zlib (.zz) format description</a>, starts with (in bits) 0aaa1000 bbbccccc, where ccccc is chosen so that the first byte times 256 plus the second byte is a multiple of 31.</li>
<li>compress (.Z) starts with 0x1f, 0x9d</li>
<li>bzip2 (.bz2) starts with 0x42, 0x5a, 0x68</li>
</ul>
","19127748"
"read input files, fastest way possible?","27528","","<p>I have numerous text files of data in the form of float numbers. I'm looking for the fastest way to read them in C++. I can change the file to binary if that's the fastest. </p>

<p>It would be great if you could give me hint or refer me to a website with complete explanation. I don't know whether there is any library that does the work fast. Even if there is any open source software that does the work, that would be helpful.</p>
","<p>Having a binary file is the fastest option. Not only you can read it directly in an array with a raw <code>istream::read</code> in a single operation (which is very fast), but you can even map the file in memory if your OS supports it; you can use <code>open</code>/<code>mmap</code> on POSIX systems, <code>CreateFile</code>/<code>CreateFileMapping</code>/<code>MapViewOfFile</code> on Windows, or even the Boost cross-platform solution (thanks @Cory Nelson for pointing it out).</p>

<p>Quick &amp; dirty examples, assuming the file contains the raw representation of some <code>float</code>s:</p>

<p>""Normal"" read:</p>

<pre><code>#include &lt;fstream&gt;
#include &lt;vector&gt;

// ...

// Open the stream
std::ifstream is(""input.dat"");
// Determine the file length
is.seekg(0, std:ios_base::end);
std::size_t size=is.tellg();
is.seekg(0, std::ios_base::beg);
// Create a vector to store the data
std::vector&lt;float&gt; v(size/sizeof(float));
// Load the data
is.read((char*) &amp;v[0], size);
// Close the file
is.close();
</code></pre>

<p>With shared memory:</p>

<pre><code>#include &lt;boost/interprocess/file_mapping.hpp&gt;
#include &lt;boost/interprocess/mapped_region.hpp&gt;

using boost::interprocess;

// ....

// Create the file mapping
file_mapping fm(""input.dat"", read_only);
// Map the file in memory
mapped_region region(fm, read_only);
// Get the address where the file has been mapped
float * addr = (float *)region.get_address();
std::size_t elements  = region.get_size()/sizeof(float);
</code></pre>
","6755132"
"How do I convert a binary string to a number in Perl?","27443","","<p>How can I convert the binary string <code>$x_bin=""0001001100101""</code> to its numeric value <code>$x_num=613</code> in Perl?</p>
","<pre><code>sub bin2dec {
    return unpack(""N"", pack(""B32"", substr(""0"" x 32 . shift, -32)));
}
</code></pre>
","483668"
"Floating Point to Binary Value(C++)","27398","","<p>I want to take a floating point number in C++, like 2.25125, and a int array filled with the binary value that is used to store the float in memory (IEEE 754).</p>

<p>So I could take a number, and end up with a int num[16] array with the binary value of the float:
num[0] would be 1
num[1] would be 1
num[2] would be 0
num[3] would be 1
and so on...</p>

<p>Putting an int into an array isn't difficult, just the process of getting the binary value of a float is where I'm stuck. Can you just read the binary in the memory that the float variable? If not, how could I go about doing this in C++?</p>

<p>EDIT: The reason for doing the comparison this way is that I am wanting to learn to do bitwise operations in C++.</p>
","<p>Use union and bitset:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;bitset&gt;

int main()
{
    union
    {
         float input;   // assumes sizeof(float) == sizeof(int)
         int   output;
    }    data;

    data.input = 2.25125;

    std::bitset&lt;sizeof(float) * CHAR_BIT&gt;   bits(data.output);


    std::cout &lt;&lt; bits &lt;&lt; std::endl;

    // or

    std::cout &lt;&lt; ""BIT 4: "" &lt;&lt; bits[4] &lt;&lt; std::endl;
    std::cout &lt;&lt; ""BIT 7: "" &lt;&lt; bits[7] &lt;&lt; std::endl;
}
</code></pre>

<p>It may not be an array but you can access bits with [] operator as if you were using an array.</p>

<p>Output</p>

<pre><code>$ ./bits
01000000000100000001010001111011
BIT 4: 1
BIT 7: 0
</code></pre>
","474058"
"C read binary stdin","27343","","<p>I'm trying to build an instruction pipeline simulator and I'm having a lot of trouble getting started. What I need to do is read binary from stdin, and then store it in memory somehow while I manipulate the data. I need to read in chunks of exactly 32 bits one after the other.</p>

<p>How do I read in chunks of exactly 32 bits at a time? Secondly, how do I store it for manipulation later?</p>

<p>Here's what I've got so far, but examining the binary chunks I read further, it just doesn't look right, I don't think I'm reading exactly 32 bits like I need.</p>

<pre><code>char buffer[4] = { 0 }; // initialize to 0
unsigned long c = 0;
int bytesize = 4; // read in 32 bits
while (fgets(buffer, bytesize, stdin)) {
  memcpy(&amp;c, buffer, bytesize); // copy the data to a more usable structure for bit manipulation later
  // more stuff
  buffer[0] = 0; buffer[1] = 0; buffer[2] = 0; buffer[3] = 0; // set to zero before next loop
}
fclose(stdin);
</code></pre>

<p>How do I read in 32 bits at a time (they are all 1/0, no newlines etc), and what do I store it in, is <code>char[]</code> okay?</p>

<p>EDIT: I'm able to read the binary in but none of the answers produce the bits in the correct order — they are all mangled up, I suspect endianness and problems reading and moving 8 bits around ( 1 char) at a time — this needs to work on Windows and C ... ?</p>
","<p>I had it right the first time, except, I needed ntohl ... <a href=""https://stackoverflow.com/questions/1614399/c-endian-conversion-bit-by-bit/1615275#1615275"">C Endian Conversion : bit by bit</a></p>
","1615322"
"Python: Searching/reading binary data","27311","","<p>I'm reading in a binary file (a jpg in this case), and need to find some values in that file. For those interested, the binary file is a jpg and I'm attempting to pick out its dimensions by looking for the binary structure as <a href=""http://www.anttikupila.com/flash/getting-jpg-dimensions-with-as3-without-loading-the-entire-file/"" rel=""noreferrer"">detailed here</a>. </p>

<p>I need to find FFC0 in the binary data, skip ahead some number of bytes, and then read 4 bytes (this should give me the image dimensions).</p>

<p>What's a good way of searching for the value in the binary data? Is there an equivalent of 'find', or something like re?</p>
","<p>You could actually load the file into a string and use</p>

<pre><code>s.find('\xff\xc0')
</code></pre>
","3217350"
"Read binary file c++","27193","","<p>I'm trying to read an image into a char array. Here is my try:</p>

<pre><code>ifstream file (""htdocs/image.png"", ios::in | ios::binary | ios::ate);
ifstream::pos_type fileSize;
char* fileContents;
if(file.is_open())
{
    fileSize = file.tellg();
    fileContents = new char[fileSize];
    file.seekg(0, ios::beg);
    if(!file.read(fileContents, fileSize))
    {
        cout &lt;&lt; ""fail to read"" &lt;&lt; endl;
    }
    file.close();

    cout &lt;&lt; ""size: "" &lt;&lt; fileSize &lt;&lt; endl;
    cout &lt;&lt; ""sizeof: "" &lt;&lt; sizeof(fileContents) &lt;&lt; endl;
    cout &lt;&lt; ""length: "" &lt;&lt; strlen(fileContents) &lt;&lt; endl;
    cout &lt;&lt; ""random: "" &lt;&lt; fileContents[55] &lt;&lt; endl;
    cout &lt;&lt; fileContents &lt;&lt; endl;
}
</code></pre>

<p>And this is the output:</p>

<pre><code>size: 1944
sizeof: 8
length: 8
random: ?
?PNG
</code></pre>

<p>Can anyone explain this to me? Is there an end-of-file char at position 8? This example was taken from <a href=""http://www.cplusplus.com/doc/tutorial/files/"" rel=""noreferrer"">cplusplus.com</a></p>

<p>Running Mac OS X and compiling with XCode. </p>
","<ol>
<li><p>Returns the size of the file. size of your <code>image.png</code> is <code>1944 bytes</code>.</p>

<p><code>cout &lt;&lt; ""size: "" &lt;&lt; fileSize &lt;&lt; endl;</code></p></li>
<li><p>Returns the <code>sizeof(char*)</code>, which is <code>8</code> on your environment. <strong><em>Note that size of any pointer is always the same on any environment.</em></strong> </p>

<p><code>cout &lt;&lt; ""sizeof: "" &lt;&lt; sizeof(fileContents) &lt;&lt; endl;</code></p></li>
<li><p>The file you are reading is a binary file so it might contain <code>0</code> as a valid data. When you use <code>strlen</code>, it returns the length until a <code>0</code> is encountered, which in the case of your file is <code>8</code>.</p>

<p><code>cout &lt;&lt; ""length: "" &lt;&lt; strlen(fileContents) &lt;&lt; endl;</code></p></li>
<li><p>Returns the character at the <code>56th location</code> (remember array indexing starts from 0) from start of file.</p>

<p><code>cout &lt;&lt; ""random: "" &lt;&lt; fileContents[55] &lt;&lt; endl;</code></p></li>
</ol>

<p><strong>A suggestion:</strong>    </p>

<p><em><strong>Do remember to deallocate the dynamic memory allocation for <code>fileContents</code> using:</em></strong></p>

<pre><code>delete[] fileContents;
</code></pre>

<p>if you don't, you will end up creating a <strong><em>memory leak</em></strong>.</p>
","6162672"
"How to check my byte flag?","27101","","<p>I use a byte to store some flag like <code>10101010</code>and I would like to know how to verify that a specific bit is at <code>1</code> or <code>0</code>.</p>
","<p>Here's a function that can be used to test any desired bit:</p>

<pre><code>bool is_bit_set(unsigned value, unsigned bitindex)
{
    return (value &amp; (1 &lt;&lt; bitindex)) != 0;
}
</code></pre>

<p>A bit of explanation:</p>

<p>The left shift operator (&lt;&lt;) is used to create a bit mask.  (1 &lt;&lt; 0) will be equal to 00000001, (1 &lt;&lt; 1) will be equal to 00000010, (1 &lt;&lt; 3) will be equal to 00001000, etc.  So a shift of 0 tests the rightmost bit.  A shift of 31 would be the leftmost bit of a 32-bit value.</p>

<p>The bitwise-and operator (&amp;) gives a result where all the bits that are 1 on both sides are set.  Examples: 1111 &amp; 0001 = 0001; 1111 &amp; 0010 == 0010; 0000 &amp; 0001 = 0000.  So, the expression (value &amp; (1 &lt;&lt; bitindex)) will return the bitmask if the associated bit is 1 in value, or will return 0 if the associated bit is 0.</p>

<p>Finally, we just check whether the result is non-zero.  (This could actually be left out, but I like to make it explicit.)</p>
","127062"
"PHP: How to convert an image from URL to Base64?","27050","","<p>I want to convert image from its url to base64.</p>
","<p>Do you want to create a data url? You need a MIME-Type and some other additional information then (see <a href=""http://en.wikipedia.org/wiki/Data_URI_scheme"" rel=""noreferrer"">Wikipedia</a>). If this is not the case, this would be a simple base64 representation of the image:</p>

<pre><code>$b64image = base64_encode(file_get_contents('path/to/image.png'));
</code></pre>

<p>Relevant docs: <a href=""http://php.net/base64_encode"" rel=""noreferrer""><code>base64_encode()</code>-function</a>, <a href=""http://php.net/file_get_contents"" rel=""noreferrer""><code>file_get_contents()</code>-function</a>.</p>
","4343723"
"Fast read/write from file in delphi","26613","","<p>I am loading a file into a array in binary form this seems to take a while
is there a better faster more efficent way to do this.
i am using a similar method for writing back to the file.</p>

<pre><code>procedure openfile(fname:string);
var
    myfile: file;
    filesizevalue,i:integer;
begin
  assignfile(myfile,fname);
  filesizevalue:=GetFileSize(fname); //my method
  SetLength(dataarray, filesizevalue);
  i:=0;
  Reset(myFile, 1);
  while not Eof(myFile) do
    begin
      BlockRead(myfile,dataarray[i], 1);
      i:=i+1;
    end;
  CloseFile(myfile);
end;
</code></pre>
","<p>You generally shouldn't read files byte for byte. Use BlockRead with a larger value (512 or 1024 often are best) and use its return value to find out how many bytes were read.</p>

<p>If the size isn't too large (and your use of SetLength seems to support this), you can also use one BlockRead call reading the complete file at once. So, modifying your approach, this would be:</p>

<pre><code>AssignFile(myfile,fname);
filesizevalue := GetFileSize(fname);
Reset(myFile, 1);
SetLength(dataarray, filesizevalue);
BlockRead(myFile, dataarray[0], filesizevalue);
CloseFile(myfile);
</code></pre>

<p>Perhaps you could also change the procedure to a boolean function named OpenAndReadFile and return false if the file couldn't be opened or read.</p>
","455795"
"Determining binary/text file type in Java?","26433","","<p>Namely, how would you tell an archive (jar/rar/etc.) file from a textual (xml/txt, encoding-independent) one?</p>
","<p>There's no guaranteed way, but here are a couple of possibilities:</p>

<p>1) Look for a header on the file.  Unfortunately, headers are file-specific, so while you might be able to find out that it's a RAR file, you won't get the more generic answer of whether it's text or binary.</p>

<p>2) Count the number of character vs. non-character types.  Text files will be mostly alphabetical characters while binary files - especially compressed ones like rar, zip, and such - will tend to have bytes more evenly represented.</p>

<p>3) Look for a regularly repeating pattern of newlines.</p>
","621003"
"Problem writing int to binary file in C","26264","","<p>I need to write data to a binary file using C's I/O functions. The following code causes a runtime exception :</p>

<pre><code>
#include ""stdio.h""

int main(int argc,char* argv[]) {
    FILE *fp = fopen(""path_to_file.bin"",""wb"");
    if(fp == NULL) {
        printf(""error creating file"");
        return -1;
    }
    int val = 4;
    fwrite((const void*)val,sizeof(int),1,fp);
    fclose(fp);
    return 0;
}
</code></pre>

<p>The code dies at the fwrite. Can you spot what I'm doing wrong? Apparently, I'm, trying to access data at 0x0000004 or something like that.</p>

<p>Thanks !</p>
","<pre><code> fwrite((const void*)val,sizeof(int),1,fp);
</code></pre>

<p>should be:</p>

<pre><code> fwrite((const void*) &amp; val,sizeof(int),1,fp);
</code></pre>

<p>BTW, if you don't use the cast, you will get a sensible error message. Casts tend to be used by C (and C++) programmers far more often than they should be - a good rule of thumb  is ""if it needs a cast, it's probably wrong"".</p>
","772126"
"Python PIL bytes to Image","26210","","<pre><code>import PIL
from PIL import Image
from PIL import ImageDraw
from PIL import ImageFont
import urllib.request

with urllib.request.urlopen('http://pastebin.ca/raw/2311595') as in_file:
    hex_data = in_file.read()
print(hex_data)
img = Image.frombuffer('RGB', (320,240), hex_data) #i have tried fromstring
draw = ImageDraw.Draw(img)
font = ImageFont.truetype(""arial.ttf"",14)
draw.text((0, 220),""This is a test11"",(255,255,0),font=font)
draw = ImageDraw.Draw(img)
img.save(""a_test.jpg"")
</code></pre>

<p>i m trying to convert binary to image,and then draw the text.but i get the error with:</p>

<pre><code>img = Image.frombuffer('RGB', (320,240), hex_data) 
raise ValueError(""not enough image data"")
ValueError: not enough image data
</code></pre>

<p>i have uploaded the bytes string at here <a href=""http://pastebin.ca/raw/2311595"" rel=""nofollow noreferrer"">http://pastebin.ca/raw/2311595</a><br>
and the picture size i can sure that is 320x240</p>

<h2>ADDITIONAL</h2>

<p>here is what i can sure the picture bytes string are from 320x240,just run the code will create a image from the bytes string</p>

<pre><code>import urllib.request
import binascii
import struct

# Download the data.
with urllib.request.urlopen('http://pastebin.ca/raw/2311595') as in_file:
     hex_data = in_file.read()
# Unhexlify the data.
bin_data = binascii.unhexlify(hex_data)
print(bin_data)
# Remove the embedded lengths.
jpeg_data = bin_data
# Write out the JPEG.
with open('out.jpg', 'wb') as out_file:
    out_file.write(jpeg_data)
</code></pre>

<h2>SOLVED, THIS IS THE CODE UPDATED</h2>

<pre><code>from PIL import Image
from PIL import ImageDraw
from PIL import ImageFont
import urllib.request
import io
import binascii

data = urllib.request.urlopen('http://pastebin.ca/raw/2311595').read()
r_data = binascii.unhexlify(data)
#r_data = """".unhexlify(chr(int(b_data[i:i+2],16)) for i in range(0, len(b_data),2))

stream = io.BytesIO(r_data)

img = Image.open(stream)
draw = ImageDraw.Draw(img)
font = ImageFont.truetype(""arial.ttf"",14)
draw.text((0, 220),""This is a test11"",(255,255,0),font=font)
draw = ImageDraw.Draw(img)
img.save(""a_test.png"")
</code></pre>
","<p>That image is not formed of raw bytes - rather it is an encoded JPEG file.
Moreover, you are not parsing the ascii HEX representation of the stream into proper bytes:
that is, an ""ff"" sequence in that file is being passed to PIL as two c letters ""f"" instead of a byte with the number 255.</p>

<p>So, first, you decode the string to a proper byte sequence - sorry for the convolution - it is likely there is a better way to do that, but I am on a slow day:</p>

<pre><code>data = urllib.urlopen(""http://pastebin.ca/raw/2311595"").read()
r_data = """".join(chr(int(data[i:i+2],16)) for i in range(0, len(data),2)) 
</code></pre>

<p>Ah, C.Y. posted on hte comment - this way:</p>

<pre><code>&gt;&gt;&gt; import binascii
&gt;&gt;&gt; b_data = binascii.unhexlify(data)
</code></pre>

<p>And now, you import it to PIL as a JPEG image:</p>

<pre><code>&gt;&gt;&gt; from PIL import Image
&gt;&gt;&gt; import cStringIO as StringIO
&gt;&gt;&gt; stream = StringIO.StringIO(b_data)
&gt;&gt;&gt; img = Image.open(stream)
&gt;&gt;&gt; img.size
(320, 240)
</code></pre>
","14760096"
"Manipulating binary data in Python","26134","","<p>I am opening up a binary file like so: </p>

<pre><code>file = open(""test/test.x"", 'rb')
</code></pre>

<p>and reading in lines to a list. Each line looks a little like:</p>

<pre><code>'\xbe\x00\xc8d\xf8d\x08\xe4.\x07~\x03\x9e\x07\xbe\x03\xde\x07\xfe\n'
</code></pre>

<p>I am having a hard time manipulating this data. If I try and print each line, python freezes, and emits beeping noises (I think there's a binary beep code in there somewhere). How do I go about using this data safely? How can I convert each hex number to decimal?</p>
","<p>To print it, you can do something like this:</p>

<pre><code>print repr(data)
</code></pre>

<p>For the whole thing as hex:</p>

<pre><code>print data.encode('hex')
</code></pre>

<p>For the decimal value of each byte:</p>

<pre><code>print ' '.join([str(ord(a)) for a in data])
</code></pre>

<p>To unpack binary integers, etc. from the data as if they originally came from a C-style struct, look at the <a href=""http://docs.python.org/library/struct.html"" rel=""nofollow noreferrer"">struct</a> module.</p>
","3059345"
"How to convert integer number into binary vector?","25940","","<p>How to convert an integer number into binary vector using R?</p>

<p>For example :</p>

<pre><code>number &lt;- 11
[1] 1 0 1 1
</code></pre>

<p>what is the fastest possible method of conversion (using R code or some existing functions from packages) if I need to convert whole vector of numbers (minimum value = 0, maximum =300) into binary matrix ?</p>
","<p>There's the <code>intToBits</code> function that converts any integer to a vector of 32 raws,  so you can do this:</p>

<pre><code>decimals &lt;- c(3,5,11,4)
m &lt;- sapply(decimals,function(x){ as.integer(intToBits(x))})
m

&gt; m
      [,1] [,2] [,3] [,4]
 [1,]    1    1    1    0
 [2,]    1    0    1    0
 [3,]    0    1    0    1
 [4,]    0    0    1    0
 [5,]    0    0    0    0
 [6,]    0    0    0    0
 [7,]    0    0    0    0
 [8,]    0    0    0    0
 [9,]    0    0    0    0
[10,]    0    0    0    0
[11,]    0    0    0    0
[12,]    0    0    0    0
[13,]    0    0    0    0
[14,]    0    0    0    0
[15,]    0    0    0    0
[16,]    0    0    0    0
[17,]    0    0    0    0
[18,]    0    0    0    0
[19,]    0    0    0    0
[20,]    0    0    0    0
[21,]    0    0    0    0
[22,]    0    0    0    0
[23,]    0    0    0    0
[24,]    0    0    0    0
[25,]    0    0    0    0
[26,]    0    0    0    0
[27,]    0    0    0    0
[28,]    0    0    0    0
[29,]    0    0    0    0
[30,]    0    0    0    0
[31,]    0    0    0    0
[32,]    0    0    0    0
</code></pre>
","12088344"
"Sign extension from 16 to 32 bits in C","25921","","<p>I have to do a sign extension for a 16-bit integer and for some reason, it seems not to be working properly. Could anyone please tell me where the bug is in the code? I've been working on it for hours.</p>

<pre><code>int signExtension(int instr) {
    int value = (0x0000FFFF &amp; instr);
    int mask = 0x00008000;
    int sign = (mask &amp; instr) &gt;&gt; 15;
    if (sign == 1)
        value += 0xFFFF0000;
    return value;
}
</code></pre>

<p>The instruction (instr) is 32 bits and inside it I have a 16bit number.</p>
","<p>Try:</p>

<pre><code>int signExtension(int instr) {
    int value = (0x0000FFFF &amp; instr);
    int mask = 0x00008000;
    if (mask &amp; instr) {
        value += 0xFFFF0000;
    }
    return value;
}
</code></pre>
","6215333"
"flask return image created from database","25907","","<p>my images are stored in MongoDB, I'd like to return them to the client, here is how the code is like:</p>

<pre><code>@app.route(""/images/&lt;int:pid&gt;.jpg"")
def getImage(pid):
    # get image binary from MongoDB, which is bson.Binary type
    return image_binary
</code></pre>

<p>However, it seems that I can't return binary directly in Flask?</p>

<p>Here is what I came up with now:</p>

<ol>
<li>return the base64 of the image binary. -> IE&lt;8 doesn't support this.</li>
<li>create a temp file then return it with <code>send_file</code>.</li>
</ol>

<p>Is there better solutions ?</p>
","<p>Setting the correct headers should do the trick:</p>

<pre><code>@app.route(""/images/&lt;int:pid&gt;.jpg"")
def getImage(pid):
    response = make_response(image_binary)
    response.headers['Content-Type'] = 'image/jpeg'
    response.headers['Content-Disposition'] = 'attachment; filename=img.jpg'
    return response
</code></pre>

<p>Relevant: <a href=""http://werkzeug.pocoo.org/docs/#werkzeug.Headers"" rel=""noreferrer"">werkzeug.Headers</a> and <a href=""http://flask.pocoo.org/docs/api/#response-objects"" rel=""noreferrer"">flask.Response</a></p>

<p><strong>Edit:</strong> I've just seen you can pass a file-descriptor to <code>flask.sendfile</code>, so:</p>

<pre><code>return send_file(io.BytesIO(image_binary))
</code></pre>

<p>is the better way.</p>
","11017839"
"Convert integer from (pure) binary to BCD","25680","","<p>I'm to stupid right now to solve this problem...</p>

<p>I get a BCD number (every digit is an own 4Bit representation)</p>

<p>For example, what I want:</p>

<ul>
<li>Input: 202 (hex) == 514 (dec)</li>
<li><p>Output: BCD 0x415</p></li>
<li><p>Input: 0x202</p></li>
<li>Bit-representation: 0010 0000 0010 = 514</li>
</ul>

<p>What have I tried: </p>

<pre><code>unsigned int uiValue = 0x202;
unsigned int uiResult = 0;
unsigned int uiMultiplier = 1;
unsigned int uiDigit = 0;


// get the dec bcd value
while ( uiValue &gt; 0 )
{
    uiDigit= uiValue &amp; 0x0F;
    uiValue &gt;&gt;= 4;
    uiResult += uiMultiplier * uiDigit;
    uiMultiplier *= 10;
}
</code></pre>

<p>But I know that's very wrong this would be 202 in Bit representation and then split into 5 nibbles and then represented as decimal number again</p>

<p>I can solve the problem on paper but I just cant get it in a simple C-Code </p>
","<p>You got it the wrong way round. Your code is converting from <strong>BCD to binary</strong>, just as your question's (original) title says. But the input and output values you provided are correct only if you convert from <strong>binary to BCD</strong>. In that case, try:</p>

<pre><code>#include &lt;stdio.h&gt;

int main(void) {

   int binaryInput = 0x202; 
   int bcdResult = 0;
   int shift = 0;

   printf(""Binary: 0x%x (dec: %d)\n"", binaryInput , binaryInput );

   while (binaryInput &gt; 0) {
      bcdResult |= (binaryInput % 10) &lt;&lt; (shift++ &lt;&lt; 2);
      binaryInput /= 10;
   }

   printf(""BCD: 0x%x (dec: %d)\n"", bcdResult , bcdResult );
   return 0;
}
</code></pre>

<p>Proof: <a href=""http://ideone.com/R0reQh"" rel=""nofollow noreferrer"">http://ideone.com/R0reQh</a></p>
","13247858"
"Deserializing a byte array","25609","","<p>If I wanted to fill a structure from a binary file, I would use something like this:</p>



<pre class=""lang-cs prettyprint-override""><code>using (BinaryReader br = new BinaryReader(File.Open(filename, FileMode.Open)))
{
    myStruct.ID = br.ReadSingle();
    myStruct.name = br.ReadBytes(20);
}
</code></pre>

<p>However, I must read the whole file into a byte array before deserializing, because I want to do some pre-processing. Is there any <strong>managed</strong> way to fill my structure from the byte array, preferably similar to the one above?</p>
","<p>This is a sample to take some data (actually a System.Data.DataSet) and serialize to an array of bytes, while compressing using DeflateStream.</p>

<pre><code>try
{
    var formatter = new BinaryFormatter();
    byte[] content;
    using (var ms = new MemoryStream())
    {
         using (var ds = new DeflateStream(ms, CompressionMode.Compress, true))
         {
             formatter.Serialize(ds, set);
         }
         ms.Position = 0;
         content = ms.GetBuffer();
         contentAsString = BytesToString(content);
     }
}
catch (Exception ex) { /* handle exception omitted */ }
</code></pre>

<p>Here is the code in reverse to deserialize: </p>

<pre><code>        var set = new DataSet();
        try
        {
            var content = StringToBytes(s);
            var formatter = new BinaryFormatter();
            using (var ms = new MemoryStream(content))
            {
                using (var ds = new DeflateStream(ms, CompressionMode.Decompress, true))
                {
                    set = (DataSet)formatter.Deserialize(ds);                        
                }
            }
        }
        catch (Exception ex)
        {
            // removed error handling logic!
        }
</code></pre>

<p>Hope this helps.  As Nate implied, we are using MemoryStream here. </p>
","6587124"
"Two's Complement Binary in Python?","25454","","<p>Integers in Python are stored in two's complement, correct?</p>

<p>Although:</p>

<pre><code>&gt;&gt;&gt; x = 5
&gt;&gt;&gt; bin(x)
0b101
</code></pre>

<p>And:</p>

<pre><code>&gt;&gt;&gt; x = -5
&gt;&gt;&gt; bin(x)
-0b101
</code></pre>

<p>That's pretty lame. How do I get python to give me the numbers in REAL binary bits, and without the 0b infront of it? So:</p>

<pre><code>&gt;&gt;&gt; x = 5
&gt;&gt;&gt; bin(x)
0101
&gt;&gt;&gt; y = -5
&gt;&gt;&gt; bin(y)
1011
</code></pre>
","<p>Not sure how to get what you want using the standard lib.  There are a handful of scripts and packages out there that will do the conversion for you.</p>

<p>I just wanted to note the ""why"" , and why it's not lame.</p>

<p>bin() doesn't return binary bits. it converts the number to a binary string.  the leading '0b' tells the interpreter that you're dealing with a binary number , as per the python language definition.  this way you can directly work with binary numbers, like this </p>

<pre><code>&gt;&gt;&gt; 0b01
1
&gt;&gt;&gt; 0b10
2
&gt;&gt;&gt; 0b11
3
&gt;&gt;&gt; 0b01 + 0b10
3
</code></pre>

<p>that's not lame. that's great.</p>

<hr>

<p><a href=""http://docs.python.org/library/functions.html#bin"" rel=""nofollow noreferrer"">http://docs.python.org/library/functions.html#bin</a></p>

<blockquote>
  <p>bin(x)</p>
  
  <blockquote>
    <p>Convert an integer number to a binary string. </p>
  </blockquote>
</blockquote>

<p><a href=""http://docs.python.org/reference/lexical_analysis.html#integers"" rel=""nofollow noreferrer"">http://docs.python.org/reference/lexical_analysis.html#integers</a></p>

<blockquote>
  <p>Integer and long integer literals are described by the following lexical definitions:</p>
  
  <blockquote>
    <p>bininteger     ::=  ""0"" (""b"" | ""B"") bindigit+</p>
    
    <p>bindigit       ::=  ""0"" | ""1""</p>
  </blockquote>
</blockquote>
","12946252"
"writing into binary files","25322","","<pre><code>#include &lt;iostream&gt;
#include &lt;fstream&gt;

using namespace std;

class info {

private:
    char name[15];
    char surname[15];
    int age;
public:
    void input(){
        cout&lt;&lt;""Your name:""&lt;&lt;endl;
            cin.getline(name,15);
        cout&lt;&lt;""Your surname:""&lt;&lt;endl;
        cin.getline(surname,15);
        cout&lt;&lt;""Your age:""&lt;&lt;endl;
        cin&gt;&gt;age;
        to_file(name,surname,age);
    }

    void to_file(char name[15], char surname[15], int age){
        fstream File (""example.bin"", ios::out  | ios::binary | ios::app);
    // I doesn't know how to fill all variables(name,surname,age) in 1 variable (memblock) 
        //example File.write ( memory_block, size ); 

File.close();
    }

};

int main(){

info ob;
ob.input();

 return 0;
}
</code></pre>

<p>I don't know how to write more than 1 variable into a file, please help, I included an example ;) Maybe there are better ways to write to a file, please help me with this, it's to hard for me to solve.</p>
","<p>For a <em>text</em> file, you could easily output one variable per line using a similar <code>&lt;&lt;</code> to the one you use with <code>std::cout</code>. </p>

<p>For a <em>binary</em> file, you need to use <a href=""http://en.cppreference.com/w/cpp/io/basic_ostream/write"" rel=""noreferrer""><code>std::ostream::write()</code></a>, which writes a sequence of bytes. For your <code>age</code> attribute, you'll need to <code>reinterpret_cast</code> this to <code>const char*</code> and write as many bytes as is necessary to hold an <code>int</code> for your machine architecture. Note that if you intend to read this binary date on a different machine, you'll have to take <a href=""http://en.wikipedia.org/wiki/Word_%28computer_architecture%29"" rel=""noreferrer"">word size</a> and <a href=""http://en.wikipedia.org/wiki/Endianness"" rel=""noreferrer"">endianness</a> into consideration. I also recommend that you zero the <code>name</code> and <code>surname</code> buffers before you use them lest you end up with artefacts of uninitialised memory in your binary file.</p>

<p>Also, there's no need to pass attributes of the class into the <code>to_file()</code> method.</p>

<pre><code>#include &lt;cstring&gt;
#include &lt;fstream&gt;
#include &lt;iostream&gt;

class info
{
private:
    char name[15];
    char surname[15];
    int age;

public:
    info()
        :name()
        ,surname()
        ,age(0)
    {
        memset(name, 0, sizeof name);
        memset(surname, 0, sizeof surname);
    }

    void input()
    {
        std::cout &lt;&lt; ""Your name:"" &lt;&lt; std::endl;
        std::cin.getline(name, 15);

        std::cout &lt;&lt; ""Your surname:"" &lt;&lt; std::endl;
        std::cin.getline(surname, 15);

        std::cout &lt;&lt; ""Your age:"" &lt;&lt; std::endl;
        std::cin &gt;&gt; age;

        to_file();
    }

    void to_file()
    {
        std::ofstream fs(""example.bin"", std::ios::out | std::ios::binary | std::ios::app);
        fs.write(name, sizeof name);
        fs.write(surname, sizeof surname);
        fs.write(reinterpret_cast&lt;const char*&gt;(&amp;age), sizeof age);
        fs.close();
    }
};

int main()
{
    info ob;
    ob.input();
}
</code></pre>

<p>A sample data file may look like this:</p>

<pre><code>% xxd example.bin
0000000: 7573 6572 0000 0000 0000 0000 0000 0031  user...........1
0000010: 3036 3938 3734 0000 0000 0000 0000 2f00  069874......../.
0000020: 0000                                     ..
</code></pre>
","8550824"
"Saving data to a binary file","24915","","<p>I would like to save a file as binary, because I've heard that it would probably be smaller than a normal text file.</p>

<p>Now I am trying to save a binary file with some text, but the problem is that the file just contains the text and <code>NULL</code> at the end. I would expect to see only zero's and one's inside the file.</p>

<p>Any explaination or suggestions are highly appreciated.</p>

<p><strong>Here is my code</strong></p>

<pre><code>#include &lt;iostream&gt;
#include &lt;stdio.h&gt;

int main()
{
     /*Temporary data buffer*/
     char buffer[20];

     /*Data to be stored in file*/
     char temp[20]=""Test"";

     /*Opening file for writing in binary mode*/
     FILE *handleWrite=fopen(""test.bin"",""wb"");

     /*Writing data to file*/
     fwrite(temp, 1, 13, handleWrite);

     /*Closing File*/
     fclose(handleWrite);

    /*Opening file for reading*/
    FILE *handleRead=fopen(""test.bin"",""rb"");

    /*Reading data from file into temporary buffer*/
    fread(buffer,1,13,handleRead);

    /*Displaying content of file on console*/
    printf(""%s"",buffer);

    /*Closing File*/
    fclose(handleRead);
    std::system(""pause"");

    return 0;
}
</code></pre>
","<p>All files contain only ones and zeroes, on binary computers that's all there is to play with.</p>

<p>When you save text, you are saving the binary representation of that text, in a given <em>encoding</em> that defines how each letter is mapped to bits.</p>

<p>So for text, a text file or a binary file almost doesn't matter; the savings in space that you've heard about generally come into play for other data types.</p>

<p>Consider a floating point number, such as 3.141592653589. If saved as text, that would take one character per digit (just count them), plus the period. If saved in binary as just a copy of the <code>float</code>'s bits, it will take four characters (four bytes, or 32 bits) on a typical 32-bit system. The exact number of bits stored by a call such as:</p>

<pre><code>FILE *my_file = fopen(""pi.bin"", ""wb"");
float x = 3.1415;
fwrite(&amp;x, sizeof x, 1, my_file);
</code></pre>

<p>is <code>CHAR_BIT * sizeof x</code>, see <code>&lt;stdlib.h&gt;</code> for <code>CHAR_BIT</code>.</p>
","5648510"
"Write a raw binary file with NumPy array data","24906","","<p>I'd like to save the contents of a numpy float array into a raw binary file as signed 16 bit integers. I tried to accomplish this using <a href=""http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.tofile.html"" rel=""noreferrer"">ndarray.tofile</a> but I can't figure out the right format string. It seems that the file is saved in double format, mo matter how I choose the format string. How do I do this?
Thanks.</p>
","<p>I think the easiest way to do this is to first convert the array to int16,</p>

<pre><code>array.astype('int16').tofile(filename)
</code></pre>
","10536046"
"binary protocols v. text protocols","24859","","<p>does anyone have a good definition for what a binary protocol is? and what is a text protocol actually? how do these compare to each other in terms of bits sent on the wire? </p>

<p>here's what wikipedia says about binary protocols:</p>

<p>A binary protocol is a protocol which is intended or expected to be read by a machine rather than a human being (<a href=""http://en.wikipedia.org/wiki/Binary_protocol"" rel=""noreferrer"">http://en.wikipedia.org/wiki/Binary_protocol</a>)</p>

<p>oh come on! </p>

<p>to be more clear, if I have jpg file how would that be sent through a binary protocol and how through a text one? in terms of bits/bytes sent on the wire of course. </p>

<p>at the end of the day if you look at a string it is itself an array of bytes so the distinction between the 2 protocols should rest on what actual data is being sent on the wire. in other words, on how the initial data (jpg file) is encoded before being sent.</p>

<p>any coments are apprecited, I am trying to get to the essence of things here.</p>

<p>salutations!</p>
","<p>Binary protocol versus text protocol isn't really about how binary blobs are encoded. The difference is really whether the protocol is oriented around data structures or around text strings. Let me give an example: HTTP. HTTP is a text protocol, even though when it sends a jpeg image, it just sends the raw bytes, not a text encoding of them. </p>

<p>But what makes HTTP a text protocol is that the exchange to <em>get</em> the jpg looks like this:</p>

<p>Request:</p>

<pre><code>GET /files/image.jpg HTTP/1.0
Connection: Keep-Alive
User-Agent: Mozilla/4.01 [en] (Win95; I)
Host: hal.etc.com.au
Accept: image/gif, image/x-xbitmap, image/jpeg, image/pjpeg, */*
Accept-Language: en
Accept-Charset: iso-8859-1,*,utf-8
</code></pre>

<p>Response:</p>

<pre><code>HTTP/1.1 200 OK
Date: Mon, 19 Jan 1998 03:52:51 GMT
Server: Apache/1.2.4
Last-Modified: Wed, 08 Oct 1997 04:15:24 GMT
ETag: ""61a85-17c3-343b08dc""
Content-Length: 60830
Accept-Ranges: bytes
Keep-Alive: timeout=15, max=100
Connection: Keep-Alive
Content-Type: image/jpeg

&lt;binary data goes here&gt;
</code></pre>

<p>Note that this could very easily have been packed much more tightly into a structure that would look (in C) something like</p>

<p>Request:</p>

<pre><code>struct request {
  int requestType;
  int protocolVersion;
  char path[1024];
  char user_agent[1024];
  char host[1024];
  long int accept_bitmask;
  long int language_bitmask;
  long int charset_bitmask;
};
</code></pre>

<p>Response:</p>

<pre><code>struct response {
  int responseType;
  int protocolVersion;
  time_t date;
  char host[1024];
  time_t modification_date;
  char etag[1024];
  size_t content_length;
  int keepalive_timeout;
  int keepalive_max;
  int connection_type;
  char content_type[1024];
  char data[];
};
</code></pre>

<p>Where the field names would not have to be transmitted at all, and where, for example, the <code>responseType</code> in the response structure is an int with the value 200 instead of three characters '2' '0' '0'. That's what a text based protocol is: one that is designed to be communicated as a flat stream of (usually human-readable) lines of text, rather than as structured data of many different types.</p>
","2645168"
"How do you read binary data in C# .NET and then convert it to a string?","24717","","<p>As opposed to using <code>StreamReader/Filestream</code> I want to read binary data from files and show that data (formatted) in a textbox.</p>
","<p>There are different cases when one need to read binary file, since it is unclear what you really trying to achieve here are some:</p>

<ul>
<li>read random file and display as series of hex values (similar to binary file view in Visual Studio or any other binary file viewer). Berfectly covered by Jeff M's answer.</li>
<li>Reading and writing your own objects using binary serialization. Check serialization walkthrough on MSDN - <a href=""http://msdn.microsoft.com/en-us/library/et91as27.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/et91as27.aspx</a> and read on BinaryFormatter objects.</li>
<li>Reading someone elses binary format (like JPEG, PNG, ZIP, PDF). In this case you need to know structure of the file (you can often find file format documentation) and use BinaryReader to read individual chunks of the file. For most of the common file formats it is easy to find existing libraries that allow reading such files in more convinient way. MSDN article on BinaryReader have basic usage sample also: <a href=""http://msdn.microsoft.com/en-us/library/system.io.binaryreader.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/system.io.binaryreader.aspx</a>.</li>
</ul>
","5454376"
"Binary representation of float in Python (bits not hex)","24593","","<p>How to get the string as binary IEEE 754 representation of a 32 bit float?</p>

<p><strong>Example</strong></p>

<p>1.00 -> '00111111100000000000000000000000'</p>
","<p>You can do that with the <code>struct</code> package:</p>

<pre><code>import struct
def binary(num):
    return ''.join(bin(ord(c)).replace('0b', '').rjust(8, '0') for c in struct.pack('!f', num))
</code></pre>

<p>That packs it as a network byte-ordered float, and then converts each of the resulting bytes into an 8-bit binary representation and concatenates them out:</p>

<pre><code>&gt;&gt;&gt; binary(1)
'00111111100000000000000000000000'
</code></pre>

<p><strong>Edit</strong>:
There was a request to expand the explanation. I'll expand this using intermediate variables to comment each step.</p>

<pre><code>def binary(num):
    # Struct can provide us with the float packed into bytes. The '!' ensures that
    # it's in network byte order (big-endian) and the 'f' says that it should be
    # packed as a float. Alternatively, for double-precision, you could use 'd'.
    packed = struct.pack('!f', num)
    print 'Packed: %s' % repr(packed)

    # For each character in the returned string, we'll turn it into its corresponding
    # integer code point
    # 
    # [62, 163, 215, 10] = [ord(c) for c in '&gt;\xa3\xd7\n']
    integers = [ord(c) for c in packed]
    print 'Integers: %s' % integers

    # For each integer, we'll convert it to its binary representation.
    binaries = [bin(i) for i in integers]
    print 'Binaries: %s' % binaries

    # Now strip off the '0b' from each of these
    stripped_binaries = [s.replace('0b', '') for s in binaries]
    print 'Stripped: %s' % stripped_binaries

    # Pad each byte's binary representation's with 0's to make sure it has all 8 bits:
    #
    # ['00111110', '10100011', '11010111', '00001010']
    padded = [s.rjust(8, '0') for s in stripped_binaries]
    print 'Padded: %s' % padded

    # At this point, we have each of the bytes for the network byte ordered float
    # in an array as binary strings. Now we just concatenate them to get the total
    # representation of the float:
    return ''.join(padded)
</code></pre>

<p>And the result for a few examples:</p>

<pre><code>&gt;&gt;&gt; binary(1)
Packed: '?\x80\x00\x00'
Integers: [63, 128, 0, 0]
Binaries: ['0b111111', '0b10000000', '0b0', '0b0']
Stripped: ['111111', '10000000', '0', '0']
Padded: ['00111111', '10000000', '00000000', '00000000']
'00111111100000000000000000000000'

&gt;&gt;&gt; binary(0.32)
Packed: '&gt;\xa3\xd7\n'
Integers: [62, 163, 215, 10]
Binaries: ['0b111110', '0b10100011', '0b11010111', '0b1010']
Stripped: ['111110', '10100011', '11010111', '1010']
Padded: ['00111110', '10100011', '11010111', '00001010']
'00111110101000111101011100001010'
</code></pre>
","16444778"
"Binary to decimal in c","24550","","<p>I have a simple code to convert binary to decimal numbers. In my compiler, the decomposition works just fine for number less than 1000, beyond the output is always the same 1023. Anybody has an idea ? </p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

// how many power of ten is there in a number 
// (I don't use the pow() function to avoid trouble with floating numbers)
int residu(int N)
{
    int i=0;
    while(N&gt;=1){
        N=N/10;
        i++;
    }
    return i;
}

//exponentiating a number a by a number b
int power(int a, int b){
    int i;
    int res=1;
    for (i=0;i&lt;b;i++){res=a*res;}
    return res;
}

//converting a number N
int main()
{
    int i;

    //the number to convert
    int N;
    scanf(""%d"",&amp;N);

    //the final decimal result
    int res=0;
    //we decompose N by descending powers of 10, and M is the rest
    int M=0;

    for(i=0;i&lt;residu(N);i++){
        // simple loop to look if there is a power of (residu(N)-1-i) in N, 
        // if yes we increment the binary decomposition by 
        // power(2,residu(N)-1-i)
        if(M+ power(10,residu(N)-1-i) &lt;= N)
        {
            M = M+power(10,residu(N)-1-i);
            res=power(2,residu(N)-1-i)+res;
        }
    }
    printf(""%d\n"",res);
}
</code></pre>
","<p>Yes try this : </p>

<pre><code>#include &lt;stdio.h&gt;
int main(void) 
{ 
char bin; int dec = 0;

while (bin != '\n') { 
scanf(""%c"",&amp;bin); 
if (bin == '1') dec = dec * 2 + 1; 
else if (bin == '0') dec *= 2; } 

printf(""%d\n"", dec); 

return 0;

}
</code></pre>
","12338966"
"How to convert binary to string?","24404","","<pre><code>static List&lt;int&gt; ConvertTextToBinary(int number, int Base)
{
    List&lt;int&gt; list = new List&lt;int&gt;();
    while (number!=0)
    {
        list.Add(number % Base);
        number = number / Base;
    }
    list.Reverse();
    return list;
}



static void Main(string[] args)
{

   string s = ""stackoverflow"";
   int counter=0;
   while (counter!=s.Length)
   {
       int[] a = ConvertTextToBinary(s[counter], 2).ToArray();
       for (int i = 0; i &lt; a.Length; i++)
       {
           Console.Write(a[i]);
       }
       Console.Write(""\n"");
       counter++;
   }
}
</code></pre>

<p>I wrote a method to convert string to binary, its working fine. But now I want to convert binary to string eg: 1101000 is equal to h.</p>
","<pre><code>static string ConvertBinaryToText(List&lt;List&lt;int&gt;&gt; seq){
    return new String(seq.Select(s =&gt; (char)s.Aggregate( (a,b) =&gt; a*2+b )).ToArray());
}

static void Main(){
   string s = ""stackoverflow"";
   var binary = new List&lt;List&lt;int&gt;&gt;();
   for(var counter=0; counter!=s.Length; counter++){
       List&lt;int&gt; a = ConvertTextToBinary(s[counter], 2);
       binary.Add(a);
       foreach(var bit in a){
           Console.Write(bit);
       }
       Console.Write(""\n"");
   }
   string str = ConvertBinaryToText(binary);
   Console.WriteLine(str);//stackoverflow
}
</code></pre>
","8279462"
"Storing hex value in C string?","24300","","<p>I have a string <code>""SOMETHING /\xff""</code> and I want to save the hex representation of <code>0xff</code> into a <code>char</code> buffer.  So I <code>strncpy</code> everything after the forward slash (<code>/</code>) into my buffer (let's call it <code>buff</code>). </p>

<p>However, when I use the gdb command <code>print \x buff</code> to view the contents of <code>buff</code>, it doesn't show <code>0xff</code>.  Any ideas as to what could be wrong?  Is it possible that my forward slash is messing things up?</p>
","<p>I think your problem has to do with the way you're printing the variable in gdb. Take this simple program, compile as debug (<code>-g</code> if using gcc), and run and break at the first <code>puts</code> statement:</p>

<pre><code>int main(void)
{
   char *ptr = ""str \xff"";
   char arr[] = ""str \xff"";
   puts(ptr);
   puts(arr);

   return 0;
}
</code></pre>

<p>If I try and print <code>ptr</code> the way you've mentioned, <code>p /x ptr</code>, it'll print the value of <code>ptr</code> (the address it's pointing to):</p>

<pre><code>(gdb) p /x ptr
$1 = 0x4005f8
</code></pre>

<p>However if I do the same command for <code>arr</code>, I'll get:</p>

<pre><code>(gdb) p /x arr
$2 = {0x73, 0x74, 0x72, 0x20, 0xff, 0x0}
</code></pre>

<p>That's because gdb can see that <code>arr</code> is of type <code>char[6]</code> and not <code>char*</code>. You can get the same results with the command <code>p /x ""str \xff""</code>, which is useful for testing things:</p>

<pre><code>(gdb) p /x ""str \xff""
$3 = {0x73, 0x74, 0x72, 0x20, 0xff, 0x0}
</code></pre>

<p><br/></p>

<p>Now if you want to be able to print a certain amount of bytes from the address pointed to by a pointer, use the examine (<code>x</code>) memory command instead of print (<code>p</code>):</p>

<pre><code>(gdb) x/6bx ptr
0x4005f8 &lt;__dso_handle+8&gt;:  0x73    0x74    0x72    0x20    0xff    0x00
</code></pre>

<p>That'll print 6 bytes in hex from the address pointed to by <code>ptr</code>. Try that with your <code>buff</code> variable and see how you go.</p>

<p><br/></p>

<p>Alternatively, another thing you can try is:</p>

<pre><code>(gdb) p /x (char[6])*ptr
$4 = {0x73, 0x74, 0x72, 0x20, 0xff, 0x0}
</code></pre>

<p>This will treat the <code>char</code> pointed to by <code>ptr</code> as the first element in an array of 6 <code>char</code>s, and will allow you to use the print command.</p>
","10059026"
"Write a binary integer or string to a file in python","23823","","<p>I have a string (it could be an integer too) in Python and I want to write it to a file. It contains only ones and zeros I want that pattern of ones and zeros to be written to a file. I want to write the binary directly because I need to store a lot of data, but only certain values. I see no need to take up the space of using eight bit per value when I only need three.</p>

<p>For instance. Let's say I were to write the binary string <code>""01100010""</code> to a file. If I opened it in a text editor it would say <code>b</code> (01100010 is the ascii code for b). Do not be confused though. I do not want to write ascii codes, the example was just to indicate that I want to directly write bytes to the file.</p>

<hr>

<p>Clarification:</p>

<p>My string looks something like this:</p>

<pre><code>binary_string = ""001011010110000010010""
</code></pre>

<p>It is not made of of the binary codes for numbers or characters. It contains data relative only to my program.</p>
","<p>Alright, after quite a bit more searching, I found an answer. I believe that the rest of you simply didn't understand (which was probably my fault, as I had to edit twice to make it clear). I found it <a href=""http://www.linuxquestions.org/questions/programming-9/writing-binary-data-under-python-718165/"" rel=""nofollow"">here</a>.</p>

<p>The answer was to split up each piece of data, convert them into a binary integer then put them in a binary array. After that, you can use the array's <code>tofile()</code> method to write to a file.</p>

<pre><code>from array import *

bin_array = array('B')

bin_array.append(int('011',2))
bin_array.append(int('010',2))
bin_array.append(int('110',2))

f = file('binary.mydata','wb')
bin_array.tofile(f)
f.close()
</code></pre>
","16888298"
"converting decimal to signed binary","23818","","<p>Let's say I want to convert ""-128"" into binary.</p>

<p>From what I understand, I get the binary representation of ""128"", invert the bits and then add 1.</p>

<p>So 128 = 10000000</p>

<p>So the ""inverse"" is 01111111</p>

<p>So and ""01111111"" + ""1"" = ""10000000"" which is ""-0"" isn't it?</p>

<p>My textbook makes this seem so easy but I can't figure out what I'm doing wrong. Thanks for the help.</p>
","<p>No, that's definitely <code>-128</code> (in two's complement anyway, which is what you're talking about given your description of negating numbers). It's only <code>-0</code> for the sign/magnitude representation of negative numbers.</p>

<p>See <a href=""https://stackoverflow.com/questions/3952123/representation-of-negative-numbers-in-c/3952262#3952262"">this answer</a> for details on the two representations plus the third one that C allows, one's complement, but I'll copy a snippet from there to keep this answer as self-contained as possible.</p>

<hr>

<p>To get the negative representation for a positive number, you:</p>

<ul>
<li>invert all bits then add one for two's complement.</li>
<li>invert all bits for one's complement.</li>
<li>invert just the sign bit for sign/magnitude.</li>
</ul>

<p>You can see this in the table below:</p>

<pre><code>number | twos complement     | ones complement     | sign/magnitude
=======|=====================|=====================|====================
     5 | 0000 0000 0000 0101 | 0000 0000 0000 0101 | 0000 0000 0000 0101
    -5 | 1111 1111 1111 1011 | 1111 1111 1111 1010 | 1000 0000 0000 0101
</code></pre>

<hr>

<p>You should be aware that there is no 128 in 8-bit two's complement numbers, the largest value is 127.</p>

<p>Where the numbers pass the midpoint is where the ""clever"" stuff happens:</p>

<pre><code>00000000 -&gt;    0
00000001 -&gt;    1
: :
01111110 -&gt;  126
01111111 -&gt;  127
10000000 -&gt; -128
10000001 -&gt; -127
: :
11111110 -&gt;   -2
11111111 -&gt;   -1
</code></pre>

<p>because adding the bit pattern of (for example) <code>100</code> and <code>-1</code> with an 8-bit wrap-around will auto-magically give you <code>99</code>:</p>

<pre><code>100+  0 0110 0100
  1-  0 1111 1111
      ===========
      1 0110 0011  99+ (without that leading 1)
</code></pre>
","4720324"
"How many bits do you need to store a number?","23762","","<p>How many bits would you need to store a number for example in the billions. Would you have to use the log2 N to find this out? </p>
","<p>Since I've seen the answer reported incorrectly so many times, I thought I would post the correct answer.</p>

<p>The number of bits needed to represent the positive integer n is</p>

<pre><code>bits = floor( log2(n) + 1 )
</code></pre>

<p>where log2 means log base 2.</p>
","23400205"
"Replacing ""=="" with bitwise operators","23652","","<p>Using only bitwise operators (|, &amp;, ~, ^, >>, &lt;&lt;) and other basic operators like +, -, and !, is it possible to replace the ""=="" below?</p>

<pre><code>int equal(int x, int y) {
    return x == y;
}
</code></pre>
","<p>Two numbers are equal if there is no difference between them:</p>

<pre><code>int equal(int x, int y){
   return !(x-y);
}
</code></pre>
","4161674"
"Bitwise operations equivalent of greater than operator","23651","","<p>I am working on a function that will essentially see which of two ints is larger. The parameters that are passed are 2 32 bit ints. The trick is the only operators allowed are ! ~ | &amp; &lt;&lt; >> ^ (no casting, other data types besides signed int, *, /, -, etc..).</p>

<p>My idea so far is to ^ the two binaries together to see all the positions of the 1 values that they dont share. What I want to do is then take that value and isolate the 1 farthest to the left.  Then see of which of them has that value in it. That value then will be the larger.
(Say we use 8 bit ints instead of 32 bit)
if the two values passed were 01011011 and 01101001
I used ^ on them to get 00100010.
I then want to make it 00100000 in other words 01xxxxxx-> 01000000
Then &amp; it with the first number
!! the result and return it. 
If it is 1, then the first # is larger.</p>

<p>Any thoughts on how to 01xxxxxx->01000000 or anything else to help?</p>

<p>Forgot to note: no ifs, whiles, fors etc...</p>
","<p>Here's a loop-free version which compares unsigned integers in O(lg b) operations where b is the word size of the machine. Note the OP states no other data types than <code>signed int</code>, so it seems likely the top part of this answer does not meet the OP's specifications. (Spoiler version as at the bottom.)</p>

<p>Note that the behavior we want to capture is when the most significant bit mismatch is <code>1</code> for <code>a</code> and <code>0</code> for <code>b</code>. Another way of thinking about this is any bit in <code>a</code> being larger than the corresponding bit in <code>b</code> means <code>a</code> is greater than <code>b</code>, so long as there wasn't an earlier bit in <code>a</code> that was less than the corresponding bit in <code>b</code>.</p>

<p>To that end, we compute all the bits in <code>a</code> greater than the corresponding bits in <code>b</code>, and likewise compute all the bits in <code>a</code> less than the corresponding bits in <code>b</code>. We now want to mask out all the 'greater than' bits that are below any 'less than' bits, so we take all the 'less than' bits and smear them all to the right making a mask: the most significant bit set all the way down to the least significant bit are now <code>1</code>.</p>

<p>Now all we have to do is remove the 'greater than' bits set by using simple bit masking logic.</p>

<p>The resulting value is 0 if <code>a &lt;= b</code> and nonzero if <code>a &gt; b</code>. If we want it to be <code>1</code> in the latter case we can do a similar smearing trick and just take a look at the least significant bit.</p>

<pre><code>#include &lt;stdio.h&gt;

// Works for unsigned ints.
// Scroll down to the ""actual algorithm"" to see the interesting code.

// Utility function for displaying binary representation of an unsigned integer
void printBin(unsigned int x) {
    for (int i = 31; i &gt;= 0; i--) printf(""%i"", (x &gt;&gt; i) &amp; 1);
    printf(""\n"");
}
// Utility function to print out a separator
void printSep() {
    for (int i = 31; i&gt;= 0; i--) printf(""-"");
    printf(""\n"");
}

int main()
{
    while (1)
    {
        unsigned int a, b;

        printf(""Enter two unsigned integers separated by spaces: "");
        scanf(""%u %u"", &amp;a, &amp;b);
        getchar();

        printBin(a);
        printBin(b);
        printSep();

            /************ The actual algorithm starts here ************/

        // These are all the bits in a that are less than their corresponding bits in b.
        unsigned int ltb = ~a &amp; b;

        // These are all the bits in a that are greater than their corresponding bits in b.
        unsigned int gtb = a &amp; ~b;

        ltb |= ltb &gt;&gt; 1;
        ltb |= ltb &gt;&gt; 2;
        ltb |= ltb &gt;&gt; 4;
        ltb |= ltb &gt;&gt; 8;
        ltb |= ltb &gt;&gt; 16;

        // Nonzero if a &gt; b
        // Zero if a &lt;= b
        unsigned int isGt = gtb &amp; ~ltb;

        // If you want to make this exactly '1' when nonzero do this part:
        isGt |= isGt &gt;&gt; 1;
        isGt |= isGt &gt;&gt; 2;
        isGt |= isGt &gt;&gt; 4;
        isGt |= isGt &gt;&gt; 8;
        isGt |= isGt &gt;&gt; 16;
        isGt &amp;= 1;

            /************ The actual algorithm ends here ************/

        // Print out the results.
        printBin(ltb); // Debug info
        printBin(gtb); // Debug info
        printSep();
        printBin(isGt); // The actual result
    }
}
</code></pre>

<p>Note: This should work for signed integers as well if you flip the top bit on <em>both</em> of the inputs, e.g. <code>a ^= 0x80000000</code>.</p>

<h1><strong>Spoiler</strong></h1>

<p>If you want an answer that meets all of the requirements (including 25 operators or less):</p>

<pre><code>int isGt(int a, int b)
{
    int diff = a ^ b;
    diff |= diff &gt;&gt; 1;
    diff |= diff &gt;&gt; 2;
    diff |= diff &gt;&gt; 4;
    diff |= diff &gt;&gt; 8;
    diff |= diff &gt;&gt; 16;

    diff &amp;= ~(diff &gt;&gt; 1) | 0x80000000;
    diff &amp;= (a ^ 0x80000000) &amp; (b ^ 0x7fffffff);

    return !!diff;
}
</code></pre>

<p>I'll leave explaining why it works up to you.</p>
","10097167"
"Convert PHP file to binary","23372","","<p>Is it possible to convert a PHP file to binary and deploy it on a webserver?</p>
","<p>Since PHP is a (relatively)portable language, compiling PHP source to bytecode instead of binary code is more preferable. For this purpose there is an experimental project called <a href=""http://www.php.net/manual/en/intro.bcompiler.php"" rel=""nofollow noreferrer"">bcompiler</a>. </p>
","1845213"
"Binary data with pyserial(python serial port)","23320","","<p>serial.write() method in pyserial seems to only send string data. I have arrays like [0xc0,0x04,0x00] and want to be able to send/receive them via the serial port? Are there any separate methods for raw I/O?</p>

<p>I think I might need to change the arrays to ['\xc0','\x04','\x00'], still, null character might pose a problem.  </p>
","<p>You need to convert your data to a string</p>

<pre><code>""\xc0\x04\x00""
</code></pre>

<p>Null characters are not a problem in Python -- strings are not null-terminated the zero byte behaves just like another byte <code>""\x00""</code>.</p>

<p>One way to do this:</p>

<pre><code>&gt;&gt;&gt; import array
&gt;&gt;&gt; array.array('B', [0xc0, 0x04, 0x00]).tostring()
'\xc0\x04\x00'
</code></pre>
","473057"
"Display file in binary format","23159","","<p>I'd like to view executable file in Vim.</p>

<p>I used <code>:set binary</code> and thought that I will see only ones and zeros, but nothing changed.</p>

<p>How can I achieve to see only ones and zeros?</p>
","<p>Instead of ones and zeros, you can get an hexadecimal representation with:</p>

<pre><code>:setlocal display=uhex
</code></pre>

<p>Also, you can get an hexadecimal dump of a buffer with:</p>

<pre><code>:%!xxd
</code></pre>

<p><a href=""http://vim.wikia.com/wiki/Hex_dump"">Source</a></p>
","8953412"
"script/tool to convert file to C/C++ source code array","23129","","<p>I need a script/tool which reads a binary file and outputs a C/C++ source code array (which represents the file content). Are there any?</p>

<hr>

<p>(This question was deleted earlier. I put this question back in because it is valuable. I was searching for exactly this on Google and didn't found anything. Of course it is trivial to code myself but I would have saved some minutes if I would have found such a simple script. Thus it is valuable.</p>

<p>This questions also had a lot of down-votes without much explanation. Please comment before you down-vote why you think this is of no value or of bad value.</p>

<p>This question also caused a lot of confusion about what I am asking about. If something is unclear, please ask. I don't really know how to make it more clear. See the answers for examples.</p>

<p>Also (after putting the question here), I already have several answers. I just want to put/link them here (again) because I think it might be useful for someone else searching for this.)</p>
","<p>On Debian and other Linux distros is installed by default (along with <code>vim</code>) the <code>xxd</code> tool, which, given the <code>-i</code> option, can do what you want:</p>

<pre><code>matteo@teodeb:~/Desktop$ echo Hello World\! &gt; temp
matteo@teodeb:~/Desktop$ xxd -i temp 
unsigned char temp[] = {
  0x48, 0x65, 0x6c, 0x6c, 0x6f, 0x20, 0x57, 0x6f, 0x72, 0x6c, 0x64, 0x21,
  0x0a
};
unsigned int temp_len = 13;
</code></pre>
","8707241"
"Edit (patch) a binary file in IDA Pro","22883","","<p>i would like to know how to edit a binary file in ida pro (i just need to change one instruction!)</p>

<p>(its ARM binary)</p>

<p>thanks</p>
","<p>I think IDA used to have a feature to do that, but it's not present in the current versions.</p>

<p>You should just use a hex editor. Note the file offset in IDA and edit the file at that address. If you'd like to see the changes in IDA, use the ""File"" -> ""Load file"" -> ""Reload the input file"" menu item.</p>
","969919"
"How to perform round to even with floating point numbers","22585","","<p>In regards to IEEE-754 single precision floating point, how do you perform round to nearest, where ties round to the nearest even digit in the required position (the default and by far the most common mode)?</p>

<p>Basically I have the guard bit, round bit, and sticky bit.
So if we form those into a vector and call it GRS, then the following rules apply:</p>

<ol>
<li>If <code>G = 0</code>, round down (do nothing)</li>
<li>If <code>G = 1</code>, and <code>RS == 10</code> or <code>RS == 01</code>, round up (add one to mantissa)</li>
<li>if <code>GSR = 111</code>, round to even</li>
</ol>

<p>So I am not sure how to perform the round to nearest.  Any help is greatly appreciated.</p>
","<p>Just to make sure we're on the same page, <code>G</code> is the most significant bit of the three, <code>R</code> comes next and <code>S</code> can be thought of as the least significant bit because its value partially represents the even less significant bits that have been truncated in the calculations. These three bits are only used while doing calculations and aren't stored in the floating-point variable before or after the calculations.</p>

<p>This is what you should do in order to round the result to the nearest even number using <code>G</code>, <code>R</code> and <code>S</code>:</p>

<p><strong>GRS</strong> - Action<br>
<strong>0xx</strong> - round down = do nothing (x means any bit value, 0 or 1)<br>
<strong>100</strong> - this is a <strong>tie</strong>: round up if the mantissa's bit just before <strong>G</strong> is 1, else round down=do nothing<br>
<strong>101</strong> - round up<br>
<strong>110</strong> - round up<br>
<strong>111</strong> - round up</p>

<p>Rounding up is done by adding 1 to the mantissa in the mantissa's least significant bit position just before <code>G</code>. If the mantissa overflows (its 23 least significant bits that you will store become zeroes), you have to add 1 to the exponent. If the exponent overflows, you set the number to +infinity or -infinity depending on the number's sign.</p>

<p>In the case of a tie, you add 1 to the mantissa if the mantissa is odd and you add nothing if it's even. That's what makes the result rounded to the nearest even value.</p>
","8984135"
"how to know if a binary number represents a negative number?","22509","","<p>I am reading some C text. In the Negative and Positive Values session, the author mentioned several ways of representing a negative number in binary form.</p>

<p>I understood all of the way and was wondering if with a give binary number, can we determine if it is negative?</p>

<p>For example, the -92 has the binary form: 10100100. But if we are given 10100100, can we say that is -92, and not other non-negative number?</p>
","<p>It depends on the representation, of course. In two's complement, which is widely used, you simply look at the most significant bit.</p>
","7794693"
"Converting from hex to binary without losing leading 0's python","22486","","<p>I have a hex value in a string like </p>

<pre><code>h = '00112233aabbccddee'
</code></pre>

<p>I know I can convert this to binary with:</p>

<pre><code>h = bin(int(h, 16))[2:]
</code></pre>

<p>However, this loses the leading 0's. Is there anyway to do this conversion without losing the 0's? Or is the best way to do this just to count the number of leading 0's before the conversion then add it in afterwards.</p>
","<p>I don't think there is a way to keep those leading zeros by default.</p>

<p>Each hex digit translates to 4 binary digits, so the length of the new string should be exactly 4 times the size of the original.</p>

<pre><code>h_size = len(h) * 4
</code></pre>

<p>Then, you can use <code>.zfill</code> to fill in zeros to the size you want:</p>

<pre><code>h = ( bin(int(h, 16))[2:] ).zfill(h_size)
</code></pre>
","3258407"
"Convert binary string to byte array","22456","","<p>I have a string of ones and zeros that I want to convert to an array of bytes.</p>

<p>For example <code>String b = ""0110100001101001""</code> How can I convert this to a <code>byte[]</code> of length 2?</p>
","<p>Parse it to an integer in base 2, then convert to a byte array.  In fact, since you've got 16 bits it's time to break out the rarely used <code>short</code>.</p>

<pre><code>short a = Short.parseShort(b, 2);
ByteBuffer bytes = ByteBuffer.allocate(2).putShort(a);

byte[] array = bytes.array();
</code></pre>
","17727359"
"PHP read file as an array of bytes","22420","","<p>I have a file written using <code>JAVA</code> program which has an array of integers written as binary I made an for loop over this array and write it using this method</p>

<pre><code>public static void writeInt(OutputStream out, int v) throws IOException {
    out.write((v &gt;&gt;&gt; 24) &amp; 0xFF);
    out.write((v &gt;&gt;&gt; 16) &amp; 0xFF);
    out.write((v &gt;&gt;&gt; 8) &amp; 0xFF);
    out.write((v &gt;&gt;&gt; 0) &amp; 0xFF);
}
</code></pre>

<p>I'm ask about how to read this file in <code>PHP</code>.</p>
","<p>I believe the code you are looking for is:</p>

<pre><code>$byteArray = unpack(""N*"",file_get_contents($filename));
</code></pre>

<p><strong>UPDATE:</strong> Working code supplied by OP</p>

<pre><code>$filename = ""myFile.sav""; 
$handle = fopen($filename, ""rb""); 
$fsize = filesize($filename); 
$contents = fread($handle, $fsize); 
$byteArray = unpack(""N*"",$contents); 
print_r($byteArray); 
for($n = 0; $n &lt; 16; $n++)
{ 
    echo $byteArray [$n].'&lt;br/&gt;'; 
}
</code></pre>
","17963326"
"How do I extract ASCII data from binary file with unknown format, in Windows?","22411","","<p>On Windows, what is the best way to convert a binary file where the internal structure is unknown less that its contents are ASCII in nature back to plain text?</p>

<p>Ideally the conversion would produce a ""human""-readable version.  I think the file should contain something like the following:</p>

<pre><code>Date: 10 FEB 2010
House: 345 Dogwood Drive
Exterior: Brick
</code></pre>
","<p>In Linux/Unix:</p>

<pre><code>$ strings &lt; unknown.dat &gt; ascii-from-unknown.txt
</code></pre>

<p>This is of course not so much a ""conversion"" as a straight up extraction, by just filtering out the non-ASCII bytes. It's useful quite often, though.</p>

<p>In general, without more knowledge of the file's internal format, I don't think you can do much better.</p>
","2236694"
"C, fread binary from bin file","22386","","<p>I'm pretty new to C, but I have come across a problem with fread...</p>

<p>My end goal is to read (and then printf to console) the binary from a .bin file, but for now i'm taking it one step at a time and trying to just read the first bit...</p>

<p>My code:</p>

<pre><code>...
FILE *file = fopen(""test1.bin"", rb);
int i = 0;
fread(&amp;i, 1, 1, file);
printf(""%i\n"", i);
...
</code></pre>

<p>Now i've tried this on three different .bin files, one outputted 0, other 2 and the other 12!</p>

<p>Why is it outputting 2/12 when I am reading in just one 1 bit from file? Shouldn't it be a 0 or a 1? what am I doing wrong? Thanks alot.</p>
","<p>Change the <a href=""http://www.cplusplus.com/reference/clibrary/cstdio/fread/"" rel=""noreferrer""><code>fread()</code></a> call to:</p>

<pre><code>fread(&amp;i, sizeof(int), 1, file);
</code></pre>

<p>The second argument is the size of an element to read, the third argument is the number of elements to read. The posted code is reading a single byte into an <code>int</code>.</p>

<p>You should also check the return values from <code>fopen()</code> and <code>fread()</code> calls to ensure they were successful.</p>
","10841985"
"Opening Binary Files in Fortran: Status, Form, Access","22375","","<p>I have been working with Fortran for years, but the file I/O is still hazy to me. My understanding of <code>status</code>, <code>form</code>, <code>access</code>, <code>recl</code> is limited, because I only <i>needed</i> certain use-cases in grad school.<br>
I know that Fortran binary files have extra information at the top of the file that describe the size of the file. But that has never been an issue for me before because I have only had to deal with Fortran files in Fortran code, where the extra information is necessary, but invisible.</p>

<p><b>But how do I open a flat, binary file in Fortran?</b></p>

<p>In the past, I might open a Fortran binary using Fortran by doing something like this:</p>

<pre><code>open(id,file=file_name,status='old',
     +     form='unformatted',access='direct',recl=4,iostat=ok)
      if (ok .ne. 0) then
        write(1,20) id,ok,file_name
                else
        write(1,21) id,file_name
</code></pre>

<p>But how does this change for a flat, binary file that doesn't have the Fortran header information?  More importantly, where is a good link to describe these terms in greater detail: <code>status</code>, <code>form</code>, <code>access</code>, <code>recl</code>?</p>
","<p>I hate to do this, but I feel that if I were hoping to find answers in this post, the way forward would not be clear. So here is the way forward.</p>

<p><b>The Short Version</b></p>

<p>In Fortran 77/90, to open a standard Fortran binary file you might write:</p>

<pre><code>OPEN (5, FILE=""myFile.txt"")
</code></pre>

<p>But to open a flat, non-Fortran binary file you would have to write something more like this:</p>

<pre><code>OPEN(5, file=""myFile.txt"", form='unformatted', access='direct', recl=1)
</code></pre>

<p>This difference is because Fortran-styled binary files have a 4-byte header and footer around each ""record"" in the file. These headers/footers describe the size of the data contained in the record. (In the most common case, each binary file you encounter will only have one record.)</p>

<p><b>The Long Version</b></p>

<p>Fortran assumes a lot of default <code>open</code> arguments. In fact, our original example can be written in the following verbose form to show all the defaults that were assumed.</p>

<pre><code>OPEN (5, FILE=""myFile.txt"") 
OPEN (5, FILE=""myFile.txt"", FORM=""FORMATTED"", 
     +   ACCESS=""SEQUENTIAL"", STATUS=""UNKNOWN"")
</code></pre>

<p>Let us look at each argument:</p>

<ul>
<li><p><strong>FORM</strong> defines if a file consists of text (<code>form='formatted'</code>) or binary data (<code>form='unformatted'</code>).</p></li>
<li><p><strong>ACCESS</strong> defines if you are reading data from the file in order (<code>access='sequential'</code>) or in any order you want (<code>access='direct'</code>).</p></li>
<li><p><strong>RECL</strong> defines the number of bytes that goes into each record. For instance, <code>recl=1</code> just says that the record lengths are 1 byte each; perhaps they are 1-byte integers.</p></li>
<li><p><strong>STATUS</strong> defines if the file already exists. The <code>STATUS=""UNKNOWN""</code> argument means that the file might not exist yet, but if it doesn't it will be created.  If you want to protect against the possibility of writing over an old file use: <code>STATUS=""OLD""</code>. Similarly, if you know the file doesn't exist yet, you will want to use: <code>STATUS=""NEW""</code>.</p></li>
</ul>

<p><strong>For More Information:</strong></p>

<p>These open statements also have an impact on the read/write/close statements that will follow. In my original post, I needed to know that if you open a direct access file you have to write to a direct access file. (That is, there will be no Fortran headers/footers included in your binary.) However, Fortran’s default functionality is to create sequential access files with Fortran headers and footers included.</p>

<p>For more information on <code>open</code> statements in Fortran 77/90, there are a good resources online:</p>

<p><a href=""http://cs.ubishops.ca/ljensen/fortran/fortran.htm"" rel=""noreferrer"">A nice page</a> by Lin Jinsen of Bishop University (thank you so much).</p>

<p><a href=""http://publib.boulder.ibm.com/infocenter/comphelp/v8v101/index.jsp?topic=%2Fcom.ibm.xlf101a.doc%2Fxlflr%2Fopen.htm"" rel=""noreferrer"">Slightly more official documentation</a> by IBM for it's compilers.</p>
","10018031"
"Getting binary content in node.js with http.request","22166","","<p>I would like to retrieve binary data from an https request.</p>

<p>I found a <strong>similar question</strong> that uses the request method, 
<a href=""https://stackoverflow.com/questions/14855015/getting-binary-content-in-node-js-using-request"">Getting binary content in Node.js using request</a>, is says setting <strong>encoding</strong> to <strong>null</strong> should work, but it doesn't.</p>

<pre><code>options = {
hostname: urloptions.hostname,
path: urloptions.path,
method: 'GET',
rejectUnauthorized: false,
encoding: null
};

req = https.request(options, function(res) {
var data;
data = """";
res.on('data', function(chunk) {
    return data += chunk;
});
res.on('end', function() {
    return loadFile(data);
});
res.on('error', function(err) {
    console.log(""Error during HTTP request"");
    console.log(err.message);
});
})
</code></pre>

<p>Edit: setting encoding to <strong>'binary'</strong> doesn't work either</p>
","<p>The accepted answer did not work for me (i.e., setting encoding to binary), even the user who asked the question mentioned it did not work.</p>

<p>Here's what worked for me, taken from: <a href=""http://chad.pantherdev.com/node-js-binary-http-streams/"">http://chad.pantherdev.com/node-js-binary-http-streams/</a></p>

<pre><code>http.get(url.parse('http://myserver.com:9999/package'), function(res) {
    var data = [];

    res.on('data', function(chunk) {
        data.push(chunk);
    }).on('end', function() {
        //at this point data is an array of Buffers
        //so Buffer.concat() can make us a new Buffer
        //of all of them together
        var buffer = Buffer.concat(data);
        console.log(buffer.toString('base64'));
    });
});
</code></pre>

<p><strong>Edit:</strong> Update answer following a suggestion by Semicolon</p>
","21024737"
"How to convert binary floating point number to decimal number","22129","","<p>I have used that site: <a href=""http://sandbox.mc.edu/~bennet/cs110/flt/dtof.html"" rel=""nofollow"">http://sandbox.mc.edu/~bennet/cs110/flt/dtof.html</a> they say that <code>2.625</code> is <code>0_100_0101</code> based on that the exponent is <code>4</code> and mantisa is <code>5/16</code>. So the number is <code>(5/16) * 2^4</code> and this is definetly not <code>2.625</code>.</p>

<p>So how it should be.</p>
","<p>The most significant '1' is not encoded. So you need to add that on when converting.</p>

<p>In this case, the digits are '0101', so adding a '1' would give '1.0101'. Then the exponent is 4, but needs to be offset by 3, so the actual multiplier is just 2^1.</p>

<p>That gives a result of '10.101' which is indeed 2.625</p>
","15321836"
"Algorithm to find the most significant bit","22069","","<p>Hi and thanks for taking the time to answer my question.</p>

<p>A friend of mine was asked at an interview the following question: ""Given a binary number, find the most significant bit"". I immediately thought of the following solution but am not sure if it is correct.</p>

<p>Namely, divide the string into two parts and convert both parts into decimal. If the left-subarray is 0 in decimal then the do binary search in the right subarray, looking for 1.</p>

<p>That is my other question. Is the most significant bit, the left-most 1 in a binary number? Can you show me an example when a 0 is the most significant bit with an example and explanation.</p>

<h2>EDIT:</h2>

<p>There seems to be a bit of confusion in the answers below so I am updating the question to make it more precise. The interviewer said ""you have a website that you receive data from until the most significant bit indicates to stop transmitting data"" How would you go about telling the program to stop the data transfer""</p>
","<p>You could also use bit shifting. Pseudo-code:</p>

<pre><code>number = gets
bitpos = 0
while number != 0
  bitpos++             # increment the bit position
  number = number &gt;&gt; 1 # shift the whole thing to the right once
end
puts bitpos
</code></pre>

<p>if the number is zero, bitpos is zero.</p>
","17028008"
"Calculating the total number of possibilities in binary?","21873","","<p>How would you calculate the total number of possibilities that binary can have in one byte?</p>

<p><code>00000000</code> through <code>11111111</code> = <code>num_of_possibilities</code></p>
","<p>The total number is 2 to the power of the number of bits.  So, eight bits has 2<sup>8</sup> possible values.</p>

<p>If you really mean ""how to compute it"", consider that each bit has two possible values.</p>

<p>So one bit implies 2 values.</p>

<p>Two bits has one set of two values of each possible value of the other bit, so</p>

<pre><code>00
01
10
11
</code></pre>

<p>which means a total of 4 (= 2&times;2) values.</p>

<p>Three bits gives four values <em>twice</em>, or 8 (=4&times;2) values.  Four bits, 8&times;2; five bits, 16&times;2, and so on.</p>

<p>So eight bits is 2&times;2&times;2&times;2&times;2&times;2&times;2&times;2 or 256.</p>
","5072726"
"Reading and writing binary file in Java (seeing half of the file being corrupted)","21720","","<p>I have some working code in python that I need to convert to Java.</p>

<p>I have read quite a few threads on this forum but could not find an answer. I am reading in a JPG image and converting it into a byte array. I then write this buffer it to a different file. When I compare the written files from both Java and python code, the bytes at the end do not match. Please let me know if you have a suggestion. I need to use the byte array to pack the image into a message that needs to be sent over to a remote server.</p>

<p>Java code (Running on Android)</p>

<h2>Reading the file:</h2>

<pre><code>File queryImg = new File(ImagePath);
int imageLen = (int)queryImg.length();
byte [] imgData = new byte[imageLen];
FileInputStream fis = new FileInputStream(queryImg);
fis.read(imgData);
</code></pre>

<h2>Writing the file:</h2>

<pre><code>FileOutputStream f = new FileOutputStream(new File(""/sdcard/output.raw""));
f.write(imgData);
f.flush();
f.close();
</code></pre>

<p>Thanks!</p>
","<p><code>InputStream.read</code> is not guaranteed to read any particular number of bytes and may read less than you asked it to. It returns the actual number read so you can have a loop that keeps track of progress:</p>

<pre><code>public void pump(InputStream in, OutputStream out, int size) {
    byte[] buffer = new byte[4096]; // Or whatever constant you feel like using
    int done = 0;
    while (done &lt; size) {
        int read = in.read(buffer);
        if (read == -1) {
            throw new IOException(""Something went horribly wrong"");
        }
        out.write(buffer, 0, read);
        done += read;
    }
    // Maybe put cleanup code in here if you like, e.g. in.close, out.flush, out.close
}
</code></pre>

<p>I believe Apache Commons IO has classes for doing this kind of stuff so you don't need to write it yourself.</p>
","4663422"
"Reading a binary file bit by bit","21685","","<p>I know the function below:</p>

<pre><code>size_t fread(void *ptr, size_t size_of_elements, size_t number_of_elements, FILE *a_file);
</code></pre>

<p>It only reads byte by byte, my goal is to be able to read 12 bits at a time and then take them into an array. Any help or pointers would be greatly appreciated!</p>
","<p>Adding to the first comment, you can try reading one byte at a time (declare a char variable and write there), and then use the bitwise operators >> and &lt;&lt; to read bit by bit. Read more here: <a href=""http://www.cprogramming.com/tutorial/bitwise_operators.html"">http://www.cprogramming.com/tutorial/bitwise_operators.html</a></p>
","11680278"
"Java two's complement binary to integer","21619","","<p>I know that converting a decimal to binary with <code>Integer.toBinaryString(355)  = 0000000101100011</code> and 
                                           <code>Integer.toBinaryString(-355) = 1111111010011101</code> (where I take the lower 16 bits of the 32 bit result).</p>

<p>What I would like to do is the other way and take a 16-bit twos's complement binary string and to convert to decimal.</p>

<p>i.e.</p>

<pre><code>0000000000110010 =  50
1111111111001110 = -50
</code></pre>

<p>Rather than <code>1111111111001110 = 65486</code></p>

<p>How would I do this?</p>
","<p>You need to read the result into <code>short</code>.</p>

<pre><code>short res = (short)Integer.parseInt(""1111111111001110"", 2);
System.out.println(res);
</code></pre>

<p>This <a href=""http://ideone.com/RQJ92F"" rel=""nofollow"">prints <code>-50</code></a>.</p>
","15837952"
"Insert hex values into MySql","21503","","<p>I have a table with a VARBINARY column.  I need to insert a string such as '4D2AFF' which represents the hex values 0x4D, 0x2A and 0xFF respectively.  How do I construct this statement?</p>
","<p>You can use <a href=""http://dev.mysql.com/doc/refman/5.0/en/string-functions.html#function_unhex"" rel=""noreferrer""><code>UNHEX()</code></a> function to convert a hexstring with hex pairs to binary and <a href=""http://dev.mysql.com/doc/refman/5.0/en/string-functions.html#function_hex"" rel=""noreferrer""><code>HEX()</code></a> to do the other way round.</p>

<p>I.e.</p>

<pre><code>INSERT INTO tbl (col) VALUES (UNHEX('4D2AFF'))
</code></pre>

<p>and</p>

<pre><code>SELECT HEX(col) FROM tbl
</code></pre>
","3126225"
"How can I convert a REG_BINARY value from the registry into a string ? (vb.net)","21477","","<p>I have a registry value which is stored as a binary value (REG_BINARY) holding information about a filepath. The value is read out into an byte array. But how can I transform it into a readable string?</p>

<p>I have read about system.text.encoding.ASCII.GetString(value) but this does not work. As far as I got to know the registry value is arbitrary binary data and not ASCII which is the reason for the method to produce useless data.</p>

<p>Does anybody know how I can convert the data? </p>

<p>Sample:
(A piece of the entry)</p>

<pre><code>01 00 00 00 94 00 00 00 14 00 00 00 63 00 3A 00 5C 00 
70 00 72 00 6F 00 67 00 72 00 61 00 6D 00 6d 00 65 00 
5C 00 67 00 65 00 6D 00 65 00 69 00 6E 00 73 00 61 00 
6D 00 65 00 20 00 64 00 61 00 74 00 65 00 69 00 65 00 
6E 00 5C
</code></pre>

<p>Due to the regedit this is supposed to be:</p>

<pre><code>............c.:.\.p.r.o.g.r.a.m.m.e.\.g.e.m.e.i.n.s.a.m.e. .d.a.t.e.i.e.n.\
</code></pre>

<p>The entry itself was created from Outlook. It's an entry for an disabled addin item (resiliency)</p>
","<p>Well, it's not <em>arbitrary</em> binary data - it's text data in <em>some</em> kind of encoding. You need to find out what the encoding is.</p>

<p>I wouldn't be surprised if <code>Encoding.Unicode.GetString(value)</code> worked - but if that doesn't, please post a sample (in hex) and I'll see what I can do. What does the documentation of whatever's put the data in there say?</p>

<p>EDIT: It looks like Encoding.Unicode is your friend, but starting from byte 12. Use</p>

<pre><code>Encoding.Unicode.GetString(bytes, 12, bytes.Length-12)
</code></pre>
","349428"
"How does ASN.1 encode an object identifier?","21418","","<p>I am having trouble understanding the basic concepts of ASN.1.</p>

<p>If a type is an OID, does the corresponding number get actually encoded in the binary data?</p>

<p>For instance in this definition:</p>

<pre><code>id-ad-ocsp         OBJECT IDENTIFIER ::= { id-ad 1 }
</code></pre>

<p>Does the corresponding 1.3.6.1.5.5.7.48.1 get encoded in the binary exactly like this?</p>

<p>I am asking this because I am trying to understand a specific value I see in a DER file (a certificate), which is 04020500, and I am not sure how to interpret it.</p>
","<p>Yes, the OID is encoded in the binary data. The OID 1.3.6.1.5.5.7.48.1 you mention becomes 2b 06 01 05 05 07 30 01 (the first two numbers are encoded in a single byte, all remaining numbers are encoded in a single bytes as well because they're all smaller than 128).</p>

<p>A nice description of OID encoding is found <a href=""http://msdn.microsoft.com/en-us/library/bb540809%28v=vs.85%29.aspx"" rel=""noreferrer"">here</a>.</p>

<p>But the best way to analyze your ASN.1 data is to paste in into an online decoder, e.g. <a href=""http://lapo.it/asn1js/"" rel=""noreferrer"">http://lapo.it/asn1js/</a>.</p>
","5929189"
"Insert binary file in SQLite database with Python","21333","","<p>I trying to write a simple Python script that inserts .odt documents into an SQLite database. Here what I have so far, but it doesn't seem to work:</p>

<pre><code>f=open('Loremipsum.odt', 'rb')
k=f.read()
f.close()
cursor.execute=""INSERT INTO notes (note) VALUES ('%s')"" %(sqlite.Binary(k))
cursor.close()
conn.close()
</code></pre>

<p>I don't get any error messages, but as far as I can see the record is not inserted. What am I doing wrong? Also, how can I extract the stored document back? Thanks!</p>
","<p>Not sure what is that <code>sqlite.Binary</code> you're using, but, anyway, here's a working example:</p>

<pre><code>import sqlite3

# let's just make an arbitrary binary file...
with open('/tmp/abin', 'wb') as f:
  f.write(''.join(chr(i) for i in range(55)))
# ...and read it back into a blob
with open('/tmp/abin', 'rb') as f:
  ablob = f.read()

# OK, now for the DB part: we make it...:
db = sqlite3.connect('/tmp/thedb')
db.execute('CREATE TABLE t (thebin BLOB)')
db.execute('INSERT INTO t VALUES(?)', [buffer(ablob)])
db.commit()
db.close()

# ...and read it back:
db = sqlite3.connect('/tmp/thedb')
row = db.execute('SELECT * FROM t').fetchone()
print repr(str(row[0]))
</code></pre>

<p>When run with Python 2.6, this code shows, as expected and desired:
    '\x00\x01\x02\x03\x04\x05\x06\x07\x08\t\n\x0b\x0c\r\x0e\x0f\x10\x11\x12\x13\x14\x15\x16\x17\x18\x19\x1a\x1b\x1c\x1d\x1e\x1f !""#$%&amp;\'()*+,-./0123456'</p>

<p>Note the need to use <code>buffer</code> to insert the blob, and <code>str</code> to read it back as a string (since it uses the <code>buffer</code> type as a result as well) -- if you're just going to write it to disk the latter passage would not be needed (since the <code>write</code> method of files does accept buffer objects just as well as it accepts strings).</p>
","3311116"
"Hex to Binary conversion in bash","21282","","<p>I'm trying to convert a series of bytes from hex to bin using bash.
but I keep getting (seemingly random) ""(standard_in) 1: syntax error"" replies from the following code:</p>

<pre><code>for j in c4 97 91 8c 85 87 c4 90 8c 8d 9a 83 81
do
        BIN=$(echo ""obase=2; ibase=16; $j"" | bc )
        echo $BIN
done
</code></pre>

<p>I did a similar thing with dec to bin, which works perfectly fine:</p>

<pre><code>for i in {0..120}
do
        KEYBIN=$(echo ""obase=2; ibase=10; $i"" | bc)
        echo $KEYBIN
done
</code></pre>

<p>Does anyone have an idea why it works with decimal, but not with hex?
In my opinion the syntax is pretty much the same (unless I'm missing something really hard.)</p>
","<p>BC is a bit sensitive to case for hex values, change to uppercase and it should work</p>

<pre><code>for j in C4 97 91 8C 85 87 C4 90 8C 8D 9A 83 81
do
        BIN=$(echo ""obase=2; ibase=16; $j"" | bc )
        echo $BIN
done
</code></pre>

<p>Output:</p>

<pre><code>11000100
10010111
10010001
10001100
10000101
10000111
11000100
10010000
10001100
10001101
10011010
10000011
10000001
</code></pre>
","11120688"
"C++ Binary to decimal?","21080","","<p>I made a function that converts binary numbers to decimals, but if i go to high on the binary numbers, it just returns 256??? What could cause this? I'm using int variables. Any help would be really appreciated</p>

<pre><code>    #include &lt;iostream&gt;

using namespace std;

int FromBin (int n)
{
    int increment;
    int Result;
    increment = 1;
    Result = 0;
    while(n != 0)
    {
        if (n % 10 == 1){
            Result = Result+increment;
            n = n-1;
        }
        n = n/10;
        increment = increment*2;
    }
    cout&lt;&lt;Result;
}

void ToBin(int n)
{
    if (n / 2 != 0) {
        ToBin(n / 2);
    }
    cout&lt;&lt;n % 2;
}

int main()
{
    int choice;
    int n;
    cout&lt;&lt;""Choose a function: press 0 for decimals to binary, press 1 for binary to decimal\n"";
    cin&gt;&gt;choice;
    if (choice == 0){
        cout&lt;&lt;""Enter a number: \n"";
        cin&gt;&gt;n;
        ToBin(n);
    }
    else if (choice == 1){
        cout&lt;&lt;""Enter a number: \n"";
        cin&gt;&gt;n;
        FromBin(n);
    }
    else{
        cout&lt;&lt;""Invalid input"";
    }
}
</code></pre>

<p>I'm new to C++ so I don't understand this... :/</p>
","<p>This is a cool program you got going on here...
This is what I found for a possible solution to your problem...</p>

<pre><code> /* C++ program to convert binary number into decimal */
 #include &lt;iostream&gt;
     using namespace std;
 int main()
 {
     long bin, dec = 0, rem, num, base = 1;
     cout &lt;&lt; ""Enter the binary number(1s and 0s) : "";
     cin &gt;&gt; num;
     bin = num;
     while (num &gt; 0)
     {
         rem = num % 10;
         dec = dec + rem * base;
         base = base * 2;
         num = num / 10;
     }
     cout &lt;&lt; ""The decimal equivalent of "" &lt;&lt; bin &lt;&lt; "" : "" &lt;&lt; dec &lt;&lt; endl;
     return 0;
 }
</code></pre>
","27049553"
"Bytes to Binary in C","20905","","<p>I'm trying to simply convert a byte received from fget into binary.</p>

<p>I know the value of the first byte was 49 based on printing the value. I now need to convert this into its binary value.</p>

<pre><code>unsigned char byte = 49;// Read from file
unsigned char mask = 1; // Bit mask
unsigned char bits[8];

  // Extract the bits
for (int i = 0; i &lt; 8; i++) {
    // Mask each bit in the byte and store it
    bits[i] = byte &amp; (mask &lt;&lt; i);
}
 // For debug purposes, lets print the received data
for (int i = 0; i &lt; 8; i++) {
printf(""Bit: %d\n"",bits[i]);
}
</code></pre>

<p>This will print:</p>

<pre><code>Bit: 1
Bit: 0
Bit: 0
Bit: 0
Bit: 16
Bit: 32
Bit: 0
Bit: 0
Press any key to continue . . .
</code></pre>

<p>Clearly, this is not a binary value. Any help?</p>
","<p>The problem you're having is that your assignment isn't resulting in a true or false value.</p>

<pre><code>bits[i] = byte &amp; (mask &lt;&lt; i);
</code></pre>

<p>This gets the value of the bit.  You need to see if the bit is on or off, like this:</p>

<pre><code>bits[i] = (byte &amp; (mask &lt;&lt; i)) != 0;
</code></pre>
","1683018"
"open a jpeg image from binary format","20845","","<p>I have a binary file that I want to open as (or to convert to) jpeg image.
The file is only supposed by me to be a jpeg within a binary format, therefore I include a part of it so that You can tell me if I'm wrong ('cause unfortunately I never saw one of those before):</p>

<pre><code>0000000000 0E 03 13 01 00 10 00 00 EC B0 00 1E 00 01 00 00 [................]
0000000016 00 CA 00 00 00 5C 00 0F 00 01 00 00 01 26 00 00 [.....\.......&amp;..]
0000000032 00 00 01 2F 00 01 00 00 01 26 00 00 83 B2 00 6A [.../.....&amp;.....j]
0000000048 00 01 00 00 84 D8 00 00 00 04 01 2C 00 01 00 00 [...........,....]
0000000064 84 DC 00 00 00 14 01 32 00 01 00 00 84 F0 00 00 [.......2........]
0000000080 00 08 07 AD 00 02 00 00 84 F8 00 00 00 19 00 0F [................]
0000000096 00 02 00 00 85 11 00 00 00 00 01 2F 00 02 00 00 [.........../....]
0000000112 85 11 00 00 0D D3 01 2C 00 02 00 00 92 E4 00 00 [.......,........]
0000000128 00 14 01 32 00 02 00 00 92 F8 00 00 00 08 07 AD [...2............]
0000000144 00 03 00 00 93 00 00 00 00 19 00 0F 00 03 00 00 [................]
0000000160 93 19 00 00 00 00 01 2F 00 03 00 00 93 19 00 00 [......./........]
0000000176 59 7B 01 2C 00 03 00 00 EC 94 00 00 00 14 01 32 [Y{.,...........2]
0000000192 00 03 00 00 EC A8 00 00 00 08 00 00 00 04 00 00 [................]
0000000208 00 02 00 00 00 00 4E 43 53 41 20 48 44 46 20 56 [......NCSA HDF V]
0000000224 65 72 73 69 6F 6E 20 34 2E 32 20 52 65 6C 65 61 [ersion 4.2 Relea]
0000000240 73 65 20 30 2C 20 44 65 63 65 6D 62 65 72 20 32 [se 0, December 2]
0000000256 2C 20 32 30 30 33 00 00 00 00 00 00 00 00 00 00 [, 2003..........]
0000000272 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 [................]
0000000288 00 00 00 00 00 00 FF D8 FF E0 00 10 4A 46 49 46 [............JFIF]
0000000304 00 01 01 00 00 01 00 01 00 00 FF DB 00 43 00 10 [.............C..]
0000000320 0B 0C 0E 0C 0A 10 0E 0D 0E 12 11 10 13 18 28 1A [..............(.]
0000000336 18 16 16 18 31 23 25 1D 28 3A 33 3D 3C 39 33 38 [....1#%.(:3=&lt;938]
0000000352 37 40 48 5C 4E 40 44 57 45 37 38 50 6D 51 57 5F [7@H\N@DWE78PmQW_]
0000000368 62 67 68 67 3E 4D 71 79 70 64 78 5C 65 67 63 FF [bghg&gt;Mqypdx\egc.]
0000000384 DB 00 43 01 11 12 12 18 15 18 2F 1A 1A 2F 63 42 [..C......./../cB]
0000000400 38 42 63 63 63 63 63 63 63 63 63 63 63 63 63 63 [8Bcccccccccccccc]
0000000416 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 [cccccccccccccccc]
0000000432 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 [cccccccccccccccc]
0000000448 63 63 63 63 FF C0 00 11 08 01 A0 01 C0 03 01 22 [cccc...........""]
0000000464 00 02 11 01 03 11 01 FF C4 00 1F 00 00 01 05 01 [................]
0000000480 01 01 01 01 01 00 00 00 00 00 00 00 00 01 02 03 [................]
0000000496 04 05 06 07 08 09 0A 0B FF C4 00 B5 10 00 02 01 [................]
</code></pre>

<p>How can I convert it to jpeg to view its content (that is supposed to be an image)?
Is this conversion necessary or would You reccomend a software that can open it as I like?
I hope someone could help me, thanks in advance.</p>

<p><strong>ANSWER</strong></p>

<p>(As I can't answer my own question right now, I'm doing it here...)</p>

<p>At the end I came up with a solution thanks to the input information of unwind.
I downloaded HEX editor (<a href=""http://www.hhdsoftware.com/free-hex-editor"" rel=""nofollow"">http://www.hhdsoftware.com/free-hex-editor</a>) to edit my binary file. Then I searched for the string where the 0xff 0xd8 was (in may case in line 0000000288). This is supposed to be the beginning of a JPEG file. Then I deleted everything that came before of that (also the six pair of zeros within the same line). Then I saved m edits and tried again to open it with an image processing program (in my case, I'm usin ENVI), and....IT WORKS! Now the binary file is red as an image file!
The problem now is that I have plenty of those files (302), and I need to edit all of them. Moreover, they each contain more than one jpeg, so I need to modify each one ore times. Guess I need to improve my programming knowledge...</p>
","<p>Well, according to <a href=""http://en.wikipedia.org/wiki/Magic_number_%28programming%29#Magic_numbers_in_files"" rel=""nofollow"">this page</a> JPEG files begin with the byte pair <code>0xff 0xd8</code>, so you could search forwards for that sequence, and throw away the data before it.</p>

<p>In your file, it happens on the line starting <code>0000000288</code>.</p>
","15160588"
"Decimal to Binary on C library","20673","","<p>I want to know if there is a function in C library that convert a decimal to binary number and save number by number in a position on an array. 
For example: 2 -> 10 -> array [0] = 0 array[1] = 1.
Thanks.</p>
","<p>here:</p>

<pre><code>void dec2bin(int c)
{
   int i = 0;
   for(i = 31; i &gt;= 0; i--){
     if((c &amp; (1 &lt;&lt; i)) != 0){
       printf(""1"");
     }else{
       printf(""0"");
     } 
   }
}
</code></pre>

<p>But this only prints the value of an integer in binary format. All data is represented in binary format internally anyway. </p>
","13099270"
"How to convert char to it's ascii binary code","20657","","<p>All I want is to go from 'a' to 0110 0001 </p>
","<p>if you write <code>int i = 'a';</code> you get you want since all numbers physically are base 2. But if it's needed to get a string with ones and zeros then here is an example</p>

<pre><code>/* itoa example */
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main ()
{
  int i = 'a';
  char buffer [33];
  itoa(i,buffer,2);
  printf (""binary: %s\n"",buffer);
  return 0;
}
</code></pre>
","5753289"
"Reading Binary File into a Structure (C++)","20643","","<p>So I'm having a bit of an issue of not being able to properly read a binary file into my structure.  The structure is this:</p>

<pre><code>struct Student
{
    char name[25];
    int quiz1;
    int quiz2;
    int quiz3;
};
</code></pre>

<p>It is 37 bytes (25 bytes from char array, and 4 bytes per integer).  My .dat file is 185 bytes.  It's 5 students with 3 integer grades.  So each student takes up 37 bytes (37*5=185).</p>

<p>It looks something like this in plain text format:</p>

<pre><code>Bart Simpson          75   65   70
Ralph Wiggum          35   60   44
Lisa Simpson          100  98   91
Martin Prince         99   98   99
Milhouse Van Houten   80   87   79
</code></pre>

<p>I'm able to read each of the records individually by using this code:</p>

<pre><code>Student stud;

fstream file;
file.open(""quizzes.dat"", ios::in | ios::out | ios::binary);

if (file.fail())
{
    cout &lt;&lt; ""ERROR: Cannot open the file..."" &lt;&lt; endl;
    exit(0);
}

file.read(stud.name, sizeof(stud.name));
file.read(reinterpret_cast&lt;char *&gt;(&amp;stud.quiz1), sizeof(stud.quiz1));
file.read(reinterpret_cast&lt;char *&gt;(&amp;stud.quiz2), sizeof(stud.quiz2));
file.read(reinterpret_cast&lt;char *&gt;(&amp;stud.quiz3), sizeof(stud.quiz3));

while(!file.eof())
{
    cout &lt;&lt; left 
         &lt;&lt; setw(25) &lt;&lt; stud.name
         &lt;&lt; setw(5)  &lt;&lt; stud.quiz1
         &lt;&lt; setw(5)  &lt;&lt; stud.quiz2
         &lt;&lt; setw(5)  &lt;&lt; stud.quiz3
         &lt;&lt; endl;

    // Reading the next record
    file.read(stud.name, sizeof(stud.name));
    file.read(reinterpret_cast&lt;char *&gt;(&amp;stud.quiz1), sizeof(stud.quiz1));
    file.read(reinterpret_cast&lt;char *&gt;(&amp;stud.quiz2), sizeof(stud.quiz2));
    file.read(reinterpret_cast&lt;char *&gt;(&amp;stud.quiz3), sizeof(stud.quiz3));
}
</code></pre>

<p>And I get a nice looking output, but I want to be able to read in one whole structure at a time, not just individual members of each structure at a time.  This code is what I believe needed to accomplish the task, but... it doesn't work (I'll show output after it):</p>

<p>*not including the similar parts as far as opening of the file and structure declaration, etc.</p>

<pre><code>file.read(reinterpret_cast&lt;char *&gt;(&amp;stud), sizeof(stud));

while(!file.eof())
{
    cout &lt;&lt; left 
         &lt;&lt; setw(25) &lt;&lt; stud.name
         &lt;&lt; setw(5)  &lt;&lt; stud.quiz1
         &lt;&lt; setw(5)  &lt;&lt; stud.quiz2
         &lt;&lt; setw(5)  &lt;&lt; stud.quiz3
         &lt;&lt; endl;

    file.read(reinterpret_cast&lt;char *&gt;(&amp;stud), sizeof(stud));
}
</code></pre>

<p>OUTPUT:</p>

<pre><code>Bart Simpson             16640179201818317312
ph Wiggum                288358417665884161394631027
impson                   129184563217692391371917853806
ince                     175193530917020655191851872800
</code></pre>

<p>The only part it doesn't mess up is the first name, after that it's down the hill.. I've tried everything and I've no idea what is wrong.  I've even searched through the books I have and I couldn't find anything.  Things in there look like what I have and they work, but for some odd reason mine doesn't.  I did the file.get(ch) (ch being a char) at byte 25 and it returned K, which is ASCII for 75.. which is the 1st test score, so, everything's where it should be.  It's just not reading in my structures properly.</p>

<p>Any help would be greatly appreciated, I'm just stuck with this one.</p>

<p><strong>EDIT:</strong>  After receiving such a large amount of unexpected and awesome input from you guys, I've decided to take your advice and stick with reading in one member at a time.  I made things cleaner and smaller by using functions.  <strong>Thank you once again for providing such quick and enlightening input.  It's much appreciated.</strong></p>

<p><strong>IF you're interested</strong> in a workaround that's not recommended by most, scroll towards the bottom, to the 3rd answer by user1654209.  That workaround works flawlessly, but read all the comments to see why it's not favored.</p>
","<p>Your struct has almost certainly been padded to preserve the alignment of its content. This means that it will not be 37 bytes, and that mismatch causes the reading to go out of sync. Looking at the way each string is losing 3 characters, it seems that it has been padded to 40 bytes.</p>

<p>As the padding is likely to be between the string and the integers, not even the first record reads correctly.</p>

<p>In this case I would recommend not attempting to read your data as a binary blob, and stick to reading individual fields. It's far more robust, especially if you even want to alter your structure.</p>
","15542699"
"Algorithm for binary arithmetic in Java","20545","","<p>On paper, binary arithmetic is simple, but as a beginning programmer, I'm finding it a little difficult to come up with algorithms for the addition, subtraction, multiplication and division of binary numbers.</p>

<p>I have two binary numbers stored as strings, assume that any leading zeroes have been dropped. How would I go about performing these operations on the two numbers?</p>

<p>Edit: I need to avoid converting them to an int or long.</p>
","<p>The following code implements binary addition without actually doing any arithmetic, binary or otherwise. The actual ""addition"" is done by <code>lookupTable</code>, and everything else is straight-up string manipulation. I wrote it with the intention of making it as instructive as possible, emphasizing the process instead of efficiency. Hope it helps.</p>

<pre><code>public class BinaryArithmetic {
    static String[] lookupTable = {
        ""0+0+0=00"",
        ""0+0+1=01"",
        ""0+1+0=01"", 
        ""0+1+1=10"",
        ""1+0+0=01"",
        ""1+0+1=10"",
        ""1+1+0=10"",
        ""1+1+1=11"",
    };
    static String lookup(char b1, char b2, char c) {
        String formula = String.format(""%c+%c+%c="", b1, b2, c);
        for (String s : lookupTable) {
            if (s.startsWith(formula)) {
                return s.substring(s.indexOf(""="") + 1);
            }
        }
        throw new IllegalArgumentException();
    }
    static String zeroPad(String s, int length) {
        while (s.length() &lt; length) {
            s = ""0"" + s;
        }
        return s;
    }   
    static String add(String s1, String s2) {
        int length = Math.max(s1.length(), s2.length());
        s1 = zeroPad(s1, length);
        s2 = zeroPad(s2, length);
        String result = """";
        char carry = '0';
        for (int i = length - 1; i &gt;= 0; i--) {
            String columnResult = lookup(s1.charAt(i), s2.charAt(i), carry);
            result = columnResult.charAt(1) + result;
            carry = columnResult.charAt(0);
        }
        if (carry == '1') {
            result = carry + result;
        }
        return result;
    }
    public static void main(String args[]) {
        System.out.println(add(""11101"", ""1001""));
    }
}
</code></pre>

<hr>

<p>While we're at it, I might as well do <code>multiply</code> too.</p>

<pre><code>static String multiply(String s1, String s2) {
    String result = """";
    String zeroSuffix = """";
    for (int i = s2.length() - 1; i &gt;= 0; i--) {
        if (s2.charAt(i) == '1') {
            result = add(result, s1 + zeroSuffix);
        }
        zeroSuffix += ""0"";
    }
    return result;
}
</code></pre>
","2413080"
"What's the prefix for binary in PHP?","20511","","<p>It's neither <code>0x</code> nor <code>0</code>; what is it? Is there?</p>
","<p>As of PHP 5.4+ the prefix for binary number is:</p>

<pre><code>0b
</code></pre>

<p><hr/>
For ealier version, there is no such prefix. Instead, you can use <code>0x</code>, for hexadecimal.</p>

<p>For more informations, see the <strong><a href=""http://fr2.php.net/manual/en/language.types.integer.php"" rel=""noreferrer"">Integers section of the PHP manual</a></strong>.</p>

<p>Still, if you really need to write values using binary before PHP 5.4, you can use the <a href=""http://fr2.php.net/bindec"" rel=""noreferrer""><code>bindec</code></a> function, that takes a string containing the binary, and returns the corresponding value.</p>

<p>For example, the following portion of code :</p>

<pre><code>echo bindec('10011');
</code></pre>

<p>Will get you : </p>

<pre><code>19
</code></pre>

<p>But note you shouldn't do that too often : calling a function to do that each time the script is executed is quite bad for performances ^^
<br>Instead, it's really a better solution to write your values using hexadecimal, where each digit codes for 4 bits.</p>
","2507227"
"How to convert a grayscale image to binary in MATLAB","20481","","<p>I have to write a program that converts intensity images into black-and-white ones. I just figured I could take a value from the original matrix, I, and if it's above the mean value, make the corresponding cell in another array equal to 1, otherwise equal to zero:</p>

<pre><code>for x=1:X
    for y=1:Y
        if I(x,y)&gt;mean(I(:))
            bw(x,y)=1;
        elseif I(x,y)&lt;mean(I(:))
            bw(x,y)=0;
        end
    end
end
image(bw)
</code></pre>

<p>Unfortunately, the image I get is all black. Why?</p>

<p>I is in <code>uint8</code>, btw. 2-D Lena.tiff image</p>
","<p>Use <code>imagesc(bw)</code> (instead of <code>image(bw)</code>). That automatically scales the image range.</p>

<p>Also, note that you can replace all your code by this vectorized, more efficient version:</p>

<pre><code>bw = double(I&gt;mean(I(:)));
</code></pre>
","20569145"
"Howto convert decimal (xx.xx) to binary","20406","","<p>This isn't necessarily a programming question but i'm sure you folks know how to do it. How would i convert floating point numbers into binary.</p>

<p>The number i am looking at is 27.625.</p>

<p>27 would be 11011, but what do i do with the .625?</p>
","<p>Assuming you are not thinking about inside a PC, just thinking about binary vs decimal as physically represented on a piece of paper:</p>

<p>You know .1 in binary should be .5 in decimal, so the .1's place is worth .5 (1/2)</p>

<p>the .01 is worth .25 (1/4) (half of the previous one)</p>

<p>the .001 is worth (1/8) (Half of 1/4)</p>

<p>Notice how the denominator is progressing just like the whole numbers to the left of the decimal do--standard ^2 pattern?  The next should be 1/16...</p>

<p>So you start with your .625, is it higher than .5?  Yes, so set the first bit and subtract the .5</p>

<p>.1 binary with a decimal remainder of .125</p>

<p>Now you have the next spot, it's worth .25dec, is that less than your current remainder of .125?  No, so you don't have enough decimal ""Money"" to buy that second spot, it has to be a 0</p>

<p>.10 binary, still .125 remainder.</p>

<p>Now go to the third position, etc. (Hint: I don't think there will be too much etc.)</p>
","3781115"
"How to convert a decimal number to a binary number with fixed bits","20300","","<p>I want to convert numbers from 0 to 15 like this:</p>

<pre><code>0000
0001
0010
0011
.
.
.
1111
</code></pre>

<p>The problem is that when we convert 2 to a binary number it gives only 10 in binary, but I want to convert 2 to 4-bit binary number 0010.</p>
","<p>This code should do what you're looking for:</p>

<pre><code>For i As Integer = 0 To 15
    Console.WriteLine(Convert.ToString(i, 2).PadLeft(4, ""0""C))
Next
</code></pre>

<blockquote>
  <p>0000
  <br>0001
  <br>0010
  <br>0011
  <br>0100
  <br>0101
  <br>0110
  <br>0111
  <br>1000
  <br>1001
  <br>1010
  <br>1011
  <br>1100
  <br>1101
  <br>1110
  <br>1111</p>
</blockquote>

<p>The ""2"" in <code>Convert.ToString(i, 2)</code> means binary.  <code>PadLeft(4, ""0""C)</code> means that if the string isn't four characters, append zeros to the beginning until it is four characters.</p>
","4048478"
"Java File to Binary Conversion","20148","","<p>How can i convert File to Binary? I just need it for my project. I need to encrypt a file by its binaries.</p>
","<p>If you're referring to accessing the ACTUAL BINARY form then read in the file and convert every byte to a binary representation...</p>

<p>EDIT:</p>

<p>Here's some code to convert a byte into a string with the bits:</p>

<pre><code>String getBits(byte b)
{
    String result = """";
    for(int i = 0; i &lt; 8; i++)
        result += (b &amp; (1 &lt;&lt; i)) == 0 ? ""0"" : ""1"";
    return result;
}
</code></pre>

<p>If you're referring to accessing the bytes in the file then simply use the following code (you can use this for the first case as well):</p>

<pre><code>File file = new File(""filename.bin"");
byte[] fileData = new byte[file.length()];
FileInputStream in = new FileInputStream(file);
in.read(fileData):
in.close();
// now fileData contains the bytes of the file
</code></pre>

<p>To use these two pieces of code you can now loop over every byte and create a String object (8X larger than the original file size!!) with the bits:</p>

<pre><code>String content = """";
for(byte b : fileData)
    content += getBits(b);
// content now contains your bits.
</code></pre>
","7119189"
"Most binary combinations from 4 bits, with single change per bit","19890","","<p>I have 4 binary bits</p>

<pre><code>Bit 3  Bit 2  Bit 1  Bit 0
</code></pre>

<p>Normally the answer is simple: 2^4, or 16 different combinations; and it would looks something like the following:</p>

<p>0000 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 1100 1101 1110 1111</p>

<p>However, The LSB (Bit 0) changes state every iteration.</p>

<p>I need an algorithm where the state of a bit only changes once through all the iterations; i.e, I need all my bits to act like the MSB (Bit 3).</p>

<p>How can I do this?</p>

<h3>Edit</h3>

<p>It seems that most people are converging to there being only 5 possible solutions. However this assumes there is a starting point for the value and an ending point. This doesn't matter so I'm going to give a real world scenario to better explain.</p>

<p>Suppose I have an digital alarm clock that gives me 4 outputs. Each output can be programmed to go on at a certain time and off at a certain time and are programmed independent of each other, eg. I can program output 1 to go on at 1 am and off at 3 am, while I can program output 2 to go on at 7 pm and off at 2 am. There are no restrictions to how long each output can stay on. </p>

<p>Now I want to hook this alarm clock to a computer and get as close as possible to the current correct time. i.e If the clock says the time is 2:15 pm, my computer knows that the alarm is within the 12 pm to 6 pm range for example. I want to be able to get the smallest possible range. Whats the smallest possible range I can get?</p>
","<ol>
<li>There are 4 bits. </li>
<li>Each bit may change state only once.</li>
<li>For each new value, at least one of the bits must have changed state from the previous value.</li>
</ol>

<p>Therefore, you can have at most 4 state changes, and at most 5 different values.</p>

<p>Example:</p>

<pre><code>0000 -&gt; 0001 -&gt; 0011 -&gt; 0111 -&gt; 1111
</code></pre>

<p><strong>Edit:</strong></p>

<p>Very well, let's restate from what you mean rather than from what you say.</p>

<ol>
<li>There are 4 bits. </li>
<li>Each bit may change state only <strong>twice</strong>. (once from 0 to 1, and once from 1 to 0)</li>
<li>For each new value, at least one of the bits must have changed state from the previous value.</li>
</ol>

<p>Therefore, you can have at most 8 state changes, and at most 8 different values (since the last state change necessarily brings all bits back to their initial state)</p>

<p>Example:</p>

<pre><code>0000 -&gt; 0001 -&gt; 0011 -&gt; 0111 -&gt; 1111 -&gt; 1110 -&gt; 1100 -&gt; 1000 -&gt; 0000
</code></pre>

<p>So, by setting the outputs for: 3 AM - 3 PM, 6 AM - 6 PM, 9 AM - 9 PM and noon - midnight, you can determine which 3-hour period it is from the outputs. I'd suggest plugging wires into the visual output instead.</p>
","450648"
"what is the best practice of distributing binaries from a github project?","19749","","<p>what is the best practice of distributing binaries from a github project? </p>

<p>I can think of:</p>

<ul>
<li>Create a bin folder in your project where you keep a copy of the binaries. 
However, github is meant to store source code and not binaries Storing large and 
regularly changing binaries may be expensive qua diskspace and bandwidth?</li>
<li>Upload a copy of the binaries to the <a href=""http://pages.github.com/"">github pages</a> of the 
project, or use a separate web site for hosting your binaries. 
However, that is not always feasible, and requires more (hand)work to keep the
binaries up to date, I rather want to have the binaries updated automatically or with a
single action. </li>
</ul>
","<p>It is clear to me now that it is important <em>not</em> to store binaries in your github project itself. Thus, you will need to store binaries elsewhere. Possible solutions I came across are:</p>

<ul>
<li>Store the binaries in a separate submodule (<a href=""https://stackoverflow.com/a/10400835/1262753"">dalores idea</a>). It makes sense to store them in your projects <a href=""http://pages.github.com/"" rel=""nofollow noreferrer"">github pages</a>, which you use to host your projects website via github.</li>
<li>If you have only a few binaries or zip file only, you can upload them to github via Downloads -> Upload a new file. This feature is quite limited though, you cannot put files in structured folders.</li>
<li>In case of java jar files, there are solutions out there like <a href=""http://www.sonatype.org/nexus/"" rel=""nofollow noreferrer"">Nexus</a> for managing your libraries.</li>
<li>Store the binaries on a completely separate site that you host yourself</li>
</ul>
","10433468"
"Converting binary file to Base64 string","19716","","<p>I need to convert uploaded binary files to base64 string format on the fly. I'm using ASP, Vbscript. Using Midori's component for base64 conversion. For small size files (&lt;20K) the performance is okay. But when it exceeds 75 or 100K, its totally lost. Is there any efficient way to convert big binary files (2MB) to base64 string format?</p>

<p>Thanks in advance,
Kenney</p>
","<p>I have solved this issue by implementing a .net component for converting to base64 string. The hard part is the binary data sent to the .net COM from ASP is received as a string. Convert.ToBase64() accepts only byte[]. So I tried converting string to byte[].</p>

<p>But the encoding available in .net (Unicode, ASCII, UTF) doesn't works fine. There are data loss, while these encodings are used. Finally I get it done by using StringReader object. Read char by char(16 bit) and converted them to (8 bit) byte[] array.</p>

<p>And the performance is best.</p>

<p>Regards,
Siva.</p>
","1198172"
"Float to binary","19562","","<p>I'm trying to convert a floating point number to binary representation; how can I achieve this?
My goal is, however, not to be limited by 2m so I'm hoping for something that could be easily extended to any base (3, 4, 8) ecc.</p>

<p>I've got a straightforward implementation so far for integers:</p>

<pre><code>import string

LETTER = '0123456789' + string.ascii_lowercase
def convert_int(num, base):
    if base == 1:
        print ""WARNING! ASKING FOR BASE = 1""
        return '1' * num if num != 0 else '0'

    if base &gt; 36: raise ValueError('base must be &gt;= 1 and &lt;= 36')

    num, rest = divmod(num, base)
    rest = [LETTER[rest]]
    while num &gt;= base:
        num, r = divmod(num, base)
        rest.append(LETTER[r])
    rest.reverse()
    return (LETTER[num] if num else '') + ''.join(str(x) for x in rest)
</code></pre>

<p>any help appreciated :)</p>

<p>edit:</p>

<pre><code>def convert_float(num, base, digits=None):
    num = float(num)
    if digits is None: digits = 6

    num = int(round(num * pow(base, digits)))
    num = convert_int(num, base)
    num = num[:-digits] + '.' + num[:digits]
    if num.startswith('.'): num = '0' + num
    return num
</code></pre>

<p>is that right? why do i get this behaviour?</p>

<pre><code>&gt;&gt;&gt; convert_float(1289.2893, 16)
'509.5094a0'
&gt;&gt;&gt; float.hex(1289.2983)
'0x1.42531758e2196p+10'
</code></pre>

<p>p.s.
<a href=""https://stackoverflow.com/questions/3954498/how-to-convert-float-number-to-binary"">How to convert float number to Binary?</a></p>

<p>I've read that discussion, but I don't get the answer.. I mean, does it work only for 0.25, 0.125? and I dont understand the phrase 'must be in reverse order'...</p>
","<p>Next answer with a bit of theory.</p>

<p><em><strong>Explanation below does not explain IEEE Floating Point standard only general ideas concerning representation of floating point numbers</em></strong></p>

<p>Every float number is represented as a fractional part multiplied by an exponent multiplied by a sign. Additionally there is so called bias for exponent, which will be explained bellow.</p>

<p>So we have</p>

<ol>
<li>Sign bit</li>
<li>Fractional part digits</li>
<li>Exponent part digits</li>
</ol>

<p><strong>Example for base 2 with 8 bit fraction and 8 bit exponent</strong></p>

<p>Bits in fraction part tell us which summands (numbers to be added) from sequence below are to be included in represented number value</p>

<p>2^-1 + 2^-2 + 2^-3 + 2^-4 + 2^-5 + 2^-6 + 2^-7 + 2^-8</p>

<p>So if you have say 01101101 in fractional part it gives</p>

<p>0*2^-1 + 1*2^-2 + 1*2^-3 + 0*2^-4 + 1*2^-5 + 1*2^-6 + 0*2^-7 + 1*2^-8 = 0.42578125</p>

<p>Now non-zero numbers that are representable that way fall between 
2 ** -8 = 0.00390625 and 1 - 2**-8 = 0.99609375</p>

<p>Here the exponent part comes in. Exponent allows us to represent very big numbers by multiplying the fraction part by exponent. So if we have an 8bit exponent we can multiply the resulting fraction by numbers between 0 and 2^255.</p>

<p>So going back to example above let's take exponent of 11000011 = 195.</p>

<p>We have fractional part of 01101101 = 0.42578125 and exponent part 11000011 = 195. It gives us the number 0.42578125 * 2^195, this is really big number.</p>

<p>So far we can represent non-zero numbers between 2^-8 * 2^0 and (1-2^-8) * 2^255. This allows for very big numbers but not for very small numbers. In order to be able to represent small numbers we have to include so called bias in our exponent. It is a number that will be always subtracted from exponent in order to allow for representation of small numbers.</p>

<p>Let's take a bias of 127. Now all exponents are subtracted 127. So numbers that can be represented are between 2^-8 * 2^(0 - 127) and (1-2^-8) * 2^(255 - 127 = 128)</p>

<p>Example number is now 0.42578125 * 2^(195-127 = 68) which is still pretty big.</p>

<p><strong>Example ends</strong></p>

<p>In order to understand this better try to experiment with different bases and sizes for fractional and exponential part. At beginning don't try with odd bases because it only complicates things necessary.</p>

<p>Once you grasp how this representation works you should be able to write code to obtain representation of any number in any base, fractional/exponential part combination. </p>
","4842624"
"Regular expression parsing a binary file?","19558","","<p>I have a file which mixes binary data and text data. I want to parse it through a regular expression, but I get this error:</p>

<pre class=""lang-none prettyprint-override""><code>TypeError: can't use a string pattern on a bytes-like object
</code></pre>

<p>I'm guessing that message means that Python doesn't want to parse binary files.
I'm opening the file with the <code>""rb""</code> flags.</p>

<p>How can I parse binary files with regular expressions in Python?</p>

<p><strong>EDIT:</strong> I'm using Python 3.2.0</p>
","<p>I think you use Python 3 .</p>

<blockquote>
  <p>1.Opening a file in <strong>binary mode</strong> is simple but subtle. The only difference
  from opening it in text mode is that
  the mode parameter contains a <strong>'b'</strong>
  character.</p>
  
  <p>........</p>
  
  <p>4.Here’s one difference, though: a <strong>binary stream</strong> object has no encoding
  attribute. That makes sense, right?
  <strong>You’re reading (or writing) bytes</strong>, not
  strings, so there’s no conversion for
  Python to do.</p>
  
  <p><a href=""http://www.diveintopython3.net/files.html#read"" rel=""noreferrer"">http://www.diveintopython3.net/files.html#read</a></p>
</blockquote>

<p>Then, in Python 3, since a binary stream from a file is a stream of bytes, a regex to analyse a stream from a file must be defined with a bytes sequence, not a charcaters sequence.</p>

<blockquote>
  <p>In Python 2, a string was an array of
  bytes whose character encoding was
  tracked separately. If you wanted
  Python 2 to keep track of the
  character encoding, you had to use a
  Unicode string (u'') instead. But in
  Python 3, a string is always what
  Python 2 called a Unicode string —
  that is, an array of Unicode
  characters (of possibly varying byte
  lengths).</p>
  
  <p><a href=""http://www.diveintopython3.net/case-study-porting-chardet-to-python-3.html"" rel=""noreferrer"">http://www.diveintopython3.net/case-study-porting-chardet-to-python-3.html</a></p>
</blockquote>

<p>and</p>

<blockquote>
  <p><strong>In Python 3, all strings are sequences</strong>
  <strong>of Unicode characters</strong>. There is no
  such thing as a Python string encoded
  in UTF-8, or a Python string encoded
  as CP-1252. “Is this string UTF-8?” is
  an invalid question. UTF-8 is a way of
  encoding characters as a sequence of
  bytes. If you want to take a string
  and turn it into a sequence of bytes
  in a particular character encoding,
  Python 3 can help you with that. </p>
  
  <p><a href=""http://www.diveintopython3.net/strings.html#boring-stuff"" rel=""noreferrer"">http://www.diveintopython3.net/strings.html#boring-stuff</a></p>
</blockquote>

<p>and</p>

<blockquote>
  <p>4.6. Strings vs. Bytes# Bytes are bytes; characters are an abstraction.
  An immutable sequence of Unicode
  characters is called a string. An
  immutable sequence of
  numbers-between-0-and-255 is called a
  bytes object.</p>
  
  <p>....</p>
  
  <p>1.<strong>To define a bytes object, use the b' '  “byte literal” syntax</strong>. Each byte
  within the byte literal can be an
  ASCII character or an encoded
  hexadecimal number from \x00 to \xff
  (0–255).</p>
  
  <p><a href=""http://www.diveintopython3.net/strings.html#boring-stuff"" rel=""noreferrer"">http://www.diveintopython3.net/strings.html#boring-stuff</a></p>
</blockquote>

<p>So you will define your regex as follows</p>

<pre><code>pat = re.compile(b'[a-f]+\d+')
</code></pre>

<p>and not as</p>

<pre><code>pat = re.compile('[a-f]+\d+')
</code></pre>

<p>More explanations here:</p>

<p><a href=""http://www.diveintopython3.net/case-study-porting-chardet-to-python-3.html"" rel=""noreferrer"">15.6.4. Can’t use a string pattern on a bytes-like object</a></p>
","5620074"
"(Java) Specify number of bits (length) when converting binary number to string?","19401","","<p>I'm trying to store a number as a binary string in an array but I need to specify how many bits to store it as.</p>

<p>For example, if I need to store 0 with two bits I need a string ""00"". Or 1010 with 6 bits so ""001010"".</p>

<p>Can anyone help?</p>

<p>EDIT: Thanks guys, as I'm rubbish at maths/programming in general I've gone with the simplest solution which was David's. Something like:</p>

<pre><code>binaryString.append(Integer.toBinaryString(binaryNumber));
for(int n=binaryString.length(); n&lt;numberOfBits; n++) {
                        binaryString.insert(0, ""0"");
}
</code></pre>

<p>It seems to work fine, so unless it's very inefficient I'll go with it.</p>
","<p>Use <code>Integer.toBinaryString()</code> then check the string length and prepend it with as many zeros as you need to make your desired length.</p>
","625850"
"Fast way to convert a binary number to a decimal number","19156","","<p>I have to convert a binary number like for example <code>unsigned int bin_number = 10101010</code> into its decimal representation (i.e. <code>170</code>) as quickly as possible? What is the best algorithm?</p>
","<p>Using templates you can solve this problem at <em>compile-time</em>.</p>

<pre><code>template&lt;unsigned long num&gt;
struct binary
{
    static unsigned const value =
        binary&lt;num/10&gt;::value &lt;&lt; 1 | num % 10;
};

// Specialization for zero
template&lt;&gt;
struct binary&lt;0&gt;
{ static unsigned const value = 0; };
</code></pre>

<p>The binary template is instantiated again with a smaller <code>num</code>, until <code>num</code> reaches zero and the specialization is used as a termination condition. </p>

<p>Example: <code>std::cout &lt;&lt; binary&lt;10101010&gt;::value;</code></p>

<p>For <em>run-time</em> problem:</p>

<pre><code>unsigned binary_to_decimal(unsigned num)
{
    unsigned res = 0;

    for(int i = 0; num &gt; 0; ++i)
    {
        if((num % 10) == 1)
            res += (1 &lt;&lt; i);

        num /= 10;
    }

    return res;
}
</code></pre>
","10949520"
"How to SQL insert a raw/Binary field value from bytes/integer array using VBScript (or VB6)?","19114","","<p>Does anyone know how to pass a several bytes into a Binary (or varbinary) field using SQL and ideally in ADO (classic) &amp; VBScript (or Visual Basic 6)?</p>

<p>I wish to encode 10-20 (maybe more) bytes of data and have this data stored in a SQL db field. (Its not MS-SQLSVR, but I'm hoping that a standard SQL supported format will work!)</p>

<p>The bytes are available as either a string of bytes obtained via AscB/ChrB, OR, an array of 'bytes' (actually variants of type byte obtained via 'cbyte') and stored in the array.</p>

<p><strong>First option: using the string format</strong> 
I have had some (limited) success creating the SQL insert as:</p>

<pre><code>x = "".&gt;?hD-&amp;91k[=""    '&lt;psuedo string of chars, some unprintable
Insert Into rawtest (byt) Values (CAST('"" &amp; x &amp; ""' as SQL_BINARY(12)))
</code></pre>

<p>But I am concerned that string nulls will truncate the data in the field and other non-printing control characters will get in the way of handling the data. Is there a way to avoid this?</p>

<p><strong>Second Option: Byte Array</strong>
I can put the data in a array easily enough, but cannot see how to pass to the SQL Insert statement. If I attempt to pass in 12 bytes, the insert fails due to the CAST attempting to store the data into a Integer (4bytes). If I pass in a single byte, it works, eg: </p>

<pre><code>x = a(0)
</code></pre>

<p>And continues to work for 4 bytes, but fails when the Integer overflows. Also, it reorders the data </p>

<p>I've attempted to use various workarounds:</p>

<pre><code>Insert Into rawtest (byt) Values (CAST('12,34,45' as SQL_BINARY(12)))
Insert Into rawtest (byt) Values (CAST(&amp;h12&amp;h34 as SQL_BINARY(12)))
Insert Into rawtest (byt) Values (CAST(0x123456789012 as SQL_BINARY(12)))
</code></pre>

<p>I've also tried similar combinations with:</p>

<pre><code>Insert Into rawtest (byt) Values (CONVERT('"" &amp; x &amp; ""', SQL_BINARY)
</code></pre>

<p>But these all fail!</p>

<p>Ideally, I want a method, any method, that takes a small binary-array of upto 20 bytes(ideally full byte range 0-255, but could take less) and passes them thru to a plain, raw, binary SQL field. </p>

<p>Ideally I need to do this in VBScript/ADO, but can take a VB6 based solution if available. I want this as 'raw' binary, I don't want to use an ascii-encoding, like Base64.</p>

<p>I've googled till I'm numb and havn't not found much atall relevant to binary fields in SQL. </p>

<p>Can you help? Any answers appreciated. Many thx.</p>
","<p>Classic ADO can manipulate very large (>8000) varbinary and image (blob) fields directly without chunking. Below is a sample against MS SQL Server that inserts binary data into a table with an INT ID field and a varbinary(100) field. In this example a parameterized SQL query is inserting the binary data from a Variant. The Variant just needs to be populated with the binary data.</p>

<pre><code>Dim vntBlobData As Variant
vntBlobData = ""ReplaceThisWithBinaryData - A byte array will work""

Dim cn As ADODB.Connection
Set cn = New ADODB.Connection
cn.ConnectionString = ""Provider = sqloledb; Data Source = DBServerName; Initial Catalog = DBName; User ID = UserID; Password = Password; Persist Security Info = False""
cn.Open

Dim strQry As String
strQry = ""INSERT INTO TestBinaryTable (ID, BlobData) VALUES (?, ?)""

Dim cm As ADODB.Command
Set cm = New ADODB.Command
cm.ActiveConnection = cn
cm.CommandText = strQry
cm.Parameters.Append cm.CreateParameter(""@ID"", adInteger, adParamInput, , 1)
cm.Parameters.Append cm.CreateParameter(""@BlobData"", adVarBinary, adParamInput, 100, vntBlobData)
cm.CommandType = adCmdText
cm.Execute
</code></pre>
","924104"
"How do I convert a binary string to hex using C?","19050","","<p>How do I convert an 8-bit binary string (e.g. ""10010011"") to hexadecimal using C?</p>
","<p>Something like that:</p>

<pre><code>char *bin=""10010011"";
char *a = bin;
int num = 0;
do {
    int b = *a=='1'?1:0;
    num = (num&lt;&lt;1)|b;
    a++;
} while (*a);
printf(""%X\n"", num);
</code></pre>
","5307692"
"Determine if number is in the binary sequence 1 2 4 8 16 32 64 etc","18985","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/600293/how-to-check-if-a-number-is-a-power-of-2"">How to check if a number is a power of 2</a>  </p>
</blockquote>



<p>I want to determine if a number is in </p>

<p><code>
1
2
4
8
16
32
64
128
256
512
1024
2048
4096
8192
16384
...</code></p>

<p>I tried this:</p>

<pre><code>public static void Main(string[] args)
{            
    int result = 1;  
    for (int i = 0; i &lt; 15; i++)
    {          
        //Console.WriteLine(result);
        Console.WriteLine(result % 2);
        result *= 2;

    }  
}
</code></pre>

<p><a href=""http://rextester.com/MPCN19785"" rel=""nofollow noreferrer"">As you can see</a> it returns 
<code>
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
...</code></p>

<p>How should I efficiently make the above print to be <code>0</code> for all of them including 1?</p>
","<p>The following expression should be true if <code>i</code> is in your sequence.</p>

<p><code>(i &amp; (i-1)) == 0)</code></p>

<p><a href=""http://rextester.com/JRH41036"" rel=""noreferrer"">http://rextester.com/JRH41036</a></p>
","9260097"
"Getting a specific bit value in a byte string","18855","","<p>There is a byte at a specific index in a byte string which represents eight flags; one flag per bit in the byte. If a flag is set, its corresponding bit is 1, otherwise its 0. For example, if I've got</p>

<pre><code>b'\x21'
</code></pre>

<p>the flags would be</p>

<pre><code>0001 0101    # Three flags are set at indexes 0, 2 and 4
             # and the others are not set
</code></pre>

<p>What would be the best way to get each bit value in that byte, so I know whether a particular flag is set or not? (Preferably using bitwise operations)</p>
","<p>Typically, the least-significant bit is bit index 0 and the most-significant bit is bit index 7. Using this terminology, we can determine if bit index k is set by taking the bitwise-and with 1 shifted to the left by k. If the bitwise and is non-zero, then that means that index k has a 1; otherwise, index k has a 0. So:</p>

<pre>
def get_bit(byteval,idx):
    return ((byteval&amp;(1&lt;&lt;idx))!=0);
</pre>

<p>This will correctly determine the value of bits at indices 0...7 of the byte, going from right-to-left (i.e. the least significant bit to the most significant bit, or equivalently from the 1s place to the 2<sup>7</sup> = 128 place). </p>

<p><b>Why it works</b><br />
I figured I should add an explanation of why it works...</p>

<p>1&lt;&lt;0 is 1 = 0000 0001<br />
1&lt;&lt;1 is 2 = 0000 0010<br />
1&lt;&lt;2 is 4 = 0000 0100<br /></p>

<p>As you can see,  1&lt;&lt;k is equivalent to 2<sup>k</sup> and contains a 1 at exactly the index we are interested and at no other location. Consequently, the bitwise and with 1&lt;&lt;k will either return 0 or 1&lt;&lt;k; it will be 0 if the bit at the index we are interested in is 0 (because 1 and 0 is 0, and all other bits in 1&lt;&lt;k are zero). If the bit we are interested in is 1, then we get a 1 and a 1 in that position, and a 0 and something else, everywhere else.</p>
","2591555"
"Saving a Dictionary<String, Int32> in C# - Serialization?","18795","","<p>I am writing a C# application that needs to read about 130,000 (String, Int32) pairs at startup to a Dictionary. The pairs are stored in a .txt file, and are thus easily modifiable by anyone, which is something dangerous in the context. I would like to ask if there is a way to save this dictionary so that the information can be reasonably safely stored, without losing performance at startup. I have tried using <code>BinaryFormatter</code>, but the problem is that while the original program takes between 125ms and 250ms at startup to read the information from the txt and build the dictionary, deserializing the resulting binary files takes up to 2s, which is not too much by itself but when compared to the original performance is a 8-16x decrease in speed.</p>

<p><strong>Note:</strong> Encryption is important, but the most important should be a way to save and read the dictionary from the disk - possibly from a binary file - without having to use Convert.ToInt32 on each line, thus improving performance.</p>
","<p>interesting question. I did some quick tests and you are right - BinaryFormatter is surprisingly slow:</p>

<ul>
<li>Serialize 130,000 dictionary entries: <strong>547ms</strong></li>
<li>Deserialize 130,000 dictionary entries: <strong>1046ms</strong></li>
</ul>

<p>When I coded it with a StreamReader/StreamWriter with comma separated values I got:</p>

<ul>
<li>Serialize 130,000 dictionary entries: <strong>121ms</strong> </li>
<li>Deserialize 130,000 dictionary entries: <strong>111ms</strong></li>
</ul>

<p>But then I tried just using a BinaryWriter/BinaryReader:</p>

<ul>
<li>Serialize 130,000 dictionary entries: <strong>22ms</strong></li>
<li>Deserialize 130,000 dictionary entries: <strong>36ms</strong></li>
</ul>

<p>The code for that looks like this:</p>

<pre><code>public void Serialize(Dictionary&lt;string, int&gt; dictionary, Stream stream)
{
    BinaryWriter writer = new BinaryWriter(stream);
    writer.Write(dictionary.Count);
    foreach (var kvp in dictionary)
    {
        writer.Write(kvp.Key);
        writer.Write(kvp.Value);
    }
    writer.Flush();
}

public Dictionary&lt;string, int&gt; Deserialize(Stream stream)
{
    BinaryReader reader = new BinaryReader(stream);
    int count = reader.ReadInt32();
    var dictionary = new Dictionary&lt;string,int&gt;(count);
    for (int n = 0; n &lt; count; n++)
    {
        var key = reader.ReadString();
        var value = reader.ReadInt32();
        dictionary.Add(key, value);
    }
    return dictionary;                
}
</code></pre>

<p>As others have said though, if you are concerned about users tampering with the file, encryption, rather than binary formatting is the way forward.</p>
","4022629"
"Convert Decimal to Binary Vector","18779","","<p>I need to convert a Decimal Number to a Binary Vector</p>

<p>For example, Something like this:</p>

<pre><code>  length=de2bi(length_field,16);
</code></pre>

<p>Unfortunately, because of licensing, I cannot use this command. Is there any quick short technique for converting binary to a vector.</p>

<p>Here is what I am looking for,</p>

<pre><code>If 
Data=12;
Bin_Vec=Binary_To_Vector(Data,6) should return me
Bin_Vec=[0 0 1 1 0 0]
</code></pre>

<p>Thanks</p>
","<p>Here's a solution that is reasonably fast:</p>

<pre><code>function out = binary2vector(data,nBits)

powOf2 = 2.^[0:nBits-1];

%# do a tiny bit of error-checking
if data &gt; sum(powOf2)
   error('not enough bits to represent the data')
end

out = false(1,nBits);

ct = nBits;

while data&gt;0
if data &gt;= powOf2(ct)
data = data-powOf2(ct);
out(ct) = true;
end
ct = ct - 1;
end
</code></pre>

<p>To use:</p>

<pre><code>out = binary2vector(12,6)
out =
     0     0     1     1     0     0

out = binary2vector(22,6)
out =
     0     1     1     0     1     0
</code></pre>
","5744712"
"How to read little endian integers from file in C++?","18583","","<p>Say I have a binary file; it contains positive binary numbers, but written in <b>little endian</b> as 32-bit integers</p>

<p>How do I read this file?  I have this right now.</p>

<pre><code>int main() {
    FILE * fp;
    char buffer[4];
    int num = 0;
    fp=fopen(""file.txt"",""rb"");
    while ( fread(&amp;buffer, 1, 4,fp) != 0) {

        // I think buffer should be 32 bit integer I read,
        // how can I let num equal to 32 bit little endian integer?
    }
    // Say I just want to get the sum of all these binary little endian integers,
    // is there an another way to make read and get sum faster since it's all 
    // binary, shouldnt it be faster if i just add in binary? not sure..
    return 0;
}
</code></pre>
","<p>This is one way to do it that works on either big-endian or little-endian architectures:</p>

<pre><code>int main() {
    unsigned char bytes[4];
    int sum = 0;
    FILE *fp=fopen(""file.txt"",""rb"");
    while ( fread(bytes, 4, 1,fp) != 0) {
        sum += bytes[0] | (bytes[1]&lt;&lt;8) | (bytes[2]&lt;&lt;16) | (bytes[3]&lt;&lt;24);
    }
    return 0;
}
</code></pre>
","13001446"
"How to check if the binary representation of an integer is a palindrome?","18543","","<p>How to check if the binary representation of an integer is a palindrome?</p>
","<p>Since you haven't specified a language in which to do it, here's some C code (not the most efficient implementation, but it should illustrate the point):</p>

<pre><code>/* flip n */
unsigned int flip(unsigned int n)
{
    int i, newInt = 0;
    for (i=0; i&lt;WORDSIZE; ++i)
    {
        newInt += (n &amp; 0x0001);
        newInt &lt;&lt;= 1;
        n &gt;&gt;= 1;
    }
    return newInt;
}

bool isPalindrome(int n)
{
    int flipped = flip(n);
    /* shift to remove trailing zeroes */
    while (!(flipped &amp; 0x0001))
        flipped &gt;&gt;= 1;
    return n == flipped;
}
</code></pre>

<p><strong>EDIT</strong> fixed for your 10001 thing.</p>
","845786"
"How to used the alphabet binary symbols","18500","","<p>I was reading an article on binary numbers and it had some practice problems at the end but it didn't give the solutions to the problems. The last is ""How many bits are required to represent the alphabet?"". Can tell me the answer to that question and briefly explain why?
Thanks.</p>
","<p>You would only need 5 bits because you are counting to 26 (if we take only upper or lowercase letters). 5 bits will count up to 31, so you've actually got more space than you need. You can't use 4 because that only counts to 15. </p>

<p>If you want both upper and lowercase then 6 bits is your answer - 6 bits will happily count to 63, while your double alphabet has (2 * 24 = 48) characters, again leaving plenty of headroom.</p>
","4115571"
"Writing hex data into a file","18471","","<p>I'm trying to write hex data taken from ascii file to a newly created binary file</p>

<p>ascii file example:</p>

<pre><code>98 af b7 93 bb 03 bf 8e ae 16 bf 2e 52 43 8b df
4f 4e 5a e4 26 3f ca f7 b1 ab 93 4f 20 bf 0a bf
82 2c dd c5 38 70 17 a0 00 fd 3b fe 3d 53 fc 3b
28 c1 ff 9e a9 28 29 c1 94 d4 54 d4 d4 ff 7b 40
</code></pre>

<p>my code </p>

<pre><code>hexList = []
with open('hexFile.txt', 'r') as hexData:
    line=hexData.readline()
    while line != '':
        line = line.rstrip()
        lineHex = line.split(' ')
        for i in lineHex:
            hexList.append(int(i, 16))
        line = hexData.readline()


with open('test', 'wb') as f:
    for i in hexList:
        f.write(hex(i))
</code></pre>

<p>Thought <code>hexList</code> holds already hex converted data and <code>f.write(hex(i))</code> should write these hex data into a file, but python writes it with ascii mode</p>

<p>final output: <code>0x9f0x2c0x380x590xcd0x110x7c0x590xc90x30xea0x37</code> which is wrong!</p>

<p>where is the issue?</p>
","<p>Use <a href=""https://docs.python.org/3/library/binascii.html#binascii.unhexlify"" rel=""noreferrer""><code>binascii.unhexlify</code></a>:</p>

<pre><code>&gt;&gt;&gt; import binascii
&gt;&gt;&gt; binascii.unhexlify('9f')
'\x9f'

&gt;&gt;&gt; hex(int('9f', 16))
'0x9f'
</code></pre>

<hr>

<pre><code>import binascii

with open('hexFile.txt') as f, open('test', 'wb') as fout:
    for line in f:
        fout.write(
            binascii.unhexlify(''.join(line.split()))
        )
</code></pre>
","26796853"
"Remove 'b' character do in front of a string literal in Python 3","18342","","<p>I am new in python programming and i am a bit confused. I try to get the bytes from a string to hash and encrypt but i got</p> 

<pre><code>b'...'
</code></pre>

<p>b character in front of string just like the below example. Is any way avoid this?.Can anyone give a solution? Sorry for this silly question</p>

<pre><code>import hashlib

text = ""my secret data""
pw_bytes = text.encode('utf-8')
print('print',pw_bytes)
m = hashlib.md5()
m.update(pw_bytes)
</code></pre>

<p>OUTPUT:</p>

<pre><code> print b'my secret data'
</code></pre>
","<p>You get the <code>b</code> because you encoded to <code>utf-8</code> and it's a bytes object. So, you can print just the string first, or a bit redundant decode it after encoding, if you didn't want to see the <code>b</code> denoting it as this. Since you need to encode before updating, I suppose you could just encode before this</p>

<p>Also, converting to a <code>str</code> beforehand is redundant. It's already a string.</p>
","37016987"
"""grep"" offset of ascii string from binary file","18300","","<p>I'm generating binary data files that are simply a series of records concatenated together.  Each record consists of a (binary) header followed by binary data.  Within the binary header is an ascii string 80 characters long.  Somewhere along the way, my process of writing the files got a little messed up and I'm trying to debug this problem by inspecting how long each record actually is.</p>

<p><a href=""https://stackoverflow.com/questions/4180081/linux-binary-grep"">This</a> seems extremely related, but I don't understand perl, so I haven't been able to get the accepted answer there to work.  The other answer points to <code>bgrep</code> which I've compiled, but it wants me to feed it a hex string and I'd rather just have a tool where I can give it the ascii string and it will find it in the binary data, print the string and the byte offset where it was found.</p>

<p>In other words, I'm looking for some tool which acts like this:</p>

<pre><code>tool foobar filename
</code></pre>

<p>or</p>

<pre><code>tool foobar &lt; filename
</code></pre>

<p>and its output is something like this:</p>

<pre><code>foobar:10
foobar:410
foobar:810
foobar:1210
...
</code></pre>

<p>e.g. the string which matched and a byte offset in the file where the match started.  In this example case, I can infer that each record is 400 bytes long.</p>

<p>Other constraints:</p>

<ul>
<li>ability to search by regex is cool, but I don't need it for this problem</li>
<li>My binary files are big (3.5Gb), so I'd like to avoid reading the whole file into memory if possible.</li>
</ul>
","<p>You could use <code>strings</code> for this:</p>

<pre><code>strings -a -t x filename | grep foobar
</code></pre>

<p>Tested with GNU binutils.</p>

<p>For example, where in <code>/bin/ls</code> does <code>--help</code> occur:</p>

<pre><code>strings -a -t x /bin/ls | grep -- --help
</code></pre>

<p>Output:</p>

<pre><code>14938 Try `%s --help' for more information.
162f0       --help     display this help and exit
</code></pre>
","14141121"
"Express - Return binary data from distant webservice","18116","","<p>I try to return some binary data with Express. In the example, it's a PDF but theorically, this can be any sort of file.</p>

<p>But focus on the pdf for the moment. I wrote this code : </p>

<pre><code>app.get('*', function (req, res) {
    getBinaryData(req.url,
        function (answer) {
            res.type('pdf');
            res.end(new Buffer(answer, 'binary'));
        },
        function (error) {
            res.setHeader('Content-Type', 'text/plain');
            return res.end(error);
        }
    );
});
</code></pre>

<p>Based on what I saw here : <a href=""https://github.com/strongloop/express/issues/1555"" rel=""noreferrer"">https://github.com/strongloop/express/issues/1555</a></p>

<p>But, i get a pdf file with the right number of pages, right title.... but all the pages are blank</p>

<p>I'm sure concern the return of getBinaryData(), because this function asked an external Web Service and when I asked directly this service, I got the right document.</p>

<p>Thank you in advance for your answers</p>
","<p>I found a more simple solution : </p>

<pre><code>request(req.url).pipe(res);
</code></pre>

<p>This pipes the original response from distant Web Service directly to my response! I got the correct file regardless of the file type.</p>
","30218377"
"How can I unpack binary hex formatted data in Python?","18104","","<p>Using the PHP <a href=""http://www.php.net/pack"" rel=""noreferrer"">pack()</a> function, I have converted a string into a binary hex representation:</p>

<pre><code>$string = md5(time); // 32 character length
$packed = pack('H*', $string);
</code></pre>

<p>The H* formatting means ""Hex string, high nibble first"".</p>

<p>To unpack this in PHP, I would simply use the <a href=""http://www.php.net/unpack"" rel=""noreferrer"">unpack()</a> function with the H* format flag.</p>

<p>How would I unpack this data in Python?</p>
","<p>There's an easy way to do this with the <code>binascii</code> module:</p>

<pre><code>&gt;&gt;&gt; import binascii
&gt;&gt;&gt; print binascii.hexlify(""ABCZ"")
'4142435a'
</code></pre>

<p>Unless I'm misunderstanding something about the nibble ordering (high-nibble first is the default), that should be perfectly sufficient!</p>

<p>Furthermore, Python's <code>hashlib.md5</code> objects have a <code>hexdigest()</code> method to automatically convert the MD5 digest to an ASCII hex string, so that this method isn't even necessary for MD5 digests.  Hope that helps.</p>
","201325"
"How to use NetCat for Windows to send a binary file to a TCP connection?","17971","","<p>If I want to transfer a binary file ""binary.bin"" (located in the same directory as NetCat) to IP address 127.0.0.1 port 1200 using TCP, how do I specify this using <a href=""http://www.rodneybeede.com/Compile_Netcat_on_Windows_using_MinGW.html"" rel=""noreferrer"">NetCat</a> for windows?</p>
","<p>I found the solution. Its</p>

<pre><code>nc 127.0.0.1 1200 &lt; binary.bin
</code></pre>

<p>In addition, if the response needs to be saved then </p>

<pre><code>nc 127.0.0.1 1200 &lt; binary.bin &gt; response.bin
</code></pre>
","2046507"
"How to calculate decimal and hex values of one and two's complmement binary representation?","17865","","<p>For an example, assume an initial value of:</p>

<p>0100 0011</p>

<p>What is this in hex and what is it in decimal if using two's complement?</p>

<p>Similarly, what is it in hex and decimal if using one's complement?</p>

<p>More generally, how do you work out the hex and decimal values of both forms of binary representation?  </p>
","<p>Hex is easy. Simply separate into 4 bit groups and convert each group to decimal. Then, obviously, replace 10 with A, 11 with B, 12 with C, 13 with D, 14 with E and 15 with F. Hex representations usually don't care about one or two's complement and simply reflect the bits exactly.</p>

<p>As to converting into decimal: depending on being one or two's complement, work out what the sign and absolute values would be. If the first bit is 0, it's positive, if it's 1 it's negative.</p>

<p>Positive values require no further modification. The absolute value of a negative value depends on it being one's or two's complement. One's complement is simply the negated bits (0 becomes 1, 1 becomes 0). For two's complement subtract 1 and then negate the bits.</p>

<p>Then sum the values of the bits set to 1 in the absolute value. The values of each bit are successive powers of two of increasing exponent, starting with 2^0 (=1) for the rightmost bit and increasing to the left.</p>

<p>Here are some wikipedia references:</p>

<ul>
<li><a href=""http://en.wikipedia.org/wiki/Ones&#39;_complement"" rel=""nofollow noreferrer"">One's complement</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Two&#39;s_complement"" rel=""nofollow noreferrer"">Two's complement</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Binary_numeral_system"" rel=""nofollow noreferrer"">Binary</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Hexadecimal"" rel=""nofollow noreferrer"">Hexadecimal</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Signed_number_representations"" rel=""nofollow noreferrer"">Signed number representations</a></li>
</ul>
","1852384"
"Read VBA macros (or vbaProject.bin) of an Excel file without opening it in MS Excel","17775","","<p>I would like to analyze Excel files, especially those which contain VBA programs inside. because I plan to run this analysis on lots of Excel files one by one, I don't want to open these files within Microsoft Excel to analyze them.</p>

<p>One difficulty is to find and parse the VBA macros of an Excel file. We know that an Excel file can be converted to <code>.zip</code> file which contains lots of <code>.xml</code> and <code>vbaProject.bin</code>, it is pretty certain that VBA macros are in <code>vbaProject.bin</code>. However, the problem is how to read it?</p>

<p>Does anyone know if there is any tool or API to find and parse the VBA macros?</p>

<p>Does anyone know if there is any tool or API to read <code>vbaProject.bin</code>?</p>
","<p>There is a very large PDF from Microsoft which documents how to extract functions from the <code>vbaproject.bin</code>:</p>

<p><a href=""http://download.microsoft.com/download/2/4/8/24862317-78f0-4c4b-b355-c7b2c1d997db/%5BMS-OVBA%5D.pdf"">http://download.microsoft.com/download/2/4/8/24862317-78f0-4c4b-b355-c7b2c1d997db/%5BMS-OVBA%5D.pdf</a>  [<a href=""http://answers.microsoft.com/en-us/office/forum/office_2007-customize/extract-functions-in-the-vbaprojectbin/3db716a0-fdec-4be4-a6bb-38894b0f2cea"">Source</a>]</p>

<p>Some additional information which may or may not be complimentary to the above:</p>

<p><a href=""http://www.codeproject.com/Articles/15216/Office-2007-bin-file-format"">http://www.codeproject.com/Articles/15216/Office-2007-bin-file-format</a></p>
","17538985"
"What type is the best to manage binary data in Java?","17634","","<p>I'm getting some documents from the web and many of them are binary files (executables, PDF, etc.). In Java, what is the correct type to hold the binary data until save it in database? Can I use a String for this?</p>
","<p>Use a byte array (byte[]) or InputStream (e.g. ByteArrayInputStream).  Java Strings are not a good container for generic binary data.</p>

<p>The Apache library <a href=""http://commons.apache.org/io/"" rel=""noreferrer"">commons-io</a> has some nice utility classes for dealing with bytes and streams.</p>

<p>e.g. <a href=""http://commons.apache.org/io/api-release/org/apache/commons/io/IOUtils.html#toByteArray%28java.io.InputStream%29"" rel=""noreferrer"">IOUtils.toByteArray(InputStream)</a></p>

<hr>

<p><a href=""http://docs.oracle.com/javase/1.5.0/docs/api/java/nio/ByteBuffer.html"" rel=""noreferrer"">ByteBuffer</a> was introduced as part of <a href=""http://en.wikipedia.org/wiki/New_I/O"" rel=""noreferrer"">Java NIO</a>, available in Java 4 (1.4) and later.  In specialized scenarios, it can have performance benefits over using a byte[].  It also has some helpful convenience methods.   I still usually use byte[], though, since it is more widely known, more common in APIs, and almost always performs well enough.</p>
","9606687"
"Subtracting a large unsigned binary number from a smaller one","17612","","<p>I'm taking a computer organization and assembly language course.  The written part of our lab this week has a question on it that has me stumped.  The question reads...</p>

<p><strong>Subtract the following unsigned binary numbers (show the borrow and overflow bits).  Do not convert to two's complement.</strong></p>

<pre><code> 0101 0111 1101
-1110 1011 0110
 --------------
</code></pre>

<p>I realize that the answer is <strong>-1001 0011 1001</strong> but I'm having a hard time trying to figure out how to borrow to actually perform this subtraction by taking the larger number and subtracting it from the smaller number and show my work.  My whole life when subtracting a large number from a small number I have reversed the problem and instead subtracted the smaller number from the larger number and added a negative sign in front of the result.  I asked the professor and he says that he wants the problem solved the way that it is written.  I am not allowed to solve this by subtracting the smaller number from the larger number and negating like I normally would.  I haven't been able to find any examples online of subtracting a larger unsigned binary number from a smaller one.</p>

<p>I would really appreciate it if someone could describe to me how to perform subtraction in this scenario.</p>

<p>Update:
@Alex is correct.  The professor was looking for</p>

<pre><code>0110 1100 0111 (1735)
</code></pre>

<p>Thanks everyone.</p>
","<p>You do it the same way irrespective of which number is bigger and which is smaller.</p>

<pre><code> bb b      bb   &lt;- borrows
 0101 0111 1101 (1405)
-1110 1011 0110 (3766)
 --------------
 0110 1100 0111 (1735?)
</code></pre>

<p>Now, if you want a proper difference, you need to take into account the overflow since the above result doesn't include the sign bit:</p>

<pre><code> b bb b      bb   &lt;- borrows
 0 0101 0111 1101 (1405)
-0 1110 1011 0110 (3766)
 ----------------
 1 0110 1100 0111 (-2361 signed 2's complement)
</code></pre>

<p>Really, the CPU doesn't care what gets subtracted from what. It uses the same algorithm for integer addition/subtraction, moreover, this algorithm is the same for signed and unsigned integers. You only have to correctly interpret the result and the carry and overflow flags. That's all.</p>
","9526822"
"Writing blob from SQLite to file using Python","17359","","<p>A clueless Python newbie needs help. I muddled through creating a simple script that inserts a binary file into a blog field in a SQLite database:</p>

<pre><code>import sqlite3
conn = sqlite3.connect('database.db')
cursor = conn.cursor()
input_note = raw_input(_(u'Note: '))
    input_type = 'A'
    input_file = raw_input(_(u'Enter path to file: '))
        with open(input_file, 'rb') as f:
            ablob = f.read()
            f.close()
        cursor.execute(""INSERT INTO notes (note, file) VALUES('""+input_note+""', ?)"", [buffer(ablob)])
        conn.commit()
    conn.close()
</code></pre>

<p>Now I need to write a script that grabs the contents of the blob field of a specific record and writes the binary blob to a file. In my case, I use the SQLite database to store .odt documents, so I want to grab and save them as .odt files. How do I go about that? Thanks!</p>
","<p>Here's a script that does read a file, put it in the database, read it from database and then write it to another file:</p>

<pre><code>import sqlite3
conn = sqlite3.connect('database.db')
cursor = conn.cursor()

with open(""..."", ""rb"") as input_file:
    ablob = input_file.read()
    cursor.execute(""INSERT INTO notes (id, file) VALUES(0, ?)"", [sqlite3.Binary(ablob)])
    conn.commit()

with open(""Output.bin"", ""wb"") as output_file:
    cursor.execute(""SELECT file FROM notes WHERE id = 0"")
    ablob = cursor.fetchone()
    output_file.write(ablob[0])

cursor.close()
conn.close()
</code></pre>

<p>I tested it with an xml and a pdf and it worked perfectly. Try it with your odt file and see if it works.</p>
","3387596"
"How do you calculate a decimal number to 8-bit excess binary?","17315","","<p>For example I have the number <code>-17</code>. I know that the binary representation of <code>17</code> is: <code>00010001</code>, how would you turn that into an 8-bit excess binary?</p>
","<p>First of all you need to pick a bias for the excess representation. Since it's typical to select a bias equal to half the available range in magnitude, for 8 bits we 'll pick -127 as the bias.</p>

<p>What this means is that you have 8 bits which will be interpreted as an unsigned integer and 127 will be subtracted from that integer to get the final result. Therefore, since we have</p>

<pre><code>final = unsigned + bias
final = -17
bias  = -127
</code></pre>

<p>We end up with</p>

<pre><code>unsigned = final - bias = -17 - (-127) = 110
</code></pre>

<p>Therefore the excess-127 representation of -17 would be 01101110 (decimal 110).</p>
","18074750"
"Backslash zero delimiter '\0'","17230","","<p>I have seen <code>'\0'</code> to be used as a delimiter in mixed binary files (UTF8 strings + binary data). Could anyone explain what <code>'\0'</code> means or point to a good place to study?</p>
","<p>It's the null character; more info in this Wikipedia <a href=""http://en.wikipedia.org/wiki/Null_character"" rel=""noreferrer"">article</a>.</p>
","6380172"
"How to store a secret API key in an application's binary?","17204","","<p>I am creating a Twitter client for Mac OS X and I have a Consumer secret. It's to my understanding I should not share this <strong>secret</strong> key. The problem is that when I put it as a string literal into my application and use it, like this:</p>

<pre><code>#define QQTwitterConsumerSecret @""MYSECRETYOUMAYNOTKNOW""

[[QQTwitterEngine alloc] initWithConsumerKey:QQTwitterConsumerKey consumerSecret:QQTwitterConsumerSecret];
</code></pre>

<p>It is in the data section of my application's binary. Hackers can read this, disassemble the application, etcetera.</p>

<p>Is there any safe way of storing the Consumer secret? Should I encrypt it?</p>
","<p>There is no real perfect solution. No matter what you do, someone dedicated to it will be able to steal it.</p>

<p>Even Twitter for iPhone/iPad/Android/mac/etc. has a secret key in there, they've likely just obscured it somehow.</p>

<p>For example, you could break it up into different files or strings, etc.</p>

<p>Note: Using a hex editor you can read ascii strings in a binary, which is the easiest way. By breaking it up into different pieces or using function calls to create the secret key usually works to make that process more difficult.</p>
","5525384"
"Converting string of 1s and 0s into binary value","17139","","<p>I'm trying to convert an incoming sting of 1s and 0s from stdin into their respective binary values (where a string such as ""11110111"" would be converted to 0xF7). This seems pretty trivial but I don't want to reinvent the wheel so I'm wondering if there's anything in the C/C++ standard libs that can already perform such an operation?</p>
","<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main(void) {
    char * ptr;
    long parsed = strtol(""11110111"", &amp; ptr, 2);
    printf(""%lX\n"", parsed);
    return EXIT_SUCCESS;
}
</code></pre>

<p>For larger numbers, there as a <code>long long</code> version, <code>strtoll</code>.</p>
","117870"
"Storing MySQL GUID/UUIDs","16961","","<p>This is the best way I could come up with to convert a MySQL GUID/UUID generated by UUID() to a binary(16):</p>

<pre><code>UNHEX(REPLACE(UUID(),'-',''))
</code></pre>

<p>And then storing it in a BINARY(16)</p>

<p>Are there any implications of doing it this way that I should know of?</p>
","<p>Not many implications. It will slow down the queries a little, but you will hardly notice it.</p>

<p><code>UNIQUEIDENTIFIER</code> is stored as <code>16-byte binary</code> internally anyway.</p>

<p>If you are going to load the binary into a client and parse it there, note the <code>bit order</code>, it may have other string representation than the initial <code>NEWID()</code>.</p>

<p><code>Oracle</code>'s <code>SYS_GUID()</code> function is prone to this issue, converting it to a string gives different results on client and on server.</p>
","547141"
"Converting list of integers into a binary ""string"" in python","16957","","<p>I have a list of numbers that i would like to send out onto a socket connection as binary data. </p>

<p>As an example, i start off with the following list:</p>

<pre><code>data = [2,25,0,0,ALPHA,0,23,18,188]
</code></pre>

<p>In the above list, <strong>ALPHA</strong> can be any value between 1 and 999. Initially, I was converting this into a string using</p>

<pre><code> hexdata = ''.join([chr(item) for item in data])
</code></pre>

<p>So if ALPHA is 101, this would return the following string:</p>

<pre><code>&gt;&gt;&gt; data = [2,25,0,0,101,0,23,18,188]
&gt;&gt;&gt; hexdata = ''.join([chr(item) for item in data])
&gt;&gt;&gt; hexdata
'\x02\x19\x00\x00e\x00\x17\x12\xbc'
</code></pre>

<p>This works just fine and '\x02\x19\x00\x00e\x00\x17\x12\xbc' is the string that i need to send out.</p>

<p>However, this does not work for values of ALPHA that are over 255 because its out of range of the chr statement. If for example ALPHA were 999, then i would like to get the following string:</p>

<pre><code>data = [2,25,0,0,999,0,23,18,188]
hexdata = '\x02\x19\x00\x03\xed\x00\x17\x12\xbc'
</code></pre>

<p>Ive been looking at the documentation on the struct.pack() but cannot see how that could be used to acheive the above string. ALPHA is the only variable in the list.</p>

<p>Any help would be greatly appreciated.</p>

<p><strong>EDIT 1</strong></p>

<blockquote>
  <p>What behavior do you want? Anything
  between 256 and 65535 takes 2 bytes to
  represent. Do you want to unpack it on
  the other side? Please update the post
  with your intent. – gahooa 1 min ago</p>
</blockquote>

<p>Thats correct, since 999 is over the 256 threshold, its represented by two bytes:</p>

<pre><code>data = [2,25,0,0,999,0,23,18,188]

hexdata = '\x02\x19\x00**\x03\xed**\x00\x17\x12\xbc'
</code></pre>

<p>Does this make sense? </p>

<p>As far as unpacking is concerned, im only sending this data out onto the socket, I will be receiving data but thats taken care of already.</p>

<p><strong>EDIT 2</strong></p>

<p>The string i send out is always fixed length. 
For simplicity, I think its better to represent the list as follows:</p>

<pre><code>ALPHA = 101

data = [25,alpha1,alpha2,1]
hexdata = '\x19\x00e\x01'


ALPHA = 301

data = [25,alpha1,alpha2,1]
hexdata = 'x19\x01\x2d\x01'
</code></pre>

<p>as you can see in the hexdata string, this then becomes: \x01\x2d\</p>

<p>If ALPHA &lt; 256, alpha1 = 0.</p>
","<p>You want to send a single byte for ALPHA if it's &lt; 256, but two bytes if >= 256?  This seems weird -- how is the receiver going to know which is the case...???</p>

<p>But, if this IS what you want, then</p>

<pre><code>x = struct.pack(4*'B' + 'HB'[ALPHA&lt;256] + 4*'B', *data)
</code></pre>

<p>is one way to achieve this.</p>
","1331227"
"Opening a File in C# using FileStream","16945","","<p>I am trying to open a Binary file that I plan on converting to hex  but I am running into issues with reading the file via FileStream, </p>

<pre><code>private void button1_Click(object sender, EventArgs e)
{
    openFD.Title = ""Insert a BIN file"";
    openFD.InitialDirectory = ""C:""; // Chooses the default location to open the file
    openFD.FileName = "" ""; // Iniitalizes the File name
    openFD.Filter = ""Binary File|*.bin|Text File|*.txt""; // FIlters the types of files allowed to by chosen

    if (openFD.ShowDialog() != DialogResult.Cancel)
    {
        chosenFile = openFD.FileName;
        string directoryPath = Path.GetDirectoryName(chosenFile); // Returns the directory and the file name to reference the file
        string dirName = System.IO.Path.GetDirectoryName(openFD.FileName); // Returns the proper directory with which to refernce the file 
        richTextBox1.Text += dirName;
        richTextBox1.Text += chosenFile;
        FileStream InputBin = new FileStream(
            directoryPath, FileMode.Open, FileAccess.Read, FileShare.None);
    }
}
</code></pre>

<p>I am receiving an error saying that the access to the path is denied, any ideas?</p>

<p>Now that I have gotten that error taken care of I have ran into another Issue, I can read the binary file, but I want to display it as a Hex file, I'm not sure what I am doing wrong but I'm not getting an output in HEX, it seems to be Int values...</p>

<pre><code>if (openFD.ShowDialog() != DialogResult.Cancel)
        {

            chosenFile = openFD.FileName;
            string directoryPath = Path.GetDirectoryName(chosenFile); 
            string dirName = System.IO.Path.GetDirectoryName(openFD.FileName);
            using (FileStream stream = new FileStream(chosenFile, FileMode.Open, FileAccess.Read))
            {
                size = (int)stream.Length;
                data = new byte[size];
                stream.Read(data, 0, size);
            }

            while (printCount &lt; size)
            {
                richTextBox1.Text += data[printCount];
                printCount++;
            }
</code></pre>
","<p>Your code is miscommented</p>

<pre><code>string directoryPath = Path.GetDirectoryName(chosenFile); // Returns the directory and the file name to reference the file
</code></pre>

<p>is not the filename, it's the directory path.  You want:</p>

<pre><code>FileStream InputBin = new FileStream(chosenFile, FileMode.Open,FileAccess.Read, FileShare.None);
</code></pre>

<p>Addtionally, if I were to guess based on your intentions, you should update your full function to be:</p>

<pre><code>private void button1_Click(object sender, EventArgs e)
{
    openFD.Title = ""Insert a BIN file"";
    openFD.InitialDirectory = ""C:""; // Chooses the default location to open the file
    openFD.FileName = "" ""; // Iniitalizes the File name
    openFD.Filter = ""Binary File|*.bin|Text File|*.txt""; // FIlters the types of files allowed to by chosen

    if (openFD.ShowDialog() != DialogResult.Cancel)
    {
        chosenFile = openFD.FileName;

        richTextBox1.Text += chosenFile; //You may want to replace this with = unless you mean to append something that is already there.

        FileStream InputBin = new FileStream(chosenFile, FileMode.Open,FileAccess.Read, FileShare.None);
    }
}
</code></pre>
","11637410"
"Storing hexadecimal values as binary in MySQL","16874","","<p>I was thinking about how I'm storing passwords in my database : appropriately salted SHA1 strings in a CHAR(40) field. However, since the character data in there is actually just a hex representation of a 160 bit number, I thought it might be better to store it as BINARY(20).</p>

<pre><code>CREATE TABLE users (
    password BINARY(20)
    /* snip */
);

INSERT INTO users (password) VALUES (UNHEX(SHA1('mypassword'));
</code></pre>

<p>As I see it, one benefit of this approach is that it halves the size of that field, but I can imagine there's probably some downsides too.</p>

<p>What's your opinion?</p>
","<p>We used binary for a ton of different ids in our database to save space, since the majority of our data consisted of these ids. Since it doesn't seem like you need to save space (as it's just passwords, not some other huge scale item), I don't see any reason to use binary here.</p>

<p>The biggest problem we ran into was constantly, annoyingly, having binary data show up in the console (everytime you type select * you hear a million beeps), and you have to always do select HEX() or insert UNHEX(), which is a pain.</p>

<p>Lastly, if you mix and match (by mistake) binary and HEX/UNHEX and join on this value, you could match records you never intended to.</p>
","1713083"
"error: struct has no member named X","16806","","<pre><code> #include &lt;stdio.h&gt;
 #include &lt;stdlib.h&gt;

 struct treeNode
 {
    *char word;
    int NumberCnt; 
    struct treeNode *rightPTR, *leftPTR; 

 };
 typedef struct treeNode node;

  node *rootPTR = NULL;

 void freeTree(node *currPTR)
 {
     if (currPTR!= NULL)
    {
        freeTree(currPTR -&gt; leftPTR);
        free(currPTR);
        freeTree(currPTR -&gt; rightPTR);
    }
 }

void printTree(node *currPTR)
{
    if (currPTR != NULL)
        {
            printTree(currPTR -&gt;leftPTR);   
            printf(""%d\n"", currPTR-&gt;word);
            printTree(currPTR -&gt;rightPTR);  
        }
}



int insertNode (char* input)
{

    node *tempPTR = malloc(sizeof(node));
    tempPTR -&gt; word = input;
    tempPTR -&gt; NumberCnt=0;
    tempPTR -&gt; leftPTR = NULL;
    tempPTR -&gt; rightPTR = NULL;

    if (rootPTR == NULL)
    {   
        rootPTR = tempPTR;
        rootPTR -&gt; NumberCnt++;
    }
     else 
    {
        int comp;
        node *currPTR = rootPTR;
        node *prevPTR = NULL;

            while (currPTR != NULL)
            {
                comp = strcmp(input, (currPTR-&gt;word));
                if (comp = 0)
                {
                    printf (""Entry already exists"");
                    return 1;   
                }
                else if (comp &lt; 0)
                {
                    prevPTR = currPTR;
                    currPTR = currPTR-&gt;leftPTR;
                }
                else if (comp &gt; 0)
                {
                    prevPTR = currPTR;
                    currPTR = currPTR-&gt;rightPTR;
                }

            }

        comp = strcmp(input, (prevPTR -&gt;word));
        if (comp &lt; 0)
        {
            prevPTR-&gt;leftPTR = tempPTR;

        }

        else if (comp &gt; 0)
        {
            prevPTR-&gt;rightPTR = tempPTR;

        }

        return 0;   
    }

    return 2;
}

int search(char* input) 
{
     if (input == rootPTR -&gt;data)
    {
        printf(""Node found %d\n"", rootPTR-&gt;data);
        return 0;
    }
    else
    {
        if (input &lt; rootPTR -&gt;data)
            {

                node *currPTR = rootPTR-&gt;leftPTR;

                while (currPTR != NULL)
                 {
                    if (input == currPTR-&gt;data)
                    {
                        printf(""Node found %d\n"", currPTR-&gt;data);
                         return 0;
                     }
                    else if (input &lt; currPTR-&gt;data)
                    {
                        currPTR = (currPTR -&gt; leftPTR); 
                    }
                    else if (input &gt; currPTR-&gt;data)
                    {
                        currPTR = (currPTR -&gt; rightPTR);
                     } 
                }
                printf (""Node not in tree\n"");
                return 1;
            }

             if (input &gt; rootPTR -&gt;data)
            {

                node *currPTR = rootPTR-&gt;rightPTR;

                while (currPTR != NULL)
                {

                    if (input == currPTR-&gt;data)
                    {
                        printf (""Node found %d\n"", currPTR-&gt;data);
                        return 0;
                    }

                    else if (input &lt; currPTR-&gt;data)
                    {
                        currPTR = (currPTR -&gt; leftPTR); 
                    } 

                    else if (input &gt; currPTR-&gt;data)
                    {
                        currPTR = (currPTR -&gt;rightPTR);
                    }
                }
                printf (""Node not in tree\n"");
                return 1;
            }

    }

return 2;
}

void fixWord(char* buff)
{
    char* unfixed = buff;
    char* fixed = buff;

    while (*unfixed)
    {

            if (isalpha(*unfixed))
        {
            *fixed=tolower(*unfixed);
                *fixed++;

        }   
            *unfixed++;


    }
    *fixed=0;

}


int main()
{   
    FILE *ptr_file;
    char buff [100];
  //ptr_file = fopen (""sherlock.txt"", ""r"");
    ptr_file = fopen (""input.txt"", ""r"");
    if (!ptr_file)
        printf(""File read error"");


        while(fscanf(ptr_file, ""%s "", buff ) != EOF)
        {
            int comparison = strcmp(buff, ""endoffile"");
            if (comparison == 0)
            {
                return 0;
            }

             fixWord(buff);
             insert(buff);
        }

    fclose(ptr_file);

}
</code></pre>

<p>I have this code which is a binary tree which reads in text from a file and then adds it to a binary tree. I have a struct to represent a new node which takes in a string and a integer which increments to show word count. I originally had this tree set up to take in integers to test the tree functionality and it worked just fine, however since updating my struct to take in the string and the incremented integer the compiler is complaining the struct does not longer contains any of the members of the struct. I have no idea why this happening.  </p>
","<p>Look at the <em>first</em> error message of the compiler. It should complain about the <code>*char</code> in line 6, which should be <code>char *</code>.</p>

<p>By the way: always copy and paste error messages, so that we get the original messages.</p>
","20033591"
"Regex for binary multiple of 3","16791","","<p>I would like to know how can I construct a regex to know if a number in base 2 (binary) is multiple of 3. I had read in this thread <a href=""https://stackoverflow.com/questions/844867/check-if-a-number-is-divisible-by-3"">Check if a number is divisible by 3</a> but they dont do it with a regex, and the graph someone drew is wrong(because it doesn't accept even numbers). I have tried with: ((1+)(0*)(1+))<em>(0</em>) but it doesn't works for some values. Hope you can help me.</p>

<p>UPDATE:
Ok, thanks all for your help, now I know how to draw the NFA, here I left the graph and the regular expresion:</p>

<p>In the graph, the states are the number in base 10 mod 3.</p>

<p>For example: to go to state 1 you have to have 1, then you can add 1 or 0, if you add 1, you would have 11(3 in base 10), and this number mod 3 is 0 then you draw the arc to the state 0.</p>

<p><img src=""https://i.stack.imgur.com/5wqTS.png"" alt=""Whiteboard version""></p>

<p><code>((0*)((11)*)((1((00) *)1) *)(101 *(0|((00) *1 *) *0)1) *(1(000)+1*01)*) *</code></p>

<p>And the other regex works, but this is shorter.</p>

<p>Thanks a lot :)</p>
","<p>If I may plug my solution for <a href=""https://codegolf.stackexchange.com/questions/3503/hard-code-golf-regex-for-divisibility-by-7/3580#3580"">this code golf question</a>! It's a piece of JavaScript that generates regexes (probably inefficiently, but does the job) for divisibility for each base.</p>

<p>This is what it generates for divisibility by 3 in base 2:</p>

<p><code>/^((((0+)?1)(10*1)*0)(0(10*1)*0|1)*(0(10*1)*(1(0+)?))|(((0+)?1)(10*1)*(1(0+)?)|(0(0+)?)))$/</code></p>

<p><s>Edit: comparing to Asmor's, probably <em>very</em> inefficient :)</s></p>

<p>Edit 2: Also, this is a duplicate of <a href=""https://stackoverflow.com/questions/867279/regular-expression-to-define-some-binary-sequence"">this question</a>.</p>
","7974713"
"Convert string to binary zeros and ones","16776","","<p>I want to convert string to binary and I tried this code </p>

<pre><code>byte[] arr = System.Text.Encoding.ASCII.GetBytes(aa[i]);
</code></pre>

<p>and this </p>

<pre><code>System.Text.ASCIIEncoding encoding = new System.Text.ASCIIEncoding();
byte[] arr= encoding.GetBytes(aa[i]);
</code></pre>

<p>but it returned numbers not binary
say If I write 'm' it convert it to ""0109""
and I want to convert to zeros &amp; Ones only
Thanks in advance </p>
","<p>Here is an example:</p>

<pre><code>foreach (char c in ""Test"")
    Console.WriteLine(Convert.ToString(c, 2).PadLeft(8, '0'));
</code></pre>
","16660105"
"PHP: Simple, Validate if string is hex?","16689","","<p>I have no clue how to validate this string. I am simply supplying an IV for an encryption, but can find no 1is_hex()1 or similar function, I can’t wrap my head around it! I read on a comment in the php documentation (user contrib. notes) this:</p>

<pre><code>if($iv == dechex(hexdec($iv))) {
  //True
} else {
  //False
}
</code></pre>

<p>But that doesn't seem to work at all.. It only says false.
If it helps my input of my IV would be this:</p>

<pre><code>92bff433cc639a6d
</code></pre>
","<p>Use function :  <a href=""http://php.net/ctype_xdigit"" rel=""noreferrer"">ctype_xdigit</a> </p>

<pre><code>&lt;?php
$strings = array('AB10BC99', 'AR1012', 'ab12bc99');
foreach ($strings as $testcase) {
    if (ctype_xdigit($testcase)) {
        echo ""The string $testcase consists of all hexadecimal digits.\n"";
    } else {
        echo ""The string $testcase does not consist of all hexadecimal digits.\n"";
    }
}
?&gt; 
</code></pre>

<p>The above example will output:</p>

<ul>
<li>The string <code>AB10BC99</code> consists of all hexadecimal digits.</li>
<li>The string <code>AR1012</code> does not consist of all hexadecimal digits.</li>
<li>The string <code>ab12bc99</code> consists of all hexadecimal digits.</li>
</ul>
","2643191"
"Java - Is binary code the same as ByteCode?","16684","","<p>In Java, does ""binary code"" means the same as ""Java bytecode?""</p>

<p>Is this the flow in Java ?  </p>

<blockquote>
  <p>Java File (.java) -> [javac] ->
  ByteCode File (.class) -> [JVM/Java
  Interpreter] -> Running it(by first
  converting it into binary code
  specific to the machine)</p>
</blockquote>

<p>Thanks!</p>
","<p>The answer depends on what you mean by <strong><code>binary code</code></strong>.</p>

<p><em><strong><code>Java bytecode</code></em></strong> is a binary data format that includes loading information and execution instructions for the Java virtual machine.  In that sense, <strong><em><code>Java bytecode</code></em></strong> is a special kind of <strong>binary code</strong>.</p>

<p>When you use the term ""<strong>binary code</strong>"" to mean machine instructions for a real processors architecture (like IA-32 or Sparc) then it is different.<br>
<strong><em><code>Java bytecode</code></em></strong> is not a <strong>binary code</strong> in that sense.  It is not processor-specific.  </p>
","4841094"
"Convert hex to binary in MySQL","16676","","<p>Currently I search a function in MySQL to do conversion between hex string to binary representation, example:</p>

<pre><code>0000 -&gt; 0000000000000000
00AA -&gt; 0000000010101010
FFFF -&gt; 1111111111111111
</code></pre>

<p>I have already tried</p>

<pre><code>UNHEX('00AA')
CAST('00AA' AS BINARY)
CONVERT('00AA', BINARY)
</code></pre>

<p>but didn't get the results I want.</p>
","<p>Use <code>CONV()</code> function:</p>

<pre><code>CONV(string, 16, 2)
</code></pre>

<p>To have length according to input:</p>

<pre><code>LPAD(CONV(string, 16, 2), LENGTH(string)*4, '0')
</code></pre>

<p>As <code>CONV()</code> works with 64-bit precision, you can't have more than 64 bits converted, so you can use this as well:</p>

<pre><code>LPAD(CONV(string, 16, 2), 64, '0')
</code></pre>

<p>and you should check that <code>LENGTH(string) &lt;= 16</code> or you may get erroneous results. </p>
","5699482"
"How to seek and append to a binary file in python?","16621","","<p>I am having problems appending data to a binary file. When i seek() to a location, then write() at that location and then read the whole file, i find that the data was not written at the location that i wanted. Instead, i find it right after every other data/text.</p>

<p>My code</p>

<pre><code>file = open('myfile.dat', 'wb')
file.write('This is a sample')
file.close()

file = open('myfile.dat', 'ab')
file.seek(5)
file.write(' text')
file.close()

file = open('myfile.dat', 'rb')
print file.read()

#prints: This is a sample **text**
</code></pre>

<p>You can see that the seek does not work. How do i resolve this, are there other ways of achieving this?</p>

<p>Thanks</p>
","<p>On some systems, <code>'ab'</code> forces all writes to happen at the end of the file. You probably want <code>'r+b'</code>.</p>
","4388244"
"Integer array to binary array","16615","","<p>I have an integer array:</p>

<pre><code>a=[3,4,5,6,7];
</code></pre>

<p>I want to convert it to a binary array with four bits each. For the above integer array I would like get the following binary array:</p>

<pre><code>abinary=[0,0,1,1, 0,1,0,0, 0,1,0,1, 0,1,1,0, 0,1,1,1];
</code></pre>

<p>Is there any fast way to do it?</p>
","<p>Matlab has the built-in function <a href=""http://www.mathworks.com/access/helpdesk/help/techdoc/ref/dec2bin.html"" rel=""noreferrer"">DEC2BIN</a>. It creates a character array, but it's easy to turn that back to numbers.</p>

<pre><code>%# create binary string - the 4 forces at least 4 bits
bstr = dec2bin([3,4,5,6,7],4)

%# convert back to numbers (reshape so that zeros are preserved)
out = str2num(reshape(bstr',[],1))'
</code></pre>
","2687738"
"Processing binary data in Web API from a POST or PUT REST request","16563","","<p>I'm currently developing a <strong>REST</strong> web service using <strong>Web API</strong>. I have encountered a problem processing <strong>binary data</strong> (an image) that has been transmitted via a POST request.</p>

<p>From the perspective of the client, I have managed to send binary data using the <strong>jQuery Form Plugin</strong>. But because I'm very new to .NET (I'm a PHP developer), I'm having difficulty processing this binary data via Web API on the server.</p>

<p>To confirm that the jQuery Form Plugin is sending the image data correctly, I have written a working <strong>PHP</strong> handler that makes use of the simple <code>$_FILE</code> global variable.</p>

<p>Now I am trying to accomplish the same via Web API. Here is an outline of what I have tried. How do I access the binary data that has been sent?</p>

<p><strong>Model:</strong></p>

<pre><code>namespace EDHDelivery.Models
{
    public class Oferta
    {
        public int OfertaID { get; set; }
        public string Nombre { get; set; }
        public string Imagen { get; set; }
        public int ComercioID { get; set; }
    }
}
</code></pre>

<p><strong>Controller (partial code shown):</strong></p>

<pre><code>public Oferta Add(Oferta item)
{
    /*here my item will have the POST body with form values, 
    automatically serialized by the framework and I think an image binary*/
    var n = item.Nombre; //...etc.
}
</code></pre>
","<p>In short, you have to send the data as <code>multipart/form-data</code> (which, I'm pretty sure, you are already doing through the plugin you mentioned) and then you have to extract that data using one of Web API <code>MultipartContent</code> providers.</p>

<p>There are plenty of resources explaining how to that:</p>

<ul>
<li><a href=""http://www.asp.net/web-api/overview/working-with-http/sending-html-form-data,-part-2"" rel=""noreferrer"">File Upload and Multipart MIME</a></li>
<li><a href=""http://code.msdn.microsoft.com/ASPNET-Web-API-File-Upload-a8c0fb0d"" rel=""noreferrer"">ASP.NET Web API: File Upload and Multipart MIME</a></li>
<li><a href=""http://www.strathweb.com/2012/08/a-guide-to-asynchronous-file-uploads-in-asp-net-web-api-rtm/"" rel=""noreferrer"">A guide to asynchronous file uploads in ASP.NET Web API RTM</a></li>
</ul>
","14742134"
"Getting Image size of JPEG from its binary","16507","","<p>I have a lot of jpeg files with varying image size. For instance, here is the first 640 bytes as given by hexdump of an image of size 256*384(pixels):</p>

<pre><code>0000000: ffd8 ffe0 0010 4a46 4946 0001 0101 0048  ......JFIF.....H
0000010: 0048 0000 ffdb 0043 0003 0202 0302 0203  .H.....C........
0000020: 0303 0304 0303 0405 0805 0504 0405 0a07  ................
0000030: 0706 080c 0a0c 0c0b 0a0b 0b0d 0e12 100d  ................
</code></pre>

<p>I guess the size information mus be within these lines. But am unable to see which bytes give the sizes correctly. Can anyone help me find the fields that contains the size information?</p>
","<p>According to the <a href=""http://en.wikipedia.org/wiki/Jpeg#Syntax_and_structure"" rel=""noreferrer"">Syntax and structure</a> section of the <a href=""http://en.wikipedia.org/wiki/Jpeg"" rel=""noreferrer"">JPEG page on wikipedia</a>, the width and height of the image don't seem to be stored in the image itself -- or, at least, not in a way that's quite easy to find.</p>

<p><br>
Still, quoting from <a href=""http://www.faqs.org/faqs/jpeg-faq/part1/"" rel=""noreferrer"">JPEG image compression FAQ, part 1/2</a> :</p>

<blockquote>
  <p><strong>Subject: [22] How can my program extract image dimensions from a JPEG
  file?</strong></p>
  
  <p>The header of a JPEG file consists of
  a series of blocks, called ""markers"".
  <strong>The image height and width are stored
  in a marker of type SOFn</strong> <em>(Start Of
  Frame, type N)</em>.  <br>To find the SOFn
  you must skip over the preceding
  markers; you don't have to know what's
  in the other types of markers, just
  use their length words to skip over
  them.  <br>The minimum logic needed is
  perhaps a page of C code.  <br><em>(Some
  people have recommended just searching
  for the byte pair representing SOFn,
  without paying attention to the marker
  block structure. This is unsafe
  because a prior marker might contain
  the SOFn pattern, either by chance or
  because it contains a JPEG-compressed
  thumbnail image.  If you don't follow
  the marker structure you will retrieve
  the thumbnail's size instead of the
  main image size.)</em>  <br>A profusely
  commented example in C can be found in
  rdjpgcom.c in the IJG distribution
  (see part 2, item 15).  <br>Perl code
  can be found in wwwis, from
  <a href=""http://www.tardis.ed.ac.uk/~ark/wwwis/"" rel=""noreferrer"">http://www.tardis.ed.ac.uk/~ark/wwwis/</a>.</p>
</blockquote>

<p><em>(Ergh, that link seems broken...)</em></p>

<p><br>
Here's a portion of C code that could help you, though : <a href=""http://www.64lines.com/jpeg-width-height"" rel=""noreferrer"">Decoding the width and height of a JPEG (JFIF) file</a></p>
","2517888"
"Missing Localized Screenshots Error on itunes","16393","","<p>I have selected Default Language as ""Australian English"" as Default language. When I am submitting the binary it showing as rejected""Red Icon"" with status ""Missing Localized Screenshots"". The application is in only single language. I have added screen shots also the application is only for iphone.</p>

<p>When I am looking binary information that is showing as:</p>

<p>Localizations :     ( ""en-AU"" )</p>

<p>Please suggest me where I am making mistake.</p>
","<p>Check if you have screenshots for iPhone 5. I had this same error, when screenshots for iP5 were missing.</p>
","12760736"
"Writing unsigned chars to a binary file using write()","16329","","<p>I was making a program that read binary files. So, I read the individual bytes into unsigned chars (actually reading the data as chars and casting them to unsigned chars for each character). Now I have to write back the unsigned chars to the binary file.</p>

<p>The problem is that now I am forced to write individual bytes after casting them to chars (because write() for binary files expects char* buffer). So, now i have to do the following:</p>

<pre><code>for(int x=0; x&lt;data_size; x++)
{
    ch=(char)data[x];
    outfile.write(&amp;ch,1);
}
</code></pre>

<p>Is there any way to get around this thing so that the amount of I/O operations are reduced in case of reading and writing?</p>
","<p>You can do the casting on a pointer...</p>

<pre><code>outfile.write((char *)&amp;data[0], data_size);
</code></pre>

<p>the same can be done for reading (i.e. just pass a pointer to the first element of an array of unsigned char casting it to a pointer to char).</p>
","6996042"
"how to make my python script easy portable? or how to compile into binary with all module dependencies?","16320","","<p>Is there any way to compile python script into binary?
I have one file python script which uses a lot of modules.
What I would like is to have its copy on other machines (freebsd) but without installing all needed modules on every host.</p>

<p>What are possible solutions in such cases?</p>

<p>Thanks in advance! </p>
","<p>Programs that can do what you ask for are:</p>

<ul>
<li>PyInstaller: <a href=""http://www.pyinstaller.org/"">http://www.pyinstaller.org/</a> [Windows, Linux, OS X]</li>
<li>cx_freeze: <a href=""http://cx-freeze.sourceforge.net/"">http://cx-freeze.sourceforge.net/</a> [Windows, Linux]</li>
<li>py2exe: <a href=""http://www.py2exe.org/"">http://www.py2exe.org/</a> [Windows]</li>
<li>py2app: <a href=""http://svn.pythonmac.org/py2app/py2app/trunk/doc/index.html"">http://svn.pythonmac.org/py2app/py2app/trunk/doc/index.html</a> [os x]</li>
</ul>

<p>But as mentioned you can also create a Package with Distribute and have the other packages as dependencies. You can then uses <code>pip</code> to install that package, and it will install all of the packages. You still need to install Python and pip, though.</p>
","4558781"
"Fixing my implementation of ""inorder tree traversal"" algorithm with a Stack","16284","","<p>Part of it is that I have to implement a non-recursive method of a inorder traversal of a binary tree. I am kind of stuck. Here is what I have so far:</p>



<pre><code>public void inorder(BinaryTree v) {
    Stack&lt;BinaryTree&gt; stack = new Stack&lt;BinaryTree&gt;();
    stack.push(v);
    System.out.println(v.getValue());

    while(!stack.isEmpty()) {
        while(v.getLeft() != null) {
            v = v.getLeft();
            stack.push(v);
            System.out.println(v.getValue());
        }

        while(v.getRight() != null) {
            v = v.getRight();
            stack.push(v);
            System.out.println(v.getValue());
        }
                stack.pop();
    }
}
</code></pre>

<p>I noticed that it only prints out the left side of my tree, e.g.</p>

<pre><code>          A
        /   \
       B     C
     /   \  /  \
    D     E F   G
   /  \
  H     I
 / \
J   K
</code></pre>

<p>Gives <code>A B D H J</code></p>
","<p>Following your code, the while loop for the <code>getLeft()</code> part goes all the way down the left of the tree, then exits.  <code>v</code> is now node <code>J</code>, which has no right child so the next while loop doesn't run.</p>

<p>Try this code example: <a href=""http://www.ashishsharma.me/2011/09/inorder-traversal-without-recursion.html"" rel=""nofollow noreferrer"">http://www.ashishsharma.me/2011/09/inorder-traversal-without-recursion.html</a></p>

<p>StackOverflow answer: <a href=""https://stackoverflow.com/a/12718147/1178781"">https://stackoverflow.com/a/12718147/1178781</a></p>

<pre class=""lang-java prettyprint-override""><code>// Inorder traversal:
// Keep the nodes in the path that are waiting to be visited
Stack s = new Stack(); 
// The first node to be visited is the leftmost
Node node = root;
while (node != null)
{
    s.push(node);
    node = node.left;
}
// Traverse the tree
while (s.size() &gt; 0)
{
    // Visit the top node
    node = (Node)s.pop();
    System.out.println((String)node.data);
    // Find the next node
    if (node.right != null)
    {
        node = node.right;
        // The next node to be visited is the leftmost
        while (node != null)
        {
            s.push(node);
            node = node.left;
        }
    }
}
</code></pre>
","15375665"
"decompile an app binary to get back to source code","16230","","<p>Is there anyway to take a binary - even signed by yourself, and get back to the code? I'm trying to recover something that I deleted a while ago... but have the binary here. </p>

<p>Any ideas?</p>
","<p>You can disassemble a binary and get back assembly source, but there is no way to get back your original Objective-C structured source code.</p>

<hr>

<p><strong>EDIT:</strong>
You may want to give <a href=""http://hopperapp.com/"" rel=""noreferrer"">Hopper</a> a try. I didn't try it personally yet but <a href=""http://www.mikeash.com/pyblog/friday-qa-2012-01-06-the-hopper-disassembler.html"" rel=""noreferrer"">Mike Ash says it's good</a>.</p>
","2661737"
"C: send file to socket","16103","","<p>I`m trying to send binary file using socket.</p>

<pre><code>        FILE *file;
        char *file_data;
        file = fopen(filepath, ""rb"");

        //Allocate memory
        file_data=(char *)malloc(fileLen+1);

        //Read file contents into buffer
        fread(file_data, fileLen, 1, file);
        fclose(file);

        sent = send(client, file_data, strlen(header)+fileLen, 0);
</code></pre>

<p>It works OK, but some files a too large and I want to read a part to buffer, send it, then read the second part, send it and so on.</p>

<p>I tried to get parts using fread and fgets, but i failed =( How to do it correctly?</p>

<p>UPD: the trouble was in reading incoming request from client. I didnt read it. If i do it, nothing bad happens</p>
","<p>the trouble was in reading incoming request from client. I didnt read it. If i do it, nothing bad happens</p>
","9686458"
"Convert integer to zero-padded binary string","16092","","<p>when converting int to binary, how to output it to 8 character, currently it only display 1 and short of the 7 zeros</p>

<h2>code</h2>

<pre><code>int x = 1;
String bin = Integer.toBinaryString(x);
System.Out.Println(bin);
</code></pre>

<p>example output to 0000 0001</p>
","<p>I am not sure if that is what you mean but how about something like</p>

<pre><code>String.format(""%8s"", Integer.toBinaryString(1)).replace(' ', '0')
</code></pre>

<p>will generate <code>00000001</code></p>
","21856765"
"JavaScript converting decimal to binary","16073","","<p>From my understanding the binary number system uses as set of two numbers, 0's and 1's to perform calculations.</p>

<p>Why does:</p>

<p><code>console.log(parseInt(""11"", 2));</code> return <code>3</code> and not <code>00001011</code>?
<a href=""http://www.binaryhexconverter.com/decimal-to-binary-converter"" rel=""noreferrer"">http://www.binaryhexconverter.com/decimal-to-binary-converter</a></p>
","<p><code>parseInt(number, base)</code> returns <strong>decimal</strong> value of a number presented by <code>number</code> parameter in <code>base</code> base.</p>

<p>And 11 is 3 in binary number system.</p>
","31126405"
"How to get path of the php binary on server where it is located","16050","","<p>I am using the <code>exec</code> command as below in PHP :</p>

<pre><code>exec(""/usr/bin/php /path/to/Notification.php &gt;&gt; /path/to/log_file.log 2&gt;&amp;1 &amp;"");
</code></pre>

<p>In my local environment (MAMP), I know the PHP installation path, so I can replace <code>/usr/bin/php</code> with <code>/Applications/MAMP/bin/php/php5.4.10/bin/php</code>. But I don't know where the PHP installation (PHP binary) is located on the production server.</p>
","<p>It's usually <code>/usr/bin/php</code> but you could try to capture and parse the output of the command '<code>whereis php</code>' or '<code>which php'</code>'.</p>

<p>Or better yet, use the constant <code>PHP_BINARY</code> if it is available. Have a look <a href=""http://php.net/manual/en/reserved.constants.php"" rel=""noreferrer"">here</a>.</p>
","18656780"
"Python 2.x - Write binary output to stdout?","16033","","<p>Is there any way to write binary output to sys.stdout in Python 2.x? In Python 3.x, you can just use sys.stdout.buffer (or detach stdout, etc...), but I haven't been able to find any solutions for Python 2.5/2.6. </p>

<p>EDIT, <strong>Solution</strong>:
From ChristopheD's link, below:</p>

<pre><code>import sys

if sys.platform == ""win32"":
    import os, msvcrt
    msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)
</code></pre>

<p>EDIT: I'm trying to push a PDF file (in binary form) to stdout for serving up on a web server. When I try to write the file using sys.stdout.write, it adds all sorts of carriage returns to the binary stream that causes the PDF to render corrupt.</p>

<p>EDIT 2: For this project, I need to run on a Windows Server, unfortunately, so Linux solutions are out.</p>

<p>Simply Dummy Example (reading from a file on disk, instead of generating on the fly, just so we know that the generation code isn't the issue):</p>

<pre><code>file = open('C:\\test.pdf','rb') 
pdfFile = file.read() 
sys.stdout.write(pdfFile)
</code></pre>
","<p>Which platform are you on?</p>

<p>You could try <a href=""http://code.activestate.com/recipes/65443-sending-binary-data-to-stdout-under-windows/"" rel=""noreferrer"">this recipe</a> if you're on Windows (the link suggests it's Windows specific anyway).</p>

<pre><code>if sys.platform == ""win32"":
    import os, msvcrt
    msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)
</code></pre>

<p>There are some references on the web that there would/should be a function in Python 3.1 to reopen <code>sys.stdout</code> in binary mode but I don't really know if there's a better alternative then the above for Python 2.x.</p>
","2374507"
"Converting from an integer to its binary representation","16019","","<p>Has anyone got an idea if there is any inbuilt functionality in Go for converting from any one of the numeric types to its binary number form.</p>

<p>For example, if <code>123</code> was the input, the string <code>""1111011""</code> would be the output.</p>
","<p>The <code>strconv</code> package has <code>FormatInt</code>, which accepts an <code>int64</code> and lets you specify the base.</p>

<pre><code>n := int64(123)

fmt.Println(strconv.FormatInt(n, 2)) // 1111011
</code></pre>

<p><em><strong>DEMO:</em></strong> <a href=""http://play.golang.org/p/leGVAELMhv"">http://play.golang.org/p/leGVAELMhv</a></p>

<blockquote>
  <p><a href=""http://golang.org/pkg/strconv/#FormatInt"">http://golang.org/pkg/strconv/#FormatInt</a></p>
  
  <p><code>func FormatInt(i int64, base int) string</code></p>
  
  <p>FormatInt returns the string representation of i in the given base, for 2 &lt;= base &lt;= 36. The result uses the lower-case letters 'a' to 'z' for digit values >= 10. </p>
</blockquote>
","13870865"
"Math.Pow gives ""Cannot implicitly convert type 'double' to 'float' "" error","16003","","<p>In this program I am trying to create a simple calculator. However, I can't seem to find a way to overcome the aforementioned error when reaching the <code>Math.Pow</code> line. </p>

<pre><code>namespace BinaryCalc
{
    class Binary
    {
        public static void Main()
        {

        int addition,subtraction;
        float division, multiplication, power, sqrt;

        int x;
        int y;
        x = 10;
        y = 7;

        //Console.WriteLine(""Please enter a number for x"");
        //string line = Console.ReadLine();
        //int x = int.Parse(line);

        //Console.WriteLine(""Please enter a number for y"");
        //string line2 = Console.ReadLine();
        //int y = int.Parse(line2);


        addition = (int)x + (int)y;
        subtraction = (int)x - (int)y;
        division = (float)x / (float)y;
        multiplication = (float)x * (float)y;

        power = Math.Pow(x,2);
        sqrt = Math.Sqrt(x);


        Console.WriteLine("" Addition results in {0}"", addition);
        Console.WriteLine("" Subtraction results in {0}"", subtraction);
        Console.WriteLine("" Division results in {0}"", division);
        Console.WriteLine("" Multiplication results in {0}"", multiplication);
        Console.WriteLine("" {0} squared results in {0}"",x, power);
        Console.WriteLine("" Square root of {0} is: {0}"", x, sqrt);

        }
    }
}
</code></pre>
","<p>Math.Pow uses a <code>double</code> argument. As the error says, there is no <em>implicit</em> conversion from <code>double</code> to <code>float</code>, so convert the result <em>explicitly</em> to float: </p>

<pre><code>power = (float)Math.Pow(x, 2);
</code></pre>

<p><strong>EDIT</strong><br>
corrected the conversion order</p>
","4584825"
"Parsing a binary file. What is a modern way?","15690","","<p>I have a binary file with some layout I know. For example let format be like this:</p>

<ul>
<li>2 bytes (unsigned short) - length of a string</li>
<li>5 bytes (5 x chars) - the string - some id name</li>
<li>4 bytes (unsigned int) - a stride</li>
<li>24 bytes (6 x float - 2 strides of 3 floats each) - float data</li>
</ul>

<p>The file should look like (I added spaces for readability):</p>

<pre><code>5 hello 3 0.0 0.1 0.2 -0.3 -0.4 -0.5
</code></pre>

<p>Here 5 - is 2 bytes: 0x05 0x00. ""hello"" - 5 bytes and so on.</p>

<p>Now I want to read this file. Currently I do it so:</p>

<ul>
<li>load file to <strong>ifstream</strong></li>
<li>read this stream to <code>char buffer[2]</code> </li>
<li>cast it to unsigned short: <code>unsigned short len{ *((unsigned short*)buffer) };</code>. Now I have length of a string.</li>
<li>read a stream to <code>vector&lt;char&gt;</code> and create a <code>std::string</code> from this vector. Now I have string id.</li>
<li>the same way read next 4 bytes and cast them to unsigned int. Now I have a stride.</li>
<li>while not end of file read floats the same way - create a <code>char bufferFloat[4]</code> and cast <code>*((float*)bufferFloat)</code> for every float.</li>
</ul>

<p>This works, but for me it looks ugly. Can I read directly to <code>unsigned short</code> or <code>float</code> or <code>string</code> etc. without <code>char [x]</code> creating? If no, what is the way to cast correctly (I read that style I'm using - is an old style)?</p>

<p>P.S.: while I wrote a question, the more clearer explanation raised in my head - how to cast arbitrary number of bytes from arbitrary position in <code>char [x]</code>?</p>

<p>Update: I forgot to mention explicitly that string and float data length is not known at compile time and is variable.</p>
","<p>The C way, which would work fine in C++, would be to declare a struct:</p>

<pre><code>#pragma pack(1)

struct contents {
   // data members;
};
</code></pre>

<p>Note that</p>

<ul>
<li>You need to use a pragma to make the compiler align the data <em>as-it-looks</em> in the struct;</li>
<li>This technique only works with <a href=""https://stackoverflow.com/questions/146452/what-are-pod-types-in-c"">POD types</a></li>
</ul>

<p>And then cast the read buffer directly into the struct type:</p>

<pre><code>std::vector&lt;char&gt; buf(sizeof(contents));
file.read(buf.data(), buf.size());
contents *stuff = reinterpret_cast&lt;contents *&gt;(buf.data());
</code></pre>

<p>Now if your data's size is variable, you can separate in several chunks. To read a single binary object from the buffer, a reader function comes handy:</p>

<pre><code>template&lt;typename T&gt;
const char *read_object(const char *buffer, T&amp; target) {
    target = *reinterpret_cast&lt;const T*&gt;(buffer);
    return buffer + sizeof(T);
}
</code></pre>

<p>The main advantage is that such a reader can be specialized for more advanced c++ objects:</p>

<pre><code>template&lt;typename CT&gt;
const char *read_object(const char *buffer, std::vector&lt;CT&gt;&amp; target) {
    size_t size = target.size();
    CT const *buf_start = reinterpret_cast&lt;const CT*&gt;(buffer);
    std::copy(buf_start, buf_start + size, target.begin());
    return buffer + size * sizeof(CT);
}
</code></pre>

<p>And now in your main parser:</p>

<pre><code>int n_floats;
iter = read_object(iter, n_floats);
std::vector&lt;float&gt; my_floats(n_floats);
iter = read_object(iter, my_floats);
</code></pre>

<p><strong>Note:</strong> As Tony D observed, even if you can get the alignment right via <code>#pragma</code> directives and manual padding (if needed), you may still encounter incompatibility with your processor's alignment, in the form of (best case) performance issues or (worst case) trap signals. This method is probably interesting only if you have control over the file's format.</p>
","26845612"
"Convert from a binary to char in C","15674","","<p>I'm flummoxed by how to convert from a binary value to a char in c. </p>

<p>For example, let's say I have 01010110 and want to print the corresponding letter 'V' from that. How do I do this? </p>

<p>Thanks for any help! </p>
","<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
int main(void)
{
    char *data = ""01010110"";
    char c = strtol(data, 0, 2);
    printf(""%s = %c = %d = 0x%.2X\n"", data, c, c, c);
    return(0);
}
</code></pre>

<p>Output:</p>

<pre><code>01010110 = V = 86 = 0x56
</code></pre>

<p>References:</p>

<ul>
<li><a href=""http://pubs.opengroup.org/onlinepubs/9699919799/functions/strtol.html"" rel=""nofollow noreferrer""><code>strtol()</code></a></li>
<li><a href=""https://stackoverflow.com/questions/14176123"">Correct usage of <code>strtol()</code></a></li>
</ul>
","10825280"
"What is the best format to store images in a database?","15642","","<p>What is the best format to store images in a database, such as binary,base64...etc, for optimal speed/size.</p>
","<p>Binary.</p>

<p>Other than that, it's up to the uses of the images (quality, compression, etc.) in terms of whether you choose PNG, GIF, JPEG, TIFF, etc.</p>

<p>The use case will (should) drive the format more than the database.</p>
","522964"
"faster than binary search for ordered list","15629","","<p>is there an algorithm that is faster than binary search, for searching in sorted values of array?</p>

<p>in my case, I have a sorted values (could be any type values) in an <code>A</code> array, I need to return <code>n</code> if the value I was looking is in range of <code>A[n] and A[n+1]</code></p>
","<p>You can do better than O(log n) if the values are integers, in which case the best worst-case running time you can achieve, in terms of n, is O(sqrt(log n)). Otherwise, there is no way to beat O(log n) unless there are patterns in the input sequence. There are two approaches used to beat O(log n) in the case of integers.</p>

<p>First, you can use y-fast trees which work by storing in a hash table all prefixes for which you are storing at least one integer with that prefix. This enables you to perform a binary search to find the length of the longest matching prefix. This enables you to find the successor of an element for which you are searching in time O(log w) where w is the number of bits in a word. There are some details to work though to make this work and use only linear space, but they aren't too bad (see the link below).</p>

<p>Second, you can use fusion trees, which use bit tricks to enable you to perform w^O(1) comparisons in just a constant number of instructions, yielding a running time of O(log n / log w).</p>

<p>The optimum tradeoff between these two data structures occurs when log w = sqrt(log n), giving a running time of O(sqrt(log n)).</p>

<p>For details on the above, see lectures 12 and 13 of Erik Demaine's course: <a href=""http://courses.csail.mit.edu/6.851/spring07/lec.html"" rel=""noreferrer"">http://courses.csail.mit.edu/6.851/spring07/lec.html</a></p>
","4057372"
"Can someone explain to me the pack() function in PHP?","15599","","<p>I would like to know more about the pack() function in PHP: <a href=""http://fi.php.net/manual/en/function.pack.php"" rel=""noreferrer"">http://fi.php.net/manual/en/function.pack.php</a></p>

<p>I know it packs data into binary, but I'm not sure what all those v V n N c C mean and I was wondering if someone could be kind and give me a practical demonstration when to use which formats?</p>

<p>The online documentation, for change, lacks of information, in my opinion.</p>
","<p>Those represent how you want the data you are packing to be represented in binary format:</p>

<p>so </p>

<p><code>$bin = pack(""v"", 1);  =&gt;  0000000000000001</code>   (16bit)</p>

<p>where </p>

<p><code>$bin = pack(""V"", 1)   =&gt; 00000000000000000000000000000001</code>   (32 bit)</p>

<p>It tells pack how you want the data represented in the binary data.
The code below will demonstrate this.  Note that you can unpack with a different
format from what you packed the data as.  </p>

<pre><code>&lt;?php

$bin = pack(""S"", 65535);
$ray = unpack(""S"", $bin);
echo ""UNSIGNED SHORT VAL = "", $ray[1], ""\n"";

$bin = pack(""S"", 65536);
$ray = unpack(""S"", $bin);
echo ""OVERFLOW USHORT VAL = "", $ray[1], ""\n"";

$bin = pack(""V"", 65536);
$ray = unpack(""V"", $bin);
echo ""SAME AS ABOVE BUT WITH ULONG VAL = "", $ray[1], ""\n"";
?&gt;
</code></pre>
","987903"
"binary sed replacement","15589","","<p>I was attempting to do a <code>sed</code> replacement in a binary file however I am beginning to believe that is not possible.  Essentially what I wanted to do was similar to the following:</p>

<pre><code>sed -bi ""s/\(\xFF\xD8[[:xdigit:]]\{1,\}\xFF\xD9\)/\1/"" file.jpg
</code></pre>

<p>The logic I wish to achieve is: scan through a binary file until the hex code <code>FFD8</code>, continue reading until <code>FFD9</code>, and only save what was between them (discards the junk before and after, but include <code>FFD8</code> and <code>FFD9</code> as the saved part of the file)</p>

<p>Is there a good way to do this?  Even if not using <code>sed</code>?</p>

<p><strong>EDIT:</strong>  I just was playing around and found the cleanest way to do it IMO.  I am aware that this grep statement will act greedy.</p>

<pre><code>hexdump -ve '1/1 ""%.2x""' dirty.jpg | grep -o ""ffd8.*ffd9"" | xxd -r -p &gt; clean.jpg
</code></pre>
","<p><a href=""http://sourceforge.net/projects/bbe-/"" rel=""noreferrer"">bbe</a> is a ""sed for binary files"", and should work more efficiently for large binary files than hexdumping/reconstructing.</p>
","4999140"
"Get the most significant bit from an 8-bit value","15541","","<p>I know there are similar questions on this site, however, I couldn't seem to find something that really helped me out with the issue i'm having.</p>

<p>So far:</p>

<p>I have 1-byte (8-bits) that could be any combination of 1's and 0's.</p>

<p>Ex: 11000010 is my byte of data. (Little-Endian)</p>

<p>What i need to do is determine if the Most Significant Bit (MSB), in this case the 11, is either a 00, 01, 10, 11 and from there do some other things.</p>

<p>I have so far gotten the program to output the Byte as 11000010 (stored in a string) and am trying to extract the 11 from it.  (If i can figure that out then creating a switch case or if statement to check what the contents is simple enough on my own).</p>

<p>**I haven't been so good with C++ which is why i'm asking for assistance.</p>

<p>Any help is greatly appreciated.</p>
","<p>It seemes that you want to get the value of first two most significant bits.</p>

<p>This can be done by filtering them out and moving the value 6 bits to the left:</p>

<pre><code>unsigned char input;
unsigned char output;

input = whatever_you_want;

output = input &amp; 0xc0; //0xc00 = 0b11000000
output = output &gt;&gt; 6;
</code></pre>
","19734039"
"how to convert binary to decimal using python without using the bin function","15467","","<p>iv made a decimal to binary converter but I need a binary to decimal converter without using the bin function and that looks simple enough to fit with this code. can anyone help? </p>

<pre><code>choice=input('Please enter b for a binary to decimal conversion or d for a decimal to binary conversion:\n')
if choice == 'd':
decimalNum=int(input('Please enter a decimal number:\n'))

bit8=0
bit7=0
bit6=0
bit5=0
bit4=0
bit3=0
bit2=0
bit1=0
bit8=decimalNum%2
decimalNum=decimalNum//2
bit7=decimalNum%2
decimalNum=decimalNum//2
bit6=decimalNum%2
decimalNum=decimalNum//2
bit5=decimalNum%2
decimalNum=decimalNum//2
bit4=decimalNum%2
decimalNum=decimalNum//2
bit3=decimalNum%2
decimalNum=decimalNum//2
bit2=decimalNum%2
decimalNum=decimalNum//2
bit1=decimalNum%2
decimalNum=decimalNum//2

print(str(bit1)+str(bit2)+str(bit3)+str(bit4)+str(bit5)+str(bit6)+str(bit7)+str(bit7))
</code></pre>
","<p>To convert from binary to decimal, just do:</p>

<pre><code>int(binary_string, 2)  # The 2 is the base argument from which we convert.
</code></pre>

<p>Demo:</p>

<pre><code>&gt;&gt;&gt; int('0b10110', 2)
22
</code></pre>

<hr>

<p><em>Note- There are many issues with the code you are using to convert decimal to binary. If you are insistent on not using a built-in function for that purpose, you may be interested by this post:</em> </p>

<p><a href=""https://stackoverflow.com/questions/13522773/convert-an-integer-to-binary-without-using-the-built-in-bin-function"">Convert an integer to binary without using the built-in bin function</a></p>

<p>Although personally if I were to want to avoid the <code>bin()</code> function, I would do something like:</p>

<pre><code>""{0:#b}"".format(an_integer)
</code></pre>

<p>Demo:</p>

<pre><code>&gt;&gt;&gt; ""{0:#b}"".format(22)
'0b10110'
</code></pre>

<p>This is much more Pythonic than your current code.</p>
","23020627"
"Translating a String containing a binary value to Hex","15373","","<p>I am trying to translate a String that contains a binary value (e.g. 000010001010011) to it's Hex value.(453)</p>

<p>I've been trying several options, but mostly I get a converted value of each individual character. (0=30 1=31)</p>

<p>I have a function that translates my input to binary code through a non-mathematical way, but through a series of ""if, else if"" statements. (the values are not calculated, because they are not standard.) The binary code is contained in a variable String ""binOutput""</p>

<p>I currently have something like this:</p>

<pre><code>        String bin = Integer.toHexString(Integer.parseInt(binOutput));
</code></pre>

<p>But this does not work at all.</p>
","<p>Try using <code>Integer.parseInt(binOutput, 2)</code> instead of <code>Integer.parseInt(binOutput)</code></p>
","5760027"
"php - ftp_get - Warning: ftp_get(): Opening BINARY mode data connection ","15334","","<p>I'm trying to write a script that will download files from an FTP server.  They're all fairly large (nearly 2GB each).  The script starts running, but then eventually terminates with the above error.  Is it size related?  Is there a way around this?  Here's the code:</p>

<pre><code>&lt;?php

$ftp_server = ""ftp.EXAMPLE.com"";
$conn_id = ftp_connect ($ftp_server) or die(""Couldn't connect to $ftp_server"");
$login_result = ftp_login($conn_id, ""USERNAME"", ""PASSWORD"");
if ((!$conn_id) || (!$login_result)) die(""FTP Connection Failed"");
ftp_sync(""download"");   
ftp_close($conn_id); 

$mkdir = date('Y-m-d');
mkdir('encrypted/'.$mkdir, 0777);
smartCopy(""./download/"", 'encrypted/'.$mkdir);
chmodr(""encrypted/"".$mkdir, 0777);

function ftp_sync ($dir) {

    global $conn_id;

    if ($dir != ""."") {
        if (ftp_chdir($conn_id, $dir) == false) {
            echo (""Change Dir Failed: $dir&lt;BR&gt;\r\n"");
            return;
        }
        if (!(is_dir($dir)))
            mkdir($dir);
        chdir ($dir);
    }

    $contents = ftp_nlist($conn_id, ""."");
    foreach ($contents as $file) {

        if ($file == '.' || $file == '..')
            continue;

        if (@ftp_chdir($conn_id, $file)) {
            ftp_chdir ($conn_id, "".."");
            ftp_sync ($file);
        }
        else
            ftp_get($conn_id, $file, $file, FTP_BINARY);
    }

    ftp_chdir ($conn_id, "".."");
    chdir ("".."");

}

function chmodr($path, $filemode) {
    if (!is_dir($path))
        return chmod($path, $filemode);

    $dh = opendir($path);
    while (($file = readdir($dh)) !== false) {
        if($file != '.' &amp;&amp; $file != '..') {
            $fullpath = $path.'/'.$file;
            if(is_link($fullpath))
                return FALSE;
            elseif(!is_dir($fullpath) &amp;&amp; !chmod($fullpath, $filemode))
                    return FALSE;
            elseif(!chmodr($fullpath, $filemode))
                return FALSE;
        }
    }

    closedir($dh);

    if(chmod($path, $filemode))
        return TRUE;
    else
        return FALSE;
}

function smartCopy($source, $dest, $folderPermission='0777',$filePermission='0777'){

    $result=false;

    if (is_file($source)) {
        if(is_dir($dest)) {
            if ($dest[strlen($dest)-1]!='/') 
                $__dest=$dest.""/"";
            $__dest .= basename($source);
            }
        else { 
            $__dest=$dest;
            }
        $result=copy($source, $__dest);
        chmod($__dest,$filePermission);
        }
    elseif(is_dir($source)) { 
        if(!is_dir($dest)) {
            @mkdir($dest,$folderPermission);
            chmod($dest,$folderPermission);
            }
        if ($source[strlen($source)-1]!='/') 
            $source=$source.""/"";
        if ($dest[strlen($dest)-1]!='/') 
            $dest=$dest.""/"";

        $return = true;
        $dirHandle=opendir($source);
        while($file=readdir($dirHandle)) { 
            if($file!=""."" &amp;&amp; $file!="".."") { 
                $result=smartCopy($source.$file, $dest.$file, $folderPermission, $filePermission);
                }
            }
        closedir($dirHandle);
        }
    else {
        $result=false;
        }
    return $result;
}

function deleteDirectory($dir) {
    if (!file_exists($dir)) return true;
    if (!is_dir($dir) || is_link($dir)) return unlink($dir);
        foreach (scandir($dir) as $item) {
            if ($item == '.' || $item == '..') continue;
            if (!deleteDirectory($dir . ""/"" . $item)) {
                chmod($dir . ""/"" . $item, 0777);
                if (!deleteDirectory($dir . ""/"" . $item)) return false;
            };
        }
        return rmdir($dir);
    } 
?&gt;
</code></pre>
","<p>Are you sure each file is binary?</p>

<p>You may try to guess the file type from its extension in order to adjust the download mode, as suggested in this comment: <a href=""http://www.php.net/manual/fr/function.ftp-get.php#86516"" rel=""nofollow noreferrer"">http://www.php.net/manual/fr/function.ftp-get.php#86516</a></p>
","2501038"
"C++ STL's String eqivalent for Binary Data","15327","","<p>I am writing a C++ application and I was wondering what the C++ conventional way of storing a byte array in memory. </p>

<p>Is there something like a string, except specifically made for binary data. </p>

<p>Right now I am using a *unsigned char**  array to store the data, but something more STL/C++ like would be better. </p>
","<p>I'd use <code>std::vector&lt;unsigned char&gt;</code>. Most operations you need can be done using the STL with iterator ranges. Also, remember that if you really need the raw data <code>&amp;v[0]</code> is guaranteed to give a pointer to the underlying array.</p>
","837601"
"Converting numbers to ASCII in assembly","15324","","<p>Can someone explain why doing an OR operation on a binary number with 0x0030 as the operand produces the ASCII character of that number?</p>
","<p>Because looking at the ASCII chart, the digits 0 through nine start at 0x30. So you want the ASCII value for character 1? 0x30 or 0x01 = 0x31 = ASCII value for the number 1.</p>

<pre><code>In binary it's easy to see:

(0x30)   110000
or
(0x01)   000001
=        110001

Which is 0x31 - ASCII value of 1.
</code></pre>

<p><img src=""https://i.stack.imgur.com/wgJwb.gif"" alt=""enter image description here""></p>
","12903263"
"How to tell binary from text files in linux","15199","","<p>The linux <code>file</code> command does a very good job in recognising file types and gives very fine-grained results. The <code>diff</code> tool is able to tell binary files from text files, producing a different output.</p>

<p>Is there a way to tell binary files form text files? All I want is a yes/no answer whether a given file is binary. Because it's difficult to define binary, let's say I want to know if <code>diff</code> will attempt a text-based comparison.</p>

<p>To clarify the question: I do not care if it's ASCII text or XML as long as it's text. Also, I do not want to differentiate between MP3 and JPEG files, as they're all binary.</p>
","<p>The <a href=""http://www.gnu.org/software/diffutils/manual/html_mono/diff.html#Binary"" rel=""noreferrer"">diff manual</a> specifies that</p>

<blockquote>
  <p>diff determines whether a file is text
  or binary by checking the first few
  bytes in the file; the exact number of
  bytes is system dependent, but it is
  typically several thousand. If every
  byte in that part of the file is
  non-null, diff considers the file to
  be text; otherwise it considers the
  file to be binary.</p>
</blockquote>
","2645088"
"Difference between machine language, binary code and a binary file","15177","","<p>I'm studying programming and in many sources I see the concepts: ""machine language"", ""binary code"" and ""binary file"". The distinction between these three is unclear to me, because according to my understanding machine language means the raw language that a computer can understand i.e. sequences of 0s and 1s. </p>

<p>Now if machine language is a sequence of 0s and 1s and binary code is also a sequence of 0s and 1s then does <strong>machine language = binary code</strong>?</p>

<p>What about binary file? What really is a binary file? To me the word ""binary file"" means a file, which consists of binary code. So for example, if my file was:</p>

<pre><code>010010101010010
010010100110100
010101100111010
010101010101011
010101010100101
010101010010111
</code></pre>

<p>Would this be a binary file? If I google binary file and see <a href=""http://en.wikipedia.org/wiki/Binary_file"" rel=""noreferrer"">Wikipedia</a> I see this example picture of binary file which confuses me (it's not in binary?....)</p>

<p><img src=""https://i.stack.imgur.com/686wZ.png"" alt=""Hex image""></p>

<p>Where is my confusion happening? Am I mixing file encoding here or what? If I were to ask one to SHOW me what is machine language, binary code and binary file, what would they be? =) I guess the distinction is too abstract to me.</p>

<p>Thnx for any help! =)</p>

<p><strong>UPDATE</strong>: </p>

<p>In Python for example, there is one phrase in a file I/O <a href=""http://www.tutorialspoint.com/python/python_files_io.htm"" rel=""noreferrer"">tutorial</a>, which I don't understand: <strong>Opens a file for reading only in binary format.</strong> What does reading a file in binary format mean?</p>
","<p>Machine code and binary are the same - a number system with base 2 - either a 1 or 0. <strong>But machine code can also be expressed in hex-format <em>(hexadecimal)</em> - a number system with base 16</strong>. The binary system and hex are very interrelated with each other, its easy to convert from binary to hex and convert back from hex to binary. And because hex is much more readable and useful than binary - it's often used and shown. For instance in the picture above in your question -uses hex-numbers!</p>

<p>Let say you have the binary sequence 1001111000001010 - it can easily be converted to hex by grouping in blocks - each block consisting of four bits. </p>

<pre><code> 1001 1110 0000 1010 =&gt; 9  14 0 10 which in hex becomes: 9E0A. 
</code></pre>

<p>One can agree that 9E0A is much more readable than the binary - and hex is what you see in the image.</p>
","21578250"
"JavaScript: Need functions to convert a string containing binary to hex, then convert back to binary","15158","","<p>Lets say I have a string in JavaScript with binary data in it. It may look like this:</p>

<pre><code>var binary = '00001000010001000101010100001110';
</code></pre>

<p>I need some reliable functions to convert this into a hexadecimal string, and then convert back from that hexadecimal to a binary string again. I know about the following functions</p>

<pre><code>// Convert binary to hexadecimal
var hex = parseInt(binaryCharacters, 2).toString(16);

// Convert hexadecimal to binary
var binary = parseInt(hex, 16).toString(2)
</code></pre>

<p>But I'm not sure how to convert the whole string at once. Am I right in understanding I need to convert each 4 binary bits at a time into a single hexadecimal character? Then to get back to binary I loop through each hexadecimal character and convert to binary again?</p>

<p>I have hunted for some simple examples doing this in JavaScript but can't find any.</p>

<p>Many thanks</p>
","<p><a href=""http://jsfiddle.net/2YbkH/"" rel=""noreferrer"">Try this jsfiddle</a>.</p>

<p>The more interesting functions to you are here. Not necessarily the cleanest or most efficient ones, but yea:</p>

<pre><code>// converts binary string to a hexadecimal string
// returns an object with key 'valid' to a boolean value, indicating
// if the string is a valid binary string.
// If 'valid' is true, the converted hex string can be obtained by
// the 'result' key of the returned object
function binaryToHex(s) {
    var i, k, part, accum, ret = '';
    for (i = s.length-1; i &gt;= 3; i -= 4) {
        // extract out in substrings of 4 and convert to hex
        part = s.substr(i+1-4, 4);
        accum = 0;
        for (k = 0; k &lt; 4; k += 1) {
            if (part[k] !== '0' &amp;&amp; part[k] !== '1') {
                // invalid character
                return { valid: false };
            }
            // compute the length 4 substring
            accum = accum * 2 + parseInt(part[k], 10);
        }
        if (accum &gt;= 10) {
            // 'A' to 'F'
            ret = String.fromCharCode(accum - 10 + 'A'.charCodeAt(0)) + ret;
        } else {
            // '0' to '9'
            ret = String(accum) + ret;
        }
    }
    // remaining characters, i = 0, 1, or 2
    if (i &gt;= 0) {
        accum = 0;
        // convert from front
        for (k = 0; k &lt;= i; k += 1) {
            if (s[k] !== '0' &amp;&amp; s[k] !== '1') {
                return { valid: false };
            }
            accum = accum * 2 + parseInt(s[k], 10);
        }
        // 3 bits, value cannot exceed 2^3 - 1 = 7, just convert
        ret = String(accum) + ret;
    }
    return { valid: true, result: ret };
}

// converts hexadecimal string to a binary string
// returns an object with key 'valid' to a boolean value, indicating
// if the string is a valid hexadecimal string.
// If 'valid' is true, the converted binary string can be obtained by
// the 'result' key of the returned object
function hexToBinary(s) {
    var i, k, part, ret = '';
    // lookup table for easier conversion. '0' characters are padded for '1' to '7'
    var lookupTable = {
        '0': '0000', '1': '0001', '2': '0010', '3': '0011', '4': '0100',
        '5': '0101', '6': '0110', '7': '0111', '8': '1000', '9': '1001',
        'a': '1010', 'b': '1011', 'c': '1100', 'd': '1101',
        'e': '1110', 'f': '1111',
        'A': '1010', 'B': '1011', 'C': '1100', 'D': '1101',
        'E': '1110', 'F': '1111'
    };
    for (i = 0; i &lt; s.length; i += 1) {
        if (lookupTable.hasOwnProperty(s[i])) {
            ret += lookupTable[s[i]];
        } else {
            return { valid: false };
        }
    }
    return { valid: true, result: ret };
}
</code></pre>
","17210335"
"How is overflow detected at the binary level?","15123","","<p>I'm reading the textbook Computer Organization And Design by Hennessey and Patterson (4th edition). On page 225 they describe how overflow is detected in signed, 2's complement arithmetic. I just can't even understand what they're talking about.</p>

<blockquote>
  <p>""How do we detect [overflow] when it <em>does</em> occur? Clearly, adding or
  substracting two 32-bit numbers can yield a result that needs 33 bits
  to be fully expressed.""</p>
</blockquote>

<p>Sure. And it won't need 34 bits because even the smallest 34 bit number is twice the smallest 33 bit number, and we're adding 32 bit numbers.</p>

<blockquote>
  <p>""The lack of a 33rd bit means that when overflow occurs, the sign bit
  is set with the <em>value</em> of the result instead of the proper sign of
  the result.""</p>
</blockquote>

<p>What does this mean? The sign bit is set with the ""value"" of the result... meaning it's set as if the result were unsigned? And if so, how does that follow from the lack of a 33rd bit?</p>

<blockquote>
  <p>""Since we need just one extra bit, only the sign bit can be wrong.""</p>
</blockquote>

<p>And that's where they lost me completely.</p>

<p>What I'm getting from this is that, when adding signed numbers, there's an overflow if and only if the sign bit is wrong. So if you add two positives and get a negative, or if you add two negatives and get a positive. But I don't understand their explanation.</p>

<p>Also, this only applies to unsigned numbers, right? If you're adding signed numbers, surely detecting overflow is much simpler. If the last half-adder of the ALU sets its carry bit, there's an overflow.</p>

<p>note: I really don't know what tags are appropriate here, feel free to edit them.</p>
","<p>Any time you want to deal with these kind of alu items be it add, subtract, multiply, etc, start with 2 or 3 bit numbers, much easier to get a handle on than 32 or 64 bit numbers. after 2 or 3 bits it doesnt matter if it is 22 or 2200 bits it all works exactly the same from there on out.  Basically you can by hand if you want make a table of all 3 bit operands and their results such that you can examine the whole table visually, but a table of all 32 bit operands against all 32 bit operands and their results, cant do that by hand in a reasonable time and cannot examine the whole table visually.</p>

<p>Now twos complement, that is just a scheme for representing positive and negative numbers, and it is not some arbitrary thing it has a reason, the reason for the madness is that your adder logic (which is also what the subtractor uses which is the same kind of thing the multiplier uses) DOES NOT CARE ABOUT UNSIGNED OR SIGNED.  It does not know the difference.  YOU the programmer cares in my three bit world the bit patter 0b111 could be a postitive seven (+7) or it could be a negative one.  Same bit pattern, feed it to the add logic and the same thing comes out, and the answer that comes out I can choose to interpret as unsigned or twos complement (so long as I interpret the operands and the result all as either unsigned or all as twos complement).  Twos complement also has the feature that for negative numbers the most significant bit (msbit) is set, for positive numbers it is zero.  So it is not sign plus magnitude but we still talk about the msbit being the sign bit, because except for two special numbers that is what it is telling us, the sign of the number, the other bits are actually telling us the magnitude they are just not an unsigned magnitude as you might have in sign+magnitude notation.</p>

<p>So, the key to this whole question is understanding your limits.  For a 3 bit unsigned number our range is 0 to 7, 0b000 to 0b111. for a 3 bit signed (twos complement) interpretation our range is -4 to +3 (0b100 to 0b011).  For now limiting ourselves to 3 bits if you add 7+1, 0b111 + 0b001 = 0b1000 but we only have a 3 bit system so that is 0b000, 7+1 = 8, we cannot represent 8 in our system so that is an overflow, because we happen to be interpreting the bits as unsigned we look at the ""unsigned overflow"" which is also known as the carry bit or flag.  Now if we take those same bits but interpret them as signed, then 0b111 (-1) + 0b001 (+1) = 0b000 (0). Minus one plus one is zero.  No overflow, the ""signed overflow"" is not set...What is the signed overflow?</p>

<p>First what is the ""unsigned overflow"".</p>

<p>The reason why ""it all works the same"" no matter how many bits we have in our registers is no different than elementary school math with base 10 (decimal) numbers.  If you add 9 + 1 which are both in the ones column you say 9 + 1 = zero carry the 1.  you carry a one over to the tens column then 1 plus 0 plus 0 (you filled in two zeros in the tens column) is 1 carry the zero.  you have a 1 in the tens column and a zero in the ones column</p>

<pre><code>  1
  09
 +01
====
  10
</code></pre>

<p>what if we declared that we were limited to only numbers in the ones column, there isnt any room for a tens column.  Well that carry bit being a non-zero means we have an overflow, to properly compute the result we need another column, same with binary</p>

<pre><code>  111 
   111
 + 001
=======
  1000
</code></pre>

<p>7 + 1 = 8, but we cant do 8 if we declare a 3 bit system, we can do 7 + 1 = 0 with the carry bit set.  Here is where the beauty of twos complement comes in:</p>

<pre><code>  111 
   111
 + 001
=======
   000
</code></pre>

<p>if you look at the above three bit addition, you cannot tell by looking if that is 7 + 1 = 0 with the carry bit set or if that is -1 + 1 = 0.</p>

<p>So for unsigned addition, as we have known since grade school that a carry over into the next column of something other than zero means we have overflowed that many placeholders and need one more placeholder, one more column, to hold the actual answer.</p>

<p>Signed overflow.  The sort of academic answer is if the carry in of the msbit column does not match the carry out.   lets take some examples in our 3 bit world.   So with twos complement we are limited to -4 to +3.  so if we add -2 + -3 = -5 that wont work correct?
To figure out what minus two is we do an invert and add one  0b010, inverted 0b101, add one 0b110.  minus three is 0b011 -> 0b100 -> 0b101</p>

<p>so now we can do this:</p>

<pre><code>  abc
  100 
   110
 + 100
======
   010
</code></pre>

<p>If you look at the number under the b that is the ""carry in"" to the msbit column, the number under the a the 1, is the carry out, these two do not match so we know there is a ""signed overflow""</p>

<p>lets try 2 + 2 = 4</p>

<pre><code>  abc
  010
   010
 + 010
======
   100
</code></pre>

<p>You may say but that looks right, sure unsigned it does, but we are doing signed math here, so the result is actually a -4 not a positive 4.  2 + 2 != -4.  the carry in which is under the b is a 1, the carry out of the msbit is a zero, the carry in and the carry out dont match.  signed overflow.</p>

<p>there is a shortcut to figuring out the signed overflow without having to look at the carry in (or carry out).  if (  msbit(opa) == msbit(opb) ) &amp;&amp; ( msbit(res) != msbit(opb) ) signed overflow, else no signed overflow.  opa being one operand, opb being the other and res the result.</p>

<pre><code>   010
 + 010
======
   100
</code></pre>

<p>Take this +2 + +2 = -4.  msbit(opa) and msbit(opb) are equal, and the result msbit is not equal to opb msbit so this is a signed overflow.  You could think about it using this table</p>

<pre><code>x ab cr 
0 00 00
0 01 01
0 10 01
0 11 10 signed overflow
1 00 01 signed overflow
1 01 10
1 10 10
1 11 11
</code></pre>

<p>this table is all the possible combinations if carry in bit, operand a, operand b, carry out and result bit for a single column turn your head sideways to the left to sort of see this x is the carry in, a and b columns are the two operands.  cr as a pair is the result xab of 011 means 0+1+1 = 2 decimal which is 0b10 binary.  So taking the rule that has been dictated to us, that if the carry in and carry out do not match that is a signed overflow. Well the two cases where the item in the x column does not match the item in the c column are indicated those are the cases where a and b inputs match each other, but the result bit is the opposite of a and b.  So assuming the rule is correct this quick shortcut that does not require knowing what the carry bits are, will tell you if there was a signed overflow.</p>

<p>Now you are reading an H&amp;P book.  Which probably means mips or dlx, neither mips or dlx deal with carry and signed flags in the way that most other processors do.  mips is not the best first instruction set IMO primarily for that reason, their approach is not wrong in any way, but being the oddball, you will spend forever thinking differently and having to translate when going to most other processors.  Where if you learned the typical znvc flags (zero flag, negative flag, v=signed overflow, c=carry or unsigned overflow) way then you only have to translate when going to mips.  Normally these are computed on every alu operation (for the non-mips type processors) you will see signed and unsigned overflow being computed for add and subtract. (I am used to an older mips, maybe this gen of books and the current instruction set has something different).  Calling it addu add unsigned right at the start of mips after learning all of the above about how an adder circuit does not care about signed vs unsigned, is a huge problem with mips it really puts you in the wrong mindset for understanding something this simple.  Leads to the belief that there is a difference between signed addition and unsigned addition when there isnt.  It is only the overflow flags that are computed differently.  Now multiply, and divide there is definitely a twos complement vs unsigned difference and you ideally need a signed multiply and an unsigned multiply or you need to deal with the limitation.</p>

<p>I recommend a simple (depending on how strong your bit manipulation is and twos complement) exercise that you can write in some high level language.  Basically take all the combinations of unsigned numbers 0 to 7 added to 0 to 7 and save the result.  Print out both as decimal and as binary (three bits for operands, four bits for result) and if the result is greater than 7 print overflow as well.  Repeat this using signed variables using the numbers -4 to +3 added to -4 to +3. print both decimal with a +/- sign and the binary.  If the result is less than -4 or greater than +3 print overflow.  From those two tables you should be able to see that the rules above are true.  Looking strictly at the operand and result bit patterns for the size allowed (three bits in this case) you will see that the addition operation gives the same result, same bit pattern for a given pair of inputs independent of whether those bit patterns are considered unsigned or twos complement.  Also you can verify that unsigned overflow is when the result needs to use that fourth column, there is a carry out off of the msbit.  for signed when the carry in doesnt match the carry out, which you see using the shortcut looking at the msbits of the operands and result.  Even better is to have your program do those comparisons and print out something.  So if you see a note in your table that the result is greater than 7 and a note in your table that bit 3 is set in the result, then you will see for the unsigned table that is always the case (limited to inputs of 0 to 7).  And the more complicated one, signed overflow, is always when the result is less than -4 and greater than 3 and when the operand upper bits match and the result upper bit does not match the operands.</p>

<p>I know this is super long and very elementary.  If I totally missed the mark here, please comment and I will remove or re-write this answer.</p>

<p>the other half of the twos complement magic.  hardware does not have subtract logic.  one way to ""convert"" to twos complement is to ""invert and add one"".  if I wanted to subtract 3 - 2 using twos complement what actually happens is that is the same as +3 + (-2) right, and to get from +2 to to -2 we invert and add one.  Looking at our elementary school addition, did you notice the hole in the carry in on the first column?</p>

<pre><code>  111H
   111
 + 001
=======
  1000
</code></pre>

<p>I put an H above where the hole is.  Well that carry in bit is added to the operands right?  our addition logic is not a two input adder it is a three input adder yes?  most of the columns have to add three one bit numbers in order to compute two operands.  If we use a three input adder on the first column now we have a place to ... add one.  If I wanted to subtract 3 - 2 = 3 + (-2) = 3 + (~2) + 1 which is:</p>

<pre><code>    1
  011
+ 101
=====
</code></pre>

<p>before we start and filled in it is:</p>

<pre><code> 1111
  011
+ 101
=====
  001
</code></pre>

<p>3 - 2 = 1.</p>

<p>What the logic does is:</p>

<p>if add then carry in = 0; the b operand is not inverted, the carry out is not inverted.
if subtract then carry in = 1; the b operand is inverted, the carry out MIGHT BE inverted.</p>

<p>the addition above shows a carry out, I didnt mention that this was an unsigned operation 3 - 2 = 1.  I used some twos complement tricks to perform an unsigned operation, because here again no matter whether I interpret the operands as signed or unsigned the same rules apply for if add or if subtract.  Why i said that the carry out MIGHT BE inverted is that some processors invert the carry out and some dont.  it has to do with cascading operations, taking say a 32 bit addition logic and using the carry flag and an add with carry or subtract with borrow instruction creating a 64 bit add or subtract, or any multiple of the base register size.  say you have two 64 bit numbers in a 32 bit system a:b + c:d where a:b is the 64 bit number but it is held in the two registers a and b where a is the upper half and b is the lower half.  so a:b + c:d = e:f on a 32 bit system unsigned that has a carry bit and add with carry:</p>

<pre><code>add f,b,d
addc e,a,c
</code></pre>

<p>The add leaves its carry out bit from the upper most bit lane in the carry flag in the status register, the addc instruction is add with carry takes the operands a+c and if the carry bit is set then adds one more.  a+c+1 putting the result in e and the carry out in the carry flag, so </p>

<pre><code>add f,b,d
addc e,a,c
addc x,y,z
</code></pre>

<p>Is a 96 bit addition, and so on.  Here again something very foreign to mips since it doesnt use flags like other processors.  Where the invert or dont invert comes in for signed carry out is on the subtract with borrow for a particular processor.  for subtract:</p>

<p>if subtract then carry in = 1; the b operand is inverted, the carry out MIGHT BE inverted.</p>

<p>for subtract with borrow you have to say if the carry flag from the status register indicates a borrow then the carry in is a 0 else the carry in is a 1, and you have to get the carry out into the status register to indicate the borrow.  </p>

<p>Basically for the normal subtract some processors invert b operand and carry on in the way in and carry out on the way out, some processors invert the b operand and carry in in the way in but dont invert carry out on the way out.  Then when you want to do a conditional branch you need to know if the carry flag means greater than or less than (often the syntax will have a branch if greater or branch if less than and sometimes tell you which one is the simplified branch if carry set or branch if carry clear).  (if you dont ""get"" what I just said there that is another equally long answer which wont mean anything so long as you are studying mips).</p>
","11355057"
"Performing arithmetic operations in binary using only bitwise operators","15029","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/2776211/how-can-i-multiply-and-divide-using-only-bit-shifting-and-adding"">How can I multiply and divide using only bit shifting and adding? </a>  </p>
</blockquote>



<p>I have to write functions to perform binary subtraction, multiplication, and division without using any arithmetic operators except for loop control. I've only written code in Java before now, so I'm having a hard time wrapping my head around this.</p>

<p>Starting with subtraction, I need to write a function with prototype </p>

<pre><code>int bsub(int x, int y)
</code></pre>

<p>I know I need to convert y to two's complement in order to make it negative and add it to x, but I only know how to do this by using one's complement ~ operator and adding 1, but I can't use the + operator. </p>

<p>The badd function was provided, and I will be able to implement it in bsub if I can figure out how to make y a negative number. The code for badd is shown below. Thanks in advance for any tips. </p>

<pre><code>int badd(int x,int y){

int i;

char sum;
char car_in=0;
char car_out;
char a,b;

unsigned int mask=0x00000001;
int result=0;

for(i=0;i&lt;32;i++){

  a=(x&amp;mask)!=0;
  b=(y&amp;mask)!=0;
  car_out=car_in &amp; (a|b) |a&amp;b;
  sum=a^b^car_in;

  if(sum) {
     result|=mask;
  }

  if(i!=31) {
     car_in=car_out;
  } else {
     if(car_in!=car_out) {
        printf(""Overflow occurred\n"");
     }
  }

  mask&lt;&lt;=1;
  }

 return result;
  }
</code></pre>
","<p>Well, subtracting in bitwise operations without the <code>+</code> or <code>-</code> operators is slightly tricky, but can be done. You have the basic idea with the complement, but without using <code>+</code> it becomes slightly tricky.</p>

<p>You can do it by first setting up addition with bit-wise only, then using that, you can do subtraction. Which is used for the complement, So the code looks like this:</p>

<pre><code>int badd(int n1, int n2){
    int carry, sum;
    carry = (n1 &amp; n2) &lt;&lt; 1; // Find bits that are used for carry
    sum = n1 ^ n2; // Add each bit, discard carry.
    if (sum &amp; carry) // If bits match, add current sum and carry.
        return badd(sum, carry);
    else
        return sum ^ carry; // Return the sum.
}

int bsub(int n1, int n2){
    // Add two's complement and return.
    return badd(n1, badd(~n2, 1));
}
</code></pre>

<p>And then if we use the above code in an example:</p>

<pre><code>int main(){
printf(""%d\n"", bsub(53, 17));
return 0;
}
</code></pre>

<p>Which ends up returning <code>36</code>. And that is how subtraction works with bitwise only operations.</p>

<p>Afterwards multiplication and division get more complicated, but can be done; for those two operations, use shifts along with addition and/or subtraction to get the job done. You may also want to read <a href=""https://stackoverflow.com/questions/2776211/how-can-i-multiply-and-divide-with-only-using-bit-shifting-and-adding"">this question</a> and <a href=""http://en.wikipedia.org/wiki/Multiplication_algorithm#Peasant_or_binary_multiplication"" rel=""nofollow noreferrer"">this article</a> on how to do it.</p>
","12538905"
"How do you write a binary literal in ruby?","14992","","<p>Most languages (Ruby included) allow number literals to be written in at least three bases: decimal, octal and hexadecimal. Numbers in decimal base is the usual thing and are written as (most) people naturally write numbers, 96 is written as <code>96</code>. Numbers prefixed by a zero are usually interpreted as octal based: 96 would be written as <code>0140</code>. Hexadecimal based numbers are usually prefixed by <code>0x</code>: 96 would be written as <code>0x60</code>.</p>

<p>The question is: can I write numbers as binary literals in Ruby? How?</p>
","<p>use 0b prefix</p>

<pre><code>&gt;&gt; 0b100
=&gt; 4
</code></pre>
","101482"
"Splitting a string into two halfs","14980","","<p>I am making a new conversion software to hide messages (for fun). I have made a Binary and Decimal conversion class and my idea is, a user inputs string, it converts all to Binary format. Then splits it in half, converts one half to decimal, then adds the string back together again to make it a mix of binary and decimal. In other versions I will add more conversions, more splits,and maybe convert to languages too. I need splitting the string in half. This is my code so far::</p>

<pre><code>public ray() {
    Scanner in = new Scanner(System.in);

    while (true) {
        System.out.println(""Please input the text you wish to encode!"");
        System.out.println(""Type '#' to quit the Software."");
        String s1 = in.nextLine();
        if (""#"".equalsIgnoreCase(s1)) {
            System.out.println(""Goodbye, hope you enjoyed RAYConversion v1.0 Alpha."");
            // close software
        }

        // convert all to binary
        binary Binary = new binary();

        //what i need to do is split stirng s1 in half, make it into different strings. Then I will convert
        //the two strings to binary and decimal. I made a converter for that.

    }
}
</code></pre>
","<pre><code>final int mid = s1.length() / 2; //get the middle of the String
String[] parts = {s1.substring(0, mid),s1.substring(mid)};
System.out.println(parts[0]); //first part
System.out.println(parts[1]); //second part
</code></pre>
","32423445"
"Binary search in an ordered list in java","14964","","<p>Im looking for a way to implement a code in java that works the same way as a binary search in an ordered ArrayList but for an ordered List
Thanks</p>
","<p>The algorithm should be the same for both an <code>ArrayList</code> and a <code>List</code>, given they are both ordered. </p>
","18110707"
"Write Binary File","14875","","<p>I am reading data from an IPhone App that uses http POST to transfer the image to the Server I can read this into a an binary and it does write to a file (See below) the issue I have is when I open the image it fails.</p>

<p>You can see the code from the Iphone on this post:
<a href=""https://stackoverflow.com/questions/1547967/asp-http-post-read-data"">asp http POST Read Data</a></p>

<p>Code:</p>

<pre><code>byte[] buffer = new byte[Request.ContentLength];
using (BinaryReader br = new BinaryReader(Request.InputStream))
    br.Read(buffer, 0, buffer.Length);

string fileName = @""C:\test\test.jpg"";
FileStream fs = new FileStream(fileName, FileMode.Create, 
    FileAccess.ReadWrite);
BinaryWriter bw = new BinaryWriter(fs);
bw.Write(buffer);
bw.Close();
</code></pre>

<p>The image Content-Type is application/octet-stream</p>

<p>Can anyone shine any light onto this please.</p>
","<p>Does the following work?  For this it would probably be better to change the FileStream to a MemoryStream</p>

<pre><code>fs.Position = 0;
Bitmap bit_map = Bitmap.FromStream(fs) as Bitmap;
bit_map.Save(@""C:\test\test.jpg"");
</code></pre>

<p>Or</p>

<pre><code>fs.Position = 0;
Image image = Image.FromStream(fs); 
image.Save(@""C:\test\test.jpg"", ImageFormat.Jpeg);
</code></pre>

<p>Full Example (using your example, but if you want to change how the binary data is read from the other post, that is fine too, just confinue from after you have the buffer):</p>

<pre><code>byte[] buffer = new byte[Request.ContentLength];
using (BinaryReader br = new BinaryReader(Request.InputStream))
    br.Read(buffer, 0, buffer.Length);
MemoryStream mem_stream = new MemoryStream (buffer); 
mem_stream.Write(buffer, 0, buffer.Length); 
mem_stream.Position = 0;
Image image = Image.FromStream(mem_stream); 
image.Save(@""C:\test\test.jpg"", ImageFormat.Jpeg);
mem_stream.Close();
</code></pre>
","1572537"
"Count number of 1's in binary format of decimal number","14848","","<p>I am trying to find out the number of 1's in binary form of a large decimal number (decimal number can be as large as 1000000).</p>

<p>I tried this piece of code:</p>

<pre><code>while(sum&gt;0)  
{  
    if(sum%2 != 0)  
    {  
        c++;   // counting number of ones  
    }  
    sum=sum/2;  
}  
</code></pre>

<p>I want a faster algorithm as it takes long time for large decimal input. Please suggest me an efficient algorithm.</p>
","<p>In C++ you can just do this.</p>

<pre><code>#include &lt;bitset&gt;
#include &lt;iostream&gt;
#include &lt;climits&gt;

size_t popcount(size_t n) {
    std::bitset&lt;sizeof(size_t) * CHAR_BIT&gt; b(n);
    return b.count();
}

int main() {
    std::cout &lt;&lt; popcount(1000000);
}
</code></pre>
","14682757"
"-128 and 128 in 2's complement","14747","","<p>In 2's complement, 0-127 is represented as 00000000 to 01111111. In case of negative numbers, we invert all bits in the unsigned representation and add 1 to get the 2's complement.</p>

<p>(Reference: <a href=""http://en.wikipedia.org/wiki/Signed_number_representations#Two.27s_complement"">http://en.wikipedia.org/wiki/Signed_number_representations#Two.27s_complement</a>)</p>

<p>so -1 in 2's complement will  be:</p>

<pre>

 unsigned 1 =      00000001

 invert all bits = 11111110

 add 1 =           11111111
</pre>

<p>But for -128, if we follow the same steps:</p>

<pre>

 unsigned 128 =    10000000

 invert all bits=  01111111

 add 1=            10000000

</pre>

<p>so -128 and 128 have the same representation in 2's complement notation? Why isn't the range of 2's complement for 8 bits given as -127 to 128? In short, why is -128 preferred over representing unsigned 128 using the same number of bits?           </p>
","<p>There is no ""128"" in a signed byte. The range is</p>

<ul>
<li>0 to 127 : 128 values</li>
<li>-1 to -128 : 128 values</li>
</ul>

<p>Total 256 values, ie 2^8.</p>

<p><em>Addendum</em> based on comment (and rereading the question)</p>

<p><code>0x80</code> could have been considered as -128, or +128. <a href=""http://en.wikipedia.org/wiki/Two%27s_complement#The_most_negative_number"" rel=""noreferrer"">Wikipedia explanation</a> is worth reading</p>

<blockquote>
  <p>The two's complement of the minimum number in the range will not have the desired effect of negating the number.</p>
  
  <p>For example, the two's complement of −128 in an 8-bit system results in the same binary number. This is because a positive value of 128 cannot be represented with an 8-bit signed binary numeral. Note that this is detected as an overflow condition since there was a carry into but not out of the most-significant bit. This can lead to unexpected bugs in that an unchecked implementation of absolute value could return a negative number in the case of the minimum negative. The abs family of integer functions in C typically has this behaviour. This is also true for Java. In this case it is for the developer to decide if there will be a check for the minimum negative value before the call of the function.</p>
  
  <p>The most negative number in two's complement is sometimes called ""the weird number,"" because it is the only exception. Although the number is an exception, it is a valid number in regular two's complement systems. All arithmetic operations work with it both as an operand and (unless there was an overflow) a result.</p>
</blockquote>

<p>Furthermore, right-shifting a signed integer would have the CPU propagate the MSb (bit 7) to the right, which would be against simple logic if <code>0x80</code> is +128, as, after only one shift, we would obtain <code>0xC0</code> which is a negative number (-64)... (while a right-shift from a positive number can, normally, <em>never</em> produce a negative result).</p>
","17007650"
"Convert binary string to binary or decimal value","14565","","<p>Is there any function to convert binary string into binary or decimal value?</p>

<p>If I have a binary string <code>000101</code>, what should I do to convert it into <code>5</code>?</p>
","<p>Here is what you can try:</p>

<pre><code>binStr &lt;- ""00000001001100110000010110110111"" # 20121015
(binNum &lt;- 00000001001100110000010110110111) # 20121015
[1] 1.0011e+24
binVec &lt;- c(1,0,1,0,0,0,1,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1) # 2670721
shortBin &lt;- 10011010010 # 1234
BinToDec &lt;- function(x) 
    sum(2^(which(rev(unlist(strsplit(as.character(x), """")) == 1))-1))
BinToDec(binStr)
[1] 20121015
BinToDec(binNum)
[1] 576528
BinToDec(binVec)
[1] 2670721
BinToDec(shortBin)
[1] 1234
</code></pre>

<p>That is, you can input both strings (because of <code>as.character()</code>) and numeric binary values  but there are some problems with large numbers like <code>binNum</code>. As I understand you also want to convert binary string to numeric binary values, but unfortunately there is no such data type at least in base R.</p>

<p><strong>Edit:</strong> Now <code>BinToDec</code> also accepts binary vectors, which might be a solution for large numbers. Function <code>digitsBase()</code> from package <code>sfsmisc</code> returns such a vector:</p>

<pre><code>(vec &lt;- digitsBase(5, base= 2, 10))
Class 'basedInt'(base = 2) [1:1]
      [,1]
 [1,]    0
 [2,]    0
 [3,]    0
 [4,]    0
 [5,]    0
 [6,]    0
 [7,]    0
 [8,]    1
 [9,]    0
[10,]    1
BinToDec(vec)
[1] 5
</code></pre>

<p>Finally, another possibility is package <code>compositions</code> , for example:</p>

<pre><code>(x &lt;- unbinary(""10101010""))
[1] 170
(y &lt;- binary(x))
[1] ""10101010""
</code></pre>
","12892614"
"Reading/writing a BINARY File with Strings?","14556","","<p>How can I write/read a string from a binary file?</p>

<p>I've tried using <code>writeUTF</code> / <code>readUTF</code> (DataOutputStream/DataInputStream) but it was too much of a hassle.</p>

<p>Thanks.</p>
","<p>Forget about FileWriter, DataOutputStream for a moment.</p>

<ul>
<li>For binary data one uses <code>OutputStream</code> and <code>InputStream</code> classes. They handle <code>byte[]</code>.</li>
<li>For text data one uses <code>Reader</code> and <code>Writer</code> classes. They handle <code>String</code> which can store all kind of text, as it internally uses Unicode.</li>
</ul>

<p>The crossover from text to binary data can be done by specifying the encoding, which defaults to the OS encoding.</p>

<ul>
<li><code>new OutputStreamWriter(outputStream, encoding)</code></li>
<li><code>string.getBytes(encoding)</code></li>
</ul>

<p>So if you want to avoid <code>byte[]</code> and use String you must abuse an encoding which covers all 256 byte values in any order. So no ""UTF-8"", but maybe ""windows-1252"" (also named ""Cp1252"").</p>

<p>But internally there is a conversion, and in very rare cases problems might happen. For instance <code>é</code> can in Unicode be one code, or two, <code>e</code> + combining diacritical mark right-accent <code>'</code>. There exists a conversion function (java.text.Normalizer) for that.</p>

<p>One case where this already led to problems is file names in different operating systems; MacOS has another Unicode normalisation than Windows, and hence in version control system need special attention.</p>

<p>So on principle it is better to use the more cumbersome byte arrays, or ByteArrayInputStream, or java.nio buffers. Mind also that String <code>char</code>s are 16 bit.</p>
","11586315"
"reading binary code of a file...in PHP","14555","","<p>How can I read the binary code(to get the 1s and 0s) of a file.</p>

<pre><code>$filename = ""something.mp3"";
$handle = fopen($filename, ""rb"");
$contents = fread($handle, filesize($filename));
fclose($handle);
</code></pre>

<p>I tried this but it shows some strange characters... I presume that this is the formated binary? I was hoping to get the 1's and 0's instead.</p>

<p>Also I am not looking only <code>.mp3</code> files it could be anything .e.g: <code>.txt</code> , <code>.doc</code> , <code>.mp4</code>, <code>.php</code>, <code>.jpg</code>, <code>.png</code> etc.... </p>
","<p>Files are stored on the computer in binary form indeed, but the 1s and 0s are stored together in groups of 8 (called bytes). Now, traditionally, each byte may be represented by an ASCII character because of the fact that there are 256 possible values that can be represented in a byte - which happens to coincide with the total number of different ASCII characters available (this was not a coincidence but actually by design).</p>

<p>That being said, what you are getting back from the <code>fread</code> function is what you're supposed to get: i.e. the contents of the file. </p>

<p>If you want to <em>see the <code>1s an 0s</code></em> you will need to print each byte that your receive into it's <a href=""http://en.wikipedia.org/wiki/Binary_numeral_system"" rel=""noreferrer"">base 2</a> representation. You can achieve that using a function such as <a href=""http://us2.php.net/base-convert"" rel=""noreferrer"">base_convert</a> or by writing your own.</p>

<pre><code>$filename = ""something.mp3"";
$handle = fopen($filename, ""rb"");
$fsize = filesize($filename);
$contents = fread($handle, $fsize);
fclose($handle);

// iterate through each byte in the contents
for($i = 0; $i &lt; $fsize; $i++)
{ 
   // get the current ASCII character representation of the current byte
   $asciiCharacter = $contents[$i];
   // get the base 10 value of the current characer
   $base10value = ord($asciiCharacter);
   // now convert that byte from base 10 to base 2 (i.e 01001010...)
   $base2representation = base_convert($base10value, 10, 2);
   // print the 0s and 1s
   echo($base2representation);
}
</code></pre>

<p><em>NOTE</em></p>

<p>If you have a string of 1s and 0s (the base 2 representation of a character) you can convert it back to the character like so:</p>

<pre><code>$base2string = '01011010';
$base10value = base_convert($base2string, 2, 10);  // =&gt; 132
$ASCIICharacter = chr($base10value);               // =&gt; 'Z'
echo($ASCIICharacter);                             // will print Z
</code></pre>
","2200618"
"First occurrence in a binary search","14395","","<p>I'm tinkering with some code and I realized something I never knew.  A normal binary search will return a random index in a data set for a key that occurs more than once.  How can I modify this code below to return the <em>first occurrence</em>?  Is this something people do?</p>

<pre><code>//ripped from the JDK
public static int binarySearchValue(InvertedContainer.InvertedIndex[] a, long key) {
    return bSearchVal(a, 0, a.length, key);
}

private static int bSearchVal(InvertedContainer.InvertedIndex[] a, int fromIndex,
                                 int toIndex, long key) {
    int low = fromIndex;
    int high = toIndex - 1;

    while (low &lt;= high) {
        int mid = (low + high) &gt;&gt;&gt; 1;
        long midVal = a[mid].val;

        if (midVal &lt; key)
            low = mid + 1;
        else if (midVal &gt; key)
            high = mid - 1;
        else
            return mid; // key found
    }
    return (low); // key not found. return insertion point
}
</code></pre>
","<p>Having found <em>a</em> matching value, you basically need to walk up the collection until you find an entry which <em>doesn't</em> match.</p>

<p>You could <em>potentially</em> make it faster by fetching the index of a key immediately lower than the one you were looking for, then do a binary chop between the two - but I'd probably go for the simpler version, which is likely to be ""efficient enough"" unless you've got a really large number of equal entries.</p>
","6676390"
"How to identify binary and text files using Python?","14343","","<p>I need identify which <strong>file</strong> is <strong>binary</strong> and which is a <strong>text</strong> in a directory. </p>

<p>I tried use <em>mimetypes</em> but it isnt a good idea in my case because it cant identify all files mimes, and I have strangers ones here... I just need know, binary or text. Simple ? But I couldn´t find a solution... </p>

<p>Thanks</p>
","<p>Thanks everybody, I found a solution that suited my problem. I found this code at <a href=""http://code.activestate.com/recipes/173220/"" rel=""nofollow noreferrer"">http://code.activestate.com/recipes/173220/</a> and I changed just a little piece to suit me.</p>

<p>It works fine. </p>

<pre><code>from __future__ import division
import string 

def istext(filename):
    s=open(filename).read(512)
    text_characters = """".join(map(chr, range(32, 127)) + list(""\n\r\t\b""))
    _null_trans = string.maketrans("""", """")
    if not s:
        # Empty files are considered text
        return True
    if ""\0"" in s:
        # Files with null bytes are likely binary
        return False
    # Get the non-text characters (maps a character to itself then
    # use the 'remove' option to get rid of the text characters.)
    t = s.translate(_null_trans, text_characters)
    # If more than 30% non-text characters, then
    # this is considered a binary file
    if float(len(t))/float(len(s)) &gt; 0.30:
        return False
    return True
</code></pre>
","1446870"
"Java: convert binary string to hex string","14254","","<p>I need to convert the binary string to a hex string but i have a problem.
I  converted the binary string to a hex string by this method:</p>

<pre><code>public static String binaryToHex(String bin){
   return Long.toHexString(Long.parseLong(bin,2));
}
</code></pre>

<p>it's ok! but I lose the zeros to the left of the string.
Ex:</p>

<p>the method return this: 123456789ABCDEF,
but i want returned this:</p>

<p>00000123456789ABCDEF</p>
","<p>Instead of <code>Long.toHexString</code> I would use <code>Long.parseLong</code> to parse the value and then <code>String.format</code> to output the value with the desired width (21 in your example):</p>

<pre><code>
public static String binaryToHex(String bin) {
   return String.format(""%21X"", Long.parseLong(bin,2)) ;
}
</code></pre>
","19494472"
"How to write binary literals in Scala?","14249","","<p>Scala has direct support for using hex and octal numbers:</p>

<pre><code>scala&gt; 01267 + 0100
res1: Int = 759

scala&gt; 0x12AF + 0x100
res2: Int = 5039
</code></pre>

<p>but how do you do express an integer as a binary number in Scala ?. </p>
","<p>If performance is not an issue, you can use a String and convert it to an integer.</p>

<pre><code>val x = Integer.parseInt(""01010101"", 2)
</code></pre>

<p>Binary numbers aren't supported directly in part because you can easily convert from hexadecimal to binary and vice versa. To make your code clearer, you can put the binary number in a comment.</p>

<pre><code>val x = 0x55 //01010101
</code></pre>
","7197325"
"c++ boost serialization with stringstream","14211","","<p>I am new to boost and c++ and is attempting to serialize an object to binary and then unserialize it.</p>

<p>I'm using the classes from the example in: <a href=""http://en.highscore.de/cpp/boost/serialization.html"" rel=""noreferrer"">http://en.highscore.de/cpp/boost/serialization.html</a></p>

<p>So suppose this is the class I am trying to serialize: </p>

<pre><code>class person 
{ 
public: 
  person() { } 

  person(int age) : age_(age) {  } 

  int age() const { return age_; } 

private:
  friend class boost::serialization::access;

  template &lt;typename Archive&gt;
  void serialize(Archive &amp;ar, const unsigned int version)
  {
    ar &amp; age_;
  }

  int age_;
}; 
</code></pre>

<p>This is the serialization code: </p>

<pre><code>const char * save(Object ss)
{
    boost::archive::binary_oarchive oa(ss);
    person p(31);
    oa &lt;&lt; p;

    return ss.str().data();
}
</code></pre>

<p>This is the unserialization code:</p>

<pre><code>void load(const char * str)
    {

        stringstream s;
        s &lt;&lt; str;

        boost::archive::binary_iarchive ia(s);
        person p;
        ia &gt;&gt; p;
        std::cout &lt;&lt; p.age() &lt;&lt; std::endl;

    }
</code></pre>

<p>When I attempt to run this code, I receive this error:</p>

<pre><code>terminate called after throwing an instance of 'boost::archive::archive_exception'
  what():  stream error
</code></pre>

<p>Which brings me to ask, is there a proper way of doing this? </p>

<p>Thanks, much appreciated. </p>

<p>EDIT:
This version works: </p>

<p>This is the serialization code: </p>

<pre><code>string save()
{
    boost::archive::binary_oarchive oa(ss);
    person p(31);
    oa &lt;&lt; p;

    return ss.str();
}
</code></pre>

<p>This is the unserialization code:</p>

<pre><code>void load(string str)
    {

        stringstream s;
        s &lt;&lt; str;

        boost::archive::binary_iarchive ia(s);
        person p;
        ia &gt;&gt; p;
        std::cout &lt;&lt; p.age() &lt;&lt; std::endl;

    }
</code></pre>

<p>EDIT2:
This version does not work. Would appreciate comments on a fix. Thanks.</p>

<pre><code>void Serialization::save()
{
    stringstream ss;
    {
        boost::archive::binary_oarchive oa(ss);
        person p(31);
        oa &lt;&lt; p;
     }


        const char * temp1 = ss.str().data();

        stringstream s;
        s &lt;&lt; temp1;

        cout &lt;&lt; ""UNSERIALIZING\n"";
        boost::archive::binary_iarchive ia(s);
        person p1;
        ia &gt;&gt; p1;
        std::cout &lt;&lt; p1.age() &lt;&lt; std::endl;

}
</code></pre>
","<p>Using binary archives with <code>std::stringstream</code> is allowed, as any character can be stored in a <code>std::stringstream</code>/<code>std::string</code>.</p>

<p>The problem is passing around the resulting data as a null terminated C-string, as binary data is highly likely to have embedded nulls thus upon load your data will be truncated. Additionally, your save function is returning data pointing into a destroyed object, invoking <a href=""http://en.wikipedia.org/wiki/Undefined_behavior"" rel=""nofollow"">undefined behavior</a>.</p>
","5188352"
"compact binary representation of json","14150","","<p>Are there any compact binary representations of JSON out there?  I know there is <a href=""http://bsonspec.org"" rel=""noreferrer"">BSON</a>, but even that webpage says ""in many cases is not much more efficient than JSON. In some cases BSON uses even more space than JSON"".</p>

<p>I'm looking for a format that's as compact as possible, preferably some kind of open standard?</p>
","<p>Yes: <a href=""http://wiki.fasterxml.com/SmileFormat"" rel=""noreferrer"">Smile</a> data format. It is relatively new as far as data formats go, has public Java implementation, C version in the works at github (libsmile). It has benefit of being more compact than JSON (reliably), but being 100% compatible logical data model, so it is easy and possible to convert back and forth with textual JSON.</p>

<p>For performance, you can see <a href=""https://github.com/eishay/jvm-serializers/wiki/"" rel=""noreferrer"">jvm-serializers</a> benchmark, where smile competes well with other binary formats (thrift, avro, protobuf); sizewise it is not the most compact (since it does retain field names), but does much better with data streams where names are repeated.</p>

<p>It is being used by some projects (like Elastic Search, Protostuff-rpc supports it), although not as widely as say Thrift.</p>

<p>EDIT (Dec 2011) -- there are now also <code>libsmile</code> bindings for PHP, Ruby and Python, so language support is improving. In addition there are measurements on data size; and although for single-record data alternatives (Avro, protobuf) are more compact, for data streams Smile is often more compact due to key and String value back reference option.</p>
","4904525"
"Correct way to losslessly convert to and from std::string and QByteArray","14020","","<p>What is the correct way to convert losslessly between std::string and QByteArray... mostly for the purpose of handling binary data?</p>

<p>I'm using:</p>

<pre><code>QByteArray qba = QString::fromStdString(stdString).toAscii();
</code></pre>

<p>and</p>

<pre><code>QString(qba).toStdString();
</code></pre>

<p>but I wanted to check whether this is actually correct.</p>
","<p>For binary data your solution is problematic since non-ASCII characters would be converted to <code>'?'</code> by <code>QString::toAscii()</code>. There is also the unnecessary overhead of UTF-16 conversion for the internal representation of <code>QString</code>. As you might have guessed, <code>QString</code> should only be used if the data is textual, not binary.</p>

<p>Both <code>QByteArray</code> and <code>std::string</code> have constructors for raw data (C-string + length) and also a conversion to C-string + length. So you can use them for conversion:</p>

<pre><code>// std::string =&gt; QByteArray
QByteArray byteArray(stdString.c_str(), stdString.length());

// QByteArray =&gt; std::string
std::string stdString(byteArray.constData(), byteArray.length());
</code></pre>

<p>They are both binary-safe, meaning that the string may contain <code>'\0'</code> characters and doesn't get truncated. The data also doesn't get touched (there is no UTF conversion), so this conversion is ""lossless"".</p>

<p>Make sure to use the constructors with the length as the second argument (for both <code>QByteArray</code> and <code>std::string</code>), as most other constructors will truncate the data before the first occurrence of a zero.</p>
","10767823"
"C reverse binary","13971","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/9144800/c-reverse-bits-in-unsigned-integer"">C reverse bits in unsigned integer</a>  </p>
</blockquote>



<p>How can I reverse a binary number only using binary operators?</p>

<p>E.g:</p>

<pre><code>11100000 -&gt; 00000111
00110100 -&gt; 00101100
00111111 -&gt; 11111100
</code></pre>
","<p>For this sort of thing I recommend that you take a look at the awesome page <a href=""http://graphics.stanford.edu/~seander/bithacks.html#ReverseByteWith64BitsDiv"" rel=""noreferrer"">Bit Twiddling Hacks</a>.</p>

<p>Here is just one example solution taken from that page:</p>

<blockquote>
  <p><strong>Reverse the bits in a byte with 3 operations (64-bit multiply and
  modulus division)</strong></p>

<pre><code>unsigned char b; // reverse this (8-bit) byte 
b = (b * 0x0202020202ULL &amp; 0x010884422010ULL) % 1023;
</code></pre>
</blockquote>

<p>And as pointed out in the comments, here's another option:</p>

<blockquote>
  <p><strong>Reverse an N-bit quantity in parallel in 5 * lg(N) operations</strong></p>

<pre><code>unsigned int v; // 32-bit word to reverse bit order

// swap odd and even bits
v = ((v &gt;&gt; 1) &amp; 0x55555555) | ((v &amp; 0x55555555) &lt;&lt; 1);
// swap consecutive pairs
v = ((v &gt;&gt; 2) &amp; 0x33333333) | ((v &amp; 0x33333333) &lt;&lt; 2);
// swap nibbles ... 
v = ((v &gt;&gt; 4) &amp; 0x0F0F0F0F) | ((v &amp; 0x0F0F0F0F) &lt;&lt; 4);
// swap bytes
v = ((v &gt;&gt; 8) &amp; 0x00FF00FF) | ((v &amp; 0x00FF00FF) &lt;&lt; 8);
// swap 2-byte long pairs
v = ( v &gt;&gt; 16             ) | ( v               &lt;&lt; 16);
</code></pre>
</blockquote>
","12903429"
"Writing an array of structs to a binary file in C","13930","","<p>I have an array of structs I would like to write to a binary file. I have a write.c program and a read.c program. The write.c program seems to be working properly but when I run the read.c program I get a segmentation fault. I'm new to C so It would be great if someone could look over my code for any obvious errors. I promise it's not too long :)</p>

<p>write.c:</p>

<pre><code>#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;

struct Person 
{
    char f_name[256];
    char l_name[256];
    int age;
};

int main(int argc, char* argv[])
{
    struct Person* people;
    int people_count;

    printf(""How many people would you like to create: "");
    scanf(""%i"", &amp;people_count);
    people = malloc(sizeof(struct Person) * people_count);  

    int n;
    for (n = 0; n &lt; people_count; n++)
    {
        printf(""Person %i's First Name: "", n);
        scanf(""%s"", people[n].f_name);

        printf(""Person %i's Last Name: "", n);
        scanf(""%s"", people[n].l_name);

        printf(""Person %i's Age: "", n);
        scanf(""%i"", &amp;people[n].age);
    }

    FILE* data;
    if ( (data = fopen(""data.bin"", ""wb"")) == NULL )
    {
        printf(""Error opening file\n"");
        return 1;   
    }

    fwrite(people, sizeof(struct Person) * people_count, 1, data);
    fclose(data);

    return 0;
}
</code></pre>

<p>read.c:</p>

<pre><code>#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;

struct Person 
{
    char f_name[256];
    char l_name[256];
    int age;
};

int main(int argc, char* argv[])
{
    FILE* data;
    if ((data = fopen(""data.bin"", ""rb"")) == NULL)
    {
        printf(""Error opening file\n"");
        return 1;
    }

    struct Person* people;

    fread(people, sizeof(struct Person) * 1/* Just read one person */, 1, data);
    printf(""%s\n"", people[0].f_name);

    fclose(data);

    return 0;
}
</code></pre>

<p>Thanks for the help!</p>
","<pre><code>struct Person* people;
</code></pre>

<p>This allocates just a pointer to struct, but you don't have any allocated space for actual struct contents.  Either use <code>malloc</code> similarly to your write program, or try something like:</p>

<pre><code>struct Person people;
fread(&amp;people, sizeof(people), 1, data);
</code></pre>
","4368712"
"how to xor binary with python","13892","","<p>I'm trying to xor 2 binaries using python like this but my output is not in binary
any help?</p>

<pre><code>a = ""11011111101100110110011001011101000""
b = ""11001011101100111000011100001100001""
y = int(a) ^ int(b)
print y
</code></pre>
","<pre><code>a = ""11011111101100110110011001011101000""
b = ""11001011101100111000011100001100001""
y = int(a,2) ^ int(b,2)
print '{0:b}'.format(y)
</code></pre>
","19414115"
"convert decimal to 32 bit binary?","13874","","<p>convert a positive integer number in C++ (0 to 2,147,483,647) to a 32 bit binary and display.</p>

<p>I want do it in traditional ""mathematical"" way (rather than use <strong>bitset</strong> or use <strong>vector</strong> *<em>.pushback</em>* or recursive function or some thing special in C++...), (one reason is so that you can implement it in different languages, well maybe)</p>

<p>So I go ahead and implement a simple program like this:</p>

<pre><code>#include &lt;iostream&gt;
using namespace std;
int main()
{
    int dec,rem,i=1,sum=0;
    cout &lt;&lt; ""Enter the decimal to be converted: "";
    cin&gt;&gt;dec;
    do
    {
        rem=dec%2;
        sum=sum + (i*rem);
        dec=dec/2;
        i=i*10;
    } while(dec&gt;0);

    cout &lt;&lt;""The binary of the given number is: "" &lt;&lt; sum &lt;&lt; endl;

    system(""pause"");
    return 0;
}
</code></pre>

<p>Problem is when you input a large number such as 9999, result will be a negative or some weird number because sum is integer and it can't handle more than its max range, so you know that a 32 bit binary will have 32 digits so is it too big for any number type in C++?. Any suggestions here and about display 32 bit number as question required?</p>
","<p>Using a for-loop, and a predefined array of zero-chars:</p>

<pre><code>#include &lt;iostream&gt;
using namespace std;
int main()
{
    int dec;
    cout &lt;&lt; ""Enter the decimal to be converted: "";
    cin &gt;&gt; dec;

    char bin32[]  = ""00000000000000000000000000000000"";
    for (int pos = 31; pos &gt;= 0; --pos)
    {
        if (dec % 2) 
            bin32[pos] = '1';
        dec /= 2;
    }

    cout &lt;&lt; ""The binary of the given number is: "" &lt;&lt; bin32 &lt;&lt; endl;
}
</code></pre>

<p>For performance reasons, you may prematurely suspend the for loop:</p>

<pre><code>    for (int pos = 31; pos &gt;= 0 &amp;&amp; dec; --pos)
</code></pre>

<p>Note, that in C++, you can treat an integer as a boolean - everything != 0 is considered true. </p>
","10684197"
"How can I send data in binary form over a Java socket?","13810","","<p>I've seen lots of examples of sending serialized data over sockets in Java, but all I want is to send some simple integers and a string. And, the problem is I'm trying to communicate these to a binary written in C.</p>

<p>So, bottom line: how can I just send some bytes over a socket in Java?</p>
","<p>I would really recommend not using the Java Sockets library directly.  I've found Netty (from JBoss) to be really easy to implement and really powerful.  The Netty ChannelBuffer class comes with a whole host of options for writing different data types and of course to can write your own encoders and decoders to write POJOs down the stream if you wish.</p>

<p>This page is a really good starter - I was able to make a fairly sophisticated client/server with custom encoders and decoders in under 30 minutes reading this: <a href=""http://docs.jboss.org/netty/3.2/guide/html/start.html"" rel=""nofollow"">http://docs.jboss.org/netty/3.2/guide/html/start.html</a>.</p>

<p>If you really want to use Java sockets.  The socket output stream can be wrapped in a DataOutputStream which allows you to write many different data types as well, for example:</p>

<pre><code>new DataOutputStream(socket.getOutputStream()).writeInt(5);
</code></pre>

<p>I hope that's useful.</p>
","3865061"
"PHP read binary file in real binary","13807","","<p>I searched google for my problem but found no solution.
I want to read a file and convert the buffer to binary like 10001011001011001.</p>

<p>If I have something like this from the file</p>

<pre><code>bmoov���lmvhd�����(tF�(tF�_�
K�T��������������������������������������������@���������������������������������trak���\tkh
d����(tF�(tF������� K������������������������������������������������@������������$edts��
</code></pre>

<p>How can I convert all characters (including also this stuff ��) to 101010101000110010 representation??</p>

<p>I hope someone can help me :)</p>
","<p>Use ord() on each byte to get its decimal value and then sprintf to print it in binary form (and force each byte to include 8 bits by padding with 0 on front).</p>

<pre><code>&lt;?php
$buffer = file_get_contents(__FILE__);
$length = filesize(__FILE__);

if (!$buffer || !$length) {
  die(""Reading error\n"");
}

$_buffer = '';
for ($i = 0; $i &lt; $length; $i++) {
  $_buffer .= sprintf(""%08b"", ord($buffer[$i]));
}

var_dump($_buffer);
</code></pre>

<p>$ php test.php</p>

<pre><code>string(2096) ""00111100001111110111000001101000011100000000101000100100011000100111010101100110011001100110010101110010001000000011110100100000011001100110100101101100011001010101111101100111011001010111010001011111011000110110111101101110011101000110010101101110011101000111001100101000010111110101111101000110010010010100110001000101010111110101111100101001001110110000101000100100011011000110010101101110011001110111010001101000001000000011110100100000011001100110100101101100011001010111001101101001011110100110010100101000010111110101111101000110010010010100110001000101010111110101111100101001001110110000101000001010011010010110011000100000001010000010000100100100011000100111010101100110011001100110010101110010001000000111110001111100001000000010000100100100011011000110010101101110011001110111010001101000001010010010000001111011000010100010000000100000011001000110100101100101001010000010001001010010011001010110000101100100011010010110111001100111001000000110010101110010011100100110111101110010010111000110111000100010001010010011101100001010011111010000101000001010001001000101111101100010011101010110011001100110011001010111001000100000001111010010000000100111001001110011101100001010011001100110111101110010001000000010100000100100011010010010000000111101001000000011000000111011001000000010010001101001001000000011110000100000001001000110110001100101011011100110011101110100011010000011101100100000001001000110100100101011001010110010100100100000011110110000101000100000001000000010010001011111011000100111010101100110011001100110010101110010001000000010111000111101001000000111001101110000011100100110100101101110011101000110011000101000001000100010010100110000001110000110010000100010001011000010000001100100011001010110001101100010011010010110111000101000011011110111001001100100001010000010010001100010011101010110011001100110011001010111001001011011001001000110100101011101001010010010100100101001001110110000101001111101000010100000101001110110011000010111001001011111011001000111010101101101011100000010100000100100010111110110001001110101011001100110011001100101011100100010100100111011""
</code></pre>
","7652077"
"Write Java objects to file","13740","","<p>Is it possible to write objects in Java to a binary file?  The objects I want to write would be 2 arrays of <code>String</code> objects.  The reason I want to do this is to save persistent data. If there is some easier way to do this let me know.</p>
","<p>If you want to write arrays of String, you may be better off with a text file.  The advantage of using a text file is that it can be easily viewed, edited and is usuable by many other tools in your system which mean you don't have to have to write these tools yourself.  </p>

<p>You can also find that a simple text format will be faster and more compact than using XML or JSON.  Note: Those formats are more useful for complex data structures.</p>

<pre><code>public static void writeArray(PrintStream ps, String... strings) {
    for (String string : strings) {
        assert !string.contains(""\n"") &amp;&amp; string.length()&gt;0;
        ps.println(strings);
    }
    ps.println();
}

public static String[] readArray(BufferedReader br) throws IOException {
    List&lt;String&gt; strings = new ArrayList&lt;String&gt;();
    String string;
    while((string = br.readLine()) != null) {
        if (string.length() == 0)
            break;
        strings.add(string);
    }
    return strings.toArray(new String[strings.size()]);
}
</code></pre>

<p>If your start with</p>

<pre><code>String[][] theData = { { ""a0 r0"", ""a0 r1"", ""a0 r2"" } {""r1 c1""} }; 
</code></pre>

<p>This could result in </p>

<pre><code>a0 r0
a0 r1
a0 r2

r1 c1
</code></pre>

<p>As you can see this is easy to edit/view.</p>

<p>This makes some assumptions about what a string can contain (see the asset).  If these assumptions are not valid, there are way of working around this.</p>
","3031509"
"C++ string to binary code / binary code to string","13677","","<p>I need to convert a string into a string with the binary code of the first string.
For the first part i used this: <a href=""https://stackoverflow.com/questions/10184178/fastest-way-to-convert-string-to-binary"">Fastest way to Convert String to Binary?</a> Worked perfectly but i can't figure out a way to write it into a new string.</p>

<p>Here's the code i'm using so far:</p>

<pre><code>for (size_t i = 0; i &lt; outputInformations.size(); ++i)
{
    cout &lt;&lt; bitset&lt;8&gt;(outputInformations.c_str()[i]);
}
</code></pre>

<p>Output:</p>

<pre><code>01110100011001010111001101110100011101010111001101100101011100100110111001100001011011010110010100001010011101000110010101110011011101000111000001100001011100110111001101110111011011110111001001100100
</code></pre>

<p>Is there a way to write this into a new string? So that i have a string called ""binary_outputInformations"" with the binary code inside it.</p>
","<p>Are you looking for this ?</p>

<pre><code>  string myString = ""Hello World"";
  std::string binary_outputInformations;
  for (std::size_t i = 0; i &lt; myString.size(); ++i)
  {
  bitset&lt;8&gt; b(myString.c_str()[i]);
      binary_outputInformations+= b.to_string();
  }

  std::cout&lt;&lt;binary_outputInformations;
</code></pre>

<p><strong>Output :</strong></p>

<p><code>0100100001100101011011000110110001101111001000000101011101101111011100100110110001100100</code></p>
","18937965"
"Post binary data to a RESTful application","13623","","<p>I'm working on a RESTful web application (Django+Piston). The POST request sends data encoded with Json to the web application. This works fine for all my text only database tables but I also have a table which stores text and binary files. What is the best way to post text and binary data to a RESTful application?</p>
","<p>You can either Base64-encode it and send it as a string in a JSON message, or you can POST or PUT the binary as a separate resource and refer to it by ID or URL in the JSON message. The latter approach is a kind of out-of-band data channel that is quite common in XML-based protocols (e.g., voice chat using XMPP).</p>

<p>You could even quite easily support a hybrid model, whereby:</p>

<ol>
<li>A small image is sent as <code>{""base64"":""OGZmNjJmOWNhYzFlODE0NDBjYmYzNjhjYz...""}</code>;</li>
<li>A large image is uploaded as a reference, <code>{""ref"":""http://myserver.com/bits/E4304205-29B7-48EE-A359-74250E19EFC4""}</code>.</li>
</ol>

<p>To avoid the double-POST needed for externally referenced binaries, you could design some protocol that allows JSON and binary stuff to be mixed in a single transfer. But the incremental gain is unlikely to adequately reward that level of effort.</p>

<p>Finally, from a design perspective, stick to the simple solution until it becomes a problem.</p>
","4032079"
"Get the largest key in a dictionary","13529","","<p>I have a dictionary with keys that are ints. I would like to get the largest key. I don't keep track of keys so they might be consecutive (e.g. 1,2,3,4,5,6) but might skip (1,3,4,5) although I doubt that makes any difference.</p>

<p>Do I just use a binary search or is there a method? As far as I see you can hardly beat binary search for such a simple task - maybe you can halve it.</p>
","<p>If you have LINQ available, you should be able to do:</p>

<pre><code>myDictionary.Keys.Max();
</code></pre>
","8315171"
"How many bits are there in a nibble?","13507","","<p>binary question :)</p>
","<p>The answer is 4 bits. 2 nibbles make a byte.</p>

<p><a href=""http://www.geneziegler.com/clocktower/DrSeuss.html"" rel=""nofollow noreferrer"">See here</a> for a cute poem.</p>
","101494"
"C Post-order/Pre-order Traversal of Binary Tree","13464","","<p>so I have a pre-order traversal function that looks like this</p>

<pre><code>void listInPreOrder(node* hd){
if(hd != NULL) {
        printf(""%d, "", hd-&gt;value);
        listInPreOrder(hd-&gt;left);
        listInPreOrder(hd-&gt;right);
    }
}
</code></pre>

<p>That in fact works, but I thought that making it post order would be as simple as this</p>

<pre><code>void listInPostOrder(node* hd){
if(hd != NULL) {
        listInPreOrder(hd-&gt;left);
        listInPreOrder(hd-&gt;right);
        printf(""%d, "", hd-&gt;value);
    }
}
</code></pre>

<p>But unfortunately it does not work so well. I'm wondering how to fix this, maybe I'm doing something simple wrong. Or maybe it's completely wrong. </p>

<p>Thanks in advance.</p>
","<p>How about you change this:</p>

<pre><code>void listInPostOrder(node* hd){
if(hd != NULL) {
        listInPreOrder(hd-&gt;left);  // PRE order ???
        listInPreOrder(hd-&gt;right); // PRE order ???
        printf(""%d, "", hd-&gt;value);
    }
}
</code></pre>

<p>to this:</p>

<pre><code>void listInPostOrder(node* hd){
if(hd != NULL) {
        listInPostOrder(hd-&gt;left);
        listInPostOrder(hd-&gt;right);
        printf(""%d, "", hd-&gt;value);
    }
}
</code></pre>
","13609815"
"Converting Binary to Decimal using while loop in C++","13450","","<p>I am currently reading a book on C++ and there is a task which asks the reader to convert a binary number (inputted by the user) to a decimal equivalent. So far I have the following code, but all it does is output 0. Any idea what has gone wrong?</p>

<pre><code>#include &lt;iostream&gt;
using namespace std;

int main()
{
int x, b = 10, decimalValue = 0, d, e, f, count = 1, counter = 0;
cout &lt;&lt; ""Enter a binary number: "";
cin &gt;&gt; x;
x /= 10;
while( x &gt; 0)
{
count++;
x = x/10;
}
while (counter &lt; count)
{
      if (x == 1)
      {
            f = 1;
      }
      else{
           f = x % b;
      }
      if (f != 0)
      {
            if (counter == 0)
            {
               decimalValue = 1;
            }
            else
            {
               e = 1;
               d = 1;
               while (d &lt;= counter)
               {
                  e *= 2;
                  d++;
               }
               decimalValue += e;
            }
      }
      x /= b;
      counter++;
}
cout &lt;&lt; decimalValue &lt;&lt; endl;
system(""pause"");
return 0;
</code></pre>

<p>}</p>
","<p>Because the <code>while( x &gt; 0)</code> loop only stops when <code>x &lt;= 0</code>. Besides, <code>cin &gt;&gt; x</code> lets the user input a <em>decimal</em> number.</p>
","6540326"
"How do you convert a string to ascii to binary in C#?","13445","","<p>A while back (freshman year of high school) I asked a really good C++ programmer who was a junior to make a simple application to convert a string to binary. He gave me the following code sample:</p>

<pre><code>void ToBinary(char* str)
{
    char* tempstr;
    int k = 0;

    tempstr = new char[90];

    while (str[k] != '\0')
    {
        itoa((int)str[k], tempstr, 2);
        cout &lt;&lt; ""\n"" &lt;&lt; tempstr;
        k++;
    }

    delete[] tempstr;
}
</code></pre>

<p>So I guess my question is how do I get an equivalent to the itoa function in C#? Or if there is not one how could I achieve the same effect?</p>
","<p>This is very easy to do with C#.</p>

<pre><code>var str = ""Hello world"";

With LINQ
foreach (string letter in str.Select(c =&gt; Convert.ToString(c, 2)))
{
  Console.WriteLine(letter);
}

Pre-LINQ
foreach (char letter in str.ToCharArray())
{
  Console.WriteLine(Convert.ToString(letter, 2));
}
</code></pre>
","736550"
"Convert IP address string to binary in Python","13289","","<p>As part of a larger application, I am trying to convert an IP address to binary. Purpose being to later calculate the broadcast address for Wake on LAN traffic. I am assuming that there is a much more efficient way to do this then the way I am thinking. Which is breaking up the IP address by octet, adding 0's to the beginning of each octet where necessary, converting each octet to binary, then combining the results. Should I be looking at netaddr, sockets, or something completely different?</p>

<p>Example: From 192.168.1.1 to 11000000.10101000.00000001.00000001</p>
","<p>You think of something like below ?</p>

<pre><code>ip = '192.168.1.1'
print '.'.join([bin(int(x)+256)[3:] for x in ip.split('.')])
</code></pre>

<p>I agree with others, you probably should avoid to convert to binary representation to achieve what you want.</p>
","2737863"
"Forcing the ASP.NET Application to load the assembly from bin not from GAC","13141","","<p>Is there any way to force my asp.net application to load the assembly from local bin directory since there is another older version of the assembly with the same name in the gac?</p>

<p>I can't delete the gac version since other applications are using it and I am facing some difficulties when adding the newer version to the gac.</p>
","<p>I found it </p>

<p>To force your application to read from local bin directory you have to remove signing from your assembly and then the application will load the assembly from bin.</p>

<p>Thanks Wyatt Barnett and murad.</p>
","991502"
"Java: Syntax and meaning behind ""[B@1ef9157""? Binary/Address?","13013","","<p>Hey, <strong>I'm trying to figure out what the [B@ prefix means in java.</strong>  They come out when I attempt to print byte arrays. However, byte arrays of size 32 and size 4 are identical in length.  Always ""[@B1234567"".  </p>

<p>What is this? Also, they have the property of only printing hex values.  I know it can't just be a binary print because random extended ascii chars would appear. </p>

<p>Here is an example of a byte[] to byte[] hashtable mapping print, where mappings are separated by a colon, and these are byte arrays of 4-byte keys and 32-byte elements.</p>

<pre><code>[B@1ef9157:[B@1f82982
[B@181ed9e:[B@16d2633
[B@27e353:[B@e70e30
[B@cb6009:[B@154864a
[B@18aaa1e:[B@3c9217
[B@20be79:[B@9b42e6
[B@16925b0:[B@14520eb
[B@8ee016:[B@1742700
[B@1bfc93a:[B@acb158
[B@107ebe1:[B@1af33d6
[B@156b6b9:[B@17431b9
[B@139b78e:[B@16c79d7
[B@2e7820:[B@b33d0a
[B@82701e:[B@16c9867
[B@1f14ceb:[B@89cc5e
[B@da4b71:[B@c837cd
[B@ab853b:[B@c79809
[B@765a16:[B@1ce784b
[B@1319c:[B@3bc473
</code></pre>
","<p>You're looking at the object ID, not a dump of the contents.</p>

<ul>
<li>The <strong>[</strong> means array.</li>
<li>The <strong>B</strong> means byte.</li>
<li>The <strong>@</strong> separates the type from the ID.</li>
<li>The <strong>hex digits</strong> are an object ID or hashcode.</li>
</ul>

<p>If the intent is to print the contents of the array, there are many ways. For example:</p>

<pre><code>byte[] in = new byte[] { 1, 2, 3, -1, -2, -3 };
System.out.println(byteArrayToString(in));

String byteArrayToString(byte[] in) {
    char out[] = new char[in.length * 2];
    for (int i = 0; i &lt; in.length; i++) {
        out[i * 2] = ""0123456789ABCDEF"".charAt((in[i] &gt;&gt; 4) &amp; 15);
        out[i * 2 + 1] = ""0123456789ABCDEF"".charAt(in[i] &amp; 15);
    }
    return new String(out);
}
</code></pre>

<p>A <a href=""http://download.oracle.com/javase/6/docs/technotes/guides/jni/spec/types.html#wp16432"" rel=""noreferrer"">complete list</a> of the type nomenclature can be found in the <a href=""http://download.oracle.com/javase/6/docs/technotes/guides/jni/spec/types.html#wp16432"" rel=""noreferrer"">JNI documentation</a>.</p>

<p>Here is the entire list:</p>

<ul>
<li><strong>B</strong> - byte</li>
<li><strong>C</strong> - char</li>
<li><strong>D</strong> - double</li>
<li><strong>F</strong> - float</li>
<li><strong>I</strong> - int</li>
<li><strong>J</strong> - long</li>
<li><strong>L***fully-qualified-class*</strong>;** - between an <code>L</code> and a <code>;</code> is the full class name, using <code>/</code> as the delimiter between packages (for example, <code>Ljava/lang/String;</code>)</li>
<li><strong>S</strong> - short</li>
<li><strong>Z</strong> - boolean</li>
<li><strong>[</strong> - one <code>[</code> for every dimension of the array</li>
<li><strong>(***argument types*</strong>)***return-type* - method signature, such as <code>(I)V</code>, with the additional pseudo-type of <code>V</code> for void method</li>
</ul>
","1040883"
"Override git's choice of binary file to text","13003","","<p>I've seen several question asking how to make git treat a text file as binary, but haven't seen the opposite yet:</p>

<p>How do I change git's choice of treating a text file as binary? I have a text file where in some configuration strings an EOT and ETX is used to separate parts of the configuration parameters.</p>

<p>For example, the source code contains lines like this:</p>

<pre><code>INPUT 'ScrollRemote[EOT]no[ETX]NumDown[EOT]0[ETX]CalcWidth[EOT]no[ETX]MaxWidth[EOT]80[ETX]FetchOnReposToEnd[EOT]yes[ETX].....'
</code></pre>
","<p>The way files are actually stored inside the Git repository is not relevant to how they are treated when displayed. So the <code>git diff</code> program, when asked to compare two files, first obtains both complete files from the repository and then runs a difference algorithm against them.</p>

<p>Normally, <code>git diff</code> looks for non-printable characters in the files and if it <em>looks</em> like the file is likely to be a binary file, it refuses to show the difference. The rationale for that is binary file diffs are not likely to be human readable and will probably mess up your terminal if displayed.</p>

<p>However, you can instruct <code>git diff</code> to always treat files as text using the <code>--text</code> option. You can specify this for one <code>diff</code> command:</p>

<pre><code>git diff --text HEAD HEAD^ file.txt
</code></pre>

<p>You can make Git always use this option by setting up a <a href=""https://www.kernel.org/pub/software/scm/git/docs/gitattributes.html""><code>.gitattributes</code></a> file that contains:</p>

<pre><code>file.txt diff
</code></pre>

<p>The <code>diff</code> attribute here means:</p>

<blockquote>
  <p>A path to which the <code>diff</code> attribute is set is treated as text, even when they contain byte values that normally never appear in text files, such as NUL.</p>
</blockquote>
","15009104"
"How do I type literal binary in VB.NET?","12991","","<p>How do you type binary literals in VB.NET? </p>

<pre><code>&amp;HFF          // literal Hex -- OK
&amp;b11111111    // literal Binary -- how do I do this?
</code></pre>
","<p>You could define it as string and then parse it:</p>

<pre><code>myBin = Convert.ToInt32(""1010101010"", 2)
</code></pre>
","1417685"
"How to get nth bit (from right) in a binary equivalent of an integer in PHP?","12978","","<p>Suppose I want to find 2nd bit in binary equivalent of 13 (binary : 1101). It should return 0.</p>
","<p><a href=""http://php.net/manual/en/language.operators.bitwise.php"" rel=""noreferrer"">http://php.net/manual/en/language.operators.bitwise.php</a></p>

<pre><code>($x &gt;&gt; 1) &amp; 1
</code></pre>
","2643735"
"java: converting binary to text?","12968","","<p>I wrote this code for converting binary to text . </p>

<pre><code>public static void main(String args[]) throws IOException{

      BufferedReader b = new BufferedReader(new InputStreamReader(System.in));
      System.out.println(""Enter a binary value:"");
      String h = b.readLine();
      int k = Integer.parseInt(h,2);  
      String out = new Character((char)k).toString();
      System.out.println(""string: "" + out);
      } 
}
</code></pre>

<p>and look at the output !</p>

<pre><code>Enter a binary value:
0011000100110000
string: ?
</code></pre>

<p>what's the problem?</p>
","<p>instead of</p>

<pre><code>String out = new Character((char)k).toString();
</code></pre>

<p>do</p>

<pre><code>String out = String.valueOf(k);
</code></pre>

<h2>EDIT:</h2>

<pre><code>String input = ""011000010110000101100001"";
String output = """";
for(int i = 0; i &lt;= input.length() - 8; i+=8)
{
    int k = Integer.parseInt(input.substring(i, i+8), 2);
    output += (char) k;
}   
</code></pre>
","10283034"
"How do machines interpret binary?","12965","","<p>I was just thinking, how do machines interpreter binary code? All I understand is your code get's turned into 1 and 0's so the machine can understand them, but how do they do that? Is it just a normal text to binary translation?</p>
","<p>First, ""binary"" doesn't mean what you think it means (any data on the computer, including text is already binary, it just the way we decide to display and handle is different). </p>

<p>Second, compilation is not a simple transformation to funny characters (if it were, we wouldn't need different compilers for different languages). To actually have some understanding of machine code, you need to understand the architecture that it targets. There are many computer architectures, your PC is just one of them. It is a very broad subject and needs firm understanding of computer architecture to grasp.</p>

<p>I will show an example of a MIPS instructions. If you are interested, you can read on and get some actual knowledge about the subject, try the links at the end of my post.</p>

<p>MIPS is a popular introductory subject because its instruction format is one of the more digestible ones. MIPS instructions are 32 bit wide. There are 3 kinds of instructions in MIPS: ""R"", ""I"" and ""J"". We will take a look at the ""I"" instructions.</p>

<p>When the processor gets an instruction (32 bits of data) it reads it and decides what to do with it. ""I"" instructions look like this:</p>

<pre><code>|------|-----|-----|----------------|
 opcode   rs    rt    immediate
   6      5     5     16               (the numbers show how wide are each part)
</code></pre>

<p>The meaning of these:</p>

<ul>
<li><strong>opcode</strong> tells what kind of instruction this is (for example: addition, subtraction, multiplication and many others). All instructions (including ""R"" and ""J"" types) start with the 6-bit opcode, and that's how the processor knows which kind it is.</li>
<li><strong>rs</strong> and <strong>rt</strong> are registers, a kind of storage in the processor that can hold 32 bit values. MIPS has 32 of these and they are identified by their number. This is not the same as memory, it's inside the CPU itself.</li>
<li><strong>immediate</strong> is a number. It is called that because the number is ""right there"" in the instruction, not in a register or memory.</li>
</ul>

<p>A concrete example of adding an <em>immediate</em> to a number stored in a register:</p>

<pre><code>001000 00001 00010 0000000000000011
</code></pre>

<p>In this example, I broke the instruction into parts as above. The meaning of the values is the following:</p>

<ul>
<li><strong>opcode</strong>: <code>001000</code> means <code>addi</code> or ""add immediate"".</li>
<li><strong>rs</strong>: <code>00001</code> is <code>1</code> in decimal, so this part of the instruction tells the processor that we want to use register 1 as <strong>rs</strong>.</li>
<li><strong>rd</strong>: <code>00010</code> is <code>2</code> in decimal, same idea as with rs.</li>
<li><strong>immediate</strong>: <code>0000000000000011</code> is <code>3</code> in decimal. </li>
</ul>

<p>The <code>addi</code> instruction works like this: it takes the value found in <strong>rs</strong> and adds the <strong>immediate</strong> value to it. After that it puts the outcome into <strong>rd</strong>. So, when the instruction is done, <strong>rd</strong> will contain 3+2=5.</p>

<p>In a nutshell, compilers parse your text and generate instructions to the target processor that does the same thing that you intended to do with your program. As you can see, there is a huge gap between the textual representation of the program that us programmers write, and the runnable machine code.</p>

<p>A few useful resources on MIPS and computer architecture:</p>

<ul>
<li><a href=""http://www.youtube.com/watch?v=4TzMyXmzL8M"" rel=""noreferrer"">Video lecture on computer architecture</a></li>
<li><a href=""http://www.scss.tcd.ie/~jones/vivio/dlx/dlxtutorial.htm"" rel=""noreferrer"">How instruction decoding works inside a MIPS processor</a></li>
<li><a href=""http://rads.stackoverflow.com/amzn/click/0123744938"" rel=""noreferrer"">Computer organization and design</a></li>
<li><a href=""http://courses.missouristate.edu/KenVollmar/MARS/"" rel=""noreferrer"">MARS</a> allows you to play with MIPS machine code</li>
</ul>
","9547498"
"How Does Ruby handle bytes/binary?","12951","","<p>I'm trying to send a series of binary bytes across a socket, to meet a particular standard my company uses. No one in my company has used Ruby for this before, but in other languages, they send the data across one byte at a time, (usually with some sort of ""pack"" method). </p>

<p>I can't find anyway to create binary on the fly, or create bytes at all (the closest I can find it how you can turn a string into the bytes representing it's characters).  </p>

<p>I know you can say something like :</p>

<p>@var = 0b101010101</p>

<p>But how would I convert a string in the form ""101010101"" or the resulting integer created when I do string.to_i(2) into an actual binary. If I just send the string accross a socket, won't that just send the ASCII for ""0"" and ""1"" instead of the literal characters?  </p>

<p>Surely there is SOME way to do this natively in Ruby?</p>
","<p>To make a string that has an arbitrary sequence of bytes, do something like this:</p>

<pre><code>binary_string = ""\xE5\xA5\xBD""
</code></pre>

<p>The ""\x"" is a special escape to encode an arbitrary byte from hex, so ""\xE5"" means byte 0xE5.</p>

<p>Then try sending that string on the socket.</p>
","4235560"
"Automatically open a file as binary with Ruby","12895","","<p>I'm using Ruby 1.9 to open several files and copy them into an archive. Now there are some binary files, but some are not. Since Ruby 1.9 does not open binary files automatically as binaries, is there a way to open them automatically anyway? (So "".class"" would be binary, "".txt"" not)</p>
","<p>Actually, the previous answer by Alex D is incomplete. While it's true that there is no ""text"" mode in Unix file systems, Ruby does make a difference between opening files in binary and non-binary mode:</p>

<pre><code>s = File.open('/tmp/test.jpg', 'r') { |io| io.read }
s.encoding
=&gt; #&lt;Encoding:UTF-8&gt;
</code></pre>

<p>is different from (note the <code>""rb""</code>)</p>

<pre><code>s = File.open('/tmp/test.jpg', 'rb') { |io| io.read }
s.encoding
=&gt; #&lt;Encoding:ASCII-8BIT&gt;
</code></pre>

<p>The latter, as the <a href=""http://www.ruby-doc.org/core-1.9.3/IO.html"" rel=""noreferrer"">docs</a> say, set the external encoding to ASCII-8BIT which tells Ruby to not attempt to interpret the result at UTF-8. You can achieve the same thing by setting the encoding explicitly with <code>s.force_encoding('ASCII-8BIT')</code>. This is key if you want to read binary into a string and move them around (e.g. saving them to a database, etc.).</p>
","11770507"
"Converting (void*) to std::vector<unsigned char>","12837","","<p>I have a <code>(void*)</code> buffer that I need to convert to <code>std::vector&lt;unsigned char&gt;</code> before I can pass it on. Unfortunately, my C++ casting skills  a little weak. Any suggestions?</p>
","<p>You will need the length of the buffer. Once you do, we can do this:</p>

<pre><code>unsigned char *charBuf = (unsigned char*)voidBuf;
/* create a vector by copying out the contents of charBuf */
std::vector&lt;unsigned char&gt; v(charBuf, charBuf + len);
</code></pre>

<p>Okay, the comment got me started on why I did not use <code>reinterpret_cast</code>:</p>

<blockquote>
  <ul>
  <li><p>In C++, the C-style cast is a convenience function -- it asks the compiler to choose the safest and most portable form of conversion over the set of available cast operators.</p></li>
  <li><p>The <code>reinterpret_cast</code> is implementation defined and should always be the last thing on your mind (and used when you are necessarily doing a non-portable thing knowingly).</p></li>
  <li><p>The conversion between (<code>unsigned</code> doesn't change the type) <code>char *</code> and <code>void *</code> is portable (you could actually use <code>static_cast</code> if you are really picky).</p></li>
  </ul>
</blockquote>

<p>The problem with the C-style cast is: the added flexibility can cause heartaches when the pointer type changes.</p>

<p><strong>Note:</strong> I agree with the general convention of not casting as much as possible. However, without any source provided, this is the best I could do.</p>
","725066"
"String binary to Hex Java","12828","","<p>i have code that looks like this </p>

<pre><code>             public static void main(String[] args) {
    String string= ""11011100010000010001000000000000"";
   String string1= ""00000000010000110000100000101100"";

    System.out.println(Integer.toHexString(Integer.parseInt(string1,2)));

    System.out.println(Integer.toHexString(Integer.parseInt(string,2)));


}
</code></pre>

<p>the first string convert just fine but the second one has an error of  java.lang.NumberFormatException
dont know what the problem is</p>
","<p>When the most significant bit of a 32-character binary number is set to <code>1</code>, the resultant value exceeds the range of positive numbers supported by <code>int</code>, and can no longer be interpreted as a valid integer number. This causes the exception according to the documentation:</p>

<p>An exception of type NumberFormatException is thrown if any of the following situations occurs:</p>

<blockquote>
  <ul>
  <li>The first argument is null or is a string of length zero.</li>
  <li>The radix is either smaller than Character.MIN_RADIX or larger than Character.MAX_RADIX.</li>
  <li>Any character of the string is not a digit of the specified radix, except that the first character may be a minus sign '-' ('\u002D') provided that the string is longer than length 1.</li>
  <li><strong>The value represented by the string is not a value of type int.</strong> (emphasis is mine)</li>
  </ul>
</blockquote>

<p>In order to enter this negative binary value, use <code>-</code> sign in front of your number, and convert the remaining bits to 2-s complement representation.</p>

<p>If you need numbers that are longer than 32 bits, or if you would like the value to continue being interpreted as a positive number, you would need to switch to the 64-bit integer data type.</p>
","13677166"
"How can I convert 32-bit binary number to floating point number?","12820","","<p>I have this 32-bit binary number (00111111010000000000000000000000) and I want to know how I can go about converting it to a floating point number.</p>

<p>Without using programming or a converter, how can I manually convert this 32-bit binary number into a floating point number?</p>

<p>Thanks,</p>

<p>Dan</p>
","<p>Assuming you are a looking for a single floating point here is the format:</p>

<p>First digit is sign, next 8 are the exponent and finally, the last 23 are the significand.</p>

<p>For your number (00111111010000000000000000000000)</p>

<p>Sign: 0 is + <br />
Exponent: 01111110 is -1 (126-127) <br />
Significand: 10000000000000000000000 is 1.5  (The 'invisible' first bit gives you 1, then the second bit (only one set) is 0.5, the next one would have been 0.25, then 0.125 and so on) <br /> <br /></p>

<p>You then calculate the value as such:<br /><br />
sign * 2^exp * Significand<br/></p>

<p>1 * 2^-1 * 1.5<br />
1 * 0.5 * 1.5<br />
 0.75
<br /><br />
You floating point number is equal to 0.75.</p>
","14504675"
"HTTP POST binary files using Python: concise non-pycurl examples?","12735","","<p>I'm interested in writing a short python script which uploads a short binary file (.wav/.raw audio) via a POST request to a remote server.</p>

<p>I've done this with pycurl, which makes it very simple and results in a concise script; unfortunately it also requires that the end 
user have pycurl installed, which I can't rely on.  </p>

<p>I've also  seen some examples in other posts which rely only on basic libraries, urllib, urllib2, etc., however these generally seem to be quite verbose, which is also something I'd like to avoid.  </p>

<p>I'm wondering if there are any concise examples which do not require the use of external libraries, and which will be quick and easy for 3rd parties to understand - even if they aren't particularly familiar with python.</p>

<p>What I'm using at present looks like,</p>

<pre><code>
def upload_wav( wavfile, url=None, **kwargs ):
    """"""Upload a wav file to the server, return the response.""""""

    class responseCallback:
        """"""Store the server response.""""""
        def __init__(self):
            self.contents=''
        def body_callback(self, buf):
            self.contents = self.contents + buf

        def decode( self ):
            self.contents = urllib.unquote(self.contents)
            try:
                self.contents = simplejson.loads(self.contents)
            except:
                return self.contents

    t = responseCallback()
    c = pycurl.Curl()
    c.setopt(c.POST,1)
    c.setopt(c.WRITEFUNCTION, t.body_callback)
    c.setopt(c.URL,url)
    postdict = [
        ('userfile',(c.FORM_FILE,wavfile)),  #wav file to post                                                                                 
        ]
    #If there are extra keyword args add them to the postdict                                                                                  
    for key in kwargs:
        postdict.append( (key,kwargs[key]) )
    c.setopt(c.HTTPPOST,postdict)
    c.setopt(c.VERBOSE,verbose)
    c.perform()
    c.close()
    t.decode()
    return t.contents
</code></pre>

<p>this isn't exact, but it gives you the general idea.  It works great, it's simple for 3rd parties to understand, <em>but</em> it requires pycurl.</p>
","<p>POSTing a file requires <code>multipart/form-data</code> encoding and, as far as I know, there's no easy way (i.e. one-liner or something) to do this with the stdlib.  But as you mentioned, there are plenty of recipes out there.  </p>

<p>Although they seem verbose, your use case suggests that you can probably just encapsulate it once into a function or class and not worry too much, right?  Take a look at the recipe on ActiveState and read the comments for suggestions:</p>

<ul>
<li><a href=""http://code.activestate.com/recipes/146306/"" rel=""nofollow noreferrer"">Recipe 146306: Http client to POST using multipart/form-data</a></li>
</ul>

<p>or see the <code>MultiPartForm</code> class in this PyMOTW, which seems pretty reusable:</p>

<ul>
<li><a href=""http://pymotw.com/2/urllib2/"" rel=""nofollow noreferrer"">PyMOTW: urllib2 - Library for opening URLs.</a></li>
</ul>

<p>I believe both handle binary files.</p>
","1264540"
"Binary to String/Text in Python","12721","","<p>I have searched many times online and I have not been able to find a way to convert my binary string variable, <strong><em>X</em></strong></p>

<pre><code>X = ""1000100100010110001101000001101010110011001010100""
</code></pre>

<p>into a UTF-8 string value.</p>

<p>I have found that some people are using methods such as</p>

<pre><code>b'message'.decode('utf-8')
</code></pre>

<p>however, this method has not worked for me, as 'b' is said to be nonexistent, and I am not sure how to replace the 'message' with a variable. Not only, but I have not been able to comprehend how this method works. Is there a better alternative?</p>

<p>So how could I convert a binary string into a text string?</p>

<p>EDIT: I also do not mind ASCII decoding</p>

<p>CLARIFICATION: Here is specifically what I would like to happen.</p>

<pre><code>def binaryToText(z):
    # Some code to convert binary to text
    return (something here);
X=""0110100001101001""
print binaryToText(X)
</code></pre>

<p>This would then yield the string...</p>

<pre><code>hi
</code></pre>

<p>Thanks,
Daniel</p>
","<p>It looks like you are trying to decode ASCII characters from a binary string representation (bit string) of each character.</p>

<p>You can take each block of eight characters (a byte), convert that to an integer, and then convert that to a character with <code>chr()</code>:</p>

<pre><code>&gt;&gt;&gt; X = ""0110100001101001""
&gt;&gt;&gt; print(chr(int(X[:8], 2)))
h
&gt;&gt;&gt; print(chr(int(X[8:], 2)))
i
</code></pre>

<p>Assuming that the values encoded in the string are ASCII this will give you the characters. You can generalise it like this:</p>

<pre><code>def decode_binary_string(s):
    return ''.join(chr(int(s[i*8:i*8+8],2)) for i in range(len(s)//8))

&gt;&gt;&gt; decode_binary_string(X)
hi
</code></pre>

<p>If you want to keep it in the original encoding you don't need to decode any further. Usually you would convert the incoming string into a Python <em>unicode</em> string and that can be done like this (Python 2):</p>

<pre><code>def decode_binary_string(s, encoding='UTF-8'):
    byte_string = ''.join(chr(int(s[i*8:i*8+8],2)) for i in range(len(s)//8))
    return byte_string.decode(encoding)
</code></pre>
","40559005"
"How do you transfer a binary file via Connect:Direct NDM?","12667","","<p>I'm trying to submit a binary file, in this case, an Excel file from my local server (Solaris server with Mainframe rehosting software) using Connect:Direct NDM to a destination server (Mainframe).</p>

<p>Here are the environment values I set:</p>

<pre><code>SODETFL ""DetailedReport.xls""
SODDETNDM ""FIN.REPORT(+1)""
TDCOPTS "":DATATYPE=BINARY:XLATE=NO:STRIP.BLANKS=NO""
</code></pre>

<p>Here is the NDM configuration I use:</p>

<pre><code>ASSGNDD ddname='SYSIN' type='INSTREAM'  &lt;&lt; !
  SIGNON                                                                00260005
  SUBMIT  PROC=COPYFILE                    -                            00270005
              JOBNAME=JOB00001             -                            00280005
              PNODE=SERVER001              -                            00290005
              SNODE=NDMIDS                 -                            00300005
              SNODEID=(xxxxxx,xxxxxx)      -                            00310005
              HOLD=NO                      -                            00320005
              NOTIFY=CCACTD                -                            00330005
              NODE=,                       -                            00360005
    DSN1=${SODDETFL}                       -                            00370005
    DSN2=${SODDETNDM}                      -
    DCBINFO='dcb=(dsorg=ps, recfm=vb, lrecl=1504)'     -                                                                                                             00385005
              DISP1=NEW,                   -                            00390005
              DISP2=CATLG,DELETE           -                            00400005
              UNIT=BATCH                   -                            00410005
              SYSOPTS=${TDCOPTS}           -                            00440005
              AEFAJOB=PSIAPNB5
   SEL PROC WHERE (QUEUE=A) TABLE                                       00450005
   SIGNOFF                                                              00460005
</code></pre>

<p>I'm able to send text files via NDM all day long, no problems there.  However, it seems that binary is a bit more difficult.  When I try with the above configuration, I get the following error:</p>

<pre><code>Completion Code  =&gt; 8
Message Id       =&gt; XCPS009I
Short Text       =&gt; Read buffer too small. Possibly src reclen &gt; dest reclen.
Ckpt=&gt;Y  Lkfl=&gt;N  Rstr=&gt;N  Xlat=&gt;Y  Scmp=&gt;N  Ecmp=&gt;Y  Ecpr=&gt;0.00 CRC=&gt;N Zlvl=&gt;1 win=&gt;13 Zmem=&gt;4
</code></pre>

<p>Can anyone shed some light as to how I can go about submitting a binary file via NDM?</p>
","<p>Off the cuff...
Try changing RECFM=VB to RECFM=U and specify a BLKSIZE= instead of a LRECL=</p>

<p>This is really not all that different from how executable load modules are stored on the mainframe except you don't want the file to be a PDS dataset.  I'm not at my office right now and I think I have some examples of NDM that transmit load modules that I can look-up if this suggestion doesn't work but I think it will.</p>

<p>Give this suggestion a shot and if it still doesn't fly let me know.</p>
","7641853"
"How do I save a floating-point number in 2 bytes?","12650","","<p>Yes I'm aware of the IEEE-754 half-precision standard, and yes I'm aware of the work done in the field. Put very simply, I'm trying to save a simple floating point number (like <code>52.1</code>, or <code>1.25</code>) in just 2 bytes.</p>

<p>I've tried some implementations in <a href=""https://stackoverflow.com/questions/6162651/half-precision-floating-point-in-java"">Java</a> and in <a href=""http://sourceforge.net/projects/csharp-half/"" rel=""nofollow noreferrer"">C#</a> but they ruin the input value by decoding a different number. You feed in <code>32.1</code> and after encode-decode you get <code>32.0985</code>.</p>

<p>Is there ANY way I can store floating point numbers in just 16-bits without ruining the input value?</p>

<p>Thanks very much.</p>
","<p>You could store three digits in BCD and use the remaining four bits for the decimal point position:</p>

<pre><code>52.1 = 521 * 10 ^ -1 =&gt; 0x1521
1.25 = 125 * 10 ^ -2 =&gt; 0x2125
</code></pre>

<p>This would give you a range from 0.0000000000000001 to 999. You can of course add an offset for the decimal point to get for example the range 0.0000000001 to 999000000.</p>

<hr>

<p>Simple implementation of four bit used for decimal point placement, and the rest for the value. Without any error check, and not thoroughly checked. (May have precision issues with some values when using <code>!=</code> to compare doubles.)</p>

<pre><code>public static short Encode(double value) {
  int cnt = 0;
  while (value != Math.Floor(value)) {
    value *= 10.0;
    cnt++;
  }
  return (short)((cnt &lt;&lt; 12) + (int)value);
}

public static double Decode(short value) {
  int cnt = value &gt;&gt; 12;
  double result = value &amp; 0xfff;
  while (cnt &gt; 0) {
    result /= 10.0;
    cnt--;
  }
  return result;
}
</code></pre>

<p>Example:</p>

<pre><code>Console.WriteLine(Encode(52.1));
Console.WriteLine(Decode(4617));
</code></pre>

<p>Output:</p>

<pre><code>4617
52.1
</code></pre>
","10415012"
"Using Python to read and edit bitmaps","12642","","<p>I need to read a bitmap image file (.bmp) and split the binary data into an array of bytes, which I can then reconstitute into the original file. Eventually, I will be modifying part of each byte to store data and then reading it to get the data back.</p>

<h2>Details</h2>

<p>Currently, I am using</p>

<blockquote>
  <p>file = open(""example.bmp"",""rb"")</p>
  
  <p>data = file.read()</p>
  
  <p>file.close()</p>
</blockquote>

<p>to get the data. However, this is rather slow and inefficient. Next I want to split it into a byte array, and change the last bit to 0 for each bit that is not part of the metadata (I will use <code>if</code> statements to subtract 1 from each odd byte). Then I will re-merge the data, and save it into a new image file with the following code:</p>

<blockquote>
  <p>file = open(""example2.bmp"",""wb"")</p>
  
  <p>file.write(data)</p>
  
  <p>file.close()</p>
</blockquote>

<p>although I suspect this may be sub-optimal too.</p>

<p>I need to know how to split a lot of binary data into bytes.</p>
","<p><code>data</code> is already a byte array, which you can index with slice notation.  For example, according to the <a href=""http://en.wikipedia.org/wiki/BMP_file_format"" rel=""nofollow noreferrer"">BMP file format</a>, the Bitmap File Header is in <code>data[0:14]</code>.  You may want to instead use <a href=""https://stackoverflow.com/questions/10439104/reading-bmp-files-in-python"">C libraries in Python</a> to save yourself some time.</p>
","17071441"
"Convert an integer to a binary string with leading zeros","12637","","<p>I need to convert int to bin and with extra bits.</p>

<pre><code>string aaa = Convert.ToString(3, 2);
</code></pre>

<p>it returns <code>11</code>, but I need <code>0011</code>, or <code>00000011</code>.</p>

<p>How is it done?</p>
","<p><code>11</code> is <a href=""http://en.wikipedia.org/wiki/Binary_number#Representation"">binary representation</a> of <code>3</code>. The binary representation of this value is <code>2</code> bits. </p>

<p>3 = 2<sup>0</sup> * 1 + 2<sup>1</sup> * 1</p>

<p>You can use <a href=""http://msdn.microsoft.com/en-us/library/92h5dc07%28v=vs.110%29.aspx""><code>String.PadLeft(Int, Char)</code></a> method to add these zeros.</p>

<pre><code>Convert.ToString(3, 2).PadLeft(4, '0') // 0011
Convert.ToString(3, 2).PadLeft(8, '0') // 00000011
</code></pre>
","23905301"
"Binary data over serial terminal","12631","","<p>My only way of communication with my embedded device is a serial port. By default, embedded Linux uses this port as a terminal. How do I disable this terminal and use the serial link to transfer binary data? I heard of commands like rx and tx but i cannot find them.</p>

<p>I think I can just read() from and write() stuff to /dev/tty but I want to make sure no error messages or whatever mess with my data stream.</p>
","<p>You can use an application like xmodem to transfer file over any terminal. Is the serial port you speak off a terminal, or is it also the kernel console. </p>

<p>If you're kernel is not noisy, then you can use your current connection to make xmodem like transfer. On the host side, you can use kermit, which is nice AND scriptable.</p>

<p>If you want to make your serial port raw, and you have file descriptor ttyfd opened,
here is one way to do it :</p>

<pre><code>struct termios tty, orig_tty;

...

if(tcgetattr(ttyfd, &amp;tty) &lt; 0)
{
    // error checking
}
// backup tty, make it raw and apply changes
orig_tty = tty;
cfmakeraw(&amp;tty);
if(tcsetattr(ttyfd, TCSAFLUSH, &amp;tty) &lt; 0)
{
    // error checking
}

...
//end of program or error path :
tcsetattr(ttyfd, TCSAFLUSH, &amp;orig_tty)
</code></pre>

<p>Don't forget to restore the setting at the end of your program if you still want a good behaved terminal.</p>
","507235"
"C# read binary data from socket","12575","","<p>I'm working on an application that reads and writes binary data from and to a socket. So first I create a socket with TcpClient. But I'm stuck on reading the data from the socket. Are there any code samples on how to read binary data from the socket?</p>

<p>Concrete, there are 2 things I don't understand. First, how do I know if a message is ""received""? Do I need to create some kind of loop for this? And second: what is the best way to read this data, since the data I receive is binary and not just an ordinary string.</p>

<p>Thanks</p>
","<p>The <a href=""http://msdn.microsoft.com/en-us/library/system.net.sockets.tcpclient.aspx"" rel=""noreferrer"">TCPClient documentation</a> from Microsoft is actually pretty useful.</p>

<p><strong>How do read the data from the TCPClient</strong></p>

<p>The key part in the Microsoft example for reading the data from the socket is this:</p>

<pre><code>// Get the stream
NetworkStream stream = client.GetStream();
Byte[] data = new Byte[256];

// String to store the response ASCII representation.
String responseData = String.Empty;

// Read the first batch of the TcpServer response bytes.
int bytes = stream.Read(data, 0, data.Length);
responseData = System.Text.Encoding.ASCII.GetString(data, 0, bytes);
</code></pre>

<p>They use the <a href=""http://msdn.microsoft.com/en-us/library/system.net.sockets.tcpclient.getstream.aspx"" rel=""noreferrer"">GetStream</a> method of the <a href=""http://msdn.microsoft.com/en-us/library/system.net.sockets.tcpclient.aspx"" rel=""noreferrer"">TCPClient</a> class and read all the available data (up to 256 bytes) from the stream.</p>

<p>This is slightly cheating though, as they are just receiving one lot of data and assuming it is a complete and correct message.  It will work fine so long as your client is 100% predicable in that it always sends the same thing then disconnects.</p>

<p>Better way of handling this below...</p>

<p><strong>How do you know if a message is received?</strong></p>

<p>You don't, you just keep receiving data until there is no more then check what you have received (or check as you go).</p>

<p>To do this, you have to design the message to include some way of telling the length (integer at the start indicating length), or have some end of message marker (e.g. carriage return) or have a fixed length message.</p>

<p><em>For example your message specification might be like this:</em></p>

<blockquote>
  <p>DATA 
  hello friend<br>
  END</p>
</blockquote>

<p>By looking for END followed by a carriage return you will know you have found the end of the message.  Likewise the <code>DATA</code> marker at the beginning helps you to tell where a message starts and split out the message data.</p>

<p><strong>What is the best way to read this data?</strong></p>

<p>All data sent/received will be in binary, you need to Encode and Decode the data.   In the example, they are converting binary data to string (and the other way round) using the built in ASCII Encoding class <a href=""http://msdn.microsoft.com/en-us/library/744y86tc.aspx"" rel=""noreferrer"">GetString</a> and <a href=""http://msdn.microsoft.com/en-us/library/ds4kkd55.aspx"" rel=""noreferrer"">GetBytes</a> methods.</p>

<p><strong>Consider implementing a known protocol</strong></p>

<p>I would recommend to (where possible) use an established protocol rather than just sending plain text over TCP.  There are standards for almost anything and anyone connecting to your application will find it easier to follow a known and defined standard.</p>

<p>There are also many pre-built libraries for commonly used protocols saving you and your clients the hastle.</p>
","3701856"
"if two n bit numbers are multiplied then the result will be maximum how bit long","12566","","<p>I was wondering if there is any formula or way to find out much maximum bits will be required if two n bits binary number are multiplied.
I searched a lot for this but was unable to find its answer anywhere.</p>
","<p>It can be simply concluded using examples:</p>

<blockquote>
  <p>11*11(since 11 is the maximum 2 bit number)=1001(4 bit)</p>
  
  <p>111*111=110001(6 bit)</p>
  
  <p>1111*1111=11100001(8 bit)</p>
  
  <p>11111*11111=1111000001(10 bit)</p>
</blockquote>

<p>and so from above we can see your answer is 2*n</p>
","18790083"
"Why do computers work in binary?","12516","","<p>I have done some searching but have not found a truly satisfactory answer. As a developer i want to invest the necessary time in understanding this, thus i am looking for a <strong>complete</strong> explanation on this and feel free to provide any useful references. </p>

<p>Thanks.</p>
","<p>I would recommend buying this <a href=""http://www.pearsonhighered.com/educator/product/Structured-Computer-Organization/9780131485211.page"" rel=""nofollow noreferrer"">book</a> by <a href=""http://en.wikipedia.org/wiki/Andrew_S._Tanenbaum"" rel=""nofollow noreferrer"">Andrew S. Tanenbaum</a>. He developed one of the predecessors to Linux called Minix. I used <a href=""http://www.pearsonhighered.com/educator/product/Structured-Computer-Organization/9780131485211.page"" rel=""nofollow noreferrer"">Structured Computer Organization</a> as part of my university course. </p>

<p>Why computers use binary is not just a matter of switch context. </p>

<p>Relative to a reference voltage of say 3v. +1v(4v) = true or 1 and -1v(2v) = false or 0. </p>

<p>It also has to do with the most <a href=""http://en.wikipedia.org/wiki/Circuit_complexity"" rel=""nofollow noreferrer"">efficient method of creating controlling or logic circuits</a>. This has to do with cost of implementation. How much does it cost to build circuits that work with binary compared to circuits that work with decimal or analogue <a href=""https://stackoverflow.com/questions/5165013/why-computers-work-in-binary/5165174#5165174"">see this answer</a>.  </p>

<p>If you compare how many billions of binary circuit transistors fit on to a modern CPU. The cost of doing that with say decimal (or analogue) system increases exponentially for every digit you want to add as you now have to add that much more controlling circuitry. </p>

<p>If you want to understand some of the most important contributing components that have helped to make binary the default standard for logic and controlling circuitry read and understand the following topics from Wikipedia. It will take about 4 hours to read through the most important topics, which have to do with some of the electrical engineering used to create the circuits. </p>

<p>I tried to be complete in this list of concepts you need to understand how the actual switches work and why they are used. As well as why Binary <a href=""http://en.wikipedia.org/wiki/Category:Computer_arithmetic"" rel=""nofollow noreferrer"">Arithmetic</a> is such an efficient form of computation in hardware.</p>

<ul>
<li><a href=""http://en.wikipedia.org/wiki/Transistor#Types"" rel=""nofollow noreferrer"">Transistor types</a> Understand the <a href=""http://en.wikipedia.org/wiki/NPN_transistor"" rel=""nofollow noreferrer"">pnp and npn transistor types</a> to understand how the actual circuity that forms the switches works. These circuits are very cheap to make and can be shrunk to minuscule(nano meter) size</li>
<li><a href=""http://en.wikipedia.org/wiki/Logic_gate"" rel=""nofollow noreferrer"">Logic Circuitry.</a> If you understand the basic logic circuitry you will understand how the actual transistor types are used to implement them. These relate to some of the programming constructs such as ""and &amp;&amp;"" ""or ||"" and ""if, branch"" constructs. </li>
<li><a href=""http://en.wikipedia.org/wiki/Digital_electronic_circuit"" rel=""nofollow noreferrer"">DigitalCircuitry</a> has a use full disadvantages section comparing analog
and digital circuits </li>
<li><a href=""http://en.wikipedia.org/wiki/NAND_gate"" rel=""nofollow noreferrer"">NAND Logic Gate</a> is important as all other logic gate circuits can be implemented using just this one logic gate. Simplifying the manufacturing process, as the complexity of the machinery used to create the the circuits can be streamlined. </li>
<li><a href=""http://en.wikipedia.org/wiki/Half_adder"" rel=""nofollow noreferrer"">Adder Circuits</a> To understand how basic addition is done using logic gates.</li>
<li><a href=""http://en.wikipedia.org/wiki/Two%27s_complement"" rel=""nofollow noreferrer"">Twos Complement</a> this is very help full in understand number representation in actual CPUs. It is also very cheap to implement this type of arithmetic in a CPU, as it requires fewer transistors. For instance a simple addition circuitry is all that is need to do addition and subtraction. If you add a negative number you get the correct answer ie +7 + (-4) = +3. This also helps to understand the <a href=""http://en.wikipedia.org/wiki/Integer_overflow"" rel=""nofollow noreferrer"">integer overflow</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Binary_number"" rel=""nofollow noreferrer"">Binary_number</a></li>
<li>These are some of the most used circus for controlling other circuits. These control when circuits are switched on and off. <a href=""http://en.wikipedia.org/wiki/Decoder"" rel=""nofollow noreferrer"">Decoder</a> <a href=""http://en.wikipedia.org/wiki/Priority_encoder#Simple_encoder"" rel=""nofollow noreferrer"">Encoder</a> How (if or branch) condition logic is implemented. </li>
<li><a href=""http://en.wikipedia.org/wiki/Multiplexer"" rel=""nofollow noreferrer"">Multiplexer</a> Is fundamental to how routing is done. In a CPU, BUS and in a network. One of the most common logic circuits found in most digital devices. </li>
</ul>

<p>Now for some hard cores stuff. C. and C++ is used to write <a href=""http://lwn.net/Kernel/LDD3/"" rel=""nofollow noreferrer"">device drivers</a> that speak to actual hardware. If you really want to get into how certain devices work, your CPU, and or external devices <a href=""http://en.wikipedia.org/wiki/Assembly_language"" rel=""nofollow noreferrer"">learn Assembler</a>. You will begin to see how you can switch off a device by setting a certain device register to a specific value, that will be read by a logic circuit to change the devices state. For example you will understand why (0101) base2 = 5 (binary related stuff) will route a specific way through the circuits to switch the device on and off.</p>
","5167023"
"convert binary data to image using php","12484","","<p>I have binary image data saved in my old database, it is saved by my old developer, now i want to display image from that using PHP, but I can not.</p>

<p>I have tried <a href=""http://in1.php.net/imagecreatefromstring"" rel=""nofollow""><code>imagecreatefromstring</code></a> but it returns <code>FALSE</code>. </p>

<p>Binary example data: <a href=""http://freezinfo.com/gg.php"" rel=""nofollow"">http://freezinfo.com/gg.php</a></p>
","<p>Given the string displayed as text (<a href=""https://gist.github.com/hakre/281cc062d52f13373f0d"" rel=""nofollow noreferrer"">extactly this sequence</a>), it's a lineup of hexadecimal numbers.</p>

<p>In Jpeg, the magic numbers of such a file are <code>FF D8</code> as the first two bytes and <code>FF D9</code> as the last two bytes (compare with <a href=""https://stackoverflow.com/q/4550296/367456""><em>How to identify contents of a byte[] is a jpeg?</em></a>).</p>

<p>These hexadecimal (hex in short) numbers can be found at the beginning and end of your sequence as well:</p>

<pre><code>FF00D800FF00 ... 1F00FF00D9000
##  ##               ##  ##
</code></pre>

<p>Looking for these magic numbers also reveals that the hex values are append with <code>00</code> always. It also shows that at the very end an extra single <code>0</code> is found.</p>

<p>So four characters always form one value. Hex-encoded this looks like 16 bit values however the value never goes over the 8 bit range (0-255), therefore there is always <code>00</code> visible.</p>

<p>With this information alone one then can try to turn this into a binary string that PHP's <code>imagecreatefromstring</code> can deal with:</p>

<pre><code>$string = implode('',         // map array of binary strings to binary string
    array_map('chr',          // map ord integer value to character
        unpack('v*',          // unsigned short (always 16 bit, little endian byte order)
            pack(""H*"", $data) // hex to binary (high nibble first)
)));
</code></pre>

<p>Using such a string then in </p>

<pre><code>$result = imagecreatefromstring($string);
imagejpeg($result, 'test.jpg');
</code></pre>

<p>reveals the following PHP error notice:</p>

<blockquote>
  <p>imagecreatefromstring(): gd-jpeg, libjpeg: recoverable error: Corrupt JPEG data: bad Huffman code</p>
</blockquote>

<p>and the following image:</p>

<p><img src=""https://i.stack.imgur.com/lQGyC.jpg"" alt=""enter image description here""></p>

<p>This looks desperately broken. So you are probably facing an additional encoding problem here. The last <code>NUL</code> byte suggests that more has been done and there also must be a reason why the data has been stored as 16 bit hex values instead of just binary data (blob) as databases have support for that.</p>

<p>But don't waste too much time, because of the flaw in the software and configuration that was used in the past, this might just be data-loss so all you can do is to restore from backups.</p>
","17594208"
"Lua: print integer as a binary","12482","","<p>How can I represent integer as Binary?</p>

<p>so I can print <code>7</code> as <code>111</code></p>
","<p>You write a function to do this.</p>

<pre><code>num=7
function toBits(num)
    -- returns a table of bits, least significant first.
    local t={} -- will contain the bits
    while num&gt;0 do
        rest=math.fmod(num,2)
        t[#t+1]=rest
        num=(num-rest)/2
    end
    return t
end
bits=toBits(num)
print(table.concat(bits))
</code></pre>

<p>In Lua 5.2 you've already have bitwise functions which can help you ( <a href=""http://www.lua.org/manual/5.2/manual.html#6.7"" rel=""nofollow noreferrer"">bit32</a> )</p>

<hr>

<p>Here is the most-significant-first version, with optional leading 0 padding to a specified number of bits:</p>

<pre><code>function toBits(num,bits)
    -- returns a table of bits, most significant first.
    bits = bits or math.max(1, select(2, math.frexp(num)))
    local t = {} -- will contain the bits        
    for b = bits, 1, -1 do
        t[b] = math.fmod(num, 2)
        num = math.floor((num - t[b]) / 2)
    end
    return t
end
</code></pre>
","9080080"
"MATLAB: Converting a uint32 (4-byte) value to the corresponding IEEE single-precision floating-point form","12416","","<p>In MATLAB (r2009b) I have a uint32 variable containing the value 2147484101.</p>

<p>This number (its 4-bytes) has been extracted from a digital machine-vision camera in a grabbing process. According to what I understand it holds the single-precision form of the shutter-speed of the camera (should be close to 1/260s = 3.8ms).</p>

<p>How do I convert this 32-bit number to its IEEE single-precision floating-point representation - using what's available in MATLAB?</p>

<p>With mentioned value in variable <em>n</em>, I have tried using a combination of <em>nn=dec2hex(n,16)</em> and then <em>hex2num(nn)</em>. But it seems that <em>hex2num</em> expects the hexadecimal coding to be double-precision and not single as it is here. Atleast I am getting weird numbers with this method.</p>

<p>Any ideas?</p>

<p><strong>Edit:</strong> Tried @Matt's answer below:</p>

<pre><code>typecast(uint32(2147484101),'single') %# without swapbytes
typecast(swapbytes(uint32(2147484101)),'single') %# with swapbytes
</code></pre>

<p>Which gives:</p>

<pre><code>ans =

  -6.3478820e-043

ans =

  -2.0640313e+003
</code></pre>

<p>I tried the IEEE 754 converter (JAVA applet) at <a href=""http://www.h-schmidt.net/FloatApplet/IEEE754.html"" rel=""nofollow"">http://www.h-schmidt.net/FloatApplet/IEEE754.html</a>.</p>

<p>Using:</p>

<pre><code>format hex
typecast(uint32(2147484101),'uint8') %# without swapbytes
typecast(swapbytes(uint32(2147484101)),'uint8') %# with swapbytes
</code></pre>

<p>gives</p>

<pre><code>ans =

   c5   01   00   80

ans =

   80   00   01   c5
</code></pre>

<p>Entering these bytes into the applet (hexadecimal) gives me the same numbers as MATLAB.</p>
","<p>I think what you're saying is that the underlying bits represent a floating point number, but that you've got it stored as a uint32.</p>

<p>If that's that case, you can cast it (i.e. reinterpret the bits) as a single precision float using the typecast() function.</p>

<pre><code>b = typecast(a, 'single')
</code></pre>

<p>where a is your variable.</p>

<p>See:
<a href=""http://www.mathworks.com/help/techdoc/ref/typecast.html"" rel=""noreferrer"">http://www.mathworks.com/help/techdoc/ref/typecast.html</a></p>

<p>Edited: not the cast function, the typecast function... My apologies!</p>
","5002337"
"Reading binary data into struct with ifstream","12404","","<p>I'm trying to read binary data from a file using ifstream.</p>

<p>Specifically, I'm trying to populate this ""Header"" struct with data read from a file:</p>

<pre><code>struct Header {
    char id[16];
    int length;
    int count;
};
</code></pre>

<ol>
<li><p>Now, if I read the file in this way, the result is exactly what I want:</p>

<pre><code>input.read((char*)&amp;hdr, sizeof(hdr));
</code></pre></li>
<li><p>But if I instead read each variable of the struct manually, the results are gibberish:</p>

<pre><code>input.read((char*)&amp;hdr.id,     sizeof(hdr.id));
input.read((char*)&amp;hdr.length, sizeof(hdr.length));
input.read((char*)&amp;hdr.count,  sizeof(hdr.count));
</code></pre></li>
</ol>

<p>My question is, what is happening here that makes these two methods return different results?</p>
","<p>As the comment above states, you are probably missing hdr.length and hdr.count.
I tried it with gcc 4.8 and clang 3.5 and it works correctly.</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;fstream&gt;

#pragma pack(push, r1, 1)
struct Header {
    char id[15];
    int length;
    int count;
};
#pragma pack(pop, r1)

int main() {
  Header h = {""alalalala"", 5, 10};

  std::fstream fh;
  fh.open(""test.txt"", std::fstream::out | std::fstream::binary);
  fh.write((char*)&amp;h, sizeof(Header));
  fh.close();

  fh.open(""test.txt"", std::fstream::in | std::fstream::binary);

  fh.read((char*)&amp;h.id, sizeof(h.id));
  fh.read((char*)&amp;h.length, sizeof(h.length));
  fh.read((char*)&amp;h.count, sizeof(h.count));

  fh.close();

  std::cout &lt;&lt; h.id &lt;&lt; "" "" &lt;&lt; h.length &lt;&lt; "" "" &lt;&lt; h.count &lt;&lt; std::endl;
}
</code></pre>
","22192684"
"mysql case sensitive in utf8_general_ci","12388","","<p>I've a mysql database where i use utf8_general_ci (that is case insensitive), and in my tables i have some columns like ID with case-sensitive data (example: 'iSZ6fX' or 'AscSc2')</p>

<p>To distinct uppercase from lowercase is better to set on these columns only the utf8_bin, like this:</p>

<pre><code>CREATE TABLE  `test` (
`id` VARCHAR( 32 ) CHARACTER SET utf8 COLLATE utf8_bin NOT NULL ,
`value1` VARCHAR( 255 ) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL
) ENGINE = MYISAM CHARACTER SET utf8 COLLATE utf8_general_ci
</code></pre>

<p>Or use utf8_general_ci on all columns and use 'BINARY' in the php query, for example:</p>

<pre><code>mysqli_query( $link, ""SELECT * FROM table WHERE BINARY id = 'iSZ6fX'"" );
</code></pre>
","<p>It is better to use the <code>utf8_bin</code> collation because, even though it is not possible in UTF-8, in the general case it is theoretically possible (such as happens with UTF-16) for the <em>same</em> string to be represented by <em>different</em> encodings, which a binary comparison would not understand but a binary collation would.  As documented under <a href=""http://dev.mysql.com/doc/en/charset-unicode-sets.html"" rel=""noreferrer"">Unicode Character Sets</a>:</p>

<blockquote>
  <p>There is a difference between “ordering by the character's code value” and “ordering by the character's binary representation,” a difference that appears only with <code>utf16_bin</code>, because of surrogates.</p>
  
  <p>Suppose that <code>utf16_bin</code> (the binary collation for <code>utf16</code>) was a binary comparison “byte by byte” rather than “character by character.” If that were so, the order of characters in <code>utf16_bin</code> would differ from the order in <code>utf8_bin</code>. For example, the following chart shows two rare characters. The first character is in the range <code>E000-FFFF</code>, so it is greater than a surrogate but less than a supplementary. The second character is a supplementary.</p>

<pre>
Code point  Character                    utf8         utf16
----------  ---------                    ----         -----
0FF9D       HALFWIDTH KATAKANA LETTER N  EF BE 9D     FF 9D
10384       UGARITIC LETTER DELTA        F0 90 8E 84  D8 00 DF 84
</pre>
  
  <p>The two characters in the chart are in order by code point value because <code>0xff9d</code> &lt; <code>0x10384</code>. And they are in order by <code>utf8</code> value because <code>0xef</code> &lt; <code>0xf0</code>. But they are not in order by <code>utf16</code> value, if we use byte-by-byte comparison, because <code>0xff</code> &gt; <code>0xd8</code>.</p>
  
  <p>So MySQL's <code>utf16_bin</code> collation is not “byte by byte.” It is “by code point.” When MySQL sees a supplementary-character encoding in <code>utf16</code>, it converts to the character's code-point value, and then compares. Therefore, <code>utf8_bin</code> and <code>utf16_bin</code> are the same ordering. This is consistent with the SQL:2008 standard requirement for a UCS_BASIC collation: “UCS_BASIC is a collation in which the ordering is determined entirely by the Unicode scalar values of the characters in the strings being sorted. It is applicable to the UCS character repertoire. Since every character repertoire is a subset of the UCS repertoire, the UCS_BASIC collation is potentially applicable to every character set. NOTE 11: The Unicode scalar value of a character is its code point treated as an unsigned integer.”</p>
</blockquote>

<p>Therefore, if comparisons involving these columns will <em>always</em> be case-sensitive, you should set the column's collation to <code>utf8_bin</code> (so that they will remain case sensitive even if you forget to specify otherwise in your query); or if only particular queries are case-sensitive, you could specify that the <code>utf8_bin</code> collation should be used using the <code>COLLATE</code> keyword:</p>

<pre class=""lang-sql prettyprint-override""><code>SELECT * FROM table WHERE id = 'iSZ6fX' COLLATE utf8_bin
</code></pre>
","18738071"
"Negative numbers are stored as 2's complement in memory, how does the CPU know if it's negative or positive?","12348","","<p>-1 can be represented in 4 bit binary as (2's complement) 1111 </p>

<p>15 is also represented as 1111.</p>

<p>So, how does CPU differentiate between 15 and -1 when it gets values from memory?  </p>
","<p>The CPU doesn't care whether a byte holds -1 or 15 when it moves it from one place to another.  There's no such thing as a ""signed move"" (to a location of the same size - there is a signed move for larger or smaller destinations).</p>

<p>The CPU only cares about the representation when it does arithmetic on the byte.  The CPU knows whether to do signed or unsigned arithmetic according to the op-code that you (or the compiler on your behalf) chose.</p>
","7681094"
"Converting Hex to Binary and storing bits in an array","12328","","<p>I'm trying to write a function in C to convert a Hex value into its binary representation then store each bit separately in an array.</p>

<p>So currently I'm using this long winded method..</p>

<pre><code>void HexToBinary(int *bits, unsigned int hex)
{
  bits[31] = (hex &amp; 0x90000000) &gt;&gt; 31;
  bits[30] = (hex &amp; 0x50000000) &gt;&gt; 30;
  bits[29] = (hex &amp; 0x30000000) &gt;&gt; 29;
  bits[28] = (hex &amp; 0x10000000) &gt;&gt; 28;
  bits[27] = (hex &amp; 0x09000000) &gt;&gt; 27;
  bits[26] = (hex &amp; 0x05000000) &gt;&gt; 26;
  bits[25] = (hex &amp; 0x03000000) &gt;&gt; 25;
  bits[24] = (hex &amp; 0x01000000) &gt;&gt; 24;
  bits[23] = (hex &amp; 0x00900000) &gt;&gt; 23;
  bits[22] = (hex &amp; 0x00500000) &gt;&gt; 22;
  bits[21] = (hex &amp; 0x00300000) &gt;&gt; 21;
  bits[20] = (hex &amp; 0x00100000) &gt;&gt; 20;
  bits[19] = (hex &amp; 0x00090000) &gt;&gt; 19;
  bits[18] = (hex &amp; 0x00050000) &gt;&gt; 18;
  bits[17] = (hex &amp; 0x00030000) &gt;&gt; 17;
  bits[16] = (hex &amp; 0x00010000) &gt;&gt; 16;
  bits[15] = (hex &amp; 0x00009000) &gt;&gt; 15;
  bits[14] = (hex &amp; 0x00005000) &gt;&gt; 14;
  bits[13] = (hex &amp; 0x00003000) &gt;&gt; 13;
  bits[12] = (hex &amp; 0x00001000) &gt;&gt; 12;
  bits[11] = (hex &amp; 0x00000900) &gt;&gt; 11;
  bits[10] = (hex &amp; 0x00000500) &gt;&gt; 10;
  bits[9] = (hex &amp; 0x00000300) &gt;&gt; 9;
  bits[8] = (hex &amp; 0x00000100) &gt;&gt; 8;
  bits[7] = (hex &amp; 0x00000090) &gt;&gt; 7;
  bits[6] = (hex &amp; 0x00000050) &gt;&gt; 6;
  bits[5] = (hex &amp; 0x00000030) &gt;&gt; 5;
  bits[4] = (hex &amp; 0x00000010) &gt;&gt; 4;
  bits[3] = (hex &amp; 0x00000009) &gt;&gt; 3;
  bits[2] = (hex &amp; 0x00000005) &gt;&gt; 2;
  bits[1] = (hex &amp; 0x00000003) &gt;&gt; 1;
  bits[0] = (hex &amp; 0x00000001);
}
</code></pre>

<p>Which takes a 8 char (32-bit) hex value and using &amp; and bit shifts identifies the wanted bit and then stores it in the array for each bit in the hex value.</p>

<p>Obviously this is a very long method and not very nice. I'm looking for a shorter and easier way to do it.</p>

<p>The bits have to be stored separately in the array and not in quads as I have to individually access each bit in the program.</p>

<p>What's the best way to go about this?</p>

<p>Thanks </p>
","<pre><code>for (int i=0;i&lt;32;i++) {
  bits[i]=hex&amp;1;
  hex&gt;&gt;=1;
}
</code></pre>
","14005721"
"Binary file IO in python, where to start?","12310","","<p>As a self-taught python hobbyist, how would I go about learning to import and export binary files using standard formats?</p>

<p>I'd like to implement a script that takes ePub ebooks (XHTML + CSS in a zip) and converts it to a mobipocket (Palmdoc) format in order to allow the Amazon Kindle to read it (as part of a larger project that I'm working on).  </p>

<p>There is already an awesome open-source project for managing ebook libraries : <a href=""http://calibre.kovidgoyal.net/"" rel=""noreferrer"">Calibre</a>.  I wanted to try implementing this on my own as a learning/self-teaching exercise.  I started looking at their <a href=""http://bazaar.launchpad.net/~kovid/calibre/trunk/files/head%3A/src/calibre/ebooks/mobi/"" rel=""noreferrer"">python source code</a> and realized that I have no idea what is going on.  Of course, the big danger in being self-taught at anything is not knowing what you don't know.  </p>

<p>In this case, I know that I don't know much about these binary files and how to work with them in python code (<a href=""http://www.python.org/doc/2.6/library/struct.html#module-struct"" rel=""noreferrer"">struct</a>?).  But I think I'm probably missing a lot of knowledge about binary files in general and I'd like some help understanding how to work with them.  <a href=""http://wiki.mobileread.com/wiki/MOBI"" rel=""noreferrer"">Here is a detailed overview</a> of the mobi/palmdoc headers.  Thanks!</p>

<p>Edit: No question, good point!  Do you have any tips on how to gain a basic knowledge of working with binary files?  Python-specific would be helpful but other approaches could also be useful.</p>

<p>TOM:Edited as question, added intro / better title</p>
","<p>You should probably start with the <a href=""http://docs.python.org/library/struct.html"" rel=""noreferrer"">struct</a> module, as you pointed to in your question, and of course, open the file as a binary.</p>

<p>Basically you just start at the beginning of the file and pick it apart piece by piece.  It's a hassle, but not a huge problem.  If the files are compressed or encrypted, things can get more difficult.  It's helpful if you start with a file that you know the contents of so you're not guessing all the time.</p>

<p>Try it a bit, and maybe you'll evolve more specific questions. </p>
","967884"
"How do I dump the struct into the byte array without reflection?","12299","","<p>I already found <a href=""http://golang.org/pkg/encoding/binary/"" rel=""nofollow noreferrer"">encoding/binary</a> package to deal with it, but it depended on <a href=""http://golang.org/pkg/reflect/"" rel=""nofollow noreferrer"">reflect</a> package so it didn't work with uncapitalized(that is, unexported) struct fields. However I spent a week to find that problem out, I still have a question: if struct fields should not be exported, how do I dump them easily into binary data?</p>

<p><strong>EDIT:</strong> Here's the example. If you capitalize the name of fields of <code>Data</code> struct, that works properly. But <code>Data</code> struct was intended to be an abstract type, so I don't want to export these fields.</p>

<pre class=""lang-go prettyprint-override""><code>package main
import (
    ""fmt""
    ""encoding/binary""
    ""bytes""
)

type Data struct {
    id int32
    name [16]byte
}


func main() {
    d := Data{Id: 1}
    copy(d.Name[:], []byte(""tree""))
    buffer := new(bytes.Buffer)
    binary.Write(buffer, binary.LittleEndian, d)
    // d was written properly
    fmt.Println(buffer.Bytes())
    // try to read...
    buffer = bytes.NewBuffer(buffer.Bytes())
    var e = new(Data)
    err := binary.Read(buffer, binary.LittleEndian, e)
    fmt.Println(e, err)
}
</code></pre>
","<p>Your best option would probably be to use the <a href=""http://golang.org/pkg/encoding/gob"" rel=""noreferrer"">gob package</a> and let your struct implement the <a href=""http://golang.org/pkg/encoding/gob/#GobDecoder"" rel=""noreferrer"">GobDecoder</a> and <a href=""http://golang.org/pkg/encoding/gob/#GobEncoder"" rel=""noreferrer"">GobEncoder</a> interfaces in order to serialize and deserialize private fields.</p>

<p>This would be safe, platform independent, and efficient. And you have to add those GobEncode and GobDecode functions only on structs with unexported fields, which means you don't clutter the rest of your code.</p>

<pre><code>func (d *Data) GobEncode() ([]byte, error) {
    w := new(bytes.Buffer)
    encoder := gob.NewEncoder(w)
    err := encoder.Encode(d.id)
    if err!=nil {
        return nil, err
    }
    err = encoder.Encode(d.name)
    if err!=nil {
        return nil, err
    }
    return w.Bytes(), nil
}

func (d *Data) GobDecode(buf []byte) error {
    r := bytes.NewBuffer(buf)
    decoder := gob.NewDecoder(r)
    err := decoder.Decode(&amp;d.id)
    if err!=nil {
        return err
    }
    return decoder.Decode(&amp;d.name)
}

func main() {
    d := Data{id: 7}
    copy(d.name[:], []byte(""tree""))
    buffer := new(bytes.Buffer)
    // writing
    enc := gob.NewEncoder(buffer)
    err := enc.Encode(d)
    if err != nil {
        log.Fatal(""encode error:"", err)
    }
    // reading
    buffer = bytes.NewBuffer(buffer.Bytes())
    e := new(Data)
    dec := gob.NewDecoder(buffer)
    err = dec.Decode(e)
    fmt.Println(e, err)
}
</code></pre>
","12854659"
"Python struct.error: unpack requires a string argument of length 2","12175","","<p>I have written some data using C++ in byte format. I am now trying to read that data again using Python, but I run into an error;</p>

<pre><code>Traceback (most recent call last):
  File ""binary-reader.py"", line 61, in &lt;module&gt;
    interaction_types.append(struct.unpack('&lt;H',fp.read(2))[0]);
struct.error: unpack requires a string argument of length 2
</code></pre>

<p>I don't really understand since it looks like I am giving a string of length 2, right? Furthermore, I do the same thing at line 32</p>

<p>There is <a href=""https://stackoverflow.com/questions/17579444/struct-error-unpack-requires-a-string-argument-of-length-2"">another question like mine</a> but it is without an answer is targeted for Python 3.</p>

<p>Here is my code </p>

<pre><code>import sys
import struct
import os

print ""Arguments : ""
print str(sys.argv)

#N = #isects

#  2      2        3*4      2          3*4*N          4N            4N      3*4N        2N          2N
#imageX,imageY,throughput,#isects,isect_positions,primitive_ids,shape_ids,spectra,interaction_types,light_ids
file_path = str(sys.argv[1]);

byte_count = 0;
line_number = 1;

fp = open(file_path, ""rb"");
output = open('output.txt',""w"");
file_size = os.path.getsize(file_path)

print ""(input) file size = "" + str(file_size);

while byte_count &lt; file_size:
    print ""Line number = "" + str(line_number)
    print ""Current byte count = "" + str(byte_count)
    # Do stuff with byte.
    x = struct.unpack('&lt;H', fp.read(2))[0]
    y = struct.unpack('&lt;H', fp.read(2))[0]
    throughputOne = struct.unpack('&lt;f', fp.read(4))[0]
    throughputTwo = struct.unpack('&lt;f', fp.read(4))[0]
    throughputThree = struct.unpack('&lt;f', fp.read(4))[0]
    nrIsects = struct.unpack('&lt;H',fp.read(2))[0]

    # print ""x = "" + str(x)
    # print ""y = "" + str(y)
    # print ""throughputOne = "" + str(throughputOne)
    # print ""throughputTwo = "" + str(throughputTwo)
    # print ""throughputThree = "" + str(throughputThree)
    print ""nrIsects = "" + str(nrIsects)

    isect_positions = []
    for i in range(nrIsects*3):
        value = struct.unpack('&lt;f',fp.read(4))[0]
        isect_positions.append(value);

    primitive_ids = []
    for i in range(nrIsects):
        value = struct.unpack('&lt;I',fp.read(4))[0]
        primitive_ids.append(value);

    shape_ids = []
    for i in range(nrIsects):
        shape_ids.append(struct.unpack('&lt;I',fp.read(4))[0]);

    spectra = []
    for i in range(nrIsects*3):
        spectra.append(struct.unpack('&lt;f',fp.read(4))[0]);

    interaction_types = []
    for i in range(nrIsects):
        interaction_types.append(struct.unpack('&lt;H',fp.read(2))[0]);

    light_ids = []
    for i in range(nrIsects):
        light_ids.append(struct.unpack('&lt;H',fp.read(2))[0]);

    output_vars = [x,y,throughputOne,throughputTwo,throughputThree,nrIsects]

    line_string = """"

    for i in range(len(output_vars)):
        output.write(str(output_vars[i]))
        line_string += str(output_vars[i])
        if i is not len(output_vars) - 1:
            output.write(',')   
            line_string += ','

    print line_string


    #Update counters
    byte_count += 18 + 36*nrIsects
    line_number+=1

    # raw_input('Press any key to continue.');

    # print byte
</code></pre>

<p>And here is a link to a input file to use. You can run the code by passing a commandline argument specifying the path of the binary file. I have also written the code in ASCII, which reads</p>

<p>0,0,[0.127076,0.127076,0.127076],1,{[0.144978,-0.294863,2.991749]},{3917},{3916},{[1.375603,1.375603,1.375603]},{5},{0}</p>

<p><a href=""https://www.dropbox.com/s/tu1anqo5k0ygtd6/writetest.bin"" rel=""nofollow noreferrer"">https://www.dropbox.com/s/tu1anqo5k0ygtd6/writetest.bin</a></p>

<p>EDIT: The layout of my file can be found as a comment in the code</p>
","<p>50 bytes have already been read before the <code>fp.read(2)</code> that raises the error. Thus, <code>fp.read(2)</code> returns an empty string, and <code>struct.unpack</code> raises an exception:</p>

<pre><code>In [83]: 2+2+4+4+4+2+12+4+4+12
Out[83]: 50
</code></pre>

<hr>

<pre><code>x = struct.unpack('&lt;H', fp.read(2))[0]                  # 2 bytes read
y = struct.unpack('&lt;H', fp.read(2))[0]                  # 2 bytes
throughputOne = struct.unpack('&lt;f', fp.read(4))[0]      # 4 bytes
throughputTwo = struct.unpack('&lt;f', fp.read(4))[0]      # 4 bytes
throughputThree = struct.unpack('&lt;f', fp.read(4))[0]    # 4 bytes
nrIsects = struct.unpack('&lt;H',fp.read(2))[0]            # 2 bytes

print ""nrIsects = "" + str(nrIsects)

isect_positions = []
for i in range(nrIsects*3):
    value = struct.unpack('&lt;f',fp.read(4))[0]           # 12 bytes
    isect_positions.append(value)

primitive_ids = []
for i in range(nrIsects):
    value = struct.unpack('&lt;I',fp.read(4))[0]           # 4 bytes
    primitive_ids.append(value)

shape_ids = []
for i in range(nrIsects):
    shape_ids.append(struct.unpack('&lt;I',fp.read(4))[0]) # 4 bytes

spectra = []
for i in range(nrIsects*3):
    spectra.append(struct.unpack('&lt;f',fp.read(4))[0])   # 12 bytes

interaction_types = []
for i in range(nrIsects):
    interaction_types.append(struct.unpack('&lt;H', fp.read(2))[0])   # error!
</code></pre>

<hr>
","24538205"
"How to insert binary data into sqlite3 database in bash?","12127","","<p>I want to insert binary data(png,jpg,gif,etc) into a sqlite3 database within a bash script.<br>
I use the standalone binary <code>sqlite3</code>. How can I write the SQL statement?<br>
Thanks for your help.</p>
","<p>Here is one way to do it. The file <code>test.jpg</code> is inserted in the table <code>foo</code> of the database <code>foodb</code> after being <code>hexdump</code>ed to the binary literal format of sqlite:</p>

<pre><code>[someone@somewhere tmp]$ sqlite3 foodb ""create table foo (bar blob);""
[someone@somewhere tmp]$ echo ""insert into foo values (X'`hexdump -ve '1/1 ""%.2x""' test.jpg`');"" | sqlite3 foodb
</code></pre>

<p><strong>EDIT</strong></p>

<p>And here we see that the data is store in ""full-fidelity"" as the .jpg file can be restored:</p>

<pre><code>[somneone@somewhere tmp]$ sqlite3 foodb ""select quote(bar) from foo;"" | perl -ne 's/([0-9a-f]{2})/print chr hex $1/gie' &gt; bla.jpg 
[somneone@somewhere tmp]$ ll *.jpg
-rw-rw-r-- 1 someone someone 618441 Apr 28 16:59 bla.jpg
-rw-rw-r-- 1 someone someone 618441 Apr 28 16:37 test.jpg
[someone@somewhere tmp]$ md5sum *.jpg 
3237a2b76050f2780c592455b3414813  bla.jpg
3237a2b76050f2780c592455b3414813  test.jpg
</code></pre>

<p>Furthermore, this approach is space efficient as it store the .jpg using sqlite's BLOB type. It doesn't stringify the image using for example base64 encoding.</p>

<pre><code>[someone@somewhere tmp]$ ll foodb 
-rw-r--r-- 1 someone someone 622592 Apr 28 16:37 foodb
</code></pre>
","10364475"
"How to overwrite some bytes of a binary file with dd?","12109","","<p>I have a binary file and i want to replace the value <code>A2</code> at address <code>DEADBEEF</code> with some other value, say <code>A1</code>.</p>

<p>How can I do this with <code>dd</code>? If there are other tools that can do this, please suggest. But I plan to do this on iPhone so I can only work with most basic Unix tools.</p>
","<pre class=""lang-sh prettyprint-override""><code>printf '\xa1' | dd conv=notrunc of=somefile bs=1 seek=$((0xdeadbeef))
</code></pre>
","7290825"
"Store binary sequence in byte array?","12026","","<p>I need to store a couple binary sequences that are 16 bits in length into a byte array (of length 2). The one or two binary numbers don't change, so a function that does conversion might be overkill. Say for example the 16 bit binary sequence is 1111000011110001. How do I store that in a byte array of length two?</p>
","<pre><code>    String val = ""1111000011110001"";
    byte[] bval = new BigInteger(val, 2).toByteArray();
</code></pre>

<p>There are other options, but I found it best to use <code>BigInteger</code> class, that has conversion to byte array, for this kind of problems. I prefer if, because I can instantiate class from <code>String</code>, that can represent various bases like 8, 16, etc. and also output it as such. </p>

<h2>Edit: Mondays ... :P</h2>

<pre><code>public static byte[] getRoger(String val) throws NumberFormatException,
        NullPointerException {
    byte[] result = new byte[2];
    byte[] holder = new BigInteger(val, 2).toByteArray();

    if (holder.length == 1) result[0] = holder[0];
    else if (holder.length &gt; 1) {
        result[1] = holder[holder.length - 2];
        result[0] = holder[holder.length - 1];
    }
    return result;
}
</code></pre>

<p>Example:</p>

<pre><code>int bitarray = 12321;
String val = Integer.toString(bitarray, 2);
System.out.println(new StringBuilder().append(bitarray).append(':').append(val)
  .append(':').append(Arrays.toString(getRoger(val))).append('\n'));
</code></pre>
","5410101"
"Python ASCII to binary","12016","","<p>Is there a builtin function that converts ASCII to binary?</p>

<p>For example. converts 'P' to 01010000.</p>

<p>I'm using Python 2.6.6</p>
","<p>How about two together?</p>

<pre><code>bin(ord('P'))
# 0b1010000
</code></pre>
","4523564"
"How to convert an IEEE 754 single-precision binary floating-point to decimal?","11981","","<blockquote>
  <p>I am working on a program that needs to convert a 32-bit number into a decimal number. </p>
</blockquote>

<p>The number that I get from input is a 32 bit number represented as floating point. The first bit is the sign, the next 8 bits are the exponent, and the other 23 bits are mantissa. I am working the program in C. In input, I get that number as a <code>char[]</code> array, and after that I am making a new <code>int[]</code> array where I store the sign , the exponent and the mantissa. But, I have problem with the mantissa when I am trying to store it in some datatype, because I need to use the mantissa  as a number, not as an array: <code>formula=sign*(1+0.mantissa)*2^(exponent-127)</code>.</p>

<p>Here is the code I use to store the mantissa, but still the program gets me wrong results:</p>

<pre><code>double oMantissa=0;
int counter=0;
for(counter=0;counter&lt;23;counter++)
{
    if(mantissa[counter]==1)
    {
        oMantissa+=mantissa[counter]*pow(10,-counter);
    }
}
</code></pre>

<p><code>mantissa[]</code> is an <code>int</code> array where I have already converted the mantissa from a <code>char</code> array. When I get the value from <code>formula</code>, it has to be a binary number, and I have to convert it to decimal, so I will get the value of the number. Can you help me with storing the 23 bits of the mantissa? And, I mustn't use functions like <code>strtoul</code> that convert the 32-bit number directly into binary. I have to use <code>formula</code>.</p>
","<p>Which part of the below code was hard to get right given all the formulas and sample numbers and a calculator?</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;limits.h&gt;

#if UINT_MAX &gt;= 0xFFFFFFFF
typedef unsigned uint32;
#else
typedef unsigned long uint32;
#endif

#define C_ASSERT(expr) extern char CAssertExtern[(expr)?1:-1]

// Ensure uint32 is exactly 32-bit
C_ASSERT(sizeof(uint32) * CHAR_BIT == 32);

// Ensure float has the same number of bits as uint32, 32
C_ASSERT(sizeof(uint32) == sizeof(float));

double Ieee754SingleDigits2DoubleCheat(const char s[32])
{
  uint32 v;
  float f;
  unsigned i;
  char *p1 = (char*)&amp;v, *p2 = (char*)&amp;f;

  // Collect binary digits into an integer variable
  v = 0;
  for (i = 0; i &lt; 32; i++)
    v = (v &lt;&lt; 1) + (s[i] - '0');

  // Copy the bits from the integer variable to a float variable
  for (i = 0; i &lt; sizeof(f); i++)
    *p2++ = *p1++;

  return f;
}

double Ieee754SingleDigits2DoubleNoCheat(const char s[32])
{
  double f;
  int sign, exp;
  uint32 mant;
  int i;

  // Do you really need strto*() here?
  sign = s[0] - '0';

  // Do you really need strto*() or pow() here?
  exp = 0;
  for (i = 1; i &lt;= 8; i++)
    exp = exp * 2 + (s[i] - '0');

  // Remove the exponent bias
  exp -= 127;

  // Should really check for +/-Infinity and NaNs here

  if (exp &gt; -127)
  {
    // Normal(ized) numbers
    mant = 1; // The implicit ""1.""
    // Account for ""1."" being in bit position 23 instead of bit position 0
    exp -= 23;
  }
  else
  {
    // Subnormal numbers
    mant = 0; // No implicit ""1.""
    exp = -126; // See your IEEE-54 formulas
    // Account for "".1"" being in bit position 22 instead of bit position -1
    exp -= 23;
  }

  // Or do you really need strto*() or pow() here?
  for (i = 9; i &lt;= 31; i++)
    mant = mant * 2 + (s[i] - '0');

  f = mant;

  // Do you really need pow() here?
  while (exp &gt; 0)
    f *= 2, exp--;

  // Or here?
  while (exp &lt; 0)
    f /= 2, exp++;

  if (sign)
    f = -f;

  return f;
}

int main(void)
{
  printf(""%+g\n"", Ieee754SingleDigits2DoubleCheat(""110000101100010010000000000000000""));
  printf(""%+g\n"", Ieee754SingleDigits2DoubleNoCheat(""010000101100010010000000000000000""));
  printf(""%+g\n"", Ieee754SingleDigits2DoubleCheat(""000000000100000000000000000000000""));
  printf(""%+g\n"", Ieee754SingleDigits2DoubleNoCheat(""100000000100000000000000000000000""));
  printf(""%+g\n"", Ieee754SingleDigits2DoubleCheat(""000000000000000000000000000000000""));
  printf(""%+g\n"", Ieee754SingleDigits2DoubleNoCheat(""000000000000000000000000000000000""));
  return 0;
}
</code></pre>

<p>Output (<a href=""http://ideone.com/seYW5R"" rel=""nofollow"">ideone</a>):</p>

<pre><code>-98.25
+98.25
+5.87747e-39
-5.87747e-39
+0
+0
</code></pre>
","16183024"
"Convert binary files into ascii in Python","11966","","<p>I have a bunch of binary files that contain data in the following format: </p>

<p><code>i\xffhh\xffhh\xffhh\xffih\xffhh\xffhh\xffhh\xffhh\xffhi\xffii\xffjj\xffjj\xffjj\xffjk\xffkk\xffkk\xffkl\xffll\xffmm\xffmn\xffnn\xffon\xffno\xffop\xffop\xffpp\xffqq\xffrq\xffrs\xffst\xfftt\xfftt\xffuv\xffvu\xffuv\xffvv\xffvw\xffwx\xffwx\xffxy\xffyy\xffyz\xffz{\xffz{\xff||\xff}|\xff~}\xff}}\xff~~\xff~~\xff~\x7f\xff\x7f\x7f\xff\x7f\x7f\xff\x7f\x7f\xff\x80\x80\xff\x80\x81\xff\x81\x80\xff\x81\x81\xff\x81\x82\xff\x82\x82\xff\x82\x82\xff\x82\x83\xff\x83\x83\xff\x83\x83\xff\x83\x84\xff\x83\x84\xff\x84\x85\xff\x85\x85\xff\x86\x85\xff\x86\x87\xff\x87\x87\xff\x87\x87\xff\x88\x87\xff\x88\x89\xff\x88\x89\xff\x89\x8a\xff\x89\x8a\xff\x8a\x8b\xff\x8b\x8b\xff\x8b\x8c\xff\x8d\x8d\xff\x8d\x8d\xff\x8e\x8e\xff\x8e\x8f\xff\x8f\x8f</code></p>

<p>These are supposed to be pressure sensor readings from when a person is walking, so I'm assuming that they are numbers, but I want to convert them into ascii so I have some idea what they are. How do I convert them? What format are they currently in?</p>

<p>EDIT: Link to file provided here (<a href=""http://physionet.org/physiobank/database/gaitndd/als1.let"" rel=""nofollow"">Link</a>)</p>
","<p>You can not guess the format by just opening up a binary file. You will have to get the information on the way data is stored for that particular pressure sensor readings.</p>

<p>Of course, when you know the format, it is easy to read the file in binary mode and then get all the meaningful data from it </p>

<pre><code>FILE = open(filename,""rb"")
FILE.read(numBytes)
</code></pre>
","4218782"
"How to convert a ""binary string"" to base64?","11880","","<p>I've followed this: <a href=""https://dev.twitter.com/docs/auth/creating-signature"" rel=""nofollow"">https://dev.twitter.com/docs/auth/creating-signature</a></p>

<p>to the end but I can't find how to encode a ""binary string"" to base64(at the end). I wanted to try online converters first but they don't give the string the show 
""tnnArxj06cWHq44gCs1OSKk/jLY="" </p>

<p>Tried this: <a href=""http://www.motobit.com/util/base64-decoder-encoder.asp"" rel=""nofollow"">http://www.motobit.com/util/base64-decoder-encoder.asp</a></p>

<p>and </p>

<p><a href=""http://www.hash-cracker.com/base64.php#anchor"" rel=""nofollow"">http://www.hash-cracker.com/base64.php#anchor</a></p>

<p>and </p>

<p><a href=""http://www.opinionatedgeek.com/dotnet/tools/Base64Encode/"" rel=""nofollow"">http://www.opinionatedgeek.com/dotnet/tools/Base64Encode/</a></p>

<p>and none give that string.</p>

<p>I'm going to be using java. But I think all those java tools I search for will give the same result as the online converters. What has to be done to encode a ""binary string"" to base64?</p>
","<p>The problem of using those online tools isn't going to be in the base64 conversion - it's going to be parsing the hex string into a byte array to start with. In your real code that won't be a problem, as it'll be the output of another stage. Just to prove that, here's some sample Java code, using a <a href=""http://iharder.sourceforge.net/current/java/base64/"">public domain base64 encoder</a>:</p>

<pre><code>public class Test {
    public static void main(String[] args) throws Exception {
        byte[] data = { (byte) 0xB6, (byte) 0x79, (byte) 0xC0, (byte) 0xAF, 
                (byte) 0x18, (byte) 0xF4, (byte) 0xE9, (byte) 0xC5, 
                (byte) 0x87, (byte) 0xAB, (byte) 0x8E, (byte) 0x20, 
                (byte) 0x0A, (byte) 0xCD, (byte) 0x4E, (byte) 0x48, 
                (byte) 0xA9, (byte) 0x3F, (byte) 0x8C, (byte) 0xB6 };

        String text = Base64.encodeBytes(data);
        System.out.println(text);
    }
}
</code></pre>

<p>Output: tnnArxj06cWHq44gCs1OSKk/jLY=</p>
","8373752"
"How to convert array of bits to integer in Matlab?","11865","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/1552966/converting-binary-to-decimal-without-using-loop"">Converting binary to decimal without using loop</a>  </p>
</blockquote>



<p>I'm looking for the simplest and fastest solution. I tried documentation but could find anything. </p>

<p>I have an array of bits like [0, 1, 1, 1] and I want to convert it to simple int number 7. I get this array with bitget(x, 1:3), where x is an integer.</p>
","<p>@Edwin's answer uses <em>binvec2dec</em> which is part of the <a href=""http://www.mathworks.com/products/daq/"" rel=""nofollow"">Data Acquisition Toolbox</a>.  This toobox is an additional toolbox (developed by Mathworks) but not part of the base MATLAB package.  </p>

<p>Here is a solution that does not depend on this toolbox.</p>

<ol>
<li><p>Use <em>num2str</em> to convert the binary array to a string</p>

<p>str=num2str(bin_vec);</p></li>
<li><p>use <em>bin2dec</em> to get decimal value</p>

<p>dec_num=bin2dec(str);</p></li>
</ol>
","8423696"
"How to represent floating point in binary. IEEE","11800","","<p>Similar to decimal binary numbers can have represent floats too. Now I read that it can have floats of the sort</p>

<p><code>0.5</code>:<code>0.1</code> , <code>0.25</code>:<code>0.01</code> , <code>0.125</code>:<code>0.001</code> ... and so on. But then, for example,  how is the 0.1(in decimal) represented in binary?</p>

<p>Also, given a decimal float, how to convert it to the decimal equivalent, (given it is not so straightforward).</p>

<p>Edit: So I understand that the better question would have been ; how to convert a decimal float to binary? Now i get it that we multiply the decimal part, till it becomes zero. 
Now it is very much possible that two floating points can have the same representation right?</p>
","<p>Given how many bits?</p>

<p>0.1b:</p>

<pre><code>0.00011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011001100110011...
</code></pre>

<p>As you can see it's an approximation.</p>

<pre><code>Binary                                          Decimal
0.1     == 1/2^1         == 1/2              == 0.5
0.01    == 1/2^2         == 1/4              == 0.25
0.11    == 1/2^1 + 1/2^2 == 1/2 + 1/4 == 3/4 == 0.75
</code></pre>

<p>Each bit after the <a href=""http://en.wikipedia.org/wiki/Radix_point"" rel=""nofollow noreferrer"">radix point</a> represents 1/2^(position_after_bit_string).</p>

<pre><code>postion:   |1|2|3|4|5|6|7|
         0.|0|0|0|0|0|0|1|
</code></pre>

<p>So <code>0.0000001 = 1/2^7 = 0.0078125</code></p>

<p>Pseudocode:</p>

<pre><code>decimal_value = 0 
for i, bit in enumerate(binary_string):
    if bit == 1
         decimal_value += 1/2**i
</code></pre>

<p>For more info <a href=""https://stackoverflow.com/questions/1089018/why-cant-decimal-numbers-be-represented-exactly-in-binary"">Why can&#39;t decimal numbers be represented exactly in binary?</a></p>
","13663072"
"Decimal-to-binary conversion","11791","","<p>I want to convert decimal numbers to binary numbers. I want to store them in an array.
First I need to create an array that has a certain length so that I can store the binary numbers. After that I perform the conversion, here is how I do it:</p>

<pre><code>public class Aufg3 {
    public static void main(String[] args) {
        int[] test = decToBin(12, getBinArray(12));
        for(int i = 0; i &lt; test.length; i++){
            System.out.println(test[i]);
        }
    }

    public static int[] getBinArray(int number){
        int res = number, length = 0;
        while(res != 0){        
            res /= 2;
                    length++;
        }
        return new int[length];
    }

    public static int[] decToBin(int number, int[] array){
        int res = number, k = array.length-1;
        while(res != 0){
            if(res%2 == 0){
                array[k] = 0;
            }else{
                array[k] = 1;
            }
            k--;
            res /= 2;
        }
        return array;
    }
}
</code></pre>

<p>Is there anything to improve? It should print 1100 for input of 12.</p>
","<p>I assume you want to write your own code -- otherwise this is straightforward to do using methods from the standard Java library.</p>

<p>Some quick comments:</p>

<ul>
<li>You can get rid of the <code>res</code> temp vars. Work directly on <code>number</code> (remember that Java passes parameters by value).</li>
<li>Shift is more efficient than division (<code>number &gt;&gt;&gt;= 1</code> instead of <code>number /= 2</code>), although the compiler should be able to optimize this anyway</li>
<li>You can avoid the modulus in <code>decToBin</code> if you just do <code>array[k] = number &amp; 1;</code></li>
<li>While you are at it, why not call <code>getBinArray</code> from <code>decToBin</code> directly? Then you can call <code>decToBin</code> with only one arg -- the value to convert.</li>
</ul>

<p>Here is a slightly optimized version of your code:</p>

<pre><code>public static int[] getBinArray(int number) {
    int length = 0;
    while (number != 0) {
        number &gt;&gt;&gt;= 1;
        length++;
    }
    return new int[length];
}

public static int[] decToBin(int number) {
    int[] array = getBinArray(number);
    int k = array.length-1;
    while (number != 0)
    {
        array[k--] = number &amp; 1;
        number &gt;&gt;&gt;= 1;
    }
    return array;
}
</code></pre>
","4158490"
"Where can I download binary eggs with psycopg2 for Windows?","11782","","<p>I'm looking for binary eggs with psycopg2's binaries for Windows but can't find any.<br>
On <a href=""http://initd.org/psycopg/download/"" rel=""nofollow noreferrer"">http://initd.org/psycopg/download/</a> there's only source package and link to <a href=""http://www.stickpeople.com/projects/python/win-psycopg/"" rel=""nofollow noreferrer"">Windows port of Psycopg</a> which provides binary installers but no binary eggs.</p>

<p>The reason I'm looking for binary egg is I'd like to install psycopg in virtualenv and it's <s>not</s> (<a href=""https://stackoverflow.com/questions/3271590/can-i-install-python-windows-packages-into-virtualenvs/5442340#5442340"">this</a> answer describes why it usually <strong>is</strong> possible) possible with standard Windows installers which look for installed Python in the registry.  </p>

<p>Side note: I guess psycopg is rather popular library and it strikes me as odd not to provide binary eggs for download on project's page. Am I missing something here?</p>
","<p>We just use something like <code>easy_install http://www.stickpeople.com/projects/python/win-psycopg/psycopg2-2.4.win32-pyx.x-pg9.0.3-release.exe</code> from within the virtual environment. </p>

<p>Seems to work; we end up with psycopg2 in the virtual environment and not in the base environment, which I take to be the endgame here.</p>

<p><strong>UPD:</strong> List of available realeases available on <a href=""http://www.stickpeople.com/projects/python/win-psycopg/"" rel=""nofollow noreferrer"">stickpeople.com site</a></p>
","5383266"
"How to decode ""binary"" encoded string into raw binary Buffer?","11684","","<p>The <a href=""http://nodejs.org/api/buffer.html#buffer_buffer"" rel=""nofollow"">NodeJS docs</a> stress that the <code>binary</code> string encoding is heavily discouraged since it will be dropped at some point in the future.</p>

<p>However, I'm trying to generate image thumbnails with the <a href=""https://github.com/rsms/node-imagemagick"" rel=""nofollow""><code>node-imagemagick</code></a> module, which can only output <code>binary</code> encoded strings.</p>

<p>My end goal is to submit the generated thumbnail as a BLOB into a SQLite3 database (I'm using <a href=""https://github.com/developmentseed/node-sqlite3"" rel=""nofollow""><code>node-sqlite3</code></a>), so I figured I need the thumbnail as a binary Buffer object.</p>

<p>How do I directly decode the <code>binary</code> encoded output from <code>node-imagemagick</code> into a raw binary Buffer (not just a Buffer that contains a <code>binary</code> encoded string)? I'm not keen on using <code>base64</code>...</p>
","<pre><code>var buffer = new Buffer(binaryString, ""binary"");
</code></pre>

<p>Tested with:</p>

<pre><code>$ node
&gt; var binaryString = ""\xff\xfa\xc3\x4e"";
&gt; var buffer = new Buffer(binaryString, ""binary"");
&gt; console.log(buffer);
&lt;Buffer ff fa c3 4e&gt;
</code></pre>
","13824012"
"Most compact way to encode a sequence of random variable length binary codes?","11611","","<p>Let's say you have a <code>List&lt;List&lt;Boolean&gt;&gt;</code> and you want to encode that into binary form in the most compact way possible.</p>

<p>I don't care about read or write performance.  I just want to use the minimal amount of space.  Also, the example is in Java, but we are not limited to the Java system.  The length of each ""List"" is <strong>unbounded</strong>.  Therefore any solution that encodes the length of each list must in itself encode a variable length data type.</p>

<p>Related to this problem is encoding of variable length integers.  You can think of each <code>List&lt;Boolean&gt;</code> as a variable length <code>unsigned integer</code>.</p>

<p><strong>Please read the question carefully.  We are not limited to the Java system.</strong></p>

<p>EDIT</p>

<p>I don't understand why a lot of the answers talk about compression.  I am not trying to do compression per se, but just encoding <em>random</em> sequence of bits down.  Except each sequence of bits are of different lengths and order needs to be preserved.</p>

<p><strong>You can think of this question in a different way.  Lets say you have a list of arbitrary list of random unsigned integers (unbounded).  How do you encode this list in a binary file?</strong></p>

<h2>Research</h2>

<p>I did some reading and found what I really am looking for is <a href=""http://en.wikipedia.org/wiki/Universal_code_%28data_compression%29"" rel=""noreferrer"">Universal code</a></p>

<h2>Result</h2>

<p>I am going to use a variant of <a href=""http://en.wikipedia.org/wiki/Elias_omega_coding"" rel=""noreferrer"">Elias Omega Coding</a> described in the paper <a href=""http://hirosuke.it.k.u-tokyo.ac.jp/files/ABST/Y2000.html"" rel=""noreferrer"">A new recursive universal code of the positive integers</a></p>

<p>I now understand how the smaller the representation of the smaller integers is a trade off with the larger integers.  By simply choosing an Universal code with a ""large"" representation of the very first integer you save a lot of space in the long run when you need to encode the arbitrary large integers.</p>
","<p>I am thinking of encoding a bit sequence like this:</p>

<pre><code>head  | value
------+------------------
00001 | 0110100111000011
</code></pre>

<p><code>Head</code> has variable length.  Its end is marked by the first occurrence of a 1.  Count the number of zeroes in head.  The length of the <code>value</code> field will be <code>2 ^ zeroes</code>.  Since the length of value is known, this encoding can be repeated.  Since the size of <code>head</code> is <code>log value</code>, as the size of the encoded value increases, the overhead converges to 0%.</p>

<h2>Addendum</h2>

<p>If you want to fine tune the length of value more, you can add another field that stores the exact length of value. The length of the length field could be determined by the length of head.  Here is an example with 9 bits.</p>

<pre><code>head  | length | value
------+--------+-----------
00001 | 1001   | 011011001
</code></pre>
","2181065"
"How I can execute a Batch Command in C# directly?","11592","","<p>hi i have a question to c# and batch files. I want do execute a batch command and save the output in a string in c#. but i can only execute the file but not save this content in a string and show this in a textbox.</p>

<p>my batch file: </p>

<blockquote>
  <p>@echo off</p>
  
  <p>""C:\lmxendutil.exe"" -licstatxml -host serv005 -port
  6200>C:\Temp\HW_Lic_XML.xml notepad C:\Temp\HW_Lic_XML.xml</p>
</blockquote>

<p>Here is my c# code: </p>

<pre><code>private void btnShowLicstate_Click(object sender, EventArgs e)
{
     string command = ""'C:\\lmxendutil.exe' -licstatxml -host lwserv005 -port 6200"";

     txtOutput.Text = ExecuteCommand(command);
}

static string ExecuteCommand(string command)
{
     int exitCode;
     ProcessStartInfo processInfo;
     Process process;

     processInfo = new ProcessStartInfo(""cmd.exe"", ""/c "" + command);
     processInfo.CreateNoWindow = true;
     processInfo.UseShellExecute = false;
     // *** Redirect the output ***
     processInfo.RedirectStandardError = true;
     processInfo.RedirectStandardOutput = true;

     process = Process.Start(processInfo);
     process.WaitForExit();

     // *** Read the streams ***
     string output = process.StandardOutput.ReadToEnd();
     string error = process.StandardError.ReadToEnd();

     exitCode = process.ExitCode;

     process.Close();

     return output; 
}
</code></pre>

<p>I want the output i a stirng and if i can do this i want that i not have a batch file. i want do this batvchcommand direct in c# ...can i do this? </p>
","<p>Don't need to use ""CMD.exe"" for execute a commandline application or retreive the output, you can use ""lmxendutil.exe"" directly.</p>

<p>Try this:</p>

<pre><code>processInfo = new ProcessStartInfo();
processInfo.FileName  = ""C:\\lmxendutil.exe"";
processInfo.Arguments = ""-licstatxml -host serv005 -port 6200"";
//etc...
</code></pre>

<p>Do your modifications to use ""command"" there.</p>

<p>I hope this helps.</p>
","16678252"
"MySQL binary against non-binary for hash IDs","11573","","<p>Assuming that I want to use a hash as an ID instead of a numeric. Would it be an performance advantage to store them as <code>BINARY</code> over non-binary?</p>

<pre><code>CREATE TABLE `test`.`foobar` (
  `id` CHAR(32) BINARY CHARACTER SET ascii COLLATE ascii_bin NOT NULL,
  PRIMARY KEY (`id`)
)
CHARACTER SET ascii;
</code></pre>
","<p>Yes.  Often a hash digest is stored as the ASCII representation of hex digits, for example MD5 of the word 'hash' is:</p>

<pre><code>0800fc577294c34e0b28ad2839435945
</code></pre>

<p>This is a 32-character ASCII string.</p>

<p>But MD5 really produces a 128-bit binary hash value.  This <em>should</em> require only 16 bytes to be stored as binary values instead of hex digits.  So you can gain some space efficiency by using binary strings.</p>

<pre><code>CREATE TABLE test.foobar (
  id BINARY(16) NOT NULL PRIMARY KEY
);

INSERT INTO test.foobar (id) VALUES (UNHEX(MD5('hash')));
</code></pre>

<hr>

<p>Re. your comments that you are more concerned about performance than space efficiency:</p>

<p>I don't know of any reason that the BINARY data type would be speedier than CHAR.</p>

<p>Being half as large can be an advantage for performance if you use cache buffers effectively.  That is, a given amount of cache memory can store twice as many rows worth of BINARY data if the string is half the size of the CHAR needed to store the same value in hex.  Likewise the cache memory for the index on that column can store twice as much.  </p>

<p>The result is a more effective cache, because a random query has a greater chance of hitting the cached data or index, instead of requiring a disk access.  Cache efficiency is important for most database applications, because usually the bottleneck is disk I/O.  If you can use cache memory to reduce frequency of disk I/O, it's a much bigger bang for the buck than the choice between one data type or another.</p>

<p>As for the difference between a hash string stored in BINARY versus a BIGINT, I would choose BIGINT.  The cache efficiency will be even greater, and also on 64-bit processors integer arithmetic and comparisons should be very fast.</p>

<p>I don't have measurements to support the claims above.  The net benefit of choosing one data type over another depends a lot on data patterns and types of queries in your database and application.  To get the most precise answer, you must try both solutions and measure the difference.</p>

<hr>

<p>Re. your supposition that binary string comparison is quicker than default case-insensitive string comparison, I tried the following test:</p>

<pre><code>mysql&gt; SELECT BENCHMARK(100000000, 'foo' = 'FOO');
1 row in set (5.13 sec)

mysql&gt; SELECT BENCHMARK(100000000, 'foo' = BINARY 'FOO');
1 row in set (4.23 sec)
</code></pre>

<p>So binary string comparison is 17.5% faster than case-insensitive string comparison.  But notice that after evaluating this expression 100 million times, the total difference is still less than 1 second.  While we can measure the relative difference in speed, the absolute difference in speed is really insignificant.</p>

<p>So I'll reiterate:</p>

<ul>
<li>Measure, don't guess or suppose.  Your educated guesses will be wrong a lot of the time.  Measure before and after every change you make, so you know how much it helped. </li>
<li>Invest your time and attention where you get the greatest bang for the buck.</li>
<li>Don't sweat the small stuff.  Of course, a tiny difference adds up with enough iterations, but given those iterations, a performance improvement with greater absolute benefit is still preferable.</li>
</ul>
","504434"
"How to edit a binary file's hex value using C#","11559","","<p>So here's my issue. I have a binary file that I want to edit. I can use a hex editor to edit it of course, but I need to make a program to edit this particular file. Say that I know a certain hex I want to edit, I know it's address etc. Let's say that it's a 16-bit binary, and the address is 00000000, it's on row 04 and it has a value of 02. How could I create a program that would change the value of that hex, and only that hex with the click of a button? </p>

<p>I've found resources that talk about similar things, but I can't for the life of me find help with the exact issue. </p>

<p>Any help would be appreciated, and please, don't just tell me the answer if there is one but try and explain a bit. </p>
","<p>I think this is best explained with a specific example. Here are the first 32 bytes of an executable file as shown in Visual Studio's hex editor:</p>

<pre><code>00000000  4D 5A 90 00 03 00 00 00  04 00 00 00 FF FF 00 00
00000010  B8 00 00 00 00 00 00 00  40 00 00 00 00 00 00 00
</code></pre>

<p>Now a file is really just a linear sequence of bytes. The rows that you see in a hex editor are just there to make things easier to read. When you want to manipulate the bytes in a file using code, you need to identify the bytes by their 0-based positions. In the above example, the positions of the non-zero bytes are as follows:</p>

<pre><code>Position  Value
--------  ------
  0        0x4D
  1        0x5A
  2        0x90
  4        0x03
  8        0x04
 12        0xFF
 13        0xFF
 16        0xB8
 24        0x40
</code></pre>

<p>In the hex editor representation shown above, the numbers on the left represent the positions of the first byte in the corresponding line. The editor is showing 16 bytes per line, so they increment by 16 (0x10) at each line.</p>

<p>If you simply want to take one of the bytes in the file and change its value, the most efficient approach that I see would be to open the file using a FileStream, seek to the appropriate position, and overwrite the byte. For example, the following will change the 0x40 at position 24 to 0x04:</p>

<pre><code>using (var stream = new FileStream(path, FileMode.Open, FileAccess.ReadWrite)) {
    stream.Position = 24;
    stream.WriteByte(0x04);
}
</code></pre>
","3217953"
"Writing bits to a file in C","11480","","<p>I have this string: ""101""
I want to write it to a file, in C, not as text: ""101"" and so 8 bits x char. but directly use the string as bits: the bit ""1"", the bit ""0"" and the bit ""1"", so that the file will be of 3 bits.</p>

<p>Is it possibile?
I searched on the web and I tried doing this:</p>

<pre><code>char c[25] = ""101"";
FILE *binFile = fopen(""binFile.bin"", ""wb"");
int x = atoi(c);
fwrite(&amp;x, sizeof(x), 1, binFile);
</code></pre>

<p>But at the end, when I verify files's bytes, Windows says me that it is 4bytes file! And not 3bits!</p>

<p>How can I do this, if it is possible? Thanks a lot.</p>
","<p>All filesystems¹ deal with files in terms of bytes (and allocate storage space with a much larger granularity, 512 bytes at a time minimum). There's no way you are going to get a file that is <em>3 bits</em> long.</p>

<p>The best you can do is use up one whole byte but ignore 5 of its bits. To do that (assuming that the number is always going to fit into a byte), convert the input string to an integral type:</p>

<pre><code>long l = strtol(c, 0, 2);
</code></pre>

<p>Then get its least significant byte:</p>

<pre><code>unsigned char b = l &amp; 0xffl;
</code></pre>

<p>And write it to the file:</p>

<pre><code>fwrite(&amp;b, 1, 1, binFile);
</code></pre>

<hr>

<p>¹ Well, maybe not all. There might be some researchers somewhere that experiment with bit-sized filesystems. I wouldn't know.</p>
","13252722"
"2's complement representation of fractions?","11464","","<p>I'm a little lost on this. I need to use two fractional bits 
<code>0.(a-1)(a-2)</code></p>

<p>Like that, now I can use <code>.00 .01 .10</code> and <code>.11</code>
But I need negative numbers (in 2's complement) also, so would <code>.10</code> be <code>-.5</code> ? or would it be <code>-.25</code> ? 
The same with <code>.11</code> , that would be <code>-.75</code>? or would it be <code>-.5</code> ? 
I'm pretty sure it would be the former in both cases, but I'm not entirely positive.</p>
","<p>In two's complement notation, all of the most significant bits of a negative number are set to 1.  Let's assume you're storing these numbers as 8 bits, with 2 to the right of the ""binary point.""</p>

<p>By definition, <code>x + -x = 0</code>, so we can write:</p>

<pre><code>0.5  +  -0.5 = 0.10 + 111111.10 = 0   // -0.5  = 111111.10
0.25 + -0.25 = 0.01 + 111111.11 = 0   // -0.25 = 111111.11
0.75 + -0.75 = 0.11 + 111111.01 = 0   // -0.75 = 111111.01
</code></pre>

<p>and so on.</p>

<p>Using 8 bits like this, the largest number you can store is</p>

<pre><code>011111.11 = 31.75
</code></pre>

<p>the least-positive number is</p>

<pre><code>000000.01 = 0.25
</code></pre>

<p>the least-negative number is</p>

<pre><code>111111.11 = -0.25
</code></pre>

<p>and the smallest (that is, the most negative) is</p>

<pre><code>100000.00 = -32
</code></pre>
","9946376"
"Count number of bits in an unsigned integer","11400","","<p>I want to write a function named <code>bitCount()</code> in the file: <code>bitcount.c</code> that returns the number of bits in the binary representation of its unsigned integer argument. </p>

<p>Here is what I have so far:</p>

<pre><code>#include &lt;stdio.h&gt;

int bitCount (unsigned int n);

int main () {
    printf (""# 1-bits in base 2 representation of %u = %d, should be 0\n"",
        0, bitCount (0));
    printf (""# 1-bits in base 2 representation of %u = %d, should be 1\n"",
        1, bitCount (1));
    printf (""# 1-bits in base 2 representation of %u = %d, should be 16\n"",
        2863311530u, bitCount (2863311530u));
    printf (""# 1-bits in base 2 representation of %u = %d, should be 1\n"",
        536870912, bitCount (536870912));
    printf (""# 1-bits in base 2 representation of %u = %d, should be 32\n"",
        4294967295u, bitCount (4294967295u));
    return 0;
}

int bitCount (unsigned int n) {
    /* your code here */
}
</code></pre>

<p>Okay, when I just run this I get:</p>

<pre><code># 1-bits in base 2 representation of 0 = 1, should be 0
# 1-bits in base 2 representation of 1 = 56, should be 1
# 1-bits in base 2 representation of 2863311530 = 57, should be 16
# 1-bits in base 2 representation of 536870912 = 67, should be 1
# 1-bits in base 2 representation of 4294967295 = 65, should be 32

RUN SUCCESSFUL (total time: 14ms)
</code></pre>

<p>It doesn't return the correct numbers of bits.</p>

<p>What's the best way to return the number of bits in the binary representation of its unsigned integer argument in C?</p>
","<pre><code> int bitCount(unsigned int n) {

    int counter = 0;
    while(n) {
        counter += n % 2;
        n &gt;&gt;= 1;
    }
    return counter;
 }
</code></pre>
","14781056"
"Assigning a binary constant","11390","","<p>Is there a way to assign a binary value to a VB variable?  All of the obvious choices don't work.  I've tried prefixing with <code>&amp;B</code>, appending with <code>b</code> but nothing seems to work.  I'm not having much luck searching for it either.  I don't <em>need</em> this for my application, but I'm rather, just curious so alternate solutions are not necessary.</p>

<p>[Edit]
For clarification, what I was looking for (which does not appear to be possible) was how to assign a literal binary number to a variable, in a similar manner in which you can assign a hex or octal number.  I was just looking for a more visually engaging way to assign values to a flag enum.</p>

<p>Code:</p>

<pre><code>Dim num as Integer = &amp;H100ABC       'Hex'
Dim num2 as Integer = &amp;O123765      'Octal'

Dim myFantasy as Integer = &amp;B1000   'What I would like to be able to do'
Dim myReality as Integer = 2 ^ 3    'What I ended up doing'
</code></pre>
","<p>I might stab myself after this one:</p>

<pre><code>Convert.ToInt32(""1100101"", 2);
</code></pre>

<p>On a more serious note (noticing that you have updated the question), for flag <code>enums</code> what you may want is the <a href=""http://msdn.microsoft.com/en-us/library/7haw1dex.aspx"" rel=""noreferrer"">left shift operator (<code>&lt;&lt;</code>)</a>:</p>

<pre><code>Dim myReality as Integer          = 1 &lt;&lt; 0   // 1
Dim myAlternateReality as Integer = 1 &lt;&lt; 1   // 2
Dim myParallelUniverse as Integer = 1 &lt;&lt; 2   // 4
...
</code></pre>

<p>and so on up to 31.</p>
","660043"
"Make Eclipse generate C++ executable file","11339","","<p>Using latest MinGW and C++ Eclipse. </p>

<p>If I create an ""Executable Hello World"" project, build it and run it, everything works as expected.</p>

<p>If I create an ""Executable Empty Project"", then create a main.cpp file, build and run, I get the error message ""Launch failed. Binary not found.""</p>

<p>How can I make empty project generate binary files? I looked everywhere in the project properties but I must have missed it.</p>
","<p>For me the solution was this:</p>

<p>select your project and goto ""project""-menu/properties (on mac).</p>

<p>c/c++ Build/Settings.</p>

<p>Binary parsers. now tick the one that suits your system (elf for linux, mach 64 for mac, pe for windows etc). the default is always elf and it reverts to it after every project, at least for me.</p>
","22708962"
"decimal to 8 bit binary conversion in c++","11327","","<p>I am working on decimal to binary conversion. I can convert them, using 
char bin_x [10];
  itoa (x,bin_x,2);
but the problem is, i want answer in 8 bits. And it gives me as, for example x =5, so output will be 101, but i want 00000101. 
Is there any way to append zeros in the start of array? or is it possible to get answer in 8 bits straight away? I am doing this in C++</p>
","<p>In C++, the easiest way is <em>probably</em> to use a <code>std::bitset</code>:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;bitset&gt;

int main() { 
    int x = 5;

    std::bitset&lt;8&gt; bin_x(x);
    std::cout &lt;&lt; bin_x;

    return 0;
}
</code></pre>

<p>Result:</p>

<blockquote>
  <p>00000101</p>
</blockquote>
","4923971"
"Read a binary file using Numpy fromfile and a given offset","11311","","<p>I have a binary file which contains records of position of a plane.
Each record look like:</p>

<pre><code>0x00: Time, float32
0x04: X, float32 // X axis position
0x08: Y, float32 // Y axis position
0x0C: Elevation, float32
0x10: float32*4 = Quaternion (x,y,z axis and w scalar)
0x20: Distance, float32 (unused)
</code></pre>

<p>So each record is 32 bytes long.</p>

<p>I would like to get a Numpy array.</p>

<p>At offset 1859 there is an unsigned int 32 (4 bytes) which indicates the number of elements of the array. 12019 in my case.</p>

<p>I don't care (for now) header data (before offset 1859)</p>

<p>Array only start at offset 1863 (=1859+4).</p>

<p>I defined my own Numpy dtype like</p>

<pre><code>dtype = np.dtype([
    (""time"", np.float32),
    (""PosX"", np.float32),
    (""PosY"", np.float32),
    (""Alt"", np.float32),
    (""Qx"", np.float32),
    (""Qy"", np.float32),
    (""Qz"", np.float32),
    (""Qw"", np.float32),
    (""dist"", np.float32),
])
</code></pre>

<p>And I'm reading file using <code>fromfile</code>:</p>

<pre><code>a_bytes = np.fromfile(filename, dtype=dtype)
</code></pre>

<p>But I don't see any parameter to provide to <code>fromfile</code> to pass offset.</p>
","<p>You can open the file with a standard python file open, then seek to skip the header, then pass in the file object to <code>fromfile</code>. Something like this:    </p>

<pre><code>import numpy as np
import os

dtype = np.dtype([
    (""time"", np.float32),
    (""PosX"", np.float32),
    (""PosY"", np.float32),
    (""Alt"", np.float32),
    (""Qx"", np.float32),
    (""Qy"", np.float32),
    (""Qz"", np.float32),
    (""Qw"", np.float32),
    (""dist"", np.float32),
])

f = open(""myfile"", ""rb"")
f.seek(1863, os.SEEK_SET)

data = np.fromfile(f, dtype=dtype)
print x 
</code></pre>
","30126751"
"Error: binary '<<' : no operator found which takes a right-hand operand of type 'std::string'","11291","","<p>My Question is similar to others but I wasn't able to find and answer that quite fit, maybe I'm just missing it, but anyways.</p>

<p>Given that this is at the top of my .cpp:</p>

<pre><code>#include &lt;cstring&gt;

#include &lt;iostream&gt;

using namespace std
</code></pre>

<p>why would this line have an error:</p>

<pre><code>cout &lt;&lt; endl &lt;&lt; output &lt;&lt; endl;
</code></pre>

<p>the error being:</p>

<blockquote>
  <p>binary '&lt;&lt;' : no operator found which takes a right-hand operand of type 'std::string' (or there is no acceptable conversion)</p>
</blockquote>
","<p><code>&lt;cstring&gt;</code> is the header for C strings, i.e, its content is the same as the C header <code>string.h</code>. What you need to handle <code>std::string</code> is <code>&lt;string&gt;</code></p>

<p>Another problem is that you missed the semicolon:</p>

<pre><code>using namespace std;
//                 ^
</code></pre>

<p>Note that this style works, but is not recommend, it's better not to use this line and use:</p>

<pre><code>std::cout &lt;&lt; std::endl &lt;&lt; output &lt;&lt; std::endl;
</code></pre>
","19872432"
"Decimal to Binary in C++","11243","","<p>I'm a total beginner in C++ and today I thought I'd write myself a small program that converts a decimal number to binary. The code looked something like this:</p>

<pre><code>#include &lt;iostream&gt;
void binaryConvert(int);
int main() {
    using namespace std;
    cout &lt;&lt; ""Enter decimal number for conversion:"" &lt;&lt; endl;
    int dec;
    cin &gt;&gt; dec;
    binaryConvert(dec);
}
void binaryConvert(int number) {
    using namespace std;
    while(number &gt; 0) {
        int bin = number % 2;
        number /= 2;
        cout &lt;&lt; bin;
    }
}
</code></pre>

<p>Logically, this program would print the binary the other way around. I spent a long time trying to figure out how to invert the order of the binary digits so that the binary number would appear the right way around when I came across this piece of code:</p>

<pre><code>void binaryConvert(int number) {
    using namespace std;
    if(number &gt; 0) {
        int bin = number % 2;
        number /= 2;
        binaryConvert(number);
        cout &lt;&lt; bin;
    }
}
</code></pre>

<p>I know its probably a stupid question (I'm an absolute beginner), but I can't figure out why this code prints the bits in the correct order. Also, how come the bits actually get printed if the function gets called again before cout even gets executed?</p>
","<p>It utilizes recursion, the bin at the end will not be printed until the base case is hit (number &lt;= 0) and then it will go up the stack trace.</p>
","13553670"
"Java Advanced Imaging - where to get latest binary build?","11213","","<p>I am searching for the latest official binary builds of Java Advanced Imaging (at least the platform independent Java-only build). </p>

<p>The official project web page is on <a href=""http://java.net/projects/jai-core/"" rel=""noreferrer"">http://java.net/projects/jai-core/</a> but it only links to the source - binary builds are not mentioned - or am I too blind to see them?</p>
","<p>You are referring to the wrong site...the correct site is as follows:</p>

<p><a href=""http://www.oracle.com/technetwork/java/javasebusiness/downloads/java-archive-downloads-java-client-419417.html"" rel=""nofollow"">http://www.oracle.com/technetwork/java/javasebusiness/downloads/java-archive-downloads-java-client-419417.html</a></p>

<p>Edited: ok, this is strange...last time I did see a JAI package which I used to test JAI features in JUNG 2.0 Framework...I remembered I downloaded it from somewhere from the link above...</p>

<p>Well, I've googled it: get JAI 1.1.3 from here...</p>

<p><a href=""http://www.java2s.com/Code/Jar/j/Downloadjaicore113jar.htm"" rel=""nofollow"">http://www.java2s.com/Code/Jar/j/Downloadjaicore113jar.htm</a></p>
","5300702"
"Convert a decimal number to hexadecimal and binary in a shell script","11181","","<p>I have a decimal number in each line of a <code>file.txt</code>:</p>

<pre><code>    1
    2
    3
</code></pre>

<p>I am trying (for too long now) to write a one-liner script to have an output where each row has a column with the decimal, hexadecimal and the binary. To ease the task we can say that the original number is expressed in a byte. So the maximum value is 255.</p>

<ol>
<li><p>I first try to decode each number as a bynary with prepended 0 so to have an 8 bits pattern:</p>

<p><code>awk '{print ""ibase=10;obase=2;"" $1}' $1 | bc | xargs printf ""%08d\n""</code></p>

<p>where the outer $1 in the awk statement is <code>file.txt</code>. The output is :</p>

<pre><code>00000001
00000010
00000011
</code></pre></li>
<li><p>Same for hex with one prepended 0</p>

<p><code>awk '{printf(""0x%02x\n"", $1)}' $1</code></p>

<p>Same as before. The Output is :</p>

<pre><code>0x01
0x02
0x03
</code></pre></li>
<li><p>Well, the decimal should be just a print:</p>

<pre><code>1
2
3
</code></pre></li>
</ol>

<p>What I'd like to have is one liner where I have:</p>

<pre><code>    1 00000001 0x01
    2 00000001 0x02
</code></pre>

<p>so basically to put 1. 2. and 3. in each line of the output.</p>

<p>I tried to execute bc (and other command) within awk using system() without success. And a zillion other ways. What is the way you would do it?</p>
","<p>The following one-liner should work:</p>

<pre><code>printf ""%s %08d 0x%02x\n"" ""$1"" $(bc &lt;&lt;&lt; ""ibase=10;obase=2;$1"") ""$1""
</code></pre>

<p>Example output:</p>

<pre><code>$ for i in {1..10}; do printf ""%s %08d 0x%02x\n"" ""$i"" $(bc &lt;&lt;&lt; ""ibase=10;obase=2;$i"") ""$i""; done
1 00000001 0x01
2 00000010 0x02
3 00000011 0x03
4 00000100 0x04
5 00000101 0x05
6 00000110 0x06
7 00000111 0x07
8 00001000 0x08
9 00001001 0x09
10 00001010 0x0a
</code></pre>
","18870516"
"Python: How do I convert from binary to base 64 and back?","11122","","<p>Lets say I have some binary value:</p>

<pre><code>0b100
</code></pre>

<p>and want to convert it to base64</p>

<p>doing <code>base64.b64decode(0b100)</code> tells me that it is expecting a string, not an int.... now, I don't want to work with strings.</p>

<p>So, could anyone point me in the right direction for converting binary numbers to base64 numbers? thanks! </p>

<p>=D</p>
","<p>Depending on how you represent the value <code>0b100</code></p>

<pre><code>&gt;&gt;&gt; import struct
&gt;&gt;&gt; val = 0b100
&gt;&gt;&gt; print struct.pack('I', val).encode('base64')
BAAAAA==
</code></pre>

<p>This will turn your value into a 4-byte integer in native endianness, and encode that value into base64. You need to specify the width of your data as base64 is really made for representing binary data in printable characters. </p>

<p>You can typically encode data as a string of bytes via struct's functions, and then encode into base64. Ensure you're using the same data layout and endianess when decoding.</p>
","5305469"
"Inserting and selecting UUIDs as binary(16)","11121","","<p>I don't understand why</p>

<pre><code>SELECT UUID();
</code></pre>

<p>Returns something like:</p>

<pre><code>3f06af63-a93c-11e4-9797-00505690773f
</code></pre>

<p>But if I insert it into a binary(16) field (the UUID() function) with for instance a BEFORE INSERT trigger and run a select, it returns something like:</p>

<pre><code>0782ef48-a439-11
</code></pre>

<p>Note that these two UUIDs are not the same data.</p>

<p>I realize binary and an UUID string doesn't look identical, but shouldn't the selected data at least be just as long? Otherwise how can it possibly be equally likely to be unique?</p>

<p>Is it better to store it as char(36)? I just need it to be unique to prevent duplicate inserts. It is never selected or used for joins.</p>

<p>EDIT:</p>

<p>before trigger would be like:</p>

<pre><code>BEGIN

if NEW.UUID IS NULL THEN

NEW.UUID = UUID();

END IF

END
</code></pre>
","<p>So, as a response to comments. The correct way of storing a 36-char UUID as binary(16) is to perform the insert in a manner like:</p>

<pre><code>INSERT INTO sometable (UUID) VALUES (UNHEX(REPLACE(""3f06af63-a93c-11e4-9797-00505690773f"", ""-"","""")))
</code></pre>

<p><code>UNHEX</code> because an UUID is already a hexed value. We trim (<code>REPLACE</code>) the dashes in the statement to bring the length down to 32 ASCII characters (our 16 bytes represented as <code>HEX</code>). You can do this at any point before storing it, obviously, so it doesn't have to be handled by the database.</p>

<p>You may retrieve the UUID like this:</p>

<pre><code>SELECT HEX(UUID) FROM sometable;
</code></pre>

<p>Just in case someone comes across this thread and is unsure how this works.</p>

<p>And remember: If you're selecting a row using the UUID, <strong>use <code>UNHEX()</code> on the condition</strong>:</p>

<pre><code>SELECT * FROM sometable WHERE UUID = UNHEX('3f06af63a93c11e4979700505690773f');
</code></pre>

<p><strong>And not <code>HEX()</code>on the column:</strong></p>

<pre><code>SELECT * FROM sometable WHERE HEX(UUID) = '3f06af63a93c11e4979700505690773f';
</code></pre>

<p>The second solution, while it works, requires that MySQL <code>HEX</code>es all UUIDs before it can determine which rows match. It's very inefficient.</p>
","28252188"
"Int to UInt (and vice versa) bit casting in Swift","11076","","<p>I am looking for a direct way to bit cast the bit values of an Int to UInt and vice versa. For example (using the 8 bits integers for simplicity) I want to achieve the following:</p>

<pre><code>let unsigned: UInt8 = toUInt8(-1)  // unsigned is 255 or 0xff
let signed:   Int8  = toInt8(0xff) // signed is -1 
</code></pre>

<p>At first I came out with the following solution:</p>

<pre><code>let unsigned = unsafeBitCast(Int8(-1), UInt8.self)
let signed   = unsafeBitCast(UInt8(0xff), Int8.self)
</code></pre>

<p>But Apple in the ""unsafeBitCast()"" documentation states the following:</p>

<blockquote>
  <p>.. Caution:: Breaks the guarantees of Swift's type system; use with
  extreme care. There's almost always a better way to do anything.</p>
</blockquote>

<p>Does anyone have the better way?</p>
","<p>You can do:</p>

<pre><code>let unsigned = UInt8(bitPattern: Int8(-1)) // -&gt; 255
let signed   = Int8(bitPattern: UInt8(0xff)) // -&gt; -1
</code></pre>

<p>Many similar initializers exist:</p>

<pre><code>extension Int8 {
    init(_ v: UInt8)
    init(_ v: UInt16)
    init(truncatingBitPattern: UInt16)
    init(_ v: Int16)
    init(truncatingBitPattern: Int16)
    init(_ v: UInt32)
    init(truncatingBitPattern: UInt32)
    init(_ v: Int32)
    init(truncatingBitPattern: Int32)
    init(_ v: UInt64)
    init(truncatingBitPattern: UInt64)
    init(_ v: Int64)
    init(truncatingBitPattern: Int64)
    init(_ v: UInt)
    init(truncatingBitPattern: UInt)
    init(_ v: Int)
    init(truncatingBitPattern: Int)
    init(bitPattern: UInt8)
}
</code></pre>
","27127573"
"Perl: Reading binary file one byte at a time","11028","","<p>I'm writing a tool that needs to read a binary file one byte at a time, process each byte, and potentially take some action depending on the processed value. But for some reason the values Perl is getting are not the same as the data in the file. I'm using code similar to this (stripped down for brevity, but this still exhibits the issue):</p>

<pre><code>#!/usr/bin/perl
use strict;

my $bytesToProcess = 16;
my $fileName = 'datafile.bin';

print ""Processing $bytesToProcess bytes...\n"";

open FILE, ""&lt;:raw"", $fileName or die ""Couldn't open $fileName!"";

for my $offset (0 .. $bytesToProcess - 1)
{
    my $oneByte;
    read(FILE, $oneByte, 1) or die ""Error reading $fileName!"";
    printf ""0x%04X\t0x%02X\n"", $offset, $oneByte;
}

close FILE;
</code></pre>

<p>Input values (first 16 bytes of data file): <code>50 53 4D 46 30 30 31 35 00 00 70 00 07 3F 10 00</code></p>

<p>Output:</p>

<pre><code>Processing 16 bytes...
0x0000  0x00
0x0001  0x00
0x0002  0x00
0x0003  0x00
0x0004  0x00
0x0005  0x00
0x0006  0x01
0x0007  0x05
0x0008  0x00
0x0009  0x00
0x000A  0x00
0x000B  0x00
0x000C  0x00
0x000D  0x00
0x000E  0x00
0x000F  0x00
</code></pre>

<p>Any idea what's going wrong here?</p>
","<p><code>read</code> returns the byte as the char <code>""\x50""</code>, not the number <code>0x50</code>. Change the <code>printf</code> line to</p>

<pre><code>printf ""0x%04X\t0x%02X\n"", $offset, ord $oneByte;
</code></pre>

<p>Another option is to use <code>unpack 'c', $oneByte</code>.</p>
","13191589"
"How to get the IEEE 754 binary representation of a float in C#","10931","","<p>I have some single and double precision floats that I want to write to and read from a byte[]. Is there anything in .Net I can use to convert them to and from their 32 and 64 bit IEEE 754 representations?</p>
","<p>.NET Single and Double are already in IEEE-754 format.  You can use BitConverter.ToSingle() and ToDouble() to convert byte[] to floating point, GetBytes() to go the other way around.</p>
","4249445"
"2's complement example, why not carry?","10914","","<p>I'm watching some great lectures from David Malan (<a href=""http://academicearth.org/lectures/binary-numbers-programming-languages-linux"" rel=""nofollow noreferrer"">here</a>) that is going over binary. He talked about signed/unsigned, 1's compliment, and 2's complement representations. There was an addition done of 4 + (-3) which lined up like this:</p>

<pre><code>0100
1101 (flip 0011 to 1100, then add ""1"" to the end)
----
0001
</code></pre>

<p>But he waved his magical hands and threw away the last carry. I did some wikipedia research bit didn't quite get it, can someone explain to me why that particular carry (in the 8's ->16's columns) was dropped, but he kept the one just prior to it?</p>

<p>Thanks!</p>
","<p>The last carry was dropped because it does not fit in the target space. It would be the fifth bit.</p>

<p>If he had carried out the same addition, but with for example 8 bit storage, it would have looked like this:</p>

<pre><code>00000100
11111101
--------
00000001
</code></pre>

<p>In this situation we would also be stuck with an ""unused"" carry.</p>

<p>We have to treat carries this way to make addition with two's compliment work properly, but that's all good, because this is the easiest way of treating carries when you have limited storage. Anyway, we get the correct result, right :)</p>

<hr>

<p>x86-processors store such an additional carry in the carry flag (CF), which is possible to test with certain instructions.</p>
","1663664"
"How to pad a binary string with zeros?","10896","","<pre><code>string binary = Convert.ToString(15, 2);

Console.WriteLine(""{0}"", binary);
</code></pre>

<p>Prints:</p>

<p><code>1111</code></p>

<p>I want it to print <code>00001000</code></p>

<p>Because the data type is of string and not integer I cannot do something like this:</p>

<pre><code>Console.WriteLine(""{0:00000000}"", binary);
</code></pre>
","<pre><code>Console.WriteLine( binary.PadLeft(8, '0'));
</code></pre>
","7682636"
"Converting Ascii to binary in C","10891","","<p>So here is my code </p>

<pre><code>void ascToBinary(int character, int *ones)
{
    if(character == 1)
    {
       printf(""1"");
       *ones+=1;
       return;
    }
    else
    {
        if((character%2) == 0)
        {
             printf(""0"");
             character = character/2;
        }
        else
        {
             printf(""1"");
             character = character/2;
             *ones+=1;

        }
        binaryPrinter(character, ones);
    }
}
</code></pre>

<p>Can anyone try to help me out on where something is wrong here. It compiles fine and does some ascii letters correct. If you try an 'e' though it will print out '1010011' instead of the correct binary. </p>

<p>All help appreciated Thanks Guys.</p>
","<p>You print the results in the wrong order. The correct output is '1100101'. You can flip it like this:</p>

<pre><code>    void ascToBinary(int character, int *ones)
    {
        if(character == 1)
        {
           printf(""1"");
           *ones+=1;
           return;
        }
        else
        {
            char out;
            if((character%2) == 0)
            {
                 out = '0';
                 character = character/2;
            }
            else
            {
                 out = '1';
                 character = character/2;
                 *ones+=1;

            }
            ascToBinary(character, ones);
            putchar (out);
        }
    }
</code></pre>
","21964728"
"How to implement Decimal to Binary function in Haskell","10878","","<p>I implemented a binary to decimal function in Haskell and am currently working on a function that would convert a decimal into a binary value. (I'm aware that these functionalities are available somewhere although they're not part of Prelude.hs) </p>

<p>I came up with the following code for a C-type procedural language, but I have trouble adapting it into the functional paradigm.</p>

<pre><code>while (n &gt; 0)
{
    if (n % 2 == 1)
        str = str + ""1"";
    else
        str = str + ""0"";
    n = n / 2;
}
</code></pre>

<p>I ventured into functional programming in Haskell only recently so I'm quite new to the functional way of thinking. I attempted the above using both recursion and list comprehension, but I'm not sure on how to place the guards and the logic properly since this involves multiple conditions. I use an Int list to hold the separate binary bits.</p>

<pre><code>--Decimal to binary
toBin:: Int -&gt; [Int]
toBin 0 = [0]
toBin n | (n % 2 == 1) =
        |(n % 2 == 0) = 
</code></pre>

<p>I've understood that the above pattern would let the program choose either guard and end evaluating the function. Am I on the wrong track here?</p>

<p>Below is what I came up with primitive recursion to convert any base (less than 10, in place of the 2) to decimal.</p>

<pre><code>toDecimal :: [Int] -&gt; Int
toDecimal [] = 0
toDecimal (x:xs) = (x * 2 ^(length xs)) + bin xs
</code></pre>

<p>Thanks in advanced.</p>
","<p>There's no <code>%</code> operator; you're probably looking for <code>`mod`</code> instead:</p>

<pre><code>toBin 0 = [0]
toBin n | n `mod` 2 == 1 = ...
        | n `mod` 2 == 0 = ...
</code></pre>

<p>Guards let you choose between multiple branches of a function. In this case, each <code>...</code> will be the result of <code>toBin n</code> if its corresponding condition is true. To append two lists together, you can use the <code>++</code> operator, and <code>`div`</code> corresponds to integer division:</p>

<pre><code>toBin 0 = [0]
toBin n | n `mod` 2 == 1 = toBin (n `div` 2) ++ [1]
        | n `mod` 2 == 0 = toBin (n `div` 2) ++ [0]
</code></pre>

<p>However, this has a few problems. For a start, it always starts the result with <code>0</code>, which is redundant; additionally, using <code>++ [1]</code> is slow, since it has to go through the entire list to add an element on to the end; it would be better to <em>prepend</em> each element as we go, and then <em>reverse</em> the result at the end.</p>

<p>To fix both these things, we'll split <code>toBin</code> up into a main function and a helper function:</p>

<pre><code>toBin 0 = [0]
toBin n = reverse (helper n)

helper 0 = []
helper n | n `mod` 2 == 1 = 1 : helper (n `div` 2)
         | n `mod` 2 == 0 = 0 : helper (n `div` 2)
</code></pre>

<p>In this version, we use the <code>:</code> operator, which takes a value and a list, and returns the list with the value prepended to the beginning. We also return an empty result for 0 in our helper, and handle the 0 case in <code>toBin</code> instead, so that there's no more 0s than necessary in the result.</p>

<p>We can simplify <code>helper</code>'s code by skipping the guards altogether, since we just write the result of <code>n `mod` 2</code> again on the right-hand side:</p>

<pre><code>helper 0 = []
helper n = (n `mod` 2) : helper (n `div` 2)
</code></pre>

<p>Finally, there's a function that does a <code>div</code> and a <code>mod</code> in one go, which can be more efficient:</p>

<pre><code>helper 0 = []
helper n = let (q,r) = n `divMod` 2 in r : helper q
</code></pre>

<p>As an additional note, this doesn't really convert decimal to binary, it converts an integer to binary; Haskell implementations are unlikely to store integers in decimal format, although they are written and printed in that format. To write a full conversion of decimal to binary, a function that parses a decimal string into an integer would be required.</p>
","9166342"
"django store image in database","10864","","<p>Does anyone know if there's an out-of-the box way of storing images directly in the database vs. using ImageField model type that simply uploads it to the MEDIA_ROOT. 
And if there is, how does one serve those images then?</p>

<p>Cheers</p>
","<p>No, there isn't. And for good reason. It's horribly inefficient to store and serve images from the database. Store them on the filesystem, and serve them directly from Apache.</p>
","3772448"
"Hamming distance between two binary strings not working","10756","","<p>I found an interesting algorithm to calculate hamming distance on <a href=""http://jhafranco.com/2012/02/12/hamming-distance/"" rel=""nofollow"">this</a> site: </p>

<pre><code>def hamming2(x,y):
    """"""Calculate the Hamming distance between two bit strings""""""
    assert len(x) == len(y)
    count,z = 0,x^y
    while z:
        count += 1
        z &amp;= z-1 # magic!
    return count
</code></pre>

<p>The point is that this algorithm only works on bit strings and I'm trying to compare two strings that are binary but they are in string format, like</p>

<pre><code>'100010'
'101000'
</code></pre>

<p>How can I make them work with this algorithm?</p>
","<p>Implement it:</p>

<pre><code>def hamming2(s1, s2):
    """"""Calculate the Hamming distance between two bit strings""""""
    assert len(s1) == len(s2)
    return sum(c1 != c2 for c1, c2 in zip(s1, s2))
</code></pre>

<p>And test it:</p>

<pre><code>assert hamming2(""1010"", ""1111"") == 2
assert hamming2(""1111"", ""0000"") == 4
assert hamming2(""1111"", ""1111"") == 0
</code></pre>
","31007358"
"Erlang io:formatting a binary to hex","10702","","<p>Can I format an Erlang binary so that each byte is written in hex? I.e.,</p>

<pre><code>&gt; io:format(???, [&lt;&lt;255, 16&gt;&gt;]).
&lt;&lt;FF, 10&gt;&gt;
</code></pre>

<p>I don't see an obvious way to do it in <a href=""http://www.erlang.org/doc/man/io.html#format-2"" rel=""noreferrer"">io:format</a> documentation, but perhaps I am simply missing one? Converting a binary to list and formatting its elements separately is too inefficient.</p>
","<p>No, there is not such formating option but you can do something like:</p>

<pre><code>io:format(""&lt;&lt;~s&gt;&gt;~n"", [[io_lib:format(""~2.16.0B"",[X]) || &lt;&lt;X:8&gt;&gt; &lt;= &lt;&lt;255,16&gt;&gt; ]]).
</code></pre>

<p>There is a lot faster solution if you need.</p>

<pre><code>-module(bin_to_hex).

-compile([native, {hipe, [o3]}]).

-export([bin_to_hex/1]).

bin_to_hex(B) when is_binary(B) -&gt;
  bin_to_hex(B, &lt;&lt;&gt;&gt;).

-define(H(X), (hex(X)):16).

bin_to_hex(&lt;&lt;&gt;&gt;, Acc) -&gt; Acc;
bin_to_hex(Bin, Acc) when byte_size(Bin) band 7 =:= 0 -&gt;
  bin_to_hex_(Bin, Acc);
bin_to_hex(&lt;&lt;X:8, Rest/binary&gt;&gt;, Acc) -&gt;
  bin_to_hex(Rest, &lt;&lt;Acc/binary, ?H(X)&gt;&gt;).

bin_to_hex_(&lt;&lt;&gt;&gt;, Acc) -&gt; Acc;
bin_to_hex_(&lt;&lt;A:8, B:8, C:8, D:8, E:8, F:8, G:8, H:8, Rest/binary&gt;&gt;, Acc) -&gt;
  bin_to_hex_(
    Rest,
    &lt;&lt;Acc/binary,
      ?H(A), ?H(B), ?H(C), ?H(D), ?H(E), ?H(F), ?H(G), ?H(H)&gt;&gt;).

-compile({inline, [hex/1]}).

hex(X) -&gt;
  element(
    X+1, {16#3030, 16#3031, 16#3032, 16#3033, 16#3034, 16#3035, 16#3036,
          16#3037, 16#3038, 16#3039, 16#3041, 16#3042, 16#3043, 16#3044,
          16#3045, 16#3046, 16#3130, 16#3131, 16#3132, 16#3133, 16#3134,
          16#3135, 16#3136, 16#3137, 16#3138, 16#3139, 16#3141, 16#3142,
          16#3143, 16#3144, 16#3145, 16#3146, 16#3230, 16#3231, 16#3232,
          16#3233, 16#3234, 16#3235, 16#3236, 16#3237, 16#3238, 16#3239,
          16#3241, 16#3242, 16#3243, 16#3244, 16#3245, 16#3246, 16#3330,
          16#3331, 16#3332, 16#3333, 16#3334, 16#3335, 16#3336, 16#3337,
          16#3338, 16#3339, 16#3341, 16#3342, 16#3343, 16#3344, 16#3345,
          16#3346, 16#3430, 16#3431, 16#3432, 16#3433, 16#3434, 16#3435,
          16#3436, 16#3437, 16#3438, 16#3439, 16#3441, 16#3442, 16#3443,
          16#3444, 16#3445, 16#3446, 16#3530, 16#3531, 16#3532, 16#3533,
          16#3534, 16#3535, 16#3536, 16#3537, 16#3538, 16#3539, 16#3541,
          16#3542, 16#3543, 16#3544, 16#3545, 16#3546, 16#3630, 16#3631,
          16#3632, 16#3633, 16#3634, 16#3635, 16#3636, 16#3637, 16#3638,
          16#3639, 16#3641, 16#3642, 16#3643, 16#3644, 16#3645, 16#3646,
          16#3730, 16#3731, 16#3732, 16#3733, 16#3734, 16#3735, 16#3736,
          16#3737, 16#3738, 16#3739, 16#3741, 16#3742, 16#3743, 16#3744,
          16#3745, 16#3746, 16#3830, 16#3831, 16#3832, 16#3833, 16#3834,
          16#3835, 16#3836, 16#3837, 16#3838, 16#3839, 16#3841, 16#3842,
          16#3843, 16#3844, 16#3845, 16#3846, 16#3930, 16#3931, 16#3932,
          16#3933, 16#3934, 16#3935, 16#3936, 16#3937, 16#3938, 16#3939,
          16#3941, 16#3942, 16#3943, 16#3944, 16#3945, 16#3946, 16#4130,
          16#4131, 16#4132, 16#4133, 16#4134, 16#4135, 16#4136, 16#4137,
          16#4138, 16#4139, 16#4141, 16#4142, 16#4143, 16#4144, 16#4145,
          16#4146, 16#4230, 16#4231, 16#4232, 16#4233, 16#4234, 16#4235,
          16#4236, 16#4237, 16#4238, 16#4239, 16#4241, 16#4242, 16#4243,
          16#4244, 16#4245, 16#4246, 16#4330, 16#4331, 16#4332, 16#4333,
          16#4334, 16#4335, 16#4336, 16#4337, 16#4338, 16#4339, 16#4341,
          16#4342, 16#4343, 16#4344, 16#4345, 16#4346, 16#4430, 16#4431,
          16#4432, 16#4433, 16#4434, 16#4435, 16#4436, 16#4437, 16#4438,
          16#4439, 16#4441, 16#4442, 16#4443, 16#4444, 16#4445, 16#4446,
          16#4530, 16#4531, 16#4532, 16#4533, 16#4534, 16#4535, 16#4536,
          16#4537, 16#4538, 16#4539, 16#4541, 16#4542, 16#4543, 16#4544,
          16#4545, 16#4546, 16#4630, 16#4631, 16#4632, 16#4633, 16#4634,
          16#4635, 16#4636, 16#4637, 16#4638, 16#4639, 16#4641, 16#4642,
          16#4643, 16#4644, 16#4645, 16#4646}).
</code></pre>

<p>Which performs 90MB/s on mine notebook i5 CPU M 520 @ 2.40GHz when tested on 10MB chunks. But optimization was brought to the extreme there. It can also do 97MB if using 16bit lookup but it is crazy and too long to post here.</p>
","3771421"
"compile python script in linux","10698","","<p>So I have a python script that relies on a couple modules. Specifically pexpect and pyinoitify. I know you can compile a python script into a .exe in windows, but is there something relatively equivalent in linux? I don't care about it being a binary, I'd just like to be able to distribute my script without requiring the separate installation of pexpect and pyinotify. Is that possible/worthwhile?</p>
","<p><a href=""http://cx-freeze.sourceforge.net/"" rel=""noreferrer""><code>cx_Freeze</code></a> is a cross-platform way to ""freeze"" a Python script into standalone binary form. According to their site:</p>

<blockquote>
  <p>cx_Freeze is a set of scripts and
  modules for freezing Python scripts
  into executables in much the same way
  that py2exe and py2app do. Unlike
  these two tools, cx_Freeze is cross
  platform and should work on any
  platform that Python itself works on.
  It requires Python 2.3 or higher since
  it makes use of the zip import
  facility which was introduced in that
  version.</p>
</blockquote>
","3671533"
"Reading binary data from a child process in Node.js","10697","","<p>When trying to read data in Node.js from an ImageMagick child process, it comes out corrupted.</p>

<p>A simple test case would be the following:</p>

<pre><code>var fs = require('fs');
var exec = require('child_process').exec;

var cmd = 'convert ./test.jpg -';
exec(cmd, {encoding: 'binary', maxBuffer: 5000*1024}, function(error, stdout) {
  fs.writeFileSync('test2.jpg', stdout);
});
</code></pre>

<p>I would expect that to be the equivalent of the command line <code>convert ./test.jpg - &gt; test2.jpg</code> that does write the binary file correctly.</p>

<p>Originally there was a problem with the maxBuffer option being too small and resulting in a truncated file. After increasing that, the file now appears slightly larger than expected and still corrupted.
The data from stdout is required to send over HTTP.</p>

<p>What would be the correct way to read this data from the ImageMagick stdout?</p>
","<p>There were two problems with the initial approach.</p>

<ol>
<li><p>The maxBuffer needs to be high enough to handle the whole response from the child process.</p></li>
<li><p>Binary encoding needs to be properly set everywhere. </p></li>
</ol>

<p>A full working example would be the following:</p>

<pre><code>var fs = require('fs');
var exec = require('child_process').exec;

var cmd = 'convert ./test.jpg -';
exec(cmd, {encoding: 'binary', maxBuffer: 5000*1024}, function(error, stdout) {
  fs.writeFileSync('test2.jpg', stdout, 'binary');
});
</code></pre>

<p>Another example, sending the data in an HTTP response using the Express web framework, would like this:</p>

<pre><code>var express = require('express');
var app = express.createServer();

app.get('/myfile', function(req, res) {
  var cmd = 'convert ./test.jpg -';
  exec(cmd, {encoding: 'binary', maxBuffer: 5000*1024}, function(error, stdout) {
     res.send(new Buffer(stdout, 'binary'));
  });
});
</code></pre>
","6170723"
"Converting binary data to characters in java","10696","","<p>I have a file in which its content is only 0's and 1's</p>

<p>I want to write a java program that convert each 8 bit of 0's and 1's to char 
or in other word, to convert the file content from binary to chars.</p>

<p>Which function can I use for that purpose?</p>
","<p>This one is also work</p>

<pre><code>    String s = ""0110100001100101011011000110110001101111"";
    String str = """";

    for (int i = 0; i &lt; s.length()/8; i++) {

        int a = Integer.parseInt(s.substring(8*i,(i+1)*8),2);
        str += (char)(a);
    }

    System.out.println(str);
</code></pre>
","8635037"
"Why use bin2hex when inserting binary data from PHP into MySQL?","10683","","<p>I heard a rumor that when inserting binary data (files and such) into MySQL, you should use the <code>bin2hex()</code> function and send it as a HEX-coded value, rather than just use <code>mysql_real_escape_string</code> on the binary string and use that.</p>

<pre><code>// That you should do
$hex = bin2hex($raw_bin);
$sql = ""INSERT INTO `table`(`file`) VALUES (X'{$hex}')"";

// Rather than
$bin = mysql_real_escape_string($raw_bin);
$sql = ""INSERT INTO `table`(`file`) VALUES ('{$bin}')"";
</code></pre>

<p>It is supposedly for performance reasons. Something to do with how MySQL handles large strings vs. how it handles HEX-coded values</p>

<p>However, I am having a hard time confirming this. All my tests indicate the exact oposite; that the <code>bin2hex</code> method is ~85% slower and uses ~24% more memory.<br>
<em>(I am testing this on PHP 5.3, MySQL 5.1, Win7 x64 - Using a farily simple insert loop.)</em></p>

<p>For instance, this graph shows the private memory usage of the <em>mysqld</em> process while the test code was running:</p>

<p><a href=""http://atli.advefir.com/images/priv_mem_cropped.gif"">Private Bytes used by the mysqld process http://atli.advefir.com/images/priv_mem_cropped.gif</a></p>

<p>Does anybody have any explainations or reasources that would clarify this?</p>

<p>Thanks.</p>
","<p>This sounds like an urban legend to me.</p>

<p><code>bin2hex()</code> maps each byte in the input to <em>two</em> bytes in the output (<code>'a'</code> -> <code>'61'</code>), so you should notice a significant memory increase of the script performing the query - it should use at least as much memory more as the byte length of the binary data to be inserted.</p>

<p>Furthermore, this implies that running <code>bin2hex()</code> on a long string takes <em>much</em> longer than running <code>mysql_real_escape string()</code>, which - as explained in <a href=""http://dev.mysql.com/doc/refman/5.0/en/mysql-real-escape-string.html"" rel=""noreferrer"">MySQL's documentation</a> - just escapes 6 characters: <code>NULL</code>, <code>\r</code>, <code>\n</code>, <code>\</code>, <code>,</code> and 'Control-Z'.</p>

<p>That was for the PHP part, now for MySQL: The server needs to do the reverse operation to store the data correctly. Reversing either of the functions takes almost as long as the original operation - the reverse function of <code>mysql_real_escape_string()</code> needs to replace escaped values (<code>\\</code>) with unescaped ones (<code>\</code>), whereas the reverse of <code>bin2hex()</code> would need to replace <em>each and every byte tuple</em> with a new byte.</p>

<p>Since calling <code>mysql_real_escape_string()</code> on binary data is safe (according to MySQL's and <a href=""http://php.net/manual/en/function.mysql-real-escape-string.php"" rel=""noreferrer"">PHP's documentation</a> or even when just considering that the operation does not do any other conversions than the ones listed above), it would make absolutely no sense to perform such a costly operation.</p>
","2612978"
"Simple edit to a binary file in python","10678","","<p><strong>THIS SHOULD BE EASY!</strong>  But i've been unable to find the answer to this question.</p>

<p>Using python, I want to read a binary file into memory, modify the first four bytes of the file, and then write the file back. </p>

<p>There has to be a simple way to edit four measly bytes! right?</p>
","<p>Why read the entire file to change four bytes at the beginning? Shouldn't this work?</p>

<pre><code>with open(""filename.txt"", ""r+b"") as f:
     f.write(chr(10) + chr(20) + chr(30) + chr(40))
</code></pre>

<p>Even if you need to read these bytes from the file to calculate the new values, you could still do:</p>

<pre><code>with open(""filename.txt"", ""r+b"") as f:
    fourbytes = [ord(b) for b in f.read(4)]
    fourbytes[0] = fourbytes[1]  # whatever, manipulate your bytes here
    f.seek(0)
    f.write("""".join(chr(b) for b in fourbytes))
</code></pre>
","4599864"
"In Perl, can I treat a string as a byte array?","10663","","<p>In Perl, is it appropriate to use a string as a byte array containing 8-bit data? All the documentation I can find on this subject focuses on 7-bit strings.</p>

<p>For instance, if I read some data from a binary file into <code>$data</code></p>

<pre><code>my $data;

open FILE, ""&lt;"", $filepath;
binmode FILE;
read FILE $data 1024;
</code></pre>

<p>and I want to get the first byte out, is <code>substr($data,1,1)</code> appropriate? (again, assuming it is 8-bit data)</p>

<p>I come from a mostly C background, and I am used to passing a <code>char</code> pointer to a <code>read()</code> function. My problem might be that I don't understand what the underlying representation of a string is in Perl.</p>
","<p>The bundled documentation for the <code>read</code> command, reproduced here, provides a lot of information that is relevant to your question. </p>

<p><code>read FILEHANDLE,SCALAR,LENGTH,OFFSET</code></p>

<p><code>read FILEHANDLE,SCALAR,LENGTH</code></p>

<blockquote>
  <p>Attempts to read LENGTH <strong>characters</strong> of data into variable SCALAR
          from the specified FILEHANDLE.  Returns the number of
          characters actually read, 0 at end of file, or undef if there
          was an error (in the latter case $! is also set).  SCALAR will
          be grown or shrunk so that the last character actually read is
          the last character of the scalar after the read.</p>
  
  <p>An OFFSET may be specified to place the read data at some place
          in the string other than the beginning.  A negative OFFSET
          specifies placement at that many characters counting backwards
          from the end of the string.  A positive OFFSET greater than the
          length of SCALAR results in the string being padded to the
          required size with ""\0"" bytes before the result of the read is
          appended.</p>
  
  <p>The call is actually implemented in terms of either Perl's or
          system's fread() call.  To get a true read(2) system call, see
          ""sysread"".</p>
  
  <p>Note the <strong>characters</strong>: depending on the status of the filehandle,
          either (8-bit) bytes or characters are read.  <strong>By default all
          filehandles operate on bytes, but for example if the filehandle
          has been opened with the "":utf8"" I/O layer (see ""open"", and the
          ""open"" pragma, open), the I/O will operate on UTF-8 encoded
          Unicode characters, not bytes.</strong>  Similarly for the "":encoding""
          pragma: in that case pretty much any characters can be read.</p>
</blockquote>
","3065962"
"String to binary and vice versa: extended ASCII","10639","","<p>I want to convert a String to binary by putting it in a byte array (<code>String.getBytes[]</code>) and then store the binary string for each byte (<code>Integer.toBinaryString(bytearray)</code>) in a String[]. Then I want to convert back to normal String via <code>Byte.parseByte(stringarray[i], 2)</code>. This works great for standard ASCII-Table, but not for the extended one. For example, an <code>A</code> gives me <code>1000001</code>, but an <code>Ä</code> returns </p>

<pre><code>11111111111111111111111111000011
11111111111111111111111110000100
</code></pre>

<p>Any ideas how to manage this?</p>

<pre><code>public class BinString {
    public static void main(String args[]) {
        String s = ""ä"";
        System.out.println(binToString(stringToBin(s)));

    }

    public static String[] stringToBin(String s) {
        System.out.println(""Converting: "" + s);
        byte[] b = s.getBytes();
        String[] sa = new String[s.getBytes().length];
        for (int i = 0; i &lt; b.length; i++) {
            sa[i] = Integer.toBinaryString(b[i] &amp; 0xFF);
        }
        return sa;
    }

    public static String binToString(String[] strar) {
        byte[] bar = new byte[strar.length];
        for (int i = 0; i &lt; strar.length; i++) {
            bar[i] = Byte.parseByte(strar[i], 2);
            System.out.println(Byte.parseByte(strar[i], 2));

        }
        String s = new String(bar);
        return s;
    }

}
</code></pre>
","<p>First off: ""extended ASCII"" is a very misleading title that's used to refer to a ton of different encodings.</p>

<p>Second: <code>byte</code> in Java is signed, while bytes in encodings are usually handled as unsigned. Since you use <code>Integer.toBinaryString()</code> the <code>byte</code> will be converted to an <code>int</code> using sign extension (because byte values > 127 will be represented by negative values in Java).</p>

<p>To avoid this simply use <code>&amp; 0xFF</code> to mask all but the lower 8 bit like this:</p>

<pre><code>String binary = Integer.toBinaryString(byteArray[i] &amp; 0xFF);
</code></pre>
","5536013"
"Detect non-printable characters in JavaScript","10524","","<p>Is it possible to detect binary data in JavaScript?</p>

<p>I'd like to be able to detect binary data and convert it to hex for easier readability/debugging.</p>

<hr>

<p>After more investigation I've realized that detecting binary data is not the right question, because binary data can contain regular characters, and non-printable characters.</p>

<p>Outis's question and answer (/[\x00-\x1F]/) is really the best we can do in an attempt to detect binary characters.</p>

<p>Note: You must remove line feeds and possibly other characters from your ascii string sequence for the check to actually work.</p>
","<p>If by ""binary"", you mean ""contains non-printable characters"", try:</p>

<pre><code>/[\x00-\x1F]/.test(data)
</code></pre>

<p>If whitespace is considered non-binary data, try:</p>

<pre><code>/[\x00-\x08\x0E-\x1F]/.test(data)
</code></pre>

<p>If you know the string is either ASCII or binary, use:</p>

<pre><code>/[\x00-\x1F\x80-\xFF]/.test(data)
</code></pre>

<p>or:</p>

<pre><code>/[\x00-\x08\x0E-\x1F\x80-\xFF]/.test(data)
</code></pre>
","1677660"
"Coverting String Decimal to Binary and Hexa in Assembly 8086","10467","","<p>I'm trying to convert a string I read with this code to binary and hexa.</p>

<pre><code>READ_STRING:
    MOV DX, offset buffer
    MOV AH, 0Ah
    INT 21h
    MOV SI, 1d
    MOV AX, 0
    XOR CX, CX
    MOV CL, buffer[SI]
    INC SI

LOOP_1:
    MOV DX, 10
    MUL DX
    MOV DL, buffer[SI]
    SUB DL, 30h
    MOV DH, 0
    ADD AX, DX
    INC SI
    LOOP LOOP_1

    RET
</code></pre>

<p>So far I have this code for binary output but it always prints ""1001"" (9 in decimal):</p>

<pre><code>NEXT:

    XOR AX, AX
    XOR BX, BX
    XOR CX, CX
    MOV CL, 2
    MOV AL, byte ptr[nombre]
    MOV DI, offset binaire

; DIV : divide AX by CL. Remainder in AH and result in AL

LOOP:
    DIV CL ; remainder in AH, quotient in AL
    ADD AH, '0' ;  0 -&gt; '0' , 1 -&gt; '1'
    MOV [DI], AH ; Saves the remainder in the array
    INC DI
    MOV AH, 0 ; reset AH for next division
    CMP AL, 0 ; if result is 0, end
    JNE LOOP

;Prints the binary number               
    MOV DX, offset binaire
    CALL WRITE_STRING
</code></pre>

<p>Thanks! If you need anything else just ask.</p>
","<p>Before worrying about whether or not you can display the value as binary or hexadecimal; check to make sure your code correctly converts the user's input into an integer (e.g. with a debugger).</p>

<p>For binary, consider something like this:</p>

<pre><code>    mov bx,ax              ;bx = the value to display as binary
    mov cx,16              ;cx = number of bits to display
    mov di,offset binaire  ;es:di = address to store string

.nextBit:
    xor ax,ax              ;al = 0
    add bx,bx              ;bx = value * 2; carry flag = overflow
    adc al,0               ;al = '0' or '1'
    stosb                  ;Add new character to string
    loop .nextBit
    mov byte [di],0        ;Terminate the string (ASCIIZ?)

    mov dx, offset binaire
    call WRITE_STRING
</code></pre>

<p>For hexadecimal, it's the same basic idea, except you need to extract the highest 4 bits:</p>

<pre><code>    mov bx,ax              ;bx = the value to display as binary
    mov cx,4               ;cx = number of nibbles to display
    mov di,offset binaire  ;es:di = address to store string

.nextNibble:
    mov ax,bx              ;ax = value
    shr ax,12              ;ax = highest 4 bits of value
    shl bx,4               ;bx = value &lt;&lt; 4
    add al,'0'
    cmp al,'9'
    jbe .gotChar
    add al,'A' - '9'
.gotChar:
    stosb                  ;Add new character to string
    loop .nextBit
    mov byte [di],0        ;Terminate the string (ASCIIZ?)

    mov dx, offset binaire
    call WRITE_STRING
</code></pre>

<p>Note 1: I haven't tested any of the code above, and I normally use NASM (not MASM), so it may not assemble ""as is"".</p>

<p>Note 2: Example code above is intentionally simple. For performance you could do a lot better using lookup tables instead.</p>

<p>Note 3: These aren't complex algorithms and you shouldn't need to mess about with high level languages first (unless you don't understand the theory/maths behind binary/hex conversion perhaps). Also, an algorithm that seems elegant in one language can be an ugly mess in another language (e.g. you can't detect overflow in an easy/clean way in C, so the method used for binary conversion above wouldn't be obvious or elegant in C; and a different method that is elegant in C might suck badly in assembly).</p>
","9753322"
"Binary String to Integer with 'atoi()'","10459","","<p>I have a string of binary that I then convert to an integer using <code>atoi()</code>. When I do this it seems to automatically convert the binary to decimal. The issue is that the resulting integer is negative and doesn't agree with any of the online binary-to-decimal converters. Is something broken with <code>atoi()</code>? Should I be using a different function instead?</p>

<p>Code:</p>

<pre><code>string myString = ""01000101"";
int x = atoi(myString.c_str());
cout &lt;&lt; x;
</code></pre>

<p>Thanks</p>
","<p><code>atoi</code> doesn't handle binary numbers, it just interprets them as big decimal numbers. Your problem is that it's too high and you get an integer overflow due to it being interpreted as decimal number.</p>

<p>The solution would be to use <code>stoi</code>, <code>stol</code> or <code>stoll</code> that got added to <code>string</code> in C++11. Call them like</p>

<pre><code>int i = std::stoi(""01000101"", nullptr, 2);
</code></pre>

<ul>
<li>The returned value is the converted <code>int</code> value.</li>
<li>The first argument is the <code>std::string</code> you want to convert.</li>
<li>The second is a <code>size_t *</code> where it'll save the index of the first non digit character.</li>
<li>The third is an <code>int</code> that corresponds to the base that'll be used for conversion..</li>
</ul>

<p>For information on the functions look at <a href=""http://en.cppreference.com/w/cpp/string/basic_string/stol"" rel=""nofollow noreferrer"">its cppreference page</a>.</p>

<hr>

<p>Note that there are also pre C++11 functions with nearly the same name, as example: <code>strtol</code> compared to the C++11 <code>stol</code>.<br>
They do work for different bases too, but they don't do the error handling in the same way (they especially lack when no conversion could be done on the given string at all e.g trying to convert ""hello"" to a string) and <strong>you should probably prefer the C++11 versions</strong>.</p>

<p>To make my point, passing ""Hello"" to both <code>strtol</code> and the C++11 <code>stol</code> would lead to:</p>

<ul>
<li><code>strtol</code> returns <code>0</code> and doesn't give you any way to identify it as error,</li>
<li><code>stol</code> from C++11 throws <code>std::invalid_argument</code> and indicates that something is wrong.</li>
</ul>

<p>Falsely interpreting something like ""Hello"" as integers might lead to bugs and should be avoided in my opinion.</p>

<p>But for completeness sake a link to <a href=""http://en.cppreference.com/w/cpp/string/byte/strtol"" rel=""nofollow noreferrer"">its cppreference page</a> too.</p>
","23597029"
"How to complement bytes in java?","10452","","<p>I need to complement string binaries.</p>

<p><code>st=br.readLine() //I used readline to read string line</code></p>

<p><code>byte[] bytesy = st.getBytes(); //and put it to bytes array.</code></p>

<p>Now how can I complement the binary equivalent of the bytes (or how to XOR it to 11111111) ?</p>

<p>Expected output :</p>

<p>If first char of st is  x then binary equivalent is 01111000 </p>

<p>and the output must be 10000111 by complementing ( or XOR to 11111111)</p>
","<p>To complement a byte, you use the <code>~</code> operator. So if x is 01111000, then <code>~x</code> is 10000111. For XORing you can use <code>x ^= 0xFF</code> (11111111b == 0xFF in hex)</p>
","7256783"
"Insert binary data into SQL from c# without a stored procedure","10448","","<p>Does anyone know whether if its possible to insert binary data into an SQL field from c# without using a stored procedure?</p>

<p>For example - convert a byte array into base64 or something like that and then use a text command like the following...</p>

<pre><code>String.Format(""update A set B = {0} where C = D"", Convert.ToBase64String(b));
</code></pre>

<p>where b is a byte array.</p>

<p>Thanks</p>
","<p>Of course, you should use parameterized statements, but if you really need to, you can do it like this:</p>

<pre><code>byte[] b = null; //(your input should be a byte[])
String.Format(""update A set B = 0x{0} where C = D"", BitConverter.ToString(b).Replace(""-"", """").ToLower());
</code></pre>

<p>SQL Server expects binary data in a hexadecimal format without hyphens and in lower case with a prefix of '<strong>0x</strong>'</p>
","1956004"
"How to calculate excess-256 and excess-128?","10404","","<p>I have the number -37 in decimal. Could you please tell me what its representation is in excess-256 and excess-128?</p>

<p>Its normal binary representation is -100101 and in 8 bits 1010 0101. How exactly do I then get the excess-N representation for it? Am I allowed to have a number larger than 8 bits when writing excess-N? Would I thus have: </p>

<p>01010 0000 (first digit) + 10000 0000 and 00101 + 10000 00000?</p>
","<p>to get it into excess 128, add the true value (-37) to 128. = 91, then get the binary value for 91, 1011011. Same applies for 256 i think.</p>
","7631718"
"Binary to Integer -> Erlang","10396","","<p>I have a binary M such that 34= will always be present and the rest may vary between any number of digits but will always be an integer.</p>

<pre><code>M = [&lt;&lt;""34=21""&gt;&gt;]
</code></pre>

<p>When I run this command I get an answer like</p>

<pre><code>hd([X || &lt;&lt;""34="", X/binary &gt;&gt; &lt;- M])

Answer -&gt; &lt;&lt;""21""&gt;&gt;
</code></pre>

<p>How can I get this to be an integer with the most care taken to make it as efficient as possible?</p>
","<pre><code>[&lt;&lt;""34="",X/binary&gt;&gt;] = M,
list_to_integer(binary_to_list(X)).
</code></pre>

<p>That yields the integer <code>21</code></p>
","4771970"
"Reading and writing binary data over serial port","10351","","<p>So I searched around, and couldn't exactly find what I needed. I need help reading and writing binary data over a serial port, and would appreciate any advice you may have. Please note, I asked a question similar to this earlier when I was at a different stage of this project.</p>

<p>Below are programs. The first program opens a file ""test.jpg"", reads it in binary mode and stores the result in a buffer. It then closes the file, and is supposed to send that file over a serial port.</p>

<p>The second program creates a file called ""testout.jpg"", and is supposed to read in the data sent from the previous program.</p>

<p>I have a hunch that the problem in my code lies in the second program. Perhaps I need to use fread for that too? I tried, but I cannot figure out how to implement it for a serial port as I am relatively new to programming.</p>

<p>Many thanks for your time.</p>

<p>Serial write:</p>

<pre><code>    #include &lt;stdio.h&gt;   /* Standard input/output definitions */
    #include &lt;string.h&gt;  /* String function definitions */
    #include &lt;unistd.h&gt;  /* UNIX standard function definitions */
    #include &lt;fcntl.h&gt;   /* File control definitions */
    #include &lt;errno.h&gt;   /* Error number definitions */
    #include &lt;termios.h&gt; /* POSIX terminal control definitions */
    #include &lt;stdlib.h&gt;

    int main()
        {
                //writing
                int writeport = open_port(""/dev/ttyUSB0"");

                //open file

                FILE *file;
                char *buffer;
                int fileLen;

                file = fopen(""test.jpg"", ""rb"");

                //get file size

                fseek(file, 0, SEEK_END);
                fileLen = ftell(file);
                fseek(file, 0, SEEK_SET);

                buffer = (char *)malloc(fileLen + 1);

                //read file contents

                fread(buffer, fileLen, 1, file);
                fclose(file);

                int n = write(writeport, buffer, fileLen + 1);
                if (n &lt; 0)
                        fputs(""write() of bytes failed!\n"", stderr);

                //closing ports
                close(writeport);
        }

        int open_port(char str[])
    {
        int fd = open(str, O_RDWR | O_NOCTTY | O_NONBLOCK); // ?? NDELAY or NONBLOCK?

      if (fd == -1)
      {
                        perror(""open_port: Unable to open /dev/ttyS0 - "");
      }
      else
                        fcntl(fd, F_SETFL, 0);

          struct termios options;
          tcgetattr(fd, &amp;options); //this gets the current options set for the port

          // setting the options

          cfsetispeed(&amp;options, B9600); //input baudrate
          cfsetospeed(&amp;options, B9600); // output baudrate
          options.c_cflag |= (CLOCAL | CREAD); // ?? enable receicer and set local mode
          //options.c_cflag &amp;= ~CSIZE; /* mask the character size bits */
          options.c_cflag |= CS8;    /* select 8 data bits */
          options.c_lflag &amp;= ~(ICANON | ECHO | ECHOE | ISIG); // choosing raw input
          options.c_iflag &amp;= ~INPCK; // disable parity check
          options.c_iflag &amp;= ~(IXON | IXOFF | IXANY); // disable software flow control
          options.c_oflag |= OPOST; // ?? choosing processed output
          options.c_cc[VMIN] = 0; // Wait until x bytes read (blocks!)
          options.c_cc[VTIME] = 0; // Wait x * 0.1s for input (unblocks!)

          // settings for no parity bit
          options.c_cflag &amp;= ~PARENB;
          options.c_cflag &amp;= ~CSTOPB;
          options.c_cflag &amp;= ~CSIZE;
          options.c_cflag |= CS8;

          tcsetattr(fd, TCSANOW, &amp;options); //set the new options ... TCSANOW specifies all option changes to occur immediately

      return (fd);
    }
</code></pre>

<p>Serial read:</p>

<pre><code>    #include &lt;stdio.h&gt;   /* Standard input/output definitions */
    #include &lt;string.h&gt;  /* String function definitions */
    #include &lt;unistd.h&gt;  /* UNIX standard function definitions */
    #include &lt;fcntl.h&gt;   /* File control definitions */
    #include &lt;errno.h&gt;   /* Error number definitions */
    #include &lt;termios.h&gt; /* POSIX terminal control definitions */

    int main()
        {
                //reading      
                int readport = open_port(""/dev/ttyUSB1"");

        //open resultant file

        FILE *file;
        //system(""rm testout.jpg"");
        file = fopen(""testout.jpg"", ""wb"");

                //trying to read one character at a time
                char buff;
                int n = 1;

           while (n &gt; 0)
           {
                n = read(readport, &amp;buff, 1);
                //printf(""%c"", buff, buff);

                **//I tried these three methods, with little success**

                //fprintf(file, ""%c"", buff);
                //fwrite(&amp;buff, 1, 1, file);
                //write(file, &amp;buff, 1);
           }

                //closing ports
                close(readport);
                fclose(file);
        }

        int open_port(char str[])
    {
        int fd = open(str, O_RDWR | O_NOCTTY | O_NONBLOCK); // ?? NDELAY or NONBLOCK?

      if (fd == -1)
      {
                        perror(""open_port: Unable to open /dev/ttyS0 - "");
      }
      else
                        fcntl(fd, F_SETFL, 0);

          struct termios options;
          tcgetattr(fd, &amp;options); //this gets the current options set for the port

          // setting the options

          cfsetispeed(&amp;options, B9600); //input baudrate
          cfsetospeed(&amp;options, B9600); // output baudrate
          options.c_cflag |= (CLOCAL | CREAD); // ?? enable receicer and set local mode
          //options.c_cflag &amp;= ~CSIZE; /* mask the character size bits */
          options.c_cflag |= CS8;    /* select 8 data bits */
          options.c_lflag &amp;= ~(ICANON | ECHO | ECHOE | ISIG); // choosing raw input
          options.c_iflag &amp;= ~INPCK; // disable parity check
          options.c_iflag &amp;= ~(IXON | IXOFF | IXANY); // disable software flow control
          options.c_oflag |= OPOST; // ?? choosing processed output
          options.c_cc[VMIN] = 0; // Wait until x bytes read (blocks!)
          options.c_cc[VTIME] = 0; // Wait x * 0.1s for input (unblocks!)

          // settings for no parity bit
          options.c_cflag &amp;= ~PARENB;
          options.c_cflag &amp;= ~CSTOPB;
          options.c_cflag &amp;= ~CSIZE;
          options.c_cflag |= CS8;

          tcsetattr(fd, TCSANOW, &amp;options); //set the new options ... TCSANOW specifies all option changes to occur immediately

      return (fd);
    }
</code></pre>
","<pre><code>file = fopen( ""zname.jpg"", ""wb"" );
while (1) { 
  n = read(readport, &amp;buff, 1);
  if (n == -1) switch(errno) {
         case EAGAIN: /* sleep() */ 
            continue;
          ...
         default: goto quit;
         }
  if (n ==0) break;
  fputc(buff, file);
  }
quit:
   fclose (file);
...
</code></pre>

<p>Even better than sleep() and loop, would be to use select/poll. (You'd still have to check for EAGAIN)</p>
","11650597"
"Use CDATA to store raw binary streams?","10298","","<p>Instead of the overhead with <a href=""https://stackoverflow.com/questions/502814/storing-base64-data-in-xml"">saving binary as Base64</a>, I was wondering if you could directly store double-byte binary streams into XML files, using CDATA, or commenting it out, or something?</p>
","<p>You can store it as CDATA, but there's the risk that some byte sequences will evaluate to valid XML that closes the CDATA section. After a quick look at <a href=""http://www.w3.org/TR/2006/REC-xml-20060816/#sec-cdata-sect"" rel=""nofollow noreferrer"">http://www.w3.org/TR/2006/REC-xml-20060816/#sec-cdata-sect</a>, it seems you can have any sequence of chars except ""]]>"". Have a look at <a href=""http://www.w3.org/TR/2006/REC-xml-20060816/#NT-Char"" rel=""nofollow noreferrer"">what is a valid XML char</a> too.</p>
","502871"
"Convert from string to binary in VB.NET","10285","","<p>Let's say that I have the string ""A3C0"", and I want to store the binary value of it in a Boolean array.</p>

<p>After the conversion (from string to binary) the result should be = 1010001111000000</p>

<p>Then I want to store it in this array,</p>

<pre><code>dim bits_array(15) as Boolean
</code></pre>

<p>at the end:</p>

<pre><code>bits_array(0)=0
bits_array(1)=0
 .
 .
 .
 .
bits_array(15)=1
</code></pre>

<p>How can I do this?</p>
","<p>It's easy.</p>

<pre><code>Function HexStringToBinary(ByVal hexString As String) As String
    Dim num As Integer = Integer.Parse(hexString, NumberStyles.HexNumber)
    Return Convert.ToString(num, 2)
End Function
</code></pre>

<p>Sample Usage:</p>

<pre><code>Dim hexString As String = ""A3C0""
Dim binaryString As String = HexStringToBinary(hexString)
MessageBox.Show(""Hex: "" &amp; hexString &amp; ""    Binary: "" &amp; binaryString)
</code></pre>

<p>To get the binary digits into an array, you can simply do:</p>

<pre><code>Dim binaryDigits = HexStringToBinary(hexString).ToCharArray
</code></pre>
","25406388"
"Can hexadecimal numbers be added/subtracted with decimal numbers?","10264","","<p>When programming in C, say if I have integer h as a hexadecimal value and integer d as a decimal number. Can I do addition or subtraction between h and d? Or do they have have to be in the same number system?</p>
","<p>Yes, you can write:</p>

<pre><code>int x = 100 - 0x100 + 0100;
</code></pre>

<p>That mixes decimal with hex and octal.  The values are all converted to binary anyway before the calculation occurs (and the compiler will do the calculation in this example; it won't be evaluated at runtime).  And any of the constants can be replaced by an <code>int</code> value that was assigned the appropriate value:</p>

<pre><code>int d = 100;
int h = 0x100;
int o = 0100;
int x = d + h + o;
</code></pre>
","28445481"
"PHP write binary response","10251","","<p>In php is there a way to write binary data to the response stream,
<br>
like the equivalent of (c# asp)
<br></p>

<pre><code>System.IO.BinaryWriter Binary = new System.IO.BinaryWriter(Response.OutputStream);
Binary.Write((System.Int32)1);//01000000
Binary.Write((System.Int32)1020);//FC030000
Binary.Close();
</code></pre>

<p><br>
<br>
I would then like to be able read the response in a c# application, like</p>

<pre><code>System.Net.HttpWebRequest Request = (System.Net.HttpWebRequest)System.Net.WebRequest.Create(""URI"");
System.IO.BinaryReader Binary = new System.IO.BinaryReader(Request.GetResponse().GetResponseStream());
System.Int32 i = Binary.ReadInt32();//1
i = Binary.ReadInt32();//1020
Binary.Close();
</code></pre>
","<p>In PHP, strings and byte arrays are one and the same. Use <code>pack</code> to create a byte array (string) that you can then write. Once I realized that, life got easier.</p>

<pre><code>$my_byte_array = pack(""LL"", 0x01000000, 0xFC030000);
$fp = fopen(""somefile.txt"", ""w"");
fwrite($fp, $my_byte_array);

// or just echo to stdout
echo $my_byte_array;
</code></pre>
","11023089"
"Binary addition of 2 values represented as strings","10242","","<p>I have two strings:</p>

<pre><code>string a = ""00001""; /* which is decimal 1 I've converted with next string:
string a = Convert.ToString(2, 2).PadLeft(5, '0'); */
string b = ""00010"";
</code></pre>

<p>I want to perform binary addition between the two so the answer will be 00011 ( 3).</p>
","<p>System.Convert should be able to do the work for you</p>

<pre><code>int number_one = Convert.ToInt32(a, 2);
int number_two = Convert.ToInt32(b, 2);

return Convert.ToString(number_one + number_two, 2);
</code></pre>

<p>(you may have to tune the strings a bit)</p>
","2252904"
"How are bits stored in memory? (In chunks? Can there be bits of multiple sizes stored toghether?)","10225","","<p>I used to think that each memory location contains 8, 16, 32 or 64 bits. So 0101 would be stored in an 8 bit machine as 00000101 (sign extended if it was negative). This was all fine and dandy until I wrote a program in java out of curiosity to find out some more inner workings of this system. </p>

<p>The method in question looks like this:</p>

<pre><code>public void printBinaryRep(File f){
        try{
            FileInputStream inputStream = new FileInputStream(f);
            int next = 0;
            byte b = 0;
            while((next = inputStream.read()) != -1){
                b = (byte)next;
                System.out.println((char)next + "" : ""+Integer.toBinaryString(next));
            }
            inputStream.close();
        }
        catch(Exception e){System.out.println(e);}
 }
</code></pre>

<p>I got this output from a file that says Hello World</p>

<pre><code>H : 1001000
e : 1100101
l : 1101100
l : 1101100
o : 1101111
  : 100000
W : 1010111
o : 1101111
r : 1110010
l : 1101100
d : 1100100
</code></pre>

<p>All of it looks fine except for the space. It has 6 bits instead of 8. 
I'm now wondering how all of that information is stored in memory. If all of it was stored in 8 bit chunks, like</p>

<p>Hello: 10010001100101110110011011001101111</p>

<p>Then you can simply look at each 8 bit chunk and figure out what number it's representing (and then what ASCII code it's referring to). 
How does it work when a different sized character (like the 6 bit space and the 4 bit /n ) is stored along with them?? Then wouldn't storing a small number in a large bit space waste a lot of bits? </p>

<p>I think I have some of the fundamental understanding wrong (or maybe the program's wrong somewhere...). Sorry if the question sounds strange or too un-necessarily in-depth. I just want to know. I've done some googling, but it didn't come up with anything relevent. If you can let me know where I've gone wrong or point me in the right direction, I'd greatly appreciate it. 
Thanks!</p>
","<p>You'll be better off experimenting in C and/or assembly, rather than Java. Those languages are lower-level and expose the address space directly.</p>

<blockquote>
  <p>I used to think that each memory
  location contains 8, 16, 32 or 64
  bits. So 0101 would be stored in an 8
  bit machine as 00000101 (sign extended
  if it was negative). This was all fine
  and dandy until I wrote a program in
  java out of curiosity to find out some
  more inner workings of this system.</p>
</blockquote>

<p>All memory locations in x86 systems contain 8 bits (1 byte). If a value contains more data than can fit into a single byte, it is stored using multiple bytes. For example, in C, the ""float"" type is stored using 4 bytes (32 bits).</p>

<blockquote>
  <p>All of it looks fine except for the
  space. It has 6 bits instead of 8. I'm
  now wondering how all of that
  information is stored in memory. If
  all of it was stored in 8 bit chunks,
  like</p>
</blockquote>

<p>The space is also stored in a single byte. Your print code is forgetting to pad out to 8 spaces. 100000 == 00100000 == 0x20.</p>
","1546395"
"Bash : echo binary output","10196","","<p>for a script i must create a file and add a line (only numeric) to this.
But this should be in binary mode, but I havent found a solution.</p>

<p>My actually commands:</p>

<pre><code>SIZE=200
touch quota
echo $SIZE &gt;&gt; quota
</code></pre>

<p>How can do this in binary mode?</p>
","<p>Perhaps you need to use the -n option?</p>

<pre><code>echo -n ""$SIZE"" &gt;&gt; quota
</code></pre>

<p>Or maybe you need the binary representation it but this is only limited to 8 bits or 255.</p>

<pre><code>echo -ne ""$(printf '\\x%x' 200)"" &gt;&gt; quota
</code></pre>

<p>Also make sure that you really need to use >> and not > as >> appends data to existing files, not overwrite it.</p>
","18102487"
"C# binary constants representation","10135","","<p>I am really stumped on this one. In C# there is a hexadecimal constants representation format as below :</p>

<pre><code>int a = 0xAF2323F5;
</code></pre>

<p>is there a binary constants representation format?</p>
","<p>As of C#7 you can represent a binary literal value in code:</p>

<pre><code>private static void BinaryLiteralsFeature()
{
    var employeeNumber = 0b00100010; //binary equivalent of whole number 34. Underlying data type defaults to System.Int32
    Console.WriteLine(employeeNumber); //prints 34 on console.
    long empNumberWithLongBackingType = 0b00100010; //here backing data type is long (System.Int64)
    Console.WriteLine(empNumberWithLongBackingType); //prints 34 on console.
    int employeeNumber_WithCapitalPrefix = 0B00100010; //0b and 0B prefixes are equivalent.
    Console.WriteLine(employeeNumber_WithCapitalPrefix); //prints 34 on console.
}
</code></pre>

<p>Further information can be found <a href=""https://www.codeproject.com/Articles/1156167/Csharp-Version-Introduction-to-new-language-featur"" rel=""nofollow noreferrer"">here</a>.</p>
","41193863"
"python: HTTP PUT with unencoded binary data","10132","","<p>I cannot for the life of me figure out how to perform an HTTP PUT request with verbatim binary data in Python 2.7 with the standard Python libraries.</p>

<p>I thought I could do it with urllib2, but <a href=""https://stackoverflow.com/questions/7983303/python-http-put-with-binary-data"">that fails</a> because <a href=""http://docs.python.org/library/urllib2.html#urllib2.Request"" rel=""nofollow noreferrer""><code>urllib2.Request</code></a> expects its data in <code>application/x-www-form-urlencoded</code> format. I do not want to encode the binary data, I just want to transmit it verbatim, after the headers that include </p>

<pre><code>Content-Type: application/octet-stream
Content-Length: (whatever my binary data length is)
</code></pre>

<p>This seems so simple, but I keep going round in circles and can't seem to figure out how. </p>

<p>How can I do this? (aside from open up a raw binary socket and write to it)</p>
","<p>I found out my problem. It seems there is some obscure behavior in <a href=""http://docs.python.org/library/urllib2.html#urllib2.Request"" rel=""nofollow""><code>urllib2.Request</code></a> / <a href=""http://docs.python.org/library/urllib2.html#urllib2.urlopen"" rel=""nofollow""><code>urllib2.urlopen()</code></a> (at least in Python 2.7)</p>

<p>The <code>urllib2.Request(url, data, headers)</code> constructor seems to expect the same type of string in its url and data parameters. </p>

<p>I was giving the data parameter raw data from a file <code>read()</code> call (which in Python 2.7 returns it in the form of a 'plain' string), but my url was accidentally Unicode because I concatenated a portion of the URL from the result of another function which returned Unicode strings.</p>

<p>Rather than trying to ""downcast"" <code>url</code> from Unicode -> plain strings, it tried to ""upcast"" the <code>data</code> parameter to Unicode, and it gave me a codec error. (oddly enough, this happens on the <code>urllib2.urlopen()</code> function call, not the <code>urllib2.Request</code> constructor)</p>

<p>When I changed my function call to</p>

<pre><code># headers contains `{'Content-Type': 'application/octet-stream'}`
r = urllib2.Request(url.encode('utf-8'), data, headers)
</code></pre>

<p>it worked fine.</p>
","8715815"
"How to convert TBytes to Binary File? (using MemoryStream)","10123","","<p>How can i convert <code>Tbytes</code> type to a <code>Binary file</code> using <code>MemoryStream</code>?</p>
","<p>Uwe's answer will work if you have TBytesStream available. If not:</p>

<pre><code>procedure SaveBytesToFile(const Data: TBytes; const FileName: string);
var
  stream: TMemoryStream;
begin
  stream := TMemoryStream.Create;
  try
    if length(data) &gt; 0 then
      stream.WriteBuffer(data[0], length(data));
    stream.SaveToFile(FileName);
  finally
    stream.Free;
  end;
end;
</code></pre>
","6445183"
"How can I convert a binary to a decimal without using a loop?","10111","","<p>I have a 12-bit binary that I need to convert to a decimal. For example:</p>

<pre><code>A = [0,1,1,0,0,0,0,0,1,1,0,0];
</code></pre>

<p>Bit 1 is the most significant bit, Bit 12 is the least significant bit.</p>
","<p>The <a href=""https://www.mathworks.com/help/matlab/ref/bin2dec.html"" rel=""nofollow noreferrer""><code>bin2dec</code></a> function is one option, but requires you to change the vector to a string first. <code>bin2dec</code> can also be slow compared to computing the number yourself. Here's a solution that's about 75 times faster:</p>

<pre><code>&gt;&gt; A = [0,1,1,0,0,0,0,0,1,1,0,0];
&gt;&gt; B = sum(A.*2.^(numel(A)-1:-1:0))

B =

        1548
</code></pre>

<p>To explain, <code>A</code> is multiplied element-wise by a vector of powers of 2, with the exponents ranging from <code>numel(A)-1</code> down to <code>0</code>. The resulting vector is then summed to give the integer represented by the binary pattern of zeroes and ones, with the first element in the array being considered the most significant bit. If you want the first element to be considered the least significant bit, you can do the following:</p>

<pre><code>&gt;&gt; B = sum(A.*2.^(0:numel(A)-1))

B =

        774
</code></pre>

<p><strong>Update:</strong> You may be able to squeeze even a little more speed out of MATLAB by using <a href=""https://www.mathworks.com/help/matlab/ref/find.html"" rel=""nofollow noreferrer""><code>find</code></a> to get the indices of the ones (avoiding the element-wise multiplication and potentially reducing the number of exponent calculations needed) and using the <a href=""https://www.mathworks.com/help/matlab/ref/pow2.html"" rel=""nofollow noreferrer""><code>pow2</code></a> function instead of <code>2.^...</code>:</p>

<pre><code>B = sum(pow2(find(flip(A))-1));  % Most significant bit first
B = sum(pow2(find(A)-1));        % Least significant bit first
</code></pre>

<p><br>
<strong>Extending the solution to matrices...</strong></p>

<p>If you have a lot of binary vectors you want to convert to integers, the above solution can easily be modified to convert all the values with one matrix operation. Suppose <code>A</code> is an N-by-12 matrix, with one binary vector per row. The following will convert them all to an N-by-1 vector of integer values:</p>

<pre><code>B = A*(2.^(size(A, 2)-1:-1:0)).';  % Most significant bit first
B = A*(2.^(0:size(A, 2)-1)).';     % Least significant bit first
</code></pre>

<p>Also note that all of the above solutions automatically determine the number of bits in your vector by looking at the number of columns in <code>A</code>.</p>
","1554876"
"how to send binary data within an xml string","10088","","<p>I want to send a binary file to .net c# component in the following xml format</p>

<pre><code>&lt;BinaryFileString fileType='pdf'&gt;
    &lt;!--binary file data string here--&gt;
&lt;/BinaryFileString&gt;
</code></pre>

<p>In the called component I will use the above xml string and convert the binary string received within the BinaryFileString tag, into a file as specified by the filetype='' attribute. The file type could be doc/pdf/xls/rtf</p>

<p>I have the code in the calling application to get out the bytes from the file to be sent. How do I prepare it to be sent with xml tags wrapped around it? I want the application to send out a string to the component and not a byte stream. This is because there is no way I can decipher the file type [pdf/doc/xls] just by looking at the byte stream. Hence the xml string with the filetype attribute. Any ideas on this?</p>

<p>method for extracting Bytes below</p>

<pre><code>   FileStream fs = new FileStream(_filePath, FileMode.Open, FileAccess.Read);
   using (Stream input = fs)
   {
      byte[] buffer = new byte[8192];
      int bytesRead;
      while ((bytesRead = input.Read(buffer, 0, buffer.Length)) &gt; 0)
      {}
   }
   return buffer;
</code></pre>

<p>Thanks.</p>

<h2>Edit:</h2>

<p>Just to clarify why I am using an xml string rather than setting properties on my component. Actually my calling app is trying to simulate how Siebel will call my component. 
<a href=""http://download.oracle.com/docs/cd/E05553_01/books/eScript/eScript_JSReference244.html#wp1014380"" rel=""noreferrer"">http://download.oracle.com/docs/cd/E05553_01/books/eScript/eScript_JSReference244.html#wp1014380</a>
Im not sure if Siebel can set my components properties as I need it to. So Im working on the angle of it sending the data in xml. </p>
","<p>Base64 representation is universaly used to represent binary data.</p>

<pre><code>public void EncodeWithString() {
    System.IO.FileStream inFile;     
    byte[] binaryData;

    try {
        inFile = new System.IO.FileStream(inputFileName,
                                          System.IO.FileMode.Open,
                                          System.IO.FileAccess.Read);
        binaryData = new Byte[inFile.Length];
        long bytesRead = inFile.Read(binaryData, 0,
                                    (int)inFile.Length);
        inFile.Close();
    }
    catch (System.Exception exp) {
        // Error creating stream or reading from it.
        System.Console.WriteLine(""{0}"", exp.Message);
        return;
    }

    // Convert the binary input into Base64 UUEncoded output.
    string base64String;
    try {
         base64String = 
            System.Convert.ToBase64String(binaryData, 
                                          0,
                                          binaryData.Length);
    }
    catch (System.ArgumentNullException) {
        System.Console.WriteLine(""Binary data array is null."");
        return;
    }

    // Write the UUEncoded version to the XML file.
    System.IO.StreamWriter outFile; 
    try {
        outFile = new System.IO.StreamWriter(outputFileName,
                                    false,
                                    System.Text.Encoding.ASCII);             
        outFile.Write(""&lt;BinaryFileString fileType='pdf'&gt;"");
        outFile.Write(base64String);
        outFile.Write(""&lt;/BinaryFileString&gt;"");
        outFile.Close();
    }
    catch (System.Exception exp) {
        // Error creating stream or writing to it.
        System.Console.WriteLine(""{0}"", exp.Message);
    }
}
</code></pre>

<p>At the receiving end you can reverse this and get back original file content as mentioned below.</p>

<pre><code>        // Convert the Base64 UUEncoded input into binary output.
        byte[] binaryData;
        try {
            binaryData = 
                System.Convert.FromBase64String(base64String);
        }
        catch (System.ArgumentNullException) {
            System.Console.WriteLine(""Base 64 string is null."");
            return;
        }
        catch (System.FormatException) {
            System.Console.WriteLine(""Base 64 string length is not "" +
                ""4 or is not an even multiple of 4."" );
            return;
        }
</code></pre>
","2941544"
"How would I convert decimal into binary?","10086","","<p>All I really know is PHP and I used the <code>decbin</code> function etc, It was fairly easy to do. In this C++ program I want to do the same thing, just a simple number or string how would I do this? </p>
","<p>A simple function could be defined such as this:</p>

<pre><code>void binary(int decimal) {
   int remainder;

   if(decimal &lt;= 1) {
       std::cout &lt;&lt; decimal;
       return;
   }
   remainder = decimal % 2;
   binary(decimal &gt;&gt; 1);    
   std::cout &lt;&lt; remainder;
}
</code></pre>

<p>Although there are many other resources on the web on how to do this..</p>

<p>A noteworthy question for efficiency of it here, as you may want more than just that: 
<a href=""https://stackoverflow.com/questions/819487/efficiently-convert-between-hex-binary-and-decimal-in-c-c"">Efficiently convert between Hex, Binary, and Decimal in C/C++</a></p>
","2801872"
"How to save (all) SQL server image datatype to file system with correct file extension","10009","","<p>I have different types of files in table (txt, doc, jpg, etc) and I want to save them all to my file system. I know how to do it file by file, but it's no use, I have to do a loop that saves all files with right extensions at once. Any advice?</p>

<p>I do it this way now:</p>

<pre><code>DECLARE @ObjectToken INT
EXEC sp_OACreate 'ADODB.Stream', @ObjectToken OUTPUT
EXEC sp_OASetProperty @ObjectToken, 'Type', 1
EXEC sp_OAMethod @ObjectToken, 'Open'
EXEC sp_OAMethod @ObjectToken, 'Write', NULL, &lt;this is where binary data goes&gt;
EXEC sp_OAMethod @ObjectToken, 'SaveToFile', NULL, 'd:/file.txt', 2
EXEC sp_OAMethod @ObjectToken, 'Close'
EXEC sp_OADestroy @ObjectToken
</code></pre>

<p>So, my question would be is there a way to do this for all records (save all files) in db table at once and with setting the correct file extension for every saved file?</p>
","<p>I resolved the problem. As I found it is REALLY not easy to migrate db from SQL Server 2000 to 2005. Only solution which works is this one - <a href=""http://tek-works.com/fixing-there-is-already-an-object-named-sysnsobjs-in-the-database/"" rel=""nofollow"">http://tek-works.com/fixing-there-is-already-an-object-named-sysnsobjs-in-the-database/</a></p>

<p>After completing those steps you just have to set Compatibility  level to 90. (Right click on database > Properties > Compatibility level)</p>

<p>Then you can use VARBINARY(MAX) and save complete image datatype binary files to filesystem.</p>

<p>Good luck with migrating!</p>
","15700047"
"Understanding Java bytes","9916","","<p>So at work yesterday, I had to write an application to count the pages in an AFP file. So I dusted off my MO:DCA spec PDF and found the structured field <code>BPG (Begin Page)</code> and its 3-byte identifier. The app needs to run on an AIX box, so I decided to write it in Java. </p>

<p>For maximum efficiency, I decided that I would read the first 6 bytes of each structured field and then skip the remaining bytes in the field. This would get me:</p>

<pre><code>0: Start of field byte
1-2: 2-byte length of field
3-5: 3-byte sequence identifying the type of field
</code></pre>

<p>So I check the field type and increment a page counter if it's <code>BPG</code>, and I don't if it's not. Then I skip the remaining bytes in the field rather than read through them. And here, in the skipping (and really in the field length) is where I discovered that Java uses signed bytes.</p>

<p>I did some googling and found quite a bit of useful information. Most useful, of course, was the instruction to do a bitwise <code>&amp;</code> to <code>0xff</code> to get the unsigned int value. This was necessary for me to get a length that could be used in the calculation for the number of bytes to skip.</p>

<p>I now know that at 128, we start counting backwards from -128. What I want to know is how the bitwise operation works here--more specifically, how I arrive at the binary representation for a negative number.</p>

<p>If I understand the bitwise <code>&amp;</code> properly, your result is equal to a number where only the common bits of your two numbers are set. So assuming <code>byte b = -128</code>, we would have:</p>

<pre><code>b &amp; 0xff // 128

1000 0000-128
1111 1111 255
---------
1000 0000 128
</code></pre>

<p>So how would I arrive at 1000 0000 for -128? How would I get the binary representation of something less obvious like -72 or -64?</p>
","<p>In order to obtain the binary representation of a negative number you calculate two's complement:</p>

<ul>
<li>Get the binary representation of the positive number</li>
<li>Invert all the bits</li>
<li>Add one</li>
</ul>

<p>Let's do -72 as an example:</p>

<pre><code>0100 1000    72
1011 0111    All bits inverted
1011 1000    Add one
</code></pre>

<p>So the binary (8-bit) representation of -72 is <code>10111000</code>.</p>

<p>What is actually happening to you is the following: You file has a byte with value <code>10111000</code>. When interpreted as an unsigned byte (which is probably what you want), this is 88.</p>

<p>In Java, when this byte is used as an int (for example because <code>read()</code> returns an int, or because of implicit promotion), it will be interpreted as a signed byte, and sign-extended to <code>11111111 11111111 11111111 10111000</code>. This is an integer with value -72.</p>

<p>By ANDing with <code>0xff</code> you retain only the lowest 8 bits, so your integer is now <code>00000000 00000000 00000000 10111000</code>, which is 88.</p>
","3845922"
"Count bits used in int","9898","","<p>If you have the binary number 10110 how can I get it to return 5? e.g a number that tells how many bits are used? There are some likewise examples listed below:</p>

<ul>
<li>101 should return 3</li>
<li>000000011 should return 2</li>
<li>11100 should return 5</li>
<li>101010101 should return 9</li>
</ul>

<p>How can this be obtained the easiest way in Java? I have come up with the following method but can i be done faster:</p>

<pre><code>public static int getBitLength(int value)
{
    if (value == 0)
    {
        return 0;
    }
    int l = 1;
    if (value &gt;&gt;&gt; 16 &gt; 0) { value &gt;&gt;= 16; l += 16; }
    if (value &gt;&gt;&gt; 8 &gt; 0) { value &gt;&gt;= 8; l += 8; }
    if (value &gt;&gt;&gt; 4 &gt; 0) { value &gt;&gt;= 4; l += 4; }
    if (value &gt;&gt;&gt; 2 &gt; 0) { value &gt;&gt;= 2; l += 2; }
    if (value &gt;&gt;&gt; 1 &gt; 0) { value &gt;&gt;= 1; l += 1; }
    return l;
}
</code></pre>
","<p>Easiest?</p>

<pre><code>32 - Integer.numberOfLeadingZeros(value)
</code></pre>

<p>If you are looking for algorithms, the implementors of the Java API agree with your divide-and-conquer bitshifting approach:</p>

<pre><code>public static int numberOfLeadingZeros(int i) {
    if (i == 0)
        return 32;
    int n = 1;
    if (i &gt;&gt;&gt; 16 == 0) { n += 16; i &lt;&lt;= 16; }
    if (i &gt;&gt;&gt; 24 == 0) { n +=  8; i &lt;&lt;=  8; }
    if (i &gt;&gt;&gt; 28 == 0) { n +=  4; i &lt;&lt;=  4; }
    if (i &gt;&gt;&gt; 30 == 0) { n +=  2; i &lt;&lt;=  2; }
    n -= i &gt;&gt;&gt; 31;
    return n;
}
</code></pre>

<p><strong>Edit</strong>: As a reminder to those who trust in the accuracy of floating point calculations, run the following test harness:</p>

<pre><code>public static void main(String[] args) {
    for (int i = 0; i &lt; 64; i++) {
        long x = 1L &lt;&lt; i;
        check(x);
        check(x-1);
    }
}

static void check(long x) {
    int correct = 64 - Long.numberOfLeadingZeros(x);
    int floated = (int) (1 + Math.floor(Math.log(x) / Math.log(2)));
    if (floated != correct) {
        System.out.println(Long.toString(x, 16) + "" "" + correct + "" "" + floated);
    }
}
</code></pre>

<p>The first detected deviation is:</p>

<pre><code>ffffffffffff 48 49
</code></pre>
","2935833"
"How to convert base64 string to binary array using php","9880","","<p>I have base 64 encoded string that looks something like this.</p>

<pre><code>cuVrcYvlqYze3OZ8Y5tSqQY205mcquu0GsHkgXe4bPg=
</code></pre>

<p>I have tried base64_decode and output is.</p>

<pre><code>råkq‹å©ŒÞÜæ|c›R©6Ó™œªë´Áäw¸lø
</code></pre>

<p>I think I may be doing something wrong. I appreciate any help to convert base64 string to binary array.</p>

<p>Thanks </p>
","<p>like this</p>

<pre><code>$a = base64_decode(""cuVrcYvlqYze3OZ8Y5tSqQY205mcquu0GsHkgXe4bPg="");
$b = array();
foreach(str_split($a) as $c)
    $b[] = sprintf(""%08b"", ord($c));
print_r($b);
</code></pre>
","3745489"
"Converting from int to binary string to int using 2's complement","9862","","<p>There is a binary string <code>10001110</code> which I know is using 2's complement. I know it will be 8 bits.</p>

<p>It is given to me in the form of an <code>unsigned int</code> which equals 142.</p>

<p>I then need to convert this back to <code>10001110</code></p>

<p>then invert all the bits and add one resulting in it equaling <code>01110010</code></p>

<p>and then convert this to a <code>signed int</code> equaling -114.</p>

<p>How can I do this? I'm relatively new to C and have spent ages trying to figure it out!</p>

<p>Essentially I want to write a function that takes the <code>unsigned int</code> 142 and returns the <code>signed int</code> -114</p>
","<p>Here's the solution I finally came up with.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int getBit(int no, int bit) // get bit at certain position
{
    bit--;
    return (no &amp; (1 &lt;&lt; bit)) &gt;&gt; bit;
}

void complementNBits(int *no, int count) // invert certain number of bits
{
    int i;
    for(i=0; i&lt;count; i++)
    {
        *no ^= 1 &lt;&lt; i;
    };
}

int main() 
{
    unsigned int unsignedNo=142;

    int negative = 0;   
    signed int signedNo=0;

    // check if MSB is set to determine if negative

    if (getBit(unsignedNo, 8)) // if MSB is set
    {
        negative = 1;
        // invert these 8 bits and add 1. the rest of the MSBs will already be 0
        complementNBits(&amp;unsignedNo, 8);
        unsignedNo++;
    }

    signedNo = unsignedNo;
    if (negative)
    {
        signedNo = signedNo * -1;
    }

    printf(""THE SIGNED INTEGER: %i\n"", signedNo);

}
</code></pre>

<p>Thanks for the help everyone!</p>
","13725947"
"how to check in c# if a input string is a binary/hexa. number?","9808","","<p>how can i check in c# if a input string from a input field is a correct binary (or hexa) number?</p>
","<pre><code>using System.Globalization;
bool valid = int.TryParse(inputString, NumberStyles.HexNumber, CultureInfo.InvariantCulture, out result);
</code></pre>

<p>works for hex numbers without prefix. If you don't know wich number type to expect, you can use</p>

<pre><code>bool isHex = inputString.Length &gt; 2 &amp;&amp;
    inputString.Substring(0, 2).ToLowerInvariant() == ""0x"" &amp;&amp;
    int.TryParse(inputString.Substring(2), NumberStyles.HexNumber, CultureInfo.InvariantCulture, out result);
</code></pre>

<p>to check and parse the string at the same time. For binary I'd use</p>

<pre><code>Regex.IsMatch(inputString, ""^[01]+$"");
</code></pre>

<p>You should use <code>inputString = inputString.Trim()</code> to make the application more tolerant regarding ""non-standard input"".</p>
","5126877"
"Writing to .bin binary file","9777","","<p>I am trying to write integer numbers to binary file, but it keeps giving weird characters in the binary file. For example, I try to write 2000, but in the file i will get something strange. How do I fix it? Couldn't find the solution anywhere.</p>

<p>I use the following code:</p>

<pre><code> //create the file
        FileStream fs = new FileStream(""iram.bin"", FileMode.Create);
        // Create the writer for data.
        BinaryWriter w = new BinaryWriter(fs);

w.Write((int) 2000);

w.Close();
fs.Close();
</code></pre>
","<p>I think the problem is that you are not reading the data back properly.</p>

<p>You will need to read the data back using a BinaryReader like so...</p>

<pre><code>    using (FileStream fs2 = new FileStream(""iram.bin"", FileMode.Open))
    {
        using(BinaryReader r = new BinaryReader(fs2))
        {
            var integerValue = r.ReadInt32();
        }
    }
</code></pre>

<p>Unless of course you actually want to write text to the file in which case you probably don't want a BinaryWriter to write the data out.</p>

<p>If you actually want to write out text data you could do so like this...  (Be sure to set your encoding to what you need)</p>

<pre><code>    using (var tw = new StreamWriter(""iram.txt"", true, Encoding.ASCII))
    {
        tw.WriteLine(2000);
    }
</code></pre>

<p>Edit: As Jesse mentioned you normally want to wrap disposable objects in using blocks.</p>
","16552885"
"Binary file email attachment problem","9761","","<p>Using Python 3.1.2 I am having a problem sending binary attachment files (jpeg, pdf, etc.) - MIMEText attachments work fine.  The code in question is as follows...</p>

<pre><code>for file in self.attachments:
   part = MIMEBase('application', ""octet-stream"")
   part.set_payload(open(file,""rb"").read())
   encoders.encode_base64(part)
   part.add_header('Content-Disposition', 'attachment; filename=""%s""' % file)
   msg.attach(part)   # msg is an instance of MIMEMultipart()

server = smtplib.SMTP(host, port)
server.login(username, password)
server.sendmail(from_addr, all_recipients, msg.as_string())
</code></pre>

<p>However, way down in the calling-stack (see traceback below), it looks as though msg.as_string() has received an attachment which creates a payload of 'bytes' type instead of string.</p>

<p>Has anyone any idea what might be causing the problem?  Any help would be appreciated.</p>

<p>Alan</p>

<hr>

<pre><code>builtins.TypeError: string payload expected: &lt;class 'bytes'&gt;
File ""c:\Dev\CommonPY\Scripts\email_send.py"", line 147, in send
  server.sendmail(self.from_addr, all_recipients, msg.as_string())
File ""c:\Program Files\Python31\Lib\email\message.py"", line 136, in as_string
  g.flatten(self, unixfrom=unixfrom)
File ""c:\Program Files\Python31\Lib\email\generator.py"", line 76, in flatten
  self._write(msg)
File ""c:\Program Files\Python31\Lib\email\generator.py"", line 101, in _write
  self._dispatch(msg)
File ""c:\Program Files\Python31\Lib\email\generator.py"", line 127, in _dispatch
  meth(msg)
File ""c:\Program Files\Python31\Lib\email\generator.py"", line 181, in _handle_multipart
  g.flatten(part, unixfrom=False)
File ""c:\Program Files\Python31\Lib\email\generator.py"", line 76, in flatten
  self._write(msg)
File ""c:\Program Files\Python31\Lib\email\generator.py"", line 101, in _write
  self._dispatch(msg)
File ""c:\Program Files\Python31\Lib\email\generator.py"", line 127, in _dispatch
  meth(msg)
File ""c:\Program Files\Python31\Lib\email\generator.py"", line 155, in _handle_text
  raise TypeError('string payload expected: %s' % type(payload))
</code></pre>
","<p>Ok - after much frustration and web-searching, I have found that the problem is a known bug that applies to Python 3.x, encoders.py, function encode_base64, which should read as follows...</p>

<pre><code>def encode_base64(msg):
    """"""Encode the message's payload in Base64.

    Also, add an appropriate Content-Transfer-Encoding header.
    """"""
    orig = msg.get_payload()
    encdata = _bencode(orig)

    # new line inserted to ensure all bytes characters are converted to ASCII
    encdata = str(encdata, ""ASCII"")

    msg.set_payload(encdata)
    msg['Content-Transfer-Encoding'] = 'base64'
</code></pre>

<p>The bug has been raised as issue #4768, and was escalated to critical status 
on 2010-05-10.  Hopefully it will be fixed in the next version (3.1.3?)</p>

<p>Regards,  Alan</p>
","2824231"
"C#, read structures from binary file","9750","","<p>I want to read structures from binary.
In C++ I would do it like this:</p>

<pre><code>stream.read((char*)&amp;someStruct, sizeof(someStruct));
</code></pre>

<p>Is there a similar way in C#? The BinaryReader only works for built-in types. In .NET 4 there is a MemoryMappedViewAccessor. It provides methods like <code>Read&lt;T&gt;</code> which seems to be what I want, except that I manually have to keep track of where in the file I want to read.
Is there a better way?</p>
","<p>It's possible to do something similar in C#, but then you would have to apply a lot of attributes to a structure so that you control exactly how it's laid out in memory. By default the JIT compiler controls how structure members are laid out in memory, which usually means that they are rearranged and padded for the most efficient layout considering speed and memory usage.</p>

<p>The simplest way is usually to use the BinaryReader to read the separate members of the structure in the file, and put the values in properties in a class, i.e. manually deserialise the data into a class instance.</p>

<p>Normally it's reading the file that is the bottle neck in this operation, so the small overhead of reading the separate members doesn't affect the performance noticeably.</p>
","4159242"
"binary vs text protocols","9745","","<p>I am wondering what the differences are between binary and text based protocols.
I read that binary protocols are more compacts/faster to process.
How does that work out? Since you have to send the same amount of data? No?</p>

<p>E.g how would the string ""hello"" differ in size in binary format?</p>

<p>thanks</p>
","<p>If all you are doing is transmitting text, then yes, the difference between the two isn't very significant. But consider trying to transmit things like:</p>

<ul>
<li>Numbers - do you use a string representation of a number, or the binary? Especially for large numbers, the binary will be more compact.</li>
<li>Data Structures - How do you denote the beginning and ending of a field in a text protocol? Sometimes a binary protocol with fixed length fields is more compact.</li>
</ul>
","2364614"
"Convert binary string to bigint in MySQL?","9738","","<p>I am attempting to hash a string to a 64-bit value (bigint) in MySQL. I am aware of the MD5() function, which returns a 128-bit hash as a binary string. I'd be happy to just take the bottom or top 64 bits of this result. However, I cannot figure out how to get from a binary string type to a numeric type of any sort. Any pointers?</p>
","<p>Use the <code>CONV()</code> function to convert the MD5 hash from base 16 to base 10 and <code>CAST</code> to convert it to a number:</p>

<pre><code>select cast(conv(substring(md5(id), 1, 16), 16, 10) as unsigned integer) from SomeTable;
</code></pre>
","1259610"
"Boost Binary Serialization Problem","9716","","<p>I have a problem using boost serialization using binary archives. It works when using a file stream but I want to store it in my local variable and ultimately save/load it to/from berkeley db. 
When executing the program I get a <em>boost::archive::archive_exception</em>: 'stream error' when instantiating the <em>binary_iarchive</em>.</p>

<pre><code>#include &lt;sys/time.h&gt;
#include &lt;string&gt;
#include &lt;boost/serialization/serialization.hpp&gt;
#include &lt;boost/archive/binary_oarchive.hpp&gt;
#include &lt;boost/archive/binary_iarchive.hpp&gt;
#include &lt;boost/archive/text_oarchive.hpp&gt;
#include &lt;boost/archive/text_iarchive.hpp&gt;
#include &lt;fstream&gt;
#include &lt;sstream&gt;

namespace boost {
namespace serialization {

template&lt;class Archive&gt;
void serialize(Archive &amp; ar, timeval &amp; t, const unsigned int version)
{
    ar &amp; t.tv_sec;
    ar &amp; t.tv_usec;
}

}//namespace serialization
}//namespace boost


int main(int, char**)
{
    timeval t1;
    gettimeofday(&amp;t1, NULL);
    char buf[256];

    std::stringstream os(std::ios_base::binary| std::ios_base::out| std::ios_base::in);
    {
        boost::archive::binary_oarchive oa(os, boost::archive::no_header);
        oa &lt;&lt; t1;
    }

    memcpy(buf, os.str().data(), os.str().length());
    if(memcmp(buf, os.str().data(), os.str().length()) != 0)
        printf(""memcpy error\n"");

    timeval t2;
    {
        std::stringstream is(buf, std::ios_base::binary| std::ios_base::out| std::ios_base::in);

        boost::archive::binary_iarchive ia(is, boost::archive::no_header);
        ia &gt;&gt; t2;
    }

    printf(""Old(%d.%d) vs New(%d.%d)\n"", t1.tv_sec, t1.tv_usec, t2.tv_sec, t2.tv_usec);

    return 0;
}
</code></pre>

<p>It works when initializing <em>is</em> with <em>os.str()</em>, so I guess my way of copying the data to my buffer or to <em>is</em> is wrong.</p>
","<p>Well, for one thing .data() doesn't have a terminal \0.  It's not a c-string.  I didn't even realize stringstream had a char* constructor (who in their right mind uses them anymore?) but apparently it does and I'd bet it expects \0.</p>

<p>Why are you trying to do it that way anyway?  You're much better off working in C++ strings.  Initialize is with os.str().</p>

<p>Edit: binary data contains lots of \0 characters and the std::string(char*) constructor stops at the first one.  Your deserialization routine will then inevitably try to read past the end of the stream (because it isn't complete).  Use the iterator constructor for std::string when you pass buf into the stringstream.</p>

<pre><code>std::stringstream is(std::string(buf, buf+os.str().length()), flags);
</code></pre>
","3024441"
"What’s the best way to distribute a binary application for Linux?","9691","","<p>I just finished porting an application from Windows into Linux.<br>
I have to create an installer of the application.<br>
The application is <strong>not</strong> open source => I should distribute the application's binaries (executable file, couple .so files, help files and images).</p>

<p>I found several methods to do it:<br>
- <a href=""https://stackoverflow.com/questions/1279423/distributing-binary-applications-across-linux-distros"">RPM and DEB packages</a>;<br>
- <a href=""https://stackoverflow.com/questions/955460/how-do-linux-binary-installers-bin-sh-work"">installer in .sh files</a>;<br>
- <a href=""http://autopackage.org/"" rel=""nofollow noreferrer"">Autopackage</a>.</p>

<p>I don't like first method (RPM and DEB packages) because I don't want to mantain different packages for different Linux distros.  </p>

<p>What is the <strong>best way</strong> to distribute a binary application for Linux?</p>
","<p>Having been through this a couple of times with commercial products, I think the very best answer is to use the native installer for each supported platform.  Anything else produces an unpleasant experience for the end-user, and in practice you have to test on every platform you want to support anyway, so it's not really a significant burden to maintain packages for each.  The idea that you can create a binary that can ""just work"" on every platform out there, including some you've never even heard of, just really doesn't work all that well.</p>

<p>My recommendation is that you pick a platform or two to support initially (Red Hat and Ubuntu would be my suggestions) and then let user demand drive the creation of additional installation packages.  Perhaps make it known that you're willing to support additional platforms, for a modest fee that covers your time and effort in packaging and testing on that platform.  If a platform proves to be very different, you may need to charge more for ongoing support.</p>

<p>Oh, and I cannot overemphasize the value of virtual machines for scenarios like this.  You need to build VMs for each platform you support, and perhaps multiple VMs per platform to make it easy to test different configurations.</p>
","1527092"
"converting binary to utf-8 in python","9688","","<p>I have a binary like this:
    <code>1101100110000110110110011000001011011000101001111101100010101000</code></p>

<p>and  I want to convert it to utf-8.
how can I do this in python?</p>
","<p>Cleaner version:</p>

<pre><code>&gt;&gt;&gt; test_string = '1101100110000110110110011000001011011000101001111101100010101000'
&gt;&gt;&gt; print ('%x' % int(test_string, 2)).decode('hex').decode('utf-8')
نقاب
</code></pre>

<p>Inverse (from @Robᵩ's comment):</p>

<pre><code>&gt;&gt;&gt; '{:b}'.format(int(u'نقاب'.encode('utf-8').encode('hex'), 16))
1: '1101100110000110110110011000001011011000101001111101100010101000'
</code></pre>
","19256326"
"Write to, and read binary data from XML file in .Net 2.0","9678","","<p>I've ready many posts (such as <a href=""https://stackoverflow.com/a/3400927/725913"">this</a> one) on SO now which explain how to write binary data to an XML using the XMLWriter.WriteBase64 method. However, I've yet to see one which explains how to then read the base64'd data. Is there another built in method? I'm also having a hard time finding solid documentation on the subject. </p>

<p><strong>Here is the XML file that I'm using:</strong></p>

<pre><code>&lt;?xml version=""1.0""?&gt;
&lt;pstartdata&gt;
  &lt;pdata&gt;some data here&lt;/pdata&gt;
  emRyWVZMdFlRR0FFQUNoYUwzK2dRUGlBS1ZDTXdIREF ..... and much, much more.
&lt;/pstartdata&gt;
</code></pre>

<p><strong>The C# code which creates that file (.Net 4.0):</strong></p>

<pre><code>FileStream fs = new FileStream(Path.GetTempPath() + ""file.xml"", FileMode.Create);

            System.Xml.XmlTextWriter w = new System.Xml.XmlTextWriter(fs, null);
            w.Formatting = System.Xml.Formatting.None;

            w.WriteStartDocument();
            w.WriteStartElement(""pstartdata"");
            #region Main Data
            w.WriteElementString(""pdata"", ""some data here"");

            // Write the binary data
            w.WriteBase64(fileData[1], 0, fileData[1].Length);
            #endregion (End) Main Data (End)

            w.WriteEndDocument();
            w.Flush();
            fs.Close();
</code></pre>

<p><strong>Now, for the real challenge...</strong>
Alright, so as you all can see the above was written in .Net 4.0. Unfortunately, the XML file needs to be read by an application using .Net 2.0. Reading in the binary (base 64) data has proven to be quite the challenge.</p>

<h2>Code to read in XML data (.Net 2.0):</h2>

<pre><code>System.Xml.XmlDocument xDoc = new System.Xml.XmlDocument();

            xDoc.LoadXml(xml_data);

            foreach (System.Xml.XmlNode node in xDoc.SelectNodes(""pstartdata""))
            {
                foreach (System.Xml.XmlNode child in node.ChildNodes)
                {
                    MessageBox.Show(child.InnerXml);
                }
            }
</code></pre>

<p><strong>What would I need to add in order to read in the base 64'd data (shown above)?</strong></p>
","<p>You seem to write some bad XML - use the following to write the data:</p>

<pre><code>        w.WriteStartDocument();
        w.WriteStartElement(""pstartdata"");
        #region Main Data
        w.WriteElementString(""pdata"", ""some data here"");

        // Write the binary data
        w.WriteStartElement(""bindata"");
        w.WriteBase64(fileData[1], 0, fileData[1].Length);
        w.WriteEndElement();
        #endregion (End) Main Data (End)

        w.WriteEndDocument();
        w.Flush();
        fs.Close();
</code></pre>

<p>For reading you will have to use <a href=""http://msdn.microsoft.com/en-us/library/system.xml.xmlreader.readcontentasbase64.aspx"" rel=""nofollow""><code>XmlReader.ReadContentAsBase64</code></a>.</p>

<p>As you have asked for other methods to write and read binary data - there are <a href=""http://msdn.microsoft.com/en-us/library/system.xml.xmltextwriter.writebinhex.aspx"" rel=""nofollow""><code>XmlTextWriter.WriteBinHex</code></a> and <a href=""http://msdn.microsoft.com/en-us/library/system.xml.xmlreader.readcontentasbinhex.aspx"" rel=""nofollow""><code>XmlReader.ReadContentAsBinHex</code></a>. BEWARE that these produce longer data than their Base64 pendants...</p>
","9153441"
"Convert binary string representation of a byte to actual binary value in Python","9660","","<p>I have a binary string representation of a byte, such as</p>

<pre><code>01010101
</code></pre>

<p>How can I convert it to a real binary value and write it to a binary file?</p>
","<p>Use <a href=""http://docs.python.org/library/functions.html#int"" rel=""nofollow"">the <code>int</code> function</a> with a <code>base</code> of <code>2</code> to read a binary value as an integer.</p>

<pre><code>n = int('01010101', 2)
</code></pre>

<p>Python 2 uses strings to handle binary data, so you would use <a href=""http://docs.python.org/2/library/functions.html#chr"" rel=""nofollow"">the <code>chr()</code> function</a> to convert the integer to a one-byte string.</p>

<pre><code>data = chr(n)
</code></pre>

<p>Python 3 handles binary and text differently, so you need to use <a href=""http://docs.python.org/3/library/stdtypes.html#bytes"" rel=""nofollow"">the <code>bytes</code> type</a> instead. This doesn't have a direct equivalent to the <code>chr()</code> function, but the <code>bytes</code> constructor can take a list of byte values. We put <code>n</code> in a one element array and convert that to a <code>bytes</code> object.</p>

<pre><code>data = bytes([n])
</code></pre>

<p>Once you have your binary string, you can open a file in binary mode and write the data to it like this:</p>

<pre><code>open('out.bin', 'wb') as f:
    f.write(data)
</code></pre>
","7214014"
"Convert a RGB colour value to Decimal","9658","","<p>How do I convert a RGB colour value to just plain decimal?</p>

<p>So I have: RGB(255,255,255) is white<br>
Its decimal equivalent is: 16777215</p>

<p>I have tried thinking it might just be:</p>

<pre><code>var dec = r*g*b; // but this doesn't work
</code></pre>

<p>Although that doesn't work.</p>

<p>Anyone know of the algorithm/equation to convert from RGB (or rgba) to decimal?</p>
","<p>RGB integers are typically treated as three distinct bytes where the left-most (highest-order) byte is red, the middle byte is green and the right-most (lowest-order) byte is blue. You can retrieve the values of these individual bytes like this:</p>

<pre><code>var c = 0xff03c0; // 16712640
var components = {
    r: (c &amp; 0xff0000) &gt;&gt; 16, 
    g: (c &amp; 0x00ff00) &gt;&gt; 8, 
    b: (c &amp; 0x0000ff)
};
</code></pre>

<p>You can re-create a color from its components by shifting the bytes back in:</p>

<pre><code>c = (components.r &lt;&lt; 16) + (components.g &lt;&lt; 8) + (components.b);
</code></pre>

<p>In your case, simply substitute <code>components.r</code> (etc) with your actual variables.</p>
","8469042"
"PHP-powered GUI Applications for Windows","9638","","<p>I know that PHP is an interpreted language and for web-based things, isn't designed for running GUI applications on actual OSs, but is there a way?</p>

<p>Basically, is there a framework / system that allows me to create ""native"" (basically, binary, .exe, looks like a Win32 app with the native controls and all) windows, GUI-based applications?</p>

<p>So I could code a PHP app with such framework, and (somehow) compile it into an .exe, and distribute it as a normal windows application. Possible?</p>

<p>I could use VS/.NET , C# and all, but using PHP would allow me to reuse an internal framework for many extra functions, shortening the development cycle a lot.</p>

<p>So, is there such a way to do it?</p>
","<p>The best solution if you have knowledge of .Net would be to use <a href=""http://phalanger.codeplex.com"" rel=""nofollow noreferrer"">Phalanger</a> (<a href=""http://www.php-compiler.net/"" rel=""nofollow noreferrer"">Blog</a>) which basically compile php code to the .Net intermediate language and allow you to access all standard .Net libraries (including WPF and WinForms so you could create GUIs)</p>

<p><img src=""https://i.stack.imgur.com/SC6Bs.gif"" alt=""enter image description here""></p>
","6870356"
"Append bytes to string?","9615","","<p>I have a file I've opened in Python which I'm writing to another output file. I need it to be a multiple of 16 in filesize, so this is what I've devised:</p>

<pre><code> with open(input_file, 'rb') as infile:
     with open(output_file, 'wb') as outfile:
         while True:
             input_chunk = infile.read(64)

             if len(input_chunk) == 0:
                 break
             elif len(input_chunk) % 16 &gt; 0:
                 input_chunk.extend([0 for i in range(len(input_chunk) % 16)])

             output_file.write(input_chunk)
</code></pre>

<p>Unfortunately, it fails to append the zeroes with:</p>

<pre><code>AttributeError: 'str' object has no attribute 'extend'
</code></pre>

<p>First, why do I have a string here, rather than an array of bytes? I'm reading the binary file in binary mode. </p>

<p>Second, if I'm dealing with a string, how do I write a number of bytes with the value <code>0</code> to the end of that string?</p>
","<blockquote>
  <p>First, why do I have a string here, rather than an array of bytes?</p>
</blockquote>

<p>Because that's what <code>file.read</code> returns ...</p>

<blockquote>
  <p>Second, if I'm dealing with a string, how do I write a number of bytes with the value 0 to the end of that string?</p>
</blockquote>

<p>You can't write it onto that string because strings are immutable.  You can however write it onto a different string and create new strings by concatenation:</p>

<pre><code>&gt;&gt;&gt; import struct
&gt;&gt;&gt; input_chunk = 'foo bar baz'
&gt;&gt;&gt; input_chunk + struct.pack('16B',*([0]*16))
'foo bar baz\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
&gt;&gt;&gt; 
</code></pre>

<p>Note that if you know that you have 64 bytes and you want a string that is 80 bytes padded with nulls, <code>struct.pack</code> <strong>will pad it automatically with nulls</strong>:</p>

<pre><code>struct.pack('80s',string_of_64_bytes)
</code></pre>

<blockquote>
  <p>For the 's' format character, the count is interpreted as the size of the string, not a repeat count like for the other format characters; for example, '10s' means a single 10-byte string, while '10c' means 10 characters. If a count is not given, it defaults to 1. For packing, the string is truncated or padded with null bytes as appropriate to make it fit. For unpacking, the resulting string always has exactly the specified number of bytes. As a special case, '0s' means a single, empty string (while '0c' means 0 characters).</p>
</blockquote>
","14949788"
"Working with signed numbers other than 10-bit in Excel","9615","","<p>Is there some way that I am missing within Excel to set the true number of bits in a binary number, or are we stuck with the 10-bit DEC2BIN and BIN2DEC?  10-bit is a strange choice.</p>

<p>I would, ideally, want to be able to choose between a true signed 8-bit or a true signed 16-bit world, and to be able to perform operations with those numbers.  As it stands now, I can't set 11111111 to be -1 instead of 255.  Has anyone else dealt with this?</p>

<p>Thanks in advance.</p>
","<p>Excel imposes a 10-character limit on binary, octal, and hexadecimal numbers.  For binary, this coincides with a 10-bit limit.  This limit makes little sense, and I assume it was an arbitrary decision that each Excel version keeps for backward compatibility.</p>

<p>For 8-bit two's complement:</p>

<pre><code>=LEFT(A1)*-128 + BIN2DEC(MID(A1,2,7))
</code></pre>

<p><img src=""https://i.stack.imgur.com/ZHqIn.png"" alt=""enter image description here""></p>

<p>For 16-bit binary, convert each half of the binary number to hex and concatenate.  You can feed that result to <code>HEX2DEC</code>.  You can then handle two's complement like we did for 8-bit:</p>

<pre><code>=LEFT(A1)*-32768 + HEX2DEC(BIN2HEX(MID(A1,2,7),2) &amp; BIN2HEX(MID(A1,9,8),2))
</code></pre>

<p><img src=""https://i.stack.imgur.com/7vMzP.png"" alt=""enter image description here""></p>
","27871243"
"Determine if an executable (or library) is 32 or 64 bit","9613","","<p>Is it possible to get information about any binary on OS X to determine if it's a 32 bit or 64 bit binary?</p>

<p>I played with the 'otool' command but can't find this kind of information.</p>
","<p>Use the 'file' command instead of 'otool'. It will list all the architectures in the binary. On Intel Macs i386 is 32 bit and x86_64 is 64 bit. </p>
","1941898"
"Adding negative and positive binary?","9576","","<p>X = 01001001 and Y = 10101010<br/>
<br/>
If I want to add them together how do I do that? They are ""Two's Complement""...
I have tried a lots of things but I am not quite sure I am getting the right answer since there seems to be different type of rules.<br/>
<br/>
Just want to make sure it is correct:<br/>
 1. Add them as they are do not convert the negative<br/>
 2. Convert the negative number you get and that's the sum.<br/>
<br/>
f.eks<br/>
01001001+10101010 = 11110011 => 00001100 => 1101 => -13<br/>
<br/>
Or? <br/>
 1. Convert the negative<br/>
 2. Add them together and convert the negative<br/>
<br/>
f.eks<br/>
01001001+10101010 => 01001001 + 01010110 => 10011111 => 01100001 => -97 <br/>
<br/>
<br/>
So basically what I want to do is to take: X-Y, and X+Y <br/>
Can someone tell me how to do that?<br/>
<br/>
Some resource sites:
<a href=""http://www.cs.grinnell.edu/~rebelsky/Courses/CS152/97F/Readings/student-binary.html"" rel=""nofollow noreferrer"">student-binary</a>
<a href=""http://celtickane.com/computers/cs_binary.php"" rel=""nofollow noreferrer"">celtickane</a>
<a href=""http://www.swarthmore.edu/NatSci/echeeve1/Ref/BinaryMath/BinaryMath.html"" rel=""nofollow noreferrer"">swarthmore</a></p>
","<p>The beauty of two's complement is that at the binary level it's a matter of interpretation rather than algorithm - the hardware for adding two signed numbers is the same as for unsigned numbers (ignoring flag bits). </p>

<p>Your first example - ""just add them"" - is exactly the right answer. Your example numbers </p>

<ul>
<li>01001001 = 73</li>
<li>10101010 = -86</li>
</ul>

<p>So, the correct answer is indeed -13.</p>

<p>Subtracting is just the same, in that no special processing is required for two's complement numbers: you ""just subtract them"".</p>

<p>Note that where things get interesting is the handling of overflow/underflow bits. You can't represent the result of 73 - (-86) as an 8-bit two's complement number...</p>
","346803"
"fast hex to binary conversion method in .net","9560","","<p>I am developing an application in C#.net. I have to do a quick hex to binary conversion. What I have done is... </p>

<pre><code>rtpPTypeNum = string.Join(string.Empty, udp.Payload.ToHexadecimalString().Substring(2, 2).Select(C =&gt; Convert.ToString(Convert.ToInt32(C.ToString(), 16), 2).PadLeft(4, '0'))).Substring(1, 7);
</code></pre>

<p>I have checked its performance, but this is not good enough for me.</p>

<p><code>udp.Payload.ToHexadecimalString()</code> returns a string of hex digits.</p>

<p>In this conversion I have to do around 9000 iterations.</p>

<p>Can you give me a better method?</p>
","<p>The top result on Google gives me:</p>

<pre><code>return Convert.ToString(Convert.ToInt32(hexValue, 16), 2);
</code></pre>
","14211263"
"How can I access the sign bit of a number in C++?","9542","","<p>I want to be able to access the sign bit of a number in C++.  My current code looks something like this:</p>

<pre><code>int sign bit = number &gt;&gt; 31;
</code></pre>

<p>That appears to work, giving me <code>0</code> for positive numbers and <code>-1</code> for negative numbers.  However, I don't see how I get <code>-1</code> for negative numbers: if 12 is</p>

<pre><code>0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 1100
</code></pre>

<p>then -12 is</p>

<pre><code>1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 0011
</code></pre>

<p>and shifting it 31 bits would make</p>

<pre><code>0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0001
</code></pre>

<p>which is 1, not -1, so why do I get -1 when I shift it?</p>
","<p>The result of right-shifting a negative number in C++ is implementation-defined. So, no one knows what right-shifting your <code>-12</code> should get on your specific platform. You think it should make the above (<code>1</code>), while I say that it can easily produce all-ones pattern, which is <code>-1</code>. The latter is called sign-extended shifting. In sign-extended shifting the sign bit is copied to the right, but never shifted out of its place.</p>

<p>If all you are interested in is the value of the sign bit, then stop wasting time trying to use bitwise operations, like shifts etc. Just compare your number to 0 and see whether it is negative or not.</p>
","3001670"
"Converting Binary to Decimal in Java","9518","","<p>I'm almost done with implementing a code that allows the user to input a decimal number into binary and then have the binary number reversed and then converted back to decimal.</p>

<p>I solved everything except for the Binary to decimal part. It keeps giving me the same number over and over again no matter what I type. I don't understand why. Basically, why is the last part of my code wrong? I'm having trouble with finding the length of the array/string and then have it multiply by 2^n etc... </p>
","<p>There are two issues in this code.</p>

<p>1) You didn't store the result of decimal-to-binary convertation. You should introduce new String variable to store string with reversed binary value.</p>

<p>2) Your binary-to-decimal algorithm is incorrect. s.charAt(i) returns char value but you need double value to use it in calculation. Math.pow(2, (s.length() - i - 1)) is also incorrect - as I understand it's for non-reversed binary values.</p>

<p>Fixed version of code should looks like:</p>

<pre><code>public static void main(String[] args) {
    int a[] = {0, 1};

    int number;
    int remainder;
    String binary = """";

    Scanner in = new Scanner(System.in);

    System.out.print(""Enter Decimal Number: "");
    number = Integer.parseInt( in.next());

    System.out.print(""Binary Number in Reverse: "");
    do {
        remainder=number%2;
        if(remainder &gt; 0){
            binary += a[1];
            //System.out.print(a[1]);
        }
        else{
            binary += a[0];
            //System.out.print(a[0]);
        }
        number=number / 2;
    } while(number&gt;0);

    System.out.print(binary);

    System.out.print("" \nDecimal number: "");
    //String s = Integer.toString(number);
    double result = 0;
    for (int i = 0; i &lt; binary.length(); i++)
       result = result + Double.parseDouble(binary.substring(i, i + 1)) * Math.pow(2, i);
    System.out.print(result);
}
</code></pre>
","14791714"
"Understanding hexadecimals and bytes in C#","9516","","<p>I seem to lack a fundemental understanding of calculating and using hex and byte values in C# (or programming in general).</p>

<p>I'd like to know how to calculate hex values and bytes (0x--) from sources such as strings and RGB colors (like how do I figure out what the 0x code is for R255 G0 B0 ?)</p>

<p>Why do we use things like FF, is it to compensate for the base 10 system to get a number like 10? </p>
","<p>Hexadecimal is base 16, so instead of counting from 0 to 9, we count from 0 to F.  And we generally prefix hex constants with <code>0x</code>.  Thus,</p>

<pre class=""lang-none prettyprint-override""><code>Hex      Dec
-------------
0x00  =  0
0x09  =  9
0x0A  =  10
0x0F  =  15
0x10  =  16
0x200 =  512
</code></pre>

<p>A byte is the typical unit of storage for values on a computer, and on most all modern systems, a byte contains 8 bits. Note that <code>bit</code> actually means <code>binary digit</code>, so from this, we gather that a byte has a maximum value of 11111111 binary. That is 0xFF hex, or 255 decimal. Thus, one byte can be represented by a minimum of two hexadecimal characters.  A typical 4-byte <code>int</code> is then 8 hex characters, like <code>0xDEADBEEF</code>.</p>

<p>RGB values are typically packed with 3 byte values, in that order, RGB. Thus,</p>

<pre><code>R=255 G=0 B=0    =&gt;  R=0xFF G=0x00 B=0x00  =&gt;  0xFF0000  or #FF0000 (html)
R=66  G=0 B=248  =&gt;  R=0x42 G=0x00 B=0xF8  =&gt;  0x4200F8  or #4200F8 (html)
</code></pre>

<p>For my hex calculations, I like to use python as my calculator:</p>

<pre class=""lang-none prettyprint-override""><code>&gt;&gt;&gt; a = 0x427FB
&gt;&gt;&gt; b = 700
&gt;&gt;&gt; a + b
273079
&gt;&gt;&gt;
&gt;&gt;&gt; hex(a + b)
'0x42ab7'
&gt;&gt;&gt;
&gt;&gt;&gt; bin(a + b)
'0b1000010101010110111'
&gt;&gt;&gt;
</code></pre>

<p>For the RGB example, I can demonstrate how we could use <a href=""http://en.wikipedia.org/wiki/Logical_shift"" rel=""noreferrer"">bit-shifting</a> to easily calculate those values:</p>

<pre><code>&gt;&gt;&gt; R=66
&gt;&gt;&gt; G=0
&gt;&gt;&gt; B=248
&gt;&gt;&gt;
&gt;&gt;&gt; hex( R&lt;&lt;16 | G&lt;&lt;8 | B )
'0x4200f8'
&gt;&gt;&gt;
</code></pre>
","12081587"
"How to read/write binary 16-bit data in Python 2.x?","9506","","<p>I have to read and write binary data, where each element of data:</p>

<ul>
<li>size = 2 bytes (16 bit) </li>
<li>encoding =    signed 2's complement</li>
<li>endiannes = big    or little (must be
selectable)</li>
</ul>

<p>Is it possible without using any external module? If yes,</p>

<ol>
<li>How to read such data from a binary
file using read() into an array L of
integers?</li>
<li>How to write array of integers L
into a binary file using write()?</li>
</ol>
","<p>I think you are best off using the <a href=""http://docs.python.org/library/array.html"" rel=""noreferrer""><code>array</code></a> module.  It stores data in system byte order by default, but you can use <code>array.byteswap()</code> to convert between byte orders, and you can use <code>sys.byteorder</code> to query the system byte order.  Example:</p>

<pre><code># Create an array of 16-bit signed integers
a = array.array(""h"", range(10))
# Write to file in big endian order
if sys.byteorder == ""little"":
    a.byteswap()
with open(""data"", ""wb"") as f:
    a.tofile(f)
# Read from file again
b = array.array(""h"")
with open(""data"", ""rb"") as f:
    b.fromfile(f, 10)
if sys.byteorder == ""little"":
    b.byteswap()
</code></pre>
","5031191"
"Opening file in another directory in C","9501","","<p>How is this achieved? I want to use</p>

<pre><code>pFile = fopen( file, ""rb"" );
</code></pre>

<p>Where file is a char, string or long containing the literal text containing a local path to a binary file</p>

<pre><code>C:\Documents and Settings\Supernovah\Desktop\Supernovah.bin
</code></pre>

<p>but of course that crashes.</p>

<p>I am also interested in how to recur over the current directory in a portable way. windows.h is a little ugly but if I can't do it in a portable way. So be it.</p>

<p>thanks :)</p>
","<pre><code>char* file=""C:\\Documents and Settings\\Supernovah\\Desktop\\Supernovah.bin"";
FILE* pFile = fopen( file, ""rb"" );
</code></pre>
","1547452"
"Two's complement binary form","9484","","<p>In a TC++ compiler, the binary representation of <strong>5</strong> is <strong>(00000000000000101)</strong>.
I know that negative numbers are stored as 2's complement, thus <strong>-5</strong> in binary is <strong>(111111111111011)</strong>. The most significant bit (sign bit) is 1 which tells that it is a negative number.</p>

<p>So how does the compiler know that it is <strong>-5</strong>?  If we interpret the binary value given above <strong>(111111111111011)</strong> as an unsigned number, it will turn out completely different?</p>

<p>Also, why is the 1's compliment of <strong>5</strong> <strong>-6 (1111111111111010)</strong>?</p>
","<p><strong>The compiler doesn't know</strong>. If you cast <code>-5</code> to <code>unsigned int</code> you'll get <code>32763</code>.</p>
","655275"
"Convert XLS to XLSB Programatically?","9470","","<p>I have a customer that needs to convert XLS files to XLSB. Has anyone done this programatically, (with or without an add-on --- doesn't matter --- just need to be able to automate it)? I'm looking for a way to automate this.</p>

<p>As a side note, the customer is asking about this because they use Sharepoint, and it seems it has a way to analyze XLSB files quicker and easier than XLS??? I'm working to improve my Sharepoint knowledge, but in the meantime, I'm trying to find an answer to this XLSB issue.</p>

<p>Thanks.</p>
","<p>Well, then there is a short format verison:</p>

<pre><code>using Microsoft.Office.Interop.Excel;

// init excel
Application excelApplication = new Application();

// ...

// open book in any format
Workbook workbook = excelApplication.Workbooks.Open(""1.xls"", XlUpdateLinks.xlUpdateLinksNever, true, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing);

// save in XlFileFormat.xlExcel12 format which is XLSB
workbook.SaveAs(""1.xlsb"", XlFileFormat.xlExcel12, Type.Missing, Type.Missing, Type.Missing, Type.Missing, XlSaveAsAccessMode.xlExclusive, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing);

// close workbook
workbook.Close(false, Type.Missing, Type.Missing);

// ...

// shutdown excel
excelApplication.Quit();
</code></pre>

<p>You will need a Excel installation with .NET programming support (disabled by default in installer!) and reference MS Office PIA assembly for Excel from your project:</p>

<p><img src=""https://i.stack.imgur.com/DRdPS.png"" alt=""add Excel PIA reference""></p>

<p>References:
<a href=""http://msdn.microsoft.com/en-us/library/microsoft.office.interop.excel.workbooks.open%28v=Office.11%29.aspx"" rel=""noreferrer"">Workbooks.Open</a>, <a href=""http://msdn.microsoft.com/en-us/library/microsoft.office.tools.excel.workbook.saveas%28v=VS.80%29.aspx"" rel=""noreferrer"">workbook.SaveAs</a>, <a href=""http://msdn.microsoft.com/en-us/library/microsoft.office.interop.excel.xlfileformat.aspx"" rel=""noreferrer"">XlFileFormat.xlExcel12</a></p>
","6496118"
"Inserting NSData into SQLite on the iPhone","9439","","<p>So far I've managed to create this method for inserting into a SQLite database on the iPhone:</p>

<pre><code>- (void) insertToDB :(NSString *)Identifier :(NSString *)Name
{
    sqlite3 *database;

    if(sqlite3_open([databasePath UTF8String], &amp;database) == SQLITE_OK)
    {
        char *sql1 = ""INSERT INTO table VALUES ('"";
        const char *sql2 = [Identifier cStringUsingEncoding:[NSString defaultCStringEncoding]];
        char *sql3 = ""', '"";
        const char *sql4 = [Name cStringUsingEncoding:[NSString defaultCStringEncoding]];
        char *sql5 = ""')"";

        char *sqlStatement[255];
        strcpy(sqlStatement, sql1);
        strcat(sqlStatement, sql2);
        strcat(sqlStatement, sql3);
        strcat(sqlStatement, sql4);
        strcat(sqlStatement, sql5);

        sqlite3_stmt *compiledStatement;

        if(sqlite3_prepare_v2(database, sqlStatement, -1, &amp;compiledStatement, NULL) == SQLITE_OK)
        {
            sqlite3_last_insert_rowid(database);
            sqlite3_reset(compiledStatement);
        }

        sqlite3_finalize(compiledStatment);
    }
    sqlite3_close(database);
}
</code></pre>

<p>Now I'm looking at storing an image in the database. So far I've <a href=""https://stackoverflow.com/questions/643682/reading-and-writing-images-to-an-sqlite-db-for-iphone-use"">found this</a>:</p>

<pre><code>UIImage *cachedImage = [UIImage imageNamed:@""Icon.png""];
NSData *dataForImage = UIImagePNGRepresentation(cachedImage);
</code></pre>

<p>But i'm having trouble trying to insert this NSData into the char array which makes the sqlStatement. Anyone got an idea how to do this?</p>

<p>(I have a field in the database of type blob for this).</p>

<p>Thanks</p>
","<p>I would use <code>sqlite3_stmt</code> instead of a string.  Then, you could use <code>sqlite3_bind_blob</code> to bind the blob to the prepared statement. </p>

<pre><code>sqlite3_stmt *insert_statement;     
char *sql = ""INSERT INTO table (blobcolumn, column2, column3) VALUES (? , ?, ?)"" ;
if(sqlite3_prepare_v2(database, sql, -1, &amp;insert_statement, NULL) != SQLITE_OK)
          {
              //handle error
          } 

sqlite3_bind_blob(insert_statement, 1, [dataForImage bytes], [dataForImage length], NULL);
</code></pre>

<p>But, really, it would be best for performance to store the image on disk and the path in the database.</p>

<p>Another way to do it, one that I use to send image data in XML, is to base 64 encode the data.  I have it here as a category on NSString:</p>

<pre><code>static char base64EncodingTable[64] = {
'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P',
'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f',
'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',
'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '/'
};

@implementation NSString (NSStringCategories)

+ (NSString *) base64StringFromData: (NSData *)data length: (int)length {
    unsigned long ixtext, lentext;
    long ctremaining;
    unsigned char input[3], output[4];
    short i, charsonline = 0, ctcopy;
    const unsigned char *raw;
    NSMutableString *result;

    lentext = [data length]; 
    if (lentext &lt; 1)
        return @"""";
    result = [NSMutableString stringWithCapacity: lentext];
    raw = [data bytes];
    ixtext = 0; 

    while (true) {
        ctremaining = lentext - ixtext;
        if (ctremaining &lt;= 0) 
            break;        
        for (i = 0; i &lt; 3; i++) { 
            unsigned long ix = ixtext + i;
            if (ix &lt; lentext)
                input[i] = raw[ix];
            else
                input[i] = 0;
        }
        output[0] = (input[0] &amp; 0xFC) &gt;&gt; 2;
        output[1] = ((input[0] &amp; 0x03) &lt;&lt; 4) | ((input[1] &amp; 0xF0) &gt;&gt; 4);
        output[2] = ((input[1] &amp; 0x0F) &lt;&lt; 2) | ((input[2] &amp; 0xC0) &gt;&gt; 6);
        output[3] = input[2] &amp; 0x3F;
        ctcopy = 4;
        switch (ctremaining) {
            case 1: 
                ctcopy = 2; 
                break;
            case 2: 
                ctcopy = 3; 
                break;
    }

    for (i = 0; i &lt; ctcopy; i++)
        [result appendString: [NSString stringWithFormat: @""%c"",             base64EncodingTable[output[i]]]];

    for (i = ctcopy; i &lt; 4; i++)
        [result appendString: @""=""];

    ixtext += 3;
    charsonline += 4;

    if ((length &gt; 0) &amp;&amp; (charsonline &gt;= length))
        charsonline = 0;
    }
    return result;
}
</code></pre>
","3320375"
"decimal to binary in java","9412","","<p>I'm having trouble in getting the binary. I do not know what's wrong. The binary number always ends up in gibberish. Also some parts like the <code>new int[31]</code> thing was from HW but I can't get around to make print the actual binary.</p>

<pre><code>public class DectoBinary {
    public static void main(String[]args) {
        Scanner CONSOLE = new Scanner(System.in);
        System.out.print(""Please enter a nonnegative integer: "");
        int value = CONSOLE.nextInt();
        while (value &lt; 0) {
            System.out.print(""number outside range."");
            System.out.print
                (""Please enter a nonnegative interger more than 0: "");
            value = CONSOLE.nextInt();
        }
        int[] intArray = new int[31];
        decimalToBinary(value, intArray);
        System.out.println(value + """" + intArray);
    }
    public static int[] decimalToBinary(int value, int[]intArray) {
        int i = 0;
        while (value != 0) {
            if (value % 2 == 1)
                intArray[i] = 1;

            else
                intArray[i] = 0;

            value /= 2;
            i++;
        }
        return intArray;
    }
}
</code></pre>
","<p>I think the error is on this line:</p>

<pre><code>System.out.println(value + """" + intArray);
</code></pre>

<p>You cannot print an array of integers like this: you should either convert it to string, or write a loop that prints the array digit by digit:</p>

<pre><code>for (int i : inrArray) {
    System.out.print(intArray[i]);
}
System.out.println();
</code></pre>

<p>You do not need to pass in the output array as well: you can create it inside the function.</p>

<pre><code>public static int[] decimalToBinary(int value) {
    int count = 1;
    int tmp = value;
    while (tmp != 0) {
        tmp /= 2;
        count++;
    }
    int[] intArray = new int[count];
    // Do the conversion here...
    return intArray;
}
</code></pre>
","10308808"
"Convert jpeg image to hex format","9395","","<p>I want to convert a jpeg file to hexadecimal format, I found some of the solutions where initially the image is converted into byte array and then to hex format.Is there any method which directly convert jpeg image to hex format in C#.</p>
","<p>using <code>System.Runtime.Remoting.Metadata.W3cXsd2001</code> namespace :)</p>

<pre><code>var str = new SoapHexBinary(File.ReadAllBytes(fName)).ToString();
</code></pre>

<p>or using <code>BitConverter</code></p>

<pre><code>var str2 = BitConverter.ToString(File.ReadAllBytes(fName));
</code></pre>
","18717470"
"Differences between: INT 10H , INT 16H, INT 21H","9384","","<p>Could anyone please explain to me the differences between: INT 10H , INT 16H, INT 21H in assembly language? When should we use any of them and for what? </p>

<p>For example: in this simple code for printing ""Hello, World!"" 
Why did we use int 10h in the fourth line?
Why did we use int 16h in the line before the last?</p>

<pre><code>name ""hi-world""
org 100h     
mov ax, 3     
int 10h      
mov ax, 1003h
mov bx, 0
int 10h
mov ax, 0b800h
mov ds, ax
mov [02h], 'H'

mov [04h], 'e'

mov [06h], 'l'

mov [08h], 'l'

mov [0ah], 'o'

mov [0ch], ','

mov [0eh], 'W'

mov [10h], 'o'

mov [12h], 'r'

mov [14h], 'l'

mov [16h], 'd'

mov [18h], '!'


mov cx, 12  ; number of characters.
mov di, 03h ; start from byte after 'h'

c:  mov [di], 11101100b 
add di, 2 ; skip over next ascii code in vga memory.
loop c

; wait for any key press:
mov ah, 0
int 16h

ret
</code></pre>
","<p>First of all <code>INT</code> means interrupt and has nothing to do with <code>int</code> data type.</p>

<p>Each <code>INT</code> represents a functions family, where usually <code>AH</code> represents the function number.</p>

<p>For example :</p>

<ol>
<li><p>INT 0x10 is used for screen manipulation</p>

<ul>
<li>AH=0x00 -> set video mode</li>
<li>AX=0x1003 -> Set Blinking mode</li>
<li>AH=0x13 -> write string</li>
<li>AH=0x03 -> get cursor position</li>
</ul></li>
<li><p>INT 0x13 is for storage (HDD and FDD)</p>

<ul>
<li>AH=0x42 -> DISK READ</li>
<li>AH=0x43 -> DISK WRITE</li>
</ul></li>
<li>INT 0x16 is for Keyboard control and read:
<ul>
<li>AH=0x00 -> GetKey</li>
<li>AH=0x03 -> Set typematic rate and delay</li>
</ul></li>
</ol>

<p>You can find all these functions here: <a href=""http://www.ctyme.com/intr/int.htm"" rel=""nofollow"">Interrupt Jump Table</a></p>

<p>But these are just BIOS INT, which can be rewritten by OS during startup. For example, Windows uses <code>INT 0x21</code> for communication between user space and kernel space; Linux-based use <code>INT 0x80</code>. See also <a href=""http://docs.cs.up.ac.za/programming/asm/derick_tut/syscalls.html"" rel=""nofollow"">Linux System Call Table</a></p>

<p>In your code:</p>

<ul>
<li>INT 0x10 with AH = 0x00 and AL = 3 (<code>mov ax, 3</code>) means: set video mode to TextMode 80x25 chars and 16 colors.</li>
<li>INT 0x10 with AX = 0x1003 means: TOGGLE INTENSITY/BLINKING BIT to background intensity enabled</li>
</ul>
","30188146"
"Are binary protocols dead?","9376","","<p>It seems like there used to be way more binary protocols because of the very slow internet speeds of the time (dialup). I've been seeing everything being replaced by HTTP and SOAP/REST/XML. </p>

<p>Why is this? </p>

<p>Are binary protocols really dead or are they just less popular? Why would they be dead or less popular? </p>
","<p><strong>You Just Can't Beat the Binary</strong></p>

<p>Binary protocols will always be more space efficient than text protocols.  Even as internet speeds drastically increase, so does the amount and complexity of information we wish to convey.</p>

<p>The text protocols you reference are outstanding in terms of standardization, flexibility and ease of use.  However, there will always be applications where the efficiency of binary transport will outweigh those factors.</p>

<p>A great deal of information is binary in nature and will probably never be replaced by a text protocol. Video streaming comes to mind as a clear example.</p>

<p>Even if you compress a text-based protocol (e.g. with GZip), a general purpose compression algorithm will never be as efficient as a binary protocol designed around the specific data stream.</p>

<p><strong>But Sometimes You Don't Have To</strong></p>

<p>The reason you are seeing more text-based protocols is because transmission speeds and data storage capacity have indeed grown fast compared to the data size for a wide range of applications.  We humans find it much easier to work with text protocols, so we designed our ubiquitous XML protocol around a text representation.  Certainly we could have created XML as a binary protocol, if we really had to save every byte, and built common tools to visualize and work with the data.</p>

<p><strong>Then Again, Sometimes You Really Do</strong></p>

<p>Many developers are used to thinking in terms of multi-GB, multi-core computers.  Even your typical phone these days puts my first IBM PC-XT to shame.  Still, there are platforms such as embedded devices, that have rather strict limitations on processing power and memory.  When dealing with such devices, binary may be a necessity.</p>
","2525215"
"Javascript: Equivalent of PHP's hash_hmac() with RAW BINARY output?","9330","","<p>I am connecting to the Amazon Product Advertising API, and to sign my request I need to base64-encode the <strong>raw binary</strong> output of an HMAC-SHA256 hash.</p>

<p>In <a href=""http://php.net/manual/en/function.hash-hmac.php"">the PHP documentation for hash_hmac</a>, the fourth parameter <code>bool $raw_output</code> controls whether the output is raw binary data (true) or lowercase hexits (false). My program works in PHP by simply setting that parameter to true.</p>

<p>However, I am now trying to port this over to Javascript. I tried using the CryptoJS.HmacSHA256() function, but it seems to be returning the lowercase hexits. How can I convert this to binary?</p>

<p>I have tried the following according to the CryptoJS documentation, but both outputs are identical:</p>

<pre><code>var hash = CryptoJS.HmacSHA256(""hello"", ""key"");
console.log(hash.toString());
console.log(hash.toString(CryptoJS.enc.Base64));
</code></pre>
","<p>This is explained in their <a href=""http://code.google.com/p/crypto-js/#The_Hasher_Output"" rel=""noreferrer"">documentation</a>. Try this:</p>

<pre><code>var hash = CryptoJS.HmacSHA256(""Message"", ""Secret Passphrase"");

var base64 = hash.toString(CryptoJS.enc.Base64);
</code></pre>

<p>You need to include <a href=""http://crypto-js.googlecode.com/svn/tags/3.0.2/build/components/enc-base64-min.js"" rel=""noreferrer"">http://crypto-js.googlecode.com/svn/tags/3.0.2/build/components/enc-base64-min.js</a> for this. If you didn't include this, <code>CryptoJS.enc.Base64</code> will be <code>undefined</code> and fallback to the default.</p>

<p>Working demo: <a href=""http://jsfiddle.net/ak5Qm/"" rel=""noreferrer"">http://jsfiddle.net/ak5Qm/</a></p>
","12099138"
"What is lower and higher bits?","9318","","<p>Can anyone tell me what is lower and higher bits?. How to identify a higher and lower bit?. Below is binary form. How does <code>0110</code> is higher bit in it?.</p>

<pre><code>0110 0111 1100 1010 1100 0111 1001 1011
</code></pre>
","<p>Just like in decimal, higher places are generally written to the left in binary. So if you see '0111', the '0' is the high bit. So this would represent 7 in decimal. The same applies when spaces are used, just like when commas (or dots, depending on your locale) are used to separate groups of digits in decimal.</p>
","19063231"
"Inline BLOB / BINARY data types in SQL / JDBC","9315","","<p>Let's say I want to avoid using bind variables in JDBC and run SQL using ""ad-hoc"" statements, e.g:</p>

<pre><code>connection.createStatement().executeQuery(""SELECT ..."");
</code></pre>

<p>Is there any convention / JDBC escape syntax to inline BLOB data types? I know that <a href=""http://www.h2database.com/html/grammar.html#bytes"">H2 has this syntax</a>:</p>

<pre><code>INSERT INTO lob_table VALUES (X'01FF');
</code></pre>

<p>But that's not a standard. Any general solutions? Note, I'm interested in a general approach. I know that this can turn out to be terribly inefficient.</p>
","<p>There probably isn't a JDBC escape syntax, so I searched around a bit and found and successfully tested the following:</p>

<ul>
<li><p>SQL Server, Sybase ASE, Sybase SQL Anywhere</p>

<pre><code>INSERT INTO lob_table VALUES (0x01FF);
</code></pre></li>
<li><p>DB2</p>

<pre><code>-- Use a blob constructor. This is not needed for VARCHAR FOR BIT DATA types
INSERT INTO lob_table VALUES (blob(X'01FF'));
</code></pre></li>
<li><p>Derby, H2, HSQLDB, Ingres, MySQL, SQLite</p>

<pre><code>INSERT INTO lob_table VALUES (X'01FF');
</code></pre></li>
<li><p>Oracle</p>

<pre><code>-- As mentioned by a_horse_with_no_name, keep in mind the relatively low
-- limitation of Oracle's VARCHAR types to hold only 4000 bytes!
INSERT INTO lob_table VALUES (hextoraw('01FF'));
</code></pre></li>
<li><p>Postgres</p>

<pre><code>-- There is also hex encoding as of Postgres 9.0
-- The explicit cast is important, though
INSERT INTO lob_table VALUES (E'\\001\\377'::bytea);
</code></pre>

<p>See <a href=""https://stackoverflow.com/questions/9320200/inline-blob-binary-data-types-in-sql-jdbc#9324883"">A.H.'s answer</a> for more details about Postgres' hex encoding</p></li>
<li><p>SQL Standard</p>

<pre><code>-- SQL actually defines binary literals as such 
-- (as implemented by DB2, Derby, H2, HSQLDB, Ingres, MySQL, SQLite):
&lt;binary string literal&gt; ::=
  X &lt;quote&gt; [ &lt;space&gt;... ] 
  [ { &lt;hexit&gt; [ &lt;space&gt;... ] &lt;hexit&gt; [ &lt;space&gt;... ] }... ] &lt;quote&gt;

&lt;hexit&gt; ::=
  &lt;digit&gt; | A | B | C | D | E | F | a | b | c | d | e | f
</code></pre></li>
</ul>
","9320943"
"Binary run length encoding","9223","","<p>I have a web form, for the contents of which I would like to generate a short representation in Base64. The form, among other things, contains a list of 264 binary values, the greater part of which are going to be 0 at any single time. (They represent regions on a geographical map). Even in Base64, this 264-bit number generates a long, intimidating string. I want to implement run-length encoding, as efficiently as possible. Can you help me with this? I've googled binary RLE, but have found nothing of use.</p>

<p><strong>What I've tried this far</strong> - running RLE on the binary string using decimal counts and ""A"" as a separator denoting a change between 0 and 1, then converting the result from base 11 to base 64. For example:</p>

<pre><code>00000000001111111000000010000000000000000000000001111111110001111010101000000000000000000000000000000000000111111111110111000000000000111111100000001000000000000000000000000111111111000111101010100000000000000000000000000000000000011111111111011100
</code></pre>

<p>becomes</p>

<pre><code>10A5A5AA22A7A1A2AAAAAAA34A9AA1A10A5A5AA22A7A1A2AAAAAAA34A9AA1A
</code></pre>

<p>which in turn becomes</p>

<pre><code>CNnbr/FxkgbbOw0LNAKgk65P8SdvaTG+t74o
</code></pre>

<p>or, in base 62,</p>

<pre><code>6imo7zq1pqr2mqglTHzXwJRAksm7fvHZHWQK
</code></pre>

<p>It's better, but I still can't help but doubt if I'm doing something wrong - is using the digit ""A"" as a separator is the best way to do this?</p>

<p><strong>And another update:</strong></p>

<p>Thanks to <strong>@comingstorm</strong>, I have shortened the compressed string some more.</p>

<pre><code>ILHHASCAASBYwwccDASYgAEgWDI=
</code></pre>

<p>As I mentioned it in the comments, real usage cases would generally result in an even shorter string.</p>
","<p>Since you're coding bits, you probably want to use a bit-based RLE instead of a byte-based one.  In this context, you should consider <a href=""http://en.wikipedia.org/wiki/Elias_gamma_coding"" rel=""noreferrer"">Elias gamma coding</a> (or some variant thereof) to efficiently encode your run lengths.</p>

<p>A reasonable first approximation for your encoding format might be:</p>

<ul>
<li>first bit = same as the first bit of the uncompressed string (to set initial polarity)</li>
<li>remaining bits: Elias coded lengths of successive bit runs (alternating 1 and 0)</li>
</ul>

<p>Since you know how many bits are in your uncompressed string, you don't need a termination code; you can just add any necessary binary padding as arbitrary bits.</p>

<p>Note that it is always possible for the run-length ""compression"" to expand your bit string; if you're concerned about this, you can add another initial bit to indicate whether your data is in compressed or uncompressed format, limiting your compression overhead to 1 bit.</p>
","7603969"
"nodejs/express and binary data in POST","9219","","<p>I'm trying to send binary data to an express app. It works fine, as long as my values are smaller than 0x80.  If a single value is 0x80 or greater, it messes up the whole buffer.  </p>

<p>Express Handler:</p>

<pre><code>binary = require('binary');

exports.api = function(req, res){
    var body = req.body.name;
    var buf = new Buffer(body,'binary');

    console.log('body',req.body);
    console.log('req body len', body.length);
    console.log('buf len', buf.length);

    var g = binary.parse(buf)
        .word16bu('a') // unsigned 16-bit big-endian value
        .word16bu('b').vars

    console.log('g.a', g.a);
    console.log('g.b', g.b);

  res.send(""respond with a resource"");
};
</code></pre>

<p>Python client (Content-Type: application/x-www-form-urlencoded):</p>

<pre><code>import requests
from struct import pack
# send two unsigned shorts (16-bits each).
requests.post('http://localhost:3000/api', data={'name':pack('!HH',1,2)})
</code></pre>

<p>Express output when data = 1,2.  <strong>This is what I'd expect</strong>.</p>

<pre><code>body { name: '\u0000\u0001\u0000\u0002' }
req body len 4
buf len 4
g.a 1
g.b 2
POST /api 200 1ms - 23b
</code></pre>

<p>Express output when data = 1,0xFF.  It's interesting to note that 9520 is actually 0x25 0x30 in hex, which corresponds to ""%0"" in ASCII.  Yes, it appears to be parsing the '%00%01...' string.  <strong>I wish I knew how to prevent this!!!</strong></p>

<pre><code>body { name: '%00%01%00%FF' }
req body len 12
buf len 12
g.a 9520
g.b 12325
POST /api 200 2ms - 23b
</code></pre>
","<p>It turned out to be an encoding issue.  Everything seems to default to 'utf8', but in this case it needs to be set to 'binary'.</p>

<p>For example:</p>

<pre><code>var buf = new Buffer(body.toString('binary'),'binary');
</code></pre>

<p>Equally as important, I needed to set nodejs multiparty parser's encoding to 'binary'.  See: <a href=""https://github.com/superjoe30/node-multiparty/issues/37"" rel=""nofollow"">https://github.com/superjoe30/node-multiparty/issues/37</a></p>
","20529572"
"HTTP Headers for Unknown Content-Length","9212","","<p>I am currently trying to stream content out to the web after a trans-coding process. This usually works fine by writing binary out to my web stream, but some browsers (specifically IE7, IE8) do not like not having the Content-Length defined in the HTTP header. I believe that ""valid"" headers are supposed to have this set.</p>

<p>What is the proper way to stream content to the web when you have an unknown Content-Length? The trans-coding process can take awhile, so I want to start streaming it out as it completes.</p>
","<p>Try sending them in chunks along with <a href=""http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.41"" rel=""noreferrer""><code>Transfer-Encoding:</code></a> <a href=""http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.6.1"" rel=""noreferrer""><code>chunked</code></a>. More details in <a href=""http://en.wikipedia.org/wiki/Chunked_transfer_encoding"" rel=""noreferrer"">wikipedia</a>.</p>

<p><strong>Update</strong> as per the comments, here's an example how a ""ChunkedOutputStream"" in Java may look like:</p>

<pre><code>package com.stackoverflow.q2395192;

import java.io.IOException;
import java.io.OutputStream;

public class ChunkedOutputStream extends OutputStream {

    private static final byte[] CRLF = ""\r\n"".getBytes();
    private OutputStream output = null;

    public ChunkedOutputStream(OutputStream output) {
        this.output = output;
    }

    @Override
    public void write(int i) throws IOException {
        write(new byte[] { (byte) i }, 0, 1);
    }

    @Override
    public void write(byte[] b, int offset, int length) throws IOException {
        writeHeader(length);
        output.write(CRLF, 0, CRLF.length);
        output.write(b, offset, length);
        output.write(CRLF, 0, CRLF.length);
    }

    @Override
    public void flush() throws IOException {
        output.flush();
    }

    @Override
    public void close() throws IOException {
        writeHeader(0);
        output.write(CRLF, 0, CRLF.length);
        output.write(CRLF, 0, CRLF.length);
        output.close();
    }

    private void writeHeader(int length) throws IOException {
        byte[] header = Integer.toHexString(length).getBytes();
        output.write(header, 0, header.length);
    }

}
</code></pre>

<p>...which can basically be used as:</p>

<pre><code>OutputStream output = new ChunkedOutputStream(response.getOutputStream());
output.write(....);
</code></pre>

<p>You see in the source, every chunk of data exist of a header which represents the length of data in hex, a CRLF, the actual data and a CRLF. The end of the stream is represented by a header denoting a 0 length and two CRLFs.</p>

<p><strong>Note:</strong> despite the example, you actually do <strong>not</strong> need it in a JSP/Servlet based webapplication. Whenever the content length is not set on a response, the webcontainer will automatically transfer them in chunks.</p>
","2395224"
"Using Binary Search with Vectors.","9182","","<p>I'm trying to implement an algorithm that for each string in the first vector it does a binary search in the second vector and will output ""YES:"" if it finds a match or ""No:"" otherwise. </p>

<p>Right now with my program my algo always outputs ""NO:"" and I can't find out what's going wrong. Any hints or tips would be appreciated.  </p>

<p>My Binary search: </p>

<pre><code>bool binary_search(const vector&lt;string&gt;&amp; sorted_vec, string key) {
size_t mid, left = 0 ;
size_t right = sorted_vec.size(); // one position passed the right end
while (left &lt; right) {
    mid = left + (right - left)/2;
    if (key &gt; sorted_vec[mid]){
        left = mid+1;
   } else if (key &lt; sorted_vec[mid]){                                        
        right = mid;
   } else {                                                                  
        return true;

            }                                                                
        return false;                                                        
    }
}
</code></pre>

<p>My Algo: </p>

<pre><code>if(algo_speed == ""fast""){

    string key = fileContent[i];

    while(getline(ifs1, line)){

            fileContent1.push_back(line);

    }

    sort(fileContent1.begin(), fileContent1.end());
    for(size_t i = 0; i &lt; fileContent.size(); i++){
    string temp = fileContent[i];
    bool found = binary_search(fileContent1,temp) ;

     if(found == true) {
            cout &lt;&lt; ""YES:"" &lt;&lt; fileContent.at(i) &lt;&lt; endl;
        } else {
            cout &lt;&lt; ""NO:"" &lt;&lt; fileContent.at(i) &lt;&lt; endl;
        }
    }
</code></pre>

<p>}</p>
","<p>You are exiting your function on the first miss with the misplaced <code>return false</code>:</p>

<pre><code>bool binary_search(const vector&lt;string&gt;&amp; sorted_vec, string key) {
   size_t mid, left = 0 ;
   size_t right = sorted_vec.size(); // one position passed the right end
   while (left &lt; right) {
      mid = left + (right - left)/2;
      if (key &gt; sorted_vec[mid]){
          left = mid+1;
      }
      else if (key &lt; sorted_vec[mid]){                                        
        right = mid;
      }
      else {                                                                  
        return true;
     }                                                                                                               
   }

   return false;      
}
</code></pre>
","18774907"
"Python, how to decode Binary coded decimal (BCD)","9163","","<p>Description of the binary field is:</p>

<blockquote>
  <p>Caller number, expressed with compressed BCD code, and the surplus bits are filled with “0xF” </p>
</blockquote>

<p>I have tried to print with struct format <code>'16c'</code> and I get: <code>('3', '\x00', '\x02', '\x05', '\x15', '\x13', 'G', 'O', '\xff', '\xff', '\xff', '\xff', '\xff', '\xff', '\xff', '\xff')</code> and if I use <code>'16b'</code> i get <code>(51, 0, 2, 5, 21, 19, 71, 79, -1, -1, -1, -1, -1, -1, -1, -1)</code>. And it is not correct, I should get phone number, and numbers above are invalid.</p>

<pre><code>print struct.unpack_from('&gt;16b', str(data.read()),offset=46)
</code></pre>

<p>Above is code that didn't work and I get invalid numbers. With what format should I unpack that 16 byte field and how to convert BCD code ?</p>
","<p>BCD codes work with 4 bits per number, and normally encode only the digits 0 - 9. So each byte in your sequence contains 2 numbers, 1 per 4 bits of information.</p>

<p>The following method uses a generator to produce those digits; I am assuming that a 0xF value means there are no more digits to follow:</p>

<pre><code>def bcdDigits(chars):
    for char in chars:
        char = ord(char)
        for val in (char &gt;&gt; 4, char &amp; 0xF):
            if val == 0xF:
                return
            yield val
</code></pre>

<p>Here I use a <a href=""http://docs.python.org/reference/expressions.html#shifting-operations"" rel=""noreferrer"">right-shift operator</a> to move the left-most 4 bits to the right, and a <a href=""http://docs.python.org/reference/expressions.html#shifting-opera"" rel=""noreferrer"">bitwise AND</a> to select just the right-most 4 bits.</p>

<p>Demonstration:</p>

<pre><code>&gt;&gt;&gt; characters = ('3', '\x00', '\x02', '\x05', '\x15', '\x13', 'G', 'O', '\xff', '\xff', '\xff', '\xff', '\xff', '\xff', '\xff', '\xff')
&gt;&gt;&gt; list(bcdDigits(characters))
[3, 3, 0, 0, 0, 2, 0, 5, 1, 5, 1, 3, 4, 7, 4]
</code></pre>

<p>The method works with the <code>c</code> output; you can skip the <code>ord</code> call in the method if you pass integers directly (but use the <code>B</code> unsigned variant instead). Alternatively, you could just read those 16 bytes straight from your file and apply this function to those bytes directly without using struct.</p>
","11669177"
"Optimize Binary Search Algorithm","9161","","<p>In a binary search, we have two comparisons one for greater than and other for less
than, otherwise its the mid value. How would you optimize so that we need to check only once?</p>

<pre><code>bool binSearch(int array[], int key, int left, int right)
{

    mid = left + (right-left)/2;
    if (key &lt; array[mid])
        return binSearch(array, key, left, mid-1);
    else if (key &gt; array[mid])
        return binSearch(array, key, mid+1, right);
    else if (key == array[mid])
        return TRUE; // Found

    return FALSE; // Not Found
}
</code></pre>
","<p>I would try the <a href=""http://www.manpagez.com/man/3/bsearch/"" rel=""noreferrer"">bsearch()</a> standard function first. Chances are good that it performes better than your approach.</p>
","673901"
"Search for Binary Pattern in C (Read buffered binary file)","9155","","<p>Hey there. I'm trying to write a small program that will read the four following bytes after the last occurrence of ""0xFF 0xC0 0x00 0x11"" which can be converted easily to binary or decimal. The purpose is that the 2-5 bytes following the last occurrence of that hex pattern represent the width and height of a JPEG file.</p>

<pre><code>#include &lt;stdio.h&gt;

 int main () {
  FILE * pFile;
  long lSize;
  char * buffer;
  size_t result;

  pFile = fopen ( ""pano8sample.jpg"" , ""rb"" );
  if(pFile==NULL){
   fputs (""File error"",stderr);
   exit (1);
  }

  fseek (pFile , 0 , SEEK_END);
  lSize = ftell (pFile);
  rewind (pFile);

  printf(""\n\nFile is %d bytes big\n\n"", lSize);

  buffer = (char*) malloc (sizeof(char)*lSize);
  if(buffer == NULL){
   fputs(""Memory error"",stderr);
   exit (2);
  }

  result = fread (buffer,1,lSize,pFile);
  if(result != lSize){
   fputs(""Reading error"",stderr);
   exit (3);
  }

  //0xFF 0xC0 0x00 0x11 (0x08)

  //Logic to check for hex/binary/dec

  fclose (pFile);
  free (buffer);
  return 0;
 }
</code></pre>

<p>The problem is I don't know how to read from the buffered memory recursively and use the most recently read variable as an int to compare against my binary/hex/dec.</p>

<p>How do I do this?</p>
","<pre><code>byte needle[4] = {0xff, 0xc0, 0x00, 0x11};
byte *last_needle = NULL;
while (true) {
  byte *p = memmem(buffer, lSize, needle, 4); 
  if (!p) break;
  last_needle = p;
  lSize -= (p + 4) - buffer;
  buffer = p + 4;
}
</code></pre>

<p>If <code>last_needle</code> is not null, you can print out <code>last_needle+4</code>...</p>
","1541821"
"how to read signed int from bytes in java?","9119","","<p>I have a spec which reads the next two bytes are signed int.</p>

<p>To read that in java i have the following</p>

<p>When i read a signed int in java using the following code i get a value of 65449</p>

<p>Logic for calculation of unsigned</p>

<pre><code>int a =(byte[1] &amp; 0xff) &lt;&lt;8

int b =(byte[0] &amp; 0xff) &lt;&lt;0

int c = a+b 
</code></pre>

<p>I believe this is wrong because if i and with 0xff i get an unsigned equivalent</p>

<p>so i removed the &amp; 0xff and the logic as given below</p>

<pre><code>int a = byte[1] &lt;&lt;8
int b = byte[0] &lt;&lt; 0
int c = a+b
which gives me the value -343
byte[1] =-1
byte[0]=-87
</code></pre>

<p>I tried to offset these values with the way the spec reads but this looks wrong.Since the size of the heap doesnt fall under this.</p>

<p>Which is the right way to do for signed int calculation in java?</p>

<p>Here is how the spec goes</p>

<p><code>somespec() { xtype 8 uint8 xStyle 16 int16 }</code> 
 xStyle :A signed integer that represents an offset (in bytes) from the start of this Widget() structure to the start of an xStyle() structure that expresses inherited styles for defined by page widget as well as styles that apply specifically to this widget.</p>
","<p>If you value is a signed 16-bit you want a <code>short</code> and int is 32-bit which can also hold the same values but not so naturally.</p>

<p>It appears you wants a signed little endian 16-bit value.</p>

<pre><code>byte[] bytes = 
short s = ByteBuffer.wrap(bytes).order(ByteOrder.LITTLE_ENDIAN).getShort();
</code></pre>

<p>or</p>

<pre><code>short s = (short) ((bytes[0] &amp; 0xff) | (bytes[1] &lt;&lt; 8));
</code></pre>

<p>BTW: You can use an int but its not so simple.</p>

<pre><code>// to get a sign extension.
int i = ((bytes[0] &amp; 0xff) | (bytes[1] &lt;&lt; 8)) &lt;&lt; 16 &gt;&gt; 16;
</code></pre>

<p>or</p>

<pre><code>int i = (bytes[0] &amp; 0xff) | (short) (bytes[1] &lt;&lt; 8));
</code></pre>
","7158045"
"How to send binary data with socket.io?","9114","","<p>so I have been having real trouble sending binary data with socket.io  in node.js (Js client and Android client). </p>

<p>There is not much information neither in:</p>

<p><a href=""http://socket.io/blog/introducing-socket-io-1-0/"" rel=""noreferrer"">http://socket.io/blog/introducing-socket-io-1-0/</a></p>

<p><a href=""http://socket.io/get-started/chat/"" rel=""noreferrer"">http://socket.io/get-started/chat/</a></p>

<p>I need to use socket io to send a binary array, that I create and fill.</p>

<p>the only code they give is the following:</p>

<pre><code>var socket = new WebSocket('ws://localhost');
socket.binaryType = 'arraybuffer';
socket.send(new ArrayBuffer);
</code></pre>

<p>My answer is bellow.</p>
","<p>Finally I have it working with JS and Android ( Java ), so I decided to share it with you guys.</p>

<p>Let's start with the Server Code: (Node js)</p>

<pre><code>var http = require('http');

var app = http.createServer(function ejecute(request, response){});
var io = require('socket.io').listen(app);


io.on('connection', function(socket) {
        socket.on('message', function(data){
            console.log(""recieved data:"");
            console.log(data);

            var bufArr = new ArrayBuffer(4);
            var bufView = new Uint8Array(bufArr);
            bufView[0]=6;
            bufView[1]=7;
            bufView[2]=8;
            bufView[3]=9;
            socket.emit('message',bufArr);
        });
    });
app.listen(3000);
</code></pre>

<p>Lets jump on to the Javascript client</p>

<pre><code>  var socket = io(""http://localhost:3000"");
  socket.emit('message', 'hola from js client');

  socket.on('message', function(msg){
    var bufView = new Uint8Array(msg);
    console.log(msg)
  });
</code></pre>

<p>And finally, let's show the Android (java) client:</p>

<pre><code>    final Socket socket = IO.socket(""http://localhost:3000"",opts);

    socket.on(Socket.EVENT_CONNECT, new Emitter.Listener() {
        @Override
        public void call(Object... args) {
            socket.emit(""message"",""hello from java"");
        }
    });


    socket.on(""message"", new Emitter.Listener() {

        @Override
        public void call(Object... args) {
            byte[] bytearray = (byte[])args[0]; //received bytes

            for  (byte b : bytearray) {
                System.out.println(""byte""+b);
            }
        }

    });

   socket.on(Socket.EVENT_DISCONNECT, new Emitter.Listener() {
    @Override
    public void call(Object... args) {}
});
</code></pre>

<p>I hope it is useful to you all.
Cheers!</p>
","34056706"
"Need Linux cmd-line app to compare binary files and exit on 1st mis-match","9108","","<p>Is there a Linux command-line app which will compare two binary files and exit on the first mis-match?</p>

<p><code>cmp</code> doesn't seem to have the quit opition. </p>
","<p><code>cmp</code> doesn't have this <em>option</em>, because it always quits on the first mismatch.</p>

<pre><code>$ cmp -b /bin/ls /bin/sed
/bin/ls /bin/sed differ: byte 25, line 1 is 320 M-P 300 M-@
</code></pre>
","4013240"
"Capturing binary output from Process.StandardOutput","9093","","<p>In C# (.NET 4.0 running under Mono 2.8 on SuSE) I would like to run an external batch command and capture its ouput in binary form. The external tool I use is called 'samtools' (samtools.sourceforge.net) and among other things it can return records from an indexed binary file format called BAM. </p>

<p>I use Process.Start to run the external command, and I know that I can capture its output by redirecting Process.StandardOutput. The problem is, that's a text stream with an encoding, so it doesn't give me access to the raw bytes of the output. The almost-working solution I found is to access the underlying stream.</p>

<p>Here's my code:</p>

<pre><code>        Process cmdProcess = new Process();
        ProcessStartInfo cmdStartInfo = new ProcessStartInfo();
        cmdStartInfo.FileName = ""samtools"";

        cmdStartInfo.RedirectStandardError = true;
        cmdStartInfo.RedirectStandardOutput = true;
        cmdStartInfo.RedirectStandardInput = false;
        cmdStartInfo.UseShellExecute = false;
        cmdStartInfo.CreateNoWindow = true;

        cmdStartInfo.Arguments = ""view -u "" + BamFileName + "" "" + chromosome + "":"" + start + ""-"" + end;

        cmdProcess.EnableRaisingEvents = true;
        cmdProcess.StartInfo = cmdStartInfo;
        cmdProcess.Start();

        // Prepare to read each alignment (binary)
        var br = new BinaryReader(cmdProcess.StandardOutput.BaseStream);

        while (!cmdProcess.StandardOutput.EndOfStream)
        {
            // Consume the initial, undocumented BAM data 
            br.ReadBytes(23);
</code></pre>

<p>// ... more parsing follows</p>

<p>But when I run this, the first 23bytes that I read are  not the first 23 bytes in the ouput, but rather somewhere several hundred or thousand bytes downstream. I assume that StreamReader does some buffering and so the underlying stream is already advanced say 4K into the output. The underlying stream does not support seeking back to the start.</p>

<p>And I'm stuck here. Does anyone have a working solution for running an external command and capturing its stdout in binary form? The ouput may be very large so I would like to stream it.</p>

<p>Any help appreciated. </p>

<p>By the way, my current workaround is to have samtools return the records in text format, then parse those, but this is pretty slow and I'm hoping to speed things up by using the binary format directly.</p>
","<p>Using <code>StandardOutput.BaseStream</code> is the correct approach, but you must not use any other property or method of <code>cmdProcess.StandardOutput</code>. For example, accessing <code>cmdProcess.StandardOutput.EndOfStream</code> will cause the <code>StreamReader</code> for <code>StandardOutput</code> to read part of the stream, removing the data you want to access.</p>

<p>Instead, simply read and parse the data from <code>br</code> (assuming you know how to parse the data, and won't read past the end of stream, or are willing to catch an <code>EndOfStreamException</code>). Alternatively, if you don't know how big the data is, use <a href=""http://msdn.microsoft.com/en-us/library/system.io.stream.copyto.aspx"" rel=""noreferrer""><code>Stream.CopyTo</code></a> to copy the entire standard output stream to a new file or memory stream.</p>
","4535927"
"Extracting Binary Data (a jpeg image) in the Request Body Sent to a Node.js Server","9072","","<h2>Problem To Solve</h2>

<p>Hello. I have been given an iPhone app that, as part of its functionality, sends a request to the server with a binary jpeg image in the request body. I have to find a way to read that binary data, send it to a client via socket.io, and log a copy of the image to the disk on the server.</p>

<h2>First Try:</h2>

<p>I have tried a few approaches with no luck. First I tried this:</p>

<pre><code>var http = require('http');
var fs = require('fs');

http.createServer(function (req, res) {
console.log(""Request In"");
    var body = '';
    req.on('data', function (data) {
        body += data;
    });
    req.on('end', function () {
        fs.writeFile(""./1.jpeg"", body, function(err) {
        if(err) {
            console.log(err);
           } else {
            console.log(""The file was saved!"");
     }
});
    });
res.writeHead(200, {'Content-Type':'text/plain'});
res.end('Image Saved!');
}).listen(3000);
console.log('Server running at http://127.0.0.1:3000/');
</code></pre>

<p>This didn't work. I could not get an image that would open in Windows Photo Viewer. The Windows Photo Viewer gave me the error <code>Windows Photo Viewer can't open this picture because either Photo Viewer doesn't support this file format, or you don't have the latest updates to Photo Viewer</code> I'm sure I have the latest version. I next wondered if the request was getting messed up between the phone and the server. </p>

<h2>Checking Request Fidelity</h2>

<p>I installed <a href=""http://fiddler2.com/"" rel=""nofollow noreferrer"">Fiddler 2</a>. I setup a reverse proxy, detailed <a href=""https://stackoverflow.com/questions/4428680/how-do-i-monitor-all-incoming-http-requests"">here</a>. I clicked on the request and then went to the hex view. I save the bytes after the header information by right-clicking selecting save bytes. I named the file test.jpg and it opened up in Windows Photo Viewer just fine.</p>

<p><img src=""https://i.stack.imgur.com/2iDsG.png"" alt=""saving bytes""></p>

<p>I chose which bytes to save based on the different colors on the ""header bytes"" and the ""body bytes""</p>

<p><img src=""https://i.stack.imgur.com/2Nqj7.png"" alt=""colored bytes""></p>

<p>Here is an example of the image I ended up getting from saving those bytes</p>

<p><img src=""https://i.stack.imgur.com/BOGTR.jpg"" alt=""enter image description here""></p>

<h2>Second Try:</h2>

<p>Now that I know that the image is in the request and I know I can get to using fiddler, I searched stackoverflow and google to find how to capture the request body. I tried a bunch of solutions but none gave me an image that I could open.</p>

<pre><code>//Express.js
var express = require('express');
var app = express();
var fs = require('fs');

app.configure(function(){
    app.use(express.bodyParser());
    app.use(function(req, res, next) {
        req.rawBody = '';
        // req.setEncoding('base64');
        req.setEncoding(null);
        req.on('data', function(chunk) { 
            req.rawBody += chunk;
        });
        req.on('end', function() {
            next();
        });
    });
});

app.listen(3000);

app.get('*', function(req, res){
    res.writeHead(200);
    res.end('Hello World');
    console.log(req.rawBody);
});

app.put('*',  function(req, res){
    console.log(""putted"");
    res.writeHead(200);
    res.end('Hello World');
    fs.writeFile(""./1.jpg"", req.rawBody, function(err) {
        if(err) {
            console.log(err);
        } else {
            console.log(""The file was saved!"");
        }
    });
    console.log(req.headers);
    console.log(req.params);
    console.log(req.body);
});
console.log(""running"");
</code></pre>

<p>As I understand, the express bodyParser looks for json key-value pairs and because the request body is just a bunch of binary data, its return an empty array/object (not sure which). I wrote the custom middleware that adds a rawBody variable to the request object (req) at the suggestion of <a href=""https://stackoverflow.com/questions/9920208/expressjs-raw-body"">this answer on stackoverflow</a>. A few articles said to use <code>req.setEncoding('something')</code> to let the Node.js know how that data is encoded. I tried <code>null</code> <code>base64</code> <code>hex</code> and <code>binary</code>. </p>

<p>I have uploaded the saved request from Fiddler 2, if you would like to take a look. <a href=""http://dev.briananglin.me/Fiddler_Saved_Request"" rel=""nofollow noreferrer"">Fiddler 2 Request</a>. <em>Note: I wasn't sure what file extension to use so I didn't use any file extension.</em></p>

<p><strong>I am currently stuck.</strong> I have tried all the solutions I could find on google and stackoverflow. Please ask for clarification if you need it. I tried to be as detailed as possible (sorry for the length). <strong>Thank you for taking the time to read this far!</strong></p>

<h2>Side Note/Extra</h2>

<p>I don't know much about Node.js buffers work. I would like to be able to accept a ""stream"" of these images if possible. I don't know how a buffer might play into an answer but if it does please try to explain it, assuming I have little knowledge about buffers.</p>

<p>I also mentioned wanting to send the image to a browser over socket.io. If you would like to include this second set in your answer it would be greatly appreciated. </p>

<p>If you would like, please include information about how your solution would perform. (Heavy on CPU or mem or light on one, etc)</p>
","<p>This should do it:</p>

<pre><code>var http = require('http');
var fs = require('fs');

var app = http.createServer(function (req, res) {
  req.pipe(fs.createWriteStream(__dirname + req.url));

  res.writeHead(200, {'Content-Type': 'text/plain'});
  res.end('OK!');
});

app.listen(3000);
</code></pre>

<p>Verified with <code>curl</code>:</p>

<pre><code>curl -H 'Content-Type: application/octet-stream' --data-binary @file.jpg localhost:3000/foo.jpg
</code></pre>

<p>If this doesn't work, I'd test it with curl to make sure it's not the client which is doing something weird.</p>

<p>When it comes to sending it over socket.io, I wouldn't do that, but send the URL instead. If that's not an option I guess you would have to <code>base64</code> encode the data.</p>
","19635270"
"base 13 - The Hitchhiker's Guide to the Galaxy","9063","","<p>I know base 13 is not practical. However,  i was checking out The Hitchhiker's Guide to the Galaxy again because todays date is  10/10/10 = 42 in binary. (you know, the answer to the ultimate question of life, the universe, and everything) It takes Deep Thought 7½ million years to compute and check the answer, which turns out to be 42. Unfortunately, The Ultimate Question itself is unknown. Anyways, he said """"Six by nine. Forty two."" ""That's it. That's all there is.""""I always thought something was fundamentally wrong with the universe""</p>

<p>My question is how is 6 x 9 in base 13 = 42?</p>

<p>I know how to convert base 10, 2,16,8 but going from base 10 to base 13 is a mystery to me.
I understand that in base 13 that 6 probably =6 and 9 probably =9 S0, it is just a matter of multiplying in base 13? </p>

<p>Can someone work it out?
I have found this but doesnt help much</p>

<pre><code>in base 13, 6 13 × 9 13 is actually 4213 
(as 4 × 13 + 2 = 54, i.e. 54 in decimal is 
  equal to 42 expressed in base 13).
</code></pre>
","<p>This is a method that can convert a base-10 number to base-13:</p>

<p>Start with a number 9x6=54, we want to find the equivalent of 54 in base 13.</p>

<pre><code>54 / 13 = 4 remainder 2
4  / 13 = 0 remainder 4
</code></pre>

<p>and we concatenate the remainders, from bottom-up, 42.</p>

<p>A more general algorithm, start with a decimal number N, we want to find the equivalent of N in base B.</p>

<pre><code>N  / B = a1 remainder r1
a1 / B = a2 remainder r2
....
an / B = 0 remainder rn
</code></pre>

<p>and concatenate the digits, bottom-up: rn . ... . r2 . r1</p>

<p>an iterative implementation in Python:</p>

<pre><code>digits = '0123456789abcdefghijklmnopqrstuvwxyz'
def rebase(n, base=2):
    ''' Convert a positive integer to number string with base `base` '''
    s = []
    while n != 0:
        n, rem = divmod(n, base)
        s.append(digits[rem])
    return ''.join(reversed(s))
</code></pre>

<p>a recursive implementation in Python:</p>

<pre><code>digits = '0123456789abcdefghijklmnopqrstuvwxyz'
def rebase(n, base=2):
    ''' Convert a positive integer to number string with base `base` '''
    return rebase(n // base, base) + digits[n % base] if n != 0 else ''
</code></pre>

<p>even more generally, if you have a string representing a number in base N and you want to convert it to a string representing the number in base M:</p>

<pre><code>digits = '0123456789abcdefghijklmnopqrstuvwxyz'
def rebase(orig, orig_base=10, target_base=2):
    ''' Convert a positive integer to number string with base `base` '''
    num = 0
    for i, n in enumerate(reversed(orig)):
        num += digits.find(n) * (orig_base**i)
    target = []
    while num != 0:
        num, rem = divmod(num, target_base)
        target.append(digits[rem])
    return ''.join(reversed(target))
</code></pre>
","3902946"
"Setting specific bits in a number","9052","","<p>var d = 7;</p>

<p>in binary: 7 = (111)</p>

<p>What I want to do is to set second place from right to 1 or 0 at disposal,</p>

<p>and return the decimal value.</p>

<p>For example,if I want to make the second 1 to 0,then after process should return a 5,</p>

<p>because 5=(101).</p>

<p>How to implement this in javascript? </p>

<p><strong>EDIT</strong></p>

<p>the answer should be something like this:</p>

<pre><code>function func(decimal,n_from_right,zero_or_one)
{

}
</code></pre>

<p>Where decimal is the number to be processed,
n_from_right is how many bits from right,in my example above it's 2.
zero_or_one means to set that specific bit to 0 or 1 at disposal.</p>
","<p>The easiest way to clear a bit, is to use the and operation with it's bit complement.</p>

<pre><code>7 =  0000000000000111
~2 = 1111111111111101
&amp; :  0000000000000101
</code></pre>

<p>In code:</p>

<pre><code>var d = 7, mask = 2;
d &amp;= ~mask;
</code></pre>

<p>To set a bit instead of clearing it, you use the or operator instead:</p>

<pre><code>d |= mask;
</code></pre>

<p>If you need to create the mask dynamically to handle different bits, you start with the value one (binary 0000000000000001) and shift the bit to the correct index. The second bit has index one (the rightmost bit has index zero), so:</p>

<pre><code>var index = 1;
var mask = 1 &lt;&lt; index;
</code></pre>
","1459056"
"python inserting and retrieving binary data into mysql","9035","","<p>I'm using the MySQLdb package for interacting with MySQL. I'm having trouble getting the proper type conversions.</p>

<p>I am using a 16-byte binary uuid as a primary key for the table and have a mediumblob holding zlib compressed json information.</p>

<p>I'm using the following schema:</p>

<pre><code>CREATE TABLE repositories (
    added_id int auto_increment not null,
    id binary(16) not null,
    data mediumblob not null,
    create_date int not null,
    update_date int not null,
    PRIMARY KEY (added_id),
    UNIQUE(id)
) DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci ENGINE=InnoDB;
</code></pre>

<p>Then I create a new row in the table using the following code:</p>

<pre><code>data = zlib.compress(json.dumps({'hello':'how are you :D'})
row_id = uuid.uuid(4).hex
added_id = cursor.execute('
    INSERT INTO repositories (id, data, create_date, update_date) 
    VALUES (%s, %s, %s, %s)',
    binascii.a2b_hex(row_id), 
    data, 
    time.time(), 
    time.time()
)
</code></pre>

<p>Then to retrieve data I use a similar query:</p>

<pre><code>query = cursor.execute('SELECT added_id, id, data, create_date, update_date ' \
    'FROM repositories WHERE id = %s',
    binascii.a2b_hex(row_id)
)
</code></pre>

<p>Then the query returns an empty result.</p>

<p>Any help would be appreciated. Also, as an aside, is it better to store unix epoch dates as integers or TIMESTAMP?</p>

<p><strong>NOTE:</strong> I am not having problems inserting the data, just trying to retrieve it from the database. The row exists when I check via mysqlclient.</p>

<p>Thanks Alot!@</p>
","<p>One tip: you should be able to call <code>uuid.uuid4().bytes</code> to get the raw 
bytes.  As for timestamps, if you want to perform time/date manipulation 
in SQL it's often easier to deal with real TIMESTAMP types.</p>

<p>I created a test table to try to reproduce what you're seeing:</p>

<pre><code>CREATE TABLE xyz (
    added_id INT AUTO_INCREMENT NOT NULL,
    id BINARY(16) NOT NULL,
    PRIMARY KEY (added_id),
    UNIQUE (id)
) DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci ENGINE=InnoDB;
</code></pre>

<p>My script is able to insert and query for the rows using the binary field as a
key without problem. Perhaps you are incorrectly fetching / iterating over the
results returned by the cursor?</p>

<pre><code>import binascii
import MySQLdb
import uuid

conn = MySQLdb.connect(host='localhost')

key = uuid.uuid4()
print 'inserting', repr(key.bytes)
r = conn.cursor()
r.execute('INSERT INTO xyz (id) VALUES (%s)', key.bytes)
conn.commit()

print 'selecting', repr(key.bytes)
r.execute('SELECT added_id, id FROM xyz WHERE id = %s', key.bytes)
for row in r.fetchall():
    print row[0], binascii.b2a_hex(row[1])
</code></pre>

<p>Output:</p>

<pre><code>% python qu.py    
inserting '\x96\xc5\xa4\xc3Z+L\xf0\x86\x1e\x05\xebt\xf7\\\xd5'
selecting '\x96\xc5\xa4\xc3Z+L\xf0\x86\x1e\x05\xebt\xf7\\\xd5'
1 96c5a4c35a2b4cf0861e05eb74f75cd5
% python qu.py
inserting '\xac\xc9,jn\xb2O@\xbb\xa27h\xcd&lt;B\xda'
selecting '\xac\xc9,jn\xb2O@\xbb\xa27h\xcd&lt;B\xda'
2 acc92c6a6eb24f40bba23768cd3c42da
</code></pre>
","5241478"
"How to concatenate strings with binary values in python?","9007","","<p>What's the easiest way in python to concatenate string with binary values ?</p>

<pre><code>sep = 0x1
data = [""abc"",""def"",""ghi"",""jkl""]
</code></pre>

<p>Looking for result data <code>""abc0x1def0x1ghi0x1jkl""</code> with the 0x1 being binary value not string ""0x1"".</p>
","<p>I think</p>

<pre><code>joined = '\x01'.join(data) 
</code></pre>

<p>should do it. <code>\x01</code> is the escape sequence for a byte with value 0x01.</p>
","1012472"
"Embedding binary blobs using gcc mingw","8978","","<p>I am trying to embed binary blobs into an exe file. I am using mingw gcc.</p>

<p>I make the object file like this:</p>

<pre><code>ld -r -b binary -o binary.o input.txt
</code></pre>

<p>I then look objdump output to get the symbols:</p>

<pre><code>objdump -x binary.o
</code></pre>

<p>And it gives symbols named:</p>

<pre><code>_binary_input_txt_start
_binary_input_txt_end
_binary_input_txt_size
</code></pre>

<p>I then try and access them in my C program:</p>

<pre><code>#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;

extern char _binary_input_txt_start[];

int main (int argc, char *argv[])
{
    char *p;
    p = _binary_input_txt_start;

    return 0;
}
</code></pre>

<p>Then I compile like this:</p>

<pre><code>gcc -o test.exe test.c binary.o
</code></pre>

<p>But I always get:</p>

<pre><code>undefined reference to _binary_input_txt_start
</code></pre>

<p>Does anyone know what I am doing wrong?</p>
","<p>In your C program remove the leading underscore:</p>

<pre><code>#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;

extern char binary_input_txt_start[];

int main (int argc, char *argv[])
{
    char *p;
    p = binary_input_txt_start;

    return 0;
}
</code></pre>

<p>C compilers often (always?) seem to prepend an underscore to <code>extern</code> names. I'm not entirely sure why that is - I assume that there's some truth to <a href=""http://en.wikipedia.org/wiki/Underscore#Origins_in_identifiers"" rel=""noreferrer"">this wikipedia article's</a> claim that</p>

<blockquote>
  <p>It was common practice for C compilers to prepend a leading underscore to all external scope program identifiers to avert clashes with contributions from runtime language support</p>
</blockquote>

<p>But it strikes me that if underscores were prepended to all externs, then you're not really partitioning the namespace very much.  Anyway, that's a question for another day, and the fact is that the underscores do get added.</p>
","2627243"
"How to read exactly one byte in a binary file in C++","8970","","<p>I am trying to a read a single byte from a binary file, and I am getting inaccurate results.</p>

<p>This is the content of binary file:</p>

<p><code>00000000  00 04 0A 07 00 00 00 00 00 00 74 00 00 00 00 61 69 6E 62 6F 77 00                                                                               ..........t....ainbow.
</code></p>

<p>The point is that I can read more than one byte, but I just can't read exactly one byte. If tried to read the third byte <code>0A</code> which is equal to <code>10</code>, instead it gives me a value of <code>32522</code> or in hexadecimal <code>7F0A</code>. What am I missing here?</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;fstream&gt;
#include &lt;cstring&gt;
#include &lt;fstream&gt;

using namespace std;

int main()
{
    fstream file(""foo.daf"", ios::in | ios::out | ios::binary);

    file.seekg(2);

    int x;

    file.read(reinterpret_cast&lt;char *&gt;(&amp;x), 1);

    cout&lt;&lt;x&lt;&lt;endl;

    return 0;
}
</code></pre>
","<p><code>x</code> is not initialized, and you modify only one byte of it, so you have garbage for the other bytes.</p>

<p>Use directly the correct type should solve your issue (and avoid a cast).</p>

<pre><code>char x;
</code></pre>
","27698306"
"In Swift, how do I read an existing binary file into an array?","8962","","<p>As part of my projects, I have a binary data file consisting of a large series of 32 bit integers that one of my classes reads in on initialization.  In my C++ library, I read it in with the following initializer:</p>

<pre><code>Evaluator::Evaluator() {
    m_HandNumbers.resize(32487834);
    ifstream inputReader;

    inputReader.open(""/path/to/file/7CHands.dat"", ios::binary);

    int inputValue;
    for (int x = 0; x &lt; 32487834; ++x) {
        inputReader.read((char *) &amp;inputValue, sizeof (inputValue));
        m_HandNumbers[x] = inputValue;
    }
    inputReader.close();
};
</code></pre>

<p>and in porting to Swift, I decided to read the entire file into one buffer (it's only about 130 MB) and then copy the bytes out of the buffer.</p>

<p>So, I've done the following:</p>

<pre><code>public init() {
    var inputStream = NSInputStream(fileAtPath: ""/path/to/file/7CHands.dat"")!
    var inputBuffer = [UInt8](count: 32478734 * 4, repeatedValue: 0)
    inputStream.open()
    inputStream.read(&amp;inputBuffer, maxLength: inputBuffer.count)
    inputStream.close()
}
</code></pre>

<p>and it works fine in that when I debug it, I can see inputBuffer contains the same array of bytes that my hex editor says it should.  Now, I'd like to get that data out of there effectively.  I know it's stored in.. whatever format you call it where the least significant bytes are first (i.e. the number 0x00011D4A is represented as '4A1D 0100' in the file).  I'm tempted to just iterate through it manually and calculate the byte values by hand, but I'm wondering if there's a quick way I can pass an array of [Int32] and have it read those bytes in.  I tried using NSData, such as with:</p>

<pre><code>    let data = NSData(bytes: handNumbers, length: handNumbers.count * sizeof(Int32))
    data.getBytes(&amp;inputBuffer, length: inputBuffer.count)
</code></pre>

<p>but that didn't seem to load the values (all the values were still zero).  Can anyone please help me convert this byte array into some Int32 values?  Better yet would be to convert them to Int (i.e. 64 bit integer) just to keep my variable sizes the same across the project.</p>
","<p>Not sure about your endian-ness, but I use the following function. The difference from your code is using <code>NSRanges</code> of the actual required type, rather than lengths of bytes. This routine reads one value at a time (it's for ESRI files whose contents vary field by field), but should be easily adaptable. </p>

<pre><code>func getBigIntFromData(data: NSData, offset: Int) -&gt; Int {
    var rng = NSRange(location: offset, length: 4)
    var i = [UInt32](count: 1, repeatedValue:0)

    data.getBytes(&amp;i, range: rng)
    return Int(i[0].bigEndian)// return Int(i[0]) for littleEndian
}
</code></pre>
","28992260"
"ASCII with odd parity","8936","","<p>Consider a data communications system that represents characters using ASCII with odd parity. Each 7-bit ASCII character is followed by a parity bit.</p>

<p>Specify the resulting 8-bit code word for each of the characters in the following message that is to be transmitted:</p>

<p><strong>IAcademy!</strong></p>

<p>(The characters in this message, including the exclamation mark.)</p>

<hr>

<p>Using a <a href=""http://web.cs.mun.ca/~michael/c/ascii-table.html"" rel=""nofollow"">Table of ASCII Characters</a>, I converted the ASCII character ""c"" from 0x63 to binary:
<strong>0110 0011</strong></p>

<p>There are an even number of 1's.</p>

<p>1) Where do I add the parity bit (prefix or suffix)?</p>

<p>2) Adding a parity bit to make the number of 1's odd will result to 9-bits. How do I keep it to 8-bits?</p>
","<p>First you need to know what is sent first: LSB or MSB. Second, you append the ODD parity bit at the end of the transmission such that the total number of 1s is odd. So, if you want to send the ASCII 'B' (0x42 -> 1000010) using a communication system that sends LSB first (most common), you would send 0xC2 (11000010), so you would see on the wire 0,1,0,0,0,0,1,1. If you're using a communication system that sends MSB first, the same 'B' would be sent as 0x85. In that case, you would see on the wire 1,0,0,0,0,1,0,1. I hope this helps!</p>
","19345128"
"Encoding an integer in 7-bit format of C# BinaryReader.ReadString","8890","","<p><code>C#</code>'s <code>BinaryReader</code> has a function that according to MSDN, reads an integer encoded as ""seven bit integer"", and then reads a string with the length of this integer.</p>

<p>Is there a clear documentation for the seven bit integer format (I have a rough understanding that the MSB or the LSB marks whether there are more bytes to read, and the rest bits are the data, but I'll be glad for something more exact).</p>

<p>Even better, is there a <code>C</code> implementation for reading and writing numbers in this format?</p>
","<p>Well, the documentation for <a href=""http://msdn.microsoft.com/en-us/library/system.io.binaryreader.read7bitencodedint.aspx"" rel=""noreferrer"">BinaryReader.Read7BitEncodedInt</a> already says, that it expects the value to be written with <a href=""http://msdn.microsoft.com/en-us/library/system.io.binarywriter.write7bitencodedint.aspx"" rel=""noreferrer"">BinaryWriter.Write7BitEncodedInt</a> and that method documentation details the format:</p>

<blockquote>
  <p>The integer of the value parameter is written out seven bits at a time, starting with the seven least-significant bits. The high bit of a byte indicates whether there are more bytes to be written after this one.</p>
  
  <p>If value will fit in seven bits, it takes only one byte of space. If value will not fit in seven bits, the high bit is set on the first byte and written out. value is then shifted by seven bits and the next byte is written. This process is repeated until the entire integer has been written.</p>
</blockquote>

<p>So the integer 1259551277, in binary 1001011000100110011101000101101 will be converted into that 7-bit format as follows:</p>

<pre><code>Remaining integer                 encoded bytes
1001011000100110011101000101101
100101100010011001110100          00101101
10010110001001100                 10101101 01110100
1001011000                        10101101 11110100 01001100
100                               10101101 11110100 11001100 01011000
0                                 10101101 11110100 11001100 11011000 00000100
</code></pre>

<p>I'm not that confident in my C skills right now to provide a working implementation, though. But it's not very hard to do, based on that description.</p>
","1550568"
"Convert Hex string to Binary string C#","8888","","<p>I am trying to convert hex string into binary. My code looks as follows:</p>

<pre><code>sw.Write(Convert.ToString(Convert.ToInt32(value, 16), 2));
</code></pre>

<p>However this works for most of the values; But when I convert hex string 0x101 to binarystring, my result is 100000001, rathen than 000100000001. Please help me.</p>
","<p>How about using String.PadLeft() ?</p>

<pre><code>string value = ""0x001"";
string binary = Convert.ToString(Convert.ToInt32(value, 16), 2).PadLeft(12, '0');
</code></pre>
","24191029"
"Convert a string of binary into an ASCII string (C++)","8880","","<p>I have a string variable containing 32 bits of binary. What would be the best way to convert these 4 characters (8 bits is one character) represented by the binary back into their ASCII characters?</p>

<p>For example, a variable contains ""01110100011001010111001101110100"" which should be converted back into the string ""test"".</p>
","<p>An alternative if you're using C++11:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;sstream&gt;
#include &lt;bitset&gt;

int main()
{
    std::string data = ""01110100011001010111001101110100"";
    std::stringstream sstream(data);
    std::string output;
    while(sstream.good())
    {
        std::bitset&lt;8&gt; bits;
        sstream &gt;&gt; bits;
        char c = char(bits.to_ulong());
        output += c;
    }

    std::cout &lt;&lt; output;

   return 0;
}
</code></pre>

<p>Note that bitset is part of C++11.</p>

<p>Also note that if data is not well formed, the result will be silently truncated when sstream.good() returns false.</p>
","23344876"
"Bitwise Operators and Binary string evaluations","8852","","<p>I have an assignment where I have to convert a hexadecimal to a 16 bit binary string and then compare two of these using bitwise operators. I have a for loop which executes <code>a.charAt[i]</code> &amp; <code>b.charAt[i]</code> to a string builder string. Now, I expect that to output a binary number but I've gotten to a point where every time that line executes, it gives me numbers that are not 0 or 1. And it gives me 2 numbers (2 and 3). What am I doing wrong?</p>

<p>Some code:</p>

<pre><code>    int bin = 0;
    hex = hex.replaceFirst(""0x"", """");
    bin = Integer.parseInt(hex, 16);
    hex = String.format(""%16s"", Integer.toBinaryString(bin));
    return hex;
</code></pre>

<p>The two hexadecimals I am trying to evaluate are <code>FFF7</code> and <code>0001</code>. I've successfully converted them to binary strings. Also I don't know why but the preceding zeros are not showing up, just the spaces :/</p>

<p>I've looked online extensively for hours and can't seem to find the problem I am having.</p>
","<p>I'm assuming that you want to bitwise AND two 16-bit, big-endian, hexadecimal numbers together and display the result as binary.</p>

<p>As others have said using numbers rather than strings would make your life easier - unless this is a constraint of the assignment? </p>

<p>If I were doing this task, with my assumptions and as I understand it, I would:</p>

<ul>
<li>Convert the strings into numbers</li>
<li>For each bit of the numbers, from <code>0x8000</code> down to and including <code>0x0001</code>:

<ul>
<li><code>&amp;</code> the corresponding bits</li>
<li>Append the result to a <code>StringBuilder</code></li>
</ul></li>
<li>Return the contents of the <code>StringBuilder</code></li>
</ul>

<p>To step through corresponding bits of each number I would use <a href=""http://en.wikipedia.org/wiki/Mask_%28computing%29"" rel=""nofollow noreferrer"">bit masking</a> and <a href=""https://stackoverflow.com/questions/141525/absolute-beginners-guide-to-bit-shifting"">bit shifting</a>. </p>

<p>N.B. <code>0x8000</code> is the top bit of a 16-bit number.</p>

<p>An alternative is to let Java do the lot, however this may not be the point of your assignment:</p>

<pre><code>final int a = Integer.parseInt(""FFF7"", 16); // 0b1111111111110111
final int b = Integer.parseInt(""0001"", 16); // 0b0000000000000001

final int result = a &amp; b;

final String output = String.format(""%16s"", 
    Integer.toBinaryString(result)).replace(' ', '0');

System.out.println(output); 
</code></pre>

<p>This will print:</p>

<pre><code>0000000000000001
</code></pre>

<p>I hope this helps in some way and that I'm not too far off the mark with my assumptions. Good luck!</p>
","12730358"
"Jump to byte address in vim?","8816","","<p>I'm investigating a mainly UTF-8 file with lot of long lines.  However, the file is not entirely text file, there is some garbage.  To find my point of interest I'm using <code>hd</code> and <code>grep</code>.</p>

<p>So at some point I know it'm interested in e.g. 0000301a, so I want to quickly open the file in Vim and jump to that position.</p>

<p>Example (actually a tiny file, here the position is 0000001c):</p>

<pre><code>me@here:~$ hd file | grep -C 10 \ 00\ 
00000000  6c 69 6e 65 31 0a 6c 69  6e 65 32 0a 6c 69 6e 65  |line1.line2.line|
00000010  33 0a 6c 69 6e 65 34 0a  6c 69 6e 65 00 35 0a 6c  |3.line4.line.5.l|
00000020  69 6e 65 36 0a 6c 69 6e  65 37 0a 6c 69 6e 65 38  |ine6.line7.line8|
00000030  0a 6c 69 6e 65 39 0a 6c  69 6e 65 31 30 0a        |.line9.line10.|
0000003e
me@here:~$ 
</code></pre>

<p>Is there a trick in Vim to jump to a <em>byte position</em>?  Or as close as possible?</p>
","<p>Yes, there is. It's the normal mode command <code>go</code>.</p>

<p>From <a href=""http://vimdoc.sourceforge.net/htmldoc/motion.html#go""><code>:h go</code></a>:</p>

<blockquote>
  <p><strong>[count]go</strong> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Go to {count} byte in the buffer.</p>
</blockquote>

<p>For example, <code>42go</code> jumps to byte 42.</p>

<p>In order to jump to a hexadecimal or octal address you would need to construct a command with <code>:normal! go</code> or the equivalent <code>:goto</code>, and the <code>str2nr()</code> or <code>printf()</code> function.</p>

<pre><code>:exe 'normal! ' . str2nr('0x2a', 16) . 'go'
:exe 'goto' str2nr('0x2a', 16)
</code></pre>
","18238886"
"Are there binary literals in Java?","8804","","<p>I want to declare my integer number by a binary literal. Is it possible in Java?</p>
","<p>Look at this link:</p>

<p><a href=""http://en.wikibooks.org/wiki/Java_Programming/Literals/Numeric_Literals/Integer_Literals"" rel=""noreferrer"">http://en.wikibooks.org/wiki/Java_Programming/Literals/Numeric_Literals/Integer_Literals</a></p>

<p>In Java, you may enter integer numbers in several formats:</p>

<p><strong>1)</strong> As decimal numbers such as 1995, 51966. Negative decimal numbers such as -42 are actually expressions consisting of the integer literal with the unary negation operation.</p>

<p><strong>2)</strong> As octal numbers, using a leading 0 (zero) digit and one or more additional octal digits (digits between 0 and 7), such as 077. Octal numbers may evaluate to negative numbers; for example 037777777770 is actually the decimal value -8.</p>

<p><strong>3)</strong> As hexadecimal numbers, using the form 0x (or 0X) followed by one or more hexadecimal digits (digits from 0 to 9, a to f or A to F). For example, 0xCAFEBABEL is the long integer 3405691582. Like octal numbers, hexadecimal literals may represent negative numbers.</p>

<p><strong>4)</strong> Starting in J2SE 7.0, as binary numbers, using the form 0b (or 0B) followed by one or more binary digits (0 or 1). For example, 0b101010 is the integer 42. Like octal and hex numbers, binary literals may represent negative numbers.</p>

<p>If you do not have J2SE 7.0 use this:</p>

<pre><code>int val = Integer.parseInt(""001101"", 2);
</code></pre>
","10961097"
"Convert Python str/unicode object to binary/hex blob","8733","","<p>Is there an easy way to get some str/unicode object represented as a big binary number (or an hex one)?</p>

<p>I've been reading some answers to related questions but none of them works for my scenario.</p>

<p>I tried using the <a href=""http://docs.python.org/library/struct.html"" rel=""noreferrer"">struct</a> module from the <strong>STL</strong> but it didn't work as expected. Chars, like in binary files are displayed as, well chars.</p>

<p>Am I trying something impossible?</p>

<p>Example:</p>

<pre><code>def strbin(inp):
    # sorcery!
    return out

&gt;&gt; print strbin(""hello"")
# Any of these is cool (outputs are random keystrokes)
0b1001010101010000111001110001...
0xad9f...
</code></pre>
","<p>You could try <a href=""http://pypi.python.org/pypi/bitarray"" rel=""noreferrer""><code>bitarray</code></a>:</p>

<pre><code>&gt;&gt;&gt; import bitarray
&gt;&gt;&gt; b = bitarray.bitarray()
&gt;&gt;&gt; b.fromstring('a')
&gt;&gt;&gt; b
bitarray('01100001')
&gt;&gt;&gt; b.to01()
'01100001'
&gt;&gt;&gt; b.fromstring('pples')
&gt;&gt;&gt; b.tostring()
'apples'
&gt;&gt;&gt; b.to01()
'011000010111000001110000011011000110010101110011'
</code></pre>
","6728094"
"Go to a certain point of a binary file in C (using fseek) and then reading from that location (using fread)","8731","","<p>I am wondering if this is the best way to go about solving my problem. </p>

<p>I know the values for particular offsets of a binary file where the information I want is held...What I want to do is jump to the offsets and then read a certain amount of bytes, starting from that location.</p>

<p>After using google, I have come to the conclusion that my best bet is to use fseek() to move to the position of the offset, and then to use fread() to read an amount of bytes from that position.</p>

<p>Am I correct in thinking this? And if so, how is best to go about doing so? i.e. how to incorporate the two together.</p>

<p>If I am not correct, what would you suggest I do instead?</p>

<p>Many thanks in advance for your help.</p>

<p>Matt</p>

<p><em>Edit</em>:</p>

<p>I followed a tutorial on fread() and adjusted it to the following:</p>

<pre><code>    `#include &lt;stdio.h&gt;
    int main()
    {
      FILE *f;
      char buffer[11];
      if (f = fopen(""comm_array2.img"", ""rt""))
      {
        fread(buffer, 1, 10, f);
        buffer[10] = 0;
        fclose(f);
        printf(""first 10 characters of the file:\n%s\n"", buffer);
      }
      return 0;
    }`
</code></pre>

<p>So I used the file 'comm_array2.img' and read the first 10 characters from the file.</p>

<p>But from what I understand of it, this goes from start-of-file, I want to go from some-place-in-file (offset)</p>

<p>Is this making more sense?</p>

<p>Edit Number 2:</p>

<p>It appears that I was being a bit dim, and all that is needed (it would seem from my attempt) is to put the fseek() before the fread() that I have in the code above, and it seeks to that location and then reads from there.</p>
","<p>If you are using file streams instead of file descriptors, then you can write yourself a (simple) function analogous to the POSIX <a href=""http://pubs.opengroup.org/onlinepubs/9699919799/functions/pread.html"" rel=""nofollow""><code>pread()</code></a> system call.</p>

<p>You can easily emulate it using streams instead of file descriptors<sup>1</sup>. Perhaps you should write yourself a function such as this (which has a slightly different interface from the one I suggested in a comment):</p>

<pre><code>size_t fpread(void *buffer, size_t size, size_t mitems, size_t offset, FILE *fp)
{
     if (fseek(fp, offset, SEEK_SET) != 0)
         return 0;
     return fread(buffer, size, nitems, fp);
}
</code></pre>

<p>This is a reasonable compromise between the conventions of <code>pread()</code> and <code>fread()</code>.</p>

<hr>

<blockquote>
  <p>What would the syntax of the function call look like? For example, reading from the offset 732 and then again from offset 432 (both being from start of the file) and filestream called <code>f</code>.</p>
</blockquote>

<p>Since you didn't say how many bytes to read, I'm going to assume 100 each time.  I'm assuming that the target variables (buffers) are <code>buffer1</code> and <code>buffer2</code>, and that they are both big enough.</p>

<pre><code>if (fpread(buffer1, 100, 1, 732, f) != 1)
    ...error reading at offset 732...
if (fpread(buffer2, 100, 1, 432, f) != 1)
    ...error reading at offset 432...
</code></pre>

<p>The return count is the number of complete units of 100 bytes each; either 1 (got everything) or 0 (something went awry).</p>

<p>There are other ways of writing that code:</p>

<pre><code>if (fpread(buffer1, sizeof(char), 100, 732, f) != 100)
    ...error reading at offset 732...
if (fpread(buffer2, sizeof(char), 100, 432, f) != 100)
    ...error reading at offset 432...
</code></pre>

<p>This reads 100 single bytes each time; the test ensures you got all 100 of them, as expected.  If you capture the return value in this second example, you can know how much data you did get.  It would be very surprising if the first read succeeded and the second failed; some other program (or thread) would have had to truncate the file between the two calls to <code>fpread()</code>, but funnier things have been known to happen.</p>

<hr>

<p><sup>1</sup> The emulation won't be perfect; the <code>pread()</code> call provides guaranteed atomicity that the combination of <code>fseek()</code> and <code>fread()</code> will not provide.  But that will seldom be a problem in practice, unless you have multiple processes or threads concurrently updating the file while you are trying to position and read from it.</p>
","9863486"
"How to find all connected components in a binary image in Matlab?","8708","","<p>I have been trying to find all connected components using 8 neighbors in a binary image, without using the function ""bwlabel"".</p>

<p>For example, my input matrix is:</p>

<pre><code>a =

     1     1     0     0     0     0     0
     1     1     0     0     1     1     0
     1     1     0     0     0     1     0
     1     1     0     0     0     0     0
     0     0     0     0     0     1     0
     0     0     0     0     0     0     0
</code></pre>

<p>I would to have something like this:</p>

<pre><code>a =

     1     1     0     0     0     0     0
     1     1     0     0     2     2     0
     1     1     0     0     0     2     0
     1     1     0     0     0     0     0
     0     0     0     0     0     3     0
     0     0     0     0     0     0     0
</code></pre>

<p>There are 3 connected objects in this image.</p>
","<p>This is a common problem in image processing.  There are many variations, such as flood filling a region in an image, or finding what pixels belong to the same region.  One common approach is to use <a href=""http://en.wikipedia.org/wiki/Depth-first_search"" rel=""nofollow noreferrer"">depth first search</a>.  The idea is that you traverse your image from left to right and top to bottom and for any pixels encountered that are equal to 1, you add them to a stack.  For each pixel in your stack, you pop off the stack, then look at the neighbouring pixels that are surrounding this pixel.  Any pixels that are 1 you add to the stack.  You need to keep an additional variable where any pixels <strong>you have already visited</strong>, you don't add these to the stack.  When the stack is empty, we have found those pixels that are an entire region, so you mark these with a unique ID.  You then repeat this procedure until you run out of regions in your image.</p>

<p>As such, given that your matrix is stored in <code>A</code>, this is the basic algorithm:</p>

<ol>
<li><p>Initialize an array that's the same size as <code>A</code> that is <code>logical</code>.  This will record which pixels we have examined or visited.  Also initialize an output array <code>B</code> to all zeroes that gives you all of the connected components that you are seeking.  Any locations that are zero in the end don't belong to any connected components.  Also initialize an ID counter that keeps track of what connected component label each of these will have.</p></li>
<li><p>For each location that's in our matrix:</p>

<p>a. If the location is <code>0</code>, mark this location as visited and continue.</p>

<p>b. If we have already visited this location, then continue.</p>

<p>c. If we have not visited this location... go to Step #3.</p></li>
<li><p>Add this unvisited location to a stack.</p>

<p>a. While this stack is not empty...</p>

<p>b. Pop this location off of the stack</p>

<p>c. If we have visited this location, then continue.</p>

<p>d. Else, mark this location as visited and mark this location with the connected components ID.</p>

<p>e. Given this location, look at the 8 neighbouring pixels.</p>

<p>f. Remove those pixels in this list that have been visited, not equal to 1 or out of bounds of the matrix</p>

<p>g. Whatever locations are remaining, add these to the stack.</p></li>
<li><p>Once the stack is empty, increment the counter, then go back to Step #2.</p></li>
<li><p>Keep going until we have visited all of the locations in our array.</p></li>
</ol>

<p>Without further ado, here's the code.</p>

<hr>

<pre><code>%// Step #1
visited = false(size(A));
[rows,cols] = size(A);
B = zeros(rows,cols);
ID_counter = 1;

%// Step 2
%// For each location in your matrix...
for row = 1 : rows
    for col = 1 : cols
        %// Step 2a
        %// If this location is not 1, mark as visited and continue
        if A(row,col) == 0
            visited(row,col) = true;

        %// Step 2b
        %// If we have visited, then continue
        elseif visited(row,col)
            continue;

        %// Step 2c
        %// Else...
        else
            %// Step 3
            %// Initialize your stack with this location
            stack = [row col];

            %// Step 3a
            %// While your stack isn't empty...
            while ~isempty(stack)
                %// Step 3b
                %// Pop off the stack
                loc = stack(1,:);
                stack(1,:) = [];

                %// Step 3c
                %// If we have visited this location, continue
                if visited(loc(1),loc(2))
                    continue;
                end

                %// Step 3d
                %// Mark location as true and mark this location to be
                %// its unique ID
                visited(loc(1),loc(2)) = true;
                B(loc(1),loc(2)) = ID_counter;

                %// Step 3e
                %// Look at the 8 neighbouring locations
                [locs_y, locs_x] = meshgrid(loc(2)-1:loc(2)+1, loc(1)-1:loc(1)+1);
                locs_y = locs_y(:);
                locs_x = locs_x(:);

                 %%%% USE BELOW IF YOU WANT 4-CONNECTEDNESS
                 % See bottom of answer for explanation
                 %// Look at the 4 neighbouring locations
                 % locs_y = [loc(2)-1; loc(2)+1; loc(2); loc(2)];
                 % locs_x = [loc(1); loc(1); loc(1)-1; loc(1)+1];

                %// Get rid of those locations out of bounds
                out_of_bounds = locs_x &lt; 1 | locs_x &gt; rows | locs_y &lt; 1 | locs_y &gt; cols;

                locs_y(out_of_bounds) = [];
                locs_x(out_of_bounds) = [];

                %// Step 3f
                %// Get rid of those locations already visited
                is_visited = visited(sub2ind([rows cols], locs_x, locs_y));

                locs_y(is_visited) = [];
                locs_x(is_visited) = [];

                %// Get rid of those locations that are zero.
                is_1 = A(sub2ind([rows cols], locs_x, locs_y));
                locs_y(~is_1) = [];
                locs_x(~is_1) = [];

                %// Step 3g
                %// Add remaining locations to the stack
                stack = [stack; [locs_x locs_y]];
            end

            %// Step 4
            %// Increment counter once complete region has been examined
            ID_counter = ID_counter + 1;
        end
    end %// Step 5
 end   
</code></pre>

<p>With your example matrix, this is what I get for <code>B</code>:</p>

<pre><code>B =

     1     1     0     0     0     0     0
     1     1     0     0     2     2     0
     1     1     0     0     0     2     0
     1     1     0     0     0     0     0
     0     0     0     0     0     3     0
     0     0     0     0     0     0     0
</code></pre>

<hr>

<h1>To search in a 4-connected neighbourhood</h1>

<p>To modify the code to search in a 4-connected region, that is only North, East, West and South, the section where you see <code>%// Look at the 8 neighbouring locations</code>, that is:</p>

<pre><code> %// Look at the 8 neighbouring locations
 [locs_y, locs_x] = meshgrid(loc(2)-1:loc(2)+1, loc(1)-1:loc(1)+1);
 locs_y = locs_y(:);
 locs_x = locs_x(:);
</code></pre>

<p>To search in a 4-connected fashion, you simply have to modify this code to only give those cardinal directions:</p>

<pre><code> %// Look at the 4 neighbouring locations
locs_y = [loc(2)-1; loc(2)+1; loc(2); loc(2)];
locs_x = [loc(1); loc(1); loc(1)-1; loc(1)+1];
</code></pre>

<p>The rest of the code remains untouched.</p>

<h1>To match MATLAB's <code>bwlabel</code> function</h1>

<p>If you want to match the output of MATLAB's <a href=""https://www.mathworks.com/help/images/ref/bwlabel.html"" rel=""nofollow noreferrer""><code>bwlabel</code></a> function, <code>bwlabel</code> searches for connected components in column major or FORTRAN order.  The above code searches in row major or C order.  Therefore you simply have to search along columns first rather than rows as what the above code is doing and you do this by swapping the order of the two <code>for</code> loops.  </p>

<p>Specifically, instead of doing:</p>

<pre><code>for row = 1 : rows
    for col = 1 : cols
        ....
        ....
</code></pre>

<p>You would do:</p>

<pre><code>for col = 1 : cols
    for row = 1 : rows
        ....
        ....
</code></pre>

<p>This should now replicate the output of <code>bwlabel</code>.</p>
","26333226"
"How to get the binary code behind ASCII (C#)","8675","","<p>I'm trying to find out how to convert input to a console, into binary; how can such a conversion be made in C#?<br>
Thank you in advance.</p>
","<pre><code>string s = Console.ReadLine();
byte[] bytes = Encoding.ASCII.GetBytes(s);
</code></pre>

<p>Note that the encoding used by the console isn't actually ASCII... you should probably use <code>Console.InputEncoding</code> instead of <code>Encoding.ASCII</code></p>

<p>To get the binary representation of each byte, you can use <code>Convert.ToString</code>:</p>

<pre><code>foreach(byte b in bytes)
{
    Console.WriteLine(Convert.ToString(b, 2));
}
</code></pre>
","5578264"
"How to convert java BigDecimal to normal byte array (not 2's complement)","8671","","<p>How do I convert from  big integer to a byte array which is not in 2's complement format. Bascially I only need to convert positive numbers and do not need the sign bit.</p>

<p>So something like 10 would become a byte 0x0a i.e-> 00001010 </p>

<p><strong>[Update]</strong>
As per comment I tried this</p>

<pre><code>public void testBinary()
{
    BigDecimal test = new BigDecimal(35116031);
    BigInteger theInt = test.unscaledValue();
    byte[] arr = theInt.toByteArray();
    System.out.println(getCounterVal(arr, new BigInteger(""256"")));
}
public BigInteger getCounterVal(byte[] arr, BigInteger multiplier)
{
    BigInteger counter = BigInteger.ZERO;
    for(int i = (arr.length - 1); i &gt;=0; i--)
    {
        int b = arr[i];
        //int val = (int) b &amp; 0xFF;
        BigInteger augend = BigInteger.valueOf(b);
        counter = counter.add(augend.multiply(multiplier.pow(i)));
    }
    return counter;
}
</code></pre>

<p>The out put value I got was -19720446 And with the //int val = (int) b &amp; 0xFF; uncommented and used as augend, I got the value 4292024066</p>

<p><strong>[Update2]</strong>
Here is a test I ran which works. Not sure if it is bug free but looks fine.</p>

<pre><code>@Test
public void bigIntegerToArray()
{
    BigInteger bigInt = new BigInteger(""35116444"");
    byte[] array = bigInt.toByteArray();
    if (array[0] == 0)
    {
        byte[] tmp = new byte[array.length - 1];
        System.arraycopy(array, 1, tmp, 0, tmp.length);
        array = tmp;
    }

    BigInteger derived = BigInteger.ZERO;
    BigInteger twofiftysix = new BigInteger(""256"");
    int j = 0;
    for (int i = array.length - 1; i &gt;= 0; i--)
    {
        int val = (int) array[i] &amp; 0xFF;
        BigInteger addend = BigInteger.valueOf(val);
        BigInteger multiplier = twofiftysix.pow(j);
        addend = addend.multiply(multiplier);
        derived = derived.add(addend);
        j++;
    }

    Assert.assertEquals(bigInt, derived);
}
</code></pre>
","<p>The difference is largely conceptual. Unsigned numbers are the same in 2's compliment. 2's compliment just describes how to represent negative numbers which you say you don't have.</p>

<p>i.e. 10 is 00001010 in signed and unsigned representation.</p>

<p>To get the bytes from a BigDecimal or BigInteger you can use the methods it provides.</p>

<pre><code>BigDecimal test = new BigDecimal(35116031);
BigInteger theInt = test.unscaledValue();
byte[] arr = theInt.toByteArray();
System.out.println(Arrays.toString(arr));

BigInteger bi2 = new BigInteger(arr);
BigDecimal bd2 = new BigDecimal(bi2, 0);
System.out.println(bd2);
</code></pre>

<p>prints</p>

<pre><code>[2, 23, -45, -1]
35116031
</code></pre>

<p>The bytes are correct and reproduce the same value.</p>

<p>There is a bug in the way you rebuild your BigInteger.  You assume the byte serialization is little endian when Java typically uses big endian <a href=""http://en.wikipedia.org/wiki/Endianness"" rel=""noreferrer"">http://en.wikipedia.org/wiki/Endianness</a></p>
","6167724"
"Send binary file in HTTP response using C sockets","8641","","<p>I`m trying to send a binary file (png image) in http response.</p>

<pre><code>FILE *file;
char *buffer;
int fileLen;

//Open file
file = fopen(""1.png"", ""rb"");
if (!file)
{
    return;
}

//Get file length
fseek(file, 0, SEEK_END);
fileLen=ftell(file);
fseek(file, 0, SEEK_SET);

//Allocate memory
buffer=(char *)malloc(fileLen+1);
if (!buffer)
{
    fprintf(stderr, ""Memory error!"");
    fclose(file);
    return;
}

//Read file contents into buffer
fread(buffer, fileLen, 1, file);
fclose(file);
//free(buffer);




char header[102400];

sprintf(header, 
""HTTP/1.1 200 OK\n""
""Date: Thu, 19 Feb 2009 12:27:04 GMT\n""
""Server: Apache/2.2.3\n""
""Last-Modified: Wed, 18 Jun 2003 16:05:58 GMT\n""
""ETag: \""56d-9989200-1132c580\""\n""
""Content-Type: image/png\n""
""Content-Length: %i\n""
""Accept-Ranges: bytes\n""
""Connection: close\n""
        ""\n"", fileLen);

char *reply = (char*)malloc(strlen(header)+fileLen);
strcpy(reply, header);
strcat(reply, buffer);

printf(""msg %s\n"", reply);


//return 0;
int sd = socket(PF_INET, SOCK_STREAM, 0);

struct sockaddr_in addr;
bzero(&amp;addr, sizeof(addr));
addr.sin_family = AF_INET;
addr.sin_port = htons(8081);
addr.sin_addr.s_addr = INADDR_ANY;

if(bind(sd,&amp;addr,sizeof(addr))!=0)
{
    printf(""bind error\n"");
}

if (listen(sd, 16)!=0)
{
    printf(""listen error\n"");
}

for(;;)
{
    int size = sizeof(addr);
    int client = accept(sd, &amp;addr, &amp;size);

    if (client &gt; 0)
    {
        printf(""client connected\n"");
        send(client, reply, strlen(reply), 0);
    }
}
</code></pre>

<p>but my browser does not understand this =( What am I doing wrong exactly?</p>

<p>UPD: I tried to send text data - its OK. But binary data fails</p>
","<p>The problem is that your message body is being treated as a null-terminated text string (you use <code>strcat</code> and <code>strlen</code> on it), when it isn't one: it is binary data (a PNG file). Therefore, <code>strcat</code> and <code>strlen</code> both stop on the first 0 byte in the image (typically quite early).</p>

<p>Your program is even printing out the response body: notice that it gives the correct header, but that once the PNG header (binary data) starts, there is only a few bytes.</p>

<ol>
<li>The line <code>strcat(reply, buffer)</code>, where <code>buffer</code> potentially contains 0 bytes. Change it to <code>memcpy(reply+strlen(header), buffer, fileLen)</code>.</li>
<li>The line <code>send(client, reply, strlen(reply), 0)</code>, where <code>reply</code> potentially contains 0 bytes. Pre-calculate the length of the reply, or replace the strlen with <code>strlen(header)+fileLen</code>.</li>
</ol>

<p>Another bug is that you aren't closing the connection when you're done, so the browser will just wait forever. You need this, after <code>send</code>:</p>

<pre><code>close(client);
</code></pre>
","5496638"
"Binary representation of a number in Matlab","8610","","<p>Is there a Matlab function that returns the binary representation of a float number?</p>
","<p>In Matlab, one can use Java JDK functions.</p>

<p>The short answer for converting float (single precision 32-bit number) in Matlab to a binary string representation might be:</p>

<pre><code>flt=3.14
import java.lang.Integer java.lang.Float;
Integer.toBinaryString(Float.floatToIntBits(flt))
</code></pre>

<p>The long answer: conversion of float (single precision 32-bit number) in Matlab to a binary string representation</p>

<pre><code>function out=float2binstring(flt)
% converts a float number to binary in matlab according to IEEE754
%
% Usage:
% float2binstring(-3.14)
%
% http://www.h-schmidt.net/FloatApplet/IEEE754.html
%
% Limitations:
% Rounding errors: Not every decimal number can be expressed exactly as a     floating
% point number. This can be seen when entering ""0.1"" and examining its binary     representation which is either slightly smaller or larger, depending on the last bit. 
%
% Andrej Mosat, nospam@mosi.sk
% 03/2012
% v0.0
% License: GNU GPL
%
% See also: BINSTRING2FLOAT


% this is a trick to use java JDK should be installed, tested on Matlab R2010
import java.lang.Integer java.lang.Float;

if ( ~isnumeric(flt) )
    error('input must be a number');
end

out=Integer.toBinaryString(Float.floatToIntBits(flt));
end
</code></pre>

<p>And a conversion of binary string to float with a little overhead:</p>

<pre><code>function out=binstring2float(binstr)
    % converts a binary string to float number according to IEEE754
    %
    % Usage:
    % binstring2float('11000000010010001111010111000011')
    %   -3.14
    %
    % 
    % http://www.h-schmidt.net/FloatApplet/IEEE754.html
    %
    % Limitations:
    % Rounding errors: Not every decimal number can be expressed exactly as a floating
    % point number. This can be seen when entering ""0.1"" and examining its binary representation which is either slightly smaller or larger, depending on the last bit. 
    %
    % Andrej Mosat, nospam@mosi.sk
    % 03/2012
    % v0.0
    % License: GNU GPL
    %
    % See also: FLOAT2BINSTRING

    import java.lang.Long java.lang.Float;

    if isequal(class(binstr), 'java.lang.String')
            binstr=char(binstr);
    end

    if ( ~isstr(binstr) )
        error('input must be a binary string');                                             
    end
    % Error handling for binary strings should be added here

    % the sign is negative

    if binstr(2)=='1'
        binstr(2)='';
        isnegative=1;
    else
        isnegative=0;
    end

    out=Float.intBitsToFloat( Long.parseLong(  binstr  , 2) );
    if isnegative
     out=-out;
    end

end
</code></pre>
","9959752"
"Strategies for checking ISNULL on varbinary fields?","8590","","<p>In the past I've noted terrible performance when querying a varbinary(max) column. Understandable, but it also seems to happen when checking if it's null or not, and I was hoping the engine would instead take some shortcuts. </p>

<pre><code>select top 100 * from Files where Content is null
</code></pre>

<p>I would suspect that it's slow because it's</p>

<ol>
<li>Needing to pull the whole binary out, and</li>
<li>It's not indexed (varbinary can't be part of a normal index)</li>
</ol>

<p><a href=""https://stackoverflow.com/questions/2816096/efficiency-of-checking-for-null-varbinarymax-column"">This question</a> seems to disagree with my premise of slowness here, but I seem to have performance problems with binary fields time and time again.</p>

<p>One possible solution I thought of is to make a computed column that <em>is</em> indexed:</p>

<pre><code>alter table Files
add ContentLength as ISNULL(DATALENGTH(Content),0) persisted

CREATE NONCLUSTERED INDEX [IX_Files_ContentLength] ON [dbo].[Files] 
(
    [ContentLength] ASC
)

select top 100 * from Files where ContentLength = 0
</code></pre>

<p>Is that a valid strategy? What other ways are there to efficiently query when binary fields are involved?</p>
","<p>I think it's slow because the varbinary column is not (and can't be) indexed. Therefore, your approach to use a computed (and indexed) column is valid. </p>

<p>However, I would use <code>ISNULL(DATALENGTH(Content), -1)</code> instead, so that you can distinguish between length 0 and NULL. Or just use <code>DATALENGTH(Content)</code>. I mean, Microsoft SQL Server is not Oracle where an empty string is the same as NULL.</p>
","3775900"
"Difference between opening a file in binary vs text","8587","","<p>I've done some stuff like:</p>

<pre><code>FILE* a = fopen(""a.txt"", ""w"");
const char* data = ""abc123"";
fwrite(data, 6, 1, a);
fclose(a);
</code></pre>

<p>and then in the generated text file, it says ""abc123"" just like expected. But then I do:</p>

<pre><code>//this time it is ""wb"" not just ""w""
FILE* a = fopen(""a.txt"", ""wb"");
const char* data = ""abc123"";
fwrite(data, 6, 1, a);
fclose(a);
</code></pre>

<p>and get the exact same result. If I read the file using binary or normal mode, it also gives me the same result. So my question is, what is the difference between fopening with or without binary mode.</p>

<p>Where I read about fopen modes: <a href=""http://www.cplusplus.com/reference/cstdio/fopen/"" rel=""noreferrer"">http://www.cplusplus.com/reference/cstdio/fopen/</a></p>
","<p>The link you gave does actually describe the differences, but it's buried at the bottom of the page:</p>

<p><a href=""http://www.cplusplus.com/reference/cstdio/fopen/"">http://www.cplusplus.com/reference/cstdio/fopen/</a></p>

<blockquote>
  <p>Text files are files containing sequences of lines of text. <strong>Depending on the environment where the application runs, some special character conversion may occur in input/output operations in text mode to adapt them to a system-specific text file format</strong>. Although on some environments no conversions occur and both text files and binary files are treated the same way, using the appropriate mode improves portability.</p>
</blockquote>

<p>The conversion could be to normalize <code>\r\n</code> to <code>\n</code> (or vice-versa), or maybe ignoring characters beyond 0x7F (a-la 'text mode' in FTP). Personally I'd open everything in binary-mode and use a good text-encoding library for dealing with text.</p>
","20863975"
"How to edit raw PCM audio data without an audio library?","8557","","<p>I'm interested in precisely extracting portions of a PCM WAV file, down to the sample level.  Most audio modules seem to rely on platform-specific audio libraries.  I want to make this cross platform and speed is not an issue, are there any native python audio modules that can do this?</p>

<p>If not, I'll have to interpret the PCM binary.  While I'm sure I can dig up the PCM specs fairly easily, and raw formats are easy enough to walk, I've never actually dealt with binary data in Python before.  Are there any good resources that explain how to do this?  Specifically relating to audio would just be icing.</p>
","<p>I read the question and the answers and I feel that I must be missing something completely obvious, because nobody mentioned the following two modules:</p>

<ul>
<li><a href=""https://docs.python.org/library/audioop.html"" rel=""nofollow noreferrer"">audioop</a>: manipulate raw audio data</li>
<li><a href=""https://docs.python.org/library/wave.html"" rel=""nofollow noreferrer"">wave</a>: read and write WAV files</li>
</ul>

<p>Perhaps I come from a parallel universe and Guido's time machine is actually a space-time machine :)</p>

<p>Should you need example code, feel free to ask.</p>

<p>PS Assuming 48kHz sampling rate, a video frame at 24/1.001==23.976023976… fps is 2002 audio samples long, and at 25fps it's 1920 audio samples long.</p>
","841363"
"Store binary values in an array in C","8315","","<p>I wish to store some binary values in an array in C. How it can be done and how can i access any bit of a binary number.</p>

<p>Plz let me know if i i am unclear in posting the doubt.</p>
","<p>Store your values in a normal array and write a simple function that would pick proper element <em>and</em> state of its bit, something like</p>

<pre><code>int get_bit_from_array( unsigned char *A, int element, int bit ) {
    return A[element] &amp;  ( 1 &lt;&lt; bit ) ;                 
}
</code></pre>

<p>or even</p>

<pre><code>int get_bit_from_array( unsigned char *A, int bit_absolute) {
    int element = bit_absolute / 8;
    int bit = bit_absolute % 8;
    return A[element] &amp;  ( 1 &lt;&lt; bit ) ;                 
}
</code></pre>
","6943877"
"C# binary data conversion to string","8225","","<p>Here is the deal. I found a source code and changed it a little bit so i can retrieve data from a receiver that is on com6. The data i am receiving is binary. What i want is to convert it to a string so i can cut parts of the string and decode them seperately. how can i dot his?
The source code is beneath. </p>

<pre><code>using System;
using System.IO.Ports;
using System.Threading;

public class PortChat
{
    static bool _continue;
    static SerialPort _serialPort;

    public static void Main()
    {
        string name;
        string message;
        StringComparer stringComparer = StringComparer.OrdinalIgnoreCase;
        Thread readThread = new Thread(Read);

        // Create a new SerialPort object with default settings.
        _serialPort = new SerialPort();

        // Allow the user to set the appropriate properties.
        _serialPort.PortName = SetPortName(_serialPort.PortName);
        _serialPort.BaudRate = SetPortBaudRate(_serialPort.BaudRate);
        _serialPort.Parity = SetPortParity(_serialPort.Parity);
        _serialPort.DataBits = SetPortDataBits(_serialPort.DataBits);
        _serialPort.StopBits = SetPortStopBits(_serialPort.StopBits);
        _serialPort.Handshake = SetPortHandshake(_serialPort.Handshake);

        // Set the read/write timeouts
        _serialPort.ReadTimeout = 1000;
        _serialPort.WriteTimeout = 1000;

        _serialPort.Open();
        _continue = true;
        readThread.Start();

        Console.Write(""Name: "");
        name = Console.ReadLine();

        Console.WriteLine(""Type QUIT to exit"");

        while (_continue)
        {
            message = Console.ReadLine();

            if (stringComparer.Equals(""quit"", message))
            {
                _continue = false;
            }
            else
            {
                _serialPort.WriteLine(
                    String.Format(""&lt;{0}&gt;: {1}"", name, message));
            }
        }

        readThread.Join();
        _serialPort.Close();
    }

    public static void Read()
    {
        while (_continue)
        {

            try
            {             


                string message = _serialPort.ReadLine();
                Console.WriteLine(message);
            }
            catch (TimeoutException) { }
        }
    }

    public static string SetPortName(string defaultPortName)
    {
        string portName;

            portName = ""COM6"";

        return portName;
    }

    public static int SetPortBaudRate(int defaultPortBaudRate)
    {
        string baudRate;


        baudRate = ""9600"";

        return int.Parse(baudRate);
    }

    public static Parity SetPortParity(Parity defaultPortParity)
    {
        string parity;

        parity = ""None"";

        return (Parity)Enum.Parse(typeof(Parity), parity);
    }

    public static int SetPortDataBits(int defaultPortDataBits)
    {
        string dataBits;

        dataBits = ""8"";

        return int.Parse(dataBits);
    }

    public static StopBits SetPortStopBits(StopBits defaultPortStopBits)
    {
        string stopBits;

        stopBits = ""One"";

        return (StopBits)Enum.Parse(typeof(StopBits), stopBits);
    }

    public static Handshake SetPortHandshake(Handshake defaultPortHandshake)
    {
        string handshake;

        handshake = ""None"";

        return (Handshake)Enum.Parse(typeof(Handshake), handshake);
    }
}
</code></pre>
","<p>Data from ports will always come in binary(bytes), therefore it depends on how to interpret the data. Assuming that the bytes are ASCII, you can encode it to a string as follows:</p>

<pre><code>byte[] binaryData ; // assuming binaryData contains the bytes from the port.

string ascii =  Encoding.ASCII.GetString(binaryData);
</code></pre>
","6214496"
"C++ binary constant/literal","8218","","<p>I'm using a well known template to allow binary constants</p>

<pre><code>template&lt; unsigned long long N &gt;
struct binary
{
  enum { value = (N % 10) + 2 * binary&lt; N / 10 &gt; :: value } ;
};

template&lt;&gt;
struct binary&lt; 0 &gt;
{
  enum { value = 0 } ;
};
</code></pre>

<p>So you can do something like binary&lt;101011011>::value. Unfortunately this has a limit of 20 digits for a unsigned long long.</p>

<p>Does anyone have a better solution?</p>
","<p>Does this work if you have a leading zero on your binary value?  A leading zero makes the constant octal rather than decimal.</p>

<p>Which leads to a way to squeeze a couple more digits out of this solution - always start your binary constant with a zero! Then replace the 10's in your template with 8's.</p>
","699807"
"How to check whether the file is binary?","8204","","<p>I wrote the following method to see whether particular file contains ASCII text characters only or control characters in addition to that. Could you glance at this code, suggest improvements and point out oversights?</p>

<p>The logic is as follows: ""If first 500 bytes of a file contain 5 or more Control characters - report it as binary file""</p>

<p>thank you.</p>

<pre><code>public boolean isAsciiText(String fileName) throws IOException {

    InputStream in = new FileInputStream(fileName);
    byte[] bytes = new byte[500];

    in.read(bytes, 0, bytes.length);
    int x = 0;
    short bin = 0;

    for (byte thisByte : bytes) {
        char it = (char) thisByte;
        if (!Character.isWhitespace(it) &amp;&amp; Character.isISOControl(it)) {

            bin++;
        }
        if (bin &gt;= 5) {
            return false;
        }
        x++;
    }
    in.close();
    return true;
}
</code></pre>
","<p>Since you call this class ""isASCIIText"", you know exactly what you're looking for. In other words, it's not ""isTextInCurrentLocaleEncoding"".  Thus you can be more accurate with:</p>

<pre><code>if (thisByte &lt; 32 || thisByte &gt; 127) bin++;
</code></pre>

<p><em>edit, a long time later</em> &mdash; it's pointed out in a comment that this simple check would be tripped up by a text file that started with a lot of newlines. It'd probably be better to use a table of ""ok"" bytes, and include printable characters (including carriage return, newline, and tab, and possibly form feed though I don't think many modern documents use those), and then check the table.</p>
","3093643"
"Converting from 1Mbyte to Hex","8201","","<p>I am having problem understanding the following text,</p>

<blockquote>
  <p><code>8088</code> supports <code>1</code> Mbyte of external memory. This memory space is
  organized from a software point of view as individual bytes of data
  stored at consecutive address over the address range <code>00000</code> to <code>FFFFF</code>.</p>
</blockquote>

<p>Now I don't get how the author converted from 1 Mbyte to FFFFF. Can anyone please help me out?</p>

<p>Thanks.</p>
","<p>1 Megabyte is <code>2^20</code>.  That means that you need 20 bits to represent it.  The range <code>00000-FFFFF</code> holds all possible values of 20 bits.</p>
","10173875"
"(Qt C++) Write QString to file as Binary","8175","","<p>I am working on a project and I need to write (and in the future read) a string (QString) as binary. The string is in HEX format, like this ""00010203040506070a0f01"" etc...</p>

<p>I got this far through a tutorial on YouTube:</p>

<pre><code>void Output()
{
    QString ye(""01020a"");
    QFile file(""C:\\Users\\Public\\Documents\\Qt_Projects\\myfile.dat"";

    if(!file.open(QIODevice::WriteOnly))
    {
        qDebug() &lt;&lt; ""Could not open file to be written"";
        return;
    }

    QDataStream out(&amp;file);
    out.setVersion(QDataStream::Qt_5_0);

    out &lt;&lt; ye;

    file.flush();
    file.close();
   }
</code></pre>

<p>But when I open ""myfile.dat"" with a hex editor, the hex values are different, the QString ""ye"" was written to the text side of things. </p>

<pre><code>00 00 00 0C 00 30 00 31 00 30 00 32 00 30 00 61
</code></pre>

<p>Help?</p>
","<p>You should convert it before writing. </p>

<pre><code>QByteArray array = QByteArray::fromHex(ye.toLatin1());
file.write(array);
</code></pre>

<p>You don't need to use <code>QDataStream</code> since you already have <code>QByteArray</code> and can write it directly.</p>

<p>You can read and convert the data back to hex representation as follows:</p>

<pre><code>QString s = file.readAll().toHex();
</code></pre>
","17602950"
"Difference between a stripped binary and a non stripped binary in Linux","8175","","<p>Could anyone please explain me whats the actual difference between a stripped and a non-stripped binary in Linux ?</p>

<p>After a little bit of googling, I found that non-stripped binary contains the debugging info and stripped binary does'nt.</p>
","<p>Although you have found your answer from the Google. Just putting that , non-stripped binaries have debugging information built into it. So if you compile an executable with <code>gcc's -g</code> flag, it contains debugging information. Whereas Strip binaries  generally remove this debugging information from the exe which is not necessary for execution so as to reduce the size of the exe.</p>
","22682228"
"C: read binary file to memory, alter buffer, write buffer to file","8168","","<p><strong>The goal:</strong> 
Open a file with binary data, read the whole file into memory, change some parts oft he file, write the memory buffer to the file, close the file. Profit?</p>

<p><strong>The problem:</strong> 
I have just started learning C and I can't find enough information about how to change to binary data in the memory buffer. Coming from a web developer background (php, python, as3) this is new territory for me. </p>

<p><strong>The context:</strong> 
I have a function which takes the path to the file and a pointer adress to a char pointer memory buffer. It then opens the file, loops through the file and writes data to the memory buffer. Finally closes the file. </p>

<p>The purpose of the binary file is to hold category-ids for some objects and their position is their own id. The category-ids are represented as 2 byte shorts. So essentially it's just a binary file filled with lots of shorts that I want to be able to read and change. </p>

<p>Here's what I got so far:</p>

<p>main.c:</p>

<pre><code>#include ""binary-handler.h""

void showFileBuffer(char *buffer, unsigned int fileSize){
    int i = 0;
    for(; i &lt; fileSize; ++i){
        printf(""&lt;%d:%x&gt;\n"", i, ((char *)buffer)[i]);
    }
}

int main(){
    char path[] = ""assets/map-squares.bin"";
    char *buffer;
    int fileSize;
    fileSize = readFileToMemory(path, &amp;buffer);
    showFileBuffer(buffer, fileSize);

    //Code to change buffer
    //Code to write buffer to file
    return 0;
}
</code></pre>

<p>binary-handler.c:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

unsigned int getFileSize(FILE **file){
    unsigned int size;
    if(fseek(*file, 0, SEEK_END) == -1){ return -1; }
    size = ftell(*file);
    fseek(*file, 0, SEEK_SET);
    return size;
}

char *getFileBuffer(FILE **file, unsigned int fileSize){
    char *buffer = malloc(fileSize + 1);
    fread(buffer, fileSize, 1, *file);
    return buffer;
}

unsigned int readFileToMemory(char path[], char **buffer){
    unsigned int fileSize;

    FILE *file = fopen(path, ""rb"");
    if(file != NULL){
        fileSize = getFileSize(&amp;file);
        *buffer = getFileBuffer(&amp;file, fileSize);
        fclose(file);
        return fileSize;
    }else{
        *buffer = NULL;
        return -1;
    }
}
</code></pre>

<p><strong>1.</strong> Will this code produce the first step (reading file to memory) correctly?</p>

<p><strong>2.</strong> If yes, how can I change, say the 2nd object in the buffer to have a value of 0F 00?</p>

<p><strong>3.</strong> How can I take the buffer and write it back to the file?</p>

<p><strong>4.</strong> Is there a way for me to check the values in the buffer in a verbose way?</p>

<p><em>All in all I just want help with getting a grasp of the whole concept so I can solve this myself.</em> </p>

<p><strong>Thanks!</strong></p>

<p>Edit: Removed the looping of the file. Added a function which prints the whole buffer. </p>
","<p>1) No. You do not need to loop in <code>getFileBuffer</code> since you read the entire file with <code>fread</code>. You also do not need to call <code>fseek</code> because every time you read from the file you will advance within the file stream automatically. I haven't debugged your code, but it looks like by the time your loop completes, every element in buffer will contain the same value and it will be equal to whatever is the last byte in your file.</p>

<p>Note: The arguments your specified for fread are backwards. The second parameter is the size of the type you are reading which should be <code>sizeof(char)</code>. The third parameter should be the amount of chars you want to read which should be <code>fileSize</code>. Your code still works, though, but it is saying it wants to read <code>1</code> object that is <code>fileSize</code> bytes long when you are reading <code>fileSize</code> objects that are <code>1</code> byte long.</p>

<p>2) You can read the second short value like this (in little endian):</p>

<pre><code>short n = 0;
n |= buffer[2] &lt;&lt; 0;
n |= buffer[3] &lt;&lt; 8;
</code></pre>

<p>You can write the short back to the file like this:</p>

<pre><code>buffer[2] = n &gt;&gt; 0;
buffer[3] = n &gt;&gt; 8;
</code></pre>

<p>3) <code>fwrite</code></p>

<p><s>4) I don't understand what you are asking.</s></p>
","5134530"
"Java: How to output all possible binary combinations (256 different sequences)?","8142","","<p>I need to create a function that outputs all possible binary combinations (2^8 == 256 different sequences of 8 bits.). I'm really stumped on this. I have to do it with nested loops, and am not sure how to go about it. Below is what I tried so far. I was told that I could write this program using 8 nested loops, each one going from 0 to 1; Also, I could try to do this with bit manipulation operators. </p>

<p>Although what I have below is obviously wrong, I tried my best to show that I at least tried this. I also need to put new line's after each closing bracket, to separate the output.</p>

<p><strong>The output should look like this:</strong></p>

<p>00000000</p>

<p>00000001</p>

<p>00000010</p>

<p>00000011</p>

<p>00000100</p>

<p>...</p>

<p>11111110</p>

<p>11111111</p>

<pre><code>public static void outputBinary(){

int[][][][][][][][] num = new int[2][2][2][2][2][2][2][2];

    for (int i = 0; i &lt; 2; i++){

    for (int j = 0; j &lt; 2; j++){

    for (int k = 0; k &lt; 2; k++){

    for (int l = 0; l &lt; 2; l++){

    for (int m = 0; m &lt; 2; m++){

    for (int n = 0; n &lt; 2; n++){

    for (int o = 0; o &lt; 2; o++){

    for (int p = 0; p &lt; 2; p++){

        System.out.print(num[i][j][k][l][m][n][o][p]);

    } }}}}}}}
</code></pre>

<p>}</p>

<p><strong>Thanks for looking.</strong></p>
","<p>No need for the array. Here is a slight modification to your code that will output all the permutations.</p>

<pre><code>for (int i = 0; i &lt; 2; i++){
  for (int j = 0; j &lt; 2; j++){
    for (int k = 0; k &lt; 2; k++){
      for (int l = 0; l &lt; 2; l++){
        for (int m = 0; m &lt; 2; m++){
          for (int n = 0; n &lt; 2; n++){
            for (int o = 0; o &lt; 2; o++){
              for (int p = 0; p &lt; 2; p++){
                System.out.println("""" + i + j + k + l + m + n + o + p);
              }
            }
          }
        }
      }
    }
  }
}
</code></pre>

<p>Do you <em>have</em> to use nested loops? Because this is trivially easy when you simply take advantage of the fact that the binary representation of all the numbers from 0 through 255 cover every permutation.</p>

<pre><code>for (int i=0; i&lt;256; i++) {
    System.out.println(Integer.toBinaryString(i));
}
</code></pre>
","22208618"
"Reading bytes one by one from binary file","8135","","<p>this is my question, i want to open a .jpg file and write each byte as a decimal number (0-255) separated with a comma, into another .txt file. now it should be able to build the .jpf file again using that txt file. this is how i tried to do it.</p>

<pre><code>#include&lt;iostream&gt;
#include&lt;fstream&gt;
using namespace std;
int main()
{
long x;
char *s;

ifstream ifs(""image.jpg"",ios::binary);
ifs.seekg(0,ios::end);
x=ifs.tellg();
ifs.seekg(0,ios::beg);

s=new char[x];
ifs.read(s,x);
ifs.close();

ofstream is(""image.txt"");

for(int i=0;i&lt;x;i++){
is&lt;&lt;(unsigned int)s[i]&lt;&lt;"","";
}
</code></pre>

<p>now this program creats image.txt with decimal numbers as follows,
 4294967295,4294967256,4294967295,4294967264,0,16,74,70,73,70,0,1,......
here some numbers seems to be 4bytes long, s[i] refers only one byte, so how can (int)s[i] return a large number than 255. please can some one help me on this.... thanks..</p>
","<p>It seems on your machine <code>char</code> is <em>signed</em>. So when you cast a negative number to <code>unsigned int</code>, you get a big value. The big values in the output are negative values when representing them using <code>char</code>. Note that when <code>char</code> is <em>signed</em>, its value can be <code>-128</code> to <code>127</code> but a <em>byte</em> can be between <code>0</code> to <code>255</code>. So any value greater than <code>127</code> would become negative between the range <code>-128 to -1</code>.</p>

<p>Use <code>unsigned char</code> as:</p>

<pre><code>unsigned char *s;
</code></pre>

<p>Or do this:</p>

<pre><code>is&lt;&lt; static_cast&lt;unsigned int&gt; (static_cast&lt;unsigned char&gt;(s[i]) )&lt;&lt;"","";
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                                casting to unsigned char first
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
               then casting to unsigned int 
</code></pre>

<p>That is, cast first <code>char</code> to <code>unsigned char</code>, then to <code>unsigned int</code>.</p>

<hr>

<p>Well that is all about the issue you're facing. Now some notes on style and idioms. In C++, you should avoid using <code>new</code> as much as possible. In your case, you can use <code>std::vector</code> as:</p>

<pre><code>//define file stream object, and open the file
std::ifstream file(""image.jpg"",ios::binary);

//prepare iterator pairs to iterate the file content!
std::istream_iterator&lt;unsigned char&gt; begin(file), end;

//reading the file content using the iterator!
std::vector&lt;unsigned char&gt; buffer(begin,end);
</code></pre>

<p>The last line reads all the  data from the file into <code>buffer</code>. Now you can print them as:</p>

<pre><code>std::copy(buffer.begin(), 
          buffer.end(), 
          std::ostream_iterator&lt;unsigned int&gt;(std::cout, "",""));
</code></pre>

<p>For all these to work, you need to include the following headers in addition to what you have already added in your code:</p>

<pre><code>#include &lt;vector&gt;     //for vector
#include &lt;iterator&gt;   //for std::istream_iterator and std::ostream_iterator
#include &lt;algorithm&gt;  //for std::copy
</code></pre>

<p>As you can see, this idiomatic solution doesn't use <em>pointer</em> and <code>new</code>, neither does it use <em>cast</em>!</p>
","11435466"
"Create DES key from 56 bit binary string","8108","","<p>I have a 56 bit binary string that i want to use as the secret key for DES encryption.</p>

<p>I found the following code at the JCA docs website </p>

<pre><code>byte[] desKeyData = { (byte)0x01, (byte)0x02, (byte)0x03, 
(byte)0x04, (byte)0x05, (byte)0x06, (byte)0x07, (byte)0x08 };
DESKeySpec desKeySpec = new DESKeySpec(desKeyData);
SecretKeyFactory keyFactory = SecretKeyFactory.getInstance(""DES"");
SecretKey secretKey = keyFactory.generateSecret(desKeySpec);
</code></pre>

<p>However this uses 8 bytes for the key (instead of 7). It is not clear if the desKeyData[0] corresponds to the least significant byte or the most significant one. Also, is it possible to use the 56 bit string directly to generate the byte array that can be used for this purpose ?</p>
","<p>From <a href=""http://en.wikipedia.org/wiki/Data_Encryption_Standard"" rel=""noreferrer"">Wikipedia</a>:</p>

<blockquote>
  <p>The key ostensibly consists of 64 bits; however, only 56 of these are actually used by the algorithm. Eight bits are used solely for checking parity, and are thereafter discarded. Hence the effective key length is 56 bits, and it is never quoted as such. Every 8th bit of the selected key is discarded, i.e. positions 8, 16, 24, 32, 40, 48, 56, 64 are removed from the 64 bit key leaving behind only the 56 bit key.</p>
</blockquote>

<p>So, the least significant bits (i.e. 0th bits) are not used for key construction, they can be used for checking parity by <code>DESKeySpec.isParityAdjusted()</code>.</p>

<p><strong>EDIT:</strong> Simple test showing that the least significant bits are ignored:</p>

<pre><code>SecretKeyFactory sf = SecretKeyFactory.getInstance(""DES"");
byte[] in = ""test"".getBytes(""UTF-8"");

Cipher c1 = Cipher.getInstance(""DES"");
c1.init(Cipher.ENCRYPT_MODE, sf.generateSecret(new DESKeySpec(
   new byte[] {0x10,0x20,0x30,0x40,0x50,0x60,0x70,(byte) 0x80})));
byte[] r1 = c1.doFinal(in);

Cipher c2 = Cipher.getInstance(""DES"");
c2.init(Cipher.ENCRYPT_MODE, sf.generateSecret(new DESKeySpec(
    new byte[] {0x11,0x21,0x31,0x41,0x51,0x61,0x71,(byte) 0x81})));
byte[] r2 = c2.doFinal(in);

assertArrayEquals(r1, r2);  
</code></pre>
","4985827"
"Check if only one single bit is set within an integer (whatever its position)","8067","","<p>I store flags using bits within a 64-bits integer.<br>
I want to know if there is a single bit set whatever the position within the 64-bits integer (e.i. I do not care about the position of any specific bit).</p>

<pre><code>boolean isOneSingleBitSet (long integer64)
{
   return ....;
}
</code></pre>

<p>I could count number of bits using the <a href=""http://graphics.stanford.edu/~seander/bithacks.html"" rel=""nofollow noreferrer""><em>Bit Twiddling Hacks</em> (by Sean Eron Anderson)</a>, but I am wondering what is the most efficient way to just detect whether one single bit is set...</p>

<p>I found some other related questions:</p>

<ul>
<li><a href=""https://stackoverflow.com/questions/3007541/8051-check-if-a-single-bit-is-set"">(8051) Check if a single bit is set</a></li>
<li><a href=""https://stackoverflow.com/questions/462609/detecting-single-one-bit-streams-within-an-integer"">Detecting single one-bit streams within an integer</a></li>
</ul>

<p>and also some Wikipedia pages:</p>

<ul>
<li><a href=""http://en.wikipedia.org/wiki/Find_first_one"" rel=""nofollow noreferrer"">Find first one</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Bit_manipulation"" rel=""nofollow noreferrer"">Bit manipulation</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Hamming_weight#Efficient_implementation"" rel=""nofollow noreferrer"">Hamming weight</a></li>
</ul>

<p>NB: my application is in java, but I am curious about optimizations using other languages...</p>

<hr>

<p><strong>EDIT</strong>: <a href=""https://stackoverflow.com/users/995714"">Lưu Vĩnh Phúc</a> pointed out that my first link within my question already got the answer: see section <a href=""http://graphics.stanford.edu/~seander/bithacks.html#DetermineIfPowerOf2"" rel=""nofollow noreferrer"">Determining if an integer is a power of 2</a> in the <em>Bit Twiddling Hacks</em> (by Sean Eron Anderson). I did not realized that <strong><em>one single bit</em></strong> was the same as <strong><em>power of two</em></strong>.</p>
","<p>If you just literally want to check if one single bit is set, then you are essentially checking if the number is a power of 2. To do this you can do:</p>

<pre><code>if ((number &amp; (number-1)) == 0) ...
</code></pre>

<p>This will also count 0 as a power of 2, so you should check for the number not being 0 if that is important. So then:</p>

<pre><code>if (number != 0 &amp;&amp; (number &amp; (number-1)) == 0) ...
</code></pre>
","13420373"
"Binary Java 7 for Mac","8056","","<p>Is there any binary release of Java 7 (using the Mac/BSD-port project) anywhere?  Some blogs (e.g. <a href=""http://infernus.org/2009/02/building-java-7-on-mac-os-x/"" rel=""noreferrer"">Building Java 7 on Mac OS X</a>) have a detailed instructions to build the jdk from source, but I was hoping that someone have a binary of it available for download.</p>

<p>The problem with the instructions is that it's quite annoying to get all the version numbers correct, and slight variations might lead to wasted hours of work.</p>
","<p>This just got released by Oracle: <a href=""http://jdk7.java.net/macportpreview/"" rel=""nofollow"">http://jdk7.java.net/macportpreview/</a></p>
","7653771"
"Binary search algorithm with string array","8050","","<p>The program is supposed to search for a name in a string array. Originally, the program was adapted to the int data type but changed to string. I tried to modify the code to make it run and it does, but I do not get the correct output. There is something wrong with my binary search function. My binary search function has not been correctly edited to suit the change in data type from int to string. It will not function since I have strings in the array instead of int which it was originally created for. Everything else seems to work correctly.</p>

<p>This is the output I get. </p>

<blockquote>
  <p>Please enter an employee's name: <strong>Looney</strong></p>
  
  <p>That name does that exist in the array.</p>
</blockquote>

<p>Technically, I am supposed to get the message that it exists and what position it does. </p>

<pre><code>// This program demonstrates the binarySearch function, which
// performs a binary search on an integer array.

#include ""stdafx.h""
#include &lt;iostream&gt;
#include &lt;string&gt; 
using namespace std;

// Function prototype
void sortArray(string [], int); 
int binarySearch(string [], int, string);
const int SIZE = 20;

int main()
{
    // Defined array 
    const int NUM_NAMES = 20;
    string names[NUM_NAMES] = {""Collins, Bill"", ""Smith, Bart"", ""Allen, Jim"",
                               ""Griffin, Jim"", ""Stamey, Marty"", ""Rose, Geri"",
                               ""Taylor, Terri"", ""Johnson, Jill"", ""Allison, Jeff"",
                               ""Looney, Joe"", ""Wolfe, Bill"", ""James, Jean"",
                               ""Weaver, Jim"", ""Pore, Bob"", ""Rutherford, Greg"",
                               ""Javens, Renee"", ""Harrison, Rose"", ""Setzer, Cathy"",
                               ""Pike, Gordon"", ""Holland, Beth"" };

    // Variables 
    string empName; 
    int results;  

    // Sort array first
    sortArray(names, NUM_NAMES); 

    // Prompt for user input to enter an employee name 
    cout &lt;&lt; ""Please enter an employee's name: ""; 
    getline(cin, empName); 

    // Search for name
    results = binarySearch(names, NUM_NAMES, empName); 

    // If results contains -1 the name was not found.
    if (results == -1)
        cout &lt;&lt; ""That name does not exist in the array.\n"";
    else
    {
        // Otherwise results contains the subscript of
        // the specified employee ID in the array.
        cout &lt;&lt; ""That name is found at element "" &lt;&lt; results;
        cout &lt;&lt; "" in the array.\n"";
    }

    system(""PAUSE""); 

    return 0;
}

//**************************************************************
// Definition of function sortArray.                           *
// This function performs an ascending order selection sort on *
// array. size is the number of elements in the array.         *
//**************************************************************
void sortArray(string names[], int size)
{
    int startScan, minIndex; 
    string minValue;

    for (startScan = 0; startScan &lt; (size - 1); startScan++)
    {
        minIndex = startScan;
        minValue = names[startScan];
        for(int index = startScan + 1; index &lt; size; index++)
        {
            if (names[index] &lt; minValue)
            {
                minValue = names[index];
                minIndex = index;
            }
        }
        names[minIndex] = names[startScan];
        names[startScan] = minValue;
    }
}

//***************************************************************
// The binarySearch function performs a binary search on an     *
// integer array. array, which has a maximum of size elements,  *
// is searched for the number stored in value. If the number is *
// found, its array subscript is returned. Otherwise, -1 is     *
// returned indicating the value was not in the array.          *
//***************************************************************
int binarySearch(string names[], int size, string value)
{
    int first = 0,             // First array element
        last = size - 1,       // Last array element
        middle,                // Mid point of search
        position = -1;         // Position of search value
    bool found = false;        // Flag

    while (!found &amp;&amp; first &lt;= last)
    {
        middle = (first + last) / 2;     // Calculate mid point
        if (names[middle] == value)      // If value is found at mid
        {
            found = true;
            position = middle;
        }
        else if (names[middle] &gt; value)  // If value is in lower half
            last = middle - 1;
        else
            first = middle + 1;           // If value is in upper half
    }
    return position;
}
</code></pre>
","<p>Because name <code>Looney</code> does not exist in the array.</p>

<p>You should input <code>Looney, Joe</code> to get the expected output.</p>

<p>Input is bad, otherwise your implementation appear good.</p>
","29642417"
"Writing a binary buffer to a file in python","8005","","<p>I have some python code that:</p>

<ol>
<li>Takes a BLOB from a database which is compressed.</li>
<li>Calls an uncompression routine in C that uncompresses the data.</li>
<li>Writes the uncompressed data to a file.</li>
</ol>

<p>It uses <a href=""http://docs.python.org/library/ctypes.html"" rel=""nofollow noreferrer"">ctypes</a> to call the C routine, which is in a shared library.</p>

<p>This mostly works, except for the actual writing to the file. To uncompress, I get the data uncompressed into a python buffer, created using the ctypes <code>create_string_buffer</code> method:</p>

<p><code>c_uncompData_p = create_string_buffer(64000)</code></p>

<p>so the uncompression call is like this:</p>

<p><code>c_uncompSize = mylib.explodeCharBuffer (c_data_p, c_data_len, c_uncompData_p)</code></p>

<p>The size of the resulting uncompressed data is returned as the return value.</p>

<p>But... I have no idea how to force python on only write <code>c_uncompSize</code> bytes out - if I do:</p>

<p><code>myfile.write (c_uncompData_p.raw)</code></p>

<p>it writes the whole 64k buffer out (the data is binary - so it is not null terminated).</p>

<p>So, my question is - using Python 2.5 how do I get c_uncompSize bytes printed out, rather than the whole 64k?</p>

<p>Thanks
Jamie</p>
","<p>Slicing works for c_char_Arrays too:</p>

<pre><code>myfile.write(c_uncompData_p[:c_uncompSize])
</code></pre>
","652565"
"GCC Error: Invalid operands to binary +","7995","","<p>Why is GCC giving me this error ? What am I doing wrong here ?</p>

<pre><code> temp.c: In function main:
 temp.c:6: error: invalid operands to binary +
</code></pre>

<p>Code:</p>

<pre><code> main()
 {
     char *Address1,*Address2,*NewAddress;
     Address1= (char*)0x12;
     Address2= (char*)0x34;
     NewAddress = Address1+Address2;
 }
</code></pre>
","<p>Why do you want to do that?</p>

<p><strong>The C language forbids addition of two pointers</strong>. It only defines (with severe restrictions) the addition of a pointer and an integer. </p>

<p>Basically, you can only add to a pointer an integer small enough so that the result was inside, or at the ending border, of some allocated memory zone.</p>
","8579513"
"Should I use Base64 encoding or byte[] for returning binary data in .NET web service","7983","","<p>I have a simple question. Should I return a byte-array or simply base64 encode my binary data, when exposing it through a web service in .NET?
Is there any pros/cons with either method, which is mostly supported etc.</p>
","<p>Use byte array. Over a SOAP protocol this byte array will automatically be serialized using base64 encoding. Your web service will be also more descriptive if you use a byte array. Imagine someone who wants to consume your web service and looking at a method whose signature looks like this:</p>

<pre><code>string GetBinaryImageFromDatabase();
</code></pre>

<p>He might wonder why does this method returns a string and what am I going to do with this string, while if it returns a byte array it is much more clear.</p>

<p>I've seen web service method that look like this:</p>

<pre><code>string SaveCustomer(string customer);
</code></pre>

<p>Guess what the <code>customer</code> and the return types were: they were some proprietary XML. There's absolutely no sense of using SOAP if people reinvent protocols over it.</p>
","2521899"
"Read in Raw Binary Image in Python","7982","","<p>I have a very simple script in Matlab that opens a 'raw' binary image file and displays it.  Is this easily reproducible using numpy in python?  I've come across various posts discussing unpacking, dealing with endian, specifying buffers, etc.  But this seems like it should be simple, based on how simple the matlab interface is</p>

<pre><code>&gt;&gt; fileID = fopen('sampleX3.raw','rb')

fileID =

     1

&gt;&gt; A = fread(fileID,[1024,1024],'int16');
size(A)

ans =

        1024        1024

&gt;&gt; max(max(A))

ans =

       12345

&gt;&gt; close all; figure; imagesc(A);
</code></pre>
","<p>This will do the same thing using numpy and matplotlib:</p>

<pre><code>import numpy as np
from matplotlib import pylab as plt

A = np.fromfile(filename, dtype='int16', sep="""")
A = A.reshape([1024, 1024])
plt.imshow(A)
</code></pre>

<p>I feel obligated to mention that using raw binary files to store data is generally a bad idea.</p>
","17479412"
"Sending binary data to (Rails) RESTful endpoint via JSON/XML?","7961","","<p>I am currently putting together a rails-based web application which will only serve and receive data via json and xml. However, some requirements contain the ability to upload binary data (images).</p>

<p>Now to my understanding JSON is not entirely meant for that... but how do you in general tackle the problem of receiving binary files/data over those two entrypoints to your application? </p>
","<p>I suggest encoding the binary data in something like base64. This would make it safe to use in XML or JSON format. </p>

<p><a href=""http://en.wikipedia.org/wiki/Base64"" rel=""noreferrer"">http://en.wikipedia.org/wiki/Base64</a></p>
","426702"
"python adding binary number","7949","","<p>There is an unexpected output when I am dealing with binary number in Python 3.</p>

<p>We can easily convert any integer to binary by built-in bin() function. For example:</p>

<pre><code>&gt;&gt;&gt;bin(4243125)
</code></pre>

<p>Here's the issue when I try to add 2 binary function:</p>

<pre><code>&gt;&gt;&gt;bin(x)+bin(y)
</code></pre>

<p>The output is concatenation of two binary number, not addition of binary number. The output of binary function has become a string.</p>

<p>Addition in a binary function works fine:</p>

<pre><code>&gt;&gt;&gt;bin(x+y)
</code></pre>

<p>And try to add two binary number without bin() is viable too:</p>

<pre><code>&gt;&gt;&gt;0b100+0b10111
</code></pre>

<p>What is the reasons/purposes of setting a bin() output to a string? </p>
","<p><code>bin</code>, like <code>hex</code>, converts a decimal to a string literal representing the number in that base.</p>

<p>If you want to add 2 numbers together simply do so:</p>

<pre><code>x = 10
y = 2
x + y
</code></pre>

<p>If you want to take binary strings as input and add them together convert them back from string literals with <code>int</code> base 2, like this:</p>

<pre><code>x = bin(10)
y = bin(2)
int(x, 2) + int(y, 2)
</code></pre>

<p>If you're looking to do bitwise operations look at the Python bitwise operators:</p>

<p><a href=""https://wiki.python.org/moin/BitwiseOperators"" rel=""nofollow"">https://wiki.python.org/moin/BitwiseOperators</a></p>
","25106105"
"Optimising binary serialization for multi-dimensional generic arrays","7939","","<p>I have a class that I need to binary serialize. The class contains one field as below:</p>

<pre><code>private T[,] m_data;
</code></pre>

<p>These multi-dimensional arrays can be fairly large (hundreds of thousands of elements) and of any primitive type. When I tried standard .net serialization on an object the file written to disk was large and I think .net is storing a lot of repeated data about element types and possibly not as efficiently as could be done.</p>

<p>I have looked around for custom serializers but have not seen any that deal with multi-dimensional generic arrays. I have also experimented with built-in .net compression on a byte array of the memory stream following serializing with some success, but not as quick / compressed as I had hoped.</p>

<p>My question is, should I try and write a custom serializer to optimally serialize this array for the appropriate type (this seems a little daunting), or should I use standard .net serialization and add compression?</p>

<p>Any advice on the best approach would be most appreciated, or links to resources showing how to tackle serialization of a multi-dimensional generic array - as mentioned <a href=""http://www.codeproject.com/KB/dotnet/FastSerializer.aspx"" rel=""noreferrer"">existing examples</a> I have found do not support such structures.</p>
","<p>Here's what I came up with.  The code below makes an int[1000][10000] and writes it out using the BinaryFormatter to 2 files - one zipped and one not.  </p>

<p>The zipped file is 1.19 MB (1,255,339 bytes)
Unzipped is 38.2 MB (40,150,034 bytes)</p>

<pre><code>        int width = 1000;
        int height = 10000;
        List&lt;int[]&gt; list = new List&lt;int[]&gt;();
        for (int i = 0; i &lt; height; i++)
        {
            list.Add(Enumerable.Range(0, width).ToArray());
        }
        int[][] bazillionInts = list.ToArray();
        using (FileStream fsZ = new FileStream(""c:\\temp_zipped.txt"", FileMode.Create))
        using (FileStream fs = new FileStream(""c:\\temp_notZipped.txt"", FileMode.Create))
        using (GZipStream gz = new GZipStream(fsZ, CompressionMode.Compress))
        {
            BinaryFormatter f = new BinaryFormatter();
            f.Serialize(gz, bazillionInts);
            f.Serialize(fs, bazillionInts);
        }
</code></pre>

<p>I can't think of a better/easy way to do this.  The zipped version is pretty damn tight.</p>

<p>I'd go with the BinaryFormatter + GZipStream.  Making something custom would not be fun at all.</p>

<hr>

<p>[edit by MG]
I hope you won't be offended by an edit, but the uniform repeated Range(0,width) is skewing things vastly; change to:</p>

<pre><code>        int width = 1000;
        int height = 10000;
        Random rand = new Random(123456);
        int[,] bazillionInts = new int[width, height];
        for(int i = 0 ; i &lt; width;i++)
            for (int j = 0; j &lt; height; j++)
            {
                bazillionInts[i, j] = rand.Next(50000);
            }
</code></pre>

<p>And try it; you'll see <code>temp_notZipped.txt</code> at 40MB, <code>temp_zipped.txt</code> at 62MB. Not so appealing...</p>
","224008"
"How can I write binary data to disk in VBScript?","7929","","<p>I have a binary string that I need to write to a file. I have a feeling that this <em>should</em> be a simple procedure, but then again, VBScript. The <code>FileSystemObject</code> is of no help, since it munges the data. The <code>Stream</code> object looks promising, with it's <code>adBinaryMode</code> and its <code>Write</code> method, but the <code>Write</code> method requires a byte array and won't seem to accept a variant array instead. Since VBScript arrays are <em>all</em> variant arrays, this seems problematic.</p>

<p>So, how do I just write the data to a file?</p>

<p>EDIT: I should add that the whole thing has to be VBScript. No extra components. Sorry, I don't like it either.</p>
","<p>It's also possible with the ordinary <code>FileSystemObject</code>, here is code I'm using in custom upload script that I wrote long time ago using code I found online that converts binary string to ASCII:</p>

<pre><code>Set objFSO = Server.CreateObject(""Scripting.FileSystemObject"")
Set objFile = objFSO.CreateTextFile(""file path here"")
objFile.Write(RSBinaryToString(strBinaryContents))
objFile.Close
Set objFile=Nothing
Set objFSO=Nothing

Private Function RSBinaryToString(xBinary)
    'Antonin Foller, http://www.motobit.com
    'RSBinaryToString converts binary data (VT_UI1 | VT_ARRAY Or MultiByte string)
    'to a string (BSTR) using ADO recordset

    Dim Binary
    'MultiByte data must be converted To VT_UI1 | VT_ARRAY first.
    If vartype(xBinary)=8 Then Binary = MultiByteToBinary(xBinary) Else Binary = xBinary

    Dim RS, LBinary
    Const adLongVarChar = 201
    Set RS = CreateObject(""ADODB.Recordset"")
    LBinary = LenB(Binary)

    If LBinary&gt;0 Then
        RS.Fields.Append ""mBinary"", adLongVarChar, LBinary
        RS.Open
        RS.AddNew
        RS(""mBinary"").AppendChunk Binary 
        RS.Update
        RSBinaryToString = RS(""mBinary"")
    Else  
        RSBinaryToString = """"
    End If
End Function

Function MultiByteToBinary(MultiByte)
    '© 2000 Antonin Foller, http://www.motobit.com
    ' MultiByteToBinary converts multibyte string To real binary data (VT_UI1 | VT_ARRAY)
    ' Using recordset
    Dim RS, LMultiByte, Binary
    Const adLongVarBinary = 205
    Set RS = CreateObject(""ADODB.Recordset"")
    LMultiByte = LenB(MultiByte)
    If LMultiByte&gt;0 Then
        RS.Fields.Append ""mBinary"", adLongVarBinary, LMultiByte
        RS.Open
        RS.AddNew
        RS(""mBinary"").AppendChunk MultiByte &amp; ChrB(0)
        RS.Update
        Binary = RS(""mBinary"").GetChunk(LMultiByte)
    End If
    MultiByteToBinary = Binary
End Function
</code></pre>
","5612798"
"C++ Converting binary data to a hex string and back","7899","","<p>I have a matching pair of static functions in a utility class that I use to convert between binary data (unsigned characters) and it's string representation (a-f and 0-9). They seemed to work correctly but recently I tried to compile my code under Visual C++ (2010 Express) and to my dismay, they cause nothing but heap corruption errors. What am I doing wrong?</p>

<pre><code>void Utility::string_to_binary(const std::string source, unsigned char* destination, unsigned int length)
{
    unsigned int effective_length = min(length, (unsigned int) source.length() / 2);
    for(unsigned int b = 0; b &lt; effective_length; b++)
    {
        sscanf(source.data() + (b * 2), ""%02x"", (unsigned int*) &amp;destination[b]);
    }
}

void Utility::binary_to_string(const unsigned char* source, unsigned int length, std::string&amp; destination)
{
    destination.clear();
    for(unsigned int i = 0; i &lt; length; i++)
    {
        char digit[3];
        sprintf(digit, ""%02x"", source[i]);
        destination.append(digit);
    }
}
</code></pre>

<p><strong>Edit: Here's a complete program that illustrates the problem.</strong></p>

<pre><code>#include &lt;iostream&gt;
#include &lt;hdcs/Utility.h&gt;

using namespace std;

int main(int argc, char* argv[])
{
    //Generate some data
    unsigned int size = 1024;
    unsigned char* data = new unsigned char[size];

    //Convert it to it's string representation
    string hex;
    Utility::binary_to_string(data, size, hex);

    //Output it to the screen
    cout &lt;&lt; hex &lt;&lt; endl;

    //Clear the data buffer
    memset(data, 0, sizeof(unsigned char) * size);

    //Convert the hex string back to binary
    Utility::string_to_binary(hex, data, size);

    //Cleanup
    delete[] data;
}
</code></pre>

<p>The error occurs on <code>delete[] data</code>.</p>
","<p>In this code, </p>

<pre><code>for(unsigned int b = 0; b &lt; effective_length; b++)
{
    sscanf(source.data() + (b * 2), ""%02x"", (unsigned int*) &amp;destination[b]);
}
</code></pre>

<p>you seem to be writing an <code>unsigned int</code> at locations <code>destination</code>, <code>destination+1</code>, <code>destination+2</code>, &amp;c. As you approach the final bytes of your <code>destination</code> buffer, you will write beyond its limit.</p>

<p>For the sake of example, let us assume that destination is a four-byte buffer, and that <code>sizeof (unsigned int)</code> is 4 in your environment.  Then each <code>sscanf</code> is writing four bytes.</p>

<p>The first iteration writes bytes 0, 1, 2, 3</p>

<p>The second iteratino writes bytes 1, 2, 3, 4</p>

<p>The third iteration writes bytes 2, 3, 4, 5</p>

<p>The final iteration writes bytes 3, 4, 5, 6</p>

<p>Since the buffer was only four bytes to start with, you have written beyond the end of your buffer. Boom.</p>

<p><hr />
<strong>EDIT</strong></p>

<p>The minimum change required to avoid this particular bug follows:</p>

<pre><code>for(unsigned int b = 0; b &lt; effective_length; b++)
{
    unsigned int ui;
    sscanf(source.data() + (b * 2), ""%02x"", &amp;ui);
    destination[b] = ui;
}
</code></pre>
","7363929"
"Efficient storage of binary files in a git repository","7895","","<p>I would like to have a git repository that consists mainly of binary files. </p>

<p>I need to keep track of the changed, added and removed files to the repository, but I don't want for git to version the content of the files themselves.</p>

<p>In other words, I just need for git to keep track of changes (change log), but not the content.</p>

<p>Is this even possible with git?</p>

<p>Should I be using something else for this?</p>
","<p>git is a content tracker, so if you don't want to track content it sounds like it's the wrong tool for the job. I'm not sure exactly how you would track changes to files without tracking their content, though.</p>
","799519"
"how to read and write float numbers from and into binary files?","7873","","<p>How to read and write float numbers from and into binary files? in C or Vala language?
The common APIs to do writings and readings are generally designed to write in byte format. I mean you have to write arrays of one-byte data into file and read in the same format.</p>

<p>I'm looking for a way to write and read in float format. without typecasting and without having to change the number into string. Is it possible?</p>
","<p>fwrite() and fread() or write() and read() will work just fine. </p>

<pre><code>float da, db ;
    ...
fwrite( &amp;da, 1, sizeof(da), fpout ) ;
    ...
fread( &amp;db, 1, sizeof(db), fpin ) ;
</code></pre>
","4465303"
"Generating a 10000 bit random sequence","7860","","<p>Is there a more efficient way to generate a 10 kBit (10,000 bits) random binary sequence in Python than appending 0s and 1s in a loop?</p>
","<p>If you want a random binary sequence then it's probably quickest just to generate a random integer in the appropriate range:</p>

<pre><code>import random
s = random.randint(0, 2**10000 - 1)
</code></pre>

<p>After this it really depends on what you want to do with your binary sequence. You can query individual bits using bitwise operations:</p>

<pre><code>s &amp; (1 &lt;&lt; x)  # is bit x set?
</code></pre>

<p>or you could use a library like <a href=""http://pypi.python.org/pypi/bitarray/"" rel=""noreferrer"">bitarray</a> or <a href=""http://code.google.com/p/python-bitstring/"" rel=""noreferrer"">bitstring</a> if you want to make checking, setting slicing etc. easier:</p>

<pre><code>from bitstring import BitArray
b = BitArray(uint=s, length=10000)
p, = b.find('0b000000')
if b[99]:
    b[100] = False
...
</code></pre>
","13922797"
"Starting binary input with 0s in a cell","7857","","<p>First up, I'm not sure if this is the right place to ask this or not, so if it's not please let me know.</p>

<p>Ok so,I'm working on a project that deals with numbers in the binary format as inputs, however, when the input let's say begins with ""00"" or any number of 0s, it discards it in Excel so I was wondering how to force excel to accept 0s at the beginning of a binary input</p>
","<p>I found the simplest solution after working with Excel this past week.</p>

<p>To include leading 0s, I should select the cell containing my decimal number and simply use the dec2bin function in Excel and define how many bits I want to output to be.</p>

<p>=DEC2BIN([number or cell reference],[#bits])</p>

<p>So if you enter ""=DEC2BIN(A1,8)"" in the formula bar, and the value of A1 is 15, the value output will be 00001111.</p>
","28884226"
"Write a ""string"" as raw binary into a file Python","7849","","<p>I'm trying to write a series of files for testing that I am building from scratch. The output of the data payload builder is of type string, and I'm struggling to get the string written directly to the file. </p>

<p>The payload builder only uses hex values, and simply adds a byte for each iteration. </p>

<p>The 'write' functions I have tried all either fall over the writing of strings, or write the ASCII code for the string, rather than the string its self...  </p>

<p>I want to end up with a series of files - with the same filename as the data payload (e.g. file ff.txt contains the byte 0xff</p>

<pre><code>def doMakeData(counter):
    dataPayload = ""%X"" %counter
    if len(dataPayload)%2==1:
        dataPayload = str('0') + str(dataPayload)
    fileName = path+str(dataPayload)+"".txt""
    return dataPayload, fileName

def doFilenameMaker(counter):
    counter += 1
    return counter

def saveFile(dataPayload, fileName):
    # with open(fileName, ""w"") as text_file:
          # text_file.write(""%s""%dataPayload)  #this just writes the ASCII for the string
    f = file(fileName, 'wb')
    dataPayload.write(f) #this also writes the ASCII for the string
    f.close()
    return

if __name__ == ""__main__"":
    path = ""C:\Users\me\Desktop\output\\""
    counter = 0
    iterator = 100
    while counter &lt; iterator:
        counter = doFilenameMaker(counter)
        dataPayload, fileName = doMakeData(counter)
        print type(dataPayload)
        saveFile(dataPayload, fileName)
</code></pre>
","<p>To write just a byte, use <code>chr(n)</code> to get a byte containing integer <code>n</code>.</p>

<p>Your code can be simplified to:</p>

<pre><code>import os
path = r'C:\Users\me\Desktop\output'
for counter in xrange(100):
    with open(os.path.join(path,'{:02x}.txt'.format(counter)),'wb') as f:
        f.write(chr(counter))
</code></pre>

<p>Note use of raw string for the path.  If you had a '\r' or '\n' in the string they would be treated as a carriage return or linefeed without using a raw string.</p>

<p><code>f.write</code> is the method to write to a file.  <code>chr(counter)</code> generates the byte.  Make sure to write in binary mode <code>'wb'</code> as well.</p>
","12024441"
"PHP: Show JPG from Binary","7842","","<p>I have a jpg blob thats been stored in an external DB and I'm looking to display that as an image via php. The issue is whenever I set the <code>Content-Type</code> to <code>image/jpeg</code> and echo out the blob I get the broken image icon when browsing to it.</p>

<p>I have tried making the file from scratch via sublime and that works when I save it as a hexadecimal file so I know the data is valid.</p>

<p>I have tried making the script create a file but it sets the <code>charset=us-ascii</code> so it won't get seen as a image file.</p>

<p>Does anyone have any experience with raw image binary files? anyone know how I can display the image or even save it out to a file?</p>

<p>Thanks in advance.</p>

<p>P.S. I would provide the binary but its just too big to put on here.</p>

<p>EDIT: (added some code)</p>

<pre><code>&lt;?php
header('Content-Type: image/jpeg;');

$data = 'some long string of hex';


// tried echoing it directly..
echo $data;

// and writing to a file...
file_put_contents('test.jpg', $data);
?&gt;
</code></pre>
","<p>After continuing research I found this post <a href=""https://stackoverflow.com/questions/5662779/php-create-file-from-an-hex-string"">PHP: create file from an HEX string</a> </p>

<p>With the following code I fixed the issue.</p>

<pre><code>&lt;?php
header('Content-Type: image/jpeg;');

$data = 'The hex data';

$data = pack('H*',$data);

$im = imagecreatefromstring($data);

imagejpeg($im);

?&gt;
</code></pre>
","18949819"
"Java binary literals - Value -128 for byte","7833","","<p>Since SE 7 Java allows to specify values as binary literal. The documentation tells me 'byte' is a type that can hold 8 Bit of information, the values -128 to 127.</p>

<p>Now i dont know why but i cannot define 8 bits but only 7 if i try to assign a binary literal to a byte in Java as follows:</p>

<pre><code>byte b = 0b000_0000;    //solves to the value 0
byte b1 = 0b000_0001;   //solves to the value 1
byte b3 = 0b000_0010;   //solves to the value 2
byte b4 = 0b000_0011;   //solves to the value 3     
</code></pre>

<p>And so on till we get to the last few possibilitys using those 7 bits:</p>

<pre><code>byte b5 = 0b011_1111;   //solves to the value 63
byte b6 = 0b111_1111;   //solves to the value 127
</code></pre>

<p>If i want to make it negative numbers i have to add a leading - in front like this:</p>

<pre><code>byte b7 = -0b111_1111;   //solves to the value -127
</code></pre>

<p>Now half of the problem i have is that i use just 7 bits to describe what they tell me is a 8 bit data type. Second half is that they dont seem to be threaded as twos complement unless using a 32bit int type where i can define all of the 32 bits (""sign indicator bit"" included). </p>

<p>Now when i search on how to display the in-range number -128 i was told to do it this way without any further explanation:</p>

<pre><code>byte b8 = 0b1111_1111_1111_1111_1111_1111_1000_0000;
</code></pre>

<p>I can clearly see that the last 8 Bit (1000 0000) do represent -128 in twos compelment using 8 Bit, still i never was confused more and try to ask my questions:</p>

<ul>
<li>Isnt the above 32 bit long nr a 32 Bit (java-) int value?</li>
<li>Why can i assign a 32 bit value to a 8 bit (java-) byte type? </li>
</ul>

<p><strong>Or in general: Why do i have to assign it this way?</strong></p>

<p>Any links/ informations about this would be great!
Thank you for the time you took to read this as well as any further information in advance.</p>

<p>Regards
Jan</p>
","<p>According to the Java Specification,</p>

<p><a href=""http://docs.oracle.com/javase/specs/jls/se7/html/jls-3.html#jls-3.10.1"">http://docs.oracle.com/javase/specs/jls/se7/html/jls-3.html#jls-3.10.1</a></p>

<p><em>all</em> your declarations (b, b1,..., and b8) use <strong>int</strong> literals, even when they would fit in a byte. There's no byte literal in Java, you can only use an int to initialize a byte.</p>

<p>I did some tests and <code>byte neg128 = -0b1000_0000;</code> works fine. <code>0b1000_0000</code> is 128, so you just need to put a <code>-</code> sign before it. Notice that that <code>1</code> <strong>is not a sign bit</strong> at all (don't think about 8-bit bytes, think about 32-bit ints converted to bytes). So if you want to specify the sign bit you need to write all 32 bits, as you have demonstrated.</p>

<p>So <code>byte b8 = 0b1000_0000;</code> is an error just like <code>byte b8 = 128;</code> is an error (+128 does not fit in a byte). You can also force the conversion with a cast:</p>

<p><code>byte b = (byte) 0b1000_0000;</code>
or
<code>byte b = (byte) 128;</code></p>

<p>The cast tells the compiler that you know 128 does not fit in a byte and the bit-pattern will be reinterpreted as -128.</p>
","18900325"
"C Binary Tree Insertion Recursively","7824","","<p>So I'm trying to insert a value into a binary tree using this recursive function:</p>

<pre><code>void add(node* *hd, int v){
node* curr = *hd;
if(curr == NULL){
    curr = (node*)malloc(sizeof(node));
    curr-&gt;value = v;
}else{
    if(v &lt; curr-&gt;value){
        add(&amp;curr-&gt;left, v);
    }else{
        add(&amp;curr-&gt;right, v);
    }
}
}
</code></pre>

<p>It doesn't seem to be working, and I just don't understand why I can't do something like this. How would I go about fixing it?</p>

<p>Thanks in advance</p>
","<p>You need to initilize the pointers, as they probably will be set to whatever you get when allocating space. Right now when you pass <code>add(&amp;curr-&gt;left, v);</code> <code>curr-&gt;left</code> may not be a pointer somewhere but it is still not <code>NULL</code>;</p>

<pre><code>void add(node* *hd, int v){
    node* curr = *hd;
    if(curr == NULL){
        curr = malloc(sizeof(node));
        curr-&gt;left = curr-&gt;right = NULL;
        curr-&gt;value = v;
        *hd = curr; // from Mohamed KALLEL
    }else{
        if(v &lt; curr-&gt;value){
            add(&amp;curr-&gt;left, v);
        }else{
            add(&amp;curr-&gt;right, v);
        }
    }
}
</code></pre>
","13607931"
"CoreData (for iphone) storing images","7773","","<p>i wonder if its a wise choice to store images with core data into binary property</p>

<p>say i have a collection of movies and i want to save the image dvd cover into a property the avg size of a cover is 20/30kb (320x480px)</p>

<p>the reason i want to do this is for storage management, once i delete the movie i know the image is also deleted</p>

<p>i'm just not quite sure if it's a good idea, data load, speed?</p>

<p>anyone has experience with this ?</p>
","<p>It seems to me that storing images in a core data isn't a good idea, and I'm pretty sure I've also read it on one of Apple's programming guides. Just consider this, when you fetch your collection, all the images will also be loaded into memory, even if you're only displaying 8 images, your entire image collection will be loaded by core data.</p>

<p>If you want to make sure you delete the image files when a move record was deleted I suggest you listen to notifications by the managedObjectContext and delete files when a movie was deleted:</p>

<p>You can either register for the willSave or didSave notification, each with it's own advantages/disadvantages.</p>

<pre><code>    [[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(contextDidSave:) name:NSManagedObjectContextDidSaveNotification object:managedObjectContext];
</code></pre>

<p>Getting the deleted objects: </p>

<pre><code>- (void) contextDidSave:(NSNotification *)notification
{
    NSDictionary *userInfo = [notification userInfo];
    for (NSManagedObject *currObject in [userInfo objectForKey:NSDeletedObjectsKey])
    {
         // Code for deleting file associated with the NSManagedObject, you can still
         // access the managed object's properties.
    }
}
</code></pre>
","2131864"
"What is the simplest way to write to stdout in binary mode?","7759","","<p>I've been trying to figure out the best way to write binary data to stdout from a C program. It works fine on Linux, but I'm having issues when I compile on Windows because ""\n"" gets converted to ""\r\n"".</p>

<p>Is there a standard way to write to stdout in some sort of binary mode which avoids newline conversion? If not, what is the simplest way to get Windows to stop doing this?</p>

<p>I'm using GCC and MinGW.</p>
","<p>You can use <code>setmode(fileno(stdout), O_BINARY)</code></p>

<p>Wrap it in an ifdef if you want to keep it compatible with Linux.</p>

<p>See also  <a href=""http://msdn.microsoft.com/en-us/library/tw4k6df8(v=vs.80).aspx"" rel=""noreferrer"">http://msdn.microsoft.com/en-us/library/tw4k6df8(v=vs.80).aspx</a></p>
","16888382"
"Bash script containing binary executable","7743","","<p>Is it possible to write a bash script, which would contain a binary executable program inside?</p>

<p>I mean a script, which would contain a dump of an executable in a textual form, which will be dumped back to an executable by this script when it is executed?</p>

<p>I would love to know a solution, which will work out of the box without a need of installing additional packages. Is it possible?</p>

<p>Thanks!</p>
","<p>i never done something like this before ;)
this will compile some c source, create a <code>b.bash</code> script containing the binary (and the original script for simple development)</p>

<p>(a.bash)</p>

<pre><code>#!/bin/bash

if [ ""$0"" == ""b.bash"" ];then
  tail -n +$[ `grep -n '^BINARY' $0|cut -d ':' -f 1` + 1 ] $0 | base64 -d &gt; a2.out
  chmod +x a2.out
  ./a2.out
  echo $?
  exit
fi

cat ""$0"" &gt; b.bash
echo ""BINARY"" &gt;&gt; b.bash
cat &gt; a.c &lt;&lt; EOF
int     main(){
        return 12;
}
EOF
gcc a.c 
base64 a.out &gt;&gt; b.bash
</code></pre>

<p>invoke with (a.bash generates b.bash):</p>

<pre><code>bash a.bash ;bash b.bash
</code></pre>

<p>i don't know how to evade writing out the binary into a temporary file before execution...</p>
","18410939"
"How did we get this real number in binary?","7735","","<p>from <a href=""http://community.topcoder.com/tc?module=Static&amp;d1=tutorials&amp;d2=integersReals"" rel=""nofollow"">this article</a>:</p>

<p>the number 5.125 (binary 101.001) why? 101 is 5  , but how are decimal places converted?</p>

<p>Also from that article -  a bias is added to the actual exponent e. </p>

<p>What is bias? What is the purpose of it?</p>
","<p>See <a href=""http://floating-point-gui.de/formats/binary/"" rel=""nofollow"">the Floating-Point guide</a> for a detailed explanation of how binary fractions work.</p>

<blockquote>
  <p>What is bias? What is the purpose of it?</p>
</blockquote>

<p>A <a href=""http://en.wikipedia.org/wiki/Exponent_bias"" rel=""nofollow"">biased exponent</a> is used because it allows floating-point numbers to compared for value exactly like integer numbers, i.e. if a bit pattern A is greater than a bit pattern B when interpreted as integer, the same is always true if you interpret the patters as floating-point numbers.</p>
","7604377"
"Text with binary code","7724","","<p>The binary code for HELLO is 0100100001000101010011000100110001001111** but I can't found how to convert for example A in binary code.  </p>

<p>How can I convert it and make a word like WORLD because I don't see free spaces in the binary code for HELLO?  </p>

<p>For example <em>WORLD</em>, what is <em>W</em>, what is <em>O</em>, what is <em>R</em> ....  </p>

<p>Should I add something between the different codes (for example: if W is 1010101, O - 000101, R - 1010111, L - 100001, D - 111111 Is it <strong>1010101</strong><em>000101</em><strong>1010111</strong><em>100001</em><strong>111111</strong> WORLD? )</p>
","<p>The binary representation of a string is entirely dependent on its <a href=""http://en.wikipedia.org/wiki/Character_encoding"" rel=""nofollow"">encoding</a>. If you want to use the simple <a href=""http://en.wikipedia.org/wiki/Ascii"" rel=""nofollow"">ASCII</a> case (one byte per character), then all you need to do is look up the hex code for the character you care about, 0x41 for 'A' for instance. From this point, converting it to a binary sequence is trivial. It's important to note that things like <a href=""http://en.wikipedia.org/wiki/Endianness"" rel=""nofollow"">Endianness</a> comes into play with the actual binary representation. </p>

<p>For an encoding such as UTF-8, UNICODE, or a multi-byte encoding, the process is less straight forward and you'd be better off using a library function to get the binary representation.</p>
","15646367"
"C++ writing to a Binary file with ofstream","7708","","<p>For a small file format I'm developing I need to output a header of 519 bytes to a file. I'm a bit new to the whole ofstream concept. Though I have some experience with reading the header of a Truevision Targa file. But output is something I'm far lees familiar with.</p>

<p>So basically, here is my problem.</p>

<p>I opened an instance of ofstream, and I need to output a header like so:</p>

<pre><code>typedef struct header {
    char      version;   // offset 0, length 1
    short int width;     // offset 1, length 2
    short int height;    // offset 3, length 2
    short int pathlen;   // offset 5, length 2
    char      desc[512]; // offset 7, length 512
} fileHeader;
</code></pre>

<p>Now I need to get all of this in the first 519 bytes of a file, the rest of the content varies, how would I go around copying this header into my file?</p>

<p>I preferably want to do this using the ofstream class, but I'm also fine with the original C library. I've been at this for 2 hours now, and I've not gotten anywhere yet and trying to search on Google doesn't help much either.</p>
","<pre><code>std::ofstream&amp; operator&lt;&lt;(std::ofstream&amp; out, const header&amp; myheader) {
    out.write((char*)&amp;myheader.version, sizeof(myheader.version));
    out.write((char*)&amp;myheader.width, sizeof(myheader.width));
    out.write((char*)&amp;myheader.height, sizeof(myheader.height));
    out.write((char*)&amp;myheader.pathlen, sizeof(myheader.pathlen));
    out.write((char*)&amp;myheader.desc, sizeof(myheader.desc));
    return out;
}
std::ifstream&amp; operator&gt;&gt;(std::ifstream&amp; in, header&amp; myheader) {
    in.read((char*)&amp;myheader.version, sizeof(myheader.version));
    in.read((char*)&amp;myheader.width, sizeof(myheader.width));
    in.read((char*)&amp;myheader.height, sizeof(myheader.height));
    in.read((char*)&amp;myheader.pathlen, sizeof(myheader.pathlen));
    in.read((char*)&amp;myheader.desc, sizeof(myheader.desc));
    return in;
}

int main() {
    std::cout &lt;&lt; fileHeader &lt;&lt; '\n';
    std::cin &gt;&gt; fileHeader;
    return 0;
}
</code></pre>

<p>Since you have no pointers, it's fairly easy!  (Note this only works with narrow streams)<br>
Another example to show things with text, and dynamic memory/pointers/etc</p>

<pre><code>class thing {
    std::string name;
    int height;
    friend std::ofstream&amp; operator&lt;&lt;(std::ofstream&amp; out, const thing &amp; myheader);
    friend std::ifstream&amp; operator&gt;&gt;(std::ifstream&amp; in, thing &amp; myheader);
public: 
    thing() {}
};

std::ofstream&amp; operator&lt;&lt;(std::ofstream&amp; out, const thing &amp; myheader) {
    thing &lt;&lt; name.size() &lt;&lt; ' ';
    thing.write(&amp;name[0], name.size()) &lt;&lt; ' ' &lt;&lt; height;
} 
std::ifstream&amp; operator&gt;&gt;(std::ifstream&amp; in, thing &amp; myheader) {
    int size;
    in &gt;&gt; size;
    myheader.name.resize(size);
    in.read(&amp;myheader.name[0], name.size());
    return in &gt;&gt; myheader.height;        
} 
</code></pre>
","7935430"
"How to read bits from a file?","7708","","<p>I know how to read bytes — <code>x.read(number_of_bytes)</code>, but how can I read bits in Python?</p>

<p>I have to read only 5 bits (not 8 bits [1 byte]) from a binary file</p>

<p>Any ideas or approach?</p>
","<p>Python can only read a byte at a time. You'd need to read in a full byte, then just extract the value you want from that byte, e.g.</p>

<pre><code>b = x.read(1)
firstfivebits = b &gt;&gt; 3
</code></pre>

<p>Or if you wanted the 5 least significant bits, rather than the 5 most significant bits:</p>

<pre><code>b = x.read(1)
lastfivebits = b &amp; 0b11111
</code></pre>

<p>Some other useful bit manipulation info can be found here: <a href=""http://wiki.python.org/moin/BitManipulation"">http://wiki.python.org/moin/BitManipulation</a></p>
","10689798"
"Unary ""~"" operator - What exactly is happening here?","7695","","<p>I recently did a Java course (1 week crash course), and we covered some binary mathematics.</p>

<p>This unary ~ operator (tilde I think it's called?) was explained to us thus:</p>

<p><em>It inverts the bit pattern turning every ""0"" into a ""1"" and every ""1"" into a ""0"". 
e.g. There are 8 bits to a byte.  If you have the following byte: 00000000 the inverted value would change to become 11111111.</em></p>

<p>The above explanation is clear and concise, and totally makes sense to me.  Until, that is, I try to implement it.</p>

<p>Given this:</p>

<pre><code>byte x = 3;
byte y = 5;
System.out.println(~x);
System.out.println(~y);
</code></pre>

<p>The output is:</p>

<pre><code>-4  
-6
</code></pre>

<p>I'm very confused about how this happens.</p>

<p>If +3 in binary is 11, then the inversion of this would be 00, which clearly isn't -3.</p>

<p>But as there are 8 bits in a byte, then shouldn't the binary representation of +3 be written as 00000011?</p>

<p>Which would invert to become 11111100.  Converted back to decimal value this would be 252.
If however you write the +3 as 011, then it does indeed convert to 100, which is +4, but then how do you know it's a negative number?</p>

<p>How about if you try 0011, which converts to 1100, which if you use the first bit as a sign, then it does indeed become -4.</p>

<p>Ah - so at this point I thought I was getting somewhere.  </p>

<p>But then I got to the second value of y = 5.</p>

<p>How do we write this?  Using the same logic, +5 converts to binary 0101, which inverts to 1010. </p>

<p>And it's around now that I'm horribly confused.  This looks to represent either a signed value of -2, or an unsigned value of +10 decimal?  Neither of which are the -6 I'm getting printed out.</p>

<p>Again, if I increase the length up to the 8 digits of a byte, +5 is 00000101, which inverted becomes 11111010.  And I really can't find a way to turn this into -6. </p>

<p>Does anyone out there understand this, as I have no idea what is happening here and the more numbers I print out the more confused I become.</p>

<p>Google doesn't seem to come up with anything much on this - maybe it doesn't like looking at little operator signs..   :-(</p>
","<p>From wikipedia:  In two's complement notation, a non-negative number is represented by its ordinary binary representation; in this case, the most significant bit is 0. The two's complement operation is the negation operation, so negative numbers are represented by the two's complement of the absolute value.<br>
To get the two's complement of a binary number, the bits are inverted, or ""flipped"", by using the bitwise NOT operation; the value of 1 is then added to the resulting value, ignoring the overflow which occurs when taking the two's complement of 0. <a href=""http://en.wikipedia.org/wiki/Two%27s_complement"" rel=""nofollow"">http://en.wikipedia.org/wiki/Two%27s_complement</a></p>

<p>So if you have 0101 which is +5 the inverse of that is 1010, which is -5. </p>

<p>You don't really read the 010 as a 5 though, but when you see the 1 at the beginning, you know that to get the number you have to invert the rest of the digits again to get the positive number which you want to negate.  If that makes sense.</p>

<p>It's a bit of an alien concept if you have not worked with it before. It's certainly not the way that decimal numbers work, but it is actually simple once you see what happening. </p>

<p>A value of 8 decimal is written as 01010, which negates to 10101.  The first digit (1) means it's negative, and then you flip the rest back to get the numeric value: 1010.  </p>

<p>One thing to remember is that Two's complement is not the same as ordinary old binary system counting.  In normal binary the value of 10101 (which in Two's complement is -8 as above) is of course 21.  I guess this is where the confusion comes - how do you tell the difference by looking at them?  You must know which representation has been used in order to decide what the value of the number actually is.  There is also One's complement which differs slightly.</p>

<p>A good tutorial on binary maths, including One's and Two's complement is given here.  <a href=""http://www.math.grin.edu/~rebelsky/Courses/152/97F/Readings/student-binary"" rel=""nofollow"">http://www.math.grin.edu/~rebelsky/Courses/152/97F/Readings/student-binary</a></p>
","13594276"
"Converting text to a binary file","7663","","<p>I need to convert a text file of the following format to binary:</p>

<p>The first line contains the number of products in the inventory, The following lines contains:<br>
 product name <code>'\t'</code> product price <code>'\t'</code> quantity <code>'\n'</code>
(there can be more than one \t between columns)</p>

<p>For every product the binary output file will contain an int representing the length of the product name, the chars that hold the product name, an int representing the price and an int representing the quantity.</p>

<p>Sample input file:</p>

<pre><code>Asus Zenbook    1000    10
iPhone 5        750     22
Playstation 4   1000    0
</code></pre>

<p>I have wrote the following code, and I understood that I'm supposed to see the string in plain text while the integers will show up as gibberish (in binary):</p>

<pre><code>int convertTextToBinary(char *fileName)
{
    FILE *pText, *pBinary;

    int size, i;

    char *currProdName;
    int currProdNameLen, currQuantity, currPrice;

    if (checkFileExists(fileName) == FALSE)
    {
        printf(""- Given file does not exists!\n"");
        return ERROR;
    }

    else
        pText = fopen(fileName, ""r"");

    // get the number of products in the inventory
    fscanf(pText, ""%d"", &amp;size);
    #ifdef DBG
    printf(""##DBG Successfuly read &amp;size = %d DBG##\n"", size);
    #endif  
    pBinary = fopen(strcat(fileName, "".bin""), ""wb"");

    fwrite(&amp;size, sizeof(int), 1, pBinary);
    #ifdef DBG
    printf(""##DBG Successfuly wrote &amp;size = %d DBG##\n"", size);
    #endif  
    for (i = 0; i &lt; size; i++)
    {
        // get product name and name length
        currProdNameLen = getProdName(pText, &amp;currProdName);
        #ifdef DBG
        printf(""##DBG %d Successfuly read &amp;currProdName = %s DBG##\n"", i+1, currProdName);
        printf(""##DBG %d Successfuly read &amp;currProdNameLen = %d DBG##\n"", i+1, currProdNameLen);
        #endif          
        // get product price 
        fscanf(pText, ""%d"", &amp;currPrice);
        printf(""##DBG %d Successfuly read &amp;currPrice = %d DBG##\n"", i+1, currPrice);
        // get product quantity
        fscanf(pText, ""%d"", &amp;currQuantity);
        printf(""##DBG %d Successfuly read &amp;currQuantity = %d DBG##\n"", i+1, currQuantity);
        // write data to binary file
        fwrite(&amp;currProdNameLen , sizeof(int), 1, pBinary);
        fwrite(&amp;currProdName, sizeof(char), currProdNameLen, pBinary);
        fwrite(&amp;currPrice, sizeof(int), 1, pBinary);
        fwrite(&amp;currQuantity, sizeof(int), 1, pBinary);
        free(currProdName);
    }

    fclose(pText);
    fclose(pBinary);
    return 1;
}

/* This function checks if a file in a given path exists or not by using fopen with ""read"" argument */
BOOL checkFileExists(char *fileName)
{
    FILE *fp;

    fp = fopen(fileName, ""r"");

    // file does not exists
    if (fp == NULL)
        return FALSE;

    // file does exists
    else
    {
        fclose(fp);
        return TRUE;
    }
}
int getProdName(FILE *fp, char **prodName)
{
    int nameLen = 0, offset;

    // count the length of the product name
    while (fgetc(fp) != '\t')
        nameLen++;

    // allcoate memory for the product name
    *prodName = (char*)malloc(sizeof(char)*nameLen);
    //checkalloc(&amp;prodName);

    // get the cursor back to the original position
    offset = -1 * nameLen;
    fseek(fp, offset, SEEK_CUR);

    // copy product name from text to string
    fgets(*prodName, nameLen, fp);

    return strlen(*prodName);
}
</code></pre>

<p>But the hell, my output file looks like this:</p>

<pre><code>       ¨ ּּּּּט        ¨ ּּּ¯        ¨ ּּּּּּּּ   ּּּ«
        ¨      
</code></pre>

<p>Which holds no plain text. I have tried changing the fopen argument from ""wb"" to ""w"" but I still get gibberish files. What am I doing wrong?</p>
","<p>Here you write the pointer and additional garbage instead of the string it points to:</p>

<pre><code>    fwrite(&amp;currProdName, sizeof(char), currProdNameLen, pBinary);
</code></pre>

<p>You should use:</p>

<pre><code>    fwrite(currProdName, sizeof(char), currProdNameLen, pBinary);
</code></pre>

<p>In your version you are passing the pointer to the pointer, but you want to pass the pointer itself.</p>

<p>BTW: In your function <code>getProdName()</code>, you should add an additional character, because you are allocating the exact string lenght, but no room for the <code>0</code> Byte at the end. This can also cause problems. Also <code>fgets</code> reads one char less. Check the man page for <code>fgets</code>. Instead of using <code>fgets</code>, you can also use <code>fread</code> because you know the length anyway. No additional parsing needed.</p>

<p><strong>update</strong></p>

<p>Change this:</p>

<pre><code>    fscanf(pText, ""%d"", &amp;currQuantity);
</code></pre>

<p>to</p>

<pre><code>    fscanf(pText, ""%d\n"", &amp;currQuantity);
</code></pre>
","18303213"
"binary counter in C","7659","","<p>I am busy with a project where the following function needs to be implemented in C</p>

<pre><code>void logic_circuit(int inputs[4],int outputs[2])
</code></pre>

<p>A counter needs to be created since all the 4 bit combinations needs to be inserted into this function...</p>

<pre><code>void logic_circuit(int inputs[4],int outputs[2])
{
      //some calculations
      outputs[0] = ...
      outputs[1] = ...
}

//allocate memory
int inputs[4];
int outputs[2];

for(0000 to 1111)
{
     logic_circuit(0000,outputs);
}
</code></pre>

<p>I have been searching the web intensively but unfortunately I was'nt able to find anything usefull.Does anyone have an idea on how to tackle this issue?</p>
","<p>Instead of four nested loops, you could also fill the <code>inputs</code> array from a single loop counter,</p>

<pre><code>for(mask = 0; mask &lt; 0x10; ++mask) {
    for(index = 0; index &lt; 4; ++index) {
        inputs[index] = (mask &gt;&gt; index) &amp; 1;
    }
    logic_circuit(inputs, output);
}
</code></pre>

<p>That scales better to larger <code>inputs</code> arrays.</p>
","12555623"
"Python binary EOF","7615","","<p>I want to read through a binary file.
Googling ""python binary eof"" led me <a href=""https://stackoverflow.com/questions/10581309/eof-in-a-binary-file-using-python"">here</a>.</p>

<p>Now, the questions:</p>

<ol>
<li>Why does the container (x in the SO answer) contain not a single (current) byte but a whole bunch of them? What am I doing wrong?</li>
<li>If it should be so and I am doing nothing wrong, HOW do read a single byte? I mean, is there any way to detect EOF while reading the file with <code>read(1)</code> method?</li>
</ol>
","<p>To quote the <a href=""https://docs.python.org/2/library/stdtypes.html#file.read"" rel=""nofollow noreferrer"">documentation</a>:</p>

<blockquote>
  <p><strong><code>file.read([size])</code></strong></p>
  
  <p>Read <strong>at most</strong> size bytes from the file (<strong>less if the read hits EOF</strong> before obtaining size bytes). If the size argument is negative or omitted, read all data until EOF is reached. The bytes are returned as a string object. <strong>An empty string is returned when EOF is encountered immediately</strong>. (For certain files, like ttys, it makes sense to continue reading after an EOF is hit.) Note that this method may call the underlying C function fread() more than once in an effort to acquire as close to size bytes as possible. Also note that when in non-blocking mode, less data than was requested may be returned, even if no size parameter was given.</p>
</blockquote>

<p>That means (for a <a href=""http://en.wikipedia.org/wiki/Unix_file_types#Regular_file"" rel=""nofollow noreferrer"">regular file</a>):</p>

<ul>
<li><code>f.read(1)</code> will return a byte object containing either 1 byte or 0 byte is EOF was reached</li>
<li><code>f.read(2)</code> will return a byte object containing either 2 bytes, or 1 byte if EOF is reached after the first byte, or 0 byte if EOF in encountered immediately.</li>
<li>...</li>
</ul>

<p>If you want to read your file one byte at a time, you will have to <code>read(1)</code> in a loop and test for ""emptiness"" of the result:</p>

<pre><code># From answer by @Daniel
with open(filename, 'rb') as f:
    while True:
        b = f.read(1)
        if not b:
            # eof
            break
        do_something(b)
</code></pre>

<p>If you want to read your file by ""chunk"" of say 50 bytes at a time, you will have to <code>read(50)</code> in a loop:</p>

<pre><code>with open(filename, 'rb') as f:
    while True:
        b = f.read(50)
        if not b:
            # eof
            break
        do_something(b) # &lt;- be prepared to handle a last chunk of length &lt; 50
                        #    if the file length *is not* a multiple of 50
</code></pre>

<p>In fact, you may even break one iteration sooner:</p>

<pre><code>with open(filename, 'rb') as f:
    while True:
        b = f.read(50)
        do_something(b) # &lt;- be prepared to handle a last chunk of size 0
                        #    if the file length *is* a multiple of 50
                        #    (incl. 0 byte-length file!)
                        #    and be prepared to handle a last chunk of length &lt; 50
                        #    if the file length *is not* a multiple of 50
        if len(b) &lt; 50:
            break
</code></pre>

<hr>

<p>Concerning the other part of your question:</p>

<blockquote>
  <p>Why does the container [..] contain [..] a whole bunch of them [bytes]?</p>
</blockquote>

<p>Referring to <a href=""https://stackoverflow.com/questions/10581309/eof-in-a-binary-file-using-python"">that code</a>:</p>

<pre><code>for x in file:  
   i=i+1  
   print(x)  
</code></pre>

<p>To quote again <a href=""https://docs.python.org/2/library/stdtypes.html#file.next"" rel=""nofollow noreferrer"">the doc</a>:</p>

<blockquote>
  <p>A file object is its own iterator, [..]. When a file is used as an iterator, typically in a for loop (for example, for line in f: print line.strip()), the next() method is called repeatedly. This method returns the <strong>next input line</strong>, or raises StopIteration when EOF is hit when the file is open for reading (behavior is undefined when the file is open for writing).</p>
</blockquote>

<p>The the code above read a <em>binary file</em> line-by-line. That is stopping at each occurrence of the EOL char (<code>\n</code>). Usually, that leads to chunks of various length as most binary files contains occurrences of that char randomly distributed.</p>

<p><strong>I wouldn't encourage you to read a binary file that way</strong>. Please prefer one a solution based on <code>read(size)</code>.</p>
","25466256"
"How to convert binary to text in Java?","7612","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/4211705/binary-to-text-in-java"">Binary to text in Java</a>  </p>
</blockquote>



<p>I'm writing a program that can convert multiple things, but I need help with the converting of binary. I have my code for text-to-binary working, but I'm not sure about binary-to-text. Here is my code for the button which triggers the conversion: </p>

<pre><code>String code = jTextArea5.getText();
if (code == null) {
    System.out.println(jTextArea1.getText( ));
    String writing = jTextArea1.getText();

    byte[] bytes = writing.getBytes();
    StringBuilder binary = new StringBuilder();

    for (byte b : bytes) {
        int val = b;

        for (int i = 0; i &lt; 8; i++){
            binary.append((val &amp; 128) == 0 ? 0 : 1);
            val &lt;&lt;= 1;
        }
        binary.append(' ');
    }

    jTextArea5.setText("""" + binary);
}
else
{
   System.out.println(jTextArea1.getText( ));
    String binary = jTextArea1.getText();

    int ascii = Integer.parseInt(binary, 2);
    char character = (char)ascii;

    jTextArea5.setText("""" + character); 
}
</code></pre>

<p>If anyone knows how I can fix this code to work, that'd be great. Thanks!</p>

<p>NOTE - This bit below works on it's own, just not in conjunction with any efforts to allow converting binary in jTextArea5 to text in jTextArea1. </p>

<pre><code>    System.out.println(jTextArea1.getText( ));
    String writing = jTextArea1.getText();

    byte[] bytes = writing.getBytes();
    StringBuilder binary = new StringBuilder();

    for (byte b : bytes) {
        int val = b;

        for (int i = 0; i &lt; 8; i++){
            binary.append((val &amp; 128) == 0 ? 0 : 1);
            val &lt;&lt;= 1;
        }
        binary.append(' ');
    }

    jTextArea5.setText("""" + binary);
</code></pre>
","<p>Swap the 5 and the 1 around so it grabs the binary out of the correct textbox.</p>

<p>And use StringTokenizer to process each block of 8</p>

<p>Dont forget to import StringTokenizer</p>

<pre><code>    else
    {
       System.out.println(jTextArea5.getText( ));
        String binary = jTextArea5.getText();
        StringTokenizer st = new StringTokenizer(binary,"" "");
         while(st.hasMoreTokens()){
             int ascii = Integer.parseInt(st.nextToken(), 2);
             char character = (char)ascii;
             jTextArea1.setText(jTextArea1.getText() + """" + character); 

         }
    }
</code></pre>

<p>this bit checks whats in jTextArea5.getText()</p>

<pre><code>if (code == null) {
</code></pre>

<p>change it to</p>

<pre><code>if (code.equals("""")) {
</code></pre>

<p>and make sure you clear out whats in the text boxes before you start either conversion</p>
","12966441"
"C#/.NET - Custom Binary File Formats - Where to Start?","7608","","<p>I need to be able to store some data in a custom binary file format. I've never designed my own file format before. It needs to be a friendly format for traveling between the C#, Java and Ruby/Perl/Python worlds.</p>

<p>To start with the file will consist of records. A GUID field and a JSON/YAML/XML packet field. I'm not sure what to use as delimiters. A comma, tab or newline kind of thing seems too fragile. What does Excel do? or the pre-XML OpenOffice formats? Should you use ASCII chars 0 or 1. Not sure where to begin. Any articles or books on the topic?</p>

<p>This file format may expand later to include a ""header section"".</p>

<p>Note: To start with I'll be working in .NET, but I'd like the format to be easily portable.</p>

<p><strong>UPDATE:</strong><br>
The processing of the ""packets"" can be slow, but navigation within the file format cannot. So I think XML is off the table.</p>
","<p>I'll try to add some general hints for creating a portable binary file format.</p>

<p>Note that to invent a binary file format means to document, how the bits in it must go and what they mean. It's not coding, but documentation.</p>

<p>Now the hints:</p>

<ol>
<li><p>Decide what to do with <strong>endianess</strong>. Good and simple way to go is to decide it once and forever. The choice would be preferably little endian when used on common PC (that is x86) to save conversions (performance).</p></li>
<li><p>Create <strong>header</strong>. Yes, it is good idea to always have a header. First bytes of the file should be able to tell you, what format you are messing with.</p>

<ul>
<li>Start with magic to be able to recognize your format (ASCII string will do the trick)</li>
<li>Add version. Version of your file format will not hurt to add and it will allow you to do backward compatibility later.</li>
</ul></li>
<li><p>Finally, add the data. Now, the format of the data will be specific and it will always be based on your exact needs. Basically, the data will be stored in a binary image of some data structure. The data structure is what you need to come up with.</p></li>
</ol>

<p>If you need random access to your data by some sort of indices, <a href=""https://en.wikipedia.org/wiki/B-tree"" rel=""nofollow"">B-Trees</a> are way to go, while if you just need a lot of numbers to write them all and then read them all an ""array"" will do the trick.</p>

<p>Additionally, you might use a <a href=""https://en.wikipedia.org/wiki/Type-length-value"" rel=""nofollow"" title=""TLV"">TLV (Type-Length-Value)</a> concept for forward compatibility.</p>
","29946154"
"Using Python struct.unpack with 1-byte variables","7561","","<p>How can I use <code>struct.unpack()</code> or some other function available in Python to easily convert <em>one</em> byte variable to a Python integer? Right now, it is done in a rather lame way:</p>

<pre><code>file = open(""telemetry.dat"", ""rb"").read()
magic = file[0]
int(binascii.hexlify(magic), 16)
</code></pre>

<p>Is there another?</p>
","<p>how about <code>ord(my_byte)</code> ? </p>

<p>Or if the variable content is like <code>my_byte == ""0xff""</code> or <code>ff</code>
you can simply do <code>int(my_byte, 16)</code></p>

<p>If you have a streamof hex digits, you can do:</p>

<pre><code>int_bytes = (int(my_bytes[i:i+2], 16) for i in xrange(0, len(my_bytes), 2) ) 
</code></pre>
","2051076"
"How to determine 2^x = 64","7557","","<p>I know the answer to this question is 6... but I am wondering what the formula is to figure this out.</p>

<p>I will always need to solve for x in this scenario.</p>

<p>TIA</p>
","<p>log(64) / log(2) = x.  Or in more general terms, if y^x = z, then x = log(z) / log(y) </p>
","12852211"
"PHP Hex and Binary","7547","","<p>I have a string in the following format: ""0A1344010400010005"" (hex representation)</p>

<p>I would need to convert this string into an array of bytes (0x0a, 0x13, 0x44, and so forth) so that these data can be used in the following function:</p>

<pre><code>$data = $this-&gt;data;

    for ($i = 0; $i &lt; sizeof($data); $i++) {

        // 1.value right shift 8 digits (equal to divide 256)
        // 2.XOR value and incoming data, then AND 0xFF
        // 3. get an index£¨then search related index data in CRC16_TABLE
        // XOR again
        $this-&gt;value = ($this-&gt;value &gt;&gt; 8) ^ $this-&gt;arr[($this-&gt;value ^ $data[$i]) &amp; 0xff];         

    }
</code></pre>

<p><code>$this-&gt;value</code> value is <code>0xFFFF</code>. <code>$this-&gt;arr</code> is an array containing elements: <code>array(0x0000, 0x1189, 0x2312, 0x329b, 0x4624, 0x57ad, 0x6536, 0x74bf)</code>.</p>

<p>I have done the following. Basically, this traverses the string and separates every 2 characters as hex rep per byte and convert them to binary string.</p>

<pre><code>$data = array();
    $len = strlen($str);
    if($len % 2 == 1) $str = ""0"".$str;
    $len = strlen($str);
    for($i =0; $i &lt; $len; $i=$i+2)
    {
        $data[] = hex2bin(substr($str,$i,2));
    }
    $this-&gt;data = $data;
</code></pre>

<p>It seems that it is generating result of value 0 all the time. Is there anything that I should have done?</p>

<p>Thank you so much for the help!</p>
","<p><code>pack</code> can convert a hex string into a binary string (bytes 0x0a, 0x13, 0x44, and so forth):</p>

<pre><code>$data = pack('H*', '0A1344010400010005');
</code></pre>

<p>After that, what you have done should work, with one minor change: <code>$data[$i]</code> is actually a string and to get the value of the corresponding byte you need <code>ord</code>:</p>

<pre><code>for ($i = 0; $i &lt; strlen($data); $i++) {
    $this-&gt;value = ($this-&gt;value &gt;&gt; 8) ^ $this-&gt;arr[($this-&gt;value ^ ord($data[$i])) &amp; 0xFF];         
}
</code></pre>
","11046052"
"Fastest way to generate all binary strings of size n into a boolean array?","7531","","<p>For example, if I wanted all binary strings of length 3 I could simply declare them like this:</p>

<pre><code>boolean[] str1 = {0,0,0};
boolean[] str2 = {0,0,1};
boolean[] str3 = {0,1,0};
boolean[] str4 = {0,1,1};
boolean[] str5 = {1,0,0};
boolean[] str6 = {1,0,1};
boolean[] str7 = {1,1,0};
boolean[] str8 = {1,1,1};
</code></pre>

<p>What is the most efficient way to generate all possibly binary strings of length N into a <strong>boolean array</strong>?</p>

<p>I don't necessarily need <em>the</em> most efficient method, just one that's fairly efficient and easy for me to multithread.</p>

<p>EDIT: I should note that I will be storing them all in an ArrayList, if that matters.</p>
","<p>Here's some code to generate a truth table... (works for only for 32 bits because of array size limits ( you can change the size variable to whatever and store booleans as 1/0 if you want):</p>

<pre><code>int size = 3;
    int numRows = (int)Math.pow(2, size);
    boolean[][] bools = new boolean[numRows][size];
    for(int i = 0;i&lt;bools.length;i++)
    {
        for(int j = 0; j &lt; bools[i].length; j++)
        {
            int val = bools.length * j + i;
            int ret = (1 &amp; (val &gt;&gt;&gt; j));
            bools[i][j] = ret != 0;
            System.out.print(bools[i][j] + ""\t"");
        }
        System.out.println();
    }
</code></pre>
","8374180"
"C++ How to convert decimal number to binary?","7526","","<p>I was tasked with writing some code that will take a user input and convert the number to its binary number. I have written some code so far, but am having one issue. I have to use a for loop and the quotient-remainder method. When I output the remainder(binary), it is not printing the last digit.</p>

<p>The question I'm asking is: What would I have to change in my for loop to make it print out the last digit of the binary number? </p>

<pre><code>int main()
{
    int num;
    int rem;

    cout &lt;&lt; ""Please enter a number: "";
    cin &gt;&gt; num;

    for (int i = 0; i &lt;= (num + 1); i++)
    {
        num /= 2;
        rem = num % 2;
        cout &lt;&lt; rem;
    }

    _getch();
    return 0;
} 
</code></pre>

<p>Any help is appreciated, Thank you!</p>
","<p>You lose the last binary number when you start your algorithm by dividing <code>num</code> by 2. To avoid this issue, you should exchange both instructions <code>num /= 2;</code> and <code>rem = num % 2;</code></p>

<p>Your loop also iterates too many times: in fact you can stop when <code>num == 0</code>. The following code is not valid for inputs that are &lt;= 0.</p>

<pre><code>int main()
{
    int num;
    int rem;

    cout &lt;&lt; ""Please enter a number: "";
    cin &gt;&gt; num;

    while (num != 0)
    {
        rem = num % 2;
        num /= 2;
        cout &lt;&lt; rem;
    }
    cout &lt;&lt; std::endl;

    return 0;
} 
</code></pre>

<p>If you want to write it in the right order, you should first compute the log of your number in base 2. The following solution uses a number <code>index</code> that starts with '1' and that has '0' after:</p>

<pre><code>int main()
{
    int num;
    int rem;

    cout &lt;&lt; ""Please enter a number: "";
    cin &gt;&gt; num;

    if (num &gt; 0) {
      int index = 1;
      while (index &lt;= num)
         index *= 2;
      index /= 2;

      do {
        if (num &gt;= index) {
           cout &lt;&lt; '1';
           num -= index;
        }
        else
           cout &lt;&lt; '0';
        index /= 2;
      } while (index &gt; 0);
      cout &lt;&lt; std::endl;
    }
    else
      cout &lt;&lt; '0';

    cout &lt;&lt; endl;
    return 0;
} 
</code></pre>
","39947437"
"Blob from javascript binary string","7508","","<p>I have a binary string created with <code>FileReader.readAsBinaryString(blob).</code></p>

<p>I want to create a Blob with the binary data represented in this binary string.</p>
","<p>Is the blob that you used not available for use anymore?<br>
Do you have to use <code>readAsBinaryString</code>? Can you use <code>readAsArrayBuffer</code> instead. With an array buffer it would be much easier to recreate the blob.  </p>

<p>If not you could build back he blob by cycling through the string and building a byte array then creating a blob from it.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>$('input').change(function(){
    var frb = new FileReader();
    frb.onload = function(){
        var i, l, d, array;
        d = this.result;
        l = d.length;
        array = new Uint8Array(l);
        for (var i = 0; i &lt; l; i++){
            array[i] = d.charCodeAt(i);
        }
        var b = new Blob([array], {type: 'application/octet-stream'});
        window.location.href = URL.createObjectURL(b);
    };
    frb.readAsBinaryString(this.files[0]);
    
 
});</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;script src=""https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js""&gt;&lt;/script&gt;
&lt;input type=""file""&gt;</code></pre>
</div>
</div>
</p>
","27826348"
"C# - Shifting and reversing the order of bits in a byte array","7501","","<p>I am trying to get the correct int out of an array of bytes.
The bytes is read from a RFIDTag via POS for .Net.
(Acctually I need 18 bits)</p>

<p>In binary the byte array is as follows:
00001110 11011100 00000000 00011011 10000000</p>

<p>What I need to get out of it is:
00 00000000 11101101
(int = 237)</p>

<p>From the original bytes that would be the following bits in reverse order:
------10 11011100 00000000</p>

<p>I have been looking at bitArray. Array.Reverse. And several ways of shifting bits. But I just can't wrap my head around this one. </p>

<p>Can anyone point me in the correct direction?</p>
","<p>You can get the bits and reverse them like this:</p>

<pre><code>byte[] data = { 0x0E, 0xDC, 0x00, 0x1B, 0x80 };

// get only first four bytes
byte[] bits = new byte[4];
Array.Copy(data, 0, bits, 0, 4);

// reverse array if system uses little endian
if (BitConverter.IsLittleEndian) {
  Array.Reverse(bits);
}

// get a 32 bit integer from the four bytes
int n = BitConverter.ToInt32(bits, 0); // 0x0EDC001B

// isolate the 18 bits by shifting and anding
n &gt;&gt;= 8; // 0x000EDC00
n &amp;= 0x0003FFFF; // 0x0002DC00

// reverse by shifting bits out to the right and in from the left
int result = 0;
for (int i = 0; i &lt; 18; i++) {
  result = (result &lt;&lt; 1) + (n &amp; 1);
  n &gt;&gt;= 1;
}

Console.WriteLine(result);
</code></pre>

<p>Output:</p>

<pre><code>237
</code></pre>
","14719114"
"Convert really big number from binary to decimal and print it","7472","","<p>I know how to convert binary to decimal. I know at least 2 methods: table and power ;-)</p>

<p>I want to convert binary to decimal and print this decimal. Moreover, I'm not interested in this `decimal'; I want just to print it.</p>

<p>But, as I wrote above, I know only 2 methods to convert binary to decimal and both of them required addition. So, I'm computing some value for 1 or 0 in binary and add it to the remembered value. This is a thin place. I have a really-really big number (1 and 64 zeros). While converting I need to place some intermediate result in some 'variable'. In C, I have an `int' type, which is 4 bytes only and not more than 10^11.</p>

<p>So, I don't have enough memory to store intermedite result while converting from binary to decimal. As I wrote above, I'm not interested in THAT decimal, I just want to print the result. But, I don't see any other ways to solve it ;-( Is there any solution to ""just print"" from binary?</p>

<p>Or, maybe, I should use something like BCD (Binary Coded Decimal) for intermediate representation? I really don't want to use this, 'cause it is not so cross-platform (Intel's processors have a built-in feature, but for other I'll need to write own implementation).</p>

<p>I would glad to hear your thoughts. Thanks for patience.</p>

<p>Language: C.</p>
","<p>Biggest standard integral data type is <code>unsigned long long int</code> - on my system (32-bit Linux on x86) it has range 0 - 1.8*10^20 which is not enough for you, so you need to create your own type (struct or array) and write basic math (basically you just need an addition) for that type.</p>

<p>If I were you (and memory is not an issue), I'd use an array - one byte per decimal digit rather then BCD. BCD is more compact as it stores 2 decimal digits per byte but you need to put much more effort working with high and low nibbles separately.</p>

<p>And to print you just add <code>'0'</code> (character, not digit) to every byte of your array and you get a printable string.</p>
","960404"
"django: return image data from a view","7464","","<p>I want a view to return image data. so something along the lines of</p>

<pre><code>return HttpResponse(image_data, mimetype=”image/png”)
</code></pre>

<p>I know I can do a <code>file.read()</code> to get the image data, but because the image is small (like 1x1 px) I want to just store it as a string object (or whatever object I can copy and paste in my code). This way, I save myself the disk lookup everytime the view is hit.</p>

<p>How do i go about this? I'm sure this is easy, I'm just not sure what terms to use for search.</p>

<p>p.s. I know that one does not normally serve images this way with Django.</p>
","<p>Here is a simple example from the <a href=""http://code.google.com/p/django-openid/"" rel=""nofollow noreferrer"">django-openid project</a></p>

<pre><code>def logo(request):
    return HttpResponse(
        OPENID_LOGO_BASE_64.decode('base64'), content_type='image/gif'
    )
    # Logo from http://openid.net/login-bg.gif
    # Embedded here for convenience; you should serve this as a static file
    OPENID_LOGO_BASE_64 = """"""
    R0lGODlhEAAQAMQAAO3t7eHh4srKyvz8/P5pDP9rENLS0v/28P/17tXV1dHEvPDw8M3Nzfn5+d3d
    3f5jA97Syvnv6MfLzcfHx/1mCPx4Kc/S1Pf189C+tP+xgv/k1N3OxfHy9NLV1/39/f///yH5BAAA
    AAAALAAAAAAQABAAAAVq4CeOZGme6KhlSDoexdO6H0IUR+otwUYRkMDCUwIYJhLFTyGZJACAwQcg
    EAQ4kVuEE2AIGAOPQQAQwXCfS8KQGAwMjIYIUSi03B7iJ+AcnmclHg4TAh0QDzIpCw4WGBUZeikD
    Fzk0lpcjIQA7
    """"""
</code></pre>
","8483796"
"How to manipulate and represent binary numbers in C++","7414","","<p>I'm currently trying to build a lookup table for a huffman tree using a pretty simple preorder traversal algorithm, but I'm getting stuck carrying out very basic bit wise operations. The psuedo code follows:</p>

<pre><code>void preOrder(huffNode *node, int bit) //not sure how to represent bit
{
  if (node == NULL)
    return;

  (1) bit = bit + 0; //I basically want to add a 0 onto this number (01 would go to 010)
  preOrder(node-&gt;getLeft(), bit);
  (2) bit = bit - 0 + 1; //This should subtract the last 0 and add a 1 (010 would go to 011)
  preOrder(node-&gt;getRight());


}
</code></pre>

<p>I'm getting quite confused about how to carry out the operations defined on lines (1) and (2)</p>

<p>What data type type does one use to represent and print binary numbers? In the above example I have the number represented as an int, but i'm pretty sure that that is incorrect. Also how do you add or subtract values? I understand how &amp; and | types logic works, but I'm getting confused as to  how one carries out these sorts of operations in code. </p>

<p>Could anyone post some very simple examples?</p>
","<p>Here's some basic examples of binary operations.  I've used mostly in-place operations here.</p>

<pre><code>int bit = 0x02;   //               0010
bit |= 1;         // OR  0001 -&gt;   0011
bit ^= 1;         // XOR 0001 -&gt;   0010
bit ^= 7;         // XOR 0111 -&gt;   0101
bit &amp;= 14;        // AND 1110 -&gt;   0100
bit &lt;&lt;= 1;        // LSHIFT 1 -&gt;   1000
bit &gt;&gt;= 2;        // RSHIFT 2 -&gt;   0010
bit = ~bit;       // COMPLEMENT -&gt; 1101
</code></pre>

<p>If you want to print a binary number you need to do it yourself...  Here's one slightly inefficient, but moderately readable, way to do it:</p>

<pre><code>char bitstr[33] = {0};
for( int b = 0; b &lt; 32; b++ ) {
    if( bit &amp; (1 &lt;&lt; (31-b)) )
        bitstr[b] = '1';
    else
        bitstr[b] = '0';
}
printf( ""%s\n"", bitstr );
</code></pre>

<p><strong>[edit]</strong> If I wanted faster code, I might pre-generate (or hardcode) a lookup table with the 8-bit sequences for all numbers from 0-255.</p>

<pre><code>// This turns a 32-bit integer into a binary string.
char lookup[256][9] = {
    ""00000000"",
    ""00000001"",
    ""00000010"",
    ""00000011"",
    // ... etc (you don't want to do this by hand)
    ""11111111""
};

char * lolo = lookup[val &amp; 0xff];
char * lohi = lookup[(val&gt;&gt;8) &amp; 0xff];
char * hilo = lookup[(val&gt;&gt;16) &amp; 0xff];
char * hihi = lookup[(val&gt;&gt;24) &amp; 0xff];

// This part is maybe a bit lazy =)
char bitstr[33];
sprintf( ""%s%s%s%s"", hihi, hilo, lohi, lolo );
</code></pre>

<p>Instead, you could do this:</p>

<pre><code>char *bits = bitstr;
while( *hihi ) *bits++ = *hihi++;
while( *hilo ) *bits++ = *hilo++;
while( *lohi ) *bits++ = *lohi++;
while( *lolo ) *bits++ = *lolo++;
*bits = 0;
</code></pre>

<p>Or just unroll the whole thing. ;-)</p>

<pre><code>char bitstr[33] = {
    hihi[0], hihi[1], hihi[2], hihi[3], hihi[4], hihi[5], hihi[6], hihi[7],
    hilo[0], hilo[1], hilo[2], hilo[3], hilo[4], hilo[5], hilo[6], hilo[7],
    lohi[0], lohi[1], lohi[2], lohi[3], lohi[4], lohi[5], lohi[6], lohi[7],
    lolo[0], lolo[1], lolo[2], lolo[3], lolo[4], lolo[5], lolo[6], lolo[7],
    0 };
</code></pre>

<p>Of course, those 8 bytes in the lookup are the same length as a 64-bit integer...  So what about this?  Much faster than all that pointless meandering through character arrays.</p>

<pre><code>char bitstr[33];
__int64 * intbits = (__int64*)bitstr;
intbits[0] = *(__int64*)lookup[(val &gt;&gt; 24) &amp; 0xff];
intbits[1] = *(__int64*)lookup[(val &gt;&gt; 16) &amp; 0xff];
intbits[2] = *(__int64*)lookup[(val &gt;&gt; 8) &amp; 0xff];
intbits[3] = *(__int64*)lookup[val &amp; 0xff];
bitstr[32] = 0;
</code></pre>

<p>Naturally, in the above code you would represent your lookup values as int64 instead of strings.</p>

<p>Anyway, just pointing out that you can write it however is appropriate for your purposes.  If you need to optimize, things get fun, but for most practical applications such optimizations are negligible or pointless.</p>
","11714207"
"Uploading binary file on Node.js","7403","","<p>I am using Flash to record and upload audio to a node server. The Flash client is a variation of <a href=""https://github.com/sythoos/jRecorder"" rel=""noreferrer"">jrecorder</a>. When the user is done recording the audio is uploaded using a POST request (not a form because Flash cannot create files) with the audio ByteArray as the data of the POST request (see more <a href=""https://github.com/sythoos/jRecorder/blob/master/flash-fla/Main.as#L177-207"" rel=""noreferrer"">here</a>).</p>

<p>I am able to receive the file correctly on Node-land using the code below but the audio that comes out is mangled and you cannot hear anything. With that said, the content of the file can be played by VLC and other players + Sox is able to encode it as an mp3.</p>

<p>Here is my code when using Node:</p>

<pre><code>var express = require('express');
var app = express();

app.use (function(req, res, next) {
    req.rawBody = '';
    req.setEncoding('utf8');

    if(req.method.toLowerCase() == ""post"")
    {
        req.on('data', function(chunk) { req.rawBody += chunk });
        req.on('end', function() { done(req, res); });
    }

    next();
});

function done(req, res)
{
    fs.writeFile('abc.wav', req.rawBody, 'binary', function(err){
        if (err) throw err;

        // Save file to S3
    }   
}
</code></pre>

<p>Now if I use the same Flash client and make the POST request to a Rails server and use the code below, the file is saved perfectly.</p>

<pre><code>def record
    file = request.raw_post

    # Save file to S3
end
</code></pre>

<p>Note that I am not a Node expert so please if you have any suggestions on what should I use instead of saving the chunks please post code examples. My main purpose right now is to get this to a working state before exploring other way of accomplishing more efficiently in Node (buffers, streams, etc)</p>
","<p>Take out the following line</p>

<pre><code>req.setEncoding('utf8');
</code></pre>

<p>You're not receiving <code>utf8</code> data, you're receiving <code>binary</code> data.</p>

<p>You would be better off using a buffer instead of a string</p>

<pre><code>app.use(function(req, res, next) {
  var data = new Buffer('');
  req.on('data', function(chunk) {
      data = Buffer.concat([data, chunk]);
  });
  req.on('end', function() {
    req.rawBody = data;
    next();
  });
});
</code></pre>
","16599008"
"Decimal to 2's complement binary conversion (least bits required to represent decimal number)","7393","","<p>I was asked in a class:</p>

<p>What is the least number of bits are required to represent the following decimal numbers as 2’s complement binary numbers?
-64
31
128</p>

<ol>
<li><p>So, first of all, what is the difference between 1 and 2's complement binary? How can I convert a decimal number into a 2's complement binary representation?</p></li>
<li><p>I also am wondering, is it possible to have multiple representations of that decimal number? How do I find out the least number of required bits?</p></li>
</ol>
","<ol>
<li><p>The difference between 1's and 2's complement:</p>

<ul>
<li>In 1's complement negative numbers are represented as the positive number with all of its bits flipped. So for example -6 would be ..111001 because 6 is ..000110.</li>
<li>In 2's complement negative numbers are represented as the positive number with all its bits flipped, <em>plus one</em>. So for example -6 would be ..111001 + 1 = ..111010</li>
</ul></li>
<li><p>Multiple representations of a decimal number in binary: The representation of a number in binary is unique, but for one exception: in 1's complement the number 0 can be written both as 0 and as ..111.</p></li>
</ol>

<p>Note that in both cases negative numbers have a representation with an infinite string of 1's on the left. In practice the number of bits available is finite, so we use only some of the rightmost bits. The convention is that if the leftmost bit is 1 we assume that the number has an infinite string on ones to the left before this first bit. This means that the leftmost bit gives the sign of the number: if it's 1 the number is negative, if it's 0 the number is positive. The rest of the bits give the magnitude. (Of course, there are <a href=""http://en.wikipedia.org/wiki/Signed_number_representations"" rel=""nofollow"">other ways to represent signed numbers</a> where this doesn't hold.)</p>

<p>The least number of bits required to represent a number may differ between 1's and 2's complement. For example, 1's complement needs at least 5 bits to represent -8, while 2's complement can make do with 4:</p>

<pre><code>        +8 in binary:  1000
-8 in 1's complement: 10111
-8 in 2's complement:  1000
</code></pre>
","13780677"
"Transferring binary data through a SOAP webservice? ","7392","","<p>I have a web service that returns the binary array of an object. Is there an easier way to transfer this with SOAP or does it need to be contained in XML? It's working, but I had to increase the send and receive buffer to a large value. How much is too much?</p>

<p>Transferring binary in XML as an array seems really inefficient, but I can't see any way to add a binary attachment using .NET.</p>
","<p>As an array?  Do you mean that you are sending</p>

<pre><code>&lt;byte&gt;8&lt;/byte&gt;
&lt;byte&gt;127&lt;/byte&gt;
</code></pre>

<p>etc?  If so then you can certainly improve on it by converting the byte array into a hex string beforehand, eg.</p>

<pre><code>&lt;codedArray&gt;087F09AFBD.....&lt;/codedArray&gt;
</code></pre>

<p>This is the most common approach for sending images, etc, via SOAP.  However, even then you are correct to question it.  You should really be looking at other, more RESTful transfer protocols, IMHO.</p>
","2641876"
"How to convert a negative integer into two's complement binary form? (Java)","7367","","<p>I need to convert numbers, positive and negative, into binary format - so, 2 into ""00000010"", and -2 into ""11111110"", for example. I don't need more than 12 bits or so, so if the string is longer than that I can just trim off the leading sign bits. It seems like <code>Integer.toBinaryString()</code> will do positive numbers, but is there one that can do negatives?</p>
","<p><code>Integer.toBinaryString</code> works for negatives too. :-) For example, <code>Integer.toBinaryString(-2)</code> returns 11111111111111111111111111111110.</p>

<p>If you take the rightmost 12 characters, you have the bottom 12 bits, as required.</p>
","5762030"
"Working with bytes and binary data in Python","7278","","<p>Four consecutive bytes in a byte string together specify some value. However, only 7 bits in each byte are used; the most significant bit is always zero and therefore its ignored (that makes 28 bits altogether). So...</p>

<pre><code>b""\x00\x00\x02\x01""
</code></pre>

<p>would be <code>000 0000</code> <code>000 0000</code> <code>000 0010</code> <code>000 0001</code>.</p>

<p>Or, for the sake of legibility, <code>10 000 0001</code>. That's the value the four bytes represent. But I want a decimal, so I do this:</p>

<pre><code>&gt;&gt;&gt; 0b100000001
257
</code></pre>

<p>I can work all that out myself, but how would I incorporate it into a program?</p>
","<p>Use bitshifting and addition:</p>

<pre><code>bytes = b""\x00\x00\x02\x01""
i = 0
for b in bytes:
    i &lt;&lt;= 7
    i += b     # Or use (b &amp; 0x7f) if the last bit might not be zero.
print(i)
</code></pre>

<p>Result:</p>

<pre><code>257
</code></pre>
","2587469"
"Why should I use a human readable file format?","7202","","<p>Why should I use a human readable file format in preference to a binary one? Is there ever a situation when this isn't the case?</p>

<p>EDIT:
I did have this as an explanation when initially posting the question, but it's not so relevant now:</p>

<p><em>When answering <a href=""https://stackoverflow.com/questions/567516"">this question</a> I wanted to refer the asker to a standard SO answer on why using a human readable file format is a good idea. Then I searched for one and couldn't find one. So here's the question</em></p>
","<h2> It depends </h2>

<p>The right answer is it depends. If you are writing audio/video data for instance, if you crowbar it into a human readable format, it won't be very readable! And word documents are the classic example where people have wished they were human readable, so more flexible, and by moving to XML MS are going that way. </p>

<p>Much more important than binary or text is a standard or not a standard. If you use a standard format, then chances are you and the next guy won't have to write a parser, and that's a win for everyone.</p>

<p>Following this are some opinionated reasons why you might want to choose one over the other, if you have to write your own format (and parser).</p>

<h2> Why use human readable? </h2>

<ol>
<li><strong>The next guy</strong>. Consider the maintaining developer looking at your code 30 years or six months from now. Yes, he should have the source code. Yes he should have the documents and the comments. But he quite likely won't. And having been that guy, and had to rescue or convert old, extremely, valuable data, I'll thank you for for making it something I can just look at and understand.</li>
<li><strong>Let me read AND WRITE it with my own tools</strong>. If I'm an emacs user I can use that. Or Vim, or notepad or ... Even if you've created great tools or libraries, they might not run on my platform, or even run at all any more. Also, I can then create new data with my tools.</li>
<li><strong>The tax isn't that big - storage is free</strong>. Nearly always disc space is free. And if it isn't you'll know. Don't worry about a few angle brackets or commas, usually it won't make that much difference. Premature optimisation is the root of all evil. And if you are really worried just use a standard compression tool, and then you have a small human readable format - anyone can run unzip.</li>
<li><strong>The tax isn't that big - computers are quick</strong>. It might be a faster to parse binary. Until you need to add an extra column, or data type, or support both legacy and new files. (though this is mitigated with <a href=""http://code.google.com/apis/protocolbuffers/"" rel=""noreferrer"">Protocol Buffers</a>)</li>
<li><strong>There are a lot of good formats out there</strong>. Even if you don't like XML. Try CSV. Or JSON. Or .properties. Or even XML. Lots of tools exist for parsing these already in lots of languages. And it only takes 5mins to write them again if mysteriously all the source code gets lost.</li>
<li><strong>Diffs become easy</strong>. When you check in to version control it is much easier to see what has changed. And view it on the Web. Or your iPhone. Binary, you know something has changed, but you rely on the comments to tell you what.</li>
<li><strong>Merges become easy</strong>. You still get questions on the web asking how to append one PDF to another. This doesn't happen with Text.</li>
<li><strong>Easier to repair if corrupted</strong>. Try and repair a corrupt text document vs. a corrupt zip archive. Enough said.</li>
<li><strong>Every language (and platform) can read or write it</strong>. Of course, binary is the native language for computers, so every language will support binary too. But a lot of the classic little tool scripting languages work a lot better with text data. I can't think of a language that works well with binary and not with text (assembler maybe) but not the other way round. And that means your programs can interact with other programs you haven't even thought of, or that were written 30 years before yours. There are reasons Unix was successful.</li>
</ol>

<h2>Why not, and use binary instead?</h2>

<ol>
<li><strong>You might have a lot of data</strong> - terabytes maybe. And then a factor of 2 could really matter. But premature optimization is still the root of all evil. How about use a human one now, and convert later? It won't take much time.</li>
<li><strong>Storage might be free but bandwidth isn't</strong> (Jon Skeet in comments). If you are throwing files around the network then size can really make a difference. Even bandwidth to and from disc can be a limiting factor.</li>
<li><strong>Really performance intensive code</strong>. Binary can be seriously optimised. There is a reason databases don't normally have their own plain text format.</li>
<li><strong>A binary format might be the standard</strong>. So use PNG, MP3 or MPEG. It makes the next guys job easier (for at least the next 10 years).</li>
<li><strong>There are lots of good binary formats out there</strong>. Some are global standards for that type of data. Or might be a standard for hardware devices. Some are standard serialization frameworks. A great example is <a href=""http://code.google.com/apis/protocolbuffers/"" rel=""noreferrer"">Google Protocol Buffers</a>. Another example: <a href=""http://en.wikipedia.org/wiki/Bencode"" rel=""noreferrer"">Bencode</a></li>
<li><strong>Easier to embed binary</strong>. Some data already is binary and you need to embed it. This works naturally in binary file formats, but looks ugly and is very inefficient in human readable ones, and usually stops them being human readable.</li>
<li><strong>Deliberate obscurity</strong>. Sometimes you don't want it obvious what your data is doing. Encryption is better than accidental security through obscurity, but if you are encrypting you might as well make it binary and be done with it.</li>
</ol>

<h2>Debatable</h2>

<ol>
<li><strong>Easier to parse</strong>. People have claimed that both text and binary are easier to parse. Now clearly the easiest to parse is when your language or library supports parsing, and this is true for some binary and some human readable formats, so doesn't really support either. Binary formats can clearly be chosen so they are easy to parse, but so can human readable (think CSV or fixed width) so I think this point is moot. Some binary formats can just be dumped into memory and used as is, so this could be said to be the easiest to parse, especially if numbers (not just strings are involved. However I think most people would argue human readable parsing is easier to debug, as it is easier to see what is going on in the debugger (slightly).</li>
<li><strong>Easier to control</strong>. Yes, it is more likely someone will mangle text data in their editor, or will moan when one Unicode format works and another doesn't. With binary data that is less likely. However, people and hardware can still mangle binary data. And you can (and should) specify a text encoding for human-readable data, either flexible or fixed.</li>
</ol>

<p>At the end of the day, I don't think either can really claim an advantage here.</p>

<h2> Anything else </h2>

<p>Are you sure you really want a file? Have you considered a database? :-)</p>

<p><strong>Credits</strong></p>

<p>A lot of this answer is merging together stuff other people wrote in other answers (you can see them there). And especially big thanks to Jon Skeet for his comments (both here and offline) for suggesting ways it could be improved.</p>
","568782"
"CORE Keygen Issue","7200","","<p>After fighting several versions of the CoreKeyGen created by some ""minamoto"" guy, a new version has appeared. This version is particularly sophisticated and seems to modify the actual binary itself, using a dylib known as libbassmod.dylib (this is in the keygen's Mac OS folder). </p>

<p>Has anyone ever come across this &amp; can give me advice on how to stop it?</p>

<p>If so, how can I stop the keygen? it seems like the library can see what calls my app makes and stop them somehow, I'm not too sure.</p>
","<p>I doubt that the ""Minamoto"" here is the real guy you are looking for, maybe just someone wanted to making fun of you. People in the scene won't have the time to read the post here, nor reply under their real nick.</p>

<p>Back to your questions, libbassmod.dylib is used for audio module playback. It's often used in windows key generaters by the Scene to play audio module formats such as XM, IT, S3M, MOD, MTM, UMX. more info you can read up here:</p>

<p><a href=""http://www.un4seen.com/"" rel=""noreferrer"">http://www.un4seen.com/</a></p>

<p>And about the idea of fighting them or making fun of them in your blog, IMO it will only bring you troubles(Espicially some groups like this one, CORE(which stands for ""Challenge Of Reverse Engineering""), google for it if you want to know more about it).</p>

<p>Enough said, if I were you, I'd put my time on making my applications better instead of coding protections. That's the right and only way to get more customers(And believe me they hate software protections). Those who use cracks will never buy anything from you(Just see all those thinsg on MSJ), they use the cracked version of your application was just because they can use it for free, so actually you lose nothing.</p>
","2792051"
"How to REALLY strip a binary in MacOs","7189","","<p>MacOs 10.6, if I have a file ""unwanted.c"" which contains:</p>

<pre><code>class secret_thing {
public:
secret_thing() {}
void revealing_method_name() {}
};

main()
{
    secret_thing obj;
    obj.revealing_method_name();
}
</code></pre>

<p>Now I do:</p>

<pre><code>$ g++ unwanted.c -o unwanted
$ strip unwanted
$ nm unwanted | grep secret
0000000100000eb8 T __ZN12secret_thing21revealing_method_nameEv 
0000000100000eae T __ZN12secret_thingC1Ev
</code></pre>

<p>If I split out the interface and implementation of the secret class, as most people do when writing C++ code, then there are no unwanted symbols in the stripped executable.  Sadly, I am handed an existing code base of many thousand lines of code and this isn't one of my choices.</p>

<p>I have tried -fno-rtti, as a wild guess, and that didn't fix anything.  I have prayed to the Google gods and found many references to strip clubs, but no helpful links.  I have skimmed the man pages for strip, g++, and ld on the mac, and there were no obvious things to try, though the phrase ""private externs"" was intriguing, I couldn't figure out what to do about that.</p>

<p>[ update ]
Sadly, there turns out to be a problem with my attempt to make a small example.  Here is a more complicated example, which is closer to what the real problem is, which still has unwanted symbols if it is built optimized.</p>

<p>I apologize for the bad examples.  It turns out to be hard to find the smallest actual problem.  Many thanks for the answers, though, each answer pushes me close to a solution.</p>

<pre><code>class base {
public:
    virtual int revealing_method_name() = 0;
    virtual ~base() {};
};

class secret_thing : public base {
public:
    int revealing_method_name() { return 0; };
};

class other_thing : public base {
public:
    int revealing_method_name() { return 1; };
};

int main(int argc, char**)
{
    base *object = 0;
    if( argc &gt; 1 ) object = new secret_thing;
    else object = new other_thing;

    return object-&gt;revealing_method_name();
}
</code></pre>
","<p>Using the following compile line I successfully strip the symbols from the executable:</p>

<pre><code>$ g++ -Xlinker -unexported_symbol -Xlinker ""*"" -o executable file.cpp
$ strip executable
</code></pre>

<p>Given the latest sample file, this results in:</p>

<pre><code>$ nm executable
                 U __ZTVN10__cxxabiv117__class_type_infoE
                 U __ZTVN10__cxxabiv120__si_class_type_infoE
                 U __ZdlPv
                 U __Znwm
                 U ___cxa_pure_virtual
                 U ___gxx_personality_v0
0000000100000000 A __mh_execute_header
                 U _exit
                 U dyld_stub_binder
</code></pre>
","1943253"
"python read binary from specific position","7170","","<p>I have a huge binary file from which I want to read some bytes from exact positions in the file. How can I access specific bytes from binary file not having to loop through all bytes from the beginning of the file?
Thanx,</p>
","<p>Make sure you open the file with the ""b"" attribute (for example: <code>file(""myfile.bin"", ""rb"")</code>). Then use the <code>seek()</code> method of the file object.</p>

<p>Look here: <a href=""http://docs.python.org/release/2.4.4/lib/bltin-file-objects.html"" rel=""nofollow noreferrer"">http://docs.python.org/release/2.4.4/lib/bltin-file-objects.html</a></p>
","7713338"
"Cannot read simple binary integers from file? (C++)","7162","","<p>My code is simply as this:</p>

<p><strong>UPDATED</strong>:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;fstream&gt;

using namespace std;

int main(int argc, char **argv)
{
  ifstream r(""foo.bin"", ios::binary);
  ofstream w(""foo.bin"", ios::binary);
  int i;

  int ints[10] = {0,1,2,3,4,5,6,8,9};
  w.write((char*)&amp;ints, sizeof(ints));

  int in_ints[10];
  r.read((char*)&amp;in_ints, sizeof(in_ints));

  for(i = 0;i &lt; 10;i++) {
    cout &lt;&lt; in_ints[i] &lt;&lt; "" "";
  }
  cout &lt;&lt; endl;

  return 0;
}
</code></pre>

<p>Now, the write portion appears to be successful, for example running the od command with 32 bit longs (my system is 32 bit) will display the correct sequence, including a hex dump.</p>

<p>Reading however, I get random sequences such and negative integers that should not happen (it is split up, and mostly zeros as my integers are small, the sign bits should not be on.)</p>

<p>Do you see why my read method has failed to work, when it is really an opposite of my write method?</p>
","<p>try <code>w.flush()</code> or <code>w.close()</code> before <code>r.read</code>. the problem is when you write it usually bufferes text and doesn't save it in file. so there is nothing realy in file for <code>r.read</code>.</p>
","6262260"
"Pythonic way to iterate over bits of integer","7159","","<p>Let's <code>a=109</code> or <code>1101101</code> in binary. How do I iterate over bits of this number, eg: <code>[64, 32, 8, 4, 1]</code></p>
","<p>There's a trick for just getting the 1's out of the binary representation without having to iterate over all the intervening 0's:</p>

<pre><code>def bits(n):
    while n:
        b = n &amp; (~n+1)
        yield b
        n ^= b


&gt;&gt;&gt; for b in bits(109):
    print(b)


1
4
8
32
64
</code></pre>
","8898977"
"Is ((a + (b & 255)) & 255) the same as ((a + b) & 255)?","7158","","<p>I was browsing some C++ code, and found something like this:</p>

<pre><code>(a + (b &amp; 255)) &amp; 255
</code></pre>

<p>The double AND annoyed me, so I thought of:</p>

<pre><code>(a + b) &amp; 255
</code></pre>

<p>(<code>a</code> and <code>b</code> are 32-bit unsigned integers)</p>

<p>I quickly wrote a test script (JS) to confirm my theory:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>for (var i = 0; i &lt; 100; i++) {
    var a = Math.ceil(Math.random() * 0xFFFF),
        b = Math.ceil(Math.random() * 0xFFFF);

    var expr1 = (a + (b &amp; 255)) &amp; 255,
        expr2 = (a + b) &amp; 255;

    if (expr1 != expr2) {
        console.log(""Numbers "" + a + "" and "" + b + "" mismatch!"");
        break;
    }
}</code></pre>
</div>
</div>
</p>

<p>While the script confirmed my hypothesis (both operations are equal), I still don't trust it, because 1) <a href=""https://xkcd.com/221/"" rel=""noreferrer"">random</a> and 2) I'm not a mathematician, <a href=""https://i.imgur.com/Boq967h.png"" rel=""noreferrer"">I have no idea what am I doing</a>.</p>

<p>Also, sorry for the Lisp-y title. Feel free to edit it.</p>
","<p>They are the same. Here's a proof:</p>

<p>First note the identity <code>(A + B) mod C = (A mod C + B mod C) mod C</code></p>

<p>Let's restate the problem by regarding <code>a &amp; 255</code> as standing in for <code>a % 256</code>. This is true since <code>a</code> is unsigned.</p>

<p>So <code>(a + (b &amp; 255)) &amp; 255</code> is <code>(a + (b % 256)) % 256</code></p>

<p>This is the same as <code>(a % 256 + b % 256 % 256) % 256</code> (I've applied the identity stated above: note that <code>mod</code> and <code>%</code> are equivalent for unsigned types.)</p>

<p>This simplifies to <code>(a % 256 + b % 256) % 256</code> which becomes <code>(a + b) % 256</code> (reapplying the identity). You can then put the bitwise operator back to give</p>

<p><code>(a + b) &amp; 255</code></p>

<p>completing the proof.</p>
","40751824"
"Read the full content of a binary file","7144","","<p><br />
I have this piece of <b>C</b> code:</p>

<pre><code>[...]
struct stat info;
char *filename = ""just_a_binary_file"";
stat(filename, &amp;info);
printf(""FILE SIZE: %d\n"", info.st_size);

char *content = (char *)malloc(info.st_size * sizeof(char *));
FILE *fp = fopen(filename, ""rb"");
fread(content, info.st_size, 1, fp);
fclose(fp);

printf(""STRING LENGTH: %d\n"", strlen(content));
[...]
</code></pre>

<p>the output is:</p>

<pre><code>FILE SIZE: 20481
STRING LENGTH: 6
</code></pre>

<p>the problem is that file contains some Zero-Bytes and when I put the file content into a variable char* the string is truncated at the first occurrence of '\0' (chr(0) precisely).</p>

<p>The question is how can I get the full binary content into a variable char*?</p>
","<p>First of all, you allocate way too much memory. <code>info.st_size * sizeof(char)</code> is enough. You store chars, not pointers.</p>

<p>Then you need to store the file size and use memory functions instead of string functions. A blob of data that contains null bytes is not a string per definition. So it's impossible to get its length except by using the already-known file size.</p>
","7013343"
"Writing an ASCII string as binary in python","7129","","<p>I have a ASCII string = ""abcdefghijk"". I want to write this to a binary file in binary format using python.</p>

<p>I tried following:</p>

<pre><code>str  = ""abcdefghijk""
fp = file(""test.bin"", ""wb"")
hexStr = """".join( ((""\\x%s"") % (x.encode(""hex""))) for x in str)
fp.write(hexStr)
fp.close()
</code></pre>

<p>However, when I open the test.bin I see the following in ascii format instead of binary.</p>

<pre><code>\x61\x62\x63\x64\x65\x66\x67
</code></pre>

<p>I understand it because for two slashes here (""\\x%s""). How could I resolve this issue? Thanks in advance. </p>

<p><strong>Update :</strong></p>

<p>Following gives me the expected result:</p>

<pre><code>file = open(""test.bin"", ""wb"")
file.write(""\x61\x62\x63\x64\x65\x66\x67"")
file.close() 
</code></pre>

<p>But how do I achieve this with ""abcdef"" ASCII string. ?</p>
","<p>You misunderstood what <code>\xhh</code> does in Python strings. Using <code>\x</code> notation in Python strings is <em>just syntax</em> to produce certain codepoints.</p>

<p>You can use <code>'\x61'</code> to produce a string, or you can use <code>'a'</code>; both are just two ways of saying <em>give me a string with a character with hexadecimal value 61, e.g. the <code>a</code> ASCII character</em>:</p>

<pre><code>&gt;&gt;&gt; '\x61'
'a'
&gt;&gt;&gt; 'a'
'a'
&gt;&gt;&gt; 'a' == '\x61'
True
</code></pre>

<p>The <code>\xhh</code> syntax then, is <em>not the value</em>; there is no <code>\</code> and no <code>x</code> and no <code>6</code> and <code>1</code> character in the final result. </p>

<p>You should <em>just write your string</em>:</p>

<pre><code>somestring = 'abcd'

with open(""test.bin"", ""wb"") as file:
    file.write(somestring)
</code></pre>

<p>There is nothing magical about binary files; the only difference with a file opened in text mode is that a binary file will not automatically translate <code>\n</code> newlines to the line separator standard for your platform; e.g. on Windows writing <code>\n</code> produces <code>\r\n</code> instead.</p>

<p>You certainly do not have to produce hexadecimal escapes to write binary data.</p>

<p>On Python 3 strings are Unicode data and cannot just be written to a file without encoding, but on Python the <code>str</code> type is <em>already</em> encoded bytes. So on Python 3 you'd use:</p>

<pre><code>somestring = 'abcd'

with open(""test.bin"", ""wb"") as file:
    file.write(somestring.encode('ascii'))
</code></pre>

<p>or you'd use a byte string literal; <code>b'abcd'</code>.</p>
","29151455"
"How can a bash script write out a binary file, without using uudecode?","7125","","<p>I've got a little puzzler here for the bash scripting experts... I have a bash script that needs to create a small (80 byte) binary file when it runs.  The contents of the file need to be contained inside the script itself (i.e. I don't want to just package the file along with the script).</p>

<p>My script currently does it like this:</p>

<pre><code>echo 'begin-base64 644 dummy.wav' &gt; /tmp/dummy.uu
echo 'UklGRkgAAABXQVZFZm10IBAAAAADAAEAAHcBAADcBQAEACAAZmFjdAQAAAAAAAAAUEVBSxAAAAAB' &gt;&gt; /tmp/dummy.uu
echo 'AAAAQDYlTAAAAAAAAAAAZGF0YQAAAAA=' &gt;&gt; /tmp/dummy.uu
echo '====' &gt;&gt; /tmp/dummy.uu
uudecode -o /tmp/dummy.wav /tmp/dummy.uu
rm /tmp/dummy.uu
</code></pre>

<p>... after the above runs, I have my file /tmp/dummy.wav.  But I just found out that the computer this script is to run on does not have uudecode installed (and I'm not allowed to install it), so I need to find some other way to create this file.  Any ideas?</p>
","<p>Some installers do something similar to this:</p>

<pre><code>#!/bin/bash
tail -n +4 $0 | tar xvzf -
exit
&lt;tgz file appended here&gt;&lt;newline&gt;
</code></pre>
","3122282"
"How to convert XML to Android Binary XML","7119","","<p>I'm creating a piece of software that can deploy Android apps but the AndroidManifest that is located within the apk file is in a custom binary XML format. What I am trying to find out is if there is a tool that will allow me to add my own AndroidManifest.xml file into an apk (converting it to AXML when it is added), or is the format explained anywhere so I can create my own converter</p>
","<p>Figured this out using the Android packaging tool (aapt.exe)</p>

<pre><code>aapt.exe package -f -m -J src -M AndroidManifest.xml -S res -A assets  -0 """" -I android.jar -F MyApp.apk
</code></pre>

<p>According to the <a href=""http://manpages.org/aapt"" rel=""nofollow"">docs</a>:</p>

<pre><code>-f
    force overwrite of existing files

-m
    make package directories under location specified by -J

-J
    specify where to output R.java resource constant definitions

-M
    specify full path to AndroidManifest.xml to include in zip

-S
    directory in which to find resources. Multiple directories will be scanned and the first match found (left to right) will take precedence

-A
    additional directory in which to find raw asset files

-0
    specifies an additional extension for which such files will not be stored compressed in the .apk. An empty string means to not compress any files at all.

-I
    add an existing package to base include set

-F
    specify the apk file to output
</code></pre>

<p>This takes a plain xml manifest and packages it into binary XML and inserts it into the apk.</p>

<p>Unfortunately it requires that the resources and assets be present (if you refer to them within the manifest file itself). I also have to add any other data back into the apk file. Not ideal but it works at least</p>
","11377073"
"Converting Signed Int to Unsigned String value in Java","7104","","<p>To keep this short, I am getting a signed number, -25771 (in Java), that I need the unsigned String representation of, which is ""4294941525"".  Java thinks the number is signed two's complement, but I need its unsigned value.</p>

<p>I noticed the Javadoc for the toString() method for Integers only converts to signed representation.</p>

<p>Is there not a bitwise operation such as ""&amp; 0xFF"" that I can do to get the unsigned number?</p>
","<p>I would try</p>

<pre><code>int val = -25771;
System.out.println(Long.toString(val &amp; 0xFFFFFFFFL));
</code></pre>

<p>prints</p>

<pre><code>4294941525
</code></pre>

<p>or</p>

<pre><code>"""" + (val &amp; 0xFFFFFFFFL)
</code></pre>
","10625556"
"using powershell to change registry binary data","7093","","<p>I understand that with powershell it's possible to change registry values.</p>

<p>for example, here: <a href=""http://poshcode.org/3504"" rel=""nofollow noreferrer"">http://poshcode.org/3504</a></p>

<p>we can set the properties like this:</p>

<pre><code>Set-ItemProperty 'HKCU:\Software\Microsoft\Windows\Shell\Associations\UrlAssociations\ftp\UserChoice' -name ProgId IE.FTP
</code></pre>

<p><strong>however, is it possible to set these binary values using powershell??</strong></p>

<p><img src=""https://i.stack.imgur.com/VOMTf.png"" alt=""enter image description here""></p>
","<ol>
<li>Read the value (a byte array)</li>
<li>Modify the array element</li>
<li>Write the byte array back to the registry key.</li>
</ol>

<p>Here's an example:</p>

<pre><code>$key = 'HKCU:\Software\Microsoft\Windows\CurrentVersion\Internet Settings\Connections'

$data = (Get-ItemProperty -Path $key -Name DefaultConnectionSettings).DefaultConnectionSettings
$data[8] = 9
Set-ItemProperty -Path $key -Name DefaultConnectionSettings -Value $data
</code></pre>
","15914470"
"WiX - how to create bin subdirectory?","7092","","<p>I'm missing something obvious.  How do you put the .dll's in a subdirectory called ""bin"" under your install directory?  I'm trying to follow this tutorial: 
<a href=""http://www.tramontana.co.hu/wix/lesson5.php#5.3"" rel=""nofollow noreferrer"">http://www.tramontana.co.hu/wix/lesson5.php#5.3</a>
to deploy a WCF web service.  So I need to copy the .svc files and the .bin files, along with a few other, but starting with just these two.  I'm using Wix 3.5 under Visual Studio.</p>

<pre><code>    &lt;Directory Id=""TARGETDIR"" Name=""SourceDir""&gt;
        &lt;Directory Id=""ProgramFilesFolder""&gt;
            &lt;Directory Id=""INSTALLLOCATION"" Name=""TFBIC.RCT.WCFWebServicesWIXSetup""&gt;
                &lt;Component Id=""ProductComponent"" Guid=""E9A375FB-DF6A-4806-8B0B-03BE4A50802F""&gt; 
                    &lt;File Id='SVC1' Name='CreateUpdateReturnService.svc' DiskId='1' Source='../TFBIC.RCT.WCFWebServices/CreateUpdateReturnService.svc'  /&gt;
                &lt;/Component&gt;
            &lt;/Directory&gt;
            &lt;Directory Id=""INSTALLLOCATION"" Name=""TFBIC.RCT.WCFWebServicesWIXSetup""&gt;
                &lt;Component Id=""ProductComponent"" Guid=""E9A375FB-DF6A-4806-8B0B-03BE4A50802F""&gt;
                    &lt;File Id='DLL1' Name='TFBIC.RCT.WCFWebServices.dll' DiskId='1' Source='../TFBIC.RCT.WCFWebServices/bin/TFBIC.RCT.WCFWebServices.dll'  /&gt;
                &lt;/Component&gt;
            &lt;/Directory&gt;
        &lt;/Directory&gt;
        &lt;Component Id='TestWebVirtualDirComponent' Guid='9586807E-9065-48e8-8E73-13A9191962E5'&gt;
            &lt;iis:WebVirtualDir Id='TestWebVirtualDir' Alias='Test' Directory='InstallDir'
              WebSite='DefaultWebSite'&gt;
                &lt;iis:WebApplication Id='TestWebApplication' Name='Test' /&gt;
            &lt;/iis:WebVirtualDir&gt;
        &lt;/Component&gt;

    &lt;/Directory&gt;
</code></pre>

<p>I tried putting \bin on the ID and the name attribute, and it didn't like either (invalid character). </p>

<p>Also, with IIS, is the best practice to install in c:\program files, or in c:\inetpub\wwwroot?  How to I switch the default directory to c:\inetpub\wwwroot\myproj? </p>

<p>These are my various first experiments with WiX. </p>
","<p>Each  tag creates a new directory. For each nested tag, there's a new directory. So, if you want to have a ""bin"" under INSTALLLOCATION, use like below.</p>

<pre><code>&lt;Directory Id=""INSTALLLOCATION"" Name=""TFBIC.RCT.WCFWebServicesWIXSetup""&gt; 
    &lt;Directory Id=""BinFolder"" Name=""bin""&gt; 
        &lt;Component Id=""ProductComponent"" Guid=""E9A375FB-DF6A-4806-8B0B-03BE4A50802F""&gt;  
            &lt;File Id='SVC1' Name='CreateUpdateReturnService.svc' DiskId='1' Source='../TFBIC.RCT.WCFWebServices/CreateUpdateReturnService.svc'  /&gt; 
        &lt;/Component&gt; 
     &lt;/Directory&gt; 
 &lt;/Directory&gt;
</code></pre>
","2052068"
"Convert binary string to integer string c++","7088","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/117844/converting-string-of-1s-and-0s-into-binary-value"">Converting string of 1s and 0s into binary value</a>  </p>
</blockquote>



<p>I would like to convert a binary string to an integer string in c++. e.g:</p>

<p><code>""000000000010""</code> becomes <code>""2""</code></p>

<p>I have the following constraint: i can not convert this string to an integer type and then convert it again to string because that binary string can be very huge!</p>

<p>I already tried to do it with <code>stringstream</code>, inserting the binary string to it with the flag <code>std::stringstream::binary</code> and then output the content using the <code>std::dec</code> flag, but it doesn't work</p>

<p>Thank you all in advance.</p>
","<p>You could go about it like this:</p>

<ul>
<li>create a new output string, containing ""0""</li>
<li>for each character of the (reversed) original string:
<ul>
<li>multiply the result by 2 (digit by digit, taking care of the carry)</li>
<li>if the digit is a <code>'1'</code>, add 1 to the result (as above)</li>
</ul></li>
<li>reverse the result (use <code>std::reverse</code>)</li>
</ul>
","12056817"
"How to convert a binary IPv6 address into hexadecimal","7076","","<p>I am receiving a 128-bit binary address and I need to convert it into hexadecimal format. This is what I have to do:</p>

<ul>
<li>I will receive 128-bit binary number</li>
<li><p>I need to divide it into 8 blocks of 16-bits each, so I will have 8 variables each having 16-bits.</p>

<p><strong>0010000111011010   0000000011010011   0000000000000000   0010111100111011 0000001010101010   0000000011111111   0000000000000000   0000000000000000</strong></p></li>
<li><p>Now, I need to further divide these 16-bits into 4-bits each i.e a nibble</p>

<p><strong>0010 0001 1101 1010<br>
  0000 0000 1101 0011<br>
  0000 0000 0000 0000</strong></p></li>
<li><p>So, now I will get four sub variables for each variable</p></li>
<li>Each variable is 16-bits long and sub variables are 4-bits long</li>
<li><p>Than, I need to convert each of these sub variables into hexadecimal</p>

<p><strong>0010 0001 1101 1010</strong></p>

<p><strong>2     1   D    A</strong></p></li>
<li><p>Combine all the sub variables and form an IPv6 address in hexadecimal form:</p>

<p><strong>21DA:00D3:0000:2F3B:02AA:00FF:0000:0000</strong></p></li>
</ul>

<p>Can anyone tell me how to do it in C++?</p>
","<p>To get the four highest bits of a 16-bit value, you shift it right by 12 bits. This will cause the top bits to be zeroes so no masking needed. For the others you (optionally) shift right and mask out the four lowest bits with the bitwise and operator <code>&amp;</code>.</p>

<p>To make the value gotten from the above steps to a hexadecimal digit in character form, then for values lower than 10 add <code>'0'</code> (if you're on a computer with with ASCII encoding), and for values at 10 or higher then subtract ten and add e.g. <code>'A'</code>.</p>

<hr>

<p>There are simpler ways of course, like using e.g. <code>sprintf</code> to convert the number directly. Just get the 16-bit value into an unsigned short, and do e.g.</p>

<pre><code>printf(""%04hx\n"", value_as_unsigned_short);
</code></pre>

<hr>

<p>Let say you have the binary number <code>0001001010101011</code>. This is, in hexadecimal presentation <code>12ab</code>.</p>

<p>If the binary number is in an integer variable, lets say one named <code>value</code>, we can get the hexadecimal representation as a string like this:</p>

<pre><code>// First get each digit, one by one
digit0 = value &amp; 0x0f;  // Mask out everything but the lowest four bits
digit1 = (value &gt;&gt;  4) 0x0f;
digit2 = (value &gt;&gt;  8) 0x0f;
digit3 = value &gt;&gt; 12;

// Now make a string out of those four digits
char str[5];  // Four digits plus the string terminator

// If a digit is less than 10, then add '0'  to get an ASCII character
// Else decrease by ten (to get a number between 0 and 5) and add 'A'
str[0] = digit3 &lt; 10 ? digit3 + '0' : (digit3 - 10) + 'A';
str[1] = digit2 &lt; 10 ? digit2 + '0' : (digit2 - 10) + 'A';
str[2] = digit1 &lt; 10 ? digit1 + '0' : (digit1 - 10) + 'A';
str[3] = digit0 &lt; 10 ? digit0 + '0' : (digit0 - 10) + 'A';
str[4] = '\0'; // Terminate string

printf(""value is in hex %s\n"", str);
</code></pre>

<p>The above code will print</p>

<pre>
value is in hex 12AB
</pre>

<p>However that is a lot of code, though it can be reused for all numbers. If you already have your 16-bit number in the integer variable <code>value</code>, then it's much easier to just write</p>

<pre><code>printf(""value is in hex %04hX\n"", value);
</code></pre>

<p>The result of both code snippets above will be just the same.</p>

<hr>

<p>Regarding your edit:</p>

<pre><code>std::ostringstream oss;
for (size_t i = 0; i &lt; 8; ++i, aBinaryIPAddress += 2)
{
    // Take the first byte, and shift it left 8 bits, making it
    // the high byte of a 16-bit number. Then or (or add) the next
    // byte at the low 8 bits in the 16-bit number.
    // The casting is needed because we're working with 16-bit numbers
    // and not bytes.
    uint16_t value = static_cast&lt;uint16_t&gt;(*aBinaryIPAddress &lt;&lt; 8) |
                     static_cast&lt;uint16_t&gt;(*(aBinaryIPAddress + 1));

    oss &lt;&lt; std::setfill('0') &lt;&lt; std::setw(4) &lt;&lt; std::hex &lt;&lt; value;
    if (i &lt; 7)
        oss &lt;&lt; ':';
}

std::cout &lt;&lt; ""Address is "" &lt;&lt; oss.str() &lt;&lt; '\n';
</code></pre>
","19785945"
"Represent Unsigned Integer in Binary","7061","","<p>How can I represent an unsigned integer as Binary ?</p>
","<p>To create a string representation of some integer value you can use the following <a href=""http://codepad.org/7NjcwuwA"" rel=""nofollow"">code</a>:   </p>

<pre><code>#include &lt;stdlib.h&gt;

int main(int argc, char *argv[]) {
  int j;
  unsigned int value = 1024+2048+4096; // some value
  char mask[8*sizeof(unsigned int) + 1] = {0};
  for (j = 0; j &lt; (8*sizeof(unsigned int) + 1); j++) {
    mask[j] = (value &lt;&lt; j) &amp; (1 &lt;&lt; (8*sizeof(unsigned int)-1)) ? '1' : '0';
  }
  printf(""value is b%s\n"", mask);
  return 0;
}
</code></pre>
","19823496"
"How do I extract bits from 32 bit number","7038","","<p>I have do not have much knowledge of C and im stuck with a problem since one of my colleague is on leave.</p>

<p>I have a 32 bit number and i have to extract bits from it. I did go through a few threads but im still not clear how to do so. I would be highly obliged if someone can help me.</p>

<p>Here is an example of what i need to do:</p>

<p>Assume hex number= 0xD7448EAB.
In binary= <strong>1101 01</strong><em>11 0100 0100 1000 11</em><strong>10 1010 1011</strong>
I need to extract  16 bits, and output that value.  I want bits 10 through 25.</p>

<p>The lower 10 bits (Decimal) are ignored. i.e.,10 1010 1011 are ignored.<br>
And the upper 6 bits (Overflow) are ignored. i.e., 1101 01 are ignored.</p>

<p>The remaining 16 bits of data needs to be the output which is 11 0100 0100 1000(numbers in italics are needed as the output).</p>

<p>This was an example but i will keep getting different hex numbers all the time and i need to extract the same bits as i explained.</p>

<p>How do i solve this?</p>

<p>Thank you.</p>

<p>For this example you would output 1101 0001 0010 0011, which is 0xD123, or 53,539 decimal.</p>
","<p>You need <em>masks</em> to get the bits you want. <em>Masks</em> are numbers that you can use to sift through bits in the manner you want (keep bits, delete/clear bits, modify numbers etc). What you need to know are the <em>AND, OR, XOR, NOT, and shifting</em> operations. For what you need, you'll only need a couple.</p>

<p>You know shifting: <code> x &lt;&lt; y </code> moves bits from <em>x</em> *y positions to the left*. </p>

<p>How to get x bits set to 1 in order: <code> (1 &lt;&lt; x) - 1 </code></p>

<p>How to get x bits set to 1, in order, starting from y to y + x: <code> ((1 &lt;&lt; x) -1) &lt;&lt; y </code></p>

<p>The above is your mask for the bits you need. So for example if you want 16 bits of 0xD7448EAB, from 10 to 25, you'll need the above, for x = 16 and y = 10.</p>

<p>And now to get the bits you want, just <em>AND</em> your number 0xD7448EAB with the mask above and you'll get the <em>masked</em> 0xD7448EAB with only the bits you want. Later, if you want to go through each one, you'll need to shift your result by 10 to the right and process each bit at a time (at position 0).</p>

<p>The answer may be a bit longer, but it's better design than just hard coding with 0xff or whatever.</p>
","21540299"
"How do you programmatically change the WCF message encoding for NetTcp?","7029","","<p>I have a custom intranet application that has no interoperability requirements.  We programatically construct a NetTcp channel in duplex mode for passing messages.  We wanted to change the message encoding but haven't been able to figure out how to make that happen.</p>

<p>The approach we have taken (unsuccessfully) has been to extend the NetTcpBinding into a new class called LeanTcpBinding as follows:</p>

<pre><code>
internal class LeanTcpBinding : NetTcpBinding
{
    private static readonly ILog _log =
        LogManager.GetLogger(System.Reflection.MethodBase.GetCurrentMethod().DeclaringType);

    public override BindingElementCollection CreateBindingElements()
    {
        BindingElementCollection bindingElementCollection = base.CreateBindingElements();
        BindingElement encodingElement = bindingElementCollection.FirstOrDefault(
            bindingElement => bindingElement is BinaryMessageEncodingBindingElement);
        if (encodingElement != null)
        {
            int index = bindingElementCollection.IndexOf(encodingElement);
            bindingElementCollection.RemoveAt(index);
            bindingElementCollection.Insert(index, new LeanBinaryMessageEncodingBindingElement());
        }
        else
        {
            _log.Warn(""Encoding not found"");
        }

        return bindingElementCollection;
    }
}
</code></pre>

<p>Obviously, we're trying to replace the default BinaryMessageEncodingBindingElement with our own.  Just to get use started, the LeanBinaryMessageEncodingBindingElement is an extension of the BinaryMessageEncodingBindingElement as follows:</p>

<pre><code>
 internal class LeanBinaryMessageEncodingBindingElement : MessageEncodingBindingElement
 {
        private readonly BinaryMessageEncodingBindingElement _bindingElement;

        /// 
        /// Initializes a new instance of the  class.
        /// 
        public LeanBinaryMessageEncodingBindingElement()
        {
            _bindingElement = new BinaryMessageEncodingBindingElement();
        }

        /// 
        /// Initializes a new instance of the  class.
        /// 
        /// The binding element.
        public LeanBinaryMessageEncodingBindingElement(BinaryMessageEncodingBindingElement bindingElement)
        {
            _bindingElement = bindingElement;
        }

        /// 
        /// Initializes a new instance of the  class.
        /// 
        /// The element to be cloned.
        /// The binding element.
        public LeanBinaryMessageEncodingBindingElement(MessageEncodingBindingElement elementToBeCloned, BinaryMessageEncodingBindingElement bindingElement)
            : base(elementToBeCloned)
        {
            _bindingElement = bindingElement;
        }

        /// 
        /// When overridden in a derived class, returns a copy of the binding element object.
        /// 
        /// 
        /// A  object that is a deep clone of the original.
        /// 
        public override BindingElement Clone()
        {
            return new LeanBinaryMessageEncodingBindingElement(
                (BinaryMessageEncodingBindingElement)_bindingElement.Clone());
        }

        /// 
        /// When overridden in a derived class, creates a factory for producing message encoders.
        /// 
        /// 
        /// The  used to produce message encoders.
        /// 
        public override MessageEncoderFactory CreateMessageEncoderFactory()
        {
            return new LeanBinaryMessageEncoderFactory(_bindingElement.CreateMessageEncoderFactory());
        }

        /// 
        /// When overridden in a derived class, gets or sets the message version that can be handled by the message encoders produced by the message encoder factory.
        /// 
        /// 
        /// The  used by the encoders produced by the message encoder factory.
        /// 
        public override MessageVersion MessageVersion
        {
            get { return _bindingElement.MessageVersion; }
            set { _bindingElement.MessageVersion = value; }
        }
 }
</code></pre>

<p>When I try to use the binding it does exactly what I think it should do ... it replaces the BinaryMessageEncodingBindingElement.  However, I never get any calls to the LeanBinaryMessageEncodingBindingElement.CreateMessageEncoderFactory(), even though messages are being exchanged across the channel.</p>

<p>Anyone have any suggestions on how to do this properly?</p>
","<p>Kenny Wolf clarified what was missing and it's documented in the blog entry below.</p>

<p><a href=""http://kennyw.com/?p=170"" rel=""nofollow noreferrer"">http://kennyw.com/?p=170</a></p>

<p>For the impatient, the problem is that by default the MessageEncoderBindingElement does not add itself to the context's binding parameters.  As a result, when the transport later goes to find the MessageEncoderBindingElement it can not find the one that I (or you) have created and has the silent failure that I noted in my original post.</p>

<p>Unfortunately, you'll have to override all of the CanBuildXXX and BuildXXX methods as follows to ensure that you are adding the binding element to the binding parameters of the context.</p>

<pre>
<code>
        public override bool CanBuildChannelFactory(BindingContext context)
        {
            if (context == null) {
                throw new ArgumentNullException(""context"");
            }

            context.BindingParameters.Add(this);
            return context.CanBuildInnerChannelFactory();
        }

        public override bool CanBuildChannelListener(BindingContext context)
        {
            if (context == null) {
                throw new ArgumentNullException(""context"");
            }

            context.BindingParameters.Add(this);
            return context.CanBuildInnerChannelListener();
        }

        public override IChannelFactory BuildChannelFactory(BindingContext context)
        {
            if (context == null) {
                throw new ArgumentNullException(""context"");
            }

            context.BindingParameters.Add(this);
            return context.BuildInnerChannelFactory();
        }

        public override IChannelListener BuildChannelListener(BindingContext context)
        {
            if (context == null) {
                throw new ArgumentNullException(""context"");
            }

            context.BindingParameters.Add(this);
            return context.BuildInnerChannelListener();
        }
</code>
</pre>
","2011062"
"reading binary data from a socket in python","7015","","<p>When I run the following python example code,</p>

<pre><code>tick = 0
while True:
    tick += 1
    print tick
    data = s.recv(1024)
    if (tick == 1) and data:
        print 'from client: %s' %(data)
    elif (tick == 2) and data:
        print 'from client: %s' %(data)
</code></pre>

<p>I see,</p>

<pre><code>1
from client: client msg
2
from client: ?
3
</code></pre>

<p>My intuition tells me the 2nd call to s.recv() actually returns some data. And I am fairly certain the client is not sending the `?' character.</p>

<p>So I modify the code hoping to print the first byte of `data',</p>

<pre><code>    elif (tick == 2) and data:
        print 'from client: %s' %(data)
        print struct.unpack(""!B"", data)
</code></pre>

<p>But then I get a traceback stating: ""struct.error: unpack requires a string argument of length 1.""</p>

<p>The struct package seems to be the standard way of handling socket data.  However, this situation seems odd.  I am receiving data visually by printing and seeing a ""?"" and the code also has an ""and data"" in the conditional but I cannot unpack.</p>

<p>Is there a different way to handle binary data off a socket?</p>
","<pre><code>elif (tick == 2) and data:
        print 'from client: %r' % data # (note 1)
        print struct.unpack(""!B"", data[0]) # (note 2)
</code></pre>

<ol>
<li>Print the representation like Ignacio suggested.</li>
<li>You want to unpak one byte, so give <code>struct.unpack</code> one byte.</li>
</ol>
","6562752"
"How to create boolean method using return true statement","7014","","<p>I need to make a boolean method that takes in a string and checks if it is a binary number. If it is binary it should return true, if it contains anything other than 0s and 1s, return false.  Here is my code: </p>

<pre><code>public static boolean CheckInputCorrect(String input) {
    int len = input.length();
    for(int i=0; i&lt;len; i++)

        if(input.charAt(i) == '1' || input.charAt(i) == '0') {
            continue;
            return true;
        } else {
            break; 
            return false;
      }
 }
</code></pre>

<p>I suspect a syntax error, however no matter what I try it finds an error.
Any help would be greatly appreciated!</p>
","<p>If the current character is a <code>1</code> or a <code>0</code>, then you can't make a decision yet; it's just good so far.</p>

<p>If it's not <code>1</code> and it's not <code>0</code>, then you can immediately return <code>false</code>.  Once you have run through the entire <code>String</code>, then you can return <code>true</code> after the <code>for</code> loop ends.</p>

<pre><code>for(int i=0; i&lt;len; i++)
{
    if(! (input.charAt(i) == '1' || input.charAt(i) == '0'))
    {
       return false;
    }
}
return true;
</code></pre>
","26130815"
"How to convert bash file to a binary executable","7013","","<p>I created a binary executable from bash script on linux server through SHC. The binary created works fine on linux machines, but through mistake on Mac. How could I convert my bash file to binary executable that is able to run everywhere(ubuntu, CentOS, Mac, Cygwin)?</p>

<pre><code>    shc -v -r -T -f ir16fetcher.sh
    mv ir16fetcher.sh.x ir16fetcher
</code></pre>

<p>Shebang of my bash script</p>

<pre><code>    #!/bin/bash
</code></pre>

<p>On Linux machines</p>

<pre><code>    ./ir16installer 
    USAGE  : ir16fetcher &lt;servername/ip address&gt; [the n th latest build - optional. Default 1]
    EXAMPLE: ir16fetcher jagger 2
    EXAMPLE: ir16fetcher 167.116.6.155
    REQUIRE: Please make sure conf file in installation folder ~/IRinstall/ir16 &amp; ~/IRinstall/irmanager
</code></pre>

<p>On my Mac</p>

<pre><code>    ./ir16installer 
    -bash: ./ir16installer: cannot execute binary file
</code></pre>
","<p>You will have to do this for every architecture and operating system you need to support. In any case, there doesn't really seem to be any benefits of using this method for distribution. It adds dependencies and complicates delivery, and I'm pretty sure whatever obfuscation the ""shc"" compiler implements is easily reversed.</p>
","17325594"
"String to byte[] and vice versa?","6997","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/472906/net-string-to-byte-array-c"">.NET String to byte Array C#</a>  </p>
</blockquote>



<p>How do I convert String to byte[] array and vice versa? I need strings to be stored in some binary storage. Please show example in both directions. And one more thing: each string maybe bigger than 90Kb.</p>
","<p>If you want to use UTF-8 encoding:</p>

<pre><code>// string to byte[]
byte[] bytes = Encoding.UTF8.GetBytes(someString);

// byte[] to string
string anotherString = Encoding.UTF8.GetString(bytes);
</code></pre>
","4318718"
"Send binary file to server using post with Qt","6990","","<p>In Qt I need to send a sqlite file (binary file) up to a website using post. So what I do is that I open the file and try to read the content of it into a QByteArray that I with help of QNetworkRequest can send to the server. I can handle the request as the file is sent to the server but the file is just empty. Am I reading the content of the sqlite file wrong? (I know that the file excist) Can you see anything wrong with my code?</p>

<pre><code>QByteArray data;
QFile file(""database.sqlite"");
if (!file.open(QIODevice::ReadWrite))
    return;

QDataStream in(&amp;file);
in.setVersion(QDataStream::Qt_4_6);
in &gt;&gt; data ;

QString boundary;
QByteArray dataToSend; // byte array to be sent in POST

boundary=""-----------------------------7d935033608e2"";

QString body = ""\r\n--"" + boundary + ""\r\n"";
body += ""Content-Disposition: form-data; name=\""database\""; filename=\""database.sqlite\""\r\n"";
body += ""Content-Type: application/octet-stream\r\n\r\n"";
body += data;
body += ""\r\n--"" + boundary + ""--\r\n"";
dataToSend = body.toAscii();

QNetworkAccessManager *networkAccessManager = new QNetworkAccessManager(this);
QNetworkRequest request(QUrl(""http://www.mydomain.com/upload.aspx""));
request.setRawHeader(""Content-Type"",""multipart/form-data; boundary=-----------------------------7d935033608e2"");
request.setHeader(QNetworkRequest::ContentLengthHeader,dataToSend.size());
connect(networkAccessManager, SIGNAL(finished(QNetworkReply*)),this, SLOT(sendReportToServerReply(QNetworkReply*)));
QNetworkReply *reply = networkAccessManager-&gt;post(request,dataToSend); // perform POST request
</code></pre>
","<p>You don't need a QDataStream. Just do </p>

<pre><code>body += file.readAll()
</code></pre>
","2683665"
"(c++) Read .dat file as hex using ifstream","6976","","<p>This is my first post so sorry if I break any unwritten rules. :P I am a beginner/intermediate programmer and I need help with this program.</p>

<p>I am trying to infile/read/ifstream (whatever) a .dat file as HEX into one big string.</p>

<p>I don't want to read it as text. I want the hex format so I can search through the string and make changes to it. (Like an automatic hex editor)</p>

<p>ex. my file ""00000000.dat"" is ~7kb in size.</p>

<p>In hex editor, the hex look like this:</p>

<pre><code>0A 00 00 0A 00 05 4C 65 76 65 6C 07 00 06 42 6C 6F 63 6B 73 00 00 80 00 07 FF 39
01 FF 03 03 02 FF 3F 00 07 FF 39 01 FF 03 03 02 FF 3F 00 07 FF 39 01 FF 03 03 02
FF 3F 00 07 FF 39 01 FF 03 03 02 FF 3F 00 07 FF 39 01 FF 03 03 02 FF 3F 00 07 FF
39 01 FF 03 03 02 FF 3F 00 07 FF 39 01 FF 03 03 02 FF 3F 00 07 FF 39 01 FF 03 03
02 FF 3F 00..... for a while...
</code></pre>

<p>I need all of it in a string variable (with no spaces preferably).</p>

<p>My current code sucks and for now only prints the result. (got it from ehow) and seems to pick and choose what it wants to input/print.</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;iomanip&gt;
#include &lt;string&gt;
#include &lt;fstream&gt;

using namespace std;

int main()
{
    ifstream input;
    input.open(""00000000.dat"");

    unsigned char h1,h2;

    do
    {
        input &gt;&gt; h1;
        cout &lt;&lt; hex &lt;&lt; (unsigned int)h1;
        input &gt;&gt; h2;
        cout &lt;&lt; hex &lt;&lt; (unsigned int)h2;
    }while(!input.eof());

cin.get();
return 0;
}
</code></pre>

<p>It's a big file so I can't show yo what it prints, but it is missing some bytes. (ex ""0A 00 00 0A 00 05....."" prints as ""00 05....."") this is true for the ending as well.</p>

<p>Sorry if I didn't explain it well :(</p>
","<p>You should open the stream as binary, as mentioned. You can use the regular <code>&gt;&gt;</code> operator if you tell it not to skip white space.</p>

<pre><code>unsigned char x;
std::ifstream input(""00000000.dat"", std::ios::binary);
input &gt;&gt; std::noskipws;
while (input &gt;&gt; x) {
    std::cout &lt;&lt; std::hex &lt;&lt; std::setw(2) &lt;&lt; std::setfill('0')
              &lt;&lt; (int)x;
}
</code></pre>

<p>To get the content into a string, you can use an <code>ostringstream</code> instead of <code>cout</code>.</p>
","16410748"
"Write Int array to Stream in .NET","6976","","<p>what's the best way to write the binary representation of an int array (<code>Int32[]</code>) to a <code>Stream</code>? </p>

<p><code>Stream.Write</code> only accepts <code>byte[]</code> as source and I would like to avoid converting/copying the array to an <code>byte[]</code> (array but instead streaming directly from the 'original location').</p>

<p>In a more system-oriented language (a.k.a. C++) I would simply cast the int array to a <code>byte*</code> but as far as I understood this isn't possible with C# (and moreover, casting <code>byte*</code> to <code>byte[]</code> wouldn't work out either way)</p>

<p>Thanks</p>

<p>Martin</p>

<p>PS: Actually, I would also like to stream single <code>int</code> values. Does using <code>BinaryConverter.GetBytes()</code> create a new byte array? In this case I extend my question to how to efficiently stream single <code>int</code> values ...</p>
","<p>The simplest option would be to use <a href=""http://msdn.microsoft.com/en-us/library/system.io.binarywriter.aspx"" rel=""noreferrer""><code>BinaryWriter</code></a> wrapping your output stream, and call <a href=""http://msdn.microsoft.com/en-us/library/24e33k1w.aspx"" rel=""noreferrer""><code>Write(int)</code></a> for each of your <code>int</code> values. If that doesn't use the right endianness for you, you could use <code>EndianBinaryWriter</code> from my <a href=""http://pobox.com/~skeet/csharp/miscutil"" rel=""noreferrer"">MiscUtil</a> library.</p>

<p>I don't know of anything built-in to do this more efficiently... I'd hope that the buffering within the stream would take care of it for the most part.</p>
","3652033"
"How to send binary post data via HTTP?","6943","","<p>I already have binary data read from a file. Most of the examples I see online link directly to the file, and upload the whole file. I am looking how to upload the binary data that I already have from another source via HTTP POST in python.</p>
","<p>Alternatively:</p>

<pre><code>req = urllib2.Request(""http://example.com"", data, {'Content-Type': 'application/octet-stream'})
urllib2.urlopen(req)
</code></pre>

<p>That also shows how you can specify the Content-Type of the data.</p>
","7864829"
"Binary column SELECT with LIKE","6935","","<p>I'm trying to find specific lines of data from a <code>BINARY</code> column.</p>

<p>Example data in the <code>BINARY(2000)</code> column:</p>

<pre><code>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
</code></pre>

<p>This data has 1 result of <code>2201</code> somewhere in it. (try searching the data for 2201 and you will get 1.)</p>

<p>Now I'm trying to use this query: (it should give me 512 rows of results)</p>

<pre><code>SELECT * 
FROM table
WHERE binaryfield LIKE '%2201%'
ORDER BY key
</code></pre>

<p>But no luck in getting results.</p>

<p>Notes: 2201 actually is 290. I'm trying to look for the decimal value 290 which is 2201 in hex in the data that is in endian.</p>

<p><strong>Update:</strong></p>

<p>Tried this query (searching for: 15584)</p>

<pre><code>SELECT *
FROM CHAR_DATA1
WHERE CHAR_DATA LIKE '%'+CAST(0xE03C AS nvarchar(MAX))+'%'
ORDER BY CHAR_KEY;
</code></pre>

<p>Now its returning almost all rows. Even manually checked the rows for E03C but none was found, but when running the query it gets returned. very odd. ideas?</p>
","<p>The <a href=""http://msdn.microsoft.com/en-us/library/ms179859.aspx"" rel=""nofollow"">LIKE</a> operator only works on character data types. Try doing a <a href=""http://msdn.microsoft.com/en-us/library/ms187928.aspx"" rel=""nofollow"">CAST</a> to a string, like this:</p>

<pre><code>SELECT * 
  FROM table
 WHERE CAST(binaryfield AS nvarchar(MAX)) LIKE '%290%'
 ORDER BY key;
</code></pre>

<p>-- or --</p>

<pre><code>SELECT * 
  FROM table
 WHERE CAST(binaryfield AS nvarchar(MAX)) LIKE '%'+CAST(0x2201 AS nvarchar(MAX))+'%'
 ORDER BY key;
</code></pre>

<p>Also, if you want to look at a subset of the data (e.g. the file header), you can do something like this:</p>

<pre><code>SELECT * 
  FROM table
 WHERE CAST(LEFT(binaryfield, 8) AS nvarchar(MAX)) -- Only compares the first 8 bytes
         LIKE '%'+CAST(0x2201 AS nvarchar(MAX))+'%'
    OR CAST(SUBSTRING(binaryfield, 34, 4) AS nvarchar(MAX)) -- Compares bytes 34-38
         LIKE '%'+CAST(0x2201 AS nvarchar(MAX))+'%'
 ORDER BY key;
</code></pre>

<hr>

<p><strong>Edit</strong></p>

<p>Regarding your updated question, does this give you the results that you're expecting:</p>

<pre><code> SELECT *
   FROM CHAR_DATA1
  WHERE CHAR_DATA COLLATE SQL_Latin1_General_CP1_CI_AS
          LIKE '%'+CAST(0xE03C AS nvarchar(MAX))+'%'
 ORDER BY CHAR_KEY;
</code></pre>

<p>You shouldn't have to cast/convert the character data to binary.</p>
","13262501"
"How can I do binary search in java ArrayList<Long>?","6919","","<p>I am trying to make binary search in ArrayList, but the binarySearch method does not work for Long, as well as Double and Float. My code is</p>

<pre><code>import java.util.*;

 public class BinarySearchInArrayList
 {
     public static void main(String[]args)
     {
         ArrayList&lt;Long&gt; ar = new ArrayList();

         for(long l = 1;l&lt;100000;l++)
         {
             ar.add(l);
         }

         System.out.println(""arraylist: ""+ar); 
         System.out.println(""Which number's index do you want to know? "");
         Scanner scan = new Scanner(System.in);
         int p = scan.nextInt();
         int index = Collections.binarySearch(ar,p);
         System.out.println(""number ""+p+"" has index ""+index);
     }
</code></pre>

<p>When I use Integer instead of <code>Long</code>, it works fine, but I want to make it with <code>Long</code>. Can you help me, please?</p>
","<pre><code>int p = scan.nextInt();
int index = Collections.binarySearch(ar,p);
</code></pre>

<p>Above should be:</p>

<pre><code>long index = Collections.binarySearch(ar,p);
long p = scan.nextLong();
</code></pre>
","16237187"
"Convert byte[] to String","6910","","<p>Is there an easy way to print <code>byte[]</code> array ( zeros and ones, basically to every bit convert in ascii '1' or ascii '0') to the console ?</p>
","<p>You can output the individual bytes by converting their numeric value to base 2. Here are two ways to do it. In both, I will use this byte array:</p>

<pre><code>byte[] array = ""HälLø123§$%"".getBytes();
</code></pre>

<h2>Walk the array</h2>

<pre><code>for(final byte b : array){
    System.out.print(Integer.toString(b &amp; 0xFF /* thx Jason Day */, 2));
}
</code></pre>

<p><strong>Output:</strong></p>

<blockquote>
  <p>10010001100001110100100110110010011001100001110111000110001011001001100110110000101010011110010001001010</p>
</blockquote>

<p><strong>Reference:</strong></p>

<ul>
<li><a href=""http://download.oracle.com/javase/6/docs/api/java/math/BigInteger.html#toString%28int%29"" rel=""nofollow""><code>Integer.toString(i, radix)</code></a></li>
</ul>

<h2>Use BigInteger</h2>

<p>If you want to output the entire array in one piece, use <a href=""http://download.oracle.com/javase/6/docs/api/java/math/BigInteger.html"" rel=""nofollow""><code>BigInteger</code></a>:</p>

<pre><code>System.out.println(new BigInteger(array).toString(2));
</code></pre>

<p><strong>Output:</strong></p>

<blockquote>
  <p>100100011000011101001000110110001001100110000111011100000110001001100100011001111000010101001110010010000100101</p>
</blockquote>

<p><strong>Reference:</strong></p>

<ul>
<li><a href=""http://download.oracle.com/javase/6/docs/api/java/math/BigInteger.html#BigInteger%28byte%5B%5D%29"" rel=""nofollow""><code>BigInteger(byte[])</code></a></li>
<li><a href=""http://download.oracle.com/javase/6/docs/api/java/math/BigInteger.html#toString%28int%29"" rel=""nofollow""><code>BigInteger.toString(radix)</code></a></li>
</ul>
","4875083"
"Binary stdin and stdout","6890","","<p>I'm looking to write a pair of utilities that read in a newline separated list of integers on stdin and output their binary (4 byte) equivalent to stdout, and vice versa.</p>

<p>My first thought was a simple bash/linux command that would do this, but I was unable to find one.  My second thought was to do this in C++, but I can't figure out how to change stdin or stdout to a binary stream.</p>

<p>Any thoughts on a good way to do this?  I'm impartial to any particular programming language.</p>
","<p>In Perl, you could just try:</p>

<pre><code>perl -ne 'chomp; print pack 'i', $_;'
</code></pre>

<p>That will give you a host native signed integer of at least 32 bits, but possibly more depending on your local C compiler.</p>

<p>Other options to pack can go in place of the <code>'i'</code>, such as <code>'l'</code> which will give you a signed long, which should be 32-bits.  And there yet more options for little-endian or big-endian.</p>

<p>For the full description, please see <a href=""http://perldoc.perl.org/functions/pack.html"" rel=""nofollow noreferrer"">http://perldoc.perl.org/functions/pack.html</a>.</p>

<p>And here's your solution in C, in case you want to do it the boring way.  <code>:)</code></p>

<pre><code>#include &lt;stdio.h&gt;

int main () {
   int x;

   while (fscanf(stdin, ""%i"", &amp;x)) {
      fwrite(&amp;x, sizeof(x), 1, stdout);
   }

   return 0;
}
</code></pre>
","1477230"
"Recursive method function that counts binary 1s of an integer","6875","","<p>I want to write a recursive method function that takes a nonnegative integer n as input and returns the number of 1s in the binary representation on n. I am instructed to use the fact that this is equal to the number of 1s in the representation of n//2 (integer division), plus 1 if n is odd.</p>

<pre><code>    Usage:
    &gt;&gt;&gt; ones(0)
    0
    &gt;&gt;&gt; ones(1)
    1
    &gt;&gt;&gt; ones(14)
    3
</code></pre>

<p>ok so this is the code I got so far, it still doesn't work though. it gives me 0 no matter what I input as n.</p>

<pre><code>     def numOnes(n):
     # base case
       if n==0:
          print (0)
       elif n ==1:
          print (1)
     # recursive case
       else:
           return numOnes(n//2)+numOnes(n%2)
</code></pre>

<p>Thank you</p>
","<p>These elements you need to do it yourself:</p>

<pre><code>if integer &amp; 1 == 1: # &amp; is the binary and. &amp; 1 will give the lowest bit
    # there is a 1 in the end

integer = integer // 2 # loose one bit in the end
# or
integer = integer &gt;&gt; 1 # loose one bit in the end
</code></pre>

<p>Tell me if you need more input.</p>

<p>Your code works for me:</p>

<pre><code>&gt;&gt;&gt; def numOnes(n):
     # base case
       if n==0:
          return (0)
       elif n == 1:
          return (1)
     # recursive case
       else:
           return numOnes(n//2)+numOnes(n%2)


&gt;&gt;&gt; numOnes(0b1100011)
4
</code></pre>
","16796788"
"Replace least significant bit with bitwise operations","6874","","<p>What is a optimal way to replace the Least Significant Bit of a byte, with a provided bit?</p>

<p>I know how to do checking and comparing last bit (using for example posix ffs() function), but I want to know if there are solutions with better performance, without checking if replacing bit is 0 or 1. </p>

<p>The example is written in python as pseudocode, but I will implement the working algorithm in C:</p>

<pre><code>&gt;&gt;&gt; bin(0b1)             # bit is  '0b1'
&gt;&gt;&gt; bin(128)             # byte is '0b10000000'
&gt;&gt;&gt; bin(129)             # byte is '0b10000001'

&gt;&gt;&gt; bin(128 OPERATOR 0b1)       # Replace LSB with 1
'0b10000001'
&gt;&gt;&gt; bin(128 OPERATOR 0b0)       # Keep LSB at 0
'0b10000000'

&gt;&gt;&gt; bin(129 OPERATOR 0b1)       # Keep LSB at 1
'0b10000001'
&gt;&gt;&gt; bin(129 OPERATOR 0b0)       # Replace LSB with 0
'0b10000000'
</code></pre>

<p>Obviously operator can be a set of operations, but I'm looking for the optimal (fastest) method.</p>
","<p><code>n &amp; ~1</code> replaces the least significant bit of <code>n</code> with zero; <code>n | 1</code>, with one.</p>

<p>To replace the LSB with <code>b</code>, where <code>b</code> can be either 0 or 1, you can use <code>(n &amp; ~1) | b</code>.</p>

<p>To replace the <code>k</code>-th bit with <code>b</code> (where <code>k=0</code> stands for the LSB): <code>(n &amp; ~(1 &lt;&lt; k)) | (b &lt;&lt; k)</code>.</p>
","6059487"
"Check if a binary number has a '0' or a '1' at a specific position","6862","","<p>I'd like to check if a binary number has a '0' or a '1' at a specific position.</p>

<p>example:</p>

<p>if the binary number is: 101000100</p>

<ul>
<li>checking at position zero (that is at
the rightmost '0') should result in
'0'.</li>
<li>checking at position 2 should result
in '1'.</li>
<li>checking at position 3 should result
in '0'.</li>
<li><p>checking at position 6 should result
in '1'.</p>

<p>etc...</p></li>
</ul>

<p>I'm coding in C, so obviously I could use sprintf / scanf and the likes, but I guess there must be something better (read: more time efficient / easier)!</p>

<p>What would be a good mechanism to do this?</p>
","<p>This will filter out the bit you're looking for:</p>

<pre><code>number &amp; (1 &lt;&lt; position)
</code></pre>

<p>If you really need a 1 or 0 response, you can use this to make it a boolean value:</p>

<pre><code>!!(number &amp; (1 &lt;&lt; position))
</code></pre>

<p>Or even better (thanks <a href=""https://stackoverflow.com/users/20845/vadim-k"">Vadim K.</a>):</p>

<pre><code>(number &gt;&gt; position) &amp; 1
</code></pre>
","1981629"
"How can I do a binary encoding of a string in python?","6809","","<p>I am trying to build an md5 cracker for practice. Before I go any further here is my code:</p>

<pre><code>def offline_wordlist_attack(list_path):
      with fileinput.input(files=(list_path)) as wordlist:
          for word in wordlist:
              md5_hash_object = hashlib.md5() # constructing an md5 hash object
              md5_hash_object.update(binascii.a2b_uu(word))
              word_digest = md5_hash_object.digest() # performing the md5 digestion of the word   
              print(word_digest) # Debug
</code></pre>

<p>My issue is with <code>md5_hash_object.update(binascii.a2b_uu(word))</code>. The <a href=""http://docs.python.org/py3k/library/hashlib.html"" rel=""noreferrer"">hashlib</a> Python 3 documentation states that the string passed to <code>update()</code> should be in <strong>binary representation</strong>. The documentation uses <code>m.update(b""Nobody inspects"")</code> as an example. In my code, I can not simply attach <code>b</code> in front of the variable <code>word</code>. So I tried to use the <a href=""http://docs.python.org/py3k/library/binascii.html"" rel=""noreferrer"">binascii</a> library, but that library too, has a note in the documentation stating:</p>

<blockquote>
  <p>Note</p>
  
  <p>Encoding and decoding functions do not accept Unicode strings. Only
  bytestring and bytearray objects can be processed.</p>
</blockquote>

<p>Could somebody help me out with this? It is getting the better of me.</p>
","<p>You need to pass in a <code>bytes</code> object, rather than a <code>str</code>. The typical way to go from <code>str</code> (a unicode string in Python 3) to <code>bytes</code> is to use the <code>.encode()</code> method on the string and specify the encoding you wish to use.</p>

<pre><code>my_bytes = my_string.encode('utf-8')
</code></pre>
","12175478"
"Power of 2 formula help","6796","","<p>I understand that (2 * i == (i ^( i - 1) + 1) in Java will let me find if a number is a power of two. But can someone explain why this works?</p>
","<p>2*i == (i ^ (i-1)) + 1</p>

<p>Basically, if <code>i</code> was a a power of 2, it would have a single <code>1</code> in its bit pattern. If you subtract 1 from that, all the lower bits of that <code>1</code> bit become <code>1</code>, and that power-of-two bit will become 0. Then you do an <code>XOR</code> on the bits, which produces an all 1 bit pattern. You add 1 to that, and you get the next power of 2.</p>

<p>Remember XOR truth table:</p>

<pre><code>1 ^ 1 = 0
1 ^ 0 = 1
0 ^ 1 = 1
0 ^ 0 = 0
</code></pre>

<p>Example:</p>

<p>Let's say <code>i</code> is 256, which is this bit pattern.</p>

<pre><code>100000000 = 2^8 = 256

100000000 - 1 = 011111111 = 2^7 + 2^6 + ... + 2^0 = 255

100000000 ^ 011111111 = 111111111 = = 2^8 + 2^7 + ... + 2^0 = 511

111111111 + 1 = 1000000000 = 2^9 = 512 = 2*i
</code></pre>

<p><strong>Here's an example when you are not presented with a power of 2</strong></p>

<pre><code>i = 100 = 2^6 + 2^5 + 2^2

0110 0100

0110 0100 - 1 = 99 = 2^6 + 2^5 + 2^1 + 2^0 = 0110 0011

0110 0100 ^ 0110 0011 = 0000 0111 = 2^2 + 2^1 + 2^0 = 7

0000 0111 + 1 = 000 1000 = 2^3 = 8 != (2*i)
</code></pre>

<p><strong>Simplified Version</strong></p>

<p>Also, there's a modified version of this check to determine if some positive, unsigned integer is a power of 2.</p>

<pre><code>(i &amp; (i-1)) == 0
</code></pre>

<p>Basically, same rationale</p>

<p>If <code>i</code> is a power of 2, it has a single <code>1</code> bit in its bit representation. If you subtract 1 from it, the <code>1</code> bit becomes 0, and all the lower bits become <code>1</code>. Then <code>AND</code> will produce an all <code>0</code> bit-pattern.</p>
","5082376"
"How do I convert Hex values to 32-bit MIPS instructions?","6781","","<p>I need to convert these Hex values to MIPS instructions:</p>

<p>I converted them to binary first, but not sure if it is necessary.</p>

<pre><code>Hex: 0x0000 0000 - Binary: 0000 0000 0000 0000 0000 0000 0000 0000
Hex: 0xAFBF 0000 - Binary: 1010 1111 1011 1111 0000 0000 0000 0000
Hex: 0x3424 001E - Binary: 0011 0100 0010 0100 0000 0000 0000 0000
</code></pre>

<p>Please explain the process so I can do it in the future.</p>

<p>I have this <a href=""http://docs.google.com/viewer?a=v&amp;q=cache:q-lunUDHzmYJ:inst.eecs.berkeley.edu/~cs61c/resources/MIPS_Green_Sheet.pdf%20mips%20reference%20data%20green%20card&amp;hl=en&amp;gl=us&amp;pid=bl&amp;srcid=ADGEESgid7aJtK2DbfQzzBvq9d_hHI9jhC1imBXZ0YGwJClVHvFDqWoSMsPrXrwzBEzfoY-5k9cdMBKv8BDUGG_AHg5UZBp9TChDJZB-W29mt4lY005DRbJsdPAKwF8GGUpQQ72nX9G9&amp;sig=AHIEtbQA17rihy7IN3Cfx6xxuRODByvzAQ&amp;pli=1"" rel=""nofollow noreferrer"">MIPS reference data sheet</a></p>
","<p>The MIPS instruction encoding is very simple and it was explained in every MIPS documents including the sheet you read above. Just get the opcode field and determine if that's an R, I or J-type instruction to get the remaining parameters correctly. If the opcode is 0 then it's always R type, in that case look up the function field</p>

<p>For the first instruction <code>0x00000000</code>:</p>

<pre><code>6-bit opcodes = 000000: R type
6-bit funct: 000000 ==&gt; sll
rs, rd, rt = 0
==&gt; sll $0, $0, $0 or nop
</code></pre>

<p>The second instruction <code>0xAFBF0000</code>:</p>

<pre><code>opcode: 101011 = 0x2B =&gt; sw
</code></pre>

<p>The last one <code>0x3424001E</code>:</p>

<pre><code>opcode: 001101 = 0x0D =&gt; ori
</code></pre>

<p>If you use some disassembler like <a href=""http://onlinedisassembler.com/odaweb/"" rel=""nofollow"">ODA</a> you'll see the result like this</p>

<pre><code>.data:0x00000000    00000000    nop   
.data:0x00000004    afbf0000    sw ra,0(sp)   
.data:0x00000008    3424001e    ori a0,at,0x1e
</code></pre>
","24378650"
"Convert .wav file to binary and then back to .wav?","6778","","<p>I'm doing a project in java which requires me to encrypt a wave file. So, is there a straight forward process to convert a wave file into binary and back? I'll be applying an encryption algorithm on the binary data.</p>
","<p>Yes. </p>

<pre><code>File file = new File(""music.wav"");
byte[] data = new byte[file.length()];
FileInputStream in = new FileInputStream(file);
in.read(data);
in.close();

//encrypt data

FileOutputStream out = new FileOutputStream(file);
out.write(data);
out.close();
</code></pre>

<p>Of course assuming it's still a valid wav file after you play around with the data.</p>
","6358502"
"apply a bit mask in python","6768","","<p>I would like to apply a bit mask to a variable in python to figure out which bits are set. I've been trying around but haven't figured out the correct way to do it. My variable is binary and to display its value, i use th function hexlify():</p>

<pre><code>    corr = fh.read(1)
    mac = fh.read(6)[-3:]
    print ""corr ""+ hexlify(corr)
</code></pre>

<p>no I have troubles to apply the bitmask to corr:</p>

<pre><code>    print hexlify(corr&amp;0x01)
</code></pre>

<p>it says</p>

<pre><code>TypeError: unsupported operand type(s) for &amp;: 'str' and 'int'
</code></pre>

<p>but why is that? Any help would be appreciated!
Thank you very much!</p>
","<p>Now, I don't like this but it seems to work:</p>

<pre><code>print (int(hexlify(corr),16))&amp;0x01
</code></pre>

<p>this converts corr to a hex string which again gets converted baclk to an integer, base 16 before the mask gets applied..... any hints on how I could solve this otherwise would be appreciated.
Thanks!</p>
","13145384"
"decimal to binary converter c++?","6742","","<pre><code>int inputNumber=0;
int divisionStore=0,modStore=0;
vector&lt;int&gt; mainVector;

cout &lt;&lt; ""\nEnter a Number to Convert to Binary.\n"" &lt;&lt; endl;

cin &gt;&gt; inputNumber;

do
{
    modStore=inputNumber%2;
    inputNumber=inputNumber/2;
    mainVector.push_back(modStore);

}while(inputNumber!=1);

for (int i=0;i&lt;mainVector.size();i++)
{
    cout&lt;&lt;endl&lt;&lt;mainVector[i]&lt;&lt;endl;
}
</code></pre>

<p>Seems like there is a logical error but I cant find whats wrong with it? The program does not print the correct conversion as it seems like the loop ends before it can push the last number. </p>
","<p>I think you need to change:</p>

<pre><code>}while(inputNumber!=1)
</code></pre>

<p>to:</p>

<pre><code>}while(inputNumber!=0)
</code></pre>
","16632553"
"Difference between BINARY(16) and CHAR(32) when storing MD5 in database","6724","","<p>Based on various recommendations such as <a href=""https://stackoverflow.com/questions/247304/mysql-what-data-type-to-use-for-hashed-password-field-and-what-length"">What data type to use for hashed password field and what length?</a>, I could store md5 as either CHAR(32) or BINARY(16).  But when I do so using BINARY(16), the stored value is identical to the first 16 characters of the CHAR(32) stored results as well as the first 16 characters of the <code>SELECT MD5()</code> results.  What are the significance of the later 16 characters, and is their lack of presence in the binary column resulting in lost data?</p>

<pre><code>CREATE  TABLE test (id INT NOT NULL AUTO_INCREMENT, value VARCHAR(6), md5_char CHAR(32) NOT NULL, md5_binary BINARY(16) NOT NULL, PRIMARY KEY (id)) ENGINE = InnoDB;
INSERT INTO test(value,md5_char,md5_binary) VALUES(""one!"",md5(""one!""),md5(""one!""));
INSERT INTO test(value,md5_char,md5_binary) VALUES(""two%"",md5(""two%""),md5(""two%""));
INSERT INTO test(value,md5_char,md5_binary) VALUES(""three~"",md5(""three~""),md5(""three~""));
SELECT value,md5(value),md5_char,md5_binary FROM test;
DROP TABLE test;

+--------+----------------------------------+----------------------------------+------------------+
| value  | md5(value)                       | md5_char                         | md5_binary       |
+--------+----------------------------------+----------------------------------+------------------+
| one!   | 633c8403325f1cf963809e6eb224d77e | 633c8403325f1cf963809e6eb224d77e | 633c8403325f1cf9 |
| two%   | 48bbec047b4451a2018e0f652807b7d0 | 48bbec047b4451a2018e0f652807b7d0 | 48bbec047b4451a2 |
| three~ | fee453bb4eb68dcdfee07575e75c8cc5 | fee453bb4eb68dcdfee07575e75c8cc5 | fee453bb4eb68dcd |
+--------+----------------------------------+----------------------------------+------------------+
</code></pre>
","<p>Currently you are losing half of the checksum when using <code>BINARY(16)</code>. When you store an MD5 checksum in <code>BINARY(16)</code> you should store it as binary data, <em>not</em> encoded in hexadecimal. That is:</p>

<pre><code>INSERT INTO test (md5_binary) VALUES(UNHEX(md5(""one!"")));
</code></pre>

<p>You can use the HEX function to encode it into hex again if you want to eye-ball compare it with another checksum:</p>

<pre><code>SELECT HEX(md5_binary) FROM test;
</code></pre>

<p>The benefit of using BINARY to store the checksum instead of hexadecimal text is that half the storage is needed.</p>
","19069786"
"Python - Reading BLOB type from SQLite3 DB","6705","","<p>This is a follow on from: <a href=""https://stackoverflow.com/questions/7595148/python-converting-hex-to-int-char"">Python - Converting Hex to INT/CHAR</a></p>

<p>I now have a working solution for converting the stored hex value of an IP from an sqlite3 db into a readable and usable format. However up until now I have been testing by copying and pasting the values directly from a sqlite3 db viewer.</p>

<p>I have been trying to poll the db with a script to lookup that information however I have discovered that it apparantly stores blob data into a buffer which isn't instantly human readable.</p>

<p>For example, the IP 192.168.0.1 is stored as blob type under the field ip as X'C0A80001'</p>

<p>Since I worked from a copied and pasted example into my code I have constructed code to strip the X' and ' from the hex to be able to then convert it. What I cannot get is that value from the database (X'C0A80001' &lt;- this value that I can view with a db manager).
Searching I found <a href=""http://eli.thegreenplace.net/2009/05/29/storing-blobs-in-a-sqlite-db-with-pythonpysqlite/"" rel=""nofollow noreferrer"">http://eli.thegreenplace.net/2009/05/29/storing-blobs-in-a-sqlite-db-with-pythonpysqlite/</a> which showed an example of reading blobs to and from a sqlite db but their methods didn't work. They displayed the error;</p>

<blockquote>
<pre><code>print row[0], str(row[1]).encode('hex')
IndexError: tuple index out of range
</code></pre>
</blockquote>

<p>I am fairly new to Python so apologies if I am missing something basic but any pointers or code examples anyone has to help me get my head around this would  be appreciated.</p>

<p>EDIT:
Doh, didn't paste the code from the above example;</p>

<pre><code>c = conn.cursor()
c.execute('select ip from item where name = ' + ""\'"" + host + ""\'"")
for row in c:
        print row[0], str(row[1]).encode('hex')
</code></pre>

<p>It may be my understanding thats really off here as to why I can't read it back the way I want to</p>

<p>UPDATE:
Using the below answer I modified my code to;</p>

<pre><code>rows = c.execute('select ip from item where name= ' + ""\"""" + host + ""\"""") 
   for row in rows:
       print str(row[0]).encode(""hex"")
</code></pre>
","<p>After checking the link, it seems the most likely explanation is an empty row. On line 29 you set up a for loop to go over the results of a query. In python this means you have a list:
<code>[item,item2,item3]</code> and each time you go through the loop, your <code>row</code> variable points to the next item.</p>

<p>Within the loop, you are checking the <em>contents</em> of the current item. Each of these items is a tuple which suppposedly has at least two entries. But if any of those items don't have an entry for <code>row[0]</code> or <code>row[1]</code> then you will get an index out of range exception.</p>

<p>You haven't posted enough code to make determining <em>why</em> this occurred feasible, but to get the code running I'd suggest this:</p>

<pre><code>for row in cur.execute(""select * from frames""):
    try:
        print row[0], str(row[1]).encode('hex') 
    except IndexError, e:
        print ""IndexError: {0}"".format(e)
</code></pre>

<p>That will continue across your entire query result, even if some of them are bad.</p>

<p><em>Edit:</em> I just saw your update, and your problem is that c does not hold the contents of your query. <code>c.execute('select ip from item where name = ' + ""\'"" + host + ""\'"")</code> returns a list, which you ignore.</p>

<p>The original example works because you get the list in the for loop, and so it's an anonymous variable <em>only within the loop context</em>. To fix your code:</p>

<pre><code>c = conn.cursor()
rows = c.execute('select ip from item where name = ' + ""\'"" + host + ""\'"")
for row in rows:
        print row[0], str(row[1]).encode('hex')
</code></pre>
","7597900"
"Directly reading large binary file in C# w/out copying","6698","","<p>I am looking for the most efficient/direct way to do this simple C/C++ operation:</p>

<pre><code>void ReadData(FILE *f, uint16 *buf, int startsamp, int nsamps)
{
   fseek(f, startsamp*sizeof(uint16), SEEK_SET);
   fread(buf, sizeof(uint16), nsamps, f);
}
</code></pre>

<p>in C#/.NET. (I'm ignoring return values for clarity - production code would check them.) Specifically, I need to read in many (potentially 10's to 100's of millions) 2-byte (16-bit) ""ushort"" integer data samples (fixed format, no parsing required) stored in binary in a disk file. The nice thing about the C way is that it reads the samples directly into the ""uint16 *"" buffer with no CPU involvement, and no copying. Yes, it is potentially ""unsafe"", as it uses void * pointers to buffers of unknown size, but it seems like there should be a ""safe"" .NET alternative.</p>

<p>What is the best way to accomplish this in C#? I have looked around, and come across a few hints (""unions"" using FieldOffset, ""unsafe"" code using pointers, Marshalling), but none seem to quite work for this situation, w/out using some sort of copying/conversion. I'd like to avoid BinaryReader.ReadUInt16(), since that is very slow and CPU intensive. On my machine there is about a 25x difference in speed between a for() loop with ReadUInt16(), and reading the bytes directly into a byte[] array with a single Read(). That ratio could be even higher with non-blocking I/O (overlapping ""useful"" processing while waiting for the disk I/O).</p>

<p>Ideally, I would want to simply ""disguise"" a ushort[] array as a byte[] array so I could fill it directly with Read(), or somehow have Read() fill the ushort[] array directly:</p>

<pre><code>// DOES NOT WORK!!
public void GetData(FileStream f, ushort [] buf, int startsamp, int nsamps)
{
    f.Position = startsamp*sizeof(ushort);
    f.Read(buf, 0, nsamps);
}
</code></pre>

<p>But there is no Read() method that takes a ushort[] array, only a byte[] array.</p>

<p>Can this be done directly in C#, or do I need to use unmanaged code, or a third-party library, or must I resort to CPU-intensive sample-by-sample conversion? Although ""safe"" is preferred, I am fine with using ""unsafe"" code, or some trick with Marshal, I just have not figured it out yet.</p>

<p>Thanks for any guidance!</p>

<hr>

<p>[UPDATE]</p>

<p>I wanted to add some code as suggested by dtb, as there seem to be precious few examples of ReadArray around. This is a very simple one, w/no error checking shown.</p>

<pre><code>public void ReadMap(string fname, short [] data, int startsamp, int nsamps)
{
    var mmf = MemoryMappedFile.CreateFromFile(fname);
    var mmacc = mmf.CreateViewAccessor();

    mmacc.ReadArray(startsamp*sizeof(short), data, 0, nsamps);
}
</code></pre>

<p>Data is safely dumped into your passed array. You can also specify a type for more complex types. It seems able to infer simple types on its own, but with the type specifier, it would look like this:</p>

<pre><code>    mmacc.ReadArray&lt;short&gt;(startsamp*sizeof(short), data, 0, nsamps);
</code></pre>

<hr>

<p>[UPATE2]</p>

<p>I wanted to add the code as suggested by Ben's winning answer, in ""bare bones"" form, similar to above, for comparison. This code was compiled and tested, and works, and is FAST. I used the SafeFileHandle type directly in the DllImport (instead of the more usual IntPtr) to simplify things.</p>

<pre><code>[DllImport(""kernel32.dll"", SetLastError=true)]
[return:MarshalAs(UnmanagedType.Bool)]
static extern bool ReadFile(SafeFileHandle handle, IntPtr buffer, uint numBytesToRead, out uint numBytesRead, IntPtr overlapped);

[DllImport(""kernel32.dll"", SetLastError=true)]
[return:MarshalAs(UnmanagedType.Bool)]
static extern bool SetFilePointerEx(SafeFileHandle hFile, long liDistanceToMove, out long lpNewFilePointer, uint dwMoveMethod);

unsafe void ReadPINV(FileStream f, short[] buffer, int startsamp, int nsamps)
{
    long unused; uint BytesRead;
    SafeFileHandle nativeHandle = f.SafeFileHandle; // clears Position property
    SetFilePointerEx(nativeHandle, startsamp*sizeof(short), out unused, 0);

    fixed(short* pFirst = &amp;buffer[0])
        ReadFile(nativeHandle, (IntPtr)pFirst, (uint)nsamps*sizeof(short), out BytesRead, IntPtr.Zero);
}
</code></pre>
","<p><strike><a href=""https://stackoverflow.com/questions/3206391/directly-reading-large-binary-file-in-c-w-out-copying/3206424#3206424"">dtb's answer</a> is an even better way</strike> (actually, it has to copy the data as well, no gain there), but I just wanted to point out that to extract ushort values from a byte array you should be using <a href=""http://msdn.microsoft.com/en-us/library/system.bitconverter.aspx"" rel=""nofollow noreferrer""><code>BitConverter</code></a> not <code>BinaryReader</code></p>

<p>EDIT: example code for p/invoking <a href=""http://pinvoke.net/default.aspx/kernel32/ReadFile.html"" rel=""nofollow noreferrer"">ReadFile</a>:</p>

<pre><code>[DllImport(""kernel32.dll"", SetLastError=true)]
[return:MarshalAs(UnmanagedType.Bool)]
static extern bool ReadFile(IntPtr handle, IntPtr buffer, uint numBytesToRead, out uint numBytesRead, IntPtr overlapped);

[DllImport(""kernel32.dll"", SetLastError=true)]
[return:MarshalAs(UnmanagedType.Bool)]
static extern bool SetFilePointerEx(IntPtr hFile, long liDistanceToMove, out long lpNewFilePointer, uint dwMoveMethod);

unsafe bool read(FileStream fs, ushort[] buffer, int offset, int count)
{
  if (null == fs) throw new ArgumentNullException();
  if (null == buffer) throw new ArgumentNullException();
  if (offset &lt; 0 || count &lt; 0 || offset + count &gt; buffer.Length) throw new ArgumentException();
  uint bytesToRead = 2 * count;
  if (bytesToRead &lt; count) throw new ArgumentException(); // detect integer overflow
  long offset = fs.Position;
  SafeFileHandle nativeHandle = fs.SafeFileHandle; // clears Position property
  try {
    long unused;
    if (!SetFilePositionEx(nativeHandle, offset, out unused, 0);
    fixed (ushort* pFirst = &amp;buffer[offset])
      if (!ReadFile(nativeHandle, new IntPtr(pFirst), bytesToRead, out bytesToRead, IntPtr.Zero)
        return false;
    if (bytesToRead &lt; 2 * count)
      return false;
    offset += bytesToRead;
    return true;
  }
  finally {
    fs.Position = offset; // restore Position property
  }
}
</code></pre>
","3206510"
"Verilog : Use of assign and always","6683","","<pre><code>module circuit_1 (a, b, c);
input [1:0J a,b;
output [3:0J c;
assign c = a + b;
</code></pre>

<p>If input a = 2'b11 and input b = 2'b10, </p>

<p>what value would output c have ? Please give a descriptive answer.</p>

<p>Also kindly tell me functionality of assign and always. I am a bit confused.</p>
","<pre><code>c = 4'b0101      // Output, implicitly a wire
</code></pre>

<p>""assign"" is used for net type  declarations(Wire,Tri etc).Since wires change values according to the value driving them, whenever the operands on the RHS changes,the value is evaluated and assigned to LHS(simulating a wire)</p>

<p>always - is used for registers + combinational logic.
If it is always(@ posedge clk)- The event posedge clk triggers the always block and the logic inside the block is evaluated and assigned.</p>

<p>always @ (*) - If something in the RHS of the always block changes,that particular expression is evaluated and assigned.</p>

<p>Imagine assign as wires and always blocks as registers (For now) , as their behavior is same. </p>
","15627236"
"Why Do Computers Use the Binary Number System (0,1)?","6643","","<p>Why Do Computers Use the Binary Number System (0,1)? Why don't they use Ternary Number System (0,1,2) or any other number system instead? What is the gain in using Binary Numbers?</p>
","<p>This is a classic example of software thinking in a hardware world :)</p>

<p>Oh my. Am I the only one who remembers vacuum tubes, or valves as we used to call them? Logic DIDN'T start with transistors, friends. The first computer (ENIAC) used lots of tubes, diodes and relays.</p>

<p>As has been mentioned, the usage of the binary system in modern computers relates to electrical states and logic. If you will recall, TTL (Transistor-Transistor Logic) advanced computing significantly (making it orders of magnitude faster, cheaper and more reliable to create memory and logic circuits) TTL devices are made up of electronic semi-conducting material (Silicon) which when assembled and configured as a transistor, can be made to either amplify a signal or act as a gated switch. </p>

<p>You can arrange large arrays of these TTL circuits to ""store"" states. We can go on, but suffice to say the reason for BINARY being around is the same then as it is today. </p>

<p>Numbers are represented by bits, those bits are discrete electrical lines with the state logic of TRUE/FALSE, which is mapped directly to the electrical representations of ON/OFF.  </p>

<p>This is the only reliable and economic hardware architecture that makes sense. Ones (1's) and Zero's (0's) rule the world because they are the most granular, reliable and cost effective circuits to produce. </p>
","24317735"
"Real binary write PHP","6634","","<p>How do I do something as simple as (in PHP) this code in C:</p>

<pre><code>char buffer[5] = ""testing"";
FILE* file2 = fopen(""data2.bin"", ""wb"");
fwrite(buffer, sizeof buffer, 1, file2);
fclose(file2);
</code></pre>

<p>Whenever I try to write a binary file in PHP, it doesn't write in real binary.</p>

<p>Example:</p>

<pre><code>$ptr = fopen(""data2.bin"", 'wb');

fwrite($ptr, ""testing"");

fclose($ptr);
</code></pre>

<p>I found on internet that I need to use <code>pack()</code> to do this...</p>

<p>What I expected:</p>

<pre><code>testing\9C\00\00
or
7465 7374 696e 679c 0100 00
</code></pre>

<p>What I got:</p>

<pre><code>testing412
</code></pre>

<p>Thanks</p>
","<p>You're making the classic mistake of confusing <em>data</em> with the <em>representation</em> of that data.</p>

<p>Let's say you have a text file. If you open it in Notepad, you'll see the following:</p>

<pre><code>hello
world
</code></pre>

<p>This is because Notepad <strong>assumes</strong> the data is <a href=""http://www.asciitable.com/"">ASCII</a> text. So it takes every byte of raw data, interprets it as an ASCII character, and renders that text to your screen.</p>

<p>Now if you go and open that file with a hex editor, you'll see something entirely different<sup>1</sup>:</p>

<pre><code>68 65 6c 6c 6f 0d 0a 77 6f 72 6c 64          hello..world
</code></pre>

<p>That is because the hex editor instead takes every byte of the raw data, and displays it as a two-character hexadecimal number.</p>

<p><sub>1 - Assuming Windows <code>\r\n</code> line endings and ASCII encoding.</sub></p>

<hr>

<p>So if you're expecting hexadecimal ASCII output, you need to <em>convert</em> your string to its hexadecimal encoding before writing it (as ASCII text!) to the file.</p>

<p>In PHP, what you're looking for is the <a href=""http://www.php.net/manual/en/function.bin2hex.php""><code>bin2hex</code></a> function which ""Returns an ASCII string containing the hexadecimal representation of str.""  For example:</p>

<pre><code>$str = ""Hello world!"";
echo bin2hex($str);      // output:  48656c6c6f20776f726c6421
</code></pre>

<hr>

<p>Note that the <code>""wb""</code> mode argument doesn't cause any special behavior. It guarantees <strong><em>binary</em></strong> output, not <strong><em>hexadecimal</em></strong> output. I cannot stress enough that there is a difference. The only thing the <code>b</code> really does, is guarantee that line endings will not be converted by the library when reading/writing data.</p>
","17461853"
"Convert between Decimal, Binary and Hexadecimal in Swift","6623","","<p>What I want to know is the most code efficient way to convert (in swift 2):</p>

<ul>
<li>Decimal to Binary</li>
<li>Binary to Decimal</li>
<li>Decimal to Hexadecimal</li>
<li>Hexadecimal to Decimal</li>
<li>Binary to Hexadecimal</li>
<li>Hexadecimal to Binary</li>
</ul>

<p>I already have a rudimentary and long-winded way of achieving this, but I would like to find out a very efficient way of doing it.</p>

<p>Sorry if the question is a bit long...</p>
","<p>Both <code>String</code> and <code>Int</code> have constructors which take a <code>radix</code> (base).  Combining those, you can achieve all of the conversions:</p>

<pre><code>// Decimal to binary
let d1 = 21
let b1 = String(d1, radix: 2)
print(b1) // ""10101""

// Binary to decimal
let b2 = ""10110""
let d2 = Int(b2, radix: 2)!
print(d2) // 22

// Decimal to hexadecimal
let d3 = 61
let h1 = String(d3, radix: 16)
print(h1) // ""3d""

// Hexadecimal to decimal
let h2 = ""a3""
let d4 = Int(h2, radix: 16)!
print(d4) // 163

// Binary to hexadecimal
let b3 = ""10101011""
let h3 = String(Int(b3, radix: 2)!, radix: 16)
print(h3) // ""ab""

// Hexadecimal to binary
let h4 = ""face""
let b4 = String(Int(h4, radix: 16)!, radix: 2)
print(b4) // ""1111101011001110""
</code></pre>
","36967037"
"Using binary flags to represent states, options, etc","6602","","<p>If I wanted to represent states or options or something similar using binary ""flags"" so that I could pass them and store them to an object like <code>OPTION1 | OPTION2</code> where <code>OPTION1</code> is 0001 and <code>OPTION2</code> is 0010, so that what gets passed is 0011, representing a mix of the options.</p>

<p>How would I do this in C++? I was thinking something like</p>

<pre><code>enum Option {
    Option_1 = 0x01,
    Option_2 = 0x02,
    Option_3 = 0x04,
    //...
}

void doSomething(Option options) {
    //...
}

int main() {
    doSomething(Option_1|Option_2);
}
</code></pre>

<p>But then ideally, <code>doSomething</code> knows how to interpret the given Option.</p>

<p>Am I on the right track? Is there a better way? </p>

<p><strong>Update</strong></p>

<p>And wouldn't I have to define an <code>Option</code> for every possible combination, also?</p>
","<p>This is a common way these things are done. <code>doSomething</code> can use bitwise <code>and</code> operator to see if an option is selected:</p>

<pre><code>if (options &amp; Option_1){ 
  // option 1 is selected
}
</code></pre>

<p>Alternatively, you can consider using <a href=""http://msdn.microsoft.com/en-us/library/ewwyfdbe(VS.71).aspx"" rel=""noreferrer"">bit fields</a>:</p>

<pre><code>struct Options {
    unsigned char Option_1 : 1;
    unsigned char Option_2 : 1;
};

Options o;
o.Option_1 = 1;
o.Option_2 = 0;
</code></pre>
","1407206"
"How do I turn a binary string into a float or double?","6594","","<p>In this question, Bill The Lizard asks <a href=""https://stackoverflow.com/q/397692/50151"">how to display the binary representation of a float or double</a>.</p>

<p>What I'd like to know is, given a binary string of the appropriate length, how could I perform the reverse operation (in  C#)? In other words, how do I turn a binary string into a float or double?</p>

<p>As a side note, are there any bit strings which would not result in a valid float or double?</p>

<hr>

<p>EDIT: By binary string I mean a string of 0s and 1s.</p>

<p>So, my input will be a string like this:</p>

<pre><code>01010101010101010101010101010101
</code></pre>

<p>and my output should be a floating point number. (Or, if there were 64 bits in the string, a double.)</p>
","<pre><code>string bstr = ""01010101010101010101010101010101"";
long v = 0;
for (int i = bstr.Length - 1; i &gt;= 0; i--) v = (v &lt;&lt; 1) + (bstr[i] - '0');
double d = BitConverter.ToDouble(BitConverter.GetBytes(v), 0);
// d = 1.41466386031414E-314
</code></pre>
","8272792"
"Why don't we send binary around instead of text on http?","6582","","<p>It seems that binary would be more compact and can be deserialized in a standard way, why is text used instead?  It seems inefficient and web frameworks are forced to do nothing more than screwing around with strings.  Why isn't there a binary standard?  The web would be way faster and browsers would be able to load binary pages very fast.</p>

<p>If I were to start a binary protocol (HBP hyper binary protocol) what sort of standards would I define?</p>
","<p>The HTTP protocol itself is readable as text. This is useful because you can telnet into any server at all and communicate with it.  </p>

<p>Being text also allows you to easily watch HTTP communication with a program like wireshark.  You can then diagnose the source of problems easily.</p>

<p>HTTP defines a way to work with <code>resources</code>.  These resources do not need to be text, they can be images, or anything else.   A text resource can be sent as binary by specifying the <code>Content-Encoding</code> header.  Your resource type is specified via the <code>Content-Type</code> header.</p>

<p>So your question really only applies to the HTTP protocol itself, and not the payload which is the resources.</p>

<blockquote>
  <p>The web would be way faster and browsers would be able to load binary pages very fast.</p>
</blockquote>

<p>I don't think this is true. The slowest part is probably connection establishment and <a href=""http://en.wikipedia.org/wiki/Slow-start"" rel=""noreferrer"">slow TCP start</a>.</p>

<p>Here is an example of how an HTTP response would send a text resource with a binary representation:</p>

<blockquote>
  <p>HTTP/1.1 200 OK<br>
  Server: Apache/2.0<br>
  Content-Encoding: gzip<br>
  Content-Length: 1533
  Content-Type: text/html; charset=ISO-8859-1</p>
</blockquote>
","1892044"
"How to query or insert a value into a binary(1) field in SQL Server 2012?","6557","","<p>I've tried googling for a while and couldn't find anything, but apologies if this is really obvious.</p>

<p>I have a Boolean array that is always length 8 and I want to insert the corresponding binary value into a <code>binary(1)</code> field. I'm using SQL Server 2012.</p>

<p>Currently I convert it into a string, e.g <code>""10100101""</code>, and create a query string that looks something like <code>""INSERT INTO Table1 VALUES('10100101');""</code> Also have been trying to get a <code>SELECT</code> statement equivalent <code>""SELECT * FROM Table1 WHERE bin_val=10100101;""</code></p>

<p>When I execute the statement I always get a syntax error. I've tried multiple variations (e.g with/without quote marks etc and putting the number in different format e.g <code>""0xA5""</code>) with no luck.</p>

<p>Any suggestions?</p>

<p>p.s Writing code in java</p>
","<p>First, you will need to convert your binary based number to a decimal based one. Then, you can simply convert that value to the datatype <code>BINARY</code>. So, assuming that your string is always 8 bits long, you can try this:</p>

<pre><code>DECLARE @BinaryNumber CHAR(8)
SET @BinaryNumber = '10100101'
INSERT INTO Table1
SELECT  CAST(SUBSTRING(@BinaryNumber,8,1)+
             SUBSTRING(@BinaryNumber,7,1)*2+
             SUBSTRING(@BinaryNumber,6,1)*4+
             SUBSTRING(@BinaryNumber,5,1)*8+
             SUBSTRING(@BinaryNumber,4,1)*16+
             SUBSTRING(@BinaryNumber,3,1)*32+
             SUBSTRING(@BinaryNumber,2,1)*64+
             SUBSTRING(@BinaryNumber,1,1)*128 AS BINARY(1))
</code></pre>
","14882062"
"(Beginner) Binary conversion program Issue","6550","","<p>I am a beginner to development and have made a flowchart in RAPTOR which can be run.
The program converts an 8-bit binary value to decimal, however whenever it's run it always outputs 0 as the final answer.</p>

<p>The issue I think is the if statement circled in Red which always seems to evaluate to 0 for some reason.</p>

<p>Many thanks</p>

<p>-Josh Taylor</p>

<p><img src=""https://i.stack.imgur.com/DnuSe.png"" alt=""My Flowchart in Raptor of Binary Conversion program""></p>
","<p>Answer by summary of the conversation by @Jtaylor-Pentacle, @Rotem.  </p>

<p>The <a href=""http://raptor.martincarlisle.com/"" rel=""nofollow"">RAPTOR Flowchart based programming</a> seems to have some unique syntax and is primarily used as a training tool in some Universities. 
If you are looking to learn programming, the suggestion is to move away from Raptor and dive in and find a language to learn. </p>
","18869635"
"Embed a Executable Binary in a shell script","6477","","<p>First, I already googled but only found examples where a compressed file (say a <code>.tar.gz</code>) is embedded into a shell script.</p>

<p>Basically if I have a C program (<code>hello.c</code>) that prints a string, say <strong>Hello World!</strong>.</p>

<p>I compile it to get an executable binary</p>

<pre><code>gcc hello.c -o hello
</code></pre>

<p>Now I have a shell script <code>testEmbed.sh</code></p>

<p>What I am asking is if it is possible to embed the binary (<strong>hello</strong>) inside the shell script so that when I run</p>

<pre><code>./testEmbed.sh
</code></pre>

<p>it executes the binary to print <strong>Hello World!</strong>.</p>

<p><strong>Clarification</strong>:
One alternative is that I compress the executable into an archive and then extract it when the script runs. What I am asking is if it is possible to run the program without that.</p>

<p>Up until now, I was trying the method <a href=""http://www.45rpmsoftware.com/45rpmdump/?p=137"" rel=""noreferrer"">here</a>. But it does not work for me. I guess the author was using some other distribution on another architecture. So, basically this did not work for me. :P</p>

<p>Also, if the workflow for a C program differs from a Java <code>jar</code>, I would like to know that too!</p>
","<p>Yes, this can be done. It's actually quite similar in concept to your linked article. The trick is to use <code>uuencode</code> to encode the binary into text format then tack it on to the end of your script.</p>

<p>Your script is then written in such a way that it runs <code>uudecode</code> on itself to create a binary file, change the permissions then execute it.</p>

<p><code>uuencode</code> and <code>uudecode</code> were originally created for shifting binary content around on the precursor to the internet, which didn't handles binary information that well. The conversion into text means that it can be shipped as a shell script as well. If, for some reason your distribution complains when you try to run <code>uuencode</code>, it probably means you have to install it. For example, on Debian Squeeze:</p>

<pre><code>sudo aptitude install sharutils
</code></pre>

<p>will get the relevant executables for you. Here's the process I went through. First create and compile your C program <code>hello.c</code>:</p>

<pre><code>pax&gt; cat hello.c

#include &lt;stdio.h&gt;
int main (void) {
    printf (""Hello\n"");
    return 0;
}

pax&gt; gcc -o hello hello.c
</code></pre>

<p>Then create a shell script <code>testEmbed.sh</code>, which will decode itself:</p>

<pre><code>pax&gt; cat testEmbed.sh

#!/bin/bash
rm -f hello
uudecode $0
./hello
rm -f hello
exit
</code></pre>

<p>The first <code>rm</code> statement demonstrates that the <code>hello</code> executable is being created anew by this script, not left hanging around from your compilation. Since you need the payload in the file as well, attach the encoded executable to the end of it:</p>

<pre><code>pax&gt; uuencode hello hello &gt;&gt;testEmbed.sh
</code></pre>

<p>Afterwards, when you execute the script <code>testEmbed.sh</code>, it extracts the executable and runs it.</p>

<p>The reason this works is because <code>uudecode</code> looks for certain marker lines in its input (<code>begin</code> and <code>end</code>) which are put there by <code>uuencode</code>, so it only tries to decode the encoded program, not the entire script:</p>

<pre><code>pax&gt; cat testEmbed.sh

#!/bin/bash
rm -f hello
uudecode $0
./hello
rm -f hello
exit

begin 755 hello
M?T5,1@$!`0````````````(``P`!````$(,$""#0```#`!@```````#0`(``'
M`""@`'@`;``8````T````-(`$""#2`!`C@````X`````4````$`````P```!0!
: : :
M:&amp;%N9&amp;QE`%]?1%1/4E]%3D1?7P!?7VQI8F-?8W-U7VEN:70`7U]B&lt;W-?&lt;W1A
M&lt;G0`7V5N9`!P=71S0$!'3$E""0U\R+C``7V5D871A`%]?:38X-BYG971?&lt;&amp;-?
4=&amp;AU;FLN8G@`;6%I;@!?:6YI=```
`
end
</code></pre>

<p>There are other things you should probably worry about, such as the possibility that your program may require shared libraries that don't exist on the target system, but the process above is basically what you need.</p>

<hr>

<p>The process for a JAR file is very similar, except that the way you run it is different. It's still a single file but you need to replace the line:</p>

<pre><code>./hello
</code></pre>

<p>with something capable of running JAR files, such as:</p>

<pre><code>java -jar hello.jar
</code></pre>
","10491738"
"How to make Integer.toBinaryString return at least 4 bits","6475","","<p>I am writing a method where I am converting int values into binary strings and storing them. I am using the method Integer.toBinaryString to do so, and it's working correctly, but the problem is that I need the method to return exactly 4 bits in the string instead of less (it will never be more because the numbers are not large enough). Here is an example of my code and where the problem is occurring:</p>

<pre><code>int value5 = 3;
String strValue5 = Integer.toBinaryString(value5);
for(int index = 0; index &lt; 4; index++){
     sBoxPostPass[4][index] = strVal5.charAt(index);
}
</code></pre>

<p>Clearly, this will throw an ArrayOutOfBoundsException because <code>strValue5 == 11</code> and not <code>0011</code>, like it needs to be. I hope this is sufficiently clear. Thanks in advance for the help.</p>
","<p>If your value will always have exactly 4 bits then that's small enough to use a look-up table for the 16 values in question. Correcting any errors in my Java is left as an exercise for the reader.</p>

<pre><code>static String binary4[16] = {""0000"", /* another exercise for the reader */, ""1111""};
static String toBinary4(int value) {
    return binary4[value &amp; 0xF];
}
</code></pre>
","11804627"
"PHP Binary to Hex with leading zeros","6472","","<p>I have the follow code:  </p>

<pre><code>&lt;?
$binary = ""110000000000"";
$hex = dechex(bindec($binary));
echo $hex;
?&gt;
</code></pre>

<p>Which works fine, and I get a value of c00.</p>

<p>However, when I try to convert 000000010000 I get the value ""10"".  What I actually want are all the leading zeros, so I can get ""010"" as the final result.</p>

<p>How do I do this?</p>

<p>EDIT:  I should point out, the length of the binary number can vary.  So $binary might be 00001000 which would result it 08.</p>
","<p>You can prepend the requisite number of leading zeroes with something such as:</p>

<pre><code>$hex = str_repeat(""0"", floor(strspn($binary, ""0"") / 4)).$hex;
</code></pre>

<p>What does this do?</p>

<ol>
<li>It finds out how many leading zeroes your binary string has with <code>strspn</code>.</li>
<li>It translates this to the number of leading zeroes you need on the hex representation. Whole groups of 4 leading zero bits need to be translated to one zero hex digit; any leftover zero bits are already encoded in the first nonzero hex digit of the output, so we use <code>floor</code> to cast them out.</li>
<li>It prepends that many zeroes to the result using <code>str_repeat</code>.</li>
</ol>

<p>Note that if the number of input bits is not a multiple of 4 this might result in one less zero hex digit than expected. If that is a possibility you will need to adjust accordingly.</p>
","16576236"
"How to copy binary data from one stream to another?","6446","","<p>Currently i have a program that loads binary data into a stringstream and then pases the data to a fstream like so:</p>

<pre><code>stringstream ss(stringstream::binary | stringstream::in | stringstream::out);
ss.write(data, 512);  // Loads data into stream

// Uses a memory block to pass the data between the streams
char* memBlock = new char[512];
ss.read(memBlock, 512);

ofstream fout(""someFile.bin"", ios::binary);
fout.write(memBlock, 512);  // Writes the data to a file
fout.close();

delete[] memBlock;
</code></pre>

<p>My question is: is there a better way to pass the binary data between the streams?</p>
","<p>Use the <a href=""http://www.cplusplus.com/reference/iostream/streambuf/"" rel=""noreferrer""><code>streambuf</code></a> members, that's what they are for:</p>

<pre><code>fout &lt;&lt; ss.rdbuf();
</code></pre>
","3738267"
"Binary long division algorithm","6424","","<p>I have been trying to recreate the following algorithm in java:</p>

<pre><code>Set quotient to 0
Align leftmost digits in dividend and divisor
Repeat
If that portion of the dividend above the divisor is greater than or equal to the divisor
Then subtract divisor from that portion of the dividend and
Concatentate 1 to the right hand end of the quotient
Else concatentate 0 to the right hand end of the quotient
Shift the divisor one place right
Until dividend is less than the divisor
quotient is correct, dividend is remainder
STOP
</code></pre>

<p>This can also be found here:</p>

<p><img src=""https://i.stack.imgur.com/DAJph.gif"" alt=""Long division in binary""></p>

<p>Here is my code:</p>

<pre><code>public class Division {
    public static void main(String[] args) {
        int quotient =0;
        int a = 123;
        int b = 5;
        int bfirst = b;
        String a1 = Integer.toBinaryString(a);
        String b1 = Integer.toBinaryString(b);
        int aLength = a1.length();
        int bLength = b1.length();
        int power = aLength - bLength;
        b =(int) Math.pow(b, power);    

        while(a &gt; bfirst) {
            if(a &gt;= b) {
                a = a-b;
                quotient = quotient*2+1;
                b = b/2;
            } else {
                quotient = quotient*2;
                b = b/2;
            }
        }
        System.out.println(quotient);
    }
}
</code></pre>

<p>It sometimes returns answers which are right, but other times will not. Any ideas?</p>
","<p>I believe</p>

<pre><code>b = (int) Math.pow(b, power);    
</code></pre>

<p>should be</p>

<pre><code>b = (int) (b * Math.pow(2, power));
</code></pre>

<p>The variable <code>b</code> appears to be the current digit to be compared with, and got subtracted by <code>a</code>. You are doing binary division, and in the code following this line I found this value were only divided by 2. In this case, <code>Math.pow(b, power)</code> does not make sense.</p>

<hr>

<p>Furthermore, there is a missing step. Because <code>a - b</code> will bring all the values down to the end and get <code>a &lt; bFirst</code>, all ending zeroes are not counted into quotient, as we have already exited the loop.</p>

<p>Replace </p>

<pre><code>a = a-b;
quotient = quotient*2+1;
b = b/2;
</code></pre>

<p>with</p>

<pre><code>bLength = Integer.toBinaryString(b).length();
int bfirstLength = Integer.toBinaryString(bfirst).length();
a = a-b;
quotient = quotient*2+1;
b = b/2;
if (a &lt; bfirst) {
    quotient = quotient * (int)Math.pow(2, bLength - bfirstLength);
}
</code></pre>

<p>To account for missing zeroes of the quotient.</p>

<hr>

<p>Furthermore there is an Off-by-one-error.</p>

<pre><code>while (a &gt; bfirst) {
</code></pre>

<p>should be</p>

<pre><code>while (a &gt;= bfirst) {
</code></pre>

<p>If <code>a</code> is divisible by <code>b</code>, long division should go ahead and subtract the remaining dividend, instead of stopping the procedure.</p>

<hr>

<p>Finally, number of binary digits in a number can be computed by</p>

<pre><code>(int) (Math.ln(a) / Math.ln(2)) + 1
</code></pre>

<hr>

<p>Last, try to make use of <code>System.out.println</code> inside your algorithm when debugging, it helps a lot and let you precisely know where your algorithm goes wrong. Better, if you know how and is available (usually integrated into IDEs), use a debugger.</p>

<p>And, the last one, do the algorithm by hand with some examples before coding - this can definitely help you understand how the algorithm works.</p>

<p>The entire thing, with debug statements: <a href=""http://ideone.com/JBzHdf"" rel=""nofollow"">http://ideone.com/JBzHdf</a></p>
","20637712"
"Convert an Mac OS X binary formatted plist to readable format in C#","6424","","<p>Does anyone know if/how I can convert a binary formatted Mac OS X plist file to a plain XML string in C#?</p>

<p>I know there are some plist editors for Windows available that says they support binary formatted plist files, but I need to do this inline in my own application.</p>
","<p>I realize this is super old, but I'm posting my solution for posterity.</p>

<p>I couldn't find anything usable sort of launching an external process when I embarked on binary plist serialization a few weeks ago, so I had to roll my own.</p>

<p>For others looking for C#/.NET binary plist serialization, you can find my implementation at <a href=""https://github.com/ChadBurggraf/plists-cs"" rel=""noreferrer"">https://github.com/ChadBurggraf/plists-cs</a>.</p>

<p>Hopefully this helps some folks out.</p>
","5517549"
"Storing Binary number in Integer variable","6420","","<p>I am making a simulator, which simulates the method of multiplication of a processor. The thing is first I have to convert the decimal form to binary, each bit of binary representation is stored at separate location in an array. Now the multiplication of two binary numbers, stored in arrays as mentioned above is very complex and also very memory consuming.</p>

<p>because I have to follow this method;</p>

<p><code>1000</code></p>

<p>x</p>

<p><code>1110</code></p>

<hr>

<pre><code>   `0000`

  `1000`

 `1000`

`1000`
</code></pre>

<hr>

<p>=
1110000</p>

<p>I know that I can easily do this by multiplying decimals forms together and then convert them to binary but unfortunately that's not required here.</p>

<p>I was thinking if there is a way to store the binary number stored in array as a single integer containing binary no. Or any other easy way for multiplying binary bits stored in array. For Example:</p>

<p><code>a[0]=1,a[1]=1, .... ,a[32]=0</code></p>

<p>so I want the integer variable to contain</p>

<p><code>int x=110....0</code></p>

<p>Is there a way to do this?</p>

<p>Regards</p>
","<p>Depending on what your focus is, you can also use std::string-s (and std::stringstream-s),
since there the conversion to/from binary form is quite easy and you can use <a href=""http://www.cplusplus.com/reference/string/string/operator%5B%5D/"" rel=""nofollow"">indexed accessing</a> too.</p>

<p><code>std::string s; s[0], s[1]</code>, etc.</p>

<p>Of course the drawback is you use <code>s[i]=='0'</code> to check whether an index is '0'.</p>

<p>Besides, <strong>I would not worry about memory consumption</strong> as it is not soo much really and only temporary. Note that std::string is an array of <code>char</code>-s which are 8-bit values, therefore <strong>your multiplication (if you have 8 binary digits) takes only 64bytes</strong>. That is not much, fits easily into the highest level cache.</p>

<pre><code>Series  Intel Core i5/i7
Level 1 Cache   128 KB &lt;- this is the interesting part for you, should be larger than 6k, ok.
Level 2 Cache   512 KB
Level 3 Cache   3072 KB(i5) 4096 KB(i7)
</code></pre>

<p>Source: <a href=""http://www.notebookcheck.net/Intel-Core-i5-3320M-Notebook-Processor.74457.0.html"" rel=""nofollow"">notebook check</a></p>
","13630396"
"Adding two Negative Numbers using 2's Complement","6400","","<p>I was wondering if someone could double check my work for me real quick. If I'm given two negative numbers: -33 and -31. If I add them together what will be the result using 2's complement. </p>

<p><strong>NOTE: A word length of 6-bits MUST being used for the operation.</strong></p>

<hr>

<p><strong>MY ANSWER</strong></p>

<p>So after doing this I computed -31 to be 100001 in 2's. I also computed -33 to be 011111 in 2's complement. When adding them together I got 1000000, however this number is 7 digits so I chopped off the higher order bit since I'm bound to a word length of 6-bits. This yields the number 000000. Which contains a sign bit of 0, meaning it would be even. However since the sum of 2 negative's cannot be even it's obviously an overflow. So I take the 2's of 000000 which is simply 000000.</p>

<p>So the answer should be: 0 since a buffer overflow occurred. Does this seem right to you guys? THANKS. :)</p>
","<p>First of all: -33 + (-31) cannot be 0.</p>

<p>-33 is not representable in 6bit 2's complement. <code>01 1111b</code> is <code>+31</code> in decimal, so the addition results in 0.</p>

<p>So the correct answer is something like that: There is no result because -33 is an invalid number in 6bit representation.</p>

<p>in 7 bit 2's complement <code>-33 = 101 1111b</code></p>

<pre><code> 110 0001
+101 1111
    =
1100 0000
</code></pre>

<p>which is equal to -64.</p>
","25648895"
"MAC address to binary bits conversion","6385","","<p>I am trying to convert a mac address,  </p>

<pre><code>mac = '00:de:34:ef:2e:f4'  
</code></pre>

<p>into binary format. And the program i am using is,  </p>

<pre><code>mac = '00:de:34:ef:2e:f4'
r = mac.replace(':', '').decode('hex')  
print r
</code></pre>

<p>But i am getting a strange output when i run this program, and the output is  </p>

<p>$Ã$  </p>

<p>What am i doing wrong? </p>
","<p>I don't think you want to use <code>decode</code>, that does unicode conversion and other stuff you don't want.  Just do:</p>

<pre><code>n = int(mac.replace(':', ''), 16)
</code></pre>

<p>Which will convert your mac address to a number.  Print it with <code>'%012x'%n</code> to get the hex back.</p>

<p><strong>Edit:</strong></p>

<p>If you want to convert to binary, then just do <code>bin(n)</code>.</p>
","12430508"
"Binary division in C","6377","","<pre><code>#include ""stdio.h""

int bdiv( int dividend , int divisor )
{
  int remainder = dividend ;
  int quotient  = 0 ;

  int i ;
  for( i = 0 ; i &lt; 17 ; i++ )
    {
      remainder = remainder - divisor ;
      if( (remainder &amp; 0x8000)  )
        {
          remainder = remainder + divisor ;
          quotient  = quotient &lt;&lt; 1 ;
        }
      else
        quotient = ( quotient &lt;&lt; 1 ) | 0x1 ;

      divisor = divisor &gt;&gt; 1 ;
    }
  return quotient ;
}

int main()
{
  int a = 7 ;
  int b = 2 ;

  printf( ""%d\n"" , bdiv(a,b) ) ;

}
</code></pre>

<p>Pseudo-Code of the algorithm I tried to implement : </p>

<pre><code>START
Remainder = Dividend ;
Quotient = 0 ;
1.Subtract Divisor register from remainder and place result in remainder . 
2. Test Remainder 
2a . If remainder &gt;= 0 shift quotient to right setting rightmost bit to 1
2b. If remainder &lt; 0 , restore the original value of the remainder register . Also shift the quotient register to the left setting the new least significant bit to 0 .
3. Shift the divisor right 1 bit .
4. is it the 33rd repetition ( for 32 bit division ) ? No : GOTO 1 
   Yes : STOP 
</code></pre>

<p>I wrote this program for binary division in C for 16 bit division and it's not working . Can anyone suggest me what's not working ? 
It is giving output as <code>131071</code> for a division of 7 by 2 . </p>
","<p>The second shift needs to be:</p>

<pre><code>quotient = (( quotient &gt;&gt; 1 ) | 0x1) ;
</code></pre>

<p>Also, why not:</p>

<pre><code>if (remainder &lt; 0 )
</code></pre>

<p>???</p>
","23848379"
"Conversion from binary file to hex in C","6366","","<p>I am trying to write some simple program to uploading files to my server. I' d like to convert binary files to hex. I have written something, but it does not work properly.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;stdlib.h&gt;

static int bufferSize = 1024;
FILE *source;
FILE *dest;

int n;
int counter;

int main() {
    unsigned char buffer[bufferSize];
    source = fopen(""server.pdf"", ""rb"");
    if (source) {
        dest = fopen(""file_test"", ""wb"");

        while (!feof(source)) {
            n = fread(buffer, 1, bufferSize, source);
            counter += n;
            strtol(buffer, NULL, 2);
            fwrite(buffer, 1, n, dest);
        }
    }
    else {
        printf(""Error"");
    }
    fclose(source);
    fclose(dest);
}
</code></pre>

<p>I use <a href=""http://www.cplusplus.com/reference/cstdlib/strtol/"" rel=""nofollow"">strtol</a> to convert binary do hex. After invoking this code I have still strange characters in my file_test file.</p>

<p>I' d like to upload a file on server, for example a <a href=""http://en.wikipedia.org/wiki/Portable_Document_Format"" rel=""nofollow"">PDF</a> file. But firstly I have to write a program, that will convert this file to a hex file. I'd like that the length of a line in hex file would be equal 1024. After that, I will upload this file line by line with <a href=""http://en.wikipedia.org/wiki/PL/SQL"" rel=""nofollow"">PL/SQL</a>.</p>
","<p>Your code is fantastically confused.</p>

<p>It's reading in the data, then doing a <code>strtol()</code> call on it, with a base of 2, and then <em>ignoring the return value</em>. What's the point in that?</p>

<p>To convert the first loaded byte of data to hexadecimal string, you should probably use something like:</p>

<pre><code>char hex[8];

sprintf(hex, ""%02x"", (unsigned int) buffer[0] &amp; 0xff);
</code></pre>

<p>Then write <code>hex</code> to the output file. You need to do this for all bytes loaded, of course, not just <code>buffer[0]</code>.</p>

<p>Also, as a minor point, you can't call <code>feof()</code> before you've tried reading the file. It's better to not use <code>feof()</code> and instead check the <em>return value</em> of <code>fread()</code> to detect when it fails.</p>
","9292973"
"how to simulate correlated binary data with R?","6356","","<p>Supposing I want 2 vectors of binary data with specified phi coefficients, how could I simulate it with R?</p>

<p>For example, how can I create two vectors like <code>x</code> and <code>y</code> of specified vector length with the cor efficient of 0.79</p>

<pre><code>&gt; x = c(1,  1,  0,  0,  1,  0,  1,  1,  1)
&gt; y = c(1,  1,  0,  0,  0,  0,  1,  1,  1)
&gt; cor(x,y)
[1] 0.7905694
</code></pre>
","<p>The <strong>bindata</strong> package is nice for generating binary data with this and more complicated correlation structures. (<a href=""http://www.statistik.lmu.de/~leisch/papers/sfb-am/wp13.pdf"" rel=""noreferrer"">Here's a link to a working paper (warning, pdf)</a> that lays out the theory underlying the approach taken by the package authors.)</p>

<p>In your case, assuming that the independent probabilities of x and y are both 0.5:</p>

<pre><code>library(bindata)

## Construct a binary correlation matrix
rho &lt;- 0.7905694
m &lt;- matrix(c(1,rho,rho,1), ncol=2)   

## Simulate 10000 x-y pairs, and check that they have the specified
## correlation structure
x &lt;- rmvbin(1e5, margprob = c(0.5, 0.5), bincorr = m) 
cor(x)
#           [,1]      [,2]
# [1,] 1.0000000 0.7889613
# [2,] 0.7889613 1.0000000
</code></pre>
","16089734"
"Binary diff and patch utility for a virtual machine image","6352","","<p>I need to release some software quite frequently, and the software is contained as a VMWare disk file, i.e., <code>.vmdk</code> file. 
What I want is some kind of binary diff and patch utility to make the delta generated as small as possible.</p>
","<p>Let me start off with tried-and-true approaches, then point out some more recent approaches.</p>

<p><strong>approaches that I have seen work with binary files</strong></p>

<p>A long time ago, people expanded the old and the new versions of a binary file into temporary ""text"" files (every byte expanded to 3 bytes: 2 hex digits and a newline).
Then run these two ""text"" files through an old version of ""diff"" (that definitely couldn't handle binary files) to make a patch file.
Then we transmitted that ""text"" patch file over communication lines that were not yet 8-bit-clean.
On the receive end, one expanded the old binary file into a temporary text version, then patched that old text file, and then compressed the new text file back into a binary file (compressing each pair of hex digits into one byte, and throwing away the newlines and any carriage returns that might have crept in).</p>

<p>More recently, I have been using <a href=""http://en.wikipedia.org/wiki/rsync"" rel=""nofollow noreferrer"">rsync</a> (or some utility built on top of it such as Unison).
It handles arbitrary binary files just fine.
I generally do a live update, with Unison running on my local machine and rsync running on the file server, talking back and forth to each other.</p>

<p>No matter how a patch file is generated, you can use any data compression utility to compress that file.</p>

<p><strong>approaches that, as far as I know, ought to work with binary files</strong></p>

<p><a href=""https://stackoverflow.com/questions/2415127/how-to-crate-a-patch-file-for-the-binary-difference-output-file"">StackOverflow: ""how to crate a PATCH file for the binary difference output file""</a>
suggests using <a href=""http://www.daemonology.net/bsdiff/"" rel=""nofollow noreferrer"">bsdiff</a>.</p>

<p>Another <a href=""https://stackoverflow.com/questions/777949/can-i-make-git-recognize-a-utf-16-file-as-text"">StackOverflow question</a> implies that ""vimdiff"" seems to handle arbitrary bytes adequately.</p>

<p><a href=""https://stackoverflow.com/questions/3707962/useful-binary-diff-tool-other-than-msdnapatch-and-mpatch-xdelta-bsdiff-vbin"">StackOverflow: ""Useful Binary Diff Tool""</a> mentions a few other binary difference tools.</p>

<p>I hear that some tools based on rsync -- ""<a href=""http://en.wikipedia.org/wiki/Rsync#Variations"" rel=""nofollow noreferrer"">rdiff</a>"" and ""rdiff-backup"" and ""duplicity"" -- allow you create a patch file.
Then a person who receives that patch file can use it to update their old binary file to a new binary file.</p>

<p>The <a href=""http://en.wikipedia.org/wiki/diff"" rel=""nofollow noreferrer"">Wikipedia claims</a> that recent versions of the standard ""diff"" and ""patch"" utilities support binary files.
Have you tried that?</p>

<p><strong>cutting-edge research in executable file compression</strong></p>

<p>If you are interested in cutting-edge research on making the delta file as small as possible when updating executable files, you'll want to check out
<a href=""http://dev.chromium.org/developers/design-documents/software-updates-courgette"" rel=""nofollow noreferrer"">""How Courgette works""</a>
by Stephen Adams 2009 at The Chromium Projects.</p>

<p>Among other things, the computer that receives the patch ""disassembles"" the old application, converting all absolute addresses and offsets into symbols; then patches the disassembled code; then ""reassembles"" the patched code into the new version of the application.</p>
","4731485"
"How do I convert a decimal fraction to binary in Java?","6336","","<p>I need to convert 0.5 in base 10 to base 2 (0.1). 
I have tried using </p>

<pre><code>Double.doubleToRawLongBits(0.5)
</code></pre>

<p>and it returns <code>4602678819172646912</code> which I guess is in hex, but it does not make sense to me.</p>
","<p>Multiply you number by 2^n, convert to an BigInteger, convert to <em>binary</em> String, add a decimal point at position n (from right to left).</p>

<p>Example (quick &amp; ++dirty):</p>

<pre><code>private static String convert(double number) {
    int n = 10;  // constant?
    BigDecimal bd = new BigDecimal(number);
    BigDecimal mult = new BigDecimal(2).pow(n);
    bd = bd.multiply(mult);
    BigInteger bi = bd.toBigInteger();
    StringBuilder str = new StringBuilder(bi.toString(2));
    while (str.length() &lt; n+1) {  // +1 for leading zero
        str.insert(0, ""0"");
    }
    str.insert(str.length()-n, ""."");
    return str.toString();
}
</code></pre>
","756715"
"How can I read an unsigned int from a binary file in Perl?","6332","","<p>Let's say I have a binary file that is formatted like</p>

<pre><code>    [unsigned int(length of text)][text][unsigned int(length of text)][text][unsigned int(length of text)][text]
</code></pre>

<p>And that pattern for the file just keeps repeating. How do I read the unsigned int and print it out followed by the text block in Perl?</p>

<p>Again, this is a binary file and not a plain text file.</p>
","<p>Here is a small working example.</p>

<pre><code>#!/usr/bin/perl

use strict;
use warnings;

my $INT_SIZE = 2;
my $filename = 'somefile.bin';

open my $fh, '&lt;', $filename or die ""Couldn't open file $filename: $!\n"";

binmode $fh;

while ( read $fh, my $packed_length, $INT_SIZE ) {

    my $text = '';
    my $length = unpack 'v', $packed_length;

    read $fh, $text, $length;

    print $length, ""\t"", $text, ""\n"";
}
</code></pre>

<p>Change INT_SIZE and the size and endianness of the unpack template to suit (either 'v' or 'n' or 'V' or 'N'). See the <a href=""http://perldoc.perl.org/functions/unpack.html"" rel=""nofollow noreferrer"">unpack</a> manpage for more details.</p>
","1370246"
"Send binary data via WCF: binary vs MTOM encoding","6322","","<p>I have limited knowledge in WCF as well as sending binary data via WCF, so this question may be somewhat rudimental. </p>

<p>I would like to know the difference between sending data with <code>BinaryMessageEncodingBindingElement</code> and <code>MtomMessageEncodingBindingElement</code>. It is still not clear to me when to use which approach after reading this page from MSDN on <a href=""http://msdn.microsoft.com/en-us/library/ms733742.aspx"" rel=""nofollow"">Large Data and Streaming</a>. </p>

<p>Also, a small question: are a message with attachments and an MTOM message the same thing?</p>
","<p>MTOM is a standard that uses multi-part mime-encoded messages to send portions of the message that are large and would be too expensive to base64 encode as pure binary. The SOAP message itself is sent as the initial part of the message and contains references to the binary parts which a web service software stack like WCF can then pull back together to create a single representation of the message.</p>

<p>Binary encoding is entirely proprietary to WCF and really doesn't just have to do with large messages. It presents a binary representation of the XML Infoset which is far more compact across the wire and faster to parse than text based formats. If you happen to be sending large binary chunks of data then it just fits right in with the other bytes that are being sent.</p>

<p>Streaming can be done used with any message format. That's more about when the data is written across the network vs. being buffered entirely in memoery before being presented to the network transport. Smaller messages make more sense to buffer up before sending and larger messages, especially those containing large binary chunks or streams, necessitate being streamed or will exhaust memory resources.</p>
","6846454"
"Send binary message in MSMQ","6297","","<p>In a .NET service, I'd like to send the content of a stream in a MSMQ message. I receive a Stream object from WCF (which can be an image, a .doc file or anything else) and I would just like to put the content in MSMQ. I tried setting the System.Messaging.Message.BodyStream property to the stream object, but I receive a ""Method not supported"" error when I try to Send the message.</p>

<p>Does anyone have a sample or tutorial on how to do that ?</p>

<p>I'm looking for something like this :</p>

<p>Message contract :</p>

<pre><code>    &lt;MessageContract()&gt; _
   Class UploadStreamMessage
        &lt;MessageHeader()&gt; _
        Public guidCaller As Guid
        &lt;MessageBodyMember()&gt; _
        Public data As Stream
    End Class
</code></pre>

<p>And then the WriteToMSMQ method implementation :</p>

<pre><code>   &lt;OperationBehavior(TransactionScopeRequired:=True, Impersonation:=ImpersonationOption.Required)&gt; _
   Public Sub WriteToMSMQ (ByVal stream As IServiceMSMQ.UploadStreamMessage) Implements IServiceMSMQ.WriteToMSMQ 

Using queue As New MessageQueue(NOM_QUEUE)

    Dim msmqMessage As New Message
    msmqMessage = New System.Messaging.Message()
    msmqMessage.Body = stream.data
    queue.Send(msmqMessage, transaction)
    stream.data.Close()

End Using
</code></pre>

<p>Thanks !   </p>
","<p>MSMQ doesn't support streaming, because it is explicitly message based and loosely coupled. You should declare field of contract as <code>byte[]</code> and gather data there.</p>
","5582726"
"Output binary data on PowerShell pipeline","6290","","<p>I need to pipe some data to a program's stdin.</p>

<ol>
<li>First 4 bytes are a 32 bit unsigned integer representing the length of the data.  These 4 bytes are exactly the same as C would store an unsigned int in memory.  I refer to this as binary data.</li>
<li>Remaining bytes are the data.</li>
</ol>

<p>In c, this is trivial:</p>

<pre><code>WriteFile(h, &amp;cb, 4);  // cb is a 4 byte integer
WriteFile(h, pData, cb);
</code></pre>

<p>or</p>

<pre><code>fwrite(&amp;cb, sizeof(cb), 1, pFile);
fwrite(pData, cb, 1, pFile);
</code></pre>

<p>or c# you would use a BinaryWriter (I think this code is right, i don't have c# lying around right now...)</p>

<pre><code>Bw.Write((int)Data.Length);
Bw.Write(Data, 0, Data.Length);
</code></pre>

<p>In PowerShell I'm sure it's possible, but this is as close as I could get.  This is obviously printing out the 4 bytes of the size as 4 human readable numbers:</p>

<pre><code>$file = ""c:\test.txt""
Set-content $file ""test data"" -encoding ascii
[int]$size = (Get-ChildItem $file).Length
$bytes = [System.BitConverter]::GetBytes($size)
$data = Get-content $file
$bytes
$data

11
0
0
0
test data
</code></pre>

<p>I need the binary data sent out on the pipe to look like this (\xA is the escaped representation of a non printable character, I don't want '\' in my output, I want the BYTE that '\xA' represents in the output) :</p>

<pre><code>\xA\x0\x0\0test data
</code></pre>

<p>I don't know how to write a byte array out the pipeline in binary format.  I also don't know how to get rid of the carriage returns.</p>

<p><strong>EDIT:</strong>
I have found that I can do this:</p>

<pre><code>$file = ""c:\test.txt""
Set-content $file ""test data"" -encoding ascii
""File: """"{0}"""""" -f (Get-content $file)
[int]$size = (Get-ChildItem $file).Length
""Size: "" + $size
$bytes = [System.BitConverter]::GetBytes($size)
""Bytes: "" + $bytes
$data = Get-content $file
$file1 = ""c:\test1.txt""
Set-content $file1 $bytes -encoding byte
Add-Content $file1 $data -encoding ASCII
""File: """"{0}"""""" -f (Get-content $file1)
""Size: "" + (Get-ChildItem $file1).Length

File: ""test data""
Size: 11
Bytes: 11 0 0 0
File: ""   test data""
Size: 15
</code></pre>

<p>But this requires me to build a temporary file.  There must be a better way!</p>

<p><strong>EDIT:</strong>
That solution above, corrupts any character code > 127.  There is no ""binary"" encoding mode for the pipe.</p>

<p><strong>EDIT:</strong> 
I finally discovered a roundabout way to get a BinaryWriter wired up to an app's stdin.  See my answer.</p>
","<p>Bill_Stewart is correct that you can't pipe binary data.  When you use the | operator, powershell uses the encoding dictated by $OutputEncoding.  I could not find an encoding that would not corrupt data.</p>

<p>I found something that does work though, BinaryWriter.</p>

<p>Here is my test code, starting with c:\foo.exe that simply outputs the data it receives:</p>

<pre><code>#include &lt;windows.h&gt;
#include &lt;stdio.h&gt;

int main(int argc, char* argv[])
{
    HANDLE hInput = GetStdHandle(STD_INPUT_HANDLE); 
    BYTE aBuf[0x100];
    int nRet;
    DWORD cbRead;
    if (!(nRet = ReadFile(hInput, aBuf, 256, &amp;cbRead, NULL)))
        return printf(""err: %u %d %d"", cbRead, nRet, GetLastError());
    for (int i=0 ; i&lt;256 ; ++i)
        printf(""%d "", aBuf[i]);
    return 0;
}
</code></pre>

<p>This ps script demonstrates the ""corruption"":</p>

<pre><code>$file = ""c:\foo.bin""
Set-Content $file ([Byte[]](0..255)) -encoding byte
$data = (Get-content $file -encoding byte)
$prefix = ($data | foreach-object {
  $_ -as [char]
}) -join """"
""{0}"" -f $prefix
$OutputEncoding = [System.text.Encoding]::GetEncoding(""us-ascii"")
$prefix | c:\foo.exe
</code></pre>

<p>Here is the output.  First you see that $prefix does have the complete charset. Second, you see the data that got to foo.exe has been converted.</p>

<pre><code> !""#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
 ¡¢£¤¥¦§¨©ª«¬­®¯°±²³´µ¶·¸¹º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿ
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 5
0 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 9
7 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 63 63 63 63 63 63 63 
63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 
63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 
63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63
</code></pre>

<p>Using BinaryWriter works:</p>

<pre><code>$file = ""c:\foo.bin""
Set-Content $file ([Byte[]](0..255)) -encoding byte
$data = (Get-content $file -encoding byte)

$ProcessInfo = New-Object System.Diagnostics.ProcessStartInfo 
$ProcessInfo.FileName = ""c:\foo.exe""
$ProcessInfo.RedirectStandardInput = $true 
$ProcessInfo.RedirectStandardOutput = $true 
$ProcessInfo.UseShellExecute = $false 
$Proc = New-Object System.Diagnostics.Process 
$Proc.StartInfo = $ProcessInfo 
$Proc.Start() | Out-Null 

$Writer = new-object System.IO.BinaryWriter($proc.StandardInput.BaseStream);
$Writer.Write($data, 0, $data.length)
$Writer.flush()
$writer.close()

$Proc.WaitForExit()
$Proc.StandardOutput.ReadToEnd()


0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 5
0 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 9
7 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 1
33 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 16
8 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203
 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 
239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255
</code></pre>

<p>So, my final script which writes the length in binary before writing the data file, would look something like this:</p>

<pre><code>$file = ""c:\foo.bin""
Set-Content $file ([Byte[]](0..255)) -encoding byte
$data = (Get-content $file -encoding byte)

$ProcessInfo = New-Object System.Diagnostics.ProcessStartInfo 
$ProcessInfo.FileName = ""c:\foo.exe""
$ProcessInfo.RedirectStandardInput = $true 
$ProcessInfo.RedirectStandardOutput = $true 
$ProcessInfo.UseShellExecute = $false 
$Proc = New-Object System.Diagnostics.Process 
$Proc.StartInfo = $ProcessInfo 
$Proc.Start() | Out-Null 

$Writer = new-object System.IO.BinaryWriter($proc.StandardInput.BaseStream);
$Writer.Write([int]$data.length)
$Writer.Write($data, 0, $data.length)
$Writer.flush()
$writer.close()

$Proc.WaitForExit()
$Proc.StandardOutput.ReadToEnd()
</code></pre>

<p>you can see the first 4 bytes 0 1 0 0 are the raw binary representation of an [int] that is equal to 256</p>

<pre><code>0 1 0 0 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 1
31 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 16
6 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201
 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 
237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
</code></pre>
","24745250"
"Converting to binary in C++","6273","","<p>I made a function that converts numbers to binary. For some reason it's not working. It gives the wrong output. The output is in binary format, but it always gives the wrong result for binary numbers that end with a zero(at least that's what I noticed..)</p>

<pre><code>unsigned long long to_binary(unsigned long long x)
{
    int rem;
    unsigned long long converted = 0;

    while (x &gt; 1)
    {
        rem = x % 2;
        x /= 2;
        converted += rem;
        converted *= 10;
    }

    converted += x;

    return converted;
}
</code></pre>

<p>Please help me fix it, this is really frustrating..</p>

<p>Thanks!</p>
","<ol>
<li>You're reversing the bits.</li>
<li>You cannot use the remains of x as an indicator when to terminate the loop. </li>
</ol>

<p>Consider e.g. 4. </p>

<p>After first loop iteration:</p>

<pre><code>rem == 0
converted == 0
x == 2
</code></pre>

<p>After second loop iteration:</p>

<pre><code>rem == 0
converted == 0
x == 1
</code></pre>

<p>And then you set converted to 1.</p>

<p>Try:</p>

<pre><code>int i = sizeof(x) * 8; // i is now number of bits in x
while (i&gt;0) {
  --i;
  converted *= 10;
  converted |= (x &gt;&gt; i) &amp; 1;
  // Shift x right to get bit number i in the rightmost position, 
  // then and with 1 to remove any bits left of bit number i,
  // and finally or it into the rightmost position in converted
}
</code></pre>

<p>Running the above code with x as an unsigned char (8 bits) with value 129 (binary 10000001)</p>

<p>Starting with <code>i = 8</code>, size of unsigned char * 8. In the first loop iteration <code>i</code> will be 7. We then take <code>x</code> (129) and shift it right 7 bits, that gives the value 1. This is OR'ed into <code>converted</code> which becomes 1. Next iteration, we start by multiplying <code>converted</code> with 10 (so now it's 10), we then shift <code>x</code> 6 bits right (value becomes 2) and ANDs it with 1 (value becomes 0). We OR 0 with <code>converted</code>, which is then still 10. 3rd-7th iteration do the same thing, <code>converted</code> is multiplied with 10 and one specific bit is extracted from <code>x</code> and OR'ed into <code>converted</code>. After these iterations, <code>converted</code> is 1000000. </p>

<p>In the last iteration, first <code>converted</code> is multiplied with 10 and becomes 10000000, we shift <code>x</code> right 0 bits, yielding the original value 129. We AND x with 1, this gives the value 1. 1 is then OR'ed into <code>converted</code>, which becomes 10000001.</p>
","5144431"
"How to embed a file into an executable file?","6259","","<p>I have two problems, the first has been solved.</p>

<p><strong>Current problem</strong><br>
If I embed a file that requires a library to load it, such as a jpeg image or a mp3 music, I will need to use the file as input to the library. However, each library is different and uses a way to get a file as input, the input may be the file name or a FILE* pointer (from libc's file interface).</p>

<p>I would like to know how to access an embedded file with a name. It will be inefficient if I create a temporary file, is there another way? Can I map a file name to memory? My platforms are Windows and Linux.</p>

<p>If <strong>show_file(const char* name)</strong> is a function from a library, I will need a string to open the file.<br>
I have seen these questions:<br>
<a href=""https://stackoverflow.com/questions/1558772/how-to-get-file-descriptor-of-buffer-in-memory"">How to get file descriptor of buffer in memory?</a><br>
<a href=""https://stackoverflow.com/questions/1188757/getting-filename-from-file-descriptor-in-c"">Getting Filename from file descriptor in C</a></p>

<p>and the following code is my solution. Is it a good solution? Is it inefficient?</p>

<pre><code># include &lt;stdio.h&gt;
# include &lt;unistd.h&gt;

extern char _binary_data_txt_start;
extern const void* _binary_data_txt_size;
const size_t len = (size_t)&amp;_binary_data_txt_size;

void show_file(const char* name){
    FILE* file = fopen(name, ""r"");
    if (file == NULL){
        printf(""Error (show_file): %s\n"", name);
        return;
    }

    while (true){
        char ch = fgetc(file);
        if (feof(file) )
            break;
        putchar( ch );
    }
    printf(""\n"");

    fclose(file);
}

int main(){

    int fpipe[2];
    pipe(fpipe);

    if( !fork() ){
        for( int buffsize = len, done = 0; buffsize&gt;done; ){
            done += write( fpipe[1], &amp;_binary_data_txt_start + done, buffsize-done );
        }
        _exit(0);
    }

    close(fpipe[1]);
    char name[200];
    sprintf(name, ""/proc/self/fd/%d"", fpipe[0] );

    show_file(name);

    close(fpipe[0]);
}
</code></pre>

<hr>

<p><strong>The other problem (solved)</strong><br>
I tried to embed a file on Linux, with GCC, and it worked. However, I tried to do the same thing on Windows, with Mingw, and it did not compile.</p>

<p>The code is:</p>

<pre><code># include &lt;stdio.h&gt;

extern char _binary_data_txt_start;
extern char _binary_data_txt_end;

int main(){
    for (char* my_file = &amp;_binary_data_txt_start; my_file &lt;= &amp;_binary_data_txt_end; my_file++)
        putchar(*my_file);
    printf(""\n"");
}
</code></pre>

<p>The compilation commands are:</p>

<pre><code>objcopy --input-target binary --output-target elf32-i386 --binary-architecture i386 data.txt data.o
g++ main.cpp data.o -o test.exe
</code></pre>

<p>On Windows, I get the following compiler error:</p>

<pre><code>undefined reference to `_binary_data_txt_start'
undefined reference to `_binary_data_txt_end'
</code></pre>

<p>I tried to replace <strong>elf32-i386</strong> with <strong>i386-pc-mingw32</strong>, but I still get the same error.</p>
","<p>I think that for this to work with MinGW you'll need to remove the leading underscore from the names in the .c file.  See <a href=""https://stackoverflow.com/questions/2627004/embedding-binary-blobs-using-gcc-mingw"">Embedding binary blobs using gcc mingw</a> for some details.</p>

<p>See if using the following helps:</p>

<pre><code>extern char binary_data_txt_start;
extern char binary_data_txt_end;
</code></pre>

<p>If you need the same source to work for Linux or MinGW builds, you might need to use the preprocessor to have the right name used in the different environments. </p>
","6785947"
"Fast modulo 3 or division algorithm?","6221","","<p>is there a fast algorithm, similar to power of 2, which can be used with 3, i.e. n%3.
Perhaps something that uses the fact that if sum of digits is divisible by three, then the number is also divisible.</p>

<p>This leads to a next question.  What is the fast way to add digits in a number?  I.e. 37 -> 3 +7 -> 10
I am looking for something that does not have conditionals as those tend to inhibit vectorization</p>

<p>thanks</p>
","<p><code>4 % 3 == 1</code>, so <code>(4^k * a + b) % 3 == (a + b) % 3</code>.  You can use this fact to evaluate x%3 for a 32-bit x:</p>

<pre><code>x = (x &gt;&gt; 16) + (x &amp; 0xffff);
x = (x &gt;&gt; 10) + (x &amp; 0x3ff);
x = (x &gt;&gt; 6) + (x &amp; 0x3f);
x = (x &gt;&gt; 4) + (x &amp; 0xf);
x = (x &gt;&gt; 2) + (x &amp; 0x3);
x = (x &gt;&gt; 2) + (x &amp; 0x3);
x = (x &gt;&gt; 2) + (x &amp; 0x3);
if (x == 3) x = 0;
</code></pre>

<p>(Untested - you might need a few more reductions.)  Is this faster than your hardware can do x%3?  If it is, it probably isn't by much.</p>
","1697422"
"How do you convert A binary number to a BigInteger in Java?","6219","","<p>I needed to convert a very big binary value into its decimal equivalent. As it is a big integer I was using BigInteger. So how do I convert this binary number to a BigInteger? </p>
","<p>If you have the <code>String</code> representation of your binary number, provide it to this overloaded <code>BigInteger</code> constructor to create an instance:</p>

<pre><code>BigInteger(String val, int radix);
</code></pre>

<p>In your case, radix is clearly 2, i.e. you can use something like this:</p>

<pre><code>BigInteger yourNumber = new BigInteger(""101000101110...1010"", 2);
</code></pre>
","17833566"
"SQL: Binary to IP Address","6201","","<p>I'm trying to convert A binary IP to a human-readable IP</p>

<pre><code>SELECT HEX( `ip_bin` ) FROM `log_metadata`
</code></pre>

<p>gives me
    <code>4333D26E000000000000000000000000</code></p>

<p>And </p>

<pre><code>SELECT INET_NTOA(0x4333D26E)
</code></pre>

<p>gives me <code>67.51.210.110</code></p>

<p>So I tried: </p>

<pre><code>SELECT
  SUBSTRING( CONVERT(HEX(`ip_bin`), CHAR(32)), 1, 8 ) AS `A`
, INET_NTOA( 
  SUBSTRING( CONVERT(HEX(`ip_bin`), CHAR(32)), 1, 8 ) 
                                                     ) AS `B`
, INET_NTOA(hex(`ip_bin`))  AS `C`
, INET_NTOA(`ip_bin`)       AS `D`
FROM `log_metadata`
</code></pre>

<p>But I only get</p>

<pre><code>+----------+------------+------------+---------+
| A        | B          | C          | D       |
+----------+------------+------------+---------+
| 4333D26E | 0.0.16.237 | 0.0.16.237 | 0.0.0.0 |
+----------+------------+------------+---------+
</code></pre>

<p>Any suggestions?</p>
","<pre><code>mysql&gt; select inet_ntoa(conv('4333d26e', 16, 10));
+-------------------------------------+
| inet_ntoa(conv('4333d26e', 16, 10)) |
+-------------------------------------+
| 67.51.210.110                       |
+-------------------------------------+
1 row in set (0.00 sec)
</code></pre>

<p>Check if it works there too =)</p>

<h2>Edit</h2>

<p>The problem is that <code>inet_ntoa</code> seems to parse from <em>decimal</em> <code>strings</code> number representation, not hexadecimal ones, or from hexadecimal <code>integers</code>. Compare:</p>

<pre><code>mysql&gt; select inet_ntoa(0x4333d26e);
+-----------------------+
| inet_ntoa(0x4333d26e) |
+-----------------------+
| 67.51.210.110         |
+-----------------------+
1 row in set (0.02 sec)

mysql&gt; select inet_ntoa('0x4333d26e');
+-------------------------+
| inet_ntoa('0x4333d26e') |
+-------------------------+
| 0.0.0.0                 |
+-------------------------+
1 row in set, 1 warning (0.00 sec)
</code></pre>

<h2>Edit</h2>

<p>This is simpler and seems to work too:</p>

<pre><code>SELECT INET_NTOA(CONV(ip_bin, 2, 10)) FROM log_metadata
</code></pre>
","15370950"
"Why ""010"" equals 8?","6170","","<p>My simple question is why:</p>

<pre><code>System.out.println(010|4);
</code></pre>

<p>prints ""12""? I understand bitwise OR operator but why ""010"" equals 8? It's definitely not compliment 2's notification, so how to decode this number?</p>
","<p>Have a look at the <a href=""http://docs.oracle.com/javase/specs/jls/se7/html/jls-3.html#jls-3.10.1"" rel=""nofollow"">Java Language Specification, Chapter 3.10.1 Integer Literals</a></p>

<blockquote>
  <p>An integer literal may be expressed in decimal (base 10), hexadecimal
  (base 16), <strong>octal (base 8)</strong>, or binary (base 2).</p>
  
  <p>[...]</p>
  
  <p>An <strong>octal numeral consists of an ASCII digit 0 followed by one or more
  of the ASCII digits 0 through 7</strong> interspersed with underscores, and can
  represent a positive, zero, or negative integer.</p>
</blockquote>

<p>Now you should understand why <code>010</code> is <code>8</code>.</p>
","17469940"
"List of all binary combinations for a number in Java","6157","","<p>I am working on a project involving ""Dynamic Programming"" and am struck on this trivial thing, please help.</p>

<p>Suppose I take 4 as an input, I want to display something like: 0000 to 1111</p>

<p>But, if I input 5, I want to display like: 00000 to 11111 and so on.</p>

<p>Thanks in advance,</p>

<p><strong>EDIT</strong>: Please don't post asking me for the code. This is not a homework problem and I don't need any code, just tell me the logic for it and I would be happy.</p>

<p><strong>EDIT2</strong>: WTH is happening with Stackoverflow, did I ask any of you to write code for me? I want the person who downvoted to upvote it. What is a point of this forum if I can't for help?</p>

<p>Share the logic with me. We can discuss and I do not require the code for this.</p>

<p><strong>EDIT3</strong>: Here I am posting the code which I tried. I hope this ""SATISFIES"" all the people who were thinking I have not tried anything.</p>

<pre><code>import java.util.ArrayList;
</code></pre>

<p>public class RegularInvestigator {</p>

<p>public ArrayList createCombinations(ArrayList listOfFlightNumbers) {</p>

<pre><code>ArrayList&lt;String&gt; result = new ArrayList&lt;String&gt;();

for(int i = 1; i &lt; listOfFlightNumbers.size(); i++) {

  String binaryEqvivalent = Integer.toBinaryString(i);System.out.println(binaryEqvivalent);
  String element = """";

  for(int j = 0; j &lt; binaryEqvivalent.length(); j++)
    if(binaryEqvivalent.charAt(j) == '1')
      element += listOfFlightNumbers + "" "";

  result.add(element.substring(0, element.length() - 1));
}

return result;
</code></pre>

<p>}</p>

<pre><code>private String getContent(ArrayList&lt;String&gt; flight) {
String temp = """";

for(int i = 0; i &lt; flight.size() - 1; i++)  temp += flight.get(i) + "" "";

temp += flight.get(flight.size() - 1);

return temp;
</code></pre>

<p>}</p>

<p>private ArrayList removeElementAtIndex(ArrayList flight, int position) {</p>

<pre><code>ArrayList&lt;String&gt; res = new ArrayList&lt;String&gt;();

for(int i = 0; i &lt; flight.size(); i++) {
  if(i != position) res.add(flight.get(i));
}

return res;
</code></pre>

<p>}
}</p>

<p><strong>EDIT4</strong>: Thank you phoxis, PengOne, Jerry Coffin and oliholz for your valuable answers :)</p>
","<ul>
<li>Get input <code>n</code></li>
<li>Count from <code>i=0</code> to <code>(2^n) - 1</code></li>
<li>for each value of <code>i</code> bitmask each bit of <code>i</code> and display.</li>
</ul>
","6463400"
"What is the Decimal value for the 8-bit 2's complement number 11010110?","6148","","<p>This more of a hw question but I cannot figure this one out. I thought it would be 214 but because of the first bit on the left, I am not so sure. </p>
","<p>As it's a 2's complement number, the first bit being one means that it's a negative number.</p>

<p>The value is 214 - 256 = -42.</p>

<p>It can also be calculated as -(~214 + 1) = -(41 + 1) = -42.</p>

<p>Binary that would be -(~11010110 + 1) = -(00101001 + 1) = -00101010.</p>
","14927961"
"What is a suitable buffer for Python's struct module","6129","","<p>In Python I'm accessing a binary file by reading it into a string and then using <code>struct.unpack(...)</code>. Now I want to write to that string using <code>struct.pack_into(...)</code>, but I get the error <em>""Cannot use string as modifiable buffer""</em>. What would be a suitable buffer for use with the <code>struct</code> module?</p>
","<p>If you aren't trying to pack it into a specific object, just use <a href=""http://docs.python.org/library/struct.html#struct.pack"" rel=""noreferrer""><code>struct.pack</code></a> to return a string.</p>

<p>Otherwise, <a href=""http://docs.python.org/library/ctypes.html#ctypes.create_string_buffer"" rel=""noreferrer""><code>ctypes.create_string_buffer</code></a> is one way to obtain a mutable buffer.</p>
","1732698"
"Python - convert a raw binary dump into ASCII HEX bytes","6058","","<p>Further to this question: <a href=""https://stackoverflow.com/questions/12574587/handling-and-working-with-binary-data-hex-with-python"">Handling and working with binary data HEX with python</a>  (and thanks to awesome pointers I received) I'm stuck on one last aspect of tool. </p>

<p>I am basically writing a cleaner for files that I have with data past the EOF marker. This extra data means they fail some validation tools. I need to strip the extra data, so they be presented to the validator, however I don't want to throw this data away (in fact I have to keep it...) </p>

<p>I've written an XML container to hold the data, and a few other provenance/audit type values, but I'm (still) stuck on elegantly moving between raw binary and something I can ""bake"" in to a file. </p>

<p>example:</p>

<p>A jpg file ends with (hex editor view)
<code>96 1a 9c fd ab 4f 9e 69 27 ad fd da 0a db 76 bb
ee d2 6a fd ff 00 ff d9 ff ff ff ff ff ff ff ff
ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff
ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff
ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff
ff ff ff ff ff ff ff</code></p>

<p>The EOF marker for jpg is <code>ff d9</code>, so the cleaner works backwards through the file until its a match against the EOF marker. In this case it would create a new jpg file stopping at the <code>ff d9</code> and then attempt to write the stripped data to the XML (via the elementTree lib): <code>changeString.text =str(excessData)</code></p>

<p>Of course this wont work as the XML writer is looking to write ASCII not binary dumps.</p>

<p>In the above case, the error is <code>UnicodeDecodeError: 'ascii' codec can't decode byte 0xff in position 0: ordinal not in range(128)</code> which I can see if because its not a valid ASCII character</p>

<p>My question therefore, is how do I elegantly deal with this raw data, in a way it can stored and used in the future? (I plan to write an 'uncleaner' next that can take the clean file and the XML and reconstruct the original file...) </p>

<p>______EDIT_______</p>

<p>Using the suggestions from below, this is the traceback:</p>

<pre><code>Traceback (most recent call last):
  File ""C:\...\EOF_cleaner\scripts\test6.py"", line 87, in &lt;module&gt; main()
  File ""C:\...\EOF_cleaner\scripts\test6.py"", line 73, in main splitFile(f_data, offset)
  File ""C:\...EOF_cleaner\scripts\test6.py"", line 60, in splitFile makeXML(excessData)
  File ""C:\...\EOF_cleaner\scripts\test6.py"", line 53 in makeXML ET.ElementTree(root).write(noteFile)
  File ""c:\python27\lib\xml\etree\ElementTree.py"", line 815, in write serialize(write, self._root, encoding, qnames, namespaces)
  File ""c:\python27\lib\xml\etree\ElementTree.py"", line 934, in _serialize_xml_serialize_xml(write, e, encoding, qnames, None)
  File ""c:\python27\lib\xml\etree\ElementTree.py"", line 934, in _serialize_xml_serialize_xml(write, e, encoding, qnames, None)
  File ""c:\python27\lib\xml\etree\ElementTree.py"", line 934, in _serialize_xml_serialize_xml(write, e, encoding, qnames, None)
  File ""c:\python27\lib\xml\etree\ElementTree.py"", line 932, in _serialize_xml write(_escape_cdata(text, encoding))
  File ""c:\python27\lib\xml\etree\ElementTree.py"", line 1068, in _escape_cdata  return text.encode(encoding, ""xmlcharrefreplace"")
  UnicodeDecodeError: 'ascii' codec can't decode byte 0xff in position 0: ordinal not in range(128)
</code></pre>

<p>The line that throws things is <code>changeString.text = excessData.encode('base64')</code> (line 45) and <code>ET.ElementTree(root).write(noteFile)</code> (line 53)</p>
","<p>Use <a href=""https://en.wikipedia.org/wiki/Base64"" rel=""nofollow"">Base64</a>:</p>

<pre><code>excessData.encode('base64')
</code></pre>

<p>It'll be easy to turn that back to binary data later on with a simple <code>.decode('base64')</code> call.</p>

<p>Base64 encodes to ASCII data safe for inclusion in XML, in a reasonably compact format; every 3 bytes of binary information become 4 Base64 characters.</p>
","12592144"
"Read string from binary file","6041","","<p>I want to read bytes 1,2 and 3 from a file. I know it corresponds to a string (in this case it's <code>ELF</code> of a Linux binary header)</p>

<p>Following examples I could find on the net I came up with this:</p>

<pre><code>with open('hello', 'rb') as f:
    f.seek(1)
    bytes = f.read(3)
    string = struct.unpack('s', bytes)
    print st
</code></pre>

<p>Looking at the official documentation of <a href=""https://docs.python.org/2.7/library/struct.html"" rel=""nofollow"">struct</a> it seems that passing <code>s</code> as argument should allow me to read a string.</p>

<p>I get the error:</p>

<pre><code>st = struct.unpack('s', bytes)
struct.error: unpack requires a string argument of length 1
</code></pre>

<p>EDIT: Using Python 2.7</p>
","<p>In your special case, it is enough to just check</p>

<pre><code>if bytes == 'ELF':
</code></pre>

<p>to test all three bytes in one step to be the three characters <code>E</code>, <code>L</code> and <code>F</code>.</p>

<p>But also if you want to check the numerical values, you do not need to unpack anything here.  Just use <code>ord(bytes[i])</code> (with i in 0, 1, 2) to get the byte values of the three bytes.</p>

<p>Alternatively you can use</p>

<pre><code>byte_values = struct.unpack('bbb', bytes)
</code></pre>

<p>to get a tuple of the three bytes.  You can also unpack that tuple on the fly in case the bytes have nameable semantics like this:</p>

<pre><code>width, height, depth = struct.unpack('bbb', bytes)
</code></pre>

<p>Use <code>'BBB'</code> instead of <code>'bbb'</code> in case your byte values shall be unsigned.</p>
","23424157"
"convert decimal numbers to excess-127 representations","6040","","<p>Represent the following decimal numbers in binary using 8-bit signed magnitude, one’s complement, two’s complement, and excess-127 representations.</p>

<p>a) 77</p>

<p>b) –42</p>

<p>c)  119</p>

<p>d)  –107</p>

<p>I've converted them to the other representations just need to know how to convert to excess-127</p>

<p>a) Signed magnitude: 01001101 
One's complement: 01001101
Two's complement: 01001101 </p>

<p>b) Signed magnitude: 10101010
One's complement: 11010101 
Two's complement: 11010110 </p>

<p>c) Signed magnitude: 01110111 
One's complement: 01110111 
Two's complement: 01110111 </p>

<p>please help</p>
","<p>Assuming you are referring to Offset binary: <a href=""https://en.wikipedia.org/wiki/Offset_binary"" rel=""nofollow"">https://en.wikipedia.org/wiki/Offset_binary</a>, of which the most famous example would be Excess-3: <a href=""https://en.wikipedia.org/wiki/Excess-3"" rel=""nofollow"">https://en.wikipedia.org/wiki/Excess-3</a>, then the solution would be:</p>

<ul>
<li>a) 77 + 127 mod 256 = 204 mod 256 = 204 = 11001100</li>
<li>b) -42 + 127 mod 256 = 85 mod 256 = 85 = 01010101</li>
</ul>

<p>etc...</p>
","34976842"
"How to parse a binary file using Javascript and Ajax","6038","","<p>I am trying to use JQuery to pull a binary file from a webserver, parse it in Javascript and display the contents. I can get the file ok and parse some of the file correctly. How ever I am running into trouble with one byte not coming out as expected.</p>

<p>I am parsing the file a byte at a time, it is correct until I get to the hex value B6 where I am getting FD instead of B6.</p>

<p>Function to read a byte</p>

<pre><code>data.charCodeAt(0) &amp; 0xff;
</code></pre>

<p>File As Hex:
02 00 00 00 55 4C 04 00 B6 00 00 00</p>

<p>The format I want to parse the file out into.</p>

<ul>
<li>short: 0002 </li>
<li>short: 0000 </li>
<li>string: UL</li>
<li>short: 0004 </li>
<li>long: 0000B6</li>
</ul>

<p>Any hints as to why the last value is incorrect?</p>
","<p>A similar question was answered <a href=""https://stackoverflow.com/questions/327685/is-there-a-way-to-read-binary-data-into-javascript"">here</a>.  The short answer is that you can't easily handle binary data in javascript, and charCodeAt deals with Unicode characters so it's certainly not suitable for binary manipulation.</p>
","1919423"
"Storing a binary SHA1 hash into a mySQL BINARY(20) column","6025","","<p>I want to store a SHA1 hash into a BINARY(20) column.  I tried it by preparing <code>INSERT INTO foo SET ( hash=? )</code> followed by executing the statement binding to a variable containing the 20-byte binary value, but got a runtime syntax error ""... hash='\0\0#*$^!...'"".  (I'm baffled why executing a prepared statement would represent values like this.)  <a href=""https://stackoverflow.com/questions/614476/storing-sha1-hash-values-in-mysql"">This post</a> doesn't indicate there's anything wrong with storing a SHA1 into a BINARY(20) column, but doesn't indicate how it's done with SQL.</p>

<p><strong>UPDATE</strong>: ""Why binary and not hex?"" There will be about a billion rows, so 20 extra bytes is significant, and also I'm told that numeric lookups are twice as fast as string lookups (and that BINARY fields will be treated like numerics)</p>

<p><strong>UPDATE 2</strong>: The error message was not complaining about the representation of the binary value, but about the parentheses around the SET list.  </p>
","<p>Use the <a href=""http://dev.mysql.com/doc/refman/5.0/en/string-functions.html#function_unhex"" rel=""nofollow"">UNHEX</a> function to translate it before insertion:</p>

<pre><code> INSERT INTO foo SET hash=UNHEX('0beec7b5ea3f0fdbc95d0dd47f3c5bc275da8a33');
</code></pre>

<p>You will have the space requirements tackled, but you could get some performance hits translating your hash from binary to hex back to binary.</p>
","14608728"
"Determine source language from a binary?","6004","","<p>I <a href=""https://stackoverflow.com/questions/1703088/what-is-the-state-of-non-objective-c-programming-for-iphone/1703160#1703160"">responded</a> to another question about developing for the iPhone in non-Objective-C languages, and I made the assertion that using, say, C# to write for the iPhone would strike an Apple reviewer wrong. I was speaking largely about UI elements differing between the ObjC and C# libraries in question, but a commenter made an interesting point, leading me to this question:</p>

<p><strong>Is it possible to determine the language a program is written in, solely from its binary?</strong> If there are such methods, what are they?</p>

<p>Let's assume for the purposes of the question:</p>

<ul>
<li>That from an interaction standpoint (console behavior, any GUI appearance, etc.) the two are identical.</li>
<li>That performance isn't a reliable indicator of language (no comparing, say, Java to C).</li>
<li>That you don't have an interpreter or something between you and the language - just raw executable binary.</li>
</ul>

<p>Bonus points if you're language-agnostic as possible.</p>
","<p>I'm not a compiler hacker (someday, I hope), but I figure that you may be able to find telltale signs in a binary file that would indicate what compiler generated it and some of the compiler options used, such as the level of optimization specified.</p>

<p>Strictly speaking, however, what you're asking is impossible.  It could be that somebody sat down with a pen and paper and worked out the binary codes corresponding to the program that they wanted to write, and then typed that stuff out in a hex editor.  Basically, they'd be programming in assembly without the assembler tool.  Similarly, you may never be able to tell with certainty whether a native binary was written in straight assembler or in C with inline assembly.</p>

<p>As for virtual machine environments such as JVM and .NET, you should be able to identify the VM by the byte codes in the binary executable, I would expect.  However you may not be able to tell what the source language was, such as C# versus Visual Basic, unless there are particular compiler quirks that tip you off.</p>
","1704254"
"How to Post Binary File From JQuery Client to Java Server using REST","5998","","<p>I'm trying to post a binary file from my client (jQuery) to my server (Java).  I'm using Apache CXF and REST.  The file is making it to the server, which promptly throws an exception.</p>

<p>Here's the JavaScript on the client side:</p>

<pre><code>  function handleFileUpload() {
     console.log(""handleFileUpload called"");
     var url = ""http://myserver:8181/bootstrap/rest/upload/license"";
     var file = $('#file_upload').get(0).files[0];
     $.ajax({
        url: url,
        type: ""post"",
        data: file,
        processData: false,
        success: function(){
           $(""#file_upload_result"").html('submitted successfully');
        },
        error:function(){
          $(""#file_upload_result"").html('there was an error while submitting');
        }   
    }); 
  }
</code></pre>

<p>Here is the server-side code:</p>

<pre><code>@POST
@Consumes(MediaType.MULTIPART_FORM_DATA)
@Produces(MediaType.TEXT_PLAIN)
@Path(""/license"")
public String uploadLicenseFile(@FormParam(""file"") InputStream pdfStream) 
{
    try 
    {
        //byte[] pdfByteArray = convertInputStreamToByteArrary(pdfStream);
        //fileLength = pdfByteArray.length;
        fileLength = pdfStream.available();
        response = ""Upload successful!"";
        // TODO read file and store params in memory
    } 
    catch (Exception ex) 
    {
        response = ""Upload failed: "" + ex.getMessage();
        fileLength = 0;
    }
    return getFileLength();
}
</code></pre>
","<p>You are sending the file as the post body, what you want to do is send the file in a multi-part form data body. You can use the FormData object to do this.</p>

<pre><code>  function handleFileUpload() {
     console.log(""handleFileUpload called"");
     var url = ""http://myserver:8181/bootstrap/rest/upload/license"";
     var file = $('#file_upload').get(0).files[0];
     var formData = new FormData();
     formData.append('file', file)
     $.ajax({
        url: url,
        type: ""post"",
        data: formData,
        processData: false,
        contentType: false,
        success: function(){
           $(""#file_upload_result"").html('submitted successfully');
        },
        error:function(){
          $(""#file_upload_result"").html('there was an error while submitting');
        }   
    }); 
  }
</code></pre>
","19148112"
"How to convert hex number to bin in Swift?","5990","","<p>I have string variable:
var str = ""239A23F""
How do I convert this string to a binary number?
<code>str.toInt()</code> does not work.</p>
","<p>You can use <code>NSScanner()</code> from the Foundation framework:</p>

<pre><code>let scanner = NSScanner(string: str)
var result : UInt32 = 0
if scanner.scanHexInt(&amp;result) {
    println(result) // 37331519
}
</code></pre>

<p>Or the BSD library function <code>strtoul()</code></p>

<pre><code>let num = strtoul(str, nil, 16)
println(num) // 37331519
</code></pre>

<p>As of <em>Swift 2 (Xcode 7),</em> all integer types have an</p>

<pre><code>public init?(_ text: String, radix: Int = default)
</code></pre>

<p>initializer, so that a pure Swift solution is available:</p>

<pre><code>let str = ""239A23F""
let num = Int(str, radix: 16)
</code></pre>
","26284562"
"Download a file from Node.JS server with AngularJS","5989","","<p>I would like to download files with my browser from my server running with NodeJS.
On the server side, to serve the file i have :</p>

<pre><code>exports.download = function(req, res) {
  var filename = ""33.jpg"";
  var filePath = path.join(__dirname, '..', '..', 'downloads', filename);
  var stat = fs.statSync(filePath);

  var fileToSend = fs.readFileSync(filePath);

  res.writeHead(200, {
      'Content-Type': 'image/jpeg',
      'Content-Length': stat.size,
      'Content-Disposition': filename
  });
  res.end(fileToSend);
};
</code></pre>

<p>The file called 33.jpg exists and is 744Kb sized. The call from the client works great</p>

<p>On the client side with AngularJS here is how i call a post call to get the file (currently the parameter uri is not used) :</p>

<pre><code>$scope.downloadTrack = function(uri) {
  $http.post('/api/files/download', {uri: uri}).then(function(response) {
    var blob = new Blob([response.data], { type: 'image/jpeg' });
    var fileName = response.headers('content-disposition');
    saveAs(blob, fileName);
  }, function(response) {
    console.log('Download error');
    console.log(response);
  });
}
</code></pre>

<p>The headers are ok (i can retrieve the file name)</p>

<p>My issue is that a file is downloaded but with a size of 1.5Mb and is unreadable. I tried different methods with streams, append data to response, pipe, etc. without success.
Another point (not sure is important) : within Safari the files is opened with a broken icon displayed, within Chrome the file is saved</p>

<p>PS : i created the project with Yeoman if the information is useful</p>

<p>Thanks all</p>

<p><strong>[Update]</strong>
New version of server function (still not working)</p>

<pre><code>exports.download = function(req, res) {
  var filename = ""33.jpg"";
  var filePath = path.join(__dirname, '..', '..', 'downloads', filename);
  var stat = fs.statSync(filePath);
  var fileToSend = fs.readFileSync(filePath);
  res.set('Content-Type', 'image/jpeg');
  res.set('Content-Length', stat.size);
  res.set('Content-Disposition', filename);
  res.send(fileToSend);
};
</code></pre>

<p><strong>[Update 2]</strong>
The double sized file contains extra ""efbffd"" char sequence randomly in the file making it unreadable</p>
","<p>Problem solved with a definition of the response type set to blob</p>

<pre><code>  $http({
      url: '/api/files/download',
      method: ""POST"",
      data: {
        uri: uri
      },
      responseType: 'blob'
  }).success(function (data, status, headers, config) {
      var blob = new Blob([data], { type: 'audio/mpeg' });
      var fileName = headers('content-disposition');
      saveAs(blob, fileName);
  }).error(function (data, status, headers, config) {
    console.log('Unable to download the file')
  });
</code></pre>
","32456871"
"I need a binary comparison tool for Win/Linux","5986","","<p>First of all, I don't need a textual comparison so Beyond Compare doesn't do what I need.</p>

<p>I'm looking for a util that can report on the differences between two files, at the byte level.  Bare minimum is the need to see the percentage change in the file, or a report on affected bytes/sectors.  </p>

<p>Is there anything available to save me the trouble of doing this myself?</p>
","<p>I found <a href=""http://www.cjmweb.net/vbindiff/"" rel=""nofollow noreferrer"">VBinDiff</a>.  I haven't used it, but it probably does what you want.  </p>
","98736"
"Whats the largest denormalized and normalized number?(64bit, IEE 754-1985)","5962","","<p>I am struggeling with floating point arithmetic, because I really want to understand this topic!</p>

<p>I know that the numbers can be represented in scientific notation.</p>

<p>So for both numbers the exponent should look like:</p>

<p><strong>Denormalized Number:</strong>
11....11 so (1+1/2 + 1/2^2 + ... + 1/2^52)*2^1023</p>

<p><strong>Normalized Number:</strong>
11....11 so (1+1/2 + 1/2^2 + ... + 1/2^52)*2^1024</p>

<p>However, I am not sure if this is correct?</p>

<p>I really would appreciate your answer!</p>

<p>PS.: On wikipedia the number is <a href=""http://en.wikipedia.org/wiki/IEEE_754-1985#Examples"" rel=""noreferrer"">given!</a> However, I do not know how they came up with that...</p>
","<p>As you know, the double-precision format looks like this:</p>

<p><img src=""https://i.stack.imgur.com/KnUkN.png"" alt=""enter image description here""></p>

<p>The key to understanding denormalized numbers is that they are not actually floating-point numbers but instead use a fixed-point micro-format using the representations that are not used in the 'normal' format.</p>

<p><em>Normal</em> floating-point numbers are of the form: <code>m*2^e</code> where <code>e</code> is found by subtracting the bias from the exponent field above, and <code>m</code> is a number between 1 and 2, where the bits after the 'binary' point are given by the fraction above. The 1 in front of the binary point is not stored, because it is known to be always 1. The exponent field has a value from 1 to 2046. The values 0 (all zeroes) and 2047 (all ones) are reserved for special uses.</p>

<p>All ones in the exponent field means we have either an infinity or a NaN (Not-a-Number).</p>

<p>All zeroes means we're dealing with <em>denormal</em> floating-point numbers. These are still of the same form, <code>m*2^e</code>, but the values of <code>m</code> and <code>e</code> are derived differently. <code>m</code> is now a number between 0 and 1, so there is a 0 in front of the binary point instead of a 1 for normal numbers. <code>e</code> always has the same value: -1022. So the exponent is a constant, which is why I called it a fixed-point format earlier.</p>

<p>So, the largest possible values for each are:</p>

<ul>
<li>Normal: (1+1/2 + 1/2^2 + ... + 1/2^52)*2^1023 = (2-2^-52)*2^1023 = 1.797...e+308</li>
<li>Denormal: (<em>0</em>+1/2 + 1/2^2 + ... + 1/2^52)*2^-1022 = (1-2^-52)*2^-1022 = 2.225...e-308</li>
</ul>
","20588022"
"Multiplying two integers given in binary","5960","","<p>I'm working on a program that will allow me to multiply/divide/add/subtract binary numbers together. In my program I'm making all integers be represented as vectors of digits.</p>

<p>I've managed to figure out how to do this with addition, however multiplication has got me stumbled and I was wondering if anyone could give me some advice on how to get the pseudo code as a guide for this program. </p>

<p>Thanks in advance!</p>

<p>EDIT: I'm trying to figure out how to create the algorithm for multiplication still to clear things up. Any help on how to figure this algorithm would be appreciated. I usually don't work with C++, so it takes me a bit longer to figure things out with it. </p>
","<p>You could also consider the Booth's algorithm if you'd like to multiply:
<a href=""http://en.wikipedia.org/wiki/Booth%27s_multiplication_algorithm"" rel=""nofollow"">Booth's multiplication algorithm</a></p>
","12341908"
"C# BinaryWrite over SSL","5959","","<p>I am trying to respond back to a client with a PDF stored in a MSSQL varbinary(MAX) field. The response works on my localhost and a test server over http connection, but does not work on the production server over https connection. I am using just a simple BinaryWrite (code below).</p>

<pre><code>    byte[] displayFile = DatabaseFiles.getPdfById(id);

    Response.ContentType = ""application/pdf"";
    Response.BinaryWrite(displayFile);
</code></pre>

<p>Nothing fancy here. Just grab the binary data, set the content type, and write back to client. Is there anything special that needs to be done in order to respond back over https in this way?</p>

<p><strong>Edit:</strong> By doesn't work, I mean that I get a blank document in the browser. Acrobat does not load in browser.</p>

<p><strong>Edit:</strong> I just noticed that this problem is only occurring in IE 7. The PDF loads correctly in Firefox 3. Our client uses IE 7 exclusively (better than IE 6 which I persuaded them upgrade from...lol).</p>

<p><strong>Edit:</strong> Tried to add the header ""content-disposition"" to make the file act as an attachment. Browser failed to loaded under SSL with the IE error ""Internet Explorer cannot download displayFile.aspx from ProductionServer.net."" (Code Below)</p>

<pre><code>    byte[] displayFile = DatabaseFiles.getPdfById(id);
    Response.Clear();
    Response.AddHeader(""content-disposition"", String.Format(""attachment;filename={0}"", fileName));
    Response.ContentType = ""application/pdf"";
    Response.BinaryWrite(displayFile);
</code></pre>

<p><strong>Edit:</strong> If the file is viewed over http on the Production Server, the browser displays the code for the PDF like it was being viewed through NotePad. (e.g. %PDF-1.4 %âãÏÓ 6 0 obj &lt;> endobj xref 6 33 ...etc)</p>
","<p>I just managed to get around this by replacing</p>

<pre><code>Response.Clear();
</code></pre>

<p>with</p>

<pre><code>Response.ClearContent();
Response.ClearHeaders();
</code></pre>

<p>so the whole thing looks like:</p>

<pre><code>byte[] downloadBytes = doc.GetData();
Response.ClearContent();
Response.ClearHeaders();

Response.Buffer = true;
Response.ContentType = ""application/pdf"";
Response.AddHeader(""Content-Length"", downloadBytes.Length.ToString());
Response.AddHeader(""Content-Disposition"", ""attachment; filename=myFile.pdf"");
Response.BinaryWrite(downloadBytes);
Response.Flush();
Response.End();
</code></pre>
","561882"
"Converting a boolean array into a hexadecimal number","5951","","<p>Is there an easy way to convert an array of boolean values into 8-bit hexadecimal equivlents? For example, if I have</p>

<pre><code> bool[] BoolArray = new bool[] { true,false,true,true,false,false,false,true };
</code></pre>

<p>If true values=1 and false values=0 then I'd like a method or function that would convert the above array to 0xB1 (10110001).</p>

<p>Does there exist such a function or method to do this? I am using C#, by the way.</p>
","<p>Yes, you can use the <code>BitArray</code> class. Something like this should do it:</p>

<pre><code>BitArray arr = new BitArray(BoolArray);
byte[] data = new byte[1];
arr.CopyTo(data, 0);
</code></pre>

<p>If by ""8-bit hexadecimal"" you mean the string representation, you can use the <code>BitConverter</code> class for that:</p>

<pre><code>string hex = BitConverter.ToString(data);
</code></pre>
","5533572"
"Convert float to its binary representation (using MemoryStream?)","5941","","<p>I'd like to convert a given <code>float</code> into its binary representation. I tried to write the float value into a <code>MemoryStream</code>, read this <code>MemoryStream</code> byte by byte and convert the bytes into their binary representation. But every attempt failed.</p>

<ul>
<li>""Can't read closed stream"" (but I only closed the writer)</li>
<li>For test purposes I simply wrote an integer (I think four bytes in size) and the length of the <code>MemoryStream</code> was 0, when I didn't flush the <code>StreamWriter</code>, and 1, when I did.</li>
</ul>

<p>I'm sure there is a better way to convert <code>float</code>s to binary, but I also wanted to learn a little bit about the <code>MemoryStream</code> class.</p>
","<p>You can use <a href=""http://msdn.microsoft.com/en-us/library/yhwsaf3w%28v=vs.110%29.aspx""><code>BitConverter.GetBytes(float)</code></a> or use a <code>BinaryWriter</code> wrapping a <code>MemoryStream</code> and use <a href=""http://msdn.microsoft.com/en-us/library/t7cxfc93%28v=vs.110%29.aspx""><code>BinaryWriter.Write(float)</code></a>. It's not clear exactly what you did with a <code>MemoryStream</code> before, but you <em>don't</em> want to use <code>StreamWriter</code> - that's for text.</p>
","21244330"
"Reading a .dat file as ""rb"" read binary","5941","","<p>I have a folder <code>\folder\</code> above the webroot that contains <code>.php</code>, <code>.inc</code>, <code>.dat</code> files</p>

<ul>
<li><p>the <code>.php</code> can access the <code>.inc</code> no problem</p></li>
<li><p>but when the <code>.inc</code> tries to access the <code>.dat</code> using <code>fopen('mydat.dat', ""rb"");</code> it gives an error that it can't find <code>mydat.dat</code> <strong>inside</strong> <code>\folder\myinc.inc</code> </p></li>
</ul>

<p>Of course it can't find it since <code>.inc</code> is a file not a folder. Why is php treating it as such?</p>

<p>Any ideas why php is trying to find the <code>.dat</code> inside the <code>.inc</code>?</p>

<p>or any other alternatives to <code>fopen($filename, ""rb"")</code>?</p>
","<p>After reading your comments, I think you expect fopen to use the include_path.</p>

<p>fopen() doesn't use the include_path by default(unlike include). It's an option. See the manual.
<a href=""http://www.php.net/manual/en/function.fopen.php"" rel=""nofollow noreferrer"">http://www.php.net/manual/en/function.fopen.php</a></p>
","2586839"
"Methods to hex edit binary files via Powershell","5919","","<p>Am trying to perform binary hex edit from the command line using only powershell.  Have had partial success performing a hex replace with this snip.  Problem springs up when 123456 occurs multiple times and the replacement was only supposed to occur at a specific location.</p>

<p>NOTE: The snip requires the <code>Convert-ByteArrayToHexString</code> and <code>Convert-HexStringToByteArray</code> functions found here. </p>

<p><a href=""http://www.sans.org/windows-security/2010/02/11/powershell-byte-array-hex-convert"" rel=""noreferrer"">http://www.sans.org/windows-security/2010/02/11/powershell-byte-array-hex-convert</a></p>

<pre><code>$readin = [System.IO.File]::ReadAllBytes(""C:\OldFile.exe"");
$hx = Convert-ByteArrayToHexString $readin -width 40 -delimiter """";
$hx = $hx -replace ""123456"",""FFFFFF"";
$hx = ""0x"" + $hx;
$writeout = Convert-HexStringToByteArray $hx;
set-content -value $writeout -encoding byte -path ""C:\NewFile.exe"";
</code></pre>

<p>How can we specify an offset position into powershell to replace this sketchy -replace command.</p>
","<p>You already have a byte array, so you could simply modify the bytes at any given offset.</p>

<pre><code>$bytes  = [System.IO.File]::ReadAllBytes(""C:\OldFile.exe"")
$offset = 23

$bytes[$offset]   = 0xFF
$bytes[$offset+1] = 0xFF
$bytes[$offset+2] = 0xFF

[System.IO.File]::WriteAllBytes(""C:\NewFile.exe"", $bytes)
</code></pre>
","20935550"
"How binary numbers are evaluated for true or false?","5895","","<p>if i write</p>

<pre><code>PORTA =0b00000001;
PORTB =0b00000000;
PORTC =0b11111111;
PORTD =0b10100110;
if(PORTA){
//will this block be true?if yes then why and how it is evaluated
}
if(PORTB){
//smae here,to check true or false.
}
if(PORTC){
//if true then why or false,why?
}
if(PORTD){
//same
}
</code></pre>

<p>if above statement are wrong then how to check the status of a port?</p>
","<p>Normally in C, any non-zero number will evaluate to true. If you want to check the value of a specific bit in your port, use the binary-AND operator <code>&amp;</code>. Note: Logical AND, <code>&amp;&amp;</code>, and binary AND, <code>&amp;</code>, are not the same thing.</p>

<p>In your question, only PORTB will evaluate to false.</p>
","17260904"
"What is the difference between plaintext and binary data?","5890","","<p>Many languages have functions which only process ""plaintext"", not binary. Does this mean that only characters within the ASCII range will be allowed? </p>

<p>Binary is just a series of bytes, isn't it similar to plaintext which is just a series of bytes interpreted as characters? So, can plaintext store the same data formats / protocols as binary?</p>
","<p>One thing it often means is that the language might feel free to interpret certian control characters, such as the values 10 or 13, as logical line terminators. In other words, an output operation might automagicly append these characters at the end, and an input operation might strip them from the input (and/or terminate reading there).</p>

<p>In contrast, language I/O operations that advertise working on ""binary"" data will usually include an input parameter for the length of data to operate on, since there is no other way (short of reading past end of file) to know when it is done.</p>
","1434929"
"methods to store binary files in SVN","5888","","<p>Are There different methods to store binary files in SVN? if so, what are they, and how I modify the storage options?</p>

<p>I read that there are 4 ways to store binary files in SVN:</p>

<ol>
<li>Compressed tar - import - export.</li>
<li>Tar - import - export.</li>
<li>import - export.</li>
<li>Efficient check-in.</li>
</ol>

<p>Which of those are the most useful for time efficiancy? and how do I set the SVN to use any of those methods?</p>

<p>Thanks,
Oded.</p>

<hr>

<p>I have many small-sized binary files and a few large-sized ones. All are changed frequently. I'm currently working on CVS and switching to SVN soon and I wanted to know about ways to store binaries. </p>

<p>I read Performance tuning Subversion (mentioned above) and found it useful but no examples made so I didn't exactly understand how to do each of the 4 ways he suggested. </p>

<p>My basic question is weather or not the defaults are good (and what are they?) My first consideration is time-efficient and then space. Thanks :)  </p>
","<p>You don't set Subversion to use any of those methods, you specify which method to use when putting files into the repository. And by ""method"", I don't mean any of the 4 you mention, but rather just ""import"" or ""commit"", and you'll have to keep telling Subversion about the method chosen each time you want to store a new revision of that file into the repository.</p>

<p>See <a href=""http://www.ibm.com/developerworks/java/library/j-svnbins.html?ca=dgr-lnxw16javapts"" rel=""nofollow noreferrer"">Performance tuning Subversion</a>.</p>

<p>As you can see from the description there, in order to use ""method 1"", compressing to tar and then use import, they have to themselves compress all the binary files into a .tar file, and then use the import command of Subversion to add the files into the repository.</p>

<p>Also note that caveat there, the import command stores files as new files, not as deltas to a previous revision, so it might be time-efficient, but not space-efficient, if few changes to a big file has been committed.</p>

<p>Subversion by itself only does commits and imports. A commit is a new revision to an existing file, stored as a sequence of deltas (or the first revision of a new file, which isn't), and an import is just a new file. Anything else you'll have to do yourself.</p>

<p>If the binary files are only changed now and then, this might be worth looking more into, but if they are changed regularly, I'd suggest just using Subversion as normal, with the commit command.</p>

<p>Also note that the typical advice when it comes to binary files is that you instead of the binary file store the source code to whatever it is that produces those binary files, if possible, and then re-runs the tools to reproduce the actual binary files. If the binary files are time or space-consuming to reproduce, only then do you also store the binary files in question.</p>

<p>Binary files have the problem of not really being good to compare, and thus if developer a and b both retrieves the latest version, and then developer a commits a new revision before developer b tries to do the same, some type of conflict will occur. Developer B might be left with no option but to try to figure out the changes by himself.</p>

<hr>

<p><strong>Edit</strong>: Let me emphasize what I mean by COMMIT and IMPORT.</p>

<p>The main difference is that COMMIT will, assuming you already have the file in the repository already, try to diff the file in your working copy against the previous repository version, and store only the changes. This will take time, and memory, in order to work out those differences, but will typically result in a small revision changeset in your repository. In other words, disk space on your Subversion server will be less impacted than with the IMPORT command.</p>

<p>IMPORT, on the other hand, will import the new file as though you just gave it a new file and said ""forget about the previous one, just store this file"", and thus no time or memory will be spent on working out the differences, but the resulting changeset in the repository will be larger. In other words, disk space on your Subversion server will be more impacted than with the COMMIT command, but IMPORT will typically run much faster.</p>

<p>Any other workflow you want to impose has to be done outside of Subversion. This includes the TAR command and compression options available in your operating system. If you want to go with ""method 1"", you, yourself, has to manually compress the file(s) you want to import into a single .tar file before you give it to Subversion. You can not ask Subversion to do any of that for you. You can of course make script files that automate the process somewhat, but still, it's not a Subversion problem.</p>

<p>I would do some serious tests with this to figure out if the gains are actually worth the extra work you will impose on your Subversion workflow.</p>
","1151961"
"character to binary conversion in C++ two characters at a time to get 16 bit binary form","5877","","<p>Hello i want to convert two characters at a time in a string to binary? how can i do that by applying simple arithmetic (that is by making my own function?)</p>

<p>For example: our string is = <code>hello world</code>: </p>

<p>Desired output (two characters at a time):</p>

<pre><code> he       // need binaryform of 0's and 1's (16 bits for 2 characters 'h' and 'e'
 ll       // similarly
 o(space) // single space also counts as a character with 8 zero bit in binary.
 wo
 rl
 d(space) // space equals a character again with 8 zero bits
</code></pre>

<p>how to go about with it. i dont want any ascii in between. directly from character to binary...is that possible? </p>
","<p>If you're looking for a way to <em>textually</em> represent the binary representation of characters, then here's a small example of how you can do it:</p>

<p>A small function that prints out the binary representation of <code>c</code> to <code>std::cout</code> (will only work for standard ASCII letters):</p>

<pre><code>void printBinary(char c) {
    for (int i = 7; i &gt;= 0; --i) {
        std::cout &lt;&lt; ((c &amp; (1 &lt;&lt; i))? '1' : '0');
    }
}
</code></pre>

<p>Use it like this (will only print out pairs of characters):</p>

<pre><code>std::string s = ""hello ""; // Some string.

for (int i = 0; i &lt; s.size(); i += 2) {
    printBinary(s[i]);
    std::cout &lt;&lt; "" - "";
    printBinary(s[i + 1]);
    std::cout &lt;&lt; "" - "";
}
</code></pre>

<p>Outputs:</p>

<pre><code>01101000 - 01100101 - 01101100 - 01101100 - 01101111 - 00100000 -
</code></pre>

<p><strong>Edit:</strong></p>

<p>Actually, using <code>std::bitset</code> this is all that is needed:</p>

<pre><code>std::string s = ""hello ""; // Some string.

for (int i = 0; i &lt; s.size(); i += 2) {
    std::cout &lt;&lt; std::bitset&lt;8&gt;(s[i]) &lt;&lt; "" "";
    std::cout &lt;&lt; std::bitset&lt;8&gt;(s[i + 1]) &lt;&lt; "" "";
}
</code></pre>

<p>Outputs:</p>

<pre><code>01101000 01100101 01101100 01101100 01101111 00100000
</code></pre>

<p>If you want to store the binary numbers of the character pairs in a <code>std::vector</code>, as mentioned in a comment, then this will do it:</p>

<pre><code>std::vector&lt;std::string&gt; bitvec;
std::string bits;
for (int i = 0; i &lt; s.size(); i += 2) {
    bits = std::bitset&lt;8&gt;(s[i]).to_string() + std::bitset&lt;8&gt;(s[i + 1]).to_string();
    bitvec.push_back(bits);
}
</code></pre>
","19844674"
"Any efficient way to read datas from large binary file?","5869","","<p>I need to handle tens of Gigabytes data in one binary file. Each record in the data file is variable length.</p>

<p>So the file is like:</p>

<pre><code>&lt;len1&gt;&lt;data1&gt;&lt;len2&gt;&lt;data2&gt;..........&lt;lenN&gt;&lt;dataN&gt;
</code></pre>

<p>The data contains integer, pointer, double value and so on. </p>

<p>I found python can not even handle this situation. There is no problem if I read the whole file in memory. It's fast. But it seems the <code>struct</code> package is not good at performance. It almost stuck on unpack the bytes.</p>

<p>Any help is appreciated.</p>

<p>Thanks.</p>
","<p><code>struct</code> and <code>array</code>, which other answers recommend, are fine for the details of the implementation, and might be all you need if your needs are always to sequentially read all of the file or a prefix of it. Other options include <a href=""http://docs.python.org/library/functions.html?highlight=buffer#buffer"" rel=""nofollow noreferrer"">buffer</a>, <a href=""http://docs.python.org/library/mmap.html"" rel=""nofollow noreferrer"">mmap</a>, even <a href=""http://docs.python.org/library/ctypes.html"" rel=""nofollow noreferrer"">ctypes</a>, depending on many details you don't mention regarding your exact needs. Maybe a little specialized Cython-coded helper can offer all the extra performance you need, if no suitable and accessible library (in C, C++, Fortran, ...) already exists that can be interfaced for the purpose of handling this humongous file as you need to.</p>

<p>But clearly there are peculiar issues here -- how can a data file contain <strong>pointers</strong>, for example, which are intrinsically a concept related to addressing <em>memory</em>? Are they maybe ""offsets"" instead, and, if so, how exactly are they based and coded? Are your needs at all more advanced than simply sequential reading (e.g., random access), and if so, can you do a first ""indexing"" pass to get all the offsets from start of file to start of record into a more usable, compact, handily-formatted auxiliary file? (<em>That</em> binary file of offsets would be a natural for <code>array</code> -- unless the offsets need to be longer than <code>array</code> supports on your machine!). What is the distribution of record lengths and compositions and number of records to make up the ""tens of gigabytes""?  Etc, etc.</p>

<p>You have a very large scale problem (and no doubt very large scale hardware to support it, since you mention that you can easily read all of the file into memory that means a 64bit box with many tens of GB of RAM -- wow!), so it's well worth the detailed care to optimize the handling thereof -- but we can't help much with such detailed care unless we know enough detail to do so!-).</p>
","1288382"
"Fastest way of reading and writing binary","5865","","<p>I'm currently optimizing an application, one of the operations that is done very often is reading and writing binary. I need 2 types of functions:</p>

<pre><code>Set(byte[] target, int index, int value);

int Get(byte[] source, int index);
</code></pre>

<p>These functions are needed for signed and unsigned short, int and long in big and little endian order.</p>

<p>Here are some examples i've made, but i need a evaluation about the advantages and disadvantages:</p>

<p>first method is using Marshal to write the value into the memory of the byte[], the second is using plain pointers to accomplish this and the third uses BitConverter and BlockCopy to do this</p>

<pre><code>unsafe void Set(byte[] target, int index, int value)
{
    fixed (byte* p = &amp;target[0])
    {
        Marshal.WriteInt32(new IntPtr(p), index, value);
    }
}

unsafe void Set(byte[] target, int index, int value)
{
    int* p = &amp;value;
    for (int i = 0; i &lt; 4; i++)
    {
        target[offset + i] = *((byte*)p + i);
    }
}

void Set(byte[] target, int index, int value)
{
    byte[] data = BitConverter.GetBytes(value);
    Buffer.BlockCopy(data, 0, target, index, data.Length);
}
</code></pre>

<p>And here are the Read/Get methods:</p>

<p>the first is using Marshal to read the value from the byte[], the second is using plain pointers and the third is using BitConverter again:</p>

<pre><code>unsafe int Get(byte[] source, int index)
{
    fixed (byte* p = &amp;source[0])
    {
        return Marshal.ReadInt32(new IntPtr(p), index);
    }
}

unsafe int Get(byte[] source, int index)
{
    fixed (byte* p = &amp;source[0])
    {
        return *(int*)(p + index);
    }
}

unsafe int Get(byte[] source, int index)
{
    return BitConverter.ToInt32(source, index);
}
</code></pre>

<p>boundary checking needs to be done but isn't part of my question yet...</p>

<p>I would be pleased if someone can tell what would be the best and fastest way in this case or give me some other solutions to work on. A generic solution would be preferable</p>

<hr>

<p>I Just did some performance testing, here are the results:</p>

<p>Set Marshal: 45 ms, Set Pointer: 48 ms, Set BitConverter: 71 ms
Get Marshal: 45 ms, Get Pointer: 26 ms, Get BitConverter: 30 ms</p>

<p>it seems that using pointers is the fast way, but i think Marshal and BitConverter do some internal checking... can someone verify this?</p>
","<p><strong>Important:</strong> if you only need the one endian, see the pointer magic by wj32 / dtb</p>

<hr>

<p>Personally, I would be writing directly to a <code>Stream</code> (perhaps with some buffering), and re-using a shared buffer that I can generally assume is clean. Then you can make some shortcuts and assume index 0/1/2/3.</p>

<p>Certainly don't use <code>BitConverter</code>, as that can't be used for both little/big-endian, which you require. I would also be inclined to just use bit-shifting rather than unsafe etc. It is actally the fastest, based on the following (so I'm glad that this is how I already do it my code <a href=""http://code.google.com/p/protobuf-net/source/browse/branches/v1/protobuf-net/SerializationContext.Write.cs#184"" rel=""nofollow noreferrer"">here</a>, look for <code>EncodeInt32Fixed</code>):</p>

<pre><code>Set1: 371ms
Set2: 171ms
Set3: 993ms
Set4: 91ms &lt;==== bit-shifting ;-p
</code></pre>

<p>code:</p>

<pre><code>using System;
using System.Diagnostics;
using System.Runtime.InteropServices;
static class Program
{
    static void Main()
    {
        const int LOOP = 10000000, INDEX = 100, VALUE = 512;
        byte[] buffer = new byte[1024];
        Stopwatch watch;

        watch = Stopwatch.StartNew();
        for (int i = 0; i &lt; LOOP; i++)
        {
            Set1(buffer, INDEX, VALUE);
        }
        watch.Stop();
        Console.WriteLine(""Set1: "" + watch.ElapsedMilliseconds + ""ms"");

        watch = Stopwatch.StartNew();
        for (int i = 0; i &lt; LOOP; i++)
        {
            Set2(buffer, INDEX, VALUE);
        }
        watch.Stop();
        Console.WriteLine(""Set2: "" + watch.ElapsedMilliseconds + ""ms"");

        watch = Stopwatch.StartNew();
        for (int i = 0; i &lt; LOOP; i++)
        {
            Set3(buffer, INDEX, VALUE);
        }
        watch.Stop();
        Console.WriteLine(""Set3: "" + watch.ElapsedMilliseconds + ""ms"");

        watch = Stopwatch.StartNew();
        for (int i = 0; i &lt; LOOP; i++)
        {
            Set4(buffer, INDEX, VALUE);
        }
        watch.Stop();
        Console.WriteLine(""Set4: "" + watch.ElapsedMilliseconds + ""ms"");

        Console.WriteLine(""done"");
        Console.ReadLine();
    }
    unsafe static void Set1(byte[] target, int index, int value)
    {
        fixed (byte* p = &amp;target[0])
        {
            Marshal.WriteInt32(new IntPtr(p), index, value);
        }
    }

    unsafe static void Set2(byte[] target, int index, int value)
    {
        int* p = &amp;value;
        for (int i = 0; i &lt; 4; i++)
        {
            target[index + i] = *((byte*)p + i);
        }
    }

    static void Set3(byte[] target, int index, int value)
    {
        byte[] data = BitConverter.GetBytes(value);
        Buffer.BlockCopy(data, 0, target, index, data.Length);
    }
    static void Set4(byte[] target, int index, int value)
    {
        target[index++] = (byte)value;
        target[index++] = (byte)(value &gt;&gt; 8);
        target[index++] = (byte)(value &gt;&gt; 16);
        target[index] = (byte)(value &gt;&gt; 24);
    }
}
</code></pre>
","2036774"
"MySQL SELECT against varbinary column","5857","","<p>This is a follow up to a previous issue I had posted <a href=""https://stackoverflow.com/questions/10486025/alternative-to-hashed-ssn-as-a-key-in-mysql"">here</a>.</p>

<p>I created a test table:</p>

<pre><code>CREATE TABLE `my_test_table` (
    `record_id` INT(11) UNSIGNED NOT NULL AUTO_INCREMENT,
    `col1` BINARY(20) NULL DEFAULT NULL,
    `col2` CHAR(40) NULL DEFAULT NULL,
    PRIMARY KEY (`record_id`)
)
</code></pre>

<p>Then ran the statement:</p>

<pre><code>INSERT INTO my_test_table (col1, col2) VALUES(sha1('test'), sha1('test') );
</code></pre>

<p>The data looks like...</p>

<p>1     0x6139346138666535636362313962613631633463    a94a8fe5ccb19ba61c4c0873d391e987982fbbd3</p>

<p>I'm not sure how I can select against the VARBINARY column. I can select against the CHAR like:</p>

<pre><code>SELECT * FROM my_test_table WHERE col2 = sha1('test');
</code></pre>

<p>I've tried</p>

<pre><code>SELECT * FROM my_test_table WHERE col1 = hex(sha1('test'));
</code></pre>

<p>And other variations but can't seem to find a solution (if there is one). I need to be able to check to see if a value already exists in the database before I allow a new insert. I was looking at VARBINARY and BINARY based on previous suggestions. Thanks.</p>
","<p>I have not read your previous question, but based on the source code in this question, you are only storing the first 20 characters of the sha1 hash in col1, so if you want to select it you should just look for the first 20 characters of the sha1 hash.</p>

<p>For example:</p>

<pre><code>SELECT * 
FROM my_test_table 
WHERE col1 = left(sha1('test'),20);
</code></pre>
","10606794"
"Define smallest possible datatype in c++ that can hold six values","5819","","<p>I want to define my own datatype that can hold a single one of six possible values in order to learn more about memory management in c++. In numbers, I want to be able to hold 0 through 5. Binary, It would suffice with three bits (101=5), although some (6 and 7) wont be used. The datatype should also consume as little memory as possible.</p>

<p>Im not sure on how to accomplish this. First, I tried an enum with defined values for all the fields. As far as I know, the values are in hex there, so one ""hexbit"" should allow me  to store 0 through 15. But comparing it to a char (with sizeof) it stated that its 4 times the size of a char, and a char holds 0 through 255 if Im not misstaken.</p>

<pre><code>#include &lt;iostream&gt;

enum Foo
{
    a = 0x0, 
    b = 0x1,
    c = 0x2,
    d = 0x3,
    e = 0x4,
    f = 0x5,
};

int main()
{
    Foo myfoo = a;
    char mychar = 'a';

    std::cout &lt;&lt; sizeof(myfoo); // prints 4
    std::cout &lt;&lt; sizeof(mychar); // prints 1

    return 1;
}
</code></pre>

<p>Ive clearly misunderstood something, but fail to see what, so I turn to SO. :)</p>

<p>Also, when writing this post I realised that I clearly lack some parts of the vocabulary. Ive made this post a community wiki, please edit it so I can learn the correct words for everything.</p>
","<p>A <code>char</code> is the smallest possible type.</p>

<p>If you happen to know that you need several such 3 bit values in a single place you get use a structure with bitfield syntax:</p>

<pre><code>struct foo {
  unsigned int val1:3;
  unsigned int val2:3;
};
</code></pre>

<p>and hence get 2 of them within one byte.  In theory you could pack 10 such fields into a 32-bit ""int"" value.</p>
","740245"
"What is the ""biggest"" negative number on a 4-bit machine?","5813","","<p>Or, what is the range of numbers that can be represented on a 4-bit machine using 2s-complement?</p>
","<p>That would be -8 to +7</p>
","2263663"
"Why HTTP protocol is designed in plain text way?","5805","","<p>Yesterday, I have a discussion with my colleagues about HTTP. It is asked why HTTP is designed in plain text way. Surely, it can be designed in binary way just like TCP protocol, using flags to represents different kinds of method(POST, GET) and variables (HTTP headers). So, why HTTP is designed in such way? Is there any technical or historical reasons?</p>
","<p>A <em>reason</em> that's both technical and historical is that text protocols are almost always preferred in the Unix world. </p>

<p>Well, this is not really a reason but a <em>pattern</em>. The rationale behind this is that text protocols allows you to <em>see</em> what's going on on the network by just dumping everything that goes through. You don't need a specialized analyzer as you need for TCP/IP. This makes it easier to debug and easier to maintain. </p>

<p>Not only HTTP, but many protocols are text based (e.g., FTP, POP3, SMTP, IMAP). </p>

<p>You might want to take a look at <em>The Art of Unix Programming</em> for a much more detailed explanation of this Unix thing. </p>
","393416"
"Python - how to a open remote file in binary read mode?","5799","","<p>I'm trying to use the mutagen module to read the metadata of an <code>mp3</code> file. The problem is that the module is expecting a local <code>mp3</code> file, but my <code>mp3</code> files are on a remote server.</p>

<p>This is the line in the module that raises an error when I send a remote mp3 URL as the first parameter.</p>

<pre><code>fp = file(f, ""rb"")
</code></pre>

<p>How can I alter this line of code so that it can open a remote file (e.g. <code>http://remotedomain.com/file.mp3</code>) in <code>rb mode</code>?</p>
","<pre><code>fp = urllib2.urlopen(""http://remotedomain.com/file.mp3"")
</code></pre>

<p>binary mode is default</p>
","6543751"
"efficiently converting hex to binary","5797","","<p>In the following program I'm converting a hex String ""0123456789ABCDEF"" into binary.</p>

<pre><code>public static void main(String[] args) {
    // TODO Auto-generated method stub
    String key = ""0123456789ABCDEF""; //hexadecimal key
    char[] keyCharArray = key.toCharArray();
    for (int i = 0; i &lt; key.length(); i++) {
        System.out.print(HexToBinary((keyCharArray[i]))+"","");
    }
}

public static String HexToBinary(char Hex) {
    int i = Integer.parseInt(Character.toString(Hex), 16);
    String Bin = Integer.toBinaryString(i);
    return Bin;
}
</code></pre>

<p>I'm getting the following output</p>

<pre><code>0,1,10,11,100,101,110,111,1000,1001,1010,1011,1100,1101,1110,1111,
</code></pre>

<p>but i require the output to be as follows</p>

<pre><code>0000,0001,0010,0011,0100,0101,0110,0111,1000,1001,1010,1011,1100,1101,1110,1111,
</code></pre>

<p>one way I found is appending <code>0x</code> in front of each hex character. 
as follows:</p>

<pre><code>0x0, 0x1, 0x2,............,0xE,0xF
</code></pre>

<p>another way is to manually check how many characters the output is short of 4, and append those many <code>0</code>'s to it. But I do not know how to implement the former in the above code. Is there any efficient method to do what im trying to do above?</p>
","<p>You can always do a static lookup:</p>

<pre><code>private static String[] staticLookup = new String[]
    {0000,0001,0010,0011,0100,0101,0110,0111,
     1000,1001,1010,1011,1100,1101,1110,1111};


public static String HexToBinary(char Hex) {
    return staticLookup[Integer.parseInt(Character.toString(Hex), 16)];
}
</code></pre>
","12546024"
"Convert NSString to ASCII Binary Equivilent (and then back to an NSString again)","5796","","<p>I'm having some problems with this.</p>

<p>I want to take an NSString and convert it to an integer array of only 0,1 values that would represent the binary equivalent of an ascii string.</p>

<p>So for example say I have the following</p>

<pre><code>NSString *string = @""A""; // Decimal value 65
</code></pre>

<p>I want to end up with the array</p>

<pre><code>int binary[8] = {0,1,0,0,0,0,0,1};
</code></pre>

<p>then given that I have the binary integer array, how do I go back to an NSString?</p>

<p>I know that NSString stores characters as multiple bytes but I only want to use ASCII.
I tried using,</p>

<pre><code>NSData *data = [myString dataUsingEncoding:NSASCIIStringEncoding allowLossyConversion:YES];
</code></pre>

<p>to convert my string to ascii, but I'm still having a lot of issues.  Can someone please help me out? :)</p>
","<p>*Note this code leaves out the extra requirement of storing the bits into an integer array in order to be easier to understand.</p>

<pre><code>// test embed
NSString *myString = @""A""; //65
for (int i=0; i&lt;[myString length]; i++) {
    int asciiCode = [myString characterAtIndex:i];
    unsigned char character = asciiCode; // this step could probably be combined with the last
    printf(""---&gt;%c&lt;---\n"", character);
    printf(""---&gt;%d&lt;---\n"", character);
    // for each bit in a byte extract the bit
    for (int j=0; j &lt; 8; j++) {
        int bit = (character &gt;&gt; j) &amp; 1;
        printf(""%d "", bit);
    }           
}


// test extraction
int extractedPayload[8] = {1,0,0,0,0,0,1,0}; // A (note the byte order is backwards from conventional ordering)
unsigned char retrievedByte = 0;

for (int i=0; i&lt;8; i++) {
    retrievedByte += extractedPayload[i] &lt;&lt; i;
}

printf(""***%c***\n"", retrievedByte);
printf(""***%d***\n"", retrievedByte);
</code></pre>

<p>Now I guess I've just got to filter out any non ascii characters from my NSString before I do these steps.</p>
","5493943"
"Code golf - hex to (raw) binary conversion","5754","","<p>In response to <a href=""https://stackoverflow.com/questions/794902/whats-the-opposite-of-od1"">this question</a> asking about hex to (raw) binary conversion, a comment suggested that it could be solved in ""5-10 lines of C, or any other language.""</p>

<p>I'm sure that for (some) scripting languages that could be achieved, and would like to see how.  Can we prove that comment true, for C, too?</p>

<p>NB: this doesn't mean hex to <em>ASCII</em> binary - specifically the output should be a raw octet stream corresponding to the input ASCII hex.  Also, the input parser should skip/ignore white space.</p>

<p><strong>edit</strong> (by Brian Campbell) May I propose the following rules, for consistency? Feel free to edit or delete these if you don't think these are helpful, but I think that since there has been some discussion of how certain cases should work, some clarification would be helpful.</p>

<ol>
<li>The program must read from stdin and write to stdout (we could also allow reading from and writing to files passed in on the command line, but I can't imagine that would be shorter in any language than stdin and stdout)</li>
<li>The program must use only packages included with your base, standard language distribution. In the case of C/C++, this means their respective standard libraries, and not POSIX.</li>
<li>The program must compile or run without any special options passed to the compiler or interpreter (so, 'gcc myprog.c' or 'python myprog.py' or 'ruby myprog.rb' are OK, while 'ruby -rscanf myprog.rb' is not allowed; requiring/importing modules counts against your character count).</li>
<li>The program should read integer bytes represented by pairs of adjacent hexadecimal digits (upper, lower, or mixed case), optionally separated by whitespace, and write the corresponding bytes to output. Each pair of hexadecimal digits is written with most significant nibble first.</li>
<li>The behavior of the program on invalid input (characters besides <code>[a-fA-F \t\r\n]</code>, spaces separating the two characters in an individual byte, an odd number of hex digits in the input) is undefined; any behavior (other than actively damaging the user's computer or something) on bad input is acceptable (throwing an error, stopping output, ignoring bad characters, treating a single character as the value of one byte, are all OK)</li>
<li>The program may write no additional bytes to output.</li>
<li>Code is scored by fewest total bytes in the source file. (Or, if we wanted to be more true to the original challenge, the score would be based on lowest number of lines of code; I would impose an 80 character limit per line in that case, since otherwise you'd get a bunch of ties for 1 line).</li>
</ol>
","<p><strong>edit</strong> Checkers has reduced my C solution to <a href=""https://stackoverflow.com/questions/795027/code-golf-hex-to-raw-binary-conversion/795944#795944"">46 bytes</a>, which was then reduced to 44 bytes thanks to a tip from BillyONeal plus a bugfix on my part (no more infinite loop on bad input, now it just terminates the loop). Please give credit to Checkers for reducing this from 77 to 46 bytes:</p>

<pre><code>main(i){while(scanf(""%2x"",&amp;i)&gt;0)putchar(i);}
</code></pre>

<p>And I have a much better Ruby solution than my last, in <del>42</del> <em>38</em> bytes (thanks to Joshua Swank for the regexp suggestion):</p>

<pre><code>STDIN.read.scan(/\S\S/){|x|putc x.hex}
</code></pre>

<p><strong>original solutions</strong></p>

<p>C, in 77 bytes, or two lines of code (would be 1 if you could put the <code>#include</code> on the same line). Note that this has an infinite loop on bad input; the 44 byte solution with the help of Checkers and BillyONeal fixes the bug, and simply stops on bad input.</p>

<pre><code>#include &lt;stdio.h&gt;
int main(){char c;while(scanf(""%2x"",&amp;c)!=EOF)putchar(c);}
</code></pre>

<p>It's even just 6 lines if you format it normally:</p>

<pre><code>#include &lt;stdio.h&gt;
int main() {
  char c;
  while (scanf(""%2x"",&amp;c) != EOF)
    putchar(c);
}
</code></pre>

<p>Ruby, 79 bytes (I'm sure this can be improved): </p>

<pre><code>STDOUT.write STDIN.read.scan(/[^\s]\s*[^\s]\s*/).map{|x|x.to_i(16)}.pack(""c*"")
</code></pre>

<p>These both take input from STDIN and write to STDOUT</p>
","795452"
"Stream binary file from MySQL to download with PHP","5717","","<p>I have Excel spreadsheets stored in a MySQL table longblob field. I need to retrieve this data and then stream it to the user as a downloadable file, preferably without writing it to disk first.</p>

<p>Possible?</p>

<p>Edit - Eh, just figured it out... Posted in answer below.</p>
","<pre><code>function getfile($blockid)
{
    global $msa_db;
    $sql = ""select filename, filedata from blocks where blockid = '$blockid'"";
    $query = mysql_query($sql, $msa_db);
    $result['filename'] = mysql_result($query,0,0);
    $result['filedata'] = mysql_result($query,0,1);
    return $result;

}

function download($fileinfo)
{
    $file = base64_decode($fileinfo['filedata']);
    header(""Cache-Control: no-cache private"");
    header(""Content-Description: File Transfer"");
    header('Content-disposition: attachment; filename='.$fileinfo['filename']);
    header(""Content-Type: application/vnd.ms-excel"");
    header(""Content-Transfer-Encoding: binary"");
    header('Content-Length: '. strlen($file));
    echo $file;
    exit;
}

$fileinfo = getfile($blockid);

download($fileinfo);
</code></pre>
","1563102"
"Erlang howto make a list from this binary <<""a,b,c"">>","5708","","<p>I have a binary &lt;&lt;""a,b,c"">> and I would like to extract the information from this binary. </p>

<p>So I would like to have something like A=a, B=b and so on. 
I need a general approach on this because the binary string always changes.
So it could be &lt;&lt;""aaa"",""bbb"",""ccc"">>...</p>

<p>I tried to generate a list </p>

<p>erlang:binary_to_list(&lt;&lt;""a"",""b"",""c"">>) </p>

<p>but I get string as a result.</p>

<p>""abc""</p>

<p>Thank you.</p>
","<p>You did use the right method.</p>

<blockquote>
  <p><a href=""http://erldocs.com/R14B/erts/erlang.html?i=3&amp;search=binary_to#binary_to_list/1"">binary_to_list(Binary) -> [char()]</a></p>
  
  <p>Returns a list of integers which correspond to the bytes of Binary.</p>
</blockquote>

<p>There is no string type in Erlang: <a href=""http://www.erlang.org/doc/reference_manual/data_types.html#id63119"">http://www.erlang.org/doc/reference_manual/data_types.html#id63119</a>. The console just displays the lists in string representation as a courtesy, if all elements are in printable ASCII range.</p>

<p>You should read Erlang's <a href=""http://www.erlang.org/doc/reference_manual/expressions.html#bit_syntax"">""Bit Syntax Expressions""</a> documentation to understand how to work on binaries. </p>

<p><strong>Do not convert the whole binary into a list if you don't need it in list representation!</strong></p>

<p>To extract the first three bytes you could use</p>

<pre><code>&lt;&lt;A, B, C, Rest/binary&gt;&gt; = &lt;&lt;""aaa"",""bbb"",""ccc""&gt;&gt;.
</code></pre>

<p>If you want to iterate over the binary data, you can use binary comprehension.</p>

<pre><code>&lt;&lt; &lt;&lt;(F(X))&gt;&gt; || &lt;&lt;X&gt;&gt; &lt;= &lt;&lt;""aaa"",""bbb"",""ccc""&gt;&gt; &gt;&gt;.
</code></pre>

<p>Pattern matching is possible, too:</p>

<pre><code>test(&lt;&lt;A, Tail/binary&gt;&gt;, Accu) -&gt; test(Tail, Accu+A);
test(_, Accu) -&gt; Accu.

882 = test(&lt;&lt;""aaa"",""bbb"",""ccc""&gt;&gt;, 0).
</code></pre>

<p>Even for reading one UTF-8 character at once. So to <a href=""http://erldocs.com/R14B/stdlib/unicode.html?i=3&amp;search=unicode%3a#characters_to_binary/3"">convert a binary UTF-8 string</a> into Erlang's ""list of codepoints"" format, you could use:</p>

<pre><code>test(&lt;&lt;A/utf8, Tail/binary&gt;&gt;, Accu) -&gt; test(Tail, [A|Accu]);
test(_, Accu) -&gt; lists:reverse(Accu).

[97,97,97,600,99,99,99] = test(&lt;&lt;""aaa"", 16#0258/utf8, ""ccc""&gt;&gt;, """").
</code></pre>

<p>(Note that <code>`&lt;&lt;""aaa"",""bbb"",""ccc""&gt;&gt; = &lt;&lt;""aaabbbccc""&gt;&gt;</code>. Don't actually use the last code snipped but the linked method.)</p>
","6142481"
"How does a computer store decimal point values?","5705","","<p>I have a few questions:</p>

<ol>
<li><p>Computers only use 1s and 0s to represent numbers. Then how does it represent a decimal point like 5.512.</p></li>
<li><p>The computer doesn't know whether we are entering an ASCII value or just a random binary for it to process. In earlier days, people used to program using hex and binary. How would they achieve in outputting a character on the screen. Apart from that how does the computer understand that 65(decimal) is not a number but a capital A?</p></li>
</ol>
","<p>For your first point, see the <a href=""http://en.wikipedia.org/wiki/IEEE_754-1985"" rel=""nofollow"">IEEE754-1985 Wikipedia page</a> for one approach (probably the most common).</p>

<p>For your second point, you need to realise that there is a disconnect between a value and the representation of that value. A value can be stored in one way and interpreted in a host of different ways.</p>

<p>For example, the octets <code>0x30, 0x31</code> may be represented as the value <code>0x3031</code> in big-endian 16-bit values, <code>0x3130</code> in little-endian or the character sequence <code>'0', '1'</code> in ASCII. It would be something else again if it was treated as EBCDIC or fixed point values.</p>

<p>It all comes down to how you <em>interpret</em> the data.</p>
","14972134"
"How exactly do executables work?","5657","","<p>I know that executables contain instructions, but what exactly are these instructions? If I want to call the <code>MessageBox</code> API function for example, what does the instruction look like?</p>

<p>Thanks.</p>
","<p><a href=""http://en.wikipedia.org/wiki/Executables"" rel=""noreferrer"">Executables</a> are binary files that are understood by the operating system. The executable will contain sections which have data in them. Windows uses the <a href=""http://en.wikipedia.org/wiki/PE_format"" rel=""noreferrer"">PE format</a>. The PE Format has a section which has <a href=""http://en.wikipedia.org/wiki/Machine_Code"" rel=""noreferrer"">machine</a> instructions. These instructions are just numbers which are ordered in a sequence and is understood by the CPU. </p>

<p>A function call to MessageBox(), would be a sequence of instructions which will </p>

<p>1) have the address of the function which is in a DLL. This address is put in by the compiler</p>

<p>2) instructions to ""push"" the parameters onto a stack</p>

<p>3) The actual function call</p>

<p>4) some sort of cleanup (depends on the calling convention).</p>

<p>Its important to remember that EXE files are just specially formatted files. I dont have a disassembly for you, but you can try compiling your code, then open your EXE in visual studio to see the disassembly.</p>
","1616783"
"How to convert binary private key file in to pem format which is acceptable by openssl","5656","","<p>I have a private key file which is in binary format. I need to convert it into <code>.pem</code> format. I am able to convert using base64 but <code>openssl</code> is not accepting this file. Is there any other way to convert binary to <code>.pem</code> which is acceptable by <code>openssl</code>. </p>
","<p>Chances are you have a DER encoded key. To convert it you can (likely) do this</p>

<pre><code>openssl rsa -inform der -in &lt;yourfile&gt; -outform pem -out output.pem
</code></pre>

<p>Please note that this will only work for unencrypted RSA private keys. If you have a DSA or EC (or PKCS8 formatted) key you'll need to change the command a bit, but you did not provide enough detail for me to narrow it down for you.</p>

<p>(There are also many other private key formats such as PVK, so if this still doesn't work please provide some more information)</p>
","20723097"
"How can I read and write binary files?","5629","","<p>I don't have access to a PC for the next couple of days but I can't get this problem off my mind. I am just playing around with compression algorithms, created one of my own for audio and I am stuck at the output to file step. So here are my questions, hopefully I can figure out an answer before I am back or else this will eat my mind.</p>

<p>1) If I have a numpy X array with some integers (say int16), if I open a file object and do file.write(X) what will the file output be like? Numbers? Or ASCII of numbers? Or binary?</p>

<p>2) Depending on the above answer, how do I read this file into a numpy array X?</p>

<p>Essentially my compression does some wavelet and fft transforms, does some filtering here and there and returns an array with some numbers, I know the format of this array and I already achieve a high % of compression here, the next step is to first dump this array into a binary file. Once I achieve this my next goal is to implement some kind of entropy coding of the file/vector.</p>

<p>Any input appreciated.</p>
","<p>1) Writing:</p>



<pre><code>In [1]: f = open('ints','wb')
In [2]: x = numpy.int16(array([1,2,3]))
Out[2]: array([1, 2, 3], dtype=int16)
In [3]: f.write(x)
In [4]: f.close()
</code></pre>

<p>2) Reading:</p>

<pre><code>In [5]: f = open('ints','wb')
In [6]: x = f.read()
In [7]: x
Out[7]: '\x01\x00\x02\x00\x03\x00'
In [8]: numpy.fromstring(x, dtype=np.uint16, count=3)
Out[8]: array([1, 2, 3], dtype=uint16)
</code></pre>

<p><strong>Update:</strong></p>

<p>As J.F.Sebastian suggested there are better ways to do this, like using:</p>

<ul>
<li><a href=""http://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html"" rel=""nofollow"">numpy.save</a></li>
<li><a href=""http://docs.scipy.org/doc/numpy/reference/generated/numpy.load.html"" rel=""nofollow"">numpy.load</a></li>
</ul>

<p>or as Janne Karila suggested using:</p>

<ul>
<li><a href=""http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.tofile.html"" rel=""nofollow"">numpy.ndarray.tofile</a></li>
<li><a href=""http://docs.scipy.org/doc/numpy/reference/generated/numpy.fromfile.html"" rel=""nofollow"">numpy.fromfile</a></li>
</ul>
","13220992"
"How does Float.intBitsToFloat work?","5608","","<p>Can anyone explain me or link some helpful resource in order to understand the algorithm behind the Java method <a href=""http://download.oracle.com/javase/6/docs/api/java/lang/Float.html#intBitsToFloat%28int%29"" rel=""nofollow""><code>Float.intBitsToFloat(int)</code></a>?</p>
","<p>Java uses IEEE 754 floating point.  <code>Float.intBitsToFloat(int)</code> works by interpreting the 32 bits of its argument as if they specified a 32-bit float in the format <a href=""http://en.wikipedia.org/wiki/Single_precision_floating-point_format#IEEE_754_single_precision_binary_floating-point_format:_binary32"" rel=""noreferrer"">described here</a>.  </p>

<p><code>Double.longBitsToDouble(long)</code> works similarly for 64-bit floats <a href=""http://en.wikipedia.org/wiki/Double_precision_floating-point_format#Double_precision_binary_floating-point_format"" rel=""noreferrer"">as described here</a>.</p>

<p>In C you might achieve the same effect like so:</p>

<pre><code>#include &lt;stdint.h&gt;

union int_float_bits {
    int32_t int_bits;
    float float_bits;
};

float intBitsToFloat(int32_t x)
{
    union int_float_bits bits;
    bits.int_bits = x;
    return bits.float_bits;
}
</code></pre>

<p>(Although technically this would be undefined behavior, in fact it virtually always works as expected.)</p>
","5645512"
"Android: Convert Grayscale to Binary Image","5603","","<p>i hava done with get grayscale value, but i don't know how to use function to convert the grayscale to be binary image. Please help me, here my function code:</p>

<pre><code>public Bitmap toBinary(Bitmap bmpOriginal) {
    int width, height, threshold;
    height = bmpOriginal.getHeight();
    width = bmpOriginal.getWidth();
    threshold = 127;
    final Bitmap bmpBinary = null;

    for(int x = 0; x &lt; width; ++x) {
        for(int y = 0; y &lt; height; ++y) {
            // get one pixel color
            int pixel = bmpOriginal.getPixel(x, y);

            //get grayscale value
            int gray = (int)(pixel &amp; 0xFF);

            //get binary value
            if(gray &lt; threshold){
                bmpBinary.setPixel(x, y, 0);
            } else{
                bmpBinary.setPixel(x, y, 255);
            }

        }
    }
    return bmpBinary;
}
</code></pre>

<p>here my full code:</p>

<pre><code>public class MainActivity extends Activity {

    ImageView img;
    Button btn;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);

        //convert imageview to bitmap
        img =(ImageView) findViewById(R.id.imageView1);
        BitmapDrawable drawable = (BitmapDrawable) img.getDrawable();
        final Bitmap imgbitmap = drawable.getBitmap();


        btn.setOnClickListener(new View.OnClickListener() {
            public void onClick(View v) {
                //convert bitmap to grayscale 
                Bitmap imgnew;
                imgnew = toGrayscale(imgbitmap);    
                //convert to binary
imgnew = toBinary(imgnew);

                //convert bitmap to imageview 
                ImageView imgbit;
                imgbit = (ImageView) findViewById(R.id.imageView2);
                imgbit.setImageBitmap(imgnew);
            }
        });

    }

    public Bitmap toGrayscale(Bitmap bmpOriginal){        
        int width, height;
        height = bmpOriginal.getHeight();
        width = bmpOriginal.getWidth();    

        Bitmap bmpGrayscale = Bitmap.createBitmap(width, height, Bitmap.Config.RGB_565);
        Canvas c = new Canvas(bmpGrayscale);
        Paint paint = new Paint();
        ColorMatrix cm = new ColorMatrix();
        cm.setSaturation(0);
        ColorMatrixColorFilter f = new ColorMatrixColorFilter(cm);
        paint.setColorFilter(f);
        c.drawBitmap(bmpOriginal, 0, 0, paint);
        return bmpGrayscale;
    }


public Bitmap toBinary(Bitmap bmpOriginal) {
    int width, height, threshold;
    height = bmpOriginal.getHeight();
    width = bmpOriginal.getWidth();
    threshold = 127;
    final Bitmap bmpBinary = null;

    for(int x = 0; x &lt; width; ++x) {
        for(int y = 0; y &lt; height; ++y) {
            // get one pixel color
            int pixel = bmpOriginal.getPixel(x, y);

            //get grayscale value
            int gray = (int)(pixel &amp; 0xFF);

            //get binary value
            if(gray &lt; threshold){
                bmpBinary.setPixel(x, y, 0);
            } else{
                bmpBinary.setPixel(x, y, 255);
            }

        }
    }
    return bmpBinary;
}

}
</code></pre>
","<p>First, you get a NullReferenceException because bmpBinary is NULL. <br>
Second, to get one Color chanel you can use int red = Color.red(pixel);<br>
Third, to set a pixel white use bmpBinary.setPixel(x, y, 0xFFFFFFFF);<br><br></p>

<p>I modified your code a bit:</p>

<pre><code>public Bitmap toBinary(Bitmap bmpOriginal) {
    int width, height, threshold;
    height = bmpOriginal.getHeight();
    width = bmpOriginal.getWidth();
    threshold = 127;
    Bitmap bmpBinary = Bitmap.createBitmap(bmpOriginal);

    for(int x = 0; x &lt; width; ++x) {
        for(int y = 0; y &lt; height; ++y) {
            // get one pixel color
            int pixel = bmpOriginal.getPixel(x, y);
            int red = Color.red(pixel);

            //get binary value
            if(red &lt; threshold){
                bmpBinary.setPixel(x, y, 0xFF000000);
            } else{
                bmpBinary.setPixel(x, y, 0xFFFFFFFF);
            }

        }
    }
    return bmpBinary;
}
</code></pre>

<p>An even better way is not to use just the value of one color chanel but a weighted average of red green and blue for example:<br></p>

<pre><code>int gray = (int)(red * 0.3 + green * 0.59 + blue * 0.11);
</code></pre>
","20300082"
"Read each line from a file and split the line into a string and an array in C","5598","","<p><strong>Homework</strong> - I have an assignment to write a program that will read a file. The file looks like this:</p>

<pre><code>B 34 55 66 456 789 78 59 2 220 366 984 132 2000 65 744 566 377 905 5000
I 9000
I 389
Dm
DM
</code></pre>

<p>Where <code>B</code> is build a binary heap from an array of numbers(the numbers following the B.
I is insert a number into the array/heap
Dm is delete minimum and DM is delete maximum.</p>

<p>I have written the code for the heap, and can fill an array with <code>random numbers</code>. My problem is reading that <code>first line</code> and parsing it into a <code>string B</code> and an <code>array</code>.</p>

<p>I have tried using the following code but obviously it does not work.</p>

<pre><code>char line[8];
char com[1];
int array[MAX] //MAX is pre-defined as 100

FILE* fp = fopen( ""input_1.txt"", ""r"" );
if( fp )
{
    while( fgets ( line, sizeof(line), fp ) != NULL  )
    {
        sscanf(line, ""%s"" ""%d"", &amp;com, &amp;array );
        ... //Following this, I will have a nested if that will take
        each string and run the appropriate function.

        if ( strcmp( com, ""B"" ) == 0 )
        {
            fill_array( array, MAX );
            print_array( array, MAX );
        }        
</code></pre>

<p>I have read for about 6 hours over a total of 3 days and can't find a solution to my problem. Any help would be great.</p>
","<p>First of all, the <code>line</code> array should probably have a size greater than 8, probably something like <code>char line[256]</code>. The same goes for the <code>com</code> array, which should have at least 3 characters.</p>

<pre><code>char line[256];
char com[3];
</code></pre>

<p>You'll have to read the file line by line using <code>fgets(line, sizeof(line), fp)</code> and the use <code>strtok()</code> to separate the command from the command arguments.</p>

<pre><code>char separators[] = "" "";
fgets(line, sizeof(line), fp);

char * p = strtok(line, separators);    // p will be a pointer to the command string
strncpy(&amp;com, p, sizeof(com));    // copy the command string in com


// If the command is B, read an array
if (strcmp(com, ""B"") == 0) {
    p = strtok(NULL, separators);

    while (p != NULL) {
        int value_to_add_to_your_array = atoi(p);
        // ... add code to add the value to your array
        p = strtok(NULL, separators);
    }

    // ... call the function that creates your heap
}

// ... add code to handle the other commands
</code></pre>

<p>The idea is to read the file line by line, then for each line to first read the command and based on its value determine in which way you should read the rest of the line. </p>

<p>In the code above I considered the <code>B</code> command, for which I added code to read an array.</p>
","13653006"
"Is there a C# function that formats a 64bit ""Unsigned"" value to its equivalent binary value?","5593","","<p>To format/display a number to its equivalent binary form (in C#), I have always simply called:</p>

<pre><code>Convert.ToString(myNumber, 2);
</code></pre>

<p>Today, I just realized that the .ToString() overload that I have been calling does not support values that are greater than 9223372036854775807. Note the .ToString() overload's signature is: <code>.ToString(long, int)</code>. Where ""long"" is a 64bit <strong>signed</strong> value which max's out at 9223372036854775807.</p>

<p>To put it another way, using C#, when I run this:</p>

<pre><code>Convert.ToString(9223372036854775808,2);
</code></pre>

<p>It's no surprise (due to the signature) that I receive this exception message: </p>

<blockquote>
  <p>The best overloaded method match for 'System.Convert.ToString(object,
  System.IFormatProvider)' has some invalid arguments
    - Argument 2: cannot convert from 'int' to 'System.IFormatProvider'</p>
</blockquote>

<p>My question: Is there a .NET function that allows us to convert values greater than 9223372036854775807 to their equivalent binary format?</p>
","<p>You can call it unsigned or signed, but its the same if you look at it bitwise!</p>

<p>So if you do this:</p>

<pre><code>Convert.ToString((long)myNumber,2);
</code></pre>

<p>you would get the same bits as you would if there were ulong implementation of Convert.ToString(), and thats why there is none... ;)</p>

<p>Therefore, <code>((long)-1)</code> and <code>((ulong)-1)</code> looks the same in memory.</p>
","6986103"
"Read/Write string binary data - BinaryReader","5588","","<p>I wrote the below method to archive files into one file using binary mode:</p>

<pre><code>        // Compile archive
        public void CompileArchive(string FilePath, ListView FilesList, Label Status, ProgressBar Progress)
        {
            FileTemplate TempFile = new FileTemplate();
            if (FilesList.Items.Count &gt; 0)
            {
                BinaryWriter Writer = new BinaryWriter(File.Open(FilePath, FileMode.Create), System.Text.Encoding.ASCII);
                Progress.Maximum = FilesList.Items.Count - 1;
                Writer.Write((long)FilesList.Items.Count);
                for (int i = 0; i &lt;= FilesList.Items.Count - 1; i++)
                {
                    TempFile.Name = FilesList.Items[i].SubItems[1].Text;
                    TempFile.Path = ""%ARCHIVE%"";
                    TempFile.Data = this.ReadFileData(FilesList.Items[i].SubItems[2].Text + ""\\"" + TempFile.Name);
                    Writer.Write(TempFile.Name);
                    Writer.Write(TempFile.Path);
                    Writer.Write(TempFile.Data);
                    Status.Text = ""Status: Writing '"" + TempFile.Name + ""'"";
                    Progress.Value = i;
                }
                Writer.Close();
                Status.Text = ""Status: None"";
                Progress.Value = 0;
            }
        }
</code></pre>

<p>I read files data using ReadFileData which is in the above method method which return a string of data. (StreamReader) Next up I extract my archive. Everything is done great but the data which will being stored in the extraction method doesn't give me a right data so the extracted files have not right data to show their original functionality.</p>

<p>Extract method:</p>

<pre><code>    // Extract archive
    public void ExtractArchive(string ArchivePath, string ExtractPath, ListView FilesList, Label Status, ProgressBar Progress)
    {
        FileTemplate TempFile = new FileTemplate();
        BinaryReader Reader = new BinaryReader(File.Open(ArchivePath, FileMode.Open), System.Text.Encoding.ASCII);
        long Count = Reader.ReadInt64();
        if (Count &gt; 0)
        {
            Progress.Maximum = (int)Count - 1;
            FilesList.Items.Clear();
            for (int i = 0; i &lt;= Count - 1; i++)
            {
                TempFile.Name = Reader.ReadString();
                TempFile.Path = Reader.ReadString();
                TempFile.Data = Reader.ReadString();
                Status.Text = ""Status: Reading '"" + TempFile.Name + ""'"";
                Progress.Value = i;
                if (!Directory.Exists(ExtractPath))
                {
                    Directory.CreateDirectory(ExtractPath);
                }
                BinaryWriter Writer = new BinaryWriter(File.Open(ExtractPath + ""\\"" + TempFile.Name, FileMode.Create), System.Text.Encoding.ASCII);
                Writer.Write(TempFile.Data);
                Writer.Close();
                string[] ItemArr = new string[] { i.ToString(), TempFile.Name, TempFile.Path };
                ListViewItem ListItem = new ListViewItem(ItemArr);
                FilesList.Items.Add(ListItem);
            }
            Reader.Close();
            Status.Text = ""Status: None"";
            Progress.Value = 0;
        }
    }
</code></pre>

<p>The structure:</p>

<pre><code>struct FileTemplate
        {
            public string Name, Path, Data;
        }
</code></pre>

<p>Thanks.</p>
","<p>Consider using byte arrays for write and safe the data.</p>

<p>Byte array( write )</p>

<pre><code>Byte[] bytes = File.ReadAllBytes(..);
// Write it into your stream
myStream.Write(bytes.Count);
myStream.Write(bytes, 0, bytes.Count);
</code></pre>

<p>Byte array ( read )</p>

<pre><code>Int32 byteCount = myStream.ReadInt32();
Byte[] bytes = new Byte[byteCount];
myStream.Read(bytes, 0, byteCount);
</code></pre>
","8196487"
"Truncate or resize a file in order to modify its end","5588","","<p>I have a <code>FILE* file</code> that holds some binary data. Let's say that this data are a list of double and that the last entry is a string that describes what are those double. I want to modify this string (the new string might be shorter). So first i delete the old string. I need to find the starting point of the string :</p>

<pre><code>fseek(file,-size(sring.size()),SEEK_END);
</code></pre>

<p>and then what should i do ? i found <a href=""https://stackoverflow.com/questions/4005199/delete-end-of-file"">Delete End of File</a> link but i don't know which one to use... Once the file is re-sized, can i simply write my new string using <code>fwrite</code> ?</p>
","<p>Neither <code>FILE*</code> nor iostream support truncation.  If you want to
edit a file so that the new file is shorter than the old, you
have two solutions: </p>

<ul>
<li><p>The usual solution is to copy the original file into a new
file, making any changes as you go.  When finished, close the
new file, verify that there are no errors (an important point),
then delete the original file and rename to new file to have the
original name.  This may cause problems on Unix systems if
there were hard links to the original file.  (Typically, this
isn't an issue, since everyone uses soft links now.  If it is,
you should <code>stat</code> the original, and if the <code>st_nlink</code> field is
greater than 1, copy the new file onto the original, and then
delete the new file.) On the other hand, it is the most generic
option; it works for all types of modifications, anywhere in the
file.</p></li>
<li><p>There are usually system specific functions at the lower level
to truncate a file.  Under Unix, this is <code>ftruncate</code>.  But
you'll need to find the byte count where you want to truncate
first; <code>ftruncate</code> requires an open file, but it won't truncate
at the current position in the file.  So you'll have to 1) find
the start of this last line in the file, 2) seek to it, 3) write
the new value, 4) call <code>ftell</code> (or <code>ftello</code>, if the length can
be too large to fit on a <code>long</code>) to find the new end position.
At this point, you have the problem of synchronizing your
<code>FILE*</code> with the lower level; personally, I'd <code>fclose</code> the file,
then reopen it with <code>open</code>, and do the <code>ftruncate</code> on the file
descripter from this open.  (In fact, personally, I'd do the
entire job using <code>open</code>, <code>read</code>, <code>lseek</code>, <code>write</code>, <code>ftruncate</code>
and <code>close</code>.  And maybe <code>stat</code> to find out the file length up
front.  If you don't have to translate the doubles,
there's really nothing that <code>FILE*</code> adds.</p></li>
</ul>

<p>As a general rule, I'd go with the first solution, and only try
the second if it turns out to be too slow.  (If the file
contains a couple of billion doubles, for example, copying them
will take some time.)</p>
","15154682"
"Binary image in Matlab","5586","","<p>How can I know if an image read with <code>imread</code> is binary in MATLAB</p>

<p>I did this :</p>

<pre><code>Img = imread(IMGsrc);

T = Img== 1 | Img == 0;

If min(min(T)) == ??????

    imshow(T);

end
</code></pre>

<p>????? = ??????</p>
","<p>There are two ways you can test for binary images.</p>

<p>The simplest one is to test whether the image is a logical array (a logical array is returned by functions in the image processing toolbox that return binary image)</p>

<pre><code>isBinaryImage = islogical(img);
</code></pre>

<p>Alternatively, you check whether all pixels are either 1 or 0</p>

<pre><code>isBinaryImage = all( img(:)==0 | img(:)==1);
</code></pre>
","2886455"
"Exponent Binary Numbers","5582","","<p>Could someone tell me the logic behind exponenting binary numbers? For example, I want to take 110^10, but I don't know the logic behind it. If someone could supply me with that, it'd be a great help.. (And I want it to be done in pure binary with no conversions and no looping multiplication. Just logic...)</p>
","<p>peenut is correct in that exponentiation doesn't care what base you're representing your numbers in, and I don't know what you mean by ""just logic,"" but here's a stab at it. </p>

<p>A quick search over at Wikipedia reveals <a href=""https://en.wikipedia.org/wiki/Exponentiation#Efficient_computation_with_integer_exponents"" rel=""nofollow"">this algorithm</a>. The basic ideas is to square your base, store the result, and then square the result and repeat. This will give you the factors of your answer, which you can then multiply together. I think of it as a ""binary search""-flavored exponentiation algorithm since you can skip a lot of intermediate steps by squaring and storing.</p>
","12755538"
"save string to a binary file in python","5558","","<p>I would like to know a very basic thing of Python programming as I am a very basic programmer right now): how can I save a result (either a list, a string, or whatever) to a file in Python?
I've been searching a lot, but I couldn't find any good answer to this.
I was thinking about the "".write ()"" method, but (for instance) it seems not working with strings, neither I know what it is supposed to do though.
So, my situation is that I have binary fils, which I would like to edit, therefore I found easy to convert them to strings, modify them, and now I'd like to save them i) back to binary files (jpegs images) and ii) in the folder I want.
How would I do that? Please I need some help.</p>

<p><strong>UPDATE</strong></p>

<p>Here is the script I'm trying to run:</p>

<pre><code>import os, sys

newpath= r'C:/Users/Umberto/Desktop/temporary'
if not os.path.exists (newpath):
    os.makedirs (newpath)

data= open ('C:/Users/Umberto/Desktop/Prove_Script/Varie/_BR_Browse.001_2065642654_1.BINARY', 'rb+')
edit_data= str (data.read () )
out_dir= os.path.join (newpath, 'feed', 'address')

data.close ()


# do my edits in a secon time...

edit_data.write (newpath)

edit_data.close ()
</code></pre>

<p>The error I get is:</p>

<pre><code>AttributeError: 'str' object has no attribute 'write'
</code></pre>

<p><strong>UPDATE_2</strong></p>

<p>I tried to use pickle module to serialize my binary file, modify it and save it at the end, but still not getting it to work... This is what I've been trying so far:</p>

<pre><code>import cPickle as pickle
binary= open ('C:\Users\Umberto\Desktop\Prove_Script\Varie\_BR_Browse.001_2065642654_1.BINARY', 'rb')
out= open ('C:\Users\Umberto\Desktop\Prove_Script\Varie\preview.txt', 'wb')
pickle.dump (binary, out, 1)

TypeError                                 Traceback (most recent call last)
&lt;ipython-input-6-981b17a6ad99&gt; in &lt;module&gt;()
----&gt; 1 pprint.pprint (pickle.dump (binary, out, 1))

C:\Python27\ArcGIS10.1\lib\copy_reg.pyc in _reduce_ex(self, proto)
     68     else:
     69         if base is self.__class__:
---&gt; 70             raise TypeError, ""can't pickle %s objects"" % base.__name__
     71         state = base(self)
     72     args = (self.__class__, base, state)

TypeError: can't pickle file objects
</code></pre>

<p>Another thing I didn't get is that if I am supposed to create a file to poit to (in my case I had to create ""out"", otherwise I wouldn't have the right arguments for the pickle method) or it's not necessary.
Hope I'm getting close to the solution.</p>

<p>P.S.: I tried also with pickle.dumps (), not achieving a nicer result though...</p>
","<p>If you're opening a binary file and saving another binary file you could do something like this:</p>

<pre><code>with open('file.jpg', 'rb') as jpgFile:
    contents = jpgFile.read()

contents = (some operations here)

with open('file2.jpg', 'wb') as jpgFile:
    jpgFile.write(contents)
</code></pre>

<p>Some comments:</p>

<ul>
<li>'rb' and 'wb' means read and write in binary mode respectively. More info on why 'b' is recommended when working with binary files <a href=""http://docs.python.org/2/tutorial/inputoutput.html#reading-and-writing-files"" rel=""nofollow"">here</a>.</li>
<li>Python's <a href=""http://docs.python.org/2/reference/compound_stmts.html#the-with-statement"" rel=""nofollow"">with statement</a> takes care of closing the file when exiting the block.</li>
</ul>

<p>If you need to save lists, strings or other objects, and retrieving them later, use <a href=""http://docs.python.org/2/library/pickle.html"" rel=""nofollow"">pickle</a> as others pointed out.</p>
","15205374"
"Where can I get MongoDB PHP driver for PHP 5.4 precompiled for Windows?","5558","","<p>Where can I get mongo php driver for PHP 5.4? For windows vc9 not thread safe. </p>
","<p><del>I've asked <a href=""https://twitter.com/#!/stealth35"" rel=""nofollow noreferrer"">@stealth35</a> to compile the MongoDB driver on Windows for PHP 5.4 and he posted it in less than 30 minutes.</del></p>

<p><del>You can find it here: <a href=""https://github.com/stealth35/stealth35.github.com/downloads"" rel=""nofollow noreferrer"">https://github.com/stealth35/stealth35.github.com/downloads</a></del></p>

<hr>

<p><del><strong>Update (04/26/2012):</strong> Just realized that the official MongoDB PHP drivers have been updated and you can download them from the PHP driver <a href=""https://github.com/mongodb/mongo-php-driver/downloads"" rel=""nofollow noreferrer"">Github page</a>.</del></p>

<hr>

<p><strong>Update (08/27/2013):</strong> They are now available <a href=""https://s3.amazonaws.com/drivers.mongodb.org/php/index.html"" rel=""nofollow noreferrer"">here</a>. Thanks <a href=""https://stackoverflow.com/questions/9576849/where-can-i-get-mongodb-php-driver-for-php-5-4-precompiled-for-windows/9670946?noredirect=1#comment26008792_9670946"">Derick</a>!</p>
","9670946"
"serialize and deserialize SQL query","5554","","<p>I'm having an embedded device which keeps a list of inner tables. I would like it to synchronize this table's state with some outside database for debugging purposes. That is whenever I add an element to a certain struct array I wish the device to issue an ""INSERT INTO ..."" command.</p>

<p>However I'm sending the data over an RS232 serial cable, which makes the overhead of sending explicit SQL unacceptable.</p>

<p>Since there are only 3 types of SQL commands I use a lot, I can only serialize these few. Namely <code>INSERT INTO</code>,<code>DELETE FROM</code>, and <code>UPDATE</code>.</p>

<p>The general idea I had in mind is to send data with a ""compressed/serializable"" SQL protocol. We won't send commands directly to SQL server but to a custom serialized-SQL server I'll write:</p>

<ol>
<li>We'll assign a number to each database-changing simple action (ie INSERT, DELETE, UPDATE). The only available serializable-SQL commands are <code>INSERT INTO x ()</code>, <code>DELETE FROM x WHERE id=y</code>. Where we can only change <code>x</code> and <code>y</code>.</li>
<li>At first create all necessary tables on the server once. Keep a hash table on the server that maps each table to a number. This can be done in plain SQL as this is only done once.</li>
<li>Then assign a number to each table, make sure the server knows about this number</li>
<li>Finally whenever we wish to execute an SQL command, we'll send command number, followed by table number, followed by data length followed by data. The server would figure out the layout of the actual data by table's description.</li>
</ol>

<p>For example</p>

<pre><code>INSERT INTO temperature(temperature,location)
     VALUES ((108,""chille""),(120,""usa""))
</code></pre>

<p>Would be translated to</p>

<pre><code>[INSERT INTO id][2 data to send]
    [byte of 108][6 bytes string ""chille""]
    [byte of 120][3 bytes ""usa""]
</code></pre>

<p>and</p>

<pre><code>DELETE FROM people (id,""bob"") WHERE id=1 or id=2
</code></pre>

<p>Would be translated to</p>

<pre><code>[DELETE id][2 data to send][byte of 1][byte 2]
</code></pre>

<p>Since id is defined as a single byte integer.</p>

<p>Is there any known protocol/implementation in this spirit?</p>

<p>Does anyone have a better idea?</p>
","<p>Most DBMS do this with prepared statements.  You prepare a statement, such as an insert, and then execute it with just the relevant parameters.  The server (or client) gives the prepared statement some sort of ID (typically, an integer, sometimes a string), and the client-side library can re-execute it on demand.</p>

<p>Some of your ideas will need refinement - the OR in the DELETE is not obvious, in particular.  Also, you'd need to define whether your 'N data to send' identifies a number of rows or a number of values, and if a number of rows, how do you identify how many values in the row.</p>
","775906"
"C# - Search Binary File for a Pattern","5539","","<p>What is the best way to search a large binary file for a certain substring in C#?</p>

<p>To provide some specifics, I'm trying to extract the DWARF information from an executable, so I only care about certain parts of the binary file (namely the sections starting with the strings <code>.debug_info</code>, <code>.debug_abbrev</code>, etc.)</p>

<p>I don't see anything obvious in <code>Stream</code>, <code>FileStream</code>, or <code>BinaryReader</code>, so it looks like I'll have to read chunks in and search through the data for the strings myself.</p>

<p>Is there a better way?</p>
","<p>There's nothing built into .NET that will do the search for you, so you're going to need to read in the file chunk by chunk and scan for what you want to find.</p>

<p>You can speed up the search in two ways.</p>

<p>Firstly, use bufferred IO and transfer large chunks at a time - don't read byte by byte, read 64KB, 256KB or 1MB chunks.</p>

<p>Secondly, don't do a linear scan for the piece you want - check out the <a href=""http://en.wikipedia.org/wiki/Boyer-Moore_string_search_algorithm"" rel=""noreferrer"">Boyer-Moore</a> (wikipedia link) algorithm for string searches - you can apply this to searching for the DWARF information you want.</p>
","746368"
"Does Delphi sometimes revert text form files (DFM) to binary format?","5527","","<p>Our Delphi 7 development team stores form files (dfm) in text mode, and uses a source control system (Subversion) to track changes.</p>

<p>Sometimes, we noticed that a form file returned to binary format between revisions, causing diff tools like TortoiseMerge to complain.</p>

<p>Using the Subversion change log, I can see that the DFM file was stored in text form before. The software developers never change the storage file format back to binary manually.</p>

<p>Have you encountered the same? Is it a known problem?</p>
","<p>I have seen it happen in Delphi 7 when a form inheriting from another form from a different project was opened in Delphi on its own without the project it belongs to being open.</p>
","843501"
"Base64 to Binary Conversion using Java","5519","","<p>I already went over the responses I found for the question I have posted, but I wasn't able to figure out something. I would really appreciate it if somebody could please articulate on this a little bit:</p>

<p>I was trying to convert a base64 string into binary. I came across the following code, and I have the base64 string stored in a byte array. How can I convert the byte array into binary.
The code I found:</p>

<pre><code>import org.apache.commons.codec.binary.Base64;

import java.util.Arrays;

public class Base64Decode {
    public static void main(String[] args) {
           String hello = ""AAADccwwCBwOAAAAAAAAAAAAAAAAAAAAAAAAAAwAAAAAAAAAAAB=="";

           byte[] decoded = Base64.decodeBase64(hello.getBytes());

           System.out.println(Arrays.toString(decoded));

          }
}
</code></pre>

<p><strong>Output:</strong></p>

<blockquote>
  <p>[0, 0, 3, 113, -52, 48, 8, 28, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0]</p>
</blockquote>

<p>Is the output correct? When I looked up some documentation for base64 conversion, I noticed the equivalent of ""A"" is 0. How does the array have a zero in the last slot? Would it not be having the equivalent of ""B"". Should my array not begin with three 0s then? How can I convert this into binary (in terms of 0s' and 1s')?</p>
","<p>In base 64, each character represents 6 bits of information.
A four-character sequence represents 24 bits of information (i.e 3 bytes).</p>

<p>Then, the sequence <code>AAAD</code> represents <code>{0,0,3}</code>.</p>

<pre><code>   AAAD -&gt; 000000 000000 000000 000011 -&gt; 00000000 00000000 00000011
</code></pre>

<p>The last sequence <code>AAB=</code>, where the final <code>=</code> is a padding character, represents a <strong>16-bit</strong> value (there are actually 18 bits, but the last two bits are ignored), equivalent to <code>{0, 0}</code>.</p>

<pre><code>   AAB= -&gt; 000000 000000 000001 -&gt; 00000000 00000000 (ignored: 01)
</code></pre>

<p>Had the last sequence been <code>AB==</code>, it would have represented an <strong>8-bit</strong> value, equivalent to <code>{0}</code>.</p>

<pre><code>   AB== -&gt; 000000 000001 -&gt; 00000000 (ignored: 0001)
</code></pre>
","15802768"
"PHP - read 8 bit integers","5516","","<p>I have a binary file that is all 8 bit integers.  I have tried to use the php unpack() functions but I cant get any of the arguments to work for 1 byte integers.  I have tried to combine the data with a dummy byte so that I can use the 'n'/'v' arguments.  I am working with a windows machine to do this.  Ultimately I would like a function to return an array of integers based on a string of 8 bit binary integers.  The code I have tried is below - </p>

<pre><code>$dat_handle = ""intergers.dat"";
$dat_file = fopen($dat_handle, ""rb"");
$dat_data = fread($dat_file, 1);
$dummy = decbin(0);
$combined = $dummy.$dat_data;
$result = unpack(""n"", $combined);
</code></pre>
","<p>What your looking for is the char datatype. Now there are two version of this, signed (lowercase <code>c</code>) and unsigned (uppercase <code>C</code>). Just use the one that's correct for your data.</p>

<pre><code>&lt;?php
    $byte = unpack('c', $byte);
?&gt;
</code></pre>

<p>Also, if the data file is just a bunch of bytes and nothing else, and you know it's length, you can do this. (If the length is 16 signed chars in a row.)</p>

<pre><code>&lt;?php
    $bytes = unpack('c16', $byte);
?&gt;
</code></pre>

<p>If you don't know how many bytes will be in the file, but you know there is only going to be bytes you can use the asterisk code to read until EOF.</p>

<pre><code>&lt;?php
    $bytes = unpack('c*', $byte);
?&gt;
</code></pre>
","5827319"
"How to convert boolean array to binary and vice versa in Java?","5510","","<p>What is the most efficient way to output a boolean array to (and input from) a file in Java? I was going to use a string with each character being either 't' or 'f' and then I thought, why not take eight time less space?</p>

<p><strong>NOTE</strong></p>

<p>I actually have no idea which answer is the better method, I've just chosen Peter's because I understand it. Thanks to both answerers!</p>
","<p>Say you have a boolean[]</p>

<pre><code>boolean[] ar = {true,false,false,true,false,true,true,true,false,true,false,false,false,true,tr‌​ue};
</code></pre>

<p>and you want to write this to a disk, and you don't care how its is implemented in memory.</p>

<pre><code>public static void main(String... args) throws IOException {
    boolean[] ar = {true, false, false, true, false, true, true, true, false, true, false, false, false, true, true};

    FileOutputStream out = new FileOutputStream(""test.dat"");
    writeBooleans(out, ar);
    out.close();

    FileInputStream in = new FileInputStream(""test.dat"");
    boolean[] ar2 = new boolean[ar.length]; 
    readBooleans(in, ar2);
    in.close();

    System.out.println(Arrays.toString(ar));
    System.out.println(Arrays.toString(ar2));
    System.out.println(""The file size was ""+new File(""test.dat"").length()+"" bytes."");
}

private static void writeBooleans(OutputStream out, boolean[] ar) throws IOException {
    for (int i = 0; i &lt; ar.length; i += 8) {
        int b = 0;
        for (int j = Math.min(i + 7, ar.length-1); j &gt;= i; j--) {
            b = (b &lt;&lt; 1) | (ar[j] ? 1 : 0);
        }
        out.write(b);
    }
}

private static void readBooleans(InputStream in, boolean[] ar) throws IOException {
    for (int i = 0; i &lt; ar.length; i += 8) {
        int b = in.read();
        if (b &lt; 0) throw new EOFException();
        for (int j = i; j &lt; i + 8 &amp;&amp; j &lt; ar.length; j++) {
            ar[j] = (b &amp; 1) != 0;
            b &gt;&gt;&gt;= 1;
        }
    }
}
</code></pre>

<p>prints</p>

<pre><code>[true, false, false, true, false, true, true, true, false, true, false, false, false, true, true]
[true, false, false, true, false, true, true, true, false, true, false, false, false, true, true]
The file size was 2 bytes.
</code></pre>

<p>but if I look at how big the file actually is</p>

<pre><code>$ ls -l test.dat
-rw-rw-r-- 1 peter peter 2 2012-02-19 14:04 test.dat
$ du -h test.dat 
4.0K    test.dat
</code></pre>

<p>It says the length is 2 bytes, but the disk space used is actually 4 KB.</p>

<p>Note: About 1 minute of your time is worth about the same as 80 MB of SSD (expensive disk, more for HDD) So if you don't think you will be saving at least 80 MB by using this, you could be wasting your time. ;)</p>

<hr>

<p>You can use BitSet, which can take 16x less space as each character is 16-bit.</p>
","9349545"
"Reading file into a struct (C++)","5481","","<p>I'm trying to read data from a binary file and put it into a struct.
The first few bytes of <code>data.bin</code> are:</p>

<pre><code>03 56 04 FF FF FF ...
</code></pre>

<p>And my implementation is:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;fstream&gt;

int main()
{
    struct header {
        unsigned char type;
        unsigned short size;
    } fileHeader;

    std::ifstream file (""data.bin"", std::ios::binary);
    file.read ((char*) &amp;fileHeader, sizeof header);

    std::cout &lt;&lt; ""type: "" &lt;&lt; (int)fileHeader.type;
    std::cout &lt;&lt; "", size: "" &lt;&lt; fileHeader.size &lt;&lt; std::endl;

}
</code></pre>

<p>The output I was expecting is <code>type: 3, size: 1110</code>, but for some reason it's <code>type: 3, size: 65284</code>, so basically the second byte in the file is skipped. What's happening here?</p>
","<p>Actually the behavior is implementation-defined. What actually happens in your case probably is, there is a padding of 1 byte, after <code>type</code> member of the struct, then after that follows the second member <code>size</code>. I based this argument after seeing the output.</p>

<p>Here is your input bytes:</p>

<pre><code>03 56 04 FF FF FF
</code></pre>

<p>the first byte <code>03</code> goes to the first byte of the struct, which is <code>type</code>, and you see this <code>3</code> as output. Then next byte <code>56</code> goes to the second byte which is the padding hence ignored, then the next two bytes <code>04 FF</code> goes to the next two bytes of the struct which is <code>size</code> (which is of size <code>2</code> bytes). On little-endian machine, <code>04 FF</code> is interpreted as <code>0xFF04</code> which is nothing but <code>66284</code> which you get as output.</p>

<p>And you need basically a compact struct so as to squeeze the padding. Use <code>#pragma</code> pack. But such a struct would be slow compared to the normal struct. A better option is to fill the struct manually as:</p>

<pre><code>char bytes[3];
std::ifstream file (""data.bin"", std::ios::binary);
file.read (bytes, sizeof bytes); //read first 3 bytes

//then manually fill the header
fileHeader.type = bytes[0];
fileHeader.size = ((unsigned short) bytes[2] &lt;&lt; 8) | bytes[1]; 
</code></pre>

<p>Another way to write the last line is this:</p>

<pre><code>fileHeader.size = *reinterpret_cast&lt;unsigned short*&gt;(bytes+1); 
</code></pre>

<p>But this is implementation-defined, as it depends on the endian-ness of the machine. On little-endian machine, it most likely would work. </p>

<p>A friendly approach would be this (implementation-defined):</p>

<pre><code>std::ifstream file (""data.bin"", std::ios::binary);
file.read (&amp;fileHeader.type, sizeof fileHeader.type);
file.read (reinterpret_cast&lt;char*&gt;(&amp;fileHeader.size), sizeof fileHeader.size);
</code></pre>

<p>But again, the last line depends on the endian-ness of the machine.</p>
","9852749"
"How to read a whole binary file (Nippy) into byte array in Clojure?","5472","","<p>I need to convert Nippy data structures stored on disk into something that can be read by Nippy? Nippy uses byte arrays, so I need some way to convert the file into a byte array. I have tried </p>

<pre><code>(clojure.java.io/to-byte-array (clojure.java.io/file folder-path file-path))
</code></pre>

<p>but this gives</p>

<pre><code>java.lang.IllegalArgumentException: Value out of range for byte: ? 
</code></pre>

<p>Then I try:</p>

<pre><code>(into-array Byte/TYPE  (map byte (slurp (clojure.java.io/file folder-path file-path)))) 
</code></pre>

<p>but somehow the namespace is wrong, and I can't find the right one.</p>

<p>To write the Nippy structures in the first place, I am using:</p>

<pre><code>(with-open [w (clojure.java.io/output-stream file-path)]
    (.write w (nippy/freeze data)))))
</code></pre>
","<p>I'm not aware of anything built-in to Clojure that will handle this. You definitely don't want <code>slurp</code> because that will decode the stream contents as text.</p>

<p>You could write your own method to do this, basically reading from the <code>InputStream</code> into a buffer and writing the buffer to a <code>java.io.ByteArrayOutputStream</code>. Or you could use the <a href=""http://commons.apache.org/proper/commons-io/apidocs/org/apache/commons/io/IOUtils.html"" rel=""nofollow noreferrer""><code>IOUtils</code> class</a> from Apache Commons IO:</p>

<pre><code> (require '[clojure.java.io :as io])
 (import '[org.apache.commons.io IOUtils])

 (IOUtils/toByteArray (io/input-stream file-path))
</code></pre>

<p>You should also take a look at Nippy's <code>thaw-from-in!</code> and <code>freeze-to-out!</code> functions:</p>

<pre><code> (import '[java.io DataInputStream DataOutputStream])

 (with-open [w (io/output-stream file-path)]
   (nippy/freeze-to-out! (DataOutputStream. w) some-data))

 (with-open [r (io/input-stream file-path)]
   (nippy/thaw-from-in! (DataInputStream. r)))
</code></pre>
","23019996"
"Proper way of converting C's uint32 to int in java","5468","","<p>I am building a project which consists of multiple components and these components communicate with each other in byte arrays using sockets. The problem is one component is written in C and supports Unsigned primitive types while other components are written in Java and does not support Unsigned types. I am trying to develop support for Unsigned types in Java. I am new to Java. Can anyone please tell me the proper way to decode uint32 and uint64 from a byte array.</p>

<p>I am using the following functions for conversion of int32 and int64</p>

<pre><code>public static int int32Converter(byte b[], int start) {
    return ((b[start] &lt;&lt; 24) &amp; 0xff000000 |(b[start + 1] &lt;&lt; 16) &amp; 0xff0000
            | (b[start + 2] &lt;&lt; 8) &amp; 0xff00 | (b[start + 3]) &amp; 0xff);
}
public static long int64Converter(byte buf[], int start) {
    return ((buf[start] &amp; 0xFFL) &lt;&lt; 56) | ((buf[start + 1] &amp; 0xFFL) &lt;&lt; 48)
            | ((buf[start + 2] &amp; 0xFFL) &lt;&lt; 40)
            | ((buf[start + 3] &amp; 0xFFL) &lt;&lt; 32)
            | ((buf[start + 4] &amp; 0xFFL) &lt;&lt; 24)
            | ((buf[start + 5] &amp; 0xFFL) &lt;&lt; 16)
            | ((buf[start + 6] &amp; 0xFFL) &lt;&lt; 8)
            | ((buf[start + 7] &amp; 0xFFL) &lt;&lt; 0);
}
</code></pre>

<p>Thank you!</p>
","<p>You cannot exactly ""convert"" them. The closest you'll find to handling unsigned values is Guava's <a href=""http://docs.guava-libraries.googlecode.com/git-history/v16.0.1/javadoc/com/google/common/primitives/UnsignedInteger.html"" rel=""nofollow""><code>UnsignedInteger</code></a> and its utility class <code>UnsignedInts</code>. There is the same for bytes, shorts and longs too.</p>

<p>Note about your code, don't be bothere writing such stuff by hand, use a <code>ByteBuffer</code>:</p>

<pre><code>public static int bytesToInt(final byte[] array, final int start)
{
     final ByteBuffer buf = ByteBuffer.wrap(array); // big endian by default
     buf.position(start);
     buf.put(array);
     return buf.position(start).getInt();
}
</code></pre>

<p>Using Guava for an unsigned int:</p>

<pre><code>public static UnsignedInteger bytesToUnsignedInt(final byte[] array, final int start)
{
         return UnsignedInteger.fromIntBits(bytesToInt(array, start);
}
</code></pre>

<p>However, I suspect that <code>UnsignedInts</code> is really what you want. (for comparison, printing them out etc)</p>
","22142822"
"Create bitmap from binary data","5443","","<p>I have the following: </p>

<pre><code>byte[] pixels = new byte[28] { 0x00, 0x00, 0x30, 0x00, 0x30, 0x00, 0x00, 0x00, 0x00, 0x00, 0x30, 0x00, 0x30, 0x00, 0x30, 0x00, 0x30, 0x00, 0x30, 0x00, 0x30, 0x00, 0x30, 0x00, 0x30, 0x00, 0x00, 0x00 };
</code></pre>

<p>This is an upside down exclamation mark like this:</p>

<pre><code>0x00, 0x00,
0x30, 0x00,
0x30, 0x00,
0x00, 0x00,
0x00, 0x00,
0x30, 0x00,
0x30, 0x00,
0x30, 0x00,
0x30, 0x00,
0x30, 0x00,
0x30, 0x00,
0x30, 0x00,
0x30, 0x00,
0x00, 0x00
</code></pre>

<p>Which in binary is:</p>

<pre><code>00000000    00000000
00110000    00000000
00110000    00000000
00000000    00000000
00000000    00000000
00110000    00000000
00110000    00000000
00110000    00000000
00110000    00000000
00110000    00000000
00110000    00000000
00110000    00000000
00110000    00000000
00000000    00000000
</code></pre>

<p>I need to convert this to a bitmap / create a bitmap. So the exclamation mark is white and the background is black. I need to be able to color the pixels also.</p>

<p>How to do this??</p>
","<p>Assuming all your images are 16x14</p>

<pre><code>Bitmap bmp = new Bitmap(16, 14);
int line=0;

for (int i = 0; i &lt; pixels.Length; i++)
{
    for (int j = 0; j&lt;8; j++)
    {
        if (((pixels[i] &gt;&gt; j) &amp; 1) == 1)
        {
            bmp.SetPixel( (i%2)*8 + 7-j, line, Color.Black);
        }
    }
    if(i%2==1) line++;
}
</code></pre>
","9414275"
"In Sql Server, how to convert binary strings to binary?","5439","","<p>I have some data in string format that represents binary data (e.g. '0x0002').  Is there some function or trick where I can convert these from literal strings to binary?  That is, I want '0x0002' to become 0x0002, and SELECT CAST('0x0002' AS BINARY(20)) obviously won't do that.  I did come up with some painfully slow process that involves building up SQL Statements and assigning them to a variable and executing that (e.g. ""EXEC (@Query)""), but I'm looking for something where I don't have to do that.</p>

<p>If it helps, here is a sample table that you can test this on:</p>

<pre><code>CREATE TABLE #T (BinaryString VARCHAR(100))
INSERT INTO #T VALUES('0x0000000000000000000000000000000000000002') -- Binary = the integer 2
INSERT INTO #T VALUES('0x000000000000000000000000000000000000007B') -- Binary = the integer 123
</code></pre>
","<p><a href=""http://support.microsoft.com/kb/104829"" rel=""nofollow noreferrer"">Older code, SQL 7, sp_hexadecimal</a></p>

<p><a href=""http://decipherinfosys.wordpress.com/2008/06/11/converting-a-hex-string-to-a-varbinary-or-vice-versa/"" rel=""nofollow noreferrer"">SQL 2005 (+ 2000 maybe), master.dbo.fn_varbintohexstr</a></p>

<p><a href=""http://decipherinfosys.wordpress.com/2008/07/31/sql-server-2008-converting-binary-and-character-values/"" rel=""nofollow noreferrer"">SQL 2008, native</a></p>
","655734"
"How do i get an integer to set the value the same as a scanner","5428","","<p>I was wondering how to get a <code>Scanner</code> to set its value to an integer. </p>

<p>The reason I want to do this is because I have my program:</p>

<ul>
<li>reading a line of input that is only numbers, </li>
<li>then takes the input, puts it into an <code>int</code>, </li>
<li>and then uses the <code>Integer.toBinaryString(&lt;name of int&gt;);</code> to show the number in binary</li>
</ul>

<p>The only problem is that the name of in HAS to be an int; it can't be a <code>String</code>. </p>

<p>Here's my code if you need it:</p>

<pre><code>package base.pkg10.to.binary.txt.converter;

import java.util.Scanner;
import static java.lang.System.out;

public class Base10ToBinaryTXTConverter {

    public static void main(String[] args) {

        Scanner input = new Scanner(System.in);
        int output;

        out.println(""This converts base 10 numbers to binary numbers."");
        out.println(""Please enter your Base 10 Number:"");
        out.println(""Please wait..."");
        out.println(""Your numeber in Binary is:"");
        out.println(Integer.toBinaryString(input));

    }
}
</code></pre>
","<p>So, you need to convert the input from the scanner to an integer?</p>

<p>Try:</p>

<pre><code>int result = Integer.parseInt(input.nextLine());
</code></pre>

<p>Then you could write:</p>

<pre><code>out.println(Integer.toBinaryString(result));
</code></pre>

<p>Edit: When using <code>Integer.parseInt</code>, it is a good idea to catch any <code>NumberFormatException</code>s that may arise from invalid input, e.g. <code>Integer.parseInt(""foo"");</code> will throw such an exception.</p>
","8542395"
"Check if a file is binary or ASCII with Node.js?","5396","","<p>I'm wondering what would be the best way to check if a file is binary or ASCII with Node.js?</p>

<p>There appears to be two ways not specific to node.js:</p>

<ol>
<li><p>Checking the MIME type: <a href=""https://stackoverflow.com/questions/632685/how-to-check-if-file-is-ascii-or-binary-in-php"">How to Check if File is ASCII or Binary in PHP</a> - however this has it's problems, as for instance pre-precessors often don't have a recognised mime type and revert to <code>application/octet-stream</code> when checking them using <a href=""https://github.com/bentomas/node-mime"" rel=""nofollow noreferrer"">mime</a></p></li>
<li><p>Via checking the byte size using a stream buffer with <a href=""https://stackoverflow.com/questions/277521/how-to-identify-the-file-content-is-in-ascii-or-binary#277538"">How to identify the file content as ASCII or binary</a> - which seems quite intensive, and does yet provide a node.js example.</p></li>
</ol>

<p>So is there another way already? Perhaps a secret node.js call or module that I don't know about? Or if I have to do this myself, what way would be suggested?</p>

<p>Thanks</p>
","<p>Thanks to the comments on this question by <a href=""https://stackoverflow.com/users/721269/david-schwartz"">David Schwartz</a>, I created <a href=""https://github.com/bevry/istextorbinary"" rel=""nofollow noreferrer"">istextorbinary</a> to solve this problem.</p>
","10391758"
"Way to add leading zeroes to binary string in JavaScript","5384","","<p>I've used .toString(2) to convert an integer to a binary, but it returns a binary only as long as it needs to be (i.e. first bit is a 1).</p>

<p>So where:</p>

<pre><code>num = 2;
num.toString(2) // yields 10. 
</code></pre>

<p>How do I yield the octet 00000010?</p>
","<p>It's as simple as</p>

<pre><code>var n= num.toString(2);
n=""00000000"".substr(n.length)+n;
</code></pre>
","27641835"
"C# Program that converts decimal number to binary","5381","","<p>So, I have to make a program that converts a decimal number to binary and prints it, but without using Convert. I got to a point where I can print out the number, but it's in reverse(for example: 12 comes out as 0011 instead of 1100), anyone has an idea how to fix that ? Here's my code:</p>

<pre><code>        Console.Write(""Number = "");
        int n = int.Parse(Console.ReadLine());
        string counter = "" "";


        do
        {

            if (n % 2 == 0)
            {                  
                counter = ""0"";
            }

            else if (n % 2 != 0)
            {
                 counter = ""1"";
            }

            Console.Write(counter);

            n = n / 2;
        }
        while (n &gt;= 1);
</code></pre>
","<p>simple solution would be to add them at the beginning:</p>

<pre><code>Console.Write(""Number = "");
int n = int.Parse(Console.ReadLine());
string counter = """";

while (n &gt;= 1)
{
   counter = (n % 2) + counter;
   n = n / 2;
}
Console.Write(counter);
</code></pre>

<p>You actually don't even need the if statement</p>
","18390727"
"converting double to binary in java","5373","","<p>I am generating sequence of numbers of type double like
0.9913963644564902 
0.0341175990344773 
0.13181105852355268 
0.45773616980747556 
and I have to convert it to binary representation in java. </p>
","<p>This will help you. I have tried out using one of your input double value - 0.9913963644564902</p>

<pre><code> public static void main(String[] args){
        double d = 0.9913963644564902;
        System.out.println(""0b""+Long.toBinaryString(Double.doubleToRawLongBits(d)));
    }
</code></pre>

<p>The output would be</p>

<pre><code>run:
0b11111111101111101110011000010011011110010101101101100001110011
BUILD SUCCESSFUL (total time: 0 seconds)
</code></pre>
","20730218"
"Converting two bytes into 16 bit signed number","5363","","<p>I got two bytes: </p>

<p><code>byte[0]</code> is 0000 0000</p>

<p><code>byte[1]</code> is 1000 0000</p>

<p>I would like to put them together and make one float value of them. So the result should be 128 is decimal and 0000 0000 1000 0000 in binary. Not negative because of the leading zero. </p>

<p>My solution so far is this approach: </p>

<pre><code>float f = (bytes[0] &lt;&lt; 8 | bytes[1]);
</code></pre>

<p>But this will result in a value of minus 128 for value f. It's because of the 2s complement i guess. Therefore <code>byte[1]</code> will be interpreted as negative. How can I just see the leading bit of <code>byte[0]</code> as the bit for negative/positive? </p>
","<p>Try this:</p>

<pre><code>short int16 = (short)(((bytes[0] &amp; 0xFF) &lt;&lt; 8) | (bytes[1] &amp; 0xFF));
</code></pre>

<p>You need to use parenthesis because of operation precedence.</p>

<p>once you have your 16 bit integer, you can assign it to your float:</p>

<pre><code>float f = int16;
</code></pre>

<p>yes, you could have done it in one step, but I wanted to go step by step.</p>
","18219407"
"Strange behaviour of .NET binary serialization on Dictionary<Key, Value>","5351","","<p>I encountered a, at least to my expectations, strange behavior in the binary serialization of .NET.</p>

<p>All items of a <code>Dictionary</code> that are loaded are added to their parent AFTER the <code>OnDeserialization</code> callback. In contrast <code>List</code> does the other way. This can be really annoying in real world repository code, for example when you need to add some delegates to dictionary items. Please check the example code and watch the asserts.</p>

<p>Is it normal behaviour?</p>

<pre><code>[Serializable]
public class Data : IDeserializationCallback
{
    public List&lt;string&gt; List { get; set; }

    public Dictionary&lt;string, string&gt; Dictionary { get; set; }

    public Data()
    {
        Dictionary = new Dictionary&lt;string, string&gt; { { ""hello"", ""hello"" }, { ""CU"", ""CU"" } };
        List = new List&lt;string&gt; { ""hello"", ""CU"" };
    }

    public static Data Load(string filename)
    {
        using (Stream stream = File.OpenRead(filename))
        {
            Data result = (Data)new BinaryFormatter().Deserialize(stream);
            TestsLengthsOfDataStructures(result);

            return result;
        }
    }

    public void Save(string fileName)
    {
        using (Stream stream = File.Create(fileName))
        {
            new BinaryFormatter().Serialize(stream, this);
        }
    }

    public void OnDeserialization(object sender)
    {
        TestsLengthsOfDataStructures(this);
    }

    private static void TestsLengthsOfDataStructures(Data data)
    {
        Debug.Assert(data.List.Count == 2, ""List"");
        Debug.Assert(data.Dictionary.Count == 2, ""Dictionary"");
    }
}
</code></pre>
","<p>I can reproduce the problem.  Had a look around Google and found this: <a href=""http://connect.microsoft.com/VisualStudio/feedback/ViewFeedback.aspx?FeedbackID=94265"" rel=""noreferrer"">http://connect.microsoft.com/VisualStudio/feedback/ViewFeedback.aspx?FeedbackID=94265</a> although I'm not sure it's the exact same problem, it seems pretty similar.</p>

<p>EDIT:</p>

<p>I think that adding this code may have fixed the problem?</p>

<pre><code>    public void OnDeserialization(object sender)
    {
            this.Dictionary.OnDeserialization(sender);
    }
</code></pre>

<p>No time to exhaustively test, and I want to beat Marc to the answer ;-)</p>
","457204"
"Incrementing a binary number in python","5341","","<p>I wonder, how can I increment a string representing a binary number, all the way up to another binary number? (for use in a while loop, for example).</p>

<p>For example I start with ""0000"" and after 15 incs, I should reach ""1111"" (in other words: ""0000"", ""0001"", ""0010"", ..., ""1111""). At first this problem seemed really simple, but the only solutions I could come up with were quite ridiculous (not pythonic, some might say). Does anyone have an advice?</p>

<p>Thanks in advance!</p>
","<p>To do what you literally asked for you should convert to an integer, add one, then change back to binary.</p>

<pre><code>x = to_binary(int(x, 2) + 1)
</code></pre>

<p>You may find the <code>bin</code> built-in method useful in implementing <code>to_binary</code>, though you will need to modify its output slightly to match your desired result.</p>

<p>However it would be better if possible to not convert back and forth: just store an integer and convert it to binary when you need to display it.</p>

<p>On reading your question carefully though, it seems that all you want to do is to generate the strings <code>'0000'</code>, <code>'0001'</code>, <code>'0010'</code>, etc. If this is correct, then I suggest using <a href=""http://docs.python.org/library/itertools.html#itertools.product"" rel=""nofollow""><code>itertools.product</code></a>.</p>

<p>Example:</p>

<pre><code>import itertools
for x in map(''.join, itertools.product('01', repeat=4)):
    print x

0000
0001
0010
...
</code></pre>

<p>See it working online: <a href=""http://ideone.com/HSdcE"" rel=""nofollow"">ideone</a></p>
","10673019"
"Convert binary string to bytearray in Python 3","5339","","<p>Despite the many related questions, I can't find any that match my problem.  I'd like to change a binary string (for example, <code>""0110100001101001""</code>) into a byte array (same example, <code>b""hi""</code>).</p>

<p>I tried this:  </p>

<pre><code>bytes([int(i) for i in ""0110100001101001""])
</code></pre>

<p>but I got:</p>

<pre><code>b'\x00\x01\x01\x00\x01' #... and so on
</code></pre>

<p>What's the correct way to do this in Python 3?</p>
","<p>Here's an example of doing it the first way that Patrick mentioned: convert the bitstring to an int and take 8 bits at a time. The natural way to do that generates the bytes in reverse order. To get the bytes back into the proper order I use extended slice notation on the bytearray with a step of -1: <code>b[::-1]</code>.</p>

<pre><code>def bitstring_to_bytes(s):
    v = int(s, 2)
    b = bytearray()
    while v:
        b.append(v &amp; 0xff)
        v &gt;&gt;= 8
    return bytes(b[::-1])

s = ""0110100001101001""
print(bitstring_to_bytes(s))
</code></pre>

<p>Clearly, Patrick's second way is more compact. :)</p>

<p>However, there's a better way to do this in Python 3: use the <a href=""https://docs.python.org/3/library/stdtypes.html#int.to_bytes"" rel=""nofollow"">int.to_bytes</a> method:</p>

<pre><code>def bitstring_to_bytes(s):
    return int(s, 2).to_bytes(len(s) // 8, byteorder='big')
</code></pre>
","32676625"
"Reading binary file defined by a struct","5335","","<p>Could somebody point me in the right direction of how I could read a binary file that is defined by a C struct?
It has a few #define inside of the struct, which makes me thing that it will complicate things.<br>
The structure looks something like this: (although its larger and more complicated than this)</p>

<pre><code>struct Format {
    unsigned long str_totalstrings;
    unsigned long str_name;
    #define STR_ORDERED 0x2
    #define STR_ROT13 0x4
    unsigned char stuff[4];
    #define str_delimiter stuff[0]
}
</code></pre>

<p>I would really appreciate it if somebody could point me in the right direction on how to do this. Or if theres any tutorial out there that covers this topic?</p>

<p>Thanks a lot in advance for your help.</p>
","<p>Reading a binary defined by a struct is easy.</p>

<pre><code>Format myFormat;
fread(&amp;myFormat, sizeof(Format), 1, fp);
</code></pre>

<p>the #defines don't affect the structure at all.  (Inside is an odd place to put them, though).</p>

<p>However, this is not cross-platform safe.  It is the simplest thing that will possibly work, in situations where you are assured the reader and writer are using the same platform.</p>

<p>The better way would be to re-define your structure as such:</p>

<pre><code>struct Format {
    Uint32 str_totalstrings;  //assuming unsigned long was 32 bits on the writer.
    Uint32 str_name;
    unsigned char stuff[4];
};
</code></pre>

<p>and then have a 'platform_types.h"" which typedefs Uint32 correctly for your compiler.  Now you can read directly into the structure, but for endianness issues you still need 
to do something like this:</p>

<pre><code>myFormat.str_totalstrings = FileToNative32(myFormat.str_totalstrings);
myFormat.str_name =   FileToNative32(str_name);
</code></pre>

<p>where FileToNative is either a no-op or a byte reverser depending on platform.</p>
","868546"
"WCF Service with Binary Data","5333","","<p>I have a unique problem and I would like the capability to process an incoming HTTP POST request that contains arbitrary binary data.</p>

<p>I can currently process this data using a standard ASP.NET Page handler or in an ASP web service, but I want to know if its possible to processing INCOMING binary data in a WCF service?  Can I drill down into the WCF processing stack to bypass the SOAP processing and handle the raw message in my own code?</p>

<p>I understand that this breaks the 'contract' publishing of WCF (WSDL whatever), but I don't really care about that.</p>

<p>-Jeff</p>
","<p>After spending a few weeks on this problem, I have pretty much a definitive answer:</p>

<p>Can you replace XML/SOAP with a custom binary serialization for WCF?</p>

<p>The short answer:  no</p>

<p>The long answer: yes, but you have to rewrite almost all of the transport layer interfaces so you might as well just create a custom IHttpHandler and avoid WCF all together.</p>

<p>Microsoft, in attempting to follow the SOAP standard (and the standard is responsible for this problem in my opinion) breaks one of the simple programming rules -> separation of responsibilities in the layers.  WCF/SOAP may appear to be a elegantly layered protocol and transport, but the reality is, is that there are intricate connections between the layers.  This means that WCF is an extremely complex communication protocol that provides transport, security, reliability, publishing, serialization and other features that are all interdependent at some level.  If all you want is a transport channel, WCF/SOAP adds a tremendous amount of complexity.</p>

<p>I'm sure I could start huge rants about SOAP yes/no, but I finally realized that WCF/SOAP is not what I needed for my application.</p>

<p>-Jeff</p>
","1141206"
"How to create BinaryArray in VbScript?","5321","","<p>I want to manually create a binary script and then save it as binary file.</p>

<p>I want to append all of the following bytes and create a binary file out of them. </p>

<pre><code>&amp;HF0
&amp;HF1
&amp;HF2
</code></pre>

<p>I want to able to do something like this : </p>

<pre><code>Dim generateData(3) As Byte
generateData(0) = &amp;HFF
generateData(1) = &amp;HFE
generateData(2) = &amp;HFC
</code></pre>

<p>But obviously <strong>As Byte</strong> doesn't work on Vbscript. I do use the following function to write binary array to disk (at least I'll when I able to create a binary array)</p>

<pre><code>Function SaveBinaryData(FileName, ByteArray)
  Const adTypeBinary = 1
  Const adSaveCreateOverWrite = 2

  'Create Stream object
  Dim BinaryStream
  Set BinaryStream = CreateObject(""ADODB.Stream"")

  'Specify stream type - we want To save binary data.
  BinaryStream.Type = adTypeBinary

  'Open the stream And write binary data To the object
  BinaryStream.Open
  BinaryStream.Write ByteArray

  'Save binary data To disk
  BinaryStream.SaveToFile FileName, adSaveCreateOverWrite
End Function
</code></pre>
","<p>I have seen something along these lines used:</p>

<pre><code>Sub WriteBinary(FileName, Buf)  

    Dim I, aBuf, Size, bStream  

    Size = UBound(Buf): ReDim aBuf(Size \ 2)  

    For I = 0 To Size - 1 Step 2  

        aBuf(I \ 2) = ChrW(Buf(I + 1) * 256 + Buf(I))  

    Next  

    If I = Size Then aBuf(I \ 2) = ChrW(Buf(I))  

    aBuf=Join(aBuf, """")  

    Set bStream = CreateObject(""ADODB.Stream"")  

    bStream.Type = 1: bStream.Open  

    With CreateObject(""ADODB.Stream"")  

        .Type = 2 : .Open: .WriteText aBuf  

        .Position = 2: .CopyTo bStream: .Close  

    End With  

    bStream.SaveToFile FileName, 2: bStream.Close  

    Set bStream = Nothing  

End Sub
</code></pre>
","548127"
"How can i split a binary in erlang","5320","","<p>What I want is, I think, relatively simple:</p>

<pre><code>&gt; Bin = &lt;&lt;""Hello.world.howdy?""&gt;&gt;.
&gt; split(Bin, ""."").
[&lt;&lt;""Hello""&gt;&gt;, &lt;&lt;""world""&gt;&gt;, &lt;&lt;""howdy?""&gt;&gt;]
</code></pre>

<p>Any pointers?</p>
","<p>There is no current OTP function that is the equivalent of <code>lists:split/2</code> that works on a binary string. Until <a href=""http://www.erlang.org/eeps/eep-0009.html"" rel=""nofollow noreferrer"">EEP-9</a> is made public, you might write a binary split function like:</p>

<pre><code>split(Binary, Chars) -&gt;
    split(Binary, Chars, 0, 0, []).

split(Bin, Chars, Idx, LastSplit, Acc)
  when is_integer(Idx), is_integer(LastSplit) -&gt;
    Len = (Idx - LastSplit),
    case Bin of
        &lt;&lt;_:LastSplit/binary,
         This:Len/binary,
         Char,
         _/binary&gt;&gt; -&gt;
            case lists:member(Char, Chars) of
                false -&gt;
                    split(Bin, Chars, Idx+1, LastSplit, Acc);
                true -&gt;
                    split(Bin, Chars, Idx+1, Idx+1, [This | Acc])
            end;
        &lt;&lt;_:LastSplit/binary,
         This:Len/binary&gt;&gt; -&gt;
            lists:reverse([This | Acc]);
        _ -&gt;
            lists:reverse(Acc)
    end.
</code></pre>
","428852"
"Key/Value database for storing binary data","5319","","<p>I am looking for a lightweight, reliable and fast key/value database for storing binary data. Simple without server. Most of popular key/value databases like CDB and BerkeleyDB does not natively store <code>BLOB</code>. What can be the best choice that I missed?</p>

<p>My current choice is SQLite, but it is too advanced for my simple usage.</p>
","<p>As it was previously pointed out, BerkeleyDB does support opaque values and keys, but I would suggest a better alternative: LevelDB.</p>

<p><strong>LevelDB:</strong></p>

<p>Google is your friend :), so much so that they even provide you with an embedded database: <a href=""https://github.com/google/leveldb"" rel=""nofollow"">A fast and lightweight key/value database library by Google.</a></p>

<p><strong>Features:</strong></p>

<ul>
<li>Keys and values are arbitrary byte arrays.</li>
<li>Data is stored sorted by key.</li>
<li>Callers can provide a custom comparison function to override the sort order.</li>
<li>The basic operations are Put(key,value), Get(key), Delete(key).</li>
<li>Multiple changes can be made in one atomic batch.</li>
<li>Users can create a transient snapshot to get a consistent view of data.</li>
<li>Forward and backward iteration is supported over the data.</li>
<li>Data is automatically compressed using the Snappy compression library.</li>
<li>External activity (file system operations etc.) is relayed through a virtual interface so users can customize the operating system interactions.</li>
<li>Detailed documentation about how to use the library is included with the source code. </li>
</ul>
","9806855"
"Tool for 3-Way Binary (Hex) File Comparison?","5316","","<p>I have a set of binary configuration files with three versions each -- an original, and two differently-modified versions of each file. I need to be able to see the differences between the two versions as well as the original, all at the same time.</p>

<p>What I need is a three-way diff tool for binary files. Through a rather exhausting Google search, I eventually happened upon a <em>screenshot</em> of an application that does exactly what I need -- unfortunately, the forum post containing the image does not mention what application it is they're using:</p>

<p><a href=""http://www.xboxhacker.org/index.php?topic=15032.0"" rel=""nofollow"">http://www.xboxhacker.org/index.php?topic=15032.0</a></p>

<p>Can someone point me in the direction of a (Windows) application that provides a binary-safe (hex) comparison of three binary files??</p>
","<p>The screenshot is from <a href=""http://www.araxis.com/merge/topic_comparing_binary_files.html"" rel=""nofollow"">Araxis Merge</a>.  Their pro edition ($270) supports 3-way compares.</p>
","4598013"
"Creating binary variables in R from categorical and NA variables","5305","","<p>I have a dataset of 12901 <code>categorical</code> and <code>NA</code> observations with 34 variables. I will use the dataset for create a market segmentation study by clustering consumer demographics. </p>

<p>For the <code>categorical</code> variables, I want to convert to <code>numeric</code> binary data. For example, variable <code>HouseholdIncome</code> has six categories: 50K-75k, 75k-100k, 35k-50k, 100k-125k, 150k-175k, and Other. I want <code>HouseholdIncome</code> to be broken up into six variables (0,0,0,0,0,1), (0,0,0,0,1,0), (0,0,0,1,0,0), (0,0,1,0,0,0), (0,1,0,0,0,0), and (1,0,0,0,0,0). </p>

<p><strong>Question:</strong> how can I change the categorical values to binary variables, yet keep the <code>NA</code>s?</p>

<p>My machine: </p>

<pre><code>&gt; sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)
</code></pre>

<p>My data: </p>

<pre><code>#Head of first six rows of the first six columns
&gt; head(Store4df)
     Age Gender HouseholdIncome MaritalStatus PresenceofChildren HomeOwnerStatus
1  55-64 Female         50k-75k        Single                 No             Own
2   &lt;NA&gt; Female            &lt;NA&gt;          &lt;NA&gt;               &lt;NA&gt;            &lt;NA&gt;
3   &lt;NA&gt;   Male            &lt;NA&gt;          &lt;NA&gt;               &lt;NA&gt;            &lt;NA&gt;
4   &lt;NA&gt;   Male            &lt;NA&gt;          &lt;NA&gt;               &lt;NA&gt;            &lt;NA&gt;
5    65+   Male        75k-100k        Single                 No             Own
6   &lt;NA&gt; Female            &lt;NA&gt;          &lt;NA&gt;               &lt;NA&gt;            &lt;NA&gt;
</code></pre>

<p>I have read other posts about the command, but none have solutions for <code>NA</code> values. I followed a link about <a href=""https://stackoverflow.com/questions/3384506/create-new-dummy-variable-columns-from-categorical-variable"">Creating new dummy variable columns from categorical variables</a>. I used the second suggestion and the data in binary form, but the code did not include the <code>NA</code> values. </p>

<pre><code>&gt; #Use model.matrix function to 
&gt; binary1 &lt;- model.matrix(~ factor(Store4df$HomeMarketValue) - 1)
&gt; #Find which rows have NA values
&gt; which(rowSums(is.na(binary1))==ncol(binary1))
# named integer(0)
&gt; #Get head of model.matrix of two columns with five rows
&gt; head(binary1, n=5)
   factor(Store4df$HomeMarketValue)100k-150k factor(Store4df$HomeMarketValue)150k-200k
1                                          0                                         0
2                                          0                                         0
3                                          1                                         0
4                                          0                                         0
5                                          0                                         0
</code></pre>

<p><strong>EDIT:</strong> I forgot to post that I have two types of categorical variables. One with categories and <code>NA</code> values, with another having <code>TRUE</code> and <code>NA</code> values. I got an error about putting the variables with <code>TRUE</code> and <code>NA</code> values into a <code>model.matrix</code>.</p>

<pre><code>&gt; model.matrix(~ -1 + . , data = Store4df)
#Error in `contrasts&lt;-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
  contrasts can be applied only to factors with 2 or more levels
</code></pre>

<p>Here's what the variable looks like:</p>

<pre><code>&gt; che &lt;- Store4df$Pets
&gt; summary(che)
   Mode    TRUE    NA's 
logical    3535    9628 
</code></pre>

<p>After putting one factor variable into <code>model.matrix</code>:</p>

<pre><code>&gt; data &lt;- model.matrix(~  Pets, data = Store4df)
&gt; summary(data)

  (Intercept)    PetsTRUE
 Min.   :1    Min.   :1  
 1st Qu.:1    1st Qu.:1  
 Median :1    Median :1  
 Mean   :1    Mean   :1  
 3rd Qu.:1    3rd Qu.:1  
 Max.   :1    Max.   :1  
</code></pre>

<p>How can I get the TRUE value replaced in columns 10 and 12:34? </p>
","<p>I don't think <code>model.matrix</code> can take an argument to detail how to treat missing data However, you can change the default options to <code>na.pass</code> thus keeping the missing values in the <code>model.matrix</code> call.</p>

<pre><code># create data with missing values
set.seed(1)
dat &lt;- data.frame(x=sample(letters[1:3],20,TRUE), y=rnorm(20), 
                                                  stringsAsFactors=FALSE)
dat[c(5,10,15),1] &lt;- NA

# set default options for handling missing data
options(na.action='na.pass')

# note that rows with missing data are retained
m &lt;- model.matrix(~ -1 + x + y, data=dat)

# return option to default
options(na.action='na.omit')
</code></pre>

<p>From <a href=""https://stackoverflow.com/questions/5616210/model-matrix-with-na-action-null"">here</a></p>
","25798366"
"Counting Hamming Distance for 8-bit binary Values in C Language","5290","","<p>I write a new program that compares 2 two digit unsigned integer. Compares by hamming distances. But my algorithm doesn't work perfectly. Can yo tell me what is wrong with this code :( THANKS A LOT!!</p>

<p>this is my counting method;</p>

<pre><code>int countHammDist(unsigned int n, unsigned int m)
{
int i=0;
unsigned int count = 0 ;
for(i=0; i&lt;8; i++){
if( n&amp;1 != m&amp;1 ) {
    count++;
    }
n &gt;&gt;= 1;
m &gt;&gt;= 1;

}
return count;
}
</code></pre>

<p>a and b 8 bit binaries.</p>

<pre><code> PrintInBinary(a);
 PrintInBinary(b);

 printf(""\n %d"", countHammDist(a,b));
</code></pre>

<p>let me show you output;</p>

<pre><code>Enter two unsigned integers (0-99): 55 64
Your choices are 55 and 64
Number A: 00110111
Number B: 01000000
Hamming distance is ; 5
</code></pre>
","<p>Put parantheses around n&amp;1 and m&amp;1.</p>

<pre><code>if ((n&amp;1) != (m&amp;1))
</code></pre>

<p><a href=""http://ideone.com/F7Kyzg"">http://ideone.com/F7Kyzg</a></p>

<p>This is because != is before &amp;: <a href=""http://www.swansontec.com/sopc.html"">http://www.swansontec.com/sopc.html</a></p>
","19825325"
"How to convert a binary value to ASCII in JAVA?","5267","","<p>This is a homework assignment that I can't wrap my head around.  I have to do it manually, so I can't use ""getBytes().""  Also, I have to convert to decimal format first, and then convert the decimal to ASCII (e.g. {0,1,1,0,0,0,1,0} = 98 in decimal format, which is a 'b').  I have arranged the binary code into an array, and want to use a for loop to traverse the array position by position.  However, I'm not sure I'm using the correct parameters for the for loop, and am not sure how to divide the code into bits of ""8.""  Another thing, how to I convert the decimal value to ASCII?  Should I just list out all the possible letters I know I will get, and then refer to them using an if-else loop?  Or could I just convert the decimal to a char?  Here is my code so far... (It's a bit messy, sorry)</p>

<pre><code>class Decoder
{
    public void findCode(Picture stegoObj)
    {
    Pixel pixTar = new Pixel(stegoObj,0,0);
    Pixel [] pixelArray = stegoObj.getPixels();
    int blueVal = 0;

    for(int length = 0; length &lt; pixelArray.length; length++)
    {
        blueVal = pixTar.getBlue();                
    }
    System.out.println(blueVal);
    stegoObj.explore();
    }

    public void decode(int [] binary)
    {
        int binaryLen = binary.length;
        int totVal = 0;
        int newVal = 0;
        int bitVal = 0;

        for(int x = binaryLen - 1; x &gt;= 0; x--)
        {
            bitVal = binary[x];
            int exp = x - (binaryLen - 1);
            totVal += (pow(bitVal, exp));
        }

        System.out.println(totVal);
     }
}
public class DecodeImage
{
    public static void main(String[] args)
    {
        Picture stegoObj = new Picture(""SecretMessage.bmp"");
        Decoder deco = new Decoder();
        int[] binArray =     {0,1,0,1,0,1,0,0,0,1,1,0,1,0,0,0,0,1,1,0,0,1,0,1,0,0,1,0,0,0,0,0,0,1,1,1,0,1,1,1,0,1,1,0,1,1,1,1,0,1,1,1,0,0,1,0,0,1,1,0,1,1,0,0,0,1,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,1,0,1,0,0,1,0,1,1,1,0,0,1,1,0,0,1,0,0,0,0,0,0,1,1,0,1,1,0,1,0,1,1,0,1,0,0,1,0,1,1,0,1,1,1,0,0,1,1,0,0,1,0,1,0,0,0,0,1,1,0,1,0,0,0,0,1,0,1,0};
        //int[] binArray = {0,1,1,0,0,0,1,0};
        //deco.findCode(stegoObj);
        deco.decode(binArray);        
    }
}
</code></pre>

<p>EDIT:</p>

<p>Okay, so I figured out this much, under the class Decoder, in the decode block, in the for loop:                                       </p>

<pre><code>for(int x = binaryLen - 1; x &gt;= 0; x--)
{
    bitVal = binary[x];
    preVal = bitVal * base;
    totVal += preVal;
    base = base * 2;
}
</code></pre>
","<p>You've got the right idea for <code>decode</code>.  I don't see why your code wouldn't work, although I don't see the <code>pow</code> implementation anywhere.</p>

<p>Decimal to ascii is easy, just cast the value to a char:</p>

<pre><code>int v = ...;       // decimal value
char c = (char)v;  // ascii value
</code></pre>
","15103478"
"Convert Intel HEX file to binary file","5257","","<p>I have a Intel HEX file and I want to have a binary file.
How, in python ?</p>

<p>I think use the <a href=""http://docs.python.org/library/binascii.html"" rel=""noreferrer"">binascii module</a> but I don't know what function is the most appropriate.
Thanks</p>
","<p>You may be interested in <a href=""http://packages.python.org/IntelHex/part1-1.html#motivation"">the IntelHex python lib</a>.</p>
","6758868"
"Binary Serialization of std::bitset","5255","","<p><code>std::bitset</code> has a <code>to_string()</code> method for serializing as a <code>char</code>-based string of <code>1</code>s and <code>0</code>s. Obviously, this uses a single 8 bit <code>char</code> for <em>each</em> bit in the bitset, making the serialized representation 8 times longer than necessary.<br>
I want to store the bitset in a binary representation to save space. The <code>to_ulong()</code> method is relevant only when there are less than 32 bits in my bitset. I have hundreds.<br>
I'm not sure I want to use <code>memcpy()</code>/<code>std::copy()</code> on the object (address) itself, as that assumes the object is a POD.</p>

<p>The API does not seem to provide a handle to the internal array representation from which I could have taken the address.</p>

<p>I would also like the option to deserialize the bitset from the binary representation.</p>

<p>How can I do this?</p>
","<p>This is a possible approach based on explicit creation of an <code>std::vector&lt;unsigned char&gt;</code> by reading/writing one bit at a time...</p>

<pre><code>template&lt;size_t N&gt;
std::vector&lt;unsigned char&gt; bitset_to_bytes(const std::bitset&lt;N&gt;&amp; bs)
{
    std::vector&lt;unsigned char&gt; result((N + 7) &gt;&gt; 3);
    for (int j=0; j&lt;int(N); j++)
        result[j&gt;&gt;3] |= (bs[j] &lt;&lt; (j &amp; 7));
    return result;
}

template&lt;size_t N&gt;
std::bitset&lt;N&gt; bitset_from_bytes(const std::vector&lt;unsigned char&gt;&amp; buf)
{
    assert(buf.size() == ((N + 7) &gt;&gt; 3));
    std::bitset&lt;N&gt; result;
    for (int j=0; j&lt;int(N); j++)
        result[j] = ((buf[j&gt;&gt;3] &gt;&gt; (j &amp; 7)) &amp; 1);
    return result;
}
</code></pre>

<p>Note that to call the de-serialization template function <code>bitset_from_bytes</code> the bitset size <code>N</code> must be specified in the function call, for example</p>

<pre><code>std::bitset&lt;N&gt; bs1;
...
std::vector&lt;unsigned char&gt; buffer = bitset_to_bytes(bs1);
...
std::bitset&lt;N&gt; bs2 = bitset_from_bytes&lt;N&gt;(buffer);
</code></pre>

<p>If you really care about speed one solution that would gain something would be doing a loop unrolling so that the packing is done for example one byte at a time, but even better is just to write your own bitset implementation that doesn't hide the internal binary representation instead of using <code>std::bitset</code>.</p>
","7463972"
"LC-3 How to print two digit number","5254","","<p>I have an LC-3 program that has a counter. I can print the counter to the screen using TRAP x21. However, if the counter number has two digits my program does not work.</p>

<p>Example: 9 will print perfectly, but not 19. </p>

<p>I am guessing that before I print my Register which contains the counter I need a loop, which will chop the number by dividing by 2 (same as I would in decimal by dividing by 10, but 2 in binary). Then I guess I would print digit1, digit0. I have a problem though, how do I divide in LC-3? Right shift? That seems too hard for this problem and beyond my knowledge.</p>

<p>Please help.</p>

<pre><code>    0010 000 000000011    ; R0 &lt;= x30 which is for  
    0001 000 000 0 00 010 ; R0 &lt;= R0 + R2 

    1111 0000 00100001    ; TRAP x21 
    1111 0000 00100101    ; TRAP x25 
    0000000000110000
</code></pre>
","<p>It only works with one digit because of your number->digit routine.  You're adding a number to the character '0', and obviously there's no character '11', etc.</p>

<p>You can find the maximal divisor by multiplying by ten (usually by repeated addition) until the divisor exceeds the number (then backing off to the previous value).  This will let you use Gareth's method, above.</p>
","11423540"
"Turn a count matrix into a binary existence matrix","5243","","<p>I have a data frame stores the possession of numbers of different kinds of fruits of different people. Like below</p>

<pre><code>    apple  banana  orange
Tim     3       0       2
Tom     0       1       1
Bob     1       2       2
</code></pre>

<p>Again, the numbers are the counts of fruits. How can I change it into a existence matrix which means if a person has one fruit, no matter how many he has, then the I record 1, if not, record 0. Like below</p>

<pre><code>    apple  banana  orange
Tim     1       0       1
Tom     0       1       1
Bob     1       1       1
</code></pre>
","<p>Here's your <code>data.frame</code>:</p>

<pre><code>x &lt;- structure(list(apple = c(3L, 0L, 1L), banana = 0:2, orange = c(2L, 
1L, 2L)), .Names = c(""apple"", ""banana"", ""orange""), class = ""data.frame"", row.names = c(""Tim"", 
""Tom"", ""Bob""))
</code></pre>

<p>And your matrix:</p>

<pre><code>as.matrix((x &gt; 0) + 0)
    apple banana orange
Tim     1      0      1
Tom     0      1      1
Bob     1      1      1
</code></pre>

<h2>Update</h2>

<p>I had no idea that a quick pre-bedtime posting would generate <a href=""https://stackoverflow.com/questions/14526429/turn-a-count-matrix-into-a-binary-existence-matrix/14526637#comment20256941_14526637"">any</a> <a href=""http://chat.stackoverflow.com/transcript/message/7380500#7380500"">discussion</a>, but the discussions themselves are quite interesting, so I wanted to summarize here:</p>

<p>My instinct was to simply take the fact that underneath a <code>TRUE</code> and <code>FALSE</code> in R, are the numbers <code>1</code> and <code>0</code>. If you try (a not so good way) to check for equivalence, such as <code>1 == TRUE</code> or <code>0 == FALSE</code>, you'll get <code>TRUE</code>. My shortcut way (which turns out to take <strong>more time</strong> than the <em>correct</em>, or at least <em>more conceptually correct</em> way) was to just add <code>0</code> to my <code>TRUE</code>s and <code>FALSE</code>s, since I know that R would coerce the logical vectors to numeric.</p>

<p>The correct, or at least, more appropriate way, would be to convert the output using <code>as.numeric</code> (I think that's what @JoshO'Brien intended to write). BUT.... unfortunately, that removes the dimensional attributes of the input, so you need to re-convert the resulting vector to a matrix, which, as it turns out, is <strong><em>still</em></strong> faster than adding <code>0</code> as I did in my answer.</p>

<p>Having read the comments and criticisms, I thought I would add one more option---using <code>apply</code> to loop through the columns and use the <code>as.numeric</code> approach. That is <em>slower</em> than manually re-creating the matrix, but <em>slightly faster</em> than adding <code>0</code> to the logical comparison.</p>

<pre><code>x &lt;- data.frame(replicate(1e4,sample(0:1e3)))
library(rbenchmark)
benchmark(X1 = {
            x1 &lt;- as.matrix((x &gt; 0) + 0)
          },
          X2 = {
            x2 &lt;- apply(x, 2, function(y) as.numeric(y &gt; 0))
          },
          X3 = {
            x3 &lt;- as.numeric(as.matrix(x) &gt; 0)
            x3 &lt;- matrix(x3, nrow = 1001)
          },
          X4 = {
            x4 &lt;- ifelse(x &gt; 0, 1, 0)
          },
          columns = c(""test"", ""replications"", ""elapsed"", 
                      ""relative"", ""user.self""))
#   test replications elapsed relative user.self
# 1   X1          100 116.618    1.985   110.711
# 2   X2          100 105.026    1.788    94.070
# 3   X3          100  58.750    1.000    46.007
# 4   X4          100 382.410    6.509   311.567

all.equal(x1, x2, check.attributes=FALSE)
# [1] TRUE
all.equal(x1, x3, check.attributes=FALSE)
# [1] TRUE
all.equal(x1, x4, check.attributes=FALSE)
# [1] TRUE
</code></pre>

<p>Thanks for the discussion y'all!</p>
","14526637"
"Algorithms question: flipping columns","5219","","<p>Suppose that we are given an m x n grid of zeros and ones and want to transform the grid so that the maximum number of rows are composed solely of ones.  The only operation we are allowed to perform on the grid is picking some column and flipping all of the zeros and ones in that column.  We are also given some integer k and must perform <strong>exactly</strong> k columns flips.  Given the grid and the value of k, how do we determine which columns to flip to maximize the number of rows that are all ones?</p>

<p>I'm thinking something dynamic would need to be done, but I'm not able to arrive at a good answer. Can someone help out?</p>
","<p>Let's begin by thinking about an important detail of the problem: if two rows contain a column that differ across the rows (for example, in one row it's a zero and in one row it's a one), then there is no possible way to make both rows all ones.  To see this, suppose that row x has a zero in some column and row y has a one in that column.  Then if we don't flip that column, row x can't be all ones, and if we do flip the column then row y can't be all ones.  Consequently, if we take a look at the original matrix and try to think about what rows we are going to make all ones, we are essentially just going to pick some set of rows that are all equal to one another.  Our goal is then to pick the set of identical rows that is as large as possible and can be made into all ones using exactly k flips.  Let's say that a row that can be made into all ones using exactly k flips is a ""candidate row."". Then we just need to find the candidate row in the matrix that appears the greatest number of times.</p>

<p>The actual algorithm for doing this depends on whether or not we are allowed to flip the same column twice.  If we aren't, then a candidate row is one that has exactly k zeros in it.  If we can flip the same column multiple times, then this is a bit trickier.  To make the row all ones, we would need to convert each zero to a one, then would need to keep spending the remaining flips flipping the same column twice to avoid changing any one to a zero.  This is true if the difference between k and the number of zeros in the row is a nonnegative even number.</p>

<p>Using this, we get the following algorithm:</p>

<ol>
<li>Maintain a hash table mapping from candidate rows to their frequency.</li>
<li>For each row:

<ol>
<li>Count the number or zeros in the row.</li>
<li>If the difference between k and this number is a nonnegative even number, update the hash table by incrementing the frequency of this particular row.</li>
</ol></li>
<li>Find the candidate row in the hash table with the greatest total frequency.</li>
<li>Output the frequency of that row.</li>
</ol>

<p>Overall, on an m x n matrix (m rows, n columns), we visit each row once.  During the visit, we do O(n) work to count the number of zeros, then O(1) work to see if it is valid.  If so, it takes an expected O(n) time to update the hash table, since the hashing step takes O(n) time to hash the row.  This means that we spend O(mn) time filling in the table.  Finally, the last step takes time O(m) to find the max frequency row, for a net runtime of O(mn), which is linear in the size of the input.  Moreover, this is asymptotically optimal, since if we spent less time than this we couldn't look at al, the matrix elements!</p>

<p>Hope this helps!  This is a cool problem!</p>
","7118342"
"Regex Binary multiple of 4","5215","","<p>How can I write a Reg-ex Expression to check whether a string is a binary multiple of 4? I am not good at making DFA and finding expressions. </p>
","<p>A multiple of 4 in binary is any binary number that ends with <code>00</code>, so this regexp should do it:</p>

<pre><code>^[10]*00$
</code></pre>

<p>If you mean a multiple of 4 in decimal, I wouldn't do that with a regexp, except perhaps to verify that it's a number. Then I'd parse it and check whether <code>number % 4</code> is zero.</p>
","19305090"
"Convert an image from CFHTTP filecontent to binary data with Coldfusion","5198","","<p>I'm trying to convert an image (jpg) loaded via <code>cfhttp</code> to binary data. I can't use <code>cffile action=""readBinary""</code> as it is not a local file.</p>
","<p>Here's how I handle this, and I use this to grab and process hundreds of images a day with ColdFusion 8.</p>

<pre><code>&lt;cfhttp
    timeout=""45""
    throwonerror=""false""
    url=""http://domain/image.jpg""
    method=""get""
    useragent=""Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.8.1.12) Gecko/20080201 Firefox/2.0.0.12""
    getasbinary=""yes""
    result=""local.objGet""
&gt;

&lt;cfset local.objImage = ImageNew(local.objGet.FileContent)&gt;
</code></pre>

<p>Once you have the image object you can then do whatever you want with it. Save it to disk, resize, you name it :). I've obviously left out all of my error checking (200 status codes, is it an image, etc), but this should get you started.</p>
","1537433"
"Why is 0x00000100 = 256?","5193","","<p>Shouldn't 0x00000100 = 4.</p>

<p>I understand that 0x00000001 = 1 since 2^0 and 0x00000010 = 2 since 2^1. What is wrong with my thinking?</p>

<pre><code>initVariable(&amp;variable1, ""variable1"", ""1, 2, 3"", 0x00000100);

assertIntegerEquals(variable1.address, 4); // 0x00000100 = 4?
</code></pre>

<p>My assertion fails because it says that 256 != 4 </p>
","<p>Numbers that begin with <code>0x</code> are interpreted as hexadecimal (base 16) in C.</p>

<p>So <code>0x10 == 16</code>, and <code>0x100 == 256</code>, <code>0x10000 == 65536</code>, etc.</p>

<p>Powers of two are:</p>

<ul>
<li>2<sup>0</sup> = 0x1</li>
<li>2<sup>1</sup> = 0x2</li>
<li>2<sup>2</sup> = 0x4</li>
<li>2<sup>3</sup> = 0x8</li>
<li>2<sup>4</sup> = 0x10</li>
<li>2<sup>5</sup> = 0x20</li>
<li>2<sup>6</sup> = 0x40</li>
<li>2<sup>7</sup> = 0x80</li>
</ul>
","20102802"
"Efficient bitwise operations for counting bits or find the right|left most ones","5188","","<p>Given an unsigned int, I have to implement the following operations :</p>

<ol>
<li>Count the number of bits set to 1</li>
<li>Find the index of the left-most 1 bit</li>
<li>Find the index of the righ-most 1 bit</li>
</ol>

<p>(the operation should not be architecture dependents).</p>

<p>I've done this using bitwise shift, but I have to iterate through almost all the bits(es.32) .
For example, counting 1's:</p>

<pre><code>unsigned int number= ...;
while(number != 0){
    if ((number &amp; 0x01) != 0)
        ++count;
    number &gt;&gt;=1;
}
</code></pre>

<p>The others operation are similar.</p>

<p>So my question is: is there any faster way to do that?</p>
","<p>If you want the <em>fastest</em> way, you will need to use non-portable methods.</p>

<p><strong>Windows/MSVC:</strong></p>

<ul>
<li><a href=""http://msdn.microsoft.com/en-us/library/wfd9z0bb%28v=vs.80%29.aspx"" rel=""noreferrer"">_BitScanForward()</a></li>
<li><a href=""http://msdn.microsoft.com/en-us/library/fbxyd7zd%28v=vs.80%29.aspx"" rel=""noreferrer"">_BitScanReverse()</a></li>
<li><a href=""http://msdn.microsoft.com/en-us/library/bb385231.aspx"" rel=""noreferrer"">__popcnt()</a></li>
</ul>

<p><strong>GCC:</strong></p>

<ul>
<li><a href=""http://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html"" rel=""noreferrer"">__builtin_ffs()</a></li>
<li><a href=""http://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html"" rel=""noreferrer"">__builtin_ctz()</a></li>
<li><a href=""http://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html"" rel=""noreferrer"">__builtin_clz()</a></li>
<li><a href=""http://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html"" rel=""noreferrer"">__builtin_popcount()</a></li>
</ul>

<p>These typically map directly to native hardware instructions. So it doesn't get much faster than these.</p>

<p>But since there's no C/C++ functionality for them, they're only accessible via compiler intrinsics.</p>
","9093395"
"Reading 16-bit integers from binary file c++","5178","","<p>I'm not sure if I'm doing this right so I want to check my code. it works but I'm not sure its working right. I need it to read the binary file, and store the 16 bit integers in an array of ints that is the exact size needed. I tried to do <code>sizeof(storage[i])</code> so I could see if I was storing 16 bits but it says 32 (I'm guessing because int automatically allocates 4 bytes? </p>

<pre><code>        void q1run(question q){
        int end;
        std::string input = q.programInput;
        std::ifstream inputFile (input.c_str(), ios::in | ios::binary);                     //Open File
        if(inputFile.good()){                                       //Make sure file is open before trying to work with it
                                                                    //Begin Working with information
           cout &lt;&lt; ""In File:  \t"" &lt;&lt; input &lt;&lt; endl;
           inputFile.seekg(0,ios::end);
           end=inputFile.tellg();
           int numberOfInts=end/2;
           int storage[numberOfInts];
           inputFile.clear();
           inputFile.seekg(0);
           int test = 0;


           while(inputFile.tellg()!=end){       
               inputFile.read((char*)&amp;storage[test], sizeof(2));
               cout &lt;&lt; ""Currently at position"" &lt;&lt; inputFile.tellg() &lt;&lt; endl;
               test++;
           }

           for(int i=0;i&lt;numberOfInts;i++){
               cout &lt;&lt; storage[i] &lt;&lt; endl;
           }
       }else{
           cout &lt;&lt; ""Could not open file!!!"" &lt;&lt; endl;
      }
 }
</code></pre>

<p>EDIT:::::::::::::::::::::::::::::::::::::::::::::;</p>

<p>I changed the read statement to:</p>

<pre><code>      inputFile.read((char*)&amp;storage[test], sizeof(2));
</code></pre>

<p>and the array to type <code>short</code>. now Its pretty well working except the output is a little strange:</p>

<pre><code>      In File:        data02b.bin
      8
      Currently at position4
      Currently at position8
      10000
      10002
      10003
      0
</code></pre>

<p>I'm not sure what's in the .bin file, but I'm guessing the 0 shouldn't be there. lol</p>
","<p>Yes, int is 4 bytes (on 32-bit x86 platform).</p>

<p>You have two problems:</p>

<ol>
<li>As Alec Teal correctly mentioned in comment, you have your storage declared as int, which means 4 bytes. Not a problem, really - your data will fit.</li>
<li>Actual problem: your line which is reading the file: <code>inputFile.read((char*)&amp;storage[test], sizeof(2));</code> is actually reading 4 bytes, because 2 is integer, so <code>sizeof(2)</code> is 4. You don't need <code>sizeof</code> there.</li>
</ol>
","20526797"
"Convert uint8 value of a pixel in the grayscale image to binary value in matlab","5173","","<p>I have an grayscale image, in grayscale images, each pixel have a uint8 value. for example when i use <code>myImage(2, 3)</code> , then i received a value between 0 to 255 corresponding pixel value. now i want convert this value to a binary array of 8 bits. for example : if <code>myImage(2, 3)</code> is equivalent to 15, then i want converted value of this pixel be <code>00001111</code>.</p>
","<p><code>dec2bin(15, 8)</code> returns <code>00001111</code>, as a string. Here, 8 specifies the minimum length of the binary string.</p>

<p>See <a href=""http://www.mathworks.nl/help/matlab/ref/dec2bin.html"" rel=""nofollow"">here</a> for full info.</p>

<p>If you want it as a matrix, you could do something like this:</p>

<pre><code>binstring = dec2bin(pixelVal, 8);
m = str2num(binstring(:))';
</code></pre>

<p>Which, with a pixelVal of 15, results in <code>m = [0 0 0 0 1 1 1 1]</code>.</p>
","12716156"
"Converting hex to binary and one and two's complement in 16 bits","5165","","<p>I am trying to convert FFAD (hex) to a decimal value and then do one and two's complement on it. FFAD is represented as a 16 bit integer.
When I convert FFAD to base 2 I get 1111111110101101.</p>

<p>My problem is how I know if it is a negative number or not?</p>

<p>I have the binary, now to do ones complement normally I would change the last bit from a 0 to a 1 and then flip all the bits, but as a 16 bit integer I don't have any more available bits. Since the 16th bit is a 1 does that mean it is a negative number? How would I do the complement of that? I am just all around confused with this problem and any pointers would be greatly appreciated.</p>
","<p>Its negative because it is left padded with ones.  Left padding with zeros would indicate a positive number.  For example, here are the decimal values for three bit numbers:</p>

<ul>
<li>011 = 3</li>
<li>010 = 2</li>
<li>001 = 1</li>
<li>000 = 0</li>
<li>111 = -1</li>
<li>110 = -2</li>
<li>101 = -3</li>
<li>100 = -4</li>
</ul>

<p>Notice, numbers that are left padded with ones are negative and numbers that are left padded with  zeros are positive.</p>

<p>Standard procedure for 2's compliment is to negate your bits, and then add 1.</p>

<p>1111111110101101 becomes 0000000001010010.  Then you add 1 to get 0000000001010011.</p>
","7654427"
"Text to binary conversion and writing to file. help please","5153","","<p>I'm trying to convert plain text data to binary format so that it becomes non-redable.
The data needs to be written to a file. The conversion works if I print it in console window, and cannot read original text.
However, when it is written to a file, the same original text appears.
How can I write this binary data to a file, without encrypting it, but making it non-readable?</p>

<p>This file, later needs to be processed by another third party tool which accepts binary data. This is why I cannot encrypt it using my own algo.</p>

<p>This is my code:</p>

<pre><code>import java.io.*;
import java.lang.*;
public class convert{
public static void main( String args[] ){
String s= ""This is text"";
try{
File file= new File(""test.php"");
file.createNewFile();
FileWriter fw= new FileWriter( file.getName(), true );
BufferedWriter bw= new BufferedWriter( fw );

byte[] b= s.getBytes();
for(int x=0; x&lt;b.length; x++){
byte c=b[x];
bw.write( c );
System.out.println(c);
}

bw.close();
}catch( Exception e ){ e.printStackTrace(); }
}//main
}//class
</code></pre>
","<p>Plain text is in itself a binary format, where each byte is interpreted as a character (or other variants, depending on assumed or specified encoding, e.g. UTF-8, UTF-16...).</p>

<p>This means that if you write an ASCII character as a byte to a file, it will look identical and will be readable by anyone. In fact, a lot of binary file formats still save strings as normal bytes, which means they can be read when opened in a hex editor, such as here:
<img src=""https://i.stack.imgur.com/ma2vl.png"" alt=""hex editor""></p>

<p>What you will need to do to make it unreadable is to serialize it into some common format that is not readable. Normal serialization in Java is unfortunately readable, but you can check <a href=""http://www.ibm.com/developerworks/java/library/j-5things1/index.html#N101BB"" rel=""nofollow noreferrer"">here</a> for advice on how to obscure it. You can also use ZIP or similar compression algorithms as well.</p>

<p>Another, more hacky way, is to shift all your character bytes by some known value. This will result in them becoming a different character and it will be unreadable. This can be seen as a very basic <a href=""http://en.wikipedia.org/wiki/Caesar_cipher"" rel=""nofollow noreferrer"">Caesar Chipher</a>.</p>

<p>But in the end, all that matters is which formats your target program is able to read.</p>
","15016750"
"unicode to binary?","5122","","<p>In Javascript, how can I convert BMP unicode characters to binary (and back)?</p>

<p>I can't seem to find any built-in string method <code>binaryCharCodeAt()</code> does something like that exist?</p>

<p>If not, my guess as to how to do it manually would be to create an array containing for example <code>[00001111], [00001110], [00001100]</code> and so on...</p>

<p>Then to get binary, I could do <code>myArray[String.charCodeAt(j)]</code></p>

<p>Then to go from binary to unicode, I could search the array for a binary string, returning its position in the array, and put that into <code>String.fromCharCode()</code></p>

<p>In this case, these binary codes are arbitrarily assigned, and arent the correct ones for each character. But thats ok.. (although correct would be preferred) I just need any binary.</p>

<p>The problem I foresee is, to search an array containing 65000+ items, hundreds or thousands of times, could end up costing a lot of processing time. </p>

<p>So, is there any pre-existing method or library, or can you suggest a better way to do this manually?</p>
","<p>Do note that it is not totally correct to say ""to binary and back"", because unicode characters do not need to have a unique binary representation (it depends on the encoding, e.g. UTF-8). However I believe most of the UTF-... encodings are backwards-compatible with each other in terms of binary encodings.</p>

<p>But since you stated that you don't care what encoding you are using, you can do exactly as Kolink said (his answer was improperly downvoted, but was also not complete):</p>

<p><em>edit:</em> As Esailija points out, the OP was only interested in basic multilingual plane characters, which only have one codepoint. The below code is overkill, though will still work on both BMP and non-BMP codepoints.</p>

<p><code>""some string"".charCodeAt</code> gives you the hex of the codepoints of some encoding. In my case it is UTF-16:</p>

<pre><code>""🃁"".charCodeAt(0)==55356
""🃁"".charCodeAt(1)==56513
</code></pre>

<p>In UTF-16 this is <code>0xF0 0x9F 0x83 0x81</code> (<code>f09f8381</code>), or ""\uD83C\uDCC1"":</p>

<pre><code>""\uD83C\uDCC1""==""🃁""
</code></pre>

<p>You cannot just assume that charCodeAt will give you the number you want without some amount of work. Unicode is a variable-width encoding. Therefore you can do the following to get a self-consistent result.</p>

<pre><code>var UTF_BITS = 16;

function padLeftTo(string, padChar, numChars) {
    return (new Array(numChars-string.length+1)).join(padChar) + string;
}

function unicodeToBinary(char) {
    return char.split('').map(function(codepoint) {
        return padLeftTo(codepoint.charCodeAt(0).toString(2), 0, UTF_BITS);
    }).join('').split('').map(function(char){return parseInt(char)});
    //         ^^^^( ignore this part if you just want a string )^^^^
}

function binaryToUnicode(binaryList) {
    var codepointsAsNumbers = [];
    while( binaryList.length&gt;0 ){
        var codepointBits = binaryList.slice(0,UTF_BITS);
        binaryList = binaryList.slice(UTF_BITS);
        codepointsAsNumbers.push( parseInt(codepointBits.join(''),2) );
    }
    return String.fromCharCode.apply(this,codepointsAsNumbers);
}
</code></pre>

<p>Demo:</p>

<pre><code>&gt; unicodeToBinary(""🃁"")
[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1]

&gt; binaryToUnicode(unicodeToBinary(""🃁""))
""🃁""
</code></pre>

<p>Do note that since you didn't say what your use-case was, binary might not be really what you want. For example if you are content with unique identifiers, you could use the strings themselves, or hex-string or even integer representations. It is much more likely you want a simpler representation.</p>

<p>complete sidenote: If you are planning to use an object as a lookup table, you can just use the original original string ""🃁"" as the key, e.g. <code>table={}; table[""🃁""]='something'; table[""🃁""]</code>. However because there are 95156 characters in the unicode 3.2 standard, I would not suggest doing any such thing in memory. You also said something which made me think you were not familiar with the performance of a lookup table: in case you were not aware, it takes O(1) time to do <code>table[...]</code>.</p>
","10321522"
"In Java why does this return a negative number when searching the array with binary search?","5117","","<p>I am a beginner in Java and is learning to use array. I understand that when using the binary search method of Array, it will return a negative number if the entry is not found. However, in the following code, I am getting a negative number returned for 9, 10, and 11.</p>

<p>I am wondering if anyone could help point out what I am doing wrong? thanks!      </p>

<pre><code>   String [] oneToSixteen = {""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"", ""11"", ""12"", ""13"", ""14"", ""15"", ""16""};

   System.out.println(""Searching for 7: ""+ Arrays.binarySearch(oneToSixteen, ""7""));
   System.out.println(""Searching for 8: ""+ Arrays.binarySearch(oneToSixteen, ""8""));
   System.out.println(""Searching for 9: ""+ Arrays.binarySearch(oneToSixteen, ""9""));
   System.out.println(""Searching for 10: ""+ Arrays.binarySearch(oneToSixteen, ""10""));
   System.out.println(""Searching for 11: ""+ Arrays.binarySearch(oneToSixteen, ""11""));
</code></pre>

<p>The output i get are:</p>

<pre><code>Searching for 7: 6
Searching for 8: 7
Searching for 9: -17
Searching for 10: -2
Searching for 11: -2
</code></pre>

<p>Any help would be much appreciated.</p>
","<p>This is because your array is an an array of <code>String</code> and not <code>int</code> and <strong>it is not sorted</strong>.</p>

<p>The documentation clearly states that the array being searched must be sorted and if it isn't the results are undefined.</p>

<p>To sort the array you can use the <a href=""http://docs.oracle.com/javase/6/docs/api/java/util/Arrays.html#sort%28java.lang.Object%5B%5D%29"" rel=""nofollow"">sort method</a> of the Arrays class.</p>
","10493493"
"How to read content of .EXE file in Java","5112","","<p><em>What are the possible options and the most appropiate for reading an executable file in Java.</em></p>

<p>I want produce the hexadecimal representation of an .exe file. Im thinking of reading the file in binary and then doing the conversion. But how can i read the .exe?</p>
","<p>1) read the file in as bytes. use</p>

<pre><code>
   BufferedInputStream( new FileInputStream( new File(""bin.exe"") ) )
</code></pre>

<p>2) convert each byte to hex format. </p>

<pre><code>
    static final String HEXES = ""0123456789ABCDEF"";
  public static String getHex( byte [] raw ) {
    if ( raw == null ) {
      return null;
    }
    final StringBuilder hex = new StringBuilder( 2 * raw.length );
    for ( final byte b : raw ) {
      hex.append(HEXES.charAt((b & 0xF0) >> 4))
         .append(HEXES.charAt((b & 0x0F)));
    }
    return hex.toString();
  }
</code></pre>
","4074694"
"why IEEE floating point number calculate exponent using a biased form?","5103","","<p>let's say, for the <em>float</em> type in c, according to the IEEE floating point specification, there are 8-bit used for the fraction filed, and it is calculated as first taken these 8-bit and translated it into an <strong>unsigned</strong> number, and then minus the BIASE, which is 2^7 - 1 = 127, and the result is an exponent ranges from -127 to 128, inclusive. But why can't we just treat  these 8-bit pattern as a signed number, since the resulting range is [-128,127], which is almost the same as the previous one. </p>
","<p>The purpose of the bias is so that the exponent is stored in <em>unsigned</em> form, making it easier to do comparisons. From <a href=""http://en.wikipedia.org/wiki/Exponent_bias"" rel=""noreferrer"">Wikipedia</a>:</p>

<blockquote>
  <p>By arranging the fields so the sign
  bit is in the most significant bit
  position, the biased exponent in the
  middle, then the mantissa in the least
  significant bits, the resulting value
  will ordered properly, whether it's
  interpreted as a floating point or
  integer value. This allows high speed
  comparisons of floating point numbers
  using fixed point hardware.</p>
</blockquote>

<p>So basically, a floating point number is:</p>

<pre><code>[sign] [unsigned exponent (aka exponent + bias)] [mantissa]
</code></pre>

<p><a href=""http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm"" rel=""noreferrer"">This website</a> provides excellent information about why this is good - specifically, compare the implementations of floating point comparison functions.</p>

<p>Also, no complete answer about floating point oddities can go without mentioning ""<a href=""http://docs.sun.com/source/806-3568/ncg_goldberg.html"" rel=""noreferrer"">What Every Computer Scientist Should Know About Floating-Point Arithmetic</a>."" It's long,  dense and a bit heavy on the math, but it's long dense <em>mathematical gold</em> (or something like that).</p>
","2612804"
"Converting MP3 to Binary","5102","","<p>I'm just wondering...is it possible to use Java to convert a .mp3 file into a text file of straight up binary (just 1's and 0's)?  I figure it would involve the usage of <code>AudioInputStream</code> and then some method to decode individual bytes, but can someone give me an idea on where to start?</p>

<p>Thanks!</p>
","<p>It's certainly possible, but you don't need to use a special audio stream.  What you're looking for is to turn any type of file into a file of 1 and 0 characters.  I have not tested this code, but the algorithm should be clear.</p>

<pre><code>FileInputStream fin = new FileInputStream(new File(path));
BufferedWriter bw = new BufferedWriter(new FileWriter(otherpath));
byte contents[] = new byte[100];
while (fin.read(contents)!= -1)
{
  for (byte b : contents)
    for (int x = 0; x &lt; 8; x++)
      bw.write(b&gt;&gt;x &amp; 1);
}
</code></pre>

<p>Edit:  If you just wanted to see what it looks like, you can open any kind of file with a hex editor.</p>
","9336376"
"Inserting a string into a Binary Search Tree C","5101","","<p>I need to insert strings into a binary search tree but each run through my insert function updates all the nodes and not just the appropriate one. 
Its required that each word placed in the binary search tree has the exact amount of memory allocated for it (+1 for the NULL pointer).</p>

<p>Here's the struct being used:</p>

<pre><code>typedef struct node_t{
   char *word;
   struct node_t *left, *right;
} node_t;
</code></pre>

<p>Here's how I am passing in the word:</p>

<pre><code>for(i=0; i&lt; original_words -1; i++)
{
    fscanf(ifp, ""%s"", y);
    head = insert(head, y);
}
</code></pre>

<p>And here's my insert function:</p>

<pre><code>node_t *insert(struct node_t *head, char *word)
{

if(strcmp(head-&gt;word, word) &gt; 0)
{

    if(head-&gt;left == NULL)
    {
        head-&gt;left = create_node(word);
    }
    else
    {
        head-&gt;left = insert(head-&gt;left, word);
    }
}

else
{
    if(head-&gt;right == NULL)
    {
        head-&gt;right = create_node(word);
    }
    else
    {
        head-&gt;right = insert(head-&gt;right, word);
    }
}

return head;

}
</code></pre>

<p>EDIT: Heres an example of the input file.</p>

<pre><code>4
-------
bravo
-------
alpha
-------
gamma
-------
delta
</code></pre>
","<p>Your answer (the <code>insert</code> function) assumes that <code>head</code> has already been defined on first call, it should start with the line:</p>

<pre><code>if (head == null) return create_node(word);
</code></pre>

<p>This will also save you from the need for the null lines in the code. I'm not sure that this is <em>the</em> issue, but it is one.</p>

<p>Perhaps more important: how does <code>create_node</code> set up <code>word</code>? If it's something like:</p>

<pre><code> new_node-&gt;word = word
</code></pre>

<p>Then all you are doing is creating a collection of pointers to the word pulled out of the file. It is quite possible that each reading of a word from the file reads the word into the same piece of memory, so all you are doing is collecting a tree of pointers to the same place in memory. It should be something like:</p>

<pre><code> new_node-&gt;word = malloc(strlen(word)+1);
 if (new_note-&gt;word == null) {FAIL MEMORY LOSS}
 strcpy(new_node-&gt;word, word);
</code></pre>
","15935604"
"Get length of bits used in int","5100","","<p>If you have the binary number 10110 how can I get it to return 11111? e.g a new binary number that sets all bits to 1 after the first 1, there are some likewise examples listed below:</p>

<p>101 should return 111 (3 bit length)
011 should return 11 (2 bit length)
11100 should be return 11111 (5 bit length)
101010101 should return 111111111 (9 bit length)</p>

<p>How can this be obtained the easiest way in Java? I could come up with some methods but they are not very ""pretty"".</p>
","<p>You could use this code:</p>

<pre><code>int setBits (int value)
{
    value |= (value &gt;&gt; 1);
    value |= (value &gt;&gt; 2);
    value |= (value &gt;&gt; 4);
    value |= (value &gt;&gt; 8);
    value |= (value &gt;&gt; 16);
    return value;
}
</code></pre>

<p>The idea is that leftmost 1 will get copied to all positions on the right.</p>

<p>EDIT: Also works fine with a negative <code>value</code>.  If you replace <code>int</code> with <code>long</code>, add one extra <code>|=</code> statement: <code>value |= (value &gt;&gt; 32)</code>.  In general, last shift must be a power of 2 that is at least half of <code>value</code> size in bits.</p>
","2891946"
"Using binary data in C++ string","5094","","<p>I am working with binary data coming from a service provider. I am subscribing to this data through HTTP request, using C++.
Every now and then, I get an HTML payload coming from this provider. The HTML payload is actually binary data, which looks like that:</p>

<p><code>! ¦ô¿ÂË¤ ÍÌL?  Àÿ  Àÿ¥ š™©@  Àÿ  Àÿ</code> or <code>! H·ô¿ÂË¤ ÍÌL?  Àÿ333?¥ š™©@  Àÿff¦@</code></p>

<p>I would like to do simulation using the data I get. To do so I hard code the data in a string and launch my program that will use those strings.</p>

<p><code>std::string input = ""! ¦ô¿ÂË¤ ÍÌL?  Àÿ  Àÿ¥ š™©@  Àÿ  Àÿ""</code></p>

<p>The first issue I have is that I have to escape all characters like <code>\n</code>. But I don't know how to escape <code>\0</code> for example. Also, I have this error message, which may be due to the fact that I don't escape the end of file character properly:</p>

<p><code>Error  3   fatal error C1004: unexpected end-of-file found</code></p>

<p>So the main question is: what does the end-of-file character looks like, and how can I escape it ?</p>

<p>Then, is there a linux command or a way to take binary data from a binary file, and escape all the special character with <code>\</code> so then I just copy paste it in my C++ code.</p>

<p>Eventually, I would like to put all the different payloads I have got, in a binary file, so I can launch my simulation using this file. The issue is that I don't know how to separate different payloads, since just going to the next line won't do the trick, because it will be interpreted as a random character (and the payload don't have a fix size). I don't know what kind of separator to use.</p>
","<p>You can write your payload in a file and read it using a <code>std::ifstream</code>. That would allow you to change the payload without having to recompile.</p>

<p>If you really want to store it as binary data, you can use an array of char, and initialize it like that :</p>

<pre><code>const unsigned char raw_data[] = {
    0x21, 0x20, 0xc2, 0xa6, 0xc3, 0xb4, 0xc2, 0xbf,
    0xc3, 0x82, 0xc3, 0x8b, 0xc2, 0xa4, 0x20, 0xc3,
    0x8d, 0xc3, 0x8c, 0x4c, 0x3f, 0x20, 0x20, 0xc3,
    0x80, 0xc3, 0xbf, 0x20, 0x20, 0xc3, 0x80, 0xc3,
    0xbf, 0xc2, 0xa5, 0x20, 0xc5, 0xa1, 0xe2, 0x84,
    0xa2, 0xc2, 0xa9, 0x40, 0x20, 0x20, 0xc3, 0x80,
    0xc3, 0xbf, 0x20, 0x20, 0xc3, 0x80, 0xc3, 0xbf,
    0x60, 0x20, 0x6f, 0x72, 0x20, 0x60, 0x21, 0x20,
    0x48, 0xc2, 0xb7, 0xc3, 0xb4, 0xc2, 0xbf, 0xc3,
    0x82, 0xc3, 0x8b, 0xc2, 0xa4, 0x20, 0xc3, 0x8d,
    0xc3, 0x8c, 0x4c, 0x3f, 0x20, 0x20, 0xc3, 0x80,
    0xc3, 0xbf, 0x33, 0x33, 0x33, 0x3f, 0xc2, 0xa5,
    0x20, 0xc5, 0xa1, 0xe2, 0x84, 0xa2, 0xc2, 0xa9,
    0x40, 0x20, 0x20, 0xc3, 0x80, 0xc3, 0xbf, 0x66,
    0x66, 0xc2, 0xa6, 0x40, 0x0a,
};

std::string data(
    reinterpret_cast&lt; const char* &gt;(raw_data),
    reinterpret_cast&lt; const char* &gt;(raw_data) + sizeof(raw_data));
</code></pre>

<p>Oh, BTW, I converted your payload to a buffer using the following simple Python code:</p>

<pre><code>#!/usr/bin/python

def convert_file(path, stream):
    data = open(path, 'rb').read()
    stream.write('const unsigned char raw_data[] = {')
    for i, char in enumerate(data):
        if i % 8 == 0:
            stream.write('\n   ')
        stream.write(' 0x%02x,' % (ord(char),))
    stream.write('\n};\n')

if __name__ == '__main__':
    import sys
    convert_file(sys.argv[1], sys.stdout)
</code></pre>
","4873514"
"In JAVA, what is the fastest way to convert RGB value of image to binary?","5057","","<p>I am trying to get the RGB value of any given pixel on an image into 12 bit binary, with each channel represented by 4 bits. For example, if a pixel has it's red channel at '255', or in binary ""11111111"". I wish to convert that to ""1111"".</p>

<p>I have got a code working, but it is rather slow, and I am wondering if there is a better way to do this.</p>

<p>Here's what i did. </p>

<ol>
<li>I use the method getRGB(x, y) to get the RGB value of one pixel.
e.g. -4278864</li>
<li>I convert that into 3 separate channels e.g. r 190 g 181 b 176</li>
<li>I divide that by 16 to get integer equivalent of 4 bit
representation</li>
<li>I convert the number to a binary.</li>
<li>Add 0's in front of the binary if the binary generated is less
than 4 bit.</li>
<li>Concatenate to a 12bit binary to represent 12bit color output. e.g. 101110111011</li>
</ol>

<p>Here are my code:</p>

<pre><code>import java.awt.Component;
import java.awt.image.BufferedImage;
import java.io.File;
import java.io.IOException;
import javax.imageio.ImageIO;

public class LoadImageApp extends Component {
    private static int[] rgbArray;
    private static double bitPerColor = 4.0;

    public static void main(String[] args) {

       BufferedImage img = null;
       String fileName = ""Image.jpg"";

       try {
           //Read in new image file
           img = ImageIO.read(new File(""src/""+fileName));
       } 
       catch (IOException e){
       }

       if (img == null) {
             System.out.println(""No image loaded"");
        } 
       else {

                //Get RGB Value
                int val = img.getRGB(500, 500);
                System.out.println(""rgbValue from getRGB is: "" + val);


                //Convert to three separate channels
                int a = (0xff000000 &amp; val) &gt;&gt;&gt; 24;
                int r = (0x00ff0000 &amp; val) &gt;&gt; 16;
                int g = (0x0000ff00 &amp; val) &gt;&gt; 8;
                int b = (0x000000ff &amp; val);

                System.out.println(""rgbValue in RGB is: "");
                System.out.println(""a "" + a + "" r "" + r + "" g "" + g + "" b "" + b);

                double power = Math.pow(2.0, bitPerColor);
                //Convert each channel to binary
                String r4bit = Integer.toBinaryString((int)(r/(power)));
                String g4bit = Integer.toBinaryString((int)(g/(power)));
                String b4bit = Integer.toBinaryString((int)(b/(power)));



                //Convert concatonate 0's in front to get desired bit count
                int rDifference = (int)bitPerColor - r4bit.length();
                int gDifference = (int)bitPerColor - g4bit.length();
                int bDifference = (int)bitPerColor - b4bit.length();


                for (int i = rDifference; i &gt; 0; i--){
                    r4bit=""0""+r4bit;}

                for (int i = gDifference; i &gt; 0; i--){
                    g4bit = ""0""+g4bit;}

                for (int i = bDifference; i &gt; 0; i--){
                    b4bit = ""0""+b4bit;}

                //Concatonate three channel together to form one binary
                String rgbValue = r4bit + g4bit + b4bit;

                System.out.println(""rgbValue in binary is: "" + rgbValue);


           }     
       }
}
</code></pre>

<p>It all works fine as as desired. However it's just really, really ugly, and slow, 2-3 seconds just to read one pixel. I was hoping to use the code to read a section of an image at a time, but i can imaging it taking AGES.</p>

<p>So any help would be very much appreciated.</p>

<p>Thanks in advance.</p>
","<p>Your original code (in hex) is <code>0x00rrggbb</code>.  You want to convert this to <code>0x00000rgb</code>. This will do it:</p>

<pre><code>int rgb24 = ....;
int rgb12 = (rgb24 &amp; 0x00f00000) &gt;&gt; 12 + 
            (rgb24 &amp; 0x0000f000) &gt;&gt; 8  + 
            (rgb24 &amp; 0x000000f0) &gt;&gt; 4;
</code></pre>

<p>If you wanted to ""round"" to the nearest color instead of truncating you could do this:</p>

<pre><code>int r = (rgb24 &amp; 0x00ff0000);
int g = (rgb24 &amp; 0x0000ff00);
int b = (rgb24 &amp; 0x000000ff);
r += (r &gt;= 0x00f00000) ? 0x00080000 : 0;
g += (g &gt;= 0x0000f000) ? 0x00000800 : 0;
b += (b &gt;= 0x000000f0) ? 0x00000008 : 0;
int rgb12 = (r &amp; 0x00f00000) &gt;&gt; 12 + (g &amp; 0x0000f000) &gt;&gt; 8 + (b &amp; 0x000000f0) &gt;&gt; 4;
</code></pre>

<p>This rounds up but only if the high-order 4 bits are not already 1111 (when you would risk overflow).</p>
","10544787"
"Do ghc-compiled binaries require GHC or are they self-contained?","5048","","<p>If a friend wants to run my Haskell binaries, does he have to first install Haskell, or can he immediately run the binary by itself?</p>

<p>Is the answer the same on Mac, Windows, and Linux?</p>
","<p>GHC does produce stand-alone binaries that do not require GHC itself to be installed, however they do link against some dynamic libraries, most notably <code>libgmp</code>. The remaining libraries are commonly found out of the box on most Linux systems. I believe the situation is similar on Windows.</p>

<p>You can check which dynamic libraries you depend on using <code>ldd</code> on Linux. Here's what I get on Ubuntu Natty for a simple Hello World program:</p>



<pre class=""lang-bsh prettyprint-override""><code>$ echo 'main = putStrLn ""Hello World""' &gt; Hello.hs                                                   
$ ghc --make Hello.hs                                                                     
[1 of 1] Compiling Main             ( Hello.hs, Hello.o )
Linking Hello ...
$ ldd Hello                                                                                
    linux-vdso.so.1 =&gt;  (0x00007fffe45ff000)
    libgmp.so.3 =&gt; /usr/lib/libgmp.so.3 (0x00007f8874cf9000)
    libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007f8874a74000)
    librt.so.1 =&gt; /lib/x86_64-linux-gnu/librt.so.1 (0x00007f887486b000)
    libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f8874667000)
    libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f88742d3000)
    libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f88740b4000)
    /lib64/ld-linux-x86-64.so.2 (0x00007f8874f7a000)
</code></pre>
","6390064"
"Can XmlDictionaryReader really handle binary XML? If not, what does?","5027","","<p>I'm trying to write a <a href=""https://stackoverflow.com/questions/1257627/is-there-a-fiddler-plugin-for-binary-xml"">debugging tool</a> that allows the user to view WCF's new binary XML format (application/soap +msbin1) in plain text.  Once I found the <a href=""http://msdn.microsoft.com/en-us/library/system.xml.xmldictionaryreader.createbinaryreader.aspx"" rel=""nofollow noreferrer"">XmlDictionaryReader</a> class I thought I'd be done in minutes, but it's not working as expected.  </p>

<pre><code>private string DecodeBinaryXML(byte[] binaryBuffer)
{
    if (binaryBuffer == null)
    {
        return """";
    }

    try
    {
        var doc = new XmlDocument();
        using (var binaryReader = XmlDictionaryReader.CreateBinaryReader(binaryBuffer, XmlDictionaryReaderQuotas.Max))
        {                    
            doc.Load(binaryReader);
            binaryReader.Close();
        }

        var textBuffer = new StringBuilder();
        var settings = new XmlWriterSettings()
        {
            // lots of code not relevant to the question
        };
        using (var writer = XmlWriter.Create(textBuffer, settings))
        {
            doc.Save(writer);
            writer.Close();
        }

        return textBuffer.ToString();
    }
    catch (Exception ex)
    {
        // just display errors in the text viewer
        return ex.ToString();
    }
}
</code></pre>

<p>Every single ""soap+msbin1"" sample I've found online or generated myself throws a parse exception at <strong>doc.Load()</strong>.</p>

<p>To see what was going on, I created a simple test app and attacked the problem from the other direction.</p>

<pre><code>// client
static void Main(string[] args)
{
    var binding = new CustomBinding(new TextMessageEncodingBindingElement(), 
                                    new HttpTransportBindingElement());            
    var proxy = ChannelFactory&lt;IService1&gt;.CreateChannel(binding, 
               new EndpointAddress(""http://ipv4.fiddler:25381/Service1.svc""));
    Console.WriteLine(proxy.Echo(""asdf""));
}

// shared interface
[ServiceContract()]
public interface IService1
{
    [OperationContract]
    string Echo(string input);
}

// server
public class Service1 : IService1
{
    public string Echo(string input)
    {
        return ""WCF says hi to: "" + input;
    }
}
</code></pre>

<p>Running it kicks off an http request that looks like:</p>

<pre><code>&lt;s:Envelope xmlns:s=""http://www.w3.org/2003/05/soap-envelope"" 
            xmlns:a=""http://www.w3.org/2005/08/addressing""&gt;
  &lt;s:Header&gt;
     &lt;a:Action s:mustUnderstand=""1""&gt;http://tempuri.org/IService1/Echo&lt;/a:Action&gt;
     &lt;a:MessageID&gt;urn:uuid:21a33e81-bfab-424f-a2e5-5116101a7319&lt;/a:MessageID&gt;
     &lt;a:ReplyTo&gt;
        &lt;a:Address&gt;http://www.w3.org/2005/08/addressing/anonymous&lt;/a:Address&gt;
     &lt;/a:ReplyTo&gt;
     &lt;a:To s:mustUnderstand=""1""&gt;http://ipv4.fiddler:25381/Service1.svc&lt;/a:To&gt;
  &lt;/s:Header&gt;

  &lt;s:Body&gt;
      &lt;Echo xmlns=""http://tempuri.org/""&gt;
          &lt;input&gt;asdf&lt;/input&gt;
      &lt;/Echo&gt;
  &lt;/s:Body&gt;
&lt;/s:Envelope&gt;
</code></pre>

<p>I converted this XML <em>into</em> binary two different ways.  First, using XmlDictionaryWriter:</p>

<pre><code>$fs = [system.io.file]::Create(""c:\temp\soap.bin"")
$writer = [system.xml.xmldictionarywriter]::CreateBinaryWriter($fs)
$xml = [xml] (gc C:\temp\soap.xml)
$xml.Save($writer)
$writer.Close(); $fs.Close()
</code></pre>

<p>Then, using WCF and the same network sniffer:</p>

<pre><code>    @@ -1,7 +1,7 @@
     // client
     static void Main(string[] args)
     {
-        var binding = new CustomBinding(new TextMessageEncodingBindingElement(), 
+        var binding = new CustomBinding(new BinaryMessageEncodingBindingElement(), 
                                         new HttpTransportBindingElement()); 
</code></pre>

<p>Method #1 gave 397 bytes of binary-looking gunk.  Method #2 shows 169 bytes of very different binary gunk.  Apart from a few strings that appear in both outputs, I don't see a lot of similarity in the two encodings.  No wonder, then, that XmlDictionaryReader can't understand the output of a WCF service!</p>

<p>Is there a secret to decoding this format, or am I on the wrong path entirely?</p>
","<p>Got a promising response from Carlos Figueira @ MS.</p>

<blockquote>
  <p>WCF uses a ""static dictionary"" which encode some well-known strings into (small) ids. For example, the strings ""Envelope"", ""<a href=""http://www.w3.org/2003/05/soap-envelope"" rel=""nofollow noreferrer"">http://www.w3.org/2003/05/soap-envelope</a>"", ""<a href=""http://www.w3.org/2005/08/addressing"" rel=""nofollow noreferrer"">http://www.w3.org/2005/08/addressing</a>"" and so on are represented only as a few bytes. So to be able to parse the requests that are sent by WCF, you need to pass that dictionary (IXmlDictionary) to the XmlDictionaryReader.CreateBinaryReader method.</p>
  
  <p>The whole dictionary is documented at <a href=""http://msdn.microsoft.com/en-us/library/cc219175(PROT.10).aspx"" rel=""nofollow noreferrer"">http://msdn.microsoft.com/en-us/library/cc219175(PROT.10).aspx</a>. The code to read the request should look something like:</p>
</blockquote>

<pre><code>public class Post_e9208540_7877_4318_909d_92eb8490ab58
{
    static XmlDictionary dictionary;
    static XmlDictionary GetDictionary()
    {
        if (dictionary == null)
        {
            XmlDictionary temp = new XmlDictionary();
            dictionary = temp;
            temp.Add(""mustUnderstand"");
            temp.Add(""Envelope"");
            temp.Add(""http://www.w3.org/2003/05/soap-envelope"");
            temp.Add(""http://www.w3.org/2005/08/addressing"");
            ...
        }
        return dictionary;
    }
    public static void DecodeBinaryMessage(byte[] message)
    {
        XmlDictionaryReader reader = XmlDictionaryReader.CreateBinaryReader(message, 0, message.Length, GetDictionary(), XmlDictionaryReaderQuotas.Max);
        Console.WriteLine(reader.ReadOuterXml());
    }
} 
</code></pre>

<p>I'll update this answer with more details if it leads to a working solution.</p>

<p>edit: yup, works like a charm!  Only problem with Carlos' solution is that ReadOuterXml() doesn't seem to work.  Reading into an XmlDocument and then writing out a Stream allows much better control of the formatting anyway, so that's what I stuck with.</p>

<p>Note: replicating the dictionary in the MS spec takes about 500 lines of code.  I'd recommend copying mine unless you're a masochist - <a href=""http://tfstoys.codeplex.com/sourcecontrol/changeset/view/26191?projectName=tfstoys#499486"" rel=""nofollow noreferrer"">http://tfstoys.codeplex.com/sourcecontrol/changeset/view/26191?projectName=tfstoys#499486</a></p>
","1302800"
"Convert Hex String to Binary String - Java","5018","","<p>Ok so i want to convert a Hex string to a Binary String so that i can do some bit swaps and subs etc down the line and i come across what i thought was the answer on here <a href=""https://stackoverflow.com/questions/8640803/convert-hex-string-to-binary-string"">Convert hex string to binary string</a> but this caused me some problems.</p>

<pre><code>String hexToBinary(String hexadecimalString) {
    int i = Integer.parseInt(hexadecimalString, 16);
    String binaryString = Integer.toBinaryString(i);
    return binaryString;
}
</code></pre>

<p>However, for example if i passed in the hexadecimal string ""03"" it would only return a binary string of ""11"". Or if i were to pass in the hex string ""41"" it would return a binary string of ""1000001"". 
How can I make it so that it will always return a binary string of length 8 bits?
All help greatly appreciated in advance :)</p>

<p>Tried your suggestion of padding the binary string but it didn't work, this is what i tried, can you see what I've done wrong?</p>

<pre><code>String hexToBinary(String hexString) {
    int i = Integer.parseInt(hexString, 16);
    String binaryString = Integer.toBinaryString(i);
    String padded = String.format(""%8s"", binaryString.replace(' ', '0'));
    return padded;
}
</code></pre>
","<p>Use <a href=""http://docs.oracle.com/javase/7/docs/api/java/lang/String.html#format%28java.lang.String,%20java.lang.Object...%29"" rel=""nofollow"">String.format</a></p>

<p>Try this:</p>

<pre><code>String.format(""%8s"", Integer.toBinaryString(i)).replace(' ', '0')
</code></pre>
","29648246"
"C++ FILE readInt function? (from a binary file)","5007","","<p>Is there a function for FILE (fopen?) that allows me to just read one int from a binary file?</p>

<p>So far I'm trying this, but I'm getting some kind of error I can't see cause the program just crashes without telling me.</p>

<pre><code>void opentest()
{
    FILE *fp = fopen(""dqmapt.mp"", ""r"");
    int i = 0;
    int j = 0;
    int k = 0;
    int * buffer;
    if (fp)
    {
        buffer = (int *) (sizeof(int));

        i = (int) fread(buffer,1, (sizeof(int)), fp);
        fscanf(fp, ""%d"", &amp;j);
        fclose(fp);
    }

    printf(""%d\n"", i);
    printf(""%d\n"", j);
}
</code></pre>
","<p>Now that you have changed your question, let me ask one. What is the format of the file you are trying to read? </p>

<p>For a binary file there are some changes required how you open the file:</p>

<pre><code>/* C way */
FILE *fp = fopen(""text.bin"", ""rb""); /* note the b; this is a compound mode */

/* C++ way */
std::ifstream ifs(""test.txt"", ios::in | ios::binary);
</code></pre>

<p>Reading in the contents is easy. But remember, your file has 2 integers at the begining -- width, height which determine how many more to read i.e. another width * height number of integers. So, your best bet is to read the first two integers first. You will need to use two buffers -- one for the width and height and then depending on their value another one to read the rest of the file. So, lets read in the first two integers:    </p>

<pre><code>char buf[ 2 * sizeof(int) ]; /* will store width and height */
</code></pre>

<p>Read in the two integers:</p>

<pre><code>/* C way */
fread(buf, sizeof(int), 2, fp); /* the syntax changes, FILE pointer is last */

/* C++ way*/ 
ifs.read(buf, sizeof buf);
</code></pre>

<p>Now, the tricky part. You have to convert the stuff to double. This again depends on your system endianness -- whether a simple assignment works or whether a byte swapping is necessary. As another poster has pointed out <code>WriteInt()</code> writes integers in big-endian format. Figure out what system you are on. And then you can proceed further.</p>

<p><code>FILE</code> is a C datastructure. It is included in C++ for C compatibility. You can do this:</p>

<pre><code>/* The C way */
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main(void) {
   FILE *fp = fopen(""test.txt"", ""r"");
   int i = 0;
   if (fp) {
      fscanf(fp, ""%d"", &amp;i);
      fclose(fp);
   }
   printf(""%d\n"", i);
}
</code></pre>

<p>You can use the <code>std::ifstream</code> thing to open a file for reading. You have to read in the contents using some other incantation to read the file contents and extract the desired information out of it yourself.</p>

<pre><code>/* The C++ way */
#include &lt;fstream&gt;
#include &lt;iostream&gt;

int main() {
   std::ifstream ifs(""test.txt"");
   int i = 0;
   if (ifs.good()) {
      ifs &gt;&gt; i;
   }
   std::cout &lt;&lt; i &lt;&lt; std::endl;
}
</code></pre>

<p>Note you can use the C style functions in C++ as well, though this is the least recommended way:</p>

<pre><code>/* The C way in C++ */
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;

int main() {
   using namespace std;
   FILE *fp = fopen(""test.txt"", ""r"");
   int i = 0;
   if (fp) {
      fscanf(fp, ""%d"", &amp;i);
      fclose(fp);
   }
   printf(""%d\n"", i);
}
</code></pre>

<p>[<strong>Note:</strong> Both examples assume you have a text file to read from]</p>
","600010"
"how a source code is converted into 1's and 0's?","4993","","<p>computers do not understand anything except one's and zero's.But I want to know the details how a source code or an instruction set is converted into 1's and 0's.Is the exe file only contains 1's and 0's?</p>
","<p>Each type of operation in a  microprocessor's <a href=""http://en.wikipedia.org/wiki/Instruction_set"" rel=""noreferrer"">instruction set</a> is specified by an opcode, which is represented as a pattern of 1s and 0s. A <a href=""http://en.wikipedia.org/wiki/Compiler"" rel=""noreferrer"">compiler</a> or <a href=""http://en.wikipedia.org/wiki/Interpreter_(computing)"" rel=""noreferrer"">interpreter</a> translates code in a source language to <a href=""http://en.wikipedia.org/wiki/Machine_code"" rel=""noreferrer"">machine code</a> made up of those instructions. </p>

<p>For example, take this code, where a variable, <code>x</code>, is assigned the value of 50:</p>

<pre><code>x = 50;
</code></pre>

<p>The compiler might translate that to the following assembly language, where the AX register (for the <code>x</code> variable) is set with the value, 50 (in hexidecimal), using the <a href=""http://en.wikipedia.org/wiki/MOV_(x86_instruction)"" rel=""noreferrer"">MOV</a> instruction:</p>

<pre><code>mov ax, 0x32
</code></pre>

<p>If the opcode for <code>MOV</code> was <strong>0xA0</strong> and the code for the AX register was <strong>0xB</strong> then the machine code, in binary, would look like this:</p>

<pre><code>10100000 00001011 00110010
</code></pre>
","3617837"
"Index of lowest order bit","4991","","<p>I want to find the fastest way to get the index of the lowest order bit of a long long.  ie:</p>

<pre><code>00101001001000 -&gt; 3
</code></pre>

<p>Solutions involving looping and shifting are too slow.  ie:</p>

<pre><code>int i;
if(bits == 0ULL) {
  i = 64;
} else {
  for(i = 0;!(bits &amp; 1ULL);i++)
    bits &gt;&gt;= 1;
}
</code></pre>

<p>EDIT: Info on usage</p>

<p>The function that uses ffsll can't really reduce its usage, but here it is (simplified of course).  It just iterates through the indices and does something with them.  This function is perhaps the most widely used function in my whole application despite a lot of caching of its value.  It's a legal move generator in my <a href=""http://en.wikipedia.org/wiki/Alpha-beta_pruning"" rel=""noreferrer"">alpha-beta</a> search engine.</p>

<pre><code>while(bits){
  index = ffsll(bits);
  doSomething(index);
  index &amp;= index-1;
}
</code></pre>
","<p>Intel has specialized instructions for finding either lowest or highest order set bit. <a href=""http://siyobik.info/index.php?module=x86&amp;id=19"" rel=""nofollow noreferrer"">BSF</a> seems like what you need. as far as doing it in plain C, maybe the <a href=""http://graphics.stanford.edu/~seander/bithacks.html"" rel=""nofollow noreferrer"">bit twiddling hacks page</a> has what you need.</p>

<p>At the very least you could use a table of nibbles or bytes to speed things up. Something like this (demonstrated for int, but easily changeable to longlong as needed).</p>

<pre><code>/*
0000 - 0
0001 - 1
0010 - 2
0011 - 1
0100 - 3
0101 - 1
0110 - 2
0111 - 1
1000 - 4
1001 - 1
1010 - 2
1011 - 1
1100 - 3
1101 - 1
1110 - 2
1111 - 1
*/

int ffs(int i) {
    int ret = 0;
    int j = 0;
    static const int _ffs_tab[] = 
        { 0, 1, 2, 1, 3, 1, 2, 1, 4, 1, 2, 1, 3, 1, 2, 1 };

    while((i != 0) &amp;&amp; (ret == 0)) {
        ret = _ffs_tab[i &amp; 0x0f];

        if(ret &gt; 0) {
            break;
        }

        i &gt;&gt;= 4;
        j += 4;

        /* technically the sign bit could stay, so we mask it out to be sure */
        i &amp;= INT_MAX;
    }

    if(ret != 0) {
        ret += j;
    }

    return ret;
}
</code></pre>
","1478060"
"Angular : show image from REST Service","4987","","<p>After reseaches and tests... I still can't show an image form ReST API on my Angular App. I have images available on my ReST web service, why do I use a ReST service ? Because for accessing you need to be authenticated (I use oAuth 2 protocol), well... When I use POSTMan (ReST client very usefull) everything works great, the image is displayed without doing nothing. But when I try to display it with Angular after a $http it doesn't work...</p>

<p>Here are the headers received form the service :</p>

<p>Content-Length → 51756
Content-Type → image/jpeg; charset=binary
Server → Apache/2.4.9 (Win64) PHP/5.5.12
X-Powered-By → PHP/5.5.12</p>

<p>Here is my Angular code :</p>

<pre><code>var data64 = $base64.encode(unescape(encodeURIComponent(data)));
scope.src = 'data:image/jpeg;charset=binary;base64,' + data64;
</code></pre>

<p>and my HTML :</p>

<pre><code>&lt;img ng-src=""{{src}}"" border=""0"" /&gt;
</code></pre>

<p>For information I use angular-base64 (<a href=""https://github.com/ninjatronic/angular-base64"" rel=""nofollow"">https://github.com/ninjatronic/angular-base64</a>) for the encodage. Without ""unescape"" and ""encodeURIComponent"" I have an error, I've tried to remove white spaces but it still doesn't work...</p>

<p>Thank you :)</p>
","<p>Seems that this will not work since you tell the browser that the image data is base64 encoded, but you also transformed it with <code>unescape</code> and <code>encodeURIComponent</code>.</p>

<p>Why don't you fetch your image data into a binary data structure (requires a modern browser), instead of into a string:</p>

<pre><code>$http.get(req, {responseType: ""arraybuffer""}).
    success(function(data) {
        $scope.src = 'data:image/jpeg;base64,' + _arrayBufferToBase64(data);
    });
</code></pre>

<p><code>_arrayBufferToBase64</code> is defined <a href=""https://stackoverflow.com/questions/9267899/arraybuffer-to-base64-encoded-string"">here</a>.</p>

<hr>

<p>A different approach would be to install a request interceptor, recognize the image url and add the oauth headers for this case.</p>
","31539307"
"Using Binary Search to add to an ArrayList in order","4983","","<p>Hello everyone hoping you can help me here,</p>

<p>My problem is that I need to be able to search through an ArrayList using binary search and find where the correct place to add an object so that the list stays in order. I cannot use the collections sort as this is a homework. I have correctly implemented a boolean method that tells if the list contains an item you want to search for. That code is here:</p>

<pre><code>    public static boolean search(ArrayList a, int start, int end, int val){
    int middle = (start + end)/2;
    if(start == end){
        if(a.get(middle) == val){
            return true;
        }
        else{
            return false;
        }
    }
    else if(val &lt; a.get(middle)){
        return search(a, start, middle - 1, val);
    }
    else{
        return search(a, middle + 1, end, val); 
    }
}
</code></pre>

<p>What I need to do is use this method to see if the number already exists in the list and if that returns false then I need to be able to use another binary search to figure out where in the list the number (val) should go. Any help is greatly appreciated, thank you!!!</p>

<p>Justin</p>
","<p>Well instead of returning true or false, you can return the last index in your search. So if the value isn't in the List, then return the last index you visited, and see if the value is less than or larger than the current value at that index, and add the new value accordingly.</p>
","15467691"
"how to efficiently read a binary file into a vector C++","4976","","<p>I need to read a large binary file (~1GB) into a <code>std::vector&lt;double&gt;</code>. I'm currently using <code>infile.read</code> to copy the whole  thing into a <code>char *</code> buffer (shown below) and I currently plan to convert the whole thing into <code>doubles</code> with <code>reinterpret_cast</code>. surely there must be a way to just put the <code>doubles</code> straight into the <code>vector</code>?</p>

<p>I'm also not sure about the format of the binary file,  the data was produced in python so it's probably all floats </p>

<pre><code>ifstream infile(filename, std--ifstream--binary);

infile.seekg(0, infile.end);     //N is the total number of doubles
N = infile.tellg();              
infile.seekg(0, infile.beg);

char * buffer = new char[N];

infile.read(buffer, N);
</code></pre>
","<p>Assuming the entire file is double, otherwise this wont work properly.</p>

<pre><code>std::vector&lt;double&gt; buf(N / sizeof(double));// reserve space for N/8 doubles
infile.read(reinterpret_cast&lt;char*&gt;(buf.data()), buf.size()*sizeof(double)); // or &amp;buf[0] for C++98
</code></pre>
","28707981"
"Download binary file from Github using Java","4964","","<p>I'm trying to download this file (<a href=""http://github.com/downloads/TheHolyWaffle/ChampionHelper/ChampionHelper-4.jar"" rel=""noreferrer"">http://github.com/downloads/TheHolyWaffle/ChampionHelper/ChampionHelper-4.jar</a>) with the following method and it doesn't seem to work. I'm getting an empty/corrupt file.</p>

<pre><code>String link = ""http://github.com/downloads/TheHolyWaffle/ChampionHelper/ChampionHelper-4.jar"";
String fileName = ""ChampionHelper-4.jar"";

URL url = new URL(link);
URLConnection c = url.openConnection();
c.setRequestProperty(""User-Agent"", ""Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; .NET CLR 1.0.3705; .NET CLR 1.1.4322; .NET CLR 1.2.30703)"");

InputStream input;
input = c.getInputStream();
byte[] buffer = new byte[4096];
int n = -1;

OutputStream output = new FileOutputStream(new File(fileName));
while ((n = input.read(buffer)) != -1) {
    if (n &gt; 0) {
        output.write(buffer, 0, n);
    }
}
output.close();
</code></pre>

<p>But I can successfully download the following file from my dropbox (<a href=""https://dl.dropbox.com/u/13226123/ChampionHelper-4.jar"" rel=""noreferrer"">http://dl.dropbox.com/u/13226123/ChampionHelper-4.jar</a>) with the same method. </p>

<p>So somehow Github knows that I'm not a regular user trying to download a file. I already tried to change the user agent, but that didn't help either.</p>

<p>So how should I download a file that is hosted on my Github account using Java?</p>

<p>EDIT: I tried to use the apache commons-io for this but I get the same effect, an empty/corrupt file.</p>
","<p>This one do the work:</p>

<pre><code>public class Download {
   private static boolean isRedirected( Map&lt;String, List&lt;String&gt;&gt; header ) {
      for( String hv : header.get( null )) {
         if(   hv.contains( "" 301 "" )
            || hv.contains( "" 302 "" )) return true;
      }
      return false;
   }
   public static void main( String[] args ) throws Throwable
   {
      String link =
         ""http://github.com/downloads/TheHolyWaffle/ChampionHelper/"" +
         ""ChampionHelper-4.jar"";
      String            fileName = ""ChampionHelper-4.jar"";
      URL               url  = new URL( link );
      HttpURLConnection http = (HttpURLConnection)url.openConnection();
      Map&lt; String, List&lt; String &gt;&gt; header = http.getHeaderFields();
      while( isRedirected( header )) {
         link = header.get( ""Location"" ).get( 0 );
         url    = new URL( link );
         http   = (HttpURLConnection)url.openConnection();
         header = http.getHeaderFields();
      }
      InputStream  input  = http.getInputStream();
      byte[]       buffer = new byte[4096];
      int          n      = -1;
      OutputStream output = new FileOutputStream( new File( fileName ));
      while ((n = input.read(buffer)) != -1) {
         output.write( buffer, 0, n );
      }
      output.close();
   }
}
</code></pre>
","13442063"
"How can I convert a hex ASCII string to a signed integer","4951","","<p>Input = 'FFFF'                  # 4 ASCII F's</p>

<p>desired result ... -1 as an integer</p>

<p>code tried:</p>

<pre><code>hexstring = 'FFFF'
result = (int(hexstring,16))
print result #65535
</code></pre>

<p>Result: 65535</p>

<p>Nothing that I have tried seems to recognized that a 'FFFF' is a representation of a negative number.</p>
","<p>Python converts FFFF at 'face value', to decimal 65535 </p>

<pre><code>input = 'FFFF'
val = int(input,16) # is 65535
</code></pre>

<p>You want it interpreted as a 16-bit signed number.
The code below will take the lower 16 bits of any number, and 'sign-extend', i.e. interpret
as a 16-bit signed value and deliver the corresponding integer</p>

<pre><code>val16 = ((val+0x8000)&amp;0xFFFF) - 0x8000
</code></pre>

<p>This is easily generalized</p>

<pre><code>def sxtn( x, bits ):
     h= 1&lt;&lt;(bits-1)
     m = (1&lt;&lt;bits)-1
     return ((x+h) &amp; m)-h
</code></pre>
","14003981"
"Saving binary string to file in php sent from POST","4947","","<p>I have a drag and drop uploader for (.jpg,.ai,.pdf,.flv,.psd ....etc.)</p>

<p>I'm reading the file as binary and sending the string in a jquery post:</p>

<pre><code>function importZoneDrop(evt) {
    evt.stopPropagation();
    evt.preventDefault();

    var files = evt.dataTransfer.files; // FileList object.

    // files is a FileList of File objects. List some properties.
    for (var i = 0, f; f = files[i]; i++) {
        var start = 0;
        var stop = files[0].size - 1;
        var reader1 = new FileReader();
        var reader2 = new FileReader();
        var ext = f.name.substring(f.name.indexOf(""."")+1);
        if(ext == ""JPEG"" || ext == ""jpeg"" || ext == ""JPG""){
            ext =""jpg"";
        }

        reader1.onload = (function(theFile) {
            return function(e) {
              // Render thumbnail.
              $(""#import-drop-zone"").append('&lt;img src=""'+e.target.result+'"" /&gt;');
            };
         })(f);

        reader2.onloadend = function(evt) {
          if (evt.target.readyState == FileReader.DONE) { // DONE == 2
            $.post(""/process/upload.php"",{""blob"":evt.target.result,""extension"":ext},function(data){
                console.log(data);
            });
          }
        };

        reader1.readAsDataURL(f);
        var blob = f.slice(start, stop + 1);
        reader2.readAsBinaryString(f);
    }
  }
</code></pre>

<p>This works and send the file. Next Get the string and write it using file_put_contents:</p>

<pre><code>$extension = $_POST['extension'];
$file = $_POST['blob'];//sent from jquery post
$filePath = ""../_temp/monkey."".$extension;

file_put_contents($filePath,$file);
if(file_put_contents($filePath,$file)){
    echo json_encode(""it worked"");
}else{
    echo json_encode(""it failed"");
}
</code></pre>

<p>This will successfully write the file. But the file does not work, it's broke.</p>

<p>What am I doing wrong?</p>
","<p>You need to use <a href=""http://php.net/base64_decode"" rel=""nofollow""><code>base64_decode</code></a>.</p>

<pre><code>file_put_contents($filePath, base64_decode($file));
</code></pre>

<p>Note, you're currently writing the data twice. Don't.</p>

<pre><code>if (file_put_contents($filePath, base64_decode($file))) {
</code></pre>

<p>is fine</p>

<h2>Edit</h2>

<p>Also worth nothing that it's more efficient to upload the binary file directly, then you can skip <code>base64_decode</code>. Something like this:</p>

<pre><code>var xhr  = new XMLHttpRequest(),
    data = new FormData();

data.append(""file"", f); // You don't need to use a FileReader
// append your post fields

// attach your events
xhr.addEventListener('load', function(e) {});
xhr.upload.addEventListener('progress', function(e) {});

xhr.open('POST', '/process/upload.php', true);
xhr.send(data);
</code></pre>

<p>You can view the rest of the events <a href=""https://developer.mozilla.org/en-US/docs/DOM/XMLHttpRequest"" rel=""nofollow"">here</a> with some samples <a href=""https://developer.mozilla.org/en-US/docs/DOM/XMLHttpRequest/Using_XMLHttpRequest"" rel=""nofollow"">here</a>.</p>
","12497470"
"Writing Binary String to file","4939","","<p>I m getting a request, when i use <code>echo</code> it prints it out on the shell and everything is awesome. </p>

<p>I want to write human readable string to file.</p>

<p>When i try to write these messages to file. i see binary string.</p>

<p>like this:</p>

<pre><code>6^@8^@3^@7^@8^@1^@0^@,^@,^@1^@1^@b^@c^@d^@9^@0^@f^@-^@e^@3^@3^@a^@-^@4^@e^@0^@5^@-^@9^@e^@3^@d^@-^@5^@f^@a^@1^@8^@3^@4^@f^@d^@5^@e^@7^@,^@,^@:^@:^@1^@,^@M^@o^@z^@i^@l^@l^@a^@/^@5^@.^@0^@ ^@(^@W^@i^@n^@d^@o^@w^@s^@ ^@N^@T^@ ^@6^@.^@1^@;^@
 ^@W^@O^@W^@6^@4^@;^@ ^@r^@v^@:^@9^@.^@0^@.^@1^@)^@ ^@G^@e^@c^@k^@o^@/^@2^@0^@1^@0^@0^@1^@0^@1^@ ^@F^@i^@r^@e^@f^@o^@x^@/^@9^@.^@0^@.^@1^@,^@F^@i^@r^@e^@f^@o^@x^@,^@9^@.^@0^@,^@W^@i^@n^@d^@o^@w^@s^@,^@,^@0^@,^@0^@,^@0^@,^@0^@,^@0^@,^@,^@
 ^@:^@:^@1^@,^@ ^@1^@/^@2^@1^@/^@2^@0^@1^@2^@ ^@5^@:^@4^@5^@:^@5^@0^@ ^@P^@M^@
</code></pre>

<p>but i expect this:</p>

<pre><code>6837817,,01497aed-181b-4054-b68f-3b41b4e707fc,,::1,Mozilla/5.0 (Windows NT 6.1; WOW64; rv:9.0.1) Gecko/20100101 Firefox/9.0.1,Firefox,9.0,Windows,,0,0,0,0,0,, ::1, 1/21/2012 5:45:51 PM
</code></pre>

<p>ok i saw that there are methods like <code>pack</code> and <code>unpack</code> to get string from binary string but i failed.</p>

<pre><code>&lt;?php

$context = new ZMQContext();
$receiver = new ZMQSocket($context, ZMQ::SOCKET_PULL);
$receiver-&gt;bind(""tcp://*:5557"");

$fp = fopen('data.txt', 'w');

while(true){ 
$str = $receiver-&gt;recv();

echo $str.""\n"";

file_put_contents('foo.txt', $str);

//fwrite($fp, $str.""\n"");


}
fclose($fp);
?&gt;
</code></pre>

<p>How can i get this done? I just wanted to write the string to file:(</p>

<p>Also, is this an expensive operation?</p>
","<p>What you have there isn't binary data, but a different encoding for text. It's some form of <code>UCS-2</code> I'd say. So you can ""decode"" it with:</p>

<pre><code> $string = iconv(""UCS-2LE"", ""UTF-8"", $string);
 file_put_contents(...);
</code></pre>

<p>See <a href=""http://php.net/iconv"" rel=""nofollow""><code>iconv</code></a> and <a href=""http://en.wikipedia.org/wiki/UTF-16"" rel=""nofollow""><code>UCS-2</code></a>, <a href=""http://en.wikipedia.org/wiki/Byte_Order_Mark"" rel=""nofollow"">BOM</a> <code>FF FE</code>.</p>
","8958686"
"How to make SVN ADD ignore binaries","4931","","<p>Binaries (under Linux) don't have an extension so I cannot exclude them using patterns. Thus when I use <code>SVN add</code> to add a directory I will get something like</p>

<pre><code>$ svn add recursion_vector/
A         recursion_vector
A         recursion_vector/rec_vec.cxx
A         recursion_vector/rec_vec.h
A  (bin)  recursion_vector/rec_vec
</code></pre>

<p>Here <code>rec_vec</code> is the executable I would like to exclude. SVN obviously recognizes it as binary. Now can I tell Subversion to ignore all binary files?</p>
","<p>This is a bit verbose because it uses find:</p>

<p><code>find [TARGET-DIRECTORY] \( -executable -type f \) -prune -o -print | xargs svn add --depth empty</code></p>

<p>Passing the target-directory to find, find will recurse the directory printing out all the contents except for executable files (<code>\( -executable -type f \) -prune</code>).  Without <code>-type f</code> find would also prune directories since these usually have the execute bit or ""search bit"" set.</p>

<p>The <code>--depth empty</code> option on <code>add</code> tells svn not to itself recurse a file object, since find is handling the recursion.</p>

<p>If you like the result, you can put this in a shell function that would allow you to pass in arguments for <code>[TARGET-DIRECTORY]</code>.</p>

<p>Thank you,</p>

<p>Zachary</p>
","3026243"
"iPhone App Binary File to Source Code","4922","","<p>I just have a question about binary file in an iPhone app.</p>

<p>When an iPhone developer wants to submit their app to testers or App store they build the binary file of their appliction. My question is it possible to edit your app's binary to get the source code, or just simply edit the binary for someones purpose.</p>

<p>If it is posible how can I prevent it to happen.</p>
","<p>In general, getting source from compiled code is technically possible, but not to the extent you fear. Decompiling isn't usually done for a few reasons.</p>

<ul>
<li>One of the things a compiler is optimize a lot of different things in your application, e.g. unrolling some loops or inlining some functions. That would make a decompiled code very different from the source and harder to modify.</li>
<li>Symbols are generally lost when compiling. I don't know the process for every compiler (Especially not for iPhone apps), but I know Visual Studio keeps a separate database for debugging. Without that database, var UserPreferences would turn to _a or something along those lines.</li>
</ul>

<p>All that said, you can't completely keep someone from decompiling your code, but there's pretty much nothing you need to do to make it hard for them to get something useful.</p>
","1186318"
"Random access of a large binary file","4922","","<p>I have a large binary file (12&nbsp;GB) from which I want to assemble a smaller binary file (16&nbsp;KB) on the fly. Assume the file is on disk, and that the bytes for the smaller file are somewhat randomly distributed in the large binary file. What's the best and fastest way to do this? So far I've not been able to do better than about three minutes.</p>

<p>Things I've tried, which have more or less the same performance:</p>

<ol>
<li>Converting the file to the HDF5 format and using the C interface (slow).</li>
<li>Writing a small C program to fseek() through the file (slow).</li>
</ol>

<p>How can I randomly access this data really <em>fast</em>?</p>

<p>I want to get to less than a couple of seconds for the query.</p>
","<p>The answer is basically ""no"".</p>

<p>A single mechanical disk drive is going to take 10&nbsp;ms or so to perform a seek, because it has to move the disk head. 16000 seeks times 10 milliseconds per seek equals 160 seconds. It makes absolutely no difference how you write your code; e.g. mmap() is going to make no difference.</p>

<p>Welcome to the physical world, software person  :-).  You must improve the locality of your operations.</p>

<p>First, sort the locations you are accessing. Nearby locations in the file are likely to be nearby on disk, and seeking between nearby locations is faster than seeking randomly.</p>

<p>Next, your disk can probably read sequential data at around 100 megabytes/second; that is, it can read 1 megabyte sequentially in around the same time it takes to perform a seek. So if two of your values are less than 1 megabyte apart, you are better off reading <em>all of the data between them</em> than performing the seek between them. (But benchmark this to find the optimal trade-off on your hardware.)</p>

<p>Finally, a RAID can help with throughput (but not seek time). It can also provide multiple disk heads that can seek concurrently if you want to multi-thread your read code.</p>

<p>But in general, accessing random data is about the worst thing you can ask your computer to do, whether in memory or on disk. And the relative difference between sequential access and random access increases every year because physics is local. (Well, the physics we depend on here, anyway.)</p>

<p>[edit]</p>

<p><a href=""https://stackoverflow.com/questions/6651503/random-access-of-a-large-binary-file/6651752#6651752"">@JeremyP's suggestion</a> to use SSDs is a good one. If they are an option, they have an effective seek time of 0.1&nbsp;ms or so. Meaning you could expect your code to run 50-100 times faster on such hardware. (I did not think of this because I usually work with files in the 1&nbsp;TB range where SSDs would be too expensive.)</p>

<p>[edit 2]</p>

<p>As @FrankH mentions in a comment, some of my suggestions assume that the file is contiguous <em>on disk</em>, which of course is not guaranteed. You can help to improve this by using a good file system (e.g. XFS) and by giving ""hints"" at file creation time (e.g. use <a href=""http://pubs.opengroup.org/onlinepubs/9699919799/functions/posix_fallocate.html"" rel=""nofollow noreferrer"">posix_fallocate</a> to inform the kernel you intend to populate a large file).</p>
","6652922"
"Java converting negative binary back to integer","4907","","<p>I'm trying to convert an base 10 number to a base 2 and back to base 10. It works only for positive argument_decimal</p>

<pre><code>argument_binary = Integer.toBinaryString(argument_decimal);
back_converted_argument_decimal = Integer.valueOf(argument_binary, 2);
</code></pre>

<p>For argument_decimal beeing negative, I get ""java.lang.NumberFormatException: For input string: ""11111111111111111111111111111111""""</p>

<p>EDIT: here is what I do:</p>

<pre><code>latitude_binary = Integer.toBinaryString((int)(latitude_decimal * 1000000));   
back_converted_latitude_decimal =  Long.parseLong(latitude_binary, 2) / 1000000.0;
</code></pre>

<p>which gives me bad results like -1.1 being forth and back converted to 4293.867296</p>
","<p>Try  to go via a long:</p>

<pre><code>String binary = Integer.toBinaryString(-1);
long l = Long.parseLong(binary, 2);
int i = (int) l;
</code></pre>

<p>Tested, and working.</p>

<p>Why this works is because -1 is represented as a sequence of 32 bits 1 in system memory. When using the toBinaryString method, it creates a string using that exact representation. But, 32 bits of one is in fact equal to 2^32 - 1. That is too large for an int (4 bytes), because an int goes from [-2^31, 2^31-1]. This is because the most left bit is representing the sign. So to fix that overflow, first interpret that sequence of 1 and 0 characters as a Long. A long will do because the maximum value for a long is 2^63-1. Then convert the long to an int. This is done by simply taking the lower 32 bits.</p>

<hr>

<p>The bug in your code is that you didn't cast the Long.parseLong to an int. So this should work:</p>

<pre><code>lat_bin = Integer.toBinaryString((int)(lat_dec * 1000000));   
lat_dec_conv =  ((int) Long.parseLong(lat_bin, 2)) / 1000000.0;
</code></pre>
","14012142"
"How can I get the position of bits","4905","","<p>I have a decimal number which I need to convert to binary and then find the position of one's in that binary representation.</p>

<p>Input is 5 whose binary is <code>101</code> and Output should be </p>

<pre><code>1
3
</code></pre>

<p>Below is my code which only provides output as <code>2</code> instead I want to provide the position of one's in binary representation. How can I also get position of set bits starting from 1?</p>

<pre><code>public static void main(String args[]) throws Exception {
    System.out.println(countBits(5));
}

private static int countBits(int number) {
    boolean flag = false;

    if (number &lt; 0) {
        flag = true;
        number = ~number;
    }
    int result = 0;
    while (number != 0) {
        result += number &amp; 1;
        number = number &gt;&gt; 1;
    }
    return flag ? (32 - result) : result;
}
</code></pre>
","<p>Your idea of having <code>countBits</code> return the result, instead of putting a <code>System.out.println</code> inside the method, is generally the best approach.  If you want it to return a list of bit positions, the analogue would be to have your method return an array or some kind of List, like:</p>

<pre><code>private static List&lt;Integer&gt; bitPositions(int number) {
</code></pre>

<p>As I mentioned in my comments, you will make life a lot easier for yourself if you use <code>&gt;&gt;&gt;</code> and get rid of the special code to check for negatives.  Doing this, and adapting the code you already have, gives you something like</p>

<pre><code>private static List&lt;Integer&gt; bitPositions(int number) {
    List&lt;Integer&gt; positions = new ArrayList&lt;&gt;();
    int position = 1;
    while (number != 0) {
        if (number &amp; 1 != 0) {
            positions.add(position);
        }
        position++;
        number = number &gt;&gt;&gt; 1;
    }
    return positions;
}
</code></pre>

<p>Now the caller can do what it wants to print the positions out.  If you use <code>System.out.println</code> on it, the output will be <code>[1, 3]</code>.  If you want each output on a separate line:</p>

<pre><code>for (Integer position : bitPositions(5)) {
     System.out.println(position);
}
</code></pre>

<p>In any case, the decision about how to print the positions (or whatever else you want to do with them) is kept separate from the logic that computes the positions, because the method returns the whole list and doesn't have its own <code>println</code>.</p>

<p>(By the way, as Alex said, it's most common to think of the lower-order bit as ""bit 0"" instead of ""bit 1"", although I've seen hardware manuals that call the low-order bit ""bit 31"" and the high-order bit ""bit 0"".  The advantage of calling it ""bit 0"" is that a 1 bit in position N represents the value 2<sup>N</sup>, making things simple.  My code example calls it ""bit 1"" as you requested in your question; but if you want to change it to 0, just change the initial value of <code>position</code>.)</p>
","30430111"
"Reading and writing a malloc'd linked list from/to a binary file","4892","","<p>I need to do an assignment for a class I'm taking. 
It's a simple phonebook app in C, and i'm having a little trouble with it since I need to use some new stuff in the program and the deadline is pretty tight.</p>

<p>I looked around and found some answers, but a new one came up every time. :)</p>

<p>This is my (simplified) program:</p>

<pre><code>typedef struct record
{
    char fname[31];
    char lname[31];
    char tel[21];
    struct record *next;
} record;


record *new_entry(record *first, char *fname, char *lname, char *tel)
{
    record *new;
    new=(record*) malloc(sizeof(record));
    strcpy(new-&gt;fname, fname);
    strcpy(new-&gt;lname, lname);
    strcpy(new-&gt;tel, tel);
    new-&gt;next=first;
}


void fileopen (char *db_file)
{
    FILE *fp;  

    fp=fopen(db_file, ""rb"");
    if (fp==NULL) 
    {
        fp=fopen(db_file, ""wb"");
        fclose(fp);
        fp=fopen(db_file, ""r+b"");
    }
}



int main
{
 char db[51];
 record *next = NULL;

 printf(""File:           ""); scanf(""%s, db);
 fileopen(db);
 printf(""First name:     ""); scanf(""%s"", fname);
 printf(""Last name:      ""); scanf(""%s"", lname);
 printf(""Phone number:   ""); scanf(""%s"", tel);
 first=new_entry(*first, fname, lname, tel);
}
</code></pre>

<p>I left out the unessential parts.
Now I know it's not much, but my class leader said I should use binary files to store and restore the data. But I got really confused if how am I supposed to use fread and fwrite.</p>

<hr>

<p>Thanks so much for the solution! I think I start to understand the concept.
The program now stores the data (At least I think it does, because the file keeps growing as I add more data.)
When starting a fresh binary file, the program correctly displays the data when requested, but if I close it, and reopen the same file, nothing happens when it tries to list the contacts.</p>

<p>Here's the (simplified again, i have 10 details in one record in the actual assignment) open function:</p>

<pre><code>record *open (char *db_file, record start)
{
  FILE *fp
  record *temp = start;
  fp=fopen(db_file, ""rb"");
  while (fread(temp, sizeof(rekord), 1, fp)&gt;0) 
    {
        fread(temp-&gt;fname, sizeof temp-&gt;fname, 1, fp);
        fread(temp-&gt;lname, sizeof temp-&gt;lname, 1, fp);
        fread(temp-&gt;tel, sizeof temp-&gt;tel, 1, fp);
    temp=temp-&gt;next;
    }
  fclose(fp);
  return temp;
}
</code></pre>

<p>And in main(), I use:</p>

<pre><code>start=open(db, start);
</code></pre>

<p>The declaration part:</p>

<pre><code>record *start=NULL;
</code></pre>

<p>Thanks again if someone replies.</p>
","<p>To write your linked list to a file, you can run through the list, and write your structure.</p>

<pre><code>#include &lt;stdio.h&gt;

record *it = first;

while (it != NULL) {
    fwrite (it-&gt;fname, sizeof it-&gt;name, 1, stream);
    fwrite (it-&gt;lname, sizeof it-&gt;lname, 1, stream);
    fwrite (it-&gt;tel, sizeof it-&gt;tel, 1, stream);
    it = it-&gt;next;
}
</code></pre>

<p><code>stream</code> is a file you can open with <code>wb</code> mode in <code>fopen</code>.</p>
","13330527"
"How to append binary values in VBScript","4884","","<p>If I have two variables containing binary values, how do I append them together as one binary value?  For example, if I used WMI to read the registry of two REG_BINARY value, I then want to be able to concatenate the values.</p>

<p>VBScript complains of a type mismatch when you try to join with the '&amp;' operator.</p>
","<p>For the record, I wanted VBScript code for a large userbase as a logon script that has the least chance of failing.  I like the ADO objects, but there are so many mysterious ways ADO can be broken, so I shy away from ADODB.Stream.</p>

<p>Instead, I was able to write conversion code to convert binary to hex encoded strings.  Then, to write back to a <code>REG_BINARY</code> value, I convert it to an array of integers and give it to the <code>SetBinaryValue</code> WMI method.</p>

<p>Note: <code>WshShell</code> can only handle <code>REG_BINARY</code> values containing 4 bytes, so it's unusable.</p>

<p>Thank you for the feedback.</p>
","213730"
"Remove new version's placeholder itunes connect","4879","","<p>How can I remove the version placeholder on iTunes Connect?
I have uploaded a version on a wrong application and when I realized that I removed the binary but I have never thought of this - can I also delete the placeholder? - because there is no update developed for this app yet.</p>

<p>Image for explanation</p>

<p><img src=""https://i.stack.imgur.com/vpzXq.png"" alt=""enter image description here""> </p>
","<p>To edit the version number, select the falsely numbered version on the left on iTunes Connect (so NOT the ""App Information"", but under that the version ""1.0.1 Prepare for Submission"" etc), scroll down in the right pane to ""General App Information"" -- just below the App Icon you can see the version number and it's editable! Change it, hit save, and you'll see the version number change on the left side.</p>

<p>(My answer is valid for iTunes Connect web UI as of 5. Jan 2016)</p>
","34618469"
"Finding trailing 0s in a binary number","4878","","<p>How to find number of trailing 0s in a binary number?Based on K&amp;R bitcount example of finding 1s in a binary number i modified it a bit to find the trailing 0s.</p>

<pre><code>int bitcount(unsigned x)
{
  int b;
  for(b=0;x!=0;x&gt;&gt;=1)
      {
        if(x&amp;01)
          break;
        else
          b++;
      }
</code></pre>

<p>I would like to review this method.</p>
","<p>Here's a way to compute the count in parallel for better efficiency:</p>

<pre><code>unsigned int v;      // 32-bit word input to count zero bits on right
unsigned int c = 32; // c will be the number of zero bits on the right
v &amp;= -signed(v);
if (v) c--;
if (v &amp; 0x0000FFFF) c -= 16;
if (v &amp; 0x00FF00FF) c -= 8;
if (v &amp; 0x0F0F0F0F) c -= 4;
if (v &amp; 0x33333333) c -= 2;
if (v &amp; 0x55555555) c -= 1;
</code></pre>
","7813486"
"HTML5 using src using raw binary data","4876","","<p>Let's say I am storing an audio file in the database and later on I would want to use that BLOB or binary in my application. </p>

<pre><code>&lt;audio src =""${sessionScope.user.music}""&gt; 
</code></pre>

<p>Where <code>${sessionScope.user.music}</code> returns a binary data that has been retrieve from the database.</p>

<p>would it be possible to load an audio file in an audio tag, using binary data instead of a uri? or path?</p>
","<p>A bit like inline images:</p>

<pre><code>&lt;img src=""data:image/gif;base64,R0lGODlhEAAOALMAAOazToeHh0tLS/7LZv/0jvb29t/
f3//Ub//ge8WSLf/rhf/3kdbW1mxsbP//mf///yH5BAAAAAAALAAAAAAQAA4AAARe8L1Ekyky67
QZ1hLnjM5UUde0ECwLJoExKcppV0aCcGCmTIHEIUEqjgaORCMxIC6e0CcguWw6aFjsVMkkIr7g7
7ZKPJjPZqIyd7sJAgVGoEGv2xsBxqNgYPj/gAwXEQA7""
    width=""16"" height=""14"" alt=""embedded folder icon""&gt;
</code></pre>

<p>Where this works for <code>&lt;img&gt;</code>, I am far from sure that <code>data:audio/mp3;base64, ...</code> (or <code>audio/ogg</code>) would work. It is not in my HTML5 reference.</p>

<p>For the encoding, see <a href=""https://stackoverflow.com/questions/9388264/jeditorpane-with-inline-image"">JEditorPane with inline Image</a>.</p>
","13645510"
"How can I return binary image data from an abortable AJAX request and set the result to the src of an HTML/DOM image?","4868","","<p>I'm writing a web application that involves a continuous cycle of creating (and removing) a fair number of images on a webpage. Each image is dynamically generated by the server.</p>

<pre><code>var img = document.createElement(""img"");
img.src = ""http://mydomain.com/myImageServer?param=blah"";
</code></pre>

<p>In certain cases, some of these images outlive their usefulness before they've finished downloading. At that point, I remove them from the DOM.</p>

<p>The problem is that the browser continues to download those images even <em>after they've been removed from the DOM</em>. That creates a bottleneck, since I have new images waiting to be downloaded, but they have to wait for the old unneeded images to finish downloading first.</p>

<p>I would like to <strong>abort</strong> those unneeded image downloads. The obvious solution <em>seems</em> to be to request the binary image data via AJAX (since AJAX requests can be aborted), and set the img.src once the download is complete:</p>

<pre><code>// Code sample uses jQuery, but jQuery is not a necessity

var img = document.createElement(""img"");

var xhr = $.ajax({
        url: ""http://mydomain.com/myImageServer?param=blah"",
        context: img,
        success: ImageLoadedCallback
    });

function ImageLoadedCallback(data)
{
    this.src = data;
}

function DoSomethingElse()
{
    if (condition)
        xhr.abort();
}
</code></pre>

<p>But the problem is that this line does not work the way I had hoped:</p>

<pre><code>this.src = data;
</code></pre>

<p>I've searched high and low. Is there no way to set an image source to binary image data sent via AJAX?</p>
","<p>You would have to base64-encode the <code>data</code> into a <a href=""http://en.wikipedia.org/wiki/Data_URI_scheme"" rel=""nofollow noreferrer""><code>data:</code> URI</a> to achieve that. But it wouldn't work in IE6-7, and there are limitations on how much data you can put in there, especially on IE8. It might be worth doing as an optimisation for browsers where it's supported, but I wouldn't rely on it.</p>

<p>Another possible approach is to use the <code>XMLHttpRequest</code> to preload the image, then just discard the response and set the <code>src</code> of a new <code>Image</code> to point to the same address. The image should be loaded from the browser's cache. However, in the case where you're generating the images dynamically you would need to pay some attention to your caching headers to ensure the response is cachable.</p>
","2331066"
"What's the absolute minimum a programmer should know about binary numbers and arithmetic?","4863","","<p>Although I know the basic concepts of binary representation, I have never really written any code that uses binary arithmetic and operations.</p>

<p>I want to know</p>

<ul>
<li><p>What are the basic concepts any
programmer should know about binary
numbers and arithmetic ? , and</p></li>
<li><p>In what ""practical"" ways can binary
operations be used in programming. I
have seen some ""cool"" uses of shift
operators and XOR etc. but are there
some typical problems where using binary
operations is an obvious choice.</p></li>
</ul>

<p>Please give pointers to some good reference material. </p>
","<p>If you are developing lower-level code, it is critical that you understand the binary representation of various types. You will find this particularly useful if you are developing embedded applications or if you are dealing with low-level transmission or storage of data. </p>

<p>That being said, I also believe that understanding how things work at a low level is useful even if you are working at much higher levels of abstraction. I have found, for example, that my ability to develop efficient code is improved by understanding how things are represented and manipulated at a low level. I have also found such understanding useful in working with debuggers.</p>

<p>Here is a short-list of binary representation topics for study:</p>

<ul>
<li>numbering systems (binary, hex, octal, decimal, ...)</li>
<li>binary data organization (bits, nibbles, bytes, words, ...)</li>
<li>binary arithmetic</li>
<li>other binary operations (AND,OR,XOR,NOT,SHL,SHR,ROL,ROR,...)</li>
<li>type representation (boolean,integer,float,struct,...)</li>
<li>bit fields and packed data</li>
</ul>

<p>Finally...here is a nice set of <a href=""http://graphics.stanford.edu/~seander/bithacks.html"" rel=""noreferrer"">Bit Twiddling Hacks</a> you might find useful.</p>
","1030707"
"Why do unsigned int x = -1 and int y = ~0 have the same binary representation?","4845","","<p>In the following code segment what will be:</p>

<ul>
<li>the result of function</li>
<li>value of x </li>
<li>value of y</li>
</ul>

<pre>
    {
         unsigned int x=-1;
         int y;
         y = ~0;
         if(x == y)
             printf(""same"");
         else
             printf(""not same"");
     }
</pre>

<pre>
a. same, MAXINT, -1
b. not same, MAXINT, -MAXINT
c. same , MAXUINT, -1
d. same, MAXUINT, MAXUINT
e. not same, MAXINT, MAXUINT
</pre>

<p>Can someone explain me how its works or can just explain the snippet??</p>

<p>I know it's about two's complement n etc..
What is the significance of MAXINT and -1 ?
It is because of unsigned int and int thing - am I right ?</p>
","<p>If you run this program, you will see that the answer a is <em>wrong</em> and c is the correct answer:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;limits.h&gt;

int main() {
    unsigned int x=-1;
    int y;
    y = ~0;
    if(x == y)
        printf(""same\n"");
        if(x==INT_MAX) printf(""INT_MAX\n"");
        if(x==UINT_MAX) printf(""UINT_MAX\n"");
    else
        printf(""not same"");
    return 0;
}
</code></pre>
","3141420"
"Writing binary files in QT and reading in matlab","4840","","<p>Trying to do the simplest thing ever. Write a number in QT in binary mode (unsigned 16) and read the file in matlab. I use Append mode since I will be adding numbers to the file in the future But can't seem to do this right.</p>

<p>This is the QT code:</p>

<pre><code>QFile f(""C:\\temp.dat"");
f.open(QIODevice::WriteOnly | QIODevice::Append)
QDataStream out(&amp;f);
out&lt;&lt;quint16(270);
f.close();
</code></pre>

<p>And this is the Matlab code:</p>

<pre><code>fid = fopen('C:\\temp.dat');
F_nums = fread(fid,1,'*uint16');
fclose(fid);
</code></pre>

<p>Seems very simple but it reads the numbers wrongly...</p>

<p>Thank you!</p>
","<p>The problem is really simple: you are writing big-endian data (MSB comes first), but Matlab by default expects little endian data. The fix is simple:</p>

<pre><code>QFile f(""C:\\temp.dat"");
f.open(QIODevice::WriteOnly | QIODevice::Append)
QDataStream out(&amp;f);
out.setByteOrder(QDataStream::LittleEndian); // *** set little endian byte order
out&lt;&lt;quint16(270);
f.close();
</code></pre>
","11125267"
"Why Does C++ Support Hex Assignment, But Lack Binary Assignment? How best to store flags?","4834","","<p>I have a set of bit flags that are used in a program I am porting from C to C++.</p>

<p>To begin...</p>

<p>The flags in my program were previously defined as:</p>

<pre><code>/* Define feature flags for this DCD file */
#define DCD_IS_CHARMM       0x01
#define DCD_HAS_4DIMS       0x02
#define DCD_HAS_EXTRA_BLOCK 0x04
</code></pre>

<p>...Now I've gather that #defines for constants (versus class constants, etc.) are generally considered bad form.</p>

<p>This raises questions about how best to store bit flags in c++ and why c++ doesn't support assignment of binary text to an int, like it allows for hex numbers to be assigned in this way (via ""0x"").  These questions are summarized at the end of this post.</p>

<p>I could see one simple solution is to simply create individual constants:</p>

<pre><code>namespace DCD {
   const unsigned int IS_CHARMM = 1;
   const unsigned int HAS_4DIMS = 2;
   const unsigned int HAS_EXTRA_BLOCK = 4;
};
</code></pre>

<p>Let's call this idea 1.</p>

<p>Another idea I had was to use an integer enum:</p>

<pre><code>namespace DCD {
   enum e_Feature_Flags {
      IS_CHARMM = 1,
      HAS_4DIMS = 2,
      HAS_EXTRA_BLOCK = 8
   };
};
</code></pre>

<p>But one thing that bothers me about this is that its less intuitive when it comes to higher values, it seems... i.e.</p>

<pre><code>namespace DCD {
   enum e_Feature_Flags {
      IS_CHARMM = 1,
      HAS_4DIMS = 2,
      HAS_EXTRA_BLOCK = 8,
      NEW_FLAG = 16,
      NEW_FLAG_2 = 32,
      NEW_FLAG_3 = 64,
      NEW_FLAG_4 = 128
   };
};
</code></pre>

<p>Let's call this approach option 2.</p>

<p>I'm considering using Tom Torf's macro solution:</p>

<pre><code>#define B8(x) ((int) B8_(0x##x))

#define B8_(x) \
( ((x) &amp; 0xF0000000) &gt;( 28 - 7 ) \
| ((x) &amp; 0x0F000000) &gt;( 24 - 6 ) \
| ((x) &amp; 0x00F00000) &gt;( 20 - 5 ) \
| ((x) &amp; 0x000F0000) &gt;( 16 - 4 ) \
| ((x) &amp; 0x0000F000) &gt;( 12 - 3 ) \
| ((x) &amp; 0x00000F00) &gt;( 8 - 2 ) \
| ((x) &amp; 0x000000F0) &gt;( 4 - 1 ) \
| ((x) &amp; 0x0000000F) &gt;( 0 - 0 ) )
</code></pre>

<p>converted to inline functions, e.g.</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;string&gt;
....

/* TAKEN FROM THE C++ LITE FAQ [39.2]... */
class BadConversion : public std::runtime_error {
 public:
   BadConversion(std::string const&amp; s)
     : std::runtime_error(s)
     { }
};

inline double convertToUI(std::string const&amp; s)
{
   std::istringstream i(s);
   unsigned int x;
   if (!(i &gt;&gt; x))
     throw BadConversion(""convertToUI(\"""" + s + ""\"")"");
   return x;
} 
/** END CODE **/

inline unsigned int B8(std::string x) {
   unsigned int my_val = convertToUI(x.insert(0,""0x"").c_str());
   return ((my_val) &amp; 0xF0000000) &gt;( 28 - 7 ) |
            ((my_val) &amp; 0x0F000000) &gt;( 24 - 6 ) | 
            ((my_val) &amp; 0x00F00000) &gt;( 20 - 5 ) |
            ((my_val) &amp; 0x000F0000) &gt;( 16 - 4 ) |
            ((my_val) &amp; 0x0000F000) &gt;( 12 - 3 ) |
            ((my_val) &amp; 0x00000F00) &gt;( 8 - 2 ) |
            ((my_val) &amp; 0x000000F0) &gt;( 4 - 1 ) |
            ((my_val) &amp; 0x0000000F) &gt;( 0 - 0 );
}

namespace DCD {
   enum e_Feature_Flags {
      IS_CHARMM       = B8(""00000001""),
      HAS_4DIMS       = B8(""00000010""),
      HAS_EXTRA_BLOCK = B8(""00000100""),
      NEW_FLAG        = B8(""00001000""),
      NEW_FLAG_2      = B8(""00010000""),
      NEW_FLAG_3      = B8(""00100000""),
      NEW_FLAG_4      = B8(""01000000"")
   };
};
</code></pre>

<p>Is this crazy?  Or does it seem more intuitive?  Let's call this choice 3.</p>

<p>So to recap, my over-arching questions are:</p>

<p><strong>1.</strong>  Why doesn't c++ support a ""0b"" value flag, similar to ""0x""?<br>
<strong>2.</strong>  Which is the best style to define flags...<br>
    <strong>i.</strong>   Namespace wrapped constants.<br>
    <strong>ii.</strong>  Namespace wrapped enum of unsigned ints assigned directly.<br>
    <strong>iii.</strong> Namespace wrapped enum of unsigned ints assigned using readable binary string.<br></p>

<p>Thanks in advance!  And please don't close this thread as subjective, because I really want to get help on what the best style is and why c++ lacks built in binary assignment capability.</p>

<hr>

<p><strong>EDIT 1</strong><br></p>

<p>A bit of additional info.  I will be reading a 32-bit bitfield from a file and then testing it with these flags.  So bear that in mind when you post suggestions.</p>
","<p>Prior to C++14, binary literals had been discussed off and on over the years, but as far as I know, nobody had ever written up a serious proposal to get it into the standard, so it never really got past the stage of talking about it.</p>

<p>For C++ 14, somebody finally wrote up a proposal, and the committee accepted it, so if you can use a current compiler, the basic premise of the question is false--you can use binary literals, which have the form <code>0b01010101</code>.</p>

<p>In C++11, instead of adding binary literals directly, they added a much more general mechanism to allow general user-defined literals, which you could use to support binary, or base 64, or other kinds of things entirely. The basic idea is that you specify a number (or string) literal followed by a suffix, and you can define a function that will receive that literal, and convert it to whatever form you prefer (and you can maintain its status as a ""constant"" too...)</p>

<p>As to which to use: if you can, the binary literals built into C++14 or above are the obvious choice. If you can't use them, I'd generally prefer a variation of option 2: an enum with initializers in hex:</p>

<pre><code>namespace DCD {
   enum e_Feature_Flags {
      IS_CHARMM = 0x1,
      HAS_4DIMS = 0x2,
      HAS_EXTRA_BLOCK = 0x8,
      NEW_FLAG = 0x10,
      NEW_FLAG_2 = 0x20,
      NEW_FLAG_3 = 0x40,
      NEW_FLAG_4 = 0x80
   };
};
</code></pre>

<p>Another possibility is something like:</p>

<pre><code>#define bit(n) (1&lt;&lt;(n))

enum e_feature_flags = { 
    IS_CHARM = bit(0), 
    HAS_4DIMS = bit(1),
    HAS_EXTRA_BLOCK = bit(3),
    NEW_FLAG = bit(4),
    NEW_FLAG_2 = bit(5),
    NEW_FLAG_3 = bit(6),
    NEW_FLAG_4 = bit(7)
};
</code></pre>
","3834473"
"How do computers process ascii/text & images/color differently?","4825","","<p>I've recently been thinking more about what kind of work computer hardware has to do to produce the things we expect.</p>

<p>Comparing text and color, it seems that both rely on combinations of 1's and 0's with 256 possible combinations per byte. ASCII may represent a letter such as (01100001) to be the letter 'A'. But then there may be a color R(01100001), G(01100001), B(01100001) representing some random color. Considering on a low level, the computer is just reading these collections of 1's and 0's, what needs to happen to ensure the computer renders the color R(01100001), G(01100001), B(01100001) and not the letter A three times on my screen?</p>
","<p>I'm not entirely sure this question is appropriate for Stack Overflow, but I'll go ahead and give a basic answer anyways.  Though it's actually a very complicated question because depending on how deep you want to go into answering it I could write an entire book on computer architecture in order to do so.</p>

<p>So to keep it simple I'll just give you this: It's all a matter of context.  First let's just tackle text:</p>

<p>When you open, say, a text editor the implicit assumption is the data to be displayed in it is textual in nature.  The text to be displayed is some bytes in memory (possibly copied out of some bytes on disk).  There's no magical internal context from the memory's point of view that these bytes are text.  Instead, the source for text editor contains some commands that point to those bytes and say ""these bytes represent 300 characters of text"" for example.  Then there's a complex sequence of steps involving library code all the way to hardware that handles mapping those bytes according to an encoding like ASCII (there are many other ways of encoding text) to characters, finding those characters in a font, writing that font to the screen, etc.</p>

<p>The point is it doesn't <em>have</em> to interpret those bytes as text. It just does because that's what a text editor does.  You could hypothetically open it in an image program and tell it to interpret those same 300 bytes as a 10x10 array (or image) of RGB values.</p>

<p>As for colors the same logic applies.  They're just bytes in memory.  But when the code that's drawing something to the screen has decided what pixels it wants to write with what colors, it will pipe those bytes via a memory mapping to the video card which will then translate them to commands that are sent to the monitor (still in some binary format representing pixels and the colors, though the reality is a lot more complicated), and the monitor itself contains firmware that then handles the detail of mapping those colors to the physical pixels.  The numbers that represent the colors themselves will at some point be converted to a specific current to each R/G/B channel to raise or lower its intensity.</p>

<p>That's all I have time for for now but it's a start.</p>

<p><strong>Update:</strong> Just to illustrate my point, I took the text of Flatland from <a href=""http://www.gutenberg.org/files/97/97.txt"" rel=""nofollow"">here</a>. Which is just 216624 bytes of ASCII text (interpreted as such by your web browser based on context: the .txt extension helps, but the web server also provides a MIME type header informing the browser that it should be interpreted as plain text. Your browser might also analyze the bytes to determine that their pattern does look like that of plain text (and that there aren't an overwhelming number of bytes that don't represent ASCII characters).  I appended a few spaces to the end of the text so that its length is 217083 which is 269 * 269 * 3 and then plotted it as a 269 x 269 RGB image:</p>

<p><img src=""https://lh5.googleusercontent.com/-vXmDA5cWNCY/USaNEdG9jKI/AAAAAAAACRs/S2xLIC_PM9M/w706-h714-p-o-k/flatland.png"" /></p>

<p>Not terribly interesting-looking. But the point is that I just took those same exact bytes and told the software, ""okay, these are RGB values now"".  That's not to say that looking at plain text bytes as images can't be useful.  For example, it can be a useful way to visualize an encryption algorithm.  <a href=""http://en.wikipedia.org/wiki/File:Tux_ecb.jpg"" rel=""nofollow"">This</a> shows an image that was encrypted with a pretty insecure algorithm--you can still get a very good sense of the patterns of bytes in the original unencrypted file.  If it were text and not an image this would be no different, as text in a specific language like English also has known statistical patterns.  A good encryption algorithm would look make the encrypted image look more like random noise.</p>
","15011708"
"Decimal to Binary Converter in Java","4822","","<p>I need to make a decimal to binary converter in Java. I can't use Integer.toBinaryString() and every answer I've seen uses that. I need to actually make the algorithm. I want to keep the input an int and the output a String because if I change that the rest of the program this is from gets messed up. If you can, keep it pretty basic. This is what I've ended up with after hours of drafting and scrapping and there's many things wrong with it, like it doesn't even put together a binary number. Please, please help, I'm so confused and my brain is a mess.</p>

<pre><code>public static String decToBin(int dec)
  {
    String bin = """";
    int exp = 0;

    for(int expLevel = 0; Math.pow(2, expLevel) &lt;= dec; expLevel++)
    {
      if(dec - Math.pow(2, expLevel) &gt;= 0)
      {
        dec -= Math.pow(2, expLevel-1);
      }
    }
    return bin;
  }
</code></pre>
","<p>Looks like you need to review your math notes. Here's a good explanation of the basic algorithm: <a href=""http://www.wikihow.com/Convert-from-Decimal-to-Binary"" rel=""nofollow"">How to Convert from Decimal to Binary</a>.</p>

<p>If you check the provided link, you will see that you just need to get the remainder of the divisions of the number divided by 2. As a brief algorithm:</p>

<pre><code>int n &lt;- user input (or other source)
String binaryForm &lt;- empty string
while (n &gt; 0) {
    int res &lt;- n % 2;
    n &lt;- n / 2;
    binaryForm &lt;- res + binaryForm
}
</code></pre>
","13464808"
"Convert 2D binary matrix to black/white image in java","4819","","<p>I am new for java. I have 2D binary matrix with only 1s and 0s now. I want to save it as jpg image(black and white) with same width and height. How could I realize that? I tried the code below but failed, saying  ""java.lang.IllegalArgumentException: image == null!"" Please help me with that or give me your better solution. Thank you very much.</p>

<pre><code>public static void main(String[] args) throws IOException {

    //result is double[25][33] binary matrix with only 1s and 0s;
    int height=result.length;
    int width=result[0].length;;
    byte[] data = new byte[height*width];
    int k=0;
    for(int i = 0;i &lt; height;i++){
        for(int j = 0; j &lt; width; j++){
            data[k]=(byte)result[i][j];
            k++;
        }
        System.out.print(""\n"");
    }
    InputStream input = new ByteArrayInputStream(data);
    BufferedImage output = ImageIO.read(input);
    ImageIO.write(ouput, ""jpg"", new File(""c:/result.jpg""));

}
</code></pre>
","<p>This is a simple example that creates a 30x30 checkered box:</p>

<p><img src=""https://i.stack.imgur.com/CkfEY.jpg"" alt=""enter image description here""></p>

<pre><code>public static void main(String... args) throws IOException {
    int w = 30, h = 30;

    // create the binary mapping
    byte BLACK = (byte)0, WHITE = (byte)255;
    byte[] map = {BLACK, WHITE};
    IndexColorModel icm = new IndexColorModel(1, map.length, map, map, map);

    // create checkered data
    int[] data = new int[w*h];
    for(int i=0; i&lt;w; i++)
        for(int j=0; j&lt;h; j++)
            data[i*h + j] = i%4&lt;2 &amp;&amp; j%4&lt;2 || i%4&gt;=2 &amp;&amp; j%4&gt;=2 ? BLACK:WHITE;

    // create image from color model and data
    WritableRaster raster = icm.createCompatibleWritableRaster(w, h);
    raster.setPixels(0, 0, w, h, data);
    BufferedImage bi = new BufferedImage(icm, raster, false, null);

    // output to a file
    ImageIO.write(bi, ""jpg"", new File(""C:\\Users\\user\\Desktop\\test.jpg""));
}
</code></pre>

<hr>

<p><strong>EDIT:</strong></p>

<p>For what you are doing you actually don't need to create your own ImageColorModel, you can use a built in type: BufferedImage.TYPE_BYTE_GRAY or TYPE_BYTE_BINARY. Here is a better example and shows how to use grayscale to get a checkered box:</p>

<p><img src=""https://i.stack.imgur.com/A27kp.jpg"" alt=""enter image description here""></p>

<pre><code>public static void main(String... args) throws IOException {
    int w = 40, h = 40, divs = 5;

    BufferedImage bi = new BufferedImage(w, h, BufferedImage.TYPE_BYTE_GRAY);
    WritableRaster raster = bi.getRaster();

    for(int i=0; i&lt;w; i++)
        for(int j=0; j&lt;h; j++)
            raster.setSample(i,j,0,128+(int)(127*Math.sin(Math.PI*i/w*divs)*Math.sin(Math.PI*j/h*divs)));

    ImageIO.write(bi, ""jpg"", new File(""C:\\Users\\user\\Desktop\\test.jpg""));
}
</code></pre>
","20321766"
"C++ Reading a PDF file","4815","","<p>I'm using the following code to read the content of a PDF file:</p>

<pre><code>string document;
FILE * f;
f = fopen ( path , ""rb"");
unsigned char buffer[1024];
while(!feof(f)){   
    int bytes = fread(buffer,1,1024,f);
    for(int i = 0; i &lt; bytes; i++){
        document += buffer[i];
        cout &lt;&lt; buffer[i];
    }
}
fclose ( f );
</code></pre>

<p>The problem is, that the chars are not the same as when I open the file in a text editor.
For example this file
files.flashfan.ch/file.png</p>

<p>results in this output:
files.flashfan.ch/output.png</p>

<p>How can I read the file, so that the chars are exactly the same as in the editor?
I want to parse PDF files, but without the original chars I cant to this.
I've testet the code with this file (its not a PDF file, just a part of one, so you can't display it):</p>

<p><a href=""http://files.flashfan.ch/PDF%20Header.pdf"" rel=""nofollow"">PDF Head.pdf</a></p>

<p>Thanks for your help!</p>
","<p>I don't see any errors in the way you read the file (the code actually works on my Linux box when I redirect the output to a file). Probably the issue is in the control characters that mess up with the console. Try to output to a file and compare with the input.</p>
","4448956"
"Extracting certain bits from binary data","4799","","<p>I have a binary number that looks like this:</p>

<p>00000000 00000000 00000011 00001101  =  781 integer value  = integer name ""packed""</p>

<p>How am i able to extract each of those as separate integer values using bit wise in java. Like the following:</p>

<pre><code>int a = (function) = 00000000;
int b = (function) = 00000000;
int c = (function) = 00000011;
int d = (function) = 00001101;
</code></pre>

<p>If you can see what i am doing up there.. I want the first 8 into one integer the next into a second integer and so on.. I think you do this using bit wise in java but i am completely unsure. Any help is appreciated. Sorry but i am completely new to this kind of thing and really need help with this, Thanks! Basically (function) should equal something like this:</p>

<pre><code>packed &gt;&gt; 5; (I know this isn't nearly right that is why i am needing help on this)...
</code></pre>

<p>This question was answered for me 2 days ago and it worked perfectly fine but now it broke... I have NO idea why.. here is the method i used for doing this:</p>

<pre><code>public static int getNthByte(int n, int packed) 
{
   // shift the desired bits into the last 8 bits
   int shifted = packed &gt;&gt; (8 * n);
   // and now get those bits
   int masked = 0x000000FF &amp; shifted;
   return masked;
}
</code></pre>

<p>But when i put this line of code: I get this answer:</p>

<pre><code>int x = 781;
System.out.println(getNthByte(3, x)); (Which should give me 00001101, in integer value)
</code></pre>

<p>I printlns the following:</p>

<pre><code>0
</code></pre>

<p>Why? This was working fine for me yesterday... but i noticed When i did:</p>

<pre><code>System.out.println(getNthByte(5, x));
</code></pre>

<p>It gave me the 3rd bit:</p>

<pre><code>3
</code></pre>

<p>Which was correct...</p>

<p>tl;dr this method was working fine yesterday now it is all messed up and i need help fixing it or possibly it is my error? I don't know.. Yesterday i put in getNthByte(3,x) and it gave me the correct integer value related to 00001101...</p>

<p>Any help is appreciated.. maybe there is something wrong with the method? or is it just me?</p>
","<p>When in Java, you have to deal with binary data, one word should pop to your mind immediately: <a href=""http://docs.oracle.com/javase/7/docs/api/java/nio/ByteBuffer.html""><code>ByteBuffer</code></a>:</p>

<pre><code>final ByteBuffer buf = ByteBuffer.allocate(4); // sizeof(int)
buf.putInt(yourInt);
</code></pre>

<p>Returning the nth byte is now as simple as:</p>

<pre><code>return (int) buf.get(byteIndex);
</code></pre>

<p>Note that you make the assumption that your integer is in big endian order; fortunately, you re right: this is the case in Java. Always. Whatever the endianness of the underlying architecture.</p>
","17156610"
"How to use ""typedbytes"" or ""rawbytes"" in Hadoop Streaming?","4786","","<p>I have a problem that would be solved by Hadoop Streaming in ""typedbytes"" or ""rawbytes"" mode, which allow one to analyze binary data in a language other than Java.  (Without this, Streaming interprets some characters, usually \t and \n, as delimiters and complains about non-utf-8 characters.  Converting all my binary data to Base64 would slow down the workflow, defeating the purpose.)</p>

<p>These binary modes were added by <a href=""https://issues.apache.org/jira/browse/HADOOP-1722"" rel=""nofollow"">HADOOP-1722</a>.  On the command line that invokes a Hadoop Streaming job, ""-io rawbytes"" lets you define your data as a 32-bit integer size followed by raw data of that size, and ""-io typedbytes"" lets you define your data as a 1-bit zero (which means raw bytes), followed by a 32-bit integer size, followed by raw data of that size.  I have created files with these formats (with one or many records) and verified that they are in the right format by checking them with/against the output of <a href=""https://github.com/klbostee/typedbytes"" rel=""nofollow"">typedbytes.py</a>.  I've also tried all conceivable variations (big-endian, little-endian, different byte offsets, etc.).  I'm using Hadoop <a href=""https://ccp.cloudera.com/display/CDH4DOC/Installing+CDH4+on+a+Single+Linux+Node+in+Pseudo-distributed+Mode"" rel=""nofollow"">0.20 from CDH4</a>, which has the classes that implement the typedbytes handling, and it is entering those classes when the ""-io"" switch is set.</p>

<p>I copied the binary file to HDFS with ""hadoop fs -copyFromLocal"".  When I try to use it as input to a map-reduce job, it fails with an OutOfMemoryError on the line where it tries to make a byte array of the length I specify (e.g. 3 bytes).  It must be reading the number incorrectly and trying to allocate a huge block instead.  Despite this, it does manage to get a record to the mapper (the previous record? not sure), which writes it to standard error so that I can see it.  There are always too many bytes at <em>the beginning</em> of the record: for instance, if the file is ""\x00\x00\x00\x00\x03hey"", the mapper would see ""\x04\x00\x00\x00\x00\x00\x00\x00\x00\x07\x00\x00\x00\x08\x00\x00\x00\x00\x03hey"" (reproducible bits, though no pattern that I can see).</p>

<p>From page 5 of <a href=""http://static.last.fm/johan/huguk-20090414/klaas-hadoop-1722.pdf"" rel=""nofollow"">this talk</a>, I learned that there are ""loadtb"" and ""dumptb"" subcommands of streaming, which copy to/from HDFS and wrap/unwrap the typed bytes in a SequenceFile, in one step.  When used with ""-inputformat org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat"", Hadoop correctly unpacks the SequenceFile, but then misinterprets the typedbytes contained within, in exactly the same way.</p>

<p>Moreover, I can find no documentation of this feature.  On Feb 7 (I e-mailed it to myself), it was briefly mentioned in the <a href=""http://hadoop.apache.org/docs/mapreduce/r0.21.0/streaming.html#Specifying+the+Communication+Format"" rel=""nofollow"">streaming.html page on Apache</a>, but this r0.21.0 webpage has since been taken down and <a href=""http://hadoop.apache.org/docs/r1.1.1/streaming.html"" rel=""nofollow"">the equivalent page for r1.1.1</a> has no mention of rawbytes or typedbytes.</p>

<p><strong>So my question is:</strong> what is the correct way to use rawbytes or typedbytes in Hadoop Streaming?  Has anyone ever gotten it to work?  If so, could someone post a recipe?  It seems like this would be a problem for anyone who wants to use binary data in Hadoop Streaming, which ought to be a fairly broad group.</p>

<p>P.S. I noticed that <a href=""https://github.com/klbostee/dumbo"" rel=""nofollow"">Dumbo</a>, <a href=""http://www.hadoopy.com/en/latest/"" rel=""nofollow"">Hadoopy</a>, and <a href=""https://github.com/RevolutionAnalytics/RHadoop/wiki/rmr"" rel=""nofollow"">rmr</a> all use this feature, but there ought to be a way to use it directly, without being mediated by a Python-based or R-based framework.</p>
","<p>Okay, I've found a combination that works, but it's weird.</p>

<ol>
<li><p>Prepare a valid typedbytes file in your local filesystem, following the <a href=""http://hadoop.apache.org/docs/current/api/org/apache/hadoop/typedbytes/package-summary.html"" rel=""nofollow"">documentation</a> or by imitating <a href=""https://github.com/klbostee/typedbytes"" rel=""nofollow"">typedbytes.py</a>.</p></li>
<li><p>Use</p>

<pre><code>hadoop jar path/to/streaming.jar loadtb path/on/HDFS.sequencefile &lt; local/typedbytes.tb
</code></pre>

<p>to wrap the typedbytes in a SequenceFile and put it in HDFS, in one step.</p></li>
<li><p>Use</p>

<pre><code>hadoop jar path/to/streaming.jar -inputformat org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat ...
</code></pre>

<p>to run a map-reduce job in which the mapper gets input from the SequenceFile.  Note that <code>-io typedbytes</code> or <code>-D stream.map.input=typedbytes</code> should <em>not</em> be used--- explicitly asking for typedbytes leads to the misinterpretation I described in my question.  But fear not: Hadoop Streaming splits the input on its binary record boundaries and not on its '\n' characters.  The data arrive in the mapper as ""rawdata"" separated by '\t' and '\n', like this:</p>

<ol>
<li>32-bit signed integer, representing length (note: no type character)</li>
<li>block of raw binary with that length: this is the key</li>
<li>'\t' (tab character... why?)</li>
<li>32-bit signed integer, representing length</li>
<li>block of raw binary with that length: this is the value</li>
<li>'\n' (newline character... ?)</li>
</ol></li>
<li><p>If you want to additionally send raw data from mapper to reducer, add</p>

<pre><code>-D stream.map.output=typedbytes -D stream.reduce.input=typedbytes
</code></pre>

<p>to your Hadoop command line and format the mapper's output and reducer's expected input as valid typedbytes.  They also alternate for key-value pairs, but this time with type characters and without '\t' and '\n'.  Hadoop Streaming correctly splits these pairs on their binary record boundaries and groups by keys.</p></li>
</ol>

<p>The only documentation on <code>stream.map.output</code> and <code>stream.reduce.input</code> that I could find was in the <a href=""https://issues.apache.org/jira/browse/HADOOP-1722"" rel=""nofollow"">HADOOP-1722</a> exchange, starting 6 Feb 09.  (Earlier discussion considered a different way to parameterize the formats.)</p>

<p>This recipe does not provide strong typing for the input: the type characters are lost somewhere in the process of creating a SequenceFile and interpreting it with the <code>-inputformat</code>.  It does, however, provide splitting at the binary record boundaries, rather than '\n', which is the really important thing, and strong typing between the mapper and the reducer.</p>
","15172498"
"generate binary representation of numbers from 1 to 2^k-1","4781","","<p>I would like to obtain a list of binary represented integers in range 1... 2^k-1. Or otherwise, I need a list of all possible combinations of k bits. So, for example, given that k is 3 I need:    </p>

<pre><code>001
010
011
100
101
110
111
</code></pre>

<p>As I am planning on doing this in Java, I was thinking of using a BitSet for representing each number, and storing a value in a list, but I think this question could be language-agnostic. Basically, I need to figure out the algorithm for generating the entire set.</p>

<p>I think I need a recursive solution, something that would take into account the previously set bit.</p>

<pre><code>void fill(int k, int i, boolean wasSet) {
    if (i==k) return;
        BitSet bs = new BitSet();
        for (int j=0; j&lt;k; j++) {
          if (!wasSet) {
              bs.set(i);
              fill(k, i, true);
          } else {
              fill(k, j, false);
          }
    }
</code></pre>

<p>Note: this function prototype is obviously very wrong.</p>

<p>Note2: I would really really like to avoid using strings, as I later need to use this values to perform some other calculations, and BitSet comes quite handy for that</p>
","<p>Below is the recursive solution I came up with.</p>

<p>It simply, for every position, tries to set that bit, and then recurses.</p>

<p>It uses the same <code>BitSet</code> for all permutations. If you wish to have one for each, you'll probably have to copy it.</p>

<pre><code>static BitSet bs = new BitSet(3);   
static void fill(int k, int n)
{
   if (k == n)
   {
      System.out.println(bs);
      return;
   }
   bs.set(k, false);
   fill(k+1, n);
   bs.set(k, true);
   fill(k+1, n);
}

public static void main(String[] args)
{
    fill(0, 3);
}
</code></pre>
","20035759"
"binary data in database, blob vs compressed base64","4779","","<p>There is a column type named blob in database, and it is used to store binary data.</p>

<p>But more often than not, I see solutions which compress binary data, then convert binary data to base64, and store base64 string as varchar or text in database.</p>

<p>Python code example:</p>

<pre><code>import zlib, base64
base64_str = base64.b64encode(zlib.compress(binary_data, 9))
</code></pre>

<p>So there are two ways to store binary data into database:</p>

<ol>
<li>as blob </li>
<li>as compressed base64</li>
</ol>

<p>My Questions is:
Which way is better and why?</p>
","<p>It seems that I have to answer my own question. Most of the time, storing compressed base64 into database is not a good idea. It is complex than storing blob. And most of the time, binary is smaller than base64 string.</p>

<p>I only find one case that compressed base64 is useful: you can't alter the table schema, and there is only text columns, you have to store binary data into that table. The only possible way is to convert binary to base64 string.</p>
","8236317"
"how to loop through the digits of a binary number?","4770","","<p>I have a binary number 1011011, how can I loop through all these binary digits one after the other ?</p>

<p>I know how to do this for decimal integers by using modulo and division.</p>
","<pre><code>int n = 0x5b; // 1011011
</code></pre>

<p>Really you should just do this, hexadecimal in general is much better representation:</p>

<pre><code>printf(""%x"", n); // this prints ""5b""
</code></pre>

<p>To get it in binary, (with emphasis on easy understanding) try something like this:</p>

<pre><code>printf(""%s"", ""0b""); // common prefix to denote that binary follows
bool leading = true; // we're processing leading zeroes
// starting with the most significant bit to the least
for (int i = sizeof(n) * CHAR_BIT - 1; i &gt;= 0; --i) {
    int bit = (n &gt;&gt; i) &amp; 1;
    leading |= bit; // if the bit is 1, we are no longer reading leading zeroes
    if (!leading)
        printf(""%d"", bit);
}
if (leading) // all zero, so just print 0
    printf(""0"");

// at this point, for n = 0x5b, we'll have printed 0b1011011
</code></pre>
","4116895"
"Convert a subnet mask into binary (octets) in vb.net","4749","","<p>How can I convert a subnetmask into binary, so I'll end up with 32 digits?</p>

<p>I can convert it into Binary, using Convert.ToString(Long-to-convert, 2)</p>

<p>But a subnetmask of 255.255.255.0 returns(it returns it without the spaces though):</p>

<p>1111 1111  1111 1111  1111 1111  0</p>

<p>When I want it to be:</p>

<p>1111 1111  1111 1111  1111 1111  0000 0000</p>
","<p>If you convert each byte separately then before the concatenate step you can do a PadLeft(8, '0') on each value. This would add the missing '0's.</p>
","1624165"
"GetAsyncKeyState's return values don't seem to correspond with the description","4715","","<p>I investigated <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/ms646293%28v=vs.85%29.aspx"" rel=""nofollow"">GetAsyncKeyState</a> after seeing it in a code example on how to make a fictional character move on the screen through the WASD keys.</p>

<p>I read this on its MSDN page:</p>

<blockquote>
  <p><strong>Return value</strong></p>
  
  <p>Type: <em>SHORT</em></p>
  
  <p>If the function succeeds, the return value specifies whether the key
  was pressed since the last call to GetAsyncKeyState, and whether the
  key is currently up or down.</p>
  
  <p><em>If the most significant bit is set, the
  key is down, and if the least significant bit is set, the key was
  pressed after the previous call to GetAsyncKeyState.</em></p>
</blockquote>

<p>I'm having trouble understanding the structure of the return value:</p>

<p>It says the type is <code>short</code>, so through it I suppose you could represent the number zero, in binary, as <code>0000000000000000</code>, or in hex as <code>0x0000</code> (since as far as I know one hex digit represents four binary digits).</p>

<p>The description says that the <em>most significant bit</em> should be set when the key is pressed. That makes me think that, if said bit was set, the number would appear like this:</p>

<pre><code>1000000000000000
</code></pre>

<p>To make better use of it in my program, I shortened it by translating it to hex, resulting into:</p>

<pre><code>0x8000
</code></pre>

<p>Because <code>8</code> in hex should correspond to <code>1000</code> in binary.</p>

<p>When I saw that said mechanism was not working in my program (doing <code>GetAsyncKeyState(chr) == 0x8000</code> would always yield false, no matter if the key was pressed or not) I took one more look to the original example I saw the function employed in first. There, the return value was being compared with the number <code>-32767</code>, which, when quickly translated to hex using the Windows calculator, results into the value <code>0xFFFFFFFFFFFF8001</code>. Now, don't mind the last hex digit (1) because that's the bit used to check whether the least significant bit is also active, but I don't want that in my case.</p>

<p>The things that I can't understand here are the following:</p>

<ol>
<li>Why, if one hex digit represents four binary digits, and the output value of the function is a short (two bytes), here the number is represented by sixteen hex digits? Aren't those eight bytes?</li>
<li>The description of the return value said that the <em>most significant bit</em> would be set to 1 if the key was being pressed, and that led me to believe that the number would look like <code>1000000000000000</code>, not <code>0000000000001000</code>. What am I missing here?</li>
</ol>
","<pre><code>GetAsyncKeyState(chr) == 0x8000
</code></pre>

<p>This is incorrect check. Use:</p>

<pre><code>!!(GetAsyncKeyState(chr) &amp; 0x8000)
</code></pre>

<p>to see if the most-significant bit is set.</p>

<p>The value <code>0xFFFFFFFFFFFF8001</code> doesn't correspond to the actual returned value from GetAsyncKeyState. Windows calculator doesn't know the size of the value returned from GetAsyncKeyState, so it assumes you're working with 64-bit number. You can override it in its settings.</p>
","7895965"
"Get binary value of any file","4712","","<p>If suppose I have a file such as <code>music.mp3</code> or <code>image.jpg</code> or any file to be considered. How do i get the binary representation of those files to a string value in java so that i can view it ??</p>

<p>Eg: Suppose I have file called <code>'video.mp4'</code> then it must be represented as <code>101011010101000111010</code> or something like that in memory i need to get the value and store it in String like <code>String s = ""101011010101000111010""</code></p>

<p>Does anyone have any idea on how to do this in java ??</p>

<p>EDIT 2
How can i convert back the string to the actual file ??</p>
","<p>I would suggest hexadecimal, it's much more compact and readable</p>

<pre><code>    StringBuilder sb = new StringBuilder();
    try (BufferedInputStream is = new BufferedInputStream(new FileInputStream(""1.txt""))) {
        for (int b; (b = is.read()) != -1;) {
            String s = Integer.toHexString(b).toUpperCase();
            if (s.length() == 1) {
                sb.append('0');
            }
            sb.append(s).append(' ');
        }
    }
    System.out.println(sb);
</code></pre>

<p>output </p>

<pre><code>71 77 65 77 65 72 0D 0A 71 77 72 65 0D 0A 72 77 65 72 0D 0A 
</code></pre>

<p>for binary string change the code</p>

<pre><code>            String s = ""0000000"" + Integer.toBinaryString(b);
            s = s.substring(s.length() - 8); 
            sb.append(s).append(' ');
</code></pre>

<p>and get this output</p>

<pre><code>01110001 01110111 01100101 01110111 01100101 01110010 00001101 00001010 
</code></pre>

<p>and this is how to parse the string and write back to a file</p>

<pre><code>    BufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(""2.txt""));
    Scanner sc = new Scanner(s);
    while (sc.hasNextInt()) {
        int b = sc.nextInt(2);
        out.write(b);
    }
    out.close();
</code></pre>
","14396105"
"Turning binary string into an image with PIL","4709","","<p>So, what I'm trying to do is have PIL create an image based on a string of binary. 
Some backstory:</p>

<pre><code>from PIL import Image

value = ""0110100001100101011011000110110001101111""
vdiv = [value[i:i+8] for i in range(0, len(value), 8)]
</code></pre>

<p>^This creates a list of bytes from the binary string. <code>['01101000', '01100101',.....]</code></p>

<pre><code>def diff(inp):
    if inp == '1':
        return (0,0,0)
    if inp == '0':
        return (255,255,255)
    else:
        pass
</code></pre>

<p>^This returns a color tuple for each corresponding bit, and if I call:</p>

<pre><code>for i in vdiv:
    for i2 in i:
        print diff(i2)
</code></pre>

<p>It will print every color tuple for each bit in the bytes listed. <code>(0,0,0) (0,0,0) (255,255,255)...</code></p>

<p>What I want to know is, How can I get PIL to create an image where the pixels match the binary string?</p>

<p><strong>Here is what it should look like.</strong>: <img src=""https://i.imgur.com/QwToLCm.png"" alt=""screenshot""></p>

<p>What I have so far for PIL:</p>

<pre><code>img = Image.new( 'RGB', (8,len(vdiv)), ""white"")
pixels = img.load()

##
for x in range(img.size[0]):
    for y in range(img.size[1]):
        for i in vdiv:
            for i2 in i:
                pixels[x,y] = diff(i2) #Creates a black image. What do?
##

img.show()
</code></pre>

<p>It is the <code>for x in range</code> bit that gets me. I am lost.</p>
","<p>You could use <code>img.putdata</code>:</p>

<pre><code>import Image

value = ""0110100001100101011011000110110001101111""

cmap = {'0': (255,255,255),
        '1': (0,0,0)}

data = [cmap[letter] for letter in value]
img = Image.new('RGB', (8, len(value)//8), ""white"")
img.putdata(data)
img.show()        
</code></pre>

<p><img src=""https://i.stack.imgur.com/TYtyb.png"" alt=""enter image description here""></p>

<hr>

<p>If you have NumPy, you could instead use <code>Image.fromarray</code>:</p>

<pre><code>import Image
import numpy as np

value = ""0110100001100101011011000110110001101111""

carr = np.array([(255,255,255), (0,0,0)], dtype='uint8')
data = carr[np.array(map(int, list(value)))].reshape(-1, 8, 3)
img = Image.fromarray(data, 'RGB')
img.save('/tmp/out.png', 'PNG')
</code></pre>

<p>but this timeit test suggests using <code>putdata</code> is faster:</p>

<pre><code>value = ""0110100001100101011011000110110001101111""*10**5

def using_fromarray():
    carr = np.array([(255,255,255), (0,0,0)], dtype='uint8')
    data = carr[np.array(map(int, list(value)))].reshape(-1, 8, 3)
    img = Image.fromarray(data, 'RGB')
    return img

def using_putdata():
    cmap = {'0': (255,255,255),
            '1': (0,0,0)}

    data = [cmap[letter] for letter in value]
    img = Image.new('RGB', (8, len(value)//8), ""white"")
    img.putdata(data)
    return img
</code></pre>

<hr>

<pre><code>In [79]: %timeit using_fromarray()
1 loops, best of 3: 1.67 s per loop

In [80]: %timeit using_putdata()
1 loops, best of 3: 632 ms per loop
</code></pre>
","24269930"
"How would I encode a binary file to JPG format?","4708","","<p>I would like to be able to take a stream of 1's and 0's and convert it to a format that jpg can read, I.E. suppose I wrote a program and compiled and got an exe, then took and ran the 1's and 0's from the exe through said program, it would produce a .jpg. Any tips on what I need to do? I am hoping it's not as difficult as I'm suspecting it is.</p>

<p>Update: Suppose you took any old image, and brought it down to the (I suppose) Raw format, just one's and zero's, now suppose you took those 1's and 0's and somehow decoded them what kind of program would you get (obviously not a functioning one), but now I was thinking suppose we went the other way and took a .exe and lined all the 1's and 0's in some format that an ""image"" looks like, is it possible to see a picture, that's what I would like to discover. (I hope that explains what I'm interested in), so no the format doens't really matter, it could be bmp for all I care, just I want to see if there is in any way an image in a program that is distinguishable in a program.</p>
","<p>This kinda sounds silly, but by changing the extension to .raw, the file is automatically opened in photoshop (or Gimp in my case) and you can see what the ""bit patterns"" look like. That is kinda what I was aiming for.</p>
","12312064"
"Matlab binary encoding","4694","","<p>I have a vector containing a series of integers, and what I want to do is take all numbers, convert them into their corresponding binary forms, and concatenate all of the resulting binary values together. Is there any easy way to do this?</p>

<p>e.g. a=[1 2 3 4] --> b=[00000001 00000010 00000011 00000100] --> c=00000001000000100000001100000100</p>
","<p>Try:</p>

<pre><code>b = dec2bin(a)
</code></pre>
","4160681"
"What is the difference between plain binary format (.bin) and Windows Executable (.exe)?","4693","","<p>What is the difference between plain binary format (.bin) and Windows Executable (.exe)?</p>
","<p>I'm not sure what a ""bin"" file is in this case. Could be a firmware, could be an object file, could be anything really (it depends on context). </p>

<p>When talking about executables (exe files in the case of windows) these are usually self contained packages with everything required to run them packed in. These file formats usually contain all the executable data, string and other resources, linking data and exports, offsets, and other data stuffed in them. They have everything required for the OS to setup and enviroment to run them, like the dependent libraries that need to be loaded, the architecture it needs to run, etc. </p>

<p>There are lots of different ones in common use:</p>

<ul>
<li><strong>PE</strong> your standard windows executable and dll format (<a href=""http://en.wikipedia.org/wiki/Portable%5FExecutable"" rel=""noreferrer"">http://en.wikipedia.org/wiki/Portable_Executable</a>)</li>
<li><strong>ELF</strong> used by Linux and other UNIX clones (<a href=""http://en.wikipedia.org/wiki/Executable_and_Linkable_Format"" rel=""noreferrer"">http://en.wikipedia.org/wiki/Executable_and_Linkable_Format</a>)</li>
<li><strong>Mach-O</strong> used by your Mac executables (<a href=""http://en.wikipedia.org/wiki/Mach-O"" rel=""noreferrer"">http://en.wikipedia.org/wiki/Mach-O</a>)</li>
<li><strong>a.out</strong> sort of legacy executable package (<a href=""http://en.wikipedia.org/wiki/A.out"" rel=""noreferrer"">http://en.wikipedia.org/wiki/A.out</a>)</li>
</ul>

<p>Lots of others (COFF, COM, etc).  </p>

<p>If the operating system supports dynamically linkable libraries (dlls on windows, .so files on linux, dylibs on mac) then they usually share this same packaging format.  </p>
","1936877"
"How is an integer stored in memory?","4692","","<p>This is most probably the dumbest question anyone would ask, but regardless I hope I will find a clear answer for this.</p>

<p>My question is - How is an integer stored in computer memory?</p>

<p>In c# an integer is of size 32 bit. MSDN says we can store numbers from -2,147,483,648 to 2,147,483,647 inside an integer variable.</p>

<p>As per my understanding a bit can store only 2 values i.e 0 &amp; 1. If I can store only 0 or 1 in a bit, how will I be able to store numbers 2 to 9 inside a bit?</p>

<p>More precisely, say I have this code <code>int x = 5</code>; How will this be represented in memory or in other words how is 5 converted into 0's and 1's, and what is the convention behind it?</p>
","<p>It's represented in binary (base 2). <a href=""http://en.wikipedia.org/wiki/Radix"" rel=""noreferrer"">Read more about number bases</a>. In base 2 you only need 2 different symbols to represent a number. We usually use the symbols <code>0</code> and <code>1</code>. In our usual base we use <code>10</code> different symbols to represent all the numbers, <code>0</code>, <code>1</code>, <code>2</code>, ... <code>8</code>, and <code>9</code>.</p>

<p>For comparison, think about a number that doesn't fit in our usual system. Like 14. We don't have a symbol for 14, so how to we represent it? Easy, we just combine two of our symbols <code>1</code> and <code>4</code>. <code>14</code> in base 10 means <code>1*10^1 + 4*10^0</code>.</p>

<p><code>1110</code> in base 2 (binary) means <code>1*2^3 + 1*2^2 + 1*2^1 + 0*2^0 = 8 + 4 + 2 + 0 = 14</code>. So despite not having enough symbols in either base to represent <code>14</code> with a single symbol, we can still represent it in both bases.</p>

<p>In another commonly used base, base 16, which is also known as hexadecimal, we have enough symbols to represent <code>14</code> using only one of them. You'll usually see <code>14</code> written using the symbol <code>e</code> in hexadecimal.</p>

<p>For negative integers we use a convenient representation called twos-complement which is the complement (all <code>1</code>s flipped to <code>0</code> and all <code>0</code>s flipped to <code>1</code>s) with one added to it.</p>

<p>There are two main reasons this is so convenient:</p>

<ul>
<li><p>We know immediately if a number is positive of negative by looking at a single bit, the most significant bit out of the <code>32</code> we use.</p></li>
<li><p>It's mathematically correct in that <code>x - y = x + -y</code> using regular addition the same way you learnt in grade school. This means that processors don't need to do anything special to implement subtraction if they already have addition. They can simply find the twos-complement of <code>y</code> (recall, flip the bits and add one) and then add <code>x</code> and <code>y</code> using the addition circuit they already have, rather than having a special circuit for subtraction.</p></li>
</ul>
","18518095"
"Accessing binary MP3 Header in C via fopen","4673","","<p>I am trying to extract the mp3 header from a file. This is different then the ID3 tags -- the mp3 header is where information about the MPEG version, bit rate, frequency, etc is held.</p>

<p>You can see an overview of the mp3 header structure here: <a href=""http://upload.wikimedia.org/wikipedia/commons/0/01/Mp3filestructure.svg"" rel=""nofollow noreferrer"">http://upload.wikimedia.org/wikipedia/commons/0/01/Mp3filestructure.svg</a></p>

<p>My problem is, despite loading the file and now receiving valid (as far as I know) binary output, I am not seeing the expected values. The first 12 bits of the mp3 file should be all ones, for the mp3 sync word. However, I am receiving something different for the first 8 bits alone. This would suggest a problem  to me.</p>

<p>As a side note, I have a valid mp3 file being attached via fopen</p>

<pre><code>// Main function
int main (void)
{
    // Declare variables
    FILE *mp3file;
    char requestedFile[255] = """";
    unsigned long fileLength;

    // Counters
    int i;

    // Tryout
    unsigned char byte; // Read from file
    unsigned char mask = 1; // Bit mask
    unsigned char bits[8];

    // Memory allocation with malloc
    // Ignore this at the moment! Will be used in the future
    //mp3syncword=(unsigned int *)malloc(20000);

    // Let's get the name of the file thats requested
    strcpy(requestedFile,""testmp3.mp3""); // lets hardcode this into here for now

    // Open the file
    mp3file = fopen(requestedFile, ""rb""); // open the requested file with mode read, binary
    if (!mp3file){
        printf(""Not found!""); // if we can't find the file, notify the user of the problem
    }

    // Let's get some header data from the file
    fseek(mp3file,0,SEEK_SET);
    fread(&amp;byte,sizeof(byte),1,mp3file);

    // Extract the bits
    for (int i = 0; i &lt; sizeof(bits); i++) {
        bits[i] = (byte &gt;&gt; i) &amp; mask;
    }

    // For debug purposes, lets print the received data
    for (int i = 0; i &lt; sizeof(bits); i++) {
        printf(""Bit: %d\n"",bits[i]);
    }
</code></pre>
","<p>The ID3 info may come first. Are the first 3 characters <code>ID3</code>?</p>
","1683382"
"Bitwise operation - Zero-fill right shift (>>>) usages?","4672","","<p>Generally speaking , bit shifting  (<code>&gt;&gt; , &lt;&lt;</code>)allows us to divide / multiply by <code>^2</code></p>

<p>Example : </p>

<pre><code>      9 (base 10): 00000000000000000000000000001001 (base 2)
                   --------------------------------
 9 &gt;&gt; 2 (base 10): 00000000000000000000000000000010 (base 2) 
</code></pre>

<p>= 2 (base 10)</p>

<p>For <strong>negative</strong> numbers : </p>

<p>Likewise, <code>-9 &gt;&gt; 2</code> yields <code>-3</code>, because the sign is preserved:</p>

<pre><code>     -9 (base 10): 11111111111111111111111111110111 (base 2)
                   --------------------------------
-9 &gt;&gt; 2 (base 10): 11111111111111111111111111111101 (base 2) = -3 (base 10)
</code></pre>

<p>But looking at <code>&gt;&gt;&gt;</code> which acts the same for positive numbers ,m but behaves differently for negative numebrs : </p>

<p><a href=""https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Bitwise_Operators"" rel=""nofollow"">mdn</a></p>

<blockquote>
  <p><strong>Zero</strong> bits are shifted in from the left</p>
</blockquote>

<p>I can't find any reason / usage for shifting  <code>0</code> from the left ( which makes the whole number positive) from the left : </p>

<pre><code>       -9 (base 10): 11111111111111111111111111110111 (base 2)
                     --------------------------------
 -9 &gt;&gt;&gt; 2 (base 10): 00111111111111111111111111111101 (base 2) = 1073741821 (base 10)
</code></pre>

<p><strong>Question :</strong> </p>

<p>In what scenarios should I use <code>&gt;&gt;&gt;</code>   ? I don't understand why should I ever want to pad zeros from the left and mess my negative number.</p>
","<p>Let's say you were programming something to mimic a piece of hardware, specifically a <a href=""http://en.wikipedia.org/wiki/Shift_register"" rel=""nofollow"">shift register</a>.</p>

<p>To make things easier I'll use 8 bits instead of 32 bits as in your question.</p>

<p>We can add 128 every time we want to feed a high bit into this shift-register, since it will make the leftmost bit 1.</p>

<pre><code>// Assume n is initialised to 0, so n = 00000000 in binary
n += 128;                    // now n = 10000000 in binary
</code></pre>

<p>If we shift using >>> every time you want to simulate a clock cycle, then after 8 ""clock cycles"" we will have that 1 at the rightmost bit. If we read that rightmost bit out then we will get a delayed version of what was fed into the leftmost bit 8 cycles ago.</p>

<hr>

<p>This is only one example where the bits are not interpreted as a number, and I am sure there are many more. I think you'll find a few more uses elsewhere, especially in software meant to mimic hardware circuits/building blocks.</p>
","20054337"
"Writing binary data using node.js fs.writeFile to create an image file","4672","","<p>I'm trying to write a canvas data with node.js <a href=""https://nodejs.org/api/fs.html#fs_fs_writefile_file_data_options_callback"" rel=""nofollow noreferrer""><code>fs.writeFile</code></a> as a binary .JPEG file, but after the file is written I can see that the file is stored as plain test, not binary data.</p>

<p>This is an example of the <code>data</code> sent from the client to my node, representing the JPEG image data (just the few first characters):</p>

<p><code>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAFA3PEY8MlBGQUZaVVBfeM...</code></p>

<p>I'm getting this <code>data</code> <strong>on the client side</strong> by performing:</p>

<pre><code>canvas.toDataURL('image/jpeg', 0.5).replace('data:image/jpeg;base64,', '')
</code></pre>

<p>Here is the function usage in my <strong>node.js server</strong>:</p>

<pre><code>fs.writeFile('../some.jpeg', data, 'binary', function(err){});
</code></pre>

<p>Instead of the file being written as binary (<code>״״ JFIF  ...</code>), it writes exactly the data it recieved from the client.</p>

<p>What am I doing wrong here?</p>
","<blockquote>
  <p><code>JavaScript</code> language had no mechanism for reading or manipulating streams of binary data. The <code>Buffer</code> class was introduced as part of the Node.js API to make it possible to interact with octet streams in the context of things like TCP streams and file system operations.</p>
</blockquote>

<p>Pure <code>javascript</code>, while great with <code>unicode-encoded</code> strings, does not handle straight binary data very well.</p>

<p>When writing large amounts of data to a <code>socket</code>, it's much more efficient to have that data in <code>binary</code> format, vs having to convert from <code>unicode</code>.</p>

<pre><code>var fs = require('fs');
// string generated by canvas.toDataURL()
var img = ""data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0""
    + ""NAAAAKElEQVQ4jWNgYGD4Twzu6FhFFGYYNXDUwGFpIAk2E4dHDRw1cDgaCAASFOffhEIO""
    + ""3gAAAABJRU5ErkJggg=="";
// strip off the data: url prefix to get just the base64-encoded bytes
var data = img.replace(/^data:image\/\w+;base64,/, """");
var buf = new Buffer(data, 'base64');
fs.writeFile('image.png', buf);
</code></pre>

<p><a href=""https://gist.github.com/madhums/e749dca107e26d72b64d"" rel=""nofollow noreferrer""><strong>Reference</strong></a></p>
","43488020"
"What number in binary can only be represented as an approximation?","4665","","<p>In decimal (base 10), <code>1/3</code> can only be approximated to 0.33333 repeating. </p>

<p>What number is the equivalent in binary that can only be represented as an approximation?</p>
","<p>0.1 is one such example, as well as 0.2</p>

<p>This question is also similar to <a href=""https://stackoverflow.com/questions/1089018/why-cant-decimal-numbers-be-represented-exactly-in-binary""><strong>this other SO question</strong></a>, which already has very good answers.</p>
","1674502"
"Decimal to Binary conversion method Objective-C","4660","","<p>Hi I am trying to make a Decimal to binary number converter in Objective-C but have been unsucessful... I have the following method so far which is an attempted translation from Java for a similar method. Any help to make this method work is much appreciated.</p>

<pre><code> +(NSString *) DecToBinary: (int) decInt
{
    int result = 0;
    int multiplier;
    int base = 2;
    while(decInt &gt; 0)
    {
        int r = decInt % 2;
        decInt = decInt / base;
        result = result + r * multiplier;
        multiplier = multiplier * 10;
    }
return [NSString stringWithFormat:@""%d"",result];
</code></pre>
","<p>I would use bit shifting to reach each bit of the integer</p>

<pre><code>x = x &gt;&gt; 1;
</code></pre>

<p>moves the bits by one to the left, the decimal 13 is represente in bits as 1101, so shifting it to the right turns creates 110 -> 6.</p>

<pre><code>x&amp;1
</code></pre>

<p>is the bit masking x with 1</p>

<pre><code>  1101
&amp; 0001
------
= 0001
</code></pre>

<p>Combined these lines will iterate form the lowest to highest bit and we can add this bit as formatted integer to a string.</p>

<p>For unsigned int it could be this.</p>

<pre><code>#import &lt;Foundation/Foundation.h&gt;

@interface BinaryFormatter : NSObject
+(NSString *) decToBinary: (NSUInteger) decInt;
@end

@implementation BinaryFormatter

+(NSString *)decToBinary:(NSUInteger)decInt
{
    NSString *string = @"""" ;
    NSUInteger x = decInt;

    while (x&gt;0) {
        string = [[NSString stringWithFormat: @""%lu"", x&amp;1] stringByAppendingString:string];
        x = x &gt;&gt; 1;
    }
    return string;
}
@end

int main(int argc, const char * argv[])
{
    @autoreleasepool {
        NSString *binaryRepresentation = [BinaryFormatter decToBinary:13];
        NSLog(@""%@"", binaryRepresentation);
    }
    return 0;
}
</code></pre>

<p>this code will return <code>1101</code>, the binary representation of 13.</p>

<hr>

<p>Shorter form with do-while, <code>x &gt;&gt;= 1</code> is the short form of <code>x = x &gt;&gt; 1</code>:</p>

<pre><code>+(NSString *)decToBinary:(NSUInteger)decInt
{
    NSString *string = @"""" ;
    NSUInteger x = decInt ;
    do {
        string = [[NSString stringWithFormat: @""%lu"", x&amp;1] stringByAppendingString:string];
    } while (x &gt;&gt;= 1);
    return string;
}
</code></pre>
","22366831"
"What is the purpose of hex-encoding for binary data?","4657","","<p>I'm a bit curious as to why one would want to use hex encoding over base64.  It seems to me that base 64 is more efficient.  In particular, why is it that databases seem to always use hex encoding?  Is it a historical issue, or am I missing something about hex encoding?</p>
","<p>You must be a real geek to read <code>BASE64</code> off the screen.</p>

<p>In <code>Oracle</code>, when I run <code>HEXTORAW</code>, I can get some idea of what's in a <code>RAW</code> field, but I couldn't with <code>BASE64</code>.</p>

<p>Like, when I see lots of <code>0x3F</code>'s, I know there's something with encoding.</p>

<p>And internally, these are just binary bytes, there is no other need to encode them but to show to a person on the other side of the screen.</p>
","1014338"
"Writing vector<double> to binary file and reading it again","4657","","<p>I'm trying to write a vector of doubles to a binary file.
After doing this I want to read it. This doesn't seem to work.
Here is the code:</p>

<pre><code>ofstream bestand;
vector&lt;double&gt; v (32);
const char* pointer = reinterpret_cast&lt;const char*&gt;(&amp;v[0]);
size_t bytes = v.size() * sizeof(v[0]);
bestand.open(""test"",ios::out | ios::binary);
for(int i = 0; i &lt; 32; i++)
{
   v[i] = i;
   cout &lt;&lt; i;
   }
bestand.write(pointer, v.size());
bestand.close();
ifstream inlezen;
vector&lt;double&gt; v2 (32);
inlezen.open(""test"", ios::in | ios::binary);
char byte[8];
bytes = v2.size() * sizeof(v2[0]);
inlezen.read(reinterpret_cast&lt;char*&gt;(&amp;v2[0]), bytes);
for(int i =0; i &lt; 32; i++){

 cout &lt;&lt; endl &lt;&lt; v2[i] &lt;&lt; endl;
 }
</code></pre>

<p>This outputs ""0 1 2 3 0 0 0......"" so it seems it reads the first 4 numbers correctly.</p>
","<p>This <code>.write()</code> takes the number of <em>bytes</em>, not the number of <em>items</em> to write:</p>

<pre><code>bestand.write(pointer, v.size());
</code></pre>

<p>Since you've already computed the correct value, use it:</p>

<pre><code>bestand.write(pointer, bytes );
</code></pre>
","13365159"
"Convert from hexadecimal to binary C++","4656","","<p>This kind of builds up on <a href=""https://stackoverflow.com/questions/483609/how-can-i-convert-hex-numbers-to-binary-in-c"">Already asked question</a>...
However here, say, I'm given a hexadecimal input which could be a max of '0xFFFF'
I'll need it converted to binary, so that I'd end up with a max of 16 bits.</p>

<p>I was wondering if using 'bitset' it'd be quite simple.. Any ideas?</p>

<p><strong>EDIT :</strong> </p>

<p>After getting answers, improvised piece of code here : <a href=""http://pastebin.com/f7a6f0a69"" rel=""nofollow noreferrer"">http://pastebin.com/f7a6f0a69</a></p>
","<p>Supposing by ""hexadecimal input"" you mean a string containing a hexadecimal number, then this would work: </p>

<pre><code>const char* const str = ""0xFFFF"";
std::istringstream iss(str);
int i;
iss &gt;&gt; std::hex &gt;&gt; i;
if(!iss &amp;&amp; !iss.eof()) throw ""dammit!"";
std::cout &lt;&lt; '""' &lt;&lt; str &lt;&lt; ""\"": "" &lt;&lt; i &lt;&lt; ""(0x"" &lt;&lt; std::hex &lt;&lt; i &lt;&lt; "")\n"";
</code></pre>
","1815019"
"Binary to Date (C#) 64 Bit Format","4651","","<p>We have a binary file from which we have identified the following dates (as Int64). We now the following facts about the Date/Time format;</p>

<ul>
<li>The 64 bit Date has a resolution to the microsecond</li>
<li>The 64 bit Date has a range of 4095 years</li>
<li>The Int64 9053167636875050944 (0x7DA34FFFFFFFFFC0) = 9th March 2010</li>
<li>The Int64 9053176432968073152 (0x7DA357FFFFFFFFC0) = 10th March 2010</li>
<li>The Int64 9053185229061095360 (0x7DA35FFFFFFFFFC0) = 11th March 2010</li>
<li>The Int64 9053194025154117568 (0x7DA367FFFFFFFFC0) = 12th March 2010</li>
</ul>

<p>Any help on figuring out a way to convert this to a valid C# Date/Time is appreciated.</p>
","<p>Here is a solution:</p>

<pre><code>string hex_data = ""7DA34FFFFFFFFFC0"";
        Int64 int_datetime = Convert.ToInt64(hex_data, 16);

        int year = (int)(int_datetime &gt;&gt; 52);
        int month = (int)((int_datetime &gt;&gt; 48) &amp; 0x0F);
        int day = (int)(((int_datetime &gt;&gt; 43) &amp; 0x1F));

        int hour = (int)(((int_datetime &gt;&gt; 38) &amp; 0x1F)) &gt; 24 ? 0 : (int)(((int_datetime &gt;&gt; 38) &amp; 0x1F));
        int min = (int)(((int_datetime &gt;&gt; 32) &amp; 0x3F)) &gt; 60 ? 0 : (int)(((int_datetime &gt;&gt; 32) &amp; 0x3F));
        int sec = (int)(((int_datetime &gt;&gt; 26) &amp; 0x3F)) &gt; 60 ? 0 : (int)(((int_datetime &gt;&gt; 26) &amp; 0x3F));
        int mili_sec = (int)(((int_datetime &gt;&gt; 16) &amp; 0x3FF)) &gt; 100 ? 0 : (int)(((int_datetime &gt;&gt; 16) &amp; 0x3FF));
        int micro_sec = (int)(((int_datetime &gt;&gt; 6) &amp; 0x3FF)) &gt; 100 ? 0 : (int)(((int_datetime &gt;&gt; 6) &amp; 0x3FF));

        string str_date_time = year.ToString(""D4"") + ""/"" + month.ToString(""D2"") + ""/"" + day.ToString(""D2"") + "" "" + hour.ToString(""D2"") + "":"" + min.ToString(""D2"") + "":"" 
            + sec.ToString(""D2"") + ""."" + mili_sec.ToString(""D3"");

        DateTime date_time_dt=DateTime.Parse(str_date_time);
</code></pre>

<p>Returns:</p>

<pre><code>09/03/2010 12:00:00 AM
</code></pre>

<p>in the date_time_dt object. I don't think the DateTime object supports microseconds in C#, but I may be wrong. </p>
","2630844"
"php mysql update blob","4649","","<p>New to PHP/mySql and having trouble inserting and retrieving binary data.  I have a mySql table called usr_pressdata.  The field 'BinDat' is of type mediumblob.</p>

<pre><code>$dat = $this-&gt;parseOverview($sql);
    // $dat is now a binary string

$datsql = ""Update usr_pressdata Set BinDat = "" . $dat;
$datresult = mysql_query($datsql, $this -&gt; conn) or die(mysql_error());

$getdat = ""Select * from usr_pressdata"";
$getdatresult = mysql_query($getdat, $this -&gt; conn) or die(mysql_error());
$row = mysql_fetch_array( $getdatresult );
   $retval = $row['BinDat'];
</code></pre>

<p>In this example my goal is that $retval == $dat but it does not.  I suspect that my query string $datsql is incorrect.  Can someone correct this example code?  Thank you.</p>
","<p>When inserting values in a table (or more generally, when including a value in an SQL request):</p>

<ol>
<li>the string must be enclosed between quotes ('...')</li>
<li>the string must be “escaped” using <code>mysql_real_escape_string</code> so as to prevent <a href=""http://en.wikipedia.org/wiki/SQL_injection"" rel=""nofollow"">SQL injection</a>.</li>
</ol>

<p>So you need to write something like:</p>

<pre><code>$request = ""UPDATE usr_pressdata SET bindat= '"" . mysql_real_escape_string($dat) . ""';"";
</code></pre>

<p>I suspect you may want to add a <code>WHERE someColumn = someCondition</code> clause at the end, because as it is now, it would affect all the rows in the table.</p>
","5056118"
"Hex to binary conversion java","4645","","<p>I have the following code</p>

<pre><code>temp = ""0x00""
String binAddr = Integer.toBinaryString(Integer.parseInt(temp, 16)); 
</code></pre>

<p>Why do I get the following error:</p>

<p><code>Exception in thread ""AWT-EventQueue-0"" java.lang.NumberFormatException: For input string: ""0x00""</code></p>
","<p>Since the string contains <code>0x</code>, use <a href=""http://docs.oracle.com/javase/7/docs/api/java/lang/Integer.html#decode%28java.lang.String%29"" rel=""nofollow"">Integer.decode(String nm)</a>:</p>

<pre><code>String binAddr = Integer.toBinaryString(Integer.decode(temp));
</code></pre>
","19493635"
"How to access findNonZero coordinates stored in Mat C++","4645","","<p>I am a beginner with OpenCV and I have read some tutorials and manuals but I couldn't quite make sense of some things.</p>

<p>Currently, I am trying to crop a binary image into two sections. I want to know which row has the most number of white pixels and then crop out the row and everything above it and then redraw the image with just the data below the row with the most number of white pixels.</p>

<p>What I've done so far is to find the coordinates of the white pixels using findNonZero and then store it into a Mat. The next step is where I get confused. I am unsure of how to access the elements in the Mat and figuring out which row occurs the most in the array.</p>

<p>I have used a test image with my code below. It gave me the pixel locations of [2,0; 1,1; 2,1; 3,1; 0,2; 1,2; 2,2; 3,2; 4,2; 1,3; 2,3; 3,3; 2,4]. Each element has a x and y coordinate of the white pixel. First of all how do I access each element and then only poll the y-coordinate in each element to determine the row that occurs the most? I have tried using the at&lt;>() method but I don't think I've been using it right.</p>

<p>Is this method a good way of doing this or is there a better and/or faster way? I have read a different method <a href=""https://stackoverflow.com/questions/8081222/counting-bright-pixels-and-summing-them-medical-image-c/8081502#8081502"">here</a> using L1-norm but I couldn't make sense of it and would this method be faster than mine?</p>

<p>Any help would be greatly appreciated.</p>

<p>Below is the code I have so far.</p>

<pre><code>#include &lt;opencv2\opencv.hpp&gt;
#include &lt;opencv2\imgproc\imgproc.hpp&gt;
#include &lt;opencv2\highgui\highgui.hpp&gt;

#include &lt;iostream&gt;

using namespace cv;
using namespace std;


int main()
{
    int Number_Of_Elements;
    Mat Grayscale_Image, Binary_Image, NonZero_Locations;

    Grayscale_Image = imread(""Test Image 6 (640x480px).png"", 0);
    if(!Grayscale_Image.data)
    {
        cout &lt;&lt;  ""Could not open or find the image"" &lt;&lt; endl;
        return -1;
    }

    Binary_Image = Grayscale_Image &gt; 128;

    findNonZero(Binary_Image, NonZero_Locations);
    cout &lt;&lt; ""Non-Zero Locations = "" &lt;&lt; NonZero_Locations &lt;&lt; endl &lt;&lt; endl;

    Number_Of_Elements = NonZero_Locations.total();
    cout &lt;&lt; ""Total Number Of Array Elements = "" &lt;&lt; Number_Of_Elements &lt;&lt; endl &lt;&lt; endl;

    namedWindow(""Test Image"",CV_WINDOW_AUTOSIZE);
    moveWindow(""Test Image"", 100, 100);
    imshow (""Test Image"", Binary_Image);

    waitKey(0);
    return(0);
}
</code></pre>
","<p>I expect the following to work:</p>

<pre><code>Point loc_i = NonZero_Locations.at&lt;Point&gt;(i);
</code></pre>
","15866628"
"Split a Large File In C++","4644","","<p>I'm trying to write a program that takes a large file (of any type) and splits it into many smaller ""chunks"".  I think I have the basic idea down, but for some reason I cannot create a chunk size over 12 kb.  I know there are a few solutions on google, etc. but I am more interested in learning what the origin of this limitation is then actually using the program to split files.  </p>

<pre><code>//This file splits are larger into smaller files of a user inputted size.
#include&lt;iostream&gt;
#include&lt;fstream&gt;
#include&lt;string&gt;
#include&lt;sstream&gt;
#include &lt;direct.h&gt; 
#include &lt;stdlib.h&gt;
using namespace std;

void GetCurrentPath(char* buffer)
{
 _getcwd(buffer, _MAX_PATH);
}


int main()
{
 // use the function to get the path
 char CurrentPath[_MAX_PATH];
 GetCurrentPath(CurrentPath);//Get the current directory (used for displaying output)

 fstream bigFile;
 string filename;
 int partsize;
 cout &lt;&lt; ""Enter a file name: "";
 cin &gt;&gt; filename;   //Recieve target file
 cout &lt;&lt; ""Enter the number of bites in each smaller file: "";
 cin &gt;&gt; partsize;   //Recieve volume size

 bigFile.open(filename.c_str(),ios::in | ios::binary);
 bigFile.seekg(0, ios::end);  // position get-ptr 0 bytes from end
 int size = bigFile.tellg();  // get-ptr position is now same as file size
 bigFile.seekg(0, ios::beg);  // position get-ptr 0 bytes from beginning

 for (int i = 0; i &lt;= (size / partsize); i++)
 {
  //Build File Name
  string partname = filename;  //The original filename
  string charnum;     //archive number
  stringstream out;    //stringstream object out, used to build the archive name
  out &lt;&lt; ""."" &lt;&lt; i;
  charnum = out.str();
  partname.append(charnum);  //put the part name together

  //Write new file part
  fstream filePart;   
  filePart.open(partname.c_str(),ios::out | ios::binary); //Open new file with the name built above
  //Check if near the end of file
  if (bigFile.tellg() &lt; (size - (size%partsize)))
  {
   filePart.write(reinterpret_cast&lt;char *&gt;(&amp;bigFile),partsize); //Write the selected amount to the file
   filePart.close();    //close file
   bigFile.seekg(partsize, ios::cur); //move pointer to next position to be written
  }
  //Changes the size of the last volume because it is the end of the file
  else 
  {
   filePart.write(reinterpret_cast&lt;char *&gt;(&amp;bigFile),(size%partsize)); //Write the selected amount to the file
   filePart.close();    //close file
  }
  cout &lt;&lt; ""File "" &lt;&lt; CurrentPath &lt;&lt; partname &lt;&lt; "" produced"" &lt;&lt; endl; //display the progress of the split
 }


 bigFile.close();
 cout &lt;&lt; ""Split Complete."" &lt;&lt; endl;
 return 0;
}
</code></pre>

<p>Any ideas?</p>
","<p>You are writing to the split file, but not reading from the bigfile.  What you are writing it the in-memory structure of the bigfile, not the contents of bigfile.  You need to allocate a buffer, read into it from bigfile and write it to the splitfile(s).</p>
","2541509"
"How to convert 4 byte IEEE (little endian) float binary representation to float","4640","","<p>I am decoding a binary file, which has decimal numbers represented by four bytes, little endian. For example, <code>94 53 F0 40</code> represents 7.510202. Unfortunately, Python is giving me 7.51020240784.</p>

<p>When I try to parse this data using <code>unpack(""&lt;f"",sampledata)[0]</code> I don't get exact representations of the original, due to the way Python stores values (for more information, see <a href=""http://bugs.python.org/issue4114"" rel=""nofollow"">http://bugs.python.org/issue4114</a>).</p>

<p>Unfortunately, I <em>do</em> need to get the <em>exact</em> same representation- regardless of discussions about the inaccuray of floats, because I need to write these values to a text file, with the same number of decimal places as they were initially written to the binary file with.</p>

<p>I'd rather stick to Python if possible, but am happy to implement a solution in C if necessary. The reason I cannot simply truncate the return of the unpack function, is that I cannot guarantee how many decimal places the original float had, for example <code>0C 02 0F 41</code> represents 8.938 according to my hex editor, from the original binary file, which only has 3 decimal places.</p>

<p>To be clear, I need to take four hex bytes as my input, and output either a text/ASCII or number representation of the IEEE 32-bit floating point number, that has the same number of decimal places as was intended by the creator of the file. The output I will use to create a CSV of the original binary data file, not for actually performing any calculations.</p>

<p>Any suggestions?</p>

<p>Example:</p>

<pre><code>from __future__ import print_function
from struct import *

print(""Should print 7.510202"")

hexbytes = b""\x94\x53\xF0\x40""

# 01101001 11001000 11110001 01000000
# should print 7.510202

print(unpack(""&lt;f"",hexbytes)[0])
</code></pre>
","<p>A 4-byte IEEE format floating point number holds approximately 7 digits. What you want to do is round the result of <code>unpack</code> to a total of 7 digits. From there the normal Python conversion from float to string will hide all the floating point nastiness from you.</p>

<pre><code>def magnitude(x):
    return 0 if x==0 else int(math.floor(math.log10(abs(x)))) + 1

def round_total_digits(x, digits=7):
    return round(x, digits - magnitude(x))

&gt;&gt;&gt; round_total_digits(struct.unpack('&lt;f', '\x94\x53\xF0\x40')[0])
7.510202
&gt;&gt;&gt; round_total_digits(struct.unpack('&lt;f', '\x0C\x02\x0F\x41')[0])
8.938
&gt;&gt;&gt; x = struct.unpack('&lt;f', struct.pack('&lt;f', 12345.67))[0]
&gt;&gt;&gt; x
12345.669921875
&gt;&gt;&gt; round_total_digits(x)
12345.67
</code></pre>

<p>Note that if your numbers did not originate from a direct conversion of a decimal number but were the result of a calculation, this could <em>reduce</em> the total accuracy. But not by much.</p>
","24682634"
"Java beginner: convert an image to a binary array","4631","","<p>this is what I've gone so far and I can't seem to go further because I don't understand bitwise operations on the RGB </p>

<pre><code>// Read from a file
File file = new File(""src/a.gif"");
image = ImageO.read(file);
int[] rgbarr = image.getRGB(0, 0, 13, 15, null, 0, 13);// image is 13*15 
System.out.println(rgbarr.length);
for (int i : rgbarr)
    {
        System.out.println(i);
    }
</code></pre>

<blockquote>
  <p>Output: was values such as -16777216 and -1 Because I've already made an image black and white just to ease my understanding </p>
</blockquote>

<p>But in our case here let's suppose it would be just random image , how do I get from normal RGB image to binary values (0 or 1) for each pixel.</p>
","<p>I'm betting that each int in the array is a packed ARGB value;</p>

<pre><code>boolean [] output = new boolean[rgbarr.length];
for ( int i=0; i&lt;rgbarr.length; ++i ) {
  int a = (rgbarr[i] &gt;&gt; 24 ) &amp; 0x0FF;
  int r = (rgbarr[i] &gt;&gt; 16 ) &amp; 0x0FF;
  int g = (rgbarr[i] &gt;&gt; 8  ) &amp; 0x0FF;
  int b = (rgbarr[i]       ) &amp; 0x0FF;
  output[i] = (0.30*r + 0.59*g + 0.11*b) &gt; 127;
}
</code></pre>

<p>The output equation I choose was taken from a definition of Luminance from wikipedia. You can change the scales so long as the coefficients add up to 1.</p>
","4770186"
"How to convert binary string to the byte array of 2 bytes in java","4628","","<p>I have binary string <code>String A = ""1000000110101110""</code>. I want to convert this string into byte array of length 2 in <code>java</code></p>

<p>I have taken the help of <a href=""https://stackoverflow.com/questions/17727310/convert-binary-string-to-byte-array"">this</a> link</p>

<p>I have tried to convert it into byte by various ways </p>

<ol>
<li><p>I have converted that string into decimal first and then apply the code to store into the byte array</p>

<pre><code>int aInt = Integer.parseInt(A, 2);
        byte[] xByte = new byte[2];
    xByte[0] = (byte) ((aInt &gt;&gt; 8) &amp; 0XFF);
    xByte[1] = (byte) (aInt &amp; 0XFF);
    System.arraycopy(xByte, 0, record, 0,
            xByte.length);
</code></pre></li>
</ol>

<p>But the values get store into the byte array are negative</p>

<pre><code>xByte[0] :-127
xByte[1] :-82
</code></pre>

<p>Which are wrong values.</p>

<p>2.I have also tried using </p>

<pre><code>byte[] xByte = ByteBuffer.allocate(2).order(ByteOrder.BIG_ENDIAN).putInt(aInt).array();
</code></pre>

<p>But it throws the exception at the above line like</p>

<pre><code>  java.nio.Buffer.nextPutIndex(Buffer.java:519)     at
  java.nio.HeapByteBuffer.putInt(HeapByteBuffer.java:366)   at
  org.com.app.convert.generateTemplate(convert.java:266)
</code></pre>

<p>What should i do now to convert the binary string to byte array of 2 bytes?Is there any inbuilt function  in <code>java</code> to get the byte array</p>
","<p>The answer you are getting </p>

<pre><code> xByte[0] :-127
 xByte[1] :-82
</code></pre>

<p>is right.</p>

<p>This is called 2's compliment Represantation.
1st bit is used as signed bit.</p>

<pre><code>0 for +ve
1 for -ve
</code></pre>

<p>if 1st bit is 0 than it calculates as regular.
but if 1st bit is 1 than it deduct the values of 7 bit from 128 and what ever the answer is presented in -ve form.</p>

<p>In your case
1st value is<code>10000001</code>
so 1(1st bit) for -ve and 128 - 1(last seven bits) = 127
so value is -127</p>

<p>For more detail read 2's complement representation.</p>
","18976720"
"how to convert binary to decimal in asm x86?","4614","","<p>I have no idea what is wrong with my coding in DISPLAY_IN_DECIMAL.
They kept giving me this error.</p>

<pre><code> Assembling: coa.asm
coa.asm(314) : error A2006:undefined symbol : decimalArray
 DISPLAY_IN_DECIMAL(3): Macro Called From
  coa.asm(314): Main Line Code
Press any key to continue . . .
</code></pre>

<p>I thought it might be something wrong with my decimalArray but I'm not sure what.     </p>

<p>This is the code part where I finish all of my binary display. Nothing seems wrong.    </p>

<pre><code>counter db 0
        X db 00000000B
        Y db 00000000B

        deciamlArray byte 8 DUP (' ')

        decimalResult db ?
        dec1 db ?

        .code
       DISPLAY_IN_BINARY MACRO result
            local L5, printBinary, print0, print1, nextBit

            PUSH ax
            MOV al, result
            MOV cx, 8

            printBinary:
            TEST al, 10000000b    ;1 in 10000000b indicate that the bit to be compare and print out
            JZ    print0
            JNZ print1

            print1:
            displayResult1  ;If bit of result not equal to 0 ,print 1
            SHL al, 1
            JMP nextBit

            print0:     ;If bit of result = 0,print 0
            displayResult0
            SHL al, 1
            JMP nextBit

            nextBit:
            LOOP printBinary

            POP ax
        ENDM  
</code></pre>

<p>But when I try to work on my decimal they gave me the error stated right above just now. 
I thought it might be something wrong with my decimalArray but I'm not sure.</p>

<pre><code>DISPLAY_IN_DECIMAL MACRO result
    local L1,L2,L3
    MOV SI, OFFSET result
    MOV DI, OFFSET decimalArray
    MOV decimalResult, 0
    MOV CX, 8

    L1:
        MOV AL, [SI]    
        CMP AL, '1'
        JE L2
        JMP L3
    L2 :
        MOV AL, 0
        MOV AL, [DI]
        ADD decimalResult, AL
        JMP L3
    L3:
        INC SI
        INC DI
        LOOP L1
    MOVZX AX, decimalResult
    MOV BL, 10
    DIV BL
    MOV BX, AX
    MOV DH, BH
    MOV dec1, BL
    MOVZX AX, dec1
    MOV BL, 10
    DIV BL
    MOV BX, AX

    MOV AH, 02H     ; print results
    MOV DL, BL
    ADD DL, 30H
    INT 21H
    MOV DL, BH
    ADD DL, 30H
    INT 21H
    MOV DL, DH
    ADD DL, 30H
    INT 21H
 ENDM
</code></pre>
","<p>There's a typo in your code:</p>

<pre><code>deciamlArray byte 8 DUP (' ')
</code></pre>

<p>should be:</p>

<pre><code>decimalArray byte 8 DUP (' ')
</code></pre>
","20311413"
"Creating multiple numbers with certain number of bits set","4613","","<h2>Problem</h2>

<p>I need to create 32 Bit numbers (signed or unsigned doesn't matter, the highest bit will never be set anyway) and each number must have a given number of Bits set.</p>

<h2>Naive Solution</h2>

<p>The easiest solution is of course to start with the number of zero. Within a loop the number is now increased by one, the number of Bits is counted, if the count has the desired value, the number is stored to a list, if not the loop just repeats. The loop is stopped if enough numbers have been found. Of course this works just fine, but it's awfully slow once the number of desired Bits gets very high.</p>

<h2>A Better Solution</h2>

<p>The simplest number having (let's say) 5 Bits set is the number where the first 5 Bit are set. This number can be easily created. Within a loop the first bit is set and the number is shifted to the left by one. This loop runs 5 times and I found the first number with 5 Bits set. The next couple of numbers are easy to create as well. We now pretend the number to be 6 Bit wide and the highest one is not set. Now we start shifting the first zero bit to the right, so we get 101111, 110111, 111011, 111101, 111110. We could repeat this by adding another 0 to front and repeating this process. 0111110, 1011110, 1101110, etc. However that way numbers will grow much faster than necessary, as using this simple approach we leave out numbers like 1010111.</p>

<p>So is there a better way to create all possible permutations, a generic approach, that can be used, regardless how many bits the next number will have and regardless how many set bits we need set?</p>
","<p>You can use the <a href=""http://hackersdelight.org/hdcodetxt/snoob.c.txt"" rel=""nofollow noreferrer"">bit-twiddling hack from hackersdelight.org</a>.</p>

<p>In his book he has code to get the next higher number with the same number of one-bit set.</p>

<p>If you use this as a primitive to increase your number all you have to do is to find a starting point. Getting the first number with N bits set is easy. It's just 2^(N-1) -1.</p>

<p>You will iterate through all possible numbers very fast that way.</p>

<pre><code>  unsigned next_set_of_n_elements(unsigned x) 
  {
     unsigned smallest, ripple, new_smallest, ones;

     if (x == 0) return 0;
     smallest     = (x &amp; -x);
     ripple       = x + smallest;
     new_smallest = (ripple &amp; -ripple);
     ones         = ((new_smallest/smallest) &gt;&gt; 1) - 1;
     return ripple | ones;
  }

  // test code (shown for two-bit digits)

  void test (void)
  {
    int bits = 2;
    int a = pow(2,bits) - 1;
    int i;

    for (i=0; i&lt;100; i++)
    {
       printf (""next number is %d\n"", a);
       a = next_set_of_n_elements(a);
    }
  }
</code></pre>
","506862"
"c++ - properly writing std::string to binary file","4607","","<p>I am trying to get <strong><em>strings</em></strong> from <em>cin</em> and than write it to binary file.
I've read that writing pure string won't work, so I tried to convert it to char*.</p>

<p>The following code writes it ok (...probably), but <strong>only the first 8 chars, so the output in file is incomplete.</strong></p>

<pre><code>std::string nick, ip, port;

std::cout &lt;&lt; ""IP: "";
std::cin &gt;&gt; ip;
std::cout &lt;&lt; ""port: "";
std::cin &gt;&gt; port;

ofstream file1(""lastServers.bin"", ios::out | ios::binary);
if (file1.good())
{
    const char* p_IP = ip.c_str();
    const char* p_PORT = port.c_str();
    int length = sizeof(&amp;p_IP)+sizeof(&amp;p_PORT);
    char* tmp1 = new char[length];

    int index = 0;
    memcpy((tmp1 + index), p_IP, sizeof(&amp;p_IP));
    index = index + sizeof(&amp;p_IP);
    memcpy((tmp1 + index), p_PORT, sizeof(&amp;p_PORT));

    file1.write(tmp1, length);

    file1.close();
    delete[] tmp1;
}

else
{
    std::cout &lt;&lt; ""file error write"" &lt;&lt; endl;
}
</code></pre>

<hr>

<p><strong>Thanks in advance for any help :)</strong></p>
","<p>Your code can be written as</p>

<pre><code>ofstream file1(""lastServers.bin"", ios::out | ios::binary);
if (file1.good()) {
    file1.write(ip.c_str(), ip.size());
    file1.write(port.c_str(), port.size());
    file1.close();
}
else {
    std::cout &lt;&lt; ""file error write"" &lt;&lt; endl;
}
</code></pre>

<p>string::c_str() returns a const pointer to the text in the string.
string::size() returns the number of characters in the string.</p>

<p>You don't need to concatenate the data before writing to the file, writing one then the other has the same result.</p>

<p>If you wanted to write C type code rather than C++, you can use strlen(p_IP) to get the length of the IP string rather than using sizeof.</p>

<p>The sizeof operator gives you the size of the class instance, i.e. the size of the object BUT the string object's size is never affected by the size of the string it manages.</p>

<p>In C++, objects that manage something (think strings managing characters, containers managing their contents, etc.) usually have a method to determine the size of what they're managing. For std::string and other STL containers that method is size().</p>

<p>Note that writing these strings in this format means you can't tell where one string ends and another one starts. Two options to consider are using a terminating character that you know won't appear in any strings, or writing the length of the string to the file before the text of the string itself. I won't elaborate here as it was not asked in the original question.</p>
","27524428"
"Java: Changing a Binary number like 1010 and reversing the bits. 1010 = 0101. 0's to 1's and 1's to 0's","4607","","<p>I have been searching around the web and seems like I can never seem to find the answer to this question. How do you change the bits in a binary number? </p>

<blockquote>
  <p>Example: say I got 1010 and I want to change the numbers 0's to 1's and 1's to 0's.</p>
</blockquote>

<p>Right now, I have the binary number in a integer. </p>

<p>I'm completely stumped, if anyone could help me thank you.</p>

<p>Sorry if people are confused from my question . What i want to do is change the numbers 0's to 1's and 1's to 0's . </p>
","<p>If you want to flip all the bits you can do</p>

<pre><code>int i = 0b1010;
</code></pre>

<p>or in Java 6</p>

<pre><code>int i = Integer.parseInt(""1010"", 2);
int i2 = ~i; // toggle 0 and 1's.
int i3 = i ^ 0xFF; // toggle the lower 8 bit only.
</code></pre>

<p>or you can try</p>

<pre><code>public static void main(String... args) {
    System.out.println(toggleBits(""1010""));
    System.out.println(toggleBits(""00001010""));
    System.out.println(toggleBits(""1100001010""));
}

private static String toggleBits(String s) {
    long i = Long.parseLong(s, 2);
    long i2 = i ^ ((1L &lt;&lt; s.length()) - 1);
    String s2 = Long.toBinaryString(i2);
    while (s2.length() &lt; s.length()) s2 = '0' + s2;
    return s2;
}
</code></pre>
","10071940"
"Un-/Marshalling nested structures containing arrays of structures","4601","","<p>I want to be able to receive some binary data over TCP/IP which consists of a known structure.
I don't want to inter-operate with C or C++, so solutions that work for this case didn't help me.
Unfortunately the other side cannot change the protocol.
The problem should also arise when I would try to read a binary file with a given format.</p>

<p>I also checked <code>BinaryFormatter</code> and similar but they use their own format which is not acceptable for me.</p>

<p>Here is a sample set of structs. I'd like to be able to reconstruct nested arrays (of known length) of structs. With the current code I get an exception:</p>

<blockquote>
  <p>Could not load type 'NestedStruct' from assembly '...' because it
  contains an object field at offset 2 that is incorrectly aligned or
  overlapped by a non-object field.</p>
</blockquote>

<p>I want to be able to send/receive (or read/write) instances of <code>struct MainStruct</code>.</p>

<pre><code>    [StructLayout(LayoutKind.Explicit, Pack = 1, Size = 244, CharSet = CharSet.Ansi)]
    public struct NestedStruct
    {

        [FieldOffset(0)]
        public Int16 someInt;

        [FieldOffset(2), MarshalAs(UnmanagedType.ByValArray, SizeConst = 242)]
        public Byte[] characterArray; // an array of fixed length 242

    }

    [StructLayout(LayoutKind.Explicit)]
    public struct OtherNestedStruct
    {
        [FieldOffset(0)]
        public Int16 someInt;
        [FieldOffset(2)]
        public Int16 someOtherInt;

    }


    [StructLayout(LayoutKind.Explicit)]
    public struct MainStruct
    {
        [FieldOffset(0)]
        public double someDouble;
        [FieldOffset(8)]
        public NestedStruct nestedContent;
        [FieldOffset(8 + 244)]
        [MarshalAs(UnmanagedType.ByValArray, SizeConst = 13 * 4)]
        public OtherNestedStruct[] arrayOfStruct; // fixed array length 13

    }
</code></pre>

<p>UPDATE:</p>

<p>Here is my latest version:</p>

<pre><code>    [StructLayout(LayoutKind.Sequential, Pack = 1)]
    public struct NestedStruct
    {

        public Int16 someInt;

        [MarshalAs(UnmanagedType.ByValArray, ArraySubType = UnmanagedType.U1, SizeConst = 242)]
        public Byte[] characterArray; // an array of fixed length 242

    }

    [StructLayout(LayoutKind.Sequential , Pack=1)]
    public struct OtherNestedStruct
    {
        public Int16 someInt;
        public Int16 someOtherInt;

    }


    [StructLayout(LayoutKind.Sequential, Pack=1)]
    public struct MainStruct
    {

        public double someDouble;

        public NestedStruct nestedContent;

        [MarshalAs(UnmanagedType.ByValArray, ArraySubType = UnmanagedType.Struct,  SizeConst = 13)]
        public OtherNestedStruct[] arrayOfStruct; // fixed array length 13

    }
</code></pre>
","<p>you must specify the ArraySubType</p>

<pre><code>    [StructLayout(LayoutKind.Sequential, Pack = 1)]
    public struct NestedStruct
    {
        public Int16 someInt;
        [MarshalAs(UnmanagedType.ByValArray, ArraySubType = UnmanagedType.U1, SizeConst = 242)]
        public Byte[] characterArray; // an array of fixed length 242
    }

     [StructLayout(LayoutKind.Sequential, Pack = 1)]
     public struct OtherNestedStruct
     {
         public Int16 someInt;
         public Int16 someOtherInt;

     }


     [StructLayout(LayoutKind.Sequential, Pack = 1)]
     public struct MainStruct
     {
         public double someDouble;
         public NestedStruct nestedContent;
         [MarshalAs(UnmanagedType.ByValArray, SizeConst = 13 * 4)]
         public OtherNestedStruct[] arrayOfStruct; // fixed array length 13

    }  

    static void Main(string[] args)
    {
        var x = Marshal.SizeOf(typeof(MainStruct));
        //x == 460
    } 
</code></pre>
","14935659"
"How to convert Decimal to Binary Numbers in Java using JFrame?","4595","","<p>I've been searching for all codes in the internet, but all I see is for Buffered Reader. Is it possible to have it in a JFrame format? I am new to Java and I wanted to create this program which will convert a decimal number to binary and vice versa. Can you help me how to do it?</p>
","<p><em>Converting</em> and <em>rendering</em> (displaying) are completely unrelated issues.</p>

<p>To convert, use <a href=""http://docs.oracle.com/javase/6/docs/api/java/lang/Integer.html#parseInt%28java.lang.String%29"" rel=""nofollow""><code>Integer.parseInt()</code></a> and <a href=""http://docs.oracle.com/javase/6/docs/api/java/lang/Integer.html#toBinaryString%28int%29"" rel=""nofollow""><code>Integer.toBinaryString()</code></a>:</p>

<pre><code>String input = ""10""; // some number as your input
int i = Integer.parseInt(input);
String binary = Integer.toBinaryString(i);
</code></pre>

<p>To display, put that String into the display area (too trivial to bother with here)</p>
","14698238"
"Negative floating point to binary conversion","4592","","<p>I am using the AR Drone SDK to program the drone.  In the docs, is says this:</p>

<blockquote>
  <p>The number -0.8 is stored in memory as a 32- bit word whose value is
  BF4CCCCD(16), according to the IEEE-754 format. This 32-bit word can
  be considered as holding the 32-bit integer value -1085485875(10). So
  the command to send will be AT*PCMD=xx,xx,-1085485875,xx,xx.</p>
</blockquote>

<p>How are they arriving at -1085485875 for the decimal representation of the binary conversion?  It doesnt make sense to me.  Using this page: <a href=""http://kipirvine.com/asm/workbook/floating_tut.htm"" rel=""nofollow"">http://kipirvine.com/asm/workbook/floating_tut.htm</a> and this page: <a href=""http://www.madirish.net/240"" rel=""nofollow"">http://www.madirish.net/240</a> and this page <a href=""http://cs.furman.edu/digitaldomain/more/ch6/dec_frac_to_bin.htm"" rel=""nofollow"">http://cs.furman.edu/digitaldomain/more/ch6/dec_frac_to_bin.htm</a> , this is what I came up with:</p>

<pre><code>decimal value = -0.8

binary value of decimal (-0.8) = -.11001100110011001100110

biased exponent (move above decimal over once to right) = 127 - 1 = 126 = 01111110

sign, exponent, mantissa (mantissa: drop off the 1 to left of decimal point, pad to 23) = 1 01111110 10011001100110011001100

10111111010011001100110011001100 = 3209481420 (10) BF4CCCCC (16).
</code></pre>

<p>The docs says its -1085485875 (10) and BF4CCCCD (16)</p>

<p>What am I doing wrong here???</p>

<p>Thanks.</p>

<p>Edit:</p>

<p>Since I am writing an AR DRONE application with node/js, if I use these node.js functions:</p>

<pre><code>var buffer = new Buffer(4);
buffer.writeFloatBE(-0.8, 0);
return -~parseInt(buffer.toString('hex'), 16) - 1;
</code></pre>

<p>I get the correct result as per the documentation.  I just don't get what I am doing wrong when I write it out long hand.  I want to understand what is going on.  Any help is really appreciated.</p>

<p>Thanks.</p>

<p>UPDATE:</p>

<p>So, I've figured out (from the above javascript code) if I apply the bitwise NOT operator to binary first, it then produces the correct number.  My question is, why does this need to be applied?  After doing this, you'll have to determine if its negative if the first bit is a zero not a one.  Whats the point of this?</p>
","<p>-0.8 = -0.110011001100110011001100 11001100110011001100110011001100110011... (the space is between bits 24 and 25 -- bit 25 is the rounding bit). This rounds to 24 bits as 0.110011001100110011001101. Here's how it looks in IEEE single-precision format:</p>

<pre><code>sign  biased exponent    trailing 23-bits of mantissa
 \/        \/                      \/
 1      01111110         10011001100110011001101
</code></pre>

<p>That's 10111111010011001100110011001101, or BF4CCCCD in hex. If you view that as a twos-complement an integer, it's -1085485875.</p>
","13437606"
"Direct-Mapped Cache Hit & Miss","4578","","<p>4-bit address</p>

<p>tag 1-bit</p>

<p>index 2-bit</p>

<p>offset 1-bit</p>

<p>2 bytes per block</p>

<p>4 sets (1 block per set)</p>

<p>I am trying to determine if the following addresses are hits or misses. I am presenting the information I have acquired thus far.
(all credit will be given to stack overflow)</p>

<p>Addresses</p>

<p>14</p>

<p>set 3</p>

<p>v = 0</p>

<p>tag = 1</p>

<p>offset = 0</p>

<p>9</p>

<p>set 0</p>

<p>v = 0</p>

<p>tag = 1</p>

<p>offset = 1</p>

<p>2</p>

<p>set 1</p>

<p>v = 0</p>

<p>tag = 0</p>

<p>offset = 0</p>

<p>6</p>

<p>set 3</p>

<p>v = 1</p>

<p>tag = 0</p>

<p>offset = 0</p>

<p>3</p>

<p>set 1</p>

<p>v = 1</p>

<p>tag = 0</p>

<p>offset = 1</p>
","<p>As it's a direct mapped cache, and it has 4 sets, this means that it has a capacity for 4 blocks. </p>

<p>1) Address 14 which in binary is: 1110</p>

<p>Assuming that in the beginning the cache is empty, we got a miss and we store this word on the cache. Tag 1, at set #3.</p>

<p>2) Address 9 which in binary is: 1001</p>

<p>Tag 1 , Set #0, we got a miss. Therefore we store it on set 0.</p>

<p>3) Address 2 in binary; 0010</p>

<p>this block goes on set 1 and it's empty. We got a miss and store it. With the tag 0</p>

<p>4) Address 6 in binary: 0110
As we already have stored a block in set 3, we compare it. As their tags are different Tag 0 != Tag 1 we evict the previous one and we store the new one. Miss</p>

<p>5)Address 3 in binary: 0011
this block goes in set 1 and as we already had a block in set 1 we compare it.
As their tags are equal 0 = 0, we got a HIT.</p>
","20346443"
"Solving Binary Gap using Recursion","4561","","<p>I am trying to solve binary gap problem using recursion. It can be easily solved without recursion. But I want to solve this with recursion.The below program takes an integer as input and finds the binary gap.</p>

<p>Example: </p>

<pre><code>input= 9, Binary form = 1001, Answer = 2

input=37, Binary form = 100101, Answer = 2
</code></pre>

<p>It finds the maximum number of zeros that occur between two 1's in the binary representation. </p>

<p>I want to solve this in O(logn). Right now, the below program simply counts the total number of zeros and gives output 3 instead of 2. How do I correct this to get the right output?</p>

<pre><code>class BinaryGap {

    public int solution(int N){

     return solution(N, false, 0);   
    }
    public int solution(int N, boolean prevFlag, int memo) {

        if(N&lt;2)
            return 0;

        int remainder = N%2 ;


        if(prevFlag){
            if(remainder == 0){
                memo = 1 + solution(N/2, prevFlag, memo);
            } else {
                int newGap = solution(N/2, prevFlag, memo);

                if(newGap &gt; memo)
                    memo = newGap;
            }
        } else {

            prevFlag = (remainder == 1);
            return solution(N/2, prevFlag, 0);
        }

        return memo;

    }

    public static void main(String args[]){
        BinaryGap obj = new BinaryGap();

        System.out.println(obj.solution(37));
    }

}
</code></pre>
","<p>Try this.</p>

<pre><code>static int solution(int n) {
    return solution(n, 0, 0);
}

static int solution(int n, int max, int current) {
    if (n == 0)
        return max;
    else if (n % 2 == 0)
        return solution(n / 2, max, current + 1);
    else
        return solution(n / 2, Math.max(max, current), 0);
}
</code></pre>

<p>and</p>

<pre><code>int[] tests = { 9, 37, 0b1000001010001 };
for (int i : tests)
    System.out.printf(""input = %d, Binary form = %s, Answer = %d%n"",
        i , Integer.toBinaryString(i), solution(i));
</code></pre>

<p>output</p>

<pre><code>input = 9, Binary form = 1001, Answer = 2
input = 37, Binary form = 100101, Answer = 2
input = 4177, Binary form = 1000001010001, Answer = 5
</code></pre>

<p>This is simple tail recursion.  So you can write without recursion like this.</p>

<pre><code>static int solutionLoop(int n) {
    int current = 0;
    int max = 0;
    while (n &gt; 0) {
        if (n % 2 == 0)
            ++current;
        else {
            max = Math.max(max, current);
            current = 0;
        }
        n /= 2;
    }
    return max;
}
</code></pre>
","35531990"
"Why does Git think my cs file is binary?","4550","","<p>I have just one cs file in my repository which Git seems to think is binary. (In <code>git gui</code>, it just says ""binary files differ"".)</p>

<p>How can I indicate to Git that my cs file is a text file?</p>
","<p>You could try and set your cs files as text in a <code>.gitattributes</code> file.</p>

<pre><code>*.vmc diff
</code></pre>

<p>(as described in the <a href=""https://www.kernel.org/pub/software/scm/git/docs/gitattributes.html"" rel=""nofollow noreferrer""><code>.gitattributes</code> man page</a>)<br>
or try to diff them as text (<code>git diff --text</code>)</p>

<p>But if your .cs files are UTF-8 or UTF-16, this <a href=""https://stackoverflow.com/questions/778291/how-do-i-diff-utf-16-files-with-gnu-diff/778315#778315"">can be problematic</a>, unless you set your <code>diff</code> to use an <a href=""https://stackoverflow.com/questions/777949/can-i-make-git-recognize-a-utf-16-file-as-text/1300928#1300928"">external tool able to handle those encoding</a>.</p>
","2506141"
"download emacs binary for linux?","4543","","<p>I am trying to install emacs in offline computer.</p>

<p>but every time I try to build from the source and install it, it doesn't make it.</p>

<p>too complicated.</p>

<p>(terminal ./configure => error try with --without-makeinfo, 
after a while, error try with --without-x, 
after a while, error can't find emacs version...(and I also want to use X version))</p>

<p>so I want to download emacs binary file but I can't find for linux one.</p>

<p>where can I download pre-build binary emacs 23.3(lastest) for ubuntu?</p>

<p>I can download emacs 23.3 binary file for windows but not for ubuntu.</p>
","<p>You could get the deb file directly from <a href=""http://archive.ubuntu.com/ubuntu/pool/universe/e/emacs-snapshot/emacs-snapshot_20090909-1_amd64.deb"" rel=""nofollow"">http://archive.ubuntu.com/ubuntu/pool/universe/e/emacs-snapshot/emacs-snapshot_20090909-1_amd64.deb</a> and then try to install it using <code>dpkg -i</code> but there will probably be dependencies which you might miss. I'd suggest you try an <code>apt-get install emacs-snapshot</code> on your target machine. It will tell you all the packages it needs to fetch (along with URLs). Fetch all of them from a machine connected to the net and then <code>dpkg -i</code> those packages. </p>
","5596258"
"java binary search arraylist","4531","","<p>In school we just got introduced to the binary search algorithm. However, in our newest assignment we have to make the binary search do array lists. Can anyone help me modify this code to do arraylists instead of arrays?</p>

<pre><code>public static Comparable[] binarySearch(Comparable[] a, int counter, Comparable b){
        int left = 0;
        int right = counter;
        while(left &lt;= right){
            int midPoint = (left+right)/2;
            if(a[midPoint].compareTo(b) == 0){
                return b;
            }else if(a[midPoint].compareTo(b) &lt; 0)
                left = midPoint+1;
            else
                right = midPoint-1;
        }
    }
</code></pre>
","<p><a href=""http://docs.oracle.com/javase/1.5.0/docs/api/java/util/Collections.html#binarySearch(java.util.List,%20T,%20java.util.Comparator"" rel=""nofollow"">http://docs.oracle.com/javase/1.5.0/docs/api/java/util/Collections.html#binarySearch(java.util.List,%20T,%20java.util.Comparator</a>)</p>
","9352225"
"Name me a Binary Parser. A parser for binary data","4531","","<p>So, I'm getting this data. From the network socket, or out of a file.  I'm cobbling together code that will interpret the data.  Read some bytes, check some flags, and some bytes indicate how much data follows. Read in that much data, rinse, repeat.</p>

<p>This task reminds me much to parsing source code.  I'm comfy with lex/yacc and antlr, but they're not up to this task.  You can't specify bits and raw bytes as tokens (well, maybe you could, but I wouldn't know how), and you can't coax them into ""read two bytes, make them into an unsigned 16bit integer, call it <em>n</em>, and then read <em>n</em> bytes."".</p>

<p>Then again, when the spec of the protocol/data format is defined in a systematic manner (not all of them are), there should be a systematic way to read in data that is formatted according to the protocol.  Right?  </p>

<p>There's gotta be a tool that does that.</p>
","<p>You may try to employ <a href=""http://boost-spirit.com"" rel=""nofollow noreferrer"">Boost.Spirit</a> (v2) which has recently got <a href=""http://www.boost.org/doc/libs/release/libs/spirit/doc/html/spirit/qi/reference/binary.html"" rel=""nofollow noreferrer"">binary parsing tools</a>, endianness-aware <a href=""http://www.boost.org/doc/libs/release/libs/spirit/doc/html/spirit/qi/reference/binary/binary_native.html"" rel=""nofollow noreferrer"">native</a> and <a href=""http://www.boost.org/doc/libs/release/libs/spirit/doc/html/spirit/qi/quick_reference/qi_parsers/binary.html"" rel=""nofollow noreferrer"">mixed</a> <a href=""http://www.boost.org/doc/libs/release/libs/spirit/doc/html/spirit/qi/reference/binary/binary_native.html"" rel=""nofollow noreferrer"">parsers</a></p>

<pre><code>// This is not a complete and useful example, but just illustration that parsing
// of raw binary to real data components is possible
typedef boost::uint8_t byte_t;
byte_t raw[16] = { 0 };
char const* hex = ""01010000005839B4C876BEF33F83C0CA"";
my_custom_hex_to_bytes(hex, raw, 16);

// parse raw binary stream bytes to 4 separate words
boost::uint32_t word(0);
byte_t* beg = raw;
boost::spirit::qi::parse(beg, beg + 16, boost::spirit::qi::dword, word))
</code></pre>

<p>UPDATE: I found similar question, where Joel de Guzman confirms in his answer availability of binary parsers: <a href=""https://stackoverflow.com/questions/285200/can-boost-spirit-be-used-to-parse-byte-stream-data"">Can Boost Spirit be used to parse byte stream data?</a></p>
","2214945"
"Using Faraday Ruby gem to download image and write to disk","4530","","<p>When using the <a href=""https://github.com/technoweenie/faraday"" rel=""noreferrer"">Faraday</a> gem to hit a URL for an image like this:</p>

<pre><code>http_conn = Faraday.new do |builder|
  builder.adapter Faraday.default_adapter
end 
response = http_conn.get 'http://example.tld/image.png'
</code></pre>

<p>How can you write the image file from the Faraday response to disk?</p>

<p>Debugging the <code>response.body</code> attribute shows it is binary data.</p>

<p>Any help greatly appreciated.</p>
","<p>Why not just write the <code>response.body</code> like any other file?</p>

<pre><code>File.open('image.png', 'wb') { |fp| fp.write(response.body) }
</code></pre>
","7639147"
"Matlab: Search for center of objects in binary image","4525","","<p>I have an image like the following:</p>

<p><img src=""https://i.stack.imgur.com/tH9bs.jpg"" alt=""binary img""></p>

<p>It's plotted via <code>imshow(I)</code> and <code>I</code> is a logical matrix, you can get this one from here:
<a href=""http://pastebin.com/qsxA0GXy"" rel=""nofollow noreferrer"">http://pastebin.com/qsxA0GXy</a></p>

<p>Those objects are mostly something like a rough circle, but they also can be some sort of eliptic of about three times greater in size.</p>

<p>I want to find the coordinates of the center of those objects, but only estimated. I dont want to use a circular hough transform as I need only a estimated value and I need a fast algorithm.</p>

<p>My idea was: Loop each pixel and if it's a <code>true</code> value, search all neighboor-pixel which are also <code>true</code> and than get the center of the object by calculating </p>

<blockquote>
  <p>x = x_max - xmin; </p>
  
  <p>y = y_max - ymin;</p>
</blockquote>

<p>but I dont like this approach as it seems quite slow for me with using 2 nested for loops.
Anything nicer you can think of? 
thanks!</p>
","<p>This seems to be quite fast. Not too sure how it'll scale though:</p>

<pre><code>L = bwlabel(I);
stats = regionprops(L,I,'Centroid');
</code></pre>
","13719929"
"How can one generate a binary tree recursively?","4520","","<p>main class: binary tree</p>

<p>it contains the root node and a binary tree constructor</p>

<pre><code>public class BinaryTree{
Node root;
BinaryTree (int depth){
    this.root = new Node(depth);
    root.generateTree(depth);
}
</code></pre>

<p>sub class node.</p>

<p>the generateTree() method is defined in this class but doesn't work.</p>

<p>the nodes represent the branches of the tree.</p>

<p>generateTree returns a binary tree.</p>

<pre><code>class Node{
    final int LEAF = 1;
    final int BALL = 2;
    final int CANDLE = 3;
    int depth;
    int decoration;
    String color;
    boolean on;
    Node left;
    Node right;
    Node(int depth){
        this.depth = depth;
    }
    void setLeaf(){
        decoration = LEAF;
    }
    void setBall(String color){
        color = color;
    }
    void setCandle(boolean on){
        on = on;
    }
    BinaryTree generateTree(int depth) {
        if (depth == 0) {
            return root;
        }
        else if (depth &gt; 1) {
            if (root.right == null){
                root.right = new Node(depth-1);
                root.left = new Node(depth-1);
            }
            for (int i=0; i &lt; depth; i++){
                Node node = new Node(depth);
                node.right = new Node(depth-1);
                node.left = new Node(depth-1);
            }
        }
          generateTree(depth - 1);

    }
}
}
</code></pre>
","<p>Rather than returning BinaryTree as the output, try having a method that returns just a node:</p>

<pre><code>private static Node generateTree (int depth) {
    if (depth &lt; 0) return null;
    Node currentNode = new Node(depth);
    if (depth &gt; 0) {
        currentNode.left = generateTree(depth-1);
        currentNode.right = generateTree(depth-1);
    }
    return currentNode;
}
</code></pre>

<p><strong>EDIT</strong>:</p>

<p>rather than calling the generateTree method as a function of the Node class, you should call the function and set its returned value in the constructor.</p>

<pre><code>BinaryTree (int depth) {
    this.root = generateTree(depth);
}
</code></pre>
","14067882"
"Embedding a binary file inside a class library","4517","","<p>Is it possible to embed a custom binary file inside a C# class library and then at runtime read it with a binary reader?</p>

<p>I'm guessing it might be possible through resources.</p>

<p>Many thanks</p>
","<p>You can do this by adding the file to the Resources through the project properties.  Visual studio will then give you a handy class to access your file using the following code</p>

<pre><code>byte[] theFile = myNamespace.Properties.Resources.theBinaryFile;
</code></pre>

<p>Where the resource name is theBinaryFile.</p>
","892080"
"Best way storing binary or image files","4488","","<p>What is the best way <strong>storing binary</strong> or <strong>image</strong> files?</p>

<ol>
<li><strong>Database</strong> System</li>
<li><strong>File</strong> System</li>
</ol>

<p>Would you please <strong>explain</strong>, why?</p>
","<p>There is no real best way, just a bunch of trade offs.</p>

<p><strong>Database Pros</strong>:<br>
1. Much easier to deal with in a clustering environment.<br>
2. No reliance on additional resources like a file server.<br>
3. No need to set up ""sync"" operations in load balanced environment.<br>
4. Backups automatically include the files.  </p>

<p><strong>Database Cons</strong>:<br>
1. Size / Growth of the database.<br>
2. Depending on DB Server and your language, it might be difficult to put in and retrieve.<br>
3. Speed / Performance.<br>
4. Depending on DB server, you have to virus scan the files at the time of upload and export.</p>

<hr>

<p><strong>File Pros</strong>:<br>
1. For single web/single db server installations, it's fast.<br>
2. Well understood ability to manipulate files.  In other words, it's easy to move the files to a different location if you run out of disk space.<br>
3. Can virus scan when the files are ""at rest"".  This allows you to take advantage of scanner updates.</p>

<p><strong>File Cons</strong>:<br>
1. In multi web server environments, requires an accessible share.  Which should also be clustered for failover.<br>
2. Additional security requirements to handle file access.  You have to be careful that the web server and/or share does not allow file execution.<br>
3. Transactional Backups have to take the file system into account.  </p>

<hr>

<p>The above said, SQL 2008 has a thing called FILESTREAM which combines both worlds.  You upload to the database and it transparently stores the files in a directory on disk.  When retrieving you can either pull from the database; or you can go direct to where it lives on the file system.  </p>
","2028857"
"binary numbers?","4468","","<p>I am using the python shell to figure out how the print command works in python.<br>
When I type in   </p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>print 01<br>
      1<br>
      print 010<br>
      8<br>
      print 0100<br>
      64<br>
      print 030<br>
      24   </p>
    </blockquote>
  </blockquote>
</blockquote>

<p>What's going on here?  Is it just base 2?  Why does the ""one"" in the second position print as 8?  Shouldn't it be 2 if it's binary?</p>
","<p>Starting a number with a zero marks it as octal in Python 2. This has been recognized as confusing, surprising and also inconsistent, as starting with 0x will mark it as hexadecimal. Therefore, in Python 3, starting with 0 is invalid, and you get octal by starting with 0o. You can also start with 0b to mark it as binary.</p>

<pre><code>&gt;&gt;&gt; 10
10
&gt;&gt;&gt; 0x10
16
&gt;&gt;&gt; 0o10
8
&gt;&gt;&gt; 0b10
2
&gt;&gt;&gt; 010
  File ""&lt;stdin&gt;"", line 1
    010
      ^
SyntaxError: invalid token
</code></pre>

<p>0x, 0o and 0b also works in Python 2.6 and Python 2.7.</p>
","4485590"
"php, memcached, binary protocol","4465","","<p>I'm trying to squeeze each bit from an application I'm writing, I've already installed and configured igbinary for serialization on apc, sessions etc.
I'd like to know if any of you have actual benchmarks with php and memcached using binary protocol. is it something valuable?</p>

<pre><code>$memcache-&gt;setOption(Memcached::OPT_SERIALIZER, Memcached::SERIALIZER_IGBINARY);
$memcache-&gt;setOption(Memcached::OPT_BINARY_PROTOCOL,true);
</code></pre>

<p>thanks!</p>
","<p>maybe this will help you decide.</p>

<p><a href=""http://www.slideshare.net/tmaesaka/memcached-binary-protocol-in-a-nutshell-presentation"" rel=""noreferrer"">http://www.slideshare.net/tmaesaka/memcached-binary-protocol-in-a-nutshell-presentation</a></p>
","8519717"
"Binary subtraction in Java","4439","","<p>I'm trying to make a binary calculator that subtracts two binary numbers (only with base 2) without parsing it.</p>

<p>Can anyone help me with the situation that I have zero in the upper number and one in the lower number, I can't seem to write the code for it.</p>

<pre><code>for (int i = ss.length()-1; i &gt; -1; i--)
        {
            if(s.charAt(i)=='0' &amp;&amp; ss.charAt(i)=='0') sb.append(""0"");
            else if (s.charAt(i)=='1' &amp;&amp; ss.charAt(i)=='0') sb.append(""1"");
            else if (s.charAt(i)=='1' &amp;&amp; ss.charAt(i)=='1') sb.append(""0"");
            else
            {
                sb.append(""1"");
                doit(s,i+1,sb);
            }
        }

        for (int i = s.length() - ss.length(); i &gt;-1; i--) 
        {
            sb.append(s.charAt(i));
        }

        ArrayList&lt;Character&gt; res = new ArrayList&lt;&gt;();
        for (int i =  sb.length()-1; i &gt; -1; i--)
        {
            res.add(sb.charAt(i));
        }
        System.out.println(res);
    }
    public static void doit(StringBuilder s, int i, StringBuilder sb)
    {
        for (int j = i; j &gt; -1; j--)
        {
            if(s.charAt(j)=='0')
            {
                s.setCharAt(j, '1');
            }
            else
            {
                s.setCharAt(j, '0');
                break;
            }
        }
    }
</code></pre>
","<p>You can do it strictly bitwise, right to left, like at least some chips do. The tricky knowledge is a five-column table: (a,b, carry bit from prior position) -> (result, new carry bit). You don't actually borrow from the higher-level positions; you carry the underverflow into those instead. See table 2.4 here:</p>

<p><a href=""http://books.google.com.ua/books?id=vpWS-s4d5vMC&amp;pg=PA25&amp;lpg=PA25&amp;dq=binary+subtraction+table+carry&amp;source=bl&amp;ots=458JWgZl8v&amp;sig=sjuXedv96KCbNWmxQAPNQo7iuRw&amp;hl=en&amp;sa=X&amp;ei=i-6jUI7IB8jusgay8IDQDQ&amp;ved=0CBwQ6AEwAA#v=onepage&amp;q=binary%20subtraction%20table%20carrysubtract&amp;f=false"" rel=""nofollow"">http://books.google.com.ua/books?id=vpWS-s4d5vMC&amp;pg=PA25&amp;lpg=PA25&amp;dq=binary+subtraction+table+carry&amp;source=bl&amp;ots=458JWgZl8v&amp;sig=sjuXedv96KCbNWmxQAPNQo7iuRw&amp;hl=en&amp;sa=X&amp;ei=i-6jUI7IB8jusgay8IDQDQ&amp;ved=0CBwQ6AEwAA#v=onepage&amp;q=binary%20subtraction%20table%20carrysubtract&amp;f=false</a></p>

<p>Define two methods: (a,b, carry bit from prior position) -> result and (a,b, carry bit from prior position) -> new carry bit, and apply them right to left.</p>

<hr>

<p>Alternative: invert your second argument according to the rules here: <a href=""http://simple.wikipedia.org/wiki/Negative_binary_numbers"" rel=""nofollow"">http://simple.wikipedia.org/wiki/Negative_binary_numbers</a> .</p>

<p>Then add #1 to the inverted #2 :).</p>

<p>PS. Who said it's a bad assignment :)?</p>
","13385873"
"Compute fast log base 2 ceiling in python","4433","","<p>for given <code>x &lt; 10^15</code>, quickly and accurately determine the maximum integer <code>p</code> such that <code>2^p &lt;= x</code> </p>

<p>Here are some things I've tried:</p>

<p>First I tried this but it's not accurate for large numbers:</p>

<pre><code>&gt;&gt;&gt; from math import log
&gt;&gt;&gt; x = 2**3
&gt;&gt;&gt; x
8
&gt;&gt;&gt; p = int(log(x, 2))
&gt;&gt;&gt; 2**p == x
True
&gt;&gt;&gt; x = 2**50
&gt;&gt;&gt; p = int(log(x, 2))
&gt;&gt;&gt; 2**p == x #not accurate for large numbers?
False
</code></pre>

<p>I could try something like:</p>

<pre><code>p = 1
i = 1
while True:
    if i * 2 &gt; n:
        break
    i *= 2
    p += 1
    not_p = n - p
</code></pre>

<p>Which would take up to 50 operations if p was 50</p>

<p>I could pre-compute all the powers of 2 up until 2^50, and use binary search to find p. This would take around log(50) operations but seems a bit excessive and ugly?</p>

<p>I found this thread for C based solutions: <a href=""https://stackoverflow.com/questions/3272424/compute-fast-log-base-2-ceiling"">Compute fast log base 2 ceiling</a></p>

<p>However It seems a bit ugly and I wasn't exactly sure how to convert it to python.</p>
","<p>In Python >= 2.7, you can use the <code>.bit_length()</code> method of integers:</p>

<pre><code>def brute(x):
    # determine max p such that 2^p &lt;= x
    p = 0
    while 2**p &lt;= x:
        p += 1
    return p-1

def easy(x):
    return x.bit_length() - 1
</code></pre>

<p>which gives</p>

<pre><code>&gt;&gt;&gt; brute(0), brute(2**3-1), brute(2**3)
(-1, 2, 3)
&gt;&gt;&gt; easy(0), easy(2**3-1), easy(2**3)
(-1, 2, 3)
&gt;&gt;&gt; brute(2**50-1), brute(2**50), brute(2**50+1)
(49, 50, 50)
&gt;&gt;&gt; easy(2**50-1), easy(2**50), easy(2**50+1)
(49, 50, 50)
&gt;&gt;&gt; 
&gt;&gt;&gt; all(brute(n) == easy(n) for n in range(10**6))
True
&gt;&gt;&gt; nums = (max(2**x+d, 0) for x in range(200) for d in range(-50, 50))
&gt;&gt;&gt; all(brute(n) == easy(n) for n in nums)
True
</code></pre>
","13106017"
"floating point hex octal binary","4432","","<p>I am working on a calculator that allows you to perform calculations past the decimal point in octal, hexadecimal, binary, and of course decimal. I am having trouble though finding a way to convert floating point decimal numbers to floating point hexadecimal, octal, binary and vice versa. </p>

<p>The plan is to do all the math in decimal and then convert the result into the appropriate number system. Any help, ideas or examples would be appreciated. </p>

<p>Thanks!</p>
","<p>Hmm... this was a homework assignment in <em>my</em> university's CS ""weed-out"" course.</p>

<p>The operations for binary are described in <em>Schaum's Outline Series: Essential Computer Mathematics</em> by Seymour Lipschutz.  For some reason it is still on my bookshelf 23 years later.</p>

<p>As a hint, convert octal and hex to binary, perform the operations, convert back to binary.</p>

<p>Or you can perform decimal operations and perform the conversions to octal/hex/binary afterward.  The process is essentially the same for all positional number systems arithmetic.</p>
","324542"
"Converting data stored in Fortran 90 binaries to human readable format","4425","","<p>In your experience, in Fortran 90, what is the best way to store large arrays in output files?  Previously, I had been trying to write large arrays to ASCII text files.  For example, I would do something like this (thanks to the recommendation at the bottom of the page <a href=""https://stackoverflow.com/questions/6526112/in-fortran-90-what-is-a-good-way-to-write-an-array-to-a-text-file-row-wise"">In Fortran 90, what is a good way to write an array to a text file, row-wise?</a>):</p>

<pre><code>PROGRAM testing1
  IMPLICIT NONE
  INTEGER :: i, j, k
  INTEGER, DIMENSION(4,10) :: a

  k=1
  DO i=1,4
    DO j=1,10
      a(i,j)=k
      k=k+1
    END DO
  END DO

  OPEN(UNIT=12, FILE=""output.txt"", ACTION=""WRITE"", STATUS=""REPLACE"")
  DO i=1,4
    DO j=1,10
      WRITE(12, ""(i2,x)"", ADVANCE=""NO"") a(i,j)
    END DO
    WRITE(12, *)
  END DO
  CLOSE(UNIT=12)
END PROGRAM testing1
</code></pre>

<p>This works, but as pointed out by the topmost reply at <a href=""https://stackoverflow.com/questions/6526112/in-fortran-90-what-is-a-good-way-to-write-an-array-to-a-text-file-row-wise"">In Fortran 90, what is a good way to write an array to a text file, row-wise?</a>, writing large arrays to text files is very slow and creates files that are somewhat larger in size than is necessary.  The poster there recommended instead writing to an unformatted Fortran binary, using something like:</p>

<pre><code>PROGRAM testing2
  IMPLICIT NONE
  INTEGER :: i, j, k
  INTEGER, DIMENSION(4,10) :: a

  k=1
  DO i=1,4
    DO j=1,10
      a(i,j)=k
      k=k+1
    END DO
  END DO

  OPEN(UNIT=13, FILE=""output.dat"", ACTION=""WRITE"", STATUS=""REPLACE"", &amp;
      FORM=""UNFORMATTED"")
  WRITE(13) a
  CLOSE(UNIT=13)
END PROGRAM testing2
</code></pre>

<p>This seems to work, and is indeed much faster and results in smaller file sizes, as promised by the reply <a href=""https://stackoverflow.com/questions/6526112/in-fortran-90-what-is-a-good-way-to-write-an-array-to-a-text-file-row-wise"">here</a>.  However, what do I do if I would like to be able to later work with the data stored in Fortran binary (e.g., output.dat above) and analyze its contents?  For example, what if I want to open the array stored in the binary in a program such as Microsoft Excel?</p>

<p>When I mentioned matlab in my previous <a href=""https://stackoverflow.com/questions/6526112/in-fortran-90-what-is-a-good-way-to-write-an-array-to-a-text-file-row-wise"">post</a>, the reply suggested that I open the binary as a hexadecimal file and figure out and extract the records from there.  But, I am nervous that I am getting into deep water since I have no prior experience in hexadecimal sleuthing.  When I asked on the matlab board (here: <a href=""http://www.mathworks.com/matlabcentral/answers/12639-advice-on-reading-an-unformatted-fortran-binary-file-into-matlab"" rel=""nofollow noreferrer"">http://www.mathworks.com/matlabcentral/answers/12639-advice-on-reading-an-unformatted-fortran-binary-file-into-matlab</a>) about reading Fortran files into matlab, the person there suggested that using Fortran stream might be easy.  But is Fortran stream (i.e., using the directive <code>ACCESS=""STREAM""</code> in the <code>OPEN</code> command) likely to be similar in time and file size to the ASCII text file that I created in my first example above?</p>

<p>Or, do you know if there is any other software that can automatically read Fortran binaries into some sort of human readable form?  (Or, do you know of any good tutorials on either hexadecimal sleuthing or Fortran stream?)</p>

<p>Thank you very much for your time.</p>
","<p>Stream is a choice independent of the choice of formatted / unformatted -- one is ""access"", the other ""format""   The default for Fortran I/O is record oriented access.   The typical approach of a Fortran compiler for records (at least unformatted) to write a 4-byte record length before and after each record.  (The ""after"" is to make reading backwards easier.)   Using a hex edit you could verify these extra data items that I described and skip them in MatLab.  But they are not part of the language standard and are not portable and are certainly not obvious in other languages.   If you select stream and unformatted you will just get the raw sequence of bytes corresponding to your data items -- no extra data items to worry about in the other language!  In my experience  this output tends to be fairly easy to read in other languages (not tried in MatLab).   If this is a small &amp; simple project with portability of the files to other computers not an issue, I would probably use this approach (stream &amp; unformatted) rather than a file format specification such as HDF5 or FITS.  I'd write the array as write (13) a, as in your final example.     Depending on the other language, you might have to transpose the dimensions.  If this is a major and long-lived project with portability a concern, then a portable and standard file interface is worth considering.</p>

<p>I don't know whether any of these formats can be read from Excel.   More research.... You might have to write a program to read the binary file of whatever format and output a file in a format that Excel understands.</p>
","6905330"
"Java- How would I load a black and white image into binary?","4422","","<p>I am using Java with swing in FSE mode. I want to load a completely black-and-white image into binary format (a 2d array preferably) and use it for mask-based per-pixel collision detection. I don't even know where to start here, I've been researching for the past hour and haven't found anything relevant. </p>
","<p>Just read it into a <a href=""http://download.oracle.com/javase/6/docs/api/java/awt/image/BufferedImage.html"" rel=""nofollow""><code>BufferedImage</code></a> using <a href=""http://download.oracle.com/javase/6/docs/api/javax/imageio/ImageIO.html#read%28java.io.File%29"" rel=""nofollow""><code>ImageIO#read()</code></a> and get the individual pixels by <a href=""http://download.oracle.com/javase/6/docs/api/java/awt/image/BufferedImage.html#getRGB%28int,%20int%29"" rel=""nofollow""><code>BufferedImage#getRGB()</code></a>. A value of <code>0xFFFFFFFF</code> is white and the remnant is color. Assuming that you want to represent white as byte <code>0</code> and color (black) as byte <code>1</code>, here's a kickoff example:</p>

<pre><code>BufferedImage image = ImageIO.read(new File(""/some.jpg""));
byte[][] pixels = new byte[image.getWidth()][];

for (int x = 0; x &lt; image.getWidth(); x++) {
    pixels[x] = new byte[image.getHeight()];

    for (int y = 0; y &lt; image.getHeight(); y++) {
        pixels[x][y] = (byte) (image.getRGB(x, y) == 0xFFFFFFFF ? 0 : 1);
    }
}
</code></pre>

<h3>See also:</h3>

<ul>
<li><a href=""http://download.oracle.com/javase/tutorial/2d/images/index.html"" rel=""nofollow"">The Java Tutorials - 2D Graphics - Working with images</a></li>
</ul>
","5925526"
"Bitwise operations on strings in javascript","4421","","<p>In javascript the following test of character to character binary operations prints <code>0</code> 676 times:</p>

<pre><code>var s = 'abcdefghijklmnopqrstuvwxyz';
var i, j;
for(i=0; i&lt;s.length;i++){ for(j=0; j&lt;s.length;j++){ console.log(s[i] | s[j]) }};
</code></pre>

<p>If js was using the actual binary representation of the strings I would expect some non-zero values here.</p>

<p>Similarly, testing binary operations on strings and integers, the following print 26 <code>255</code>s and <code>0</code>s, respectively. (255 was chosen because it is <code>11111111</code> in binary).</p>

<pre><code>var s = 'abcdefghijklmnopqrstuvwxyz';
var i; for(i=0; i&lt;s.length;i++){ console.log(s[i] | 255) }
var i; for(i=0; i&lt;s.length;i++){ console.log(s[i] &amp; 255) }
</code></pre>

<p>What is javascript doing here?  It seems like javascript is casting any string to <code>false</code> before binary operations.</p>

<p><strong>Notes</strong></p>

<p>If you try this in python, it throws an error:</p>

<pre><code>&gt;&gt;&gt; s = 'abcdefghijklmnopqrstuvwxyz'
&gt;&gt;&gt; [c1 | c2 for c2 in s for c1 in s]
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
TypeError: unsupported operand type(s) for |: 'str' and 'str'
</code></pre>

<p>But stuff like this seems to <a href=""https://stackoverflow.com/questions/942540/how-to-bitwise-compare-a-string"">work in php</a>.</p>
","<p>In JavaScript, when a string is used with a binary operator it is first converted to a number.  Relevant portions of the ECMAScript spec are shown below to explain how this works.</p>

<p><a href=""http://www.ecma-international.org/ecma-262/5.1/#sec-11.10"" rel=""noreferrer"">Bitwise operators</a>:</p>

<blockquote>
  <p>The production A : A @ B, where @ is one of the bitwise operators in the productions above, is evaluated as follows:</p>
  
  <ol>
  <li>Let lref be the result of evaluating A.  </li>
  <li>Let lval be GetValue(lref).  </li>
  <li>Let rref be the result of evaluating B.  </li>
  <li>Let rval be GetValue(rref).  </li>
  <li>Let lnum be ToInt32(lval).  </li>
  <li>Let rnum be ToInt32(rval).  </li>
  <li>Return the result of applying the bitwise operator @ to lnum and rnum. The result is a signed 32 bit integer.</li>
  </ol>
</blockquote>

<p><a href=""http://www.ecma-international.org/ecma-262/5.1/#sec-9.5"" rel=""noreferrer"">ToInt32</a>:</p>

<blockquote>
  <p>The abstract operation ToInt32 converts its argument to one of 2<sup>32</sup> integer values in the range −231 through 231−1, inclusive. This abstract operation functions as follows:</p>
  
  <ol>
  <li>Let number be the result of calling ToNumber on the input argument.  </li>
  <li>If number is NaN, +0, −0, +∞, or −∞, return +0.  </li>
  <li>Let posInt be sign(number) * floor(abs(number)).  </li>
  <li>Let int32bit be posInt modulo 2<sup>32</sup>; that is, a finite integer value k of Number type with positive sign and less than 2<sup>32</sup> in magnitude such that the mathematical difference of posInt and k is mathematically an integer multiple of 2<sup>32</sup>.  </li>
  <li>If int32bit is greater than or equal to 2<sup>31</sup>, return int32bit − 2<sup>32</sup>, otherwise return int32bit.</li>
  </ol>
</blockquote>

<p>The internal ToNumber function will return NaN for any string that cannot be parsed as a number, and ToInt32(NaN) will give 0.  So in your code example all of the bitwise operators with letters as the operands will evaluate to <code>0 | 0</code>, which explains why only 0 is printed.</p>

<p>Note that something like <code>'7' | '8'</code> will evaluate to <code>7 | 8</code> because in this case the strings used as the operands can be successfully convered to a number.</p>

<p>As for why the behavior in Python is different, there isn't really any implicit type conversion in Python so an error is expected for any type that doesn't implement the binary operators (by using <code>__or__</code>, <code>__and__</code>, etc.), and strings do not implement those binary operators.</p>

<p>Perl does something completely different, <a href=""http://perldoc.perl.org/perlop.html#Bitwise-String-Operators"" rel=""noreferrer"">bitwise operators are implemented for strings</a> and it will essentially perform the bitwise operator for the corresponding bytes from each string.</p>

<p>If you want to use JavaScript and get the same result as Perl, you will need to first convert the characters to their code points using <a href=""https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt"" rel=""noreferrer""><code>str.charCodeAt</code></a>, perform the bitwise operator on the resulting integers, and then use <a href=""https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/fromCodePoint"" rel=""noreferrer""><code>String.fromCodePoint</code></a> to convert the resulting numeric values into characters.</p>
","22212298"
"What is the byte signature of a password-protected ZIP file?","4416","","<p>I've read that ZIP files start with the following bytes:</p>

<pre><code>50 4B 03 04
</code></pre>

<p>Reference: <a href=""http://www.garykessler.net/library/file_sigs.html"" rel=""nofollow noreferrer"">http://www.garykessler.net/library/file_sigs.html</a></p>

<p>Question: Is there a certain sequence of bytes that indicate a ZIP file has been password-protected?</p>
","<p>It's not true that ZIP files must start with </p>

<pre><code>50 4B 03 04
</code></pre>

<p><em>Entries</em> within zip files start with <code>50 4B 03 04...</code>  ..and often, pure zip files start with a zip entry as the first thing in the file.  But, there is no requirement that zip files start with those bytes. All files that start with those bytes are <em>probably</em> zip files, but not all zip files start with those bytes. </p>

<p>For example, you can create a self-extracting archive which is a PE-COFF file, a regular EXE, in which there actually <em>is</em> a signature for the file, which is <code>4D 5A ...</code>.  Then, later in the exe file, you can store zip entries, beginning with <code>50 4B 03 04...</code>.  The file is both an .exe and a .zip.  </p>

<p>A self-extracting archive is not the only class of zip file that does not start with <code>50 4B 03 04</code> .  You can ""hide"" arbitrary data in a zip file this way.  WinZip and other tools should have no problems reading a zip file formatted this way. </p>

<p>If you find the <code>50 4B 03 04</code> signature within a file, either at the start of the file or somewhere else, you can look at the next few bytes to determine whether that particular entry is encrypted. Normally it looks something like this: </p>

<pre><code>50 4B 03 04 14 00 01 00 08 00 ... 
</code></pre>

<p>The first four bytes are the entry signature.  The next two bytes are the ""version needed to extract"".  In this case it is 0x0014, which is 20.  According to the pkware spec, that means version 2.0 of the pkzip spec is required to extract the entry. (The latest zip ""feature"" used by the entry is described by v2.0 of the spec).   You can find higher numbers there if more advanced features are used in the zip file. AES encryption requires v5.1 of the spec, hence you should find 0x0033 in that header.  (Not all zip tools respect this).  </p>

<p>The next 2 bytes represents the general purpose bit flag (the spec calls it a ""bit flag"" even though it is a <em>bit field</em>), in this case 0x0001. This has bit 0 set, which indicates that the entry is encrypted.  </p>

<p>Other bits in that bit flag have meaning and may also be set. For example bit 6 indicates that strong encryption was used - either AES or some other stronger encryption. Bit 11 says that the entry uses UTF-8 encoding for the filename and the comment. </p>

<p>All this information is available in the <a href=""http://www.pkware.com/documents/casestudies/APPNOTE.TXT"" rel=""noreferrer"">PKWare AppNote.txt spec</a>.   </p>
","1495218"
"converting a binary file to HEX representation using batch file","4412","","<p>I need to convert a DLL file to HEX representation to use it as a part of string to create a sql server assembly like this</p>

<p><code>
CREATE ASSEMBLY [AssemblyNameHere]<br>
FROM 0x4D5A90000300000004000000FFFF000......<em>continue binary data</em><br>
WITH PERMISSION_SET = EXTERNAL_ACCESS</code></p>

<p>I need this to be in a batch file for many reasons, but it seems that <strong>FOR</strong> statement only suitable for text files.</p>
","<p>It is not a very good idea to create a hex output with pure batch.  </p>

<p>But you could use vbscript or for simple tasks FC.exe could work.</p>

<pre><code>@echo off
SETLOCAL EnableDelayedExpansion
set filesize=%~z1
set ""hexVal=41""
set ""x10=AAAAAAAAAA""

set /a chunks=1+filesize / 10

del dummy.txt 2&gt;nul &gt; nul
for /L %%n in (0,1,%chunks%) DO (
  &lt;nul &gt;&gt; dummy.txt set /p "".=%x10%""
)

set /a expectedNum=0
for /F ""eol=F usebackq tokens=1,2 skip=1 delims=:[] "" %%A in (`fc /b ""%~dpf1"" dummy.txt`) DO (
    set /a num=0x%%A &amp;&amp; (
            set /a numDec=num-1
        set ""hex=%%B""

        for /L %%n in (!expectedNum!=,=1 !numDec!) DO (
            echo %hexVal%
        )
        set /a expectedNum=num+1
        echo !hex!
    )
)
</code></pre>

<p>First I create a file with (nearly) the same length, and then I compare them with FC in binary mode (/B), the output is scanned and if a line missings are detected, they are filled with the hexVal of the x10 string (in this case 0x41='A').</p>
","4648636"
"byte[] array to 64 bit binary string","4397","","<p>I have problem with getting value from binary registry key.
My code so far is</p>

<pre><code>string key = ""UserPreferencesMask"";
        string key_place = @""Control Panel\Desktop"";
        RegistryKey root = Registry.CurrentUser;
        root = root.OpenSubKey(key_place);
        var byte_value = root.GetValue(key);
        byte[] bytearray = byte_value as byte[];
        //How can convert byte [] array to 64 bit binary string
         klase.Close();
         MessageBox.Show(binary_string);
</code></pre>

<p>I am stacked when i want </p>

<pre><code>UserPreferencesMask
</code></pre>

<p>binary registry key to convert 64bit binary string . something like this 
from </p>

<p>9E3E078012000000</p>

<p>hex value
to </p>

<p>1001111000111110000001111000000000010010000000000000000000000000 </p>

<p>binary value</p>

<p>But if i build code which convert from hex to binary, i have wrong binary value if in hex number has first one or two or more zero  numbers. Binary returns without first zero numbers, only count start from first byte value with 1 , and has no error if hex started with any other char,except 0
How can i solve problem ? I searched everywhere, but i found only hex to binary ., but this cause an error for me, and returned value aren't 64 bit value lenght.
Thank's !</p>
","<pre><code>Converter.ToString( BitConverter.ToInt64( bytearray, 0 ), 2 ).PadLeft( 64, '0' ); 
</code></pre>

<p>If the original number is the wrong endianness then its pretty easy to just do an:</p>

<pre><code>Array.Reverse( bytearray );
</code></pre>

<p>before you run the first line.</p>
","11890822"
"write a function in java to find the binary period of a positive integer N","4397","","<p>A non-empty zero-indexed string S consisting of Q characters is given. The period of this string is the smallest </p>

<p>positive integer P such that:</p>

<p>P ≤ Q / 2 and
S[K] = S[K+P] for 0 ≤ K &lt; Q − P.</p>

<p>For example, 7 is the period of “pepsicopepsicopep”.
A positive integer M is the binary period of a positive integer N if M is the period of the binary representation of N.</p>

<p>For example, <strong>1651</strong> has the binary representation of ""110011100111"". Hence, its <strong>binary period is 5</strong>. On the other hand, 102 does not have a binary period, because its binary representation is “1100110” and it does not have a period.</p>

<p>Consider above scenarios &amp; write a function in Java which will accept an integer N as the parameter. Given a positive integer N, the function returns the binary period of N. The function should return −1 if N does not have a binary period.</p>

<p>Below I have included the solution I worked for it as well &amp; I <strong>would like to know whether there exists any other better ways to solve it?</strong></p>
","<pre><code>public class BinaryPeriod {

    public static void main(String[] args) {
        System.out.println(""\nEx1: "" + getBinaryPeriodForInt(102));
        System.out.println(""\nEx2: "" + getBinaryPeriodForInt(1651));
    }

    static int getBinaryPeriodForInt(int n) {
        int[] d = new int[30];
        int l = 0, res = -1;
        while (n &gt; 0) {
            d[l] = n % 2;
            n /= 2;
            l++;
        }

        for (int p = 1; p &lt; l; p++) {
            if (p &lt;= l / 2) {
                boolean ok = true;
                for (int i = 0; i &lt; l - p; i++) {
                    if (d[i] != d[i + p]) {
                        ok = false;
                        break;
                    }
                }
                if (ok) {
                    res = p;
                }
            }
        }

        return res;
    }
}
</code></pre>
","33996260"
"How do you convert from IEEE 754 single-precision floating-point format to decimal?","4393","","<p>I understand that the first bit is the sign and that the next 8 bits is the exponent. So in this example you would have 1.1001*2^-4 ? How do I then interpret this in decimal? </p>

<pre>0 01111011 10010000000000000000000</pre>
","<p>Since you already figured out that this is (in binary)1.1001*10^-100, now you just have to convert the binary number to decimal.</p>

<p>In decimal, each digit has a value one-tenth as much as the one before it. In binary, each digit has a value one-half as much as the one before it.</p>

<p>First 1.1001*10^-100 = 0.00011001.</p>

<p>Which is...</p>

<pre><code>  0 * 1           0 * 1
+ 0 * 1/2       + 0 * 0.5
+ 0 * 1/4       + 0 * 0.25
+ 0 * 1/8       + 0 * 0.125
+ 1 * 1/16      + 1 * 0.0625
+ 1 * 1/32      + 1 * 0.03125
+ 0 * 1/64      + 0 * 0.015625
+ 0 * 1/128     + 0 * 0.0078125
+ 1 * 1/256     + 1 * 0.00390625 
</code></pre>

<p>0.0625 + 0.03125 + 0.00390625 = 0.09765625</p>

<p>That's all there is to it.</p>
","2406260"
"Chrome WebKitBlobBuilder doesn't append data","4392","","<p>I'm implementing some file upload feature through ajax request. I'd like to be able to send multiple files in one ajax call, so i decided to use FormData.</p>

<p>I tried to append my binary data string directly to the FormData (and it works), but the Content-Disposition doesn't have a filename attribute:
    Content-Disposition: form-data; name=""file1""</p>

<p>w3c says that i need to append a blob object to the formdata to have that attribute (or to be able to set it with the 3rd attribute of FormData.append())</p>

<p>I wrote the following code:</p>

<pre><code>function uploadAsBinary() {
    var xhr = new XMLHttpRequest();
    var fd = new FormData();

    window.BlobBuilder = window.BlobBuilder || window.WebKitBlobBuilder || window.MozBlobBuilder;
    var bb = new window.BlobBuilder();
    bb.append(""this is my binary content"");
    var blob = bb.getBlob(""text/plain""); 

    fd.append(""file1"", blob, ""file1"");

    xhr.open(""POST"", ""/mb/0/"", false);
    xhr.send(fd);
}
</code></pre>

<p>It works perfectly fine with firefox, but with google chrome (v16 and v17), the request payload is a formdata without content in it:</p>

<pre><code>------WebKitFormBoundaryVkgESMAGtmPMlPZ7
Content-Disposition: form-data; name=""file1""; filename=""file1""
Content-Type: text/plain


------WebKitFormBoundaryVkgESMAGtmPMlPZ7--
</code></pre>

<p>I've also tried to fill the blob through an ArrayBuffer, same result. 
I've been surfing the web for 2 days now, i've found no answer. I've found an open issue on android (http://code.google.com/p/android/issues/detail?id=22441) but it seems quite dead.</p>

<p>Is this a real chrome issue ? Does someone have a clue about this, or should i open an issue on chromium tracker ?</p>

<p>Thx for your help !</p>
","<p>For anyone looking for a solution here, the problem is the switch to Blob() rather than BlobBuilder() as <a href=""http://updates.html5rocks.com/2012/06/Don-t-Build-Blobs-Construct-Them"" rel=""nofollow"">explained here</a></p>

<p><strong>BlobBuilder():</strong></p>

<pre><code>window.BlobBuilder = window.BlobBuilder || window.WebKitBlobBuilder ||
                 window.MozBlobBuilder || window.MSBlobBuilder;
window.URL = window.URL || window.webkitURL;

var bb = new BlobBuilder();
bb.append('body { color: red; }');
var blob = bb.getBlob('text/css');

var link = document.createElement('link');
link.rel = 'stylesheet';
link.href = window.URL.createObjectURL(blob);

document.body.appendChild(link);
</code></pre>

<p><strong>Blob():</strong></p>

<pre><code>window.URL = window.URL || window.webkitURL;

var blob = new Blob(['body { color: red; }'], {type: 'text/css'});

var link = document.createElement('link');
link.rel = 'stylesheet';
link.href = window.URL.createObjectURL(blob);
document.body.appendChild(link);
</code></pre>
","13057335"
"php functions binary safe?","4388","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/3264514/in-php-what-does-it-mean-by-a-function-being-binary-safe"">In PHP what does it mean by a function being binary-safe ?</a>  </p>
</blockquote>



<p>Hi guys,</p>

<p>what exacly does it mean a function (example: <a href=""http://it.php.net/dirname"" rel=""nofollow noreferrer"">dirname</a>) is binary safe?</p>
","<p>It means two things. First the function works on strings that contain <code>\0</code> the NUL byte. This is not a given, because functions are often implemented in C which would treat that as string terminator. PHP however uses length-denominated strings.</p>

<p>Second, in some contexts it means that a particular string function ignores the character set and does not try to interpret UTF-8 sequences. For raw binary data the UTF-8 sequencing would be wrong, thus making functions fail if they try to treat it as text.</p>
","5024033"
"Designing a BitStream in C#","4385","","<p>I'm looking at the C# library called <a href=""http://www.codeproject.com/KB/cs/bitstream.aspx"" rel=""noreferrer"">BitStream</a>, which allows you to write and read any number of bits to a standard C# <code>Stream</code> object. I noticed what seemed to me a strange design decision:</p>

<p>When adding bits to an empty byte, the bits are added to the MSB of the byte. For example:</p>

<pre><code>var s = new BitStream();
s.Write(true);
Debug.Assert(s.ToByteArray()[0] == 0x80);  // and not 0x01

var s = new BitStream();
s.Write(0x7,0,4);
s.Write(0x3,0,4);
Debug.Assert(s.ToByteArray()[0] == 0x73); // and not 0x37
</code></pre>

<p>However, when referencing bits in a number as the <em>input</em>, the first bit of the input number is the LSB. For example</p>

<pre><code>//s.Write(int input,int bit_offset, int count_bits)
//when referencing the LSB and the next bit we'll write
s.Write(data,0,2); //and not s.Write(data,data_bits_number,data_bits_number-2)
</code></pre>

<p>It seems inconsistent to me. Since in this case, when ""gradually"" copying a byte like in the previous example (the first four bits, and then the last four bits), we will not get the original byte. We need to copy it ""backwards"" (first the last four bits, then the first four bits).</p>

<p>Is there a reason for that design that I'm missing? Any other implementation of bits stream with this behaviour? What are the design considerations for that?</p>

<p>It seems that <code>ffmpeg</code> bitstream behaves in a way I consider consistent. Look at the amount it shifts the byte before <code>OR</code>ing it with the <code>src</code> pointer in <a href=""http://cekirdek.pardus.org.tr/~ismail/ffmpeg-docs/put__bits_8h-source.html#l00148"" rel=""noreferrer"">the <code>put_bits</code> function</a>.</p>

<p>As a side note:</p>

<p>The first <em>byte</em> added, is the first byte in the byte array. For example</p>

<pre><code>var s = new BitStream();
s.Write(0x1,0,4);
s.Write(0x2,0,4);
s.Write(0x3,0,4);
Debug.Assert(s.ToByteArray()[0] == 0x12); // and not s.ToByteArray()[1] == 0x12
</code></pre>
","<p>Here are some additional considerations: </p>

<p>In the case of the boolean - only one bit is required to represent true or false.  When that bit gets added to the beginning of the stream, the bit stream is ""1."" When you extend that stream to byte length it forces the padding of zero bits to the end of the stream, even though those bits did not exist in the stream to begin with.  Position in the stream is important information just like the values of the bits, and a bit stream of ""1000000"" or 0x80 safeguards the expectation that subsequent readers of the stream may have that the first bit they read is the first bit that was added.</p>

<p>Second, other data types like integers require more bits to represent so they are going to take up more room in the stream than booleans.  Mixing different size data types in the same stream can be very tricky when they aren't aligned on byte boundaries.</p>

<p>Finally, if you are on Intel x86 your CPU architecture is ""little-endian"" which means LSB first like you are describing.  If you need to store values in the stream as big-endian you'll need to add a conversion layer in your code - similar to what you've shown above where you push one byte at a time into the stream in the order you want.  This is annoying, but commonly required if you need to interop with big-endian Unix boxes or as may be required by a protocol specification.</p>

<p>Hope that helps!</p>
","2314705"
"Process binary file in Java using FileItemStream","4350","","<p>I have a webapplication which allows to upload binary files. I have to parse them and save the content 1:1 into a String and then into the database. </p>

<p>When I use uuencode on a unix machine to encode the binary file, then it works. Is there a way to do this automatically in java?</p>

<pre><code>if (isMultipart) {

            //Create a new file upload handler
            ServletFileUpload upload = new ServletFileUpload();

            //Parse the request
            FileItemIterator iter = upload.getItemIterator(request);

            while (iter.hasNext()) {
                FileItemStream item = iter.next();
                String name = item.getFieldName();

                InputStream stream = item.openStream();

                if (!item.isFormField()) {

                    BufferedReader reader = new BufferedReader(new InputStreamReader(stream));
                    String line;
                    licenseString = """";

                    while ((line = reader.readLine()) != null) {
                        System.out.println(line);

                        // Generate License File
                        licenseString += line + ""\n"";
                    }
                }
            }
            session.setAttribute(""licenseFile"", licenseString);
            System.out.println(""adding licensestring to session. "");
        }
</code></pre>

<p>It works of course for all non-binary files uploaded. How can I extend it to support binary files?</p>
","<pre><code>// save to file
// =======================================
InputStream is = new BufferedInputStream(item.openStream());
BufferedOutputStream output = null;

try {
    output = new BufferedOutputStream(new FileOutputStream(""temp.txt"", false));
    int data = -1;
    while ((data = is.read()) != -1) {
        output.write(data);
    }
} finally {
    is.close();
    output.close();
}

// read content of file
// =======================================
System.out.println(""content of file:"");
try {
    FileInputStream fstream = new FileInputStream(""temp.txt"");

    DataInputStream in = new DataInputStream(fstream);
    BufferedReader br = new BufferedReader(new InputStreamReader(in));
    String line;

    licenseString = """";
    String strLine;
    while ((strLine = br.readLine()) != null)   {
          System.out.println(javax.xml.bind.DatatypeConverter.printBase64Binary(strLine.getBytes()));
          licenseString += javax.xml.bind.DatatypeConverter.printBase64Binary(strLine.getBytes()) + ""\n"";
    }                                           
} catch (Exception e) {
    System.err.println(""Error: "" + e.getMessage());
}
</code></pre>
","9683966"
"How to convert text to binary using javascript","4340","","<p>I want to make a text to binary converter. For example if someone types in 'Hello' it would return <code>0100100001100101011011000110110001101111</code> How can I do this? I have tried this but something is wrong:</p>

<pre><code>function convertBinary() {
    var output = document.getElementById(""outputBinary"");
    var input = document.getElementById(""inputBinary"").value;
    output.value = """";
    for (i=0; i &lt; input.length; i++) {
        output.value +=input[i].charCodeAt(0).toString(2);
    }
}
</code></pre>

<p>Here is my code:</p>

<pre><code>&lt;!doctype html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Binary Converter&lt;/title&gt;
&lt;script type=""text/javascript"" src=""http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js""&gt;&lt;/script&gt;
&lt;script type=""text/javascript""&gt;
function convertBinary() {
    var output = document.getElementById(""outputBinary"");
    var input = document.getElementById(""inputBinary"").value;
    output.value = """";
    for (i=0; i &lt; input.length; i++) {
        output.value +=input[i].charCodeAt(0).toString(2);
    }
}
&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;center&gt;
&lt;div class=""container""&gt;
    &lt;span class=""main""&gt;Binary Converter&lt;/span&gt;&lt;br&gt;
    &lt;input type=""text"" onKeyUp=""convertBinary()"" id=""inputBinary"" class=""inputBinary"" placeholder=""Enter Text""&gt;&lt;br&gt;
    &lt;input type=""text"" id=""outputBinary"" class=""outputBinary"" readonly&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>Any help will be greatly appreciated. Thanks, Omar.</p>
","<pre><code>function convertBinary() {
    var output = document.getElementById(""outputBinary"");
    var input = document.getElementById(""inputBinary"").value;
    output.value = """";
    for (i=0; i &lt; input.length; i++) {var e=input[i].charCodeAt(0);var s = """";
    do{
        var a =e%2;
        e=(e-a)/2;
        s=a+s;
        }while(e!=0);
        while(s.length&lt;8){s=""0""+s;}
        output.value+=s;
    }
}
</code></pre>

<p>You welcome my friend</p>
","21351978"
"Manually convert float point number into binary format","4328","","<p>Hi I have following float point value in base 10: <strong>0.625</strong>. I need to convert this value in base 10 to binary format which is: <strong>0.101</strong>.
Algorithm I found is below. It works, but I am not understanding why this works. Could someone please explain to be why the code below works? I am aware that numbers after the decimal point is computed in the manner such that 1/2^n where n is count from the decimal point. Thanks.</p>

<p>To clarify, I need to know the reasoning behind the mathematical formula. Not stepping through the code. </p>

<pre><code>private static String floatToBinaryString( double n ) {
    String val = ""0."";
    while ( n &gt; 0 ) {
        double r = n * 2;
        if( r &gt;= 1 ) {
            val += ""1"";
            n = r - 1;
        }else{
            val += ""0"";
            n = r;
        }
    }
    return val;
}
</code></pre>
","<p>You multiply the fraction by 2 and use the ones place digit as the binary values until the fraction is equal to zero.  Example below.</p>

<p>This is the standard formula for conversion using the 0.625 you have:</p>

<pre><code>1) Multiply fraction by 2 =&gt;  0.625 * 2 = 1.25
    The digit to the left of the decimal point is the first binary value, 0.1 so far
2) Ignore the ones-place digit and you have 0.25 which is still larger than zero.
    Multiply the fraction by 2 =&gt; 0.25 * 2 = 0.50
    The digit to the left of the decimal point is the next binary value, 0.10 so far
3) Ignore the ones-place digit and you have 0.50 which is less than zero.
    Multiply the fraction by 2 =&gt; 0.5 * 2 = 1.00
    The digit to the left of the decimal point is the next binary value, 0.101 so far
4) Ignore the ones-place digit and you have 0.00 which is equal to zero.
    Conversion complete!

private static String floatToBinaryString( double n ) {
    String val = ""0."";    // Setting up string for result
    while ( n &gt; 0 ) {     // While the fraction is greater than zero (not equal or less than zero)
        double r = n * 2;   // Multiply current fraction (n) by 2
        if( r &gt;= 1 ) {      // If the ones-place digit &gt;= 1
            val += ""1"";       // Concat a ""1"" to the end of the result string (val)
            n = r - 1;        // Remove the 1 from the current fraction (n)
        }else{              // If the ones-place digit == 0
            val += ""0"";       // Concat a ""0"" to the end of the result string (val)
            n = r;            // Set the current fraction (n) to the new fraction
        }
    }
    return val;          // return the string result with all appended binary values
}
</code></pre>
","21387849"
"Binary Addition. Is it overflow?","4325","","<p>Binary values are in 2s Complement form.</p>

<p>If I am to add 110001 (-15) and 101110 (-18), and the answer has to be stored in a 6-bit integer, is this an underflow/overflow.</p>
","<p>This is overflow, your professor is correct.  You are storing more bits that can be held in the alloted space (even though the number that the bits represent is negative.)</p>

<p>Underflow is when bits get zero'd out through shifting on big math.  Very common in fixed point math.  Divide a very small number by a very big number and you will quite often get a 0.  That is underflow.</p>
","2725949"
"Getting the Leftmost Bit","4306","","<p>I have a 5 bit integer that I'm working with.  Is there a native function in Objective-C that will let me know which bit is the leftmost?</p>

<p>i.e. I have 01001, it would return 8 or the position.</p>

<p>Thanks</p>
","<pre><code>NSInteger value = 9;
NSInteger shift = 1;
for(NSInteger bit = value; bit &gt; 1; bit = value &gt;&gt; ++shift);
NSInteger leftmostbit = 1 &lt;&lt; shift;
</code></pre>

<p>Works for every number of bits.</p>
","2893589"
"How do I convert a large binary String to byte array java?","4303","","<p>I have a large binary string ""101101110..."", and I am trying to store it into a byte array. what is the best way of doing it?</p>

<p>Lets say I have largeString = ""0100111010111011011000000001000110101""</p>

<p>Result that I'm looking for:</p>

<p>[78,  187, 96, 17, 21]</p>

<p>01001110 10111011 01100000 00010001 10101</p>

<p>What i've tried:</p>

<p><code>byte[] b= new BigInteger(largeString,2).toByteArray();</code></p>

<p>however it did not give me the result I'm looking for...</p>
","<p>You can easily build an arrayList on which you can call toArray if you want an actual array;</p>

<pre><code>ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;&gt;();

for(String str : largeString.split(""(?&lt;=\\G.{8})""))
    arrayList.add(Integer.parseInt(str, 2));

System.out.println(arrayList);  // Outputs [78, 187, 96, 17, 21]
</code></pre>
","23664301"
"RESTful design - how to model entity's attachments","4297","","<p>I am trying to model entity's attachments in REST. Let's say a defect entity can have multiple attachments attached to it. Every attachment has a description and some other properties (last modified, file size...) . The attachment itself is a file in any format (jpeg, doc ...)</p>

<p>I was wondering how should I model it RESTfully</p>

<p>I thought about the following two options:</p>

<h3>First approach (using same resource, different representations):</h3>

<ul>
<li><p>GET , content-type:XML on <strong><a href=""http://my-app/defects/"" rel=""noreferrer"">http://my-app/defects/</a>{id}/attachments</strong> will return the defect's 
attachments metadata in XML format (description, last modified, file size...)</p></li>
<li><p>GET , content-type:gzip on <strong><a href=""http://my-app/defects/"" rel=""noreferrer"">http://my-app/defects/</a>{id}/attachments</strong> will return the defect's attachments in a zip file</p></li>
<li><p>GET , content-type:mime multi-part on <strong><a href=""http://my-app/defects/"" rel=""noreferrer"">http://my-app/defects/</a>{id}/attachments</strong> will return the defect's attachments in a multi-part message (binary data and XML metadata altogether)</p></li>
<li><p>POST, content-type:XML on <strong><a href=""http://my-app/defects/"" rel=""noreferrer"">http://my-app/defects/</a>{id}/attachments</strong> will create new attachment, metadata only no file attached (then the user has to send PUT request with the binary data) </p></li>
<li><p>POST , content-type:mime\multi-part on <strong><a href=""http://my-app/defects/"" rel=""noreferrer"">http://my-app/defects/</a>{id}/attachments</strong> will create the attachment, the client can send both metadata and file itself in a single roundtrip</p></li>
</ul>

<h3>Second approach (separate the attachment's data from the metadata):</h3>

<ul>
<li><p>GET , content-type:XML on <strong><a href=""http://my-app/defects/"" rel=""noreferrer"">http://my-app/defects/</a>{id}/attachments</strong> will return the defect's 
attachments metadata in XML format (description, last modified, file size...)</p></li>
<li><p>GET , content-type:gzip on <strong><a href=""http://my-app/defects/"" rel=""noreferrer"">http://my-app/defects/</a>{id}/attachments/files</strong> will return the defect's attachments binary data in a single zip</p></li>
</ul>

<p>Creating a new attachment, first call:</p>

<ul>
<li>POST, content-type:XML on <strong><a href=""http://my-app/defects/"" rel=""noreferrer"">http://my-app/defects/</a>{id}/attachments</strong> will create new attachment, metadata only no file attached (then the user has to send PUT request with the binary data) </li>
</ul>

<p>Then add the binary data itself:</p>

<ul>
<li>POST , content-type:mime\multi-part on <strong><a href=""http://my-app/defects/"" rel=""noreferrer"">http://my-app/defects/</a>{id}/attachments/{id}/file</strong> will create the attachment file</li>
</ul>

<hr>

<p>On one hand the first approach is more robust and efficient since the client can create\get the attachments metadata and binary data in single round trip. On the other hand, I am a bit reluctant to use the mime-multipart representation as it's more cumbersome to consume and produce.</p>

<p><strong>EDIT:</strong> I checked out <a href=""http://www.flickr.com/services/api/upload.example.html"" rel=""noreferrer"">flicker upload REST API</a>. It seems they are using multi part messages to include both the photo and the photo attributes.</p>
","<p>Don't manage metadata separately.  A two-part action defeats the point of REST.</p>

<p>One smooth GET/POST/PUT/DELETE with one -- relatively -- complex payload is what's typically done.</p>

<p>The fact that it's multiple underlying ""objects"" in ""tables"" is irrelevant to REST.</p>

<p>At the REST level, it's just one complex object's state transmitted with one message.</p>
","1536988"
"sequential vs. binary search","4284","","<p>Consider a file on disk containing 100 records.</p>

<p>For both searches, what is</p>

<ol>
<li>the average number of comparisons needed to find a record in a file.</li>
<li>number of comparisons if the record is not in the file</li>
<li>the average number of comparisons if the record has a 68% chance of being in the file</li>
<li>the number of disk accesses in the previous 3 questions if the file has 25 records per block</li>
</ol>
","<p>You might want to have a look at this SO thread:</p>

<p><a href=""https://stackoverflow.com/questions/700241/what-is-the-difference-between-linear-search-and-binary-search"">What is the difference between Linear search and Binary search?</a></p>

<p>--</p>

<p>The reason people are down-voting you is that you just copied and pasted your homework problem. You have not shown in any way that you have actually tried studying your textbook, then searched using Google and SO, then attempted this problem, and <em>only then</em> posted your question.</p>
","2392007"
"python - Parsing data from binary file using structs","4282","","<p>I have a save game file that I am trying to parse out all of the characters attributes by reading the file using hex offsets. I'm able to get all strings out properly since that plain text but I am having issues with parsing the binary portions that I am working with.</p>

<p>I'm pretty sure that I'm reading in the right data but when I unpack the string I am getting unexpected (incorrect) output</p>

<p>The file I'm working with is www.retro-gaming-world.com/SAVE.DAT</p>

<pre><code>import struct
infile = open('SAVE.DAT','rb')
try:
    buff = infile.read()
finally:
    infile.close

infile.seek(0x00,0)
print ""Save Signature: "" + infile.read(0x18)
print ""Save Version: "" + str(struct.unpack('&gt;i',buff[0x18:0x18+4])[0])
infile.seek(0x1C,0)
print ""The letter R: "" + infile.read(0x01)
infile.seek(0x1D,0)
print ""Character Name: "" + infile.read(0x20)
infile.seek(0x3D,0)
print ""Save Game Name: "" + infile.read(0x1E)
print ""Save game day: "" + str(struct.unpack('&gt;i',buff[0x5B:0x5B+4])[0])
print ""Save game month: "" + str(struct.unpack('&gt;i',buff[0x5D:0x5D+4])[0])
print ""Save game year: "" + str(struct.unpack('&gt;i', buff[0x5F:0x5F+4])[0])
</code></pre>

<p>I'm having two different issues, either the wrong data is returned or when I try to unpack some of the fields I get an error that the string isn't long enough, I can read in more but the day month and year are only 2 and 4 bytes respectively and are integers, I'm not sure I'm going about this the right way, I believe I'm fetching the right fields but think I am unpacking or handling the data incorrectly some where if not completely.</p>

<p>version should return 0100
day should return 21
month should return 09
year should return 2013</p>

<p>What exactly am I getting wrong hrere, is there another way or a better way to go about parsing the fields from the binary?</p>
","<p>The error is, that although the values are of integer type, they only have the length of 2, being an unsigned short in C. Thus, you have to read them as </p>

<p><code>struct.unpack('&gt;H',buff[0x5B:0x5B+2])[0])</code> </p>

<p>and so on. signed or unsigned does not seem to make a difference here. If available, check the documentation of the save file, it should be denoted there which is appropriate. If not, good luck trying (<code>itertools</code> can be helpful).</p>

<p>For more details of types, check the table on <a href=""http://docs.python.org/2/library/struct.html#format-characters"" rel=""nofollow"">the Python documentation for structs</a></p>

<p>As a big fan of Fallout 1 and 2 I do wish you good luck and lots of success with the project (-;</p>
","18980851"
"Binary String to ASCII TEXT String","4267","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/6006425/binary-to-corresponding-ascii-string-conversion"">Binary To Corresponding ASCII String Conversion</a>  </p>
</blockquote>



<p>I posted a slimier question before but didn't got a correct answer..</p>

<p>my problem is i have a binary string as </p>

<pre><code>00100000011101110110000101101110011101000010000001110100011011110010000001100100011011110111
</code></pre>

<p>Which im required to convert to <code>""Normal ASCII String Text""</code></p>

<p>I used  <code>BinaryReader</code> and read and encode <code>System.Text.ASCIIEncoding.ASCII</code> but im getting the same <code>0101010</code> string</p>

<pre><code>    byte[] bytearray = b.ReadBytes((int)length);

    System.Text.Encoding encEncoder = System.Text.ASCIIEncoding.ASCII;

    string bb = encEncoder.GetString(bytearray);
</code></pre>

<p>any help will be grateful ! </p>
","<p>first translate the binary string into a <code>byte[]</code> using <a href=""https://stackoverflow.com/questions/3935524/how-could-i-encode-a-string-of-1s-and-0s-for-transport"">How could I encode a string of 1s and 0s for transport?</a></p>

<p>next use the <a href=""http://msdn.microsoft.com/en-us/library/system.convert.tobase64string.aspx"" rel=""nofollow noreferrer"">Convert.ToBase64String</a> method to get the actual <code>System.String</code></p>
","6007935"
"Creating a generic binary in linux for all x86 machines","4263","","<p>Im trying to compile a binary of an open-source project so that our users do not have to compile it themselves.</p>

<p>I've noticed that some binaries created on one 32-bit ubuntu machine ""A"" don't work on 32-bit machine ""B"", with errors regarding missing .so files being reported.</p>

<p>However, if I compile from scratch on machine ""B"", then all the errors are gone.</p>

<p>Could there be any reason why compiling the code on the target machine makes these errors go away? I only ran ""./configure"" and ""make"" - not ""make-install"", So its not like I made these .so files available globally.</p>

<p>Could it be that the compiler detects there are .so files missing from the system library and in this case links a static library into the executable?</p>

<p>How does Ubuntu compile its packages so that an i386 package runs on all x86 machines?</p>
","<p>I guess the issue is called ""binary compatibility"" (there's <a href=""https://stackoverflow.com/questions/tagged/binary-compatibility"">a tag</a> on stack overflow devoted to these problems).  When you link a binary on a machine, the surrounding environment affects the binary, and, having been run on another machine, it still tries to find the environment similar to the one it was compiled in.</p>

<p>Tolerance to different environments in this case is called <strong>binary compatibility</strong>.</p>

<p><strong>How does it work?</strong></p>

<p>The key point here is that, even if you specify <strong>the same</strong> options to linker on different machines, you may still get <strong>different</strong> binaries.  For example, if you link your binary against a shared library with <code>-lfoo</code>, the exact version of <code>foo</code> you have on the machine you build on (for example, <code>libfoo.so.5</code>) is hardcoded into the binary.  When it's run on machine <code>B</code>, it may only contain <code>libfoo.so.4</code>, and the binary will refuse to run because it needs the missing <code>libfoo.so.5</code> so file.  That's why recompilation helps, and without it it doesn't work.</p>

<p>Ubuntu packages—and these of any other distribution—are <strong>all</strong> compiled in the same environment (of each other).  That's why they install well.  And distribution vendors watch that each next version is backwards-compatible with previous ones.</p>

<p><strong>What should I do?</strong></p>

<p>If you want to make your software compatible with different distributions, it's easier than you thought.  First, try to <strong>compile your application at the oldest distribution possible</strong>.  Since, as I mentioned before, modern distributions are usually backwards compatible, your soft will, most likely, run on newer distros without problem.</p>

<p>To check the resultant package more thoroughly and get more advice about compatibility, you may from our free <a href=""http://ispras.linux-foundation.org/index.php/About_Linux_Application_Checker"" rel=""nofollow noreferrer"">Linux Application Checker</a> tool.  You might also be interested in <a href=""https://stackoverflow.com/questions/3545628/packaging-proprietary-software-for-linux/3547137#3547137"">generic tips for packaging Linux soft</a>.</p>
","4963291"
"Correct way to serialize binary data in C++","4248","","<p>After having read the following <a href=""https://stackoverflow.com/questions/12612488/aliasing-t-with-char-is-allowed-is-it-also-allowed-the-other-way-around"">1</a> and <a href=""https://stackoverflow.com/questions/13280771/is-this-use-of-stdarray-undefined-behavior?"">2</a> Q/As and having used the technique discussed below for many years on x86 architectures with GCC and MSVC and not seeing a problems, I'm now very confused as to what is supposed to be the correct but also as important ""most efficient"" way to serialize then deserialize binary data using C++.</p>

<p>Given the following ""wrong"" code:</p>

<pre><code>int main()
{
   std::ifstream strm(""file.bin"");

   char buffer[sizeof(int)] = {0};

   strm.read(buffer,sizeof(int));

   int i = 0;

   // Experts seem to think doing the following is bad and
   // could crash entirely when run on ARM processors:
   i = reinterpret_cast&lt;int*&gt;(buffer); 

   return 0;
}
</code></pre>

<p>Now as I understand things, the reinterpret cast indicates to the compiler that it can treat the memory at buffer as an integer and subsequently is free to issue integer compatible instructions which require/assume certain alignments for the data in question - with the only overhead being the extra reads and shifts when the CPU detects the address it is trying to execute alignment oriented instructions is actually not aligned. </p>

<p>That said the answers provided above seem to indicate as far as C++ is concerned that this is all undefined behavior.</p>

<p>Assuming that the alignment of the location in buffer from which cast will occur is not conforming, then is it true that the only solution to this problem is to copy the bytes 1 by 1?  Is there perhaps a more efficient technique?</p>

<p>Furthermore I've seen over the years many situations where a struct made up entirely of pods (using compiler specific pragmas to remove padding) is cast to a char* and subsequently written to a file or socket, then later on read back into a buffer and the buffer cast back to a pointer of the original struct, (ignoring potential endian and float/double format issues between machines), is this kind of code also considered undefined behaviour?</p>

<p>The following is more complex example:</p>

<pre><code>int main()
{
   std::ifstream strm(""file.bin"");

   char buffer[1000] = {0};

   const std::size_t size = sizeof(int) + sizeof(short) + sizeof(float) + sizeof(double);

   const std::size_t weird_offset = 3;

   buffer += weird_offset;

   strm.read(buffer,size);

   int    i = 0;
   short  s = 0;
   float  f = 0.0f;
   double d = 0.0;

   // Experts seem to think doing the following is bad and
   // could crash entirely when run on ARM processors:
   i = reinterpret_cast&lt;int*&gt;(buffer); 
   buffer += sizeof(int);

   s = reinterpret_cast&lt;short*&gt;(buffer); 
   buffer += sizeof(short);

   f = reinterpret_cast&lt;float*&gt;(buffer); 
   buffer += sizeof(float);

   d = reinterpret_cast&lt;double*&gt;(buffer); 
   buffer += sizeof(double);

   return 0;
}
</code></pre>
","<p>First, you can correctly, portably, and efficiently solve the alignment problem using, e.g., std::aligned_storage::value>::type instead of char[sizeof(int)] (or, if you don't have C++11, there may be similar compiler-specific functionality).</p>

<p>Even if you're dealing with a complex POD, <code>aligned_stored</code> and <code>alignment_of</code> will give you a buffer that you can <code>memcpy</code> the POD into and out of, construct it into, etc.</p>

<p>In some more complex cases, you need to write more complex code, potentially using compile-time arithmetic and template-based static switches and so on, but so far as I know, nobody came up with a case during the C++11 deliberations that wasn't possible to handle with the new features.</p>

<p>However, just using <code>reinterpret_cast</code> on a random char-aligned buffer is not enough. Let's look at why:</p>

<blockquote>
  <p>the reinterpret cast indicates to the compiler that it can treat the memory at buffer as an integer</p>
</blockquote>

<p>Yes, but you're also indicating that it can assume that the buffer is aligned properly for an integer. If you're lying about that, it's free to generate broken code.</p>

<blockquote>
  <p>and subsequently is free to issue integer compatible instructions which require/assume certain alignments for the data in question</p>
</blockquote>

<p>Yes, it's free to issue instructions that either require those alignments, or that assume they're already taken care of.</p>

<blockquote>
  <p>with the only overhead being the extra reads and shifts when the CPU detects the address it is trying to execute alignment oriented instructions is actually not aligned. </p>
</blockquote>

<p>Yes, it may issue instructions with the extra reads and shifts. But it may also issue instructions that don't do them, because you've told it that it doesn't have to. So, it could issue a ""read aligned word"" instruction which raises an interrupt when used on non-aligned addresses.</p>

<p>Some processors don't have a ""read aligned word"" instruction, and just ""read word"" faster with alignment than without. Others can be configured to suppress the trap and instead fall back to a slower ""read word"". But others—like ARM—will just fail.</p>

<blockquote>
  <p>Assuming that the alignment of the location in buffer from which cast will occur is not conforming, then is it true that the only solution to this problem is to copy the bytes 1 by 1? Is there perhaps a more efficient technique?</p>
</blockquote>

<p>You don't need to copy the bytes 1 by 1. You could, for example, <code>memcpy</code> each variable one by one into properly-aligned storage. (That would only be copying bytes 1 by 1 if all of your variables were 1-byte long, in which case you wouldn't be worried about alignment in the first place…)</p>

<p>As for casting a POD to char* and back using compiler-specific pragmas… well, any code that relies on compiler-specific pragmas for correctness (rather than for, say, efficiency) is obviously not correct, portable C++. Sometimes ""correct with g++ 3.4 or later on any 64-bit little-endian platform with IEEE 64-bit doubles"" is good enough for your use cases, but that's not the same thing as actually being valid C++. And you certainly can't expect it to work with, say, Sun cc on a 32-bit big-endian platform with 80-bit doubles and then complain that it doesn't.</p>

<p>For the example you added later:</p>

<pre><code>// Experts seem to think doing the following is bad and
// could crash entirely when run on ARM processors:
buffer += weird_offset;

i = reinterpret_cast&lt;int*&gt;(buffer); 
buffer += sizeof(int);
</code></pre>

<p>Experts are right. Here's a simple example of the same thing:</p>

<pre><code>int i[2];
char *c = reinterpret_cast&lt;char *&gt;(i) + 1;
int *j = reinterpret_cast&lt;int *&gt;(c);
int k = *j;
</code></pre>

<p>The variable <code>i</code> will be aligned at some address divisible by 4, say, 0x01000000. So, <code>j</code> will be at 0x01000001. So the line <code>int k = *j</code> will issue an instruction to read a 4-byte-aligned 4-byte value from 0x01000001. On, say, PPC64, that will just take about 8x as long as <code>int k = *i</code>, but on, say, ARM, it will crash.</p>

<p>So, if you have this:</p>

<pre><code>int    i = 0;
short  s = 0;
float  f = 0.0f;
double d = 0.0;
</code></pre>

<p>And you want to write it to a stream, how do you do it?</p>

<pre><code>writeToStream(&amp;i);
writeToStream(&amp;s);
writeToStream(&amp;f);
writeToStream(&amp;d);
</code></pre>

<p>How do you read back from a stream?</p>

<pre><code>readFromStream(&amp;i);
readFromStream(&amp;s);
readFromStream(&amp;f);
readFromStream(&amp;d);
</code></pre>

<p>Presumably whatever kind of stream you're using (whether <code>ifstream</code>, <code>FILE*</code>, whatever) has a buffer in it, so <code>readFromStream(&amp;f)</code> is going to check whether there are <code>sizeof(float)</code> bytes available, read the next buffer if not, then copy the first <code>sizeof(float)</code> bytes from the buffer to the address of <code>f</code>. (In fact, it may even be smarter—it's allowed to, e.g., check whether you're just <em>near</em> the end of the buffer, and if so issue an asynchronous read-ahead, if the library implementer thought that would be a good idea.) The standard doesn't say how it has to do the copy. Standard libraries don't have to run anywhere but on the implementation they're part of, so your platform's <code>ifstream</code> could use <code>memcpy</code>, or <code>*(float*)</code>, or a compiler intrinsic, or inline assembly—and it will probably use whatever's fastest on your platform.</p>

<p>So, how exactly would unaligned access help you optimize this or simplify it?</p>

<p>In nearly every case, picking the right kind of stream, and using its read and write methods, is the most efficient way of reading and writing. And, if you've picked a stream out of the standard library, it's guaranteed to be correct, too. So, you've got the best of both worlds.</p>

<p>If there's something peculiar about your application that makes something different more efficient—or if you're the guy writing the standard library—then of course you should go ahead and do that. As long as you (and any potential users of your code) are aware of where you're violating the standard and why (and you actually are optimizing things, rather than just doing something because it ""seems like it should be faster""), this is perfectly reasonable.</p>

<p>You seem to think that it would help to be able to put them into some kind of ""packed struct"" and just write that, but the C++ standard does not have any such thing as a ""packed struct"". Some implementations have non-standard features that you can use for that. For example, both MSVC and gcc will let you pack the above into 18 bytes on i386, and you can take that packed struct and <code>memcpy</code> it, <code>reinterpret_cast</code> it to <code>char *</code> to send over the network, whatever. But it won't be compatible with the exact same code compiled by a different compiler that doesn't understand your compiler's special pragmas. It won't even be compatible with a related compiler, like gcc for ARM, which will pack the same thing into 20 bytes. When you use non-portable extensions to the standard, the result is not portable.</p>
","13302561"
"Binary XML file line #2: Error inflating class","4246","","<p>I know similar questions like this has been answered but I seem to have done what the tutorial suggested and reading from other posts but still I get the Inflator error. Not sure what I am doing wrong. I don't see Google-Map. Please check the code. Thanks a lot.</p>

<p>I generate My Key with:</p>

<pre><code>keytool -list -v -keystore mystore.keystore
</code></pre>

<p>Activity_Map.java</p>

<pre><code>package pt.example.project;

import android.os.Bundle;
import android.support.v4.app.FragmentActivity;

public class Activity_Map extends FragmentActivity {

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.filexml);
    }
}
</code></pre>

<p>filexml.xml</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;fragment xmlns:android=""http://schemas.android.com/apk/res/android""
      android:id=""@+id/map""
      android:layout_width=""match_parent""
      android:layout_height=""match_parent""
      android:name=""com.google.android.gms.maps.MapFragment""/&gt;
</code></pre>

<p>AndroidManifest.xml</p>

<pre><code>&lt;manifest xmlns:android=""http://schemas.android.com/apk/res/android""
package=""pt.example.project""
android:versionCode=""1""
android:versionName=""1.0"" &gt;

&lt;uses-sdk
    android:minSdkVersion=""8""
    android:targetSdkVersion=""17"" /&gt;

&lt;!-- START COPY DEV GOOGLE DOCS --&gt;
&lt;permission
    android:name=""pt.example.project.permission.MAPS_RECEIVE""
    android:protectionLevel=""signature"" /&gt;

&lt;uses-permission android:name=""pt.example.project.permission.MAPS_RECEIVE"" /&gt;
&lt;uses-permission android:name=""android.permission.INTERNET"" /&gt;
&lt;uses-permission android:name=""android.permission.ACCESS_NETWORK_STATE"" /&gt;
&lt;uses-permission android:name=""android.permission.WRITE_EXTERNAL_STORAGE"" /&gt;
&lt;uses-permission android:name=""com.google.android.providers.gsf.permission.READ_GSERVICES"" /&gt;
&lt;!--
 The following two permissions are not required to use
 Google Maps Android API v2, but are recommended.

--&gt;
&lt;uses-permission android:name=""android.permission.ACCESS_COARSE_LOCATION"" /&gt;
&lt;uses-permission android:name=""android.permission.ACCESS_FINE_LOCATION"" /&gt;

&lt;uses-feature
    android:glEsVersion=""0x00020000""
    android:required=""true"" /&gt;
&lt;!-- END COPY DEV GOOGLE DOCS --&gt;

&lt;application
    android:allowBackup=""true""
    android:icon=""@drawable/ic_launcher""
    android:label=""@string/app_name""
    android:theme=""@style/generalnotitle"" &gt;
    &lt;uses-library android:name=""com.google.android.maps"" /&gt;

    &lt;activity
        android:name=""pt.example.project.MainActivity""
        android:label=""@string/app_name""
        android:screenOrientation=""portrait"" &gt;
        &lt;intent-filter&gt;
            &lt;action android:name=""android.intent.action.MAIN"" /&gt;

            &lt;category android:name=""android.intent.category.LAUNCHER"" /&gt;
        &lt;/intent-filter&gt;
    &lt;/activity&gt;
    &lt;activity
        android:name=""pt.example.project.Activity_Mapa""
        android:label=""@string/title_activity__mapa""
        android:theme=""@android:style/Theme.NoTitleBar""&gt;
    &lt;/activity&gt;

    &lt;meta-data
        android:name=""com.google.android.maps.v2.API_KEY""
        android:value=""My KEY"" /&gt;
&lt;/application&gt;
</code></pre>

<p></p>
","<pre><code>    android:minSdkVersion=""8""
</code></pre>

<p>Your min sdk is 8 you need to add support library or make your min sdk to 12</p>

<p><a href=""http://developer.android.com/tools/extras/support-library.html"" rel=""nofollow"">http://developer.android.com/tools/extras/support-library.html</a></p>

<p>Use SupportFragment.</p>

<pre><code> android:name=""com.google.android.gms.maps.SupportMapFragment""
</code></pre>

<p>Quoting from the docs </p>

<p>Use MapFrament class only if you are targeting API 12 and above. Otherwise, use SupportMapFragment.</p>

<p>For more Information check the link</p>

<p><a href=""https://developers.google.com/maps/documentation/android/reference/com/google/android/gms/maps/MapFragment"" rel=""nofollow"">https://developers.google.com/maps/documentation/android/reference/com/google/android/gms/maps/MapFragment</a></p>
","16437998"
"how can I decode the REG_BINARY value HKLM\Software\Microsoft\Ole\DefaultLaunchPermission to see which users have permission?","4241","","<p>I am trying to find a way to decode the REG_BINARY value for ""<strong>HKLM\Software\Microsoft\Ole\DefaultLaunchPermission</strong>"" to see which users have permissions by default, and if possible, a method in which I can also append other users by their username. </p>

<p>At work we make use of DCOM and for the most part we always give the same users permission but in some cases we are forced to accommodate our clients and add custom users/groups to suit their needs. Unfortunately the custom users we need to add are random usernames so I am unable to just add all the users and copy the value from the key like I have done with the default users we use 95% of the time.</p>

<p>I am currently working on a command-line executable application where I have a command to set permissions for pre-defined users but I would also like to be able to add an option to append a custom user(s) to add to the default permission along with our predefined default users list.</p>

<p>Currently, to set the default users list with my application I would just type:</p>

<p><strong>MyTool.exe Policies</strong></p>

<p>But I would like to be able to make it a bit more verbose, closer to how NET command is used for windows users, something like:</p>

<p><strong>MyTool.exe Policies /ADD:""MyCustomUsername""</strong></p>

<p>The problem is that the data stored in the REG_BINARY value doesn't seem to be easily decoded. I was able to decode the hex portion in python but I am left with some sort of binary data which I don't have a clue what to do with as I don't even know what kind of encoding was used in the first place to know what to use to decode it. :P</p>

<p>I have done quite a bit of googling but I think my lack of understanding the terminology around this topic has probably caused me to overlook the answer without recognizing it for what it is.</p>

<p>I guess my first real question would have to be what kind of encoding is used for the above key after it has been decoded from hex? </p>

<p>Or better yet, is it even possible to obtain/modify the key's value programmatically so that I can obtain a list of the users that are currently set, and if necessary, append additional users/groups?</p>

<p>I would prefer to keep this application written strictly in Python if possible (or WMI/WMIC), but if necessary I can attempt to implement other types of code into my python application if it means getting the job finally done! I guess it would also be useful to mention that this application is primarily used on Windows XP Professional and most Windows Server versions so I am not worried if any possible solution will not be compatible with earlier Windows OS version(s).</p>

<p>Any assistance, code or just some simple help with getting familiar with this topic, would be <em>GREATLY</em> appreciated!</p>

<p>Thanks in advance for any help you can provide!! :D</p>
","<p>Well REG_BINARY isn't any particular format, it's just a way to tell the registry the data is a custom binary format. So you're right about needing to find out what's in there.</p>

<p>Also, what do you mean by converting the data from hex? Are you unpacking it? I doubt you're interpreting it correctly until you know what has been saved in there in the first place.</p>

<p>Once you find out what's in that registry field, python's struct module will be your best friend.</p>

<p><a href=""http://docs.python.org/library/struct.html"" rel=""nofollow noreferrer"">http://docs.python.org/library/struct.html</a></p>

<p>Further reading (you've probably already seen these)</p>

<ul>
<li><a href=""http://msdn.microsoft.com/en-us/library/ms687317(VS.85).aspx"" rel=""nofollow noreferrer"">http://msdn.microsoft.com/en-us/library/ms687317(VS.85).aspx</a>
&lt;--windows info on perms</li>
<li><a href=""http://docs.python.org/library/_winreg.html"" rel=""nofollow noreferrer"">http://docs.python.org/library/_winreg.html</a>
&lt;-- python registry access</li>
</ul>
","775410"
"convert negative decimal to binary using 8 bits","4235","","<p>(Not sure if I am allow to ask a question like this but will delete if asked)
Convert -25 into binary representation using 8 bits and 2's complement format to represent a negative number. So far I got 11001.</p>

<p>I tried to google methods but I am not sure how to do it using the 8 bits way.</p>

<p>This question is not using code, just conversions but from what I did was
convert it to binary which was 11001 then I added 3 zero's to make it 8bits (assuming that is correct) 00011001 then I did 1's complement 11100110 and 2's complement by adding 1 which equals 11100111.</p>

<p>I am not sure if that is correct.</p>
","<p>Two's complement is probably one of the more straightforward operations on binary numbers. In short, you'll want to take the following actions to convert a decimal number into two's complement form:</p>

<ol>
<li>Write down the binary representation of the positive version of your number. In this case, 25 should be represented as: 00011001</li>
<li>Next, flip all the digits: 11100110</li>
<li>Add one: 11100111</li>
<li>Sit back, grab a drink, and bask in the glory of the newly-created two's complement representation of a decimal number.</li>
</ol>

<p><a href=""http://www.cs.cornell.edu/~tomf/notes/cps104/twoscomp.html"" rel=""nofollow"">Source</a></p>
","29836568"
"How to implement a logical shift (to the left) by 8 bits?","4229","","<p>I am trying to determine how to shift the last 8 bits (i.e. byte) of a 16 bit (two byte) word to the left using the LC-3 instruction set.</p>

<p>For example,</p>

<pre><code>0000 0000 1111 1111 -&gt; 1111 1111 0000 0000
</code></pre>
","<p>Now understanding that you are talking about LC-3, I found the <a href=""http://users.ece.utexas.edu/~patt/07s.360N/handouts/360n.appC.pdf"" rel=""nofollow"">LC-3b Miroarchitecture</a> and this presentation on the <a href=""http://classes.soe.ucsc.edu/cmpe012/Summer08/notes/06_LC3_ISA_markup.pdf"" rel=""nofollow"">Instruction Set</a> referenced.</p>

<p>You need to implement a <a href=""http://en.wikipedia.org/wiki/Logical_shift"" rel=""nofollow"">logical shift</a>. Specifically a <a href=""http://chortle.ccsu.edu/assemblytutorial/Chapter-12/ass12_2.html"" rel=""nofollow"">logical shift left</a>. A number of ways are available to do this. </p>

<p>If you understand <a href=""http://www.swarthmore.edu/NatSci/echeeve1/Ref/BinaryMath/BinaryMath.html"" rel=""nofollow"">binary arithmetic</a>, you will be able to do this in a straightforward way.</p>
","15649778"
"Python method for storing list of bytes in network (big-endian) byte order to file (little-endian)","4229","","<p>My present task is to dissect tcpdump data that includes P2P messages and I am having trouble with the piece data I acquire and write to a file on my x86 machine. My suspicion is I have a simple endian-ness issue with the bytes I write to to file. </p>

<p>I have a list of bytes holding a piece of P2P video read and processed using python-pcapy package BTW. </p>

<p><code>bytes = [14, 254, 23, 35, 34, 67, etc... ]</code></p>

<p>I am looking for a way to store these bytes, presently held in a list in my Python application to a file. </p>

<p>Currently I write the pieces as follows: </p>

<pre><code>def writePiece(self, filename, pieceindex, bytes, ipsrc, ipdst, ts): 
    file = open(filename,""ab"")
    # Iterate through bytes writing them to a file if don't have piece already 
    if not self.piecemap[ipdst].has_key(pieceindex):
        for byte in bytes: 
            file.write('%c' % byte)
        file.flush()
        self.procLog.info(""Wrote (%d) bytes of piece (%d) to %s"" % (len(bytes), pieceindex, filename))

    # Remember we have this piece now in case duplicates arrive 
    self.piecemap[ipdst][pieceindex] = True

    # TODO: Collect stats 
    file.close()
</code></pre>

<p>As you can see from the for loop, I write the bytes to the file in the same order as I process them from the wire (i.e. network or big-endian order). </p>

<p>Suffice to say, the video which is the payload of the pieces does not playback well in VLC :-D </p>

<p>I think I need to convert them to little-endian byte order but am not sure the best way to approach this in Python. </p>

<p><strong>UPDATE</strong> </p>

<p>The solution that worked out for me (writing P2P pieces handling endian issues appropriately) was: </p>

<pre><code>def writePiece(self, filename, pieceindex, bytes, ipsrc, ipdst, ts): 
    file = open(filename,""r+b"")
    if not self.piecemap[ipdst].has_key(pieceindex):
        little = struct.pack('&lt;'+'B'*len(bytes), *bytes) 
        # Seek to offset based on piece index 
        file.seek(pieceindex * self.piecesize)
        file.write(little)
        file.flush()
        self.procLog.info(""Wrote (%d) bytes of piece (%d) to %s"" % (len(bytes), pieceindex, filename))

    # Remember we have this piece now in case duplicates arrive 
    self.piecemap[ipdst][pieceindex] = True

    file.close()
</code></pre>

<p>The key to the solution was usage of Python struct module as suspected and in particular: </p>

<pre><code>    little = struct.pack('&lt;'+'B'*len(bytes), *bytes) 
</code></pre>

<p>Thanks to those who responded with helpful suggestions. </p>
","<p>You can also use an <a href=""http://docs.python.org/library/array.html#module-array"" rel=""nofollow noreferrer"">array.array</a>:</p>

<pre><code>from array import array
f.write(array('B', bytes))
</code></pre>

<p>instead of </p>

<pre><code>f.write(struct.pack('&lt;'+'B'*len(bytes), *bytes))
</code></pre>

<p>which when tidied up a little is</p>

<pre><code>f.write(struct.pack('B' * len(bytes), *bytes))
# the &lt; is redundant; there is NO ENDIANNESS ISSUE
</code></pre>

<p>which if len(bytes) is ""large"" might be better as</p>

<pre><code>f.write(struct.pack('%dB' % len(bytes), *bytes)) 
</code></pre>
","3541547"
"Pulling BLOB image data from MySQL in PHP","4217","","<p>I was reading from a few tutorials on how to upload my image into the DB as binary opposed to putting them on the server itself, well  I got it to work like this:</p>

<p>PHP:</p>

<pre><code>$image = chunk_split(base64_encode(file_get_contents($tmpfile)));
    mysql_query(""INSERT INTO images (`img_location`, `caption`, `user`, `genre`, `when`) VALUES ('$image', '$caption', '$id', '$genre', '$when')"");
</code></pre>

<p>My issue is how do you now pull it from the database, I've read several ways of doing it, tried them all, can't figure it out, I'm not getting a MySQL error, here's how I'm trying it:</p>

<pre><code>$get_pics = mysql_query(""SELECT * FROM images WHERE user='$id' "");
while($get_pics2 = mysql_fetch_array($get_pics))
{
$sixfour_enc = base64_decode($get_pics2['img_location']);

$new .= ""&lt;img src=\"""".$sixfour_enc.""\"" &gt;"";
}
</code></pre>

<p>This works... kind of, what's happening is that it's printing out raw binary in the IMG tag.</p>

<p>How do I get this to compile to a readble image again? Also, is storing the images in the database stupid? Should I just do what I usually do and store them on the server?</p>

<p>Thank you
-mike</p>
","<p>You can store images in your database if you want to (though there's nothing wrong with just storing them as files either, choose whatever is appropriate in your situation), but store the raw binary data in a BLOB (i.e. don't encode it with base64). You can embed the binary data you get from <code>file_get_contents</code> in your query directly, provided you use the proper escape function (<code>mysql_real_escape_string</code> in your case) first.</p>

<p>As for the outputting of the image, you can do it the way you're doing it right now, but you'll have to output it base64-encoded and with a <code>data</code> URI scheme like this:</p>

<pre><code>echo '&lt;img alt=""embedded image"" src=""data:image/png;base64,' . chunk_split(base64_encode($get_pics2['img_location'])) . '""&gt;';
</code></pre>

<p>Note that there are some advantages and disadvantages of embedded image data. Some important disadvantages to be aware of are the severe overhead of base64 encoding (around 33% larger than original) and potential caching problems.</p>
","9646126"
"Reading binary integers from a file in C","4214","","<p>All night I have been looking for answers for this &amp; haven't slept, yet, I can't make it work...
I have a binary file and I want to read it and take the value of each integer...
Here is some code:</p>

<pre><code>FILE *f;
char ch;
char t1[3];
int l, c, grayScale, i, j;
int p =0;


f = fopen(pgm, ""rb"");

(...)

c = 0;
l = 0;


fscanf(f, ""%d"", &amp;c);

fscanf(f, ""%d"", &amp;l);

fscanf(f, ""%d"", &amp;grayScale);


A = alocar_memoria_matriz(l,c);

for(i = 0; i&lt;l; i++){
    for(j=0; j&lt;c; j++){
        if(fread(&amp;p,sizeof(int),1,f) !=1){
             fprintf(stderr, ""\nError!\n"");
             fclose(f);
             free_memoria_matriz(A,l);
             return NULL;
        }else if(p&gt;grayScale|| p&lt;0){
            fprintf(stderr, ""\nError!\n"");
            fclose(f);
            free_memoria_matriz(A,l);
            return NULL;
        }else{
        A[i][j] = (tdf_elemento) p;

    }
}
}
</code></pre>

<p>I did some <code>printf</code> of that p (with %d and %i) and I get values like -1161602550, 1213357911, 994462027...
I really don't know what's going on, I also tried to change p for char[5] but didn't work so far...
Thank you in advance...</p>
","<p>The ""binary"" open mode does not change the way <code>fscanf</code> parses the file. Its only effect is to (perhaps) prevent conversion of <code>\r\n</code> line endings to <code>\n</code> as the file is read by stdio facilities.</p>

<p>To read from a stdio file <code>f</code> into an integer <code>i</code>, you can do <code>fread( &amp; i, sizeof i, 1, f )</code>. But note that this does not respect endianness. Without explicit byte-swapping your binary format will be platform-dependent on endianness.</p>
","19872615"
"How to read exe file in binary code - C++","4212","","<p>How can I make program in C++ that will read .exe or another file in binary code?  </p>
","<pre><code>#include &lt;fstream&gt;

int main()
{
    std::ifstream in(""yourfile.exe"", std::ios::in | std::ios::binary);
    ///
    in.read (buffer, buffer_size);
}
</code></pre>

<p>For a detailed example on how to read binary files in C++, see <a href=""http://courses.cs.vt.edu/~cs2604/fall02/binio.html"" rel=""nofollow"">this link</a> or do your own googling. </p>
","6816952"
"Python3 searching in bytearray","4207","","<p>I have this strange problem with using find()/index() (don't know if there is any difference between them) with bytesarray. </p>

<p>I'm working with binary file, I have loaded it as bytesarray and now I need to find tokens that indicate beginning of message and end of message. 
Everything works fine with finding the beginning of message (0x03 0x02) but I keep getting the same position where I started searching when I search for the end (0x00)</p>

<pre><code>    msg_start_token = bytearray((int(0x03), int(0x02)))
    msg_end_token = bytes(int(0x00))

    def get_message(file,start_pos):
        msg_start = file.find(msg_start_token,start_pos) + 2
        print(hex(msg_start))
        msg_end = file.find(msg_end_token,msg_start)
        print(hex(msg_end))
        msg = file[msg_start:msg_end]
        print(msg)
        return (msg, msg_end)  
</code></pre>

<p>I haven't really worked with binary files before so I don't know maybe I'm missing something really simple in fact.</p>
","<p>You need to start searching at the <em>next position</em>, so search at:</p>

<pre><code>file.find(msg_start_token, start_pos + 1)
</code></pre>

<p>because the search starts <em>at</em> <code>start_pos</code>, and if <code>msg_start_token</code> is found at that position, find will return <code>start_pos</code> of course.</p>

<p>As for the difference between <code>.index()</code> and <code>.find()</code>; <code>.index()</code> raises a <code>ValueError</code> exception if the substring is not found, while <code>.find()</code> returns <code>-1</code> instead.</p>
","14751935"
"Cannot convert type 'string' to 'byte[]'?","4197","","<p>Hi I have to display student image on image box while selecting  student ID from drop down list. The image is store in binary format in db.I want to display the image without using generic http handler. While using the given below code generation one error. The error is ""Cannot convert type string to byte[]"". Please help me.</p>

<p>Code:</p>

<pre><code>protected void DropDownList1_SelectedIndexChanged(object sender, EventArgs e)
{
    DataSet1TableAdapters.TextBoxTableTableAdapter tx;
    tx = new DataSet1TableAdapters.TextBoxTableTableAdapter();
    DataTable dt = new DataTable();
    dt = tx.GetstudData(int.Parse(DropDownList1.SelectedValue));
    foreach (DataRow row in dt.Rows)
    {
        TextBox1.Text = (row[""FirstName""].ToString());
        TextBox2.Text = (row[""SecondName""].ToString());  
        byte[] barrImg = (byte[])(row[""StudImage""].ToString());
        string base64String = Convert.ToBase64String(barrImg , 0, barrImg.Length);
        Image1.ImageUrl = ""data:image/png;base64,"" + base64String;
    }
}
</code></pre>

<p>SQL Query:</p>

<pre><code>SELECT FirstName, SecondName, StudentImage FROM TextBoxTable WHERE (Id = @Id)
</code></pre>

<p>Aspx Source:</p>

<pre><code>&lt;div&gt;
&lt;asp:DropDownList ID=""DropDownList1"" runat=""server"" AutoPostBack=""True""&gt;
&lt;asp:TextBox ID=""TextBox1"" runat=""server""&gt;&lt;/asp:TextBox&gt;
&lt;asp:TextBox ID=""TextBox2"" runat=""server""&gt;&lt;/asp:TextBox&gt;
&lt;asp:Image ID=""Image1"" runat=""server"" /&gt;
&lt;/div&gt;
</code></pre>

<p>Data Base:</p>

<p><img src=""https://i.stack.imgur.com/xdVrl.jpg"" alt=""enter image description here""></p>
","<p>Yes, the problem is here:</p>

<pre><code>byte[] barrImg = (byte[])(row[""StudImage""].ToString());
</code></pre>

<p>You're calling <code>ToString()</code> on <code>row[""StudImage""]</code>. That will result in a <code>String</code>. You're then casting that string to <code>byte[]</code> - but that doesn't work, because there's no such conversion. (What would you expect it to do?)</p>

<p>It's not clear why you're calling <code>ToString</code> at all - if the value is binary data, I'd expect this to work:</p>

<pre><code>byte[] barrImg = (byte[]) row[""StudImage""];
</code></pre>

<p>Note that you don't need to provide three arguments to <code>Convert.ToBase64String</code> - you can just use:</p>

<pre><code>string base64 = Convert.ToBase64String(barrImg);
</code></pre>

<p>I'd personally encourage you to use casting for your earlier statements as well - if the values <em>aren't</em> strings, then presumably that represents a serious issue:</p>

<pre><code>TextBox1.Text = (string) row[""FirstName""];
TextBox2.Text = (string) row[""SecondName""];  
</code></pre>

<p>On the other hand, your schema allows for null values - which currently you're not taking into consideration at all. All of the casts above will throw an exception if the values is <em>actually</em> <code>DbNull.Value</code>. You should consider how you want to handle that, as a separate matter.</p>
","26419094"
"Writing a string to file in binary mode","4176","","<p>So I'm using this code to write the file(just testing now, I'm going to write a level editor later):
<pre> <code>
int main()
{
    ofstream file(""level.bin"", ios::binary);
    int ents = 1; //number of entites
    file.write((char*)&amp;ents, sizeof(int));
    float x = 300; //x and y coords
    float y = 500;
    file.write((char*)&amp;x, sizeof(float));
    file.write((char*)&amp;y, sizeof(float));
    int imglength = 12; //strings are prefixed by a length
    file.write((char*)&amp;imglength, sizeof(int));
    string img = ""platform.png""; //string
    file.write(img.c_str(), sizeof(img.c_str()));
    cout &lt;&lt; ""wrote\n"";
    return 0;
}
</pre> </code></p>

<p>The code I'm using to load it is this:
<pre> <code></p>

<p>void SceneManager::LoadScene(std::string filename)
{
    std::ifstream file(filename.c_str(), std::ios::binary);
    int ents;
    file.read((char*)&amp;ents, sizeof(int));
    std::cout &lt;&lt; ents &lt;&lt; std::endl;
    for(int i = 0; i &lt; ents; i++)
    {
        //read x and y coords
        float x;
        float y;
        file.read((char*)&amp;x, sizeof(float));
        file.read((char*)&amp;y, sizeof(float));
        std::cout &lt;&lt; x &lt;&lt; "" "" &lt;&lt; y &lt;&lt; std::endl;
        int imglength;
        file.read((char*)&amp;imglength, sizeof(int));
        std::cout &lt;&lt; imglength &lt;&lt; std::endl;
        std::stringstream ss;
        for(int k = 0; k &lt;= imglength; k++)
        {
            //read string
            char c;
            file.read((char*)&amp;c, sizeof(char));
            ss &lt;&lt; c;
        }
        std::string image = ss.str();
        std::cout &lt;&lt; image &lt;&lt; std::endl;
        phys_static ent;
        Def edef;
        edef.SetVal(""x"", x);
        edef.SetVal(""y"", y);
        edef.SetString(""image"", image);
        ent.init(edef);
        AddEntity(ent);
    }
    file.close();
}
</pre> </code></p>

<p>Everything works fine except the string loading. I expect I'm writing it wrong, as instead of the platform.png it shows plattttttttt and errors out when I load the image. I'm also prefixing the string with it's length.
What is the correct way to write a string to a binary file?
What is the corre</p>
","<p>The error is at this line:</p>

<pre><code>file.write(img.c_str(), sizeof(img.c_str()));
</code></pre>

<p>What you want is:</p>

<pre><code>file.write(img.c_str(), img.size());
</code></pre>

<p>The <code>sizeof(img.c_str())</code> returns 4 because <code>sizeof(char *)</code> (the return type of <code>c_str()</code>) is 4 on your platform. This means first 4 characters are written and then you get just some garbage.</p>
","5442836"
"Faster version of dec2bin function for converting many elements?","4155","","<p>I am reading a bitmap file and converting <strong>each</strong> of the RGB values ranging from 0 to 255 to binary.</p>

<p>So a 240 by 320 bitmap will have 230400 RGB values to convert. The original dec2bin function was too slow, so I wrote my own as I know my value will always be between 0 to 255.</p>

<p>But going through 230400 values will still take approx. 6sec on my machine, and a single colour bitmap will take about 2.3sec.</p>

<p>Is there anyway to speed things up to be under 1sec or even better 0.5sec, as every msec counts for my application?</p>

<p>Here is my code:</p>

<pre><code>function s = dec2bin_2(input)

if input == 255
    s = [1;1;1;1;1;1;1;1];
    return;
end

s = [0;0;0;0;0;0;0;0];

if input == 0
    return;
end

if input &gt;= 128
    input = input - 128;
    s(1) = 1;
    if input == 0
        return;
    end
end

if input &gt;= 64
    input = input - 64;
    s(2) = 1;
    if input == 0
        return;
    end
end

if input &gt;= 32
    input = input - 32;
    s(3) = 1;
    if input == 0
        return;
    end
end

if input &gt;= 16
    input = input - 16;
    s(4) = 1;
    if input == 0
        return;
    end
end

if input &gt;= 8
    input = input - 8;
    s(5) = 1;
    if input == 0
        return;
    end
end

if input &gt;= 4
    input = input - 4;
    s(6) = 1;
    if input == 0
        return;
    end
end

if input &gt;= 2
    input = input - 2;
    s(7) = 1;
    if input == 0
        return;
    else
        s(8) = 1;
    end
end
end
</code></pre>

<p>I was thinking if I'm not able to do it in MATLAB then maybe I'll do the conversion in C++. Is this advisable?</p>

<p>Thanks.</p>
","<p>An even faster way is to use lookup tables. Since you know all the values are intensities between 0 and 255, you construct the binary equivalent of each to speed up the process.</p>

<pre><code>% build table (computed once) [using gnovice option#1]
lookupTable = cell2mat(arrayfun(@(i)bitget([0:255]',9-i),1:8,'UniformOutput',0));

% random' image
I = randi(256, [240 320])-1;

% decimal to binary conversion
binI = lookupTable(I(:)+1,:);
</code></pre>

<p>On my machine, it took on average 0.0036329 seconds (only the conversion). Note the lookup table has almost no space overhead:</p>

<pre><code>&gt;&gt; whos lookupTable
  Name               Size            Bytes  Class    Attributes
  lookupTable      256x8              2048  uint8 
</code></pre>
","1545490"
"C# Reading, Modifying then writing binary data to file. Best convention?","4152","","<p>I'm new to programming in general (My understanding of programming concepts is still growing.). So this question is about learning, so please provide enough info for me to learn but not so much that I can't, thank you.
(I would also like input on how to make the code reusable with in the project.)</p>

<p>The goal of the project I'm working on consists of:</p>

<ol>
<li><p>Read binary file.</p></li>
<li><p>I have known offsets I need to read to find a particular chunk of data from within this file.</p></li>
<li><p>First offset is first 4 bytes(Offset for end of my chunk).</p></li>
<li><p>Second offset is 16 bytes from end of file. I read for 4 bytes.(Gives size of chunk       in hex).</p></li>
<li><p>Third offset is the 4 bytes following previous, read for 4 bytes(Offset for start of chunk in hex).</p></li>
<li><p>Locate parts in the chunk to modify by searching ASCII text as well as offsets.</p></li>
</ol>

<p>Now I have the start offset, end offset and size of my chunk.
This should allow me to read bytes from file into a byte array and know the size of the array ahead of time.</p>

<p>(Questions: 1. Is knowing the size important? Other than verification. 2. Is reading part of a file into a byte array in order to change bytes and overwrite that part of the file the best method?)</p>

<p>So far I have managed to read the offsets from the file using BinaryReader on a MemoryStream. I then locate the chunk of data I need and read that into a byte array.</p>

<p>I'm stuck in several ways:</p>

<ul>
<li>What are the best practices for binary Reading / Writing?</li>
<li>What's the best storage convention for the data that is read?</li>
<li>When I need to modify bytes how do I go about that.</li>
<li>Should I be using FileStream?</li>
</ul>
","<p>Since you want to both read and write, it makes sense to use the FileStream class directly (using FileMode.Open and FileAccess.ReadWrite).  See <a href=""http://msdn.microsoft.com/en-us/library/system.io.filestream"" rel=""nofollow"">FileStream on MSDN</a> for a good overall example.</p>

<ol>
<li>You do need to know the number of bytes that you are going to be reading from the stream.  See the <a href=""http://msdn.microsoft.com/en-us/library/system.io.filestream.read"" rel=""nofollow"">FileStream.Read documentation</a>.</li>
<li>Fundamentally, you <em>have</em> to read the bytes into memory at some point if you're going to use and later modify their contents.  So you will <em>have</em> to make an in-memory copy (using the Read method is the right way to go if you're reading a variable-length chunk at a time).</li>
</ol>

<p>As for best practices, always dispose your streams when you're done; e.g.:</p>

<pre><code>using (var stream = File.Open(FILE_NAME, FileMode.Open, FileAccess.ReadWrite))
{
    //Do work with the FileStream here.
}
</code></pre>

<p>If you're going to do a large amount of work, you should be doing the work asynchronously.  (Let us know if that's the case.)</p>

<p>And, of course, check the FileStream.Read documentation and also the <a href=""http://msdn.microsoft.com/en-us/library/system.io.filestream.write"" rel=""nofollow"">FileStream.Write documentation</a> before using those methods.</p>

<p>Reading bytes is best done by pre-allocating an in-memory array of bytes with the length that you're going to read, then reading those bytes.  The following will read the chunk of bytes that you're interested in, let you do work on it, and then replace the original contents (assuming the length of the chunk hasn't changed):</p>

<p><em><strong>EDIT: I've added a helper method to do work on the chunk, per the comments on variable scope.</em></strong></p>

<pre><code>using (var stream = File.Open(FILE_NAME, FileMode.Open, FileAccess.ReadWrite))
{
    var chunk = new byte[numOfBytesInChunk];
    var offsetOfChunkInFile = stream.Position; // It sounds like you've already calculated this.
    stream.Read(chunk, 0, numOfBytesInChunk);

    DoWorkOnChunk(ref chunk);        

    stream.Seek(offsetOfChunkInFile, SeekOrigin.Begin);
    stream.Write(chunk, 0, numOfBytesInChunk);
}

private void DoWorkOnChunk(ref byte[] chunk)
{
    //TODO: Any mutation done here to the data in 'chunk' will be written out to the stream.
}
</code></pre>
","10941189"
"WIX: Using a temporary file during install","4127","","<p>I am writing a WIX installer and I have a following requirement:<br>
During installation, I need to pass an absolute path to a file (lets call it A) included in my installer to a COM component, which already exists on the hard drive and is a part of another program. I have already written an appropriate Custom Action which expects a path to the file A. I don't want to include A as a file installed in the Program Files folder and removed during the uninstallation process. Instead, I would like to put A only temporary on the hard drive, call my Custom Action which will cause the COM component to use the content of A, and then remove A from disk. Is there an easy way to accomplish this goal?</p>

<p>I have tried to utilize the Binary Table and store A there, however I don't know how to reference A using absolute path. I know I could put A outside of MSI file but I would like to keep every file installer needs in a single MSI.</p>

<p>Any help would be appreciated.</p>
","<p>I would take this approach.</p>

<p>Install the file ""A"" into any directory. Run your custom action needed to update the COM component. Then run another custom action or modify the currently written one to remove the file after it is no longer in use. This would leave no trace of the file ""A"" and if you schedule the custom action to only run during the install you won't have to worry about it on uninstall.</p>
","2624805"
"how to obtain the post data in binary of PHP","4123","","<p>I want to post some binary data to PHP.<br>
I know that I can use php://input or $HTTP_RAW_POST_DATA to read it.<br>
But it only can post one binary data.<br>
I want to post two key-value data which respective value is in binary.<br>
How can we do this in PHP? </p>
","<p>You can encode your binary data in Base64 using <a href=""http://php.net/manual/en/function.base64-encode.php"" rel=""nofollow""><strong><code>base64_encode()</code></strong></a> and <a href=""http://php.net/manual/en/function.base64-decode.php"" rel=""nofollow""><strong><code>base64_decode()</code></strong></a>.</p>

<blockquote>
  <p>Base64 encoding schemes are commonly used when there is a need to
  encode binary data that needs to be stored and transferred over media
  that are designed to deal with textual data.</p>
</blockquote>

<p>For example, you can post:</p>

<pre><code>key1=eW91cmJpbmFyeWRhdGE=&amp;key2=YmluYXJ5YWdhaW4=
</code></pre>

<p>And in your PHP:</p>

<pre><code>$myBinaryData1 = base64_decode($_POST['key1']);
$myBinaryData2 = base64_decode($_POST['key2']);
</code></pre>
","10596394"
"how to translate char into hex and binary","4114","","<p>I have the following example in C:</p>

<pre><code>int x = 123; 

size of int = 4 bytes.
hex value = 7b
binary value = 0111 1011
</code></pre>

<p>What will be the hex/binary value if my x was a char?</p>

<pre><code>char x = 123;
size of char = 1 byte.
hex value = ??
binary value = ??
</code></pre>
","<p>Since <code>char</code> is smaller than <code>int</code>, it would be the same. Except for leading zeros you would find in an <code>int</code>.</p>

<p>Try this:</p>

<pre><code>  6   int x = 123;
  7 
  8   printf (""Size of int is  %d bytes\n"", sizeof(int));
  9   printf (""Size of char is %d byte\n"", sizeof(char));
 10 
 11   printf (""Hex value is %x\n"", x);
 12   printf (""Hex value is %x\n"", (char)x);
 13 
 14   printf (""As for binary value .... google is your friend\n"");
</code></pre>

<p>Output is:</p>

<pre><code>Size of int is  4 bytes
Size of char is 1 byte

Hex value is 7b
Hex value is 7b
</code></pre>

<p>As for binary value .... google is your friend
This <a href=""http://www.is.wayne.edu/olmt/binary/page3.htm"" rel=""nofollow"">site</a> seems to explain things well</p>
","6393027"
"Algorithm in hardware to find out if number is divisible by five","4101","","<p>I am trying to think of an algorithm to implement this for a given n bit binary number. I tried out many examples, but am unable to find out any pattern. So how shall I proceed?</p>
","<p>How about this:</p>

<p>Convert the number to base 4 (this is trivial by simply combining pairs of bits). 5 in base 4 is 11. The values base 4 that are divisible by 11 are somewhat familiar: 11, 22, 33, 110, 121, 132, 203, ...</p>

<p>The rule for divisibility by 11 is that you add all the odd digits and all the even digits and subtract one from the other. If the result is divisible by 11 (which remember is 5), then it's divisible by 11 (which remember is 5).</p>

<p>For example:</p>

<pre><code>123456d = 1 1110 0010 0100 0000b = 132021000_4

The even digits are 1 2 2 0 0 : sum = 5d
The odd digits are   3 0 1 0  : sum = 4d

Difference is 1, which is not divisble by 5
</code></pre>

<p>Or another one:</p>

<pre><code>123455d = 1 1110 0010 0011 1111b = 132020333_4

The even digits are 1 2 2 3 3 : sum = 11d
The odd digits are   3 0 0 3  : sum = 6d

Difference is 5, which is a 5 or a 0
</code></pre>

<p>This should have a fairly efficient HW implementation because it's mostly bit-slicing, followed by N/2 adders, where N is the number of bits in the number you're interested in.</p>

<p>Note that after adding the digits and subtracting, the maximum value is 3/4 * N, so if you have 16-bit numbers max, you can get at most 12 as a result, so you only need to check for 0, &plusmn;5 and &plusmn;10 explicitly. If you're using 32-bit numbers then you can get at most 24 as a result, so you need to also check if the result is &plusmn;15 or &plusmn;20.</p>
","18474491"
"how to convert string to binary integer file using command line under linux","4098","","<p>What i want is to take an integer represented as a string, for example ""1234"", and convert it to a file called int, containing a 32-bit big endian integer, with the value 1234.</p>

<p>The only way I have figured out to do this is something like</p>

<pre><code>echo 1234 | awk '{printf ""0: %08X"", $1}' | xxd -r &gt; int
</code></pre>

<p>which is a bit nasty!</p>

<p>Does anyone know a better way?</p>
","<p>ok well seeing that mark williams seems to have gone awol i will post the corrected version of his answer</p>

<pre><code>echo 1234 | perl -e 'print pack(""N"", &lt;STDIN&gt;); &gt; int
</code></pre>
","435294"
"Can Fortran read bytes directly from a binary file?","4095","","<p>I have a binary file that I would like to read with Fortran. The problem is that it was not written by Fortran, so it doesn't have the record length indicators.  So the usual unformatted Fortran read won't work.</p>

<p>I had a thought that I could be sneaky and read the file as a formatted file, byte-by-byte (or 4 bytes by 4 bytes, really) into a character array and then convert the contents of the characters into integers and floats via the transfer function or the dreaded equivalence statement. But this doesn't work: I try to read 4 bytes at a time and, according to the POS output from the <code>inquire</code> statement, the read skips over like 6000 bytes or so, and the character array gets loaded with junk.</p>

<p>So that's a no go. Is there some detail in this approach I am forgetting?  Or is there just a fundamentally different and better way to do this in Fortran? (BTW, I also tried reading into an <code>integer*1</code> array and a byte array.  Even though these codes would compile, when it came to the read statement, the code crashed.)</p>
","<p>Yes.  </p>

<p>Fortran 2003 introduced stream access into the language.  Prior to this most processors supported something equivalent as an extension, perhaps called ""binary"" or similar.</p>

<p>Unformatted stream access imposes no record structure on the file.  As an example, to read data from the file that corresponds to a single int in the companion C processor (if any) for a  particular Fortran processor:</p>

<pre><code>USE, INTRINSIC :: ISO_C_BINDING, ONLY: C_INT
INTEGER, PARAMETER :: unit = 10
CHARACTER(*), PARAMETER :: filename = 'name of your file'
INTEGER(C_INT) :: data
!***
OPEN(unit, filename, ACCESS='STREAM', FORM='UNFORMATTED')
READ (unit) data
CLOSE(unit)
PRINT ""('data was ',I0)"", data
</code></pre>

<p>You may still have issues with endianess and data type size, but those aspects are language independent.</p>

<p>If you are writing to a language standard prior to Fortran 2003 then unformatted direct access reading into a suitable integer variable may work - it is Fortran processor specific but works for many of the current processors.</p>
","11570277"
"Python 3, Converting a string storing binary data to Int","4084","","<p>I have the variable Number which is equal to ""0b11001010"" and I want it to be the type int like a normal binary is stored e.g.   0b11001010</p>

<pre><code>Number = ""0b11001010""
NewNumber = 0b11001010
</code></pre>

<p>is there a really simple way and I am overlooking it?</p>

<p>Thanks.</p>
","<p>In python you can only create it as a binary value (as a syntactic sugar), it will be converted into an integer immediately. Try it for yourself:</p>

<pre><code>&gt;&gt;&gt; 0b11001010
202
</code></pre>

<p>The same thing will happen with octal and hexadecimal values. So you can convert your binary string to an integer, with the <code>int()</code> function's <code>base</code> argument like:</p>

<pre><code>&gt;&gt;&gt; int('0b11001010', 2)
202
</code></pre>

<p>After the conversion you can do any operations on it -- just like with an integer, since it is an integer.</p>

<p>Of course you can convert it back at any time to a binary string, with the builtin <code>bin()</code> function:</p>

<pre><code>&gt;&gt;&gt; bin(202)
0b11001010
</code></pre>
","18311529"
"Java - Integer.parseInt() not returning a negative number when radix=2","4061","","<p>As far as I know, when using 2's complement, and the first number is a 1, then you flip the numbers and find the value of the new byte and make it a negative.The javadoc says that Integer.parseInt(String s, radix) and Integer.valueOf(String s, radix) both should return a signed integer object, but when I test it out with this:</p>

<pre><code>System.out.println(Integer.parseInt(""10000001"", 2));

System.out.println(Integer.valueOf(""10000001"", 2));
</code></pre>

<p>I get:</p>

<pre><code>129

129
</code></pre>

<p>even though my calculations get me -127. Whats interesting is that</p>

<pre><code>System.out.println(Integer.parseInt(""-10000001"", 2));
</code></pre>

<p>prints out:</p>

<pre><code>-129
</code></pre>

<p>Anyone know of a different java method that if you input a byte (and radix = 2), then the method will return a correctly signed value?</p>
","<p>If it's always going to be a byte, then this should do the trick:</p>

<pre><code>int i = Integer.parseInt(""10000001"", 2);
byte b = (byte) i;
</code></pre>

<p>The integer value will be 129, but when you cast it to a byte it will change to -127.</p>
","15415639"
"Signed magnitude, 1's complement and 2's complement of +46 and -17","4056","","<p>can anyone verify if am I correct?</p>

<pre><code>+46 (7 bits)
S.M : 0101110
1's C. : 0101110 ( the same )
2's C. : 0101110 ( the same )

-17 (7 bits)
S.M : 1010001
1's C. : 1101110
2's C. : 1101111
</code></pre>
","<p>The +46 ones are all incorrect (your comment is correct).  To test the signed magnitude, just break down the magnitude component like:</p>

<pre><code>0 * 1 + 
1 * 2 +
1 * 4 +
0 * 8 +
1 * 16 + 
1 * 32
</code></pre>

<p>Once you get the signed magnitude, the others should be easy.</p>

<p>Your -17 are all correct.</p>
","9303694"
"Is that possible to run a python built program on iOS as a static lib?","4054","","<p>I have some AI code developed in python 2.7 that uses non-standard libraries. </p>

<p>I intend to compile it to work with my iPhone app.</p>

<p>I wouldn't like to re-program everything so, is that a way to compile my python code + all dependencies into a static file so I can call it from my iOS app as a function?</p>
","<p>kivy can do it </p>

<p><a href=""http://kivy.org/docs/guide/packaging-ios.html"" rel=""nofollow"">http://kivy.org/docs/guide/packaging-ios.html</a></p>

<p>also maybe look at <a href=""https://itunes.apple.com/us/app/python-for-ios/id485729872?ls=1&amp;mt=8"" rel=""nofollow"">https://itunes.apple.com/us/app/python-for-ios/id485729872?ls=1&amp;mt=8</a></p>

<p>although I doubt you can just compile your existing project into it... you will need to re-write at least part of it and you can only use pure python libraries (kivy)</p>
","18879692"
"Finding set bits of an integer","4051","","<p>Okay, got a question. I have assembled a bit mask for options. Basically my page has a list box that allows multiple selections that stores them in a list of integers (their ID value). There are 14 total choices (so ID val 1-15). The reason I am assembling this into a bit mask is because I don't want to hard code in a number in case I want to add options to the database table (where the listbox populates from). Also, I do not want to be sending in 14 parameters to my SQL stored procedure (thus hardcoding in the number 14). I can send in this integer and deconstruction it (later step). </p>

<p>However, right now I need to find out which bits are set in my integer for another reason. Basically I have a property. The get assembles the bit mask from a list of integers (gotten from user selection) and returns an integer of that binary decimal value. Here is my assembled code for the building of the bitmask.</p>

<pre><code>//optsNum is my integer list. This is the list containing the ID nums of the selections.
//so if the user selects the first, second, and fourth option, the list contains 1,2,4 (count 3)
//typeCount is an integer of the amount of options in the list box
int total = 0;
for (int c = 0; c &lt; optsNum.Count(); ++c)
{
    for (int i = 0; i &lt;= typeCount; i++)
    {
        if ((i + 1) == optsNum[c})
            total += (1 &lt;&lt; i);
    }
}
return total;
</code></pre>

<p>So if the first, second, and fourth are set, my integer is 11. This works, I tested for all selections and it is returning the correct integer/decimal value. </p>

<p>Right now I need help making my set method. This needs to take the decimal/integer that I have, find out which bits are set and place those back into the list. So if I have 11 as my value, I need to put into a list of integers 1,2,4. Can anybody help me?</p>
","<p>You should use the <a href=""http://msdn.microsoft.com/en-us/library/system.collections.bitarray.aspx"" rel=""nofollow""><code>BitArray</code> class</a> instead; it does the bitwise operations for you and has a simple interface.<br>
If you will never need more than 32 booleans, you can also use the <a href=""http://msdn.microsoft.com/en-us/library/system.collections.specialized.bitvector32.aspx"" rel=""nofollow""><code>BitVector32</code> class</a>, which is smaller.</p>

<hr>

<p>To answer your question, you need to loop over every bit (using a simple a <code>for</code> loop) and check <code>value &amp; (1 &lt;&lt; i)</code> to see whether the <code>i</code>th bit is set.</p>
","4268433"
"Interview: Adding two binary numbers given as strings","4051","","<p>While looking through some interview questions at <a href=""http://www.glassdoor.com/Interview/Facebook-Interview-Questions-E40772.htm"" rel=""nofollow"">http://www.glassdoor.com/Interview/Facebook-Interview-Questions-E40772.htm</a> I came across the following question:</p>

<blockquote>
  <p>Given two string representations of binary numbers (e.g. ""1001"", ""10"") write a function that adds them and returns the result as a string as well (e.g. ""1011"").</p>
</blockquote>

<p>Here's some Python code that I started to write for the problem (it is incomplete right now), but I am not very sure if this is the best (or even correct) approach. I also thought about implementing the same in C++ first, but gave up considering the added complexities in string manipulations.</p>

<pre><code>def add_binary(a,b):
    temp = """"
    carry = false
    //i from len(a) to 1 and j from len(b) to 1
    bit_sum = add_bit ((a[i],b[j])
    if (bit_sum == ""10""):
            temp.append(""0"")
            carry = true
    elif carry:
            temp.append(add_bit(""1"",bit_sum))
    else:
            temp.append(bit_sum)

    return temp.reverse()


def add_bit(b1, b2):
    if b1 == '0':
            return b2
    elif b2 == '0':
            return b1
    elif (b1 = '1' and b2 =='1'):
            return ""10""
    else return None

a = ""1001""
b = ""10""
add_binary(a,b)
</code></pre>
","<p>First, if the strings are short enough (less than 64 bits), I'd
probably just convert them to an internal integral type
(<code>unsigned long long</code>), do the addition there, and then
reconvert the results.  Converting between binary strings and
internal format is really, really trivial.</p>

<p>Otherwise, I'd probably first normallize them so that they have
the maximum length of the results.  Something like:</p>

<pre><code>size_t size = std::max( lhs.size(), rhs.size() ) + 1;
lhs.insert( lhs.begin(), size - lhs.size(), '0' );
rhs.insert( rhs.begin(), size - rhs.size(), '0' );
</code></pre>

<p>I'd also create a results string of this size: </p>

<pre><code>std::string results( size, '0' );
</code></pre>

<p>And a carry variable, initialized to '0':</p>

<pre><code>char carry = '0';
</code></pre>

<p>I'd then loop over the three strings, using reverse iterators,
or more likely, just an index (which will ensure accessing the
same element of each string):</p>

<pre><code>size_t current = size;
while ( current != 0 ) {
    -- current;
    //  ...
}
</code></pre>

<p>With in the loop, you really only have four possibilities: I'd
just count the '1's (in <code>lhs[current]</code>, <code>rhs[current]</code> and
<code>carry</code>), and do a switch on the results, setting
<code>results[current]</code> and <code>carry</code> appropriately:</p>

<pre><code>int onesCount = 0;
if ( carry == '1' ) {
    ++ onesCount;
}
if ( lhs[current] == '1' ) {
    ++ onesCount;
}
if ( rhs[current] == '1' ) {
    ++ onesCount;
}
swith ( onesCount ) {
case 0:
    carry = '0';
    results[current] = '0';
    break;

case 1:
    carry = '0';
    results[current] = '1';
    break;

case 2:
    carry = '1';
    results[current] = '0';
    break;

case 3:
    carry = '1';
    results[current] = '1';
    break;
}
</code></pre>

<p>Personally, I think this is the simplest and the cleanest
solution, albeit a bit verbose.  Alternatively, you can replace
the switch with something like:</p>

<pre><code>results[current] = onesCount % 2 == 0 ? '0' : '1';
carry = onesCount &lt; 2 ? '0' : '1';
</code></pre>

<p>Finally, if desired, you can suppress any leading zeros in the
results (there will be at most one), and maybe assert that
<code>carry == '0'</code> (because if it isn't, we've screwed up our
calculation of the size).</p>
","16189296"
"The binary equivalent of the decimal number 104","4034","","<p>Ok,so I know that the binary equivalent of 104 is 1101000.</p>

<p>10=1010</p>

<p>4=0100</p>

<p>so , 104=1101000 (how to get this??how these both mix together and get this binary?)</p>

<p>And from the example <a href=""http://www.dreamfabric.com/sms/hello.html"" rel=""nofollow"">here</a>...</p>

<p>the octets from ""hellohello"" are E8 32 9B FD 46 97 D9 EC 37.</p>

<p><code>This bit is inserted to the left which yields 1 + 1101000 = 11101000 (""E8"").</code></p>

<p>I still understand this part , but how to convert 11101000 to E8?</p>

<p>I'm so sorry for all these noob questions , I just learn it yesterday , I googled and search for a whole day but still not really understand the concept...</p>

<p>Thank you.</p>
","<blockquote>
  <p>Ok,so I know that the binary equivalent of 104 is 1101000.</p>
  
  <p>10=1010<br>
  4=0100</p>
</blockquote>

<p>You can't break apart a number like <code>104</code> into <code>10</code> and <code>4</code> when <a href=""http://en.wikipedia.org/wiki/Base_conversion#Base_conversion"" rel=""noreferrer"">changing bases</a>. You need to look at the number <code>104</code> in its entirety. Start with a table of bit positions and their decimal equivalents:</p>

<pre><code>1            1
2           10
4          100
8         1000
16       10000
32      100000
64     1000000
128   10000000
</code></pre>

<p>Look up the largest decimal number that is still smaller than your <code>input</code> number: <code>104</code> -- it is <code>64</code>. Write that down:</p>

<pre><code>1000000
</code></pre>

<p>Subtract <code>64</code> from <code>104</code>: <code>104-64=40</code>. Repeat the table lookup with <code>40</code> (<code>32</code> in this case), and write down the corresponding bit pattern below the first one -- aligning the lowest-bit on the furthest right:</p>

<pre><code>1000000
 100000
</code></pre>

<p>Repeat with <code>40-32=8</code>:</p>

<pre><code>1000000
 100000
   1000
</code></pre>

<p>Since there's nothing left over after the <code>8</code>, you're finished here. Sum those three numbers:</p>

<pre><code>1101000
</code></pre>

<p>That's the binary representation of <code>104</code>.</p>

<p>To convert <code>1101000</code> into hexadecimal we can use a little trick, very similar to your attempt to use <code>10</code> and <code>4</code>, to build the hex version from the binary version without much work -- look at groups of four bits at a time. This trick works because four bits of base <code>2</code> representation <em>completely</em> represent the range of options of base <code>16</code> representations:</p>

<pre><code>Bin  Dec  Hex
0000 0    0
0001 1    1
0010 2    2
0011 3    3
0100 4    4
0101 5    5
0110 6    6
0111 7    7
1000 8    8
1001 9    9
1010 10   A
1011 11   B
1100 12   C
1101 13   D
1110 14   E
1111 15   F
</code></pre>

<p>The first group of four bits, (insert enough leading <code>0</code> to pad it to four
bits) <code>0110</code> is <code>6</code> decimal, <code>6</code> hex; the second group of four bits, <code>1000</code> is
<code>8</code> decimal, <code>8</code> hexadecimal, so <code>0x68</code> is the hex representation of <code>104</code>.</p>
","8110464"
"two's complement, why the name ""two""","4034","","<p>i know unsigned,two's complement, ones' complement and sign magnitude, and the difference between these, but what i'm curious about is:</p>

<ol>
<li>why it's called two's(or ones') complement, so is there a more generalize N's complement?</li>
<li>in which way did these genius deduce such a natural way to represent negative numbers?</li>
</ol>
","<p>Two's complement came about when someone realized that 'going negative' by subtracting <code>1</code> from <code>0</code> and letting the bits rollunder actually made signed arithmetic simpler because no special checks have to be done to check if the number is negative or not. Other solutions give you a discontinuity between <code>-1</code> and <code>0</code>. The only oddity with two's complement is that you get one more negative number in your range than you have positive numbers. But, then, other solutions give you strange things like <code>+0</code> and <code>-0</code>. </p>

<p>According to Wikipedia, the name itself comes from mathematics and is based on ways of making subtraction simpler when you have limited number places. The system is actually a ""radix complement"" and since binary is base two, this becomes ""two's complement"". And it turns out that ""one's complement"" is named for the ""diminished radix complement"", which is the radix minus one. If you look at this for decimal, the meanings behind the names makes more sense.</p>

<p><a href=""http://en.wikipedia.org/wiki/Method_of_complements"" rel=""noreferrer"">Method of Complements (Wikipedia)</a></p>
","2604352"
"MinimumOSVersionn info.plist key? Itunes Connect invalid binary","4020","","<p>I'm trying to submit an app with these details:</p>

<p>Base SDK: iPhone Device 3.2</p>

<p>Architectures: Standard (armv6 armv7)</p>

<p>Target Device Family: iPhone/iPad</p>

<p>iPhone OS Deployment Target: iPhone OS 2.2.1</p>

<p>when I submit to Itunes Connect, I get an invalid binary with this followup:</p>

<p>""Invalid Binary Architecture - iOS 3.0 introduces support for multiple binary architectures. If your binary is built for multiple architectures, your Info.plist must have a MinimumOSVersion key with a value of at least 3.0. Additionally, in order to support existing devices, all iOS 3.0 binaries submitted for distribution through iTunes must contain at least an armv6 binary; ""thin"" armv7-only binaries will not be accepted unless the armv7 required device capability is also present in the Info.plist UIRequiredDeviceCapabilities key.""</p>

<p>So I just add this in the info.plist? But I want to support 2.2.1, why is the lowest acceptable value 3.0?</p>

<p>Thanks.</p>
","<p>Apple no longer accepts any apps below 3.0 for target deployment.  </p>

<blockquote>
  <p>All new applications and updates to existing applications submitted to the App Store must be built with iPhone SDK 4. iTunes Connect will no longer accept app submissions targeting iOS 2.x. These changes do not affect existing apps on the App Store. </p>
</blockquote>
","3373578"
"non-numeric argument to binary operator","4008","","<p>I have a data frame T that is a mixture of numeric and string:</p>

<pre><code> T1&lt;-c(1,2, 3,4,6)
 T2&lt;-c(4,5, 5,7,8)
 T3&lt;-c(""a"",""b"",""c"",""d"",""e"")
 T4&lt;-c(4,5, 5,7,8)
 T5&lt;-c(4,5, 5,7,8)
 T&lt;-data.frame(T1,T2,T3,T4,T5)
</code></pre>

<p>When I apply function to the numeric value of each row using follwong code:</p>

<pre><code>  P=apply(T,1,FUN=function(x) ifelse(x[1]&gt;=x[4]+2*x[5],1,0))
</code></pre>

<p>It always give error message ""Error in 2 * x[5] : non-numeric argument to binary operator"". But if I replace T3 with all numeric values, it works perfectly.</p>

<p>I am puzzled by this and wondering anyone has any insight?</p>

<p>thanks!</p>
","<p>You get coercion of each row to character because T3 is included in what is passed from your dataframe to the function by <code>apply</code>. You could fix this with:</p>

<pre><code>P=apply(T[-3],1,FUN=function(x) ifelse(x[1]&gt;=x[3]+2*x[4],1,0))
</code></pre>

<p>The error is not from the comparison but rather from the attempt to multiply a character value by a numeric. It also might have succeeded with:</p>

<pre><code>P=apply(T,1,FUN=function(x) ifelse(as.numeric(x[1])&gt;= as.numeric(x[4])+ 
                                                  2*as.numeric(x[5])
                                   ,1,0))
</code></pre>

<p>But this is ""just wrong"". The use of <code>apply</code> is appropriate for matrices where all  modes of the columns are the same, but it is generally slower than vectorized functions like <code>ifelse</code> which offer row-wise processing without resorting to <code>apply</code>. Should be:</p>

<pre><code>P=with(T,  ifelse(T1 &gt;= T4 +  2*T5, 1,0) )
</code></pre>

<p>Or just use Boolean arithmetic and convert back to numeric 0/1:</p>

<pre><code>P=  with(T, as.numeric( T1 &gt;= T4 +  2*T5 ) ) # @akrun gets the check
</code></pre>
","26744076"
"How do I extract the width and height of a PNG from looking at the header in objective c?","4007","","<p>I have a need to find the dimensions of images online without downloading them. To accomplish this I do this:</p>

<pre><code>+ (CGSize) getImageDimensions:(NSString *)url {

   // Send a synchronous request
    NSMutableURLRequest * urlRequest = [NSMutableURLRequest requestWithURL:[NSURL URLWithString: url]];
    NSString *rangeString = [url hasSuffix: @""png""] ? @""bytes=0-100"" : @""bytes=0-1300"";
    [urlRequest setValue:rangeString forHTTPHeaderField:@""Range""];
    NSURLResponse * response = nil;
    NSError * error = nil;
    NSData * data = [NSURLConnection sendSynchronousRequest:urlRequest
                                          returningResponse:&amp;response
                                                      error:&amp;error];
    if (error == nil)
        return [UIImage imageWithData: data].size;
    else
        return CGSizeMake(0, 0);

}
</code></pre>

<p>This (downloading the first 100 bytes) surprisingly works and I get the correct dimensions for PNGs this way.</p>

<p>However I do not think this is a very elegant approach. First, I chose to download the first 100 bytes by just guess and checking, making it as small as possible whilst still having it work okay.</p>

<p>Apparently in a PNG file there's this thing called a IHDR in the header and I have to find it and directly after it are the width and height. This gives me the impression that I should loop over the data and find this IHDR and get the dimensions. The problem is, when I NSLog the data I get something like this:</p>

<pre><code>... 49484452 000003b7 000001a7 08060000 006c2da0 b100000a 41694343 50494343 2050726f 66696c65 ...
</code></pre>

<p>I have no idea how to handle looping over my NSData object and detecting the IHDR token and then converting the things that come after it to numbers. I also have no idea if requesting just 100 bytes for a PNG is requesting too much just to get the dimensions, or if it's requesting not enough</p>
","<h2>Rationale</h2>

<p>According to the <a href=""http://www.libpng.org/pub/png/spec/1.2/png-1.2.pdf"">PNG specification</a>:</p>

<blockquote>
  <p>The ﬁrst <strong>eight</strong> bytes of a PNG ﬁle always contain the following
  (decimal) values: 137 80 78 71 13 10 26 10</p>
</blockquote>

<p>So you have to read those to make sure you really have a PNG file.</p>

<p>Then,</p>

<blockquote>
  <p>The IHDR chunk must appear FIRST. It contains:</p>
  
  <p>Width: 4 bytes</p>
  
  <p>Height: 4 bytes</p>
  
  <p>etc...</p>
</blockquote>

<p>So according to the structure of chunks, you first have to read the <strong>four</strong> bytes representing the length of the chunk's data field, then the <strong>four</strong> bytes representing the chunk's name, then the two 32-bit integers representing width and height, <strong>eight</strong> bytes in total.</p>

<p>So, the exact minimal number of bytes you must read in order to determine width and height is 8 + 4 + 4 + 8 = <strong>24 bytes</strong>.</p>

<h2>Objective-C code</h2>

<p>Once you have your NSData object, you simply have to access the bytes that it contains:</p>

<pre><code>unsigned char buffer[24];
[data getBytes:buffer length:24];
</code></pre>

<p>Optionally, but I recommend it strongly, check that you indeed have a PNG file:</p>

<pre><code>unsigned char png_header[] = {137, 80, 78, 71, 13, 10, 26, 10};
if (memcmp(buffer, png_header, 8)) {
     // this is not a PNG !
}
</code></pre>

<p>Make sure you have an IHDR:</p>

<pre><code>unsigned char ihdr_name[] = ""IHDR"";
if (memcmp(buffer+8+4, ihdr_name, 4)) {
    // not an IHDR chunk, invalid PNG file
}
</code></pre>

<p>Width and height can be accessed as <strong>big-endian</strong> encoded unsigned ints at offset 24 minus 8 and minus 4 bytes respectively:</p>

<pre><code>unsigned int width = OSReadBigInt32(buffer + 24 - 8);
unsigned int height = OSReadBigInt32(buffer + 24 - 4);
</code></pre>

<p><strong>Edit</strong>: Fixed buffer reading code: PNG actually stores integers in big-endian.</p>
","16725066"
"Simple bitwise manipulation for little-endian integer, in big-endian machine?","4002","","<p>For a specific need I am building a four byte integer out of four one byte chars, using nothing too special (on my little endian platform):</p>

<pre><code>    return (( v1 &lt;&lt; 24) | (v2 &lt;&lt; 16) | (v3 &lt;&lt; 8) | v4);
</code></pre>

<p>I am aware that an integer stored in a big endian machine would look like <code>AB BC CD DE</code> instead of <code>DE CD BC AB</code> of little endianness, although would it affect the my operation completely in that I will be shifting incorrectly, or will it just cause a correct result that is stored in reverse and needs to be reversed?</p>

<p>I was wondering whether to create a second version of this function to do (yet unknown) bit manipulation for a big-endian machine, or possibly to use ntonl related function which I am unclear of how that would know if my number is in correct order or not.</p>

<p>What would be your suggestion to ensure compatibility, keeping in mind I do need to form integers in this manner?</p>
","<p>As long as you are working at the <em>value</em> level, there will be absolutely no difference in the results you obtain regardless of whether your machine is little-endian or big-endian. I.e. as long as you are using language-level operators (like <code>|</code> and <code>&lt;&lt;</code> in your example), you will get exactly the same arithmetical result from the above expression on any platform. The endianness of the machine is not detectable and not visible at this level. </p>

<p>The only situations when you need to care about endianness is when the data you are working with is examined at the <em>object representation</em> level, i.e. in situations when its raw memory representation is important. What you said above about ""<code>AB BC CD DE</code> instead of <code>DE CD BC AB</code>"" is specifically about the raw memory layout of the data. That's what functions like <code>ntonl</code> do: they convert one memory layout to another memory layout. So far you gave no indication that the actual raw memory layout is in any way important to you. Is it?</p>

<p>Again, if you only care about the <em>value</em> of the above expression, it is fully and totally endianness-independent. Basically, you are not supposed to care about endianness at all when you write C programs that don't attempt to access and examine the raw memory contents.</p>
","5643008"
"Detection of Negative Binary","4000","","<p>Today in class my Computing teacher was explaining to us (or attempting to explain) how to write a negative binary number using Two's Complement. My question is this:</p>

<p>How does the end user determine the difference between 11101100 being 236 and -20? I know you can always check the most significant bit but is this always 100% accurate? Is it a convention of negative binary numbers to have the most significant bit indicate the sign?</p>

<p><em>Side note</em>:<br>
Why do we learn binary subtraction when we can just do:</p>

<blockquote>
  <p>Convert binary to denary -> subtract denary -> reconvert into binary</p>
</blockquote>
","<h2>Question 1:</h2>

<blockquote>
  <p>""Is it a convention of negative binary numbers to have the most significant bit indicate the sign?""</p>
</blockquote>

<p>There are multiple ways to represent negative numbers in binary. The most common is the two's-complement representation that you're learning about. In that system, yes, the highest-order bit will indicate the sign of the number (if 0 is grouped with the positive numbers).</p>

<p>In standard unsigned binary, numbers are represented by sequences of bits in positional notation (for brevity I'll only be using three bits):</p>

<blockquote>
  <p>b<sub>2</sub>b<sub>1</sub>b<sub>0</sub> = 2<sup>2</sup>b<sub>2</sub> + 2<sup>1</sup>b<sub>1</sub> + 2<sup>0</sup>b<sub>0</sub> = 4b<sub>2</sub> + 2b<sub>1</sub> + b<sub>0</sub>  </p>
  
  <p>111<sub>2</sub> = 7<sub>10</sub><br>
  110<sub>2</sub> = 6<sub>10</sub><br>
  101<sub>2</sub> = 5<sub>10</sub><br>
  100<sub>2</sub> = 4<sub>10</sub><br>
  011<sub>2</sub> = 3<sub>10</sub><br>
  010<sub>2</sub> = 2<sub>10</sub><br>
  001<sub>2</sub> = 1<sub>10</sub><br>
  000<sub>2</sub> = 0<sub>10</sub>  </p>
</blockquote>

<p><em><strong>Two's-complement</em></strong><br>
There are several ways to look at 2s-complement, I think the answer is apparent in all of them. One way to get this system is to take the top half of the unsigned numbers (which all have the high bit set) and move them below zero:</p>

<blockquote>
  <p>011<sub>2</sub> = 3<sub>10</sub><br>
  010<sub>2</sub> = 2<sub>10</sub><br>
  001<sub>2</sub> = 1<sub>10</sub><br>
  000<sub>2</sub> = 0<sub>10</sub><br>
  <strong>111<sub>2</sub> = -1<sub>10</sub><br>
  110<sub>2</sub> = -2<sub>10</sub><br>
  101<sub>2</sub> = -3<sub>10</sub><br>
  100<sub>2</sub> = -4<sub>10</sub></strong>  </p>
</blockquote>

<p>You can clearly see that the high bit indicates the sign. Again, 0 takes up one of the 4 positive representations, which leads to the range not being symmetric: [3, -4] (though sometimes the most negative value is considered special, making the <em>usable</em> range symmetric). Equivalently, we can reinterpret the highest-order bit as a negative number:</p>

<blockquote>
  <p>b<sub>2</sub>b<sub>1</sub>b<sub>0</sub> = <strong>-(2<sup>2</sup>)</strong> b<sub>2</sub> + 2<sup>1</sup>b<sub>1</sub> + 2<sup>0</sup>b<sub>0</sub> = <strong>-4</strong> b<sub>2</sub> + 2b<sub>1</sub> + b<sub>0</sub>  </p>
</blockquote>

<p>Clearly, since the high bit has a bigger weight (in the sense of absolute value) than all the other bits combined, if it's set, the result is negative. If it's not set, all the remaining weights are positive and hence so is the result.</p>

<p>From this definition, we can derive the third interpretation: the commonly known rule that <code>-a = ~a + 1</code> (where <code>-</code> means arithmetic negation, <code>~</code> means bitwise complementation, and we ignore overflow):</p>

<blockquote>
  <p>a + ~a = -4b<sub>2</sub> + 2b<sub>1</sub> + b<sub>0</sub> + -4(~b<sub>2</sub>) + 2(~b<sub>1</sub>) + ~b<sub>0</sub><br>
  a + ~a = -4(b<sub>2</sub>+~b<sub>2</sub>) + 2(b<sub>1</sub>+~b<sub>1</sub>) + (b<sub>0</sub>+~b<sub>0</sub>)<br>
  a + ~a = -4(1) + 2(1) + (1)<br>
  a + ~a = -1<br>
  a = -(~a + 1)<br>
  <strong>-a = ~a + 1</strong>  </p>
</blockquote>

<p>Here, we see that negation flips the high bit, so it indicates the sign of the number. Note that this is not <em>strictly</em> true, as the addition with one can flip the high bit back if all the other bits are set. However, this is only the case for 0 and the most negative number (-4<sub>10</sub>, or 100<sub>2</sub>, in this case), both of which remain the same when negated. </p>

<p>The benefit in using 2s-complement is that the same hardware can be used to do signed and unsigned addition. This nice property does not hold for the other negative binary representations that have been used in the past, some of which I'll touch on briefly. Due to this fact, modern CPUs almost always use this representation for integer arithmetic (I'm not aware of any recent commercial counterexamples, but they may be out there). This is why you are learning about it (as opposed to <code>Convert binary to denary -&gt; subtract denary -&gt; reconvert into binary</code>): to understand how operations work at the gate level of an ALU.</p>

<p><em><strong>One's-complement</em></strong><br>
1s-complement is closely related to 2s-complement. Negation is performed by inverting the bits only (no addition of 1). The leading bit still indicates sign, but there are different representations for positive and negative zero. I've never personally come across a real-world use of 1s-complement, but it's of historical interest.</p>

<blockquote>
  <p>b<sub>2</sub>b<sub>1</sub>b<sub>0</sub> = -3b<sub>2</sub> + 2b<sub>1</sub> + b<sub>0</sub>  </p>
  
  <p>011<sub>2</sub> = 3<sub>10</sub><br>
  010<sub>2</sub> = 2<sub>10</sub><br>
  001<sub>2</sub> = 1<sub>10</sub><br>
  000<sub>2</sub> = 0<sub>10</sub><br>
  111<sub>2</sub> = -0<sub>10</sub><br>
  110<sub>2</sub> = -1<sub>10</sub><br>
  101<sub>2</sub> = -2<sub>10</sub><br>
  100<sub>2</sub> = -3<sub>10</sub>  </p>
</blockquote>

<p><em><strong>Sign-and-magnitude</em></strong><br>
Sign-and-magnitude is closest to how humans normally write negative numbers. The low two bits have the same weight as in the systems above and the high bit has no (additive) weight. Instead, it <em>only</em> changes the sign of the result. Here, obviously, the leading bit indicates sign. Like 1s-complement, there are two representations of 0. It is still used today in the mantissa of IEEE floating point numbers (although the exponent sits between the sign and the magnitude).</p>

<blockquote>
  <p>b<sub>2</sub>b<sub>1</sub>b<sub>0</sub> = <strong>(-1)<sup>b<sub>2</sub></sup></strong>(2b<sub>1</sub> + b<sub>0</sub>)  </p>
  
  <p>0 11 <sub>2</sub> = + 3 <sub>10</sub><br>
  0 10 <sub>2</sub> = + 2 <sub>10</sub><br>
  0 01 <sub>2</sub> = + 1 <sub>10</sub><br>
  0 00 <sub>2</sub> = + 0 <sub>10</sub><br>
  1 00 <sub>2</sub> = - 0 <sub>10</sub><br>
  1 01 <sub>2</sub> = - 1 <sub>10</sub><br>
  1 10 <sub>2</sub> = - 2 <sub>10</sub><br>
  1 11 <sub>2</sub> = - 3 <sub>10</sub>  </p>
</blockquote>

<p><em><strong>Excess-n</em></strong><br>
Excess-n is really more like a family of systems. All values are shifted up by n (known as the <em>bias</em>) and then represented as in the unsigned case. The leading bit <em>may</em> indicate the sign if the right bias is chosen, though with different polarity than the above systems (and 0 could be grouped with either the negatives or the positives). This is still used in the exponent of IEEE floating point numbers. For n = 3, the high bit does indicate sign and 0 is grouped with the negative numbers:</p>

<blockquote>
  <p>b<sub>2</sub>b<sub>1</sub>b<sub>0</sub> = 4b<sub>2</sub> + 2b<sub>1</sub> + b<sub>0</sub> <strong>- n</strong></p>
  
  <p>111<sub>2</sub> = 4<sub>10</sub><br>
  110<sub>2</sub> = 3<sub>10</sub><br>
  101<sub>2</sub> = 2<sub>10</sub><br>
  100<sub>2</sub> = 1<sub>10</sub><br>
  011<sub>2</sub> = 0<sub>10</sub><br>
  010<sub>2</sub> = -1<sub>10</sub><br>
  001<sub>2</sub> = -2<sub>10</sub><br>
  000<sub>2</sub> = -3<sub>10</sub>  </p>
</blockquote>

<p><em><strong>Others</em></strong><br>
There are yet other, more esoteric, integer representations such as balanced-ternary, base-negative-2, or (arguably) binary coded decimal (or BCD for short). The reason I say BCD is arguable is that modern processors often still have support for it (though it's not how numbers are represented internally) and many calculators used to be based on it. In these systems, the leading bit (or trit, or base-n digit) may or may not indicate the sign (or may indicate it in some cases but not others).</p>

<h2>Question 2:</h2>

<blockquote>
  <p>""How does the end user determine the difference between 11101100 being 236 and -20?""</p>
</blockquote>

<p>In general there's no way to tell whether a number stored in a register or memory is actually meant to be 2s-complement or unsigned, as pointed out by others. You essentially have to track what's done with it to determine that.</p>

<p>However, if the number is an immediate value stored directly in a machine code instruction, the opcode could indicate whether or not it's signed (depending on the architecture). This may change, for instance, how <em>overflows</em> are handled, or whether or not <em>sign-extension</em> is performed.</p>

<p>For example, there may be separate ""load immediate"" and ""load signed immediate"" instructions that copy an immediate value value into a larger register, the second doing sign-extension and the first not. ""Branch"" instructions often have a signed immediate to indicate the size of the jump (so that both forward and backwards branches can use a single instruction). There may be different ""add immediate"" and ""add unsigned immediate"" instructions that set overflow flags appropriately for the type of addition.</p>

<p><em><strong>Sign extension</em></strong><br>
Sign extension means copying the high bit to preserve the value of a 2s-complement number. This will produce incorrect results for half the unsigned numbers.</p>

<p>Sign extension not performed:  </p>

<blockquote>
  <p>100<sub>2</sub> = 00000100<sub>2</sub><br>
  Unsigned: 4<sub>10</sub> = 4<sub>10</sub><br>
  Signed: -4<sub>10</sub> = 4<sub>10</sub>  </p>
</blockquote>

<p>Sign extension performed:  </p>

<blockquote>
  <p>100<sub>2</sub> = 11111100<sub>2</sub><br>
  Signed: -4<sub>10</sub> = -4<sub>10</sub><br>
  Unsigned: 4<sub>10</sub> = 252<sub>10</sub>  </p>
  
  <p>001<sub>2</sub> = 00000001<sub>2</sub><br>
  Signed and unsigned: 1<sub>10</sub> = 1<sub>10</sub>  </p>
</blockquote>

<p><em><strong>Overflow</em></strong><br>
Adding or subtracting two numbers may give a result that is too big (in an absolute sense) to be correctly represented. Addition of the same two binary sequences may cause overflow for signed numbers but not unsigned (or vice versa).</p>

<p>Signed overflows but unsigned does not:  </p>

<blockquote>
  <p>011<sub>2</sub> + 011<sub>2</sub> = 110<sub>2</sub><br>
  Signed: 3<sub>10</sub>+3<sub>10</sub> = -2<sub>10</sub><br>
  Unsigned: 3<sub>10</sub>+3<sub>10</sub> = 6<sub>10</sub>  </p>
</blockquote>

<p>Unsigned overflows but signed does not:  </p>

<blockquote>
  <p>111<sub>2</sub> + 010<sub>2</sub> = 001<sub>2</sub><br>
  Unsigned: 7<sub>10</sub> + 2<sub>10</sub> = 1<sub>10</sub><br>
  Signed: -1<sub>10</sub> + 2<sub>10</sub> = 1<sub>10</sub>  </p>
</blockquote>
","16625673"
"C++ Binary to Decimal","3996","","<p>So I know there is a way to convert Dec to binary using the bitset library but can you do the same for binary to decimal using the bitset library? or do you have to do it manually? </p>

<pre><code>bitset&lt;8&gt; bin_x(number);
</code></pre>
","<p>You can, but it should be a string.</p>

<pre><code>std::bitset&lt;8&gt; bits(""1111"");
std::cout &lt;&lt; bits.to_ulong() &lt;&lt; std::endl;
</code></pre>

<p>You can convert your integer to string and then pass it to <code>bitset</code> c-tor.</p>

<p><a href=""http://ideone.com/aGg2Rx"" rel=""nofollow"">Live example</a></p>
","19627816"
"Javascript Decimal to Binary - 64 bit","3971","","<p>The binary for the decimal -805306368 is:</p>

<p>11111111111111111111111111111111 11010000000000000000000000000000</p>

<p>However, in Javascript I get the <a href=""http://jsfiddle.net/FjWwf/"" rel=""noreferrer"">following</a>:</p>

<pre><code>   var str = parseInt(-805306368).toString(2);
   document.write(str);
</code></pre>

<p>-110000000000000000000000000000</p>

<p>Can anyone explain how to parse the 64 bit binary string from this decimal?</p>
","<p>JavaScript does not use the two's-complement representation, it uses a <code>-</code> character in front of the string. That's because it does not know how many bits your number range has.</p>

<p>To get the expected result, you could invert each bit:</p>

<pre><code>&gt;&gt;&gt; (~-805306368).toString(2)
""101111111111111111111111111111""
</code></pre>

<p>Yet, javascript does all binary operations on 32-bit integers, so this won't work for bigger (or smaller) numbers and at least will be very confusing. So, you would need to implement your own formatting algorithm.</p>

<pre><code>// example of to 32-bit-conversion:
&gt;&gt;&gt; (~parseInt(""1111111111111111111111111111111"",2)).toString(2)
""-10000000000000000000000000000000""
&gt;&gt;&gt; (~parseInt(""11111111111111111111111111111111"",2)).toString(2)
""0""
</code></pre>

<p>My Implementation:</p>

<pre><code>String.prototype.padleft = function(len, chr){...}

function get64binary(int) {
    if (int&gt;=0)
        return int
          .toString(2)
          .padleft(64, ""0"");
    // else
    return (-int-1)
      .toString(2)
      .replace(/[01]/g, function(d){return +!+d;}) // hehe: inverts each char
      .padleft(64, ""1"");
}
</code></pre>
","10936810"
"How can I XOR these base64'd numbers?","3970","","<p>I have are 5 binary strings base64_encode()'ed</p>

<pre class=""lang-none prettyprint-override""><code>wAD4Af8B/gHuA/4BzgP1A/8P/h//f/xv+z30D9IDSAE=

AAAgCPgf/B/4H/w1+B74Gfg/+B/8P/4f/D/8HwABAAA=

AAAAAMB/wP/A/8B/4HvAf+B/+n/3P/Y//z/4n4CDgAE=

AAAAXcB/wH/Af8B/wHfAP+B/6H/xf+7//r/4f0CngFY=

AAiwifAP+B/4D/gf8B74D/gd8V/4H/gP8B/8vwABAAA=

AAAAAAAA/QD/Af4B/iP+A/wD/A/+//7/+B+AAwAAAAA=
</code></pre>

<p>How can I XOR (<code>^</code>) each of them in pairs and count the 1bits in the result. Sounds like it should be simple but I have no idea how to work with binary in PHP.</p>
","<p>The <a href=""http://www.php.net/manual/en/function.pack.php"" rel=""nofollow noreferrer"">pack</a> and <a href=""http://www.php.net/manual/en/function.unpack.php"" rel=""nofollow noreferrer"">unpack</a> functions are the ones you want to look at. They allow conversion to and from binary strings.</p>

<p>Of course you will also have to use the base 64 decoding function and the <a href=""http://www.php.net/manual/en/language.operators.bitwise.php"" rel=""nofollow noreferrer"">bitwise functions</a></p>
","1548740"
"shc on Mac showing 'Killed: 9' error","3968","","<p>I'm using <a href=""http://www.datsi.fi.upm.es/~frosal/sources/"" rel=""nofollow"">shc</a> on Mac OS, to generate stripped binary of bash scripts, for distribution. The issue is, when i execute the stripped binary (with <code>.x</code> ext) it shows the error <code>killed: 9</code>.</p>

<p>Even when i <code>make</code> and <code>make test</code> (as shown <a href=""http://www.thegeekstuff.com/2012/05/encrypt-bash-shell-script/"" rel=""nofollow"">here</a>), it strips the dummy match script and generates match.x, which when executed, gives the same <code>killed: 9</code> error.</p>

<p>Any help would be appreciated.</p>
","<p>Got it working. Just had to do</p>

<pre><code>shc -T -f test.sh
</code></pre>

<p>I was trying it without the <code>-T</code></p>
","16441630"
"How do I print out an unsigned int in binary in C++?","3961","","<p>I am trying to print out an unsigned value in binary in C++. I have found many hacks for this task such as</p>

<p><a href=""http://www.java2s.com/Tutorial/Cpp/0040__Data-Types/Printinganunsignedintegerinbits.htm"" rel=""nofollow"">http://www.java2s.com/Tutorial/Cpp/0040__Data-Types/Printinganunsignedintegerinbits.htm</a></p>

<p>However, I feel that there should be a much more straightforward way, perhaps with <code>sprintf</code>. After all, there are very straightforward ways to print a value in hex or octal.</p>
","<p>Simple - Use STL <a href=""http://www.cplusplus.com/reference/bitset/bitset/bitset/"" rel=""noreferrer"">bitset</a>:</p>

<p>e.g.</p>

<pre><code>bitset&lt;10&gt; n (120ul); // 10 bits in this case
cout &lt;&lt; n.to_string() &lt;&lt; endl;
</code></pre>
","15319185"
"Converting from hexadecimal to binary values","3958","","<p>Am converting a value from hexadecimal to binary value.I used bin() of python like this:</p>

<pre><code>value = 05808080
print bin(int(value, 16))

output i got is 0b101100000001000000010000000(output should be 32 bit)
output should be 0000 0101 1000 0000 1000 0000 1000 0000(correct output)
</code></pre>

<p>What is this 'b' in the output and how can i replace it with correct binary values.I think two values up here is almost same except issue with ""b"" in output.How will i resolve this ?</p>
","<p>The output you get is correct, it just needs to be formatted a bit. The leading <code>0b</code> indicates that it is a binary number, similarly to how <code>0x</code> stands for hexadecimal and <code>0</code> for octal.</p>

<p>First, slice away the <code>0b</code> with <code>[2:]</code> and use <code>zfill</code> to add leading zeros:</p>

<pre><code>&gt;&gt;&gt; value = '05808080'
&gt;&gt;&gt; b = bin(int(value, 16))
&gt;&gt;&gt; b[2:]
'101100000001000000010000000'
&gt;&gt;&gt; b[2:].zfill(32)
'00000101100000001000000010000000'
</code></pre>

<p>Finally, split the string in intervals of four characters and join those with spaces:</p>

<pre><code>&gt;&gt;&gt; s = b[2:].zfill(32)
&gt;&gt;&gt; ' '.join(s[i:i+4] for i in range(0, 32, 4))
'0000 0101 1000 0000 1000 0000 1000 0000'
</code></pre>

<p>If you can live without those separator spaces, you can also use a <a href=""https://docs.python.org/3/library/string.html#formatstrings"" rel=""nofollow"">format string</a>:</p>

<pre><code>&gt;&gt;&gt; '{:032b}'.format(int(value, 16))
'00000101100000001000000010000000'
</code></pre>
","35573798"
"python struct ""unpack requires a bytes object of length 8"" while converting binay to float","3939","","<p>I'm currently trying to transform binaries into floats and viceversa using the struct module. My function works with certain values, like 2.0 or 14.0, but it doesn't with values like 1.0.</p>

<p>I took the code from another question, and changed it from python2 to python3. </p>

<pre><code>import struct

def bin_to_float(b):
    """""" convert binary string to float """"""
    bf = int_to_bytes(int(b, 2), 8)  # 8 bytes needed for IEEE 754 binary64
    bf = bytes(bf, 'UTF-8')
    print(bf)
    return struct.unpack('&lt;d', bf)[0]

def int_to_bytes(n, minlen):  # helper function
    """""" int/long to byte string """"""
    nbits = n.bit_length() + (1 if n &lt; 0 else 0)  # plus one for any sign bit
    nbytes = (nbits+7)//8  # number of whole bytes
    bytes = []
    for i in range(nbytes):
        bytes.append(chr(n &amp; 0xff))
        n &gt;&gt;= 8   
    # zero pad if needed
    if minlen &gt; 0 and len(bytes) &lt; minlen:
        bytes.extend((minlen-len(bytes)) * '0')
    bytes.reverse()  # put high bytes at beginning
    return ''.join(bytes)

# tests

def float_to_bin(f):
    """""" convert float to binary string """"""
    ba = struct.pack('&gt;d', f)
    s = ''.join('{:08b}'.format(b) for b in ba)
    # strip off leading zeros
    for i in range(len(s)):
        if s[i] != '0':
             break
    else:  # all zeros
        s = '0'
        i = 0
    return s[i:]

import math

floats = [2.0, 1.0, -14.0, 12.546, math.pi]


for f in floats:
    binary = float_to_bin(f)
    print ('float_to_bin(%f): %r' % (f, binary))
    float = bin_to_float(binary)
    print ('bin_to_float(%r): %f' % (binary, float))
    print ()
</code></pre>

<p>The problem seems to be that when I encode the str in bytes, I get 9 bytes instead of 8, but this happens only sometimes. This is the console readings:</p>

<pre><code>float_to_bin(2.000000): '100000000000000000000000000000000000000000000000000000000000000'
b'@\x00\x00\x00\x00\x00\x00\x00'
bin_to_float('100000000000000000000000000000000000000000000000000000000000000'): 0.000000

float_to_bin(1.000000): '11111111110000000000000000000000000000000000000000000000000000'
b'?\xc3\xb0\x00\x00\x00\x00\x00\x00'
Traceback (most recent call last):
  File ""C:/Users/arzuffi pc test/Desktop/prova struct.py"", line 47, in &lt;module&gt;
    float = bin_to_float(binary)
  File ""C:/Users/arzuffi pc test/Desktop/prova struct.py"", line 8, in bin_to_float
    return struct.unpack('&lt;d', bf)[0]
struct.error: unpack requires a bytes object of length 8
</code></pre>

<p>I can't seem to figure out why this happens and how to prevent it from happening :/</p>

<p>Does anybody knows why this is?</p>

<p>Thank you very much in advance.</p>

<p>EDIT: J.J. Hakala answered brilliantly, so I'll post the answer up here:</p>

<pre><code>import struct

def bin_to_float(b):
    """""" convert binary string to float """"""
    return struct.unpack('&lt;d', struct.pack('&lt;Q', int(b, 2)))[0]

def float_to_bin(f):
    """""" convert float to binary string """"""
    return '{:b}'.format(struct.unpack('&lt;Q', struct.pack('&lt;d', f))[0])
</code></pre>

<p>If someone wants to do the same with 32 bits float, this should be good:</p>

<pre><code>import struct

def bin_to_float(b):
    """""" convert binary string to float """"""
    return struct.unpack('&lt;f', struct.pack('&lt;L', int(b, 2)))[0]
def float_to_bin(f):
    """""" convert float to binary string """"""
    return '{:b}'.format(struct.unpack('&lt;L', struct.pack('&lt;f',f))[0])
</code></pre>

<p>Thank you very much everybody!!!</p>
","<p><em>struct.pack</em> / <em>struct.unpack</em> could be used to implement the functions like this</p>

<pre><code>def bin_to_float(b):
    return struct.unpack('&lt;d', struct.pack('&lt;Q', int(b, 2)))[0]

def float_to_bin(f):
    return '{:b}'.format(struct.unpack('&lt;Q', struct.pack('&lt;d', f))[0])
</code></pre>

<p>As for the original question,</p>

<pre><code>bf = bytes(bf, 'UTF-8')
</code></pre>

<p>seems to be the culprit since it may change the length of <em>bf</em>.</p>
","35090957"
"9-bit floating point representations using IEEE floating point format A and B","3937","","<p>I'm having some trouble with a problem I've run into dealing with floating points. I'm having a hard time moving from floating point representation to decimal values and also from format A of the representation to format B of the representation. </p>

<p>The problem:</p>

<p>Consider the following two 9-bit floating-point representations based on the IEEE floating-point format.</p>

<ul>
<li>Format A</li>
</ul>

<p>There is one sign bit.
There are k = 5 exponent bits. The exponent bias is 15.
There are n = 3 fraction bits.</p>

<ul>
<li>Format B</li>
</ul>

<p>There is one sign bit
There are k = 4 exponent bits. The exponent bias is 7.
There are n = 4 faction bits</p>

<p>The problem wants me to convert the floating point representation ""0 10110 011"" from Format A to Format B. It also wants to know the values for each format. Can anyone assist me with the procedure for both of these tasks. Or perhaps direct me to an informative website that would be able to show me. I've been searching for a while now and I'm having trouble finding any resources. Thanks!</p>

<p>-Matt</p>
","<p>010110011 in the 1-5-3 format is sign 0, biased exponent 10110<sub>2</sub>, and encoded significand 011. The sign is +, the unbiased exponent is 22–15 = 7, and the significand is 1.011<sub>2</sub> = 1.375. (We prefixed the encoded significand with “1.”) So the number represented is +2<sup>7</sup>•1.375 = 176.</p>

<p>To encode 176 in the 1-4-4 format, take advantage of the fact that you already know it is +2<sup>7</sup>•1.375. Thus, the sign is +, the unbiased exponent is 7, and the significand is 1.011<sub>2</sub>. This significand fits in four bits (so no rounding is needed); the encoded significand (removing the leading “1.”) is 0110. The unbiased exponent is 7, the bias is 7, so the biased exponent is 14 = 1110<sub>2</sub>. So the bit fields are sign 0, exponent 1110, significand 0110, and all nine bits are 011100110.</p>
","13262081"
"Reading binary data without reinterpret_cast","3929","","<p>Just because I've never read binary files before I wrote a program that reads binary STL files. I use <code>ifstream</code>s read member that takes a char* a parameter. To cast my struct to a char* I use a reinterpret_cast. But as far as I remember every book about C++ I read said something like ""don't use reinterpret_cast except you have to"". What would be a better way read binary data, not necessarily direct, but at last into a struct and without reinterpret_cast?</p>

<p>The main function:</p>

<pre><code>std::ifstream in (cmdline[1].c_str(), std::ios::binary);

in.seekg(80, std::ifstream::beg); //skip header

int numTriangle;
in.read (reinterpret_cast&lt;char*&gt;(&amp;numTriangle), sizeof(int)); //determine number of triangles
//create triangle data type and read data
triangle* t = new triangle();
for (int i = 0; i &lt; numTriangle; ++i)  {
    in.read(reinterpret_cast&lt;char*&gt;(t), triangle::size);
    std::cout &lt;&lt; *t;  // there's an opertor&lt;&lt; for triangle
}
delete t;

in.close(); //close file read from
</code></pre>

<p>And the triangle struct</p>

<pre><code>//attempt to get the right size of a class without structure padding
#pragma pack(push)
#pragma pack(1)

//standard STL triangle data structure
struct triangle {
public:
    float n[3]; //normals, 4*3=12 bytes

    float x[3]; //first point of the triangle, 4*3=12 bytes
    float y[3]; //second point of the triangle, 4*3=12 bytes
    float z[3]; //third point of the triangle, 4*3=12 bytes

    long int a; //attributes, 2 bytes

    static const int size = 12+12+12+12+2; //sum of member variables
    //static const int size = sizeof(n) + sizeof(x) + sizeof(y) + sizeof(z) + sizeof(a);
};
#pragma pack(pop)
</code></pre>

<p>(Extra question: #pragma pack(1) doesn't work with cygwins g++-4. How can I determine the size of the struct?)</p>
","<p>Well, that code looks fine. You are even caring about the padding issue. I don't see how you can avoid casting here. You can do this sequence:</p>

<pre><code>static_cast&lt;char*&gt;(static_cast&lt;void*&gt;(t))
</code></pre>

<p>But really, i don't do that in my code. It's just a more noisy way of doing a direct reinterpret_cast to <code>char*</code>. (See <a href=""https://stackoverflow.com/questions/1863069/casting-via-void-instead-of-using-reinterpret-cast"">casting via void* instead of using reinterpret_cast</a> ).</p>

<hr>

<p>The struct size can be determined using <code>sizeof</code>. You just have to initialize the <code>static</code> member out of the class inside the <code>.cpp</code> (however, then the compiler doesn't know the value of <code>::size</code> anymore and can't inline it).<br>
Alternatively, you can write it as a static inline member function. In its body, the class type is considered complete and <code>sizeof (triangle)</code> is allowed. Or you can just use <code>sizeof</code> like you have in the comment, but use the type and not the members (referring to nonstatic members that way is allowed only in C++0x) :</p>

<pre><code>//standard STL triangle data structure
struct triangle {
public:
    float n[3]; //normals, 4*3=12 bytes

    float x[3]; //first point of the triangle, 4*3=12 bytes
    float y[3]; //second point of the triangle, 4*3=12 bytes
    float z[3]; //third point of the triangle, 4*3=12 bytes

    long int a; //attributes, 2 bytes

    static int size() { return sizeof(triangle); } // this way
    static const int size = sizeof(float[3])*4 + sizeof(long int); // or this way
};
</code></pre>

<p>However, the second way is not nice since you can easily forget updating it when you add a member. </p>
","2356686"
"Why does -INT_MIN = INT_MIN in a signed, two's complement representation?","3928","","<p>I still haven't found a reason why the lowest signed negative number doesn't have an equivalent signed positive number?
I mean in a 3 digit binary number for simplicity
100 is -4? but we can't have a positive 4 in signed format because we can't. It overflows. 
So how do we know two's complement 1000 is -4 1000 0000 is  -128 and so on? We have no original positive number</p>
","<p>One way to think about it is that signed, two's complement format works by assigning each bit a power of two, then flipping the sign of the last power of two.  Let's look at -4, for example, which is represented as 100.  This means that the value is</p>

<pre><code>-1 x 2^2 + 0 x 2^1 + 0 x 2^0
</code></pre>

<p>If we want to get the positive version of this value, we'd have to negate it to get</p>

<pre><code> 1 x 2^2 - 0 x 2^1 - 0 x 2^0
</code></pre>

<p>Notice that this value is equal to</p>

<pre><code> 1 x 2^2 + 0 x 2^1 + 0 x 2^0
</code></pre>

<p>In other words, the normal binary representation of this value is 100.  However, we're in trouble here, because we're using a signed two's complement representation, which means that we have specifically reserved the 4's bit as the sign bit.  Consequently, when we try to interpret the bit pattern 100 as a signed, three-bit, two's complement value, it comes back out identically to what we started with.  The shortage of bits is what's hurting here.</p>

<p>More generally, given n bits, of which the first is the sign bit in a two's complement representation, trying to compute -1000...00 will give back the same value, because the bit needed to store the large positive value has the special meaning assigned to it.</p>

<p>So why do this at all?  The reason for this is that if you have only n bits, you cannot store the values -2<sup>n - 1</sup> through 2<sup>n - 1</sup>, because there are 2<sup>n</sup> + 1 different numbers here and only 2^n different bit patterns.  Excluding the largest positive number thus makes it possible to hold all the different numbers in the bit pattern specified.</p>

<p>But why drop the high value and not the low value?  This is in order to preserve binary compatibility with unsigned integers.  In an unsigned integer, the values 0 through 2<sup>n-1</sup> - 1 are all encoded using the standard base-two representation.  Consequently, for unsigned and signed integers to agree at all, the unsigned integers are designed so that they are bit-for-bit equivalent with the first 2<sup>n - 1</sup> unsigned integers, which range from 0 to 2<sup>n - 1</sup> - 1, inclusive.  After this, the unsigned values need the most significant bit to encode numbers, but the signed values are using this as the sign bit.</p>

<p>Hope this helps!</p>
","8917321"
"Convert floating point number from binary to a decimal number","3915","","<p>I have to convert floating point number from binary to usable decimal number.</p>

<p>Of course my floating point number has been separated into bytes, so 4 bytes total.<br>
1           2           3       4<br>
[xxxxxxxx][xxxxxxxx][xxxxxxxx][xxxxxxxx]</p>

<p>These 4 bytes are already converted to decimal, so I have e.g.<br>
1    2    3    4<br>
[0][10][104][79]</p>

<p>Now Mantissa is held in three parts, two rightmost bytes (3 &amp; 4) and in byte 2 but without the MSB bit (that one is easy to mask out, so let's assume we have a nice decimal number there as well). So three decimal numbers.</p>

<p><strong>Is there an straightforward mathematical conversion to a floating point mantissa for these three decimal numbers?</strong></p>

<p>This is along the lines: if I needed to get an integer, the formula would be<br>
10 * 65536 + 104 * 256 + 79.</p>
","<p>Call these bytes <code>a</code>, <code>b</code>, and <code>c</code>. I assume <code>a</code> has already been masked, so it contains only the bits of the significand and none of the exponent, and that the number is IEEE-754 32-bit binary floating-point, with bytes taken with the appropriate endianness.</p>

<p>If the raw exponent field is 1 to 254 (thus, not 0 or 255), then the significand is:</p>

<pre><code>1 + a*0x1p-7 + b*0x1p-15 + c*0x1p-23
</code></pre>

<p>or, equivalently:</p>

<pre><code>(65536*a + 256*b + c) * 0x1p-23 + 1.
</code></pre>

<p>If the raw exponent field is 0, then remove the 1 from the sum (the number is subnormal or zero). If the raw exponent field is 255, then the floating-point value is infinity (if <code>a</code>, <code>b</code>, and <code>c</code> are all 0) or a NaN (otherwise).</p>
","15393666"
"Reading Binary data from a Serial Port","3915","","<p>I previously have been reading NMEA data from a GPS via a serial port using C#. Now I'm doing something similar, but instead of GPS from a serial. I'm attempting to read a KISS Statement from a TNC. I'm using this event handler. </p>

<pre><code>comport.DataReceived += new SerialDataReceivedEventHandler(port_DataReceived);
</code></pre>

<p>Here is port_DataReceived. </p>

<pre><code>        private void port_DataReceived(object sender, SerialDataReceivedEventArgs e)
    {
        string data = comport.ReadExisting();

        sBuffer = data;

        try
        {
            this.Invoke(new EventHandler(delegate { ProcessBuffer(sBuffer); }));
        }
        catch { }
    }
</code></pre>

<p>The problem I'm having is that the method is being called several times per statement. So the ProcessBuffer method is being called with only a partial statment. How can I read the whole statement? </p>
","<p>Serial communication allows to break data flow into messages by using timeout. But following 
<a href=""http://www.ka9q.net/papers/kiss.html"" rel=""nofollow noreferrer"">KISS TNC</a> there no such functionality is presented in this protocol.</p>

<blockquote>
  <p>Each frame is both preceded and
  followed by a special FEND (Frame End)
  character, analogous to an HDLC flag.
  No CRC or checksum is provided. In
  addition, no RS-232C handshaking
  signals are employed.</p>
</blockquote>

<p>My suggestion is to break data stream into messages by decoding Frame End characters.</p>
","2655717"
"Regular Expression for Binary Numbers Divisible by 5","3902","","<p>I want to write a regular expression for Binary Numbers Divisible by 5.<br>
I have already done the regular expressions for Binary Numbers Divisible by 2 and for 3 but I couldn't find one for 5.</p>

<p>Any suggestions?</p>
","<pre><code>(0|1(10)*(0|11)(01*01|01*00(10)*(0|11))*1)*
</code></pre>

<p>Add <code>^$</code> to test it with regexp. <a href=""http://rubular.com/r/OuGOAfPnYx"" rel=""nofollow noreferrer"">See it working here</a>.
<hr>
You can build a <a href=""https://en.wikipedia.org/wiki/Deterministic_finite_automaton"" rel=""nofollow noreferrer"">DFA</a> and convert it to regular expression. The DFA was already built in <a href=""https://stackoverflow.com/a/22282792/2423164"">another answer</a>. You can read it, it is very well explained.
<hr>
The general idea is to remove nodes, adding edges.
<a href=""https://i.stack.imgur.com/2V7Dk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2V7Dk.png"" alt=""before""></a></p>

<p>Becomes:</p>

<p><a href=""https://i.stack.imgur.com/VCUUD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VCUUD.png"" alt=""after""></a>
<hr>
Using that concept and the FDS from the answer I linked, here are the steps to get the regular expression:
<a href=""https://i.stack.imgur.com/bKV1E.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bKV1E.png"" alt=""step1""></a>
<a href=""https://i.stack.imgur.com/AQYOJ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/AQYOJ.png"" alt=""step2""></a>
<a href=""https://i.stack.imgur.com/hMU3Q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hMU3Q.png"" alt=""step3""></a>
<a href=""https://i.stack.imgur.com/vXaCC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vXaCC.png"" alt=""step4""></a>
<a href=""https://i.stack.imgur.com/E10OP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/E10OP.png"" alt=""step5""></a></p>
","34478786"
"reading double from binary file in c","3899","","<p>can anyone show how to correctly convert binary represented data into double value in C. for example, i have 8 unsigned char values to be converted to double value (let's name it buffer). so buffer[0]'s 0's bit is LSB, and buffer[7]'s 7's bit is MSB. thanks a lot in advance!</p>
","<p>Just cast it, I think</p>

<pre><code>char buf[8];
double x;
...
x = *((double*) buf);
</code></pre>
","3452424"
"convert negative decimal number to binary number","3889","","<p>I tried to convert a <em>negative decimal number</em>  into a <em>binary number</em> and this code perfectly works on my computer, but the code doesn't work another computer.</p>

<p>I didn't get how it is possible. What is wrong in my code?    </p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;math.h&gt;

void decTobin(int dec, int s)
{
    int b[s], i = 0;

     while (dec &gt;= 0 &amp;&amp; i != s - 1) {
         b[i] = dec % 2;
         i++;
         dec /= 2;
     }

     int j = i;

     printf(""%d"", dec);

     for (j = i - 1; j &gt;= 0; j--) {
         if (b[j] == NULL)
             b[j] = 0;

         printf(""%d"",b[j]);
     }
}

void ndecTobin(int dec, int s)
{
    int b[s], i = 0, a[s], decimal, decimalvalue = 0, g;

    while (dec &gt;= 0 &amp;&amp; i != s-1) {
        b[i] = dec % 2;
        i++;
        dec /= 2;
    }

    int j = i;

    printf(""%d"",dec);

    for (j = i - 1; j &gt;= 0; j--) {
        if (b[j] == NULL)
            b[j] = 0;

        printf(""%d"",b[j]);
    }

    printf(""\n"");

    a[s - 1] = dec;

    for (j = s - 2; j &gt;= 0; j--) {
        a[j] = b[j];
    }

    for (j = s - 1; j &gt;= 0; j--) {
        if (a[j] == 0)
            a[j] = 1;
        else
            a[j] = 0;

        printf(""%d"",a[j]);
    }

    for (g = 0; g &lt; s; g++) {
        decimalvalue = pow(2, g) * a[g];
        decimal += decimalvalue;
    }

    decimal = decimal + 1;
    printf(""\n%d\n"", decimal);
    decTobin(decimal, s);
}

int main()
{
    int a, b;

    printf(""enter a number: "");
    scanf("" %d"", &amp;a);
    printf(""enter the base: "");
    scanf(""%d"", &amp;b);

    ndecTobin(a, b);
}
</code></pre>
","<p><code>decimal</code> and <code>int b[s]</code> not initialized.  </p>

<p>By not initializing <code>decimal</code> to 0, it might have the value of 0 on a machine one day and quite different results otherwise.</p>

<pre><code>void decTobin(int dec, int s) {
  //  while loop does not set all `b`,but following for loop uses all `b`
  // int b[s], i = 0;  
  int b[s] = { 0 }; // or int b[s]; memset(b, 0, sizeof b);
  int i = 0; 
}

void ndecTobin(int dec, int s) {
  int b[s], i = 0, a[s], decimal, decimalvalue = 0, g;
  decimal = 0;
  ...
  decimal += decimalvalue;
}
</code></pre>

<hr>

<p>Minor points:</p>

<p>1) <code>if (b[j] == NULL) b[j] = 0;</code> is strange.  <code>NULL</code> is best used as a pointer, yet code is comparing <code>b[j]</code>, an <code>int</code> to a pointer.  Further, since <code>NULL</code> typically has the arithmetic value of 0, code looks like <code>if (b[j] == 0) b[j] = 0;</code>.</p>

<p>2) <code>decTobin()</code> is challenging to follow.  It certainly is only meant for non-negative <code>dec</code> and <code>s</code>.  Candidate simplification:</p>

<pre><code>void decTobin(unsigned number, unsigned width) {
  int digit[width];
  for (unsigned i = width; i-- &gt; 0; ) {
    digit[i] = number % 2;
    number /= 2;
  }

  printf(""%u "", number);  // assume this is for debug

  for (unsigned i = 0; i&lt;width; i++) {
    printf(""%u"", digit[i]);
  }
}
</code></pre>
","27461233"
"How does the CPU interact with the monitor?","3881","","<p>So the question is: How does a computer go from binary code representing the letter ""g"" to the correct combination of pixel illuminations?</p>

<p>Here is what I have managed to figure out so far. I understand how the CPU takes the input generated by the keyboard and stores it in the RAM, and then retrieves it to do operations on using an instruction set. I also understand how it does these operations in detail. Then the CPU transmits the output of an operation which for this example is an instruction set that retrieves the ""g"" from the memory address and sends it to the monitor output.</p>

<p>Now my question is does the CPU convert the letter ""g"" to a bitmap directly or does it use a GPU that is either built-in or separate, OR does the monitor itself handle the conversion?</p>

<p>Also, is it possible to write your own code that interprets the binary and formats it for display?</p>
","<p>In most systems the CPU doesn't speak with the monitor directly; it sends commands to a graphics card which in turn generates an electric signal that the monitor translates into a picture on the screen. There are many steps in this process and the processing model is system dependent.</p>

<p>From the software perspective, communication with the graphics card is made through a graphics card driver that translates your program's and the operating system's requests into something that the hardware on the card can understand. </p>

<p>There are different kinds of drivers; the simplest to explain is a text mode driver. In text mode the screen is composed of a number of cells, each of which can hold exactly one of predefined characters. The driver includes a predefined bit map font that describes how a character looks like by specifying which pixels are on and which are off . When a program requests a character to be printed on the screen, the driver looks it up in the font and tells the card to change the electric signal it's sending to the monitor so that the pixels on the screen reflect what's in the font.</p>

<p>The text mode has limited use though. You get only one choice of font, a limited choice of colors, and you can't draw graphics like lines or circles: you're limited to characters. For high quality graphics output a different driver is used. Graphics cards typically include a memory buffer that contains the contents of the screen in a well defined format, like ""n bits per pixel, m pixels per row, .."" To draw something on the screen you just have to write to this memory buffer. In order to do that the driver maps the buffer into the computer memory so that the operating system and programs can use the buffer as if it was a part of RAM. Programs then can directly put the pixels they want to show, and to put the letter g on the screen it's up to the application programmer to output pixels in a way that resembles that letter. Of course there are many libraries to help programmers do this, otherwise the current state of the graphical user interface would be even sorrier than it is.</p>

<p>Of course, this is a simplification of what actually goes on in a computer, and there are systems that don't work exactly like this, for example some CPUs do have an integrated graphics card, and some output devices are not based on drawing pixels but plotting lines, but I hope this clears the confusion a little.</p>
","18181031"
"C# BinaryFormatter - Deserialize with the object in another namespace","3876","","<p>Recently, we moved a part of our code to different project library.</p>

<p>Unfortunately, it appears that those data have been serialized into the database with a <code>BinaryFormatter</code>(don't ask me why, I don't know and I hate this idea).</p>

<p>Now I'm responsible to create an update tool that update the database(The tool is launched automatically by our software when it detects a database that need updates, based on version):</p>

<ol>
<li>Create new columns</li>
<li>Deserialize the binary column</li>
<li>Write the deserialized columns into the new column</li>
<li>Delete the old binary columns</li>
</ol>

<p>My problem is that when I try to deserialize, it tells me that :</p>

<pre><code>Unable to find assembly 'MyOldAssemblyName, Version=2.0.0.0, Culture=neutral, PublicKeyToken=a5b9cb7043cc16da'.
</code></pre>

<p>But this assembly doesn't exists anymore. I've no issue to put this class in my ""updater"" project, but no way that I can keep this old project only to contains this file.</p>

<p>Is there a way to specify to the BinaryFormatter that it has to deserialize the Stream it receives with a specified class?</p>

<p>Or say that the assembly has been renamed, or ???</p>
","<p>In fact I think I found myself the solution.</p>

<p>We can give a <code>SerializationBinder</code> to the binary formater, which will allows us to resolve manually a class we found in the stream.</p>

<p>More informations <a href=""http://msdn.microsoft.com/en-us/library/system.runtime.serialization.formatters.binary.binaryformatter.binder.aspx"" rel=""nofollow"">here</a> </p>
","19490660"
"Convert base 10 to base 2, C programming","3874","","<p>I'm still new with programming and I'd like to ask about one specific question about the <code>C</code>language. I'm using codeblocks compiler.</p>

<p>Here is a piece of code:</p>

<pre><code>int n, c, k;

scanf(""%d"",&amp;n);

for(c = 31;c &gt;= 0;c--)
{
    k = n &gt;&gt; c;

    if(k &amp; 1)
        printf(""1"");
    else
        printf(""0"");
}

return 0;
</code></pre>

<p>that I got from one website and it converts the base to the binary one.</p>

<p>My question is, where I have an if&amp;else statement, why is there if(k &amp; 1) printf(""1"") ?? I thought that k can be both 1 and 0 and if I use (k &amp; 1) there are two options such as (0 &amp; 1) = 0 and (1 &amp; 1) = 1. Can please anybody explain me this?
 Thank you very much.</p>
","<p>The expression inside of an if statement always evaluates to true or false. In terms of integers, 0 means false, and anything non-zero means true. When you have <code>k &amp; 1</code>, that means that if the least-significant bit of <code>k</code> is 1, then that expression evaluates to 1 and is therefore considered true. If the least-significant bit of <code>k</code> is 0, then the expression evaluates to 0 and is therefore considered to be false.</p>
","24586709"
"Remove or edit entry saved with Python pickle","3874","","<p>I basically do sequences of dump and load, but at some point I want to delete one of the loaded entries. How can I do that? Is there a way to remove, or edit entries saved with Python pickle/cpickle?</p>

<p>Edit: The data is saved with pickle in a binary file.</p>
","<p>To delete a pickled object from a binary file you <em>must</em> rewrite the whole file.
The <code>pickle</code> module doesn't deal with modifications at arbitrary portions of the stream, so there is no built-in way of doing what you want.</p>

<p>Probably the simplest alternative to binary files is to use the <a href=""http://docs.python.org/2/library/shelve.html"" rel=""nofollow""><code>shelve</code></a> module.</p>

<p>This module provides a <code>dict</code> like interface to a database containing the pickled data, as you can see from the example in the documentation:</p>

<pre><code>import shelve

d = shelve.open(filename) # open -- file may get suffix added by low-level
                          # library

d[key] = data   # store data at key (overwrites old data if
                # using an existing key)
data = d[key]   # retrieve a COPY of data at key (raise KeyError if no
                # such key)
del d[key]      # delete data stored at key (raises KeyError
                # if no such key)
flag = key in d        # true if the key exists
klist = list(d.keys()) # a list of all existing keys (slow!)

# as d was opened WITHOUT writeback=True, beware:
d['xx'] = [0, 1, 2]    # this works as expected, but...
d['xx'].append(3)      # *this doesn't!* -- d['xx'] is STILL [0, 1, 2]!

# having opened d without writeback=True, you need to code carefully:
temp = d['xx']      # extracts the copy
temp.append(5)      # mutates the copy
d['xx'] = temp      # stores the copy right back, to persist it

# or, d=shelve.open(filename,writeback=True) would let you just code
# d['xx'].append(5) and have it work as expected, BUT it would also
# consume more memory and make the d.close() operation slower.

d.close()       # close it
</code></pre>

<p>The database used is <code>ndbm</code> or <code>gdbm</code>, depending on the platform and the libraries available.</p>

<p>Note: this works well if the data is not moved to an other platform. If you want to be able to copy the database to an other computer then <code>shelve</code> wont work well, since it does not provide guarantees regarding which library will be used. In this case using an explicit SQL database is probably the best option.</p>
","15115747"
"Writing binary data to middle of a sparse file","3871","","<p>I need to compile a binary file in pieces with pieces arriving in random order (yes, its a P2P project) </p>

<pre><code>def write(filename, offset, data) 
    file.open(filename, ""ab"")
    file.seek(offset) 
    file.write(data) 
    file.close()
</code></pre>

<p>Say I have a 32KB write(f, o, d) at offset 1MB into file and then another 32KB write(f, o, d) at offset 0 </p>

<p>I end up with a file 65KB in length (i.e. the gap consisting of 0s between 32KB - 1MB is truncated/disappears) </p>

<p>I am aware this may appear an incredibly stupid question, but I cannot seem to figure it out from the file.open(..) modes </p>

<p>Advice gratefully received. </p>

<p>*** UPDATE </p>

<p>My method to write P2P pieces ended up as follows (for those who may glean some value from it) </p>

<pre><code>def writePiece(self, filename, pieceindex, bytes, ipsrc, ipdst, ts): 
    file = open(filename,""r+b"")
    if not self.piecemap[ipdst].has_key(pieceindex):
        little = struct.pack('&lt;'+'B'*len(bytes), *bytes) 
        # Seek to offset based on piece index 
        file.seek(pieceindex * self.piecesize)
        file.write(little)
        file.flush()
        self.procLog.info(""Wrote (%d) bytes of piece (%d) to %s"" % (len(bytes), pieceindex, filename))

    # Remember we have this piece now in case duplicates arrive 
    self.piecemap[ipdst][pieceindex] = True
    file.close()
</code></pre>

<p>Note: I also addressed some endian issues using struct.pack which plagued me for a while. </p>

<p>For anyone wondering, the project I am working on is to analyse BT messages captured directly off the wire. </p>
","<pre><code>&gt;&gt;&gt; import os
&gt;&gt;&gt; filename = 'tempfile'
&gt;&gt;&gt; def write(filename,data,offset):
...     try:
...         f = open(filename,'r+b')
...     except IOError:
...         f = open(filename,'wb')
...     f.seek(offset)
...     f.write(data)
...     f.close()
...
&gt;&gt;&gt; write(filename,'1' * (1024*32),1024*1024)
&gt;&gt;&gt; write(filename,'1' * (1024*32),0)
&gt;&gt;&gt; os.path.getsize(filename)
1081344
</code></pre>
","3407648"
"Get string from http://xxxx.com/xx.bin file to create a UIImage on the iPhone","3868","","<p>I have images encoded as base64 stored on my server as .bins. I want to get the string contained in the .bin to create UIImages as explained in <a href=""https://stackoverflow.com/a/1378707/385559"">this post</a>. </p>

<p>How do I get the string from the url of the bin programmatically via the iPhone?</p>
","<p>You could use <a href=""http://allseeing-i.com/ASIHTTPRequest/"" rel=""nofollow"">ASIHTTP</a> wich is a wrapper around NSURLConnection and CFNetwork API, and then you could do something like this:</p>

<pre><code>  NSURL *url = [NSURL URLWithString:@""http://xxxx.com/xx.bin""];
  ASIHTTPRequest *request = [ASIHTTPRequest requestWithURL:url];
  [request startSynchronous];
  NSError *error = [request error];
  if (!error) {
    NSString *response = [request responseString];
  }
</code></pre>

<p>This is a synchronous call, you can also use ASI to do the call asynchronous with delegates, blocks, queues, etc.</p>
","8637635"
"Insert Java byte[] object into an H2 table and then retrieve it again","3866","","<p>I'm trying to insert a Java byte[] into an H2 database table and then retrieve it again, but i am not achieving success. According to <a href=""http://www.h2database.com/html/datatypes.html#binary_type"" rel=""nofollow"">this page</a>, the BINARY data type maps directly to a byte[]. So my understanding is i can write the byte[] variable directly to the column, but it is resulting in an exception when i try to retrieve it again.</p>

<p>Here is a <a href=""http://sscce.org/"" rel=""nofollow"">SSCCE</a> that illustrates my problem. What am i doing wrong here?</p>

<p>PS: You need to have an <a href=""http://www.h2database.com/html/main.html"" rel=""nofollow"">H2 database</a> installed to run this code.</p>

<pre><code>package coza.modh.fxplatform.examples.bytearray;

import javax.swing.*;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.ResultSet;
import java.sql.Statement;

/**
 * Created by Willie van Zyl on 2014/07/04.
 */
public class ByteArray {

    public static void main(String[] args) {
        ByteArray byteArray = new ByteArray();
        byteArray.createByteArray();
    }

    private void createByteArray() {

        String object = ""This is a string object"";
        byte[] bArray = null;

        System.out.println(object);

        try {
            java.io.ByteArrayOutputStream baos = new java.io.ByteArrayOutputStream();
            java.io.ObjectOutputStream objOstream = new java.io.ObjectOutputStream(baos);
            objOstream.writeObject(object);
            bArray = baos.toByteArray();

            System.out.println(bArray + "" is the byte[] representation of the string object"");

            baos.close();
            objOstream.close();

        } catch (Exception e) {
            System.out.println(e.getMessage());
        }

        System.out.println(""byte [] created successfully"");

        if (writeToDB(bArray)) {
            System.out.println(""byte[] successfully written to database"");
        }
        else {
            System.out.println(""error writing byte[] to database"");
            System.exit(-1);
        }

        bArray = readFromDB();

        java.io.ByteArrayInputStream bis = new java.io.ByteArrayInputStream(bArray);
        java.io.ObjectInput in;

        try {
            in = new java.io.ObjectInputStream(bis);
            object = in.readObject().toString();
            System.out.println(object);

        } catch (Exception e) {
            System.out.println(e.getMessage());
        }

        System.out.println(""string successfully created"");
    }

    private boolean writeToDB(byte[] object) {

        boolean result = false;

        try {
            String dbUrl = ""C:\\Users\\User\\db\\test"";
            String input = JOptionPane.showInputDialog(null, ""DB String: ("" + dbUrl +"")"");

            if (!input.equals("""")) dbUrl = ""jdbc:h2:"" + input; else dbUrl = ""jdbc:h2:"" + dbUrl;
            String dbDriverClass = ""org.h2.Driver"";
            String userName = ""sa"";
            String password = ""sa"";

            Class.forName(dbDriverClass);
            Connection connection = DriverManager.getConnection(dbUrl, userName, password);
            Statement statement = connection.createStatement();

            statement.execute(""drop table if exists TEST"");
            statement.execute(""create table TEST(OBJECT BINARY)"");

            statement.execute(""insert into TEST (OBJECT) values ('"" + object + ""')"");

            connection.close();
            statement.close();

            result = true;

        } catch (Exception except) {
            except.printStackTrace();
        }

        return result;
    }

    private byte[] readFromDB() {

        byte[] bArray = null;

        try {
            String dbUrl = ""C:\\Users\\User\\db\\test"";
            String input = JOptionPane.showInputDialog(null, ""DB String: ("" + dbUrl +"")"");

            if (!input.equals("""")) dbUrl = ""jdbc:h2:"" + input; else dbUrl = ""jdbc:h2:"" + dbUrl;
            String dbDriverClass = ""org.h2.Driver"";
            String userName = ""sa"";
            String password = ""sa"";

            Class.forName(dbDriverClass);
            Connection connection = DriverManager.getConnection(dbUrl, userName, password);
            Statement statement = connection.createStatement();

            ResultSet results = statement.executeQuery(""select * from TEST"");

            while (results.next()) {
                bArray = results.getBytes(""OBJECT"");
            }

            connection.close();
            statement.close();

        } catch (Exception except) {
            except.printStackTrace();
        }

        return bArray;
    }


}
</code></pre>

<p>This is the output i am getting:</p>

<pre><code>This is a string object

[B@11210ee is the byte[] representation of the string object

byte [] created successfully

org.h2.jdbc.JdbcSQLException: Hexadecimal string contains non-hex character:  ""[B@11210ee""; SQL statement:  insert into TEST (OBJECT) values ('[B@11210ee') -- ('[B@11210ee') [90004-178]   at org.h2.message.DbException.getJdbcSQLException(DbException.java:344)     at org.h2.message.DbException.get(DbException.java:178)     at org.h2.message.DbException.get(DbException.java:154)     at org.h2.util.StringUtils.convertHexToBytes(StringUtils.java:966)  at org.h2.value.Value.convertTo(Value.java:864)     at org.h2.table.Column.convert(Column.java:151)     at org.h2.command.dml.Insert.insertRows(Insert.java:144)    at org.h2.command.dml.Insert.update(Insert.java:115)    at org.h2.command.CommandContainer.update(CommandContainer.java:79)     at org.h2.command.Command.executeUpdate(Command.java:254)   at org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:186)    at org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:160)    at coza.modh.fxplatform.examples.bytearray.ByteArray.writeToDB(ByteArray.java:88)   at coza.modh.fxplatform.examples.bytearray.ByteArray.createByteArray(ByteArray.java:43)     at coza.modh.fxplatform.examples.bytearray.ByteArray.main(ByteArray.java:16)    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    at &gt;sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   at java.lang.reflect.Method.invoke(Method.java:483)     at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
</code></pre>

<p>The error is definitely correct as [B@11210ee does contain non hex characters. The [B@ specifically doesn't look right. I just think i don't have a good handle on how byte[] work. Any help would be appreciated.</p>
","<p>The best way is to use a prepared statement:</p>

<pre><code>byte[] object = ...;
PreparedStatement prep = conn.prepareStatement(
    ""insert into TEST (OBJECT) values (?)"");
prep.setBytes(1, object);
</code></pre>

<p>An alternative is to convert the byte array to a hex value, but that's more complicated.</p>
","24607664"
"encode binary to audio python or C","3860","","<p>using C or python (python preferred), How would i encode a binary file to audio that is then outputted though the headphone jack, also how would i decode the audio back to binary using input from the microphone jack, so far i have learned how to covert a text file to binary using python, It would be similar to RTTY communication.</p>

<p>This is so that i can record data onto a cassette tape. </p>

<pre><code>import binascii

a = open('/Users/kyle/Desktop/untitled folder/unix commands.txt', 'r')
f = open('/Users/kyle/Desktop/file_test.txt', 'w')
c = a.read()
b = bin(int(binascii.hexlify(c), 16))
f.write(b)
f.close()
</code></pre>
","<p>From your comments, you want to process the binary data bit by bit, turning each bit into a high or low sound.</p>

<p>You still need to decide exactly what those high and low sounds are, and how long each one sounds for (and whether there's a gap in between, and so on). If you make it slow, like 1/4 of a second per sound, then you're treating them as notes. If you make it very fast, like 1/44100 of a second, you're treating them as samples. The human ear can't hear 44100 different sounds in a second; instead, it hears a single sound at up to 22050Hz.</p>

<p>Once you've made those decisions, there are two parts to your problem.</p>

<p>First, you have to generate a stream of samples—for example, a stream of 44100 16-bit integers for every second. For really simple things, like playing a chunk of a raw PCM file in 44k 16-bit mono format, or generating a square wave, this is trivial. For more complex cases, like playing a chunk of an MP3 file or synthesizing a sound out of sine waves and filters, you'll need some help. The <a href=""http://docs.python.org/3/library/audioop.html"" rel=""nofollow""><code>audioop</code></a> module, and a few others in the stdlib, can give you the basics; beyond that, you'll need to search PyPI for appropriate modules.</p>

<p>Second, you have to send that sample stream to the headphone jack. There's no built-in support for this in Python. On some platforms, you can do this just by opening a special file and writing to it. But, more generally, you will need to find a third-party library on PyPI.</p>

<p>The simpler modules work for one particular type of audio system. Mac and Windows each have their own standards, and Linux has a half dozen different ones. There are also some Python modules that talk to higher-level wrappers; you may have to install and set up the wrapper, but once you do that, your code will work on any system.</p>

<hr>

<p>So, let's work through one really simple example. Let's say you've got PortAudio set up on your system, and you've installed <a href=""http://people.csail.mit.edu/hubert/pyaudio/"" rel=""nofollow"">PyAudio</a> to talk to it. This code will play square waves of 441Hz and 220.5Hz (just above middle C and low C) for just under 1/4th of a second (just because that's really easy).</p>

<pre><code>import binascii

a = open('/Users/kyle/Desktop/untitled folder/unix commands.txt', 'r')
c = a.read()
b = bin(int(binascii.hexlify(c), 16))

sample_stream = []
high_note = (b'\xFF'*100 + b'\0'*100) * 50
low_note = (b'\xFF'*50 + b'\0'*50) * 100
for bit in b[2:]:
    if bit == '1':
        sample_stream.extend(high_note)
    else:
        sample_stream.extend(low_note)

sample_buffer = b''.join(sample_stream)

p = pyaudio.PyAudio()
stream = p.open(format=p.get_format_from_width(8),
                channels=1,
                rate=44100,
                output=True)
stream.write(sample_buffer)
</code></pre>
","16930440"
"Algorithm to calculate the number of 1s for a range of numbers in binary","3858","","<p>So I just got back for the <strong>ACM Programing competition</strong> and did pretty well but there was one problem that not one team got.</p>

<p>The Problem.</p>

<blockquote>
  <p>Start with an integer N0 which is greater than 0. Let N1 be the number of ones in the binary representation of N0. So, if <code>N0 = 27</code>, <code>N1 = 4</code>. For all <code>i &gt; 0</code>, let Ni be the number of ones in the binary representation of <code>Ni-1</code>. This sequence will always converge to one. For any starting number, N0, let K be the minimum value of i >= 0 for which N1 = 1. For example, if N0 = 31, then N1 = 5, N2 = 2, N3 = 1, so K = 3.</p>
  
  <p>Given a range of consecutive numbers and a value of X how many numbers in the range have a K value equal to X?</p>
  
  <p><strong>Input</strong><br>
  There will be several test cases in the input. Each test case will consist of three integers on a single line: 
  <code>LO HI X</code><br>
  Where <code>LO</code> and <code>HI</code> (1 &lt;= <code>LO</code> &lt;= <code>HI</code> &lt;= 10^18) are the lower and upper limits of a range of integers, and <code>X</code> (0 &lt;= <code>X</code> &lt;= 10) is the target value for K. The input will end with a line of three 0s.</p>
  
  <p><strong>Output</strong><br>
  For each test case output a single integer, representing the number of integers in the range from <code>LO</code> to <code>HI</code> (inclusive) which have a K value equal to X in the input. Print each Integer on its own line with no spaces. Do not print any blank lines between answers.</p>
</blockquote>

<h3>Sample Input</h3>

<pre><code>31 31 3
31 31 1
27 31 1
27 31 2
1023 1025 1
1023 1025 2
0 0 0
</code></pre>

<h3>Sample Output</h3>

<pre><code>1
0
0
3
1
1
</code></pre>

<hr>

<p>If you guys want I can include our answer or our problem, because finding for a small range is easy but I will give you a hint first your program needs to run in <em>seconds</em> not minutes.  We had a successful solution but not an efficient algorithm to use a range similar to </p>

<pre><code>48238 10^18 9
</code></pre>

<p>Anyway good luck and if the community likes these we had some more we could not solve that could be some good brain teasers for you guys. The competition allows you to use Python, C++, or Java—all three are acceptable in an answer.</p>

<hr>

<p>So as a hint my coach said to think of how binary numbers count rather than checking every bit.  I think that gets us a lot closer.</p>
","<p>I think a key is first understanding the pattern of K values and how rapidly it grows.  Basically, you have:</p>

<pre><code>K(1) = 0
K(X) = K(bitcount(X))+1 for X &gt; 1
</code></pre>

<p>So finding the smallest X values for a given K we see</p>

<pre><code>K(1) = 0
K(2) = 1
K(3) = 2
K(7) = 3
K(127) = 4
K(170141183460469231731687303715884105727) = 5
</code></pre>

<p>So for an example like <code>48238 10^18 9</code> the answer is trivially 0.  K=0 only for 1, and K=1 only for powers of 2, so in the range of interest, we'll pretty much only see K values of 2, 3 or 4, and never see K >= 5</p>

<p><strong>edit</strong></p>

<p>Ok, so we're looking for an algorithm to count the number of values with K=2,3,4 in a range of value LO..HI without iterating over the entire range.  So the first step is to find the number of values in the range with bitcount(x)==i for i = 1..59 (since we only care about values up to 10^18 and 10^18 &lt; 2^60).  So break down the range lo..hi into subranges that are a power of 2 size and differ only in their lower n bits -- a range of the form x*(2^n)..(x+1)*(2^n)-1.  We can break down the arbitray lo..hi range into such subranges easily.  For each such subrange there will be choose(n, i) values with i+bitcount(x) set bits.
So we just add all the subranges together to get a vector of counts for 1..59, which we then iterate over, adding together those elements with the same K value to get our answer.</p>

<p><strong>edit</strong> (fixed again to be be C89 compatible and work for lo=1/k=0)</p>

<p>Here's a C program to do what I previously described:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;assert.h&gt;

int bitcount(long long x) {
    int rv = 0;
    while(x) { rv++; x &amp;= x-1; }
    return rv; }

long long choose(long long m, long long n) {
    long long rv = 1;
    int i;
    for (i = 0; i &lt; n; i++) {
        rv *= m-i;
        rv /= i+1; }
    return rv; }

void bitcounts_p2range(long long *counts, long long base, int l2range) {
    int i;
    assert((base &amp; ((1LL &lt;&lt; l2range) - 1)) == 0);
    counts += bitcount(base);
    for (i = 0; i &lt;= l2range; i++)
        counts[i] += choose(l2range, i); }

void bitcounts_range(long long *counts, long long lo, long long hi) {
    int l2range = 0;
    while (lo + (1LL &lt;&lt; l2range) - 1 &lt;= hi) {
        if (lo &amp; (1LL &lt;&lt; l2range)) {
            bitcounts_p2range(counts, lo, l2range);
            lo += 1LL &lt;&lt; l2range; }
        l2range++; }
    while (l2range &gt;= 0) {
        if (lo + (1LL &lt;&lt; l2range) - 1 &lt;= hi) {
            bitcounts_p2range(counts, lo, l2range);
            lo += 1LL &lt;&lt; l2range; }
        l2range--; }
    assert(lo == hi+1); }

int K(int x) {
    int rv = 0;
    while(x &gt; 1) {
        x = bitcount(x);
        rv++; }
    return rv; }

int main() {
    long long counts[64];
    long long lo, hi, total;
    int i, k;
    while (scanf(""%lld%lld%d"", &amp;lo, &amp;hi, &amp;k) == 3) {
        if (lo &lt; 1 || lo &gt; hi || k &lt; 0) break;
        if (lo == 0 || hi == 0 || k == 0) break;
        total = 0;
        if (lo == 1) {
            lo++;
            if (k == 0) total++; }
        memset(counts, 0, sizeof(counts));
        bitcounts_range(counts, lo, hi);
        for (i = 1; i &lt; 64; i++)
            if (K(i)+1 == k)
                total += counts[i];
        printf(""%lld\n"", total); }
    return 0; }
</code></pre>

<p>which runs just fine for values up to 2^63-1 (LONGLONG_MAX).
For <code>48238 1000000000000000000 3</code> it gives <code>513162479025364957</code>, which certainly seems plausible</p>

<p><strong>edit</strong></p>

<p>giving the inputs of</p>

<pre><code>48238 1000000000000000000 1
48238 1000000000000000000 2
48238 1000000000000000000 3
48238 1000000000000000000 4
</code></pre>

<p>gives outputs of</p>

<pre><code>44
87878254941659920
513162479025364957
398959266032926842
</code></pre>

<p>Those add up to 999999999999951763 which is correct.  The value for k=1 is correct (there are 44 powers of two in that range 2^16 up to 2^59).  So while I'm not sure the other 3 values are correct, they're certainly plausible.</p>
","4158630"
"Get SHA1 binary base64 hash of a file on C#","3851","","<p>I am thinking on creating a program on C# to get the SHA1 binary base64 hash of a series of very large files.</p>

<p>Right now I can accomplish that by running this instruction on OpenSSL:</p>

<blockquote>
  <p>openssl sha1 -binary FILENAME | openssl base64</p>
</blockquote>

<p>however I haven´t found references for the ""binary"" and ""base64"" parts to obtain the same result with C#.</p>

<p>Is it possible? Maybe call openssl inside C#?</p>

<p>Thank you.</p>
","<p>You need to use the Convert.ToBase64String method and the System.IO namespace to read binary:</p>

<pre><code>string GetBase64EncodedSHA1Hash(string filename)
{
    using (FileStream fs = new FileStream(filename, FileMode.Open, FileAccess.Read, FileShare.Read))
    using (SHA1Managed sha1 = new SHA1Managed())
    {
        return Convert.ToBase64String(sha1.ComputeHash(fs));
    }
}
</code></pre>
","19150543"
"Find nth SET bit in an int","3844","","<p>Instead of just the lowest set bit, I want to find the position of the <code>n</code>th lowest set bit. (I'm <strong>NOT</strong> talking about value on the <code>n</code>th bit position)</p>

<p>For example, say I have:<br>
<code>0000 1101 1000 0100 1100 1000 1010 0000</code></p>

<p>And I want to find the 4th bit that is set. Then I want it to return:<br>
<code>0000 0000 0000 0000 0100 0000 0000 0000</code></p>

<p>If <code>popcnt(v) &lt; n</code>, it would make sense if this function returned <code>0</code>, but any behavior for this case is acceptable for me.</p>

<p>I'm looking for something faster than a loop if possible.</p>
","<p>It turns out that it is indeed possible to do this with no loops. It is fastest to precompute the (at least) 8 bit version of this problem. Of course, these tables use up cache space, but there should still be a net speedup in virtually all modern pc scenarios. In this code, n=0 returns the least set bit, n=1 is second-to-least, etc.</p>

<p><strong>Solution with __popcnt</strong></p>

<p>There is a solution using the __popcnt intrinsic (you need __popcnt to be extremely fast or any perf gains over a simple loop solution will be moot. Fortunately most SSE4+ era processors support it).</p>

<pre><code>// lookup table for sub-problem: 8-bit v
byte PRECOMP[256][8] = { .... } // PRECOMP[v][n] for v &lt; 256 and n &lt; 8

ulong nthSetBit(ulong v, ulong n) {
    ulong p = __popcnt(v &amp; 0xFFFF);
    ulong shift = 0;
    if (p &lt;= n) {
        v &gt;&gt;= 16;
        shift += 16;
        n -= p;
    }
    p = __popcnt(v &amp; 0xFF);
    if (p &lt;= n) {
        shift += 8;
        v &gt;&gt;= 8;
        n -= p;
    }

    if (n &gt;= 8) return 0; // optional safety, in case n &gt; # of set bits
    return PRECOMP[v &amp; 0xFF][n] &lt;&lt; shift;
}
</code></pre>

<p>This illustrates how the divide and conquer approach works.</p>

<p><strong>General Solution</strong></p>

<p>There is also a solution for ""general"" architectures- without __popcnt. It can be done by processing in 8-bit chunks. You need one more lookup table that tells you the popcnt of a byte:</p>

<pre><code>byte PRECOMP[256][8] = { .... } // PRECOMP[v][n] for v&lt;256 and n &lt; 8
byte POPCNT[256] = { ... } // POPCNT[v] is the number of set bits in v. (v &lt; 256)

ulong nthSetBit(ulong v, ulong n) {
    ulong p = POPCNT[v &amp; 0xFF];
    ulong shift = 0;
    if (p &lt;= n) {
        n -= p;
        v &gt;&gt;= 8;
        shift += 8;
        p = POPCNT[v &amp; 0xFF];
        if (p &lt;= n) {
            n -= p;
            shift += 8;
            v &gt;&gt;= 8;
            p = POPCNT[v &amp; 0xFF];
            if (p &lt;= n) {
                n -= p;
                shift += 8;
                v &gt;&gt;= 8;
            }
        }
    }

    if (n &gt;= 8) return 0; // optional safety, in case n &gt; # of set bits
    return PRECOMP[v &amp; 0xFF][n] &lt;&lt; shift;
}
</code></pre>

<p>This could, of course, be done with a loop, but the unrolled form is faster and the unusual form of the loop would make it unlikely that the compiler could automatically unroll it for you.</p>
","7671563"
"Javascript: A byte is supposed to be 8 bits","3843","","<p>EDIT: <a href=""http://www.ascii-code.com/"" rel=""nofollow noreferrer"">http://www.ascii-code.com/</a> I see the BIN column as binary but I am clearly missing something..</p>

<p>Why doesn't binary conversion work for me?</p>

<p>Lowercase b is character code 98</p>

<pre><code>console.log((98).toString(2));
</code></pre>

<p>outputs</p>

<pre><code>1100010
</code></pre>

<p>The length of the output is 7 when it should be 8</p>

<p>A byte is 8 bits!!?</p>

<p><strong>EDIT</strong></p>

<blockquote>
  <p>Groups of Bits make up a Byte When 8 bits are grouped together, it is then known as a byte. And bytes are what computers use to represent various characters such as those you see on your keyboard. </p>
</blockquote>

<p>Quoted from: <a href=""http://wordsmuggler.com/Learn/Binary"" rel=""nofollow noreferrer"">http://wordsmuggler.com/Learn/Binary</a> </p>

<p>I really don't understand now what I am supposed to read. If I look on Google I always am told 8 but here I am told different. Please explain as I don't understand what I am supposed to be understanding</p>
","<p>The reason why <code>.toString(2)</code> does not produce an 8-bit representation of a number is that <code>toString</code> works for more numbers than just 0 through 255.  For example:</p>

<pre><code>(1).toString(2) ==&gt; ""1""
(2).toString(2) ==&gt; ""10""
(3).toString(2) ==&gt; ""11""
(4).toString(2) ==&gt; ""100""
(25).toString(2) ==&gt; ""11001""
(934534534).toString(2) =&gt; ""110111101100111101110110000110""
</code></pre>

<p>So what JavaScript is doing with <code>toString(2)</code> is simply giving you numbers in base 2, namely 0, 1, 10, 11, 100, 101, etc., the same way that in base 10 we write our numbers 0, 1, 2, 3, 4, 5, ... and we don't always pad out our numbers to make a certain number of digits.  That is why you are not seeing 8 binary digits in your output.</p>

<p>Now, the problem you have in mind is ""how do I take a number in the range 0..255 and show it as a binary-encoded BYTE in JavaScript?  It turns out that needs to be done by the programmer; it is not a built-in operation in JavaScript!  Writing a number in base-2, and writing an 8-bit, are related problems, but they are different.</p>

<p>To do what you would like to, you can write a function:</p>

<pre><code>function byteString(n) {
  if (n &lt; 0 || n &gt; 255 || n % 1 !== 0) {
      throw new Error(n + "" does not fit in a byte"");
  }
  return (""000000000"" + n.toString(2)).substr(-8)
}
</code></pre>

<p>Here is how it can be used:</p>

<pre><code>&gt; byteString(-4)
Error: -4 does not fit in a byte
&gt; byteString(0)
'00000000'
&gt; byteString(7)
'00000111'
&gt; byteString(255)
'11111111'
&gt; byteString(256)
Error: 256 does not fit in a byte
</code></pre>
","24337276"
"Saving Binary Data To MySQLdb - Python","3842","","<p>I have googled and searched this site, but nothing specific appears and cannot get this working. Here is the code:</p>

<pre><code>    binData = ''.join(map(lambda x: chr(x % 256), attach.attcoll))

    sql_stmt = """"""INSERT INTO attachments (attno,filename,fileextension,projNo,procNo,wpattachment) \
    VALUES ('%s','%s','%s','%s','%s','%s') ON DUPLICATE KEY UPDATE filename='%s',fileextension='%s'"""""", attach.attno,\
attach.filename,attach.fileextension,attach.projNo,attach.procNo,binData,attach.filename,attach.fileextension

    try:
        cursor.execute(MySQLdb.escape_string(sql_stmt))
        conn.commit()
</code></pre>

<p>The attach.attcoll is data that comes in over JSON from an SQLite blob and java code on the client side. I then want to write binData to MySQL with MySQLdb, but keep getting a TypeError, and a return code of 500. Any ideas on how to fix this. I want to store binData into a MySQL blob.</p>
","<p>Bunch of things here:</p>

<pre><code>binData = ''.join(map(lambda x: chr(x % 256), attach.attcoll))
sql_stmt = """"""INSERT INTO attachments (attno,filename,fileextension,projNo,procNo,wpattachment)
VALUES (%s,%s,%s,%s,%s,%s) ON DUPLICATE KEY UPDATE filename=%s,fileextension=%s"""""" 

params = (attach.attno,attach.filename,attach.fileextension,attach.projNo,attach.procNo,binData,attach.filename,attach.fileextension)

cursor.execute(sql_stmt, params)
conn.commit()
</code></pre>

<p>A summary:</p>

<ol>
<li>Make sure you are connected to the db first (if you don't know how to do this, read the MySQLdb documentation)</li>
<li>You don't want to escape your entire query, only the data parts, passing the statement and data separately to <code>cursor.execute()</code> means the cursor will escape it for you.</li>
<li>Dont quote your <code>'%s'</code>, MySQLdb does that for you as well.</li>
<li>Is your database transactional (i.e. InnoDB), is that why you are using <code>conn.commit()</code>, it is not necessary if you  aren't using  a  transactional engine.</li>
<li>Without seeing how you've structured your db table I can't guarantee this will work. As practice, have you tried creating a really simple database table and practiced inserting into it with MySQLdb, just so you familiarize yourself with the API?</li>
</ol>
","5112132"
"How to do pattern matching on a binary in Erlang?","3840","","<p>I would like to do recursion over a binary, and in each call read up to 32 bits from the binary, and return it in a new binary. But I can't get the pattern matching to work as I want.</p>

<pre><code>binaryToBinary(Source) -&gt;
    binaryToBinaryAux(Source, &lt;&lt;&gt;&gt;).

binaryToBinaryAux(&lt;&lt;&gt;&gt;, Target) -&gt;
    Target;
binaryToBinaryAux(&lt;&lt;H:32/binary, T/binary&gt;&gt;, Target) -&gt;
    binaryToBinaryAux(&lt;&lt;T/binary&gt;&gt;, &lt;&lt;Target/binary, H&gt;&gt;).
</code></pre>

<p>Here is the error I get for the pattern matching:</p>

<pre><code>10&gt; mymodule:binaryToBinary(&lt;&lt;""JonasPonas""&gt;&gt;).
** exception error: no function clause matching
                    mymodule:binaryToBinaryAux(&lt;&lt;""JonasPonas""&gt;&gt;,&lt;&lt;&gt;&gt;) 
                                                          (mymodule.erl, line 51)
</code></pre>

<p>What am I doing wrong with the pattern matching of the binary?</p>
","<p>The pattern <code>&lt;&lt;H:32/binary, T/binary&gt;&gt;</code> matches a binary containing at least 32 bytes, assigning the first 32 bytes to H and the remaining bytes to T. The pattern <code>&lt;&lt;&gt;&gt;</code> matches the empty binary. These are your only patterns.</p>

<p><code>&lt;&lt;""JonasPonas""&gt;&gt;</code> is neither empty nor does it have at least 32 bytes. Therefore it does not match either of your patterns and you get the error you do.</p>

<p>To fix this add a pattern that handles binaries that have less than 32 bytes (you can also get rid of the empty pattern as it will then be redundant).</p>
","14447072"
"Hex to binary using VBScript","3836","","<p>Is it possible to convert a Hexdump to binary using VBS?
I made a program that reads any file as Byte array, then it converts it to Hex.
In output Hexdump looks like this</p>

<pre><code>00 00 00 0A 4D
</code></pre>

<p>til the end.
Now i want to know if i can convert it back to binary and execute it using a VBScript.
I will appreciate any help, thank you.</p>
","<p>Something like this should work:</p>

<pre><code>hexstr = ""00 00 00 0A 4D""

hexarr = Split(hexstr)
ReDim binarr(UBound(hexarr))

For i = 0 To UBound(hexarr)
  binarr(i) = Chr(CInt(""&amp;h"" &amp; hexarr(i)))
Next

binstr = Join(binarr, """")
</code></pre>
","20423526"
"How to read from binary file to a text file in C?","3821","","<p>I am having trouble copying from a binary file and writing to a text file. I have written a program that is capable of copying from a text file and writing to a binary file but I cannot do the reverse.</p>

<p>Here is my function that I am having issues with:</p>

<pre><code>void CopyBin2Text(char* rafname, char* txtname)
{

FILE * fraf = fopen(rafname,""rb"");
FILE * ftxt = fopen(txtname,""r+"");

//READ FROM BINARY FILE
struct PERSON p;
int ByteOfBin;


printf(""ID \t NAME \t\t BALANCE \n"");
printf(""---------------------------------------\n"");
</code></pre>

<p><strong>when I run my program it stops here after printing the above statement</strong></p>

<pre><code>  while(!feof(fraf))
  {
       fscanf(fraf, ""%d %s %f"", &amp;p.ID, p.name, &amp;p.balance);

    ByteOfBin = ((p.ID/10-1)*sizeof(p));
    fseek(ftxt,ByteOfBin, SEEK_SET);
    fwrite((char *)&amp;p, sizeof(p), 1, ftxt);

  }


fclose(fraf);
fclose(ftxt);
}
</code></pre>

<hr>

<p>Another issue that I have noticed is that the text file becomes to large to open. The result is that I have to delete the text file and create it again.
Can anyone explain what is causing this to occur? </p>
","<p>I made a number of changes to your function. The file opening mode, checking they did open, dumping the <code>feof()</code>, using the appropriate binary and text functions to read and write, and returning a status for whether the function operated properly.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

struct PERSON {
    int ID;
    char name[20];
    float balance;
};

int CopyBin2Text(char* rafname, char* txtname)      // changed return value
{
    FILE *fraf, *ftxt;
    struct PERSON p;
    if ((fraf = fopen(rafname,""rb"")) == NULL)
        return 0;                                   // failure

    if ((ftxt = fopen(txtname,""wt"")) == NULL) {     // changed mode
        fclose(fraf);
        return 0;                                   // failure
    }
    fprintf(ftxt, ""ID\tNAME\tBALANCE\n"");
    fprintf(ftxt, ""---------------------------------------\n"");
    while(fread(&amp;p, sizeof(p), 1, fraf) == 1)       // use return value to loop
        fprintf(ftxt, ""%d\t%s\t%.2f\n"", p.ID, p.name, p.balance);
    fclose(ftxt);

    fclose(fraf);
    return 1;                                       // success
}

int makefile(char* rafname)
{
    FILE *fraf, *ftxt;
    struct PERSON p = {1,""alpha"", 123.45};
    struct PERSON q = {2,""beta"",  100.00};
    struct PERSON r = {3,""gamma"", 9.99};
    if ((fraf = fopen(rafname,""wb"")) == NULL)
        return 0;                                   // failure
    fwrite(&amp;p, sizeof(p), 1, fraf);
    fwrite(&amp;q, sizeof(q), 1, fraf);
    fwrite(&amp;r, sizeof(r), 1, fraf);
    fclose(fraf);
    return 1;                                       // success
}

int main(void)
{
    if (makefile(""file.bin"") == 0)
        printf(""Failure\n"");
    else {
        if (CopyBin2Text(""file.bin"", ""file.txt"") == 0)
            printf(""Failure\n"");
        else
            printf(""Success\n"");
    }
    return 0;
}
</code></pre>

<p>Output text file is</p>

<pre><code>ID  NAME    BALANCE
---------------------------------------
1   alpha   123.45
2   beta    100.00
3   gamma   9.99
</code></pre>
","33254251"
"count the binary gap","3817","","<p>I want to write a code that counts the binary gap of any given integers in java.</p>
","<p>The problem with giving an answer to this question is</p>

<ul>
<li>You won't learn anything</li>
<li>You can't use the answer for homework if you can't explain what you have done.</li>
</ul>

<p>.</p>

<pre><code>long l = 0b100101L;
String betweenOnes = Long.toBinaryString(l &gt;&gt; Long.numberOfTrailingZeros(l))
int zeros = Collections.max(Arrays.asList(betweenOnes).split(""1+""))).length();
System.out.println(zeros);
</code></pre>

<p>prints</p>

<pre><code>2
</code></pre>
","11966082"
"How to input an integer's binary expression into a bitSet in java","3815","","<p>How to input an integer's binary expression into a bitSet in java?</p>

<p>say <code>a = 15</code> I want put <code>1111</code> into a bitSet, </p>

<p>is there a function for this?</p>
","<p><code>BitSet</code> has a static <a href=""http://docs.oracle.com/javase/7/docs/api/java/util/BitSet.html#valueOf%28long%5B%5D%29"" rel=""nofollow""><code>valueOf(long[])</code></a> method which</p>

<blockquote>
  <p>Returns a new bit set containing all the bits in the given long array. </p>
</blockquote>

<p>So an array with one long will have 64 bits, an array with two longs will have 128 bits, etc.</p>

<p>If you only need to get a <code>BitSet</code> from a single <code>int</code> value, use it like so</p>

<pre><code>Integer value = 42;
System.out.println(Integer.toBinaryString(value));
BitSet bitSet = BitSet.valueOf(new long[] { value });
System.out.println(bitSet);
</code></pre>

<p>It prints</p>

<pre><code>101010
{1, 3, 5}
</code></pre>

<p>In other words, from the right to left in the representation above, the 2nd, 4th, and 6th bit are set.</p>
","23123809"
"Converting a repeating binary number to decimal (express as a series?)","3813","","<p>Given a binary number that repeats, for example 0.(0011) or 0.0(101), how would one go about converting it to decimal?</p>

<p>What I've been able to dig up so far is the simple method for converting a terminating binary number to decimal, as below:</p>

<pre><code>res(N+2) = res(N+1) / 2 + res(N)
</code></pre>

<p>where res is the result after step N, and N is the current iteration (N=0; n->(num binary digits)). Applying that repeatedly to a nonterminating binary number gives a good approximation, for example</p>

<pre><code>dec:0.4 || bin: 0.(0110):

0     / 2 + 0 = 0
0     / 2 + 0 = 0
0     / 2 + 1 = 1
1/2   / 2 + 1 = 3/2
3/2   / 2 + 0 = 3/4
3/4   / 2 + 0 = 3/8
3/8   / 2 + 1 = 19/16
19/16 / 2 + 1 = 51/32
51/32 / 2 + 0 = 51/64
51/64 / 2 + 0 = 51/128 = 0.3984
</code></pre>

<p>which is approximately 0.4.</p>

<p>So, I've got a means of calculating approximates, but I'm struggling with finding a way to express this. I've started trying to write it as a series I can compute at the limit as n->inf without too much success so far.</p>
","<p>One way to get an exact answer is using infinite geometric series. The infinite sum of powers of a fraction r, for exponents 1 to infinity, 0 &lt;= r &lt; 1, is r/(1-r).</p>

<p>In your example, 0.(0011), 0.0011 represents the fraction 3/16. Factor out the 3 and you get r=1/16. r/(1-r) = (1/16)/(15/16) = 1/15. Multiply that by the 3 you factored out and you get your answer: 3/15 = 1/5 = 0.2.</p>
","2127353"
"Convert floating point number 1864.78 to binary and IEEE format","3808","","<p>I've been trying to convert the value of the S&amp;P 500 which today is 1864.78 to how it would be represented in IEEE single precision format in memory.</p>

<p>Converting the left of the decimal (1864) is easy.</p>

<p>11101001000.</p>

<p>But how do I get the binary representation of the decimal (.78)?  I tried using the technique but it produces many numbers over the 8 bit exponent IEEE format:</p>

<p>.78*2=1.56  1</p>

<p>.56*2=1.12  1</p>

<p>.12*2=.24   0</p>

<p>.24*2=.48   0</p>

<p>.48*2=.96   0</p>

<p>.96*2=1.92  1</p>

<p>.92*2=1.84  1</p>

<p>.84*2=1.68  1</p>

<p>.68*2=1.36  1</p>

<p>.36*2=.72   0</p>

<p>.72*2=1.44  1</p>

<p>.44*2=.88   1 (rounded up because now we have 23 total bits)</p>

<p>11101001000.110001111011 = 23 bits for mantissa</p>

<p>Add 0 for sign</p>

<p>0 11101001000.110001111011</p>

<p>Now I need to move the decimal over 10 places</p>

<p>1.1101001000110001111011 x 2^10 exponent is 10 now</p>

<p>add a 0 bit to make full mantissa 23 bits</p>

<p>1.11010010001100011110110</p>

<p>exponent is 10 so 10 + 127 = 137</p>

<p>which is equal to 10001001</p>

<p>so 0 10001001 11010010001100011110110 which is a 32 bit number.</p>

<p>Does this look like a decent approach?  I tested the value and writing this question I was actually able to work through it on my own.</p>

<p>Testing the decimal FP with this.
<a href=""http://www.h-schmidt.net/FloatConverter/IEEE754.html"" rel=""nofollow"">http://www.h-schmidt.net/FloatConverter/IEEE754.html</a></p>
","<p>You have two different conversion routines for converting the integer and fractional parts to binary. You understand how to convert <code>1864</code> to binary, but you have problems converting <code>.78</code> to binary. <strong>Note:</strong> you must convert the actual fraction held in <em>memory</em> for the float <code>1864.78</code> which is <code>1864.780029</code> or fraction <code>0.780029</code> <em>not</em> <code>0.78</code>. That appears where your ""rounding"" confusion is coming from.</p>

<p>To convert a fraction to its binary representation, you will multiply the fraction by <code>2</code> and if the resulting number has an integer part greater than <code>1</code>, your binary representation of that bit is <code>1</code>, if not your representation is <code>0</code>. If greater than one, you subtract <code>1</code> from the number and repeat until you have exhausted the number or reached the limit of precision in question. For example:</p>

<pre><code>number   : 1864.78
float    : 1864.780029  (actual nearest representation in memory)
integer  : 1864
fraction : 0.780029

 2 * 0.780029 = 1.560059  =&gt;  integer part (1) fraction (0.560059)  =&gt;  '1'
 2 * 0.560059 = 1.120117  =&gt;  integer part (1) fraction (0.120117)  =&gt;  '1'
 2 * 0.120117 = 0.240234  =&gt;  integer part (0) fraction (0.240234)  =&gt;  '0'
 2 * 0.240234 = 0.480469  =&gt;  integer part (0) fraction (0.480469)  =&gt;  '0'
 2 * 0.480469 = 0.960938  =&gt;  integer part (0) fraction (0.960938)  =&gt;  '0'
 2 * 0.960938 = 1.921875  =&gt;  integer part (1) fraction (0.921875)  =&gt;  '1'
 2 * 0.921875 = 1.843750  =&gt;  integer part (1) fraction (0.843750)  =&gt;  '1'
 2 * 0.843750 = 1.687500  =&gt;  integer part (1) fraction (0.687500)  =&gt;  '1'
 2 * 0.687500 = 1.375000  =&gt;  integer part (1) fraction (0.375000)  =&gt;  '1'
 2 * 0.375000 = 0.750000  =&gt;  integer part (0) fraction (0.750000)  =&gt;  '0'
 2 * 0.750000 = 1.500000  =&gt;  integer part (1) fraction (0.500000)  =&gt;  '1'
 2 * 0.500000 = 1.000000  =&gt;  integer part (1) fraction (0.000000)  =&gt;  '1'
</code></pre>

<p><strong>note:</strong> how the <em>floating-point</em> fractional value will tend to zero rather than reaching your limit of digits. If you attempt to convert <code>0.78</code> (which is not capable of exact representation as the fraction to <code>1864.78</code> in a 32-bit floating point value) you will reach a different conversion in the 12th bit.</p>

<p>Once you have converted your fractional part to binary, you can continue with conversion into IEEE-754 single precision format. e.g.:</p>

<pre><code>decimal  : 11101001000
fraction : 110001111011
sign bit : 0
</code></pre>

<p>The normalization for the biased exponent is:</p>

<pre><code> 11101001000.110001111011  =&gt;  1.1101001000110001111011

     exponent bias: 10
 unbiased exponent: 127
 __________________+____

   biased exponent: 137
   binary exponent: 10001001
</code></pre>

<p>Conversion to 'hidden bit' format to form mantissa:</p>

<pre><code>1.1101001000110001111011  =&gt;  1101001000110001111011
</code></pre>

<p>Then  use the <em>sign bit</em> + <em>excess 127 exponent</em> + <em>mantissa</em> to form the IEEE-754 single precision representation:</p>

<pre><code>IEEE-754 Single Precision Floating Point Representation

  0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 0 1 1 0
 |- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -|
 |s|      exp      |                  mantissa                   |
</code></pre>

<p>Look it over and let me know if you have further questions. If you wanted a simple routine to fill a character array with the resulting conversion, you could do something similar to the following to convert a floating point fraction part to binary:</p>

<pre><code>#define MANTISSA 23
...

/** return string containing binary representation of fraction
 *  The function takes a float as an argument and computes the
 *  binary representation of the fractional part of the float,
 *  On success, the function returns a null-terminated string
 *  containing the binary value, or NULL otherwise. The conversion
 *  is limited to the length of your MANTISSA (23-bits for single
 *  precission, 52-bits for double precision). You must insure
 *  you provide a buffer for 's' of at least MANTISSA + 1 bytes.
 */
char *fpfrc2bin (char *s, float fvalue)
{
    /* obtain fractional value from fvalue */
    float fv = fvalue &gt; 1.0 ? fvalue - (int)fvalue : fvalue;
    char *p = s;
    unsigned char it = 0;

    while (fv &gt; 0 &amp;&amp; it &lt; MANTISSA + 1)
    {   /* convert fraction */
        fv = fv * 2.0;
        *p++ = ((int)fv) ? '1' : '0';
        *p = 0;  /* nul-terminate */
        fv = ((int)fv &gt;= 1) ? fv - 1.0 : fv;
        it++;
    }

    return s;
}
</code></pre>
","35401156"
"fread and fwrite in C","3808","","<p>I'm trying to make a program that creates and reads a binary file, which contains ""struct elements""; can you please tell me what I did wrong?
I got errors telling me that ""s"" is not a pointer in function fread()... so I declared ELEM *s; instead of ELEM s;</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

typedef struct element{
    char name[80];
    int p;
}ELEM;

void create()
{
    FILE *f;
    int d=0;
    char c;
    ELEM *s;
    f=fopen(""file.bin"",""wb"");
    do{
    printf(""Add elements to file?: (y/n)"");
    fflush(stdin);
    scanf(""%c"",&amp;c);
    if (c=='y')
    {
        printf(""Name="");
        gets((*s).name);
        printf(""P="");
        scanf(""%d"",(*s).p);
        fwrite(s,sizeof(ELEM),1,f);
    }
    } while(d==0);
    fclose(f);
}

void show()
{
    FILE *f;
    ELEM *s;
    f=fopen(""file.bin"",""rb"");
    while(feof(f)!=NULL)
    {
        fread(s,sizeof(ELEM),1,f);
        puts((*s).name);
        printf(""\t%d\n"",(*s).p);
    }
    fclose(f);
}

void add()
{
    FILE *f;
    int d=0;
    char c;
    ELEM *s;
    f=fopen(""file.bin"",""ab"");
    do{
    printf(""Add elements to file?: (y/n)"");
    fflush(stdin);
    scanf(""%c"",&amp;c);
    if (c=='y')
    {
        printf(""Name="");
        gets((*s).name);
        printf(""P="");
        scanf(""%d"",(*s).p);
        fwrite(s,sizeof(ELEM),1,f);
    }
    } while(d==0);
    fclose(f);
}


/*void function()
{

}*/

int main()
{
    int k=0,r;
    do{
        printf(""1 - create file\n2 - add elements to fil\n3 - show elements\n4 - put unique elements in another file\n5 - exit program\n"");
        scanf(""%d"",&amp;r);
        switch(r)
        {
            case 1 : create(); break;
            case 2 : add(); break;
            case 3 : show(); break;
            case 4 : printf(""Function not defined!\n""); break;
            case 5 : k=1; break;
            default : printf(""Command unrecognized!\n"");
        }
    } while(k==0);
    return 0;
}
</code></pre>
","<p>The first parameter passed to <strong><a href=""http://pubs.opengroup.org/onlinepubs/000095399/functions/fread.html"" rel=""nofollow"">fwrite</a></strong> should be an address, and the variable whose address you pass must have enough memory to hold the number of objects you plan to read.</p>

<p>So there are two ways:</p>

<p><strong>Creating Variable on Stack:</strong></p>

<p>You allocate the variable on stack and pass its address to <code>fwrite</code>    </p>

<pre><code>ELEM s;
fwrite(&amp;s,sizeof(ELEM),1,f);
</code></pre>

<p>or </p>

<p><strong>Dynamic Memory allocation:</strong></p>

<pre><code>ELEM *s;   
</code></pre>

<p>Should be allocated an memory equivalent to hold no of objects of type <code>ELEM</code> that you want to read. </p>

<pre><code>ELEM *s = malloc(sizeof *s);
</code></pre>

<p>In this case remember to free the memory once done with your use:</p>

<pre><code>free(s);
</code></pre>
","9047316"
"Anroid: Binary XML file line Error inflating class","3801","","<p>I've been trying to load a list of records from a database to a screen but there seems to be a problem when the app gets the data and tries to display it on the screen. I read that sometimes this type of error is thrown when displaying large images and such but I have no images and tried some other solutions I've read about. Any input is appreciated!</p>

<pre><code>E/AndroidRuntime: FATAL EXCEPTION: main
  Process: com.blackfrogweb.macrotracker, PID: 16129
  android.view.InflateException: Binary XML file line 23: Binary XML file line 23: Error inflating class &lt;unknown&gt;
  at android.view.LayoutInflater.inflate(LayoutInflater.java:539)
  at android.view.LayoutInflater.inflate(LayoutInflater.java:423)
  at com.blackfrogweb.macrotracker.FavsCustomAdapter.getView(FavsCustomAdapter.java:38)
  at android.widget.AbsListView.obtainView(AbsListView.java:2346)
  at android.widget.ListView.makeAndAddView(ListView.java:1876)
  at android.widget.ListView.fillDown(ListView.java:702)
  at android.widget.ListView.fillFromTop(ListView.java:763)
  at android.widget.ListView.layoutChildren(ListView.java:1671)
  at android.widget.AbsListView.onLayout(AbsListView.java:2148)
  at android.view.View.layout(View.java:16636)
  at android.view.ViewGroup.layout(ViewGroup.java:5437)
  at android.widget.FrameLayout.layoutChildren(FrameLayout.java:336)
  at android.widget.FrameLayout.onLayout(FrameLayout.java:273)
  at android.view.View.layout(View.java:16636)
  at android.view.ViewGroup.layout(ViewGroup.java:5437)
  at android.widget.FrameLayout.layoutChildren(FrameLayout.java:336)
  at android.widget.FrameLayout.onLayout(FrameLayout.java:273)
  at android.view.View.layout(View.java:16636)
  at android.view.ViewGroup.layout(ViewGroup.java:5437)
  at android.widget.FrameLayout.layoutChildren(FrameLayout.java:336)
  at android.widget.FrameLayout.onLayout(FrameLayout.java:273)
  at android.view.View.layout(View.java:16636)
  at android.view.ViewGroup.layout(ViewGroup.java:5437)
  at android.widget.LinearLayout.setChildFrame(LinearLayout.java:1743)
  at android.widget.LinearLayout.layoutVertical(LinearLayout.java:1586)
  at android.widget.LinearLayout.onLayout(LinearLayout.java:1495)
  at android.view.View.layout(View.java:16636)
  at android.view.ViewGroup.layout(ViewGroup.java:5437)
  at android.widget.FrameLayout.layoutChildren(FrameLayout.java:336)
  at android.widget.FrameLayout.onLayout(FrameLayout.java:273)
  at com.android.internal.policy.PhoneWindow$DecorView.onLayout(PhoneWindow.java:2678)
  at android.view.View.layout(View.java:16636)
  at android.view.ViewGroup.layout(ViewGroup.java:5437)
  at android.view.ViewRootImpl.performLayout(ViewRootImpl.java:2171)
  at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:1931)
  at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1107)
  at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:6013)
  at android.view.Choreographer$CallbackRecord.run(Choreographer.java:858)
  at android.view.Choreographer.doCallbacks(Choreographer.java:670)
  at android.view.Choreographer.doFrame(Choreographer.java:606)
  at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:844)
  at android.os.Handler.handleCallback(Handler.java:739)
  at android.os.Handler.dispatchMessage(Handler.java:95)
  at android.os.Looper.loop(Looper.java:148)
  at android.app.ActivityThread.main(ActivityThread.java:5417)
  at java.lang.reflect.Method.invoke(Native Method)
  at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726)
       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)
</code></pre>

<p>Here is the xml of the layout Im trying to ""inflate"".</p>

<pre><code>&lt;LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
    android:orientation=""vertical""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    android:paddingBottom=""16dp""
    android:paddingTop=""16dp""
    android:paddingLeft=""@dimen/activity_horizontal_margin""
    android:paddingRight=""@dimen/activity_horizontal_margin""
    android:gravity=""left""&gt;

    &lt;LinearLayout
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        android:orientation=""horizontal""&gt;

        &lt;LinearLayout
            android:layout_width=""0dp""
            android:layout_height=""wrap_content""
            android:layout_weight=""1""
            android:orientation=""vertical""&gt;

            &lt;TextView
                android:id=""@+id/favorite_name""
                android:textColor=""@color/colorText""
                android:textSize=""?android:attr/textAppearanceMedium""
                android:layout_width=""match_parent""
                android:layout_height=""wrap_content""
                android:layout_marginBottom=""5dp""/&gt;

            &lt;TextView
                android:id=""@+id/favorite_cal""
                android:textSize=""?android:attr/textAppearanceMedium""
                android:textColor=""@color/colorText""
                android:layout_width=""match_parent""
                android:layout_height=""wrap_content""
                android:layout_marginBottom=""5dp""/&gt;

            &lt;TextView
                android:id=""@+id/favorite_fat""
                android:textSize=""?android:attr/textAppearanceMedium""
                android:textColor=""@color/colorText""
                android:layout_width=""match_parent""
                android:layout_height=""wrap_content""
                android:layout_gravity=""left""
                android:layout_marginBottom=""5dp""/&gt;

            &lt;TextView
                android:id=""@+id/favorite_carb""
                android:textSize=""?android:attr/textAppearanceMedium""
                android:textColor=""@color/colorText""
                android:layout_width=""match_parent""
                android:layout_height=""wrap_content""
                android:layout_gravity=""left""
                android:layout_marginBottom=""5dp""/&gt;

            &lt;TextView
                android:id=""@+id/favorite_prot""
                android:textSize=""?android:attr/textAppearanceMedium""
                android:textColor=""@color/colorText""
                android:layout_width=""match_parent""
                android:layout_height=""wrap_content""
                android:layout_gravity=""left""
                android:layout_marginBottom=""5dp""/&gt;

        &lt;/LinearLayout&gt;

            &lt;LinearLayout
                android:layout_width=""0dp""
                android:layout_height=""wrap_content""
                android:layout_weight=""1""
                android:orientation=""horizontal""
                android:gravity=""right""&gt;

                &lt;Button
                    android:id=""@+id/add""
                    android:layout_width=""40dp""
                    android:layout_height=""40dp""
                    android:layout_marginRight=""5dp""
                    android:background=""@android:drawable/ic_menu_add""/&gt;

                &lt;Button
                    android:id=""@+id/edit""
                    android:layout_width=""40dp""
                    android:layout_height=""40dp""
                    android:layout_marginRight=""5dp""
                    android:background=""@android:drawable/ic_menu_edit""/&gt;

                &lt;Button
                    android:id=""@+id/delete""
                    android:layout_width=""40dp""
                    android:layout_height=""40dp""
                    android:background=""@android:drawable/ic_menu_delete""/&gt;
            &lt;/LinearLayout&gt;
    &lt;/LinearLayout&gt;
</code></pre>

<p>Since I'm not really sure where the error is happening, I'm not sure what piece of code to post -and I don't want to make this unreadable.</p>
","<p>Currenty you are setting <code>?android:attr/textAppearanceMedium</code> to <code>android:textSize</code>.<br>
You should replace the attribute with  <code>android:textAppearance</code>.</p>

<blockquote>
  <p>Change </p>

<pre><code>android:textSize=""?android:attr/textAppearanceMedium"" 
</code></pre>
  
  <p>TO </p>

<pre><code>android:textAppearance=""?android:attr/textAppearanceMedium""
</code></pre>
</blockquote>

<p>OR</p>

<p>Set direct value to <code>android:textSize</code>like</p>

<pre><code>android:textSize=""10sp"" 
</code></pre>
","41628456"
"extract a stored png image from a binary file the right way","3797","","<p>I have binary files which contain each one PNG file at a time (the binary file is not a DLL, not a EXE, nothing usual, just a file which contains different textual information, a PNG file and some other stuff. The format of the file is unknown to me. The PNG file is displayable with a program which does this kind of files). I have not the source of this program which does these files.
My task is now to extract this PNG file out of the binary file for displaying it or saving it as PNG. I wrote a code which works on some of these files (let's say about 50% of the files), but on anothers not. On the not working files the program which created this files can still display the containing image, so the image is inside of every file surely valid - but anyway my code doesn't work on some of the files.</p>

<p>Some images seem to have maybe another format, maybe encoding type (I tried already all different encoding types, nothing succeeded). Here is my code (I hope someone can tell me what to change that the image becomes readable always).</p>

<p>What does my code: It finds the know starting string of the PNG image ""‰PNG"" and the known ending string ""IEND®B`‚"". This strings are in any of my binary files containing the PNG's the same.
Then my code takes the string between start and end + the start and the end sequence and saves it
to a file with Encoding.Default. Most by this way extracted PNG files can be displayed with an Image Viewer, but around 50% are invalid. The image looks okay if I open it with an editor and compare the characters to a working image. Sofar I have no clue which symbol is the reason for the wrong image format.</p>

<p>If needs I'll provide more information, here my code:</p>

<pre><code>private void button2_Click(object sender, EventArgs e)
    {
        string ReadFile1 = Path.Combine(Environment.GetFolderPath(Environment.SpecialFolder.DesktopDirectory), ""file.dat"");
        string WriteFile1 = Path.Combine(Environment.GetFolderPath(Environment.SpecialFolder.DesktopDirectory), ""test.png"");
        string TMP = File.ReadAllText(Path.Combine(Environment.GetFolderPath(Environment.SpecialFolder.DesktopDirectory), ReadFile1), Encoding.Default); //System.Text.Encoding.GetEncoding(1251)
        int start1 = TMP.IndexOf(""PNG"", 0 ,StringComparison.Ordinal);
        if (start1 == 0) { return; }
        int end1 = TMP.IndexOf(""IEND"", StringComparison.Ordinal);
        string PNG = TMP.Substring(start1 - 1, (end1 + 9) - start1);
        File.WriteAllText(Path.Combine(Environment.GetFolderPath(Environment.SpecialFolder.DesktopDirectory), ""test.png""), PNG, Encoding.Default);
    }
</code></pre>

<p>I also thought first of getting the PNG with a binary method and used this code,
but I had exactly the same results then with just reading the string. Here my earlier
code. I seeked the position in the byte array using the string to compare.
I had no luck with the binary code...</p>

<pre><code> byte[] by;
        // 1.
        // Open file with a BinaryReader.
        using (BinaryReader b = new BinaryReader(File.Open(ReadFile1, FileMode.Open), Encoding.Default))
        {
            // 2.
            // Variables for our position.
            int pos = start1 - 1;           //I determine the right positions before doing this
            int required = (end1 + 9) - start1; 

            // 3.
            // Seek to our required position.
            b.BaseStream.Seek(pos, SeekOrigin.Begin);

            // 4.
            // Read the next 2000 bytes.
            by = b.ReadBytes(required);
            b.Close();
        }

        FileStream writeStream;
        writeStream = new FileStream(WriteFile1, FileMode.Create);
        BinaryWriter writeBinay = new BinaryWriter(writeStream, Encoding.Default);
        writeBinay.Write(by);
        writeBinay.Close(); */
</code></pre>
","<p>PNG files are binary. If you read them using some encoding, you'll loose information and the output of your program is not a valid PNG file any more. Refer to <a href=""https://stackoverflow.com/questions/723392/using-chunks-in-a-png"">Using Chunks in a PNG</a> for more explanation and code samples.</p>

<p>Also read <a href=""http://www.w3.org/TR/PNG-Structure.html"" rel=""nofollow noreferrer"">PNG Specifiaction: File structure</a> for detailed information.</p>
","11487798"
"Bitwise operations in BC?","3795","","<pre><code>$ bc
BC&gt; ibase=2
BC&gt; 110&amp;101                     // wanna get 100
(standar_in) 8: syntax error
</code></pre>

<p><a href=""http://en.wikipedia.org/wiki/Bc_programming_language"" rel=""nofollow noreferrer"">Wikipedia</a> informs that the ops are ""|, &amp; and ^"". It may be that they work only in certain BC-types or I misread something.</p>
","<p>Those operators are listed in the section <a href=""http://en.wikipedia.org/wiki/Bc_programming_language#.27Missing.27_operators_relative_to_C"" rel=""nofollow noreferrer"">'Missing' operators relative to C</a>, which ends with ""... are not available in POSIX bc""</p>
","2954019"
"How to convert a MIPS string of number to Hexadecimal","3781","","<p>I am starting to write a MIPS program where I get a String in hexadecimal representation say A23B , and want to put it together into 1 Entire hex number. I am really lost in the part as how to extract say one Digit , say B and convert it into hex for mips then fetch the other one. I am not looking for an entire program as I know this is not what it is for but as something to start with as I am really lost, thank you.</p>
","<p>Consider this. Say your data segment looks like this</p>

<pre><code>.data
str: .space 5 #enough room for a 4 digit hex number
</code></pre>

<p>And further, that the memory pointed to by <code>str</code> contains the string you want to convert to a number. To get its first byte into <code>$t1</code>, you would use:</p>

<pre><code>la $t0 str
lb $t1 0($t0)
</code></pre>

<p>Next, there are four cases:</p>

<ol>
<li><code>'0' &lt; $t1 &lt; '9'</code></li>
<li><code>'a' &lt; $t1 &lt; 'f'</code></li>
<li><code>'A' &lt; $t1 &lt; 'F'</code></li>
<li>Error </li>
</ol>

<p>I'll assume you know how to check these cases.</p>

<p>In all but the last case, we must increment sum by the given value; therefore the next step for the cases would be:</p>

<ol>
<li><code>sum += $t1 - '0'</code></li>
<li><code>sum += $t1 - 'a' + 10</code></li>
<li><code>sum += $t1 - 'A' + 10</code></li>
</ol>

<p>Obviously this is pseudo-code, but it illustrates the main point that the ASCII values for the digits and letters are sequential, so calculating their value is trivial.</p>

<p>Lastly, because we know that each digit represents exactly 4 bits, and because we begin reading from left to right, we must shift the sum left by 4 bits:</p>

<pre><code>sll $sum $sum 4
</code></pre>

<p>That is the steps for one character, to convert an entire string you would need to loop over each character.</p>
","20205423"
"Reading multiple precision binary files through fread in Matlab","3773","","<p>I have a huge binary file which has records with multiple precision as {'Double','Double',
'Int32','Int8','Char'}. I have used memmapfile to read in the data but its painfully slow to read in the data. Is there a way to read the whole file through fread?</p>
","<p>You can use the <code>'skip'</code> option of the <a href=""http://www.mathworks.com/help/techdoc/ref/fread.html#inputarg_skip"" rel=""noreferrer"">FREAD</a> function as well as <a href=""http://www.mathworks.com/help/techdoc/ref/fseek.html"" rel=""noreferrer"">FSEEK</a> to read the records one ""column"" at-a-time:</p>

<pre><code>%# type and size in byte of the record fields
recordType = {'double' 'double' 'int32' 'int8' 'char'};
recordLen = [8 8 4 1 1];
R = cell(1,numel(recordType));

%# read column-by-column
fid = fopen('file.bin','rb');
for i=1:numel(recordType)
    %# seek to the first field of the first record
    fseek(fid, sum(recordLen(1:i-1)), 'bof');

    %# % read column with specified format, skipping required number of bytes
    R{i} = fread(fid, Inf, ['*' recordType{i}], sum(recordLen)-recordLen(i));
end
fclose(fid);
</code></pre>

<p>This code should work for any binary records file in general, you just have to specify the data types and byte length of the records fields. The result will be returned in a cell array containing the columns.</p>
","8108683"
"Need explanation of reading and writing of wchar_t* to binary file","3772","","<p>can someone explain me what is a proper way to write wchar_t* string to binary file and then read it back(using fread/fwrite)?</p>

<p>here is what i have (its working)</p>

<pre><code>struct someStruct{
    int someint;
    wchar_t* data;
    int someint2;
}
someStruct s;
s.someint = 111;
s.data = L""blah blah .... lets say 1-1000 characters long"";
s.someint2 = 222;

//writing
FILE * f = _wfopen(L""myfile"",L""wb"");
fwrite(&amp;(s.someint), sizeof(int), 1, f);
fwrite(&amp;(s.data), sizeof(wchar*), 1, f);
fwrite(&amp;(s.someint2), sizeof(int), 1, f);
fclose(f);

//reading
FILE * f2 = _wfopen(L""myfile"",L""rb"");
fread(&amp;(s2.someint), sizeof(int), 1, f2);
fread(&amp;(s2.data), sizeof(wchar*), 1, f2);
fread(&amp;(s2.someint2), sizeof(int), 1, f2);
fclose(f2);
</code></pre>

<p>everything is working, values are properly loaded. <strong>the question is what should be the second parameter of fread and fwrite in this specific example</strong>, why is it working with e.g. 4(which is sizeof(wchar_t*)) or 20 and causing buffer overrun with 150, these values vary based on data length, </p>

<p>EDIT: these are what i have been using (was working last time i checked it :P 1 year ago):</p>

<pre><code>wchar_t* loadStrFromFile(FILE* file) {
    int strLen;
    fread(&amp;(strLen), sizeof(int), 1, file);
    wchar_t* result = new wchar_t[strLen];
    fread(result, strLen, sizeof(wchar_t), file);
    return result;
}

void saveStrToFile(const wchar_t*&amp; data, FILE* file) {
    int strLen = wcslen(data)+1;
    fwrite(&amp;strLen, sizeof(int), 1, file);
    fwrite(data, strLen, sizeof(wchar_t), file);
}
</code></pre>
","<p>This is particularly wrong:</p>

<pre><code>fwrite(&amp;(s.data), sizeof(wchar*), 1, f);
</code></pre>

<p>This would only write sizeof(wchar*) = 4 or 8 bytes.</p>

<p>Oh yes, and you probably don't want to write a pointer. Missed that one.</p>

<p>If you want to write an actual string data (assuming you're on Windows):</p>

<pre><code>size_t len = wcslen(s.data); //get the number of characters
fwrite(s.data, len, sizeof(wchar_t), f);
</code></pre>
","6975159"
"How to Convert Binary String into Array Of Integer Bit using Excel VBA","3764","","<p>I'm having hardstop with this problem to solve in my Excel macro coding. My input data is a binary string '1110'. Need to extract the binary string and return each bit of binary in sequence into array (as integer bit). Pls help me...really appreciate help for coaching.</p>

<p>For each bit = 1, the array value for that bit = Power of 2. At the end, add up all the value. Example:</p>

<p>Input = 1110 (binary string) store into Array (i). i = 3 (total bit from input =4)</p>

<pre><code>Array (0) = 1^2 to the pwr of 0 = 1
Array (1) = 1^2 to the pwr of 1 = 2
Array (2) = 1^2 to the pwr of 2 = 4
Array (3) = 1^2 to the pwr of 3 = 8
</code></pre>

<p>The final output to be returned is summation of all the array list.In this case, it'll be 15</p>
","<p>From the top of my head without testing this will get you close.</p>

<pre><code>Dim bin as String

bin=""1101""

Dim bits(Len(bin)) as Integer

Dim bitIndex as Integer

Dim sum as Integer
sum = 0
For bitIndex = 0 to Len(bin)-1
  bits(bitIndex) = CInt(Mid(bin,bitIndex+1, 1)) * (2 ^ bitIndex)
  Debug.Print bits(bitIndex)
  sum = sum + bits(bitIndex) 
Next

Debug.Print sum
</code></pre>
","5288569"
"How to send a push notification using Erlang?","3760","","<p>I'm trying to send a push notification to APNs using Erlang.
This is the code I came up with so far:</p>

<pre><code>-module(apnstest2).
-export([connect/0]).

connect() -&gt;
    application:start(ssl),
    ssl:seed(""someseedstring""),
    Address = ""gateway.sandbox.push.apple.com"",
    Port = 2195,
    Cert = ""/path/to/Certificate.pem"",
    Key = ""/path/to/Key.unenc.pem"",
    Options = [{certfile, Cert}, {keyfile, Key}, {mode, binary}],
    Timeout = 1000,
    {ok, Socket} = ssl:connect(Address, Port, Options, Timeout),

    Token = ""195ec05a962b24954693c0b638b6216579a0d1d74b3e1c6f534c6f8fd0d50d03"",
    Payload = ""{\""aps\"":{\""alert\"":\""Just testing.\"",\""sound\"":\""chime\"", \""badge\"":10}}"",
    TokenLength = length(Token),
    PayloadLength = length(Payload),

    Packet = [&lt;&lt;0:8, TokenLength, Token, PayloadLength, Payload&gt;&gt;],

    ssl:send(Socket, list_to_binary(Packet)),
    ssl:close(Socket).
</code></pre>

<p>The code doesn't take advantage of Erlang's concurrency but is just a prototype. I only want to test if I can send the push in the most simple way.</p>

<p>I think the problem is in the packet being sent to the APNs.
This is the binary format of a push notification:</p>

<p><a href=""http://developer.apple.com/IPhone/library/documentation/NetworkingInternet/Conceptual/RemoteNotificationsPG/Art/aps_provider_binary.jpg"">alt text http://developer.apple.com/IPhone/library/documentation/NetworkingInternet/Conceptual/RemoteNotificationsPG/Art/aps_provider_binary.jpg</a></p>

<p>How should I create such a packet in Erlang?
Could someone please take a look at my code and tell me where the problem is?<br />
Also I used Erlang's SSL application to create the connection and send the data and I don't know if this is the problem or the packet.<br />
Thanks!</p>
","<p>To start with, there is no need for creating a list of a single binary and then calling <code>list_to_binary/1</code> on it. You can just send the binary itself.</p>

<p>Also, make sure the field lengths and values are appropriate according to the protocol:</p>

<pre><code>TokenLength = 32 = length(Token),
Packet = &lt;&lt;0:8, TokenLength:16/big, Token, PayloadLength:16/big, Payload&gt;&gt;,
ssl:send(Socket, Packet),
</code></pre>

<p>Now that we have gotten this far, we will see that length(Token) is in fact 64, not 32:
You forgot to convert the hex string for Token to a binary, so you are sending a 64 byte hex character string instead of 32 binary bytes.</p>

<p>So... making Payload a binary from the start, and making Token a numeric constant, you can do something like the following:</p>

<pre><code>Payload = &lt;&lt;""{\""aps\"":{\""alert\"":\""Just testing.\"",\""sound\"":\""chime\"", \""badge\"":10}}""&gt;&gt;,
PayloadLength = size(Payload),
Packet = &lt;&lt;0:8, 32:16/big,
          16#195ec05a962b24954693c0b638b6216579a0d1d74b3e1c6f534c6f8fd0d50d03:256/big,
          PayloadLength:16/big, Payload/binary&gt;&gt;,
ssl:send(Socket, Packet),
</code></pre>

<p>Thanks to <a href=""https://stackoverflow.com/users/141420/christian"">Christian</a> for pointing out a number of mistakes in the former revisions of this answer.</p>
","1757293"
"http content type, and binary data","3755","","<p>I thought I knew this already but now I'm not sure: Is all content sent over http always encoded to character data? ie, if my content type is a binary file type, is it always converted to binhex, or is it possible to send ""actual"" binary data across the wire? </p>
","<p>In HTTP there is no content transfer encoding (e.g. base64) done, so binary data is sent just binary, byte-by-byte.</p>
","4180577"
"Reading a file into a binary array in c++","3753","","<p>I have got a file that contains data for multiple jpegs (along with some garbage), i need to extract binary from this file, filter out the garbage and create jpegs. I know the starting binary sequence of the jpegs.</p>

<pre><code>char buffer[30];
ifstream fin;
fin.open (""FILENAME.raw"", ios::in | ios::binary);
while (!fin.eof())
{
    fin.read(buffer,30);
    cout&lt;&lt;buffer[2]&lt;&lt;endl;
}
fin.close();
</code></pre>

<p>Here i am trying to print the file in binary but, when i run this code, alien characters are printed on the screen.</p>
","<p>I think problem here was ""cout &lt;&lt; buffer[2]"" which was converting your binary information to charecters. Try int cast before , also you should use a static ""unsigned char array""
because binary data can be unsigned .That will work : </p>

<pre><code>unsigned char buffer[ 30 ];
ifstream fin;
fin.open (""FILENAME.raw"", ios::in | ios::binary);
while (!fin.eof())
{

    fin.read( (char*)( &amp;buffer[0] ), 30 ) ;
    cout &lt;&lt; (int)buffer[2] &lt;&lt; "" "";
}
fin.close();
return 0;
</code></pre>

<p>Also if you want to traverse the binary why you are just printing buffer[2].</p>
","13026822"
"dynamic array pointer to binary file","3751","","<p>Know this might be rather basic, but I been trying to figure out how to one after create a dynamic array such as </p>

<pre><code>double* data = new double[size];
</code></pre>

<p>be used as a source of data to be kept in to a binary file such as</p>

<pre><code>ofstream fs(""data.bin"",ios:binary"");
fs.write(reinterpret_cast&lt;const char *&gt; (data),size*sizeof(double));
</code></pre>

<p>When I finish writing, I attempt to read the file through</p>

<pre><code>double* data = new double[size];
ifstream fs(""data.bin"",ios:binary"");
fs.read(reinterpret_cast&lt;char*&gt; (data),size*sizeof(double));
</code></pre>

<p>However I seem to encounter a run time error when reading the data. Do you guys have any advice how i should attempt to write a dynamic array using pointers passed from other methods to be stored in binary files?</p>
","<ol>
<li>Hy:)</li>
</ol>

<blockquote>
<pre><code>If you use Unix you have some functions:    int read(int fd, void
</code></pre>
  
  <p>*buf, int count);.   int write (int fd, void *buf, int nbytes);.</p>
</blockquote>

<pre><code>The functions are verry fast because
are kernel-functions.

i run your code and everything was
ok : 

      1 #include &lt;iostream&gt;
      2 #include &lt;fstream&gt;
      3 #include &lt;cstring&gt;
      4 using namespace std;
      5 
      6 int main()
      7 {
      8     double * s;
      9     int ns = 10;                    //information
     10     s = new double[ns];
     11 
     12     for (int i = 0 ; i &lt; ns ; ++i)
     13         s[i] = 17*i + 23;           // i put my information here
     14 
     15     ofstream os(""data.txt"", ios::binary);
     16     os.write(reinterpret_cast&lt;const char*&gt; (s), sizeof(double) * ns);
     17     os.close();
     18 
     19     double * final;
     20     final = new double[ns];
     21 
     22     ifstream is(""data.txt"", ios::binary);
     23     is.read(reinterpret_cast&lt;char *&gt;(final), sizeof(double) * ns);
     24     is.close();
     25 
     26     for (int i=0; i &lt; ns; ++i)
     27         cout&lt;&lt;s[i]&lt;&lt;"" ""&lt;&lt;final[i]&lt;&lt;""\n"";
     28 
     29     return 0;
     30 }

~            
</code></pre>

<blockquote>
<pre><code>none@Brusture:~/Desktop$ g++ -o test
test.cpp  none@Brusture:~/Desktop$
./test  23 23 40 40 57 57 74 74 91
91 108 108 125 125 142 142 159 159
176 176
</code></pre>
</blockquote>
","2442283"
"From string to ASCII to binary back to ASCII to string in Java","3741","","<p>I have sort of a funky question (that I hope hasn't been asked and answered yet). To start, I'll tell you the order of what I'm trying to do and how I'm doing it and then tell you where I'm having a problem:</p>

<ol>
<li>Convert a string of characters into ASCII numbers</li>
<li>Convert those ASCII numbers into binary and store them in a string</li>
<li>Convert those binary numbers back into ASCII numbers</li>
<li>Convert the ASCII numbers back into normal characters</li>
</ol>

<p>Here are the methods I've written so far:</p>

<pre><code>public static String strToBinary(String inputString){

    int[] ASCIIHolder = new int[inputString.length()];

    //Storing ASCII representation of characters in array of ints
    for(int index = 0; index &lt; inputString.length(); index++){
        ASCIIHolder[index] = (int)inputString.charAt(index);
    }


    StringBuffer binaryStringBuffer = new StringBuffer();

    /* Now appending values of ASCIIHolder to binaryStringBuffer using
     * Integer.toBinaryString in a for loop. Should not get an out of bounds
     * exception because more than 1 element will be added to StringBuffer
     * each iteration.
     */
    for(int index =0;index &lt;inputString.length();index ++){

        binaryStringBuffer.append(Integer.toBinaryString
                (ASCIIHolder[index]));
    }


    String binaryToBeReturned = binaryStringBuffer.toString();

    binaryToBeReturned.replace("" "", """");

    return binaryToBeReturned;
}

public static String binaryToString(String binaryString){

    int charCode = Integer.parseInt(binaryString, 2);

    String returnString = new Character((char)charCode).toString();

    return returnString;
}
</code></pre>

<p>I'm getting a NumberFormatException when I run the code and I think it's because the program is trying to convert the binary digits as one entire binary number rather than as separate letters. Based on what you see here, is there a better way to do this overall and/or how can I tell the computer to recognize the ASCII characters when it's iterating through the binary code? Hope that's clear and if not I'll be checking for comments.</p>
","<p>You've got <em>at least two</em> problems here:</p>

<ul>
<li>You're just concatenating the binary strings, with no separators. So if you had ""1100"" and then ""0011"" you'd get ""11000011"" which is the same result as if you had ""1"" followed by ""1000011"".</li>
<li>You're calling <code>String.replace</code> and ignoring the return result. This sort of doesn't matter as you're replacing spaces, and there won't be any spaces anyway... but there <em>should</em> be!</li>
</ul>

<p>Of course you don't <em>have</em> to use separators - but if you don't, you need to make sure that you include all 16 bits of each UTF-16 code point. (Or validate that your string only uses a limited range of characters and go down to an appropriate number of bits, e.g. 8 bits for ISO-8859-1 or 7 bits for ASCII.)</p>

<p>(I have to wonder what the point of all of this is. Homework? I can't see this being useful in real life.)</p>
","11812159"
"C++ write binary file. uchar* data from opencv matrices","3737","","<p>I have some data, n elements, uchar* data_ptr. How would I write this to a binary file and read it again later?</p>

<p>I tried the following :</p>

<pre><code>std::ofstream myFile (""data.bin"", std::ios::out | std::ios::binary);
myFile.write(data_ptr,100); 
</code></pre>

<p>Above won't compile. uchar not being char. </p>

<p>How do I write it. And how to I read it into a memory chunk of uchar* again.</p>

<p>I did the following test:</p>

<pre><code>cv::Mat test(10,10,CV_8UC1);
cv::randu(test,0,255);
std::cout &lt;&lt; test &lt;&lt; std::endl;
assert(test.isContinuous());

std::ofstream myFile1 (""data1.bin"", std::ios::out | std::ios::binary);
myFile1.write(reinterpret_cast&lt;char*&gt;(test.data),sizeof(uchar)*100);

uchar buf[100];
std::ifstream myFile (""data1.bin"", std::ios::in | std::ios::binary);
myFile.read(reinterpret_cast&lt;char*&gt;(buf), sizeof(buf));
cv::Mat test1(10,10,CV_8UC1,buf);
std::cout &lt;&lt; test1 &lt;&lt; std::endl;

cv::waitKey();
</code></pre>

<p>And got the following output:</p>

<pre><code>[91, 2, 79, 179, 52, 205, 236, 8, 181, 239;
  26, 248, 207, 218, 45, 183, 158, 101, 102, 18;
  118, 68, 210, 139, 198, 207, 211, 181, 162, 197;
  191, 196, 40, 7, 243, 230, 45, 6, 48, 173;
  242, 125, 175, 90, 63, 90, 22, 112, 221, 167;
  224, 113, 208, 123, 214, 35, 229, 6, 143, 138;
  98, 81, 118, 187, 167, 140, 218, 178, 23, 43;
  133, 154, 150, 76, 101, 8, 38, 238, 84, 47;
  7, 117, 246, 163, 237, 69, 129, 60, 101, 41;
  190, 50, 90, 72, 168, 109, 121, 220, 114, 248]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
  0, 0, 0, 0, 0, 0, 127, 2, 0, 0;
  32, 0, 0, 0, 255, 255, 0, 0, 178, 116;
  36, 101, 35, 0, 28, 5, 248, 227, 87, 0;
  43, 0, 0, 0, 0, 0, 0, 0, 0, 0;
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
  0, 0, 205, 18, 246, 118, 251, 10, 251, 118]
</code></pre>

<p>Clearly the two matrices are not the same. Any comment on where it went wrong?</p>
","<p>To write, you can simply cast the data to <code>char*</code>:</p>

<pre><code>file.write(reinterpret_cast&lt;char*&gt;(data_ptr), 100); // writes 100 bytes
</code></pre>

<p>To read, you need an <code>istream</code> and again a cast is required:</p>

<pre><code>uchar buf[100];
input.read(reinterpret_cast&lt;char*&gt;(buf), sizeof(buf));
</code></pre>
","9417743"
"Buffers, sockets. node.js","3733","","<p>I'm trying to utilise TCP sockets in Node.js to communicate with a Lua program. There are two issues I'm trying to get my head around. Firstly buffers.</p>

<p><b>Buffers</b> As I understand it, when data is provided to your code from the socket, it will be whatever data has been received so far (a stream rather than packets). So when you read the data received, it may be broken from what was sent.</p>

<p>i.e. data received
{ schools : [""Long</p>

<p>vs data sent
{ schools : [{""Longwood"", ""Hillbrow""}] }</p>

<p>The way to get around this is to put your data into a 'buffer' and split it by whatever method you use to show the end of that piece of information. Commonly appears to be new line.</p>

<p>My questions here:</p>

<ol>
<li>Can you end up with more 2 or more complete sections of data in the buffer, how would you handle this? For loop?</li>
<li>The same issue appears to be present with data leaving the socket. I have noticed however in other code examples, people use the Node.js <a href=""http://nodejs.org/api/buffer.html"" rel=""nofollow"">Buffer</a> before writing to the socket. Why is this not used for incoming data?</li>
<li>If more data is written than can be handled to leave, does Node handle this for you or do you need to come up with a method.</li>
</ol>

<p>Finally I seem to be misunderstanding the data side. Does all data sent and received need to be converted to binary and back? I wish to send JSON data back and forth only. I think there in lies my confusion. For example:</p>

<pre><code>var myQuestion = ""Is this acceptable and will I encounter any issues?
socket.write(myQuestion);
</code></pre>

<p>Many thanks for your time.</p>
","<ol>
<li>Yes, you could definitely end up with several sections of data. It entirely depends on the code you write on either end. </li>
<li>I don't quite follow what you mean by ""use the buffer before writing"". Buffers are just pure binary data, they are used for both incoming and outgoing data. Node also generally accepts strings for sending, and assumes they are UTF8 if no encoding is given. You can also get strings when receiving if you call <code>setEncoding</code>.</li>
<li>The OS has buffers for incoming data on the TCP socket, and when the buffer is full (being emptied too slowly by node), it will stop accepting packets until there is space.</li>
</ol>

<p>First off, <code>Buffer</code> is binary. A buffer is simply an array of bytes, and nothing more. Buffers can be created from strings, and node will do this automatically in some cases. In your case, I would recommend that you call <code>socket.setEncoding('utf8')</code>. That will automatically convert incoming data into a string to simplify your parsing.</p>

<p>As far as processing and splitting the data, it is up to you. TCP only provides a stream of bytes arriving in the same order they were send. As you said, you can gather up the bytes and when a newline is received, you take everything before that and parse it as JSON. This should work fine. You can use any character that wouldn't pop up inside JSON. As long as the programs doing the JSON serialization do not add newlines, then you are set. As 'data' is emitted, you can check the string for newline, and if not, then add it to any previously received data, and if you find it, then split it up, add the existing data.</p>
","14094303"
"Convert 64bit Binary to Long equivalent","3733","","<p>How can we convert the following 64 bit binary into the long equivalent; </p>

<pre><code>01111101 10100011 01001111 11111111 11111111 11111111 11111111 11000000  
equals 7D A3 4F FF FF FF FF C0 HEX  
equals 9053167636875050944    &lt;&lt; this is the value we want in a C# variable 
</code></pre>

<p>EDIT: The large binary number is currently stored as a String. So its a string to long conversion that I am looking for.</p>
","<p>Here you go:
<a href=""http://msdn.microsoft.com/en-us/library/system.convert.toint64.aspx"" rel=""noreferrer"">http://msdn.microsoft.com/en-us/library/system.convert.toint64.aspx</a></p>

<p>And examples here: <a href=""http://www.csharphelp.com/2007/09/converting-between-binary-and-decimal-in-c/"" rel=""noreferrer"">http://www.csharphelp.com/2007/09/converting-between-binary-and-decimal-in-c/</a></p>

<p>Specifically (where bin is a 'binary' string):</p>

<pre><code>long l = Convert.ToInt64(bin,2);
</code></pre>
","2684037"
"C decimal to binary without arrays","3729","","<p>I think I've almost got it, but I feel like I'm go in circles trying to figure this out.
The challenge to out cout without using strings or arrays. I took the number 56 as an example and 56 should equal 111000 this is not the case as it goes through fine till 7 then the number equals number*2 + number%2 makes it equal to 15 and outputs all 1's. Idk anymore, this is driving me to the moon and back.</p>

<pre><code>#include &lt;iostream&gt;

using namespace std;

int main()
{
int number = 0;
int n = 1;
int x = n;
cin&gt;&gt;number;
cout&lt;&lt;n%2;
while(n &lt;= number)
{
    if(n%2 == 0)
    {
        n = n*2;
        cout&lt;&lt;0;
    }
    else
    {
        n = n*2 + n%2;
        cout&lt;&lt;n%2;
    }
}
}
</code></pre>
","<p>You can use the binary operator &amp; to check if a single bit is 1 or 0.</p>

<pre><code>for (int i=512; i&gt;0; i/=2) {
    cout &lt;&lt; ( ( number &amp; i ) != 0 ) ;
}
</code></pre>

<p>Note that this WILL print leading 0's.
Also, I'm assuming you only want to print positive integers.</p>

<p>Alternative:</p>

<pre><code>for (int i=512; i&gt;0; i/=2) {
    if (number &gt;= i) {
        cout &lt;&lt; 1;
        number -= i;
    } else {
        count &lt;&lt; 0;
    }
}
</code></pre>
","16621263"
"How to create a binary vector with 1 if elements are part of the same vector?","3728","","<p>I would like to create a so-called matching vector consisting of binaries. All numbers should be zero unless elements belong to the same variable.</p>

<p>Here's an example:</p>

<pre><code>dataset=(""a"",""b"",""c"",""d"",""x"",""y"",""z"")
var1=c(""a"",""b"",""y"",""z"")
var2=c(""c"",""d"",""x"")
</code></pre>

<p>Thus, I have a dataset with all the variables in the first line. Now I create two groups: var1 and var2.</p>

<p>The matching vector for the element ""a"" is supposed to look like:</p>

<pre><code>matching_a=c(1,1,0,0,0,1,1)
</code></pre>

<p>The numbers correspond to my dataset. If the variables in my dataset are in the same group, there should be a 1 in my matching vector, and a 0 otherwise.</p>

<p>However, my actual data set is too big to do it manually. Does anyone understand what I wanna do?</p>
","<p>Using <code>ifelse</code> function and <code>%in%</code> operator.</p>

<pre><code>matching_a &lt;-  ifelse(dataset %in% var1, 1, 0)

matching_a
# [1] 1 1 0 0 0 1 1
</code></pre>
","8021665"
"C++ string array binary search","3726","","<pre><code>string Haystack[] =  { ""Alabama"", ""Alaska"", ""American Samoa"", ""Arizona"", ""Arkansas"", ""California"", ""Colorado"", ""Connecticut"", ""Delaware"", ""District of Columbia"",
                 ""Florida"", ""Georgia"", ""Guam"", ""Hawaii"", ""Idaho"", ""Illinois"", ""Indiana"", ""Iowa"", ""Kansas"", ""Kentucky"", 
                 ""Louisiana"", ""Maine"", ""Maryland"", ""Massachusetts"", ""Michigan"", ""Minnesota"", ""Mississippi"", ""Missouri"", ""Montana"", ""Nebraska"", 
                 ""Nevada"", ""New Hampshire"", ""New Jersey"", ""New Mexico"", ""New York"", ""North Carolina"", ""North Dakota"", ""Northern Mariana Islands"", ""Ohio"", ""Oklahoma"",
                 ""Oregon"", ""Pennsylvania"", ""Puerto Rico"",  ""Rhode Island"", ""South Carolina"", ""South Dakota"", ""Tennessee"", ""Texas"", ""US Virgin Islands"", ""Utah"",
                 ""Vermont"", ""Virginia"", ""Washington"", ""West Virginia"", ""Wisconsin"", ""Wyoming""};

 string Needle = ""Virginia"";

 if(std::binary_search(Haystack, Haystack+56, Needle))
      cout&lt;&lt;""Found"";
</code></pre>

<p>If I also wanted to find the location of the needle in the string array, is there an ""easy"" way to find out?</p>
","<p>From the <a href=""http://www.sgi.com/tech/stl/binary_search.html"" rel=""nofollow noreferrer"">SGI docs</a>:</p>

<blockquote>
  <p>Note that this is not necessarily the information you are interested in! Usually, if you're testing whether an element is present in a range, you'd like to know where it is (if it's present), or where it should be inserted (if it's not present). The functions <code>lower_bound</code>, <code>upper_bound</code>, and <code>equal_range</code> provide this information. </p>
</blockquote>

<p>I think the reasoning behind this set of interfaces is that <code>binary_search</code> doesn't really indicate whether it'll return the start of the range of matches (assuming there are matches) or the end of the range, and you might want one or the other depending on whether you want to do something with data already in the container or add a new item (possibly to the end of the matching range). Or you might want to pass the whole range on to something else.  Hence the various more or less specific interfaces to perform a binary search.  </p>

<p>Unfortunately, you're not particularly likely to find the other ones if you're thinking, ""I need a binary search routine"".  </p>
","2541998"
"How assignment from int to char works in C?","3724","","<p>What happens when you assign an int to a char in C? Does it always just ignore the extra bits on the left?</p>

<p>Example (4 bytes int):</p>

<pre><code>unsigned char c = 0;
unsigned int i = 500;

c = i; // c is 244

c = i &lt;&lt; 24 &gt;&gt; 24; //c is 244

i = i &lt;&lt; 24 &gt;&gt; 24; //i is 244
</code></pre>

<p>In binary, <code>500</code> is <code>111110100</code> and <code>244</code> is <code>11110100</code>.</p>
","<p>Typically, this is exactly what happens. Section 6.3.1.3 of the ISO/IEC 9899:2011 standard prescribes what has to happen in this case:</p>

<p><strong>6.3.1.3 Signed and unsigned integers</strong></p>

<ol>
<li>When a value with integer type is converted to another integer
type other than _Bool, if  the value can be represented by the new
type, it is unchanged.</li>
<li>Otherwise, if the new type is unsigned, the value is converted by
repeatedly adding or  subtracting one more than the maximum value
that can be represented in the new type until the value is in the
range of the new type.<sup>60)</sup></li>
<li>Otherwise, the new type is signed and the value cannot be
represented in it; either the  result is implementation-defined or
an implementation-defined signal is raised.</li>
</ol>

<p><sup>60)</sup> The rules describe arithmetic on the mathematical value, not the value of a given type of expression.</p>

<p>Your case falls under item 2 above (since your character is declared as unsigned). In a typical computer arithmetic, the result will be exactly as you described.</p>
","18294422"
"Is there a function to negate a binary number in C?","3721","","<p>I have the following binary number</p>

<pre><code>uint64_t = 0b0100;
</code></pre>

<p>And I want to negate it to</p>

<pre><code>0b1011
</code></pre>

<p>This is a specific example but I want it to work for any binary number variable. For example,</p>

<p><code>uint64_t a</code></p>

<p>So is there a function like negate that would make the following true</p>

<pre><code>a == negate(negate(a));
</code></pre>
","<p>Simply use the <a href=""http://www.eskimo.com/~scs/cclass/int/sx4ab.html"" rel=""nofollow"">bitwise negation operator</a>:</p>

<pre><code>bar = ~bar
</code></pre>
","9643470"
"How to read binary file created by C/Matlab using JAVA","3716","","<p>I have created a binary file using the following matlab code:</p>

<pre><code>x is an array of int32 numbers
n is the length of x

fid = fopen(""binary_file.dat"", ""wb"");
fwrite(fid, n, 'int32');
fwrite(fid, x, 'int32');
fclose(fid);
</code></pre>

<p>I can use the following C code to read this file:</p>

<pre><code>fp = fopen(""binary_file.dat"", ""rb"");
int n;
fread(&amp;n, 4, 1, fp);//read 4 bytes
int *x = new int[n];
for (int i = 0; i &lt; n; i++)
{
int t;
fread(&amp;t,4, 1,fp);//read 4 bytes
x[i] = t;
}
......
</code></pre>

<p>The above C code can read correct results. However, I now want to read such binary file in JAVA. My code is shown as follows:</p>

<pre><code>DataInputStream data_in = new DataInputStream(
             new BufferedInputStream(
                    new FileInputStream(
                new File(""binary_file.dat""))));
while(true)
{
   try {
      int t = data_in.readInt();//read 4 bytes
      System.out.println(t);
   } catch (EOFException eof) {
    break;
   }
}
data_in.close();
</code></pre>

<p>It DOES terminates after n+1 loops, but the results are not correct. Can anybody help me out. Thanks very much!</p>
","<p>As I was guessing it is an endianness issue, i.e.
your binary file is written as little-endian integers
(probably, because you are using a Intel or similar CPU).</p>

<p>The Java code, however, is reading big-endian integers, no matter what CPU it is running on.</p>

<p>To show the problem the following code will read your data and display the integers as hex number before and after endianness conversion.</p>

<pre><code>import java.io.*;

class TestBinaryFileReading {

  static public void main(String[] args) throws IOException {  
    DataInputStream data_in = new DataInputStream(
        new BufferedInputStream(
            new FileInputStream(new File(""binary_file.dat""))));
    while(true) {
      try {
        int t = data_in.readInt();//read 4 bytes

        System.out.printf(""%08X "",t); 

        // change endianness ""manually"":
        t = (0x000000ff &amp; (t&gt;&gt;24)) | 
            (0x0000ff00 &amp; (t&gt;&gt; 8)) | 
            (0x00ff0000 &amp; (t&lt;&lt; 8)) | 
            (0xff000000 &amp; (t&lt;&lt;24));
        System.out.printf(""%08X"",t); 
        System.out.println();
      } 
      catch (java.io.EOFException eof) {
        break;
      }
    } 
    data_in.close();
  }
}
</code></pre>

<p>If you don't want to do change endianness ""manually"", see answers to this
question:<br>
<a href=""https://stackoverflow.com/questions/3438415/convert-little-endian-file-into-big-endian"">convert little Endian file into big Endian</a></p>
","7744937"
"Compression level for binary serialized objects as file","3705","","<p>In my application I have a rather large object created from some XML files. The xml file sizes something like 30MB, and my binary serialized object from this xml file will be like 8~9MB. Funny thing is if I compress this binary file with e.g. WinRar, it will be just 1~2MB.</p>

<p>Is there a way to increase compression level of the object itself? Or should I use another level of compression by manually write code for zipping the file after saving or unzip before loading back into the program?</p>

<p>In case, this is the code I use to save my object as file:</p>

<pre><code>    public static bool SaveProject(Project proj, string pathAndName)
    {
        bool success = true;
        proj.FileVersion = CurrentFileVersion;

        try
        {
            IFormatter formatter = new BinaryFormatter();
            Stream stream = new FileStream(pathAndName, FileMode.Create, FileAccess.Write, FileShare.None);
            formatter.Serialize(stream, proj);
            stream.Close();
        }
        catch (Exception e)
        {
            MessageBox.Show(""Can not save project!"" + Environment.NewLine + ""Reason: "", ""Error"",
                            MessageBoxButtons.OK, MessageBoxIcon.Exclamation);

            success = false;
        }

        return success;
    }
</code></pre>

<p><strong>UPDATE</strong>
I tried to change my code by adding a <code>GZIPSTREAM</code> but it seems that it does not do anything! Or maybe my implementation is wrong?</p>

<pre><code>public static bool SaveProject(Project proj, string pathAndName)
{
    bool success = true;
    proj.FileVersion = CurrentFileVersion;

    try
    {
        IFormatter formatter = new BinaryFormatter();
        var stream = new FileStream(pathAndName, FileMode.Create, FileAccess.Write, FileShare.None);
        var gZipStream = new GZipStream(stream, CompressionMode.Compress);
        formatter.Serialize(stream, proj);
        stream.Close();
        gZipStream.Close();
    }
    catch (Exception e)
    {
        MessageBox.Show(""Can not save project!"" + Environment.NewLine + ""Reason: "", ""Error"",
                        MessageBoxButtons.OK, MessageBoxIcon.Exclamation);

        success = false;
    }

    return success;
}

public static Project LoadProject(string path)
{
    IFormatter formatter = new BinaryFormatter();
    Stream stream = new FileStream(path, FileMode.Open, FileAccess.Read, FileShare.Read);
    var gZipStream = new GZipStream(stream, CompressionMode.Decompress);
    var obj = (Project)formatter.Deserialize(gZipStream);
    stream.Close();
    gZipStream.Close();

    if (obj.FileVersion != CurrentFileVersion)
    {
        throw new InvalidFileVersionException(""File version belongs to an older version of the program."");
    }

    return obj;
}
</code></pre>
","<p>Wrap your <code>FileStream</code> in a <a href=""http://msdn.microsoft.com/en-us/library/system.io.compression.deflatestream.aspx"" rel=""nofollow""><code>DeflateStream</code></a> with <code>CompressionMode.Compress</code> - pass that to the serializer. Then to deserialize, wrap a <code>FileStream</code> in a <code>DeflateStream</code> with <code>CompressionMode.Decompress</code>.</p>

<p>Note that instead of calling <code>Close</code> explicitly, you should use a <code>using</code> statement, e.g.</p>

<pre><code>using (FileStream fileStream = ...)
using (DeflateStream deflateStream = new DeflateStream(fileStream, 
                                                      CompressionMode.Compress))
{
    formatter.Serialize(deflateStream, proj);
}
</code></pre>

<p>You can use <a href=""http://msdn.microsoft.com/en-us/library/system.io.compression.gzipstream"" rel=""nofollow""><code>GZipStream</code></a> in the same way - try both to see which tends to give you better compression (or better performance, if you care about that).</p>

<p>Note how this approach separates the serialization aspect from the compression aspect, composing the two while keeping good separation of concerns. The serialization code just writes to a stream without caring what happens to the data, and the compression code just compresses what it's given without caring what the data means.</p>
","12106494"
"Converting Decimal to Two's-Complement","3705","","<p><strong>Instructions:</strong> Convert these decimal numbers to 5-bit 2's-complement form, if possible. If not possible, explain why this is so.</p>

<p>(16) base 10</p>

<p>According to the online converter:</p>

<p><img src=""https://i.stack.imgur.com/gVHZX.png"" alt=""""></p>

<p>From what I understand,</p>

<p>If decimal is <em>positive</em>:</p>

<ul>
<li>STEP 1: Convert magnitude to binary.</li>
<li>STEP 2: Pad 0's to desired bitsize.</li>
</ul>

<p>If decimal is <em>negative</em>:</p>

<ul>
<li>STEP 1: Convert magnitude to binary.</li>
<li>STEP 2: Pad 0's to desired bitsize.</li>
<li>STEP 3: Invert bits to achieve 1's-complement.</li>
<li>STEP 4: Add 1 to achieve 2's-complement.</li>
</ul>

<p>Since 16 is positive, I simply converted it to binary by repeated division yielding (10000) base 2.</p>

<p>I no longer padded 0's since it is already 5-bits (containing 5 digits).</p>

<p>Can somebody explain to me why the online converter is returning an error (which also I strongly believe is the correct answer)?</p>
","<p>With 5 bits you can represent up to 2^5 different numbers, since you want negative and positive numbers the range is -16 to +15.</p>

<p>so you get error since 16 is out of the range for 5 bits. Change to 6 bits and it should work</p>
","18957230"
"Reading bytes in c++","3699","","<p>I'm trying to read bytes from binary file but to no success.
I've tried many solutions, but I get no get result.
Struct of file:</p>

<pre><code>[offset] [type]          [value]          [description] 
0000     32 bit integer  0x00000803(2051) magic number 
0004     32 bit integer  60000            number of images 
0008     32 bit integer  28               number of rows 
0012     32 bit integer  28               number of columns 
0016     unsigned byte   ??               pixel 
0017     unsigned byte   ??               pixel 
........ 
xxxx     unsigned byte   ??               pixel
</code></pre>

<p>How I tried (doesn't work):</p>

<pre><code>auto myfile = fopen(""t10k-images.idx3-ubyte"", ""r"");
char buf[30];
auto x = fread(buf, 1, sizeof(int), myfile);
</code></pre>
","<p>Knowing the endianness of your file layout whence reading multi-byte numerics is important. Assuming big-endian is <em>always</em> the written format, and assuming the value is indeed a 32bit unsigned value:</p>

<pre><code>uint32_t magic = 0;
unsigned char[4] bytes;
if (1 == fread(bytes, sizeof(bytes), 1, f))
{
   magic = (uint32_t)((bytes[0] &lt;&lt; 24) | 
                      (bytes[1] &lt;&lt; 16) | 
                      (bytes[2] &lt;&lt; 8) | 
                      bytes[3]);
}
</code></pre>

<p>Note: this will work regardless of whether the <em>reader</em> (your program) is little endian or big-endian. I'm sure I missed at least one cast in there, but hopefully you get the point. The only safe, and <em>portable</em> way of reading multi-byte numerics is to (a) <em>know</em> the endianness they were written with, and (b) read-and-assemble them byte by byte.</p>
","12876517"
"Extract n most significant non-zero bits from int in C++ without loops","3696","","<p>I want to extract the n most significant bits from an integer in C++ and convert those n bits to an integer.</p>

<p>For example</p>

<pre><code>int a=1200;
// its binary representation within 32 bit word-size is
// 00000000000000000000010010110000
</code></pre>

<p>Now I want to extract the 4 most significant digits from that representation, i.e. 1111</p>

<pre><code>00000000000000000000010010110000
                     ^^^^
</code></pre>

<p>and convert them again to an integer (1001 in decimal = 9).</p>

<p>How is possible with a simple c++ function without loops?</p>
","<p>Some processors have an instruction to count the leading binary zeros of an integer, and some compilers have instrinsics to allow you to use that instruction. For example, using GCC:</p>

<pre><code>uint32_t significant_bits(uint32_t value, unsigned bits) {
    unsigned leading_zeros = __builtin_clz(value);
    unsigned highest_bit = 32 - leading_zeros;
    unsigned lowest_bit = highest_bit - bits;

    return value &gt;&gt; lowest_bit;
}
</code></pre>

<p>For simplicity, I left out checks that the requested number of bits are available. For Microsoft's compiler, the intrinsic is called <code>__lzcnt</code>.</p>

<p>If your compiler doesn't provide that intrinsic, and you processor doesn't have a suitable instruction, then one way to count the zeros quickly is with a binary search:</p>

<pre><code>unsigned leading_zeros(int32_t value) {
    unsigned count = 0;
    if ((value &amp; 0xffff0000u) == 0) {
        count += 16;
        value &lt;&lt;= 16;
    }
    if ((value &amp; 0xff000000u) == 0) {
        count += 8;
        value &lt;&lt;= 8;
    }
    if ((value &amp; 0xf0000000u) == 0) {
        count += 4;
        value &lt;&lt;= 4;
    }
    if ((value &amp; 0xc0000000u) == 0) {
        count += 2;
        value &lt;&lt;= 2;
    }
    if ((value &amp; 0x80000000u) == 0) {
        count += 1;
    }
    return count;
}
</code></pre>
","9719532"
"How to Read-in Binary of a File in Python","3692","","<p>In Python, when I try to read in an executable file with 'rb', instead of getting the binary values I expected (0010001 etc.), I'm getting a series of letters and symbols that I do not know what to do with.</p>

<pre><code>Ex: ???}????l?S??????V?d?\?hG???8?O=(A).e??????B??$????????:    ???Z?C'???|lP@.\P?!??9KRI??{F?AB???5!qtWI??8𜐮???!ᢉ?]?zъeF?̀z??/?n??
</code></pre>

<p>How would I access the binary numbers of a file in Python?</p>

<p>Any suggestions or help would be appreciated. Thank you in advance.</p>
","<p>That is the binary. They are stored as bytes, and when you print them, they are interpreted as ASCII characters.</p>

<p>You can use <a href=""http://docs.python.org/library/functions.html#bin"" rel=""nofollow"">the bin() function</a> and <a href=""http://docs.python.org/library/functions.html#ord"" rel=""nofollow"">the ord() function</a> to see the actual binary codes.</p>

<pre><code>for value in enumerate(data):
   print bin(ord(value))
</code></pre>
","7663210"
"Binary divison java implementation","3690","","<p>It might be a weird question, but I havent found any binary division java implementation browsing the internet. I will use it for CRC16 coding, so converting to decimal is not a solution. I understand the method on paper, but I am a beginner and since it's very important I wouldn't want to make it wrong. The only thing I found is a CRC.java on the code.google.com which uses binary division, but even if I only use the division part of that (removing the other parts) I dont get the desirable value.</p>

<p>Anybody can show me a java implementation of it? I'd appreciate it very much! Thanks in advance</p>

<p>The code what I found:</p>

<p>public class CRC {
    private String data, divisor;</p>

<pre><code>public CRC(String d, String di) {
    this.data = d;
    this.divisor = di;
}
public String getRemainder(String data, String divisor) {
    int x = 1, z = divisor.length(), j = 0, i;
    String data2 = """", strOfZeros = """";
    int y = divisor.length() - 1;
    /* This is to get correct amount of zero's onto the end of the data */
    while (y &gt; 0) {
        data += ""0"";
        y--;
    }
    // Main part of method, this is the long division of Binary numbers.
    needToExit: for (i = x, j = 1; i &lt; z &amp;&amp; z &lt;= data.length(); i++, j++) {
        if (z == data.length() &amp;&amp; data2.charAt(0) == '1') {
            strOfZeros = """";
            for (i = 1; i &lt; divisor.length(); i++) {    
                if (data2.charAt(i) == divisor.charAt(i))
                    strOfZeros += '0';
                else
                    strOfZeros += '1';
            }
            data2 = strOfZeros;
            break needToExit;
        }

        if (data.charAt(i) == divisor.charAt(j))
            data2 += ""0"";
        else
            data2 += ""1"";

        if (i == divisor.length() - 1) {
            data2 += data.charAt(z);
            x++;
            z++;
            // i = x;
            j = 0;

            // when first bit is a 0
            while (data2.charAt(0) != '1' &amp;&amp; i == divisor.length() - 1) {
                for (i = 1; i &lt; divisor.length(); i++) {
                    if (data2.charAt(i) == '0')
                        strOfZeros += ""0"";
                    else
                        strOfZeros += ""1"";
                }
                strOfZeros += data.charAt(z);
                data2 = strOfZeros;
                strOfZeros = """";
                x++;
                z++;
                i = x;
            }
        }

    }
    return data2;
}
public String getDataPlusCRC(String data){
    String str = data.concat(getRemainder(this.data, this.divisor));
    return str;
}
</code></pre>

<p>}</p>

<p>The <code>getRemainder()</code> method gives me a bad result when I try to divide to numbers. And this part is not necessary, because it needs for the CRC.</p>

<pre><code>while (y &gt; 0) {
            data += ""0"";
            y--;
        }
</code></pre>
","<p>BigInteger can do base 2 division;</p>

<pre><code>    BigInteger divisor = new BigInteger(""10"", 2);
    BigInteger dividend = new BigInteger(""100"", 2);
    BigInteger result = dividend.divide(divisor);

    System.out.println(result.toString(2));
</code></pre>
","13286898"
"python: string of hex values to binary","3689","","<p>This is a sample of my input:</p>

<pre><code>a = 41cf4a077a7454
</code></pre>

<p>They represent hex values, x41 xCF x4A etc...</p>

<p>I require to convert them into one string of binary like this (DESIRED OUTPUT):</p>

<pre><code>01000001110011110100101000000111011110100111010001010100
</code></pre>

<p>x41 = 01000001
xCF = 11001111 
x4A = 01001010
etc...</p>

<p>The code I used to do it looked like this:</p>

<pre><code>return bin(int(str(a), 16))[2:]
</code></pre>

<p>However, it produces a string without a zero at the front:</p>

<pre><code>1000001110011110100101000000111011110100111010001010100
</code></pre>

<p>It appears the zero gets chopped as it's interpreted as an integer.
Is there a way I can keep the zero, because not every string being converted begins with a zero in binary.</p>

<p>I hope this makes sense. Thank you.</p>
","<p>This solution could work for you.</p>

<pre><code>&gt;&gt;&gt; a = '41cf4a077a7454'
&gt;&gt;&gt; b = [a[2*i]+a[2*i+1] for i in range(len(a)/2)]
 ['41', 'cf', '4a', '07', '7a', '74', '54']
&gt;&gt;&gt; c = map(lambda x: ""{0:08b}"".format(int(x, 16)), b)
['01000001',
 '11001111',
 '01001010',
 '00000111',
 '01111010',
 '01110100',
 '01010100']
&gt;&gt;&gt; """".join(c)
'01000001000111001100111111110100010010101010000000000111'
</code></pre>
","18485967"
"Convert Data-URL to valid byte string","3686","","<p>I am attempting to allow the user to save images that have been rendered to the canvas. There may be several images and I want the user to be able to download all the images at once as a single tar file. I am trying to write the code to generate this tar file. I have most of this working, but when the tar file is downloaded to my computer at the end I discover that some of the binary data that composes the png files has been corrupted. Here is the relevant code:</p>

<pre><code>var canvBuffer = $('&lt;canvas&gt;').attr('width', canvasWidth).attr('height', canvasHeight);
var ctxBuffer = canvBuffer[0].getContext('2d');

imgData.data.set(renderedFrames[0]);
ctxBuffer.putImageData(imgData,0,0);

var strURI = canvBuffer[0].toDataURL();
var byteString = atob(decodeURIComponent(strURI.substring(strURI.indexOf(',')+1)));

toTar([byteString]);

function toTar(files /* array of blobs to convert */){
        var tar = '';

        for (var i = 0, f = false, chkSumString, totalChkSum, out; i &lt; files.length; i++) {

            f = files[i];
            chkSumString = '';

            var content  = f;


            var name = 'p1.png'.padRight('\0', 100);
            var mode = '0000664'.padRight('\0', 8);
            var uid = (1000).toString(8).padLeft('0', 7).padRight('\0',8);
            var gid = (1000).toString(8).padLeft('0', 7).padRight('\0',8);
            var size = (f.length).toString(8).padLeft('0', 11).padRight('\0',12);

            var mtime = '12123623701'.padRight('\0', 12); // modification time
            var chksum = '        '; // enter all spaces to calculate chksum
            var typeflag = '0';
            var linkname = ''.padRight('\0',100);
            var ustar = 'ustar  \0';
            var uname = 'chris'.padRight('\0', 32);
            var gname = 'chris'.padRight('\0', 32);

            // Construct header with spaces filling in for chksum value
            chkSumString = (name + mode + uid + gid + size + mtime + chksum + typeflag + linkname + ustar + uname + gname).padRight('\0', 512);


            // Calculate chksum for header
            totalChkSum = 0;
            for (var i = 0, ch; i &lt; chkSumString.length; i++){
                ch =  chkSumString.charCodeAt(i);
                totalChkSum += ch;
            }

            // reconstruct header plus content with chksum inserted
            chksum = (totalChkSum).toString(8).padLeft('0', 6) + '\0 ';
            out = (name + mode + uid + gid + size + mtime + chksum + typeflag + linkname + ustar + uname + gname).padRight('\0', 512);
            out += content.padRight('\0', (512 + Math.floor(content.length/512) * 512)); // pad out to a multiple of 512
            out += ''.padRight('\0', 1024); // two 512 blocks to terminate the file
            tar += out;
        }

        var b = new Blob([tar], {'type': 'application/tar'});
        window.location.href =  window.URL.createObjectURL(b);

    }
</code></pre>

<p>I am putting a previously rendered frame onto a non-rendered canvas and using the canvases toDataURL() method to an encoded png version of the frame with Base64 encoding. Next I use atob to convert this to a byte string so it can be appended to the contents of the tar file I am generating.</p>

<p>When I view the file in a hex editor my tar header is correct, but the contents of the png are not quite right. The ASCII contents looks normal but binary data is scrambled.</p>

<p>Any help offered would be greatly appreciated. Thanks.</p>

<p>PS</p>

<p>I have attached links to related posts that I have looked at. They have been helpful, but I have not yet seen anything there that fully resolves my issues. Thanks.</p>

<p><a href=""https://stackoverflow.com/questions/4998908/convert-data-uri-to-file-then-append-to-formdata"">Convert Data URI to File then append to FormData</a>, and <a href=""https://stackoverflow.com/questions/9388412/data-uri-to-object-url-with-createobjecturl-in-chrome-ff"">Data URI to Object URL with createObjectURL in chrome/ff</a> </p>
","<p>OK, I have resolved the issue. The problem was the Blob constructor at the end of toTar.  passing it a string caused the blob to treat my data as UTF-8 instead of binary, I need to instead pass it arrayBuffer for an array of unsigned integers. Below is my solution</p>

<pre><code>  var byteArray = new Uint8Array(tar.length);
  for (var b = 0; b &lt; tar.length; b++) {
       byteArray[b] = tar.charCodeAt(b);
  }

  var b = new Blob([byteArray.buffer], {'type': 'application/tar'});
  window.location.href =  window.URL.createObjectURL(b);
</code></pre>

<p>I should rewrite toTar to build the file in Uint8Array and remove the need to convert at the end, but this adequately answers my question and hopefully will help someone else. Thanks.</p>
","16005512"
"How do you read the binary data of an Excel file (.xls) using .NET?","3680","","<p>No, ADO.NET will not solve my problem because the excel files I'm working with do not contain information in tabular form. In other words, there is nothing to query, and the name of the sheets and number of sheets will vary.</p>

<p>essentially my job is to search every single cell in an excel document and validate it against some other data.</p>

<p>Right now all I have is a byte[] array that represents the contents of an .xls file. Converting to a string is meaningless since it's just binary data.</p>

<p>If I use COM interop and run Excel in the background, is it possible to inject it with binary data in byte[] array form or do I have to save the file to disk and then automate the process of opening it and scanning each row?</p>

<p>Isn't there an easier way to do it?</p>
","<p><strong>How do you read the binary data of an excel file (.xls) using .NET</strong><br>
There are a number of ways, the excel file format has changed a few times so reading the files natively is hard work and version dependent, it's usually not recommended. For reading tabular data most people choose ADO.NET, but as you allude, if you need any formatting or discovery then MS would recommend COM Interop.</p>

<p><strong>If I use COM interop and run Excel in the background, is it possible to inject it with binary data in byte[] array form</strong></p>

<p>The excel COM object model <a href=""https://stackoverflow.com/questions/536636/write-array-to-excel-range"">does allow you to bulk set data</a> to a Range object you set it with a 2 dimensional object array (object[,])</p>

<p><strong>or do I have to save the file to disk and then automate the process of opening it and scanning each row?</strong></p>

<p>No, you can interact with the ""out of process"" COM server (Excel) without having to save first, you can set your data, format it etc in memory.</p>

<p><strong>Isn't there an easier way to do it?</strong><br>
Yes there is, checkout <a href=""http://www.spreadsheetgear.com/"" rel=""nofollow noreferrer"">Spreadsheet Gear</a> their object model is nearly identical to the com model, however you do not need Excel involved at all, it is also an order of magnitude faster working with large data. Its not cheap ($1000 bucks last time I checked) but will save you way more than that in coding effort. (I am not affiliated with Spreadsheet gear in any way)</p>
","10661045"
"Print in Java Char array as binary","3680","","<p>I've a char array </p>

<pre><code>static char[] myArray  ={   
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xf8, 0x48, 0x48, 0x48, 0xb0, 0x00, 0xc0, 0x20,
0x20, 0x20, 0xc0, 0x00, 0xc0, 0x20, 0x20, 0x20, 0xc0, 0x00, 0x40, 0xa0, 0xa0, 0xa0, 0x20, 0x00,
0x00, 0x20, 0xf0, 0x20, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, 0x08, 0xf8, 0x08,
};
</code></pre>

<p>How could I print it as 8-bit binary ? </p>
","<p>Use <code>toBinaryString</code> for each item:</p>

<pre><code>for (int i = 0; i &lt; myArray.length; i++) {
        String b = Integer.toBinaryString(myArray[i]);

        if (b.length() &lt; 8) {
            b = ""000000000"".substring(0, 8 - b.length()).concat(b);
        } else {
            b = b.substring(b.length() - 8);
        }

        System.out.print(b + "" "");
 }
</code></pre>

<p>Output</p>

<blockquote>
  <p>00000000 00000000 00000000 00000000 00000000 00000000 00000000
  00000000 11111000 01001000 01001000 01001000 1011000 ...</p>
</blockquote>
","16163720"
"Show NSData as binary in a NSString","3680","","<p>I have a binary file (file.bin) in the resources folder, I want to read it and show it as binary. The idea its to put the binary information into a array, but, at first, I'm trying to show it in a UILabel, like that:</p>

<p>`   NSData *databuffer;
    NSString *stringdata;</p>

<pre><code>NSString *filePath = [[NSBundle mainBundle] pathForResource:@""file"" ofType:@""bin""];  
NSData *myData = [NSData dataWithContentsOfFile:filePath];

if (myData) {  
        stringdata = [NSString stringWithFormat:@""%@"",[myData description]]; 
        labelfile.text = stringdata;
}  
</code></pre>

<p>`</p>

<p>But it shows the data in HEX. How can I do it in binary to put it in a NSMutableArray? 
Thanks.</p>
","<p>I don't know if there is anything native that does that but I can propose a workaround solution. Why don't you do your own function that does the conversion. Here is my example:</p>

<p>In the place you get the Hex values:</p>

<pre><code>NSString *str = @""Af01"";
NSMutableString *binStr = [[NSMutableString alloc] init];

for(NSUInteger i=0; i&lt;[str length]; i++)
{
    [binStr appendString:[self hexToBinary:[str characterAtIndex:i]]];
}
NSLog(@""Bin: %@"", binStr);
</code></pre>

<p>The workaround function:</p>

<pre><code>- (NSString *) hexToBinary:(unichar)myChar
{
    switch(myChar)
    {
        case '0': return @""0000"";
        case '1': return @""0001"";
        case '2': return @""0010"";
        case '3': return @""0011"";
        case '4': return @""0100"";
        case '5': return @""0101"";
        case '6': return @""0110"";
        case '7': return @""0111"";
        case '8': return @""1000"";
        case '9': return @""1001"";
        case 'a':
        case 'A': return @""1010"";
        case 'b':
        case 'B': return @""1011"";
        case 'c':
        case 'C': return @""1100"";
        case 'd':
        case 'D': return @""1101"";
        case 'e':
        case 'E': return @""1110"";
        case 'f':
        case 'F': return @""1111"";
    }
    return @""-1""; //means something went wrong, shouldn't reach here!
}
</code></pre>

<p>Hope this helps!</p>
","10665456"
"converting hex to binary","3674","","<pre><code>int hex2bin (int n)
{
  int i,k,mask;
  for(i=16;i&gt;=0;i--)
  {
    mask = 1&lt;&lt;i;
    k = n&amp;mask;
    k==0?printf(""0""):printf(""1"");
  }
  return 0;
}
</code></pre>

<p>I need this to work for any hex i give as an input. Meaning <code>hex2bin(0x101)</code> and <code>hex2bin(0x04)</code> should print out their respective binary numbers.</p>
","<p>I don't understand that why the for loop is from 16 to 0.
If int is 16 bit in your OS,
    your should set the for loop from 15 to 0,
else if int is 32 bit in your OS,
    your should set the for loop from 31 to 0.
so the code is:</p>

<pre><code>int hex2bin (int n)
{
  int i,k,mask;
  for(i=sizeof(int)*8-1;i&gt;=0;i--)
  {
     mask = 1&lt;&lt;i;
     k = n&amp;mask;
     k==0?printf(""0""):printf(""1"");
  }
 return 0;
}
</code></pre>

<p>If you want to display any input(such as ""0x10"",""0x4""),you can declare a function like this:</p>

<pre><code>int hex2bin (const char *str)
{
char *p;
for(p=str+2;*p;p++)
{
    int n;
    if(*p&gt;='0'&amp;&amp;*p&lt;='9')
    {
        n=*p-'0';
    }
    else
    {
        n=*p-'a'+10;
    }
    int i,k,mask;
    for(i=3;i&gt;=0;i--)
    {
        mask=1&lt;&lt;i;
        k=n&amp;mask;
        k==0?printf(""0""):printf(""1"");
    }

}
return 0;
}
</code></pre>

<p>then ,call hex2bin(""0x101"") will get the exact binary code of 0x101.</p>
","10529725"
"Why can't I read fstream's binary data with operator>>?","3673","","<p>If I do something like the following:</p>

<pre><code>ifstream file;
file.open(""somefile"", ios::binary);

unsigned int data;

file &gt;&gt; data;
</code></pre>

<p>My stream will always set the <code>failbit</code> and the <code>data</code> will remain uninitialized.  However, if I read a <code>char</code> or <code>unsigned char</code> instead, the stream is fine.  <code>perror()</code> is telling me ""result too large"".  </p>

<p>The only thing I saw on Google was a suggestion saying that <code>operator&gt;&gt;</code> shouldn't be used for binary data (prefer <code>read()</code>), but I find the operator to be cleaner and easier to use -- and it doesn't require casting everything.</p>

<p>Can someone explain this issue?</p>
","<p>The <a href=""http://www.cplusplus.com/reference/iostream/istream/operator%3E%3E/"" rel=""noreferrer"">iostream extraction operator (>>)</a> attempts to interpret numerical strings separated by whitespace, not binary data. There are many different ways to encode an unsigned integer in binary form (e.g. a 32-bit <a href=""http://en.wikipedia.org/wiki/Two%27s_complement"" rel=""noreferrer"">2's complement representation</a> in <a href=""http://en.wikipedia.org/wiki/Endianness"" rel=""noreferrer"">little-endian byte order</a>). That's why you must use the <a href=""http://www.cplusplus.com/reference/iostream/istream/read/"" rel=""noreferrer"">read</a>/<a href=""http://www.cplusplus.com/reference/iostream/ostream/write/"" rel=""noreferrer"">write</a> functions to operate on such binary buffers.</p>

<p>However, nothing prevents you from implementing your own class for serializing binary data in whatever form you wish using the insertion and extraction operators. Such a class would likely use the read function of an ifstream object internally. Alternatively, the <a href=""http://www.boost.org/doc/libs/1_41_0/libs/serialization/doc/index.html"" rel=""noreferrer"">boost serialization library</a> may already hold exactly what you want.</p>
","4151867"
"Upload a blob with Phonegap FileTransfer - and receive binary","3671","","<p>I want to upload some binary data (e.g. image, or zip) to a server using phonegap, and receive binary as the response. Is it possible?
While the upload works very well with the <code>FileTransfer</code> and a file stored on the disk, I cant get it to work with a blob</p>

<pre><code>var blob = new Blob([something], {type: 'application/zip'});
var blobUrl = window.URL.createObjectURL(blob);
var ft = new FileTransfer();
ft.upload(blobURL, encodeURI('http://server'), win, fail, options);
</code></pre>

<p>the blobURL of course is something like</p>

<pre><code>blob:1234-...
</code></pre>

<p>which FileTransfer does not find. I tried to save the blob first, passing its path to <code>FileTransfer</code> - but Phonegaps <code>FileWriter</code> cannot process a <code>blob</code>.</p>

<p>Using <code>xhr</code> is not an option as you cannot receive binary files with it in Phonegap (WP8). The <code>Mimetypeoverride</code> Trick does not work in this case as Internet Explorers xhr does not have this option.</p>

<p>I am working with Windows Phone 8.</p>
","<p>You can't send binary data through Phonegap file Transfer.</p>

<p>Your binary data must be converted to <strong>BASE64</strong> string and then transferred to server. Same thing goes for the other way.</p>

<p>Here's a tutorial how to handle binary data transfer with Phonegap: <a href=""http://blog.safaribooksonline.com/2012/03/01/phonegap-tip-binary-filesystem-data/"" rel=""nofollow"">http://blog.safaribooksonline.com/2012/03/01/phonegap-tip-binary-filesystem-data/</a></p>
","16464431"
"Python: Need help splitting an input of binary code, with no spaces","3649","","<p>need to split every 8 char so it will become a list whereby i can then translate into ascii and then english. I just am at a loss for how to split the input,(one large string of binary numbers) into readable binary numbers, instead of just one string.</p>

<p>For example, the input string ""010000010100001001000011"" can be split in to octets as follows: ""01000001"",""01000010"",""01000011"".</p>

<p>What i have so far:</p>

<pre><code>def main():
    import string

    #take user input of binary
    code = raw_input ('Please type in your binary code to be decoded: ')

    #split the code
    for word in code:
         print code[0::8] + ' '

    #replace the input with the variables
    ascii = ' '
    for word in code:
        ascii = ascii + int(word,2)

    english = ' '
    for word in acsii:
        english = english + chr(word)

    #print the variables to the user
    print english

#call Main
main()
</code></pre>
","<p>This should help you some of the way, with list comprehensions:</p>

<pre><code>&gt;&gt;&gt; b = '010000010100001001000011'
&gt;&gt;&gt; bin_chunks = [b[8*i:8*(i+1)] for i in xrange(len(b)//8)]
&gt;&gt;&gt; print bin_chunks
['01000001', '01000010', '01000011']
&gt;&gt;&gt; ints = [int(x, 2) for x in bin_chunks]
&gt;&gt;&gt; print ints
[65, 66, 67]
&gt;&gt;&gt; chars = [chr(x) for x in ints]
&gt;&gt;&gt; print chars
['A', 'B', 'C']
&gt;&gt;&gt; print ''.join(chars)
ABC
</code></pre>
","9270749"
"Hex to Binary Angle Measurement (BAMS) in any language","3644","","<p>I have a 32-bit hex value, for example <code>04FA4FA4</code> and I want to know how to convert it to <a href=""http://en.wikipedia.org/wiki/Binary_scaling"" rel=""nofollow"">BAMS</a> in the form of a double. An example in any language would work fine, I am only concerned about learning the algorithm or formula to make the conversion. I know how to convert to BAMS when I have a form like, <code>000:00.0000</code> but I can't figure out how to make the conversion from Hex.</p>
","<p><a href=""http://www.globalspec.com/reference/14722/160210/Chapter-7-5-3-Binary-Angular-Measure"" rel=""nofollow"">This link</a> is the easiest to understand resource I found. The algorithm is simple:</p>

<pre><code>(decimal hex value) * 180 / 2^(n-1)       //where n is the number of bits
</code></pre>

<p>The example in the reference is,</p>

<pre><code>0000 0000 1010 0110
 0    0    A    6
166 * 180 * 2^−15 = 0.9118 degrees
</code></pre>

<p>The code for this algorithm is so simple, I don't think I need to enumerate it here. Let me know, if someone feels this is incorrect.</p>
","15709430"
"How to convert Memory Stream to System.Data.Linq.Binary?","3627","","<p>I just need to do the reverse conversion as exposed in <a href=""https://stackoverflow.com/questions/3208580/how-to-convert-system-data-linq-binary-to-a-stream"">this question</a>.</p>

<p>I have a MemoryStream and want to store it in a System.Data.Linq Binary field of my SQL CE database (FYI I'm using EF code first).</p>

<p>The MemoryStream is actually a XML, which is larger than the max size of a String field, so I found no other way than storing it in a Binary (suggestions on this subject REALLY appreciated).</p>

<p>My code (adapted)</p>

<pre><code>   private Stream _userLayout;
   _userLayout = new MemoryStream();
   DXGridControl_Table.SaveLayoutToStream(_userLayout);
   MyDatabse.SomeTable.SomeBinaryField = _userLayout.????
</code></pre>
","<p>First there is </p>

<pre><code>        byte[] buffer = new byte[LENGTH];
        MemoryStream memoryStream  = new MemoryStream(buffer);
</code></pre>

<p>In your example you can use </p>

<pre><code>        DXGridControl_Table.SaveLayoutToStream(_userLayout);
        byte[] doSomethingwithyourData = _userLayout.GetBuffer();
        var length = _userLayout.Length;
</code></pre>

<p>With that information you can write the binary data to whatever. </p>

<blockquote>
  <p>Note that the buffer contains allocated bytes which might be unused.
  For example, if the string ""test"" is written into the MemoryStream
  object, the length of the buffer returned from GetBuffer is 256, not
  4, with 252 bytes unused. To obtain only the data in the buffer, use
  the ToArray method; however, ToArray creates a copy of the data in
  memory.</p>
</blockquote>

<p>Or</p>

<pre><code>Binary binary = new Binary(_userLayout.ToArray());
</code></pre>

<p>Like in the other answer said, there is an implicit conversion on binary:</p>

<pre><code>public static implicit operator Binary(byte[] value) {
    return new Binary(value); 
}
</code></pre>

<p>You requested examples.
A little example about the usage:</p>

<pre><code>namespace Stackoverflow.Hannish.SaveLayout
{
    using System;
    using System.Collections.Generic;
    using System.IO;
    using System.Text;
    using System.Windows.Forms;

    public partial class Form1 : Form
    {
        /// &lt;summary&gt;
        /// Here we store the layout data as a string. This is the data, that
        /// gets saved to disk / database / etc.
        /// &lt;/summary&gt;
        private string layoutdata = string.Empty;

        public Form1()
        {
            this.InitializeComponent();
        }

        private void Form1_Load(object sender, EventArgs e)
        {
            // Just some FooBar data.
            var data = new List&lt;DataValue&gt;
                           {
                               new DataValue { Id = 1, Name = ""Xyz"", IsCool = true }, 
                               new DataValue { Id = 2, Name = ""Abc"", IsCool = false }
                           };

            this.gridControl1.DataSource = data;
        }

        private void bnLoadLayout_Click(object sender, EventArgs e)
        {
            using (var stream = new MemoryStream())
            {
                var strdata = Encoding.Default.GetBytes(this.layoutdata);
                stream.Write(strdata, 0, strdata.Length);
                stream.Seek(0, SeekOrigin.Begin);
                this.gridView1.RestoreLayoutFromStream(stream);
            }
        }

        private void bnSaveLayout_Click(object sender, EventArgs e)
        {
            using (var stream = new MemoryStream())
            {
                this.gridView1.SaveLayoutToStream(stream);
                this.layoutdata = Encoding.Default.GetString(stream.ToArray());
            }
        }
    }
}
</code></pre>

<p>And some byte to file magic:</p>

<pre><code>    private void bnLoadBinLayout_Click(object sender, EventArgs e)
    {
        using (FileStream fstream = File.Open(""Layoutdata.bin"", FileMode.Open))
        {
            int length = (int)fstream.Length;
            byte[] buffer = new byte[length];
            fstream.Read(buffer, 0, length);

            var memstream = new MemoryStream(buffer);
            this.gridView1.RestoreLayoutFromStream(memstream);
        }
    }

    private void bnSaveBinLayout_Click(object sender, EventArgs e)
    {
        using (FileStream fstream = File.Create(""Layoutdata.bin""))
        {
            var memstream = new MemoryStream();
            this.gridView1.SaveLayoutToStream(memstream);
            fstream.Write(memstream.GetBuffer(), 0, (int)memstream.Length);
        }
    }
</code></pre>

<p>... just as example. DevExpress GridView can save the layout itself with SaveLayoutToXml();</p>
","15718303"
"Convert from binary to floating point","3621","","<p>I'm doing some exercises for Computer Science university and one of them is about converting an <code>int</code> array of 64 bit into it's double-precision floating point value.</p>

<p>Understanding the first bit, the sign +/-, is quite easy. Same for the exponent, as well as we know that the bias is 1023.</p>

<p>We are having problems with the <strong>significand</strong>. How can I calculate it?</p>

<p>In the end, I would like to obtain the real numbers that the bits meant.</p>
","<p>computing the significand of the given 64 bit is quite easy.</p>

<p>according to the <a href=""http://en.wikipedia.org/wiki/Double_precision_floating-point_format"" rel=""nofollow"">wiki article</a> using the IEEE 754, the significand is made up the first 53 bits (from bit 0 to bit 52). 
Now if you want to convert number having like 67 bits to your 64 bits value, it would be rounded by setting the trailing 64th bits of your value to 1, even if it was one before... because of the other 3 bits:</p>

<p><strong>11110000 11110010 11111</strong> becomes <strong>11110000 11110011</strong> after the rounding of the last byte;</p>

<p>therefore the there is no need to store the 53th bits because it has always a value a one.
that's why you only store in 52 bits in the significand instead of 53.</p>

<p>now to compute it, you just need to target the bit range of the significand [bit(1) - bit(52)] -bit(0) is always 1- and use it .</p>

<pre><code>int index_signf = 1; // starting at 1, not 0
int significand_length = 52;
int byteArray[53]; // array containing the bits of the significand

double significand_endValue = 0;
for( ; index_signf &lt;= significand_length ; index_signf ++)
{
    significand_endValue += byteArray[index_signf] * (pow(2,-(index_signf)));
}

significand_endValue += 1; 
</code></pre>

<p>Now you just have to fill <code>byteArray</code> accordlingly before computing it, using function like that: </p>

<pre><code>int* getSignificandBits(int* array64bits){

    //returned array

    int significandBitsArray[53];
    // indexes++
    int i_array64bits = 0; 
    int i_significandBitsArray=1;
    //set the first bit = 1

    significandBitsArray[0] = 1;



    // fill it  
    for(i_significandBitsArray=1, i_array64bits = (63 - 1); i_array64bits &gt;= (64 - 52); i_array64bits--, i_significandBitsArray ++)
        significandBitsArray[i_significandBitsArray] = array64bits[i_array64bits];

    return significandBitsArray;
}
</code></pre>
","10636600"
"Memory Leak Observed in Erlang Application","3620","","<p>
Let me put my question as simple as below. Mine is a network router software built in erlang, but at a particular scenario I am observing very high memory growth as shown by VM.
</p>

<p>
I have one process which receives binary packet from some other process from socket.
<p>
This process, parses the binary packet and passes the binary packet to a gen_server (handle_cast is called)
</p>
<p>
The gen_server again stores some information in ETS table and send the packet to the peer server.
<p>
When the peer server responds back the entry from the ETS is deleted and the gen_server responds back to the first process
</p>
Also if the first process (which sent packet to gen_server) gets timedout after 5 seconds waiting for response from gen_server , it also deletes the ETS entry in the gen_server and exits.
</p>
</p>

<p>
Now I am observing high memory growth when lots of events gets timed out (due to unavailability of peer server) and from what i have researched its the ""**binary**"" and ""**processes_used**"" given by erlang:memory command thats using most of the memory.
<p>
but the same is not true when events are processed successfully.
</p>
</p>
","<p>The memory lost can be basically only in three places:</p>

<ol>
<li><p>The state of your gen_server</p>

<ul>
<li>look at you state, find out if there is some big or growing stuff there</li>
</ul></li>
<li><p>Your processes mailboxes</p>

<ul>
<li><p>see to it that there is some way to always drain unmatched messages (for gen_server <code>handle_info</code> callback) in normal <code>receive</code>s a <code>Any -&gt;</code>clause.</p></li>
<li><p>if the mailbox only fills up temporarily its probably because of the receiving process being too slow for the rate of messages produced.  This is usually a problem for asynchronous communication.  If its only temporary bursts that don't break anything this could be intended.</p>

<ul>
<li><p>In this case you can either optimize the receiving process</p></li>
<li><p>or fix your protocol to use fewer messages</p></li>
<li><p>if you have multiple functions that receive some messages, make sure all receiving parts are being called regularly.  Dont forget the <code>Any -&gt;</code> clauses.</p></li>
</ul></li>
<li><p>Be aware that while you are processing in a gen_servers callback no messages will be received, so if you need more time in a callback that would be necessary asyncronous messages might pile up (e.g. random message arrival + fixed processing time builds a unbounded growing queue, for details see <a href=""http://en.wikipedia.org/wiki/Queueing_theory"" rel=""noreferrer"">Queueing theory</a></p></li>
</ul></li>
<li><p>In your ETS table</p>

<ul>
<li>maybe the information in the ETS is not be completely removed?  Forgot to remove something in certain cases?</li>
</ul></li>
</ol>
","5044197"
"Change Subversion's default mime-type for binary files that don't have a specific extension?","3613","","<p>Subversion sets a binary file's <code>svn:mime-type</code> property to <code>application/octet-stream</code> by default.</p>

<p>I need to change this default to some other mime-type.  When I import for the first time this code, I would like Subversion to set mime-type to the one I choose.</p>

<p>The reason is that my code base contains code in binary files (proprietary format), and I have the applications necessary to emulate diff and diff3 for these.  But Subversion does not let me due to their default mime-type.</p>

<p><strong>Please note:</strong>  There is no default extension (*.jar, *.py, etc) for these code files.  Some files don't even have an extension.  <strong>So configuring mime-type by file extension is not possible</strong>.</p>
","<p>--- Edited after response that there is no default extension for these files ---</p>

<p>If there is no default extension for these files, you can sill use the <code>[auto-props]</code> directive in the client, under a few circumstances.</p>

<p>If the file has a known reserved file name (like Makefile), then you can put in a directive that matches the entire file name, like</p>

<pre><code>Makefile = svn:mime-type=text/x-makefile
</code></pre>

<p>Should you only have a few file names to cover, you could just add in the directives for the each of the desired file names.</p>

<p>The * is not just limited to extension matching, the directives match file name patters, so you could also write a directive like</p>

<pre><code>Image* = svn:mime-type=image/png
</code></pre>

<p>Finally, if your files do not follow a naming pattern which can be explicitly reserved for your mime type, then you'll just be better off writing a small script to tag the files and remembering to run it occasionally.</p>

<p>Note that changing the client defaults will change the client behavior for access to all SVN repositories, so it's a good idea to only put in sane choices which probably would apply to every repository you intend to use.</p>

<p>--- Original post follows ---</p>

<p>The svn:mime-type is a property.  For existing entries, you can edit it with <code>svn propedit</code></p>

<p>To change the mime-type's default, on the client side, you can edit the svn <code>config</code> file to include a directive in the <code>[auto-props]</code> section of the config file.</p>

<pre><code>*.png = svn:mime-type=image/png
</code></pre>

<p>would automatically add a <code>svn:mime-type</code> of <code>image/png</code> to any new file created that ended in <code>*.png</code></p>

<p>I'm not aware of any technique where this can be done server side, unless you want to write up a script in one of the pre-commit triggers to add the property before the change is committed to the repository.</p>
","3015991"
"C++ Native Way to Pack and Unpack String","3611","","<p>Following my earlier <a href=""https://stackoverflow.com/questions/684931/content-of-binary-output-file-created-with-output-stream"">question</a>. Is there a way to write a string in a compressed/bit version using C++ native idiom. I am thinking something like Perl's native <a href=""http://perldoc.perl.org/functions/pack.html"" rel=""nofollow noreferrer"">pack and unpack</a>.</p>
","<p>Based on reading your previous question, I think you mean to say that you want a binary encoded output, rather than a ""compressed"" output.  Generally, ""compressed"" is used to refer specifically to data that has been reduced in size through the application of an algorithm such as LZW encoding.  In your case, you may find that the output is ""compressed"" in the sense that it is smaller because for a wide variety of numbers a binary representation is more efficient than an ASCII representation, but this is not ""compression"" in the standard sense, which may be why you are having trouble getting the answer you are looking for.</p>

<p>I think you are really asking the following:</p>

<p><em>Given a number in ASCII format (stored in a std::string, for example), how can I write this to a file as a binary encoding integer?</em></p>

<p>There are two parts to the answer.  First, you must convert the ASCII encoded string to an integer value.  You may use a function such as strtol, which will return a long integer equivalent in value to your ASCII encoded number.  Do be aware that there are limitations on the magnitude of the number that may be represented in a long integer, so if your numbers are very, very large, you may need to be more creative in translating them.</p>

<p>Second, you must write the data to the output stream using ostream::write(), which does not attempt to format the bytes you give it.  If you simply use the default operator&lt;&lt;() stream operation to write the values, you'll find that your numbers just get translated back to ASCII and written out that way.  Put this all together like this:</p>

<pre><code>#include &lt;stdlib.h&gt;        // For strtol().
#include &lt;arpa/inet.h&gt;     // For htonl().
#include &lt;fstream&gt;         // For fstream.
#include &lt;string&gt;          // For string.

int main(int argc, char *argv[]) {
    char *dummy = 0;
    std::string value(""12345"");

    // Use strtol to convert to an int; ""10"" here means the string is 
    // in decimal, as opposed to, eg, hexadecimal or octol, etc.

    long intValue = strtol(value.c_str(), &amp;dummy, 10);

    // Convert the value to ""network order""; not strictly necessary, 
    // but it is good hygiene.  Note that if you do this, you will 
    // have to convert back to ""host order"" with ntohl() when you read 
    // the data back.

    uint32_t netValue = htonl(intValue);

    // Create an output stream; make sure to open the file in binary mode.

    std::fstream output;
    output.open(""out.dat"", std::fstream::out | std::fstream::binary);

    // Write out the data using fstream::write(), not operator&lt;&lt;()!

    output.write(reinterpret_cast&lt;char *&gt;(&amp;netValue), sizeof(netValue));
    output.close();
}
</code></pre>
","691009"
"PHP: Split string into chunks of 8, how do I do this?","3610","","<p>I have binary basically, say it's 300 in length. How would I split (much like using explode) it into 8 bit chunks? I look at <i>chunk_split()</i> but it only seems to have an 'end' parameter, not an option to put it into an array.. Or can it be socketed into an array?</p>

<p>The end 8 digits can be below 8 (in case a miscopy from someone, and it's 4) so no validation is needed, just consistantly in 8 number chunks from the start to end.</p>
","<p><a href=""http://us3.php.net/manual/en/function.str-split.php"" rel=""noreferrer""><code>str_split</code></a>:</p>

<pre><code>$chunks = str_split($data, 8);
</code></pre>
","2191207"
"Bitwise Logic in C","3607","","<p>I have some familiarity with bitwise operations, but this function just went over my head.</p>

<pre><code>void binary_print(unsigned int value) {
  unsigned int mask = 0xff000000;   // Start with a mask for the highest byte.
  unsigned int shift = 256*256*256; // Start with a shift for the highest byte.
  unsigned int byte, byte_iterator, bit_iterator;

  for (byte_iterator=0; byte_iterator &lt; 4; byte_iterator++) {
    byte = (value &amp; mask) / shift; // Isolate each byte.
    printf("" "");

    for (bit_iterator=0; bit_iterator &lt; 8; bit_iterator++) {
      // Print the byte's bits.
      if (byte &amp; 0x80) // If the highest bit in the byte isn't 0,
        printf(""1"");   // print a 1.
      else
        printf(""0"");   // Otherwise, print a 0.

      byte *= 2;       // Move all the bits to the left by 1.
    }
    mask /= 256;       // Move the bits in mask right by 8.
    shift /= 256;      // Move the bits in shift right by 8.
  }
}
</code></pre>

<p>This function receives bit flags for the <code>open()</code> function and produces the following output with the help of a display_flags function that adds the appropriate labels:</p>

<pre><code>O_RDONLY : 0 : 00000000 00000000 00000000 00000000
O_WRONLY : 1 : 00000000 00000000 00000000 00000001
O_RDWR : 2 : 00000000 00000000 00000000 00000010
O_APPEND : 1024 : 00000000 00000000 00000100 00000000
O_TRUNC : 512 : 00000000 00000000 00000010 00000000
O_CREAT : 64 : 00000000 00000000 00000000 01000000
O_WRONLY|O_APPEND|O_CREAT : 1089 : 00000000 00000000 00000100 01000001 
</code></pre>

<p>I have no problem understanding the output, but I don't understand the actual process: </p>

<ol>
<li>How does <code>byte = (value &amp; mask) / shift</code> isolate individual bits?</li>
<li>Why <code>if(byte &amp; 0x80)</code> means ""If the highest bit in the byte isn't 0?""</li>
<li>How do these lines: <code>byte *= 2;</code> , <code>mask /= 256;</code> and <code>shift /= 256;</code> move bits and why is this operation significant? </li>
</ol>
","<p><strong>1. How does <code>byte = (value &amp; mask) / shift</code> isolate individual bits?</strong></p>

<p><code>mask</code> is a bit pattern that always has 8 consecutive bits set to 1, the rest to 0 (it starts with <code>0xff000000</code>, then <code>0x00ff0000</code>, and so on. So when you take the bitwise and of <code>mask</code> and <code>value</code>, all bits from <code>value</code> will be set to 0, except those that correspond to the byte that is specified by <code>mask</code>. Those keep their value.</p>

<p><code>shift</code> is set to the corresponding value that by the division with <code>shift</code> exactly those bits that survived the masking will end up in the rightmost bits (see answer to question 3 how that works).</p>

<p>So assume <code>value</code> is <code>0xDEADBEEF</code>, <code>mask</code> has its initial value <code>0xff000000</code>, and <code>shift</code> has its initial value <code>256*256*256</code>. Then <code>value &amp; mask</code> is <code>0xDE000000</code>, and the final result is <code>0x000000DE</code>.</p>

<p>In binary the example would be</p>

<pre><code>value       = 11011110101011011011111011101111
mask        = 11111111000000000000000000000000
byte &amp; mask = 11011110000000000000000000000000
result      = 00000000000000000000000001101111
</code></pre>

<p><strong>2. Why <code>if(byte &amp; 0x80)</code> means ""If the highest bit in the byte isn't 0?""</strong></p>

<p>Here the code author thinks of <code>byte</code> being an 8-bit variable. Although it is technically larger, the higher bits are never used here. So when the author refers to the ""highest bit"", think of the 8th bit from the right (the highest bit that would be there if <code>byte</code> was actually only one byte in size).</p>

<p>Now note that <code>0x80</code> is <code>10000000</code> in binary. So when you take <code>byte &amp; 0x80</code>, all bits from <code>byte</code> will be set to 0, except the ""highest"" (8th from right) one. So <code>byte &amp; 0x80</code> is zero, if the highest bit from <code>byte</code> is zero, and greater than zero, if the ""highest"" bit from <code>byte</code> is 1.</p>

<p><strong>3. How do these lines: <code>byte *= 2;</code>, <code>mask /= 256;</code> and <code>shift /= 256;</code> move bits and why is this operation significant?</strong></p>

<p>Multiplication with 2 is equivalent to a shift of bits to the left by 1. Consider for example the value 9, which is <code>1001</code> in binary. A multiplication by 2 gives 18, which is <code>10010</code> in binary.</p>

<p>Similar for a division by 2, this is a shift to the right by 1. Division by 256 is equivalent to 8 divisions by 2, so dividing by 256 is equivalent to a right shift by 8 bits.
These operations are used here for example to change the value <code>mask</code> from <code>0xff000000</code> to <code>0x00ff0000</code>, <code>0x0000ff00</code>, and finally to <code>0x000000ff</code>.</p>

<p><strong>Description of full function</strong></p>

<p>With this knowledge, we can see what the full function does. In the outer loop it loops over the 4 bytes that are in <code>value</code>, starting with the left-most one and ending with the right-most one. It does so by masking out the current byte and stores it in <code>byte</code>.</p>

<p>The inner loop then goes over the 8 bits that are stored in <code>byte</code>. It always looks at 8th bit from the right and prints 1 or 0 accordingly. Then it shifts the bits to the left, so that in the second iteration the bit that was the 7th from right is now the 8th from right and will be printed, and then next one etc. until all 8 bits are printed in right-to-left order.</p>

<p>An alternative way to write this function would be</p>

<pre><code>for (int i = 31; i &gt;= 0; i--) {
  if (value &amp; (1 &lt;&lt; i))
    printf(""1"");
  else
    printf(""0"");

  if (i % 8 == 0)
    printf("" "");
}
</code></pre>

<p>This would simply go through all bits from <code>value</code> in left-to-right order. The expression <code>value (1 &lt;&lt; i)</code> selects the desired bit from <code>value</code>, starting with the 32th from right (when <code>i</code> is 31), and ending with the 1st from right (when <code>i</code> is 0).</p>
","14911322"
"How to get binary file using eclipse c++?","3607","","<p>I need to get <code>.hex</code> file from <code>eclipse c++</code> compiler. I received only <code>.elf</code> file.
Eventually, I should write that binary code into controller which can adopt only binary code.</p>

<p>I converted the <code>.elf</code> file to binary file using an utility, but it's not the way.</p>

<p>Oh, I forgot to say that I used <code>atollic truestudio</code>.</p>
","<p>First of all Elf is ""binary"" file (you probably mean compiled executable). You can load that to controller using jtag/debugger. With GNU toolchain you can use objcopy to convert .elf to raw binary. Objcopy can be added as another compilation step in Eclipse/cdt, but probably your IDE provider should do this (check if there is no option to enable this already there).</p>
","9512160"
"Python reading file in binary, binary data to string?","3607","","<p>I'm trying to learn Python and currently doing some exercises online. One of them involves reading zip files.</p>

<p>When I do:</p>

<pre><code>import zipfile
zp=zipfile.ZipFile('MyZip.zip')
print(zp.read('MyText.txt'))
</code></pre>

<p>it prints:</p>

<pre><code>b'Hello World'
</code></pre>

<p>I just want a string with ""Hello World"". I know it's stupid, but the only way I could think of was to do:</p>

<pre><code>import re
re.match(""b'(.*)'"",zp.read('MyText.txt'))
</code></pre>

<p>How am I supposed to do it?</p>
","<p>You need to decode the raw bytes in the string into real characters. Try running <code>.decode('utf-8')</code> on the value you are getting back from <code>zp.read()</code> before printing it.</p>
","7629532"
"Writing Hexadecimal and Binary Values to File","3601","","<p>How can I write hexadecimal and binary values (not their string representation) to a file? For example, how can I write the hexadecimal value 1A (26 in decimal) to a file? </p>

<p>Previously, I've tried using a BufferedWriter.</p>
","<pre><code>(ns test.core
  (:use [clojure.java.io]))

(with-open [os (output-stream ""/tmp/foo"")]
  (.write os 0x1A))
</code></pre>

<p>Note that the <code>with-open</code> macro is quite handy when dealing with I/O.</p>
","8012667"
"Arranging strings alphabetically in binary tree","3599","","<p>I am constructing a binary tree consisting of words from a sample paragraph, sorted alphabetically. So far, I have implemented all of the basic ""behind the scenes"" work to define the binary tree (constructors, methods), and I am now working on adding elements (words) to the tree.
Every word has had its non-alphanumeric characters removed and every letter in the word is converted to lowercase. I am wondering how I could enter words into the tree alphabetically? All I have done with binary trees have to do with numbers, so I am not sure what to do in this case. (I was thinking of something to do with ASCII values?) Any assistance is appreciated!</p>
","<p>You say you've done this with numbers before.</p>

<p>Nothing has really changed with your new tree.</p>

<p>You can think of an alphabetical comparison as just a way of giving something a precedence ranking over something else.</p>

<p>So, think of these strings as being a number, the smaller the number, the lower level in the tree the string will occupy. You're simply making your tree sort by smallest numbers first. <code>A</code> is smaller than <code>B</code>, <code>B</code> is smaller than <code>C</code> and so on.</p>

<p>Check out <a href=""https://stackoverflow.com/questions/6203411/comparing-strings-by-their-alphabetical-order"">this related question</a> for coming up with a comparison function to give you the ""numbers"" you're looking for.</p>
","10068195"
"writing binary data (std::string) to an std::ofstream?","3582","","<p>I have an <code>std::string</code> object containing binary data which I need to write to a file. Can <code>ofstream f(""name""); f &lt;&lt; s;</code> be problematic in any way? I need to read the data back exactly as it was originally.</p>

<p>I can of course use <code>fwrite(s.c_str(), s.size(), 1, filep)</code>, are there any pros / cons to either method?</p>
","<p>You should be ok as long as you open the ofstream for binary access.</p>

<pre><code>ofstream f(""name"", ios::binary | ios::out); 
f &lt;&lt; s;
</code></pre>

<p>Don't forget to open your file in binary mode when reading the data back in as well.</p>
","5355217"
"c++ read (big endian) binary float","3574","","<p>I have a binary file that contains n single-precision values. I know that the format used when writing data was big-endian. When I read in the data into a float vector ('mainvector' in the code below), by default, the data is read in according to little-endian format. I use the following to read data:</p>

<pre><code>ifstream inputfile(""filepath"",ifstream::in|ifstream::binary)
inputfile.read(reinterpret_cast&lt;char*&gt;(&amp;mainvector[0]), n*4);
inputfile.close()
</code></pre>

<p>There is a lot of discussion on endianness and conversion on stackoverflow itself. However, this is the first time I have to deal with the endianness issue and all the information available is a bit overwhelming. In the process I learned that the bytes are reversed (big vs. little endian).</p>

<p>Is there a one-liner that I can incorporate to change the default little-endian treatment of my binary data to big-endian, or post-process my <em>mainvector</em> in order to get the original data ? or would I need to manually reverse byte-order of each of the n values ?</p>

<p><strong>UPDATE</strong>: It appears that there is no one-liner for this. Individually changing the byte order is the way to do it! How to do that is discussed here by Mats and elsewhere (e.g. <a href=""http://www.gamedev.net/page/resources/_/technical/game-programming/writing-endian-independent-code-in-c-r2091"" rel=""nofollow"">here</a>).</p>
","<p>You will need to reverse each value individually. So something like this would work:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;fstream&gt;

int main()
{
    const int n = 34;
    float mainvector[n];

    std::ifstream inputfile;

    for(int i = 0; i &lt; n; i++)
    {
    unsigned char temp[sizeof(float)];
    inputfile.read(reinterpret_cast&lt;char*&gt;(temp), sizeof(float));
    unsigned char t = temp[0];
    temp[0] = temp[3];
    temp[3] = t;
    t = temp[1];
    temp[1] = temp[2];
    temp[2] = t;
    mainvector[i] = reinterpret_cast&lt;float&amp;&gt;(temp);
    }
}
</code></pre>

<p>You may be able to use some form of built in function to swap the order, but that will make it compiler specific... </p>
","19081635"
"Python: convert a byte to binary and shift its bits?","3572","","<p>I want to convert an encoding to another encoding in Python for a school project. However, the encoding I am translating from will add a padding to its encoding on the first bit.</p>

<p>How do I shift an binary number sequence to the left by one, so that it goes from:</p>

<p>00000001 11001100 01010101 and so on</p>

<p>to</p>

<p>00000011 10011000 10101010 and so on</p>

<p>so the end result's lowest bit will be the former's highest bit number?</p>
","<p>You can convert the string to one big integer and then do the left-shift (and then convert the big integer back into a string):</p>

<pre><code>large_int = bytes2int(mystring)
large_int &lt;&lt;= 1
mystring = int2bytes(large_int)
</code></pre>

<p>using e.g. this simplistic implementation:</p>

<pre><code>def bytes2int(str):
    res = ord(str[0])
    for ch in str[1:]:
        res &lt;&lt;= 8
        res |= ord(ch)
    return res

def int2bytes(n):
    res = []
    while n:
        ch = n &amp; 0b11111111
        res.append(chr(ch))
        n &gt;&gt;= 8
    return ''.join(reversed(res))

bytes = 'abcdefghijklmnopqrstuv'
assert int2bytes(bytes2int(bytes)) == bytes
</code></pre>
","31884957"
"read binary file into a 2d array matlab","3572","","<p>I use this code fragment to read a binary file into a array</p>

<pre><code> fid=fopen('data.bin','rb') % opens the file for reading
 A = fread(fid, count, 'int16') % reads _count_ elements and stores them in A
</code></pre>

<p>But it reads the file into a 1 dimensional array. Is there a direct method to read a binary file into a 2d array without me having to write loops to do that ?</p>
","<p>I believe this is what you need:</p>

<pre><code>fid = fopen('data.bin','rb');
A = fread(fid, [rows columns], 'int16')
</code></pre>
","8053987"
"Converting Dot Decimal IP Address to Binary (Python)","3567","","<p>I need a program that would convert a user inputted IPv4 Address to a Binary and Base 10 Address. Something like this:</p>

<pre><code>input: 142.55.33.1
output (base 10): [2385977601]
output (base 2): [10001110 00110111 00100001 00000001]
</code></pre>

<p>So far I have managed to convert it into a base10 address but I can't seem to get around the base 2 problem:</p>

<pre><code>#!/usr/bin/python3

ip_address = input(""Please enter a dot decimal IP Address: "")

#splits the user entered IP address on the dot
ListA = ip_address.split(""."")
ListA = list(map(int, ListA))

ListA = ListA[0]*(256**3) + ListA[1]*(256**2) + ListA[2]*(256**1) + ListA[3]
print(""The IP Address in base 10 is: "" , ListA)

#attempt at binary conversion (failing)
#ListA = ListA[0]*(2**3) + ListA[1]*(2**2) + ListA[2]*(2**1) + ListA[3]
#print(""The IP Address in base 2 is: "" , ListA)
</code></pre>

<p>Any help would be greatly appreciated. Thank you. </p>
","<p>Use <code>format</code>:</p>

<pre><code>&gt;&gt;&gt; text = '142.55.33.1'
&gt;&gt;&gt; ' ' .join(format(int(x), '08b') for x in text.split('.'))
'10001110 00110111 00100001 00000001'
</code></pre>

<p>In case if you want a list:</p>

<pre><code>&gt;&gt;&gt; [format(int(x), '08b') for x in text.split('.')]
['10001110', '00110111', '00100001', '00000001']
</code></pre>

<p>Here format converts an integer to its binary string representation:</p>

<pre><code>&gt;&gt;&gt; format(8, 'b')
'1000'
&gt;&gt;&gt; format(8, '08b')  #with padding
'00001000'
</code></pre>
","19744253"
"Any difference between text file and ascii file?","3559","","<p>I hear the 2 words ""text file"" and ""ascii file"". Is there any difference between these 2 terms or they mean the same thing?</p>
","<p>Ascii refers to <a href=""http://en.wikipedia.org/wiki/ASCII"" rel=""nofollow"">ASCII</a> encoding where text file is general file containing text in any encoding.</p>
","7685478"
"How to get the endianness type in PHP?","3551","","<p>In C# I can get the endianness type by this code snippet:</p>

<pre><code>if(BitConverter.IsLittleEndian)
{
   // little-endian is used   
}
else
{
   // big-endian is used
}
</code></pre>

<p>How can I do the same in PHP?</p>
","<p>PHP's string type is an 8-bit binary string, a <code>char</code> sequence. It has no endianness.  Thus for the most part endianness is a non-issue in PHP.</p>

<p>If you need to prepare binary data in a specific endianness, use the <a href=""http://www.php.net/manual/en/function.pack.php"" rel=""noreferrer""><code>pack()</code></a> and <a href=""http://www.php.net/manual/en/function.unpack.php"" rel=""noreferrer""><code>unpack()</code></a> functions.</p>

<p>If you need to determine the machine's native endianness, you can use <code>pack()</code> and <code>unpack()</code> in the same way.</p>

<pre><code>function isLittleEndian() {
    $testint = 0x00FF;
    $p = pack('S', $testint);
    return $testint===current(unpack('v', $p));
}
</code></pre>
","9745170"
"Is there a C library that converts integers to hexadecimal or binary?","3550","","<p>Is there a library function that takes in an integer and converts it to a single-byte hexadecimal or binary number?</p>

<p>For example, if I passed it the input of <code>64</code>, it would output <code>0x40</code>.</p>
","<p>For hex numbers, you can use <code>sprintf</code>:</p>

<pre><code>char buff[80];
sprintf(buff, ""0x%02x"", 64);
</code></pre>
","9636892"
"TFS and storing binary files","3544","","<p>Our project group stored binary files of the project that we are working on in SVN repository for over a year, in the end our repository grew out of control, taking backups of SVN repo became impossible at one point since each binary that is checked in is around 20 MB.</p>

<p>Now we switched to TFS,we are not responsible for backing the repository up, our IT tream takes care of it and we have more network and storage capacity for backups because of that but we want to decide what to do with the binaries. As far as I know TFS stores deltas and for binary files but deltas will be huge, but we might end up reaching our disk space quota one day, so I would like to plan things better from the start, I don't want to get caught up in a bad situation when it's too late to fix the problem.</p>

<p>I would prefer not keeping builds in the source control but our project group insists to keep a copy of every binary for reproducing the problems that we see in the production system, I can't get them to get the source code from TFS, build it and create the binary, because it is not straightforward according to them. </p>

<p>Does TFS offer a better build versioning method? If someone can share some insight I'd really be grateful.</p>
","<p>As a general rule you should not be storing build output in TFS. Occasionally you may want to store binaries for common libraries used by many applications but tools such as nuget get around that.</p>

<p>Build output has a few phases of its life and each phase should be stored in a separate place. e.g.</p>

<p><strong>Build output:</strong> When code is built (by TFS / Jenkins / Hudson etc.) the output is stored in a drop location. This storage should be considered volatile as you'll be producing a lot of builds, many of which will be discarded.</p>

<p><strong>Builds that have been passed to testers:</strong> These are builds that have passed some very basic QA e.g. it compiles, static code analysis tools are happy, unit tests pass. Once a build has been deemed good enough to be given to test it should be moved from the drop location to another area. This could be a network share (non production as the build can be reproduced) there may be a number of builds that get promoted during the lifetime of a project and you will want to keep track of what versions the testers are using in each environment.</p>

<p><strong>Builds that have passed test and are in production:</strong> Your test team deem the build to be of a high enough quality to ship. As part of your go live process, you should take the build that has been signed off by test and store it in a 3rd location. In <a href=""http://en.wikipedia.org/wiki/ITIL"" rel=""nofollow"">ITIL</a> speak this is a <a href=""http://en.wikipedia.org/wiki/Definitive_Media_Library"" rel=""nofollow"">Definitive Media Library</a>. This can be a simple file share, but it should be considered to be ""production"" and have the same backup and resilience criteria as any other production system. </p>

<p>The DML is the place where you store the binaries that are in production (and associated configuration items such as install instructions, symbol files etc.) The tool producing the build should also have labelled the source in TFS so that you can work out what code was used to produce the binary. Your branching strategy will also help with being able to connect the binary to the code.</p>

<p>It's also a good idea to have a ""live like"" environment, this should be separate from your regular dev and test environments. As the name suggests it contains only the code that has been released to production. This enables you to quickly reproduce bugs in production</p>
","14899248"
"C++ binary file I/O to/from containers (other than char *) using STL algorithms","3536","","<p>I'm attempting a simple test of binary file I/O using the STL copy algorithm to copy data to/from containers and a binary file. See below:</p>

<pre><code> 1 #include &lt;iostream&gt;
 2 #include &lt;iterator&gt;
 3 #include &lt;fstream&gt;
 4 #include &lt;vector&gt;
 5 #include &lt;algorithm&gt;
 6 
 7 using namespace std;
 8
 9 typedef std::ostream_iterator&lt;double&gt; oi_t;
10 typedef std::istream_iterator&lt;double&gt; ii_t;
11 
12 int main () {
13
14   // generate some data to test
15   std::vector&lt;double&gt; vd;
16   for (int i = 0; i &lt; 20; i++)
17   {
18     double d = rand() / 1000000.0;
19     vd.push_back(d);
20   }
21 
22   // perform output to a binary file
23   ofstream output (""temp.bin"", ios::binary);
24   copy (vd.begin(), vd.end(), oi_t(output, (char *)NULL));
25   output.close();
26 
27   // input from the binary file to a container
28   std::vector&lt;double&gt; vi;
29   ifstream input (""temp.bin"", ios::binary);
30   ii_t ii(input);
31   copy (ii, ii_t(), back_inserter(vi));
32   input.close();
33 
34   // output data to screen to verify/compare the results
35   for (int i = 0; i &lt; vd.size(); i++)
36     printf (""%8.4f  %8.4f\n"", vd[i], vi[i]);
37 
38   printf (""vd.size() = %d\tvi.size() = %d\n"", vd.size(), vi.size());
39   return 0;
40 }
</code></pre>

<p>The resulting output is as follows and has two problems, afaik:</p>

<pre><code>1804.2894  1804.2985
846.9309    0.9312
1681.6928    0.6917
1714.6369    0.6420
1957.7478    0.7542
424.2383    0.2387
719.8854    0.8852
1649.7605    0.7660
596.5166    0.5171
1189.6414    0.6410
1025.2024    0.2135
1350.4900    0.4978
783.3687    0.3691
1102.5201    0.5220
2044.8978    0.9197
1967.5139    0.5114
1365.1805    0.1815
1540.3834    0.3830
304.0892    0.0891
1303.4557    0.4600
vd.size() = 20  vi.size() = 20
</code></pre>

<p>1) Every <code>double</code> read from the binary data is missing the information before the decimal place.
2) The data is mangled at the 3rd decimal place (or earlier) and some arbitrary error is being introduced.</p>

<p>Please any help would be appreciated. (I would love for someone to point me to a previous post about this, as I've come up short in my search)</p>
","<p>For the question 1) You need to specify a separator (for example a space). The non-decimal part was stuck to the decimal part of the previous number. Casting and using NULL is generally wrong in C++. Should have been a hint ;)</p>

<pre><code>copy (vd.begin(), vd.end(), oi_t(output, "" "")); 
</code></pre>

<p>For the question 2)</p>

<pre><code>#include &lt;iomanip&gt;
output &lt;&lt; setprecision(9);
</code></pre>
","1855756"
"Convert binary to hex to decimal","3526","","<p>I have the binary number 1010 1011. I know that this is AB in hex and I know that A = 10 and B = 11 in decimal. But how do I get from 10 and 11 in decimal to the final number of 171?</p>

<p>With hex I would do</p>

<pre><code>             A            B
0xAB = (10 * 16^1) + (11 * 16^0) = 171
</code></pre>

<p>Can I do something similar with the decimal numbers to go from 10 and 11 to 171? Basically, I'm just looking for a fast way to convert any binary number without a calculator.</p>
","<p>I don't think there's a much easier way than A &times; 16 + B.</p>
","9852928"
"How to check if a number is a multiple of 6?","3522","","<p>I would like an alogrithm that would use only shift, add or subtract operations to find whether a number is a multiple of 6.  So, basically just binary operations.</p>

<p>So far I think I should logical right shift the number twice to divide by 4 and then subtract 6 once from it.  But I know something is wrong with my approach and cannot figure out what.  </p>
","<p>how about keep subtracting the number by 6 until it reaches zero.
If you get zero the number is divisible by 6 otherwise not.
OR
keep dividing the number by 2 (shift operation on binary) until the number is less than 12.
then subtract 6 from it . If less than zero  (not divisible )
if zero divisible.
if not subtract 3 
 If less than zero  (not divisible )
if zero divisible.</p>
","9731952"
"Count how many pixels are in a binary image","3504","","<p>I want to count the pixels on a binary image in a row. But, i need to count all layers i have and the pixels black in the layer on black and the pixels white in that layers white.</p>

<p>Sorry for my english ...
My code is:</p>

<pre><code>I = rgb2gray(imread('pass_p.png'));
level = graythresh(I);
bw = im2uint8(im2bw(I,level));

imshow(bw);
[Nx, Ny] = size(I);
cP = 0;
cB = 0;

%Vectores
B = zeros(1,9);
P = zeros(1,9);
for k = 2:Ny-1
    index = 1;
    if(bw(((Nx-1)/2),k ) == 0) %preto
        cP = cP + 1;
        if(bw(((Nx-1)/2)-1, (k-1)) == 255)
            B(1,index) = B(1,cB);
            cB = 0;
            index = index +1;  
        end
      end
      if(bw(((Nx-1)/2),k) == 255) %branco
          cB = cB + 1;
      if(bw(((Nx-1)/2)-1, (k-1)) == 0)
          P(1,index) = P(1,cP);
          cP = 0;
          index = index +1;
      end
     end
    end
</code></pre>

<p>My objective is detect a crosswalk. 
Thanks for your spend time :) </p>

<p><strong>EDIT</strong></p>

<p>This is an example image :</p>

<p><img src=""https://i.stack.imgur.com/MpgXO.png"" alt=""enter image description here""></p>
","<p>I'm not sure to understand the question but there something to count number of black pixels in a bw image.</p>

<pre><code>I = rgb2gray(imread('pass_p.png'));

bw = im2bw(I,graythresh(I));

figure;imshow(bw);

[Nx,Ny] = size(bw);
BlackPixelCount = zeros(Nx,1);
WhitePixelCount = zeros(Nx,1);

for it = 1:Nx
   blackPixel = find(bw(it,:) == 0);
   BlackPixelCount(it) = size(blackPixel,1);
   WhitePixelCount(it) = Ny -  BlackPixelCount(it);
end
</code></pre>

<p><strong>EDIT</strong></p>

<p>This is for a dumb example. So we expect to have only 1 row or column selected on the way of the crosswalk.</p>

<pre><code>v = [1 1 1 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0];
w =[ 1 v 1];

InvV = ~v;

w2 = [1 InvV 1];


runs_zeros = find(diff(w)==1)-find(diff(w)==-1); % lenghts of runs of 0's
runs_ones= find(diff(w2)==1)-find(diff(w2)==-1); % lenghts of runs of 1's

nbBlackBand = size(runs_zeros,2);
nbWhiteBand = size(runs_ones,2);
</code></pre>

<p>So after that you know you have the lenght of every band and the number of band of each sort. You can maybe take multiple line in your image and do the mean of that to get the mean of pixel per band. Otherwise you just have 1 sample.</p>
","20250785"
"How to write data in specified format into a binary file with Perl?","3501","","<p>this might be quite a newbie question, but i need to process a certain text file and dump its content into a binary file and i do not know how - i decided to use perl, but my perl skills are quite low. I probably should have written this in C++, but this seem like a nice and easy task for perl, so why not learn something new? ;) The text file has thousands of lines in this format:</p>

<p><code>2A02FC42 4</code></p>

<p>You can look at it as a hexadecimal number (the length is <strong>ALWAYS</strong> 8) and a regular number. Now i need to dump all the lines into a binary file in this format (it should look like this when viewed with a hex editor):</p>

<p><code>42FC022A00000004</code></p>

<p>More examples so it is clear:</p>

<p><code>70726F67 36</code> ->  <code>676F727000000024</code> <br/>
<code>6A656374 471</code> ->  <code>7463656A000001D7</code> <br/></p>

<p>The part of parsing the input file is easy, but i'm stuck on the second part, where i should write this into a binary file. I have no idea how to format the data in this way or even how to output things in binary mode. Can someone help me out here?</p>

<p>Thanks.</p>

<p>EDIT: updated the examples, forgot about endiannes - im on a LE system.</p>
","<p>Use <a href=""http://perldoc.perl.org/functions/pack.html"" rel=""nofollow noreferrer""><code>pack</code></a>:</p>

<pre><code>#! /usr/bin/perl

use warnings;
use strict;

# demo only    
*ARGV = *DATA;

while (&lt;&gt;) {
  my($a,$b) = split;
  $a = join """", reverse $a =~ /(..)/g;
  $b = sprintf ""%08x"", $b;

  print pack ""H*"" =&gt; $a . $b;
}

__DATA__
2A02FC42 4
70726F67 36
6A656374 471
</code></pre>

<p>Sample run:</p>

<pre>$ ./prog.pl | od -t x1
0000000 42 fc 02 2a 00 00 00 04 67 6f 72 70 00 00 00 24
0000020 74 63 65 6a 00 00 01 d7
0000030</pre>
","3522588"
"Is there a Fiddler plugin for binary XML?","3489","","<p>Fiddler has <a href=""http://www.fiddler2.com/Fiddler2/extensions.asp"" rel=""noreferrer"">many useful extensions</a>.  However, I can't find one that understands WCF's binary-encoded SOAP envelopes.  (Content-Type: application/soap+msbin1)</p>

<p>Suggestions for comparable (non-Fiddler) tools are welcome too.</p>
","<p>After lots of work on ancillary stuff that doesn't really matter (eg decided to roll my own quick-n-dirty recursive descent XML parser), I've just committed the first checkin where the plugin actually does its job in a usable fashion.  Still extremely rough around the edges, with many features not implemented, but if you want to see binary WCF in Fiddler now's your chance!</p>

<p>Source code only for now: <a href=""http://tfstoys.codeplex.com/sourcecontrol/changeset/view/26191?projectName=tfstoys#BinaryXMLInspector"" rel=""noreferrer"">http://tfstoys.codeplex.com/sourcecontrol/changeset/view/26191?projectName=tfstoys#BinaryXMLInspector</a></p>

<p>I'll post binaries on CodePlex when it's polished enough for general consumption.  Probably won't remember to update this ""answer"" though.  If you're reading this months/years from now, be sure to click over to the Downloads page -- or at minimum, grab the latest source instead of this changeset.</p>
","1320981"
"Displaying histogram pixel values from PGM image (p5) using Pure C without any image processing library","3486","","<p>This question is challenging to get more understanding on Image Processing using pure C. I have done a simple program reading non-binary PGM file using C compiled with GCC. Now, it is becoming a problem when I try to read binary PGM file. This binary PGM file can be acquired by converting <strong>JPG</strong> to <strong>PGM</strong> using <a href=""http://www.irfanview.com/"" rel=""nofollow"">IrvanView</a>. </p>

<p><strong>NOTE:</strong> Please don't answer with any image processing library (such as: OpenCV).</p>

<p>My current code is: </p>

<pre><code>#include    &lt;stdio.h&gt; 
#include    &lt;stdlib.h&gt;
#define WIDTH 1024  
#define HEIGHT 768
#define READ_IMAGE_NAME ""MY_PGM_FILE_NAME.pgm""

void print_histogram_table(int *histog);

main() {
  FILE *fp;

  int i,j, height= HEIGHT, width=WIDTH;
  char line[100];

  // Color depth is 255. 
  unsigned char pixel_value;

  fp = fopen(READ_IMAGE_NAME,""r"");

  // get the first four lines.
  fgets (line,100,fp); 
  fgets (line,100,fp);
  fgets (line,100,fp);
  fgets (line,100,fp);

  // Histogram helper
  int histo[65536];
  int x;
  for ( x =0; x &lt; 65536; x++) {    
        histo[x] = 0;
  }

  for(j=0;j&lt;height;j++) {
     for(i=0;i&lt;width;i++) {
         fread(&amp;pixel_value, sizeof(unsigned char), 1, fp);
         // Turn on the code below, if you want to check color on specific row and column.
//             printf(""row num. %d column num. %d    pixel value=%d\n"",j,i,pixel_value);  

       histo[pixel_value]++;
     }
  }

  // Make histogram
  print_histogram_table(histo);

  fclose(fp);       
  getch();
}

void print_histogram_table(int *histog)
{
  int x; 
  for (x= 0; x &lt; 255; x++) {
     if ( histog[x] != 0)
        printf(""Color number %d count %d\n"", x, histog[x]); 
  }
}
</code></pre>

<p>I have read some pages related to my problem [<a href=""http://www.cplusplus.com/forum/general/2393/"" rel=""nofollow"">How to read .PGM format file?</a>] , but I cannot find any clear and simple answer. I apologize for any mistake in my code. Any suggestion and critic regarding my code would be appreciated.  </p>

<p>My script above could not display correct color histogram, because if you think rationally, you might get pixel color above 100 (not only below 100). So, the main question is <strong>How to fix this problem?</strong></p>

<p><strong>EDIT I</strong></p>

<ul>
<li>Add PGM image. <a href=""https://docs.google.com/leaf?id=0B1jK9RMcqhcvNmQyNjk5MGItMjcyNS00MmY1LWJiZjEtYjE5NjNkY2E0MDlk&amp;hl=en_US"" rel=""nofollow"">PGM Image Sample</a> </li>
<li>Add function to create image histogram.</li>
</ul>

<p><strong>EDIT II</strong></p>

<ul>
<li>Add one more <em>fgets</em>, see <a href=""https://docs.google.com/leaf?id=0B1jK9RMcqhcvNmQyNjk5MGItMjcyNS00MmY1LWJiZjEtYjE5NjNkY2E0MDlk&amp;hl=en_US"" rel=""nofollow"">sample image</a>. </li>
</ul>
","<blockquote>
  <p>My script above could not display correct color histogram, because if you think rationally, you might get pixel color above 100 (not only below 100). So, the main question is How to fix this problem?</p>
</blockquote>

<p>I'm assuming you mean:</p>

<blockquote>
  <p>Right now, running this program on the linked image only displays non-zero histogram entries for pixel values below 100.  I know of at least one pixel value in the image above 100, so there's a bug in my code.  Can anyone help me figure out why this happens?</p>
</blockquote>

<p>I suggest you re-phrase your question to make this clear.</p>

<p>The code superficially looks OK, assuming you only want it to work on the image you linked to.  However, there a lots of small mistakes that may add up.  Here are a few suggestions:</p>

<h3>Histogram size</h3>

<p>First, you can't print your entire histogram.  Consider passing the histogram size to the function that prints the histogram.  Moreover, even if the sizes <em>did</em> match (both 256), you would still have an error.  You never print the 256th value.</p>

<pre><code>int histo[65536];
// ...
print_histogram_table(histo);
// ...
void print_histogram_table(int *histog)
{
    int x; 
    for (x= 0; x &lt; 255; x++) {
       if ( histog[x] != 0)
          printf(""Color number %d count %d\n"", x, histog[x]); 
}
</code></pre>

<h3>Binary I/O</h3>

<p>You need to specify ""binary"" I/O when opening binary files.  On UNIX, this traditionally makes no difference because it is the default mode.  However, on Windows (I'm assuming your running Windows since you're using Irfan View), you need to explicitly state that you want binary I/O.</p>

<p>This is a common mistake when dealing with binary files for the first time.  Basically, as soon as the <code>fread()</code> call catches an <code>EOF</code> byte, it will <em>stop reading the file</em> and you will get garbage values for all subsequent reads (probably copies of the last real byte), which means you're not actually reading your entire image.</p>

<pre><code>fp = fopen(READ_IMAGE_NAME,""r"");
// change to:
fp = fopen(READ_IMAGE_NAME,""rb"");
</code></pre>

<h3>Other minor concerns</h3>

<p>There are loads of things not handled by your code:</p>

<ol>
<li>PNM files may have comments at the beginning of the file</li>
<li>Lines may have more than 100 characters.</li>
<li>Image size is not forcibly 1024x768</li>
<li>It's not much use to hardcode the name of the file in the program, even for just testing your code.</li>
<li>If you actually get a 16-bit-per-pixel grayscale image, your histogram is large enough, but you should be reading 2-byte values.</li>
</ol>
","7455994"
"Binary Data To Unicode","3481","","<p>Among all the encodings available here <a href=""http://docs.python.org/library/codecs.html"" rel=""nofollow"">http://docs.python.org/library/codecs.html</a>
which one is the one I should use for decoding binary data into unicode without it becoming corrupted when I encode it back to string?</p>

<p>I've used raw_unicode_data and it doesn't work.</p>

<p>Example: I upload picture in a POST (but not as file attachment). Django converts POST data to unicode using utf-8. However when converting back from unicode to string (again using utf-8), data becomes corrupted. I used raw_unicode_data and the same happened (though only a few bytes this time). Which encoding should I use so that the decode and encode steps don't corrupt the data.</p>
","<p>""Binary data"" is not text, therefore converting it to a <code>unicode</code> is meaningless. If there is text embedded in the binary data then extract it first and decode using the encoding given in the specification for the data format.</p>
","5095024"
"Binary representation in C","3479","","<p>In C why is there no standard specifier to print a number in its binary format, sth like <code>%b</code>. Sure, one can write some functions /hacks to do this but I want to know why  such a simple thing is not a standard part of the language. </p>

<p>Was there some design decision behind it? Since there are format specifiers for octal %o and %x for hexadecimal is it that octal and hexadecimal are somewhat ""more important"" than the binary representation. </p>

<p>Since In C/C++ one often encounters bitwise operators I would imagine that it would be useful to have <code>%b</code> or directly input a binary representation of a number into a variable (the way one inputs hexadecimal numbers like <code>int i=0xf2</code> )</p>

<p>Note: Threads like <a href=""https://stackoverflow.com/questions/111928/is-there-a-printf-converter-to-print-in-binary-format"">this</a>  discuss only the 'how' part of doing this and not the 'why'</p>
","<p>The main reason is 'history', I believe.  The original implementers of <code>printf()</code> et al at AT&amp;T did not have a need for binary, but did need octal and hexadecimal (as well as decimal), so that is what was implemented.  The C89 standard was fairly careful to standardize existing practice - in general.  There were a couple of new parts (locales, and of course function prototypes, though there was C++ to provide 'implementation experience' for those).</p>

<p>You can read binary numbers with <code>strtol()</code> et al; specify a base of 2.  I don't think there's a convenient way of formatting numbers in different bases (other than 8, 10, 16) that is the inverse of <code>strtol()</code> - presumably it should be <code>ltostr()</code>.</p>
","8372696"
"How does MATLAB read and interpret binary digits from a .bin file?","3465","","<p>I have a binary file with .bin extension. This file is created by a data acquisition software. Basically a ""measurement computing"" 16-bit data-acquisition hardware is receiving signals from a transducer(after amplified by an amplifier) and sending this to PC by a USB. A program/software then is generating a .bin file corresponding received serial data from data aq. hardware. There are several ways to read this .bin file and plot the signal in MATLAB. </p>

<p>When I open this .bin file with a hexeditor I can see the ASCII or ones and zeros (binary). The thing is I don't know how to interpret this knowledge. There are 208000 bytes in the file obtained in 16 seconds. I was thinking each 2 bytes corresponds to a sample since the DAQ device has 16 bit resolution. So I thought for example a 16-bit data such as 1000100111110010 is converted by MATLAB to a corresponding voltage level. But I tried to open two different .bin files with different voltage levels such as 1V and 9V and still teh numbers do not seem to be related what I think.</p>

<p>How does MATLAB read and interpret binary digits from a .bin file? </p>

<p>Thnx,</p>
","<p>Assuming your .bin file is literally just a dump of the values recorded, you can read the data using <code>fread</code> (see <a href=""http://www.mathworks.co.uk/help/matlab/ref/fread.html"" rel=""nofollow"">the documentation</a> for more info):</p>

<pre><code>fid = fopen('path_to_your_file', 'r');
nSamples = 104000;
data = fread(fid, nSamples, 'int16');
fclose(fid);
</code></pre>

<p>You will also need to know, however, whether this data is signed or unsigned - if it's unsigned you can use <code>'uint16'</code> as the third argument to <code>fread</code> instead. You should also find out if it's big-endian or little-endian... You should check the original program's source code.</p>

<p>It's a good idea to record the sample rate at which you make acquisitions like this, because you'll be hard pressed to do anything but trivial analysis on it afterwards without knowing this information. Often this kind of data is stored in .wav files, so that both the data and its sample rate (and the bit depth, in fact) are stored in the file. That way you don't need a separate bit of paper to go along with your file (also, reading .wav files in MATLAB is extremely easy).</p>
","16464949"
"Perl Decimal to Binary 32-bit then 8-bit","3464","","<p>I've got a number (3232251030) that needs to be translated from Decimal to Binary.
Once I've gotten the binary, I need to separate 8-bits of it into digits, revealing an ip address.</p>

<p>Converting Decimal to Binary is simple:</p>

<pre><code>sub dec2bin { my $str = unpack(""B32"", pack(""N"", shift)); $str =~ s/^0+(?=\d)//; # otherwise you'll get leading zeros return $str; }

sub bin2dec { return unpack(""N"", pack(""B32"", substr(""0"" x 32 . shift, -32))); }

e.g. $num = bin2dec('0110110'); # $num is 54 $binstr = dec2bin(54); # $binstr is 110110
</code></pre>

<p>Reference: <a href=""http://www.perlmonks.org/?node_id=2664"" rel=""nofollow"">http://www.perlmonks.org/?node_id=2664</a></p>

<p>So now, I need to split 8 digits off the binary and save it into numbers that makes an IP address.</p>

<pre><code>$num = dec2bin('3232251030');
</code></pre>

<p>($num is ""11000000 10101000 01000100 00001110"" in binary)</p>

<p>I need to split and save each 8-bits ""11000000 10101000 01000100 00001110"" into ""192.168.60.150"".</p>

<p>Care to advice? I'm looking into split function for this..</p>
","<p>You don't actually have to convert to a binary string, just a 32-bit integer:</p>

<pre><code>print join '.', unpack('CCCC', pack('N', 3232251030));
</code></pre>

<p>will print <code>192.168.60.150</code></p>
","6463991"
"Python: slicing a very large binary file","3464","","<p>Say I have a binary file of 12GB and I want to slice 8GB out of the middle of it. I know the position indices I want to cut between.</p>

<p>How do I do this? Obviously 12GB won't fit into memory, that's fine, but 8GB won't either... Which I thought was fine, but it appears binary doesn't seem to like it if you do it in chunks! I was appending 10MB at a time to a new binary file and there are discontinuities on the edges of each 10MB chunk in the new file.</p>

<p>Is there a Pythonic way of doing this easily? </p>
","<p>Here's a quick example.  Adapt as needed:</p>

<pre><code>def copypart(src,dest,start,length,bufsize=1024*1024):
    with open(src,'rb') as f1:
        f1.seek(start)
        with open(dest,'wb') as f2:
            while length:
                chunk = min(bufsize,length)
                data = f1.read(chunk)
                f2.write(data)
                length -= chunk

if __name__ == '__main__':
    GIG = 2**30
    copypart('test.bin','test2.bin',1*GIG,8*GIG)
</code></pre>
","2364633"
"Binary operator '|' cannot be applied to operands of type 'Int' and 'UInt8'","3453","","<p>I wish to perform simple <code>or</code> logic on 2 bit maps, yet Swift thinks this is wrong:</p>

<pre><code>let u: UInt8 = 0b1
let i: Int = 0b10
i | u // Binary operator '|' cannot be applied to operands of type 'Int' and 'UInit8'
</code></pre>

<p>Any way to conform to type inference and still have this working? </p>

<p>I could always do <code>i | Int(u) // 3</code> but this, I think, is not optimal.</p>
","<p>One of the fundamental principles of Swift is that is does not implicitly
convert between types.</p>

<pre><code>let u: UInt8 = 0b1
let i: Int = 0b10
i | Int(u)
</code></pre>

<p>forces you to think about the necessary conversions and what type the result should have,
so that <em>is</em> the correct solution (in my opinion).</p>

<p>Let's consider another example:</p>

<pre><code>let u: UInt8 = 128
let i: Int8 = -128
</code></pre>

<p>What should <code>u|i</code> be? Both</p>

<pre><code>u | UInt8(i)
Int8(u) | i
</code></pre>

<p>crash at runtime because <code>u</code> is not in the range of an <code>Int8</code>, and <code>i</code> is not 
in the range of an <code>UInt8</code>. Both </p>

<pre><code>u | UInt8(bitPattern: i)   // result is `UInt8`
Int8(bitPattern: u) | i    // result is `Int8`
</code></pre>

<p>would work, but how should the compiler choose between both?
 One could convert both to some larger type, for example</p>

<pre><code>Int(u) | Int(i)
</code></pre>

<p>but that type is somewhat arbitrary, how could it automatically be inferred from the compiler? And what is the ""larger type""
for <code>Int64</code> + <code>UInt64</code> arguments?</p>

<p>That's why I think that an explicit conversion is the right solution.</p>
","30124234"
"Java program that converts binary numbers to decimal numbers. The input is a string of zeros and ones","3449","","<p>I have to create a java program that converts binary to decimal using the following steps. Being new at this I did something, but I don't know what I did wrong or how to continue.</p>

<pre><code>public class BinaryToDecimal {
public static void main(String args[]){
    long sum = 0;
        int result;
        String s = ""1001010101011010111001011101010101010101"";
        for(int i = s.length()-1; i &lt;= 0; i--){
            result = (int)Math.pow(2, i);
            if(s.charAt(i) == '1')
                sum=sum + result;
        }
        System.out.println(sum);
    }
    }
</code></pre>

<p>Use a loop to read (charAt()) each digit (0/1 char) in the input string, scanning from right to left;</p>

<p>Use the loop to build the required powers of 2;</p>

<p>Use a conditional statement to deal with 0 and 1 separately;</p>

<p>Debug using simple input, e.g. 1, 10, 101, and print intermediate values in the loop.</p>

<p>Use your program to find the decimal value of the following binary number:</p>

<p>1001010101011010111001011101010101010101</p>
","<p>Do this only if your decimal value is at most 2147483647 or the maximum value an int can be in Java. If you don't know, just check the length of your string. If it's less than or equal to 32 i.e. 4 bytes, then you can use parseInt.:</p>

<pre><code>int decimalValue = Integer.parseInt(s, 2);
</code></pre>

<p>Refer <a href=""http://docs.oracle.com/javase/6/docs/api/java/lang/Integer.html#parseInt%28java.lang.String,%20int%29"" rel=""nofollow"">HERE</a> for more info on the Integer.parseInt(); </p>

<p>But if it's more, you can use your code. I  modified your loop which is where your problem was:</p>

<pre><code> String s = ""1001010101011010111001011101010101010101"";
 long result = 0;
 for(int i = 0; i &lt; s.length(); i++){
    result = (long) (result + (s.charAt(i)-'0' )* Math.pow(2, s.length()-i-1));
  }
    System.out.println(result);
</code></pre>
","28032592"
"Python write to file","3449","","<p>I've got a little problem here.
I'm converting binary to ascii, in order to compress data.
All seems to work fine, but when I convert '11011011' to ascii and try to write it into file, I keep getting error</p>

<p>UnicodeEncodeError: 'charmap' codec can't encode character '\xdb' in position 0: character maps to  </p>

<p>Here's my code:</p>

<pre><code>    byte = """"
    handleR = open(self.getInput())
    handleW = open(self.getOutput(), 'w')
    file = handleR.readlines()
    for line in file:
        for a in range(0, len(line)):
            chunk = result[ord(line[a])]
            for b in chunk:
                if (len(byte) &lt; 8):
                    byte+=str(chunk[b])
                else:
                    char = chr(eval('0b'+byte))
                    print(byte, char)
                    handleW.write(char)
                    byte = """"
    handleR.close()
    handleW.close()
</code></pre>

<p>Any help appreciated,</p>

<p>Thank You</p>
","<p>I think you want:</p>

<pre><code>handleR = open(self.getInput(), 'rb')
handleW = open(self.getOutput(), 'wb')
</code></pre>

<p>That will ensure you're reading and writing byte streams.  Also, you can parse binary strings without eval:</p>

<pre><code>char = chr(int(byte, 2))
</code></pre>

<p>And of course, it would be faster to use bit manipulation.  Instead of appending to a string, you can use <code>&lt;&lt;</code> (left shift) and <code>|</code> (bitwise or).</p>

<p>EDIT: For the actual writing, you can use:</p>

<pre><code>handleW.write(bytes([char]))
</code></pre>

<p>This creates and writes a <a href=""http://docs.python.org/release/3.0.1/library/functions.html#bytes"" rel=""nofollow noreferrer"">bytes</a> from a list consisting of a single number.</p>

<p>EDIT 2: Correction, it should be:</p>

<pre><code>handleW.write(bytes([int(byte, 2)]))
</code></pre>

<p>There is no need to use <code>chr</code>.</p>
","3115743"
"Perfmon .blg file specification / parsing library","3443","","<p>Where can I find a detailed, low-level spec for the Perfmon binary .blg file format? Or even better, has anyone written a low level, open source library (preferably in C, but any language would do) for parsing .blg files?</p>
","<p>This won't help for looking at historical data, but if you have access to the systems running Perfmon, you may want to look at <a href=""http://technet.microsoft.com/en-us/library/bb490956.aspx"" rel=""noreferrer"">Logman</a>. With Logman you can set performance counters AND specify the output format, that way you can just chose a format that is easy to parse. See the <code>-f</code> option:</p>

<p><code>-f { bin | bincirc | csv | tsv | SQL } : Specifies the file format used for collecting performance counter and trace data. You can use binary, circular binary, comma and tab separated, or SQL database formats when collecting performance counters.</code></p>

<p>As others have said if you also have historical records you need to parse you can use the <a href=""http://technet.microsoft.com/en-us/library/bb490958.aspx"" rel=""noreferrer"">Relog</a> utility to convert existing .blg files in to a more useful format.</p>
","6248264"
"How to return number in binary x86 assembly?","3437","","<p>so I'm saving an integer in one of my registers that is between 0 and 9, I'm trying to replace this value in the register with it's binary representation.</p>

<p>I was thinking using a shift method to do it but I'm not quite sure,</p>

<p>could anyone point me in the right direction?</p>

<p>Thanks</p>
","<p>You cannot replace a value in a register by its binary representation because it's already in binary.</p>

<p>If you want to get the individual bits of your number so you can print them, for example, you can just shift and test:</p>

<pre><code>;AX holds your number. x86 architecture. MS DOS.
          mov cx,16
          or ax,ax
GetBit:   js BitOne     ;We test for SIGN bit here (MSb)
          push ax
          mov ax,0e30h  ;putchar ('0')
          int 10h
          pop ax
          jmp EndBit
BitOne:   push ax
          mov ax,0e31h  ;putchar ('1')
          int 10h
EndBit:   shl ax,1      ;shift left
          loop GetBit
          ret
</code></pre>
","20200345"
"Decimal/Hexadecimal/Binary Conversion","3432","","<p>Right now I'm preparing for my AP Computer Science exam, and I need some help understanding how to convert between decimal, hexadecimal, and binary values by hand. The book that I'm using (Barron's) includes an example but does not explain it very well.</p>

<p>What are the formulas that one should use for conversion between these number types?</p>
","<p>Are you happy that you understand number bases? If not, then you will need to read up on this or you'll just be blindly following some rules. </p>

<p>Plenty of books would spend a whole chapter or more on this...</p>

<p>Binary is base 2, Decimal is base 10, Hexadecimal is base 16. </p>

<p>So Binary uses digits 0 and 1, Decimal uses 0-9, Hexadecimal uses 0-9 and then we run out so we use A-F as well.</p>

<p>So the position of a decimal digit indicates units, tens, hundreds, thousands... these are the ""powers of 10""</p>

<p>The position of a binary digit indicates units, 2s, 4s, 8s, 16s, 32s...the powers of 2</p>

<p>The position of hex digits indicates units, 16s, 256s...the powers of 16</p>

<p>For <strong>binary to decimal</strong>, add up each <code>1</code> multiplied by its 'power', so working from right to left:</p>

<pre><code>1001 binary = 1*1 + 0*2 + 0*4 + 1*8 = 9 decimal
</code></pre>

<p>For <strong>binary to hex</strong>, you can either work it out the total number in decimal and then convert to hex, or you can convert each 4-bit sequence into a single hex digit:</p>

<pre><code>1101 binary = 13 decimal = D hex

1111 0001 binary = F1 hex
</code></pre>

<p>For <strong>hex to binary</strong>, reverse the previous example - it's not too bad to do in your head because you just need to work out which of 8,4,2,1 you need to add up to get the desired value.</p>

<p>For <strong>decimal to binary</strong>, it's more of a long division problem - find the biggest power of 2 smaller than your input, set the corresponding binary bit to 1, and subtract that power of 2 from the original decimal number. Repeat until you have zero left.</p>

<p>E.g. for 87:</p>

<ul>
<li>the highest power of two there is 1,2,4,8,16,32,<strong>64</strong>!</li>
<li>64 is 2^6 so we set the relevant bit to 1 in our result: 1000000</li>
<li>87 - 64 = 23</li>
<li>the next highest power of 2 smaller than 23 is 16, so set the bit: 1010000</li>
<li>repeat for 4,2,1</li>
<li>final result 1010111 binary</li>
<li>i.e. 64+16+4+2+1 = 87 in decimal</li>
</ul>

<p>For <strong>hex to decimal</strong>, it's like binary to decimal, only you multiply by 1,16,256... instead of 1,2,4,8...</p>

<p>For <strong>decimal to hex</strong>, it's like decimal to binary, only you are looking for powers of 16, not 2. This is the hardest one to do manually.</p>
","9345545"
"Writing binary data","3427","","<p>I am writing to binary file using fstream and when open the file using binary flag.</p>

<p>I needed to write some text as binary, which a simple write did the trick.
The problem is that I need also to write (as shown in hexadecimal) 0. The value when opened in binary notepad is shown zero, but when tried to write this the value not zero it was value of 30 in hexadecimal.</p>

<p>How you write specific data like this?</p>
","<p>When you open the fstream use the <code>ios::binary</code> flag to specify binary output. More information can be found <a href=""http://www.cplusplus.com/doc/tutorial/files/"" rel=""nofollow noreferrer"">here</a>.</p>

<p>As for writing 0, when you see 30 in hexidecimal you are writing the <em>character</em> '0', not the binary number 0. To do that with an fstream you can do something like:</p>

<pre><code>my_fstream &lt;&lt; 0;
</code></pre>

<p>Keep in mind the binary data 0 has no textual representation, so you will not be able to read it in Notepad like you would be able to read the character '0'.</p>
","1400975"
"Using Haskell's Parsec to parse binary files?","3421","","<p>Parsec is designed to parse textual information, but it occurs to me that Parsec could also be suitable to do binary file format parsing for complex formats that involve conditional segments, out-of-order segments, etc. </p>

<p>Is there an ability to do this or a similar, alternative package that does this? If not, what is the best way in Haskell to parse binary file formats?</p>
","<p>You might be interested in <a href=""http://hackage.haskell.org/package/attoparsec"" rel=""noreferrer"">AttoParsec</a>, which was designed for this purpose, I think.</p>
","2425686"
"Converting a decimal number into binary","3415","","<p>I am currently reading Charles Petzold's book 'Code'. In it he explains how to convert a decimal number into binary using the following template:</p>

<pre><code>                [ ]   [ ]   [ ]   [ ]   [ ]   [ ]   [ ]   [ ]
                ÷128  ÷64   ÷32   ÷16   ÷8    ÷4    ÷2    ÷1
                [ ]   [ ]   [ ]   [ ]   [ ]   [ ]   [ ]   [ ]
</code></pre>

<p>In the book, his explanation on how to use the template reads:</p>

<p><em>""Put the entire decimal number (less than or equal to 255) in the box in the upper 
left corner. Divide that number (the dividend) by the first divisor (128), as 
indicated. Put the quotient in the box below (the box at the lower left corner), and 
the remainder in the box to the right (the second box on the top row). That first remainder is the dividend for the next calculation, which uses a divisor of 64. Continue in the same manner through the template.</em></p>

<p><em>Keep in mind that each quotient will be either 0 or 1. If the dividend is less than the divisor the quotient is 0 and the remainder is simply the dividend. if the dividend is greater than or equal to the divisor, the quotient is 1 and the remainder is the divider - the divisor. Here's how it's done with 150:""</em></p>

<pre><code>                [150]  [22]   [22]   [22]   [6 ]   [6 ]   [2 ]   [0 ]
                ÷128   ÷64    ÷32    ÷16    ÷8     ÷4     ÷2     ÷1
                [1 ]   [0 ]   [0 ]   [1 ]   [0 ]   [1 ]   [1 ]   [0 ]
</code></pre>

<p>But I'm puzzled! When I do the calculations as instructed, I'm getting very different results. What I'm doing is as follows:</p>

<p>150 ÷ 128 = <strong>1.171875</strong> (I don't see where the 22 comes from above?) So, I place a 1 in the box below the 150 and then carry the <strong>171875</strong> and use that as the dividend for the next calculation, which of course gets me into all sorts of problems, and ultimately, not the binary number 10010110!</p>

<p>Can somebody tell me where I'm going wrong? </p>
","<p>22 is the remainder of 150/128. </p>

<p>Since you've determined that there's 1 128 ""in"" 150, and given a value to that bit, you can forget about the 128 that's ""in"" 150, so you take it away from 150, leaving our 22. Then it's time for the digit worth 64: 64 doesn't go into 22, so that digit is a 0. And similarly for the digit worth 32. Then for the digit worth 16: 16 goes into 22 once, so there's a 1 digit there, and now you're done with the 16 ""in"" 22, so take it away -- leaving 6. And so on.</p>

<p>(Consider a similar base 10 case, let's say 309. Take the 100s column; there are 3 100s in 309, so you put a 3 there. And now there's 9 left over. Then take the 10s column; there are 0 10s in 9, so you put a 0 there. And then the 1s column: there are 9 1s in 9, so you put a 9 in there. And now there's nothing left -- you're done.)</p>

<p>I have a horrible feeling this might confuse more than clarify, but that's how I think of it anyway.</p>
","1591306"
"How many comparisons does 8 element Binary Heap need?","3413","","<p>This is a homework question, and I'm asked to show that 8 element Binary Heap needs 8 comparisons.</p>

<p>but when I use an example such: 1 2 3 4 5 6 7 8 
I'm not sure if I should go bottom up or top down.
but anyways, I've tried them both.</p>

<p>In top down:
I've done it in 8 steps but when I count the number of comparisons I get 13 :S</p>

<p>In bottum up:
I've done it in 7 steps but when I count the number of comparisons I get 10 :S</p>

<p>After Trying the algorithm here is the comparisons I got:</p>

<ol>
<li>H[L]=8 > H[i]=4 </li>
<li>H[L]=8 > H[i]=2, H[r]=5 > H[Largest]=8</li>
<li>H[L]=4 > H[i]=2</li>
<li>H[L]=6 > H[i]=3, H[r]=7 > H[Largest]=6</li>
<li>H[L]=8 > H[i]=1, H[r]=7 &lt; H[Largest]=8</li>
<li>H[L]=4 > H[i]=1, H[r]=5 > H[Largest]=4 </li>
</ol>

<p>hmmm, any help on how should I count the number of comparisons so I can show them 8?
and what method shall I use(bottom up or top down)?</p>
","<p>Building a Heap bottom-up is linear, top-down (or incrementally) is <code>O(n log n)</code>.</p>

<p>Try to follow the actual algorithm, don't just draw trees. I've seen that in too many exams, people drawing pretty trees but not following the alogrithm, which usually leads to incorrect results, inefficiencies etc. The tree is just the 'idea', not the 'method'. The method here actually uses an array.</p>

<p>Edit: bottom up starts at half of the heap size. So at element 4, and 7 comparisons:</p>

<pre><code>Level 3: 4 &lt; 8
Level 2: 3 &lt; 7, 3 &lt; 6
         2 &lt; 5, 2 &lt; 4
Level 1: 1 &lt; 3, 1 &lt; 2
</code></pre>

<p>Edit2: Max heap:</p>

<pre><code>Level 3: 4 &lt; 8 -&gt; Swap 4-8.
Level 2: 3 &lt; 7, 3 &lt; 6 -&gt; Swap 3-7, fix heap down (no-op)
         2 &lt; 5, 2 &lt; 8 -&gt; Swap 2-8, fix heap down:
           2 &lt; 4 -&gt; Swap 2-4, fix heap down (no-op)
Level 1: 1 &lt; 7, 1 &lt; 8 -&gt; Swap 1-8, fix heap down
           1 &lt; 4, 1 &lt; 5 -&gt; Swap 1-5, fix heap down (no-op)
Resulting heap:
          8
      5       7
    4   1   6   3
   2
</code></pre>

<p>Makes 10 comparisons. So I believe that either your homework question had an error, or you reported the question incorrectly. That building a heap bottom-up is <code>O(n)</code> doesn't mean it takes exactly <code>n</code> comparisons. For the exact bounds, check a textbook.</p>
","8627061"
"Nginx - Treats PHP as binary","3409","","<p>We are running Nginx+FastCgi as the backend for our Drupal site.
Everything seems to work like fine, except for this one url.
http:///sites/all/modules/tinymce/tinymce/jscripts/tiny_mce/plugins/smimage/index.php</p>

<p>(We use TinyMCE module in Drupal, and the url above is invoked when
user tries to upload an image)</p>

<p>When we were using Apache,  everything was working fine.
However, nginx treats that above url Binary and tries to Download it.
(We've verified that the file pointed out by the url is a valid PHP file)</p>

<p>Any idea what could be wrong here?</p>

<p>I think it's something to do with the NGINX configuration, but not entirely sure what that is.</p>

<p>Any help is greatly appreciated.</p>

<p>Config:
Here's the snippet from the nginx configuration file:</p>

<pre><code>      root /var/www/;
       index index.php;

       if (!-e $request_filename) {
               rewrite ^/(.*)$ /index.php?q=$1 last;
       }

       error_page 404 index.php;
       location ~*
\.(engine|inc|info|install|module|profile|po|sh|.*sql|theme|tpl(\.php)?|xtmpl)$|^(code-style\.pl|Entries.*|Repository|Root|Tag|Template)$
{
               deny all;
       }

       location ~* ^.+\.(jpg|jpeg|gif|png|ico)$ {
             access_log        off;
           expires           7d;
       }

       location ~* ^.+\.(css|js)$ {
             access_log        off;
           expires           7d;
       }

       location ~ .php$ {
           include /etc/nginx/fcgi.conf;
           fastcgi_pass 127.0.0.1:8888;
           fastcgi_index index.php;
           fastcgi_param  SCRIPT_FILENAME   $document_root$fastcgi_script_name;
           fastcgi_param  QUERY_STRING     $query_string;
           fastcgi_param  REQUEST_METHOD   $request_method;
           fastcgi_param  CONTENT_TYPE     $content_type;
           fastcgi_param  CONTENT_LENGTH   $content_length;
       }

       location ~ /\.ht {
               deny  all;
       }
</code></pre>
","<p>Make it </p>

<pre><code>location ~ \.php$ {
</code></pre>

<p>instead of</p>

<pre><code>location ~ .php$ {
</code></pre>
","1291683"
"Extract Objective-c binary","3404","","<p>Is it possible to extract a binary, to get the code that is behind the binary? With Class-dump you can see the implementation addresses, but is it possible to also see the code thats IN the implementation addresses? Is there ANY way to do it?</p>
","<p>All your code compiles to single instructions, placed in the text section of your executable. The compiler is responsible for translating your higher level language to the processor specific instructions, which are simpler. Reverting this process would be nearly impossible, unless the code is quite simple. Some problems are ambiguity of statements, and the overall readability: local variables, for instance, will be nothing but an offset address.</p>

<p>If you want to read the disassembled code (the instructions of which the higher level code was compiled to) use this command in an executable:</p>

<blockquote>
  <p><code>otool -tV</code> <em><code>file</code></em></p>
</blockquote>
","7894943"
"C# Read and replace binary data in text file","3402","","<p>I have a file that contains text data and binary data.  This may not be a good idea, but there's nothing I can do about it. 
I know the end and start positions of the binary data.</p>

<p>What would be the best way to read in that binary data between those positions, make a Base64 string out of it, and then write it back to the position it was.</p>

<p>EDIT: The Base64-encoded string won't be same length as the binary data, so I might have to pad the Base64 string to the binary data length.</p>
","<pre><code>int binaryStart = 100;
int binaryEnd = 150;

//buffer to copy the remaining data to it and insert it after inserting the base64string
byte[] dataTailBuffer = null;

string base64String = null;

//get the binary data and convert it to base64string
using (System.IO.Stream fileStream = new FileStream(@""c:\Test Soap"", FileMode.Open, FileAccess.Read))
{
    using (System.IO.BinaryReader reader = new BinaryReader(fileStream))
    {
        reader.BaseStream.Seek(binaryStart, SeekOrigin.Begin);

        var buffer = new byte[binaryEnd - binaryStart];

        reader.Read(buffer, 0, buffer.Length);

        base64String = Convert.ToBase64String(buffer);

        if (reader.BaseStream.Position &lt; reader.BaseStream.Length - 1)
        {
            dataTailBuffer = new byte[reader.BaseStream.Length - reader.BaseStream.Position];

            reader.Read(dataTailBuffer, 0, dataTailBuffer.Length);
        }
    }
}

//write the new base64string at specifid location.
using (System.IO.Stream fileStream = new FileStream(@""C:\test soap"", FileMode.Open, FileAccess.Write))
{
    using (System.IO.BinaryWriter writer = new BinaryWriter(fileStream))
    {
        writer.Seek(binaryStart, SeekOrigin.Begin);

        writer.Write(base64String);//writer.Write(Convert.FromBase64String(base64String));

        if (dataTailBuffer != null)
        {
            writer.Write(dataTailBuffer, 0, dataTailBuffer.Length);
        }
    }
}
</code></pre>
","6512125"
"Two's complement of Hex number in Python","3386","","<p>Below a and b (hex), representing two's complement signed binary numbers.
For example:</p>

<pre><code>a = 0x17c7cc6e
b = 0xc158a854
</code></pre>

<p><em>Now I want to know the signed representation of a &amp; b in base 10.</em> Sorry I'm a low level programmer and new to python; feel very stupid for asking this. I don't care about additional library's but the answer should be simple and straight forward. Background: a &amp; b are extracted data from a UDP packet. I have no control over the format. So please don't give me an answer that would assume I can change the format of those varibles before hand.</p>

<p>I have converted a &amp; b into the following with this:</p>

<pre><code>aBinary = bin(int(a, 16))[2:].zfill(32) =&gt; 00010111110001111100110001101110 =&gt; 398969966
bBinary = bin(int(b, 16))[2:].zfill(32) =&gt; 11000001010110001010100001010100 =&gt; -1051154348
</code></pre>

<p>I was trying to do something like this (doesn't work):</p>

<pre><code>if aBinary[1:2] == 1:
aBinary = ~aBinary + int(1, 2)
</code></pre>

<p><strong>What is the proper way to do this in python?</strong></p>
","<p>You'll have to know at least the width of your data. For instance, 0xc158a854 has 8 hexadecimal digits so it must be at least 32 bits wide; it appears to be an unsigned 32 bit value. We can process it using some bitwise operations:</p>

<pre><code>In [232]: b = 0xc158a854

In [233]: if b &gt;= 1&lt;&lt;31: b -= 1&lt;&lt;32

In [234]: b
Out[234]: -1051154348L
</code></pre>

<p>The L here marks that Python 2 has switched to processing the value as a long; it's usually not important, but in this case indicates that I've been working with values outside the common int range for this installation. The tool to extract data from binary structures such as UDP packets is <a href=""https://docs.python.org/2/library/struct.html"" rel=""nofollow"">struct.unpack</a>; if you just tell it that your value is signed in the first place, it will produce the correct value:</p>

<pre><code>In [240]: s = '\xc1\x58\xa8\x54'

In [241]: import struct

In [242]: struct.unpack('&gt;i', s)
Out[242]: (-1051154348,)
</code></pre>

<p>That assumes two's complement representation; one's complement (such as the checksum used in UDP), sign and magnitude, or IEEE 754 floating point are some less common encodings for numbers. </p>
","26641777"
"C++ how to store integer into a binary file?","3384","","<p>I've got a struct with 2 integers, and I want to store them in a binary file and read it again.</p>

<p>Here is my code:</p>

<pre><code>static const char *ADMIN_FILE = ""admin.bin"";
struct pw {  
  int a;  
  int b;
};

void main(){  
  pw* p = new pw();  
  pw* q = new pw();  
  std::ofstream fout(ADMIN_FILE, ios_base::out | ios_base::binary | ios_base::trunc);  
  std::ifstream fin(ADMIN_FILE, ios_base::in | ios_base::binary);  
  p-&gt;a=123;  
  p-&gt;b=321;  
  fout.write((const char*)p, sizeof(pw));  
  fin.read((char*)q, sizeof(pw));  
  fin.close();  
  cout &lt;&lt; q-&gt;a &lt;&lt; endl;
}  
</code></pre>

<p>The output I get is <code>0</code>. Can anyone tell me what is the problem?</p>
","<p>You probably want to flush <code>fout</code> before you read from it.</p>

<p>To flush the stream, do the following:</p>

<pre><code>fout.flush();
</code></pre>

<p>The reason for this is that fstreams generally want to buffer the output as long as possible to reduce cost. To force the buffer to be emptied, you call flush on the stream.</p>
","2508568"
"binary format, bitwise operations exist? eg. <<16#7F, 16#FF>> bsl 1","3377","","<p>In erlang, there are bitwise operations to operate on integers, for example:</p>

<pre><code>1&gt  127 bsl 1.
254
</code></pre>

<p>there is also the ability to pack integers into a sequence of bytes</p>

<pre><code>&lt&lt 16#7F, 16#FF &gt&gt</code></pre>

<p>is it possible, or are there any operators or BIFs that can perform bitwise operations (eg AND, OR, XOR, SHL, SHR) on binary packed data?</p>

<p>for example (if bsl worked on binary packages - which it does not):</p>

<pre><code>1&gt  &lt&lt 16#7F, 16#FF &gt&gt bsl 1.
&lt&lt 255, 254 &gt&gt</code></pre>
","<p>Try out this way:</p>

<pre><code>bbsl(Bin,Shift) -&gt; &lt;&lt;_:Shift,Rest/bits&gt;&gt; = Bin, &lt;&lt;Rest/bits,0:Shift&gt;&gt;.
</code></pre>
","397338"
"Bash echo command with binary data?","3374","","<p>Would someone please explain why this script sometime return only 15 bytes in hex string representation?</p>

<pre><code>for i in {1..10}; do 
  API_IV=`openssl rand 16`; API_IV_HEX=`echo -n ""$API_IV"" | od -vt x1 -w16 | awk '{$1="""";print}'`; echo $API_IV_HEX; 
done
</code></pre>

<p>like this:</p>

<pre><code>c2 2a 09 0f 9a cd 64 02 28 06 43 f8 13 80 a5 04
fa c4 ac b1 95 23 7c 36 95 2d 5e 0e bf 05 fe f4
38 55 d3 b4 32 bb 61 f4 fd 17 92 67 e2 9b b4 04
6d a7 f8 46 e9 99 bd 89 87 f9 7f 2b 15 5a 17 8a
11 c8 89 f4 8f 66 93 f1 6d b9 2b 64 7e 01 61 68
93 e3 9d 28 95 e1 c8 92 e5 62 d9 bf 20 b3 1c dd
37 64 ef b0 2f da c7 60 1c c8 20 b8 28 9d f9
29 f0 5a e9 cc 36 66 de 02 82 fc 8e 36 bf 5d d1
b2 57 d8 79 21 df 73 1c af 07 e9 80 0a 67 c6 15
ba 77 cb 92 39 42 39 f9 a4 57 c8 c4 be 62 19 54
</code></pre>

<p>If pipe the ""openssl rand 16"" directly to the od command then it works fine, but I need the binary value. Thanks for your help.</p>
","<p><code>echo</code>, like various other standard commands, considers <code>\x00</code> as an end-of-string marker. So stop displaying after it.</p>

<p>Maybe you are looking to the <code>-hex</code> option of <code>openssl rand</code>:</p>

<pre><code>sh$ openssl rand 16 -hex
4248bf230fc9dd927ab53f799e2a9708
</code></pre>

<p>Given that option is available on your system, your example could be rewritten:</p>

<pre><code>sh$ openssl version
OpenSSL 1.0.1e 11 Feb 2013

sh$ for i in {1..10}; do 
    openssl rand 16 -hex | sed -e 's|..|&amp; |g' -e 's| $||'
done
20 cb 6b 7a 85 2d 0b fe 9e c7 d0 4b 91 88 1b bb
5d 74 99 5e 05 c9 7d 9d 37 dd 02 f3 23 bb c5 b7
51 e9 0f dc 58 04 5e 30 e3 6b 9f 63 aa fc 95 05
fc 6b b8 cb 05 82 53 85 78 0e 59 13 3b e7 c1 4b
cf fa fc d9 1a 25 df e0 f8 59 71 a6 2c 64 c5 87
93 1a 29 b4 5a 52 77 bb 3f bb 1d 0a 46 5d c8 b4
0c bb c2 b2 b4 89 d4 37 1c 86 0a 7a 58 b8 64 e2
ee fc a7 ec 6c f8 7f 51 04 43 d6 00 d8 79 65 43
b9 73 9e cc 4b 42 9e 64 9d 5b 21 6a 20 b7 c3 16
06 8a 15 22 6a d5 ae ab 9a d2 9f 60 f1 a9 26 bd
</code></pre>

<hr/>

<p>If you need to later convert from <em>hex to bytes</em> use this <code>perl</code> one-liner:</p>

<pre><code>echo MY_HEX_STRING |
  perl -ne 's/([0-9a-f]{2})/print chr hex $1/gie' |
  my_tool_reading_binary_input_from_stdin
</code></pre>

<p>(from <a href=""https://stackoverflow.com/a/1604770/2363712"">https://stackoverflow.com/a/1604770/2363712</a>)</p>

<p>Please note I <em>pipe</em> to the client program and o not use a shell variable here, as I think it cannot properly handle the <code>\x00</code>.</p>

<hr/>

<p>As the <strong>bash cannot properly deal with binary strings containing <code>\x00</code></strong> your best bet if you absolutely want to stick with shell programming is to use an intermediate file to store binary data. And <em>not</em> a variable:</p>

<p>This is the <em>idea</em>. Feel free to adapt to your needs:</p>

<pre><code>for i in {1..10}; do
    openssl rand 16 &gt; api_iv_$i # better use `mktemp` here
    API_IV_HEX=`od -vt x1 -w16 &lt; api_iv_$i | awk '{$1="""";print}'`
    echo $API_IV_HEX; 
done

sh$ bash t.sh 
cf 06 ab ab 86 fd ef 22 1a 2c bd 7f 8c 45 27 e5
2a 01 9c 7a fa 15 d3 ea 40 89 8b 26 d5 4f 97 08
55 2e c9 d3 cd 0d 3a 6f 1b a0 fe 38 6d 0e 20 07
fe 60 35 62 17 80 f2 db 64 7a af da 81 ff f7 e0
74 9a 5c 39 0e 1a 6b 89 a3 21 65 01 a3 de c4 1c
c3 11 45 e3 e0 dc 66 a3 e8 fb 5b 8a bd d0 7d 43
a4 ee 80 f8 c8 8b 4e 50 5c dd 21 00 3b d0 bc cf
e2 d5 11 d4 7d 98 08 a7 16 7b 8c 56 44 ba 6d 53
ad 63 65 fd bf 3f 1f 4a a1 c5 d0 58 23 ae d1 47
80 74 f1 d0 b9 00 e5 1d 50 74 53 96 4b ce 59 50

sh$ hexdump -C ./api_iv_10
00000000  80 74 f1 d0 b9 00 e5 1d  50 74 53 96 4b ce 59 50  |.t......PtS.K.YP|
00000010
</code></pre>

<p>As a personal opinion, if you really have a lot of binary data processing, I would recommend to switch to some other language more data oriented (Python, ...)</p>
","24787820"
"Subtraction of binary fractions using 2's complement","3371","","<p>I have been through different posts here in Stack Overflow relating my question, but none seem to answer it because in their questions, either the decimal representation is given (mine isn't) or the answer is vague to me (like <a href=""https://stackoverflow.com/questions/9946183/2s-complement-representation-of-fractions?lq=1"">this</a>).</p>

<p>I'm trying to do subtraction of binary digits in fractions or in floating-point.</p>

<pre><code>  0.0110
- 0.100101
</code></pre>

<p>The answer given is <code>-0.001101</code>, but the solution is not shown. Since I haven't seen any direct way (<strong>not</strong> DEC to BIN) to convert a binary fractional digit to its 2's complement, I tried implementing the solution from this <a href=""http://www.engineering.uiowa.edu/~carch/lectsupp09/FltPoint.pdf"" rel=""nofollow noreferrer"">lecture</a> on 2's complement of binary fractions wherein you get the bit by bit complement and add the floating-point part (the background principle of adding the fractional part wasn't explained). Using that, my answer did not match the one indicated. </p>

<pre><code>  1.011010 &lt;- 1's complement of 0.100101
+ 0.011010
__________
  1.110100 &lt;- 2's complement of 0.100101
</code></pre>

<p>The 2's complement is then added to <code>0.0110</code>:</p>

<pre><code>  0.011000
+ 1.110100
__________
 10.001100 &lt;- discard overflow '1'            
</code></pre>

<p>I ended up with the erroneous answer of <code>0.0011</code>. What did I do wrong? Did I forget any principle that I could have used?</p>
","<p>One goes from one's complement to two's complement by adding one unit. In this case the unit is <code>0.000001</code>, not <code>1</code> (it is <code>1</code> for integers, but you are not working with integers but with multiples of <code>0.000001</code>).</p>

<pre><code>  1.011010 &lt;- 1's complement of 0.100101
+ 0.000001
__________
  1.011011 &lt;- 2's complement of 0.100101
</code></pre>

<p>The addition becomes:</p>

<pre><code>  0.011000
+ 1.011011
__________
  1.110011 &lt;- 1.110011 is the two's complement of the absolute value of the answer.
</code></pre>
","21367847"
"Why cant I do blob detection on this binary image","3369","","<p>First, now i am doing the blob detection by Python2.7 with Opencv. What i want to do is to finish the blob detection after the color detection. i want to detect the red circles(marks), and to avoid other blob interference, i want to do color detection first, and then do the blob detection.</p>

<p>and the image after color detection is <a href=""http://i.stack.imgur.com/eRCe1.png"" rel=""nofollow"">binary mask</a></p>

<p>now i want to do blob detection on this image, but it doesn't work.
This is my code.</p>

<pre><code>import cv2
import numpy as np;

# Read image
im = cv2.imread(""myblob.jpg"", cv2.IMREAD_GRAYSCALE)

# Set up the detector with default parameters.

params = cv2.SimpleBlobDetector_Params()
# Change thresholds
params.minThreshold = 10;    # the graylevel of images
params.maxThreshold = 200;

params.filterByColor = True
params.blobColor = 255

# Filter by Area
params.filterByArea = False
params.minArea = 10000

detector = cv2.SimpleBlobDetector(params)


# Detect blobs.
keypoints = detector.detect(im)

# Draw detected blobs as red circles.
# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle corresponds to the size of blob
im_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

# Show keypoints
cv2.imshow(""Keypoints"", im_with_keypoints)
cv2.waitKey(0)`
</code></pre>

<p>I am really confused by this code, because it work on this image <a href=""http://i.stack.imgur.com/c0AXO.jpg"" rel=""nofollow"">white dots</a>
I think the white dots image is quiet similar with the binary mask,but why cant i do blob detection on the binary image?could anyone tell me the difference or the right code?</p>

<p>Thanks!!</p>

<p>Regards,
Nan</p>
","<p>It looks that the blob detector has <code>filterByInertia</code> and <code>filterByConvexity</code> parameters enabled by default.
You can check this in your system:</p>

<pre><code>import cv2
params = cv2.SimpleBlobDetector_Params()
print params.filterByColor
print params.filterByArea
print params.filterByCircularity
print params.filterByInertia
print params.filterByConvexity
</code></pre>

<p>So when you call <code>detector = cv2.SimpleBlobDetector(params)</code> you are actually filtering also by inertia and convexity with the default min and max values.</p>

<p>If you explicitly disable those filtering criteria:</p>

<pre><code># Disable unwanted filter criteria params
params.filterByInertia = False
params.filterByConvexity = False
</code></pre>

<p>... and then call <code>detector = cv2.SimpleBlobDetector(params)</code> you get the following image:
<a href=""https://i.stack.imgur.com/UxBZY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UxBZY.png"" alt=""blobing result""></a></p>

<p>The third blob in that image is caused by the white frame on the lower right of your image.
You can crop the image, if the frame is always in the same place, or you can use the parameters to filter by circularity and remove the undesired blob:</p>

<pre><code>params.filterByCircularity = True
params.minCircularity = 0.1
</code></pre>

<p>And you will finally get:</p>

<p><a href=""https://i.stack.imgur.com/KPx99.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/KPx99.png"" alt=""enter image description here""></a></p>
","39085654"
"Reversed Binary Numbers","3365","","<p>I was trying a little puzzle which i found <a href=""https://www.spotify.com/int/jobs/tech/reversed-binary/"" rel=""nofollow"">here</a></p>

<p>and I was wondering how come my answer is incorrect, you see the original specification is</p>

<blockquote>
  <p>Your task will be to write a program for reversing numbers in binary.
  For instance, the binary representation of 13 is 1101, and reversing
  it gives 1011, which corresponds to number 11.</p>
</blockquote>

<p>So Here is my code..</p>

<pre><code>import java.util.Scanner;

public class ReverseBinary {

    public  String reversedIntToBinary(int val) {
        int value = val;
        StringBuilder bldr = new StringBuilder();

        while (value != 0) {
            int remainder = value % 2;
            value = value / 2;
            bldr.append(remainder);
        }
        return bldr.toString();
    }

    public  int toDecimal(String bin) {
        char[] binString = bin.toCharArray();

        int starting = 0;

        for (int i = 0; i &lt; binString.length; i++) {
            int tempoVal = starting * 2
                    + Character.getNumericValue(binString[i]);
            starting = tempoVal;
        }
        return starting;
    }

    public  int reversedBinary(int val){
        String bin =reversedIntToBinary(val);
        int result = toDecimal(bin);
        return result;
    }

    public static void main(String[] args) {
        ReverseBinary rvb = new ReverseBinary();

        Scanner input = new Scanner( System.in);
        System.out.println(""Enter A Number: "");
        int num = input.nextInt();
        System.out.println(rvb.reversedBinary(num));
    }
}
</code></pre>

<p>it is doing the said task, but upon my submission it is wrong. I wondering why it is considered wrong?  have I missed something crucial?</p>
","<blockquote>
  <p>Output <strong>one line with one integer</strong>, the number we get by reversing the binary representation of N.
  (emphasis added)</p>
</blockquote>

<p>You're outputting <em>two</em> lines, <code>Enter A Number:</code> and the integer. The text <code>Enter A Number:\n11\n</code> is not equal to the text <code>11\n</code>. If they're using an automated system to check the programs, it could be failing your submission for that reason.</p>

<p>(I haven't checked your code other than that, so there may be other issues as well -- but that one stands out immediately.)</p>
","15093327"
"Binary Right Shift, Given Only Addition","3336","","<p>I am working on a project where I am reading memory locations and need to output their hex value in ASCII.</p>

<p>The language gives me a 16 bit word length, so I have a need to divide to grab a nibble at a time to convert to hex. Unfortunately, the language only offers and, or, not, and add for mathematical/logical functions. </p>

<p>I've figured I can create the desired effect by left shifting and testing for a negative flag to add a 1 to the end after shifting, but I'm figuring there has to be a better method for doing this.</p>

<p>Any insight would be appreciated.</p>
","<p>So the original method I used worked. I also came up with another, incase anyone ever has this problem again.</p>

<p>I built a subroutine that evaluates 4 bits at a time and creates a number based on the evaluation, for some C style pseudo code it looks like this:</p>

<pre><code>16bitSignedInt bin; //binary being analyzed
int value; //number being built

for (int i = 0; i &lt; 4; i++) // while 0-3, for each nibble of the 16 bits
{
   if (bin.bit15 = 1)
      value += 8; // dominate bit in nibble

   bin &lt;&lt;= 1; // left shift 1

   if (bin.bit15 = 1)
      value += 4; // 2nd bit in nibble

   bin &lt;&lt;= 1; // left shift 1

   if (bin.bit15 = 1)
      value += 2; // 3rd bit in nibble

   bin &lt;&lt;= 1; // left shift 1

   if (bin.bit15 = 1)
      value += 1; // last bit in nibble

   bin &lt;&lt;= 1; // left shift 1

   //do work with value
}
</code></pre>

<p>Crude, but effective.</p>
","5520355"
"How to convert the binary to pdf file on iPhone?","3335","","<p>I receive a binary pdf file, which is base64Binary, how can I convert it back on the iPhone? What tool kits I can use? Thanks. </p>
","<p>Solved:</p>

<pre><code>NSData theData = [NSData dataWithData:[GTMBase64 decodeString:theBinary]]; //first transfer it to NSData.

[m_oTestingWeb loadData:theData
               MIMEType:@""application/pdf""
       textEncodingName:@""UTF-8""
                baseURL:nil];                   //using the web view to show it back
</code></pre>
","8133719"
"deserialize json base64 binary in .net using DataContractJsonSerializer","3333","","<p>Hey, I am having a problem deserializing base64 json back into the .net object using wcf datacontract....</p>

<p>I have this to deserialize:</p>

<pre><code>public static T FromJSON&lt;T&gt;( this string json )
{
    using ( MemoryStream ms = new MemoryStream(ASCIIEncoding.Default.GetBytes(json)) )
    {
        DataContractJsonSerializer ser = new DataContractJsonSerializer(typeof(T));

        return (T)ser.ReadObject(ms);
    }
}
</code></pre>

<p>and...I have this in my model class...</p>

<pre><code>[DataMember]
[Column(AutoSync = AutoSync.Always, DbType = ""rowversion not null"", CanBeNull = false, IsDbGenerated = true, IsVersion = true, UpdateCheck = UpdateCheck.Never)]
public byte[] timestamp { get; set; }
</code></pre>

<p>and...I'm passing the json back like so...</p>

<pre><code>[{""id"":""1"",""type"":""H"",""date_issued"":""\/Date(1286856000000)\/"",""date_ceu"":""\/Date(1603166400000)\/"",""current"":true,""timestamp"":""AAAAAAAAD7M=""}]
</code></pre>

<p>and for some reason it just refuses to simply put that base64 back into the byte[]...there must be some other way to get it to work...</p>

<p>also, fyi I'm using ASP.NET MVC and Html.Hidden(...) which serializes the binary into base64 to begin with....</p>

<p>thanks!</p>
","<p>I solved the issue by using JSON.NET library instead...worked immediately.</p>

<p><a href=""http://json.codeplex.com/"" rel=""nofollow noreferrer"">http://json.codeplex.com/</a></p>

<pre>
List&lt;..> result = JsonConvert.DeserializeObject&lt;List&lt;...>>( list );
</pre>
","3391706"
"Last index of multiple keys using binary-search?","3333","","<p>i have multiple occurrences of a key in a sorted array, and i want to perform binary search on them, a normal binary search returns some random index for the key having multiple occurrences, where as i want the index of the last occurrence of that key.</p>

<pre><code>int data[] = [1,2,3,4,4,4,4,5,5,6,6];
int key = 4;
int index = upperBoundBinarySearch(data, 0, data.length-1, key);

Index Returned = 6
</code></pre>
","<p>Well, thanks to all especially @Mattias, that algo sounds good. anyway i have done with my own, that seem me to give better result, but if some one can help me to measure out the complexity of both algos mine and @Mattias, or any one has some better solution, it welcome.....
anyhow here is the solution i found for the problem,</p>

<pre><code>int upperBound(int[] array,int fromIndex, int toIndex, int key)
{
    int low = fromIndex-1, high = toIndex;
    while (low+1 != high)
    {
        int mid = (low+high)&gt;&gt;&gt;1;
        if (array[mid]&gt; key) high=mid;
        else low=mid;
    }
    int p = low;
    if ( p &gt;= toIndex || array[p] != key )
        p=-1;//no key found
    return p;
}
</code></pre>

<p>this is for first occurrence, i also update the same with one other similar post <a href=""https://stackoverflow.com/questions/6676360/first-occurrence-in-a-binary-search?lq=1"">First occurrence in a binary search</a></p>

<pre><code>int lowerBound(int[] array,int fromIndex, int toIndex, int key)
{
    int low = fromIndex-1, high = toIndex;
    while (low+1 != high)
    {
        int mid = (low+high)&gt;&gt;&gt;1;
        if (array[mid]&lt; key) low=mid;
        else high=mid;
    }
    int p = high;
    if ( p &gt;= toIndex || array[p] != key )
        p=-1;//no key found
    return p;
}
</code></pre>
","14418321"
"Serving files with JSF 2 / CDI, using bookmarkable URLs","3328","","<p>My main question is : Is there a ""good practice"" to serve binary files (PDF, docs, etc) using JSF 2 with CDI, and using bookmarkable URLs ?</p>

<p>I've read the <a href=""http://download.oracle.com/otndocs/jcp/jsf-2_1-mrel2-eval-oth-JSpec/"" rel=""nofollow noreferrer"">JSF 2 spec (JSR 314)</a> and I see it exists a ""Resource Handling"" paragraph. But it seems to be used only to serve static files put in the war or jar files. I didn't really understood if it exists a way to interact here by registering some specific ResourceHandler ...</p>

<p>Actually, I was used to Seam's 2 way to do that : extending the <a href=""http://docs.jboss.org/seam/2.2.0.GA/api/org/jboss/seam/web/AbstractResource.html"" rel=""nofollow noreferrer""><code>AbstractResource</code></a> class with <code>getResource(HttpServletRequest, HttpServletResponse)</code> method and <code>getResourcePath()</code> to declare which path to serve after <code>&lt;webapp&gt;/seam/resource/</code> URL prefix and declaring the <code>SeamResourceServlet</code> in the <code>web.xml</code> file.</p>

<p>Here is what I did.</p>

<p>I've first saw <a href=""https://stackoverflow.com/questions/5498391/how-to-download-a-file-stored-in-a-database-with-jsf-2-0"">How to download a file stored in a database with JSF 2.0</a> and tried to implement it.</p>

<pre class=""lang-html prettyprint-override""><code>&lt;f:view ...

    &lt;f:metadata&gt;
        &lt;f:viewParam name=""key"" value=""#{containerAction.key}""/&gt;
        &lt;f:event listener=""#{containerAction.preRenderView}"" type=""preRenderComponent"" /&gt;
    &lt;/f:metadata&gt;

    ...

    &lt;rich:dataGrid columns=""1"" value=""#{containerAction.container.files}"" var=""file""&gt;
        &lt;rich:panel&gt;
                &lt;h:panelGrid columns=""2""&gt;
                    &lt;h:outputText value=""File Name:"" /&gt;
                    &lt;h:outputText value=""#{file.name}"" /&gt;
                &lt;/h:panelGrid&gt;
                &lt;h:form&gt;
                    &lt;h:commandButton value=""Download"" action=""#{containerAction.download(file.key)}"" /&gt;
                &lt;/h:form&gt;
        &lt;/rich:panel&gt;
    &lt;/rich:dataGrid&gt;
</code></pre>

<p>And here is the beans :</p>

<pre class=""lang-java prettyprint-override""><code>@Named
@SessionScoped
public class ContainerAction {

    private Container container;

    /// Injections
    @Inject @DefaultServiceInstance
    private Instance&lt;ContainerService&gt; containerService;

    /// Control methods
    public void preRenderView(final ComponentSystemEvent event) {
        container = containerService.get().loadFromKey(key);
    }

    /// Action methods
    public void download(final String key) throws IOException {
        final FacesContext facesContext = FacesContext.getCurrentInstance();

        HttpServletResponse response = (HttpServletResponse) facesContext.getExternalContext().getResponse();

        final ContainerFile containerFile = containerService.get().loadFromKey(key);
        final InputStream containerFileStream = containerService.get().read(containerFile);

        response.setHeader(""Content-Disposition"", ""attachment;filename=\""""+containerFile.getName()+""\"""");
        response.setContentType(containerFile.getContentType());
        response.setContentLength((int) containerFile.getSize());

        IOUtils.copy(containerFileStream, response.getOutputStream());

        response.flushBuffer();

        facesContext.responseComplete();
    }

    /// Getters / setters
    public Container getContainer() {
        return container;
    }
}
</code></pre>

<p>Here I had to <a href=""http://seamframework.org/Community/Weld111AndTomcat7Problems"" rel=""nofollow noreferrer"">switch to Tomcat 7</a> (I was using 6) in order to interpret correctly that EL expression. With <code>@SessionScoped</code> it worked, but not with <code>@RequestScoped</code> (when I clicked the button, nothing happend).</p>

<p>But then I wanted to use a link instead of a button.</p>

<p>I tried <code>&lt;h:commandLink value=""Download"" action=""#{containerAction.download(file.key)}"" /&gt;</code> but it generates some ugly javascript link (not bookmarkable).</p>

<p>Reading the JSF 2 spec, it seems that there is a ""Bookmarkability"" feature, but it is not realy clear how to use it.</p>

<p>Actually, it seems to work only with views, so I tried to create an empty view and created a <code>h:link</code> :</p>

<pre class=""lang-html prettyprint-override""><code>&lt;h:link outcome=""download.xhtml"" value=""Download""&gt;
    &lt;f:param name=""key"" value=""#{file.key}""/&gt;
&lt;/h:link&gt;
</code></pre>

<pre class=""lang-html prettyprint-override""><code>&lt;f:view ...&gt;
    &lt;f:metadata&gt;
        &lt;f:viewParam name=""key"" value=""#{containerFileDownloadAction.key}""/&gt;
        &lt;f:event listener=""#{containerFileDownloadAction.download}"" type=""preRenderComponent"" /&gt;
    &lt;/f:metadata&gt;
&lt;/f:view&gt;
</code></pre>

<pre class=""lang-java prettyprint-override""><code>@Named
@RequestScoped
public class ContainerFileDownloadAction {

    private String key;

    @Inject @DefaultServiceInstance
    private Instance&lt;ContainerService&gt; containerService;

    public void download() throws IOException {
        final FacesContext facesContext = FacesContext.getCurrentInstance();

        // same code as previously
        ...

        facesContext.responseComplete();
    }


    /// getter / setter for key
    ...
}
</code></pre>

<p>But then, I had a <code>java.lang.IllegalStateException: ""getWriter()"" has already been called for this response</code>.</p>

<p>Logic as when a view initiates, it uses getWritter to initialize the response.</p>

<p>So I created a Servlet which does the work and created the following <code>h:outputLink</code> :</p>

<pre class=""lang-html prettyprint-override""><code>&lt;h:outputLink value=""#{facesContext.externalContext.request.contextPath}/download/""&gt;
    &lt;h:outputText value=""Download""/&gt;
    &lt;f:param name=""key"" value=""#{file.key}""/&gt;
&lt;/h:outputLink&gt;
</code></pre>

<p>But even if that last technique gives me a bookmarkable URL for my file, it is not really ""JFS 2"" ...</p>

<p>Do you have some advice ?</p>
","<p>There is in fact a direct solution to this problem using <a href=""http://ocpsoft.org/prettyfaces/"" rel=""nofollow"">PrettyFaces URLRewriteFilter</a> -> <a href=""http://ocpsoft.org/prettyfaces/serving-dynamic-file-content-with-prettyfaces/"" rel=""nofollow"">http://ocpsoft.org/prettyfaces/serving-dynamic-file-content-with-prettyfaces/</a></p>

<p>This blog explains how to do exactly what you want to do, without having to use an entirely new MVC framework.</p>
","9950712"
"Converting Integers to Binary in Ruby","3326","","<p>I'm working on a codewars kata and stuck with 2 test cases that are failing. </p>

<p>The kata description is:
Convert integers to binary as simple as that. You would be given an integer as a argument and you have to return its binary form. To get an idea about how to convert a decimal number into a binary number, visit here.</p>

<p>Notes: negative numbers should be handled as two's complement; assume all numbers are integers stored using 4 bytes (or 32 bits) in any language.</p>

<p>My code:</p>

<pre><code>def to_binary(n)
  temp_array = []
  if n == 0
    temp_array &lt;&lt; 0
  elsif n &lt; 0
    n = n % 256
    while n &gt; 0 do
      temp_array &lt;&lt; (n % 2)
      n = (n / 2)
    end
    while temp_array.length &lt; 32 do
      temp_array &lt;&lt; 1
    end
  else
    while n &gt; 0 do
      temp_array &lt;&lt; (n % 2)
      n = (n / 2)
    end
  end
  binary = temp_array.reverse.join
end
</code></pre>

<p>The test cases are:</p>

<pre><code>Test Passed: Value == ""10""
Test Passed: Value == ""11""
Test Passed: Value == ""100""
Test Passed: Value == ""101""
Test Passed: Value == ""111""
Test Passed: Value == ""1010""
Test Passed: Value == ""11111111111111111111111111111101""
Test Passed: Value == ""0""
Test Passed: Value == ""1111101000""
Test Passed: Value == ""11111111111111111111111111110001""
Expected: ""11111111111111111111110000011000"", instead got: ""11111111111111111111111111111000""
Expected: ""11111111111100001011110111000001"", instead got: ""11111111111111111111111111000001""
Test Passed: Value == ""11110100001000111111""
</code></pre>

<p>I suspect the tests that are failing are with negative integers because the first failing test's expected output is <code>11111111111111111111110000011000</code> which means that either the positive argument value was <code>4294966296</code> or it was negative.  If I run <code>to_binary(4294966296)</code> I get the expected output.</p>
","<p>I am not fond of this approach since I'm sure there's an even more clever and/or compact, Ruby-esque way of accomplishing it. But using your method of loading binary digits into an array, and then joining, what you have can be done in a little more straight-forward fashion:</p>

<pre><code>def to_binary(n)
  return ""0"" if n == 0

  r = []

  32.times do
    if (n &amp; (1 &lt;&lt; 31)) != 0
      r &lt;&lt; 1
    else
      (r &lt;&lt; 0) if r.size &gt; 0
    end
    n &lt;&lt;= 1
  end

  r.join
end
</code></pre>

<p>Or, using @500_error's suggestion:</p>

<pre><code>def to_binary(n)
  if n &gt;= 0
    n.to_s(2)
  else
    31.downto(0).map { |b| n[b] }.join
  end
end
</code></pre>

<p>The asymmetry to deal with negative versus non-negative is a little annoying, though. You could do something like:</p>

<pre><code>def to_binary(n)
  31.downto(0).map { |b| n[b] }.join.sub(/^0*/, """")
end
</code></pre>
","31212455"
"WriteByte, how to use it","3321","","<p>How do I use WriteByte? The below code will not work, coming up with both a CS1502 error, and a CS1502 error at the ""stream.WriteByte(totalSeasons);"" line. It's frustrating because I am incredibly close to finishing this program.</p>

<p>Essentially, my problem is that I need to write binary data to a file on the click of a button. I can just write this for example: stream.WriteByte(0xCD); The problem is that I need to allow the user to type in the data they want to be written into a textbox, and then on the click of a button the data will be converted from decimal to hex, and then put in. I think I've figured the conversion part out, but I can't edit the binary with the data because it seems that WriteByte can only write Hex values like 0xCD, and there seems to be no way to store the hex value and still write it. I've tried stream.WriteByte(ByteName); but that comes with the errors described above. </p>

<pre><code>void BtnTotalSeasonsClick(object sender, EventArgs e)
{
    using (var stream = new FileStream(drvFile, FileMode.Open, FileAccess.ReadWrite))  
    { 
        System.Text.ASCIIEncoding enc = new System.Text.ASCIIEncoding();
        Byte[] totalSeasons = enc.GetBytes(txtTotalSeasons.Text);
        stream.Position = 4; 
        stream.WriteByte(totalSeasons);
    } 
}
</code></pre>
","<p><code>totalSeasons</code> is more than one byte, so you'd call the <a href=""http://msdn.microsoft.com/en-us/library/system.io.filestream.write.aspx"" rel=""nofollow noreferrer"">Write</a> method which writes an entire block of bytes.</p>

<p>Is <code>txtTotalSeasons.Text</code> supposed to turn into a single byte?  Maybe you're looking for <a href=""http://msdn.microsoft.com/en-us/library/system.byte.tryparse.aspx"" rel=""nofollow noreferrer""><code>Byte.TryParse</code></a> instead of <code>Encoding.GetBytes</code>.</p>

<p>EDIT: Provide the entire error message, not just the number.  Also, what exactly is in the text box.  You seem to be confused about hex vs decimal vs binary vs ASCII.  They are different string representations of a number.</p>

<p><code>0xCD</code> is not a hex value.  It is a C#-conformant hexadecimal representation of a number.  (Another hexadecimal representation, not allowed by C#, is CDh).  The compiler turns it into a number in the .NET internal format (which happens to be binary, but this isn't important).  Then the <code>WriteByte</code> or <code>Write</code> call stores the number into the file in binary.  You'd get the same result from <code>stream.WriteByte(0xCD)</code>, <code>stream.WriteByte(206)</code>, or <code>stream.WriteByte(0316)</code> since the compiler converts all of them to the same internal representation.  If you want to write a variable then there's no reason to use hex at all, you need the internal representation which <code>WriteByte</code> expects.</p>

<p>You said that the user enters a number between 0 and 255, in decimal?  Then the conversion required is from a decimal string representation to the internal representation, this is called ""parsing"".</p>

<p>Try this code:</p>

<pre><code>stream.WriteByte(Byte.Parse(txtTotalSeasons.Text));
</code></pre>
","3221077"
"pm3d in gnuplot with binary data","3319","","<p>I have some data files with content</p>

<pre><code>a1 b1 c1 d1
a1 b2 c2 d2
...
[blank line]
a2 b1 c1 d1
a2 b2 c2 d2
...
</code></pre>

<p>I plot this with gnuplot using </p>

<pre><code>splot 'file' u 1:2:3:4 w pm3d.
</code></pre>

<p>Now, I want to use a binary file. I created the file with Fortran using unformatted stream-access (direct or sequential access did not work directly). By using gnuplot with</p>

<pre><code>splot 'file' binary format='%float%float%float%float' u 1:2:3
</code></pre>

<p>I get a normal 3D-plot. However, the pm3d-command does not work as I don't have the blank lines in the binary file. I get the error message:</p>

<pre><code>&gt;splot 'file' binary format='%float%float%float%float' u 1:2:3:4 w pm3d
Warning: Single isoline (scan) is not enough for a pm3d plot.
Hint: Missing blank lines in the data file? See 'help pm3d' and FAQ.
</code></pre>

<p>According to the demo script in <a href=""http://gnuplot.sourceforge.net/demo/image2.html"" rel=""nofollow"">http://gnuplot.sourceforge.net/demo/image2.html</a>, I have to specify the record length (which I still don't understand right). However, using this script from the demo page and the command with pm3d obtains the same error message:</p>

<pre><code>splot 'scatter2.bin' binary record=30:30:29:26 u 1:2:3  w pm3d
</code></pre>

<p>So how is it possible to plot this four dimensional data from a binary file correctly?</p>

<p>Edit: Thanks, mgilson. Now it works fine. Just for the record: My fortran code-snippet:</p>

<pre><code> open(unit=83,file=fname,action='write',status='replace',access='stream',form='unformatted')
 a= 0.d0
 b= 0.d0
 do i=1,200
    do j=1,100  
       write(83)real(a),real(b),c(i,j),d(i,j)
       b = b + db
    end do
    a = a + da
    b = 0.d0
 end do
close(83)
</code></pre>

<p>The gnuplot commands:</p>

<pre><code> set pm3d map
 set contour
 set cntrparam levels 20
 set cntrparam bspline
 unset clabel
splot 'fname' binary record=(100,-1) format='%float' u 1:2:3:4 t 'd as pm3d-projection, c as contour'
</code></pre>
","<p>Great question, and thanks for posting it.  This is a corner of gnuplot I hadn't spent much time with before.  First, I need to generate a little test data -- I used python, but you could use <code>fortran</code> just as easily:</p>

<p>Note that my input array (<code>b</code>) is just a 10x10 array.  The first two ""columns"" in the datafile are just the index (i,j), but you could use anything.</p>

<pre><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.arange(10)
&gt;&gt;&gt; b = a[None,:]+a[:,None]
&gt;&gt;&gt; b
array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],
       [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],
       [ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11],
       [ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12],
       [ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13],
       [ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14],
       [ 6,  7,  8,  9, 10, 11, 12, 13, 14, 15],
       [ 7,  8,  9, 10, 11, 12, 13, 14, 15, 16],
       [ 8,  9, 10, 11, 12, 13, 14, 15, 16, 17],
       [ 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]])
&gt;&gt;&gt; with open('foo.dat','wb') as foo:
...     for (i,j),dat in np.ndenumerate(b):
...         s = struct.pack('4f',i,j,dat,dat)
...         foo.write(s)
... 
</code></pre>

<p>So here I just write 4-floating point values to the file for each data-point.  Again, this is what you've already done using <code>fortran</code>.  Now for plotting it:</p>

<pre><code>splot 'foo.dat' binary record=(10,-1) format='%float' u 1:2:3:4 w pm3d
</code></pre>

<p>I believe that this specifies that each ""scan"" is a ""record"".  Since I know that each scan will be 10 floats long, that becomes the first index in the <code>record</code> list.  The <code>-1</code> indicates that gnuplot should keep reading records until it finds the end of the file.</p>
","15885230"