title,viewcount,title,body,body,acceptedanswerid
"What are FOCs and SOCs?","41888","","<p>I keep seeing the terms first-order conditions and second-order conditions used in my undergrad economics class on production functions, monopolies, etc but I have no idea what these terms mean. It seems like a completely ambiguous term. What kind of conditions? </p>

<p><strong>Can someone explain what these terms mean? If it is context dependent, provided some of them most elementary meanings you associate with the term.</strong></p>
","<p>Suppose you have a differentiable function $f(x)$, which you want to optimize by choosing $x$. If $f(x)$ is utility or profit, then you want to choose $x$ (i.e. consumption bundle or quantity produced) to make the value of $f$ as large as possible. If $f(x)$ is a cost function, then you want to choose $x$ to make $f$ as small as possible. FOC and SOC are conditions that determine whether a solution maximizes or minimizes a given function. </p>

<p>At the undergrad level, what is usually the case is that you need to choose $x^*$ such that the derivative of $f$ is equal to zero:
$$f'(x^*)=0.$$
This is the FOC. The intuition for this condition is that a function attains its extremum (either maximum or minimum) when its derivative is equal to zero (see picture below). [You should be aware that there are more subtleties involved: look up terms like ""interior vs corner solutions"", ""global vs local maximum/minimum"", and ""saddle point"" to learn more].</p>

<p><img src=""https://i.stack.imgur.com/AGgAo.png"" alt=""Example functions where x_star is a maximum and a minimum""></p>

<p>However, as the picture illustrates, simply finding $x^*$ where $f'(x^*)=0$ is not enough to conclude that $x^*$ is the solution that maximizes or minimizes the objective function. In both graphs, the function attains a zero slope at $x^*$, but $x^*$ is a maximizer in the left graph, but a minimizer in the right graph. </p>

<p>To check whether $x^*$ is a maximizer or a minimizer, you need the SOC. The SOC for maximizer is 
$$f''(x^*)&lt;0$$ 
and the SOC for minimizer is
$$f''(x^*)&gt; 0.$$
Intuitively, if $x^*$ maximizes $f$, the slope of $f$ around $x^*$ is decreasing. Take the left graph, where $x^*$ is a maximizer. We see that the slope of $f$ is positive on the left of $x^*$ and negative on the right. Thus, around the neighborhood of $x^*$, as $x$ increases, $f'(x)$ decreases. The intuition for the case of minimizer is similar. </p>
","3120"
"How Do I Calculate the After-Tax Equilibrium Quantity of a Supply and Demand Graph?","32324","","<p>Suppose the supply of a good is given by the equation $Q_S = 360*P_S - 720$. And the demand for a good is given by $Q_D = 960 - 120*P_D$. The government decides to levy a tax of \$2 per unit on the good, to be paid by the seller.</p>

<p>And I must find the equilibrium quantity of the curves, after the \$2 tax has been taken into account for. I know the equilibrium quantity is 540 before the tax based on the following calculations:</p>

<ol>
<li>$Q_S=Q_D$</li>
<li>$360P-720 = 960-120P$</li>
<li>$480P = 1680$</li>
<li>$P = 3.5$</li>
<li>If we sub in 3.5 into both equations ($Q_S$ and $Q_D$) then we get 540.</li>
</ol>

<p>Therefore, the equilibrium quantity is 540 before taxes have been taken into account. However, I am unsure how to figure out the equilibrium quantity after the tax.</p>

<p>Does anyone know how to go about solving this issue?</p>

<p>All help is appreciated.</p>
","<p>Implementing @dismalscience comment suggestion, the unit tax burdens the suppliers. So the demand schedule is not affected, only supply. How? Since the tax is fixed per unit sold (and not a percentage charge), then the slope of the supply curve should not change. Therefore what remains is an upwards shift, that will lead to increased equilibrium price-decreased equilibrium quantity. The algebra should lead one to</p>

<p><a href=""https://i.stack.imgur.com/FZFex.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FZFex.png"" alt=""enter image description here""></a></p>

<p>One could see this as a fixed shift in overall (not just production) <em>marginal</em> cost: the quantity has the same production marginal cost as before -but now ""$2"" is added as an obligation per unit, to cover the tax.</p>
","8711"
"How to derive firm's cost function from production function?","22527","","<p>I recently learned how to solve the following type of problem using the method of Lagrangian multipliers: </p>

<p>Given a consumer with utility function $u(x,y)$, wealth $w$, prices $p =(p_x,p_y)$, budget constraint $w = xp_x + yp_y$. Find the demand function for $x$ and $y$. I also learned how to find cost functions by plugging these demand functions into my budget constraint and rewriting to give a cost function. </p>

<p>But those cases all involved having $w$ and somehow budgeting with respect to that budget. </p>

<p><strong>Problem Setup:</strong></p>

<p>Suppose a firm is a price-taker with market price for the good in question $p$. Suppose the firm has a production function $F(K,L)$. Derive the firms cost function. </p>

<p><strong>My Question:</strong> </p>

<p>How should I approach this problem? </p>

<p><strong>My Ideas / Thoughts Relevant for Solving Problem:</strong></p>

<p>I am not given wealth $w$ although I suppose I could assume any firm who is purchasing has some budget. All previous problems I have done involved two goods, but this involves one. Perhaps I could therefore have a budget constraint $w = qp$ where $q$ is the quantity and $p$ is the price as given to the price-taking firm. But Lagrangian multplier problems I have seen involve two variables and this is just a function of one. </p>

<p><strong>Remark:</strong> </p>

<p>The specific production function I am using is $F(K,L) = \sqrt{k} + \sqrt{l}$. I only include this in case it's relevant. I want to solve the problem myself. </p>
","<blockquote>
  <p><em>""I am not given wealth $w$ although I suppose I could assume any firm who
  is purchasing has some budget.""</em></p>
</blockquote>

<p><strong><em>No.</em></strong> This is <em>exactly</em> where the <em>fundamental</em> microeconomic theory of the firm differs from the microeconomic Consumer Theory: the firm is <em>not</em> constrained by a budget. The reason is that this fundamental theory deals most and foremost with the ""long-term"" view, or even better, with the ""planning view"". So we assume that the amount necessary to cover expenses, will come from sales, since the firm won't enter production at a loss (remember also, this is a deterministic set-up, there is no uncertainty). Working capital considerations (the fact that usually first you have to actually pay expenses and then to actually collect revenues), does not enter the long-term view, justifiably, it is a short-phenomenon. Also, in the long-term or planning approach, there are no fixed costs, all factors are variable.</p>

<p>Now, the ""cost-minimization"" approach to solve the firm's optimization problem, is <em>an alternative behavioral assumption</em> to the profit-maximizing setup, and it is very relevant in many real-world cases: public utilities that exist mainly to satisfy demand, and their motive is not to maximize profits -rather they want to minimize cost for the <em>given</em> level output, as determined by demand, in the context of efficient use of the always scarce resources.  </p>

<p>But also, the case of a price-taking firm that is too small compared to its market, is closer to a cost-minimizing behavior rather than profit maximizing, since the firm has not really control over its production (except downward by direct decision). </p>

<p>In both of the above cases, an exogenous variable appears: the level of output itself. So we solve the problem by treating the level of output as a ""constant"" or better, we solve it for any given level of output, and the solution we obtain has the level of output as one of its components.</p>

<p>So</p>

<p>$$\min_{K,L} C\equiv rK + wL \\
s.t. F(K,L) = \bar Q$$</p>

<p>with the Lagrangean</p>

<p>$$\Lambda = rK + wL +\lambda[\bar Q - F(K,L)]$$</p>

<p>The first order conditions are</p>

<p>$$r = \lambda F_K,\;\;\; w=\lambda F_L  \tag{1}$$</p>

<p>which gives, at the optimum,</p>

<p>$$rK + wL = C = \lambda\big(F_KK + F_L L) \tag{2}$$</p>

<p>Now assume that the production function is homogeneous of some degree $h$ (<em>not</em> necessarily homogeneous of degree one, i.e. exhibiting ""constant returns to scale"", but homogeneous -and yours is, of degree $h=1/2$.). From <a href=""http://en.wikipedia.org/wiki/Homogeneous_function#Positive_homogeneity"" rel=""nofollow"">Euler's theorem for homogeneous functions</a> of degree $h$ we have that</p>

<p>$$F_KK + F_L L = hF(K,L) = h\bar Q \tag{3}$$</p>

<p>the last equality holding given the constraint of the initial problem. Inserting $(3)$ into $(2)$ we obtain</p>

<p>$$C = \lambda h \bar Q$$</p>

<p>The multiplier $\lambda$ is <em>optimal marginal Cost</em>, denote it $C'(\bar Q)$, so we arrive at</p>

<p>$$C = C'(\bar Q)\cdot (h\bar Q) \implies C'(\bar Q) + [(-1/h\bar Q)]\cdot C =0$$</p>

<p>This is a simple homogeneous differential equation with solution</p>

<p>$$C = A\cdot \exp\left\{-\int(-1/h\bar Q) {\rm d}\bar Q \right\} = A\cdot \exp\left\{(1/h)\ln \bar Q\right\}$$</p>

<p>$$\implies C^* = A\cdot (\bar Q)^{1/h} \tag{4}$$</p>

<p>for some constant $A &gt;0$. To complete the solution, we need to express the object of interest, $C^*$, in terms of the exogenous entities: $r,w,\bar Q$.
To do that derive the optimal marginal cost (which is equal to the multiplier)</p>

<p>$$(4) \implies \lambda^* = (1/h)A(\bar Q)^{1/h-1} \tag{5}$$</p>

<p>Inserting $(5)$ into the first-order conditions we have</p>

<p>$$r = (1/h)A(\bar Q)^{1/h-1} F_K,\;\;\; w=(1/h)A(\bar Q)^{1/h-1} F_L  \tag{6}$$</p>

<p>It is time to use the specific functional form of the production function</p>

<p>$$F(K,L) = K^{1/2} + L^{1/2} \implies, F_K = \frac 12 K^{-1/2},\;\; F_L = \frac 12 L^{-1/2} \tag{7}$$</p>

<p>Inerting $(7)$ into $(6)$ together with $h=1/2$ we obtain, after manipulation,</p>

<p>$$rK = \frac {A^2}{r}(\bar Q)^2,\;\; wL = \frac {A^2}{w}(\bar Q)^2 \tag{8}$$</p>

<p>Sum the two to obtain an alternative expression for the Cost function</p>

<p>$$rK+wL = C^* = A(\bar Q)^2\cdot \left[\frac Ar + \frac Aw\right] \tag{9}$$</p>

<p>But inserting $h=1/2$ into $(4)$, we also have that </p>

<p>$$C^* = A(\bar Q)^2 \tag{10}$$
So</p>

<p>$$ (9),(10) \implies   A(\bar Q)^2\cdot \left[\frac Ar + \frac Aw\right] = A(\bar Q)^2$$</p>

<p>$$\implies \frac Ar + \frac Aw = 1 \implies A = \frac {wr}{w+r} \tag {11}$$</p>

<p>Inserting $(11)$ into $(4)$ we conclude obtaining</p>

<p>$$C^* = \frac {wr}{w+r}\cdot (\bar Q)^2 \tag{12}$$</p>

<p><strong>Three things:</strong><br>
<strong>A)</strong> Verify that the second-order-conditions hold for all this to indeed lead to the optimal cost-function.  </p>

<p><strong>B)</strong> Solve the unconstrained profit-maximization problem with the same production function, normalizing the price of output to $p=1$ (i.e. treating the exogenous prices, $w,r$ as expressed in real terms), to verify that it will lead to a cost level that it is consistent with $(12)$.  </p>

<p><strong>C)</strong> If you are interested in the theory of the firm under a budget constraint, a related paper is
<a href=""http://www.jstor.org/stable/1242132?seq=1#page_scan_tab_contents"" rel=""nofollow""><strong>Lee, H., &amp; Chambers, R. G. (1986). Expenditure constraints and profit maximization in US agriculture. American Journal of Agricultural Economics, 68(4), 857-865.</strong></a></p>
","5273"
"Marshallian Demand for Cobb-Douglas","15217","","<p>When trying maximize the utility having a cobb-douglas utility function $u=x_1^ax_2^b$, with $a+b = 1$, I found the following formulas (<a href=""http://de.wikipedia.org/wiki/Marshallsche_Nachfragefunktion#Marshallsche_Nachfragefunktionen_f.C3.BCr_g.C3.A4ngige_Nutzenfunktionen"">Wikipedia: Marshallian Demand</a>):</p>

<p>$x_1 = \frac{am}{p_1}\\
x_2 = \frac{bm}{p_2}$  </p>

<p>In one of my books I also find these formulas for the same purpose:</p>

<p>$x_1 = \frac{a}{a+b}\frac{m}{p_1} \\
x_2= \frac{b}{a+b}\frac{m}{p_2}$</p>

<p>With $p_i$: prices of the goods; $m$: budget</p>

<p>I tested all of them and they produced the same results.<br>
So are there any differences?</p>
","<p>Since $a + b=1$ the equations are exactly the same. Substituting in for $a+b$ with $1$ in the third and fourth equations gives the first and second equations. </p>
","5019"
"How can I obtain Leontief and Cobb-Douglas production function from CES function?","14972","","<p>In most Microeconomics textbooks it is mentioned that the Constant Elasticity of Substitution (CES) production function,
$$Q=\gamma[a K^{-\rho} +(1-a) L^{-\rho}  ]^{-\frac{1}{\rho}}$$</p>

<p>(where the elasticity of substitution is $\sigma = \frac 1{1+\rho},\rho &gt; -1$), has as its limits both the Leontief production function and the Cobb-Douglas one. Specifically,</p>

<p>$$\lim_{\rho\to \infty}Q= \gamma \min \left \{K , L\right\}$$</p>

<p>and</p>

<p>$$\lim_{\rho\to 0}Q= \gamma K^aL^{1-a}$$</p>

<p>But they never provide the mathematical proof for these results.  </p>

<p>Can somebody please provide these proofs?  </p>

<p>Moreover, the above CES function incorporates constant-returns-to-scale (homogeneity of degree one), due to the outside exponent being $-1/\rho$. If it was, say $-k/\rho$, then the degree of homogeneity would be $k$.  </p>

<p>How are the limiting results affected if $k\neq 1$?</p>
","<p>The proofs I will present are based on techniques relevant to the fact that the CES production function has the form of a <a href=""http://en.wikipedia.org/wiki/Generalized_mean"" rel=""noreferrer""><em>generalized weighted mean</em></a>.<br>
This was used in the original paper where the CES function was introduced, <a href=""http://www.jstor.org/stable/1927286"" rel=""noreferrer"">Arrow, K. J., Chenery, H. B., Minhas, B. S., &amp; Solow, R. M. (1961). Capital-labor substitution and economic efficiency. The Review of Economics and Statistics, 225-250.</a><br>
The authors there referred their readers to the book <a href=""http://books.google.gr/books/about/Inequalities.html?id=t1RCSP8YKt8C&amp;redir_esc=y"" rel=""noreferrer"">Hardy, G. H., Littlewood, J. E., &amp; Pólya, G. (1952). Inequalities </a>, chapter $2 $.</p>

<p>We consider the general case
$$Q_k=\gamma[a K^{-\rho} +(1-a) L^{-\rho}  ]^{-\frac{k}{\rho}},\;\; k&gt;0$$</p>

<p>$$\Rightarrow \gamma^{-1}Q_k = \frac 1{[a (1/K^{\rho}) +(1-a) (1/L^{\rho})  ]^{\frac{k}{\rho}}}$$</p>

<p><strong>1) Limit when $\rho \rightarrow \infty$</strong><br>
Since we are interested in the limit when $\rho\rightarrow \infty$ we can ignore the interval for which $\rho \leq0$, and treat $\rho$ as strictly positive.</p>

<p>Without loss of generality, assume $K\geq L \Rightarrow (1/K^{\rho})\leq (1/L^{\rho})$. We also have $K, L &gt;0$. Then we verify that the following inequality holds:</p>

<p>$$(1-a)^{k/\rho}(1/L^{k})\leq  \gamma Q_k^{-1} \leq (1/L^{k}) $$</p>

<p>$$\implies (1-a)^{k/\rho}(1/L^{k})\leq  [a (1/K^{\rho}) +(1-a) (1/L^{\rho})  ]^{\frac{k}{\rho}} \leq (1/L^{k}) \tag{1}$$</p>

<p>by raising throughout to the $\rho/k$ power to get</p>

<p>$$(1-a)(1/L^{\rho}) \leq a (1/K^{\rho}) +(1-a) (1/L^{\rho})  \leq (1/L^{\rho}) \tag {2}$$
which indeed holds, obviously, given the assumptions. Then go back to the first element of $(1)$ and</p>

<p>$$\lim_{\rho\rightarrow \infty} (1-a)^{k/\rho}(1/L^{k}) =(1/L^{k})$$</p>

<p>which sandwiches the middle term in $(1)$ to $(1/L^{k})$ , so </p>

<p>$$\lim_{\rho\rightarrow \infty}Q_k = \frac {\gamma }{1/L^k} = \gamma L^k = {\gamma }\big[\min\{K,L\}\big]^{k} \tag{3}$$</p>

<p>So for $k=1$ <strong>we obtain the basic Leontief production function.</strong>  </p>

<p><strong>2) Limit when $\rho \rightarrow 0$</strong><br>
Write the function using exponential as</p>

<p>$$\gamma^{-1}Q_k=\exp\left\{-\frac k{\rho}\cdot \ln\big[a (K^{\rho})^{-1} +(1-a) (L^{\rho})^{-1}\big]\right\} \tag {4}$$</p>

<p>Consider the first-order Maclaurin expansion (Taylor expansion centered at zero) of the term inside the logarithm, with respect to $\rho$:</p>

<p>$$a (K^{\rho})^{-1} +(1-a) (L^{\rho})^{-1} \\= a (K^{0})^{-1} +(1-a) (L^{0})^{-1} -a (K^{0})^{-2}K^{0}\rho\ln K- (1-a) (L^{0})^{-2}L^{0}\rho\ln L + O(\rho^2) \\$$</p>

<p>$$=1 - \rho a\ln K - \rho(1-a)\ln L+ O(\rho^2) = 1 +\rho \big[\ln K^{-a}L^{-(1-a)}\big]+ O(\rho^2)$$ </p>

<p>Insert this back into $(4)$ and get rid of the outer exponential,</p>

<p>$$\gamma^{-1}Q_k = \left(1 +\rho \big[\ln K^{-a}L^{-(1-a)}\big]+ O(\rho^{2})\right)^{-k/\rho}$$</p>

<p>In case it is opaque, define $r\equiv 1/\rho$ and re-write</p>

<p>$$\gamma^{-1}Q_k = \left(1 +\frac{\big[\ln K^{-a}L^{-(1-a)}\big]}{r}+ O(r^{-2})\right)^{-kr}$$</p>

<p>Now it does look like an expression whose limit at infinity will give us something exponential:</p>

<p>$$\lim_{\rho\rightarrow 0}\gamma^{-1}Q_k = \lim_{r\rightarrow \infty}\gamma^{-1}Q_k = \left(\exp\left\{ \ln K^{-a}L^{-(1-a)}\right\} \right)^{-k}$$</p>

<p>$$\Rightarrow \lim_{\rho\rightarrow 0}Q_k =\gamma\left(K^{a}L^{1-a}\right)^k$$</p>

<p>The degree of homogeneity $k$ of the function is preserved, and if $k=1$ <strong>we obtain the Cobb-Douglas function.</strong>  </p>

<p>It was this last result that made Arrow and Co to call $a$ the ""distribution"" parameter of the CES function.</p>
","399"
"What is structural estimation compared to reduced form estimation?","14682","","<p>I've heard a lot of definitions given for structural estimation. But it's never seemed entirely clear to me. Some times I've heard that what one person might call ""reduced form"" estimation should actually be called structural estimation. Sorry I don't have an example to illustrate, but I was wondering if somebody could clarify, hopefully with a link to a paper or some other source. What is structural estimation compared to reduced form estimation? Does the potential outcomes framework count as a structural equation?</p>
","<p>Structural estimation is a term coined by the Cowles commission which at the time seems to have been dominated by Haavelmo, Koopmans and a few others. The motto of the Cowles commission (after 1965) was: ""Theory and Measurement"". The phrase represents the underlying rationale of structural modelling, that measurement cannot be done without some kind of theory. To my knowledge, the phrase was first used by Koopmans in ""<a href=""http://www.jstor.org/stable/1905689"" rel=""nofollow noreferrer"">Identification Problems in Economic Model Construction</a>"":</p>

<blockquote>
  <p>Systems of structural equations may be composed entirely on the basis
  of economic ""theory."" By this term we shall understand the combination of (a) principles of economic of behavior derived from general observation--partly introspective, partly through interview or experience--of the motives of economic decisions,(b) knowledge of legal and institutional rules restricting individual behavior (tax schedules, price controls, reserve requirements, etc.), (c) technological knowledge, and (d) carefully constructed definitions of variables.</p>
</blockquote>

<p><strong>Structural equations are then equations that come from an underlying economic (or physical, or legal) model</strong>. Structural estimation is precisely estimation which uses these equations to identify parameters of interest, and inform counter-factuals. Importantly, these parameters are usually taken to be <em>invariant</em>, and therefore counter-factuals taken from their estimates will be completely ""correct"". Counter-factuals were the main unit of interest to the Cowles commission.</p>

<p>Koopmans also discusses reduced form estimation:</p>

<blockquote>
  <p>By the <em>reduced form</em> of a complete set of linear structural equations... we mean the form obtained by solving for each of the <em>dependent</em> (i.e., nonlagged endogenous) variables, and in terms of transformed disturbances (which are linear functions of the disturbances in the original structural equations).</p>
</blockquote>

<p>The linearity is an artifact of the times (this was published in 1949!) but the point is that reduced-form equations are equations written in terms of economic variables which do not have a structural interpretation as defined above. So, a linear regression will be a reduced-form of some true structural model, because linear regression <em>usually</em> does not have a true economic interpretation. This does not mean that reduced form equations cannot be used to identify parameters in structural equations - in fact this is precisely how <a href=""https://ideas.repec.org/a/jae/japmet/v8y1993isps85-118.html"" rel=""nofollow noreferrer"">indirect inference</a> works - just that they do not represent a deeper model of the data generating process. Reduced forms can (in principle) be used to identify structural parameters, in which cased you are still performing structural estimation, just through using the reduced form.</p>

<p>Another way to look at this is that <strong>structural models are generally deductive, whereas reduced forms tend to be used as part of some greater inductive reasoning</strong>.</p>

<p>For a comparison of this kind of Cowles commission structural modelling with Rubin causal modelling, check out <a href=""http://jenni.uchicago.edu/papers/koop2006/koop1-cowles_ho_2006-09-25_jlt.pdf"" rel=""nofollow noreferrer"">this awesome set of slides</a> by Heckman.</p>

<p>For other resources I'd check out more of what Koopmans wrote, the book <a href=""http://rads.stackoverflow.com/amzn/click/069115287X"" rel=""nofollow noreferrer"">Structural Macroeconomics</a> by DeJong and Dave, these <a href=""http://toni.marginalq.com/FMA.pdf"" rel=""nofollow noreferrer"">lecture notes by Whited</a>, <a href=""http://cowles.econ.yale.edu/conferences/koopmans/tck10/wolpin-2.pdf"" rel=""nofollow noreferrer"">this paper</a> by Wolpin (written for the Cowles Foundation, in honour of Koopmans) and <a href=""http://pages.stern.nyu.edu/~dbackus/Identification/Rust_Wolpin_review_Dec_13.pdf"" rel=""nofollow noreferrer"">a response</a> by Rust.</p>

<p><strong>Addendum:</strong> A simple example of reduced form and structural models.</p>

<p>Suppose we were looking at data on the prices, $p_t$ and quantities, $q_t$ produced by a monopolist. The monopolist faces a series of unknown costs in the future, and a linear demand curve (this would really have to be justified). Let's say the $\hat q_t$ and $\hat p_t$ we observe are measured with some kinds of mean-zero error, $e_t$, and $v_t$</p>

<p>Noting that both price and quantity seem to be associated with changes in cost, a reduced form equation for this model might be:
\begin{align}
\hat q_t &amp;= \gamma - \lambda c_t + \epsilon_t\\
\hat p_t &amp;= \alpha + \beta c_t + \nu_t
\end{align}
Because this is a reduced form model, it needs no justification other than that it might work empirically.</p>

<p>On the other hand, a structural model would start by specifying the demand curve (again to be strict this <em>should</em> start at the level of individual utility), and the monopolist's problem:</p>

<p>\begin{align}
\text{Demand curve: }&amp;p_t=a-bq_t\\
\text{Producer's problem: }&amp;\max E\left[\sum_{t=0}^\infty\delta^t (p_t-c_t)q_t(p_t)\right]\\
\text{Measurement equations: }&amp;\hat q_t = q_t + e_t\\
&amp;\hat p_t = p_t + v_t
\end{align}</p>

<p>From this further structural equations could be derived (structural because they are still representative of principles of economic behavior):</p>

<p>\begin{align}
\hat q_t&amp;=\frac{a-c_t}{2b} +e_t\\
\hat p_t&amp;=\frac{a+c_t}{2} + v_t\\
\end{align}</p>

<p>This is a case where a reduced form equation will have a meaningful structural interpretation, as consistent estimates $\hat a$ and $\hat b$ can be formed:</p>

<p>\begin{align}
\hat a&amp;= 2\hat\alpha \\
\hat b&amp;= \frac{1}{2\hat \lambda}
\end{align}</p>

<p>Another case of identification of structural parameters from reduced forms is the logit model in the case of valuations with extreme value errors (see <a href=""http://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf"" rel=""nofollow noreferrer"">McFadden (1974)</a>). In general it is unlikely a given reduced form model will have a structural interpretation.</p>
","187"
"Quasilinear Utility Functions","13454","","<p>We know if the utility function is quasilinear (QL) w.r.t good 1, then the demand for other goods is independent of income (no income effect for goods $(2,\dots, N)$). </p>

<p>But is the reverse implication also true: i.e can we say if all the goods except one have demand functions independent of income then the utility function must be quasilinear? </p>

<p>I have been looking up all the standard micro grad level text books but haven't got an answer yet. I see books defining (rather characterizing) QL by just one side of implication (i.e QL implies No income effect) but are silent about the other.</p>

<p>Any reference in this regard will be highly useful.</p>
","<h1>Is your claim 1 true?</h1>

<p>Let's look at an agent who's Utility is quasi linear in money, $m$, and goods $c$.</p>

<p>The utility function is given by</p>

<p>$$U(m,c) = m + f(c)$$ for some concave function $f$.</p>

<p>The maximization problem, given wealth $w$, prices of money and consumption $p, p_c$ is then</p>

<p>$$\max_{m,c} U(m,c) \text{ s.t. } pm + p_c c = w\\
= \max_c f(c) + \frac{w}{p} - \frac{p_c}{p}c\\
\Rightarrow f'(c) = \frac{p_c}{p}
$$</p>

<p>So the optimal amount for consumption $c$ is independent of the wealth level $w$, <em>if the interior solution qualifies as the global solution</em> - which it does for sufficiently high wealth level. I'm not from a micro background but I suppose this qualifies as <em>no income effect for the nonlinear good</em>.</p>

<p>The intuition is, that, beyond a threshold of income, you have your optimal consumption locus $c^*$ which is identified by the previous FOC. Having a higher income will make you want to save that money, not put it into consumption.</p>

<h1>What about the inverse?</h1>

<p>Now that we got the intuition, we can try to work it backwards. What do we need? That </p>

<p>$$\exists c^* : U(m+\epsilon, c^*) &gt; U(m, c^* + \frac{p}{p_c}\epsilon) \,\forall \epsilon &gt; 0$$</p>

<p>One can show (do it!) that if $U$ was concave in $m$, eventually the marginal value of increasing $m$ (for a large enough $\epsilon$) was smaller than investing it into $c$. </p>

<p>On the other hand, if $U$ was additively separable in $(m,c)$ and increasing but convex in $m$, we would - after a threshold - always invest all into $m$ and set $c=0$. Also here, after that threshold, the optimal locus for $c$ is trivially independent of the wealth level: no income effect.</p>

<p>Another example would be decreasing utility in $c$, which would make us set it independently of the wealth level to its global minimum (often 0).</p>

<p>You see, unless you give us a class of utility functions, there can be many valid (but economically stupid) cases of utility functions where the inverse does not hold.</p>
","3398"
"Effects of an expected increase in the inflation rate on the market for loanable funds","12767","","<p>I am supposed to answer a question in my economics class and was wondering if someone could explain it out for me. The question is,</p>

<blockquote>
  <p>What is the effect of an increase in the expected inflation rate on the loanable funds market?</p>
</blockquote>

<p>This question goes against what I was taught. I was taught about the Fisher Effect where the real interest rate is not effected by changes in expected inflation and that the quantity of loanable funds does not change with this rise in effect inflation. So, my instinctive answer upon reading the question would be to answer no effect on quantity or real interest rate and that there would be a rise in nominal interest rate. However, this was a multiple choice question and that wasn't even close to one of the answers.</p>

<p>I think I got the answer right by saying</p>

<blockquote>
  <p>It decreases the demand for loanable funds, thereby increasing the nominal interest rate.</p>
</blockquote>

<p>All of the answers involved a shift in the demand curve for loanable funds. My question is if anyone could explain to me why there would be a shift in the demand curve instead of what we would expect based on the Fisher Effect?</p>
","<p>The Fisher Hypothesis is a standard example of the approach that argues that nominal magnitudes just reflect the real economy, they do not affect it. Denote $r$ the real interest rate, $i$ the nominal interest rate, and $\pi^e$ the expected inflation. Then the Fisher Hypothesis states that</p>

<p>$$i = r+  \pi^e$$</p>

<p>I write it this way to emphasize that it is the nominal interest rate that depends on the real one. In this framework, the real interest rate is determined in the real economy, say the marginal product of capital. So an increase in expected inflation will have the effect of increasing the nominal interest rate, and nothing else.  </p>

<p>How is this rationalized?</p>

<p>The demand schedule for loanable funds is drawn with respect to their price. The price of loanable funds is the <em>nominal</em> interest rate. Magnitudes like expected inflation, if they have an effect, is to shift the whole demand schedule. </p>

<p>In a standard diagram, and with supply curve assumed unaffected, your answer appears strange: since when a ""decrease in demand"" (shift to the left of the demand schedule), leads to an <em>increase</em> in the equilibrium price? Intuitively, when customers start to demand less for any given price, this will lead to a <em>lower</em> equilibrium price, not higher. But the second part of your answer asserts that the price, i.e. the nominal interest rate, will <em>increase</em> due to this <em>downward</em> shift in the demand schedule.</p>

<p><em>Before</em> any re-equilibrium effect, a rise in expected inflation <em>reduces</em> the real interest rate that prospective borrowers face. They may pay the same nominal interest rate, but the financial burden is smaller, due to the inflationary expectations: loans have just become cheaper, in real terms (while the <em>current</em> purchasing power they represent has not been affected).</p>

<p>So inflationary expectations shift the demand schedule upwards-outwards.  </p>

<p>Now, it would be arbitrary to keep the supply schedule fixed. If expected inflation increases, prospective lenders should have a tendency to increase their current consumption, thus <em>reducing</em> the available funds: the supply schedule shifts upwards.</p>

<p>The Fisher Hypothesis says that these movements will lead to an increase in the equilibrium nominal interest rate, and the increase will be equal to the increase in expected inflation, since the real interest rate ""should"" remain constant.</p>

<p>$$\Delta i^* =  \Delta \pi^e \implies \Delta r =0$$</p>

<p>Moreover, the equilibrium quantity of loans will be unaffected, (and so real magnitudes like consumption will be unaffected).</p>

<p><img src=""https://i.stack.imgur.com/a7Rrm.png"" alt=""enter image description here""></p>

<p>If no choice reflecting the above effects was given to you, and if ""none of the above"" was not an option, then the question was deficient, <em>or</em> it postulated some additional assumption.</p>
","4660"
"Why hasn't massive derivatives exposures at banks already led to disaster?","12647","","<p>I recently heard that Deutsche Bank had 
$72trillion of ""derivatives exposure"", which 
is many times greater then the entire German GDP.</p>

<p>Now as I understand it, derivatives are essentially 
just bets on the movement of assorted prices... 
so I am assuming that ""derivatives exposure"" means
the total amount you would have to pay out if
you lost every single one of your bets. The 
likelyhood of this scenario may of course be 
vanishingly small, but presumably with 
$72trillion of exposure, you wouldn't need 
much of a losing streak in order to leave 
you bankrupt.</p>

<p>So some people are saying - ""ooh this looks 
scary, it could lead to disaster""... but my 
reaction is ""ooh this is scary... but why on 
earth hasn't it led to disaster already?"".</p>

<p>Now I know there were multiple 
disasters around 2007/8 already and derivatives 
may have played a significant role in that... but
I'm referring to, lets say, the past five years. 
How could Deutsche Bank have gotten to 
$72trillion of exposure without blowing up 
again? What kind of bets have they been doing
such that they <em>haven't</em> had enormous losses?</p>

<p><strong>EDIT:</strong> FYI this question has a followup <a href=""https://economics.stackexchange.com/questions/13094/could-massive-derivatives-exposures-at-banks-lead-to-disaster"">here</a>.</p>
","<p>While gross notional exposures are huge, <a href=""https://www.linkedin.com/pulse/derivatives-banks-must-report-gross-notional-net-pascal"">net exposures at the banks are much smaller, on the order of 0.1 percent of gross exposures</a>. Since most financial risk (but perhaps not operational risk) is proportional to net exposures this is a more sensible measure of total derivative risk at the banks. Since net exposures at the 6 banks with the largest derivative exposures circa 2014 were on the order of \$300 billion while their total assets were more than \$10 trillion, we may not have seen a disaster because the actual risk is appropriate to the scale of their broader operations. </p>

<p>Here is an example of how this works. At time 0 a bank does derivative trade with notional of 100 with A and collects the offer (or ask) price. That is, the bank sells the derivative to someone who wants to buy it. At time 1 a bank does derivative trade with B with notional of 100 and collects the bid price. That is, they buy the derivative from someone who wants to sell it. Total (gross) derivative exposure is 200, two derivative contracts each with an exposure of 100. However, net exposure is zero, and the bank keeps the spread as profit for its trouble. There is likely some remaining risk in the form of operations and credit risk, but this is what the spread and initial and variation margin are for. </p>
","10650"
"When do supply and demand curves shift?","12428","","<p>Let's assume that the price of apples has risen and that the quantity of apples sold during the last couple of weeks has decreased. From that, we can infer that the supply curve must've shifted to the left.</p>

<p>I still have trouble fully understanding this. I was told that when the endogenous variables, such as price and quantity, change, only a movement on the demand/supply curve happens and when exogenous variables change (demand shocks etc.) the curves themselves will shift to the left or right.</p>

<p>In this example a price increase takes place, so we're just moving up the demand curve, no? And when we reach the target price level, there'll be a corresponding quantity. And now because of market equilibrium the supply curve has to reach that spot, too? So it shifts to the left? Is that correct? So in a demand - supply model, there can't be singular movements on the curves, as there will always be immediate reactions that seek to recreate the equilibrium?</p>

<p>Edit: Thanks for all the answers!</p>
","<p>Supply and demand curves are a function of price and quantity.  If <em>anything</em> else changes other than P or Q that is relevant to the curve, the curve shifts.</p>

<p>For supply, these shifters generally fall into three  categories:  </p>

<ol>
<li>Technology  </li>
<li>Number of producers</li>
<li>Price of inputs</li>
</ol>

<p>For demand: </p>

<ol>
<li>Number of buyers </li>
<li>Price of complements or substitutes </li>
<li>Customer tastes and preferences</li>
<li>Consumer income</li>
</ol>

<p>If you come up with something that didn't fit into these categories, but is not P or Q, the result is still a shift! You probably just need your imagination to squeeze it into one of these 7 formal categories.  For example, if the supply curve was P=2Q+3, and there was a decrease in the cost of inputs, the demand curve could shift to P=2Q+2.  Note how the price levels are lower at every level of Q.<a href=""https://i.stack.imgur.com/EO3qZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EO3qZ.png"" alt=""Downward Shift in Supply""></a></p>

<p>Changes in supply and demand that are not ""shifts"" are called ""slides along the curve"". They are any direct change in P or Q. This is easiest to see with a linear, mathematical example. </p>

<p>Let us say the government wants to set the price of a product. If P=2Q+3 is the supply, then consider that if you set the price (by law) to be 7, then Q is now 2. The curve remains steady, but we slide along it to get to the new P=7, Q=2 position. From wherever P and Q started (P=12 in the example), we now end at point P=7,Q=2, and the curve remains unmoved along the entire line P=2Q+3.<a href=""https://i.stack.imgur.com/l9hby.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/l9hby.png"" alt=""Downward Slide along Supply Curve, Reduction in Quantity Supplied""></a></p>
","5770"
"Best resource to learn Microeconomics fast?","11908","","<p>I'm going to be honest, I have 2 full days to study for an Introductory Microeconomics exam final, and I am starting from scratch. The course was given online and the assignments were very easy to complete since we had 3 tries and the questions repeated.</p>

<p>I have no background in micro but my math is very good for this type of course (completed Calculus 3 and Combinatorics), and I am looking for a resource to learn the material quickly. </p>

<p>I have looked online and haven't really found one. The book we use in class is full babbling analysis of graphs that I already understand and random examples that don't cover the material efficiently. I am looking for a sort of summary that covers the essentials.</p>

<p>I know that I should have studied earlier, but I still want to try my best to have, at least, a passing grade.</p>

<p>Any recommendation will be appreciated.</p>

<p>Thank you in advance.</p>
","<p>It would help a lot to know at what level this class is exactly. You mention calculus, however most classes titled like yours (""Introductory Microeconomics"") tend to be very light on math. I'm going to assume that your class is of the learning-introductory-concepts variety and not of the taking-partial-derivatives-to-maximize-utility variety. If I'm wrong please correct me (or ignore this answer).</p>

<p>You have two options:</p>

<p>1) Obtain a virtual copy of an intro micro textbook (I can vouch for Mankiw's Principles of Microeconomics) and read it cover to cover.</p>

<p>2) Use a (probably) less-reliable resource such as <a href=""http://economics.about.com/od/microeconomics/a/micro_text.htm"">this</a> or the link you posted in your answer.</p>

<p>Of course, I choose these options with the assumption that your textbook is as bad as you say it is. I would still recommend you go over the course material to determine what your instructor considers important.</p>

<p>Important note: at this level of economics, knowing how to <em>do</em> things (calculate elasticity, do simple math in simple word problems about total cost and average cost, etc) is not nearly as important as <em>understanding</em> the concepts being taught. You say you've taken Calculus 3; expect basically the opposite of your Calc 3 final for this final. Of course, you should know the equation for, say, the elasticity of demand. However, the much more important thing is understanding what elasticity means and how to apply the concept to novel real-world problems.</p>

<p>Here is my off-the-top-of-my-head list of concepts you need to master.</p>

<ul>
<li><p>Competition. How does profit get driven to 0 in a competitive market? What happens when demand increases in the short run? What then happens as time goes on?</p></li>
<li><p>Monopolies. Understand why it is in a monopolist's best interest to produce less than the efficient amount. Understand <em>why</em> a monopolist faces a downward sloping MR curve while a competitive firm faces a flat MR curve. Be able to show your understanding on a graph.</p></li>
<li><p>Understand the difference between an increase in demand (ie, an outward shift in the demand function) and an increase in quantity demanded. Same for supply. Be able to show it on a graph.</p></li>
<li><p>Understand what happens to quantity supplied and quantity demanded when a binding price floor is in place. Be able to show it on a graph.</p></li>
<li><p>Firm cost and revenue graphs. How are ATC, MC, MR, P, AVC, and AFC related? Does the answer to this depend on the structure of the market? Why are supply curves upward sloping while demand curves are downward sloping? What are sunk costs?</p></li>
<li><p>Opportunity cost. what is opportunity cost? If firms in a competitive market see 0 economic profit, how is it that real-world firms achieve positive accounting profit?</p></li>
<li><p>Specialization and comparative advantage.</p></li>
<li><p>Price discrimination.</p></li>
<li><p>Deadweight loss. What is it and why do taxes create it. Be able to show it on a graph.</p></li>
<li><p>Externalities, public goods, and Pigovian taxes. </p></li>
<li><p>Elasticity. Bonus points for understanding in terms of calculus. Understand perfect elasticity and perfect inelasticity. Show it on a graph.</p></li>
</ul>
","557"
"Gross substitutes vs. net substitutes","11764","","<p><a href=""https://en.wikipedia.org/wiki/Substitute_good#Different_types"" rel=""noreferrer"">Wikipedia explains the difference</a> between products that are ""gross substitutes"" and products that are ""net substitutes"". However, the mathematical explanation doesn't give much intuition about these concepts. So my questions are:</p>

<ol>
<li>What is the intuitive difference between gross and net substitutes? </li>
<li>What are good real-life examples of these?</li>
<li>Why is the requirement for <a href=""https://en.wikipedia.org/wiki/Competitive_equilibrium"" rel=""noreferrer"">competitive equilibrium</a>, ""gross substitute"" and not ""net substitute""? I.e., why does a competitive equilibrium not exist if the products are net-substitute?</li>
</ol>
","<p>Intuitively, a higher price for pears means that I have to give up more apples to be able to afford an extra pear (or, conversely, if I give up one pear then the number of extra apples that I can afford increases). This is going to make me want to reduce my pear consumption and increase my apple consumption (in orther words, to substitute away from pears towards apples). Graphically, this corresponds to a change in the slope of the budget constraint and is known as the <em>(Hicksian) <a href=""http://en.wikipedia.org/wiki/Substitution_effect"">substitution effect</a></em>.</p>

<p>This substitution effect is, however, moderated by a second consideration. If I increase one or more prices then the total amount of ""stuff"" that I can afford to buy decreases, so it is as if my income has decreased (which would correspond to a shift of the budget constraint towards the origin). This is known as the <em><a href=""http://en.wikipedia.org/wiki/Income%E2%80%93consumption_curve"">income effect</a></em> and will usually mean that my consumption of apples decreases if the price of pears rises.</p>

<p>When the income and substitutes effects are put together, you get the total effect of an increase in the pear price upon the demand for apples. This total effect gives rise the the notion of <strong>gross substitutes</strong>: apples and pears are gross substitutes if the following is true</p>

<blockquote>
  <p>increasing the price of pears causes the consumer to demand more apples.</p>
</blockquote>

<p>Formally, this is written as $$\frac{\partial X_a}{\partial p_P}&gt;0,$$ where $X_A$ and $p_P$ are the demand for apples and the price of pears respectively.</p>

<p>To arrive at the notion of <strong>net substitutes</strong> we simply take a price change and shut-down the income effect. The hypothetical exercise works like this:</p>

<ol>
<li>we increase the price of pears, which induces both an income effect and a substitution effect.</li>
<li>to compensate the consumer for the income effect, we give him exactly enough extra money to ensure that (even though one of the prices is higher) he can still afford to get onto the same indifference curve as before. Hence his utility will remain unchanged.</li>
<li>We look at how his demand changed, which now depends only on the substitution effect (since we have compensated the consumer for any change in real income).</li>
</ol>

<p>Two goods are net substitutes if, after making this adjustment, we find that the demand for apples has increased. Thus, we say that two produces are net substitutes if</p>

<blockquote>
  <p>Increasing the price of pears while compensating the consumer for the resulting decrease in his real income causes the consumer to demand more apples.</p>
</blockquote>

<p>Formally, $$\left.\frac{\partial X_a}{\partial p_P}\right|_{\text{constant }U}&gt;0,$$ where $X_A$ and $p_P$ are the demand for apples and the price of pears respectively, and $U$ is the consumer's utility.</p>

<hr>

<p>It is not true to say that ""a competitive equilibrium [does] not exist if the products are net-substitute"". Indeed, most of the time, products that are gross substitutes will also be net substitutes as well. Thus, most examples of gross substitute preferences supporting a competitive equilibrium will also be examples of net substitutes doing the same.</p>

<p>The reason why it doesn't make sense to state the existence condition for competitive equilibrium in terms of net substitutes is that net substitutes is a purely hypothetical construction in which a fictitious agent intervenes to shut down the income effect and keep the consumer's utility constant. The whole point of a competitive equilibrium is that there is no such intervention: the equilibrium is entirely decentralised and is sustained purely by finding prices such that the market clears when consumers pick their optimal demand.</p>
","4580"
"Real Exchange Rate vs PPP rate","11732","","<p>I'm having troubles to understand the difference between the Real Exchange Rate and the PPP rate.</p>

<p>I know the first one is calculated using a basket of goods and services so that the non-tradeable basket costs the same in 2 countries (imagining a 2-country world).  Now, isn't that the rate that would hold if PPP applies?</p>

<p>I think I'm wrong if I say that the real exchange rate is the one that makes PPP become valid.  Any help appreciated.</p>
","<p>There are several exchange rate concepts that need to be distinguished. There are bilateral and multilateral (aka ""effective"") exchange rates, nominal and real exchange rates, and market-price versus PPP (purchasing power parity) exchange rates.</p>

<ul>
<li><p>Let's start with the simplest concept: A bilateral <em>nominal</em> exchange rate, e.g., 117 yen/(US dollar), 0.8 pounds/euro, 7.7 (Swedish krona)/(Swiss Franc), etc. These are the exchange rates that are commonly reported in newspapers and in any number of online outlets. </p>

<ul>
<li>Aside: There are two distinct quoting conventions for exchange rates: the ""E"" system (with the home currency in the numerator) and the inverse, the ""R"" system. A nominal exchange of 1.2 Swiss francs per euro is expressed in the ""R"" system from the point of view of a euro area resident, and in the ""E"" system from the point of view of a resident of Switzerland. The ""R"" convention is conceptually easier to work with, since an <em>increase</em> of the numbers of foreign currency units per unit of home currency corresponds naturally to an <em>appreciation</em> of the home currency. Using the ""E"" system, the opposite is the case. There seems to be little or no standardization with regard to quoting conventions of bilateral exchange rates. However, multilateral exchange rates are always expressed using the ""R"" convention, such that a larger numerical value corresponds to an appreciation of the currency, and vice versa.</li>
</ul></li>
<li><p>A bilateral <em>real</em> exchange rate is the bilateral nominal exchange rate multiplied by a ratio of price indices of the two currencies. (How the ratio is taken depends on whether the currency pair is quoted in the E or R method.) Naturally, many different price indices can be used; most common, though, is the use of headline CPIs (consumer price indices). Because CPI series are generally monthly (or even lower frequency) time series, real exchange rates too are generally monthly time series. The home currency appreciates in real terms against a foreign currency either if the home currency appreciates in nominal terms or if the home country's inflation rate is lower than that in the foreign currency.</p></li>
<li><p>While bilateral exchange rates are straightforward to report, interest often centers on multilateral exchange rates. The home economy has trade and financial ties not just with one other economy but (usually) with many different economies. To form an index of the multilateral exchange value of the home currency, it's necessary to weight the various bilateral exchange rates according to the importance of the foreign economies. Again, many different weighting schemes are possible; a common scheme uses merchandies trade weights based on imports and/or exports between the home economy and the most important foreign economies. Because bilateral exchange rates are ratios of relative prices, an exchange rate index (aka a multilateral or efffective exchange rate) is computed as a Tornqvist index (a geometric rather than arithmetic average).</p></li>
<li><p>Up to now, we've mainly dealt with market prices for both nominal and real exchange rates. While that's perfectly OK for many applications, it's not the most helpful way to proceed if one wants to make comparisons of standards of living across countries. Purchasing power parity (PPP) tries to facilitate such comparisons by figuring how much a <em>standard</em> ""basket of goods"" -- frequently, but not always, the goods in the CPI baskets -- costs in various countries. </p>

<p>A famous case of a bilateral PPP exchange rate is the ""Big Mac Index"" of <em>The Economist</em> magazine: Since a Big Mac is pretty much the same in all countries where it's sold, one can work out the PPP-based bilateral exchange between the U.S. dollar (say) and all other countries as the exchange rates that would make the cost of purchasing a Big Mac the same. (Obviously, <em>The Economist</em> makes no claim that the Big Mac features prominently in anybody's consumption basket.) </p>

<p>By comparing nominal and PPP-based exchange rates it is possible to make statements such as ""currency A is overvalued (or undervalued) against currency B"". Of course, different choices of consumption baskets will lead to different PPP exchange rates. Hence, depending on the choice of basket, conflicting answers may arise as to whether a currency is over- or undervalued.</p></li>
</ul>

<p>For more about the Big Mac index, check out the <a href=""http://www.economist.com/content/big-mac-index"">Economist Magazine's own website</a>.</p>

<p>For a non-technical discussion of the dollar indices used by the staff of the U.S. Federal Reserve Board see, e.g, the 2005 article <a href=""http://www.federalreserve.gov/pubs/bulletin/2005/winter05_index.pdf"">Indexes of the Foreign Exchange Value of the Dollar</a> in Federal Reserve Bulletin.</p>
","22"
"Equilibrium price and quantity - consumer and producer surplus","11482","","<p>Inverse function of market demand for certain good is equal to $P=100-0.25Q$, inverse supply function is $P=20+0.55Q$. Calculate equilibrium price and quantity. Furthermore calculate consumer and producer surplus.</p>

<p>Equlibrium price and quantity i think i know how to calculate:
$$20+0.55Q=100-0.25Q$$
and this will be the quantity whereas the price will be (substituting Q with value calculated above): 
20+0.55Q=P
am i correct with this?
I am lost with consumer/producer surplus need more help. 
edit: I have and idea about consumer/producer surplus:
consumer:
$0.5 \times 100 \times 25=1250$ and producer $100 \times 55 \times 0.5=2750$
is this correct?</p>
","<p>Equating supply and demand we obtain the equilibrium</p>

<p>$$P^* = 75, Q^*=100$$</p>

<p>The corresponding diagram is
<img src=""https://i.stack.imgur.com/mxrp8.png"" alt=""enter image description here""></p>

<p><strong>Consumer Surplus</strong> is the area of triangle $B-E-C$ so</p>

<p>$$CS = \frac 12 \cdot (100-75)\cdot 100 = 1250$$</p>

<p><strong>Producer Surplus</strong> is the area of the triangle $B-E-A$ so</p>

<p>$$PS = \frac 12 \cdot (75-20)\cdot 100 = 2750$$</p>
","5037"
"Fundamental equations in economics","10826","","<p>For the other sciences it´s easy to point to the most important equations that ground the discipline. If I want to explain Economics to a physicist say, what are considered to be the most important equations that underly the subject which I should introduce and attempt to explain?</p>
","<p>Instead of proposing specific equations, I will point to two concepts that <em>lead</em> to specific equations for specific theoretical set ups:</p>

<p><strong>A) Equilibrium</strong><br>
The most fundamental and the most misunderstood concept in Economics. People look around and see constant movement -how more irrelevant can a concept be, than ""equilibrium""? So the job here is to convey that Economics models the observation that things most of the time <em>tend</em> to ""settle down"" -so by characterizing this ""fixed point"", it gives us an anchor to understand the movements outside and around this equilibrium (which may be changing of course).</p>

<p>It is <em>not</em> the case that ""<strong>quantity supplied equals quantity demanded</strong>"" (here is a foundational equation)  </p>

<p>$$Q_d = Q_s$$</p>

<p>but it <em>is</em> the case that supply <em>tends to equal</em> demand (of <em>anything</em>) for reasons that any economist should be able to convincingly present to anyone interested in listening (and deep down they all have to do with finite resources).</p>

<p>Also, by determining the conditions for equilibrium, we can understand, when we observe divergence, which conditions were violated. </p>

<p><strong>B) Marginal optimization under constraints</strong><br>
In a <strong>static environment</strong>, it leads to the equation of marginal quantities/first derivatives of functions.<br>
Goods market: <strong>marginal revenue equals marginal cost</strong>.<br>
Inputs market: <strong>marginal revenue product equals marginal reward</strong> (rent, wage).<br>
Etc. (I left ""utility maximization"" out of the picture on purpose, because, here first one would have to present what this ""utility index"" is all about, and how crazy we are (<em>not</em>), by trying to model human ""enjoyment"" through the concept of utility).  </p>

<p>Perhaps you could cover it all under the umbrella ""marginal benefit equal marginal cost"" as other questions suggested:</p>

<p>$$MB = MC$$</p>

<p>Economists live in marginal optimization and most consider it self-evident. But if you try to explain it to an outsider, there is a respectable probability that he will object or remain unconvinced, instead usually proposing ""average optimization"" as ""more realistic"", since ""people do not calculate derivatives"" (we don't argue that they do, only that their thought processes can be modeled <em>as if</em> they were). So one has to get his story straight about marginal optimization, with convincing examples, and a discussion about ""why not average optimization"".</p>

<p>In an <strong>intertemporal setting</strong>, it leads to the discounted trade-off between ""the present and the future"", again ""at the margin"" -starting with the <strong>""Euler equation in consumption""</strong>, which in its discrete deterministic version reads</p>

<p>$$u'(c_{t})=\beta(1+r_{t+1})u'(c_{t+1})$$</p>

<p>...and one cannot avoid the theme of utility, after all: $u'()$ is marginal utility from consumption, $0&lt;\beta&lt;1$ is a discount rate and $r_{t+1}$ is the interest rate</p>

<p>(<em>don't</em> consult wikipedia article on Euler's equation in consumption, the concept behind it is much more generally applicable and foundational than the specific application that the wikipedia article discusses).  </p>

<p>Interestingly, although dynamic economics are more technically demanding, I find this more intuitively appealing since people seem to understand way better ""what you save today will determine what you will consume tomorrow"", than ""your wage rate will be the marginal revenue product of all labor employed"".  </p>
","49"
"How do I calculate quantity to minimize long-run average total cost?","10468","","<p>I have a formula for the long-run total cost curve,</p>

<p>$$TC(Q) = 6000Q + 40Q^2 + Q^3$$</p>

<p>and I'm trying to find the quantity that minimizes the long-run average total cost. </p>

<p>I assume I'm trying to find the value $Q$ (quantity) that produces the total cost ($TC(Q)$) where $\frac{TC(Q)}{Q}$ is the lowest. But how do I do this short of trial and error?</p>
","<p>Your are right. You have to minimize the average cost.</p>

<p>$$c(Q)=\frac{C(Q)}{Q}=6000 +40Q+Q^2$$</p>

<p>Calculate the first derivative and set it equal to zero:</p>

<p>$ c'(Q)=40+2Q=0 $</p>

<p>Solve this equation for $Q$. Denote the optimal value as $Q^*$. $Q^*$ can be a local maximum or a local minimum</p>

<p>If $c''(Q^*)&gt;0$, then you have found the local minimum.</p>

<p>The local minimum is also the absolute minimum, because</p>

<p>$$\lim_{Q \to \infty } 6000 +40Q+Q^2=\infty$$</p>

<p>$$\lim_{Q \to -\infty } 6000 +40Q+Q^2=\infty$$</p>
","5815"
"What is the definition of ""First Best"", ""Second Best"", etc. in contract theory?","10418","","<p>What is the definition of ""First Best"", ""Second Best"", etc. in contract theory?</p>

<p>Especially, what is the difference between ""First Best"" in contract theory and ""ex-post efficient"" in mechanism design?</p>
","<p><strong>In contract theory</strong></p>

<p>The <em>first-best</em> refers to the best you could do if you knew agents' preferences over labor an income (i.e., if you did not have to impose the incentive compatibility constraint), and the <em>second-best</em> is the best you can do if agents have to reveal their preferences themselves.</p>

<p><strong>In mechanism design</strong></p>

<p>A useful reference is Galichon, Alfred, Ex-Ante vs. Ex-Post Efficiency in Matching (May 21, 2011). Available at SSRN: <a href=""http://ssrn.com/abstract=1837321"" rel=""nofollow noreferrer"">http://ssrn.com/abstract=1837321</a> or <a href=""http://dx.doi.org/10.2139/ssrn.1837321"" rel=""nofollow noreferrer"">http://dx.doi.org/10.2139/ssrn.1837321</a>  :</p>

<blockquote>
  <p>""an assignment is called ex-post efficient if no other <em>deterministic assignment</em> is improving on it in a Pareto sense; and ex-ante efficient if no <em>lottery over deterministic assignments</em> is."" (my emphasis)</p>
</blockquote>

<p><strong>Difference between the two</strong></p>

<p>There is not much connexion between the two notions as defined above. Every combination of the two notions is <em>a priori</em> possible. Both a mechanism and a contract can be</p>

<ol>
<li><p>First-best ex-post efficient (i.e., efficient when incentive compatibility constraint is <em>not</em> imposed and the outcome of the mechanism/contract must be <strong>deterministic</strong>)</p></li>
<li><p>First-best ex-ante efficient (i.e., efficient when incentive compatibility constraint is <em>not</em> imposed and the outcome of the mechanism/contract can be <strong>random</strong>)</p></li>
<li><p>Second-best ex-post efficient (i.e., efficient when incentive compatibility constraint is imposed and the outcome of the mechanism/contract must be <strong>deterministic</strong>)</p></li>
<li><p>Second-best ex-ante efficient (i.e., efficient when incentive compatibility constraint is imposed and the outcome of the mechanism/contract can be <strong>random</strong>)</p></li>
</ol>

<p><strong>In the literature</strong></p>

<p>Yet, in general, you are be more likely to find the first-best/second-best terminology in contract theory (random contracts are not <em>that common</em> in contract theory), and the ex-post/ex-ante efficiency in mechanism design (knowledge of the preferences is rarely assumed in a mechanism: the fact that we do not know agents preferences is the <em>raison d'être</em> of mechanism design). </p>

<p>Thus you can expect to see 3. and 4. being discussed in the mechanism design literature, and 1. and 3. being discussed in contract theory.</p>

<p><strong>Beware</strong></p>

<p>This being said, the notions of second-best and first-best are often used outside of contract theory in a rather permissive way, which may be confusing. </p>

<p>For some people, first-best simply means ""if we do <em>not</em> impose some constraint $X$"" and second-best means ""if we <em>do</em> impose constraint $X$"". </p>

<p>Thus you may hear people talk about (beware this is where it gets confusing) </p>

<ul>
<li>an ex-post efficient mechanism as ""second-best"" efficient, because it is ""efficient under the constraint that the assignment be deterministic"". </li>
<li>an ex-ante efficient mechanism as ""first-best"" efficient, that is ""efficient if we do <em>not</em> impose constraint $X$"".</li>
</ul>

<p>Hope that clarifies it (or at least does not confuse you more).</p>
","4502"
"How does buying/selling houses affect the GDP?","9880","","<p>Suppose I buy a house and sell it off in the same year for the same price, would the GDP for that year increase by twice the value of the house, or only once, or not at all?</p>
","<p>There is only a change in GDP to the extent there are market goods and services used in the sale and only those goods and services are counted. The actual sales revenue are irrelevant. For example, the home inspection, appraisal, brokerage fees, and, I believe mortgage closing costs, would be in GDP. If you and your sister swapped houses in as-is condition without getting the market, bank, or tax authority involved, there would be no change in GDP.  </p>
","4932"
"Why do economists disagree so much?","9742","","<p>I'm coming at this from a scientific point of view, having had no formal training in economics - most of what I know about it was from self-studying an undergraduate economics textbook.</p>

<p>My question is, why do economists disagree so much? This doesn't happen in the sciences. For example, for the question ""will a driver in a car with these safeguards survive a collision at 100km/h"", most scientists will agree on an answer. It might be conditional on various things (e.g. age of the driver), but most scientists will come to the same conclusion.</p>

<p>However in economics, it's different. Faced with a question such as ""should we provide more fiscal stimulus for the economy"", it's possible that one big group of economists says ""yes"", and then another big group says ""no"". To some extent this might be because of personal interpretation of what is desirable. However I would expect that economists should still be able to say something like ""if you provide fiscal stimulus, this will happen, and it's up to you to judge whether the consequences are desirable"", and yet it seems there's no consensus on what will actually happen. It doesn't help that when I see economics debated in the media, both sides advance what looks like reasonable arguments.</p>

<p>Does economics have predictive power? If so, at what point does economics fail to give good predictions, and how should a policymaker deal with economists disagreeing? If not, what's the point of economics (it might as well be astrology)?</p>
","<p>Some areas of economics have more consensus and predictive power than others. Most economists would agree on the effects of trade barriers, could fairly accurately forecast the effects of a price change given a good demand estimate, would come to the same conclusion about the effects of allowing a merger between two large competing firms, know how asset prices will react to a change in interest rates, etc.</p>

<p>The effect of a fiscal stimulus is one of the most complicated questions in economics because you are asking about the effect of stimulating a system with millions of moving parts (people and firms) and many dimensions (consumption/saving, employment/work, trade, investment, innovation, ...). This is a long way from the simple, closed systems for which natural science is able to give sharp predictions. In fact, when you look at parts of the natural sciences that deal with similar levels of systemic complexity, the overall (lack of) predictive power looks similar to that in economics:</p>

<ul>
<li>although principles of ecology are well understood, it is almost impossible to accurately predict what the final effect of, say, introducing a new species into an ecosystem will be</li>
<li>the theory of evolution is probably one of the greatest scientific theories of all time, but can only be used to make the vaguest predictions about the future</li>
<li>medics cannot accurately predict the onset of a wide range of diseases—only diagnose them ex post</li>
<li>models of future global temperature increases have wide error bars</li>
<li>weather forecasts more than one or two days into the future have wide error bars</li>
</ul>

<p>The other thing to note is that fiscal stimulus is a highly politicised topic and economists often do a (frustratingly) poor job of keeping politics out of the debate. If you read the economic literature, you will find a story similar to that for your car crash: any outcome is possible but some look more likely, depending on the exact circumstances. Given this ambiguity, politicians of different persuasions have no difficulty finding an economist willing to ignore this nuance and take a politically expedient position (just as conservative politicians can always find scientists willing to play down anthropogenic global warming). But that is less a failing with economics than with economists.</p>
","19742"
"How much money is wire transferred every year worldwide?","8760","","<p>How much money is wire transferred every year worldwide? Estimates are fine.</p>
","<p>If you're just trying to understand the volume of electronic transactions generally to an order of magnitude, it's in the quadrillions of dollars per year. According to <a href=""https://www.fincen.gov/news_room/rp/files/Appendix_D.pdf"" rel=""nofollow"">this document</a> from the US Treasury, SWIFT handles about \$5 trillion per day, or given about 250 business days per year, about \$1.25 quadrillion dollars a year. </p>

<p>Similarly, <a href=""https://www.theclearinghouse.org/payments/chips/helpful-info"" rel=""nofollow"">CHIPS</a> handles about \$400 trillion per year, and <a href=""https://www.frbservices.org/operations/fedwire/fedwire_funds_services_statistics.html"" rel=""nofollow"">Fedwire</a> handles around \$900 trillion per year (most of both of these arise out of SWIFT messages). These transactions make up a large fraction of electronic transactions in the world, so it's safe to assume that the global total isn't much more than a few quadrillion dollars a year.</p>

<p>SWIFT payment message volumes are usually <a href=""http://www.swift.com/about_swift/company_information/fin_traffic_new"" rel=""nofollow"">around 11.5 million per day</a>, giving an average payment size of around \$45,000— though if one considers the structure of the payments system, it's evident that there's a very wide distribution of payments sizes, so this average isn't particularly representative.</p>
","9184"
"Derive the average variable cost (AVC) function and show that, when AVC is a minimum, marginal cost (MC) is equal to AVC","8371","","<p>I have lost all notes for this and can't seem to work it out, although i'm sure it is very simple I apologise in advance!</p>

<p>A manufacturer has the following short-run total cost function:</p>

<p>$$TC = 100 + 25Q – 5Q^2 + Q^3$$</p>

<p>Derive the average variable cost (AVC) function and show that, when AVC is a minimum, marginal cost (MC) is equal to AVC. </p>
","<p>Hoping I don't confuse you any further.</p>

<p>Variable cost is the cost that depends on how much you produce (hence, variable). So in your case that would be:<br>
$\text{VC}:25Q-5Q^2+Q^3$</p>

<p>Now the average cost is the cost divided by how much is produced. The average variable cost then is:<br>
$\text{AVC} = \frac{\text{VC}}{Q} =25 - 5Q + Q^2$</p>

<p>Now you want the minimum of the average cost. You find the minimum by deriving:
$\frac{\partial \text{AVC}}{\partial Q} = 0;  - 5 + 2Q = 0$<br>
So you have that the minimum is at $Q=2.50$. Hurray. The AVC at the minimum is:<br>
$\text{AVC}(2.5) = 25-5*(2.5) + (2.5)^2$, that is <strong>18.75</strong>.</p>

<p>Now you also want the marginal cost, which is just:<br>
$\text{MC}:\frac{\partial \text{TC}}{\partial Q} = 25 - 10Q + 3 Q^2$<br>
$\text{MC}(2.5)=25-10*(2.5)+3*(2.5)^2$. And look at that we get back <strong>18.75</strong>.</p>

<p>So apparently they are the same. Who would have thought.</p>
","406"
"If I gain, then someone else loses. Correct?","8360","","<p>On a very small scale, it's certainly true that if I gain, somebody else might lose. If I take away my brother's chocolate, then he will lose it, and will most probably not get anything comparable.</p>

<p>But on greater scale, say, nationally, if one person (e.g. successful start-up founder) makes a fortune, will this generally be bad for the other players? Or can it be beneficial (e.g. if the money is not saved up)? Does it entirely depend on the rich person's spending behavior?</p>
","<p>I completely agree with denesp's answer, however I think you can make it even simpler.</p>

<blockquote>
  <p>On a very small scale, it's certainly true that if I gain, somebody
  else might lose. If I take away my brother's chocolate, then he will
  lose it, and will most probably not get anything comparable.</p>
</blockquote>

<p>OK, let's say I prefer chocolate to wine gums and my brother likes wine gums better than chocolate. Then taking his chocolate away and giving him my wine gums is good for both of us, so we both win and no one loses. <strong>So the answer is no.</strong></p>

<p>You could even consider the extreme case in which your brother hates chocolate and you are doing him a favor by taking it. (Works not as well with chocolate, but you might think of recycling.)</p>

<p>In general these ""trades"" are called <a href=""http://en.wikipedia.org/wiki/Pareto_efficiency"">Pareto improvements</a>.</p>

<p>But this is only one example, if you are interested in the subject, you might be interested in one of the following basic economic ideas:</p>

<ul>
<li><p>Trade between two countries in which one of them is more efficient than the other: <a href=""http://en.wikipedia.org/wiki/Comparative_advantage#Ricardo.27s_example"">Ricardo's comparative advantage example</a></p></li>
<li><p>Your brother likes to give: <a href=""http://en.wikipedia.org/wiki/Warm-glow_giving"">altruism / warm glow</a> <em>(I really don't like the wiki page here, but was not able to find a decent non-scientific explanation of it.)</em></p></li>
<li><p>Or maybe other other-regarding preferences, for example fairness (your brother has a lot of chocolate and feels better if he gives you some): <a href=""http://web.mit.edu/14.193/www/WorldCongress-IEW-Version6Oct03.pdf"">Theories of Fairness and Reciprocity</a> <em>(On page 3 is a brief ""Non-technical summary"" which might be interesting.)</em></p></li>
</ul>

<p>As you can see there are many examples for a ""win-win"" situation and there are many many others, depending on the situation.</p>
","5915"
"Calculating rate of growth of per capita income","8169","","<p>Given this question:</p>

<p>National income is increasing by 1.5% a year and population by 2.5% a year. What is the rate of growth of per capita income?</p>

<p>Attempt: </p>

<p>Since per capita income is GDP/ population. I divided 1.5 by 2.5 and got 0.6. Is this right?
Thanks.</p>
","<p><strong>Consider:</strong> If national income is increasing at a slower rate than population growth, then intuitively per capita income will be falling. Here is a set-up for the rate of decline in per capital income.</p>

<p>$$\text{per capita income}_t = \frac{\text{GDP}(1.015)^t}{\text{population}(1.025)^t} \text{per capita income}_{t-1}$$</p>
","9088"
"Lexicographic preference relation cannot be represented by a utility function","8071","","<p>I am stuck on the following exercise, related to preference relations and <a href=""https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem"">von-Neumann-Morgenstern utility function</a>.</p>

<blockquote>
  <p>A farmer wants to dig a well in a square field $[0,1000]\times[0,1000]$. The preferences of the farmer on the possible locations are lexicographic, i.e:</p>
  
  <ul>
  <li>If $x_1&lt;x_2$ then $(x_1,y_1)\prec(x_2,y_2)$ for all $y_1,y_2$.</li>
  <li>If $x_1=x_2=x$, then $(x,y_1)\prec(x,y_2)$ iff $y_1 &lt; y_2$.</li>
  </ul>
  
  <p>Initially, assume that the well location must have integer coordinates. 
  Is there a preference relation on lotteries, that satisfies the von-Neumann-Morgenstern axioms, and extends the lexicographic preference relation? If so, what is a linear utility function that represents this relation?</p>
</blockquote>

<p>I think the answer is yes, and a possible linear utility function is: $u(x,y)=100000x + y$.</p>

<blockquote>
  <p>Now, assume that the well location can have real coordinates. Prove that there is no linear utility function that represents the preference relation on lotteries.
  Which one of von-Neumann-Morgenstern axioms is violated by the preference relation on lotteries?</p>
</blockquote>

<p>Here I am stuck. I don't understand why the utility function I suggested above doesn't work? And what axiom is violated here?</p>
","<p>We can say more generally that lexical preferences are not representable using a continuous utility function. Lexical preferences are not continuous. Note the definition of a continuous preference relation.</p>

<p>The preference relation $\succeq$ is continuous if for any sequences of consumption bundles $(x_{i})_{i \in \mathbb{N}}$ and $(y_{i})_{i \in \mathbb{N}}$ with $x_{i} \to x$, $y_{i} \to y$, and $x_{i} \succeq y_{i}$ for each $i \in \mathbb{N}$, then $x \succeq y$. That is, continuity preserves the relation at the limit point.</p>

<p>Consider $(x_{i})_{i \in \mathbb{N}}$ defined by $x_{i} = (\frac{1}{2^{i}}, 0)$ and $(y_{i})_{i \in \mathbb{N}}$ defined by $y_{i} = (0, 1)$. Clearly, $x_{i} \succeq y_{i}$ for each $i \in \mathbb{N}$. However, $x_{i} \to (0, 0)$ while $y_{i} \to (0, 1)$. So this preference relation is not preserved at the limit point.</p>

<p>Even more generally, no utility function represents the lexical preference relation. I prove for $\mathbb{R}_{+}^{2}$, but this argument extends to $\mathbb{R}_{+}^{n}$ by projecting into $\mathbb{R}_{+}^{2}$. </p>

<p><strong>Proof</strong>: Suppose to the contrary that some utility function $u : \mathbb{R}_{+}^{2} \to \mathbb{R}$ represents $\succ_{lex}$. We thus have $u(x, 1) &gt; u(x, 0)$, as $(x, 1) \succ (x, 0)$. We construct the interval $I(x) = [u(x, 0), u(x, 1)]$. Now for any two distinct $x, y \in \mathbb{R}_{+}$, $I(x) \cap I(y) = \emptyset$ as we have either $x &gt; y$ or $y &gt; x$ (so WLOG, we have $(x, 0) \succ (y, 1)$). </p>

<p>Define $\mathbb{I} = \{ I(x) : x \in \mathbb{R}_{+} \}$, and let $\phi : \mathbb{R}_{+} \to \mathbb{I}$ be given by $\phi(x) = I(x)$. Observe that $\phi$ is an injection, as each $I(x), I(y)$ are disjoint for distinct $x, y$.</p>

<p>Note that $\mathbb{Q}$ is dense in $\mathbb{R}$. So there exists a rational number in each interval. Define $\tau : \mathbb{I} \to \mathbb{Q}$ such that $\tau(I(x))$ returns a rational number contained in $I(x)$. So $\tau$ is an injection. We have $\tau$ composed with $\phi$ an injection, which implies $|\mathbb{R}_{+}| \leq |\mathbb{Q}_{+}|$, a contradiction. QED.</p>
","6892"
"Why do celebrities get high wages?","8048","","<p>In the youtube video <a href=""https://www.youtube.com/watch?v=3cfDGX7gB5M"">Why We Look down on Low Wage Earners</a> the author argued: ""economics states that wages are determined [...] by the number of people willing and being able to do a given job that others won't do."" (<a href=""https://www.youtube.com/watch?v=3cfDGX7gB5M&amp;feature=youtu.be&amp;t=1m1s"">video at 1:00</a>). While this explains much of the variance in the wages of different jobs, it does not give in my opinion a good explanation, why celebrities earn high wages.</p>

<p>Take for example actors. There are a lot of people working in this field and there are many more wanting to become an actor or actress. Due to the quoted theory the wages in this field should be low which is not the case <a href=""http://www.mywage.org/zimbabwe/main/salary/vip-celebrities-pay/celebrity-actors-pay"">for celebrities</a>. The theory does also not explain the variance of the wages inside this field (compare the <a href=""http://www.payscale.com/research/US/All_Actors_%2f_Actresses/Hourly_Rate"">median hourly earning of actors / actresses</a> with those of celebrities).</p>

<p>My question: How do economics explains the outliers in the wages in form of the high earnings of celebrities? How does popularity exert an influence here? (Do celebrities get much money because they are popular or are they popular because they are rich?) How does economics explains the different wages for a certain kind of job?</p>
","<p>If you ask yourself how much a potential employer would have to pay you to convince you to work for him, the answer is probably something like ""at least as much as I could earn by doing the same job for another employer"". So, provided there are several employers competing to hire workers, you can think of employers as bidding against each other for the best employees. But how much will firms bid? Each employer would be willing to pay up to the difference between its profit if it hired this particular worker and its profit if it took the next best alternative. </p>

<p>This is why the supply of alternative employees matters. If there are many people capable of doing the same job then a firm's profit if it hires you will be almost the same as the profit if it hire someone else. So why should it 'bid' a lot to hire you? An unskilled factory worker who asks his employer for a significant pay rise will likely be refused because virtually any worker doing the same job would have equivalent productivity.</p>

<p>Celebrities are a different story. Just as factory workers are hired to produce goods for the factory owner, actors are hired to produce movie ticket sales for the studio. But viewed in this light, Tom Hanks or Angelina Jolie are not close substitutes for as yet unknown actors at all. Indeed well-known actors <a href=""http://hbswk.hbs.edu/item/the-box-office-power-of-stars"">are considerably better at producing ticket sales than unknown talent</a>. Studios are willing to bid a lot to attract top actors because having a star in your cast is worth millions of dollars in extra ticket sales.</p>
","10745"
"Help understanding Lagrangian multipliers?","7846","","<p>I am trying to understand Lagrangian multipliers and using an example problem I found online. </p>

<p><strong>Problem Set Up:</strong></p>

<p>Consider a consumer with utility function $u(x,y) = x^{\alpha} y^{1-\alpha}$, where $\alpha \in (0,1)$. Suppose this consumer has wealth $w$ and the prices $p =(p_x,p_y)$. That's all we were given.</p>

<p><strong>Work I Did:</strong></p>

<p>I then defined a budget constraint equation: $w = xp_x + yp_y$. I also then defined an associated Lagrangian for the consumer's maximization problem: 
$\Lambda(x,y,\lambda) = x^{\alpha} y^{1-\alpha} + \lambda ((xp_x+yp_y)-w)$. </p>

<p><strong>My question:</strong></p>

<p>What does this equation allow me to do? Although I set it up given the formula on Wikipedia's page on Lagrangian multipliers, I really have no idea what the purpose of this equation is. Like I don't understand how the equation as given allows me to determine how to maximize my utility function. </p>

<p>Note: I am familiar with multivariable calculus and Lagrangians ($L = T -V$) in physics, but this method is new to me. </p>
","<p>A constrained optimization function maximizes or minimizes an objective subject to one or more constraints. As I understand it, the Lagrangian multiplier approach transforms a constrained optimization problem (I) into an unconstrained optimization problem (II) where the optimal control values to problem II are also the optimal control values to problem I. Additionally, the the objective functions in problems I and II take the same optimal values. The trick is a clever way of putting the constraints into the objective function directly rather than using them separately. </p>

<p>I agree with your presentation of the consumer's maximization problem: 
$\Lambda(x,y,\lambda) = x^{\alpha} y^{1-\alpha} + \lambda ((xp_x+yp_y)-w)$. </p>

<p>Now we take the partial derivatives with respect to x an y, set them equal to zero, and then solve for x* and y*.</p>

<p>$0=\partial\Lambda / \partial x  = \alpha x^{\alpha -1 } y^{1-\alpha} + \lambda p_x = (\alpha / x ) x^{\alpha  } y^{1-\alpha} + \lambda p_x$ </p>

<p>$\Rightarrow -\lambda = (\alpha / (x p_x)) x^{\alpha  } y^{1-\alpha}$ </p>

<p>$0 =\partial\Lambda / \partial y  = (1 - \alpha) x^{\alpha} y^{-\alpha} + \lambda p_y = ((1 - \alpha) / y ) x^{\alpha  } y^{1-\alpha} + \lambda p_y$ </p>

<p>$\Rightarrow -\lambda = ((1- \alpha) / (y p_y)) x^{\alpha  } y^{1-\alpha}$</p>

<p>$\Rightarrow (\alpha / (x p_x)) x^{\alpha  } y^{1-\alpha} = -\lambda = ((1- \alpha) / (y p_y)) x^{\alpha  } y^{1-\alpha}$</p>

<p>$\Rightarrow (\alpha / (x p_x)) = ((1- \alpha) / (y p_y))$</p>

<p>$\Rightarrow ( y p_y ) / (1- \alpha) = (x p_x) / \alpha$ (eqn 1)</p>

<p>Recover the budget constraint equation by taking the partial derivative $\partial\Lambda / \partial \lambda = 0$.</p>

<p>$0 = \partial\Lambda / \partial \lambda = xp_x + yp_y - w \Rightarrow xp_x /  w + yp_y /w = 1$ (eqn 2)</p>

<p>We now have two equations and two unknowns (x,y) and can solve for x* and y*.</p>

<p>$\Rightarrow yp_y / w  = xp_x/w \cdot (1 / \alpha - 1) = xp_x/w / \alpha - xp_x/w$</p>

<p>$\Rightarrow 1 = yp_y / w + xp_x/w = xp_x/w / \alpha$</p>

<p>$\rightarrow \alpha = xp_x/w$ (result 1)</p>

<p>$\Rightarrow \alpha = xp_x/w = 1 - yp_y /w$</p>

<p>$\rightarrow 1-\alpha =yp_y/w$ (result 2) </p>

<p>Results 1 and 2 form the famous constant expenditure shares result for the Cobb-Douglas utility and production functions. Which can also be explicitly solved for x* and y*: $x^* = \alpha w /p_x$ and $y^* = (1-\alpha) w /p_y$ which are the optimal values for both the Lagrangian and the original problems. </p>
","2961"
"What do supply-demand curves really look like?","7441","","<p>In my basic high school economics course, we've always used supply-demand curves that are lines to simplify calculations. In real markets for real goods, what do the supply and demand curves look like? From a mathematical perspective, what would be the concavity, asymptotes, and intercepts?</p>

<p>I would imagine the quantity demanded would tend to zero as the price increased to infinity and the quantity demanded would grow very large as the price approached zero, but that is just what my intuition tells me.</p>
","<p>You sometimes find textbooks drawing the supply and demand curves as concave upwards, as such:</p>

<p><img src=""https://i.stack.imgur.com/UBUfx.jpg"" alt=""concave-upwards supply and demand curves""></p>

<p>The straight-line supply and demand curves can be thought of as a magnification of this graph, where the two intersect. Thus, the units on the axes would give you a clue as to how high up the graph is being drawn, or how far to the right (if the units start at a number other than 0 or skip an interval). This shows you why they are indeed called 'curves', even when they are sometimes straight lines.</p>

<p>Supply and demand curves are drawn using straight lines for simplicity. For example, two straight-line equations may be given, from which it is relatively simple to calculate the point of intersection.</p>

<h2>In the real world</h2>

<p>Supply and demand curves are an approximation of what happens in real life. The curves are a simplified model which show the general trend in the two functions. In reality, supply and demand curves are approximated using data that is collected over many years, with many short-term variables affecting the results, if the curves are even drawn up at all (the curves are more a theoretical model than a calculative method). </p>

<h2>Economic factors which affect supply and demand</h2>

<ul>
<li><strong>Price elasticity</strong> at different points of output affect the gradient of the curve at those points. A higher price elasticity results in a shallower gradient and vice versa. A unit price elasticity at all points on a demand curve will result in a hyperbola. In that case, the asymptotes of the demand curve are the x and y axis. FYI, the asymptotes of a demand curve will always be the x and y axis if the graph is drawn using this definition of price elasticities, but different elasticities will change the compression or expansion of the graph either vertically or horizontally so that it becomes not a hyperbola, but a hyperbolic graph.</li>
<li>The supply curve for a firm (with any level of competition in the market) is the <strong>marginal cost</strong> curve faced by that firm. The marginal cost curve looks like this:</li>
</ul>

<p><img src=""https://i.stack.imgur.com/5Vd9i.jpg"" alt=""marginal cost curve""></p>

<p>However, due to the firm's variable costs, output is always greater than that at the turning point of the marginal cost curve.</p>

<ul>
<li>For interest, in the special case of an <strong>oligopoly</strong>, there exists a kinked demand curve faced by an individual firm, as shown:</li>
</ul>

<p><img src=""https://i.stack.imgur.com/aFZkE.png"" alt=""kinked demand curve""></p>
","5734"
"What is the difference between present value and face value?","7165","","<p>What is the difference between present value and face value? 
When I search this question on Google is says they're the same in some cases and different in others. It says they are the same when the market interest rate is the same as the contractual interest rate. </p>

<p>I need help understanding what this means. I do not understand the difference between these  types of interest rates, etc. 
And also does this have anything to do with discounting vs. coupon bonds, etc?</p>
","<p>Suppose the <em>face value</em> of a bond is $M$ and its <em>interest rate</em> is $\tau$. This means it will pay $\tau \cdot M$ interest every year (other periods are also possible) and at the end of its run (its maturity) it will also repay the face value $M$. Government bonds are usually sold in auctions. Whatever ends up being the market price is considered to be the <em>present value</em> of the bond. Using the cash flow you can also calculate the <em>yield</em> of the bond. If and only if the face value and the present value are equal the yield will be equal to the interest rate.</p>

<p>For an example see the US treasury's <a href=""http://www.treasurydirect.gov/instit/annceresult/annceresult.htm"" rel=""nofollow"">website</a>. Click on bonds to see face value, interest rate and maturity, click on the bond serial to see its price (present value).</p>

<p>Further reading <a href=""http://accountingexplained.com/financial/lt-liabilities/bond-price"" rel=""nofollow"">here</a>. (Link copied from a comment by @Jamzy .)</p>
","6619"
"Price elasticity of demand in the point of economic equilibrium","7046","","<p>The function of demand is:\begin{align*} D(p) = 66-3p-p^2 \\\end{align*}
The function of supply is: \begin{align*}S(p) = 4p^2+8p-114\\
\end{align*}
The task is to find price elasticity of demand in the point of economic equilibrium.</p>

<p>I have found out that the equilibrium price is 5 and equilibrium demand is 26.</p>

<p>I also have a formula that states that $E = k * P/Q$
, where $P$ - equilibrium price, $Q$ - equilibrium demand and $k$ - coefficient  of $S(p)$ slope</p>

<p>How to find $k$ or are there another methods to solve this task?</p>
","<p>Your formula is overly simplified.</p>

<p>The elasticity is supposed to be ""<em>how much does supply change if the price changes</em>"". Now, the natural way of looking at this is $S'(p)$, the derivative of $S$. However, the units of that are hard to make use of. Hence, we normalize $S'(p)$ by multiplying it with $P/S(p)$, hence getting the ""<em>percentage response of $S$ to a percent change in $P$</em>"".</p>

<p>Long story short, your $k$ should satisfy </p>

<p>$$ k = S'(p)$$</p>

<p>Note that this is the price elasticity of supply. For the price elasticity of demand, you would instead use $D'(p) P / D(p)$.</p>
","5973"
"Correlation between CPI and GDP","6913","","<p>What is the relationship between GDP and CPI(consumer price index)? My thinking is that if the CPI increases, this means that the market basket cost has increased, therefore, the consumer spending has increased. If the consumer spending increases, then GDP increases. However, depending on the consumer preferences, CPI can either underestimate or overestimate the cost of living. So from here, I cannot draw consequences about how CPI affects GDP or vice versa. Can someone please explain this? Is my thinking correct? Can there be any additions to these?</p>

<p>Any help would be appreciated!</p>

<p>Thanks in advance!</p>
","<p><a href=""http://econsmalaysia.blogspot.my/2013/05/gdp-deflator-inflation-consumer.html"" rel=""nofollow noreferrer"">http://econsmalaysia.blogspot.my/2013/05/gdp-deflator-inflation-consumer.html</a>. Here read this. Its almost a non-related type of measurement</p>

<p>From the article:</p>

<blockquote>
  <p>The differences in calculation are quite substantial and meaningful – they’re not looking at the same thing. In fact, calculating the GDP deflator is fairly convoluted as these things go – first tabulate all goods and services in current prices, then measure the same goods and services in prices prevailing in the base year, then calculate the ratio of current price production to constant price production. This ratio (multiplied by 100) is the GDP Deflator index, from which growth rates (inflation) can be calculated.</p>
  
  <p>The CPI on the other hand, is based on changes in prices only, as the volume of goods consumed by a “representative” (average) household is taken to be fixed. The index is just a weighted average of the changes in prices across the same basket of goods.</p>
</blockquote>

<p>As an example, below are the GDP deflator and CPI for Malaysia, which show weak correlation</p>

<p><a href=""https://i.stack.imgur.com/WKNse.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WKNse.png"" alt=""enter image description here""></a></p>

<p>The key thing to understand is that while both can be affected by broad macro policy (like loose money), they do not neccessarily always drive each other, as the GDP deflator could be driven by a surge in export commodity pricing that is largely captured by foreign firms with little corresponding increase in pay to local workers and consequently little increase in CPI.</p>

<p>The relationship would have to be examined in terms of a single economy because the weight of outside factors confounds the relationship between the CPI and GDP</p>
","9633"
"How does Black Friday work?","6659","","<p>On days like Black Friday, everyone rushes out expecting huge savings on everything they buy. The level of demand seems to reach ludicrous levels, and one would expect smart merchants to react by increasing all of their prices in response to demand.</p>

<p>Yet year after year we see videos of people beating each other up and trampling each other on Black Friday in a display of seemingly mindless consumerism. </p>

<p>Is Black Friday really just a marketing ploy that creates the illusion of savings where really none exist? Has the market just not caught up with consumer behavior? Or is there another mechanism driving Black Friday?</p>
","<p>Though the Black Friday savings do exist, they are less significant than in some of the early years when the ""Black Friday"" sales were just starting to get really popular.  Raising prices is one way that merchants could try to respond, but then they might exclude the deal-seekers whom they are targeting.</p>

<p>Instead, merchants have been doing other things.  This includes selling lower quality merchandise, including a lot of Refurbished equipment.  (I'm mainly thinking of websites selling computer equipment.  A lot of deals this year was refurbished stuff.)  This year, I read (somewhere) that manufacturers have been making specific models of some stuff, which is designed to be cheaper, in anticipation that these models will become Black Friday sales and sell out.</p>

<p>Stores can benefit from increased traffic, including selling add-ons (like overpriced USB cables needed to make wired printers work), and having lots of staff members but still having a high customer-to-staff ratio just due to the sheer large number of customers.  They may be able to gain some efficiency because they can successfully predict a higher amount of foot traffic compared to normal days.</p>

<p>In a nutshell: Raising prices is one way to respond to increased demand, but that would seem to go against the spirit of things, and places don't want the resulting bad rep.  So, instead, they are using every other trick in the book that they can come up with.  The major merchants are definitely aware of Black Friday, and they do manage to make it a very profitable day.</p>
","9544"
"Can A Utility Function Take On Negative Values?","6590","","<p>Can someone provide a rigorous definition of a utility function? I had thought that a utility function only needs to the preserve the order of preferences. Thus a utility function can take on negative values as long as it preserves the order of preferences. Others have told me that a utility function cannot take on negative values. Is this a condition of a rigorous definition of a utility function?</p>
","<p>A utility function can certainly be negative. The utility function is <em>nothing more than a way to represent a preference relationship.</em> This is an important conceptual point. In several theorems that typically show up in introductory texts, we show that sets of preferences that satisfy certain regularity conditions can be represented as utility function.</p>

<p>Also, there are different decision theory frameworks that allow the utility function to be transformed. You alluded to something like this in your question. In the traditional framework without uncertainty, the utility function is defined up to a monotonic transformation. Under certain kinds of uncertainty, we get Von Neumann–Morgenstern utility functions that are unique up to affine transformations. You can read more about this elsewhere. For now, the consider the following definition of a utility function. It is taken from <em>Advanced Microeconomic Theory</em> by Jehle and Reny (3rd edition):</p>

<p><img src=""https://i.stack.imgur.com/bbGb5.png"" alt=""Definition of a utility function""></p>

<p>A preference relation $\succeq$ is defined as follows:</p>

<p><img src=""https://i.stack.imgur.com/zRToV.png"" alt=""enter image description here""></p>

<p>where the axioms references are these:</p>

<p><strong>Axiom 1:</strong> <em>Completeness.</em> For all $x^1$ and $x^2$ in $X$, either $x^1 \succeq x^2$ or $x^2 \succeq x^1$.</p>

<p><strong>Axiom 2:</strong> <em>Transitivity.</em> For any three elements $x^1$, $x^2$, and $x^3$ in $X$, if $x^1 \succeq x^2$ and $x^2 \succeq x^3$, then $x^1 \succeq x^3$.</p>
","4733"
"Should I stay or should I quit?","6550","","<p>Is there an <strong><em>economic theory of quitting</em></strong> an activity? A theory that weighs the investment costs put into something and the opportunity costs of pursuing it. </p>

<p>I am aware of <a href=""http://rady.ucsd.edu/docs/faculty/GneezyTradeOff.pdf"" rel=""nofollow noreferrer"">Fershtman and Gneezy Quitting in Tournaments</a> paper that investigates the decision of quitting in the middle of a race or of a tournament. But, I am looking for a more general model of quitting something such as playing an instrument, a sport or even a job. Dropping-out from (grad)-school may obey the same investment-opportunity cost trade-off.</p>

<p>Update: I am looking for some explicit references modeling the exiting or quitting process, even if it concerns some decisions in particular without any generalization.</p>

<p>Edit: <a href=""https://economics.meta.stackexchange.com/questions/1762/should-we-explain-accepted-answers"">Here is why I picked @Ubiquitous' answer</a>.</p>
","<p>A relevant literature seems to be that on <em>optimal stopping problems</em>. There is a fairly technical Wikipedia article <a href=""https://en.wikipedia.org/wiki/Optimal_stopping"" rel=""noreferrer"">here</a> and <a href=""https://www.math.ucla.edu/~tom/Stopping/sr1.pdf"" rel=""noreferrer"">here's a book chapter</a>.  </p>

<p>In economics, such models have been used to think about <a href=""http://www.sciencedirect.com/science/article/pii/S0022053111000329"" rel=""noreferrer"">how sellers learn about selling opportunities</a>, <a href=""https://www.jstor.org/stable/1556717"" rel=""noreferrer"">investment in R&amp;D</a>, and <a href=""https://www.jstor.org/stable/2297410"" rel=""noreferrer"">optimal labor search strategies</a>.</p>
","18244"
"Why are imports subtracted from GDP?","6515","","<p>GDP is a measure of a country's <strong>production</strong>.</p>

<p>$$GDP = C + I + G + X_n$$</p>

<p>$C$ = Consumer Consumption<br>
$I$ = Gross Investment<br>
$G$ = Government Expenditures<br>
$X_n$ = Exports - Imports</p>

<p>Exports are what we produce and make a profit from by selling to buyers outside our country.  Imports are not produced by our country, so it shouldn't be included in the GDP, so it makes sense to <strong>exclude</strong> it from the calculation; ie. there should be no ""- imports"" in the calculation.</p>

<p>However, the calculation <strong>subtracts</strong> imports from the GDP.  Imports somehow take away from what we produced?  That seems to say, calculate how much I have produced, X, and then don't count some of it because I imported Y.  Which doesn't make sense given that importing doesn't remove goods and services that have already been produced!</p>

<p>For example, let's say I can take apples and make pies... I produced value in the form of the ""pie"" quality.  Importing the ""pie"" quality and tacking it on an apple creates an apple pie.  However, I didn't make that ""pie"" so I can understand how it doesn't get included in the GDP: the value of the ""pie"" quality was not produced in this country, so it isn't included in the GDP.  </p>

<p>Let's also say my GDP = ""made a cat meow"" + ""turned a tree into a fountain"".  Somehow, by importing the ""pie"" quality, I am to ignore some of the value of making a cat meow?</p>
","<p>When we import something, we consume it. So when calculating consumption we are bound to count import as a positive component of GDP. Since it is not (we did not produce imports domestically), we subtract it to make it neutral.</p>
","9563"
"Why is fuel more expensive on the high way in Europe?","6274","","<p>In Europe it's usual, that fuel prices are 10-20% higher on the highway, than in the city. This is not only my personal observation, but also mentioned on travel sites (eg <a href=""http://www.dutchtravels.net/travel/cheaper-car-fuel.htm"">here</a> and <a href=""http://about-france.com/driving.htm"">here</a>). I don't have much expertise in economics, but as I understand this should not be possible in a competitive market, since what would stop a petrol station to lower their prices to the same level as the ones in the city, and get all the customers?</p>

<p>One solution could be, that they are different companies, but even the big ones like Shell and OMV have higher prices on the highway.</p>

<p>My question is: what is the reason for this situation, and what stops petrol stations from lowering their prices?</p>
","<p>Because there is no indication in your question that you are a student or practitioner of economics, I am writing an answer for a lay audience. Let me know if you would like more technical detail.</p>

<hr>

<p>A fairly general prediction from economic models of competition between firms is that the price that maximises their profit is higher the less sensitive is demand to that price (this sensitivity is measured by the ""<a href=""https://en.wikipedia.org/wiki/Price_elasticity_of_demand"">price-elasticity of demand</a>""). Intuitively:</p>

<ul>
<li>if demand is very sensitive to price then a cut in price will cause demand to increase a lot. The firm receives less for each unit it sells, but sells very many more units and is better-off overall.</li>
<li>if demand is not sensitive to price then the firm can increase price without causing its sales to fall very much and will therefore wish to do so.</li>
</ul>

<p>There are lots of things that affect the sensitivity of demand. One example, as DornerA mentioned in a comment, is geographic location. If the nearest competing seller is very far away or inconveniently located then buyers will be reluctant to shop elsewhere, meaning their demand is likely to be less sensitive to price increases at locations that are geographically isolated in some way. This seems like a reasonable way to think of highway fuel stations.</p>

<hr>

<p>A little thought should convince you that the same principle (that prices are higher when demand is less sensitive) holds for other cases where demand is price-insensitive too. For example:</p>

<ul>
<li>why is food so expensive on trains/airplanes?</li>
<li>why are branded goods more expensive than generic ones?</li>
<li>why are the photographs from theme park rides so expensive?</li>
<li>etc.</li>
</ul>

<hr>

<p>Edit: A comment by AndrejaKo reminds me to add that the other very common reason why firms might increase their price is that they have higher costs. However, economics theory predicts that only unit costs (i.e. those that increase when you sell more units) matter for optimal pricing. Thus, for example, the fact that land near a highway is expensive would not seem like a very convincing explanation for high fuel prices (because the land costs the same regardless of how many units of fuel are supplied). But if, for some reason, supplying each litre of fuel was more expensive at highway fuel stations (because, for example, transporting the fuel there is more expensive) then we would indeed have an explanation for higher highway fuel prices.</p>
","12642"
"How does a cash deposit change the M1 measure of the money supply?","6047","","<p>The question asks what is the immediate effect of the cash deposit on the M1 measure of money supply. The official answer is ""There is no change in the M1 measure of the money supply. (Demand deposits increase by the same amount that cash holdings fall.)."" However, I think the some of the money deposited into the bank will be lend out and deposit into other banks and so on. So the multiplier also applies here, so the money supply should increase by the multiplier times the cash deposited minus the cash deposited(minus because cash holding has decreased). Why is that not true?</p>

<p>Please suggests if anything is not clear.</p>

<p>My guess: maybe it is because the question asks ""immediate"" effect and hence does not include the process of money being lend out again etc.?</p>
","<p>It's best to always check the exact definitions for M questions, because they can vary a little between countries.  I'll use the US Federal Reserve's here, viz. ""M1 is defined as the sum of currency held by the public and transaction deposits at depository institutions (which are financial institutions that obtain their funds mainly through deposits from the public, such as commercial banks, savings and loan associations, savings banks, and credit unions).""</p>

<p>The reason M1 doesn't increase is essentially semantic. Before the deposit occurs, M1 is the sum of currency held outside the banking system (""held by the public"") and deposits at banks etc. Notice that currency held by the banks is not included in the M1 definition.</p>

<p>When the deposit occurs, the accompanying double entry book keeping is [debit cash, credit customer deposit]. Now the cash is held by the bank, so not included in M1, but the customer deposit that was created by the cash deposit is - so there's no change. This is the best way to handle this btw., since once the cash is deposited at a bank, it's no longer playing an active role in the money supply.</p>

<p>As far as the potential impact on the reserve requirement, and multiplier effect. As you're quite rightly suggesting, the question is trying to avoid that by saying ""immediate"". However, if you're in the USA, reserves no longer control the money supply the way the text book tries to describe, so there would not be expected to be a long term impact either. (reserve requirements only cover a fraction of bank deposits, and capital requirements actually dominate in terms of regulatory impact.)</p>
","5375"
"Deriving the Euler Equation","6015","","<p>I want to derive the Euler Equation for the following: </p>

<p>$$max \sum\limits_{t=0}^{T} = \beta^{t}U(C_t)$$</p>

<p>$$s.t. C_t+K_{t+1} \leq f(K_t) , t=0,1,2,...,T-1$$ 
$$-K_{T+1} \leq 0$$</p>

<p>I'm a bit confused about why the F.O.C. have that: </p>

<p>$$\frac{d\mathcal{L}}{dK_{t+1}}=-\lambda_t+\lambda_{t+1}f'(k_{t+1})$$</p>

<p>and how we combine the F.O.C to yield the Euler equation: </p>

<p>$$U'(C_t)= \beta U'(C_{t+1})f'(k_{t+1})$$ </p>

<p>I assume the F.O.C w.r.t. $K_{t+1}$ is such because of the inclusion of the intensive form of the production function but I am not exactly sure how and I really want to understand this completely.  I also need to make sure I understand how we are using the FOC to produce the Euler Equation. 
Can anyone provide a bit of clarity? </p>
","<p>The question is quite straightforward, and you do not need the first
step that you have. You have (for some reason) a different multiplier
here for each time period. That is not the case- you simply have a
no-ponzi scheme condition, aka a transversality constraint. The problem
is expressed as$max\,\sum\beta^{t}U(c_{t})$ st $c_{t}+k_{t+1}\leq f(k_{t})$.
The stream of utility to the agent is $U=\sum\beta^{t}U(Cc_{t})=U(c_{0})+....\beta^{t}U(c_{t})+\beta^{t+1}U(c_{t+1})+...+\beta^{T}U(c_{T}).$</p>

<p>Substitute in $f(k_{t+1})-k_{t}$ for $c_{t}$. Then, we derive wrt
$k_{t+1}$ and set equal to 0 :$\frac{\partial U}{\partial k_{t+1}}=\beta^{t}U'(c_{t})-\beta^{t+1}U'(c_{t+1})f'(k_{t+1})=0\Rightarrow U'(c_{t})=\beta U'(c_{t+1})f'(k_{t+1}).$</p>

<p>You do not need the other equation you referred to.</p>
","7138"
"Differences between Hicksian and Slutskian approaches","5983","","<p>When deriving the substitution effect for both Slutskian and Hicksian definitions, a 'phantom' budget line is drawn.However, for a Slutskian definition, the 'phantom' budget line is drawn parallel to the new budget line(change in price) and <strong>through</strong> the point of tangency for the original budget line and indifference curve.</p>

<p>On the other hand, for a Hicksian definition, the phantom budget line is drawn parallel to the new budget line(change in price) and lies on the original indifference curve on a different point of tangency.</p>

<p>Is there any significance to this inherent difference between the Slutskian and Hicksian approaches when deriving the substitution effect?I'm familiar with the definition of the Slutskian and Hicksian approaches but am unable to reconcile the definitions of the approaches with the differences in drawing the phantom budget line, and subsequently deriving the substitution effect.</p>

<p>Any clarifications or attempts to enlighten me would be much appreciated.</p>

<p>Thanks!</p>
","<p>The income effect (IE) is about assessing purchasing-power impacts of a price change, while the substitution effect (SE) is about the impact of that price change on the relative attractiveness of the different goods. In reality these effects are not observable - when a price changes, your consumption choices will change for both reasons. But we can conceptually decompose the overall effect into IE/SE. In the SE we will be looking to isolate the impact of relative prices changing, without the purchasing-power effect.</p>

<p>Now, there are two ways of thinking about this:</p>

<p>-<strong>Slutsky</strong>: what if price changes but my purchasing power were (literally) to remain constant (i.e. I could still buy the exact same bundle as before)? How would the relative price change <em>by itself</em> affect my decision?</p>

<p>-<strong>Hicks</strong>: what if the price changes but my purchasing power were adjusted so I am still able to achieve my initial level of utility (i.e. I would be as well-off as before)? How would the relative price change <em>by itself</em> affect my decision?</p>

<p>Either way, the SE is always negative, that is, a higher price for one good will tend to make consumption of that good lower.</p>

<p>After you understand the SE, the IE is just the income adjustment needed in either case to get us to the <em>actual</em> final decision. It can reinforce the SE or contradict it, depending on whether the good is normal or inferior.</p>

<p>Hope this helps.</p>
","8574"
"Difference between 'surplus' and 'welfare'","5968","","<p>I see these two terms used interchangeably but I have the feeling they are not exactly the same. My gut feeling tells me this:</p>

<p>1)
Surplus is the additional aggregate utility from the existence of one market, while welfare is the additional aggregate utility from all existent markets</p>

<p>$$\implies  [ W(u_1,u_2,\dots,u_N) \ \mathrm{with} \  u_i=u(c_1,...,c_M) ] \gg [ S(u_1,u_2,...,u_N) \ \mathrm{with} \ u_i = u(c_i) ]$$</p>

<p>Change in surplus is thus an approximation of the aggregate gain in welfare, and is only equivalent under the conditions that: policy changes do mainly affect one market and consumers’ utility is assumed to be quasi-linear in the good at focus.</p>

<p>2) Or a second idea/notion, surplus is only the difference between supply and demand curve (i.e. it entails all aspects of the good that can be monetized), while welfare also includes non-monetizable aspects of a good.</p>

<p>Any thoughts on this?</p>
","<p>Surplus and welfare are different concepts, but not for the reasons you state, although there are elements of validity in both (1) and (2).  They may, however, be used interchangeably in certain contexts and where certain conditions are met.</p>

<p>Both “surplus” and “welfare” are terms from ordinary language that in economics are used in more precise senses.  ""Surplus"" has several senses in economics, and is commonly clarified by the words accompanying it: (in microeconomics) ""consumer surplus"", ""producer surplus"" and their sum ""total surplus"", (in macroeconomics) ""budget surplus (of a government)"" and (in Marxian economics) ""surplus value"".  Where it is used alone, the context will usually make clear which of these is meant: the question appears to be concerned with the microeconomic senses.</p>

<p>Consumer surplus and producer surplus are normally defined in terms of supply and demand curves in a single market.  Such curves can in principle be estimated from observations of supplier and consumer behaviour, without reference to utility.  So although consumer surplus can be related to utility via marginal utility theory, utility is not needed in its definition and, as Steven Landsburg points out, surplus should be measured in monetary units, not units of utility.  Welfare, equally, is often related to utility at a theoretical level, but in applied work is often estimated without reference to utility and measured in monetary units.</p>

<p>“Welfare” in economics is used both in macroeconomics, where there have been various attempts to identify an appropriate set of adjustments to GDP to provide a suitable measure of overall welfare in an economy, and in microeconomics, where the focus is on welfare in a single market or a few related markets.   But these are not entirely different senses of the term.  They both retain from ordinary language the essential idea that welfare is good - something policy should aim to increase - and in this respect there is an important difference, even in microeconomics, between surplus and welfare.  “Surplus” is a purely descriptive concept (a term of positive economics), whereas “welfare” is – to borrow a little from philosophy – a <a href=""http://en.wikipedia.org/wiki/Thick_concept"" rel=""nofollow"">thick concept</a>, one that is both descriptive and evaluative.  Let’s consider three situations which can help to clarify our understanding of these concepts.</p>

<p>Firstly, consider a standard supply-demand diagram for a single product, and suppose supply increases (the whole supply curve moves to the right).  Normally, we would say that both surplus and welfare have increased.  Now suppose that the product is one which is harmful to those consuming it.  Would we still say that surplus has increased?  Yes, because “surplus” is a purely descriptive term, so we can quite consistently say that surplus has increased while thinking it might have been better if this had not occurred.  Would we still say that welfare has increased?  Quite possibly not.  Points we might want to consider before drawing a conclusion are whether consumers are aware of the harm and acting rationally, and if not whether their pleasure from consumption outweighs the harm.  This distinction between surplus and welfare can be found in debate on the regulation of smoking (<a href=""http://www.gocolumbiamo.com/Health/Documents/AnnalofInternalMedicineArticleSmokingRegulation.pdf"" rel=""nofollow"">here</a> is an example).</p>

<p>Secondly, consider the <a href=""http://en.wikipedia.org/wiki/Tariff#Economic_analysis"" rel=""nofollow"">effect of a tariff on an imported good</a>.  The tariff raises the domestic price of the good, with resulting changes in the consumer surplus and producer surplus relating to that good. Would we say that the change in welfare is the sum of those changes?  No, because (even if we ignore effects on related markets and on exporting countries) the revenue raised by the tax is also relevant to welfare.  In a simple partial equilibrium analysis, therefore:</p>

<p>Welfare loss  =  Reduction in CS – Gain in PS – Increase in government revenue</p>

<p>This distinction between surplus and welfare can be found in (A) and (B).</p>

<p>Thirdly, consider a change in a market for a good subject to a production externality, say air pollution.  Here we would say that the change in welfare is not just the change in producer and consumer surplus in the particular market, but should also take account of the externality.  However, to draw a distinction between surplus and welfare on this basis would be an oversimplification since, in the economics of environmental valuation, the concept of consumer surplus is routinely applied to non-market goods.  For example (although the details are complex and the results unlikely to be very accurate) a demand curve for air quality (suitably measured) in a region might be estimated using the <a href=""http://www.ecosystemvaluation.org/hedonic_pricing.htm"" rel=""nofollow"">hedonic pricing method</a> which uses the housing market as a surrogate for a market in air quality.  Once a demand curve has been estimated, it is possible to calculate the change in consumer surplus due to a change in air quality and include this in a measure of change in welfare. Having said that, it is questionable whether methods are available to estimate consumer surpluses for all non-market goods, so to that extent there is validity in (2).   </p>

<p>The conditions that would be needed for a change in total surplus in the market for one product to be an accurate measure of the change in welfare resulting from a policy change would therefore be quite stringent, including at least the following:</p>

<p>•  No direct effects of the policy change on other markets;</p>

<p>•  No effects of change in the market on other markets;</p>

<p>•  No harmful effects of the product on those consuming it;</p>

<p>•  No externalities in production or consumption of the product.</p>

<p>Sometimes these conditions will be met, to a reasonable approximation, and then it might be appropriate to use the terms “surplus” and “welfare” interchangeably.</p>

<p>Finally, a brief consideration of the idea that surplus relates to one market while welfare relates to many markets. Because “welfare” is an evaluative term, it makes sense to apply it to situations involving either one or many markets, even if in some cases it is hard to find suitable criteria to determine whether a change is an increase in welfare.  “Consumer surplus”, on the other hand is normally defined for a single market, and the path-dependency problem (see (C)) is a complication in aggregation across markets, except in special cases (this is where, if the connection is made with utility theory, quasi-linear utility is relevant).  To overcome the path-dependency problem, either <a href=""http://en.wikipedia.org/wiki/Compensating_variation"" rel=""nofollow"">compensating variation</a> or equivalent variation are sometimes used as alternatives to (ordinary Marshallian) consumer surplus, but then there is the further problem that the theoretical income-compensated demand curves underlying these measures cannot be estimated from observations of consumer behaviour.  To that extent there is validity in (1).</p>

<p>References</p>

<p>A. Koo W W &amp; Kennedy P L (2005) <em>International Trade and Agriculture</em> Blackwell Publishing p 104</p>

<p>B. Mankiw B G &amp; Taylor M P (2006) <em>Economics</em> Thomson Learning pp 172-3 (a European version of the well-known textbook)</p>

<p>C. Johansson P-O (1991) An Introduction to Modern Welfare Economics  Cambridge University Press pp 42-52</p>
","1929"
"What does it mean by 'intensive form'?","5913","","<p>I encountered this phrase while reading up on growth models - that is to work with a function in intensive form. What does it mean when a function is in intensive form?</p>

<p>Thanks!</p>
","<p>The intensive form of the production function is derived from the following. Let us assume a production function, F, with inputs of capital, K, and labor and technology, AL. Thus, output, $Y = F(K,AL)$. Assuming constant returns to scale, i.e. $F(cK,cAL) = cF(K,AL)$, we can say $F(K,AL) = ALF(K/AL, 1)$. The intensive form of the production function, f, takes the argument k = K/AL. k is ratio of capital to labour, or how much capital is there per effective unit of labour. $f(k) = Y/AL = F(K/AL, 1)$, or the output per effective unit of labour.</p>

<p>The intensive form is relevant because although the production function may have constant returns to scale, each individual input may exhibit diminishing returns. In other words, if you increase both labour and capital, this will increase your output proportionally, but if you increase only capital, your output will rise proportionally less. It is also easier to express interest rates and wages in the intensive form. For more, you can read any graduate level macroeconomic textbook. (I've used Romer's Macroeconomics.) Hope this helps!</p>
","6897"
"Solow Model: Steady State v Balanced Growth Path","5804","","<p>Okay, so I'm having real problems distinguishing between the Steady State concept and the balanced growth path in this model:</p>

<p>$$ Y = K^\beta (AL)^{1-\beta} $$</p>

<p>I have been asked to derive the steady state values for capital per effective worker:</p>

<p>$$ k^*=\left(\frac{s}{n+g+ \delta }\right)^{\frac{1}{1-\beta }} $$</p>

<p>As well as the steady state ratio of capital to output (K/Y):</p>

<p>$$ \frac{K^{SS}}{Y^{SS}} = \frac{s}{n+g+\delta } $$</p>

<p>I found both of these fine, but I have been also asked to find the ""steady-state value of the marginal product of capital, dY/dK"". Here is what I did:</p>

<p>$$ Y = K^\beta (AL)^{1-\beta} $$
$$ MPK = \frac{dY}{dK} = \beta K^{\beta -1}(AL)^{1-\beta } $$</p>

<p>Substituting in for K in the steady state (calculated when working out steady state for K/Y ratio above):</p>

<p>$$ K^{SS} = AL\left(\frac{s}{n+g+\delta }\right)^{\frac{1}{1-\beta }} $$</p>

<p>$$ MPK^{SS} = \beta (AL)^{1-\beta }\left[AL\left(\frac{s}{n+g+\delta }\right)^{\frac{1}{1-\beta }}\right]^{\beta -1} $$</p>

<p>$$ MPK^{SS} = \beta \left(\frac{s}{n+g+\delta }\right)^{\frac{\beta -1}{1-\beta }} $$</p>

<p>Firstly I need to know whether this calculation for the steady state value of MPK is correct?</p>

<p>Secondly, I have been asked to Sketch the time paths of the capital-output ratio and the marginal product of capital, for an economy that converges to its balanced growth path ""from below"".</p>

<p>I am having problems understanding exactly what the balanced growth path is, as opposed to the steady state, and how to use my calculations to figure out what these graphs should look like.</p>

<p>Sorry for the mammoth post, any help is greatly appreciated! Thanks in advance.</p>
","<p>This is when the attempt at accuracy creates confusion and misunderstanding.  </p>

<p>Back in the day, growth models were not incorporating technological progress, and led to a long-run equilibrium characterized by <em>constant</em> per capita magnitudes. Verbally, the term ""steady-state"" seemed appropriate to describe such a situation. </p>

<p>Then Romer and endogenous growth models came along, which also pushed the older models to start including as a routine feature exogenous growth factors (apart from population). And ""suddenly"", per capita terms were not constant in the long-run equilibrium, but <em>growing at a constant rate</em>. Initially the literature described such a situation as ""steady state in growth rates"".  </p>

<p>Then it appears the profession thought something like ""it is inaccurate to use the word ""steady"" here because per capita magnitudes are growing. What happens is that all magnitudes <em>grow</em> at a <em>balanced</em> rate (i.e at the same rate, and so their ratios remain constant). And since they grow, they follow a <em>path</em>..."" Eureka!: the term ""balanced growth path"" was born.  </p>

<p>...To the frustration of students (at least), which have now to remember that for example, the ""saddle path"" is indeed a <em>path</em> in the Phase diagram, but the ""balanced growth path"" is only a point! (because in order to actually draw a Phase diagram and obtain a good old long-run equilibrium, we express magnitudes per effective worker, and these magnitudes do have a traditional steady-state. But we continue to call it ""balanced growth path"", because per capita magnitudes, which is what we are interested in, in our individualistic approach), continue to grow).</p>

<p>So ""balanced growth path"" = ""steady state of magnitudes per efficiency unit of labor"", and I guess you can figure out the rest for your phase diagram.</p>
","10116"
"What is the relationship between inflation and imports/exports?","5752","","<p>According to the aggregate demand curve, when the price level is higher, the real GDP demanded is lower. One of the explanations given is a consequence of the Mundell-Fleming model:</p>

<p>""As the price level drops, interest rates fall, domestic investment in foreign countries increases, the real exchange rate depreciates, net exports increases, and aggregate demand increases.""</p>

<p>So this seems to suggest that increased inflation means <strong>more imports and less exports.</strong></p>

<p>But increased inflation should also increase the exchange rate (currency depreciation). If you can trade foreign currency for more domestic currency, then <strong>exports should increase and (conversely) imports should decrease.</strong></p>

<p>How do I reconcile these two models? Is this a difference of short run vs. long run? Or is it a matter of all other factors being held constant in each scenario?</p>
","<p>As requested in comments:</p>

<p>It is a matter of <em>which</em> other factors are being held constant. If the relative-inflation-adjusted exchange rate (i.e. the real rate) stays constant, there may be no supply or demand effect on export and import volumes. </p>

<p>However exchange rates do not exactly follow relative inflation in different economies; other factors such as interest rates and investment returns, balance of payments differences, and sentiment can also have an effect.    </p>
","12966"
"How does one derive the elasticity of substitution?","5620","","<p>For two goods $x$ and $y$, the elasticity of substitution is defined as $$\sigma \equiv \frac{d\log\left(\frac{y}{x}\right)}{ d\log\left(\frac{U_x}{U_y}\right) }= \frac{\frac{d\left(\frac{y}{x}\right)}{\frac{y}{x}}}{ \frac{d\left(\frac{U_x}{U_y}\right)}{\frac{U_x}{U_y}}} $$</p>

<p>I am confused by two things: </p>

<ol>
<li>Why do we just write $d\log\left(\frac{y}{x}\right)$? What are we differentiating with respect to? </li>
<li>How do I use that that to show the above relation? </li>
</ol>

<p>Can someone explain?  </p>
","<p><strong>How to derive elasticity of substitution</strong></p>

<p>The first step is to recall the definition of a differential. If you have a function $f: \Bbb R^n \to \Bbb R$, say, $f(x_1,\cdots,x_n)$, then: $${\rm d}f = \frac{\partial f}{\partial x_1}{\rm d}x_1 + \cdots + \frac{\partial f}{\partial x_n}\,{\rm d}x_n. $$ </p>

<p>For example, $$d\log v = \frac{1}{v}dv$$</p>

<p>Now suppose $v = \tfrac{y}{x}$, then we have $$ d\log(y/x)=\frac{d(y/x)}{(y/x)}$$</p>

<p>and for $v = \tfrac{U_x}{U_y}$ </p>

<p>$$ d\log(U_x/U_y)=\frac{d(U_x/U_y)}{(U_x/U_y)}$$</p>

<p>In other words, <strong>if you reduce the problem to (1) understanding the definition of a differential and (2) use a simple change of variable</strong>, the problem becomes very straightforward. </p>

<p>You then get </p>

<p>$$\sigma \equiv \frac{d\log\left(\frac{y}{x}\right)}{ d\log\left(\frac{U_x}{U_y}\right) }= \frac{ \frac{d(y/x)}{(y/x)} }{ \frac{d(U_x/U_y)}{(U_x/U_y)} } $$</p>

<p><strong>ASIDE:</strong></p>

<p>Note, it is important to recognize that $ d(y/x)$ is a meaningful concept. You simply apply quotient rule and you find </p>

<p>$$ d(y/x)= \frac{xdy-ydx}{x^2}$$</p>

<p>This makes sense because </p>

<p>$$ d\log(y/x) = d\log(y) - d\log(x) = \frac{dy}{y}-\frac{dx}{x}$$</p>

<p>And if you compute</p>

<p>$$ d\log(y/x)=\frac{d(y/x)}{(y/x)}=\frac{ \frac{xdy-ydx}{x^2}}{y/x} =  \frac{xdy-ydx}{xy} = \frac{dy}{y}-\frac{dx}{x}$$</p>

<p>Same logic applies to $d(U_x/U_y)$. </p>

<p>Thus, all of $\sigma$ is well-defined in the sense we are using the calculus tools correctly / legally. </p>

<hr>

<p><strong>What is elasticity of substitution?</strong></p>

<p>Elasticity is by how much % one thing changes relative to a % change in another. Therefore, in this case, it is % change in ratio of two goods  relative to a single % change in the $MRS$ for those two goods. </p>
","5518"
"Nash equilibrium of a Bertrand game with different marginal costs","5417","","<p>Consider the following game of Bertrand (price competition):</p>

<ul>
<li>There are two players, $1$ and $2$. Each has a publicly known marginal cost, $c_i$.</li>
<li>A strategy is a price, $p_i\in\mathbb{R}$.</li>
<li>Player $i$'s payoff (profit) is $\pi(p_i,p_j)=p_i-c_i$ if $p_i&lt;p_j$, $\pi(p_i,p_j)=\frac{p_i-c}{2}$ if $p_i=p_j$ and $\pi(p_i,p_j)=0$ if $p_i&gt;p_j$.</li>
</ul>

<hr>

<p>If $c_i=c_j=c$ the result is the straightforward Bertrand Nash equilibrium: both firms set $p_i=c$ and make zero profit. A higher price results in zero demand/profit; a lower price results in negative profits. There is therefore no profitable deviation.</p>

<hr>

<blockquote>
  <p>Now suppose $c_1&lt;c_2$. What is the Nash equilibrium?</p>
</blockquote>

<p>I have previously contented myself with the intuition that the equilibrium is for firm 1 to take the whole market at a price 'slightly below' $c_2$? But looking at the technical details raises doubts in my mind:</p>

<ol>
<li>We can't have an equilibrium with $p_1=c_2$. The best response for $2$ would be $p_2=c_2$, but then $1$'s profit is $(p_1-c_2)/2$ and $1 $ can profitably deviate to $p_1=c_2-\epsilon$ for some small $\epsilon$.</li>
<li>It seems like we can't have an equilibrium with $p_1=c_2-\epsilon&lt; c_2\leq p_2$ because firm 1 could do better with $p_1=c_2-(\epsilon/2)$.</li>
</ol>

<p>Do we conclude that the only equilibrium of this game is in mixed strategies?</p>
","<p>Yes, there is no equilibrium in pure strategies. For any price charged by firm 2 above $c_1$, firm one could only best respond by charging the largest price that is strictly smaller. which is impossible. If both firms charge at most $c_1$, one of these firms must make a loss, which cannot be a best response. So there is no Nash equilibrium in pure strategies.</p>

<p>There are, however, equilibria in mixed strategies. Consider an equilibrium in which firm 1 chooses a price of $c_2$, while firm two randomizes uniformly over the interval $[c_2,c_2+\epsilon]$ for some $\epsilon&gt;0$. For $\epsilon&lt;c_2-c_1$, this is a Nash equilibrium and, moreover, it uses no weakly dominated strategies. Firm 1 is making a profit of $c_2-c_1$ and firm 2 a profit of $0$. Clearly, firm 2 has no profitable deviation. To see that firm $1$ has no profitable deviation, recall that there can be no profitable deviation in mixed strategies if there is no profitable deviation in pure strategies (a very general game-theoretic fact), and observe that firm $1$ cannot profit from deviating to a price strictly below $c_2$ or weakly above $c_2+\epsilon$. So take any $\delta$ satisfying $0&lt;\delta&lt;\epsilon$ and assume that firm 1 charges $c_2+\delta$ (note that $\delta=0$ would be no deviation.) The probability that firm 2 charges a lower price is $\delta/\epsilon$, so the expected profit of firm 1 is
$$(1-\delta/\epsilon)(c_2-c_1+\delta)+\delta/\epsilon~ 0.$$
Write $K$ for $c_2-c_1$. We have a profitable deviation if
$$(1-\delta/\epsilon)(K+\delta)&gt;K,$$
which we can rearrange to get
$$\delta(1-K/\epsilon-\delta/\epsilon)&gt;0,$$
which is equivalent to
$$K/\epsilon+\delta/\epsilon&lt;1.$$ If $\epsilon&lt; c_2-c_1=K$, this can never be the case, so we obtain a Nash equilibrium if $\epsilon&gt;c_2-c_1$. </p>

<p>One can actually use the same construction to construct equilibria in which firm 1 charges less than $c_2$, but in the resulting equilibrium, firm 2 must play a weakly dominated strategy. </p>

<p>The construction in this answer is taken from the following short paper:</p>

<p>Blume, Andreas. ""Bertrand without fudge."" <em>Economics Letters</em> 78.2
  (2003): 167-168.</p>
","18440"
"Find the optimal demand functions for capital and labour for this firm","5344","","<p>I'm trying to solve this question which states:</p>

<p>Suppose that a profit maximizing producer has a production function described by Q = K^3/4 L^1/4 and faces the general isocost line (TC = rK + wL). </p>

<p>Find the optimal demand functions for capital and labor for this firm.</p>

<p>Here's what I've done and know:</p>

<p>I've solved for the MP1(labor) and MP2(capital):
MP1 = 1/4 (K^3/4 * L^-3/4 )
MP2 = 3/4 (K^-1/4 * L^1/4 )</p>

<p>I also know that MP1 / MP2 = w / r. </p>

<p>Can someone point out a suggestion to solve for K and L, the optimal demand functions?</p>

<p>Thanks</p>
","<p>I think you may need some more information to find an expression for L (or K).
From what we have, we know MP1/MP2 = w/r, and that lets us say K = aL.
Now we look at our profit, the thing we want to maximize. Substituting K = aL into Q - TC, we get L(pb - 4w), where $b  = pa^{3/4}$, and p is the price.
As long as p > 4r/3, we can increase profit forever by increasing L, as long as we increase K proportionally. 
This assumes p is fixed, and labor and capital are infinitely available at r and w. So that's where our constraint has to come from. (Unless we're simply given a fixed value for Q, in which case we solve from K = aL.) 
If we have a demand curve, and we're the only supplier, we increase L and K until Q becomes such that p = 4r/3, or we hire people until we can't get aL units of capital, or we increase K until we can't get K/a units of labor. If we're not the only supplier, we play a game with the other suppliers and fix Q ourselves.
But I don't think we can maximize profit without that extra information, because the functional form of Q together with the fact that L and K are linearly related means Q is linearly related to L or K, and the cost function is as well.</p>
","4708"
"How are workers harmed, from firms' payroll tax revenue aimed at reducing workers' tax?","5196","","<p>Source: p 130, Question 6.5, <em>Principles of Microeconomics</em>, 7 Ed, 2014, by N Gregory Mankiw<br>
= (page unknown), Question 6.5, <em>Principles of Microeconomics</em>, 4 Ed, 2008, by N Gregory Mankiw</p>

<blockquote>
  <p>p 125, Case Study: a <strong>payroll tax</strong> [...] is a tax on the wages that firms pay their
  workers. ... When a payroll tax is enacted, the wage received by workers falls, and the
  wage paid by firms rises.</p>
</blockquote>

<p><img src=""https://i.stack.imgur.com/b4TaS.png"" alt=""enter image description here""></p>

<blockquote>
  <p>$5.$ A senator wants to raise tax revenue and make workers
  better off. A staff member proposes raising the
  payroll tax paid by firms and using part of the extra
  revenue to reduce the payroll tax paid by workers.
  Would this accomplish the senator’s goal? Explain.</p>
  
  <p><strong>Given Answer:</strong> Reducing the payroll tax paid by firms and using part of the extra revenue to reduce the payroll
  tax paid by workers would not make workers better off, because the division of the burden of a
  tax depends on the elasticity of supply and demand and not on who must pay the tax. Because
  the tax wedge would be larger, it is likely that both firms and workers, who share the burden of
  any tax, would be worse off.</p>
</blockquote>

<p>I reddened the transfer of tax revenue from firms, and yellowed workers' lost wages. Why are workers worsened, by the transfer of tax revenue from firms (the red as above) intended to repay workers' lost wages (yellow)? The workers receive extra money, right? Please advise if I erred, but I think Question 5 can be graphed as above (I modified Figure 8, p 126). </p>
","<p>I attached three figures. Figure 1 shows the labor market without the tax. You can see the surplus that the firms and workers receive. They enjoy a surplus because some labor would be hired at even higher wages and some labor would be willing to work at lower wages. The sum of these surpluses gives the 'welfare' of the actors in the labor market.</p>

<p>In figure 2 the government introduces a tax on labor. Whether this is collected from firms or workers does not matter as long as there is full information and all actors are rational. As you can see the surpluses are reduced. Even if you add together the surpluses and the tax collected by the government you do not get the welfare you had in the situation without tax. This is because the equilibrium amount of labor has decreased due to the tax. The welfare loss this creates is called the deadweight loss. This shows that these kind of taxes introduce some inefficiency. However that does not mean that all are worse off. If the government gives all the money to the secretary of Treasury he will be very happy. Similarly, if the government transfers all the tax to the workers (long live the proletariat) their total surplus may be bigger than in the situation without taxes. To see this, compare the area of the green polygons in figure 1 and figure 3. If the deadweight loss is too large this may not be possible.</p>

<p>What you could say is that you cannot compensate both firms and workers at the same time, as welfare is lost.</p>

<p><img src=""https://i.stack.imgur.com/Xa6aj.png"" alt=""Surplus""></p>
","5683"
"Real world production-possibility frontier example?","5195","","<p>I'm reading an economics textbook and trying to make sense of PPF (or PPC) concept. All examples I could find are like producing computers vs food. I can't understand how it can be evaluated and applied to real life situation. Do you know any practical example of PPF?</p>
","<p>In the 1940's the RAND corporation put together a series of simulations about war between the USA and the USSR. In the end, they came out with a series of two ""good"" possibilities, degree of victory and number of crew lives saved. </p>

<blockquote>
  <p>The US Air Force asked RAND to apply systems analysis to design a
  first strike on the Soviets. ....  Paxson and RAND were initially
  proud of their optimization model and the computing power that they
  brought to bear on the problem, which crunched the numbers for over
  400,000 configurations of bombs and bombers using hundreds of
  equations. The massive computations for each configuration involved
  simulated games at each enemy encounter, each of which had first been
  modeled in RAND’s new aerial combat research room. They also involved
  numerous variables for fighters, logistics, procurement, land bases,
  and so on. Completed in 1950, the study recommended that the United
  States fill the skies with numerous inexpensive and vulnerable
  propeller planes, many of them decoys carrying no nuclear weapons, to
  overwhelm the Soviet air defenses. Though losses would be high, the
  bombing objectives would be met. While RAND was initially proud of
  this work, pride and a haughty spirit often go before a fall. RAND’s
  patrons in the US Air Force, some of whom were always skeptical of the
  idea that pencil-necked academics could contribute to military
  strategy, were apoplectic. RAND had chosen a strategy that would
  result in high casualties, in part because the objective function had
  given zero weight to the lives of airplane crews.</p>
</blockquote>

<p><a href=""https://www.aeaweb.org/atypon.php?return_to=/doi/pdfplus/10.1257/jep.28.4.213"" rel=""nofollow"">Retrospectives: The Cold-War Origins of the Value of Statistical Life</a></p>

<blockquote>
  <p>RAND quickly backpedaled on the study, and instead moved to a more
  cautious approach which spelled out a range of choices: for example,
  some choices might cost more in money but be expected to have fewer
  deaths, while other choices might cost less in money but be expected
  to have more deaths. The idea was that the think tank identified the
  range of choices, and the generals would choose among them. But of
  course, financial resources were limited by political considerations,
  and so the choices made by the military would typically need to
  involve some number of deaths that was higher than the theoretical
  minimum--if more money had been available. In that sense, spelling out
  a range of tradeoffs also spelled out the monetary value that would be
  put on lives lost.</p>
</blockquote>

<p><a href=""http://conversableeconomist.blogspot.com/2014/11/the-origins-of-value-of-statistical.html"" rel=""nofollow"">The Origins of the Value of a Statistical Life Concept</a> </p>

<p>Maybe that's too much like the two input story of Aerandal. Depends on if you consider the saved lives a ""savings"" or a ""good"". For a clearer example of the guns vs. butter tradeoff, consider another example from WW II.</p>

<blockquote>
  <p>In February 1942, Fisher Body completely stopped making auto bodies
  and began assembling the famous M-4 ""Sherman"" tank in its No. 1 plant
  in Flint. The operation eventually moved to Grand Blanc and would turn
  out 11,358 tanks by 1945.</p>
  
  <p>Buick tackled the manufacture of ammunition, churning out 75,000
  casings per month for the duration. By the war's end, the division had
  supplied more than 12.5 million casings.</p>
  
  <p>Buick also retooled to meet the demands of making engines for the B-24
  bomber. At first, they talked of about 500 engines a month, but the
  government doubled its order by the time Buick had its tooling in
  place. By 1944, Buick's Melrose Park factory was regularly turning out
  2,000 engines a month....</p>
  
  <p>In all, more than 113,000 employees left GM to serve while the company
  churned out $12.3 billion in aircraft, tanks, vehicles and arms.</p>
  
  <p>When it was all counted up after the war, GM had produced 854,000
  trucks (including the legendary DUKW, or ""Duck"" amphibious vehicles),
  198,000 diesel engines, 206,000 aircraft engines, and 38,000 tanks,
  tank destroyers, and armored vehicles, not to mention vast quantities
  of guns and ammunition.</p>
</blockquote>

<p><a href=""http://www.military.com/veteran-jobs/career-advice/military-transition/how-gm-divisions-tackled-war-effort.html"" rel=""nofollow"">How GM's Divisions Tackled the War Effort</a> </p>
","3096"
"How do I change the base year of real GDP using the GDP deflator and nominal GDP?","4959","","<p>I'll use the US as an example. I have three data series</p>

<ol>
<li>nominal GDP $(Y)$</li>
<li>real GDP in 2005 USD $(\bar{Y})$</li>
<li>the GDP deflator $(d)$, with 2005 as the base year, so $d_{2005} = 100$</li>
</ol>

<p>I want to change the base year to 2000. Are these calculations accurate? I use the notation $\$_{t}$ for USD in year $t$ prices to help myself keep the units straight.</p>

<p>My goal is $\bar{Y}_{t} \ \$_{2000}$.
\begin{align}
\frac{d_{2000}}{d_{t}} \cdot Y_{t} \ \$_t
&amp;= \frac{Y_{2000} \ \$_{2000}}{\bar{Y}_{2000} \ \$_{2005}} \cdot \frac{\bar{Y}_{t} \ \$_{2005}}{Y_{t} \ \$_{t}} \cdot Y_{t} \ \$_t \\
&amp;= \frac{Y_{2000} \ \$_{2000}}{\bar{Y}_{2000}} \cdot \bar{Y}_{t} \\
&amp;= \bar{Y}_{t} \ \$_{2000} \cdot \frac{Y_{2000}}{\bar{Y}_{2000}}
\end{align}</p>

<p>I think those are all the correct unit cancellations, but now I'm stuck with the unitless quantity $\frac{Y_{2000}}{\bar{Y}_{2000}}$, so I don't know how to complete the conversion. </p>

<p>Am I doing this right?</p>
","<p>It's just nominal GDP in year t, times (deflator in year 2000 / deflator in year t). </p>
","5027"
"What does it mean to make an identification assumption?","4913","","<p>Trying to understand this problem:</p>

<blockquote>
  <p>Suppose you had access to a dataset that follows individuals from
  adolescence throughout adulthood. Each year, you observe earnings,
  educational attainment, health, and marital status.  Suppose you were
  interested in seeing how marriage causally affects the earnings of
  men. Using the described data, how would you examine this question?  What
  would be your identifying assumption?  How could you assess the
  plausibility of this assumption?</p>
</blockquote>

<p>First I'm trying to understand, what is an identifying assumption? I think it's the assumption you test that tells you whether there was a causal relationship or not. Is that right?</p>

<p>And my first thoughts on answering the homework problem are these:</p>

<p>I would have to determine that income and marriage aren't simultaneously determined, reverse causal, or both influenced by the same variable. So creating a counterfactual group (unmarried men) and matching with married men could set up a good difference in differences.</p>

<p>But how to assess the plausibility of this assumption? I usually just plug numbers into the computer and don't care about plausibility. What makes an assumption more plausible in econometrics?</p>
","<p>Identifying assumption: assumptions made about the DGP that allows you to draw causal inference. E.g. exogeneity assumption for IV, parallel trends assumption in diff-in-diff.</p>

<p>Identifying assumptions (lack of endogeneity in general) can never be
statistically confirmed (a non-reject is good, but it's not confirmation). So assessment of plausibility consists of empirical arguments based on what you know about the DGP.</p>
","10759"
"Why did US dollar appreciate during the Global Economic Crisis (2007-09)","4820","","<p>We know that the US dollar exchange rate increased during the global recession while usually when an economy performs weakly its currency should depreciate. How was there still a huge demand for USD in foreign markets even when subprime mortgage crisis was at its peak.</p>
","<p>Because dollar is a major reserve currency. When a financial crisis occurs in other countries, like India, Brasil, Russia, etc, everyone sells stocks and liquiates assets to raise cash. But the cash they want to raise is usually dollars or euros. When a crisis hit the US, everyone started selling assets FOR dollars. I.e. they were buying dollas for stocks, trillions of dollars worth. This demand for cash appreciated dollar. There was a multitude of other factors involved, as discussed in this paper: <em>Dollar Appreciation in 2008: Safe Haven, Carry Trades, Dollar Shortage and Overhedging</em> <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1519814"" rel=""nofollow"">http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1519814</a> </p>

<p>After Fed's relatively successful monetary policy decisions, the US economy recovered faster than the economies of the EU and Japan, other reserve currency emitters. Then it was natural for dollar to continue strengthening. </p>
","9424"
"Completeness of Preferences","4813","","<p>Economists assume that consumers have a set of preferences that they use to guide them in choosing between goods. These preferences have to satisfy three properties: completeness, transitivity and ""more is better"". </p>

<p>By <strong>completeness</strong> I mean that when consumers face a choice between any two bundles of goods, they can always rank them. This rules out the possibility that consumers cannot decide which bundle is preferable. I am wondering how to deal with the introduction new goods? Does it mean that this property only apply to available/existing goods? And should a consumer also rank today a good that is coming tomorrow? I have the intuition that if a new good replaces an existing one, the rank of preferences may change and I dont know how deal with that. Any reference would be appreciated.</p>
","<p>The first key to understanding this is to recognise that consumers have preferences not over goods, but over <em>states of the world</em>. A ""state"" is a complete description of all factors that are relevant to a decision.</p>

<p>For example,</p>

<ul>
<li>in a simple consumption problem where the consumer must choose between eating a banana and an apple two states of the world would be ""I have a banana"" and ""I have an apple"". Here the preferences over states collapse back to simple preferences over goods so we see that simple preferences defined over bundles of goods are really just a special case of the more general idea of preferences over states of the world.</li>
<li>Slightly more complicated: suppose you are deciding whether to take an umbrella to work. Now it's not sufficient to simply compare ""I have an umbrella"" with ""I don't have an umbrella"" because which of these I prefer will depend upon the weather! So the relevant states are something like ""I have an umbrella and rain is forecast"", ""I don't have an umbrella and rain is forecast"", ""I have an umbrella and rain is not forecast"", and ""I don't have an umbrella and rain is not forecast"".</li>
</ul>

<p>Once we think of preferences as being over states rather than goods then it becomes easy to incorporate the kinds of dynamic elements you refer to. For example, if I am choosing between watching a movie in the cinema today versus buying a blu-ray that is released tomorrow then the states could, in principle be quite complicated:</p>

<ul>
<li>""I spend time travelling in the rain to the cinema where I get to see the movie early on a large screen but there may be stupid kids making noise.""</li>
<li>""I buy the blu-ray, which means I have to wait until tomorrow to see the movie on a small television. But I won't get wet, can watch the movie more than once, and can send my kids away to their grandmothers so they don't make noise.""</li>
</ul>

<p>This example is a bit silly, but should make clear that the idea of a state is very general and allows us to define preferences over all sorts of very exotic decision problems, including those where new goods are arriving or are becoming unavailable. indeed, the choices don't even have to be about goods that I consumer, since states of the world could be things like ""I spend an extra hour in bed"" vs ""I go early to the park with my children"".</p>

<hr>

<p><strong>Completeness</strong> requires that the consumer can rank all of the relevant states of the world, where a state is relevant if it could potentially be chosen by the consumer. This is obviously a big ask because there are typically a large number of factors affecting a decision problem, so the number of states a consumer must consider is large.</p>

<p>In practice, consumers use heuristics and approximations to solve their decision problems; they, of course, do not solve the formal, fully-specified optimisation problem. This modelling approach is, nevertheless, useful if it offers a good approximation of consumer behaviour while also making a good trade-off between tractability and empirical relevance. In fact, models of consumer demand and choice based on this simple framework typically do quite well at explaining behaviour, suggesting that this particular modelling simplification is quite useful.</p>

<p>The field of behavioural economics deals with situations in which consumers systematically deviate from this optimal decision process, including cases where they do not consider the full set of states.</p>

<hr>

<p>Edit: by no means definitive, but <a href=""http://restud.oxfordjournals.org/content/78/1/235.abstract"" rel=""nofollow noreferrer"">this article by Eliaz and Spiegler (2011)</a> is a nice example of modelling consumers who are boundedly rational and do not consider all possible states. The title and abstract are as  follows:</p>

<blockquote>
  <p><strong>Consideration Sets and Competitive Marketing</strong></p>
  
  <p>We study a market model in which competing firms use costly marketing devices to influence the set of alternatives which consumers perceive as relevant. Consumers in our model are boundedly rational in the sense that they have an imperfect perception of what is relevant to their decision problem. They apply well-defined preferences to a “consideration set”, which is a function of the marketing devices employed by the firms. We examine the implications of this behavioural model in the context of a competitive market model, particularly on industry profits, vertical product differentiation, the use of marketing devices, and consumers' conversion rates.</p>
</blockquote>
","14461"
"Finding demand function given a utility min(x,y) function","4756","","<p>I am confused about a particular point regarding finding a demand function. All the problems in this practice set I am doing have involved applying the method of Lagrangian multipliers. But I am uncertain if it applies here for this problem.</p>

<p><strong>Problem Setup</strong></p>

<p>Consider a consumer with utility function $u(x,y) = \min\lbrace x,y\rbrace$. Suppose we are given wealth $w$ and prices $p_x = 1, p_y = \frac{1}{2}$. </p>

<p><strong>My Work</strong> </p>

<p>Not much to do yet. All I did was set up a budget constraint $w = xp_x +  yp_y = x + \frac{1}{2} y$.</p>

<p><strong>My Confusion</strong> </p>

<p>I was all set to setup a Lagrangian multiplier equation when suddenly I realized that my utility function is a $\min$ function. At first, I thought this function wasn't differentiable. Now, I am thinking it is not differentiable but it is partially differentiable. I am still unsure.</p>

<p><strong>My Guess</strong> </p>

<p>I suspect yes $\min$ is partially differentiable based on this thread </p>

<p><a href=""https://math.stackexchange.com/questions/150960/derivative-of-the-fx-y-minx-y"">https://math.stackexchange.com/questions/150960/derivative-of-the-fx-y-minx-y</a></p>

<p>But I suspect my answer will need a piecewise component or something. </p>

<p><strong>My Question</strong> </p>

<p>Are Lagrangian multipliers applicable here? If so, how do I define the Lagrangian in piecewise terms as I think I will need to do?  If it is not differentiable, how does one derive a demand function given a $\min$ or a $\max$ function? </p>
","<p>No, you should not use Lagrange multipliers here, but sound thinking. Suppose $x\neq y$, say for concreteness $x&lt;y$. Let $\epsilon=y-x$. Then $\min\{x,y\}=x=\min\{x,x\}=\min\{x,y-\epsilon\}.$
So the consumer could reduce her consumption of good 2, without being worse off. On the other hand for all $\delta&gt;0$, we would have $\min\{x+\delta,y-\epsilon/2\}&gt;x=\min\{x,y\}$, so the consumer could be better of by reducing the consumption of the second good and spending the freed money on the first good. In an optimum, a consumer cannot improve so optimality requires $x=y$. It is also clear that consumers improve along the $x=y$ 45° ray. So you can simply use $x=y$ as an optimality condition to be substituted into your budget constraint and bypass Lagrange multipliers.</p>
","2972"
"What happens if the ""control variables"" are also endogenous?","4755","","<p>I work in Political Economy, and a lot of the models include ""innocent"" control variables such as population, inequality, colonial legacy, etc. so that the author can claim unbiasedness on their independent variable of interest.</p>

<p>But if any of these control variables are endogenous to some omitted variable, doesn't this contaminate the unbiasedness of ALL the independent variables?</p>

<p>If that's true, then what can we do? Leave those control variables out and they lead to omitted variable bias themselves. Include those in and they will contaminate everything in the model.</p>

<p>Example: A researcher wants to know if inequality leads to violence, and he controls for a few things:
\begin{equation}
Violence = Inequality + Growth + Development + \epsilon
\end{equation}
Seeing that <em>Inequality</em> is likely to be endogenous (because of the omitted variable <em>Level of altruism</em>), he will try to find a instrumental variable for <em>Inequality</em>. But aren't <em>Growth</em> and <em>Development</em> likely to be endogenous (i.e. correlated with <em>Level of altruism</em>) too? </p>

<p>This example may look silly, but my point is in Political Economy / Development work, there are so many factors at play (yet omitted) that I'm afraid many variables included on the LHS are endogenous. Yet often, the researcher only looks for an instrument for his pet independent variable only.</p>
","<h1>""But if any of these control variables are endogenous to some omitted variable, doesn't this contaminate the unbiasedness of ALL the independent variables?""</h1>

<p>I don't want to emphasize this too much, but it's worth mentioning that this is not true in general. The following derivation will hopefully provide some understanding of the ""contamination"" you mention. As a simple counterexample, suppose that the data generating process is given by
$$
Y = X_1 \beta_1 + X_2 \beta_2 + Z \gamma + \varepsilon,
$$
where $Z$ is unobserved. Let $Cov(X_1,Z) = 0$, $Cov(X_2, Z) \neq 0$, and 
$Cov(X_1,X_2) = 0$. Then, it
is clear that $X_2$ is ""endogenous."" But notice that because $Cov(X_1,Z) = 0$, our
estimate of $\beta_1$ will still be ok:
$$
\text{plim}\, \hat \beta_{1} = \beta_1 + \gamma \frac{Cov(X_1^*, Z)}{Var(X_1^*)} = \beta_1,
$$
where $X_1^* = M_2 X_1$ and $M_2 = [I - X_2(X_2'X_2)^{-1}X_2']$. Because $Cov(X_1,X_2) = 0$, $X_1^* = X_1$. So $Cov(X_1^*,Z)=0$. </p>

<h1>""What can we do?""</h1>

<p>One of the mains challenges of doing good econometrics is thinking of potential identification strategies. In the type of situation you describe, there is probably nothing you can do but to try to approach the problem a different way.</p>
","3199"
"Where do remittances come into play in the formula for GDP?","4722","","<p>In the classic formula for GDP, i.e., GDP=C+I+G+X-M, where are remittances accounted for? With remittances as high as third of GDP for developing countries, I wonder how they are not explicit in this equation.</p>
","<p>Gross domestic product (GDP) is the total value of output in an economy, this can be measured only by Output using this formula.</p>

<p>This method uses GDP = C + I + G + (X-M) where</p>

<pre><code>C: Consumption (Household spending)
I: Investments 
G: Government spending 
X: Exports from an economy 
M: Imports into an economy
</code></pre>

<p>The remittances that you mention about are not made against any services.  While remittances can be a source of GDP growth by increasing household consumption, it does not directly add to GDP, it does affect GNP though.</p>

<p>For a clear comparison of these two terms GDP and GNP use <a href=""http://www.diffen.com/difference/GDP_vs_GNP"" rel=""nofollow"">this</a></p>

<p>Alternatively you can use incomes to calculate GDP, however note that even in that method you add only those incomes that are made from the production of goods and services are included and not transfers</p>
","385"
"Cobb-Douglas and Logarithm Utility Functions","4610","","<p>Suppose I have a consumer with a utility function $U(x,y) = x^\alpha y ^{1-\alpha} $ where $a \in (0,1)$. Suppose this consumer has wealth $w$ and the prices for $x$ and $y$ are $p_x$ and $p_y$ respectively. I have already set up budget constraints, calculated demand and expenditure functions. </p>

<p>But now I am given another utility function $\alpha \log x + (1-\alpha) \log  y$. Supposedly I can calculate the demand function for this without needing to do further calculation. I don't see how though. What property of logarithms are useful here? I know obviously the definition of a logarithm, but I haven't seen it in this context and am confused what kind of math I should apply to it to find a demand function. Is this just arithmetic? Is it calculus? What is pertinent here to solving this problem?  </p>
","<p>Utility functions are invariant with respect to positive monotonic transformations (PMT).
Take $U(x,y)=x^\alpha y^{1-\alpha}$, and let $V(x,y)=\log(U(x,y))$ be a PMT of $U$. 
Thus $V$ and $U$ both represent the same preference, and thus demand functions for $x$ and $y$ are the same.</p>
","2993"
"Bartik Instrument Intuition","4497","","<p>I have a question regarding the Bartik Instrument.</p>

<p>I understand that this instrument is a particularly important tool that is used in labor economics. From my understanding, this instrument attempts to isolate demand shocks from supply shocks.</p>

<p>Consider the following thought experiment:</p>

<p>Say that we have an equilibrium quantity determined both the labor demand and labor supply. Call it total labor employed in period t
  in region i.
  We can express it as:$$L_{it}=\sum_{j}L_{ijt}$$
  where the RHS is the summation over all industries hiring labor in this region. </p>

<p>Now, the problem is as follows: the changes in total labor hired in each industry is a result of both supply and demand shocks. What the Bartik Instrument does is that it constructs local labor demand shocks in the following manner:$$\tilde{L_{it}}=\sum_{j}\omega_{jt}L_{ijt-1}$$
 where the LHS is region $i's$
  predicted employment. The summation is basically a weighted average using weights which corresponding to growth rates in national level employment in industry $j$
  times the labor force employed in industry j
  by region $i$
  at time $t$.
  In a sense, these are changes that are unrelated to local labor supply shocks. The Bartik instrument is then calculated as $\frac{\tilde{L_{it}}-L_{it-1}}{L_{it-1}}$</p>

<p>This is where I am lost. Once I construct this 'instrument', what would be my first stage? Do I need a first stage anymore? My intuition tells me yes. What I mean is that is this already the predicted value that we obtain after a first stage? Let me phrase my question in a more intuitive manner:$$L=f(L^{d},L^{s})$$</p>

<p>As a result,$$dL=f_{L^d}dL^{d}+f_{L^S}dL^{s}$$</p>

<p>Now, in a stochastic environment:$$dL=f_{L^D}dL^{d}+f_{L^S}dL^{s}+v
 =f_{L^D}dL^{d}+\epsilon$$
 where I assume that $$cov(dL^{d},\epsilon)=0$$
  or that demand shocks and supply shocks are unrelated. In the first stage then, is the RHS the constructed Bartik instrument? In that case, I would regress the total observed change in labor on the Bartik instrument and obtain $\hat{dL}$
 . Or is it the case that the constructed Bartik instrument by itself serves as $\hat{dL}$
 ?</p>

<p>Thanks a lot! </p>
","<p>I think the ""first stage"" would be $L_{it}$ on $\tilde{L_{it}}$. In the Peri paper above, the Bartik instrument is actually just included directly as $\tilde{L_{it}}$ as a control variable because it is an exogenous regressor in that form. If you are running labor supply elasticity regressions (and thus want to see the effect of $L_{it}$ itself on labor supply), if you can argue that the Bartik instrument is in fact exogenous, you can use it as an instrument for $L_{it}$. But, putting it directly in, as you suggested, would amount to something very similar (i.e., the Reduced Form rather than the Structural Eq.). </p>
","10983"
"What is the difference between average cost and marginal cost?","4484","","<p>$$AC(q) = \frac {C(q)}{q}$$
$$MC(q) = \frac{\partial C(q)}{\partial q}$$</p>

<p>These are the definitions. But I don't understand what the difference is. </p>

<p>Is the average cost the cost per unit while the marginal cost is about infinitesimals? </p>
","<p>The average cost is the cost on average: total costs (C) divided by total number of units of production (q). Just as the equation you gave, says</p>

<p>The marginal cost is the cost at the margin: the additional cost of one extra unit of production, just as the equation you gave, says. Most goods and services come in discrete units: in those cases, it is not about infinitesimals, it is about the last unit of production, the unit that was produced to meet demand, the unit that would not have been produced had demand been one unit lower. In cases of continuous supply, the marginal cost is the gradient of the curve of total cost plotted with respect to total supply.</p>

<p>In pretty much all real-world circumstances, marginal cost is generally greater than average cost: that's guaranteed by a strictly monotonically increasing supply curve (with the trivial exception of the first unit of production, where average cost is by definition equal to marginal cost).</p>
","8649"
"How does the money supply behave when bank loans are repaid?","4387","","<p>In a fractional reserve system when banks lend out money, that money is created out of thin air by a accounting journal entry, and the money supply goes up by the amount of the loan &amp; when the loan gets paid off, that money disappears back into thin air and the money supply goes back down which is often also described as ""destroying the money""</p>

<p>As under normally amortized loan, out of monthly payments, some part goes towards interest &amp; some towards principal repayment, so the question is does the money equivalent of principal repayment disappears into thin air every time the payment is made towards principal of the loan, or does it only disappears at end of the loan term all at once when the loan has been repaid in full?</p>

<p>If the money gets destroyed or rather disappears from the money cycle every time the principal is repaid from the monthly payments, then does it means that the banks are only left with the interest parts &amp; nothing out of the principal portion on their books?</p>

<p>Also how does the money gets depleted from the money cycle and disappears into thin air in the case of ""interest only loans"", where during the term of the loan only interest payments are being paid by the borrower &amp; the principal is repaid all at once at the end of the term of loan in form of a single one time payment.</p>

<p>So is it that in such interest only loans because the principal gets repaid all at once at the end of the loan term so at that time immediately it gets depleted from the money cycle all at once &amp; disappears into the thin air?</p>

<p>And most importantly: if all of the money equivalent of the principal amount of loans disappears then how does the banks end up recovering the actual amount loaned by them to the others &amp; not just the interest on that loan?</p>
","<p>The money is removed when the loan principal is repaid. The actual point in the loan this occurs depends on the loan terms. For a typical compound interest rate loan, this means a small portion of the principal is repaid every month, and a matching liability deposit (money in the customers account) is removed.</p>

<p>For an interest only loan, this occurs at the end of the loan - assuming all the principal is repaid then.</p>

<p>Interest payments essentially circulate through the monetary system. They're deducted from the customer's account, recognised as income by the bank, and then paid out as some form of expense, e.g. salaries, rent, taxes, etc. They may also be moved into an internal account to provide required loss provisions on loans. </p>

<p>Loan defaults are also an expense, and this is the achilles heel of the banking system. If defaults on loans exceed the bank's loss provisions and profits from interest, then the bank will have to write off against its capital - and this interferes with the regulatory controls on lending, causing the money supply to shrink. In practice, central bank or government intervention is inevitable if this occurs.</p>

<p>As far as the relationship of principal to the money supply. Essentially the banking system relies on new lending always being sufficient to replace the money being removed. In most banking systems, new lending is typically in excess of loan repayment, and so we see the money supply more or less continuously expanding. </p>
","6056"
"Why should marginal cost be equal to the price an item is sold at?","4367","","<p>My interpretation of the condition $P=MC$ is that a firm's cost of producing one additional good should be equal to the firm's price. This means that the next item a the firm produces won't yield any profit to the firm.
What's the point of producing this additional unit? Do you have a hands-on explanation?</p>
","<p>You should keep in mind that the definition of profit in economics is not the same as in accounting. In particular, economists always deduct opportunity cost from accounting profits, and the price = MC formula has to be interpreted in this way.</p>

<p>For example, let's say you are a self-employed web-developer and you may make a profit in an accounting sense. Economists will subtract from this accounting profit the opportunity cost of not working elsewhere. Looking at it this way, the profit of a self-employed web-developer is just a wage he pays to himself.</p>

<p>The same is true for larger firms. Those firms usually pay out accounting profits to their shareholders. Economists would interpret this as the cost of using the equity capital provided by owners.</p>
","15140"
"In simple terms: what are the implications of homothetic and nonhomothetic consumer preferences?","4342","","<p>I am looking for a simple explanation of the implication of having homothetic/nonhomethetic preferences in relation to consumers' preferences when consuming goods. </p>
","<p>From a mathematical point of view, if the function $f(x,y)$ is homogeneous (of <em>any</em> degree), and $g()$ is a function whose first derivative is everywhere non-zero, then the function</p>

<p>$$H(x, y) = g[f(x,y)]$$</p>

<p>is homothetic. In economics, we usually impose something more restrictive, namely that $g' &gt;0$. But this makes a homothetic function a monotonic transformation of a homogeneous function. Now, homogeneous functions are a strict subset of homothetic functions: not all homothetic functions are homogeneous. </p>

<p>Therefore, <em>not all monotonic transformations preserve the homogeneity property of a utility function</em>. The simplest example is Cobb-Douglas utility. It is homogeneous of degree one. In an ordinal utility framework, we are ok with monotonic transformations, so we can consider the natural logarithm of it. Fine, but the natural logarithm will not preserve homogeneity. Nevertheless it will be homothetic. </p>

<p>The fundamental property of a homothetic function is that its expansion path is linear (this is a property also of homogeneous functions, and thankfully it proves to be a property of the more general class of homothetic functions).</p>

<p>In consumption theory, this means that, keeping the prices or the price ratio constant, if we vary the income of the consumer, in the $(x,y)$ plane the  tangency point of the income constraint with the highest feasible indifference curve will always reflect a fixed ratio $x/y$. This in turn implies that expenditures for each good grow all at the same rate as income, and so <strong>expenditure shares remain constant for the whole income range (always for a given price ratio).</strong>
While this may sound restrictive, in fact, <strong>it has been shown that homothetic preferences do not impose any special restrictions on <em>aggregate</em> demand</strong> (essentially due to the endowment vector being arbitrary and independent of preferences, which messes, or frees, things up).</p>
","10791"
"What's the difference between public debt, government debt and national debt?","4311","","<p>When it comes to non-private debt, I hear these three terms the most, but I am not sure if they're interchangeable or discernible. Also, are they recorded in the balance of payments? I'm guessing if they are, they'd be recorded in the transfers part of the current account and the capital and financial accounts.</p>

<p>I understand that this is a duplicate question, but my previous question had no contributions other than my own, so I figure it would be sensible to repeat it.</p>
","<p>With all these types of debt, there are various descriptions rather than standard definitions, and sometimes the same thing can be labelled with different names or the same name used for different things.  In addition, they can be measure gross or net, and there will be questions of how money owed by one part of the public sector to another is treated. </p>

<ul>
<li><p><em>National debt</em> can mean the debt of the national or central government.  This is how it was used for example with the debt the British government built up during the Napoleonic wars, which became the risk-free asset basis of 19th century banking</p></li>
<li><p><em>Government debt</em> can mean the combined debt of different layers of government, so combines national, municipal and other levels</p></li>
<li><p><em>Public debt</em> may include government debt and debt of other parts of the public sector, such as public corporations </p></li>
</ul>

<p>None of these explicitly appear in the balance of payments statistics, especially as most public debt is owed to the domestic private sector.</p>

<p>What does appear is in the international investment position, where all debts (public or private) owed to foreign residents or governments appear as liabilities.  Payments of interest to foreigners count as debits in the primary income part of the current account, while borrowing or repayments of principal are flows in the financial account.   </p>
","14002"
"How to intuitively understand the 'Intuitive criterion'?","4275","","<p>The intuitive criterion by Cho and Kreps is a refinement to minimise the set of perfect Bayesian equilibria in signalling games. What would a simple and intuitive example to explain this criterion be? Assume any undergrad student should be easily able to appreciate the refinement through the example.</p>
","<p>A concise, completely informal way of putting it is this: The intuitive criterion rules-out any out-of-equilibrium beliefs that can only be correct if some player did something stupid.</p>

<p>Below is a slightly more long-winded explanation with an informal example.</p>

<hr>

<p>In many signalling games (that is, games in which one player—the sender—can communicate information to another—the receiver), there are often a lot of implausible equilibria. This happens because the Perfect Bayesian solution concept does not specify what the receiver's beliefs must be when the sender deviates; we can therefore support a lot of equilibria simply by saying that if the sender deviates from those equilibria then he will be ""punished"" with very bad beliefs. Such punishment will usually be enough to make the sender play a strategy that would otherwise not be a best response.</p>

<p>For example, in <a href=""http://staff.bath.ac.uk/ecsjgs/Teaching/Advanced%20Microeconomics/Articles/spence.pdf"">Spence's classic job market signalling paper</a> there is an equilibrium in which high-ability individuals invest in education (learning is easy for them) whilst low-ability individuals do not (because they find it too costly to do so). Education is then a signal of ability. We might ask: is there also an equilibrium of this game in which nobody chooses to get an education and no information is transmitted to the receiver? The answer is 'yes'. We can support such an equilibrium by saying that a deviation in which a sender is educated causes the receiver to adopt the belief that the sender is certainly low-ability. If education has the effect of signalling low-ability then, of course, everyone is happy to play along with the putative equilibrium and not get educated.</p>

<p>It is also clear that this equilibrium is not very plausible: the receiver knows that it is less costly for a high-ability agent to get an education than a low-ability one, so it doesn't make much sense for him to think of an education as signalling low-ability. The intuitive criterion rules out this kind of equilibrium by requiring beliefs to be ""reasonable"" in the following sense:</p>

<blockquote>
  <p>Suppose the receiver observes a deviation from the equilibrium. The receiver should not believe that the sender is of type $t_{\text{bad}}$ if both of the following are true:</p>
  
  <ol>
  <li>the deviation would result in
  type $t_{\text{bad}}$ being worse off then if he has stuck to the equilibrium for any beliefs.</li>
  <li>there is some type $t_{\text{good}}$ who is better off by playing the deviation than by sticking to the equilibrium for some belief other than $t_{\text{bad}}$.</li>
  </ol>
</blockquote>

<p>Returning to the education signalling model: Suppose that the equilibrium is that nobody gets an education and that the receiver believes that a deviation to getting education signals low ability. Anticipating these beliefs, a low ability worker is made worse-off by deviating because he not only incurs the cost of the education but is then thought of as a bad type as a result. Thus, condition 1. is satisfied.</p>

<p>Can we find some alternative belief such that the high-ability worker <em>would</em> like to deviate to getting education? The answer is yes: if the receiver believes that education signals high ability then this deviation is indeed profitable for the high-type. Thus, condition 2 is also satisfied.</p>

<p>Since both conditions are satisfied, the intuitive criterion rules-out the implausible pooling equilibrium.</p>
","227"
"What is a substitute/complement in terms of mixed partial derivatives?","4272","","<p>I am trying to understand how substitutability relates to mixed partial derivatives. I thought the change in marginal utility with respect to a change in the amount of $x$ would correspond to $$\frac{\partial U}{\partial x}$$ so I got confused when I take the partial of that with respect to $y$. Does this measure the rate MU changes wrt $x$ as we change $y$? How is that related to being a substitute? </p>
","<p>It is very important here to note that there are multiple, mutually inconsistent, possibilities for how to define a substitute/complement.</p>

<p>One way is to say that $x$ and $y$ are complements if an increase in $y$ raises the marginal utility of $x$ (or, given symmetry of mixed partials, vice versa):
$$\frac{\partial^2 U}{\partial x\partial y}&gt;0\tag{1}$$This is the suggestion in foobar's answer.</p>

<p>Another way is to say that $x$ and $y$ are complements if a decrease in the price of $y$ raises the Hicksian (aka compensated) demand for $x$. Since Hicksian demand is the derivative of the cost (aka expenditure) function by <a href=""http://en.wikipedia.org/wiki/Shephard%27s_lemma"">Shephard's lemma</a>, this can also be expressed as a condition on mixed partials:
$$\frac{\partial^2 C}{\partial p_x\partial p_y}&lt;0\tag{2}$$
This is the suggestion in snoram's comment, and it is the notion more commonly taught in micro classes.</p>

<p>These definitions are not equivalent! Indeed, in <em>any</em> case with only two goods, those two goods must be substitutes according to (2), regardless of whether the cross-partial of $U$ in (1) is positive or not.</p>

<p>One can give fruitful labels to these concepts (though these labels are more common in the case of production rather than utility functions). Following Hicks, we can call complements by definition (1) <strong>q-complements</strong>: if $x$ and $y$ are q-complements, an increase in the <strong>quantity</strong> of $y$ leads to an increase in the marginal value of $x$. Meanwhile, we can call complements by definition (2) <strong>p-complements</strong>: if $x$ and $y$ are p-complements, a decrease in the <strong>price</strong> of $y$ leads to an increase in the demand for $x$. See, for instance, <a href=""http://www.jstor.org/stable/1059065"">Seidman (1989)</a> for a brief overview.</p>

<p>Both concepts are useful in different situations - it depends on what you're interested in!</p>

<hr>

<p><strong>More technical note:</strong> you might notice that (1) and (2) do not seem very similar to each other: (2) is a <em>compensated</em> concept, keeping us on the same indifference curve, while (1) is not. This is a valid criticism, and indeed there is an alternative notion of ""q-complements"" that is compensated, and a notion of ""p-complements"" that is not. </p>

<p>The compensated notion of q-complements, which is probably more relevant for most consumer theory applications than (1), asks whether the marginal return to $x$ increases as we increase $y$, while staying on the same indifference curve. (It's more relevant for consumer theory because it doesn't depend on the inherently ambiguous cardinality of $U$. Indeed, apparently Hicks introduced this as the consumer-theory definition of ""q-complements"" in his 1956 <em>Revision of Demand Theory</em>, though I don't have a copy of it myself.) This notion also has a mixed partial characterization, in terms of something called the distance function, which is a cool micro theory tool that no one learns anymore; the matrix of mixed partials of the distance function is called the Antonelli matrix, and it is a generalized inverse of the beloved Slutsky matrix. </p>

<p>If we wanted to think about other versions of p-complements, there are several options. One way is to hold income constant, and say that $x$ and $y$ are complementary if a decrease in the price of $y$ increases Marshallian demand for $x$. This is a valid notion (called ""gross"" complementarity rather than ""net""), but it's not very nice because it's not symmetric (due to income effects) and hence doesn't have a mixed partial characterization. </p>

<p>Another, nicer way is to hold <strong>marginal utility of wealth</strong> constant (this is called ""Frisch"" demand, and is the consumer theory analog of profit maximization, which holds price of output constant), and then ask whether a decrease in the price of $y$ leads to an increase in the demand for $x$. This depends on entries in the <em>inverse</em> of the Hessian matrix of mixed partials of $U$, revealing an inverse relationship with (1) (which depends on the Hessian matrix itself) that parallels the inverse relationship noted above between the Antonelli and Slutsky matrices.</p>
","5467"
"What is the advantage and disadvantage to have a high value of USD for USA?","4258","","<p>What is the advantage and disadvantage to have a high value of USD for USA?</p>

<p>China and Japan always want to keep their currency low as oppose to USA.</p>
","<p>When the USD is highly valued, it allows people from the home country, the United States in this case, to purchase goods relatively cheaply from abroad and put pressure on domestic firms to have low prices. From a consumption standpoint, this may be advantageous.</p>

<p>A high value USD may also make goods from the United States more expensive relative to goods from other countries, so the quantity demanded of U.S. goods abroad decreases. </p>

<p>Thus, the high value USD may increase the quantity demanded of foreign goods domestically and reduce the quantity demanded of U.S. produced goods abroad. Together, this <em>can</em>, but not necessarily, have long term consequences on the current account if imports are greater than exports over the long term.</p>

<p>The weak Chinese yuan renminbi allows China to export many goods cheaply and, thus, accumulate a positive current account and become richer relative to the rest of the world. In fact, China's monetary policy has been subject to criticism in the past for actively managing the renminbi's value.</p>
","554"
"Why is the Marginal Cost (MC) of a monopoly horizontal","4252","","<p>I presume it's because they're price makers, but this doesn't really answer much. Furethermore, in a monopoly is it Marginal Cost or Long run marginal cost that's horizontal?</p>

<p><a href=""https://i.stack.imgur.com/Lu1fm.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Lu1fm.gif"" alt=""enter image description here""></a></p>
","<p>That is basically an assumption here. Often in monopoly problems we assume constant marginal costs (i.e. a linear cost function) to keep things simple. In that case the Marginal Cost Curve is horizontal in the graph.</p>
","13936"
"How to interpret ""scale efficiency"" in DEA?","4170","","<p>I am reading the book <a href=""http://rads.stackoverflow.com/amzn/click/1441979603"" rel=""nofollow noreferrer""><em>Benchmarking with DEA, SFA, and R</em> by Bogetoft and Otto</a>. In Section 4.8 they discuss the concept of scale efficiency, and I am having trouble interpreting this concept.  </p>

<p>The usual output of Data Envelopment Analysis (DEA) is a collection of efficiency scores. If we consider the input efficiency scores, then these scores represent the fraction of a firm's current costs which should, in principle, be able to be used to produce a firm's current output. Thus when a firm is judged as inefficient, a reasonable reaction might be to reduce costs and focus on making internal practices more efficient. </p>

<p>When investigating scale efficiency, one compares two different DEA outputs: one using the assumption of constant returns to scale, and the other using varying returns to scale. This expresses whether a firm is operating at it's ""optimal size."" If it is not, then using further comparisons of DEA outputs (using increasing or decreasing returns to scale) it is possible to see whether the firm is ""too large"" or ""too small.""</p>

<p>While the concept of scale efficiency makes sense to me intuitively, I don't see how the practical response to a scale efficiency analysis is any different from the response to the usual DEA efficiency analysis. For example, suppose we do a DEA input efficiency analysis and find that a firm is inefficient. Then the practical response is to reduce the budget and focus on making internal practices efficient. Suppose now instead that a firm is found to be scale inefficient. The practical response again seems to be to reduce costs and focus on making internal practices more efficient... but what exactly are the proposed gains? With the original DEA analysis we had some estimate of how much we could reduce costs and keep the same level of production. But with a scale efficiency analysis, how much production should expect to keep up given the reduction in the size? Should we expect a proportional reduction in production as well? If so, what is the advantage of downsizing?</p>

<p>Finally, there is the somewhat more confusing case (whose interpretation may help me to make sense of all this) where a firm is judged to be maximally input efficient (i.e. is assigned a score of 1 by the DEA) but is not scale efficient. What is the practical response to this case?</p>

<p>Cross posted at Cross Validated: <a href=""https://stats.stackexchange.com/questions/144554/how-to-interpret-scale-efficiency-in-dea"">https://stats.stackexchange.com/questions/144554/how-to-interpret-scale-efficiency-in-dea</a></p>
","<p>First of all, let me tell you that you're doing great. I remember that, being a non-parametric method, it was more difficult for me to understand even the simplest things of DEA.</p>

<p>Now, your interpretation of DEA is correct. When a firm is considered inefficient, it is because it could have gotten the same output but with a lower cost if it had used the best practices. Nonetheless, there is another way of looking at it (the output oriented way): if the firm adopts better practices the output will be increased with the same costs. Keep that in mind.</p>

<p>To explain the scale efficiency, i'm gonna build a very simple case. Imagine a firm that manufactures some product (<em>y</em>) and uses only labor as an input (<em>x</em>) and both the product price and the wage are $1 (for easier calculation). This firm has 4 plants: <em>a</em>, <em>b</em>, <em>c</em>, and <em>d</em>. Table 1, shows the number of workers, production, profit and productivity of the 4 plants.</p>

<p><img src=""https://i.stack.imgur.com/ElLyk.png"" alt=""Table 1""><br>
Table 1 </p>

<p>It is clear, that plant <em>a</em> is the least productive of them, because every worker produces only 1 unit. Plant <em>b</em> <strong>produces the same as <em>a</em> with less workers.</strong> <em>c</em>, on the other hand, has <strong>the same number of workers as <em>a</em></strong>, but with more production and it is the most productive plant(2.5 units per worker). <em>d</em> is the biggest plant producing 29 units.</p>

<p>Now, let's calculate both the Constant Returns to Scale (CRS) efficiency and the Variable Returns to Scale (VRS) efficiency and the scale efficiency:</p>

<p><img src=""https://i.stack.imgur.com/BnxBA.png"" alt=""Table 2""><br>
Table 2</p>

<p>Now, let's plot what it looks like:</p>

<p><img src=""https://i.stack.imgur.com/iZgKF.png"" alt=""Figure 1""><br>
Figure 1</p>

<p>Where every point represents a plant, the black dotted line is the CRS efficiency frontier and the blue line is the VRS efficiency frontier. This blue line implies that <em>b</em>, <em>c</em>, and <em>d</em> are as efficient as they can be. That is, they already have the best practices. The only difference in their productivity is due to <em>economies of scale</em>. Now, if you were to decide the future of <em>a</em>, the least efficient plant, what can you do? you have two options: </p>

<ol>
<li>Fire some people keeping production constant: move to <em>b</em>.</li>
<li>Increase production keeping all the workers: move to <em>c</em>.</li>
</ol>

<p>You should be aware by now that the smart move is to increase the production without getting rid of anyone (move to <em>c</em>). So far, this is the usual DEA analysis. </p>

<p>But now, let's forget about <em>a</em>. Let's see what we can do to increase the profitability of <em>b</em>. <em>b</em> is already in the efficiency frontier of VRS DEA. This means that <em>b</em> is already using the best practices. Nonetheless, <em>because of economies of scale</em> it is impossible to achieve the same productivity. So, the smart move, would be to invest \$5 hiring 5 new workers: <strong>move to <em>c</em> in Figure 1</strong>. Note that <em>b</em> is not adopting efficiency measures this time: <em>it's just increasing the scale, while maintaining the best practices it already has</em>. This investment would be profitable indeed: we hire 5 new workers and production goes from 10 up to 25, which represents an increase in profits of \$$10=\$15-\$5$. Put in other words, for every \$1 we got \$2 return. Not bad!</p>

<p><strong>But wait a second</strong>... We already have 5 extra workers in <em>d</em>! What would happen if we just move workers from <em>d</em> to <em>b</em>? Now the three firms would have \$15 profit, leaving a total profit of \$50 <em>without investing a single penny</em>! The profit increased by 47.05% just by <strong>adjusting scales</strong>.</p>

<p>Now, what role did the scale efficiency measure of DEA played here? Take a look back to Table 2 and divide <em>b</em>'s productivity by <em>b</em>'s scale efficiency $2/0.8=2.5$ which is <em>c</em>'s productivity. Repeat this procedure with <em>d</em>: $1.93/0.77333=2.5$. So you can say that <em>b</em> is achieving 80% of the <em>optimal scale efficiency</em>, while <em>d</em> achieves 77.33% of it. </p>

<p>I have to make a remark: note that both <em>b</em>'s and <em>d</em>'s scale efficiency have a positive sign, but one has to increase its scale while the other has to reduce it. In this sense, the analysis is kind of blind, but you have other tests to know whether it's <em>increasing</em> returns to scale or <em>decreasing</em> returns to scale. </p>
","5071"
"Fixed vs pegged exchange rate: What's the difference (if any)?","4163","","<p>I am told very firmly by an economist that a pegged exchange rate is NOT the same thing as a fixed exchange rate. So what, if any, is the difference between the two?</p>

<p>Addendum: Here's one <a href=""http://www.investopedia.com/exam-guide/cfa-level-1/global-economic-analysis/fixed-pegged-exchange.asp"" rel=""nofollow"">webpage</a> about the difference. I am looking for simple explanation of the difference and ideally also some good and simple contrasting examples.</p>

<p>Add2: Robert Mundell has a lengthy classification <a href=""http://policyoptions.irpp.org/issues/one-world-one-money/one-world-one-money/"" rel=""nofollow"">here</a>, but it seems to me that his distinction is not one of kind, but merely one of degree. </p>
","<p>As Jason Nichols says, these terms are often used interchangeably. </p>

<p>The general theme is that pretty much anything can be called a ""peg"" (except perhaps the case where two countries are literally using the same currency), while ""fixed"" tends to refer to institutional arrangements that are more automatic, where changes in the exchange rate are perceived to be less likely. ""Peg"" tends to be used when some entity (e.g. a central bank) is doing the ""pegging""; the more active and less automatic the behavior of this entity is, the more likely that you'll call the arrangement a ""peg"".</p>

<p>To further explain the (inconsistent and informal) differences in usage that do seem to exist, I have to describe several different kinds of exchange rate regimes. </p>

<ol>
<li>At one extreme, country A may use the same currency as country B. Relevant cases include the Euro Area and dollarized Western Hemisphere countries like Panama and Ecuador. In this case, we might say that A and B have a ""fixed"" exchange rate (at one to one), but we probably wouldn't say that their rate is ""pegged"". A similar but less certain case would be, for instance, the CFA Franc in Africa, which is in principle distinct from the Euro but has a fixed Euro conversion rate and is guaranteed by the government of a country using the Euro (France). This might be called ""fixed"" or ""pegged"".</li>
<li>A less extreme situation is a currency board, where country A has a different currency than country B but promises to always convert them at a certain rate, and has reserves denominated in country B's currency backing up every unit of its own currency so that (in principle) this promise can always be fulfilled. Examples include Argentina's defunct currency board (a good example of a case where this promise was ultimately not fulfilled in practice) and Hong Kong's current currency board. I've seen both ""fixed"" and ""pegged"" used to describe such arrangements; as mentioned above, my sense is that ""peg"" is more common as a descriptor when the arrangement is perceived as being less automatic, with its permanence less certain.</li>
<li>Still weaker is the situation where country A sets a certain exchange rate with country B but doesn't have a formal arrangement like a currency board to back it up. This is extremely common; one rare example among developed countries is Denmark, which pegs to the Euro. This is the last case among (1)-(3) that can still often be called a ""fixed"" rate or a ""peg"". The line between this and a currency board in (2) is often blurry, since in this case too central banks often maintain large foreign reserves, perhaps enough to back up every unit of their currency outstanding; but usually this case involves a less universal guarantee of convertibility.</li>
<li>Then there is a vast set of arrangements where the rate is not perceived as being truly fixed for the indefinite future, but instead is allowed to fluctuate within a moderate or large band, or is subject to a ""crawling"" peg that is adjusted by the central bank, or is pegged to a possibly malleable basket of currencies, etc. These arrangements are usually called ""pegs"" rather than ""fixed"", because (after all) they aren't that fixed! A conspicuous modern example is China.</li>
<li>There are even looser arrangements where a central bank floats the currency but pays some attention to exchange rates and wants to avoid fluctuations that are too large (rather than exclusively hewing to some domestic objective like an inflation target), using both the tools of domestic monetary policy (interest rates) and intervention in foreign exchange markets to keep exchange rates in line. This is usually described as a ""managed"" float, ""dirty"" float, or something similar; it would rarely be described as a peg, but sometimes the line between (4) and (5) can be blurry.</li>
<li>Then at the extreme other end, we have countries that float their currencies and do not routinely intervene in foreign exchange markets. These arrangements would never be called either ""fixed"" or ""pegged"".</li>
</ol>

<p>To sum up, my overall impression is that it's pretty vague, but that among 1 to 6 above, you're more likely to call something earlier in the list ""fixed"", something more in the middle of the list a ""peg"", and something later in the list a ""float"". But I am not aware of any formal, clearly specified distinction between terms as general as ""fixed"" and ""peg"". When exchange rates are classified, as in the <a href=""https://www.imf.org/external/pubs/nft/2013/areaers/ar2013.pdf"">IMF's annual report on the topic</a>, this is usually done in a much more specific and descriptive way.</p>
","1649"
"What has caused the recent 25% unemployment rate in Spain?","4156","","<p><a href=""http://www.tradingeconomics.com/spain/unemployment-rate"">The unemployment rate in Spain has recently been fluctuating around 25%.</a></p>

<p>What has caused this?</p>
","<p>Here's an explanation from Paul Krugman. You can read more about this in Krugman's book <em>End This Depression Now!</em>. </p>

<hr>

<p>Since joining the Euro, Spain <a href=""http://www.tradingeconomics.com/spain/private-capital-flows-total-percent-of-gdp-wb-data.html"">has experience large capital inflows</a>—money flowing into Spain, mostly from Northern Europe. These inflows <a href=""http://krugman.blogs.nytimes.com/2009/03/14/spanish-doldrums/"">caused a boom in investment</a>, coupled with an increase in prices of virtually everything (including labor) relative to other Eurozone countries.</p>

<p>One consequence of this is that the recession in Spain has been exacerbated by the fact that high costs of production (especially high labor costs) made the Spanish economy less competitive so that the country wasn't able to rely on exports to substitute for the reduced domestic demand.</p>

<p>In order to remedy this situation, Spain needs to become more competitive (i.e. for labor costs to fall relative to those in other countries). Normally, this would happen automatically: as a country exports less, demand for its currency from importers (and hence the currency's value) falls so that its products become cheaper for foreigners. However, the fact that Spain is in the Eurozone means that it can't devalue its currency—it doesn't have one of its own!</p>

<p>Instead, Spain must rely on 'internal devaluation', i.e. reducing the wages of its workers relative to those elsewhere in the Eurozone. This is problematic because workers are typically reluctant to accept a pay cut (so-called downward nominal rigidities). Thus, the way that the economy adjusts is to have a sufficiently large share of the workforce unemployed that people are prepared to accept jobs on significantly lower wage than they might have expected in the pre-recession years.</p>

<p>It should be noted that this line of reasoning is not without controversy. For one, a significant share of macroeconomists do not believe the nominal rigidities story.</p>
","1809"
"If all quantities produced rise by 10 percent, and all prices fall by 10 percent, which of the following occurs?","4054","","<p>I am having a hard time deciding for this question:</p>

<p>If all quantities produced rise by 10 percent, and all prices fall by 10 percent, which of the following occurs?</p>

<p>A) Real GDP rises by 10 percent, while nominal GDP falls by 10 percent.</p>

<p>B) Real GDP rises by 10 percent, while nominal GDP is unchanged.</p>

<p>C) Real GDP is unchanged, while nominal GDP rises by 10 percent.</p>

<p>D) Real GDP is unchanged, while nominal GDP falls by 10 percent.</p>

<p>I think it is either A or B, because I know that real GDP rises but i'm not sure what happens to the nominal GDP. if anyone can help, it would be much appreciated.</p>
","<p>It helps to write out things as (simple but) proper equations. Denote production as $Y$ and prices as $P$</p>

<p>It is given that</p>

<p>$$Y_{t+1} = 1.1 Y_t \\
P_{t+1} = 0.9 P_t$$</p>

<p>Nominal GDP is given by $P_t Y_t$</p>

<p>$$ P_{t+1}Y_{t+1} = 1.1 Y_t \cdot 0.9 P_t  \\
= 1.1\cdot 0.9 \cdot Y_t P_t$$</p>

<p>So nominal GDP changed by $1.1 \cdot 0.9 = 0.99$ - it dropped by one percent. </p>

<h3>So which answer is it?</h3>

<p>I assumed that the initial value is base value for the description of the relative changes. If, instead, we have that the larger value is base for the relative change, </p>

<p>$$0.9 Y_{t+1} = Y_t \\
P_{t+1} = 0.9 P_t$$</p>

<p>we get that 
$$ P_{t+1}Y_{t+1} = \frac{1}{0.9} Y_t \cdot 0.9 P_t = Y_t P_t  $$</p>

<ul>
<li>nominal GDP does not change.</li>
</ul>
","4583"
"Are Cobb Douglas goods complements or substitutes?","4022","","<p>Given 
$$U(x,y)= x^\alpha y^{1-\alpha}$$
$\alpha \in (0,1)$, 
are Cobb Douglas goods (here $x$ and $y$) complements, substitutes, or neither? Why? </p>

<p>An explanation with mixed partial derivatives would be great. My calculus is better than my economics skills. </p>
","<p>Start with the more general CES function  $U=[a*x^b+(1-a)*y^b]^{1/b}$. Compute the elasticity of substitution of this function. Then compute the functional form of U for $b=0$,$b=1$ and $b=-\infty$. You will find the two extreme (perfect complements / substitute) cases for CES, and the common case C-D for b=0.</p>
","5336"
"Right definition of natural rate of unemployment?","3926","","<p>Earlier I studied macroeconomics from Blanchard. But now while reading Mankiw's Macroeconomics I found different definition for natural rate of unemployment. According to Blanchard,</p>

<p><strong>""the rate of unemployment (and by implication the level of output) that prevails if the price level and the expected price level are equal.""</strong> (pg. 135, sixth edition) and</p>

<p><strong>""The natural rate of unemployment is the rate of unemployment required to keep the inflation rate constant.""</strong> (pg. 170, sixth edition)</p>

<p>But according to Mankiw,</p>

<p><strong>""The natural rate is the rate of unemployment toward which the economy gravitates in the long run, given all the labor-market imperfections that impede workers from instantly finding jobs.""</strong>(pg. 177. eighth edition),<strong>i.e., where unemployment rate reaches steady-state, it neither increases or decreases, where rate of job finding is equal to rate of job separation.</strong></p>

<p>What is the common ground between all these definitions? Are they different or essentially the same? If so, then how?</p>
","<p><strong>Mankiw's definition</strong> alludes to a situation where the <em>only</em> source of unemployment is frictions and imperfections in the labor/human capital market (you could also add inherent rigidities like ""specificity"" of labor/human capital,  which is the price to pay for specialization). But also, in ""imperfections"" Mankiw may also include ""wage rigidities"".<br>
We could say that this is the ""micro"" approach, focused on the special characteristics of the labor/human capital market.  </p>

<p><strong>Blanchard's 1st definition</strong> on the other hand is more ""macroeconomic"": it is a perfect-foresight equilibrium state (or maybe a self-fulfilled one). It indirectly says that, whenever (i.e. always) expectations and forecasts on the <em>nominal</em> magnitudes are not perfect, the <em>real</em> magnitudes of the economy do not come out exactly as expected, creating variations in, among other things, the unemployment rate. But when we have such an ideal state of perfect foresight, even temporarily, the unemployment observed will be the ""natural rate"". Blanchard does not go into <em>why</em> this ""natural rate"" is <em>not</em> zero (presumably, he has in mind the ""micro-"" approach as an explanation).</p>

<p>So we could say that Mankiw describes the ""natural rate"" as the rate due to causes over and beyond expectational disequilibrium on nominal magnitudes. On the other hand, Blanchard identifies the natural rate as -...exactly, the rate that will prevail in the absence of expectational disequilibrium on nominal magnitudes (he just doesn't state what other causes create unemployment). </p>

<p>Blanchard second definition is the NAIRU concept clearly explained in @BKay's answer.</p>
","5223"
"Nash Equilibrium and Pareto efficiency","3839","","<p>What is the difference between Nash equilibrium and Pareto Efficiency. Can you give me an example where Nash equilibrium is not Pareto Optimal?</p>
","<p>Nash Equilibrium (N.E) is a general solution concept in Game Theory. N.E is a state of game when any player does not want to deviate from the strategy she is playing because she cannot do so profitably. So, no players wants to deviate from the strategy that they are playing given that others don't change their strategy. Thus, it is a mutually enforcing kind of strategy profile. </p>

<p>'Pareto optimality' is an efficiency concept. So no state will be Pareto Optimal if, at least one of the players can get more payoff without decreasing the payoff of any other player. There are many many examples of Nash Equilibria which are not pareto optimal. The most famous example could be the N.E in prisoner's dilemma. </p>
","14550"
"Is the Occupy Wall Street famous 1% stable?","3679","","<p>Occupy Wall Street has a famous slogan ""we are the 99%"", refering to the ""fact"" that 1% of the people in the US take nearly the quarter of the national income.  However, this does not seem to consider that many people with extreme incomes have very variables revenues and have to borrow a lot from the private sector to finance their source of revenue, and that this revenue is unstable.  Are there any studies/data confirming that the 1% that has nearly 25% of the national income is in fact nearly composed of the same people year after year?  Any data that considers ""permanent income"" instead of ""annual income""?</p>
","<p>I've not see a strict analysis of the top one percent but I have seen an analysis of the top 400 tax payers, the very highest income taxpayers:</p>

<blockquote>
  <p>Who are the rich? It depends who you ask and when. Since 1992, the IRS
  has tracked the top 400 earners in terms of adjusted gross income—the
  so called fortunate 400. ... Most importantly, this IRS report
  demonstrates there is a lot of income mobility at the top. Of all the
  filers who have made the list since 1992, <strong>73 percent were on the list
  just once. Virtually no one remains on the list for all 18 years</strong>, but
  for privacy concerns the IRS did not report exactly how many did, if
  any. In last year’s report, just 4 people remained on the list for all
  17 years. This suggests that most top earners do not have a portfolio
  of big investments that can be cashed in year after year, but rather
  one big asset, such as a family farm or business or stock, the sale of
  which triggers a capital gain.</p>
</blockquote>

<p><a href=""http://taxfoundation.org/article/fortunate-400"">The Fortunate 400 By William McBride</a></p>

<p>A slightly more targeted answer:</p>

<blockquote>
  <p>Considering those whose information was found in both years,
  approximately half  of taxpayers in the lowest and highest income
  quintiles remained in the same quintiles 20 years later. Nearly
  one-fourth of those in the bottom quintile moved up one quintile,
  while 4.7 percent moved to the top quintile. <strong>About one-fourth of those
  in the top 1 percent were also in the top 1 percent 20 years later,
  but nearly 70 percent remained in the top income decile.</strong> The overall
  results suggest that, while there is considerable persistence among
  observed taxpayers, there is also meaningful movement even within this
  narrow age cohort. Some taxpayers start from the bottom and move to
  the top and vice versa.</p>
</blockquote>

<p><a href=""https://www.law.upenn.edu/live/files/2934-autengeeturner-perspectives-on-mobility-inequality"">NEW PERSPECTIVES ON INCOME MOBILITY AND INEQUALITY</a>
Gerald Auten, Geoffrey Gee, and Nicholas Turner (2013)</p>
","10580"
"Consumer surplus in case of perfectly inelastic demand","3590","","<p>How do we define consumer surplus in the case of perfectly inelastic demand?</p>

<p>This question was inspired by the comments following this <a href=""https://economics.stackexchange.com/a/5841/1601"">answer</a>. For a graph of inelastic demand please also see the linked question.</p>

<p>A motivation for a definition would be that while consumer surplus would be strange in this special case, change in consumer surplus may still be measurable easily with quite reasonable definitions.</p>
","<p>From a purely theoretical perspective, if an <em>individual's</em> demand curve is perfectly inelastic, then her willingness to pay for the good is infinite. NB this also implies that she has an infinite budget. Thus, consumer surplus is well defined: it is the willingness to pay minus the price she pays, so as long as the price is finite her consumer surplus is finite.</p>

<p>In practice, no one has an infinite budget. So if the individual's demand curve is truly perfectly inelastic (i.e. the inverse demand is vertical), there exists a price such that beyond that price she can no longer afford to buy the good. This price is her willingness to pay, so consumer surplus is again well defined: the willingness to pay minus the price.</p>
","7062"
"Why does quantity supplied increase with price in economics?","3525","","<p>The Law of Supply is my worst enemy in economics because I could never truly understand it, and as a result, the stuff I learned after that was built on a weak foundation. The Law of Demand is totally different though, it makes perfect sense to me. I have spent hours thinking about this and I've figured out exactly what I don't understand. </p>

<p>The Law of Supply would make perfect sense to me if price was substituted with revenue. With each good supplied, revenue would increase in a linear manner. However, as I realized, it is not revenue we are dealing with. The way the Law of Supply works, revenue would increase in an exponential manner if we took a supply schedule and multiplied price and quantity for each price level. </p>

<p>I don't understand why price has to increase if quantity increases. Shouldn’t the increase in quantity supplied already generate more revenue to cover the extra costs of production? Why should the price be spiked up to further increase revenue? Why wasn’t the price that high in the first place if the good could be sold like that? </p>

<p>The Law of Supply seems counterintuitive to me in some ways. If you have only a small amount of something to supply, shouldn't you make the price HIGH so that those rare fools willing to pay for overpriced things (the ones at the top of the demand curve) would clear your stock and maximize your revenue? </p>

<p>One explanation that almost made sense is that the more you tried to produce, the higher the costs of production would get. A producer would have no choice but to raise prices if costs of production were that high. But this only makes sense if costs of production increase EXPONENTIALLY, which I don't understand why would happen with EVERY good! Why is it always assumed that marginal cost is increasing and not remaining constant? </p>

<p>On a side-note: how would the Law of Supply work in the digital realm, where stock is basically infinite? What would a supply and demand graph look like there? </p>

<p>On a side-side-note: why are the supply and demand graphs really considered CURVES when they are almost always represented by lines? </p>

<p>Maybe there's something fundamentally wrong about my understanding of this. It's supposed to be easy to understand, but for me it's not. I would be so grateful if someone could clear this up for me! </p>
","<p>Not all (current and potential) production has the same costs.</p>

<p>Some production has very low additional cost: maybe all the factories and workforce are already in place, they're close to where the product is sold, and it's very little effort to start production and get new product to market. Other production has higher costs.</p>

<p>When the price is very low, then in general only the lowest-cost production will happen, as any other production would generate a loss, not a profit.</p>

<p>As the price rises, then additional forms of production become profitable. It becomes worthwhile for new investors to move into the sector, and for workers to re-train into that industry, for new factories to get built even on more expensive land, and so on and on.</p>

<p>So, when the price is high, all the lowest-cost production happens, as before. AND lots of the higher-cost production happens, too. So the quantity supplied, increases.</p>

<p>In a well-functioning market, no one is a price-setter - no supplier, no demander; the price arises automatically from the collective responses of all of the participants. So if a producer has only a small quantity to sell, they can't just set a high price, and reap excess profits. If they tried to do that, then someone else would see the excess profits on offer, and go in and undercut the incumbent supplier, driving them out of business. Sometimes, we do see cases where a supplier can set an excessively high price. Then, either new investors do indeed come in, maybe after a year or two; or the industry gets investigated for anti-competitive practices, and measures are taken to restore the market's competitiveness.</p>

<p>It's important to remember that this happens in theory <strong>and in practice</strong>. It's been observed countless times over many centuries, for just about every product and service that has a functioning market.</p>
","12828"
"What does it mean when a bank is ""fully loaned up""?","3409","","<p>Please briefly explain the situation when a bank is ""fully loaned up"".</p>
","<p>The reserve requirement on deposits ensures that (for a given $reserve\ requirement(\%)$ and $deposits(\$)$): $$loans(\$) \leq deposits(\$)  \cdot (1 - reserve\ requirement(\%))$$
Fully loaned up means that this holds with equality: 
$$ loans(\$) =  deposits(\$)  \cdot (1 - reserve\ requirement(\%)) $$</p>
","3417"
"What is ""Stated-capital""?","3406","","<p>What is <strong>Stated Capital</strong>? I have found some definitions on the Google, but I have not been able to comprehend it from this definitions. Could somebody explain it to me? </p>
","<p>""Stated Capital"" is the <em>nominal</em> value (or ""par"" value) of all the outstanding shares of a company.  </p>

<p>When a company issues shares each has a nominal price, say EUR $1.00$. But of course they may be sold for more (as far as I know, it is forbidden to issue a share and receive an amount less than its nominal value. Afterwards of course, the share of a company may be re-sold for less than its nominal value -but not when it is issued originally).  </p>

<p>If it is sold for more, say EUR $1.50$, then the EUR $1.00$ is designated and presented as ""Shareholder's Capital"" in a specific line in the financial statements (usually the first line of Equity), while the ""above par"" value, the remaining EUR $0.50$, goes into another Equity line.</p>
","5160"
"No Ponzi game condition and transversality condition are the same?","3402","","<p>Given the following non-stochastic planning problem with finite horizon, 
\begin{align}
&amp;\max_{\{k_{t+1}\}}\sum^T_{t=0}\beta^tU[f(k_t-k_{t+1})] \\
\text{s.t. } &amp; 0\leq k_{t+1}\leq f(k_t)\\
&amp; k_0 &gt;0 \text{ (given)}.
\end{align}
I found that in order to make the first order conditions necessary and sufficient I have to add the so called <strong>no Ponzi game condition</strong>, i.e. 
\begin{gather}
\lim_{T \rightarrow \infty} \frac{k_{T+1}}{R_{T+1}} \geq 0
\end{gather}</p>

<p>When written with the equal sign, this condition can be interpreted as the willingness of not keeping any capital at the end of life. And this is the same interpretation of the so called <strong>transversality condition</strong>. </p>

<p>Thus, is it right to interpret the no Ponzi game condition as a finite horizon version of the transversality condition? If not, which is the difference between them?</p>
","<blockquote>
  <p><em>Is it right to interpret the no Ponzi game condition as a finite
  horizon version of the transversality condition?</em></p>
</blockquote>

<p>No. The ""No-Ponzi-Game"" or ""solvency"" condition is an <em>external constraint</em> imposed on the individual by the market/other participants. The individual would very much like to violate it.</p>

<p>The Transversality condition must be satisfied in order for the individual to maximize indeed its intertemporal utility. It is an <em>optimization condition</em>.</p>

<p>So they are conceptually very different aspects of the problem.</p>

<p>Finally the No-ponzi-game/solvency condition is not inherently of finite horizon -it extends to the infinite horizon also.</p>
","13681"
"Why is the income effect zero for quasilinear utility functions?","3351","","<p>Suppose I have the utility function $$U(x,y) = \sqrt{x} + y$$
subject to budget constraint 
$$p_x x + p_y y = m$$
Then 
$$x_M =\frac{p_y^2}{4 p_x^2}$$ 
$$y_M = \frac{m}{p_y} - \frac{p_y}{4 p_x}$$</p>

<p>where $M$ denotes Marshallian. </p>

<p>Now suppose I increase $p_x$ to $p_x'$. </p>

<p>Why is the income effect zero? </p>
","<p>From the formula for $x_M$, we see it has no dependence on income $m$. So $$\frac{\partial x_M}{\partial m} =0$$ Thus, the Slutsky equation </p>

<p>$$\frac{\partial x_M}{\partial p_x} = \frac{\partial x_H}{\partial p_x} +-\frac{\partial x_M}{\partial m}x_M$$</p>

<p>implies </p>

<p>$$\frac{\partial x_M}{\partial p_x} = \frac{\partial x_H}{\partial p_x} +(0)x_M $$
$$\frac{\partial x_M}{\partial p_x} = \frac{\partial x_H}{\partial p_x}  $$
Hence, and since $-\frac{\partial x_M}{\partial m}x_M$ is the income effect, this implies the income effect is zero and all the change is due to the substitution effect. </p>
","5961"
"How does an import quota affect the demand / supply of currency?","3317","","<p>An import quota in an open economy might not have the desired affect of increasing the GDP as it increases the demand of domestic currency in the open market raising exchange rate. How does it happen that import quota causes demand to shift positively ?</p>
","<p>The goal of import quotas is to get people to buy domestic goods, which can only be bought for local currency. Therefore import quotas increase demand for local currency. But...</p>

<p>Setting import quotas is a very undesirable economic policy. It is basically a state intrusion into a market economy. Quotas for imports are usually implemented as a desperate measure when there is a continuously negative trade balance, local currency rapidly loses value, and every other measure (increasing taxes, customs, subsidizing exporters, etc.) failed. Distribution of quotas usually involves plenty of corruption. On top of that, World Trade Organization does not normally allow import quotas. </p>

<p>The more common use of import quotas is in agriculture, to support local farmers or production of a certain crop. But such limited use of import quotas should have very limited effect on the currency, unless it is a 'banana republic' where agriculture is the main economic activity.</p>
","9608"
"Concave production function implies convex cost function","3290","","<p>Let's assume we have an increasing production function $f:\mathbb{R^+} \to \mathbb{R^+}$</p>

<p>Now, assume this production function is concave and that the price of input z is fixed (this is a single-input and single output case). I want to show this implies the corresponding cost function $C^f(w,q)$ is convex. </p>

<p>My thoughts: </p>

<p>let $z,z' \in \mathbb{R^+}$ where W.L.O.G $z'&gt;z$ and let $f(z)=q$ and $f(z')=q$</p>

<p>Since $f$ is concave, we take $\alpha \in [0,1]$  $s.t$:</p>

<p>$$f(\alpha z +(1- \alpha)z') \geq \alpha f(z) +(1- \alpha)f(z')$$ </p>

<p>let $\alpha z +(1- \alpha)z'=z''\in \mathbb{R^+}$ where by necessity $z\leq z'' \leq z'$ </p>

<p>Since cost of $z=w$ is fixed at some $w \in \mathbb{R^+}$</p>

<p>we can rewrite our cost function as $C^f(q)$ which is convex if for $\alpha \in [0,1]$:</p>

<p>$$C(\alpha q +(1- \alpha)q') \leq \alpha c(q) +(1- \alpha)c(q')$$</p>

<p>Now, since $f$ is concave, it cannot be the case that $f$ experiences increasing returns to scale. Then $f$ has constant returns to scale or diminishing returns to scale. </p>

<p>Then:</p>

<p>Since $z''$ is clearly feasible then we have that:</p>

<p>$$C(w,q'') \leq w*z''$$ 
$$=\alpha w*z + (1- \alpha) w*z'$$
$$= \alpha c(w,q) + (1- \alpha) c(w,q')$$ </p>

<p>Does this look correct? </p>
","<p>Given the fixed input price $w$, the cost function can be written as
$$
C(q)=f^{-1}(q)\times w
$$
where $f^{-1}$ is the inverse of the production function $f$. From the discussion <a href=""https://proofwiki.org/wiki/Inverse_of_Strictly_Increasing_Convex_Real_Function_is_Concave"" rel=""nofollow noreferrer"">here</a>, one can conclude that the inverse of a concave strictly increasing function is convex. Thus, $C(q)$ is convex as well. </p>

<p>Going back to your approach, you might like to have this clearly stated. Let $q''=\alpha q + (1-\alpha)q'$, $f(z)=q$, $f(z')=q'$, and $f(z'')=q''$ Then 
$$
\begin{align}
f(z'')&amp;=&amp;q''\\
&amp;=&amp;(\alpha q + (1-\alpha)q')\\
&amp;=&amp;\alpha f(z)+(1-\alpha) f(z')\\
&amp;\leq&amp;f(\alpha z +(1-\alpha z'))
\end{align}
$$
Then $f(z'')\leq f(\alpha z +(1-\alpha z'))$ implying that $\alpha z +(1-\alpha z')\geq z''$ since $f$ is (strictly) increasing. Hence, 
$$
z''w=C(q'')\leq \alpha C(q)+ (1-\alpha) C(q')
$$</p>
","8610"
"What is the difference between the Classical and Keynesian models?","3240","","<p>I have read something about the short and long run aggregate supplies, but I don't know what the <strong>main</strong> difference is about these two models. Does someone know the difference(s) between these two models?</p>
","<p>In the classical model, aggregate supply curve is vertical (price level on the y axis), meaning that output is fixed, constrained by technology and inputs. Prices are flexible. So that if the demand curve changes, the effect will be entirely on price level and not on output.</p>

<p>In the keynesian model, aggregate supply curve is horizontal at some price level. If demand changes, the effect will be entirely on output.</p>

<p>So the main difference lies on price flexibility and the power of increasing output through aggregate demand stimulus.</p>
","6284"
"Two-way clustering in Stata","3183","","<p>I have a panel dataset and I would like to estimate a linear equation in a fixed effects framework. My question is: how should I implement a two-way clustering? Stata syntax and/or .ado file necessary would be greatly appreciated.</p>
","<p>Have you seen <a href=""http://faculty.econ.ucdavis.edu/faculty/dlmiller/statafiles/"" rel=""nofollow noreferrer"">http://faculty.econ.ucdavis.edu/faculty/dlmiller/statafiles/</a> ?</p>

<p>I see some entries there such as <em>Multi-way clustering with OLS</em> and <em>Code for “Robust inference with Multi-way Clustering”</em>.</p>

<p>EDIT: At least we can calculate the two-way clustered covariance matrix (note the <code>nonest</code> option), I think, though I can't verify it for now. See the following.</p>

<pre><code>set more off
clear all
local n 50
local T 50

set obs `=`n'*`T''

gen id = floor((_n-1)/`T')+1
by id, sort: gen year = 1970+_n
xtset id year

set seed 1

gen x = rnormal()
gen y = 1+0.5*x+rnormal()

xtreg y x, re vce(cl id)
mat b = e(b)
mat V1 = e(V)
xtreg y x, re vce(cl year) nonest
mat V2 = e(V)
xtreg y x, re vce(cl id year) nonest
mat V12 = e(V)
mat V = V1+V2-V12
mat l V
ereturn post b V
ereturn display

set more on
</code></pre>

<p>This code has yet to be verified manually.</p>

<p><a href=""https://i.stack.imgur.com/SBlq0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/SBlq0.png"" alt=""enter image description here""></a></p>

<p><strong>EDIT 2</strong>: Sorry for keeping editing. Just found that Stata's <code>reg</code> (for pooled OLS) does not allow for clustering by multiple variables such as <code>vce(cluster id year)</code>. We should use <code>vce(r)</code> or just <code>r</code>. However, it seems that <code>xtreg</code> does (usually requiring <code>nonest</code>), though I counldn't find documentation.</p>
","13812"
"What is an example application of a quasilinear utility function?","3150","","<p>I am told a quasilinear utility function is a function like $$U(x,y) = \sqrt{x}+y$$</p>

<p><strong>My Question:</strong></p>

<p>Can someone provide a real world example of a quasilinear utility function? </p>
","<p>Quasilinear utility functions are useful in much of the demand estimation literature, particularly in discrete choice. For instance, check out <a href=""http://pages.stern.nyu.edu/~rslee/teaching/io/papers.demand/Berry%20%281994%20RAND%29%20-%20Estimating%20Discrete%20Choice%20Models%20of%20Product%20Differentiation.pdf"" rel=""nofollow"">Berry 1994</a>,<a href=""http://pages.stern.nyu.edu/~acollard/BLP.pdf"" rel=""nofollow"">Berry Levinsohn Pakes 1995</a> and the many applications in <a href=""http://pages.stern.nyu.edu/~rslee/teaching/io/papers.demand/Nevo%20%282000%20JEMS%29%20-%20A%20Research%20Assistants%20Guide%20to%20Random%20Coefficients%20Discrete%20Choice%20Models%20of%20Demand.pdf"" rel=""nofollow"">Nevo's papers on demand estimation (here's a ""practicioner's guide"")</a>. Ken Train's book on it is available for free <a href=""http://eml.berkeley.edu/books/choice2.html"" rel=""nofollow"">here!</a></p>

<p>To summarize, they can lead to indirect utility of the form $$u_{ijt}=\alpha_i\underbrace{(y_i-p_i)}_\text{real income}+\underbrace{X{jt}\beta_i}_\text{observed product characteristics$*\beta_i$}+\underbrace{\xi_{jt}}_\text{unobserved product characteristics}+\underbrace{\epsilon_{ijt}}_\text{mean zero stochastic term}$$
where $i$ represents individuals $i=1,\dots,I_t$ in each of the $t=1,\dots,T$ markets selling $j=1,\dots,J$ products. Here, $\alpha_i$ represents the marginal utility of income and $\beta_i$ represents the marginal utility from the product characteristics observed in $X_{jt}$.</p>

<p>Suppose that we restrict the heterogeneity across consumers to only enter through the stochastic term $\epsilon_{ijt}$. Then both the individual specific parameters $(\alpha_i,\beta_i)$ must be equal to $(\alpha,\beta)$ and the market share of each good can be represented by
$$s_{jt}=\frac{exp(X_{jt}\beta-\alpha p_{jt}+\epsilon_{jt})}{1+\Sigma_{k=1}^{J}exp(X_{kt}\beta-\alpha p_{kt}+\xi_{kt})}$$</p>

<p>The equation for the market share is a function of variables that only vary at the product-market level, so you only need information on prices and quantities (and product characteristics) for a crude estimation. However it gives some quirky results. Particularly regarding the elasticity of market share wrt own price and cross price (market share) elasticities, and consumer subsitution patterns. Things can get more robust the more you read on demand estimation, you can introduce consumer characteristics and get results that have more desirable substitution properties. </p>

<p>There are also many criticisms of the conclusions that this type of modeling can draw, but I'll leave that up to you to imagine should you want to read on the topic.</p>
","5472"
"If a GDP deflator is continually greater than 100%, does that mean inflation is still occuring?","3144","","<p>If a GDP deflator is continually greater than 100%, does that mean inflation is still occuring?</p>

<p>If the difference in deflators from year to year is continually greater than 1%, does that mean inflation is occuring at a greater and greater rate? </p>
","<p>No, a deflator greater than 100 means that the price level is higher than in the base year. It doesn't mean that inflation is still occurring. In fact, you could be <strong>experiencing deflation</strong> after a period of inflation and if prices today are still higher than the base year, have the deflator be above 100. A growing deflator is an indication of inflation. To detect inflation acceleration you'd need to see changes in the log(deflator) growing over time. </p>
","5265"
"Why must the rate of GDP growth be positive?","3124","","<p>There are always expectations that GDP should be growing at a certain rate. This is what I see in the newspapers. I am not an economics major and this is a very basic student question. After adjusting for level of prices, meaning that forget about inflation and price related issues, it is expected to grow at say $2\%$. Why is this a case and what should it be driven by? Assume there is an economy that only produces apples, for simplicity. So, it is expected to make $2\%$ more apples every year? So the growth would be driven by the larger amount of goods produced? Why is this economy expected to make more apples every year?  </p>
","<p>You would expect the rate of growth to be generally positive because inventing things or inventing more efficient ways of doing things, is generally a one way process - things don't get un-invented. So we would expect things that are made by machines to be made ever more quickly as the machines evolve and improve. Periods of negative growth are likely to correspond to some financial cock-up (e.g. asset bubbles) or increasing scarcity of some natural resources for which a replacement can not be found.</p>
","14407"
"How can power/electricity prices be negative?","3114","","<p><a href=""https://www.bloomberg.com/news/articles/2017-10-30/record-winds-in-germany-spur-free-electricity-at-weekend-chart"" rel=""noreferrer"">Bloomberg</a> shows this chart:</p>

<p><a href=""https://i.stack.imgur.com/GiYXf.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/GiYXf.png"" alt=""enter image description here""></a></p>

<p>I understand the above chart to mean that consumers were actually paid to use electricity. (Please correct me if I'm mistaken.) </p>

<p>I was wondering how this is possible? How is the power/electricity market special and different from other markets? (Or perhaps the German electricity market is special.)</p>
","<p>Yes, customers who were exposed to day-ahead wholesale market prices were paid to use electricity.</p>

<p>It is a combination of several different factors that make the day-ahead wholesale electricity market special.</p>

<p><strong>Firstly</strong>, very few electricity consumers participate in it directly. So the demand side is very illiquid, with very low short-run elasticity - and it quickly becomes perfectly inelastic.</p>

<p><strong>Secondly</strong>, there's very little time-arbitrage. The market for electricity at 0500 and the market at 1500 are two separate markets: there are very few arbitrageurs who can buy at 0500 and sell at 1500. That's because until recently, there's been very low rewards for doing so (more on this, below).</p>

<p><strong>Thirdly</strong>, there are several suppliers for whom reducing supply would incur expense: so, for market-clearing purposes, they have negative short-run marginal costs. There are two ways that can happen.</p>

<ol>
<li><p>very inflexible conventional generators (usually nuclear) just can't turn their output up and down every hour or two, without incurring maintenance costs.</p></li>
<li><p>generators with contracts that enable them to sell all their output at a pre-specified positive price: they would need wholesale prices to go negative by the more than that amount, to make it worthwhile for them to reduce their output.</p></li>
</ol>

<p>Germany now has such a high combination of those two kinds of generators, that there are times when their combined output is greater than domestic consumption, and that's when prices go negative.</p>

<p><strong>Fourthly</strong>, although Germany shares a grid with many other continental European countries, the opportunities for spatial arbitrage are very limited, because total German generation is much much larger than the interconnection power capacity to the rest of the grid: so that interconnection capacity strictly limits the amount of energy that can be arbitraged with other countries within a given trading hour.</p>

<p><strong>Finally</strong>, though it seems strange, these negative prices are a good thing. They're a temporary condition that will only last for a transition period, as electricity markets decarbonise. At the moment, we've got transmission networks and market structures that were designed for, and built around, excessively-polluting suppliers such as coal and gas. We have to stop that pollution - the cost of it way exceeds the benefits. So, the industry has to change structurally, and markets and networks will have to change too.</p>

<p>Coal- and gas-fuelled generators have been very helpful for in-day markets, because they can rapidly change the amount they supply. So the near-absence of participation from the consumption side hasn't been a problem at all, until recently - and why the rewards for arbitrageurs were low. But now, there is an increasing number of hours when those very flexible generators no longer dominate the market.</p>

<p>As we move to a grid that no longer has that supply-side responsiveness, we need responsiveness from new arbitrageurs, and from the demand-side. Period of negative pricing provide strong incentives for those new market participants to come forwards. And, as more and more of those new participants enter the market, the negative prices will become rarer and rarer.</p>

<p>So this isn't just Germany. It has happened, and will happen, elsewhere too.</p>
","19211"
"Why does the real wage = W/P?","3017","","<p>Im reading about labour markets, and the notes mention that the real wage 'w' = W/P, where W = the nominal wage, and P = the price level. Could someone please use some 'W' and 'P' as an example to show me how real wages emerge from the ratio W/P? </p>

<p>Thanks!</p>
","<p>Whenever we go from nominal to real terms, we need a base year.  As an example, let's use 2016 as the base year.  In the base year, the nominal wage $W$ is always equal to the real wage $w$ (this is true for any price or cost, not just wage).  Also, we always set the price level $P$ equal to 1 in the base year.  That's what makes it the base year.</p>

<p>Anyway, let's say that, in 2016, $w_{2016}=W_{2016}=15$.  Suppose that, between 2016 and 2017, there's 2% inflation - that is, the price level $P$ increases by 2% from $P_{2016}=1$ to $P_{2017}=1.02$.  Then, it follows that the real wage in 2017 will be $w_{2017}=\frac{W_{2016}}{P_{2017}}=\frac{15}{1.02}=14.706$.  I hope this example helped.</p>

<p>In case it didn't, you can think about it like this:  Dividing the nominal wage by the price level is just how you adjust for inflation, thus giving you the real wage.</p>
","12945"
"Why does allocative efficiency occur when P=MC rather than MB=MC","2977","","<p>I understand that allocative efficiency is where the demand curve and supply curve intersect, i.e. where MB=MC as demand and supply can be interpreted as marginal benefit and cost respectively; however, where do we get P=MC from?</p>
","<p>Question: If I set a price of $p$, which consumers will buy the good?</p>

<p>Answer: a consumer will buy the good if and only if his benefit from consuming it is bigger than his cost, $p$, of buying it. This means that the last (i.e. marginal) consumer who buys will be the one for whom the benefit is just equal to the cost. In other words, for any price, $\text{MB}=p$ must hold.</p>

<hr>

<p>For efficiency, we know that we need $\text{MB}=\text{MC}$.</p>

<hr>

<p>Putting these two equations together yields $\text{MB}=\text{MC}=p$.</p>

<hr>

<p>What is going on here? We know (as you pointed out) that  we need $\text{MB}=\text{MC}$ for allocative efficiency. But we can't just go out and tell consumers whether to buy or not. We have to give them the incentive to make the efficient choice on their own. The way this is achieved is by setting the price such that only consumers for whom purchasing is efficient will be willing to buy.</p>
","10779"
"Why teach Arrow's impossibility theorem?","2958","","<p>As part of a Macro class on social welfare, I am about to teach a very brief introduction to Arrow's impossibility theorem.</p>

<p>The classic demonstration of this involves three voters choosing between three alternatives, whose preferences are as follows:</p>

<pre><code>  A B C
1 x y z
2 y z x
3 z x y
</code></pre>

<p>We are then shown the supposedly interesting result that, given these obviously incompatible preferences, no possible voting system can pick a favoured option in a non-arbitrary way.</p>

<p>More generally, any voting system risks ending up in this kind of three-way tie situation.</p>

<p>But this seems impossibly theoretical a concern. Clearly if voters' preferences split <em>n</em> alternatives precisely <em>n</em> ways, as in this example, there's no outcome that satisfies a majority. But in an electorate, the probability of this is vanishingly small. Also, if each alternative is joint first in preference, we surely don't care which one is selected.</p>

<p>Why do we teach this mysterious theorem at all? Is it just because it's got a cool name? Has it ever been usefully applied to a real-world problem?</p>
","<p>I see the important lesson of  the impossibility theorem as establishing that <em>it is not generally speaking possible to have nicely behaved preferences of groups</em>, even if <em>individuals have nicely behaved preferences</em>. Therefore a social welfare function may not exist . Attempts to improve aggregate welfare by maximizing the outcome of a preference aggregation mechanism may result in unfair or irrational outcomes. </p>

<p><a href=""https://www.washingtonpost.com/news/wonk/wp/2013/02/11/the-political-science-of-papal-elections/"">The impossibility theorem was supposedly a major reason for reforms in the papal election process</a>. It also launched important research into if the issues Arrow raised were important for people's actual preferences and institutions. Interestingly, they are for the most common forms of preference aggregation (e.g., see <a href=""http://www.sscnet.ucla.edu/polisci/faculty/lewis/pdf/greenreform9.pdf"">Bush v. Gore. v. Nader</a> or the <a href=""http://www.economist.com/blogs/graphicdetail/2015/05/britain-s-election-2015-seats-votes-calculator"">notorious differences in seats and votes in UK elections</a>). It also shows (along with Condorcet) that agenda control (in what order do we vote on the choices) is a powerful force for determining final outcomes. Finally, it launched research into which aggregation mechanisms were the least bad, seeming to settle on something like <a href=""https://en.wikipedia.org/wiki/Single_transferable_vote"">Single Transferable Vote</a> or <a href=""https://en.wikipedia.org/wiki/Instant-runoff_voting"">Instant Runoff</a> mechanisms in most situations. </p>

<p>But for a more critical overview (with which the authors disagree), see pages 14-15 of <a href=""https://books.google.com/books?id=Vof2AwAAQBAJ&amp;pg=PA14&amp;lpg=PA14&amp;dq=empirical%20least%20bad%20arrow&amp;source=bl&amp;ots=bKvpJzk5w8&amp;sig=qvK5rIErfFncHRubbIIPexnHWIs&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwi_wJPdppjMAhVBKB4KHU7VALAQ6AEIHDAA#v=onepage&amp;q=empirical%20least%20bad%20arrow&amp;f=false"">Social Choice and Legitimacy: The Possibilities of Impossibility</a>.</p>
","11615"
"Determining the Relative Price of Trade","2826","","<p>I'm pretty sound with the concept behind comparative advantage, but still don't get how to calculate the exchange rate in terms of quantities of each products being exchanged, e.g. 1 apple for 2 cars etc.  </p>

<p>Specifically: when two counties, each having two separate comparative advantages in producing two separate goods, wish to exchange these goods, how will the exchange quantity/rate be calculated? </p>
","<p>If I understand correctly the question, the trick to calculate the equilibrium (relative) price of trade in the Ricardian model of comparative advantage is to specify demand once the opportunity costs have been determined. Prices of internationally traded goods, like other prices, are determined by supply and demand.</p>

<p>Consider two countries, two goods (computers and textiles), and given unit labor requirements such that in equilibrium the world price of computers will be between 0.5 and 2 textiles per computers. The opportunity costs define the bounds of equilibrium relative prices of trade (0.5 and 2), while the structure of demand determines <strong>the</strong> equilibrium relative price (p). </p>

<p>For instance, <code>p=1</code> can be an equilibrium price such as one country will specialize in computers and the other in textiles. This price will be determined by the interaction of the relative supply and the relative demand of computers and textiles. This interaction is discussed in the Chapter 3 of <a href=""http://www.pearsonhighered.com/educator/product/International-Economics-Theory-and-Policy-10E/9780133423648.page"" rel=""nofollow"">International Economics: Theory and Policy of Krugman, Obstfeld and Melitz</a>. An interesting video with a concrete example can be found <a href=""https://www.youtube.com/watch?v=xeJIamln9ak"" rel=""nofollow"">here</a>.</p>
","9988"
"What is the importance of Epstein-Zin preferences?","2819","","<p>I've heard that there is a lot of work being done recently that applies Epstein-Zin preferences. The Wikipedia page doesn't seem to be very full. </p>

<ol>
<li>Why are Epstein-Zin preferences important?</li>
<li>How does recursive utility differ from other preference models in general? What do they capture that can't be captured otherwise?</li>
<li>What are some good resources to learn more about them?</li>
</ol>
","<p>I think CompEcon covered most of the points that I was going to mention.  Just a few last thoughts:</p>

<p>1) Why are Epstein-Zin preferences important?</p>

<ul>
<li><p>The preferences are important because they allow you to separate two of the dimensions along which people care about their allocations; namely, risk aversion and intertemporal substitution.</p></li>
<li><p>Additionally, one short coming of standard (i.e. CRRA) is their inability to achieve the Hansen-Jagannathan lower bound for the ratio of the standard devation of the stochastic discount factor to its expected value, $\frac{\sigma(m)}{E(m)}$.  In a 2000 paper (I think his Job Market paper), Tallarini showed that recursive preferences are able to come into the Hansen-Jagannathan bounds at less ridiculous levels of risk aversion (although still not totally feasible risk aversion).</p></li>
</ul>

<p>2) How does recursive utility differ from other preference models in general? What do they capture that can't be captured otherwise?</p>

<ul>
<li><p>It allows you to capture the risk aversion - intertemporal substitution differences.</p></li>
<li><p>They are a more general set of preferences than CRRA.  I'm pretty sure you can actually write CRRA utility using Epstein-Zin preferences with the right parameters.</p></li>
<li><p>Would be interested in hearing if other people know more about this.  I know thy can be have model misspecification interpretations.  Would love to hear more about that.</p></li>
</ul>

<p>3) What are some good resources to learn more about them?</p>

<ul>
<li><p>Like I said earlier in a comment, I have found that Ljungqvist and Sargent provide a pretty good explanation of the main things happening in recursive utility.</p></li>
<li><p>Additionally, the <a href=""http://pages.stern.nyu.edu/~dbackus/Exotic/BRZ%20exotic%20latest.pdf"">paper</a> mentioned by CompEcon in another question earlier is a pretty good resource.  I'm actually working through this right now when I have some spare time.</p></li>
</ul>
","311"
"Outputting Regressions as Table in Python (similar to outreg in stata)?","2811","","<p>Anyone know of a way to get multiple regression outputs (not multivariate regression, literally multiple regressions) in a table indicating which different independent variables were used and what the coefficients / standard errors were, etc. </p>

<p>Essentially, I'm looking for something like outreg, except for python and statsmodels. This seems promising but I don't understand how it works:</p>

<p><a href=""http://statsmodels.sourceforge.net/stable/generated/statsmodels.iolib.summary.Summary.html#statsmodels.iolib.summary.Summary"" rel=""nofollow noreferrer"">http://statsmodels.sourceforge.net/stable/generated/statsmodels.iolib.summary.Summary.html#statsmodels.iolib.summary.Summary</a></p>

<p>To be fully clear here, I wondering how to make tables similar to the example below:</p>

<p><a href=""https://i.stack.imgur.com/vxKCD.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vxKCD.jpg"" alt=""enter image description here""></a></p>
","<p>You can use code like the following (making use of the as_latex function) to output a regression result to a tex file but it doesn't stack them neatly in tabular form the way that <a href=""https://ideas.repec.org/c/boc/bocode/s456416.html"" rel=""nofollow noreferrer"">outreg2</a> does:</p>

<pre><code>import pandas as pd
import statsmodels.formula.api as smf
x = [1, 3, 5, 6, 8, 3, 4, 5, 1, 3, 5, 6, 8, 3, 4, 5, 0, 1, 0, 1, 1, 4, 5, 7]
y = [0, 1, 0, 1, 1, 4, 5, 7,0, 1, 0, 1, 1, 4, 5, 7,0, 1, 0, 1, 1, 4, 5, 7]
d = { ""x"": pd.Series(x), ""y"": pd.Series(y)}
df = pd.DataFrame(d)
mod = smf.ols('y ~ x', data=df)
res = mod.fit()
print(res.summary())

beginningtex = """"""\\documentclass{report}
\\usepackage{booktabs}
\\begin{document}""""""
endtex = ""\end{document}""

f = open('myreg.tex', 'w')
f.write(beginningtex)
f.write(res.summary().as_latex())
f.write(endtex)
f.close()
</code></pre>

<p>The as_latex function makes a valid latex table but not a valid latex document, so I added some additional code above so that it would compile. The result is something like this for the print function:</p>

<pre><code>                        OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.129
Model:                            OLS   Adj. R-squared:                  0.089
Method:                 Least Squares   F-statistic:                     3.257
Date:                Fri, 29 Apr 2016   Prob (F-statistic):             0.0848
Time:                        20:12:12   Log-Likelihood:                -53.868
No. Observations:                  24   AIC:                             111.7
Df Residuals:                      22   BIC:                             114.1
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
Intercept      0.9909      0.908      1.091      0.287        -0.893     2.875
x              0.3732      0.207      1.805      0.085        -0.056     0.802
==============================================================================
Omnibus:                        3.957   Durbin-Watson:                   0.999
Prob(Omnibus):                  0.138   Jarque-Bera (JB):                1.902
Skew:                           0.380   Prob(JB):                        0.386
Kurtosis:                       1.849   Cond. No.                         8.50
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</code></pre>

<p>and like this for the latex:
<a href=""https://i.stack.imgur.com/dz4Ap.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dz4Ap.png"" alt=""enter image description here""></a></p>

<p>Update:
Not as full featured as outreg but the summary_col function does what you ask. </p>

<pre><code>import pandas as pd
import statsmodels.formula.api as smf
from statsmodels.iolib.summary2 import summary_col
x = [1, 3, 5, 6, 8, 3, 4, 5, 1, 3, 5, 6, 8, 3, 4, 5, 0, 1, 0, 1, 1, 4, 5, 7]
y = [0, 1, 0, 1, 1, 4, 5, 7,0, 1, 0, 1, 1, 4, 5, 7,0, 1, 0, 1, 1, 4, 5, 7]
d = { ""x"": pd.Series(x), ""y"": pd.Series(y)}
df = pd.DataFrame(d)
df['xsqr'] = df['x']**2  
mod = smf.ols('y ~ x', data=df)
res = mod.fit()
print(res.summary())
df['xcube'] = df['x']**3  

mod2= smf.ols('y ~ x + xsqr', data=df)
res2 = mod2.fit()
print(res2.summary())

mod3= smf.ols('y ~ x + xsqr + xcube', data=df)
res3 = mod3.fit()
print(res2.summary())

dfoutput = summary_col([res,res2,res3],stars=True)
print(dfoutput)
</code></pre>

<p>Which has the following output:</p>

<pre><code>=====================================
            y I       y II    y III  
-------------------------------------
Intercept 0.9909   -0.6576   -0.2904 
          (0.9083) (1.0816)  (1.3643)
x         0.3732*  1.7776*** 1.0700  
          (0.2068) (0.6236)  (1.6736)
xcube                        -0.0184 
                             (0.0402)
xsqr               -0.1845** 0.0409  
                   (0.0781)  (0.4995)
=====================================
Standard errors in parentheses.
* p&lt;.1, ** p&lt;.05, ***p&lt;.01
</code></pre>

<p>As before, you can use the dfoutput.as_latex() to export this to latex. </p>
","11776"
"Uncovered Interest Parity (UIP) condition approximation","2793","","<p>Until otherwise $e=\frac{\text{Domestic currency}}{\text{Foreign currency}}$.</p>

<p>The UIP condition can be written in the following form: Investing now in a domestic bond, must give the same return as investing in a foreign bond, which means, $1+i_t=e^{-1}_t\left(1+i^*_t\right)e^E_{t+1}$, implying</p>

<p>$$\frac{1+i_t}{1+i^*_t}=\frac{e^E_{t+1}}{e_{t}}=\frac{1}{1+\frac{e_{t}-e^E_{t+1}}{e^E_{t+1}}}$$ where $i_t$ is the domestic nominal interest rate at time t, $i^*_t$ is the foreign nominal interest rate at time t, $e^E_{t+1}$ is the expected exchange rate at time $t+1$.</p>

<p>Using the derivations presented <a href=""https://en.wikipedia.org/wiki/Fisher_equation#Derivation"" rel=""nofollow"">here</a> I get:
$$i_t-i^*_t=-\frac{e_{t}-e^E_{t+1}}{e^E_{t+1}}$$</p>

<p>However, if we define the $e=\frac{\text{Foreign currency}}{\text{Domestic currency}}$, we get $1+i_t=e_t\left(1+i^*_t\right)\left(e^E_{t+1}\right)^{-1}$, and using an analogous reasoning to the above:
$$i_t-i^*_t=-\frac{e^E_{t+1}-e_{t}}{e_{t}}$$</p>

<p>However, this <a href=""https://en.wikipedia.org/wiki/Interest_rate_parity#Approximation"" rel=""nofollow"">wiki link</a> gives(notice the missing minus sign):</p>

<p>$$i_t-i^*_t=\frac{e^E_{t+1}-e_{t}}{e_{t}}$$</p>

<p>It's not the first time I see this last(wiki) approximation being used.</p>

<p>What's the reasoning for this last approximation? are my approximations wrong? I would really like to know the reason for the minus signs to be missing.</p>

<p>Any help would be appreciated. </p>
","<p>From the basic equation you get
\begin{eqnarray*}
\frac{e^E_{t+1}}{e_{t}} &amp; = &amp; \frac{1+i_t}{1+i^*_t} \\
\\
(1+i^*_t) \cdot e^E_{t+1} &amp; = &amp; (1+i_t) \cdot e_t \\
\\
e^E_{t+1} - e_t &amp; = &amp; i_t \cdot e_t - i^*_t \cdot e^E_{t+1}.
\end{eqnarray*}
Now comes the approximation. You divide either by $e_t$ or by $e_{t+1}^E$.</p>

<p>First method
$$
\frac{e^E_{t+1} - e_t}{e_t} = i_t - i^*_t \cdot \frac{e^E_{t+1}}{e_t} \approx
i_t - i^*_t.
$$
Second method
$$
\frac{e^E_{t+1} - e_t}{e^E_{t+1}} = i_t \cdot \frac{e_t}{e^E_{t+1}} - i^*_t  \approx
i_t - i^*_t.
$$
I would say there is no crucial difference, both of these just assume that the proportional change in the exchange rate multiplied by the interest rate is an order of magnitude lower than either the interest rate or the change in the exchange rate alone.</p>
","9869"
"What Level of Government Debt to GDP Ratio is Sustainable?","2784","","<p>I was reading that Japan has a debt to gdp ratio of 240pc and I cannot understand why this has not left the country ""bankrupt""? From looking at this like an ordinary person this level would be completely unmanageable. Furthermore, considering Greece had problems with its national debt with a debt to gdp ratio of less than 200pc I am not sure how Japan has sustained significantly higher ratio for so long? Therefore my question is what makes a certain level of debt to gdp ratio sustainable? Also who does the government owe the debt to and does it matter who they borrow from? ie domestic vs international.</p>

<p>For interest see the following graph,</p>

<p><a href=""https://i.stack.imgur.com/8s0VI.png""><img src=""https://i.stack.imgur.com/8s0VI.png"" alt=""enter image description here""></a></p>
","<p>As you have pointed out: where it comes from is very important. As to the Japanese situation it is quiet different from the US position from example. In fact most of the Japanese debt is owned by Japanese people (90% of the current debt). More specifically the BoJ plays a big role as a buyer, and puts pressure on Japanese yield, which makes it cheaper for the government to issue bonds ! </p>

<p>Another interesting point that is usually left by anlysts: Japan is the biggest creditor in the world. The country holds a net amount of about 3 trillion USD (367 trillion yen) of financial assets through the world, which makes Japan the first creditor worldwide (before China !).</p>

<p>An interesting further reading which gives other information on the Japanese debt under stress tests of the IMF (P.40): <a href=""https://www.imf.org/external/pubs/ft/scr/2015/cr15197.pdf"" rel=""nofollow"">https://www.imf.org/external/pubs/ft/scr/2015/cr15197.pdf</a></p>

<p>You also might want to read this paper of Rogoff and Reinhart called ""<em>Growth in a time of debt</em>"": <a href=""http://www.nber.org/papers/w15639"" rel=""nofollow"">http://www.nber.org/papers/w15639</a> . It was really criticized but is a good first glimpse... Afterwards you might want to go a little bit deeper into the debt sustainability analysis of the IMF...</p>

<h2>Edit</h2>

<ul>
<li>The reference of Rogoff is more an introduction to the comprehension of debt dynamic than an argument for the existence of a threshold than would reduce growth. On the controversy of the paper, like pointed out by @dv_bn, you can check this intersting article: <a href=""http://www.newyorker.com/news/john-cassidy/the-reinhart-and-rogoff-controversy-a-summing-up"" rel=""nofollow"">http://www.newyorker.com/news/john-cassidy/the-reinhart-and-rogoff-controversy-a-summing-up</a></li>
<li>Thanks to @denesp: Whenever you see ""first creditor"" this usually takes public and private assets into account. However, if you want to analyze the public debt you should only take financial assets owned by the government (mostly T-Bills regarding Japan).</li>
<li>I add also an interesting article I have read about it, which was written by economists from the NY FED, check it out: <a href=""http://libertystreeteconomics.newyorkfed.org/2016/06/the-rapidly-changing-nature-of-japans-public-debt.html#.V2qJW2r2aM8"" rel=""nofollow"">http://libertystreeteconomics.newyorkfed.org/2016/06/the-rapidly-changing-nature-of-japans-public-debt.html#.V2qJW2r2aM8</a></li>
</ul>
","11794"
"Why does the European Central Bank use the 5y5y rate to measure inflation","2775","","<p>I cannot understand why the 5y5y swap rate measures inflation. I can see how the floating rate somewhat measures the rate of interest rates which are related to inflation. However I cannot understand why this swap rate is the preferred way to measure (medium term) inflation expectations.</p>

<p>For more information see <a href=""http://www.itcmarkets.com/news-press/itc-egbs-questions-regarding-draghis-reference-to-5y5y-forward-rate-and-inflation"" rel=""nofollow"">here</a>.</p>
","<p>To answer your question you have to understand Eurozone fixed income market structure:</p>

<ol>
<li><p>The ECB's mandate is to maintain price stability for the entire Eurozone.  Other measures of inflation---for instance the difference between French fixed-rate OATs (Obligations Assimilables du Tresor) and OAT linkers---measure only regional inflation, and suffer potentially from artifacts related to low liquidity.</p></li>
<li><p>Capital mobility within the Eurozone is quite good.  The EU banking sector dominates swaps trading volume, and the interest rate swaps market is extremely deep and liquid.  Therefore the swaps rate reflects Eurozone wide term structure.  What's more, fixed income traders tend to quote Euro pay issues' spreads off of swaps.  They are the benchmark rate.</p></li>
<li><p>There are EFSF (European Financial Stability Facility) and ESM (Eurpoean Stability Mechanism) bonds which also price to reflect Eurozone-wide term structure.  However these SPVs have not issued linkers, so it's impossible to use them to price inflation.</p></li>
<li><p>Some commenters here have forgotten their fixed-income math.  You can price counterparty risk-free interest rate swaps directly from fixed term structure.  This is because in an arbitrage free world Treasury curves reflect market participants expectations for forward rates and swap rates.  Any answer that suggests that swaps compensate for premiums and risks that are not purely term-structure related is false.</p></li>
<li><p>Swap rates pre-Dodd-Frank/MIFID used to reflect bank credit risk.  Now that they are centrally cleared in Swap Execution Facilities (SEFs), any credit risk associated with the swap is paid in margin, not as an interest rate premium.</p></li>
<li><p>The choice of term and tenor (5y/5y) is arbitrary.  The Federal Reserve also uses 5y/5y forward breakevens.</p></li>
</ol>

<p>I hope this clarifies that the 5y/5y inflation rate swap is the only sufficiently liquid measure of Eurozone-wide inflation.</p>
","14418"
"Can a country survive and prosper without international trade or investment from overseas?","2734","","<p>To what extent can a country be 100% independent from the rest of the world? Is there any country like that in the world? Maybe North Korea, but North Korea receives supports from China.</p>
","<p>In principle and in theory, anything can happen.<br>
First, as always, we have to supply some more specific content for ""survive and prosper"". Are we assuming some <em>preferences</em> underlying the whole issue? If yes, then what kind of preferences are they? What kind of material goods and services do these preferences favor? Can these material goods and services be provided by the country's own resources, and to what degree?  </p>

<p>Looking at history though, (as we should), we notice that long-long before ""global trade liberalization"" policies became an officially declared goal and agenda of the powerful economies of the planet, international trade existed and expanded. For thousand of years humans are observed to trade with abroad -and no, nobody forced them to.  So it appears that international trade <em>gets chosen</em> by human societies as a way to <em>prosper</em>. And because this choice has been revealed time and again, through different eras, civilizations, cultures, productive capabilities etc, it makes it difficult to think that a country could obtain a comparable level of prosperity without international trade.  </p>

<p>Survival, though, is another matter, since it is much more easy to survive than to prosper (as an individual or as a country).</p>
","1773"
"Calculate GDP by three different methods","2671","","<p>I have the following question to answer in my macroeconomics textbook. Steel producer makes steel worth 4000 out of which 0.25 is sold to machines producer and 0.75 of steel is being sold to the car producer. Machines are being sold to car producer for 2000. Car producer also buys tires from tires producer for 500. In effect he produces cars worth 5000 out of which 1/5 is being exported. <strong>Calculate GDP by three different methods.</strong>
And below in my textbook there is a table to calculate transaction value, value added, final goods expenditures etc. But how out of those data calculate GDP by three different methods? I know the equation GDP=C+I+G+NX, but how does it help?</p>
","<p>There are three ways to define GDP:</p>

<ul>
<li><p>Expenditure approach: The sum of all expenditures on <em>final</em> products. The only final product in this economy are cars; steel, machines, and tires are intermediate products. By this definition, GDP is 5000. Of this amount, 1000 is exported (<em>NX</em>), so 4000 must be consumed domestically (<em>C</em>). There is no information about <em>I</em> and <em>G</em>, so we must assume they're zero.</p></li>
<li><p>Production approach (value added approach). The output of the steel, machine tool, and tire sectors is worth 6500 combined (4000 for steel, 2000 for machines, 500 for tires). All output of these three sectors is consumed by the auto sector, whose output is worth 5000. Total output of all four sectors: 11,500. GDP is obtained by by subtracting sales of intermediate products from total output: 11500 - 6500 = 5000. (The car sector is making a net loss of 1500.)</p></li>
<li><p>Income approach (GDI: gross domestic income, ie., sum of wages and net profits). By definition, one entity's expenditures is another entity's income. We have no information about income shares (wages, profits, losses) of the various sectors, but in the aggregate GDI = GDP. Therefore, total GDI is also 5000. Total domestic consumption <em>C</em> on final products is 4000; thus, aggregate saving <em>S</em> must be 1000 (since GDP = <em>C+S</em>). Of this aggregate, 2500 is net saving of the household, steel, machines, and tire sectors, and -1500 is the <em>dissaving</em> of the car sector. For the non-car sectors, the only additional piece of information we have is that whereas the machine sector ""consumes"" 1000 in steel, its output is 2000. Thus, the entire <em>net</em> saving in this economy is due to the machine sector.</p></li>
</ul>
","5801"
"Why does the Brexit cause a fall in crude oil prices?","2616","","<blockquote>
  <p>Oil prices have also fallen sharply in the wake of the referendum
  outcome, with Brent crude down 5.2%. The price of Brent crude fell by
  \$2.68 to \$48.24 a barrel, its biggest fall since February. At the same
  time, US crude was down 5.4%, or \$2.69, to \$47.52 a barrel.</p>
</blockquote>

<p>From <a href=""http://www.bbc.com/news/business-36611512"" rel=""nofollow"">http://www.bbc.com/news/business-36611512</a></p>

<p>But why does this happen? </p>
","<p>I'd like to extend Lasse's excellent answer.</p>

<p>Fear and uncertainty are driving markets - but they can drive prices in either direction of course.</p>

<p>Specifically what's happening here is that the oil markets are pricing in at least two effects.</p>

<p>Firstly, the UK is an oil producer, and Sterling's slide means that its oil just got cheaper for other countries. This is a small effect, but relevant, as UK short-run marginal extraction costs are close to current prices, so some UK fields are marginal producers and thus price-setters.</p>

<p>Much more importantly, the markets are now pricing in the possibility of a further slump in oil demand, as a result of poor general economic performance. That would be driven not only by a soon-to-be-declining UK economy, but also driven by a (much larger) destabilised European economy; and also driven by the possibility that this vote will mark the turning point, where globally we move away from a consensus on the value of tariff-free international trade, and back towards protectionism and isolationism, which would leave the global economy worse off, as well as leaving most participants individually worse off too.</p>
","12490"
"What is the difference between two stage least squares and instrumental variable regression?","2608","","<p>I'm doing independent study and I am having trouble understanding the difference between these two estimators.</p>

<p>I get that 2SLS is predicting the endogenous variable, and that instrumental variables are similar to proxy variables, but I don't get how one differs from the other.</p>
","<p>2SLS estimators <em>are</em> IV estimators.</p>

<p>An IV estimator is the sample analog of the form: $\beta = \frac{Cov(Y, Z)}{Cov(X, Z)}$, where $Y$ is the outcome variable, $X$ is the endogenous variable, and $Z$ is the instrumental variable.</p>

<p>It can be shown that the 2SLS is of the above form. The advantage of 2SLS estimators over other IV estimators is that 2SLS can easily combine multiple instrumental variables, and it also makes including control variables easier.</p>
","13933"
"Solving for optimal consumption bundle","2560","","<p>Consider a consumer who can consume either A or B, with the quantities being denoted by $a$ and $b$ respectively. If the utility function of the consumer is given by $$-[(10-a)^2+(10-b)^2]$$(suppose prices of both goods are equal to $1$), then solve for optimal consumption of the consumer when his income is $40$.</p>

<p>My approach: I have the problem: $$max(-[(10-a)^2+(10-b)^2])$$ $$s.t.\ a+b \le 40,\ a\ge 0,\  b\ge 0.$$ Looking at the objective function, we see that it's maximum value is $0$ when $a=b=10$.</p>

<p>Am I right here?</p>
","<p>Yes, you are correct. That solution implies a utility of $0$, while any other solution necessarily will give you negative utility.</p>

<p>It is an odd problem for its violation of local nonsatiation: It is indeed optimal for the household to throw away the rest of his income.</p>

<p><strong>Update</strong> </p>

<p>Let's add the <em>either a or b</em> and see what happens:</p>

<p>$$max(-[(10-a)^2+(10-b)^2])$$ $$s.t.\ a+b \le 40,\ a\ge 0,\  b\ge 0,\ ab=0.$$</p>

<p>The optimal solution set now contains $\{(10, 0), (0, 10)\}$. The preferences between this one are still globally satiated at $(10,10)$, but as the point is not feasible, we set one of the coordinates to that value and keep the other one at $0$.</p>
","3337"
"What happens to a country with lot of debt?","2551","","<p>What happens to a country with lot of debt?</p>

<p>As far as I know, debt is a way to get hands on extra money which will put burden on the future governments.</p>

<p>What if every successive government keeps adding to the national debt? Isn't it like free money? Keep developing the country and keep adding to the debt as well... maybe forever? It is a win!</p>

<p>U.S has a debt of $18 trillion. How has it affected United States? Why should the government even bother to repay?</p>
","<p>What happens to a country with debt depends on several factors. </p>

<ol>
<li>Debt to GDP ratio</li>
<li>Credibility</li>
</ol>

<p>Debt is not exactly free money. It is 'free' money (apart from interest) only if you can be depended on to pay back that debt. In other words, investors are willing to lend money to a government if they are sure that the government will pay them back. Failing to pay back your debt would require your country to declare bankruptcy (or drop out of the global financial system altogether). </p>

<p>The reason why governments like the U.S. can keep borrowing money is because investors believe that the U.S. can easily make enough money to pay them back in the future. This is based on the <strong>debt to GDP ratio</strong>. If your debt to GDP ratio is too high (say, 10 to 1) that means it might be quite difficult for the country to pay back all that debt. The current U.S. debt to GDP ratio is between 0.7 and 1.0, which is relatively high (a result of the Great Recession). </p>

<p>Another smaller country might not be able to easily borrow with such a high debt to GDP ratio, but the U.S. also has credibility - it has not defaulted on its debts before, unlike some other sovereign states (Argentina). Combined with the fact that the U.S. has large financial clout and is relatively important, investors feel that the U.S. government is unlikely to default on its debts. </p>

<p>If the U.S. government were to keep on borrowing money, eventually people would get a little concerned with the amount of debt it has taken on. </p>

<p>It's possible to think of sovereign debt in a similar way to personal (your) debt. For example, if you own a credit card, you can use that credit card to get 'free' money and use that money to purchase things. The reason why banks are willing to lend you this money is because you have previously paid them back. If you were to (1) ask for a lot more money than you make (e.x. $100 million) or (2) ask for money after failing to pay the bank back at the end of the month, the bank would reject you. Investors, like the bank, require governments (and individuals like you) to meet some requirements before they are willing to lend you money.  </p>
","12927"
"GDP type: WDA, NSA, SA","2549","","<p>What are the acronyms for? SA, WDA, NSA. I was able to find WDA: written down allowance, but I am not sure is correct and how is applicable to GDP.</p>

<p><a href=""https://i.stack.imgur.com/xSrqd.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xSrqd.jpg"" alt=""enter image description here""></a></p>
","<p>SA = seasonally adjusted</p>

<p>WDA = working day adjusted </p>

<p>NSA = not seasonally adjusted</p>
","9079"
"Why is CRRA utility often used in macroeconomics DSGE model?","2545","","<p>As title says, why is CRRA utility often used in macroeconomics DSGE model? That is, the form of</p>

<p>$$u(c_t) = \frac{c_t^{1-\sigma}}{1-\sigma}$$</p>

<p>I cannot find any theoretical background around this..... After all, there is often no risk involved in DSGE models..</p>
","<p>Models at Dynamic Stochastic General Equilibrium level must be able to replicate real economies to an acceptable degree. One of the features of real economies has been a relatively stable <em>growth rate</em> (see also <a href=""https://economics.stackexchange.com/questions/460/why-is-economic-growth-measured-exponentially-rather-than-linearly/464#464"">this post</a>), $\dot x/x=\gamma$, where the dot above a variable denots the derivative with respect to time.</p>

<p>So one would want a model that admits a constant growth rate at its steady-state. In the benchmark deterministic/continuous time ""representative household"" model, the Euler equation  takes the form</p>

<p>$$r = \rho - \left(\frac {u''(c)\cdot c}{u'(c)}\right)\cdot \frac {\dot c}{c}$$</p>

<p>This is the optimal rule for the growth rate of consumption. The rate of pure time preference $\rho$ is assumed constant. The interest rate $r$ has its own way to become constant at the steady state. So in order to obtain a constant consumption growth rate at the steady state, we want the term</p>

<p>$$\left(\frac {u''(c)\cdot c}{u'(c)}\right)$$
to be constant too. The <strong>Constant Relative Risk Aversion (CRRA)</strong> utility function satisfies exactly this requirement:</p>

<p>$$u(c) = \frac {c^{1-\sigma}}{1-\sigma} \Rightarrow u'(c) = c^{-\sigma} \Rightarrow u''(c) = -\sigma c^{-\sigma-1}$$</p>

<p>So</p>

<p>$$\frac {u''(c)\cdot c}{u'(c)} = \frac {-\sigma c^{-\sigma-1} \cdot c}{c^{-\sigma}} = -\sigma $$
and the Euler equation becomes</p>

<p>$$\frac {\dot c}{c} = (1/\sigma)\cdot (r-\rho)$$</p>

<p>Barro &amp; Sala-i-Martin (2004, 2n ed.), extend the required form of the utility function when there is also leisure-labor choice (ch. 9 pp 427-428).<br>
These fundamental property extends to the case of stochastic/discrete time.</p>

<p><strong>XXXX</strong></p>

<p>To compare, if we have specified a <strong>Constant Absolute Risk Aversion (CARA)</strong> form, we would have </p>

<p>$$u(c) = -\alpha^{-1}e^{-\alpha c} \Rightarrow u'(c) = e^{-\alpha c}\Rightarrow u''(c) = -\alpha e^{-\alpha c}$$ and the Euler equation would become</p>

<p>$$\dot c = (1/\alpha)\cdot (r-\rho)$$</p>

<p>i.e.here we would obtain a constant steady-state growth in the <em>level</em> of consumption (and so a diminishing growth <em>rate</em>). </p>
","1814"
"What is the purpose of measuring GNP?","2525","","<p>I know that the GDP (the value of all final goods and services produced within a country during a given period of time) is useful for determining the productivity of a nation, the size of the nation's economy, and the standard of living.  The GNP (the value of all final goods and services produced by individuals belonging to a particular nation, both domestic and abroad, during a given period of time), I believe, is used in very similar ways.<br>
Overall, however, it seems that the GDP gives similar information and is easier to calculate  than the GNP.  That being said, what is the point of calculating the GNP?  </p>
","<p>In 1991, when the Bureau of Economic Analysis made the switch from GNP to GDP as ""their primary measure of U.S. production,"" they indicated the continued importance of <strong>GNP</strong> this way:</p>

<blockquote>
  <p>GNP, however, continues to be a useful concept. Because it refers to the income available to U.S. residents as the result of their contribution to production, it is appropriate for analyses related to sources and uses of income. For example, saving rates are normally expressed as a percentage of income, and GNP is the more appropriate measure for this propose. In addition, GNP is better than GDP for analyses that focus on the availability of resources, such as the Nation’s ability to finance expenditures on education.</p>
</blockquote>
","349"
"Did JP Morgan mitigate the effects of the Great Depression?","2518","","<p>I had heard that, at the start of the Great Depression, JP Morgan and other bankers attempted to prevent the depression by purchasing some of the overpriced stock.<br>
Did the actions of JP Morgan and the other bankers have any effect on the US economy at the time?  Were the effects of the Great Depression mitigated by their actions?</p>
","<p>Not really. While it's possible that the Morgan intervention softened the initial stock market decline, the vast majority of the ultimate collapse in securities prices, commodity prices, industrial production, and the banking sector took place after the purchases had been liquidated.</p>

<p>First some history: the bankers' pool intended to lift the stock market was assembled at the J.P. Morgan &amp; Co. offices on October 24, 1929, ""Black Thursday"", the initial day of market chaos. They pooled their resources and directed broker Richard Whitney to place high bids on blue chip stocks at the NYSE to lift the confidence of the markets. This stemmed the crash on Thursday and led to a rally that continued the next two days. Indeed, the <a href=""http://query.nytimes.com/gst/abstract.html?res=9900E4DE1E30E73ABC4F51DFB6678382639EDE"" rel=""nofollow noreferrer"">following Sunday's New York Times lauded</a> the ""carefully arranged"" plan to boost the market, and mentioned that the inclusion of the First National Bank in the buyers' pool the next day confirmed to Wall Street that ""the danger of panic had been averted"". Some history of these events is provided in <a href=""http://en.wikipedia.org/wiki/Wall_Street_Crash_of_1929"" rel=""nofollow noreferrer"">the Wikipedia article on the crash</a>.</p>

<p>Alas, the Monday and Tuesday immediately following this confident appraisal - October 28 and 29, 1929 - are known as <em>Black Monday and Tuesday</em>, respectively. They experienced the <a href=""http://en.wikipedia.org/wiki/List_of_largest_daily_changes_in_the_Dow_Jones_Industrial_Average"" rel=""nofollow noreferrer"">second and fourth largest daily percentage DJIA declines</a> in history, combining for easily the largest two-day percentage decline in history. Most newspapers at the time described the bankers' pool as waiting to intervene until late Tuesday, when they cut margin requirements and placed buying orders (<a href=""http://cdsun.library.cornell.edu/cgi-bin/cornell?a=d&amp;d=CDS19291030.2.21&amp;e=-------en-20--1--txt-txIN------#"" rel=""nofollow noreferrer"">see AP article</a>). An AP article describing the crash on Monday opened with ""powerful financial interests stepped aside today and let the stock market drop..."". Finally, on Wednesday the <a href=""http://cdsun.library.cornell.edu/cgi-bin/cornell?a=d&amp;d=CDS19291031.2.13&amp;e=-------en-20--1--txt-txIN------#"" rel=""nofollow noreferrer"">bankers' pool entered</a> with strong buying orders, leading to the third highest daily percentage DJIA <em>increase</em> in history. The next day the pool apparently <a href=""http://query.nytimes.com/gst/abstract.html?res=9D00E0DE163BE23ABC4953DFB7678382639EDE"" rel=""nofollow noreferrer"">stepped away from the markets once more</a>.</p>

<p>It kept going like this for a little while, with some more volatility in markets over the next few weeks but eventual stabilization and partial recovery. Finally, the banking group quietly wrapped up its activities in February 1930, with <a href=""http://cdsun.library.cornell.edu/cgi-bin/cornell?a=d&amp;d=CDS19300225.2.33&amp;e=-------en-20--1--txt-txIN------"" rel=""nofollow noreferrer"">press accounts mentioning</a> that it ""come out about even"".</p>

<p>Given all this, it's <em>possible</em> that the bankers' pool offered some initial stabilization of the markets. (Although even that's not clear: from press accounts, it seems just as likely that volatility was <em>increased</em> by the erratic day-to-day decisions of the pool.) But again, any significant effect seems unlikely, because the vast majority of the carnage in the Great Depression took place <em>after</em> the pool had been liquidated in February 1930. To convey some sense of this, the <a href=""http://research.stlouisfed.org/fred2/graph/?g=VCw"" rel=""nofollow noreferrer"">following graph</a> shows (in log points) the fall of the DJIA, industrial production index, and wholesale price index in the US starting in September 1929. As you can see, the initial declines in late 1929 and early 1930 - although substantial - are far smaller than the eventual ones. This is in line with the modern consensus view on the Great Depression, which <a href=""http://isites.harvard.edu/fs/docs/icb.topic467999.files/October%2022%20and%2027%20-%20Trade%20Money%20and%20Finance/Eichengreen.pdf"" rel=""nofollow noreferrer"">emphasizes the role of the gold standard</a> and its propagation of adverse monetary and banking shocks, rather than the initial market crash itself.</p>

<p><img src=""https://i.stack.imgur.com/gdHSA.png"" alt=""trajectory of the depression: stock prices, industrial production, and commodity prices""></p>

<p>This is all an interesting contrast with the more famous and successful case of intervention, performed in the <a href=""http://en.wikipedia.org/wiki/Panic_of_1907"" rel=""nofollow noreferrer"">Panic of 1907</a> by J.P. Morgan himself. (The original J.P. Morgan was long dead by 1929, though his eponymous son and firm lived on.) In 1907, Morgan engineered a wide variety of rescue measures, making large deposits in struggling banks and large call loans to brokers. These measures are thought to have helped end the panic.</p>

<p>The key difference, I think, is that the 1907 panic was a fairly conventional acute crisis in the banks and money markets: recent nominal growth and seasonal demand for currency meant that interest rates were already high, and then a run on banks and trust companies led to more hoarding of currency and extremely high interest rates. Extremely expensive margin borrowing led to a collapse in securities prices, which endangered the banks further (they were more exposed to stocks, through various channels, than they are now), leading to more run pressure, and so on. In this environment, where banks and firms were sound - and money markets would loosen - if only the panic would stop, it was possible for a few decisive interventions to swing momentum in the other direction.</p>

<p>The Depression was much different. Thanks to the Federal Reserve, seasonal fluctuations in currency demand and (to an extent) panicked currency hoarding did not lead to a spike in money market rates, which actually <a href=""http://research.stlouisfed.org/fred2/graph/?g=VCy"" rel=""nofollow noreferrer"">fell drastically in late 1929 and 1930 rather than spiking as they did in 1907</a>. Also unlike 1907, the banking crisis did not coincide with the initial stock market collapse - instead, it only started with the Bank of United States failure in December 1930, and in the initial stages was arguably due to fundamental insolvency rather than illiquidity. (Since both nominal real estate prices and food prices collapsed, mortgage default rates - residential, commercial, and farm - were all extremely high.)</p>

<p>Bottom line: the crisis of 1929-33 was different enough from the crisis of 1907 that similar measures no longer worked.</p>
","1799"
"Relationship between the Lagrangian and consumption euler equation?","2518","","<p>I think that the best way for me to ask my question would be to start with an example. </p>

<p>Suppose that consumers have a two-period horizon and their instantaneous utility is:
$\:$</p>

<p>$U(C_{t})=ln \: C_{t}$</p>

<p>$\:$</p>

<p>Where $C_{t}&gt;0$$\:$ denotes consumption. Assume that agents supply a fixed amount of labour $L$ and have no initial bonds $B$ or capital $K$. Agents discount utility of the second period with the discount factor $1&gt;\beta&gt;0$.
$\:$</p>

<p>The budget constraint is:
$\:$</p>

<p>$C_{1}+\frac{C_{2}}{1+r_{1}}$ =$\:$ $(w/P)_{1}$$L$ $\:$ + $\frac{(w/P)_{2}L}{1+r_{1}}$
$\:$</p>

<p>The Lagrangian is:
$\:$</p>

<p>$\mathcal L = \ln C_1 + \beta \ln C_2 - \mu \left[ C_1 + \frac{C_2}{1+r_1} -(w / P)_{1} L - \frac{(w/P)_{2}L}{1+r_{1}} \right]$</p>

<p>I now have two questions:</p>

<ol>
<li><p>Assuming that I compute the correct FOCs, how do I go about deriving the consumption euler equation?
$\:$</p></li>
<li><p>Could you guys please help me with the formatting of my lagrangian?
I want to make the square parentheses large enough to encapsulate everything.
$\:$</p></li>
</ol>

<p>Thanks.</p>
","<p>In this simple problem, using a Lagrangean is an overkill, direct substitution of the constraint is perhaps better.  </p>

<p>Anyway, treating the two consumption levels as two distinct decision variables under the budget constraint, the Euler equation emerges from the combination of the two first-order conditions:</p>

<p>$FOC$'s</p>

<p>$$\frac {\partial \mathcal L}{\partial C_1} = 0 \Rightarrow \frac 1{C_1} = \mu$$</p>

<p>$$\frac {\partial \mathcal L}{\partial C_2} = 0 \Rightarrow \frac {\beta}{C_2} = \mu\frac {1}{1+r_1}$$</p>

<p>Substitute the first into the second</p>

<p>$$\frac {\beta}{C_2} = \frac 1{C_1}\frac {1}{1+r_1}$$</p>

<p>re-arrange and you 're done.</p>

<p>I would suggest to also do that with a general utility function, where in the Euler equation the first derivatives of the utility will appear.</p>
","3160"
"Will price increase as demand increase?","2505","","<p>I know the law of demand which states that</p>

<blockquote>
  <p>if price of a product increases then the demand will decrease</p>
</blockquote>

<p>In this, I think we assume that price is a function of demand. But I feel otherwise i.e. </p>

<blockquote>
  <p>if demand increases then the price of the good will increases</p>
</blockquote>

<p>My reasoning:</p>

<p>If demand increases then the producers will capitalize on this fact and to increase their profits, will increase the price of the goods.</p>

<p>Where am I wrong?</p>

<p>Note: I have taken an introductory course on microeconomics as a minor and therefore know just the basic concepts only.</p>
","<p>The law of demand is a microeconomic law that states, <strong>all other factors being equal</strong>, as the price of a good or service increases, consumer demand for the good or service will decrease, and vice versa.</p>

<p>Now, when you say that ""if demand <strong>increases</strong> then the price of the good will increase"""", you aren't changing the price and based on the change in demand you are now predicting that the price would rise which is clearly against the law of demand as your ""<em>increase</em>"" in demand is obviously due to more user engagement, advertising, or some <strong><em>other external factors</em></strong>. </p>
","13486"
"Why do low-budget films charge the same amount at the box office as super-high budget films?","2504","","<p>In most occurrences, lower production costs translate into lower sales costs. Obviously there are other factors that influence price, including perceived value (affected by advertising), monopolies, and so on.</p>

<p>However there are many companies that produce films that vary greatly in budget. For instance, the Blair Witch Project came out in 1999 with a budget of \$60,000. The same year, Star Wars Episode 1 came out with a budget of \$115 million. That's almost 2000 times more expensive. Yet the two films sat side by side in the box office charging the same amount of money per viewing.</p>

<p>Why don't the makers of super-low-budget films undercut the big budget films?</p>
","<p><strong>Opportunity Cost of the Seats</strong></p>

<p>Once the movie is made the cost of production is sunk and irrelevant to the proper pricing of tickets. Only the marginal costs of serving an additional customer and the opportunity cost of showing a different film would enter into ticket pricing. Since cinemas should be setting the number of screens for each movie so that the opportunity costs of the seats are equated across films, this makes them want to charge the same for all films. In support of this idea, I offer that movies do vary in price by time of day. This is a rational response to the perishability of seats (once the movie starts an empty seat for that show is worthless) and time (of day) varying demand for film-going which varies the opportunity cost of the seats by time of day. The theater can't easily equate the opportunity cost across time the way it can across films. </p>

<p><a href=""http://www.cgu.edu/include/at_the_movies.pdf"">At the Movies: The Economics of Exhibition Contracts</a> (Filson, Switzer, and Besocke (2004)) provides the following explanation:</p>

<blockquote>
  <p>Practitioners provide several explanations for inflexible ticket
  prices. Exhibitors want to avoid menu costs and eliminate consumer
  uncertainty about what the movie will cost. Exhibitors do not increase
  prices of hits because they are engaged in repeat business with local
  consumers, and the potential loss of goodwill from increased prices
  outweighs the potential gain. Charging different prices for different
  movies at multiplexes necessitates employing monitors to ensure that
  consumers see the movies they pay for. Even offering mid-week
  discounts may lead to more time shifting than new demand. Not all
  analysts or practitioners agree that inflexible prices are optimal
  (see Orbach and Einav 2001), although it seems unlikely that such an
  easy-to-exploit profit opportunity would persist. Some practioners
  have experimented with non-uniform prices in  the U.S. in the recent
  past but inflexible prices remain the norm.</p>
</blockquote>
","10217"
"How to interpret Whited Wu index (WW-index)","2472","","<p>I want to study financial constraints on companies of different groups and for that I try to use Whited-Wu index:
<code>WW = - 0.091CF - 0.062DIVPOS + 0.021*TLTD - 0.044*LNTA + 0.102*ISG - 0.035*SG</code>
Where <code>TLTD</code> is the ratio of the long-term debt to total assets; <code>DIVPOS</code> is an indicator that takes the value of one if the firm pays cash dividends; <code>SG</code> is firm sales growth; <code>LNTA</code> is the natural log of total assets; <code>ISG</code> is the firm’s three-digit industry sales growth; <code>CASH</code> is the ratio of liquid assets to total assets; <code>CF</code> is the ratio of cash flow to total assets (see Whited and Wu. Financial Constraints Risk. 2006).</p>

<p>Although I managed to compute it, I have difficulties with results interpretation. My idea was to compare different companies/groups of firms using this index. As written in one of the papers, ""higher index values can be associated to higher need of external capital"". So if in 2010, for ""Toyota"" I got value -0.9 and for ""Fuji Technica Inc."" -0.53, may I conclude that Toyota is more financially constrained (requires more external capital)? Similarly, if I get two industries - food and car producing - then the first have higher values of WW.</p>
","<p>This is equation $(13)$ of <a href=""http://www.bauer.uh.edu/wu/Papers/RFS2006_FinConstr.pdf"" rel=""nofollow"">Whited, T. M., &amp; Wu, G. (2006). Financial constraints risk. Review of Financial Studies, 19(2), 531-559.</a></p>

<p>It is empirically estimated as regards the specific coefficient values. The important question is, </p>

<blockquote>
  <p>What is the left-hand-side?</p>
</blockquote>

<p>Looking at eq. $(12)$ of the paper the left-hand-side of $(13)$ is $\lambda_{i,t+1}$ which in turn is part of</p>

<p>$$\Lambda_{i,t+1} = \frac {1+\lambda_{i,t+1}}{1+\lambda_{i,t}}$$</p>

<p>$\Lambda_{i,t+1}$ is discussed in the middle of p. 536 (between eq. 5 and eq. 6). As the authors write,</p>

<blockquote>
  <p><em>If the outside equity constraint is binding, the effects of external
  finance constraints show up in the term $\Lambda_{i,t+1} =
 (1+\lambda_{i,t+1})/(1+\lambda_{i,t})$, which is the relative shadow
  cost of external finance. In the absence of finance constraints,
  $\Lambda_{i,t+1}=1$. On the other hand, if the equity constraint
  binds, then generally $\Lambda_{i,t+1}\neq1$, unless $\lambda_{i,t+1}
 = \lambda_{i,t}$. As also noted in Gomes, Yaron, and Zhang (2004), this last observation implies that finance constraints can only affect
  investment if they are time varying. It is the shadow value of the
  constraint today, relative to tomorrow, that is important.</em></p>
</blockquote>

<p>So $\lambda_{i,t+1}$ is the shadow cost of external finance at period $t+1$. Near the end of p. 538 the authors write</p>

<blockquote>
  <p><em>The higher $\lambda_{i,t+1}$, the greater is the effect of finance
  constraints.</em></p>
</blockquote>

<p>This is translated as ""<strong>the higher $\lambda_{i,t+1}$, the more difficult (or costly) is for a firm to obtain external financing</strong>"". It does not appear to relate to whether it <em>needs</em> more external financing or not.</p>

<p>Moreover, as the authors write in p. 540, it being a shadow value, it must be non-negative. So what do you make of the fact that you obtained negative values?</p>
","1881"
"""Competitive equilibrium"" vs. ""General equilibrium""","2385","","<p>What is the difference between the term ""competitive equilibrium"" and the term ""general equilibrium""? Here in econ.SE, they are two different tags, so there is probably a difference between them, but I don't understand what exactly.</p>
","<h3>Competitive Equilibrium</h3>

<p>A competitive equilibrium (""Walrasian Equilibrium"")'s defining characteristic is that it's competitive. It's about an equilibrium in which market forces (say, consumers, firms)' supply and demand responds to prices, and prices respond to supply and demand, and no Pareto-improving trade possibility remains in the end.</p>

<p>To be technical, consider a market with $I$ agents, $J$ goods, and initial endowments $E$ of shape $I\times J$. Also, each agent has rational preferences over the of goods.</p>

<p>A CE consists of a ($J\times 1$) vector of prices $P$ and a ($I\times j$) vector of allocations $X_i$ with two characteristics:</p>

<ul>
<li>Feasibility: $\sum_i J_i \geq \sum_i X_i \, \forall j\in J$</li>
<li>Rationality: $X_i \succsim_i \, H \forall H: HP \leq E_iP, \forall i$</li>
</ul>

<h3>General Equilibrium</h3>

<p>The general equilibrium's defining characteristic is that it is an equilibrium on more than one market; as opposed to the partial equilibrium in which we hold at least one price fixed and analyze the response of other markets/prices only.  </p>

<h3>So, what's the difference?</h3>

<p>It's about the emphasis. Any GE is a CE, but not any CE is necessarily a GE. We could look at a CE of consumer goods, but not analyze labor supply (i.e., not even model labor). Would this then <em>really</em> be a general equilibrium? Mostly, it is about the field. </p>

<p>In macroeconomics, it is a standard procedure to shut off several general equilibrium response mechanisms (for example, fix labor supply) and first look at a toy model in which only one margin is allowed to vary, and understand the mechanism - the partial equilibrium. Then, after that was understood, understand to which extent the mechanism is valid and relevant once one allows other margins to adjust. Therefore, here, it is important to be able to emphasize the difference - i.e. partial versus general equilibrium.</p>

<p>In other fields, one may not care as much about ""completely different"" markets. The distinction is for example not as important in many IO topics, and hence many there use the notion of the competitive equilibrium instead.</p>
","8718"
"The period of the business cycle in which the real GDP is increasing is called the?","2365","","<p>The period of the business cycle in which the real GDP is increasing is called the?</p>

<p>And no, this is not an homework question. I'm a college student and we starting our exams soon. I'm just going through a lot of questions. Both online and previous year's questions from my school. This is quite confusing. I think it is expansion. Then I saw an article on trough on wikipedia that says it is trough. <a href=""https://en.wikipedia.org/wiki/Trough_(economics)"" rel=""nofollow"">https://en.wikipedia.org/wiki/Trough_(economics)</a>
 Please explain</p>
","<p>The trough is not a period, it is simply the lowest <strong>point</strong>. The opposite of this is a peak, i.e. the highest point. The answer you are looking for is ""Expansion"" or ""Boom"". The period in which GDP is falling is called ""Recession"" or ""Contraction"".</p>

<p>Also note that the business cycle is typically not defined using real GDP, but rather nominal GDP.</p>
","8657"
"What was economics like as a field before Adam Smith, the father of *modern* economics?","2363","","<p>Adam Smith is called the ""father of <em>modern</em> economics"" and his book <em>The Weath of Nations</em>, a fundamental work in the field of economics, is considered the first <em>modern</em> book on economics.  In addition, economics first became a study in 1776 when <em>The Wealth of Nations</em> was published.  </p>

<p>Why is the word ""modern"" used in both descriptions?  I know that individuals throughout the centuries and even Aristotle have dabbled with some economic theories, but I do not recall anyone making any significant contributions to economics before Adam Smith.  </p>

<p>Were there important contributions to economics made before 1776?
If not, then why do we use the term ""modern"" even if there was no one in the study previously?  </p>
","<p>Direct predecessors to Adam Smith within the classical tradition (maybe a more useful distinction than modern) include Hume, Locke and Dudley North. Before the classical economists, there were the <strong>physiocrats</strong> (18th century), such as Francois Quesnay and Turgot. The physiocrats emphasised agricultural productivity as a driver of the wealth of nations. They were contemporaneous with, but also preceded by <strong>mercantilists</strong> (16th century - 18th century). Mercantilists mostly concentrated on creating a favorable balance of trade, which would allow reserves to accumulate in the possession of an absolute ruler. They emphasized government control of the economy as an extension of state power. The mercantilists had a lot of influence in the policies of nations, for instance in the form of Colbert. Famous writers might include de Malynes and Mun. Mercantilists were one of the main targets of Adam Smith's critique. The distinction being that mercantilists believed the quantity of reserves to be the ultimate source of a nation's wealth and so emphasized protectionism, while Smith focused more on trade allowing inputs to become more productive. In doing so he was very influenced by Quesnay to whom he had considered dedicating The Theory of Moral Sentiments. The inclusion of gains from trade, self-interest and competition leading to increased productivity, and division of labor distinguishes Smith from these earlier writings and forms the link to ""modern"" economics.</p>

<p>There were also ""economists"" long before the 16th century, the connections between them and economics is we understand it tends to become more tenuous the farther back you go. Iba Khaldun is a good example, Aristotle (or more likely one of his students) literally wrote a book called ""Economics"" (this deals with economics in the literal sense of management of a household), you could also talk about Hesiod's ""Works and Days"" (a very old text indeed) being an example of early economics. </p>
","175"
"Dornbusch model for exchange rate undershooting","2351","","<p>Is it possible to reproduce nominal exchange rate undershooting within the framework of Dornbusch model?</p>

<p>If the governments does fiscal expansion, does undershooting happen?<img src=""https://i.stack.imgur.com/R7ST1.png"" alt=""enter image description here""></p>
","<p>This will be long, but the subject is worth it.  </p>

<p>The gist of the ""exchange rate overshooting"" model in <a href=""http://web.econ.unito.it/bagliano/macro3/dornbusch_jpe76.pdf"" rel=""nofollow noreferrer"">Dornbusch, R. (1976). Expectations and exchange rate dynamics. The Journal of Political Economy, 1161-1176.</a> can be given using two equations:</p>

<p><strong>Uncovered Interest Rate Parity (UIRP)</strong>
$$i  = i^*+ \dot e\tag{1}$$</p>

<p>where $i$ is local interest rate, $i^*$ is international interest rate, and $e$ is the logarithm of the <em>foreign</em> exchange rate, i.e. local currency units per unit of international currency basket. So an <em>increase</em> in $e$ reflects <em>depreciation</em> of the local currency. A <em>decrease</em> in $e$ reflects <em>appreciation</em> of the local currency (I would prefer to use the local exchange rate, where conceptually we link ""rise"" with ""rise"", but it is unfriendly to the phase diagram that it will follow). Then $\dot e$ is the expected percentage change on the exchange rate.  </p>

<p><strong>Money-market Equilibrium (in logarithms)</strong></p>

<p>$$m-p = -\lambda i +\phi y \tag{2}$$</p>

<p>where $m$ is money supply, $p$ is the local price level, and $y$ is local output.  </p>

<p>The assumptions are: international interest rate is fixed. There is perfect capital mobility, so the local interest rate is a ""jump"" variable, being able to adjust instantaneously (and so eq. $(2)$ holds always). Local output is at full-employment level. Local prices are ""sticky"": this means that the local price-level is not a ""jump"" variable anymore, but its evolution is governed by a difference/differential equation that reflects gradual adjustment. Money supply is long-term neutral.  </p>

<p>The famous ""overshooting"" effect from an <em>unanticipated</em> permanent expansion of $m$ can then be derived: an increase in $m$ raises the left-hand side of $(2)$. Since prices are sticky (don't jump) and output is fixed, the only way that equilibrium can continue to hold in the money market is by a <em>decrease</em> in $i$ (due to the minus sign), so that that eq. $(2)$ continues to hold.<br>
Given the fall in $i$, and the assumption of constant $i^*$, the only way now that $(1)$ can hold with a lower $i$ is for $\dot e$ to be <em>negative</em>, i.e. if the local currency is expected to <em>appreciate</em>. But raising the long-term neutral local money supply can only create expectations for local currency <em>depreciation</em>, not appreciation.<br>
<strong>""Overshooting""</strong> cuts the Gordian Knot: the <em>immediate</em> response of the exchange rate $e$ is to <em>depreciate by more</em> (overshooting) than the eventual depreciation that is consistent with the increase in the money supply, and then it starts to <em>appreciate</em> to reach its new level (and so we can have $\dot e&lt;0$).  </p>

<p>The question asks about ""<strong>fiscal expansion</strong>"". How is this to be represented in the model? The only possible way is to assume that output can rise due to the fiscal expansion. </p>

<p>A fiscal expansion increases $y$ and raises the right-hand-side of $(2)$. Assuming that money supply is unchanged (and prices of course sticky), to equilibrate the money market, the local interest rate must now <em>rise</em> (to reduce demand for money balances that tend to rise to facilitate transactions on the higher $y$). Turning to $(1)$, with a higher local interest rate, we need expectations for currency <em>depreciation</em> ($\dot e &gt;0$) in order for UIRP to hold. But a fiscal expansion, be it temporary or permanent, given a full-employment output or not, is usually associated with local currency <em>appreciation</em> (higher $e$).<br>
<strong>So it appears that here too the overshooting effect obtains</strong>: the local currency jumps and appreciates by more than it is consistent with the fiscal expansion, and then it starts to depreciate, and we obtain the needed $\dot e &gt;0$.  </p>

<p><strong>Let's put this in a (semi) phase diagram</strong>. We need a bit more specification, how the exchange rate and the price level change. Denoting $\bar e$ and $\bar p$ their long-run equilibrium values, we specify</p>

<p>$$\dot e = \theta(\bar e -e)\; \;\;\;\text{eq.}(3a)\\ \dot p = -v(p-\bar p)\; \;\;\;\text{eq.}(3b)$$</p>

<p><strong>Notes:</strong> Both parameters are positive. The above look like ad-hoc ""adaptive"" schemes, but: the $\theta$ parameter can be determined so as to be compatible with rational expectations, the $v$ parameter is essentially determined endogenously, while the sluggishness of the price level is an  a priori assumption. This means that while both are governed optimally by a differential equation, the exchange rate <em>can jump</em>, while the price level <em>cannot</em> -it is ""slaved"" to its differential equation, while the exchange rate is only <em>optimally</em> characterized by its own equation, not chained to it.  </p>

<p>By setting $\dot e=0$ we can obtain the expression for the long-run price level:</p>

<p>$$\bar p = m+\lambda i^* - \phi y \Rightarrow m = \bar p-\lambda i^* + \phi y\tag{4}$$
Inserting equation $(3a)$ into $(1)$, then $(1)$ and $(4)$ into $(2)$, we have</p>

<p>$$\bar p-\lambda i^* + \phi y -p = -\lambda[i^*+ \theta(\bar e -e)] +\phi y$$</p>

<p>Simplifying and re-arranging we get</p>

<p>$$ e = \bar e -\frac {1}{\lambda \theta}(p-\bar p) \equiv QQ\tag{5}$$</p>

<p>Equation $(5)$ is the <em>saddle-path</em> of the economy in the $e-p$ space (although in Dornbusch's paper time it was rarely called that). And it alone can tell us about overshooting. Note that the current exchange rate level depends positively on both its long-run value but also on the long-run price level. Following Dornbusch, we normalize the initial relative price of local to foreign output to unity, and so we have that $\bar e = \bar p$. This means that in the $e-p$ space the long-run equilibrium will be on the $45^{\text{o}}$ line. Putting $p$ on the vertical axis, the $QQ$ schedule will be downward sloping. Then the phase-diagram (without fixed-point loci, we don't need them since we have the saddle-path) is, for the case of a fiscal expansion,</p>

<p><img src=""https://i.stack.imgur.com/hm7Y4.png"" alt=""enter image description here""></p>

<p>We assume that we start at the long-run equilibrium point $A$, (and we will discuss this point later). Then, fiscal expansion happens. If it is permanent, it is associated with long-run currency appreciation and a lower long-run price level. This means that the saddle-path of the economy moves permanently to the left and becomes the $Q'Q'$ schedule. How can the economy find itself on the new saddle-path? It must jump. But it cannot jump vertically because prices are sticky. It can only jump <em>horizontally</em>: so it goes from point $A$ to point $B$ which is one the new saddle-path, and then starts to travel towards the new equilibrium, that is point $C$. But at $B$ corresponds exchange rate $e_B&lt;\bar e_2$, the latter being the new long-run equilibrium exchange rate. And lower $e$ means <em>more</em> appreciated currency. So the exchange rate ""overshoots"" the appreciation level, and then starts to depreciate as the economy moves towards $C$.  </p>

<p>Assume that the fiscal expansion is considered ""temporary"" (for decades, this was a good laugh in real-world macroeconomics -not so in the last couple of years). Still, even though the long-run equilibrium point remains $A$, there is short-term and mid-term horizons that must adjust. Here the point $C$ is some sort of ""temporary"" equilibrium point, which subsequently will start again to approach $A$. But the initial adjustment will happen exactly in the same way, and we will have overshooting.  </p>

<p>Imagining a monetary expansion, amounts to shift the saddle-path outwards -and obtain overshooting related to depreciation.   </p>

<p><strong>A final note:</strong> if one plays around with the diagram, he will realize that 
<strong>if we do <em>not</em> start at the long run-equilibrium level, and if we are sufficiently far away from equilibrium on the $QQ$ schedule, we may obtain <em>undershooting</em> in either case of policy.</strong> For the case at hand (fiscal expansion), imagine that we are at point $D$ on $QQ$ that at the time of the expansion corresponds to a price level <em>below</em> the one that corresponds to new equilibrium point $C$, and we are moving upwards towards $A$. When the fiscal expansion happens and the new saddle-path is $Q'Q'$ we will jump horizontally alright -but we will jump on the <em>upward moving</em> part of the new schedule (draw an horizontal line from $D$ to see that), i.e. we will <em>undershoot</em> the needed appreciation, and then we will gradually continue to appreciate the currency.
But this case is not unique to the fiscal expansion scenario -it can also happen in the monetary expansion scenario.  </p>

<p>But if in principle the model permits everything to happen, why everybody went bonkers over Dornbusch paper back then, and it continues to be considered one of the high peaks of economic theory? For the historical framework <a href=""http://www.imf.org/external/np/speeches/2001/112901.htm#P41_10723"" rel=""nofollow noreferrer"">one can read this</a>. The fact that the model offered a clear and <em>optimizing</em> reasoning to account for the continuous ups-and-downs of the exchange rates (a new ""bizarre"" phenomenon at the time) I guess was reason enough (and also perhaps because open economies sufficiently far away from the equilibrium point of their nominal variables are not considered very likely -prices do adjust, after all).</p>
","1609"
"What does Yanis Varoufakis mean by ""surplus recycling mechanism""?","2309","","<p><a href=""http://en.wikipedia.org/wiki/Yanis_Varoufakis"">Yanis Varoufakis</a>, the current finance minister of Greece, talks about a <em>""surplus recycling mechanism""</em>, a term he coined and uses to describe (as I understand it) a relief valve for economies running a surplus.</p>

<p>While I haven't read his book, I watched some of his talks and read his blog posts. I couldn't quite figure out what he means by this. Could someone please explain what he means by ""SRM"", and why he considers it important, crucial even, to prevent major recessions?</p>

<p>Here's what I've figured out so far. The surplus being talked about is the <em>trade surplus</em>. That is, countries which export more goods than they import run a surplus, and get a net influx of cash (or, in the past, gold). This cash can either be hoarded, or reinvested. Internal expenditure is ignored as irrelevant, as only the interactions between countries are being looked at. If hoarded beyond a certain breaking point, bad things happen. A surplus recycling mechanism compels a country to reinvest the cash overseas.</p>

<p>Or so it seems. Is my understanding of what ""SRM"" means correct? Also, if so, according to Varoufakis (or Keynes, who apparently had the exact same realisation around WW2 time), how exactly does hoarding without bound cause bad things / recession?</p>

<p>It would also help to know whether Varoufakis' ideas / interpretations are widely accepted by mainstream economists, currently being debated, or are a fringe/minority view.</p>
","<p>""Surplus recycling"" is a term coined (to my knowledge) by Varoufakis to describe the fact that a country that enjoys a <a href=""http://en.wikipedia.org/wiki/Balance_of_trade"" rel=""nofollow"">trade surplus</a> should reinvest the surplus in the domestic economies of its trading partners. Such a policy was conduced with success by the United States in the years following WW2, where the <a href=""http://en.wikipedia.org/wiki/Marshall_Plan"" rel=""nofollow"">Marshall plan</a> and similar policies in Asia took place, mainly for political reasons.</p>

<p>As Varoufakis states it, there is no reason for the market to proceed to such a transfer, yet it does sound reasonable to keep trade partners in good shape.</p>

<p>In Europe, Germany's trade surplus is notable for being the only important European surplus. Surplus recycling is one way the Greek government is trying to get Germans to feel right about handing out money to European countries that are struggling with their economy, another infamous attempt being WW2 reparations.</p>

<p>I believe you're somewhat wrong in your interpretation because the question here is not whether to reinvest or not (this is a problem which is well treated by ""classic"" macroeconomics), but where to reinvest the money. The alternative is hence between domestic and foreign investments, and there is no known economic mechanism that supports foreign investments unconditionally. Varoufakis work aims at fostering foreign investment from Germany to southern Europe. I don't see anything controversial in his definition, but he is defining a <strong>policy</strong>, not a <strong>model</strong>.</p>

<p>The problem with solely-domestic investments is that, on the long term, it weakens trade partners, which weakens domestic economy in turn. I don't think there is much debate among the fact that trade balance <a href=""http://www.investopedia.com/terms/t/trade-surplus.asp"" rel=""nofollow"">is not a self-correcting problem</a>. The real debate (and it's political for the moment, an open field for economic research) is on what end the policies to solve the problem has to be carried: the one for which it is easier to solve (Germany), or the one for which the problem is worse (Greece).</p>

<p>The amount of money we're talking about is sizable to say the least, and can be viewed <a href=""http://www.eurocrisismonitor.com/Data.htm"" rel=""nofollow"">here</a> as suggested in a comment.</p>
","5704"
"Why is collective bargaining by a group of employees not the same thing as price-fixing?","2179","","<p>Employees sell their labor for wages. If a critical mass of employees get together and demand higher wages, how is this not the same thing as a critical mass of merchants illegally fixing the price of some commodity?</p>

<p>Can't a strong union be considered to have an illegal monopoly on labor? </p>
","<p>This is more of an elaboration of The Almighty Bob's answer:</p>

<p>It is true that <em>if we start from a competitive market</em> (i.e. large numbers of buyers <strong>and</strong> sellers), then granting market power to sellers (e.g. workers) by allowing the formation of a monopolistic cartel is bad for efficiency. Those sellers will use their market power to increase the price (and reduce the quantity traded), resulting in a deadweight loss. Thus, we tend to look suspiciously upon practices that create market power. Note that here, the policy intervention we have in mind is to break up the cartel and return us to a competitive world.</p>

<p>Why should the labour market be viewed differently? Part of the answer is that the relevant counterfactual has changed. Begin with a world without labour unions. The market will then typically <em>not</em> be competitive because there are often a small number of employers who themselves enjoy market power. Just as a monopolist seller can drive up the price, these monopsonistic (or oligopsonistic) buyers of labour can use their power to drive down the price.</p>

<p>Now we are faced with the following policy problem:</p>

<blockquote>
  <p>How can we correct for employers' market power and restore wages toward the (higher) efficient level?</p>
</blockquote>

<p>Two simple solutions come immediately to mind:</p>

<ol>
<li><p>Reduce employer's market power by stimulating competition between employers. This is achieved, to some extent, by antitrust policy. But it's hard to do much more here short of forcing more businesses to hire more workers.</p></li>
<li><p>Allow workers to form unions so that both workers and employers have market power. If the firms try to use their power to drive wages down and the workers use it to drive them up then there is a sense in which the two will 'cancel out' and the result can be closer to the efficient wage than a market in which only employers have market power. </p></li>
</ol>

<p>Whether the second solution indeed works or not depends upon a whole range of factors. Here are a few:</p>

<ul>
<li>If the employer side of the market is, in fact, quite competitive then the correction will likely be too big and we will end up with wages that are inefficiently high.</li>
<li>If bargaining is very costly then it might be more efficient to have one side (e.g. the employers) unilaterally set the wage.</li>
<li>If there is uncertainty about the wage that firms are willing to pay/workers are willing to accept then bargaining may inefficiently break down (see the <a href=""http://en.wikipedia.org/wiki/Myerson%E2%80%93Satterthwaite_theorem"">Myerson-Satterthwaite Theorem</a>).</li>
</ul>
","4871"
"Should we expect more structural technological unemployment if growth becomes more limited by natural resources and less by labour?","2157","","<p><a href=""https://en.wikipedia.org/wiki/Technological_unemployment"" rel=""nofollow noreferrer"">Technological unemployment</a>, where unemployment arises from (with some oversimplification) workers being replaced by machines, has so far been temporary as new jobs were created that replaced the old jobs.  Structural unemployment has been predicted many times in the past <a href=""http://zackkanter.com/2015/01/23/how-ubers-autonomous-cars-will-destroy-10-million-jobs-by-2025/"" rel=""nofollow noreferrer"">and the present</a>, but has not (yet) occurred.</p>

<p>Historical increases in productivity have led to an increase in overall production.  Physicist Timothy Garrett <a href=""http://physicsworld.com/cws/article/news/2008/nov/27/modelling-civilization-as-heat-engine-could-improve-climate"" rel=""nofollow noreferrer"">models the economy as a heat engine</a>, with more details in papers <a href=""http://www.inscc.utah.edu/~tgarrett/Economics/Economics.html"" rel=""nofollow noreferrer"">linked from Garretts personal page</a>:</p>

<blockquote>
  <p>In each of the past 40 years for which records are available, a continuous 7.1 Watts has been required to maintain every one thousand inflation-adjusted 2005 dollars of historically accumulated economic wealth (not yearly economic output or GDP). As of 2010, civilization was powered by about 17 trillion Watts of power which supported about 2352 trillion dollars of collective global wealth. In 1970, both quantities were less than half this. In the interim, energy consumption and wealth grew equally rapidly in the interim at an average rate of 1.9% per year. </p>
</blockquote>

<p>Dr. Garrett is not an economist by training, and I don't know how his models are received by mainstream economists.</p>

<p>How do contemporary forecasts on technological unemployment take into account an economy that is increasingly limited not by the availability of (sufficiently skilled) labour, but rather by the availability of resources?</p>

<p>To illustrate it further: some speculate that in the next years and decades, self-driving cars will displace professional drivers (taxi drivers, lorry drivers, etc.).  This will initially increase unemployment, but it would also lower the labour component of the price of many goods.  Historically, civilization has responded to such events more with an increase in production than with an overall decrease in hours worked.  However, production cannot be increased arbitrarily; resources become increasingly scarce. Therefore, those prices will go up.  That means that perhaps this time around, the feedback preventing structural, technological unemployment does not apply...  hence my question.</p>

<p>I welcome answers that do and answers that do not take into account externalized costs such as damage to natural ecosystems, pollution, and anthropogenic climate change.</p>
","<p>I understand that you are asking the following</p>

<blockquote>
  <p>Up to now, we have avoided structural unemployment because we increased
  production by <em>more</em> than what the technological efficiency gains
  implied (and so eventually re-employed the labor that had become
  initially obsolete, usually in other industries). But if finite resources put constraints on how
  much we can increase production, won't a time come that structural
  unemployment will emerge?</p>
</blockquote>

<p>As @Foobar notes in a comment, technically speaking this appears to have to do with the rate of increase of efficiency in resource use compared to the rate of decrease of resources available.</p>

<p>But one could argue that, efficiency in resource use has its limits, and the constraint will eventually set in. In such a technological unemployment scenario (which I don't believe anyone can really put a reliable time-line on), there is one resource that won't decrease but rather increase in availability: labor. So, and if nothing <em>truly</em> life-changing happens (like devastation of human population, massive colonizations of other planets, or the equivalent of <a href=""http://ancienthistory.about.com/od/cterms/g/cornucopia.htm"" rel=""noreferrer"">Amalthea's Horn of Plenty</a>), production will tend to utilize this available resource (which we should expect to command a relatively lower reward being in high supply). Meaning, a tendency for production to grow in <em>sectors where services delivered by humans remain central</em>, by their nature (or by the prevailing consumer preferences). Servants, personal assistants, waiters, nurses, sex workers, trainers, teachers, baby sitters, security guards, body guards, arts and sports entertainers... even if only as a relative ""luxury"", rather than strictly needed in the amounts employed. And we may even see innovative ways of using labor (i.e. once more creating new sectors) -but I leave that to anyone's imagination...<br>
Of course this labor should get paid <em>something</em> for its services, so those employing it should have the income/wealth needed to pay this something... which indirectly brings in the issue of wealth and income inequality, and whether it plays (or not) a part in all these.</p>
","3230"
"Does the US stock market tend to rise after natural disasters?","2150","","<p>It seems counter intuitive that markets would rise after a huge disaster that probably affects multiple industries like oil or produce. </p>

<p>For example, can someone explain why the US markets actually rose in the days following hurricane Harvey? </p>

<p>Edit: changed title to include natural disasters as a whole. </p>
","<p>This <a href=""https://www.cnbc.com/2017/08/28/stocks-will-likely-remain-unaffected-by-hurricane-harvey-tragedy.html"" rel=""noreferrer"">news article with some statements from financial workers</a> makes a case that usually big storms don't impact the national economy that much, even despite the large localized damages. While insurance companies will suffer in the stock market because of all those payouts they'll have to give, oil prices as you mentioned will be impacted, but in this case, gas prices will rise because of the change in the supply curve, so they will actually benefit in the stock market. The various effects combined end up with the stock market not really going up or down. It's more or less a wash. </p>

<p>To think of it another way, a shock in the short term capital in the economy won't particularly change the steady state level of capital. If markets know this, there isn't a need for huge changes in prices. In the case of the insurance companies, their money isn't so much based on capital as it is based on states of the world, so they will end up needing to adjust prices.</p>

<p>There are other reasons why the stock market may not have moved up or down in particular, but for the most part it is speculation, and even my answer is just intuitive exposition.</p>
","18107"
"Difference-in-differences in 2SLS regression","2145","","<p>Usually when we do a difference-in-differences estimation, we do it in a OLS reduced form as follows: 
$$
Y_{it}=\alpha After_t+\gamma Treatment_i+\delta After*Treatment_{i,t}+X_{it}\beta+\epsilon_{i,t}
$$
However, I was wondering, if the $Treatment$ group is endogenous (e.g. self-selected), but we can define an ""eligible"" group for the treatment, whether it would be more precise to estimate a diff-in-diff in a OLS/2SLS form as:
$$
Treatment_{i,t}=constant+\alpha After_t+\gamma Eligible_i+\delta After*Eligible_{i,t}+\epsilon_{i,t}
$$and get $\hat{Treatment_{i,t}}$, then</p>

<p>$$
Y_{i,t}=X_{it}\beta+\delta\hat{Treatment_{i,t}}+\epsilon_{i,t}
$$</p>

<p>How should we understand the diff-in-diff in a OLS/2SLS form? Are there any paper using this particular identification strategy that I could take a look?</p>

<p>Thank you very much in advance!</p>
","<p>Well, if you believe that treatment is endogenous (which depends on the problem at hand here and is not an inherent feature of the model), then using eligibility as an instrumental variable will help you to get rid of the biases due to the safe selection in treatment. (Incidentally, DID is intended to do the same, but won't do as good a job as a well chosen instrument, so there is some doubts whether applying both of them is better then resorting to only one). However it is up to you to decide whether eligibility is exogenous, as it well may be, that those who are expecting higher return to treatment made sure to be eligible.</p>

<p>Taking that we believe that there are some biases that arenot eliminated by DID and that eligibility can help us, there is still considerations of efficiency. In many cases eligibility may happen to be a weak instrument and then the reduction is bias will come at a cost of significant efficiency loss.</p>

<p>And taking a look at the particular specification that you have sugested, it seems not very reasonable in general setting. You may choose when you believe that eligibility is changing quickly, or the interaction term in second equation will be generally unhelpful. Inclusion of time After in that equation can have even more drastic consequences, as it is likely to be endogenous and will weaken the bias reduction effect. If not endogenous, it is likeliy to be negligible as well as interaction, unless Treatment is rapidly changing on it's own.</p>

<p>So in this case I would recommend leaving only the eligibility as an instrument in the first equation and specifying the third one in a DID form.</p>

<p>With respect to interpretation, my specification does not allow for a nice interpretation of difference in changes in two subgroups and should be interpreted as a difference in changes in two hypothetical subgroup where each person is divided between them with some weights.</p>

<p>Your specification, however, loses all interpretation as DID, because you do not use the resulting interaction coefficient, but just employ more variables as instruments for treatment.</p>

<p>Unfortunately, probably due to the aformentioned reasons, I was unable to recall or find any appropriate paper, sorry about that.</p>
","3024"
"Monopolies are just a mathematical misunderstanding","2144","","<p>A little head-scratcher (and a good example why we should be careful with notation).</p>

<p>Consider a profit maximizing monopoly, that solves over price </p>

<p>$$\max \pi = PQ(P) - C(Q(P)) \tag{1}$$</p>

<p>Following the routine steps (<strong><a href=""https://economics.stackexchange.com/a/1728/61"">see this post</a></strong>)</p>

<p>we arrive at the important result that, at the profit maximizing price, the price elasticity of demand should be higher than $1$ in absolute terms, or lower than $-1$ in algebraic terms. Namely at the profit-maximizing price we have</p>

<p>$$\eta^* = \frac {\partial Q }{ \partial P}\cdot \frac {P}{Q} &lt;-1 \Rightarrow \frac {\partial Q }{ \partial P}P &lt;-Q$$</p>

<p>$$\Rightarrow \frac {\partial Q }{ \partial P}P +Q &lt;0 \tag{2}$$</p>

<p>But $\frac {\partial Q }{ \partial P}P +Q$ is the derivative of $PQ(P)$ and $PQ(P) = TR$, Total Revenue. So $\frac {\partial Q }{ \partial P}P +Q = MR$, Marginal Revenue and we just obtained that at the profit maximizing price and in order to have elasticity greater than $1$ in absolute terms, we must have $MR^* &lt;0$. </p>

<p>But we also now that at the profit maximizing point we have $MR^*=MC^*&gt;0$.</p>

<p><strong>So a solution does not exist, and therefore we conclude that monopolies are just a mathematical misunderstanding.</strong></p>

<p>Now, I went into the trouble(?) to write this smirking post, I hope somebody will go into the few dozens of seconds required to write a clear answer to point out where the trick lies.</p>
","<p>$PQ(P)=TR$, Total Revenue. </p>

<p>$\frac{∂Q}{∂P}P+Q$ is the derivative of $PQ(P)$ <em>with respect to $P$</em>.</p>

<p>$MR$, Marginal Revenue, is the derivative of $TR$ <em>with respect to $Q$</em>.</p>

<p>So in general $\frac{∂Q}{∂P}P+Q \neq MR$</p>
","18813"
"What's the role of initial endowments in an edgeworth box?","2138","","<p>I am trying to solve a problem but I don't see the role of initial endowments.
For instance, the question is about finding competitive equilibria.
But there is information about initial endowment.
How should I make use of it?</p>
","<p>First, according to <a href=""http://rads.stackoverflow.com/amzn/click/0195073401"" rel=""nofollow"">MWG</a>, Def 15.B.1, <em>""a Walrasian (or competitive) equilibrium for an Edgeworth box exonomy is a price vector $p^\star$ and an allocation $x^\star = (x_1^\star, x_2^\star)$ in the Edgeworth box such that for $i=1,2$:""</em></p>

<p>$$ x_i^\star \succeq_i x_i^\prime \qquad \text{for all} \quad x_i^\prime \in B_i(p^\star) $$</p>

<p>Typically in such problems, you must have the Walrasian demands for each consumer and good, and the initial endowments for each consumer. From every endowment, $\omega_i$, you can infer the individual's wealth, just and obviously multiplying the endowment's quantities for each good with the respective prices. For example, having $\omega_1=(2,3)$, means that the individual 1 is endowed with 2 ""units"" of good 1 and 3 of good 2. So his/her wealth would be $w_1 = 2 \cdot p_1 + 3 \cdot p_2$. </p>

<p>With these, you can proceed to find the Walrasian equilibrium; however, a more detailed question on your behalf would be more enlightening.</p>
","6001"
"Are state owned enterprises really inefficient?","2121","","<p>The typical right wing/free market argument, that leads to privatisation of government assets is that the government assets will be far more efficiently managed when in the hands of profit seeking capitalists, rather than being owned by the government. </p>

<p>Certainly it's fair to say that government departments are inefficient - a department that is <em>directly funded</em> by the government can't go bankrupt, so long as the government keeps funding it. </p>

<p>However, for a SOE the company still needs to stand on its own right, the SOE doesn't receive funding directly from the government. </p>

<p>The SOEs management structure is exactly the same as a privately owned company, except that the government is choosing who the board of directors is. </p>

<p>So the question is, unless the government is electing a board of directors that have different priorities to profit seeking capitalists, how is it that a SOE would be less efficient than a privately owned company?</p>

<p>Is there any research showing that SOEs are less profitable than privately owned companies? </p>
","<p>Because of the large number of roughly comparably sized private and public firms, the petroleum industry provides a laboratory for exploring differences between private and state owned enterprises in related businesses. Without passing judgement on if it <em>has</em> to be that way,  it appears as though the private firms are vastly more efficient:</p>

<p><a href=""http://www.tandfonline.com/doi/abs/10.1080/00036849200000122"" rel=""nofollow"">Efficiency differences between private and state-owned enterprises in the international petroleum industry</a> (1992)</p>

<blockquote>
  <p>Technical (managerial), scale and allocative efficiency differences
  between private and state owned firms in the international petroleum
  industry are estimated. The estimation of Aigner-Chu deterministic
  frontiers, maximum likelihood stochastic frontiers, and maximum
  likelihood Gamma frontiers make this analysis the most complete and
  sophisticated testing of property rights theory available. The
  empirical findings suggest ceteris paribus, that <strong>state firms could
  satisfy the demand for their output with something less than half of
  their current resource inputs simply by being converted to private,
  for profit enterprises.</strong></p>
</blockquote>

<p>Of course, that last claim depends on the costs of privatization and asserting those efficiency gains can actually be realized in the sorts of places where oil firms are state owned.   </p>

<p><a href=""http://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1994.tb05147.x/abstract"" rel=""nofollow"">The Financial and Operating Performance of Newly Privatized Firms: An International Empirical Analysis</a> (1994)</p>

<blockquote>
  <p>This study compares the pre- and postprivatization financial and
  operating performance of 61 companies from 18 countries and 32
  industries that experience full or partial privatization through
  public share offerings during the period 1961 to 1990. Our results
  document strong performance improvements, achieved surprisingly
  without sacrificing employment security. <strong>Specifically, after being
  privatized, firms increase real sales, become more profitable,
  increase their capital investment spending, improve their operating
  efficiency, and increase their work forces.</strong> Furthermore, these
  companies significantly lower their debt levels and increase dividend
  payout. Finally, we document significant changes in the size and
  composition of corporate boards of directors after privatization.</p>
</blockquote>

<p>Some evidence from a broader array of industries:</p>

<p><a href=""http://www.jstor.org/stable/725378?seq=1#page_scan_tab_contents"" rel=""nofollow"">Ownership and Performance in Competitive Environments: A Comparison of the Performance
of Private, Mixed, and State-Owned Enterprises</a> (1989)</p>

<blockquote>
  <p>The coefficients for MEs [Mixed Ownership Enterprises] and SOEs [State Owned Enterprises] are negative and statistically
  significant at the .05 level for a one-sided alternative in all
  equations, which indicate that, on average, MEs and SOEs are
  significantly less profitable and less efficient than PCs [Private Corporations] after
  controlling for the factors described above. <strong>On average, SOEs have a
  return on equity of almost 12 percent less than PCs ; they have a
  return on assets and a return on sales that are about 2 percent less
  than PCs, and their net incomes are \$66 million less than PCs.</strong> MEs
  perform worse: their return on equity is more than 12 percent less
  than PCs, their return on assets and return on sales are about 3.5
  percent less than PCs, and their net income is \$165 million less than
  that of PCs. In terms of sales per asset, both SOEs and MEs fare
  equally poorly relative to PCs; but in terms of sales per employee,
  SOEs are less efficient than MEs.</p>
</blockquote>

<p>A more recent result:</p>

<p><a href=""http://www.jstor.org/stable/2677913?seq=1#page_scan_tab_contents"" rel=""nofollow"">State-Owned and Privately Owned Firms: An Empirical Analysis of Profitability, Leverage, and Labor Intensity</a> (2001)</p>

<blockquote>
  <p>The results of the comparison <strong>strongly support the proposition that
  government firms display inferior profitability</strong>. ... We test an implication
  of the Boycko et al. (1996) model that government firms will tend to
  <strong>use more labor than their private counterparts</strong>. Cross-sectional
  comparisons support the model</p>
</blockquote>
","4436"
"Is fisher equation a definition, identity? Or is it rather a very good estimate","2109","","<p>So let us agree that the fisher equation is $1 + i = (1 + r)(1 + \pi).$ Is it a definiton or good estimate. Intuition tells me this make so much sense and almost qualify as an equation that must hold. However, sources online tell me that it is a good approximation. If we accept that, can anyone suggest examples when the equation fails and why? Thank you!</p>
","<p>The fisher equation has its basis in the fact that the real return on an asset is the nominal return divided by the inflation rate. If you hold a bond today, it gives you back $1+r_{t+1}$ tomorrow. This is basically $\frac{1+\iota_{t}}{1+\pi_{t+1}}$ such that the promised nominal rate is deflated by the inflation rate. Rearranging terms, you get your definition. This is exact and always holds conceptually. The approximation is that $i\approx r+\pi$  which is obtained via a Taylor series expansion.</p>
","8555"
"How to derive the reaction function from these provided variables?","2108","","<p>This is the question. I cant seem to reach a concrete solution because of the scarce information.</p>

<p>Firm 1 spends 2 million, plus 33.33% on advertising what firm 2 spends on and firm 2 spends $7 million plus 12.5% of what firm 1 spends. Draw the reaction functions and label them from the provided information.</p>

<p>I want to know the exact procedure on such problems.</p>
","<p>Adding to HREcon's answer (can not comment yet)</p>

<p>Firm 1:
$x_1= 2 + (1/3) x_2$</p>

<p>Firm 2:
$x_2= 7 + (1/8) x_1$</p>

<p>In order to find the equilibria, you could substitute $x_2$ for firm one by $7 + (1/8) x_1$, and vice versa for firm 2, you would get:</p>

<p>$x_1= 2 + (1/3) (7 + (1/8) x_1)$
and
$x_2= 7 + (1/8)  (2 + (1/3) x_2)$</p>

<p>These equations only depend on one variable and in this case you can solve them to get exact values for x1 and x2.</p>
","8917"
"Determining cost from production function, wage, and rental rate","2099","","<p>So I have a production function $Q=2K + 20L^{1/2}$ and I suppose the wage is $w=5$ and the rental rate is $r=9$.  I want to find the long-run cost of production, which I know is constrained by $\frac{MP_{L}}{MP_{K}}=w/r$ and therefore</p>

<p>$$\frac{10L^{-1/2}}{2} = 5/9$$</p>

<p>Which implies $L=81$.  However, I don't see how to find my quantity of capital, $K$.  Any help would be appreciated.</p>
","<p><strong>A)</strong> <strong>If we care about not making losses,</strong></p>

<p>one can observe that  </p>

<p><strong>a)</strong> $Q(K=0, L&gt;0) &gt;0$  (i.e. we can obtain positive output without capital)  </p>

<p>and   </p>

<p><strong>b)</strong> Output is linear in $K$ and $MP_K = 2$, while $r=9$. So for each unit of capital we will employ,  we will obtain $2$ additional units of output, but we will have to pay $9$ units of output as capital reward: employing capital means subsidizing it here, given its price. So we should not employ capital at all, since in light of a), we can have positive output without it.</p>

<p>On the other hand if, say, $L=1$ then $Q = 20$ while $wL = 5$. So there is room for production to be carried using only labor, without subsidizing the production factor.</p>

<p>So we have $K^* = 0$. But then, </p>

<p>$$C^* =  wL^*,\;\; L^* = \frac {\bar Q^2}{400}$$</p>

<p>The cost function now has a non-interesting minimum at zero, and then it monotonically increases.</p>

<p>In order not to make losses, we need </p>

<p>$$ \bar Q - C^* \geq 0 \implies \bar Q - w\frac {\bar Q^2}{400} \geq 0 \implies \left(1-w\frac {\bar Q^*}{400}\right) \geq 0 $$</p>

<p>$$ \bar Q \leq \frac {400}{w}$$</p>

<p>So, <strong>if we care about not making losses</strong>, a) We do not employ capital and b) output level should not exceed, for $w=5$, $Q \leq 80$.</p>

<p><strong>B) If we don't care about making losses</strong> (say, this is a public utility that has to deliver a specific level of output irrespective of whether it will cost more than the revenue obtained from selling the output)</p>

<p>Let's see where the standard approach leads us.</p>

<p>$$\min_{K,L} C = rK + wL  \;\;\;s.t.\;\; g(K,L) = 2K + 20L^{1/2} = \bar Q$$</p>

<p>for any given level of output.</p>

<p>The Lagrangean is</p>

<p>$$ \Lambda = rK + wL + \lambda[\bar Q-2K - 20L^{1/2}]$$</p>

<p>and if we calculate the first-order conditions for a minimum we get</p>

<p>$$\partial \Lambda/\partial K = 0 \implies r - 2\lambda =0 \implies \lambda = r/2 \tag{1}$$</p>

<p>$$\partial \Lambda/\partial L = 0 \implies w - \lambda\cdot 10L^{-1/2} = 0 \tag {2}$$</p>

<p>which for $r=9, w=5$ leads to a <em>candidate</em> solution $\{K^*,L^*=81,\lambda^* = 4.5\}$</p>

<p>To determine what happens at the candidate solution we need to consider also second-order conditions for a minimum</p>

<p>$$\partial^2 \Lambda/\partial L^2 = 5\lambda L^{-3/2} $$</p>

<p>$$\partial^2 \Lambda/\partial K^2 = \partial^2 \Lambda/\partial L\partial K =0$$</p>

<p>Then the bordered Hessian matrix (=matrix of second derivatives of the Lagrangean bordered by the first derivatives of the constraint, and a zero in the upper left position) is</p>

<p>$$\bar H = \left [ \begin{matrix}
0 &amp; 2 &amp; 10L^{-1/2} \\
2 &amp; 0 &amp; 0 \\
10L^{-1/2} &amp; 0 &amp; 5\lambda L^{-3/2} \\
\end{matrix} \right]$$</p>

<p>For the candidate solution to be a minimum, we need the bordered principal minors (minor determinants) to all be <em>strictly negative</em> except for the first which is by construction zero), at least evaluated at the candidate solution. We have</p>

<p>$$|\bar H_2| = \left | \begin{matrix}
0 &amp; 2  \\
2 &amp; 0  \\
\end{matrix} \right| = -4 &lt;0$$</p>

<p>and </p>

<p>$$|\bar H_3| = \left | \begin{matrix}
0 &amp; 2 &amp; 10L^{-1/2} \\
2 &amp; 0 &amp; 0 \\
10L^{-1/2} &amp; 0 &amp; 5\lambda L^{-3/2} \\
\end{matrix} \right| = 0 - 2\cdot10\lambda\cdot L^{-3/2} + 0 &lt;0 $$</p>

<p>for $\lambda , L$ strictly positive. So we 're good... except we do not know the value for $K^*$. <strong>Are we free to choose any level of capital we want?</strong></p>

<p>Certainly not. Remember that the multiplier $\lambda ^*$  is <em>optimal</em> Marginal Cost (as a function of output). But here, <strong>assuming non-zero Capital is employed</strong>, <em>optimal marginal cost does not depend on the level of output, it is fixed at $\lambda ^* =4.5$</em>, due to the linear appearance of $K$ in the production function, and the assumed price-taking behavior of the organization.  </p>

<p>In other words: if we employ capital, we should have fixed $MC(Q) = 4.5$. This means that as long as we can carry production with lower marginal cost than that, we should not employ capital. But if there is a level of output produced solely by labor, at and after which, to continue producing using only labor would result in marginal cost higher than $4.5$, then, it becomes optimal to start employ capital (optimal strictly in the sense of cost-minimization).  </p>

<p>Under production solely using labor we have</p>

<p>$$C = \frac {w\bar Q^2}{400} \implies MC = \frac {\bar Q}{40}$$ </p>

<p>So for $MC \leq 4.5 \implies \bar Q \leq 180$
After $\bar Q =180$ if we employ additional labor to increase production our marginal cost will be higher than if we start employing capital. And this will continue, because the marginal product of labor will be falling, while the marginal product of capital is constant. So we conclude that up to $\bar Q =180$ we should carry production using only labor, and after that, we should stop employing any additional labor, and cover all resource needs by employing capital, the level of which will evidently be determined as given in @BKay 's answer.</p>

<p>The full mathematical treatment would require turning this into a Karush-Kuhn-Tucker framework, and include multipliers for the case of decision variables taking the value zero.</p>
","4692"
"What are the known / alleged problems against using energy as currency?","2049","","<p>What are the known (and alleged) problems of using Joules (i.e. a measure of energy/work) as a currency? I tried to find such idea in Google (searched terms like ""technocracy"", since someone told me that technocracy had such idea), but I'm not clear about where to search in.</p>

<p>(<strong>Edit</strong> : asked in contrast to fiduciary/trust/faith-based currencies)</p>

<p>(<strong>Edit 2</strong> : found <a href=""http://www.theperfectcurrency.org/"" rel=""noreferrer"">this link</a>, but i'm not quite an expert in eco to judge the possible problems, not exposed in the article)</p>

<p>(<strong>Edit 3</strong> : This one is my fault since I asked a not-so-clear question, becuase my lack of knowledge. I have to clarify that this proposal is not mine, and I want to just study the concept. In this way, many principles I should enumerate are:</p>

<ol>
<li>Energy taken into account is the ""seizable"" energy, like solar or fossil.</li>
<li>Fossil energy can be stored. Fossil industry would be credited for that.</li>
<li>Solar energy can be captured, transformed, and injected into the power network to be credited for that [as currently is, in many countries, right now], and have such energy redeemed later; the only difference with the current situation is that [the modern proposals support that] the economy could be based in such energy, instead the vice-versa case.</li>
<li>The exchange act would not involve energy directly, since a <em>wallet</em> of that type could be quite dangerous to carry in the ... ¿pocket?.</li>
</ol>

<p>In this sense, I think useful answers have already been provided to cover the expressed points, althought I don't want to consider the answer as just-closed, but narrow the extent of the issues I want to understand about).</p>
","<p>The problems with using an energy-back currency are probably the same <a href=""http://en.wikipedia.org/wiki/Gold_standard#Disadvantages"">problems as using gold</a> or anything else. </p>

<p>Some of those mentioned in the link (<a href=""http://en.wikipedia.org/wiki/Gold_standard#Disadvantages"">Wikipedia article</a>) include</p>

<blockquote>
  <ul>
  <li><p>Mainstream economists believe that economic recessions can be largely mitigated by increasing the money supply during economic downturns. A gold standard means that the money supply would be determined by the gold supply and hence monetary policy could no longer be used to stabilize the economy. The gold standard is often blamed for prolonging the Great Depression, as under the gold standard, central banks could not expand credit at a fast enough rate to offset deflationary forces.</p></li>
  <li><p>Although the gold standard brings long-run price stability, it is historically associated with high short-run price volatility. It has been argued by Schwartz, among others, that instability in short-term price levels can lead to financial instability as lenders and borrowers become uncertain about the value of debt.</p></li>
  <li><p>The money supply would essentially be determined by the rate of gold production. When gold stocks increase more rapidly than the economy, there is inflation and the reverse is also true. The consensus view is that the gold standard contributed to the severity and length of the Great Depression.</p></li>
  </ul>
</blockquote>
","4687"
"What is the difference between shareholder's equity, equity, and book value?","2046","","<p>I have been doing some reading and I have found that shareholder's equity is equal to the company's total assets minus its total liabilities. Equity is apparently defined in much the same way. Book value is equal to the total assets minus intangible assets minus liabilities. So what is the actual difference between all of them?
<br>
Intangible assets seem rather hard to quantify, if I bought a house in a good neighborhood, its location could be called an intangible asset, right? But how do I measure this asset with a monetary value so that I can subtract it from its actual value?
<br>
What is the difference between all three of these concepts?</p>
","<p><strong>Equity</strong> is defined as </p>

<blockquote>
  <p>The value of an asset less the value of all liabilities on that asset. [<a href=""http://www.investopedia.com/terms/e/equity.asp"" rel=""nofollow"">source</a>]</p>
</blockquote>

<p>This is a rather broad definition and equity can take on different forms. E.g., for a house, it is the difference between the market value of the house and the mortgage still owned by the owner.</p>

<p>In the context of a company balance sheet, we usually talk about <strong>Shareholder's equity</strong>, which, as <a href=""https://en.wikipedia.org/wiki/Equity_%28finance%29"" rel=""nofollow"">Wikipedia</a> puts it</p>

<blockquote>
  <p>represents the equity of a company as divided among individual shareholders of common or preferred stock</p>
</blockquote>

<p>Contrary to the house example, the market value of a company, is the sum of all shares. And the <a href=""http://www.investopedia.com/terms/s/shareholdersequity.asp"" rel=""nofollow"">shareholder's equity</a> is that value (asset) subtracted from liabilities (creditors, etc.). See also <a href=""http://beginnersinvest.about.com/od/analyzingabalancesheet/a/shareholder-equity.htm"" rel=""nofollow"">this page</a>.</p>

<p>The <strong>book value</strong> is the value of an <a href=""https://en.wikipedia.org/wiki/Book_value"" rel=""nofollow"">asset</a>. But the difference with the Shareholder's equity is illustrated as</p>

<blockquote>
  <p>To find a company's book value, you need to take the shareholders' equity and exclude all intangible items. This leaves you with the theoretical value of all of the company's tangible assets which are those assets that can be touched, seen, and felt as opposed to things such as patents, trademarks, copyrights, and customer relationships. [<a href=""http://beginnersinvest.about.com/od/analyzingabalancesheet/a/book-value.htm"" rel=""nofollow"">source</a>]</p>
</blockquote>
","11607"
"Does the Federal Reserve buy and sell stocks?","2037","","<p>Can the Fed buy and sell stock in publicly traded companies? Is there evidence of this and, wouldn't this behavior drive the price as opposed to actual market forces?</p>
","<p>No, the Fed is not allowed to buy stocks, they are allowed to buy government securities in open market operations in order to achieve the target rate for the federal funds rate. The guidelines for this are explained in the <a href=""https://www.federalreserve.gov/aboutthefed/section14.htm"" rel=""nofollow"">Section 14</a> of the Federal Reserve Act. You can find the Fed holdings in the <a href=""https://www.federalreserve.gov/releases/h41/Current/h41.pdf"" rel=""nofollow"">Federal Reserve Statistics</a>.</p>

<p>However other central banks, like the Bank of Japan, started buying stocks as a measure to support their financial institutions (their banks were subject to too much market risk because of their stock holdings). The have detailed their stock purchasing plan in their <a href=""http://www.boj.or.jp/en/finsys/spp/index.htm/"" rel=""nofollow"">website</a>.</p>
","12227"
"Why are real median household incomes stagnant?","1985","","<p>This image shows US real median household income.</p>

<p><a href=""https://i.stack.imgur.com/hyB8A.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/hyB8A.png"" alt=""US Real Media Household Income""></a></p>

<p>It seems remarkable for its lack of growth over the last 20 years. This has been the subject of much political debate (around the ""1%"" and ""occupy Wall Street"" movements, etc.) but I am interested in more objective economic analysis of this phenomenon.</p>

<p>Given that people are better educated and are working with better technology (which should make them more productive), and that the real economy has grown more generally, what economic theories can explain the lack of growth in real median household income?</p>
","<p>I find your question very interesting. The metric of median household income is also used by others to argue the presence of income inequality:
<a href=""https://en.wikipedia.org/wiki/Income_inequality_in_the_United_States#Causes"" rel=""noreferrer"">https://en.wikipedia.org/wiki/Income_inequality_in_the_United_States#Causes</a></p>

<p>However, it seems that it is <a href=""https://research.stlouisfed.org/fred2/graph/?chart_type=line&amp;recession_bars=on&amp;log_scales=&amp;bgcolor=%23e1e9f0&amp;graph_bgcolor=%23ffffff&amp;fo=Open%20Sans&amp;ts=12&amp;tts=12&amp;txtcolor=%23444444&amp;show_legend=yes&amp;show_axis_titles=yes&amp;drp=0&amp;cosd=1953-01-01%2C1953-01-01&amp;coed=2014-01-01%2C2014-01-01&amp;height=445&amp;stacking=&amp;range=&amp;mode=fred&amp;id=MAFAINUSA672N%2CMEFAINUSA672N&amp;transformation=lin%2C&amp;nd=%2C&amp;ost=-99999%2C&amp;oet=99999%2C&amp;lsv=%2C&amp;lev=%2C&amp;scale=left%2C&amp;line_color=%234572a7%2C&amp;line_style=solid%2C&amp;lw=2%2C&amp;mark_type=none&amp;mw=2&amp;mma=0%2C&amp;fml=a%2C&amp;fgst=lin%2C&amp;fgsnd=2007-12-01%2C&amp;fq=Annual%2C&amp;fam=avg%2C&amp;vintage_date=%2C&amp;revision_date=%2C&amp;width=670"" rel=""noreferrer"">not only the median but also the mean that stagnates</a>:</p>

<p><a href=""https://i.stack.imgur.com/awxar.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/awxar.png"" alt=""Mean vs. median""></a></p>

<p>(I used family instead of household income because I could not find a time series for mean household income.)</p>

<p>If the problem was only one of inequality then the mean income should still increase.</p>

<p>I think there are several reasons why median household income seems to stagnate. </p>

<p>First of all I think there is a visible upward trend that is only somewhat masked by the 2008 financial crisis. Granted this trend is still smaller than the increase of productivity. Why median household income grows at a slower pace than before is still a question.</p>

<p>I think the problem arises because neither the number of households nor their distribution is constant.</p>

<h2>Changing size of households</h2>

<p>One thing that I believe has an effect is that <a href=""http://www.infoplease.com/ipa/A0884238.html"" rel=""noreferrer"">average household size has decreased over the period you are looking at</a>.</p>

<p><a href=""https://i.stack.imgur.com/gZ88b.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/gZ88b.png"" alt=""enter image description here""></a></p>

<p>(I had some trouble opening the <a href=""https://www.census.gov/hhes/families/data/households.html"" rel=""noreferrer"">Census Bureau's xls files</a>.)</p>

<p>So while total household income has in fact increased it is now divided between more numerous, smaller households making both the mean and the median smaller.</p>

<h2>Changing composition of the US labor force</h2>

<p>Another reason might be immigration. According to <a href=""http://cis.org/node/3877"" rel=""noreferrer"">this site</a> (I don't know if the statistics are reliable, there are a lot of links on the site I consider to be politically biased) the mean immigrant income is lower than the mean 'native' income. This is not surprising, immigrants need time to adjust and build the social networks necessary to get good jobs. Depending on the measure of productivity you use this can mean that while productivity in any given industry increases the weight of low-productivity industries increases as well. Thereby immigration may decrease mean and median income.
Note that this does not imply anything about the effect of immigration on the welfare of 'natives'. I am not claiming that the median household income of 'natives' is increased or decreased, I am pointing out that the weights used in the calculation are shifting.</p>
","10512"
"Investment = Saving relation in an open economy","1978","","<p>I am reading the book Macroeconomics by Olivier Blanchard.</p>

<p>It states that an alternative way of looking at an goods market equilibrium is <em>investment = saving</em>.  In an open economy it states the equilibrium condition is <em>Net Exports = Saving (both private and public) - Investment</em>.</p>

<p>I am struggling a little bit with the intuition of understanding this condition.  Would it be because the difference between saving and investment would contribute to the capital account aspect of the balance of payments in some way?</p>

<p>I would be very grateful if someone could help me to gain an understanding of this equilibrium condition.</p>

<p>Thankyou.</p>
","<p>First it should be clear that this is an (ex post) national account equality:</p>

<p>$Y=C+I+G+NX$, the private saving is $S_p=Y-C-T$ and public saving is $S_g=T-G$
thus you have $S_p+S_g-I=NX$.</p>

<p>Later you see in this book that the net exports, which depend on the exchange rate, are exactly equal to the Net Capital Outflow. Why? because an export is like a capital import (and vice versa).</p>
","5083"
"What is the difference between constant elasticity of substitution and elasticity of substitution?","1975","","<p>What is the difference between constant elasticity of substitution and elasticity of substitution? Are these formulas related? How are they different concepts? <strong>I just did a whole problem set involving these and got the right answers. But my thought process was all math. I don't feel like I understand them economically. And that's what I want explained.</strong></p>

<p>By CES, I mean
$$U(x,y) = A \left(\alpha x^{-\rho} + (1-\alpha) y^{-\rho}\right)^{-\frac{1}{\rho}}$$</p>

<p>By ES, I mean </p>

<p>$$\sigma = \frac{\mathrm{d}\log \left(\frac{x}{y}\right)}{\mathrm{d}\log \left(\frac{U_y}{U_x}\right)}$$</p>
","<p>Well, you didn't get the math <em>all</em> right, otherwise you might have seen it yourself! </p>

<p>By Elasticity of substitution, you <em>should</em> refer to</p>

<p>$$ \sigma(x,y) = \frac{\mathrm{d}\log \left(\frac{x}{y}\right)}{\mathrm{d}\log \left(\frac{U_y}{U_x}\right)} $$</p>

<p>Then, constant elasticity of substitution is a property of a function $U$ such that for some constant $\bar \sigma$,</p>

<p>$$ \sigma(x,y) = \bar\sigma \, \forall y, x$$</p>

<p>That is, the elasticity doesn't depend on $x,y$. What you showed as $U$ is a function that has exactly that feature. If you compute $\sigma(x,y)$ (do it!), you will see that</p>

<p>$$ \sigma(x,y) = \bar\sigma = \frac{1}{1+\rho}$$</p>

<p>That is, the elasticity of your $U$ function is constant for any allocation. Hence, we refer to that class of function (for different $\rho$) to Constant-Elasticity-of-Substitution-Functions (with share parameters $\alpha$). Cobb-Douglas preferences would be a special (limiting) case of that, with $\sigma(x,y) = 1$</p>

<h3>Example</h3>

<p>Say, we produce happiness ($U$) with apples ($x$) and oranges ($y$). Lets look at the allocation $\{5,1\}$. We only have one orange, but we would <em>really</em> want more. Hence, we are willing to give up 2 apples to get one orange, and we would be indifferent:</p>

<p>$$ U(5,1) = U(3,2)$$</p>

<p>It is <em>very easy</em> to substitute apples with oranges, we have a high elasticity of substitution. </p>

<p>Now look at the allocation $\{1,6\}$. Do you think that you would again be willing to lose $40\%$ of $x$ to get an increase of $50\%$ in $y$? Is it true that</p>

<p>$$ U(1,6) = U(0.6, 12)$$</p>

<p>If yes, that means that the elasticity of substitution of $U$ (or my rather handwaving approximation to it) is the same at the two allocations $\{1,6\}$ and $\{5,1\}$. If that was true for <em>all</em> possible allocations, $U$ was CES.</p>

<p>There are some reasons why you would think some preferences are perhaps not CES: For example, if $x$ and $y$ are good complements. Then, when you have little of $x$, you're willing to give up a lot for the other, but that elasticity might decrease the closer you are to equality between the two inputs.</p>
","5213"
"How are shell companies used for tax evasion?","1960","","<p>The <a href=""https://en.wikipedia.org/wiki/Panama_Papers"">recent release of leaked documents</a> on <a href=""https://en.wikipedia.org/wiki/Mossack_Fonseca"">Mossack Fonseca</a> has information on corporations and individuals using the firm's services for, among other things, tax evasion:</p>

<blockquote>
  <p>The massive security breach shows how a global industry of law firms and big banks sells financial secrecy to politicians, fraudsters and drug traffickers as well as billionaires, celebrities and sports stars. [...]</p>
  
  <p>Using complex shell company structures and trust accounts Mossack Fonseca services allow its clients to operate behind an often impenetrable wall of secrecy. Mossack Fonseca's success relies on a global network of accountants and prestigious banks that hire the law firm to manage the finances of their wealthy clients. </p>
  
  <p><sup><a href=""http://www.abc.net.au/news/2016-04-04/explained-what-are-the-leaked-mossack-fonseca-panama-papers/7270690"">Panama Papers and Mossack Fonseca explained</a>, Australian Broadcasting Corporation</sup></p>
</blockquote>

<p>What are ""shell companies"" and how can they be used to hide money or avoid paying taxes?</p>
","<p>Another key feature of those shell companies is that they hide the ultimate beneficiary of the transactions. Banks, insurance companies and most financial services firm must make enquiries as part of the ""Know Your Customer"" (KYC) regulations: they should be able to find out who will benefit ultimately from the transactions, or in the name of whom they are carried out. THeoretically (ate least in the EU), if they fail to identify an ultimate beneficiary, they should refuse to carry out the transaction AND warn the responsible authority (typically the local equivalent or representative of the FATF - Financial Action Task Force)</p>

<p>But a succession of shell companies in different countries, in particular in countries which apply a strict confidentiality of the investors of a company, make it very hard to be sure that the beneficiary identified is indeed the ultimate beneficiary. </p>

<p>Thus, those shell companies also serve the purpose to hide their owner to their counterparts. This feature is most appreciated for tax evasion and money laundering (obvisouly).</p>
","11410"
"Topological concepts in economic theory","1958","","<blockquote>
  <p>QUESTION: What are the major or systematic applications of post-1960s mathematics to microeconomics? </p>
</blockquote>

<p>For example, in the late 19th century, Fisher first used the mathematical ideas of Gibbs to construct modern utility theory. In the 20th century, Mas-Colell incorporated topological ideas to study general equilibrium. What about the late 20th, early 21st century? </p>

<p>For example, consider directed graph theory, measure theory, topology, the category theory and modern homology or cohomology, topos methods, functional integration, etc.  </p>

<p><em>Note 1</em>: econometrics/statistics, without modelling, is excluded. The only modern mathematics used there is random walk theory, and the ergodic problem, solved via complex analysis. RW and EP are not specific to economics.</p>

<p>Any appropriate economics publication is an answer. This included also those published in non-strictly economics journals, e.g. the <em>Journal of Mathematical Psychology</em>.</p>

<p><em>Note 2</em>:
Yes, I know, this type of work is rarer (not to be confused with obscurity: some of it is well known). That is what makes it easy to miss such a reference when it is published. Hence the question.</p>
","<p>I strongly suspect that an emerging important area for applications of measure theory will be in approximate dynamic programming techniques. Approximate dynamic programming (aka ""reinforcement learning"" in the computer science literature) has been the direction of research work in the last ~10-20 years of the dynamic programming literature. Economics is only just now starting to adopt some of these advances. For example of the direction of the DP literature, see Bertsekas' most recent <a href=""http://rads.stackoverflow.com/amzn/click/1886529442"">4th edition expansion</a> of his dynamic programming series, or Powell's <a href=""http://www.wiley.com/WileyCDA/WileyTitle/productCd-047060445X.html"">Approximate DP: Solving the Curse of Dimensionality</a>. Economists are just starting to pick up some of these tools, both directly and indirectly, and I suspect that they will have a growing impact on the literature over the next few years. Some of the analytical background for convergence of these methods is topology and dynamical systems.</p>

<p>A good example of theoretical contribution to this type of literature from economists is Pál and Stachurski (2013), <a href=""http://www.sciencedirect.com/science/article/pii/S0165188912001728"">Fitted Value Function Iteration With Probability One Contractions</a> (ungated version <a href=""http://rse.anu.edu.au/media/44366%5C560.pdf"">here</a>). Peruse that paper and you can see the importance of a good grasp of measure theory. Stachurski's book <a href=""http://mitpress.mit.edu/books/economic-dynamics"">Economic Dynamics</a> is actually a very nice exposition of dynamic programming from this perspective, building at a pace which works for multiple levels of graduate student/professional (measure theory comes in formally at the end I believe -- I'm still working towards those insights). </p>

<p>Hopefully this answers your question to some degree. I'm afraid that the phrase ""post-1960s mathematics"" is somewhat ambiguous to me (due to my own lack of knowledge of history of maths literature), so if I've completely missed the mark, my apologies!</p>
","297"
"Derivation of Arrow-Pratt risk aversion measure","1949","","<p>This is a question about the derivation of Arrow-Pratt relative risk aversion measure $R(w)=-\dfrac{U^{''}(w)}{wU^{'}(w)}$. </p>

<p>I have an own way to derive it, but I really want how did the authors themselves come up with it. </p>

<p>I do not own the book ""Essays in theory of risk-bearing"" (1971), where this has been done, and neither does the library in my university, so I can't settle this question on my own.</p>

<p>All I can read in online reviews is that measure was designed to stay stable under positive affine transformations, and that it's a measure of the curvature since it has the second derivative in the denominator, but that still does not answer the question of why and how the authors actually derived it.</p>

<p>Any help would be appreciated.</p>
","<p>Please find below the pages which may interest you.</p>

<p><img src=""https://i.stack.imgur.com/FTfYD.jpg"" alt=""Page 94"">
<img src=""https://i.stack.imgur.com/mBuj0.jpg"" alt=""Page 95"">
<img src=""https://i.stack.imgur.com/NnkWg.jpg"" alt=""Page 96""></p>

<p>Arrow, K. J. <em><a href=""http://www.worldcat.org/title/essays-in-the-theory-of-risk-bearing/oclc/1106663"" rel=""nofollow noreferrer"">Essays in the Theory of Risk-Bearing</a></em>, North-Holland Publishing Company, 1971</p>

<p>I let the admin delete this post if the few extracts are not allowed...</p>
","5338"
"Interpreting how graphs of Cobb-Douglas utility functions. How does MRS vary as we vary $\alpha$?","1907","","<p>Suppose I have the following Cobb-Douglas function $$U(x,y) = x^\alpha y^{1-\alpha} = 1$$ where $\alpha \in [0,1]$. </p>

<p>$$MRS = -\frac{U_x}{U_y} = - \frac{\alpha}{1-\alpha} \frac{y}{x} $$
$$\frac{\partial MRS}{\partial \alpha} = -\frac{1}{(1-\alpha)^2}\frac{y}{x}$$</p>

<p>So suppose I have the following set of graphs: 
<img src=""https://i.stack.imgur.com/EYVS0.png"" alt=""enter image description here""></p>

<p>Here I just picked some values. Red is $\alpha = \frac{1}{4}$, blue is $\alpha = \frac{1}{2}$, black is $\alpha = \frac{3}{4}$  </p>

<p>I understand how the steepness and flatness of the different curves change as I vary $\alpha$. But I am confused as to what $\frac{\partial MRS}{\partial \alpha} $ tells me about the graph. In particular, $\frac{\partial MRS}{\partial \alpha} $ is dependent on $\alpha$. So even though I know $\frac{\partial MRS}{\partial \alpha}$ tells me how much $MRS$ changes as I change alpha....changing $\alpha$ changes $\frac{\partial MRS}{\partial \alpha}$...so I am very confused!</p>

<p><strong>My Question</strong></p>

<p>What is $\frac{\partial MRS}{\partial \alpha}$ telling me about the graph? Since $\frac{\partial MRS}{\partial \alpha}$ is dependent on $\alpha$, how does this affect things? </p>
","<p>I think it is important to note that $MRS(x,y)$ is a function. There is exactly one indifference curve passing through $(x,y)$. $MRS(x,y)$ shows the steepness of this curve at point $(x,y)$. Then $\frac{\partial MRS(x,y)}{\partial \alpha}$ would show how much steeper the indifference curve passing through $(x,y)$ gets at this point if you change the parameter $\alpha$.</p>

<p>As YM'fr already stated in his answer, the interpretation of this is how the marginal substition rate (the rate at which she would be willing to trade) of a consumer in possesion of the goods package $(x,y)$ would change.</p>
","5179"
"Absolute vs Relative Risk Aversion","1904","","<p>Are there results that says the monotonicity of one measure of risk aversion implies the monotonicity of the other measure?</p>

<p>For example,</p>

<ul>
<li>Does constant relative risk aversion imply decreasing absolute risk aversion?</li>
<li>Does constant absolute risk aversion imply decreasing relative risk aversion?</li>
</ul>

<p>and so on.</p>
","<p>Given a utility function $u(c)$, $c&gt;0$, with $u'(c)&gt;0, u''(c) &lt;0$. Regarding the sign of the second derivative, if it is zero, then both measures are zero, if it is positive, it would imply increasing marginal utility, and I don't remember having seen these attitude-towards-risk measures for such a utility function.  </p>

<p>Denote Absolute Risk Aversion ($ARA$) and Relative Risk Aversion ($RRA$) correspondingly by </p>

<p>$$A(c) = -\frac {u''(c)}{u'(c)},\;\;\; R(c) = cA(c), \;\; A(c) = \frac 1c R(c)$$</p>

<p><strong>1) Monotonicity of $A(c)$ in relation to $R(c)$</strong></p>

<p>$$\frac {\partial A(c)}{\partial c} = \frac {\partial [(1/c)R(c)]}{\partial c}= -\frac 1{c^2} R(c) + \frac 1{c}\frac {\partial R(c)}{\partial c} $$</p>

<p>So if 
$$\frac {\partial R(c)}{\partial c} \leq 0 \Rightarrow \frac {\partial A(c)}{\partial c} &lt; 0$$ </p>

<p>$RRA$ weakly decreasing  $\Rightarrow ARA$ is strictly decreasing in $c$.  </p>

<hr>

<p><strong>2) Monotonicity of $R(c)$ in relation to $A(c)$</strong></p>

<p>$$\frac {\partial R(c)}{\partial c} = \frac {\partial [cA(c)]}{\partial c}=A(c) + c\frac {\partial A(c)}{\partial c} $$</p>

<p>So if $$\frac {\partial A(c)}{\partial c} \geq 0 \Rightarrow \frac {\partial R(c)}{\partial c} &gt; 0$$ </p>

<p>$ARA$ weakly increasing $\Rightarrow RRA$ is strictly increasing in $c$. </p>

<hr>
","468"
"Calculate deadweight loss from cost and inverse demand function in monopoly","1900","","<p>Consider a monopolist with inverse demand p = 200 - 2*q.  The firm's total cost function is C(q) = 100 + 20*q.  What is the deadweight loss of monopoly? </p>

<p>To my understading, since we don't have any tax added, this will be zero.Please help me understand.</p>
","<p>I'm going to give you the intuition behind this exercise, so you can solve it for your own. The definition of deadweight loss is the following:</p>

<blockquote>
  <p>In economics, a deadweight loss is a loss of economic efficiency that can occur when equilibrium for a good or service is not achieved or is not achievable. Causes of deadweight loss can include <strong>monopoly pricing</strong>, externalities, taxes or subsidies, and binding price ceilings or floors (including minimum wages).</p>
</blockquote>

<p>As you can read from the above definition a monopolistic regime causes a deadweight loss. In fact, if you compare the monopolistic regime vs. the perfect competition regime you will see that there is a loss in total surplus (which is your deadweight loss). The following graph perfectly fits and illustrates your case (since you have constant marginal costs):</p>

<p><a href=""https://i.stack.imgur.com/AMH8W.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/AMH8W.png"" alt=""enter image description here""></a></p>

<p>In order to compute the DWL then you need: the quantity of goods produced under monopoly ($Q_m$), the quantity of goods produced under perfect competition ($Q_c$) and the difference between the monopolistic price ($P$) and the marginal cost ($MC$). Once you have these values the DWL will be computed as the area of that green triangle:</p>

<p>$$DWL = \frac{(Q_c - Q_m) \cdot (P-MC)}{2}$$</p>

<p>So:</p>

<ul>
<li>compute the quantity produced under monopoly (recall that under monopoly $MR=MC$, solve for $Q$);</li>
<li>compute the price applied by the monopolist by substituting the quantity produced by the monopolist in $P = 200 - 2Q$</li>
<li>compute the quantity under perfect competition (remember that under perfect competition $P=MC$, solve again for $Q$)</li>
<li>compute the $DWL$ with the formula I gave you above.</li>
</ul>

<p>Hope this helps. Let me know if there is something not clear.</p>
","12360"
"Why does Slutsky compensation ""overcompensate"" the consumer?","1898","","<p>Suppose I have a Marshallian demand function $x_M(p_x^0,p_y,m^0)$. As I understand it, Slutsky compensation is defined as </p>

<p>$$T_S = \Delta p_x \cdot x_M(p_x^0,p_y,m^0)$$</p>

<p>Can someone explain why this compensation overcompensates the consumer?</p>
","<p>For both Slutsky transfer and Hicksian transfer, the only parameter changing in the problem is income $m$. You are adding money in the case of a price increase and removing money in the case of a price decrease.  For Hicksian, this means </p>

<p>$$T_H = e(p_x^f,p_y,v^o) - m$$ </p>

<p>For Slutsky </p>

<p>$$T_S = \Delta p x_M$$ </p>

<p>To understand why Slutsky overcompensates but Hicksian does not, we need to think more carefully about them. </p>

<p>Consider Hicksian compensation. The Hicksian transfer provides the consumer with just enough money to return to his original indifference curve. But he doesn't have enough to buy the original bundle. He only has enough to buy a bundle with the same utility level. This is the same point we would get if we solved </p>

<p>$$\min p_x^f x + p_y y$$ 
subject to 
$$v^o = U(x,y)$$
In other words, the Hicksian transfer moves us to the bundle that solves that problem. So for this reason Hicks doesn't overcompensate. It is exactly the amount required given the final price and desired utility level. Hence, it is tangent. </p>

<p>Now consider the Slutsky transfer. Algebraically, we can see it allows us to purchase the original bundle </p>

<p>\begin{align*} 
y &amp;= -\frac{p_x^f}{p_y} x + \frac{m + T_s}{p_y}\\
y &amp;= -\frac{p_x^f}{p_y} x + \frac{m + p_x^f x - p_x^o x}{p_y}\\
p_y y &amp;= -p_x^fx + m + p_x^f x - p_x^o x\\
p_y y &amp;=  m + - p_x^o x\\
p_y y + p_x^o x &amp;=  m 
\end{align*} </p>

<p>So it restores the ability to purchase the original bundle. But this line doesn't have the same slope as our original budget constraint before the price change. This one is parallel to the Hicksian transfer. Yet we already established that the Hicksian transfer was the solution to the expenditure minimization problem and hence tangent. Given that we usually assume strictly convex curves, it must form a chord and thus have bundles that offer greater utility than the Hicksian transfer. Thus, the consumer can move to a higher indifference curve. And so Slutsky transfer overcompensates the consumer because we can now buy bundles on higher indifference curves than prior to the price increase.  </p>
","5636"
"Empirical estimates of CRRA and CARA utility","1880","","<p>I am working on macroeconomic model and I need to calibrate it.
I am looking primarily for a statistically-founded estimate for the 
coefficient of relative risk aversion in the CRRA utility 
function based on macroeconomic US data (but also for the coefficient of absolute risk aversion for the case of a CARA utility function). Cannot seem to find it anywhere.
Can anybody help?</p>
","<p>In <a href=""http://ageconsearch.umn.edu/bitstream/30810/1/18010017.pdf"" rel=""nofollow noreferrer"">Babcock, B. A., Choi, E. K., &amp; Feinerman, E. (1993). Risk and probability premiums for CARA utility functions. Journal of Agricultural and Resource Economics, 17-24.</a> (downloadable) we find the following table (the first column is the coefficient of absolute risk aversion)</p>

<p><img src=""https://i.stack.imgur.com/YoRO5.png"" alt=""enter image description here""></p>

<p>You can download the paper and trace the papers which it summarizes in the table.</p>
","1602"
"Negative Gini Coefficiente?","1868","","<p>Is it possible to have a negative gini coefficient?
In which situations is it possible?</p>

<p>Any help would be appreciated.</p>
","<p><strong>tl;dr</strong> No, it is not possible to have a negative Gini coefficient.</p>

<p><a href=""http://en.wikipedia.org/wiki/Gini_coefficient"">The Gini coefficient is the area between the line of equality and the Lorentz curve</a>, and this area cannot be negative. Let the area of equality as in the link be denoted by $A$, and the area under the Lorentz curve be denoted by $B$, then the Gini coefficient is given by</p>

<p>$$ G = \frac{A-B}{B}$$</p>

<p>If negative income (or whatever you are measuring) is not permitted, the maximum inequality is $1$. If negative income is permitted, it can potentially be larger than $1$. In any case, the minimum for the Gini coefficient is $0$, which corresponds to total equality.</p>
","4988"
"What is the real reason for china's stock market crash (August 2015)?","1859","","<p>I have read douzons of explanations and they all basically claim the following:</p>

<blockquote>
  <p>China's stock market continued to boom despite the country's increasingly gloomy economic outlook, and this eventually created a bubble that popped.</p>
</blockquote>

<p>The above sentence cannot be more vague and although everyone claims it's true, no one seems to give an explanation for why it is true.</p>

<p>Why is there a bubble? what is a bubble? Can someone explain to me in more depth how would a booming stock market accompanied with a slow growth economy create a crash?</p>
","<p>Stock prices predominantly are a quantification of the company's future growth and profit prospects. These are expectations, and are partly based on how the specific company performs currently and has performed in the recent past, but also on what the ""general economic outlook"" looks like (expectations again): if it is ""gloomy"", we expect that this will constrain even the best of companies.</p>

<p>A usual ""stock market bubble"" is a situation where there is a unabated inflow of new investors (so new money, available to buy stocks, flows in the market), and where the general tendency of the prices of the stocks is to rise, and at a fast rate.</p>

<p>Experience has taught us that even in a sample of a few hundred companies, there is no way that the majority of them will excel in economic performance at the same time. So the ""short-term general tendency of stock prices to rise"" must come either from positive expectations on the ""general economic outlook"" (rather than the assessment of each individual company separately), or from a ""Ponzi-scheme"" climate, which is often the case at least in new stock markets in emerging economies: investors demand to buy stocks simply because they believe they will be able to quickly sell them at a higher price to somebody else, irrespective of what the ""economic fundamentals"" are, as regards actual economic performance. This fuels stock prices which in turn represent a signal to outsiders that indeed, they too can come in and play this game.</p>

<p>The thing with Expectations is that they may have no inertia: they can swing abruptly. So if in the middle of such a rising-stock-prices trend (which already may not be based on the actual economic performance, as said), comes a change of Expectations for the gloomier, suddenly investors ""see"" that the prices are over-inflated. The inflow of willing investors to buy at even higher prices suddenly stops, and those with the papers in their hands (but not with the money) start to accept lower and lower prices in order to reduce the damage. And this too happens <em>fast</em>.  And this is when ""the bubble bursts"".</p>
","7124"
"Effect of property tax on rent","1846","","<p>Suppose the government puts a tax on all apartment owners (e.g. a certain percentage of the apartment value), whether or not the apartment is rented. Will this tax cause an increase in rent?</p>

<p>From an economics point of view, it seems the answer should be no (at least in the short run): the tax has no effect on the supply or the demand so there is no reason that the rent should change. If landlords could take a higher rent, they would do so now. If they don't take a higher rent, it means that they cannot do so in the current market conditions, so they will not be able to raise the rent even when there is tax.</p>

<p>But from a psychological point of view, the answer may be yes. Why? Because landlords often don't raise the rent to the maximum possible level given the market conditions. Often, when a tenant rents an apartment for many years, the landlord prefers to keep the rent constant in order to keep good relations with the tenant. But, when there is tax, the landlords have an excuse to raise the rent. They can say ""we are sorry, we would really like to keep the rent as it is, but we must raise it to cover the new tax"".</p>

<p>Are these considerations correct?</p>

<p>What is more likely to happen in reality?</p>
","<p><strong>A property tax:</strong></p>

<p>In the short run, a property tax will have no effect on rent, as the supply of homes is fixed (i.e., supply is totally inelastic in the short run), and demand is relatively inelastic but not completely so, so the incidence will fall on property owners. In the long run, a property tax will increase rental costs because supply of new units (i.e., construction) is highly elastic and long-run demand for housing looks just like short-run demand— relatively inelastic. As a result, the incidence of the tax will fall on occupants (both renters and owner-occupiers). </p>

<p>Intuitively, one could think of it this way: the cost of ownership will increase due to the tax, so for someone to see it as worthwhile to buy a newly-constructed home to rent out, the rental income would have to be relatively higher in the presence of a property tax than if one were not in place.</p>

<p><strong>A tax on rental income:</strong></p>

<p>The tax will increase rent; it will decrease the supply (and demand) of rental units (and increase the supply and demand of owner-occupied units). This will happen because the tax will reduce the return on apartments as revenue assets, causing some number of landlords to sell them to owner-occupiers, taking them out of the rental market. More importantly, though, there will be some renters who do not have the option of switching to owner-occupancy, and they'll bear the incidence of a tax on rental income.</p>

<p>I am assuming that there are three populations:</p>

<ul>
<li>Landlords, <em>who can choose to purchase homes for rent</em>, but live elsewhere, so their choice to buy a unit to rent out can be analyzed separately from their own housing consumption</li>
<li>Renters, <em>who must rent</em>, due to some frictions (inability to afford a down payment, poor credit, unstable or difficult-to-document income history, etc.)</li>
<li>Potential owner-occupiers, <em>who can choose between owning their own home and renting from a landlord</em>, and who have some set of preferences between ownership and rental</li>
</ul>

<p>Thus potential owner-occupiers and landlords compete for units for sale, while renters and potential owner-occupiers compete for rental units. </p>

<p>In this case, the choice of landlords to exit due to taxes will not pass through perfectly to the rental market due to the fact that while <em>potential owner-occupiers</em> who are currently renting can escape the tax by switching to ownership, there are some <em>renters</em> who are renting whose demand for renting is pretty inelastic— these people will bear the incidence of the tax.</p>

<p>Interestingly, in the US there is such a tax on rental income, though it's implicit. We have a bunch of incentives for home ownership, notably the exemption from capital gains for owner-occupied homes, but most importantly <em>the fact that income on rental properties is taxed like any other business income</em>, while owner-occupiers effectively rent their homes to themselves without paying tax on the implied rental income. (As an aside, people often point to the income tax deduction for mortgage interest payments, but this actually just creates tax equivalence between homeowners and landlords, who can deduct interest as a business expense.)</p>
","8297"
"Quasilinear Preference and MRS","1812","","<p>Do quasi-linear indifference curves have MRS's that depend only on the nonlinear variable?  For example, for a U(x) = √(x) + y, I calculated that the y would not be in the MRS.  Does that mean that a consumer does not factor the consumption of a ""linear"" good y into their utility maximization? </p>

<p>If this is the case, can someone explain to me, practically, what it means for a good to be ""linear"" and for an MRS to exclude one variable?</p>
","<p>The MRS is a function of $x$ and $y$. The fact that $y$ doesn't appear in the formula simply means that this function is constant in $y$. </p>

<p>The linearity does not imply indifference. It means that an additional value of $y$ is valued equally by the agent irrespective of his baseline consumption. In your example, this contrasts with the marginal utility of consuming $x$ which is decreasing with the baseline consumption since the function $u$ is concave in $x$.</p>
","10481"
"Mathematical Micro/Macro Economics Textbook Recommendation","1782","","<p>I was formerly an economics major and now also majoring in mathematics.
I want a textbook that is rigorously based on mathematics; not just using mathematcis whenever the author wants, but in a more unified way to explain a concept.
I've learned enough mathematics in undergraduate level so mathematics will hardly be a problem. 
I've searched for information, but I really wanted textbooks that satisfy this specific condition; explaining concepts with sound mathematics in a unified way.</p>

<p>Any help will be grateful.</p>
","<p>You should also try <a href=""http://rads.stackoverflow.com/amzn/click/0273731912"" rel=""noreferrer"">Advanced Microeconomic Theory (3rd Edition)</a> by (Jehle, Reny, 2011).
Note that, imho, Mas-colell-Whinston-Green (1995!) is the best choice for those with initial background in Math switching to Economics. When it comes to Economics majors the former seems to be more appropriate (and more modern).
For modern Macro with strong math see <a href=""http://press.princeton.edu/titles/8903.html"" rel=""noreferrer"">Introduction to Modern Economic Growth</a> (Acemoglu, 2009).
To integrate the micro/macro problems with econometrics and math see ""Economic Modeling and Inference"" (Christensen &amp; Kiefer, 2009). Hope, that helps.</p>
","4879"
"Is zero inflation desirable?","1739","","<p>Is zero inflation really desirable?</p>

<p>To be more precise: Does inflation in real life have benefits that in some situations outweigh its social cost? E.g.: it works as a disincentive against holding money. The treasury derives income from printing new bills, which usually inflates prices.</p>
","<p>The optimal level of inflation is very debated with unclear answers. There are many reasons, and a great answer would be very long. It should also distinguish between expected inflation and surprises.</p>

<p>I'm not going to do any of this, but giving you three reasons for a desirable positive level of inflation. This list is of course incomplete, also there are many reasons against too high inflation.</p>

<h3>Downward-rigidity of wages</h3>

<p>It is really unclear to economists why it is happening, but nominal wages seem to be downward rigid. It appears to be a behavioral thing (and might not be true at all, see <a href=""https://ideas.repec.org/a/eee/moneco/v3y1977i3p305-316.html"">Barro (1977)</a>), but it appears that in crises, once presented with the choice of more firings or reduction of wages, most firms/workers decide to not cut wages but rather respond to the slump with increased separations.</p>

<p>To the extent that we believe this lack of reduction in wages is suboptimal, the central bank can enforce a reduction in real wages through increased inflation rates, and thus preventing separations to some extent.</p>

<h3>Redistribution</h3>

<p>This argument is based on Keynesian theory. Keynes claimed that the marginal propensity to consume out of income is smaller for rich households (and indeed, we do find this in the data  to some extent). <strong>Unexpected</strong> inflation is similar to redistribution from debtors to borrowers, as long as debt contracts are not indexed to inflation. </p>

<p>To the extent that poor people consume more out of this unexpected wealth shock and than rich people decrease their consumption, this redistribution will lead to an increase in aggregate consumption.</p>

<h3>Room to cutback interest rates</h3>

<p>This argument was most prominently brought forward by Krugman around 2008. In recessions, you want to be able to decrease nominal interest rates in order to punish households and firms for ""holding cash"" and incentivize them to spend it instead. If you start with low (say, 2-3%) nominal interest rates during normal times, you don't have a lot of space to cut back nominal interest rates during the crises.</p>

<p>If, instead, you would have higher nominal interest rates (Krugman argued for around 8%) and relatedly higher inflation during normal times, you could easier cut back nominal interest rates during busts and stimulate the economy.</p>
","5862"
"How to find corner Pareto efficient allocations","1703","","<p>I have some troubles in understanding how to find Pareto efficient allocation that are on the frontier of the Edgeworth box. I mean, the interior ones, can be found using the equality $MRS_A = MRS_B$, where $A$ and $B$ are the two agents of our pure exchange economy, whereas I cannot find anything about frontier allocations.</p>

<p>Is there any mathematical procedure I can use or it is only something I have to deal with using intuition (using the definition of Pareto efficiency I mean). </p>

<p>To be clearer, I cite an exercise from my workbook where there are two agents with preferences $u^A(x_1,x_2) =\sqrt{x_1x_2}$ and $u^B(x_1,x_2)=x_1+3x_2$, and endowments $\omega^A=(1,0)$ and $\omega^B=(0,1)$. The question is to identify the Pareto set.</p>

<p>This is the solution, where the blue lines are the Pareto set.
<a href=""https://i.stack.imgur.com/LveEM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LveEM.png"" alt=""Solution""></a></p>
","<p>Let us take your example: </p>

<ul>
<li>First, we note that both utility functions are differentiable and quasi-concave.  </li>
<li>Noting this, we also know that the necessary and sufficient condition for internal Pareto optimality is that $MRS_{x_1,y_1}$=$MRS_{x_2,y_2}$ (as you have already correctly stated).</li>
</ul>

<p>This condition will clearly coincide with the portion of the solution identifying the locus on internal P.O. allocations. </p>

<p>Now, for the P.O. points along the right edge: </p>

<ul>
<li>We can find the bound of internal solutions by identifying the range over which the MRS condition noted above fails. </li>
<li>Because the equality fails, we know a strict inequality must prevail. </li>
<li>The directionality of the prevailing strict inequality identifies the edge along which we find our P.O. allocations.  </li>
</ul>

<p>So, there are two ways to answer your question, I think. </p>

<p>1.) For this type of graph, where one agent has linear preferences and the other has curvilinear and convex preferences, it is easy to see that the locus of P.O. allocations shifts toward the right edge of the Edgeworth box. Thus, corner solutions run along that edge across the range where points of tangency are no longer interior. </p>

<p>2.) If you encounter a situation where, for example, both agents have linear preferences, you can use the directionality of the strict inequality to identify along which edges of the Edgeworth box you have P.O. allocations. </p>

<p>An example for 2.) : </p>

<p>$U_1(x_1,y_1)=X_1+2Y_1$ and $U_2 = 2X_1+Y_1$ </p>

<p>Now, you should do the following: </p>

<ul>
<li>ensure you understand why $MRS_1 \neq MRS_2$</li>
<li>determine the direction of the strict inequality between the two </li>
<li>use this to identify along which edge of the box you will have P.O. allocations. </li>
</ul>

<p>Hints: </p>

<ul>
<li><p>$MRS_A&lt;MRS_B$ </p></li>
<li><p>the P.O. allocations are along the left and upper edges of the Edgeworth box</p></li>
</ul>

<p>Edit: </p>

<p>I also think this is a good reference:</p>

<p><a href=""http://nicolalimodio.com/wp-content/uploads/2015/11/ec202d.pdf"" rel=""nofollow"">http://nicolalimodio.com/wp-content/uploads/2015/11/ec202d.pdf</a></p>

<p>Hope something in there helps. This was an issue for me as well when I began learning such things and it took me a bit of reading and practice to finally become comfortable with it all. </p>
","11589"
"Government bonds and printing money","1699","","<p>Wikipedia: <em>If a central bank purchases a government security, such as a bond or treasury bill, it increases the money supply, in effect creating money.</em></p>

<p>My question is: what is the difference between this (government issues bonds and the central bank buys them) and directly printing money? If any. If there is no difference, then why would a government chose one way or the other?</p>
","<p>The difference is that in buying the bond, the central bank now owns a bond, and a fiscal deficit has not been directly monetised.</p>

<p>That means that:</p>

<ol>
<li><p>the government will have to keep paying interest on the bond, to the central bank, and will have to redeem it if it's not a perpetual. Remember, some governments are completely distinct entities from central banks, with no guaranteed way to move money between them in a consequence-free manner: the Eurozone governments are a good example.</p></li>
<li><p>The central bank can sell that bond when it wants to, giving it an extra means of contracting the money supply.</p></li>
<li><p>Currency speculators are less likely to start circulating around the currency like vultures that have spotted dying prey.</p></li>
</ol>
","6478"
"What is the definition of a ""Stackelberg leader-leader equilibrium""?","1678","","<p>I have encountered the equilibrium concept of ""Stackelberg leader-leader equilibrium"" while reading <a href=""http://www.jstor.org/stable/1804010?seq=1#page_scan_tab_contents"">Product Line Rivalry</a> (AER, Brander and Eaton (1984). They say ""we define a Stackelberg strategy as one which involves taking into account the contemporaneous reaction of one's rival in setting one's own strategy"". That definition does not really help me.</p>

<p>They also mention that this equilibrium concept is another way of interpreting the <a href=""http://books.google.com/books?id=dghH9OH5fDoC&amp;lpg=PR7&amp;ots=OZR6MfPESK&amp;dq=Market%20Structure%20and%20Equilibrium&amp;lr&amp;pg=PP1#v=onepage&amp;q&amp;f=false"">original</a> <a href=""http://en.wikipedia.org/wiki/Stackelberg_competition"">Stackelberg model</a> (which I know). </p>

<p>Does anyone have a reference or an explanation ? Of course, Google only returns results on the leader-follower game.</p>
","<p>A leader-leader Stackelberg is a situation in the Stackelberg model where both firms believe they are leaders. This leads to global production being much higher than expected by both firms, as they anticipate small production by the other firm in response to their high production.</p>
","5545"
"What is the difference between risk, uncertainty and ambiguity","1670","","<p>I am trying to pin down the difference between risk, uncertainty and ambiguity. </p>

<p>As I understand, when behavioral economists talk about choice under uncertainty, they mean choice when agents face risk (known probability distribution over a range of outcomes) versus ambiguity (unknown probability distribution). So uncertainty is a blanket concept that can be broken down into risk and ambiguity. See for example <a href=""http://link.springer.com/article/10.1007/s10640-014-9796-6"" rel=""noreferrer"">Dannenberg et al (2014)</a>.</p>

<p>I also understand there is a debate on the meaning of these terms going back to Knight (1921) and Ellsberg (1961). Are there any competing definitions to the one above?</p>
","<p>Here is a decision-theoretic formalization of your definitions.</p>

<p>The usual framework to talk about objective risk is the situation where a decision-maker expresses preferences over objective lotteries. Formally, if $X$ is a prize space, objective lotteries are defined as elements of the space $\Delta(X)$ of probability distributions (usually with finite support) over $X$. For instance, the decision-maker might be asked to form preferences between the lottery that offers her/him an apple with probability 0.3 and an orange with probability 0.7, and the lottery that offers her/him an apple with probability 0.5 and an orange with probability 0.5. The standard result in that area (von Neumann-Morgenstern theorem) delivers a representation that identifies the agent's attitude towards objective risk (her/his utility function), while the probabilities are given as a primitive of the model.</p>

<p>The usual framework to talk about ambiguity is the situation where a decision-maker expresses preferences over uncertain acts. Formally, if $X$ is a prize space and $S$ is a state space, acts are mappings $f:S \rightarrow X$ from $S$ to $X$. For instance, the decision-maker might be asked to form preferences between the act that offers her/him an apple if Novak Djokovic wins the 2017 Australian Open and an orange otherwise, and the lottery that offers her/him an apple if Andy Murray wins the 2017 Australian Open and an orange otherwise. The standard result in that area (von Neumann-Morgenstern theorem) delivers a representation that identifies both the agent's probabilistic beliefs regarding the states and her/his attitude towards risk (her/his utility function).</p>

<p>There is a third widely used concept, usually called Anscombe-Aumann acts or horse races, which associates both objective lotteries and uncertain acts. Formally, given a prize space $X$, an Anscombe-Aumann act is a mapping $f:S \rightarrow \Delta(X)$ that associates an objective lottery to any state in $S$.</p>

<p>Notice that the definitions of objective risk and ambiguity are to some extent subjective. The fact that risk is called ""objective"" relies very much on the assumption that the decision-maker agrees with the underlying probability model. For instance, if you observe the outcome of a coin toss, you might believe that heads happen with an objective probability of 0.5. It is implicitly imposed in the theory that the decision-maker agrees with this statement.</p>

<p>Regarding ambiguity, you might yourself believe that the act ""receive an apple if Novak Djokovic wins the 2017 Australian Open"" is very ambiguous because you have no idea on how to compute a subjective probability for this event. That said, another decision-maker might very confidently believe that Djokovic has a 74% chance of winning the tournament, in which case she/he does not perceive this act as ambiguous at all. Ambiguity is a subjective notion, which is given by people's preferences and behavior and not by the choice situation itself.</p>
","14778"
"Has the world become poorer?","1669","","<p>This question is not backed by serious economic research but mainly by a very simple attempt to look at how the world economy has changed.</p>

<p>I am asking whether and why the world has, over the past 50 or so years, become less productive (not used in the strict economic sense here) and therefore people have less money to do stuff/buy things.</p>

<p>Several reasons why I believe this to be the case (I am open to be corrected):</p>

<ul>
<li>Real wages in developed economies have not risen for a long time</li>
<li>Financial crisis now been going on for many years (almost 10)</li>
<li>Unemployment in the EU is very high</li>
<li>Tax rates are ever-increasing (it seems) relative to median wages</li>
<li>More and more people are reliant on welfare (from what I gather, unfortunately I don't have a source at this point</li>
<li>Growth in developing countries (China) has decreased</li>
<li>National debts are ever-increasing</li>
</ul>

<p>This has left me with the feeling that in many situations, there is simply 'less' money to go around and be spent. I can observe this, for example, by the seemingly constant need of companies and countries (even where I live, in wealthy Switzerland) to save money and reduce expenses <em>(I don't know if it only seems this way because of some biases or it is actually the case)</em>.</p>

<p>Again, not sure if this is actually happening or if it only seems so to me (Also apologies for not being able to express this in very 'economy' terms).</p>

<p>Several reasons that I could explain to myself why it would seem like we have less to spend and are less productive than we used to be:</p>

<ul>
<li>Rising inequality (the rich keep getting more so the majority has less)</li>
<li>Less incentive for technological progress (apart from in IT). In many industries, there is no reason to keep making everything better, only to make it cheaper and more profitable. We have most of what we need and don't see a point in improving it (cupboards, beds, kitchen utensils etc.) </li>
<li>Lethargy of people. Many people are happy with what they have and do not want to work more/harder</li>
<li>We have most of what we need, and the things that are left to buy are luxury items (which we maybe didn't think about before)</li>
</ul>

<p>Again sorry for the very vague way of asking this question without any evidence, but if someone could help me make it more concrete I would be very open to that.</p>

<p>I guess what I want to say is do people have less money and less to spend than they used to, and if so, why?</p>
","<p>The short answer is No. </p>

<p>Every single year, except 2009, for the past 55 years of continuously recorded economic history, the world has been getting richer. The -2.1% global recession in 2009 was made up in 2010 with 4.1% growth. I was just working with the World Bank's World Development Indicators, which track global GDP growth, and I double checked.</p>

<p>We measure prosperity and growth by the quantities of goods produced. Money is irrelevant. Every year we, humans, produce more and more goods and services and that makes us richer. Not every country grows steadily though. Some countries are stagnant, like Greece, and some grow remarkably rapidly over very long periods of time, like China. Moreover, there is increasing inequality withing many countries (measured by GINI coefficient). So it is very natural for many to feel like everything around them either stands still or degrades. But on average, the world keeps getting richer.</p>

<p>If you are in Switzerland, you may have felt the shock from recent currency appreciation. Sharp currency appreciations hammer exporters and industries reliant on tourism, which make up a large portion of Swiss economy.</p>
","9208"
"Does Inflation Make Money Eventually Worthless?","1654","","<p>I used this calculator: <a href=""http://www.buyupside.com/calculators/inflationjan08.htm"">http://www.buyupside.com/calculators/inflationjan08.htm</a>
to estimate the future worth of 100 dollars in 100 years at 2% inflation. Does this really mean that a decent meal at a restaurant will cost about a $100 in the future or am I misunderstanding something? So basically what I'm asking is if at some point in the future will McDonald's Dollar menu become the Hundred Dollar menu?</p>
","<p>""Worth less"" than before - yes, that's exactly what inflation does.</p>

<p>""Worthless"" - not quite. No percentage-based reduction in value can make something worth 0, but there are extreme examples from history of times inflation has spiralled so far out of control (<a href=""https://en.wikipedia.org/wiki/Hyperinflation"" rel=""nofollow noreferrer"">""hyperinflation""</a>), money became worth less than the paper it was printed on, and life savings became <em>almost</em> worthless. </p>

<p><a href=""https://en.wikipedia.org/wiki/Hyperinflation_in_the_Weimar_Republic"" rel=""nofollow noreferrer"">1920s Germany is the most famous example</a>, but there are more recent examples, such as Zimbabwe. </p>

<p>This is a <a href=""https://en.wikipedia.org/wiki/Banknotes_of_Zimbabwe"" rel=""nofollow noreferrer"">real Zimbabwean banknote from 2009</a> - you don't need the <a href=""https://en.wikipedia.org/wiki/Hyperinflation_in_Zimbabwe#Inflation_rate"" rel=""nofollow noreferrer"">terrifying inflation rates</a> to see that savings of thousands of Zimbabwean dollars made in the early 2000s had become <em>effectively</em> worthless:</p>

<p><img src=""https://i.stack.imgur.com/mq6sO.jpg"" alt=""enter image description here""></p>

<p>But those are extreme examples.</p>

<hr>

<p>As for the idea of a McDonald's <code>$100</code> Menu - it wouldn't be unbelievable looking at history. </p>

<p>According to <a href=""http://measuringworth.com/"" rel=""nofollow noreferrer"">measuringworth.com</a>, <code>$1</code> one hundred years ago would buy the equivalent of <code>$24</code> of common retail goods and the equivalent of <code>$99</code> of the time of an unskilled labourer. A time-traveller from 1914 would expect a ""<code>$1</code> menu"" to be high quality dining, worth days' wages for the average Joe. Not so different to how the idea of a <code>$100</code> menu seems to us today,</p>

<p>This seems like a big change - but even this is a small change by international standards. </p>

<p>The US dollar has historically been one of the world's most stable currencies, partly related to its <a href=""http://www.investopedia.com/articles/07/unofficial_dollarization.asp"" rel=""nofollow noreferrer"">use in international trading</a> and its status as a <a href=""https://en.wikipedia.org/wiki/Reserve_currency"" rel=""nofollow noreferrer"">reserve currency</a>. In other countries, even countries with relatively stable economies, such changes do happen in a person's lifetime. Here in the UK, it's a cliche for elderly people to complain that ""in our day"", meals could be bought for sums of money that today would considered small change.</p>

<hr>

<p>But even though it'd be perfectly believable, it might not happen. Beware of extrapolations that assume trends won't change (<a href=""http://xkcd.com/605/"" rel=""nofollow noreferrer"">cartoon from XKCD</a>): </p>

<p><img src=""https://i.stack.imgur.com/3GNpw.png"" alt=""enter image description here""></p>

<p>Anything could change. The US dollar might not keep its current world status. Governments influence inflation, and may sometimes simply change currency values if they feel it's getting out of hand. For example, <a href=""https://en.wikipedia.org/wiki/Romanian_leu#Fourth_leu_.28RON.29:_2005-Present"" rel=""nofollow noreferrer"">in 2005 Romania knocked 4 zeros off its currency. 10,000RON became 1RON overnight</a>.</p>
","1821"
"Why is the percent of Australian businesses that don't have any employees so high?","1637","","<p>I'm trying to understand this Australian Bureau of Statistics release:</p>

<p><a href=""http://www.abs.gov.au/ausstats/abs@.nsf/mf/8165.0"" rel=""nofollow"">http://www.abs.gov.au/ausstats/abs@.nsf/mf/8165.0</a></p>

<p>It says:</p>

<blockquote>
  <p>In June 2014, 61% of actively trading businesses in Australia had no
  employees, 27% had 1-4, 10% had 5-19, 2% had 20-199, and less than 1%
  had 200 or more.</p>
</blockquote>

<p>I didn't realise so many businesses didn't have employees. Why is this percentage so high?</p>
","<blockquote>
  <p>Employment excludes non-salaried directors, volunteers, persons paid by commission only, and self employed persons such as consultants and contractors.</p>
</blockquote>

<p>The actively trading businesses with zero employees are therefore those businesses where the staff members are drawn exclusively from that group. That may cover most one-person outfits, perhaps some family firms, groups of self-employed people, and so on. These businesses are typically formed in that way as a response to particular regulations, usually tax rules.</p>

<p>The answer is in <a href=""http://www.abs.gov.au/AUSSTATS/abs@.nsf/Lookup/8165.0Explanatory%20Notes1Jun%202010%20to%20Jun%202014?OpenDocument"">the explanatory notes attached to that dataset</a>, section 56, from where the above quote is taken.  The explanatory notes are attached to that dataset to answer questions such as this. When you have questions about a particular dataset, the explanatory notes (which might also be called metadata, data descriptors, or similar), will usually have the answer, as they do in this case, and should be any enquirer's first place to look.</p>
","8540"
"How does one graph indifference curves for a set of Lexicographic preferences?","1615","","<p>Two Questions: </p>

<ol>
<li>Since Lexicographic preferences are not continuous, is it still appropriate to use $\Bbb{R}^n_+$ to define my coordinate axes when drawing Lexicographic preferences? If not, what should I use instead? </li>
<li>Since the indifference sets for Lexicographic preferences are singletons, how do I draw them? What's the convention? Will a single point do? </li>
</ol>

<p>(related to <strong><a href=""https://economics.stackexchange.com/questions/4972/for-a-given-set-of-consumption-bundles-how-do-we-know-there-are-bundles-that-th"">this question</a></strong>)</p>
","<ol>
<li><p>You can draw discontinuous functions in a standard $R^2$ space. For example when you draw a floor functions (a discontinuous function), the standard coordinates are still appropriate. Just make clear what to what part the discontinuous point belongs to.
Usually, for lex. preferences, one draws only the preferred set. <a href=""http://www.econ.ohio-state.edu/miyazaki/econ804/LEXICO.pdf"" rel=""nofollow"">Here</a> you can find a graph of this kind (page 2).</p></li>
<li><p>Yes, each point is an ""indifferent singleton"" (if we may say so, as your set has only one element, and of course you're indifferent between the same thing). 
The infinity number of points is not a problem. When you draw a preference map (for standard preferences), there are an infinite number of possible indifference curves. The idea is just to know how many you need to make your point. If you're using a software, you can plot with colors instead of a huge number of lines...</p></li>
</ol>
","5069"
"Which utility function yields a constant price elasticity of demand function?","1612","","<p>How do I know which utility function I can use to find an isoelastic demand function, e.g., $x(p)=Ap^a$? 
And similarly, which cost function can I use to find an isoelastic supply function?
Does it work through trial and error, or is there a particular method?</p>
","<p>By <strong>Roy's Identity</strong> we have that Marshallian (uncompensated) demand for good $x_i$ is</p>

<p>$$x_i^M = \frac {\partial U^*/\partial p_i}{\partial U^*/\partial B} \tag{1}$$</p>

<p>where $U^*$ is optimized utility over goods vector $\mathbf x = (x_1,...,x_i,...x_n)$ and $B$, which is the available budget, and given the price vector $\mathbf p = (p_1,...,p_i,...,p_n)$. To obtain a constant elasticity demand function we require</p>

<p>$$\eta \equiv \frac {\partial x_i^M}{\partial p_i}\cdot \frac{p_i} {x_i^M}=const. \tag{2}$$</p>

<p>Using $(1)$ we have that </p>

<p>$$\frac {\partial x_i^M}{\partial p_i} = \frac {(\partial^2 U^*/\partial p^2_i)\cdot(\partial U^*/\partial B) -(\partial^2 U^*/\partial B^2)\cdot (\partial U^*/\partial p_i)}{\big[\partial U^*/\partial B\big]^2} \tag{3}$$</p>

<p>Inserting $(3)$ <em>and</em> $(1)$ into $(2)$ we have </p>

<p>$$\eta \equiv \frac {(\partial^2 U^*/\partial p^2_i)\cdot(\partial U^*/\partial B) -(\partial^2 U^*/\partial B^2)\cdot (\partial U^*/\partial p_i)}{\big[\partial U^*/\partial B\big]^2}\cdot \frac{p_i} {\frac {\partial U^*/\partial p_i}{\partial U^*/\partial B}}$$</p>

<p>$$= \frac {(\partial^2 U^*/\partial p^2_i)\cdot(\partial U^*/\partial B) -(\partial^2 U^*/\partial B^2)\cdot (\partial U^*/\partial p_i)}{(\partial U^*/\partial B)\cdot (\partial U^*/\partial p_i)} \cdot p_i$$</p>

<p>$$\implies \eta = p_i\left(\frac {\partial^2 U^*/\partial p^2_i}{ \partial U^*/\partial p_i}- \frac{\partial^2 U^*/\partial B^2}{\partial U^*/\partial B}\right) \tag{4}$$</p>

<p>For this expression to be constant over the whole range of $p_i$ we need that</p>

<p>$$\left(\frac {\partial^2 U^*/\partial p^2_i}{ \partial U^*/\partial p_i}- \frac{\partial^2 U^*/\partial B^2}{\partial U^*/\partial B}\right) = \frac {C}{p_i} \tag{5}$$</p>

<p>for some constant $C$, which becomes the constant value of the price elasticity of demand.</p>

<p>That's the general condition that must be satisfied.  </p>

<p>You could check whether the generalized Cobb-Douglas standard Utility function specification</p>

<p>$$U(\mathbf x) = \prod_{i=1}^n x_i^{a_i}$$</p>

<p>satisfies the condition, perhaps under some restrictions.  </p>

<p><strong>THE CASE OF QUASI-LINEAR UTILITY FUNCTION</strong>  </p>

<p>The OP ponders the case of a quasi-linear utility function, so let's solve this forward. We have</p>

<p>$$\max_{x,m} [cx^{\theta} +m],;\;\;\; s.t. \;\;\;p_xx + m = B,\;\;\; 0&lt;\theta &lt;1,\;\; c&gt;0$$</p>

<p>where $m$ is residual income for all other goods. The Lagrangean is</p>

<p>$$\Lambda = cx^{\theta} +m + \lambda[B-p_xx - m]$$
and first order conditions are</p>

<p>$$c\theta x^{\theta-1}=\lambda p_x,\\\;\;\; \lambda =1$$</p>

<p>So</p>

<p>$$x^* = \left(\frac {c\theta}{p_x}\right)^{1/(1-\theta)},\;\;\; m^* = B-p_xx^*$$</p>

<p>So the indirect utility function is</p>

<p>$$U^* = c\left(\frac {c\theta}{p_x}\right)^{\theta/(1-\theta)} + B-p_x\left(\frac {c\theta}{p_x}\right)^{1/(1-\theta)}$$</p>

<p>$$= \left[c(c\theta)^{\theta/(1-\theta)} - (c\theta)^{1/(1-\theta)}\right] \cdot \frac {1}{p_x^{\theta/(1-\theta)}} + B$$</p>

<p>One can easily verify that this indirect utility function satisfies the required condition $(5)$ for isoelastic demand, and also see how the preference parameters map to the demand parameters.</p>
","8416"
"Euler's theorem and Cobb-Douglas","1568","","<p>When I apply Euler's Theorem onto the Cobb-Douglas equation I receive the Cobb-Douglas equation back. That is, there is no change after applying the theorem. Can someone please explain what the intent and point of this is, seeing no difference? </p>
","<p>You are probably talking about Euler's homogeneous function theorem <a href=""http://mathworld.wolfram.com/EulersHomogeneousFunctionTheorem.html"" rel=""nofollow"">http://mathworld.wolfram.com/EulersHomogeneousFunctionTheorem.html</a> , which shows that you can decompose a function into its partial derivatives based on its homogeneity. </p>

<p>So a typical Cobb Douglass $U(x,y)=x^ay^{1-a}$</p>

<p>This function is homogeneous of degree 1 because when we multply each argument by a scalar:</p>

<p>$U(cx,cy)=(cx)^a(cy)^{1-a}=cx^ay^{1-a}=cU(x,y)$</p>

<p>So if we apply the theorem to this function we get:</p>

<p>$U(x,y)=xU_x+yU_y=xax^{a-1}y^{1-a}+x^ay(1-a)y^{-a}=x^ay^{1-a}$</p>

<p>So the result that we get back the original utility is expected. </p>
","13281"
"Monopoly pricing under constant elasticity of demand","1527","","<p>While reading Ch. 24-Monopoly from Intermediate Microeconomics by Hal Varian (8 <sup>th</sup> edition), on pg. 441, he writes that a monopolist will never choose to operate where the demand curve is inelastic. I understand the argument, but, if we have constant elasticity demand curve with</p>

<p>$|\epsilon| &lt; 1 $</p>

<p>then how this effect the monopolist's choice?</p>
","<p>In <a href=""https://economics.stackexchange.com/questions/1726/price-elasticity-of-demand-for-positive-price-increases/1728#1728"">this post</a> you can find the algebraic steps that lead to the (standard) result mentioned in Varian's book.  </p>

<p>Now, let's assume that, in a specific market, the consumer's preferences are such that they lead to a constant elasticity demand curve, with elasticity lower than unity in absolute terms, $|\eta| &lt; 1$, for example</p>

<p>$$Q^d = AP^{\eta}, -1 &lt;\eta &lt; 0$$ 
Also, let's assume that for historical or institutional reasons this market is a monopoly. From the post mentioned above we have that profit maximization by the monopolist requires that
$$P^* =  \frac {|\eta|}{|\eta|-1} MC \tag{1}$$</p>

<p>where</p>

<p>$$\eta = \frac {\partial Q }{ \partial P}\cdot \frac {P}{Q} \Rightarrow \frac {\partial Q }{ \partial P} = \eta \cdot \frac {Q}{P} \tag{2}$$
and $MC$ is marginal cost.
Obviously, this price is negative in our case, and so meaningless. We don't need to go into sophisticated constrained maximization procedures to see what happens here: the profit function is
$$\pi = P\cdot Q(P) - C(Q(P)) \tag{3}$$
and its derivative with respect to price is
$$\frac {\partial \pi}{\partial P}  = Q + P\frac {\partial Q }{ \partial P} - MC\cdot \frac {\partial Q }{ \partial P}  \tag{4}$$</p>

<p>Using $(2)$ we get</p>

<p>$$ \frac {\partial \pi}{\partial P}=Q + P\cdot \eta \cdot \frac {Q}{P} - MC\cdot \eta \cdot \frac {Q}{P} $$</p>

<p>$$\implies \frac {\partial \pi}{\partial P}= Q\cdot \left [1 + \eta  -  \eta \cdot \frac {MC}{P}\right]$$</p>

<p>$$\implies \frac {\partial \pi}{\partial P}= Q\cdot \left [1 - |\eta|  +  |\eta| \cdot \frac {MC}{P}\right] \tag{5}$$</p>

<p>From $(5)$ we see that</p>

<p>$$|\eta| &lt; 1 \implies \frac {\partial \pi}{\partial P} &gt; 0,
\;\; \forall P &gt;0 \tag{6}$$</p>

<p>So a profit maximizing monopolist would theoretically have the tendency to increase the price to ""infinity"" sending the quantity supplied to zero. Note that the Revenue function here is</p>

<p>$$R = P\cdot Q^d = P\cdot AP^{\eta} = AP^{1-|\eta|},  \uparrow \text{in} \;P$$</p>

<p>while Costs are decreasing in $Q^d$. So indeed profits would tend to infinity by selling less and less for higher and higher price.  </p>

<p>What markets could be described by such tendencies?</p>
","5016"
"Utility function is given as $U = \sqrt{XY}$ find","1522","","<p>Matthew has a utility function $U = \sqrt{XY}$ where X represents hot dogs and Y represents apples. He has an income of $20. </p>

<p>Hot dogs cost \$1.00 and apples cost \$1.25</p>

<p><strong>Part (i) asks:</strong> Matthew's utility fucntion implies that the marginal utility of apples is $0.5 \sqrt{\frac{X}{Y}}$ and the marginal utility of hotdogs is $0.5 \sqrt{\frac{Y}{X}}$. How many apples will he buy? How many hot dogs will he buy?</p>

<p><strong>Part (ii) asks:</strong> This year, the price of hot dogs rise to \$3 each while Mathew’s income is unchanged. Mathew’s father decides to help him by giving him a gift of \$20. Consider an indifference curve-budget line diagram with hot dogs on the x-axis and apples on the y-axis. After Mathew gets the \$20 gift, will his new budget line lie above, lie below, or pass through his initial optimum? Justify your choice. Will Mathew be better or worse off than he was last year?</p>

<h2>What have I done?</h2>

<p>I'm pretty stuck on this. There aren't really any similar examples from me to draw upon from our course literature. </p>

<p>Perhaps the formulas $\dfrac{MU_x}{MU_y} = \dfrac{P_x}{P_y}$ and $I = P_x \cdot x + P_y \cdot y$ might help.</p>
","<p>Rather than write a complete answer, I am going to post a couple of hints that will hopefully get you underway.</p>

<hr>

<p>For part (i), note that</p>

<ul>
<li>You have two equations: $\dfrac{MU_x}{MU_y} = \dfrac{P_x}{P_y}$ and $I = P_x \cdot x + P_y \cdot y$.</li>
<li>Since we know $MU_x$, $MU_y$, $P_x$, $P_y$, and $I$, these two equations contain two unknowns.</li>
<li>Usually, so long as we have at least as many equations as there are unknown variables, we can find the value of those variables by simultaneously solving the equations.</li>
<li>the $x$ in $I = P_x \cdot x + P_y \cdot y$ is the quantity of hot dogs that you are asked to compute in part (i), so ultimately you are going to have to solve for the value of this variable.</li>
<li>my suggestion would therefore be that you try substituting into your two equations all of the things whose value you know and then try solving for $x$.</li>
</ul>

<hr>

<p>Since a budget line is a straight line, it is characterised by an intercept, $c$, and a slope, $m$.</p>

<p>If you think about drawing this line geometrically then you should recognise that</p>

<ul>
<li>the intercept is the amount of $y$ you could afford if you didn't buy any $x$ and spent all of your available money on $y$.</li>
<li>the slope is the number of units of $y$ you would have to give up to save enough money to afford one more unit of $x$.</li>
</ul>

<p>Once you know the slope and the intercept, you can write down the equation for your budget line, $y=mx+c$, and answering part (ii) is then just a matter of algebra.</p>
","13189"
"When can the fiscal multiplier be negative?","1494","","<p>I am looking for a case study or data which shows a negative (fiscal/spending) multiplier effect.</p>

<p>Does anyone know a study where this is analyzed?</p>
","<p>The paper <a href=""http://www.nber.org/papers/w16479"" rel=""nofollow"">How Big (Small?) are Fiscal Multipliers?</a> by Ethan Ilzetzki, Enrique G. Mendoza, Carlos A. Végh (2010)should give you useful information.</p>

<blockquote>
  <p>We contribute to the debate on the macroeconomic effects of fiscal
  stimuli by showing that the impact of government expenditure shocks
  depends crucially on key country characteristics, such as the level of
  development, exchange rate regime, openness to trade, and public
  indebtedness. Based on a novel quarterly dataset of government
  expenditure in 44 countries, we find that (i) the output effect of an
  increase in government consumption is larger in industrial than in
  developing countries, (ii) the fiscal multiplier is relatively large
  in economies operating under predetermined exchange rates but is zero
  in economies operating under flexible exchange rates; (iii) fiscal
  multipliers in open economies are smaller than in closed economies;
  (iv) fiscal multipliers in high-debt countries are negative.</p>
</blockquote>
","6222"
"Why in most macro models technology is labor-augmenting?","1494","","<p>Take Romer's advanced macro book as reference. In it the Solow model,the Ramsey model and the Diamond OLG all contain the fundamental $A_t$  variable representing technological progress.<br>
In all these models, technology affects only labor, that is:<br>
$Y_t = F(K_t,A_t L_t)$</p>

<p>Now my question is why is such assumption so prevalent in these models. It seems to me that when we imagine technology as affecting output we think of the Northrop loom, the Bessemer steel, the container, the railroad. You know, stuff. All these seem to me to be mostly capital-augmenting technologies.<br>
So why do we tend to assume labor-augmenting technology instead? </p>
","<p>The mathematical reason, is that this happens in order for the model to have a steady-state in terms of growth rates: variables like Consumption, Capital, Income, grow at the steady-state, but grow at the same rate, so their ratios remain constant (and it is in this sense that this situation represents a ""steady""-state). If they were to grow at different rates, their ratios would tend to either zero or infinity which is not very realistic, since it would imply that the economy tends towards one or the other ""corner"" situation.  </p>

<p>The mathematical proof can be found in <a href=""http://down.cenet.org.cn/upfile/8/200751171644184.pdf"">Barro &amp; Sala-i-Martin book (2nd ed)</a> , section 1.5.3, pp 78-80. Relevant and useful is also the discussion in section 1.2.12, pp 51-53.</p>

<p>For functional forms like (generalized, even) Cobb-Douglas, it is really indistinguishable (not separately identifiable), especially since we predominantly use the exponential function:</p>

<p>$$Y_t = A\cdot \left (K_te^{zt}\right)^\alpha \left (L_te^{vt}\right)^\beta = A\cdot K_t^{\alpha}\left (L_te^{(v+\frac {\alpha}{\beta}z)t}\right)^\beta = A\cdot K_t^{\alpha}\left (L_te^{wt}\right)^\beta$$</p>

<p>So strictly speaking in such a functional setup we can say that technology is also capital augmenting.</p>

<p>But since for other functional forms, the above does not hold, and so we must explicitly assume that technology is ""labor-augmenting"" for the reason stated previously, authors settled in labeling it as such in order to cover all cases, and when they want to keep the functional form unspecified.  </p>

<p>Regarding the conceptual issue the OP poses, which is insightful, a conceptual way out is to think of ""Technology"" more like ""Knowledge"". So ""Knowledge"" that goes into the machines, is part of the Investment that augments capital, while the <em>other</em> knowledge turns raw labor $L$ into human capital: essentially a production function with ""exogenous labor-augmenting technology"", is equivalent to a formulation that includes Human Capital instead of labor but where the investment in Human Capital is not subject to optimizing behavior but ""automatic"" (which points to Arrow's ""Learning-by-Doing"" concept of human capital accumulation).</p>
","2945"
"Utility function types - request for review","1480","","<p>I am working on a <a href=""https://en.wikipedia.org/wiki/User:Erel_Segal/Utility_functions_on_divisible_goods"" rel=""nofollow noreferrer"">Wikipedia page</a> that compares several common utility functions. Although I found some information about these topics on the web, I didn't find it all in one place, and often got confused by the different terms. I will be happy for any comments or reviews. Most importantly: are the facts in this page correct?</p>

<p>EDIT: to make the question self-contained, I copy its current contents below. Because <a href=""https://meta.stackexchange.com/questions/73566/is-there-any-markdown-to-create-tables"">StackExchange markdown does not support tables</a>, I used <a href=""http://www.sensefulsolutions.com/2010/10/format-text-as-table.html"" rel=""nofollow noreferrer"">Senseful Solutions</a> to create the text table.</p>

<hr>

<p>This page compares the properties of several typical utility functions of divisible goods. These functions are commonly used as examples in consumer theory.</p>

<p>The utility functions are exemplified for two commodity types, $x$ and $y$. $p_x$ and $p_y$ are their prices. $w_x$ and $w_y$ are constant parameters. </p>

<pre><code>+---------------+-------------------------------------+-----------------------+-----------------------------------------------------------------------------------+----------------+-------------+-----------------------------------------+----------------------------------+
|     Name      |              Function               |  Indifference curves  |                                   Demand curve                                    |  Monotonicity  |  Convexity  |                Good type                |              Example             |
+---------------+-------------------------------------+-----------------------+-----------------------------------------------------------------------------------+----------------+-------------+-----------------------------------------+----------------------------------+
| Linear        |  ${{x\over w_x}+{y\over w_y}}$      |  Straight lines       |  Step function: only goods with minimum ${w_i p_i}$ are demanded                  |  Strong        |  Weak       |  Substitute good|perfect substitutes    |  Potatoes of two different farms |
| Leontief      |  $\min({x\over w_x},{y\over w_y})$  |  L-shapes             |  hyperbolic: ${\text{Income} \over w_x p_x+w_y p_y}$                              |  Weak          |  Weak       |  Complementary good|perfect complements |  Left and right shoes            |
| Cobb–Douglas  |  $x^{w_x} y^{w_y}$                  |  hyperbolic           |  hyperbolic: $\frac{w_x}{w_x+w_y} {\text{Income} \over p_x}$                      |  Strong        |  Strong     |  Independent good|independent           |  Apples and socks                |
| Maximum       |  $\max({x\over w_x},{y\over w_y})$  |  ר-shapes             |  Discontinuous step function: only one good with minimum ${w_i p_i}$ is demanded  |  Weak          |  Concave    |  Substitute good|substitutes            |  ?                               |
+---------------+-------------------------------------+-----------------------+-----------------------------------------------------------------------------------+----------------+-------------+-----------------------------------------+----------------------------------+
</code></pre>

<p>Are the details in the table correct?</p>

<p>EDIT: Many thanks to all commenters and answerers. I revised the page accordingly.</p>
","<p>Currently (Dec-1-2015) I see listed Linear, Leontief, Cobb-Douglas, and Maximum.</p>

<p>To incorporate here a comment by @denesp the C.E.S utility function (that nests the Leontief and Cobb-Douglas) should certainly be included</p>

<p>$$u(x,y) = B\big(ax^{-\rho}+(1-a)y^{-\rho}\big)^{-1/\rho}$$,</p>

<p>(which also is a functional form that has non-zero cross partial derivatives),</p>

<p>as should the quasi-linear form</p>

<p>$$u(x,m) = h(x) + m$$</p>

<p>which is very often used, with $m$ standing for residual money income (what's left after purchasing $x$).</p>

<p>I would also include the <strong>Translog</strong> utility function.</p>

<p>Finally, I think you should increase the scope of the page and also include in a separate section univariate utility functions that are used in environments with uncertainty and in macroeconomics (say, the HARA class of functions). We may keep in our minds these subfields of economics clearly distinct and also from basic consumer theory, but what you build is a wiki page that is likely to be visited by outsiders (e.g. mathematicians or engineers interested in the subject) or just-arrived students, so a broader scope appears useful.</p>
","9524"
"Do import tariffs tend to increase a country's exchange rate (if so, why)?","1478","","<p>From Prof. Stiglitz' Vanity Fair <a href=""http://www.vanityfair.com/news/2016/12/a-nobel-laureate-explains-how-trump-could-nuke-the-economy"" rel=""nofollow noreferrer"">article</a>:  </p>

<blockquote>
  <p>How, one might ask, is this possible, given Trump’s rhetoric, his
  determination to move against China with a 45 percent tariff? There’s
  a global macroeconomic variable that Trump left out of his calculus,
  and that’s America’s exchange rate—not just with China, but with the
  entire world. If America’s exchange rate increases, our exports become
  more expensive, and imports become cheaper.</p>
</blockquote>

<p>He doesn't explicitly say that tariffs tend to increase a country's exchange rate. He leaves it as a standalone conditional. If it's simply a conditional, he could mean that there's a nonzero chance that the Dollar's value will increase independently. However, I felt like maybe he infers some causality. </p>

<p>I feel like a tariff would change the trade balance such that the US will import less, while exports are fixed.</p>

<p>Do import tariffs tend to increase a country's exchange rate? If so, why?</p>
","<p>Suppose that there is no 45 percent tariff and the market is in some kind of equilibrium. That is the demand for yuans equals the supply of yuans at the current exchange rate.</p>

<p>Now assume Trump does impose a 45 percent tariff. This makes imported Chinese goods in the US more expensive for the American consumer. As a result the consumers will buy fewer Chinese import goods. So far they paid for these goods with dollars and the corporation importing the goods used those dollars to buy yuans and pay for the goods. As a result of the decreased import demand the corporation will want less goods and hence it will buy fewer yuans. <strong>Thus decreasing the demand for yuans.</strong> The currency exchange market is similar to other markets: If at a price (in this instance this is the USD/CNY exchange rate) the supply outstrips demand the price will decrease. This means that the dollar becomes 'stronger', you will have to pay more yuans to get a dollar.</p>

<p>As a result exports do become somewhat more expensive (in yuans) and imports do become somewhat cheaper (in dollars) until an equilibrium is reached on both the currency and the good markets.</p>
","15083"
"What is the Credit-to-GDP gap exactly?","1428","","<p>I have been hearing a lot about this metric in relation to rising fears of a Chinese financial crisis. I am wondering, what exactly does this mean? I am told it refers to the difference between current credit-to-GDP ratios and long-term trends but I don't fully understand what that would mean. What would be a nice little equation for it? I have looked at some charts and I am seeing that the US has a negative Credit-to-GDP gap, how can it be negative? I just want to know what the inputs into calculating that would be so I can understand for myself what these things signify.
Thanks.</p>
","<p>The Credit-to-GDP, say  ratio measures the relative size of the outstanding debt of <em>non-financial private sector</em>, say $D_{p,t}$ with respect to (yearly) Gross Domestic Product, say $Y_t$</p>

<p>$$\text{Credit-to-GDP ratio} =\frac { D_{p,t}}{Y_t}$$</p>

<p>Note that GDP should be measured in <em>nominal</em> terms here, since so is debt. It is a metric related to how much burden WE have placed on our future from our current decisions and activities.</p>

<p>The ""Credit-to-GDP"" gap is, as the OP notes, ""the difference of the Credit-to-GDP ratio from its trend"". How do we extract that? </p>

<p>Look for example at the, informative with data and literature, page of the <strong><a href=""http://www.bis.org/statistics/c_gaps.htm"" rel=""nofollow noreferrer"">Bank for International Settlements</a></strong>. If you hit the ""data"" link, you will see that what they do is<br>
a) calculate the Credit-to-GDP ratio (per quarter but always using past-12-months GDP in the denominator), and then decompose the obtained time series by using the <strong><a href=""https://en.wikipedia.org/wiki/Hodrick%E2%80%93Prescott_filter"" rel=""nofollow noreferrer"">HP filter</a>.</strong></p>

<p>The Credit-to-GDP <em>gap</em> is what it remains if from the actual ""Credit-to-GDP ratio"" series we subtract the (non-linear) trend as calculated by the HP filter. One can understand why then this ""gap"" can be negative: we are currently below the trend. Finally note that the Credit-to-GDP gap is also measured in GDP percentage units. But sometimes it may be reported as <em>percentage deviation from the trend</em> (i.e. ""we are 30% above trend"" does <em>not</em> mean that we are ""30 percentage points of GDP above trend""). So read carefully any source.</p>

<p><strong>The question is: why use the ""gap"" and not the ratio itself?</strong>  </p>

<p>Because we are accepting that the trend likely reflects a <em>sustainable</em> evolution of the economy over time (sustainable by the very ongoing existence of said economy), while the ""gap"" reflects short-term tendencies that may not be sustainable and may lead to crises if left unchecked and un-managed. </p>

<p>A higher positive gap means that the private sector borrows at a level that is perhaps ""not justified"" by the current output-producing abilities of the economy. Banks may tend to experience abnormally high rates of loan defaults etc, which can lead to a banking crisis. </p>

<p>A negative gap supposedly implies that there is a ""safe"" amount of additional borrowing that could be done currently (for consumption or investment purposes), and we are leaving it ""unexploited"".  </p>

<p>But never read too much on a single metric, economic systems are too complex.</p>
","15806"
"Available code for computing solutions to matching algorithms?","1420","","<p>The question of designing matching procedure (between high-schools and students, med intern and hospitals, kidney donors and receivers,...) has been widely studied by economists and vastly contributed to Roth and Shapley receiving the Nobel memorial price in economics.</p>

<p>I was wondering if you knew about any freely available <strong>code</strong> out there (ideally in a relatively high-level language) able to <strong>compute solutions</strong> to the main kind matching problems for some of the <strong>most famous algorithms</strong> proposed in the literature. I am thinking of writing one, but I'd rather not it already exists. </p>

<p>I am <strong>chiefly interested</strong> in some piece of code to compute the solution to <strong>Deferred Acceptance</strong> algorithm in a <strong>school choice</strong> problem, but anything else would be appreciated.</p>
","<p>While answering a comment, I realized I had a post-worth response. R has become the ""default language"" for a lot of computational research statistics (for a number of reasons; nice NYT article <a href=""http://www.nytimes.com/2009/01/07/technology/business-computing/07program.html?pagewanted=all&amp;_r=0"" rel=""nofollow"">here</a>). It's high level, free and open-source, and has a closely-related <a href=""http://www.jstatsoft.org/"" rel=""nofollow"">journal</a> for publishing statistical algorithms. Citations and peer review are key for academia, so you get a lot of well-described code posted to the R archives (CRAN) with descriptions posted to JStat. This spills over into a lot of blogs and quick demonstration code posts.</p>

<p>That is to say, there's an enormous user-create code base for R. When I need to find an algorithm online, I'll often first look to the massive R codebase. A quick search for R code turned up the following:</p>

<p>From an <a href=""http://plausibel.blogspot.com/2012/01/illustrating-deferred-acceptance.html"" rel=""nofollow"">R blogger</a>, with code (see the gist link):</p>

<blockquote>
  <p>The Deferred Acceptance Algorithm (DAA) goes back to Gale and Shapley (1962). They introduce a rather simple algorithm that finds a stable matching for example for college admissions or in a marriage market. ... Variations of this algorithm are used in Hospital assignments in the USA, whereby recently graduated doctors submit preferences over hospitals, and hospitals submit preferences over graduates. ... Here I'm going to use R to make a little simulation of this</p>
</blockquote>

<p>From an install-able github repository for <a href=""https://github.com/thiloklein/matchingMarkets"" rel=""nofollow"">matching markets</a>:</p>

<blockquote>
  <p>R package <code>matchingMarkets</code> comes with two estimators:</p>
  
  <ul>
  <li><p><code>stabit</code>: Implements a Bayes estimator that estimates agents' preferences and corrects for sample selection in matching markets when the selection process is a one-sided matching game (i.e. group formation).</p></li>
  <li><p><code>stabit2</code>: Implements the Bayes estimator for a two-sided matching game (i.e. the <a href=""http://en.wikipedia.org/wiki/Stable_marriage_problem#Similar_problems"" rel=""nofollow"">college admissions</a> and <a href=""http://en.wikipedia.org/wiki/Stable_marriage_problem"" rel=""nofollow"">stable marriage</a> problems).</p></li>
  </ul>
  
  <p>and three algorithms that can be used to simulate matching data:</p>
  
  <ul>
  <li><p><code>hri</code>: Constraint model for the hospital/residents problem. Finds <em>all</em> stable matchings in two-sided matching markets. Implemented for both the <a href=""http://en.wikipedia.org/wiki/Stable_marriage_problem"" rel=""nofollow"">stable marriage problem</a> (one-to-one matching) and the <a href=""http://en.wikipedia.org/wiki/Stable_marriage_problem#Similar_problems"" rel=""nofollow"">hospital/residents problem</a>, a.k.a. college admissions problem (many-to-one matching). </p></li>
  <li><p><code>sri</code>: Constraint model for the stable roommates problem. Finds all stable matchings in the <a href=""https://en.wikipedia.org/wiki/Stable_roommates_problem"" rel=""nofollow"">roommates problem</a> (one-sided matching market).</p></li>
  <li><p><code>ttc</code>: Top-Trading-Cycles Algorithm. Finds stable matchings in the <a href=""https://en.wikipedia.org/wiki/Top_trading_cycle"" rel=""nofollow"">housing market problem</a>.</p></li>
  </ul>
  
  <p>Functions <code>hri</code> and <code>sri</code> allow for <strong>incomplete preference lists</strong> (some agents find certain agents unacceptable) and <strong>unbalanced instances</strong> (unequal number of agents on both sides).  </p>
</blockquote>

<p>Hopefully one of these can help. The second one in particular looks extremely useful, particularly if it provides an empirical estimator. </p>
","1671"
"What are the applications of complex numbers in modern economics?","1413","","<p>I wonder what the most interesting applications of imaginary numbers in mainstream economics are. I read about the unit root test (Dickey-Fuller test) in time-series analysis; and I studied System Dynamics about phase portraits that were determined by complex numbers. So maybe the maths of these numbers are necessary for econometrics and for more sophisticated macroeconomic modelling. </p>

<p>To sum up, what are the most important application of complex numbers in economics? Could you give me some examples, models relevant to complex numbers?</p>

<p>I will be grateful if you can send me this information.</p>
","<p>You might refer to this answer to a <a href=""https://economics.stackexchange.com/questions/48/is-complex-analysis-used-in-economics"">question similar to yours.</a></p>

<p>Financial economics often use the complex plane to visualize duration and the internal rate of return, to which <a href=""https://www.economicsnetwork.ac.uk/cheer/ch14_1/ch14_1p04.htm"" rel=""nofollow noreferrer"">this resource</a> proves very helpful.</p>
","8672"
"What textbook can I use to really understand microeconomics, macroeconomics and mathematical economics","1407","","<p>What textbook can I use to really understand microeconomics, macroeconomics and mathematical economics. It can be different textbooks. I'm in first year college taking introductory courses in microeconomics, macroeconomics and mathematical economics. I need a really good textbook or online site to understand what I'm studying well. I like the way people on this site answer and explain questions with application. I want to be like that too. I have Greg mankiw books by the way, I have schaum's introduction to mathematical economics. I need to read more quality books to understand.</p>

<p>Thanks</p>
","<p>For micro, I would recommend McCloskey's <em>Applied Theory of Price</em>, available to download from the author's website here: <a href=""http://www.deirdremccloskey.com/docs/price.pdf"" rel=""nofollow"">http://www.deirdremccloskey.com/docs/price.pdf</a></p>

<p>Read the opening section titled ""how to use this book"" to see why I think it matches well with your needs.</p>

<p>Another intermediate–advanced undergraduate level micro book in a similar vein to McCloskey is ""Microeconomic Theory: Basic Principles and Extensions"" by Walter Nicholson and Christopher Snyder.</p>

<p>For an enthusiastic undergraduate looking to read more mathematical economics, I would recommend ""Fundamental Methods of Mathematical Economics"" by Alpha Chiang. Some commenters are correct that graduate-level economics can take you into some fairly serious topics in analysis and other areas of pure mathematics. But for now I think you would be better served trying to get a solid handle on the core tool set used be economists. In my view, Chiang is a great place to learn those tools—being a bit more advanced than typical undergraduate material, but not completely abstracted.</p>
","8961"
"Why is economic growth measured exponentially rather than linearly?","1405","","<p>If economic growth is indeed highly desirable (see <a href=""https://economics.stackexchange.com/q/455/332"">this question</a>), why must this growth be exponential? With finite resources, exponential growth might hit limits rapidly (or be impossible?). Why not express growth in linear rather than exponential terms?</p>
","<p>Growth as is meant here ""must"" be nothing in particular. It is a specific metric, the percentage change in yearly GNP/GDP, and it is what it is.<br>
In <a href=""http://mitpress.mit.edu/books/lectures-macroeconomics"" rel=""noreferrer"">Blanchard and Fischer 's ""Lectures on Macroeconomics""</a>, in the introductory chapter 1, page 2, Figure 1.1, the <em>logarithm</em> of USA GNP 1874-1986 is graphed: and it is impressively <em>linear</em> , bar a disturbance around World-War II (a dive before it that was roughly equally compensated immediately after). But this means that</p>

<p>$$\ln Y \approx at \Rightarrow Y \approx e^{at}$$</p>

<p>(for the US Economy, $a \approx 0.030\;\; \text{to} \;\;0.037$ for the period).</p>

<p>It is <em>the data</em> that told us that ""growth was exponential"" during this period.<br>
(Note that ""exponential growth"" usually includes the concept of <em>constant growth rate</em>, while  in informal language, ""exponential"" may also refer to exploding paths, paths with increasing growth rate).<br>
And so economic models were deemed relevant if they could replicate to a respectable degree the observed data.</p>

<p>The question ""can this go on forever?"" is an altogether different issue, starting with the meaning of the word ""forever"".</p>
","464"
"What is the difference between Herfindahl Index and the Concentration Ratio","1401","","<p>I was recently reading about the <a href=""https://en.wikipedia.org/wiki/Herfindahl_index"" rel=""nofollow"">Herfindahl Index</a> and from what I've learned so far, is that HHI is preferred over the <a href=""https://en.wikipedia.org/wiki/Concentration_ratio"" rel=""nofollow"">Concentration Ratio</a>. However, I didn't quite understand the reasoning that lead to this conclusion. What impact does squaring have on the final result? Any hints or suggestions for further reading will be appreciated.</p>
","<p>From the <a href=""http://www.cambridge.org/us/academic/subjects/economics/industrial-economics/industrial-organization-markets-and-strategies"">Industrial Organization by Belleflame and Petiz</a> (Page 34/35, Chapter 2):</p>

<blockquote>
  <p>While the m-firm concentration ratio adds market shares of a small number of firms in the market, the so-called Herfindahl index (also known as Herfindahl–Hirschman index) considers the full distribution of market shares.</p>
</blockquote>

<p>We can conclude that the mathematical approach in HHI is more adequate for a full market setup, rather than observing a particular concentration ratio in one firm.
Also from the same book</p>

<blockquote>
  <p>the Herfindahl index provides a better measure of concentration as it captures both the number of firms and the dispersion of the market shares.</p>
</blockquote>

<p>Hence the squared market shares. </p>

<p>For your information, there is another concentration measure called the Lerner Index, although the Lerner index is a snapshot of the intensity of competition. You can calculate L by finding the difference between price and marginal costs as a percentage of the price. More formally:
$L=\frac{p-C'}{p}$</p>

<p>But it is easily observed that L ignores some dynamics of the markets. Lower prices do not necessarily mean high levels of competition.</p>
","10103"
"Transversality Condition in neoclassical growth model","1394","","<p>In the neo-classical growth model there is the following transversality condition: </p>

<p>$$\lim_{t\rightarrow\infty}\beta^{t}u'(c_{t})k_{t+1}= 0,$$ 
where $k_{t+1}$ is the capital at period $t$. </p>

<p>My questions are: </p>

<ol>
<li><p>How we derive this condition? </p></li>
<li><p>Why do we require this, if we want to rule out paths with no debt accumulation?</p></li>
<li><p>Why are the Lagrange multipliers $\beta^{t}u'(c_{t}) = \beta^{t}\lambda_{t}$
the present discounted value of the capital? </p></li>
</ol>
","<p>The transversality condition may be more easily understood if we start from a problem with finite horizon.</p>

<p>In the standard version, our objective is to 
$$ 
\max_{\{c_t,k_{t+1}\}_{t=0}^T} \sum_{t=0}^T\beta^t u(c_t)
$$
subject to 
$$
\begin{aligned}
f(k_t)-c_t-k_{t+1}&amp;\ge0,\quad t=0,\dots,T &amp;&amp;\text{(resource/budget constraint)}\\
c_t,k_{t+1}&amp;\ge0,\quad t=0,\dots,T &amp;&amp;\text{(non-negativity constraint)}
\end{aligned}
$$
with $k_0$ given. The associated Lagrangian (with multipliers $\lambda_t$, $\mu_t$, and $\omega_t$) is 
$$
\max_{\{c_t,k_{t+1},\lambda_t,\mu_t,\omega_t\}_{t=0}^T}
\sum_{t=0}^T \beta^tu(c_t)+\lambda_t(f(k_t)-c_t-k_{t+1})+\mu_tc_t+\omega_tk_{t+1}
$$
The FOCs are 
$$
\begin{align}
c_t:&amp;&amp; \beta^tu'(c_t)-\lambda_t+\mu_t&amp;=0,\quad t=0,\dots,T \\
k_{t+1}:&amp;&amp; -\lambda_t+\lambda_{t+1}f'(k_{t+1})+\omega_t&amp;=0,\quad t=0,\dots,T-1 \\
k_{T+1}:&amp;&amp; -\lambda_T+\omega_T&amp;=0,\quad T+1 \tag{1}
\end{align}
$$ 
with the Kuhn-Tucker complementary slackness conditions: for $t=0,\dots,T$,
$$
\begin{align}
\lambda_t(f(k_t)-c_t-k_{t+1})&amp;=0 &amp; \lambda_t&amp;\ge0 \\
\mu_tc_t&amp;=0 &amp; \mu_t&amp;\ge0\\
\omega_tk_{t+1}&amp;=0&amp;\omega_t&amp;\ge0\tag{2}
\end{align}
$$
Since resource constraint must be binding in all periods, i.e. $\lambda_t&gt;0$ for all $t$, it follows that at the last period $T$, $\omega_T=\lambda_T&gt;0$, which in turn implies $k_{T+1}=0$.</p>

<p>Usually we assume $c_t&gt;0$ for all $t$ (the Inada condition), and this implies $\mu_t=0$ for all $t$. So the consumption FOC becomes
$$
\beta^tu'(c_t)=\lambda_t \tag{3}
$$</p>

<p>Looking at conditions $(1)$ $(2)$ and $(3)$ in the last period $T$, we get
$$\beta^Tu'(c_T)k_{T+1}=0$$
Extending this to the infinite horizon, we get the transversality condition
$$\lim_{T\to\infty}\beta^Tu'(c_T)k_{T+1}=0$$</p>

<p>The intuition of the transversality condition is partly that ""there is no savings in the last period"". But as there is no ""last period"" in an infinite horizon environment, we take the limit as time goes to infinity.</p>
","15299"
"How should one determine the proper number of lags in a time series regression?","1381","","<p>I am using time series data in economic model estimation. I want determine proper lag for Error Correcting Model (<a href=""https://en.wikipedia.org/wiki/Error_correction_model"" rel=""nofollow"">ECM</a>) model for example. I can check <a href=""https://en.wikipedia.org/wiki/Akaike_information_criterion"" rel=""nofollow"">AIC</a>, SC and HQ criterion for determine proper lag. But I am not sure about max lag that I must start with it. What is max lag for annual, quarterly and monthly time series. </p>

<p>Is max lag would be changed if I used another econometric approach for example ARDL, VAR or VECM? </p>
","<p>I don't have advice specific to error correcting model (ECM) setting, but in undergraduate applied econometric class they gave us the generic advice to continue to extend lags in the model until the residuals of the fitted model were serially uncorrelated. For example, in the US life expectancy data, residuals of male life expectancy is serially uncorrelated in the AR(5) model but not the AR(4) model. You can see this for yourself with the following Stata code:   </p>

<pre><code>use http://www.stata-press.com/data/r8/uslifeexp.dta
tsset year, yearly
reg le_male L(1/4).le_male
estat durbinalt, small
reg le_male L(1/5).le_male
estat durbinalt, small
</code></pre>

<p>The <a href=""http://www.stata.com/manuals13/tsvecintro.pdf"" rel=""nofollow"">Stata documentation for the vector error-correction</a> models also seems to roughly follow this approach but it looks like it is automated under the <strong>varsoc</strong> function and additionally the AIC, HQIC, and SBIC are all generated programmatically. </p>

<blockquote>
  <p>To test for cointegration or fit cointegrating VECMs, we must specify
  how many lags to include. Building on the work of Tsay (1984) and
  Paulsen (1984), Nielsen (2001) has shown that the methods implemented
  in varsoc can be used to determine the lag order for a VAR model with
  I(1) variables. As can be seen from (9), the order of the
  corresponding VECM is always one less than the VAR. vec makes this
  adjustment automatically, so we will always refer to the order of the
  underlying VAR. The output below uses varsoc to determine the lag
  order of the VAR of the average housing prices in Dallas and
  Houston....</p>
  
  <p>We will use two lags for this bivariate model because the Hannan–Quinn
  information criterion (HQIC) method, Schwarz Bayesian information
  criterion (SBIC) method, and sequential likelihood-ratio (LR) test all
  chose two lags, as indicated by the “*” in the output.</p>
</blockquote>

<pre><code>. clear all

. use http://www.stata-press.com/data/r13/txhprice

. varsoc dallas houston

   Selection-order criteria
   Sample:  1990m5 - 2003m12                    Number of obs      =       164
  +---------------------------------------------------------------------------+
  |lag |    LL      LR      df    p      FPE       AIC      HQIC      SBIC    |
  |----+----------------------------------------------------------------------|
  |  0 |  299.525                      .000091  -3.62835  -3.61301  -3.59055  |
  |  1 |  577.483  555.92    4  0.000  3.2e-06   -6.9693  -6.92326  -6.85589  |
  |  2 |  590.978  26.991*   4  0.000  2.9e-06*  -7.0851* -7.00837* -6.89608* |
  |  3 |  593.437   4.918    4  0.296  2.9e-06  -7.06631  -6.95888  -6.80168  |
  |  4 |  596.364  5.8532    4  0.210  3.0e-06  -7.05322   -6.9151  -6.71299  |
  +---------------------------------------------------------------------------+
   Endogenous:  dallas houston
    Exogenous:  _cons
</code></pre>

<p>If, as @GraemeWalsh suggests, you would like to use an <a href=""http://davegiles.blogspot.com/2013/03/ardl-models-part-i.html"" rel=""nofollow"">auto-regressive distributed lags methodology</a> (ARDL) you can do so without having to code it up yourself.</p>

<pre><code>use http://www.stata-press.com/data/r13/txhprice
sort t
net install ardl.pkg
ardl dallas houston,  maxlag(4)


ARDL regression
Model: level

Sample:  1990m5 - 2003m12 
Number of obs  = 164
Log likelihood = 313.86816
R-squared      = .96315461
Adj R-squared  = .96246376
Root MSE       = .03613756

------------------------------------------------------------------------------
      dallas |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      dallas |
         L1. |    .427744   .0789194     5.42   0.000      .271886     .583602
         L2. |   .1747019   .0720507     2.42   0.016     .0324089    .3169948
             |
     houston |   .3404766   .0567884     6.00   0.000     .2283252     .452628
       _cons |   .7276476   .2061803     3.53   0.001     .3204618    1.134833
------------------------------------------------------------------------------
</code></pre>
","6903"
"Do perfect complements have to be normal goods? If so, why?","1377","","<p>Two goods $x,y$ are perfect complements if they have the utility function 
$$U(x,y) = \min \lbrace ax,by \rbrace $$ 
$$a,b \in \Bbb{Q}^+$$
My professor said $x,y$ have to be normal goods but didn't explain why well enough that I could understand. </p>

<p><strong>My Question:</strong> </p>

<p>Are perfect complements always normal goods? If so, why?</p>
","<p>A good is <em>normal</em> if its demand is increasing in income. So let $p_x$ and $p_y$ be the price of the goods with quantities $x$ and $y$ and let $m$ be income.</p>

<p>Suppose $ax&gt;by$. Then $\min\{ax,by\}=by$. By slightly reducing $x$ by and spending the saved money on $y$, one gets a better bundle. For an optimal bundle, this cannot be.  </p>

<p>Similarly, it cannot be optimal that $by&gt;ax$. So in the optimal consumption bundle, it must be the case that $ax=by$. It is also not that hard to see that the consumer will spend all her income. So rewrite the condition as 
$$y=\frac{a}{b}x$$ and plug it into the budget equation $$p_x x+p_y y=m$$ to get
$$p_x x+ p_y\frac{a}{b}x=m=x\Big(p_x+p_y\frac{a}{b}\Big).$$
Therefore, we get the demand function given by $$x(p_x,p_y,m)=\frac{m}{p_x+p_y\frac{a}{b}},$$ which is clearly increasing in $m$. Similarly, one shows that the other good is normal too.</p>

<p>Pedantic remark: A differentiable function can be increasing at every point without the derivative being strictly positve everywhere. The function given by $x\mapsto x^3$ has derivative $0$ at $0$ but is everywhere increasing.</p>
","5618"
"What institutions are examples of ""shadow banking""?","1369","","<p>I often hear the term shadow banking tossed around when discussing the United States and Chinese economies. What exactly is shadow banking and could you give examples of some specific companies that act as ""shadow banks""? I have been told that in China, shadow banking refers to informal loans that are not written up in any documentation. Is this correct?</p>
","<p>While whomever told you about ""shadow banking"" in China is correct that in an international context, the term can often refer to informal banking arrangements (the earliest use of the term); however, these days, it is usually used in the sense first coined by Paul McCulley in a speech he delivered (""<a href=""https://www.pimco.com/insights/economic-and-market-commentary/global-central-bank-focus/teton-reflections"" rel=""nofollow"">Teton Reflections</a>"") at the 2007 Jackson Hole conference. He described them as:</p>

<blockquote>
  <p>[T]he whole alphabet soup of levered up non-bank investment conduits, vehicles, and structures... </p>
  
  <p>Unlike regulated real banks, who fund themselves with insured deposits, backstopped by access to the Fed’s discount window, unregulated shadow banks fund themselves with un-insured commercial paper, which may or may not be backstopped by liquidity lines from real banks. </p>
</blockquote>

<p>Structured investment vehicles, as noted by Kitsune, are certainly one type of shadow bank, but nonbank broker-dealers, certain real estate investment trusts, and particular hedge funds can be viewed as types of shadow bank. The question to ask in determining whether an entity is a ""shadow bank"" is twofold— do they: </p>

<ol>
<li>perform credit, liquidity, or maturity transformation; and </li>
<li>fund themselves through uninsured wholesale deposits (without recourse to liquidity facilities)?</li>
</ol>

<p>As a direct answer to your question, <a href=""https://www.newyorkfed.org/medialibrary/media/research/staff_reports/sr458.pdf"" rel=""nofollow"">Pozsar, Adrian, Ashcraft, and Boesky (2010)</a> say:</p>

<blockquote>
  <p>Examples of shadow banks include finance companies, asset-backed commercial paper (ABCP) conduits, structured investment
  vehicles (SIVs), credit hedge funds, money market mutual funds, securities lenders, limited-purpose finance companies (LPFCs), and the government-sponsored enterprises (GSEs). </p>
</blockquote>

<p>I <em>strongly</em> recommend clicking on that link and taking your time to browse the map on page 2.</p>

<p>It's worth noting both that many of these entities have existed for long periods of time without incident, and that due to choices in how banking is regulated, shadow banks are often the result of a desire to both limit the scope of regulation and to limit the risk of failure within the scope of regulation— which has the effect of pushing intermediation activities outside the regulated sphere. </p>
","11530"
"Prove the sample variance is an unbiased estimator","1346","","<p>I have to prove that the sample variance is an unbiased estimator. What is is asked exactly is to show that following estimator of the sample variance is unbiased:</p>

<p>$s^2=\frac{1}{n-1}\sum\limits_{i=1}^n(x_i-\bar x)^2$</p>

<p>I already tried to find the answer myself, however I did not manage to find a complete proof. </p>
","<p>I know that during my university time I had similar problems to find a complete proof, which shows exactly step by step why the estimator of the sample variance is unbiased.</p>

<p>The proof I used can be found under <a href=""http://economictheoryblog.wordpress.com/2012/06/28/latexlatexs2/"">http://economictheoryblog.wordpress.com/2012/06/28/latexlatexs2/</a></p>

<p>The proof itself is not very complicated but rather long. That also the reason why I am not writing it down here and probably it is not fair towards the person who actually provided it in the first place.</p>
","4745"
"How do excessive foreign reserves cause inflation?","1330","","<p>I have studied that accumulation of foreign reserve has the potential to raise inflation levels in economy as the money base increases (= domestic currency + foreign reserve increases) and if it overshoots the money demand in the economy then it will raise price levels. 
My question here is that how the foreign reserves which are under the custody of the central bank go into the system and cause inflation. Say, China has huge reserves of USD but it rests with the central bank mostly. So, how does it get into the economy and raise prices ?</p>
","<p>Because you are taking other currencies off the market and/or selling your own currency, and increasing the supply of your own currency relative to others.</p>
","10715"
"Federal Reserve vs National Bank","1319","","<p>The US had a national bank during the first few decades after its birth before it was abolished.  Today, we have the Federal Reserve.<br>
What are the differences between the Federal Reserve and a National Bank (specifically, with regard to their intervention policies and powers for acting within the economy)?</p>
","<p>The two Banks of the United States (the First and Second) were nothing like the modern Federal Reserve system.  For example, the First was prohibited from buying government bonds (one of the main roles of the Federal Reserve system is to buy and sell government bonds).  Further, neither of the national banks had any role in regulating the banking system.  They were simply the only interstate banks allowed.  All other banks had to be confined to one state.  The national banks primary impact on the money supply was to require smaller banks to pay them in silver and gold to redeem checks deposited in the national banks.  </p>

<p>By contrast, the Federal Reserve system actively regulates banks, requiring them to maintain a percentage of their deposits as reserves.  It actively sets two rates:  the rate at which it loans money to banks to cover reserve shortages (called the discount rate) and the rate it pays on excess reserves.  The latter power is relatively new.  Previously the Federal Reserve did not pay interest on excess reserves.  The Federal Reserve also sets a target for the funds rate, which is the average rate at which banks loan money to each other.  The funds rate target is what most people mean when they refer to the Federal Reserve setting interest rates.  </p>

<p>The Federal Reserve has two main ways to affect the funds rate.  First, it publishes a target rate for the average.  Second, it buys and sells government bonds in what are called open market operations.  When it buys bonds, it adds money to the system, reducing the number of banks that need to borrow and increasing the number of those with money to lend.  This pushes the average rate to fall, as there are more lenders and fewer borrowers.  When it sells bonds, it pulls money from the system, reducing the number of banks with money to lend.  </p>

<p>The Federal Reserve can also compete with lenders by loaning money to banks at the discount rate.  This decreases the number of banks looking to borrow from other banks, which would push rates down.  It rarely does this however.  Most banks prefer to borrow from other banks, as there are fewer restrictions.  </p>

<p>The Federal Reserve also has two ways to influence how much banks keep in reserve.  First, it sets an explicit reserve requirement.  Every bank must keep that much in reserve.  Second, it can pay interest on excess reserves.  The higher that rate, the more likely banks are to keep excess reserves instead of loaning them to individuals, companies, or other banks.  This would push up the funds rate average, as fewer banks loan.  </p>

<p>Again, the two Banks of the United States were not central banks the way that the Federal Reserve is.  Yes, they could print banknotes, but so could other banks of the time.  They had no special banking privileges.  They were simply the only interstate banks allowed during their charter.  </p>
","323"
"What benefits do governments receive from not eliminating debt?","1304","","<p>Most major economies have substantial government debt; for example among the OECD countries the lowest debt rate is Estonia with around 6% of GDP. Now we may be in a global recession at the moment, but even during the more prosperous times of the twentieth century most countries maintained substantial public debt. Here is a graph of the US federal debt:</p>

<p><img src=""https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/FederalDebt1940to2012.svg/640px-FederalDebt1940to2012.svg.png"" alt=""A graph of the US federal debt as a percentage of GDP since 1940""></p>

<p>And here is one of the UK's national debt:</p>

<p><img src=""https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/UK_GDP.png/640px-UK_GDP.png"" alt=""A graph of the UK&#39;s natioanl debt as a percentage of GDP since 1692""></p>

<p>(Both graphs via Wikimedia.)</p>

<p>What benefits do governments of advanced economies receive from not eliminating their debt?</p>
","<p>Most of the same considerations apply to countries as apply to businesses and people, plus a couple of extra cons</p>

<p><strong>Pros of Being Debt Free</strong></p>

<ul>
<li>No interest payments</li>
<li>Not beholden to someone else (financial freedom)</li>
</ul>

<p><strong>Cons of Being Debt Free</strong></p>

<ul>
<li>Buying things on (interest free) credit can save a little money</li>
<li>Paying for things in installments can match costs to income</li>
<li>Interest rates can be used to control economic activity and defend currency</li>
<li>Having a bond market promotes domestic financial activity</li>
<li>Having government bonds provides savers with a safe investment</li>
</ul>

<p>There is big difference between having no debt and having no net debt.  In the former case, you do not borrow any money and that is rare.  In the latter case you have the money but choose to borrow instead.  Many individuals do this by spending on credit card even though they have money in the bank, or not paying off all of their mortgage because the interest rate is good (so they can earn more with their money elsewhere).</p>

<p>For governments there are extra benefits from having debt (even if you can pay it off).</p>

<p>Perhaps the best way to understand this though is to look at a few notable examples, past and present.</p>

<p><strong>US 1836</strong></p>

<p><em>If you don't set interest rates, someone else will</em></p>

<p>The Federal Reserve was only established in 1913, prior to that the US had an uneasy relationship with the concept of central banking.</p>

<p>It seems the founding fathers were against central banking, and it wasn't until Alexander Hamilton that ""First Bank of the United States"" was created in 1791, mandated to last for 20 years, after which it's mandate was not renewed.</p>

<p>Second Bank was established in 1816.  Andrew Jackson was strongly against central banking (and banking generally!) and so when he came to power in 1832 he pulled the state money out of the bank.  The bank countered by tightening money supply to push the economy into recession.  Andrew Jackson held out and paid off the entire national debt by 1836.  The Second Bank did not have it's chartered renewed, and liquidated in 1838.</p>

<p>With no debt, and no central bank the US money supply was effectively free.  Jackson also introduces the Specie Circular which required all government land be purchased in gold and silver.  The rest of the 1830 saw significant inflation and recession, generally attributed to Jackson defeating the central bank.</p>

<p>The US government had lost control of their own economy, and in 1837 the Bank of England raise rates, forcing up domestic US interest rates, precipitating the 1837 panic.  The following years were marked by major recession.</p>

<p>For more on this see: <a href=""http://online.wsj.com/news/articles/SB123491373049303821?mg=reno64-wsj&amp;url=http%3A%2F%2Fonline.wsj.com%2Farticle%2FSB123491373049303821.html"">WDJ article on US debt</a> and <a href=""http://en.wikipedia.org/wiki/Second_Bank_of_the_United_States"">Wiki: Second Bank</a></p>

<p><strong>Norway Today</strong></p>

<p><em>Keep some debt for liquidity purposes and financial control</em></p>

<p>Norway currently has around \$170bn of public debt, with a GDP of about \$500bn.  However in 1990 the government established what is now called the ""Government Pension Fund of Norway"" into which the excess income from Norwegian oil is poured.  It is an equity and bond portfolio currently estimated to be worth in excess of \$700bn.</p>

<p>The government of Norway could choose to pay off all its debts easily, but chooses not to.  Instead they maintain issuance in sovereign debt markets in order to hold a liquid reserve to cover their daily payments.  They also mention using the money to ""develop well-functioning and efficient financial markets"".  A final consideration in their case is that their assets are abroad, and repatriating them would weaken the Krone, so there is some FX consideration here.</p>

<p>Because of this, it is not surprising that Norway has a AAA credit rating, and that also makes it cheaper for Norway to borrow than even the US (based on 5Y CDS).</p>

<p>For more on this see: <a href=""http://www.regjeringen.no/en/dep/fin/Selected-topics/economic-policy/the-central-governments-outstanding-debt.html?id=443404"">Norway Ministry of Finance</a> and <a href=""http://www.norges-bank.no/en/Liquidity-and-markets/Government-debt/Why-government-debt/"">Norges Bank</a></p>

<p><strong>Singapore Today</strong></p>

<p><em>Issue debt to give people something to invest in</em></p>

<p>Singapore has had no foreign debt (ie. non-SGD) since 1995, and consistently runs with a fiscal surplus.  Despite this they issue T-Bills and Notes of various maturities consistently and simply invests the proceeds.</p>

<p>Why?  According to the Monetary Authority of Singapore (MAS) the main objectives are:</p>

<blockquote>
  <ul>
  <li>Provide a liquid investment alternative with little or no risk of default for individual and institutional investors; </li>
  <li>Establish a liquid government bond market, which serves as a benchmark for the corporate debt securities market; and </li>
  <li>Encourage the development of skills relating to fixed income financial services available in Singapore.</li>
  </ul>
</blockquote>

<p>For more on this see: <a href=""http://www.mas.gov.sg/moneysense/understanding-financial-products/investments/guides-and-articles/making-sense-of-singapore-government-securities.aspx"">MAS MoneySense</a></p>

<p><strong>North Korea</strong></p>

<p><em>If you don't pay, its not really debt...</em></p>

<p>This is only a semi serious one, but one country that basically has no debt is North Korea, for the simple reason that no-one will lend to them.  They do technically have debts though, including a debt to Sweden for some Volvos, but in 1984 they defaulted on them all and refused to pay anything.  It seems they have no-intention of ever paying.  I don't think I need to explain the downsides to the North Korean approach to economics.</p>

<p>See: <a href=""http://www.nkeconwatch.com/category/finance/debt/"">North Korea's Stolen Volvos</a></p>
","71"
"Certainty equivalent and risk aversion parameter given utility function","1302","","<p>I know this is rather easy but I do not have any example or material to really work from that I could find online.</p>

<blockquote>
  <p>Consider an agent with a utility index over wealth given by $$v(w) = \frac{w^{1 - \gamma} - 1}{1 - \gamma}, \gamma &gt; 0$$</p>
  
  <p>Say the agent has $10$ dollars in wealth and also owns a lottery that pays $0$ dollars with probability $2/3$ and pays $12$ with probability $1/3$. What is the certainty equivalent value and risk compensation of this lottery to an agent with risk aversion parameter $\gamma = 2$?</p>
</blockquote>

<p>So for $\gamma = 2$, we have $$v(w) = \frac{w-1}{w}$$ so the expectd value of the lottery is $4$ dollars. My question is how do we calculate the Certainty equivalent and risk premium. I could not find a good example anywhere. It seems like we get at undefined part in the equation when we calculate $E[v(L)]$ where $L$ is the lottery, thus I don't see how we can find the Certainty equivalent...</p>
","<p>For the certainty equivalent and the ""risk compensation"" (which I am interpreting as probability premium because it's the only thing that intuitively makes sense in this context to me; feel free to correct me), think more intuitively about the concepts. The certainty equivalent is the amount of cold hard cash you'd be indifferent to taking in lieu of the uncertain outcome.</p>

<p>In the good outcome with $\frac{1}{3}$ probability, you'd end up with a wealth of $10 + 12$, and in the the bad state with probability $\frac{2}{3}$ where the lottery does not give you anything, you still end up with wealth of $10$. Thus, we are looking for wealth that I will denote $w^c$ where</p>

<p>$$v(w_c) = \mathbb{E}(v(w)) \implies \frac{w_c - 1}{w_c} = \left(\frac{22-1}{22}\right)\cdot \frac{1}{3} + \left(\frac{10-1}{10}\right) \cdot \frac{2}{3}$$</p>

<p>Solve for $w_c$ and that will be the certainty equivalent. You'll notice that trying to solve this out, we get:</p>

<p>$$\frac{w_c - 1}{w_c} = \frac{101}{110}$$
$$\implies \boxed{w_c = \frac{110}{9} \approx 12.2}$$</p>

<hr>

<p>As for probability premium, it is the shift in probability towards the better lottery outcome that would be needed to make the expected utility of the new lottery equal to the utility of the expected value of the old lottery.</p>

<p>$$\mathbb{E}_{\text{new}}(v(w)) = v(\mathbb{E}_{\text{old}}(w))$$
$$\implies \left(\frac{1}{3} + \pi\right) \cdot \left(\frac{22-1}{22}\right) + \left(\frac{2}{3} - \pi\right) \cdot \left(\frac{10-1}{10}\right) = \left(\frac{22 \cdot \frac{1}{3} + 10 \cdot \frac{2}{3} -1}{22 \cdot \frac{1}{3} + 10 \cdot \frac{2}{3}}\right)$$
$$\implies \frac{101}{110} + \frac{6}{110} \pi = \frac{13}{14}$$
$$\implies \pi = \frac{8}{770} \approx 0.01$$</p>

<p>(assuming I calculated my fractions correctly)</p>

<hr>

<p><strong>Edit:</strong> I see that the question was asking for a risk premium, not probability premium. Notice that the expected wealth due to the lottery is 14, but the certainty equivalent is 12.222...</p>

<p>The difference between the two is the risk premium.</p>
","15008"
"Applications of Trig functions in Economics?","1290","","<p>Are there any applications of trig functions (ie $\sin(x)$, $\cos(x)$,$\tan(x)$) in economics? </p>
","<p>The main property of trig functions is their cyclicality. Then one would think that they could be ideal in time series analysis, to model ""fluctuations around a trend"". I believe that the reasons they are not actually used in such a setting are </p>

<p>1) They are <em>deterministic</em> functions, so they do not allow for fluctuations to be stochastic</p>

<p>2) If the researcher wants to create a model that <em>produces</em> up and down fluctuations (oscillations) around a trend, he would want to <em>obtain</em> that property from the behavioral and other assumptions of the model. If he were to use a trig function, he would <em>a priori</em> impose on the model the sought theoretical outcome.</p>

<p>Instead, one opts for difference-differential equations. There we obtain oscillations (damped or not) if some characteristic roots are complex -and then the trig functions appear, but as an alternative representation, not as buidling blocks.</p>
","19181"
"Economic policies to decrease obesity (would they be effective?)","1285","","<p>According to the Center for Disease Control and Prevention, approximately 35% of adults in the United States are obese. I have done much research on the topic of economic policies to reduce obesity (I did a fat tax simulation for my undergraduate capstone thesis). I have run into three proposals:</p>

<p>1) Fat Tax: A fat tax is a tax on fatty foods or on fats themselves. Various papers I read on the topic simulated a tax on certain fatty foods. However, one paper proposed an ad valorem tax on saturated fats which seems like the most effective way to target fats. The biggest problem found with fat taxes is that fatty foods are very inelastic. This means that a tax won't change consumption much, so this doesn't seem like an effective option.</p>

<p>2) Thin Subsidy: A thin subsidy is pretty much the opposite of a fat tax. It subsidizes foods that are considered healthy. In the literature, this option by itself doesn't change behavior much, but a thin subsidy can also be paired with a fat tax. Basically, the government would use all of the revenues from the fat tax to subsidize healthy foods. When paired together, they are more effective than they are separately, but they still are not very effective in reducing calorie intake.</p>

<p>3) Gym Membership Tax Credit: This is a tax credit you can receive if you have a gym membership. I have not seen as much literature on this topic. Intuitively, if the tax credit is equal to or close to being equal to the cost of the membership, then people may have more incentive to get a gym membership. However, if the credit isn't very close to the cost of the membership, it may not cause people to go get memberships. Another problem with this method is that someone may get a membership and simply not go to the gym. I know most gyms have scanners now, so one remedy could be that the tax credit amount could depend on how many days you scan in.</p>

<p>Other than these three policies, are there any other policies being discussed to slow the trend of obesity? How effective can a policy be in reducing obesity rates?</p>
","<p>Yes, sugar tax!</p>

<p>This is probably as controversial as tobacco tax was back in the days. If you walk through a supermarket, you will find that half of the food section is food full of sugar. Sugar is what makes you fat, not fat itself. It has been known for a while, at least since the professional sports were invented. Yet the lobby of the enormous sugar industry keeps regulators from labeling it as hazardous and taxing its use. If you are doing a research into obesity I highly recommend devoting two hours to watch <em>That Sugar Film (2014)</em>.</p>

<p>I would also recommend taking a multidisciplinary approach and bringing some arguments from biochemical and nutrition fields.</p>
","9400"
"The Frisch-Waugh-Lovell Theorem: an exercise","1280","","<p>I have an equation of the form(all vectors): $y=X_1\beta_1+X_2\beta_2+u$.</p>

<p>I'm interested in knowing if the beta OLS estimators and respective residual for this equation are the same as for when we apply OLS to the following equations:</p>

<ol>
<li>$P_{X_1}y=P_{X_1}X_2\beta_2+v$</li>
<li>$P_Xy=X_1\beta_1+X_2\beta_2+v$, </li>
</ol>

<p>where the $P_Z$ are the usual definition of projection matrices, using $Z$.</p>

<p>So, I've tried using the FWL theorem, and I've got respectively:</p>

<ol>
<li>$\hat\beta_2 = (X_2' P_{X_1}X_2)^{-1}X_2'P_{X_1}y$, and $\hat v = (I- P_{X_1}X_2(X_2'P_{X_1}X_2)^{-1}X_2'P_{X_1})P_{X_1}y$. I was wondering if I miscalculated $\hat u$ since looking at equation 1, since both $y$ and $X_2\beta_2$ are projected in to the space spanned by columns of $X_1$, the residuals would be zero. </li>
<li>$\hat\beta_2 = (X_2' M_{X_1}X_2)^{-1}X_2'M_{X_1}P_X y$, and $\hat v = (I- M_{X_1}X_2(X_2'M_{X_1}X_2)^{-1}X_2'M_{X_1})P_{X}y$.  However, I do not see how the estimate for $\beta_2$ is equal in both cases, since if you notice that applying OLS to equation 2, we get $\hat \beta=(X'X)^{-1}X'P_X y=(X'X)^{-1}X'y$.</li>
</ol>

<p>Any help would be appreciated.</p>

<p>Edit1: well, I found out how to do the 2nd point. We have to notice that $M_{X_1}P_X=(I-P_{X_1})P_X=P_X-P_{X_1}=P_X'-P_{X_1}'=(M_{X_1}P_X)'=P_X'M_{X_1}'=P_X M_{X_1}$ and that $ X_2'P_X=(P_X X_2)=X_2'$.
As to the 1st point I have no idea...</p>
","<p>What we know from FWL theorem, is that the regression</p>

<p>$$M_1y = M_1X_2\beta_2 + M_1u \tag{1}$$</p>

<p>will give the same estimates for $\beta_2$ as the full regression</p>

<p>$$y = X_1\beta_1 +X_2\beta_2 + u \tag{2}$$ </p>

<p>where </p>

<p>$$M_1 = I - P_1 = I - X_1(X_1'X_1)^{-1}X_1'$$ </p>

<p>is the so-called annihilator or residual-maker matrix.  The estimator from $(1)$ is</p>

<p>$$\hat \beta_2 = (X_2'M_1X_2)^{-1}X_2'M_1y \tag{3}$$</p>

<p>So it boils down to examine whether the estimator from the specification </p>

<p>$$P_1y = P_1X_2\beta_2 + w \tag{4}$$</p>

<p>which is</p>

<p>$$\tilde \beta_2 = (X_2'P_1X_2)^{-1}X_2'P_1y \tag{5} $$</p>

<p>will be the same as $\hat \beta_2$.</p>

<p>Well,</p>

<p>$$(2),(3) \implies \hat \beta_2 - \beta_2 = (X_2'M_1X_2)^{-1}M_1u \tag{6}$$</p>

<p>while </p>

<p>$$ (2), (5) \implies \tilde \beta_2 -\beta_2 = (X_2'P_1X_2)^{-1}X_2'X_1\beta_1+ (X_2'P_1X_2)^{-1}X_2'P_1u \tag{7}$$</p>

<p>Given that $(6)$ and $(7)$ involve arbitrary exogenous quantities ($u, \beta_1$) I don't see how they could be equal, except by zero-probability chance.</p>

<p>Even if in our <em>sample</em> $X_1$ and $X_2$ are orthogonal (which would eliminate the first term in $(7)$ but which, with observational data, is a joke to even mention), then the two would be unbiased under strict exogeneity -but this is as far as similarities appear to go here.</p>
","10880"
"Visualization tools for game theory: Game trees","1276","","<p>There are many ways to draw a sequential game 'by hand'. By drawing the game I mean this:</p>

<p><a href=""https://i.stack.imgur.com/Tuwxk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Tuwxk.png"" alt=""enter image description here""></a></p>

<p>Displaying players' decision points, available actions and payoffs.</p>

<p>Is there any way I can do this in R or a similar high level programming language? To be precise: I do not want to plot geometric equations, I want to define a structure (players, points, connections, payoffs) and have the program plot it.</p>

<p>I am currently browsing the 'igraph' package but I am having some difficulty labeling so I am wondering if there is a better way.</p>
","<p>Mathematica has a graph building and drawing capability.</p>

<p>So, if you built the graph in Mathematica, then you could plot it using settings of your choosing.</p>

<p>In Mathematica, you might use the TreeGraph as way to build the graph, and <a href=""http://reference.wolfram.com/language/ref/TreePlot.html"">TreePlot</a> as a way to plot it. For example, the following code generates a tree with the nodes labeled by coordinate and has a similar format to what you want:</p>

<pre><code>TreePlot[{1 -&gt; 4, 1 -&gt; 1, 1 -&gt; 5, 2 -&gt; 4, 3 -&gt; 6, 3 -&gt; 9, 4 -&gt; 8, 
  4 -&gt; 10, 6 -&gt; 7, 8 -&gt; 9}, 
 EdgeRenderingFunction -&gt; ({If[First[#2] === Last[#2], Red, Black], 
     Arrow[#1, .1], 
     Text[#2, LineScaledCoordinate[#1, .5], Background -&gt; White]} &amp;), 
 VertexLabeling -&gt; True]
</code></pre>

<p><a href=""https://i.stack.imgur.com/39tLom.png""><img src=""https://i.stack.imgur.com/39tLom.png"" alt=""enter image description here""></a></p>

<p>Also, note that there are graphical packages like TikZ in Tex which have very powerful graph drawing capability. TikZ is mostly used in unix environments, though, and will not store data structures or do calculations like Mathematica. It is purely a graphical drawing capability.</p>

<p>The graph you have used as an illustration has the font typically used in TeX, so it was probably produced with TikZ or another TeX package. If you want a Mathematica equation to look like that you can use the TraditionalForm function, or explicitly specify the Computer Modern font.</p>
","15347"
"Are bank reserves part of M1 or only part of M2, and why?","1264","","<p>(1) Toyland earns $$100,000 revenue in cash this week.  Toyland managers use this $100,000 to pay down a short-term loan from Bank One.  Bank One keeps the cash in reserve.   As a result of this transaction M1 [x] and M2 [y]</p>

<p>(2) Bank of America takes $25,000 from reserves and makes a loan to Sissy.  Sissy uses the funds to purchase a Mini Cooper.  The funds are then deposited in the car dealer's checking account.   As a result of this transaction M1 [x] and M2 [y]</p>

<p>The answers for these 2 are: </p>

<p>(1) [x] = decreases, [y] = decreases</p>

<p>(2) [x] = increases, [y] = increases </p>

<p>I had gotten both of these questions incorrect because I considered Bank Reserves to be that part of the money that the money keeps in vaults, etc. in a fractional reserve system. 
Usually the bank reserves would be considered about 10% of the total bank's worth. 
Am I correct? Or wrong? If so, why?</p>
","<p>Using the Federal Reserve's definition for M1 (warning, M definitions can vary between countries, so always check the local definition):</p>

<blockquote>
  <p>""M1 is defined as the sum of currency held by the public and transaction deposits at depository institutions (which are financial institutions that obtain their funds mainly through deposits from the public, such as commercial banks, savings and loan associations, savings banks, and credit unions).""</p>
</blockquote>

<p>Note, reserves are not counted as part of M1. The explanation for that is in the answer here:</p>

<p><a href=""https://economics.stackexchange.com/questions/5374/how-does-a-cash-deposit-change-the-m1-measure-of-the-money-supply/5375#5375"">How does a cash deposit change the M1 Measure of the Money Supply</a></p>

<p>So in question 1) we are told that Toyland earns cash and uses it to pay down a short term loan from Bank One. Critically we are not told where Toyland has its account. Note, we can't assume that Toyland doesn't have a bank account, since the bank would have insisted on it having one to receive the loan. We'll assume to make things simple it was Bank One.</p>

<p>If it receives cash from the public that was not in the banking system, then Bank One's cash reserves would increase. At the same time so would Toyland's deposit account, so there is no change to M1 at that point in time. The decrease in the 'cash held by the public' outside the system is matched by the increase in the deposit account at Bank One.</p>

<p>Now Toyland pays off its loan. There is no change to the cash reserves, Bank One simply decreases its loan book, and removes the money from Toyland's deposit account. So M1 decreases, because the loan is repaid and the liability deposit money is removed from the banking system. M2 is essentially M1 + some savings deposits and money market funds, so M2 will decrease as well.</p>

<p>2) Bank of America takes $25k from its cash reserves and makes a loan.</p>

<p>Actually, Bank of America doesn't do that. Bank of America makes a loan by creating a liability deposit account/entry for that amount, and a matching entry in its loan book. Creating that deposit money increases M1 (and M2). Whatever Sissy does with the money subsequently is irrelevant. </p>

<p>Bank Nerd Trivia... 10% is the figure used for reserves in the example Keynes wrote for the 1931 Macmillan report, which has been subsequently copy and pasted into the textbooks. I've never seen an actual banking system that uses 10% - in 1930's reserve ratios were usually 20%+, whereas these days they are down to 1-2% in Europe. Although the US has a 10% reserve rate on ""Net Transaction Accounts"", it has a 0% rate on all other accounts, which makes the actual rate open to account classification decisions by the US banks.</p>

<p>Keynes has a lot to answer for btw., the textbook description is horribly confusing, and also partially incorrect. (Try applying loan repayments to the examples it uses.)</p>
","6654"
"intertemporal utility function usage : calculating consumption","1244","","<p>I have encountered this a lot in my exams and can not seem to understand how to use these functions here is an easy exemple :</p>

<p>A consumer who will only live 2 periods receives 1000€ in the first period and 5000€ in the second period, if the interest is at 0% how much will he consume in both periods knowing that his utility function is :</p>

<blockquote>
  <p>U(C¹,C²) = 3×C¹×C²</p>
</blockquote>

<p>Where C¹ is the consommation of first period and C² of second.</p>

<p>How do I make use of this utility function to calculate the consumption in both periods  ? </p>
","<p>Now that the OP has provided his own answer, let's also give the standard treatment of this problem.  </p>

<p>There is no production, the consumer receives windfall endowments in each period, $Y_1, Y_2$, and he can borrow (or lend) during the first period at an exogenous non-negative interest rate $r$.</p>

<p>What is the two-period budget constraint of the consumer? It is more intuitive to write it as</p>

<p>$$C_2 = Y_2 + (1+r)(Y_1-C_1) \tag{1}$$</p>

<p>The consumer can consume his second period endowment adjusted by the results of its borrowing or lending activities in the first: If his endowment is larger than his consumption in the first period, $Y_1-C_1 &gt;0$, it means that the consumer acted as a creditor, and in the second period he will receive the principal plus interest, to consume in addition to his 2nd-period endowment.</p>

<p>If $Y_1-C_1 &lt;0$ it means that the consumer acted as a borrower, and in the second period he will have to return the loan with its interest. So $(1)$ covers both cases.</p>

<p>Then the utility maximization problem is stated as</p>

<p>$$\max_{C_1,C_2} U(C_1,C_2) \\
s.t. C_2 = Y_2 + (1+r)(Y_1-C_1)  \tag{2}$$</p>

<p>We can insert the constraint into the objective function and maximize only with respect to $C_1$. So the first-order condition is</p>

<p>$$\frac {\partial U(C_1,C_2(C_1))}{\partial C_1} = 0 \tag {3}$$</p>

<p>and the second-order condition is </p>

<p>$$\frac {\partial^2 U(C_1,C_2(C_1))}{\partial C_1^2} &lt; 0 \tag {4}$$</p>

<p>at the critical point.</p>

<p>Using the specific functional form of the utility function of the question, $ U= 3C_1C_2$ we have</p>

<p>$$\frac {\partial U(C_1,C_2(C_1))}{\partial C_1} = 3C_2 - 3C_1\cdot(1+r) $$</p>

<p>$$ = 3[Y_2 + (1+r)(Y_1-C_1)] - 3(1+r)C_1$$</p>

<p>$$ = 3Y_2+ 3(1+r)Y_1 - 6(1+r)C_1 \tag{5}$$</p>

<p>Note that</p>

<p>$$\frac {\partial^2 U(C_1,C_2(C_1))}{\partial C_1^2} = -6(1+r) &lt;0$$
so the second-order condition for a maximum is satisfied.</p>

<p>Setting $(5)$ equal to zero we obtain
$$ C_1^* = \frac {Y_2}{2(1+r)}+ \frac 12 Y_1 \tag{6}$$</p>

<p>From $(6)$ we conclude that consumption in the first period will never fall below half of the period's endowment, and that it is a negative function of the interest. Moreover the consumer will find it optimal to borrow when</p>

<p>$$C_1^* &gt; Y_1 \implies   \frac {Y_2}{2(1+r)}+ \frac 12 Y_1 &gt; Y_1$$</p>

<p>$$\implies Y_2 &gt; (1+r)Y_1$$</p>

<p>Using the specific numerical assumptions of the question, $Y_1 = 1000, Y_2 = 5000, r=0$, we obtain
$$C_1^* = \frac {5000}{2}+ \frac 12 1000 = 3000 $$</p>
","5769"
"Use of mathematics and imprecise definition of terms","1234","","<p>As a postgraduate student of economics I've been trying to expand my mathematical ""toolset"". While doing so I've talked to engineers, physicists and mathematicians, many of which have disdained the use of mathematics in economics. Their arguments vary, but one common theme is summed up by mathematician <a href=""http://www.advisorperspectives.com/newsletters12/An_Attack_on_Paul_Krugman.php"">Michael Edesess' critique</a>:</p>

<blockquote>
  <p>Economics pretends to be mathematics, but it is not mathematics. There
  is a major difference. No mathematician uses a term in a formula, or a
  statement of a theorem, unless that term has first been defined with
  excruciating precision.</p>
  
  <p>And while economists may think they’ve defined terms like ""aggregate
  demand"" or ""economic growth"", they should try reading some real
  mathematics to see what a precise definition truly is. The economists,
  I think, leave the work of definition to be inferred from the way the
  terms are used in the formulas.</p>
</blockquote>

<p>I <em>believe</em> I know the precise definition of (quite a few) economic terms, but maybe Edesess is pointing out to some more profound mathematical foundations which I may not be familiar. Could someone expand on his argument and maybe even counter back?</p>
","<p>Edesess is attacking what is really just a straw man of economics. I'm not sure he really understands the field. To start, economics is not math. We're not claiming that it is. It's more of an ""applied"" science. Economists have never claimed that these definitions are precise in the way that mathematics is. These definitions are modeling constructs---they're for applied work. They're use is temporary in a way. The point is to try to convey an idea in a more precise way than just in words---but everyone knows that they're not a precise as we would like and not as precise as they ultimately should be. They're meant to be debated and later refined. But, as all applied scientists know, you've got to start somewhere and sometimes ideas are best conveyed through simpler---if less detailed mean.  </p>

<p>Coming up with better definitions is a huge part of the economic science. Consider these examples. When the Cowles Foundation was founded in 1932 its motto was ""Theory and Measurement"" (<a href=""http://dido.econ.yale.edu/about/index.htm"">the motto was first adopted in 1952</a>). Measurement is not an easy thing to do. As another example, a lot of <a href=""https://en.wikipedia.org/wiki/Laurence_Kotlikoff"">Larry Kotlikoff's</a> work has dealt with how a lot of fiscal measures are not economically well-defined concepts.</p>

<blockquote>
  <p>Einstein taught us that neither time, nor distance are well-defined physical concepts. Instead, their measurement is relative to our frame of reference – how fast we were traveling in the universe and in what direction. Our physical frame of reference can be viewed as our language or labeling convention. ... Kotlikoff, along with Harvard's Jerry Green, offered a general proof of the proposition that deficits and a number of other conventional fiscal measures are, economically speaking, content-free, concluding that the deficit is simply an arbitrary figment of language in all economic models involving rational agents.</p>
</blockquote>

<p>Also, take another example of current interest. <a href=""https://en.wikipedia.org/wiki/Lars_Peter_Hansen"">Lars Hansen's</a> recent work (winner of the 2013 Economics ""Nobel"" prize) has focused on the difficulty and ongoing failure to define certain economic concepts, including ""bubbles"" and systemic risk. See his essay <a href=""http://www.larspeterhansen.org/documents/FC_2012_Risk_BookSRMM_Challenges_in_Identifying.pdf"">""Challenges in Identifying and Measuring Systemic Risk""</a>. I'm a fan of the dictum he relays, attributed to Lord Kelvin,</p>

<blockquote>
  <p>I often say that when you can measure something that you are speaking about,
  express it in numbers, you know something about it; but when you cannot
  measure it, when you cannot express it in numbers, your knowledge is of the
  meagre and unsatisfactory kind: it may be the beginning of knowledge, but you
  have scarcely, in your thoughts advanced to the stage of science, whatever the
  matter might be. </p>
</blockquote>

<p>He notes that ""an abbreviated version appears on the Social
Science Research building at the University of Chicago."" So, yeah, economists (as social scientists) definitely take this seriously.</p>

<p>So, the point is that economists are well aware of the problems in these ""definitions."" They are a part of ongoing research in the field; sometimes they're ignored if people don't think they're first-order to the problem; etc... </p>
","513"
"Real value of debt","1232","","<p>The Wikipedia article for <a href=""http://en.wikipedia.org/wiki/Real_versus_nominal_value_(economics)"" rel=""nofollow"">real value</a> says</p>

<blockquote>
  <p>In economics, a nominal value is an economic value expressed in
  historical nominal monetary terms. By contrast, <strong>a real value is a
  value that has been adjusted from a nominal value to remove the
  effects of general price level changes over time</strong> and is thus measured
  in terms of the general price level in some reference year (the base
  year).</p>
</blockquote>

<p>Here the Wikipedia link for <em>general price level changes</em> takes me straight to the article for <em>inflation</em>. But then the Wikipedia article for <a href=""http://en.wikipedia.org/wiki/Deflation"" rel=""nofollow"">deflation</a> says</p>

<blockquote>
  <p>Economists generally believe that deflation is a problem in a modern
  economy because it increases the real value of debt</p>
</blockquote>

<p>This sounds like a contradiction to me, because by the first definition, the <em>real value of debt</em> remains constant under deflation.</p>

<p>Can someone explain this?</p>
","<p>If you take s loan for one million dollars at a certain point -  deflation will mean one million dollars is now worth more than when you loaned it, but you still owe a million dollars  (assuming you didn't return any back)  therefore the value of your debt is now increased. 
That being said you can always take loans adjusted for inflation - where you return the real value of your loan regardless of the value of the currency. </p>

<p>There is actually a big argument whether deflation is good or bad - the Keynesians think it's bad - mainly because they think it reduces spending and results in a recession. The Austrians on the other hand think it is nonsense and deflation is good because it means the price of goods is lowered. 
*this was a great simplification, but the point is still there. </p>
","4421"
"Why is MRS equal to Price ratio?","1226","","<p>I've seen a derivation of MRS, but it's not immediately obvious to me why letting MRS equal to the price ratio of two goods will give you the solution to an optimization problem. Can anyone link me to a paper that explains this (or explain it themselves)? It would be great to get both the intuition and mathematical derivation! Thanks in advance!</p>
","<p>The mathematical derivation is straightforward: set up a Lagrangian for the utility maximization the consumer solves subject to a monetary constraint, then divide its partial derivatives with respects to the quantities one with another, and there you have it: MRS equals the price ratio. 
The intuition behind it is that, given fixed prices (that is, a price taking situation), the ratio of the marginal utilities must also remain constant: suppose by contradiction this isn't the case, and that some good provides relatively high marginal utility. Then the consumer would profit from deviating to consuming a basket in which the quantity of said good is higher, since the increase in utility would be higher than the costs incurred. </p>
","11524"
"Wouldn't abolition of cash give rise to a substitute currency?","1210","","<p>Some countries (e.g. Sweden and <a href=""http://www.telegraph.co.uk/finance/personalfinance/comment/11602399/Ban-cash-end-boom-and-bust.html"" rel=""nofollow"">Denmark</a>) plan to abolish physical cash in the future and restrict the use of cash to electronical deposits. One of the reasons for this is to prevent hoarding / boost spending of money, which could be achieved by introducing negative interest rates on deposits far below zero.</p>

<p>However, as far as I know, <a href=""https://mises.org/library/multiple-currencies-and-gresham%E2%80%99s-law-zimbabwe"" rel=""nofollow"">in times of hyperinflation, people resorted to substitute currencies</a> (either foreign currencies or commodities like cigarettes). Wouldn't the same happen if cash was abolished?</p>

<p>For example, suppose the bank charges 20% or more on deposits and you can't withdraw your money in cash (since there is no cash), and you don't want to buy stocks or property for some reason (it's risky or hard to liquidate) and suppose other people have the same problems. Wouldn't it be reasonable then to create and use some alternative currency, like cigarettes or maybe a local currency, which you can store physically?</p>
","<p>""Cash"" is an emergent phenomenon of human economic organization. It exists for lots of reasons, as a provider of economic anonymity, a low transaction cost solution to the double-coincidence of wants, a portable medium of exchange, a tool economic accessibility to all including those in the informal economy, foreigners, the unbanked, and those with poor credit, among others. </p>

<p>A country can make it difficult to use cash in the interest of thwarting anonymity and convenience, usually to prevent money laundering and tax evasion. They can do so by taxing the use of cash, failing to enforce contracts calling for cash, refusing to make more, even criminalizing the possession of cash. </p>

<p>But cash is unlikely to die easily. We know from the experience with drug and alcohol prohibition as well as the international ivory and rhino horn trades that while the regulation can can certainly influence prices and thereby quantities demanded, it is awfully difficult to destroy a market for a valuable product. For a more specific example, possession of money is forbidden to US convicts. Nevertheless, they have developed internal monetary economies based around <a href=""http://www.wsj.com/articles/SB122290720439096481"">canned fish</a>, <a href=""http://www.tampabay.com/features/humaninterest/honey-buns-sweeten-life-for-florida-prisoners/1142687"">shelf-stable pastries</a>, as well as <a href=""http://www.thedailybeast.com/articles/2013/06/02/with-cigarettes-banned-in-most-prisons-gangs-shift-from-drugs-to-smokes.html"">cigarettes and stamps</a>. Cigarettes also emerged as money in <a href=""http://www.jstor.org/stable/2550133?seq=1#page_scan_tab_contents"">WWII P.O.W. camps</a>, showing that even the Nazis couldn't keep a monetary economy from forming.</p>

<p>Sweden in particular has a significant additional obstacle to keeping currency out of their economy. They share boarders with Norway and Finland, each with their own currency. Go to practically any boarder region or tourist spot around the world and you'll see tellers happy to take dollars, euros, or yen in addition to the local currency. It is especially difficult to ditch cash when other sources of cash are available. </p>
","10478"
"Prove the budget correspondence is upper hemi-continuous","1206","","<p>Let $p \in \mathbb{R}_+^L$ be price vector and let $w \in \mathbb{R}_+$ be wealth of the consumer. Define the Budget correspondence $B(p,w) =\{x \in \mathbb{R}_+^L : p\cdot x\le w  \}$ . How to prove that this budget correspondence is upper hemi-continuous?</p>

<p>A correspondence $Γ:R_+^{L+1}+→R^L_+$ is upper hemi-continuous if, $(p_n,w_n)→(p,w) $ and $x_n \to x$ where for each $n$ it's true $x_n \in 
\Gamma(p_n,w_n)$, will ensure $x \in \Gamma(p,w)$.</p>

<p>I've seen a possible solution using Bolzano–Weierstrass theorem by Mark Dean at the following link <a href=""http://www.econ.brown.edu/fac/mark_dean/Maths_HW4_13.pdf"" rel=""noreferrer"">http://www.econ.brown.edu/fac/mark_dean/Maths_HW4_13.pdf</a>. But I failed to understand the last step in his approach where he claims that if every sequence $x_m \in B(p^m, w_m)$ has convergent sub-sequence converging to a point in set $B(p^*, w^*)$, then we have hemi-continuity for budget set, aren't we supposed to show that $x_m$ converge to $B(p,w)$? Am I missing any theorem?</p>
","<p>I am assuming that the following facts do not require proofs for the purposes of this question.</p>

<p><strong>Fact 1:</strong> Let $h_n$ be a sequence in $\mathbb{R}^K$ such that $\lim_{n\rightarrow \infty} h_n =h\in \mathbb{R}^K$. Then, for each $i\in \{1,2,\ldots,K\}$, we have $h^i_n\rightarrow h^i$.</p>

<p><strong>Fact 2:</strong> Let $z_n$ and $q_n$ be sequence in $\mathbb{R}$ such that $\lim_{n\rightarrow \infty} z_n =z\in \mathbb{R}$ and $\lim_{n\rightarrow \infty} q_n =q\in \mathbb{R}$. Then, </p>

<p><strong>i)</strong> $\lim_{n\rightarrow \infty}(z_n\pm q_n)=z\pm q$</p>

<p><strong>ii)</strong> $\lim_{n\rightarrow \infty}(z_n \times q_n)=z\times q$</p>

<p><strong>Fact 3:</strong> Let $z_n$ in $\mathbb{R}$ such that for each $n$, $z_n\leq a\in \mathbb{R}$ and $\lim_{n\rightarrow \infty} z_n =z$. Then, $z\leq a$.</p>

<p><strong>Definition:</strong> A correspondence $G:X\rightrightarrows Y $ is upper hemicontinuous at $x\in X$ if for any open neighborhood of $V$ of $G(x)$. There exists a neighborhood $U$ of $x$ such that for all $x'$ in $U$, $G(x')\subseteq V$.</p>

<p>Unlike the previous remarks, the following fact requires proof. </p>

<p><strong>Fact 4:</strong> Let $G:X\rightrightarrows Y $ be a correspondence. If for every $x_n\rightarrow x\in X$ and $y_n\in G(x_n)$ there exists a subsequence $y_{n_k}$ of $y_n$ with $y_{n_k}\rightarrow y$ and $y\in G(x)$, then $G$ is upper hemicontinuous. Moreover, if $G$ is compact valued, then the converse is also true.</p>

<p>Now, let's go back to your question. Let $(p_n,w_n)$ be a sequence in $\mathbb{R}^{L+1}_{++}$ such that $\lim_{n\rightarrow \infty} (p_n,w_n) =(p,w)\in \mathbb{R}^{L+1}_{++}$. Moreover, let $x_n\in B(p_n,w_n)$ for all $n$. </p>

<p>Let $w^\ast = \sup_n w_n$. Since $w_n\rightarrow w\in \mathbb{R}_{++}$, it must be true that $w^\ast \in \mathbb{R}_{++}$ because otherwise we could have created a subsequence $w_{n_k}$ of $w_n$ for which $w_{n_k}\rightarrow\infty$ which would contradict with $w_n\rightarrow w$. Similar arguments would imply that $p^{\ast} = \min_i( \inf_n p^i_n)&gt;0$ since $p^n\rightarrow p\in\mathbb{R}_{++}^L$.</p>

<p>The previous observations imply that for all $n$ and for all $i$ we have $x_n^i\leq w^\ast/p^\ast$. Therefore, the sequence $x_n$ is bounded. By Bolzano-Weierstrass Theorem, $x_n$ has a convergent subsequence $x_{n_k}$ with $x_{n_k}\rightarrow x$. From here onwards, we will suppress the subscript $k$.</p>

<p>Since $x_n\in B(p_n,w_n)$, we have $\sum_i p_n^i\times x_n^i-w_n\leq 0$. Let $c_n = \sum_i p_n^i\times x_n^i$. By fact 1, we have $p_n^i\rightarrow p_i$ and $x_n^i\rightarrow x_i$ for each $i$, and by fact 2, we have $c_n=\sum_i p_n^i\times x_n^i\rightarrow p\cdot  x$. </p>

<p>By fact 2, $c_n-w_n\rightarrow (p\cdot  x-w)$. Fact 3 implies that $(p\cdot  x-w)\leq 0$, which in turn implies that $x\in B(p,w)$. This concludes the proof that the budget correspondence is upper hemicontinuous.</p>

<p><strong>Original (incorrect) Answer</strong></p>

<p>The following answer has been posted earlier. However, I realized that there is a mistake with this one. I am keeping this here since the original question had been wondering specifically about how Bolzano-Weierstrass theorem is relevant to the question and comparison of this incorrect answer and the correct version shows why we would need this theorem.</p>

<p><strong>Definition:</strong> A correspondence $G:X\rightrightarrows Y $ is upper hemicontinuous at $x\in X$ if for all sequences $x_n\in X$ with $x_n\rightarrow x$, for all $y_n\in G(x_n)$ with $y_n \rightarrow y \in Y$, we have $y\in G(x)$.</p>

<p>Now, let's go back to your question. Let $(p_n,w_n)$ be a sequence in $\mathbb{R}^{L+1}$ such that $\lim_{n\rightarrow \infty} (p_n,w_n) =(p,w)$. Moreover, let $x_n\in B(p_n,w_n)$ for all $n$, with $x_n\rightarrow x$. </p>

<p>Since $x_n\in B(p_n,w_n)$, we have $\sum_i p_n^i\times x_n^i-w_n\leq 0$. Let $c_n = \sum_i p_n^i\times x_n^i$. By fact 1, we have $p_n^i\rightarrow p_i$ and $x_n^i\rightarrow x_i$ for each $i$, and by fact 2, we have $c_n=\sum_i p_n^i\times x_n^i\rightarrow p\cdot  x$. </p>

<p>By fact 2, $c_n-w_n\rightarrow (p\cdot  x-w)$. Fact 3 implies that $(p\cdot  x-w)\leq 0$, which in turn implies that $x\in B(p,w)$. This concludes the proof that the budget correspondence is upper hemicontinuous.</p>
","8567"
"Corporate Finance: From External Financing Needed(EFN) to Sustainable Growth Rate","1173","","<p>Well in <a href=""http://www.zenwealth.com/businessfinanceonline/FF/EFN.html"" rel=""nofollow"">this link</a> I get the EFN definition that I know of, with the spontaneous liabilities term included. I'm trying to derive the Sustainable Growth Rate for a corporation, from this definition of EFN.</p>

<p>How does one calculate the liabilities-that-change-directly-with-sales term, using just previous year's sales (S), total assets(A), total debt(D), total equity(E), projected growth in sales(g), profit margin(PM) and retention ratio(b) as variables?</p>

<p>I found <a href=""http://homes.chass.utoronto.ca/~krybakov/teaching_files/finance/notes/ch3%20long-term%20planning.pdf"" rel=""nofollow"">this link</a>(page 11-12) that does the required derivation, but I don't understand the reasoning...</p>

<p>Any help would be appreciated.</p>
","<p>We can replace growth rate in the formulation as below
$$\frac{A_0}{S_0}gS_0-\frac{L_0}{S_0}gS_0-PM(1+g)S_0b=0$$
$$(A_0-L_0)g-PMS_0b-PMS_0bg=0$$
$$g=\frac{bPMS_0}{A_0-L_0-bPMS_0}$$</p>

<p>In the paper you linked the author assumed $A_0$ and $L_0$ to be total assets and total debt (pg.11); therefore $A_0-L_0=E_0$
$$g=\frac{bPMS_0}{E_0-bPMS_0}$$
$$g=\frac{b\frac{PMS_0}{E_0}}{1-b\frac{PMS_0}{E_0}}$$
$$g=\frac{b\times ROE}{1-b\times ROE}$$</p>
","6703"
"Who determines the exchange rate and how?","1158","","<p>I have almost no knowledge about economics. However, a question always comes in my mind. How exchange rate really differ? I live in Bangladesh. So how, why, who changing BDT and US Dollar exchange rate?</p>
","<p>In many ways, it's no different to how any other price is set - by supply and demand. The only thing is, that because it's a transaction of money for money, there's some symmetry at play.</p>

<p>When you buy USD with BDT, the price you pay for your USD will go up if the general market demand for USD goes up, or if the supply of USD goes down. Similarly, it will go down if USD demand goes down or USD supply goes up.</p>

<p>And if the supply of BDT goes up, or the demand for BDT goes down, the price of USD will go up. If the supply of BDT goes down, or the demand for BDT goes up, then the price of USD will go down.</p>

<p>Bear in mind that because there is an active international market for these currencies, then the relative values of each reflects a minute-by-minute shifting balance between buyers and sellers of each; and the exchange rates reflect all available information, as well as the market participants' future expectations.</p>
","19486"
"When countries industrialise, why do jobs from agriculture shift to manufacturing?","1153","","<p>This is a historical trend whether it may 18th century Britain or 19th century America or what's currently happening in China. What I am confused is  by the fact that manufacturing jobs such as <em>working on an assembly line</em> are not that well paying. Still the trend holds true. </p>

<p>I want to know what are the causes for the shift.</p>
","<p>This is a common area of study in Development Economics. There is for example the <a href=""https://en.wikipedia.org/wiki/Dual-sector_model"" rel=""nofollow noreferrer"">Dual-sector model</a>, first developed in 1954. It is very well explained in the link provided, but basically:</p>

<blockquote>
  <p>[the] agricultural sector is typically characterized by low wages, an abundance of labour, and low productivity through a labour-intensive production process. In contrast, the capitalist manufacturing sector is defined by higher wage rates as compared to the subsistence sector, higher marginal productivity, and a demand for more workers. Also, the capitalist sector is assumed to use a production process that is capital intensive, so investment and capital formation in the manufacturing sector are possible over time as capitalists' profits are reinvested in the capital stock. [...] </p>
  
  <p>The primary relationship between the two sectors is that when the capitalist sector expands, it extracts or draws labour from the subsistence sector. This causes the output per head of labourers who move from the subsistence sector to the capitalist sector to increase. [...] </p>
  
  <p>The agricultural sector has a limited amount of land to cultivate, the marginal product of an additional farmer is assumed to be zero as the law of diminishing marginal returns has run its course due to the fixed input, land. As a result, the agricultural sector has a quantity of farm workers that are not contributing to agricultural output since their marginal productivities are zero. This group of farmers that is not producing any output is termed surplus labour since this cohort could be moved to another sector with no effect on agricultural output. [...]</p>
  
  <p>The end result of this transition process is that the agricultural wage equals the manufacturing wage, the agricultural marginal product of labour equals the manufacturing marginal product of labour, and no further manufacturing sector enlargement takes place as workers no longer have a monetary incentive to transition.</p>
</blockquote>

<p>In other words,, <strong>low productivity in agriculture due to unlimited land and workers and low use of capital means low agricultural wages, whereas high productivity in new capital intensive industries means high wages, thereby leading to a migration process that continues until wages equalise.</strong> </p>

<p>It might be worth noticing that this model was also used by Simon Kuznets to explain why industrialised countries saw a non-monotonic evolution of wage inequality between 1870 and 1950 (i.e. an increase and then a decrease in inequality), pattern that came to be known as the <a href=""https://en.wikipedia.org/wiki/Kuznets_curve"" rel=""nofollow noreferrer"">Kuznets Curve</a>. As the article above states:</p>

<blockquote>
  <p>The Kuznets curve implies that as a nation undergoes industrialization – and especially the mechanization of agriculture – the center of the nation’s economy will shift to the cities. As internal migration by farmers looking for better-paying jobs in urban hubs causes a significant rural-urban inequality gap (the owners of firms would be profiting, while laborers from those industries would see their incomes rise at a much slower rate and agricultural workers would possibly see their incomes decrease), rural populations decrease as urban populations increase. Inequality is then expected to decrease when a certain level of average income is reached and the processes of industrialization – democratization and the rise of the welfare state – allow for the trickle-down of the benefits from rapid growth, and increase the per-capita income.</p>
</blockquote>
","18030"
"Can destruction be profitable?","1147","","<p>We often see news that some company destroys items they couldn't <a href=""http://www.huffingtonpost.com/2010/01/06/hm-wal-mart-destroy-unsol_n_413234.html"">sell</a> in time.</p>

<p>Also we can see <a href=""http://www.theatlantic.com/health/archive/2012/01/second-life-what-happens-to-old-and-expired-supermarket-products/251052/"">news of supermarkets destroying food</a> just because it's not fresh although it's perfectly edible. </p>

<p>If someone destroy goods, he would get $0 for it or even need pay for the disposal. How can this act be profitable for a company? </p>
","<p>It can be profitable for the monopolist to do so. For the conventional producer who is a price taker the profit objective function looks like this:
$$\max_{q} \Pi^c $$
where $\Pi^c = P \cdot q - C(q)$.</p>

<p>That is, they seek to maximize profits, facing an exogenous price to sell goods and where costs are a function of amount produced. If everything is nice and differentiable and concave this gives a first order maximizing condition of:
$$ 0 = \frac{\partial\Pi^c}{\partial q} = P - \frac{\partial C(q)}{\partial q} \rightarrow q = g(P) $$  where $g(P)$ is the inverse of function $\frac{\partial C(q)}{\partial q}$ (increase q from zero until marginal cost equals the price).</p>

<p>But for a monopolist $\Pi^m = P(q) \cdot q - C(q)$. That is, the monopolist is not a price taker, they know that when they produce more prices will fall. Resulting FOC:</p>

<p>$$ 0 = \frac{\partial\Pi^m}{\partial q} = P(q)+q(\frac{\partial P(q)}{\partial q}) - \frac{\partial C(q)}{\partial q}$$</p>

<p>As a result, a monopolist in this setting will not want to sell where price equals marginal cost but rather a higher price than marginal cost:
 $$ \frac{\partial C(q)}{\partial q} - q(\frac{\partial P(q)}{\partial q})= P(q) $$
Recall: $- q(\frac{\partial P(q)}{\partial q}) &gt; 0$</p>

<p>Indeed, it is this selling of goods above their marginal cost that is the source of the monopolist's monopoly rents. </p>

<p>Now back to the question itself which asks about when ""company destroys items they couldn't sell in time."" We can think of inventory as a good with low or zero marginal cost, so yes, by the argument above, it can be profit maximizing to not sell goods with a price above costs as long as it lowers the profits on the other goods you sell enough to offset the additional revenue. </p>

<p>Other forces are likely at play as well. Stores often worry about their brand value and low quality, low price, goods may harm their relationship with their customers. Many people shop at stores specifically for the high quality goods and others at different stores for low prices and it may be too costly to move spoiling goods from one venue to the other and cheaper just to toss it. We can also think of <a href=""https://en.wikipedia.org/wiki/The_Muffin_Tops"" rel=""nofollow"">the muffin stumps of the TV show Seinfeld</a> as an example of this high transaction costs / missing markets problem.  </p>

<p>That said, there are sometimes innovative alternative methods of disposal:</p>

<blockquote>
  <p>Rotisserie chickens have been around for a while. I used to bypass
  them and roast my own, until I noticed something: The rotisserie
  chickens were actually cheaper than buying and roasting my own.</p>
  
  <p>Cat Vasko noticed the same thing and decided to figure out why. The
  answer makes a surprising amount of sense: Grocery stores make them
  out of unsold chicken that is about to pass its expiration date. It's
  an elegant way to make a profit out of food that would otherwise be a
  net loss. And it's not just chicken -- according to Vasko, the
  ever-expanding prepared-foods section of the supermarket uses up all
  sorts of unsold produce and meat. It is, as she says, a bit like
  hunter-gatherers using every inch of the animal.</p>
</blockquote>

<p><a href=""http://www.bloombergview.com/articles/2014-07-24/everyone-wins-when-you-buy-a-rotisserie-chicken"" rel=""nofollow"">Everyone Wins When You Buy a Rotisserie Chicken</a> </p>
","6853"
"Has the Nash Equilibrium lead to any significant economic discoveries?","1147","","<p>The Nash Equilibrium provided a new look at certain economic problems and won the Nobel Memorial Prize in Economic Sciences in 1994.  Since it's creation, the Nash Equilibrium has been applied to ""international relations"" specifically for war and arms-race scenarios.<br>
But, has the Nash Equilibrium lead to any significant economic discoveries?  I had heard rumors of the Nash Equilibrium being applied to bank-runs and other financial crises but nothing to back it up. </p>
","<p>Two areas that have been profoundly affected by game theoretic research stemming from Nash's contribution are</p>

<h2>Oligopoly theory</h2>

<p>There are actually a few examples of what would come to be known as Nash equilibrium in the industrial organization literature that predate Nash's work (for example, Cournot's 1838 analysis of oligopoly competition). However, until Nash (and Selten, Harsanyi, and others) made game theory a general purpose tool, industrial economics was primarily focused on relatively naive models of competition. In the last 30-40 years there has been a revolution in industrial organisation as economists have used game theory to essentially reinvent the study of market competition around oligopoly theory and the study of strategic interaction. Our modern understanding of consumer search, limit pricing, strategic entry and entry deterrance, predatory pricing, strategic advertising, switching costs, product differentiation, platform competition, horizontal and vertical integration, etc. are all predicated on models that rely mostly on Nash equilibrium (or a refinement thereof) as the solution concept. Jean Tirole was recently awarded the Nobel prize largely for work in this area.</p>

<p>This work has also found great practical application in areas such as antitrust policy. Prior to the 1960s, antitrust enforcement in the US (and, to a large extent, elsewhere) was inconsistent and based on unsound economic principles. A combination of the insistence by scholars (especially those based in Chicago) on more careful analysis, and the new tools of oligopoly theory have lead to a much more robust and well-grounded approach to regulating competition.</p>

<h2>Auction theory</h2>

<p>The study of auctions is game theoretic by its very nature: most auctions involve very direct strategic interaction between a relatively small number of bidders. It should come as little surprise, then, that auction theory essentially did not exist prior to the work of Nash (the formal study of auctions can be traced to W. Vickrey (1961) ""<a href=""http://libeccio.di.unisa.it/SocialNetworkAlgo/reading/Vickrey61.pdf"">Counterspeculation, Auctions, and Competitive Sealed Tenders</a>,"" <em>Journal of Finance</em> 16(1); also the recipient of a Nobel prize).</p>

<p>None of the cornerstones of auction theory (revenue equivalence, the linkage principle, optimal auctions—source of yet another Nobel prize, etc.) would exist without the solution apparatus that can be traced to Nash. This work, too, has been of great practical importance. From radio spectrum licenses to carbon emissions permits, and from public procurement to Google ad auctions, auction theory has had a significant effect on informing good auction design. See Klemperer (2004) <a href=""http://www.nuff.ox.ac.uk/users/klemperer/VirtualBook/VirtualBookCoverSheet.asp"">Auctions: Theory and Practice</a>, Princeton University Press for an accessible summary of the theory and its applications.</p>
","1624"
"How does inflation impact the welfare of the economy?","1146","","<p>When the government causes inflation through printing money, the individuals who saved their money in the bank are poorer.<br>
Is there a way to determine how different inflation rates impact the welfare of the economy?<br>
I tried answering this question myself using the production function, and, though I was able to come up with some conjectures, I was unable to come to a definite conclusion.  </p>
","<p>First, there are direct negative effects from inflation, known as the <strong>shoe leather cost</strong> and <strong>menu costs</strong> of inflation. These are direct costs which come from price changes: People will carry less cash, need to update their knowledge about prices, firms need to update their prices and wages, and similar. These are usually small, but typically higher given higher inflation rates.</p>

<p>Second, there are direct <strong>redistributional</strong> effects, which come from the devaluation of money and everything denoted in nominal terms, including most importantly nominal bonds and debt (credits). Usually, we imagine borrowers to be less wealthy than lenders <em>(1)</em>. Here (unexpected) inflation will redistribute wealth from the rich to the poor. Under most standard welfare functions, this will be a first-order welfare improvement.</p>

<p>Third, we typically think that poorer people have higher <strong>marginal propensity to consume</strong> (MPC). Assuming that we are in a situation with inefficiently high savings rates (for example in Keynesian traps), the aforementioned redistribution will improve allocations, but this is typically a second-order effect (but also this will depend on what you believe is true about the Keynesian multipliers).</p>

<p>Wage contracts belong into the second argument, but deserve a special mentioning due to their <a href=""http://en.wikipedia.org/wiki/Phillips_curve"" rel=""nofollow"">extensive treatment</a> in the literature.</p>

<p><em>(1)</em>: This is sufficient, but not necessary. In order to get a higher MPC from borrowers than from lenders, it is sufficient that the borrowers are not optimally smoothing consumption over time (for example, because they are up against a borrowing constraint) - we call these types of consumers <em>Hand-to-mouth</em>, because they will typically consume all their disposable income. As long as the distance between the (aggregated) borrowers consumption and what they would like to consume in a frictionless environment is larger than the distance between the (aggregated) lenders' consumption and what they would like to consume in a frictionless environment <em>(2)</em>, devaluing debt will increase consumption.</p>

<p><em>(2)</em>: It may sound surprising, but there is a significant mass of wealthy hand-to-mouth consumers. See <a href=""http://www.nber.org/papers/w20073"" rel=""nofollow"">Kaplan et al, 2014</a></p>
","1793"
"Maxmin and minmax strategies","1146","","<p>I was solving for a stable equilibrium in the following 2 player zero sum game. I need to calculate the equilibrium using maxmin and minmax strategies. In this game they should come out to be identical and coincide with the mixed strategy Nash's equilibrium.</p>

<pre><code>                        P2
               L                R
   L       (0.6,0.4)         (0.8,0.2)
</code></pre>

<p>P1</p>

<pre><code>  R        (0.9,0.1)         (0.7,0.3)
</code></pre>

<p>If I solve it formally, the expected payoff of P1 will be the expression:</p>

<p>$E = 0.6(pq) + 0.8p(1-q) + 0.9(1-p)(q) + 0.7(1-p)(1-q)$</p>

<p>where p is probability of P1 playing L and q is the probability pf P2 playing L. Now, P2 is trying to minimize E keeping in mind that P1 is trying to maximize it</p>

<p>i.e. min max {E}</p>

<p>and P1 is trying to maximize E keeping in mind that P1 will try to minimize E i.e.</p>

<p>max min {E}</p>

<p>and vice versa. Essentially both strategies played simultaneously should give the same equilibrium. How to go about it, I am stuck in the maths part of the problem now.</p>
","<p>The question was clarified in the comments as</p>

<blockquote>
  <p>How to calculate $\min\limits_q \max\limits_p E(p,q)$ for a given function $E(p,q)$?</p>
</blockquote>

<p>What this notation means is that $p$ is chosen first, and $q$ is chosen afterwards.</p>

<p>Assume that $p$ is a given parameter. Then $E(p,\cdot)$ is a function over $q$ only. So you take the minimum of the function $E(p,\cdot)$. In economics this usually means taking the first derivative with respect to $q$. From this you get the optimal value of $q$, given $p$. This is basically a function $q^*(p)$. So you know how $q$ will be chosen given the choice of $p$. This gives you the function $E(q^*(p),p)$. You choose $p$ to maximize this function. Again in economics this usually means taking the first derivative w.r.t. $p$.</p>

<p>With $\max\limits_p \min\limits_q$ the procedure is essentially the same, but there you first derive the maximum for $p$ given $q$. This yields $p^*(q)$. Using this, you minimize $E(p^*(q),q)$ w.r.t. $q$.</p>

<p>A sidenote:<br>
If $E(p,q)$ is linear in both $p$ and $q$ the functions $q^*(p)$ and $p^*(q)$ are usually not continuous. To be more precise they are not functions but mappings. As such, they upper hemicontinuous but that is very technical and you may not need to know what it means.</p>
","8510"
"Why absolute value in elasticities and marginal rate of substitution?","1138","","<p>This is a point I find very confusing and very hard to justify to students. Depending on the books, one finds many different conventions regarding the sign of elasticities and marginal rate of substitution (MRS). Some define them taking absolute value, some don't, and  one sometimes finds inconsistencies inside a single book or set of notes. </p>

<p>My questions are :</p>

<ul>
<li>To your knowledge, what is the most conventional stance regarding the use of absolute value in the definition of
<ul>
<li>Own-price elasticity</li>
<li>Cross-price elasticity</li>
<li>MRS</li>
</ul></li>
<li>Is it mere convention or is there somewhat of a rational for taking absolute value in some/all/none of the cases?</li>
</ul>
","<p>I think there are pedagogical advantages to discussing both the raw numbers and the absolute values and I think the benefits of both explain why they both show up (sometimes in the same text, even).</p>

<p>Each elasticity number gives two bits of information. First, the absolute value with respect to 1 and second, the sign. Now, clearly, if you had a negative elasticity, you could compare it to -1. However, it becomes somewhat difficult to teach when using phrases like ""greater than"" or ""less than"" -1 to discuss a good being (in)elastic, since ""greater than -1"" is actually inelastic if the elasticity is negative. It is much more intuitive to be able to discuss the ratios of percent changes if ""greater than"" does in fact mean that the top is bigger than the bottom and vice versa for ""less than"".</p>

<p>Of course, there is also a bunch of information tied up in the sign of the elasticity. We get the Law of Demand out of own-price elasticity, we get compliments/substitutes from cross-price elasticity, etc. So it is important to still make sure students understand the importance of the sign.</p>

<p>When I am teaching, I try to discuss both parts explicitly, but make clear that the elasticity itself includes the appropriate sign. I think most books are trying to capture these two bits of information in one way or another. In any case, the formal definition of elasticity should include the sign, but if one is just talking about how elastic a good is, the absolute value could be reported (with the note that it is the absolute value of the elasticity, not the elasticity itself). </p>

<p>As for MRS, it's usually not the absolute value, per se, that we report, but rather the negative of the derivative dy/dx. This is quite standard, since it has the intuitive interpretation of the consumer being willing to give up so many units of x for so many units of y. Since indifference curves are usually convex, this derivative is negative, thus changing the interpretation (and intuition) somewhat if we don't negate it.</p>
","547"
"What will happen to bank loans in the event of hyper inflation?","1137","","<p>Say for example a person gets a home loan of $100,000 in a certain country at an interest rate of 10%. Inflation is normally around 5% in this country.</p>

<p>What could happen to that person's loan if the country's inflation rises to say 1000%?</p>
","<p>Complementing @FooBar 's answer, a more and more usual contractual arrangement observed is for the debt principal to <em>not</em> be indexed to inflation, but for the contractual (nominal) interest rate of the loan to be ""variable"", something like ""base + premium"". In such a case, nominal interest rates will adjust to inflation, and so the loan repayments will increase to a degree from that channel, although the nominal value of the debt principal will not change. </p>

<p>Finally, another contractual arrangement, seen in countries with weaker economies, is to have the debt indexed to an exchange rate, usually of one of the ""international currencies"". The ""lure"" for borrowers is that in such a case the interest rate is lower to what it would be otherwise. The risk is that if the exchange rate deteriorates (which will happen in high inflation cases), they will see the nominal value of their debt jump (while their income does not necessarily follow suit).</p>
","8210"
"Why could China, much poorer than US, lend so much money to US?","1126","","<p>The GDP per capita of China is only a fifth of that of US.
But China has lent more than a trillion dollars to US.</p>

<p>How could the much poorer China lend so much money?
Where did those money come from?</p>
","<p>Let's start with the balance of trade between the US and China.  China exports far more to the US than it imports.  The difference (trade balance) is over $200 billion a year:</p>

<p><img src=""https://i.stack.imgur.com/arutO.png"" alt=""US-China trade balance""></p>

<p>China's labor force is about 800 million workers according to the <a href=""http://data.worldbank.org/indicator/SL.TLF.TOTL.IN"" rel=""nofollow noreferrer"">World Bank</a>.  That is likely understated, BTW.  But assuming 800 million workers and \$450 billion in China-US exports, that is just ~$560/year per worker.  So you don't need a lot of GDP per capita to build up a massive trade balance.</p>

<p>Now, how does the trade balance affect US debt? Since China is exporting more than it imports to the US, it receives a surplus of US dollars in return.  The US also exports to China, resulting in RMB outflows to the US.  But since the China exports >> US exports, the flow of trade payments correspondingly shows US dollars >> China RMB. </p>

<p>This causes a supply-demand imbalance because the supply of USD is much greater than the supply of RMB.  That would normally cause the exchange rate to rise so that the RMB appreciates against the dollar.</p>

<p>But, China has historically wanted to keep its exchange rate low, so as to encourage exports.  So it needs to balance out this supply-demand imbalance.  Fortunately (for China), the US government runs a huge deficit annually which it needs to borrow in USD to fund.  So China just turns around and lends the USD back to the US, in effect ""re-exporting"" the USD back to the US.</p>

<p>This helps China keep the exchange rate low, and results in a growing debt balance between the <em>US government</em> and China:</p>

<p><img src=""https://i.stack.imgur.com/2bQ0h.jpg"" alt=""China holdings of US debt""></p>

<p>This shows why low GDP per capita in China can still result in large sovereign indebtedness to China.</p>
","4475"
"Why does a currency devaluation make a country more attractive for foreign direct investment?","1112","","<p>The author of <a href=""http://indianexpress.com/article/business/business-others/cheaper-imports-to-rise-devaluation-of-yuan-by-china-to-hit-indias-exports/#sthash.DwVYGCt9.dpuf"" rel=""nofollow"">this article</a> says ""[the devaluation of the yuan] may also have impact on [foreign direct investment (FDI)] if China becomes a more attractive destination vis-a-vis India"". Why is this?</p>

<p>I understand that the following sentence then says ""investors would go there where with the exchange rate he will get more kick for his dollar"", but what makes China a more attractive destination for FDI than India following the devaluation of the yuan?</p>
","<p>A depreciation in the Yuan will result in an increase of Chinese exports as where countries compete on price for goods like steel and tires the demand is very elastic. A small change in price will lead to a large shift in the quantity demanded. India knows this and after a succession of poor last few months exports will stand to lose out even more now that the Yuan has devalued. </p>

<p>Also now that China has changed its exchange rate, China could be leaning to a more flexible exchange rate (which the article suggests) opening up for an increase in capital mobility which investors look favourably upon. The devaluation of the yuan has also decreased the price of Chinese assets thus making it cheaper to invest. </p>

<p>It is likely that the further reduction of the price of Chinese exports will cause the currency to appreciate once again as demand for Chinese goods increases. Some investors will take on Chinese assets and currency, predicting the currency will appreciate in the future, resulting in a nice profit.</p>

<p>Finally as India's export reliant sectors struggle to compete with supplying major industries around the world,  the drop in market share will be swallowed up by China resulting in more attractive Chinese businesses (which may be open to FDI). India is also struggling to supply its domestic industries as it cannot compete on prices. This uncertainty around India and its lacklustre performance will likely see FDI being pulled out and reinvested into more lucrative opportunities.</p>
","8785"
"Why does deflation cause banks to increase their interest rates?","1106","","<p>I have read that in a deflationary spiral, lower prices cause banks to increase their interest rates. Is this true and what is the logic behind it? </p>
","<p>I suspect there is a small mistake in your notes. </p>

<p>Deflation does not cause <em>banks</em> to increase their interest rates. However it is true that a deflationary spiral (or plain deflation for that matter) causes <em>real</em> interest rates to increase. These are the interest rates that matter for the economy anyway, which is why in macroeconomics we often refer to the real interest rate even if it's not explicitly stated so.</p>

<p>The nominal interest rate, set by banks in part, is the interest rate in terms of money. It determines how much money we have to pay back for credit.
The real interest rate  is the rate in terms of goods and services. It determines how many goods and services we have to pay back for credit.</p>

<p>The real interest rate is defined as:</p>

<p>$ (1+r) = (1 + i) / (1 + \pi) $, which can be approximated by:
$r = i - \pi$, where r is the real interest rate, i is the nominal interest rate set by banks and $\pi$ is the inflation rate.</p>

<p>When we have deflation we get a negative $\pi$, which, as can be seen from the equations above, increases the real interest rate r. The smaller $\pi$ is, the bigger r gets. When $\pi$ is negative, even if we set $i$ to its lowest possible value, which is 0, the real interest paid on it will be positive. This means the amount paid back in goods and services is larger than the amount borrowed and increasingly so the bigger the deflation (smaller $\pi$) is.</p>
","10324"
"Common Knowledge and the Red Hats Puzzle","1096","","<p>Here is a puzzle that is supposed to help illuminate common knowledge in game theory. Three girls are sitting in a circle, each wearing a red or white hat. Each can see the color of all hats except their own. Now suppose they are all wearing red hats. </p>

<p>It is said that if the teacher announces that at least one of the hats is red, and then sequentially asks each girl if she knows the color of her hat, the third girl questioned will know her hat is red. I understand the reasoning there. The first must have seen at least one red hat on the other two to say I don't know. And the second girl must have seen a red hat on the third, or else she would deduce that the first girl saw a red hat on her. </p>

<p>What I don't understand is the necessity of the teacher. Everyone knows there is at least one red hat. And, if we start with common knowlege, they should figure out that everyone else knows that. So is the teacher only introduced if common knowledge is not an assumption?</p>

<p>Source: <a href=""http://cowles.econ.yale.edu/~gean/art/p0882.pdf"">http://cowles.econ.yale.edu/~gean/art/p0882.pdf</a></p>
","<p>Without the teacher, everyone knows that there is at least a red hat, <em>but nobody knows that everyone knows</em> - the fact is not common knowledge. </p>

<p>With the introduction of the teacher, </p>

<ul>
<li>Girl 1 doesn't answer. <strong>Due to common knowledge</strong>, 2 and 3 can reason: ""1 knows there is at least one red hat, and since she doesn't know her hat color, 2 and/or 3 must have a red hat.</li>
</ul>

<p>Without the introduction of the teacher,</p>

<ul>
<li>Girl 1 doesn't answer. Without common knowledge, there is nothing 2 and 3 can reason on top of their prior knowledge: 2 will keep knowing that 3 has a red hat, and 3 will keep knowing that 2 has a red hat. Nothing more.</li>
</ul>

<p>In other words: Without the teacher, the set of knowledge is:</p>

<ul>
<li>1: 2+3 have red hats</li>
<li>2: 1+3 have red hats</li>
<li>3: 1+2 have red hats</li>
</ul>

<p>The teacher works as an injector of additional knowledge:</p>

<ul>
<li>1: 2+3 both know that there is at least one red hat</li>
<li>2: 1+3 both know that there is at least one red hat</li>
<li>3: 1+2 both know that there is at least one red hat</li>
</ul>

<p>And, common knowledge means that in the next level, <em>everyone knows that everyone knows</em></p>

<ul>
<li>1: 2+3 both know that I know that there is at least one red hat</li>
</ul>

<p>etc, <em>ad infinitum</em>. This additional information is required to solve the puzzle.</p>
","3208"
"What is the difference between marginal cost and average cost?","1096","","<p>Marginal Cost is 
$$MC(y) = \frac{\partial C(y)}{ \partial y}$$<br>
Average Cost is 
$$AC(y) = \frac{ C(y)}{ y}$$
Average Variable Cost is 
$$AVC(y) = \frac{VC(y)}{ y}$$
Note: 
Cost is 
$$ C(y) = FC + VC(y)$$ 
I don’t understand what the differences are. Like I understand the definition of cost function, fixed costs, and variable costs, but I don’t get how marginal cost, average cost, and average variable costs are related. </p>

<p>Can someone explain? </p>
","<p>Suppose initially there are no fixed costs. </p>

<p><strong>What does it mean to take an average?</strong></p>

<p>Consider a cost function $C(y)$. What does it mean to take the “average” of this function? Mathematically, it is just $$A(y) = \frac{c(y)}{y}$$ </p>

<p>Let’s suppose we are considering $C(y) = y^3$. Suppose we now consider $y = 5$. Then $$A(5) = \frac{5^3}{5} = 25 $$
This is just saying that, for each unit I buy, I am buying them at $25$ each on average. So I could have paid 
$$ \frac{15 + 39 + 46 + 14 + 11}{5}$$
or 
$$ \frac{17 + 3 + 78 + 23 + 4}{5}$$
<strong>What information does the average cost give us?</strong></p>

<p>The 'cost per unit' given by an average cost function isn't like taking an average by adding up the cost of each unit we bought. When we are given a cost function $C(y)$, this just tells me the total cost. I don't know how much my first TV cost me from this equation alone. And the average doesn't tell me that either. <strong><em>Note how above we have two sets of 5 TVs that yielded the same average cost. Thus, the average cost function doesn't tell me how much I paid for each specific TV.</em></strong></p>

<p><strong>What does marginal cost tell me?</strong> </p>

<p>This is exactly what marginal cost provides. Marginal cost provides the specific cost of each successive infinitesimal amount of good. Consider again $C(y) = y^3$. 
$$MC(y) = \frac{d C(y)}{d y}= 3y^2$$</p>

<p>Suppose I have purchased $3.5$ units of TV. Then the MC equation thus says, for $c(y) = y^3$, each additional infinitesimal amount of TV costs me $$3(3.5)^2 = 36.75$$ <strong>at that point</strong>. If I purchase an additional $0.1$ amount of TV, then my MC changes and now I am at $$3(3.6)^2 = 38.88$$</p>

<p>Thus, this concept is a bit trickier because it involves a continuous amount of TV and the cost per infinitesimal unit changes as you buy more. So you really can't just consider how much $MC(1)$ is and $MC(2)$ is. You are considering it for some infinitesimal additional amount $dy$ at a given point (e.g. $y=2$). The trend is easier to think through if you don't restrict yourself to integers. Note, we are assuming you can have noninteger quantities of goods, otherwise we wouldn't be working in $\Bbb{R}^n$ and the integration later might be trickier.  </p>

<p><strong>Example to Clarify Marginal Cost</strong> </p>

<p>So suppose I want to buy $5$ TVs. For the $k$th TV purchased, the $$MC(k)= 3k^2$$ Going back to our example above, let's now suppose $k \in [0,5]$. To find the average cost, we simply do the addition formula used above for the 5 TV example, except now summed over each infinitesimal amount (of which there are an infinite number). This gives us  </p>

<p>$$A(5) = \frac{3(0)^2+\cdots + 3k^2+ \cdots + 3(5)^2}{5} = \frac{\int_{0}^{5} 3y^2 dy}{5}= \frac{(125-0)}{5}=\frac{c(5)}{5}=25$$</p>

<p>$$A(5) =25$$
the same as we calculated earlier. </p>

<p><strong>Summary</strong></p>

<p>Marginal Cost is 
$$MC(y) = \frac{d C(y)}{d y}$$
Average variable cost is </p>

<p>$$A(y) = \frac{\int_{0}^{y} MC(y) dy}{y}$$ </p>

<p>Note, since we assumed $FC = 0$, this formula also thus defines AC but would not be true for $FC \neq 0$. </p>

<hr>

<p>AVERAGE COST VS AVERAGE VARIABLE COST</p>

<p>I have been sloppy about the distinction between AVC and AC up until now. I have avoided this distinction by assuming $FC = 0$. Now I will try to clarify this point by assuming $FC$ can be anything.</p>

<p><strong><em>Fixed costs</em></strong> ($FC$)are costs the firm pays that do not vary with the amount produced. For example, suppose I work for Uber and I buy a car. That money is spent and doesn't change with the amount I drive. But the amount of gasoline I consume does change as with the amount I drive. Costs that scale with production are known as <strong><em>variable costs</em></strong> ($VC(y)$). </p>

<p>$$AC(y) = \frac{C(y)}{y}=\frac{VC(y) +FC}{y}= \frac{VC(y)}{y} + \frac{FC}{y}=AVC + AFC $$</p>

<p><strong>Hyperbolic Behavior of AFC with y >0</strong></p>

<p>As production goes up ($y\rightarrow \infty$), AFC goes down ($AFC \rightarrow 0$) in an inversely proportional fashion. But note, as production goes down ($y\rightarrow 0$), AFC goes to infinity ($AFC \rightarrow \infty$). Thus, the plot of AFC will always be a hyperbola unless $FC = 0$ in which case AFC is just 0.</p>

<p><strong>How does AFC affect AC?</strong> </p>

<p>Without specifying $VC(y)$, we cannot know the behavior of $AC(y)$ as $y$ moves away from $0$. There will be some $y_{0}$ such that, for $y &gt; y_{0}$, $AC(y)$ can essentially be anything. Of course, as $y \rightarrow 0$, $AC(y) \rightarrow \infty$. This is because AVC cannot be negative and so we are guaranteed any variable costs will not lower the average cost below AFC. Therefore, $AVC \geq 0$, so since $AFC \rightarrow \infty$ as $y\rightarrow 0$ (remember it is a hyperbola), thus AC must go to infinity as well. </p>

<p>Thus, since the behavior of fixed costs are always known, AVC is the missing ingredient needed to specify the behavior of AC. </p>

<p><strong>AC and AVC can't be <em>exactly</em> equal for $FC&gt;0$</strong></p>

<p>Since $AFC \rightarrow 0$ but does not ever equal 0 (for $FC &gt;0$), we know that $$AC \neq AVC$$ for any $y$ and $FC &gt;0$. But since $AFC$ approaches 0 for large enough $y$, AC approaches AVC asymptotically. </p>

<p><strong>AC and AVC can't be <em>exactly</em> parallel for $FC&gt;0$</strong> </p>

<p>If $AVC$ and $AC$ are parallel, then their derivatives should be equal. But notice that $$\frac{dAFC}{dy} = -\frac{FC}{y^2}$$
so $$\frac{dAC}{dy} = \frac{dAVC}{dy} + \frac{dAFC}{dy} = \frac{dAVC}{dy} - \frac{FC}{y^2} \neq \frac{dAVC}{dy}$$
So they aren't parallel because their derivatives aren't equal. That said, <strong>for large enough $y$, the derivatives will be very close to each other so they may appear nearly parallel over some portion of the curves.</strong></p>

<p><strong>MC intersects AC at minimum point of AC curve</strong></p>

<p>See Alecos's answer. </p>

<p><strong>MC intersects AVC at minimum point of AVC curve</strong></p>

<p>Consider the average variable cost curve. Find $y^*$ that solves </p>

<p>$$\min_{y} AVC(y)$$ </p>

<p>So at this point, 
$$\frac{dAVC(y^*)}{dy^*} = 0$$</p>

<p>This means by quotient rule </p>

<p>$$\frac{VC'(y^*)y^*-VC(y^*)}{(y^*)^2} = 0$$
and since $y^*$ can't be 0, this implies $$VC'(y^*)y^*-VC(y^*)=0$$ which rearranged gives 
$$VC'(y^*)=\frac{VC(y^*)}{y^*}$$
Recall, 
$$C(y) = FC + VC(y)$$ 
Note, since $FC$ is a constant, 
$$C'(y) = VC'(y)$$ 
Therefore, </p>

<h2>$$C'(y^*) = \frac{VC(y^*)}{y^*}$$</h2>

<p>EXTRA STUFF</p>

<p><strong>Why do we define the firm's longrun shutdown point in terms of average cost not marginal cost?</strong></p>

<p>Recall a firm's profit function is $$\pi = py - C(y)$$</p>

<p>I am not defining the behavior of $p$ here or who controls $p$. I am just considering for what $p$ will the firm shut down, and ignoring everything else because it's irrelevant.</p>

<p>So we can easily see that since $$AC(y)= \frac{C(y)}{y}$$ for $p=AC(y)$, this yields $$\pi = \left(\frac{C(y)}{y}\right)y - C(y) = C(y)- C(y) = 0$$
So the firm will shut down if $p &lt;AC(y)$ because then $\pi &lt; 0$. </p>

<p>So consider the function $C(y) = y^3$. Note, $$MC = 3y^2 &gt; AC = y^2$$ We know the firm profit maximizes at $MR = MC$. So since, for $y &gt; 0$, $MC(y) &gt; AC(y)$, the firm would always produce if $p = MC$ since this would mean for $y&gt;0$, </p>

<p>$$ MC(y)y-C(y) = \pi_{p=MC}  &gt; \pi_{p=AC} = \left(\frac{C(y)}{y}\right)y - C(y) =0$$<br>
$$\pi_{p=MC} &gt; \pi_{p=AC} = 0$$
So, for this $C(y)$, at $p=MC$, $\pi &gt;0$ for all $y$. </p>

<p>So this example clearly shows you would never shut down at $p=MC$ for $y&gt;0$ for $C(y) = y^3$. Although this isn't the most thorough explanation, this example clearly invalidates that train of thought and makes clear firms shut down for $p&lt; AC$</p>

<p><strong>Does average cost necessarily equal marginal cost at some point?</strong> </p>

<p>See Alecos's answer. </p>

<p><strong>Takeaway Rules</strong></p>

<ol>
<li>In long run, firms produce if $p \geq AC(y)$. They shut down for $p &lt; AC(y)$</li>
<li>Firms always produce at $MR = MC$ </li>
</ol>
","9562"
"What are some real-world examples of the different types of trading blocs?","1087","","<p>The subsequent types of trading blocs have the following definitions:  </p>

<blockquote>
  <p><em>Free Trade Area</em> -- free trade among members</p>
  
  <p><em>Customs Union</em> -- free trade among members <strong>and</strong> common external tariff </p>
  
  <p><em>Common Market</em> -- free trade among members, common external tariff, <strong>and</strong> free movement of factors of production</p>
  
  <p><em>Economic Union</em> -- free trade among members, common external tariff, free movement of factors of production, <strong>and</strong> harmonization of all economic policies</p>
</blockquote>

<p>What are some real-world examples of these different types of trading blocs?</p>
","<p>There are actually five different types of trading blocs: preferential trading areas, free trade areas, customs unions, common markets and economic (and monetary) unions <a href=""http://en.wikipedia.org/wiki/Trade_bloc"" rel=""nofollow"">[1]</a>.  </p>

<p>A <strong>preferential trade area</strong> (PTA) is a trading bloc that reduces tariffs on particular goods between two countries but does not abolish them completely.  There are no particularly well-known examples, but a list can be found here <a href=""http://en.wikipedia.org/wiki/Preferential_trading_area"" rel=""nofollow"">[2]</a>.  </p>

<p>A <strong>free-trade area</strong> is the agreement among all member countries to eliminate tariffs, import quotas, and preferences on goods and services traded between each other (the free-trade as defined in the question) <a href=""http://en.wikipedia.org/wiki/Free_trade_area"" rel=""nofollow"">[3]</a>.  Probably the best known free-trade area is NAFTA; but others are listed <a href=""http://en.wikipedia.org/wiki/List_of_free_trade_agreements"" rel=""nofollow"">here</a> and <a href=""http://en.wikipedia.org/wiki/List_of_bilateral_free_trade_agreements"" rel=""nofollow"">here</a>.  </p>

<p>Again, there are no well-known <strong>customs unions</strong>, but a list can be found <a href=""http://en.wikipedia.org/wiki/Customs_union"" rel=""nofollow"">here</a>.  </p>

<p>A <strong>common market</strong> has free trade and free movement of the factors of production but other economic policies of the countries may be different (one of the differences between a common market and an economic union).  You may also want to look at <a href=""http://en.wikipedia.org/wiki/Single_market"" rel=""nofollow"">single market and unified market</a>.  There are no well-known common markets, but the previous link also contains a list.  </p>

<p>The best known <strong>economic union</strong> is the EU though more can be found <a href=""http://en.wikipedia.org/wiki/Economic_and_monetary_union"" rel=""nofollow"">here</a>.  An <strong>economic and monetary union</strong> has the same qualities of an economic union but each member nation also uses the same currency.  One example would be the nations in the EU who also utilize the Euro.  </p>
","1801"
"Is a universal basic income possible in the United States?","1085","","<p>Is a <a href=""https://en.wikipedia.org/wiki/Basic_income"">universal basic income or unconditional demogrant</a> possible in the United States? (For the sake of specificity I have focused the question on the US, though the question is certainly interesting in all settings.)
It seems that without some restructuring, the answer is no. But, in order to entertain the idea (and pushing politics aside), what programs could/would be cut in order to fund a reasonably sized basic income? What size of basic income could be afforded, if any? How would tax rates have to change?</p>

<p>Of course the answer depends on the size of the basic income. It would be interesting to see how the answer would change for multiple values.</p>
","<p>This is a good question. To be concrete, I think it's easier to pick a single number - this is arbitrary, but I'll go with the figure of $10,000 offered in the <a href=""http://www.aei.org/wp-content/uploads/2014/03/-in-our-hands_105549266790.pdf"">proposal by Charles Murray</a> (one of the most prominent conservative supporters of a universal basic income). I'll assume that this is offered to every adult in the US age 18 and over, expanding slightly on Murray's 21 and over proposal.</p>

<p>This would be about 85% of the average <a href=""https://www.census.gov/hhes/www/poverty/data/threshld/"">poverty level</a> for a single individual, just above 50% of the poverty level for a single parent with two children, and (at $20,000) about 85% of the poverty level for a family of four with two parents and two children.</p>

<p>The direct budgetary cost of this program, of course, is easy to calculate: it is the number of Americans age 18 and over, times \$10,000. There are about 245 million <a href=""http://www.census.gov/popest/data/"">American adults</a> currently, making this cost \$2.45 trillion. This compares to total federal government expenditures that are currently about \$4 trillion. (See <a href=""http://bea.gov/iTable/iTableHtml.cfm?reqid=9&amp;step=3&amp;isuri=1&amp;903=87"">this NIPA table</a> for some figures.) Remarkably, the sum of ""government social benefits"" and ""grants-in-aid to state and local governments"" (the latter of which is almost entirely grants for social programs like Medicaid) is currently about \$2.4 trillion. Hence, to a first approximation, we could say that the federal government could afford the $10,000 UBI given its current budget if it <em>eliminated all other existing transfers</em>.</p>

<p>How plausible is this? Not very. More than 75% of the federal government's <a href=""http://bea.gov/iTable/iTableHtml.cfm?reqid=9&amp;step=3&amp;isuri=1&amp;903=110"">transfer</a> spending is on three programs: Social Security, Medicare, and Medicaid. This spending is overwhelmingly concentrated on the elderly, with some also on the disabled (SSDI and Medicaid) and children (Medicaid). Taking away these programs and replacing them with the basic income, which is distributed evenly throughout the adult population, would surely leave these groups receiving far less in total than they currently do. This would be politically near-impossible to push through, and any sudden change would be dubious on policy and moral grounds too. (Even if one doesn't like the distribution of transfer spending embedded in these programs, millions of people have planned their lives around it.)</p>

<p>This is just one case of a basic point - which is that unless one plans to achieve massive savings through improved administrative efficiency or improved work incentives, any reallocation of the existing transfer pie will involve offsetting winners and losers. Since existing transfer recipients (aged, disabled, poor children, etc.) are targeted for a reason, such a shift may be quite painful. Moreover, any improvements in administrative efficiency are unlikely to be large enough to save much money; the more likely source of savings would be improved incentives, particularly relative to the <a href=""http://economics.mit.edu/files/6344"">dysfunctional disability system</a> and perhaps current overspending on health care. But I haven't seen a case made that these would be anywhere near large enough to make a UBI work within the current budget without large losses to some existing party.</p>

<p>On a more positive note, I should mention that the headline cost of the UBI may not be quite as bad as it looks. Since the current tax-and-transfer system embeds <a href=""http://www.cbo.gov/sites/default/files/cbofiles/attachments/11-15-2012-MarginalTaxRates.pdf"">very large implicit marginal taxes</a> on some beneficiaries, it would be possible to replace these with higher explicit marginal taxes to claw some of grant back, without incurring additional distortions at the margin. That said, these high marginal taxes are heavily concentrated in certain segments of the population (e.g. single parents with children). The US tax-and-transfer system currently makes heavy use of <a href=""http://people.virginia.edu/~slf9s/teaching/econ452/readings/Akerlof%201978.pdf"">tagging</a>, which saves money at the expense of potentially perverse social incentives (conservatives have complained about incentives for low-income parents to avoid marriage for years). Doing away with tagging could limit these particular bad incentives and concentrated high marginal rates, but necessitate moderately higher marginal rates throughout the population.</p>

<p>Finally, if it is not realistic to eliminate existing transfers, we can think about how difficult it would be to establish a UBI through increased taxation. If (given the substantial existing transfers to the elderly) we limited the \$10,000 to adults below age 65, we are down to a population of about 200 million and cost of \$2 trillion. Since personal consumption expenditures are currently about \$12 trillion, (unrealistically) assuming a constant tax base these \$2 trillion could be raised through a 24% VAT with 70% coverage. This would be quite high, but not totally out of line with <a href=""http://en.wikipedia.org/wiki/Value-added_tax"">international norms</a>. Furthermore, since current GDP is about \$17.5 trillion, and additional \$2 trillion in transfer spending (again unrealistically assuming constant GDP) would increase the US's overall tax intake as a share of GDP by 11.5 percentage points. This would make the US <a href=""http://en.wikipedia.org/wiki/List_of_countries_by_tax_revenue_as_percentage_of_GDP"">similar to the typical European country</a>, still below states like Denmark, Sweden, and France with the highest taxation.</p>
","1898"
"Oaxaca decomposition - Interpretation Interaction","1084","","<p>I am running a Oaxaca decomposition on trends in paid work (similar to <a href=""http://sf.oxfordjournals.org/content/79/1/191.short"" rel=""nofollow"">this paper</a>) 
The estimates are expressed in minutes.</p>

<p>The total change shows an increase in about 30 minutes between Period 0 and Period 1. 
I have some difficulties to understand what the <code>Interaction</code> means here. So the <code>Endowments</code> represent the <em>observed</em> characteristics of my model and the <code>Coefficients</code> the <em>unobserved</em>. </p>

<p>What about the <code>Interaction</code>? How should interpret the fact that it is <strong>negative</strong> ?  </p>

<pre><code>                     Decomposition
Period 0                   174.66
Period 1                   204.15
Total Change               29.5
.                                
Endowments                  22.78
Coefficients                50.38
Interaction                -43.66
</code></pre>
","<p>In principle the idea is that there are three sources of the 29.5 change:</p>

<p>Lets assume we are taking period 1 as the 'baseline'. The first source of the 29.5 change is that the independent variables changed. To see the importance of this effect, you estimate education's effect on time for period 1. Then you apply the estimated model to the period 2 education and you get a predicted increase in time because the period 2 were more educated on average and the model predicts that higher education leads to more time. Suppose that estimate amounts to 22.78 minutes in this case.</p>

<p>The second source of difference is found by estimating the model with period 2 data. Then you look at the different coefficients on education from the period 1 and period 2 models and apply the difference to the period 1 data. In other words, you see how much the function changed, as measured for the period 1 education levels. Suppose that in the second period, the effect of education seems to be larger. This difference in the coefficients explains 50.38 minutes of the difference between 1 and 2.</p>

<p>Finally to interpret the interaction term, you have to imagine that you apply the difference in the models to the difference in the data. While the period 1 education using the period 2 model implies a high time and the period 1 model applied to period 2 education also implies a high time, it turns out that the period 2 model applied to the period 2 education yields a small time. This idea that when you interact the period 2 data with the period 2 model you get a different result than if you had just summed up the education change by the period 1 model and the model change by the period 1 data is what is at stake. In this case it turns out that the combination in yields a lower value than what is predicted by the sum of the differences. The interaction term is then difference between what you expected from the two individual differences and the result. In this case its a negative number, -43.66.</p>

<p>Another way to see this is to imagine we are decomposing the difference between f(x1,x2) and f(x2,y2). As you go from x1,y1 to x2,y2, you will advance over the x axis. You expect the function to change Dx=(x2-x1)*df/dx(x1,y1).AS you go from x1,1 to x1,y2 you will advance over the y axis. You expect the function to change Dy=(y2-y1) *df/dy(x1,x2). Lastly you compare your results and realize that there's an error, xi, so that f(x2,y2)=f(x1,y1)+ Dx+Dy +xi. Dx here corresponds to the endowments effect, Dy to the coefficients effect, and xi to the interaction effect.</p>
","11637"
"How does the Uber's pricing model work?","1074","","<p>I'm working on a paper on the sharing economy, and in particular on its economic implications.</p>

<p>I am aware of the surge pricing model that Uber adopts, and of how it works. But I'm wondering on what criteria and how Uber estimates the base fares of each city.</p>

<p>I would like, ultimately, to understand whether and why this artificial pricing model is better than the ""natural"" pricing models of other peer-to-peer services (e.g. AirBnB), that allow the users to set their own rates.</p>
","<p>It is important to distinguish between optimal pricing from Uber's perspective and optimal pricing from an efficiency standpoint. If Uber was the only company matching drivers and customers, it would adopt a monopoly pricing strategy on selling rides to consumers and buying rides from drivers. These rates may be very far from the efficient rates. It is therefore important to state what you mean by a ""better"" pricing model.</p>

<p>From the perspective of Uber/Airbnb, profit maximizing pricing strategies may differ because of many reasons. AirBnB is in a business where the quality of a service can vary greatly and is often unobserved to them. Uber in contrast matches customers with services that have little to no variation in quality (speed, safety), which are fairly well observable due to their GPS data. But even depending on expected company growth may lead the two companies to have optimal pricing strategies closer or further from efficient prices. Finally, the competition in each city may be very different for Uber, since cab rates are fixed by a central planner. The competition of AirBnB usually has decentralized pricing except where a hotel chain has a local monopoly.</p>

<p>Even from an efficiency standpoint, there may be large advantages from a centralized pricing strategy in the market for rides. Most urban areas have fixed cab ride rates to increase transparency. Anybody can get into a cab without worrying about being charged an unexpectedly high amount. This can greatly enhance market outcomes.</p>
","8469"
"Nash Equilibrium and Dominant Strategy","1072","","<p>If I have a game that goes as follow:</p>

<p><a href=""https://i.stack.imgur.com/t1e3D.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/t1e3D.png"" alt=""enter image description here""></a></p>

<p>Player 1 is the row player and player 2 is the column player. I think that the Nash Equilibria should be (10, 5) and (5, 10), since neither of the player has incentive to unilaterally deviate given the other's strategy. But then the dominant strategy, I thought, for both player is to always invest. Does this mean that the stable outcome is actually (5, 5) and that it is inconsistent with the NEs, which should be stable? (I only work with pure strategy here)</p>
","<p>You're on the right track here. You need to check every outcome for its potential to be a NE. You're correct in stating that outcomes (5,10) and (10,5) are NEs however you didn't identify that (5,5) is also an NE.</p>

<p>(5,5)
If player one deviates he receives a payout of 5. 
If player two deviates he receives a payout of 5.</p>

<p>Therefore no player has an incentive to unilaterally deviate and (5,5) is a Nash equilibrium.</p>

<p>You're also correct that (5,5) is the dominant strategy solution. Just keep in mind that the dominant strategy solution will always be a Nash equilibrium but not all Nash equilibria are dominant strategy solutions.</p>
","14309"
"Nominal GDP versus PPP in comparing military spending of different countries?","1072","","<p>Military spending as percentage of GDP is the most used measure of the economic capability of a certain country/military. But Some countries like India for example, have a huge difference between their nominal and PPP GDP (2 billion vs 7.7 billion). So which number is more meaningful to express the economic capability of a certain military ?</p>
","<p>One argument for using the exchange rate:</p>

<blockquote>
  <p>Market exchange rates are determined by the supply and demand of
  currencies used in international transactions. However, the prices of
  many goods and services on domestic markets are determined in partial
  or complete isolation from the rest of the world. Therefore, the MERs
  do not always accurately reflect differences in price levels between
  countries.</p>
  
  <p>An alternative is to use purchasing power parity (PPP) conversion
  factors (or PPP exchange rates). The PPP dollar rate of a country's
  currency is defined by the World Bank as 'the number of units of a
  country's currency required to buy the same amount of goods and
  services in the domestic market as a U.S. dollar would buy in the
  United States'. >1  The only PPP rates available for all countries are
  GDP- based basket of goods and services that are major components of
  the gross domestic product. Such GDP-based PPP rates are designed to
  control for differences in price levels and thus to provide a measure
  of the real purchasing power of the GDP of each country.</p>
  
  <p>Using GDP-based PPP rates instead of MERs for currency conversion
  results in much higher output and expenditure figures for many
  developing and transition countries since they have relatively low
  prices for non-traded goods and services—thus giving the currency
  higher purchasing power. A unit of local currency therefore has
  greater purchasing power within a developing country (which is better
  reflected by using PPP rates) than it has internationally (which is
  what is reflected by using MERs). For those such developing and
  transition countries for whom data was available for 2008, the median
  increase in military expenditure figures from using PPP rates instead
  of MERs was around a factor of 2. Three-quarters of these countries
  would see their relative figures increase by at least two-thirds.
  Meanwhile, using PPP rates would cause the GDP and military
  expenditure figures of most 'developed' countries to fall relative to
  the USA, by a median rate of 17 per cent—reflecting the low value of
  the US dollar at market exchange rates in 2008. <strong>However, the
  reliability of such PPP rates is lower than for MERs, since PPP rates
  are statistical estimates, calculated on the basis of collected price
  data for a basket of goods and services for benchmark years.</strong> Between
  benchmark years, the PPP rates are extrapolated forward using ratios
  of prices indexes, either GDP deflators or consumer price indexes.
  Like all statistical estimates they are subject to a margin of error.</p>
  
  <p><strong>Furthermore, GDP-based PPP rates are of limited relevance for the
  conversion of military expenditure data into US dollars. Such PPP
  rates are designed to reflect the purchasing power for goods and
  services that are representative of spending patterns in each country,
  that is, primarily for civilian goods and services. Military
  expenditure is used to purchase a number of goods and services which
  are not typical of national consumption patterns.</strong> For example, the
  price of conscripts can be assumed to be lower than the price of a
  typical basket of goods and services, while the prices of advanced
  weapon systems and of their maintenance and repair services can be
  assumed to be much higher. The extent to which this data reflects the
  amount of military goods and services that the military budget can buy
  is not known. Due to these uncertainties, SIPRI uses market exchange
  rates to convert military expenditure data into US dollars, despite
  their limitations.</p>
</blockquote>

<p><a href=""http://www.sipri.org/research/armaments/milex/measuring-military-expenditures"" rel=""nofollow"">Stockholm International Peace Research Institute: Monitoring Military Expenditures</a>  </p>

<p>But wages are a big part of military costs and those are not paid with PPP GDP but rather domestic GDP. <a href=""http://MEASURING%20HARD%20POWER:%20CHINA%E2%80%99S%20ECONOMICGROWTH%20AND%20MILITARY%20CAPACITY%20economics.stackexchange.com/questions/3359/nominal-gdp-versus-ppp-in-comparing-military-spending-of-different-countries"" rel=""nofollow"">MEASURING HARD POWER: CHINA’S ECONOMIC GROWTH AND MILITARY CAPACITY</a> says that both methods have merits but at least in China, both methods understate military capacity. </p>

<blockquote>
  <p><strong>The most appropriate way to compare real military capacity across
  countries is to deflate each country’s actual, or potential, military
  spending by the price of real military services in each country.
  Unfortunately military price indices do not exist for most countries.</strong>
  The aim of this paper, therefore, is to develop a simple method for
  computing a relative military price index, that deflates nominal
  spending into units of real military services, using readily
  accessible data. The ratio of two countries’ military price indices
  then gives an exchange rate that provides an index of relative real
  military capacity across countries. <strong>We use this military exchange rate
  to compare the level and growth of China’s real military capacity
  relative to the USA</strong>. 4 We obtain two key results. First we find that
  <strong>the value of the RMB, in terms of its ability to purchase real
  military services, is greater than both its market exchange rate value
  and its PPP value.</strong> This suggests that conventional estimates of GDP
  understate China’s real military capacity, but also that PPP exchange
  rate comparisons are much closer to the actual value than market
  exchange rate comparisons. This is mainly because of the very low cost
  of labor in China relative to the USA. 
  ... </p>
  
  <p>If we wish to infer
  country’s miliary capacity based on the size of its economy, however,
  standard PPP indices also pose a problem insofar as they reflect the
  relative price of an average basket of goods produced in the economy
  and this average price index may differ substantially from the price
  of military services. Thus C<strong>rane et al (2005) argue that, while
  military services have large personnel costs, a substantial share of
  military equipment purchased by developing-country militaries is
  imported or incorporates com- ponents that are manufactured from
  materials and parts sold at world market prices, such as electronics,
  diesel engines, or aircraft frames. Thus they suggest that, for some
  purposes, GDP measured at market exchange rates may give a more
  realistic picture of changes in military capacity</strong> (Crane et al 2005,
  pp.16-17). Similarly, the two principle military statistical
  abstracts, The Military Balance published by The International
  Institute for Strategic Studies (IISS), and the Stockholm Interna-
  tional Peace Research Institute’s (SIPRI) Yearbook report relative
  military spending and relative GDP in terms of $US converted at market
  exchange rates and also at PPP ex- change rates. IISS (2012) notes
  that market exchange rates are likely to understate the true level of
  economic resources allocated towards defence since food material and
  hous- ing costs will be lower in China, but remain noncommittal in
  recommending a preferred price index. 8 Thus they often report a
  weighted average of PPP and market exchange rates when discussing
  China’s real military capacity relative to the USA.</p>
</blockquote>
","3360"
"Local Non-Satiation Proof","1069","","<p>I have been having trouble with how to go forward with a proof for about three days now. I know the basic structure of the proof, but can't seem to construct it.</p>

<p>Basically, I am trying to do a proof by contradiction for the following:</p>

<p>Say $u: x \rightarrow \mathbb{R}$ has no local maxima. Let $p \in \mathbb{R^l}_{++}$ and $w&gt;0$. Show that if $x^*$ is a solution to the maximization problem:</p>

<p>$$\max_x \ (u(x)) \ \text{s.t.} \ x \in B(p) = [x \in \mathbb{R^l}_{++} : p \cdot x \leq w]$$
then for all $y \in \mathbb{R^l_{++}}$ such that $u(y) \geq u(x^*)$, then it must be that $p \cdot y \geq w$</p>

<p>So I'm supposed to do this proof by contradiction, (suppose we have $y \in \mathbb{R^l_{++}}$ such that $u(y) \geq u(x^*)$, then it must be that $p \cdot y &lt; w$) and use the fact that $u$ doesn't have a local max implies that the function $u$ is locally non-satiated:</p>

<p>$$\forall y \in \mathbb{R^l_{+}, \forall \epsilon &gt; 0, \exists {y'} \in \mathbb{R^l_{+}}} \ \text{s.t.} \ \|y - y'\| &lt; \epsilon \ \text{and} \ y' \succ  y$$</p>

<p>But I've been stuck for a while now. Any help would be appreciated.</p>
","<p>Assume for a contradiction that there exists $y$ such that $p\cdot y&lt;w$ and $u(y)\geq u(x^\ast)$. Let 
$$\epsilon^\ast= \frac{w-p\cdot y}{ \sum_i p_i}.$$ Then, for all $y'$, if $\ \|y - y'\| &lt; \epsilon^\ast$, we would have $\left|y_i-y_i'\right|&lt;\epsilon^\ast$. Notice that the cost of any bundle $y'$ would satisfy
$$
\begin{eqnarray}
p\cdot y' &amp;=&amp; p_1 y'_1 + p_2 y'_2 + \dots +p_n y'_n\\
&amp;&lt;&amp;p_1 (y_1+\epsilon^\ast) + p_2 (y_2+\epsilon^\ast) + \dots +p_n (y_n+\epsilon^\ast)\\
&amp;=&amp; p\cdot y+\epsilon^\ast\sum_i p_i \\
&amp;=&amp;p\cdot y + \frac{w-p\cdot y}{ \sum_i p_i} \sum_i p_i\\
&amp;=&amp; w
\end{eqnarray}
$$
which shows that for $\epsilon^\ast$, every $y'$ satisfying $\ \|y - y'\| &lt; \epsilon^\ast$ is affordable. </p>

<p>However, since $u$ is locally non satiated, there exists $y^\ast$ with $\ \|y - y^\ast\| &lt; \epsilon^\ast$ such that $y^\ast\succ y$. Since $y^\ast$ is affordable, i.e. $y^\ast\in B(p)$ this leads to a contradiction with the assumption that $x^\ast$ solves the utility maximization problem because transitivity implies that $y^\ast\succ x^\ast.$</p>
","8450"
"How interest rates affect investment","1063","","<p>We know that a rise in real interest rates will cool down the economy in terms of investments. An increase in interest rate will provide higher incentive for saving rather than consumption. So people will start to save in banks and banks would be having a high stock of these savings. Now, effectively this stock should compel banks to lend more to the people needing it and hence it should drive down interest rates and raise investment levels. How is this fallacy arising ? Please explain</p>
","<p>You are getting confused because you are ""reasoning from a price change."" Interest rate changes don't just happen by themselves, so they cannot be the cause of other effects in the economy. </p>

<p>What actually happens is:</p>

<ol>
<li><p>The central bank drains money from the economy.</p></li>
<li><p>The interest rate has to rise, otherwise people would try to borrow more money than there is available.</p></li>
</ol>

<p>The fact that other people can step in and become lenders may mean that the real interest rate wouldn't rise very much. But the central bank can take this into account. It can just drain extra money from the system to achieve its interest rate target.</p>
","8684"
"Convexity of the Market Demand Function","1062","","<p>The market demand function can be either concave or convex. I am looking for conditions under which a general market demand function can be considered convex.
For example would convex preferences or a concave utility function imply a convex market demand curve? </p>

<p>I am not asking about the demand set, but rather the function.</p>

<p>I have a hard time imagining a concave market demand function, but the literature often takes this possibility into account, leading me to believe that it cannot be ruled out without imposing further conditions.</p>

<p>The reason I'm having a hard time imagining concave functions is that when we maximize with a standard utility function, what will come out with typical functions is somthing like:</p>

<ol>
<li><p>Cobb-Douglas: $X=(\alpha/(α+β)) M/2p$</p></li>
<li><p>Perfect compliments (min): $X=αm/(βp1 + αp2)$</p></li>
<li><p>Perfect Substitutes: $X=M/p$; where X is demand for some good, M is the budget, p the price(of good 1 or 2) and α and β are just utility parameters.</p></li>
</ol>

<p>which are all convex. </p>

<p>Further, since market demand is most often defined as the sum of individual demands (which above appear to be convex mostly) and the sum of convex functions is itself a convex function, then market demand should most often be a convex function it seems.</p>

<p>Can a more general statement be made here about when the market demand curve is convex?</p>
","<p>From a mathematical point of view, a function of the form</p>

<p>$$Q_d = \left( \frac {A-p}{B}\right)^{1/\gamma},\;\; \gamma &gt;1$$</p>

<p>will have a negative second derivative and so it will be strictly concave. The function hits the (vertical) $p$-axis for $(Q_d=0,p=A)$, and the horizontal $Q$-axis for $(Q_d = (A/B)^{\gamma}, p=0$). Namely this is ""concave all the way"", not just concave in the middle which eventually becomes convex. Typically, we expect  $A&gt;B$.</p>

<p>Inverting, we obtain</p>

<p>$$p=A-BQ_d^{\gamma}$$</p>

<p>Let's now go down to the individual level, and assume quasi-linear preferences in income, an appropriate formulation when we look at one good ""against all others"":</p>

<p>$$v(q,y) = u(q) + y,\;\;\; s.t. \;\;pq+y = M$$</p>

<p>The first-order conditions will give  </p>

<p>$$u'(q) = \lambda p,\;\;\;\ \lambda =1$$</p>

<p>Combining with the inverse demand function we get</p>

<p>$$u'(q) = A-BQ_d^{\gamma}$$</p>

<p>where $Q_d = \sum q$.</p>

<p>Integrating we have</p>

<p>$$\int u'(q) dq = A\int dq - B\int \left (\sum q\right)^{\gamma}dq$$</p>

<p>from which we arrive at (setting the arbitrary constants of integration to zero)</p>

<p>$$u(q) = Aq-\frac{B}{1+\gamma}Q_d^{1+\gamma}$$</p>

<p>We obtained this result by assuming that the  individual believes that its own demand does not affect any other individual demand. So we have a <em>negative externality</em>: the more ""massive"" is a good (the more massively demanded), the less utility we obtain from it (so any individual demand does not affect any other individual demand, but their sum, does affect the individual elements). So such a specification would be appropriate for goods that are not characterized by the ""safety of the flock"" aspect, but appeal to our quest for individualism and personal uniqueness.</p>

<p>Assume now that we do not want to have this negative externality in the individual utility. Then, we assume that all consumers are identical, and we <em>start</em> with the utility specification,</p>

<p>$$u(q) =  aq-\frac{b}{1+\gamma}q^{1+\gamma}$$</p>

<p>This utility specification does imply that there exists a maximum utility level from the good and then utility declines, so it belongs to the general family of ""quadratic"" preferences.</p>

<p>Indicatively, for $a=100, b=10, \gamma=1.3$ we have</p>

<p><a href=""https://i.stack.imgur.com/HCmIA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HCmIA.png"" alt=""enter image description here""></a></p>

<p>The indifference map is constructed by calculating</p>

<p>$$y = \bar v - \left[aq-\frac{b}{1+\gamma}q^{1+\gamma}\right]$$</p>

<p>for arbitrary values for $\bar v$ (which, in quasi-linear preferences, correspond to the income constraint).For $\bar v = M=400,450,500,550,600$ the map looks like</p>

<p><a href=""https://i.stack.imgur.com/QIBGF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QIBGF.png"" alt=""enter image description here""></a></p>

<p>Such an individual utility specification will give the optimal relation</p>

<p>$$a - bq^{\gamma} = p$$</p>

<p>and the individual demand</p>

<p>$$q = \left( \frac {a-p}{b}\right)^{1/\gamma}$$</p>

<p>Summing over all $N$ consumers we get</p>

<p>$$Q_d = N\left( \frac {a-p}{b}\right)^{1/\gamma}$$</p>

<p>and we want to arrive at the market demand function</p>

<p>$$Q_d = \left( \frac {A-p}{B}\right)^{1/\gamma}$$</p>

<p>This can happen if we identify $A=a$ and $B = b/N^{\gamma}$.</p>
","10781"
"Indifference curves and preferences?","1059","","<p>I am going through some micro concepts and I am confused, is there a difference between deriving preferences through indifference curves and actual preferences of the consumers? </p>

<p>The question I was going through was: </p>

<p>Jim's utility function is $U(x; y) = xy$. Jerry's utility function is $U(x; y) = 1,000xy + 2, 000.$ Tammy's utility function is $U(x; y) = xy(1-􀀀xy)$. Oral's utility function is 􀀀$-1/(10+xy)$. Billy's utility function is $U(x; y) = x/y$. Pat's utility function is $U(x; y) = -􀀀xy$.</p>

<p>(a) No two of these people have the same preferences.</p>

<p>(b) They all have the same preferences except for Billy.</p>

<p>(c) Jim, Jerry, and Pat all have the same indifference curves, but Jerry and Oral are the only ones with the same preferences as Jim.</p>

<p>(d) Jim, Tammy, and Oral all have the same preferences.</p>

<p>(e) There is no truth in any of the above statements.</p>

<p>The answer apparently is C, which implies that even though Jim, Jerry and Pat have the same indifference curves, The preferences of Pat and Jim are different, while those of Oral and Jim are the same even though they have different indifference curves. How is that possible? </p>
","<p>A nerd loves both mathematics and physics equally, and hates sports and drinking beer equally.</p>

<p>A football player hates both mathematics and physics equally, and loves sports and drinking beer equally.</p>

<p>The nerd and the football player have the same indifference curves, but not the same preferences.</p>

<p>The point is this: Both agree on the ""grouping"" of things. But they disagree in the ranking of the groups.</p>

<h3>Your Example</h3>

<p>If you look at Jim and Pat, they have exactly inverse utility functions and hence inverse ranking in their preferences.</p>

<p>That is, if for Jim $A &gt; B = C = D &gt; E$, Pat will have $A &lt; B = C = D &lt; E$. Both agree on the three groups, but disagree on the order. Jerry's just a monotone transformation (poor Jerry).</p>
","5239"
"From an economics perspective, what are the ramifications of a currency with fixed money supply?","1057","","<p>I'm thinking specifically of bitcoins.</p>

<p>What are the pros and cons of having a fixed number of coins, as opposed to more ""normal"" currencies?  Would the currency have no inflation?</p>
","<p>FooBar is quite right that unless you expect GDP growth to stop, fixed nominal supply currencies will lead to deflation.</p>

<p>A moderate degree of currency inflation serves a number of useful functions in the economy. The most obvious are:</p>

<ul>
<li>It induces people to spend their money before it loses its value. In
a deflationary environment there is an incentive to put money under
your mattress and spend it in a year when it has greater purchasing
power. If everbody does this then the lack of demand will lead to a
decrease in overall economic activity (i.e. a recession).</li>
<li>It provides a weapon against downward nominal rigidities. For example, workers are generally reluctant to accept a nominal pay cut, even if market conditions are such that the current wage is above the equilibrium level. Inflation means that their employer can simply increase wages at less than the inflation rate so that the real wage is decreasing.</li>
<li>It erodes the real value of nominally denominated debt. Now, this is obviously only a pseudo-advantage because (whilst it benefits debtors) it harms creditors. However, this kind of erosion of debt may be desirable if national economic stability is threatened by high debt levels. Also, since debtors are usually poorer on average than creditors, it can reduce inequality, which may be a normative objective for the government.</li>
</ul>

<p>Without inflation you miss out on these benefits. The first benefit might not seem like a big deal if you think you can simply set the rate of inflation at zero percent. But it is very hard to hold inflation constant at some target level so attempting to hit zero inflation will almost certainly result in occasional lapses into deflation, with the attendant negative economic consequences.</p>
","168"
"Explaining mixed strategies for one-shot games","1047","","<p>In the classic introduction to non-cooperative game theory, the mixed strategy for a player is taught as a distribution over strategy space for the player. The distribution essentially gives us the probabilities (say, discrete strategy set) with which a player should play the strategies in a Nash equilibrium. </p>

<p>However probabilities carry the notion of being frequencies and these essentially mean the long-run fraction of games in which the player should play the strategy. However the setting is a one-shot game and this is a contradiction.</p>

<p>How do we resolve the contradiction when explaining what a mixed strategy is?  </p>
","<p>Ariel Rubinstein tends to be insightful regarding these kinds of questions. </p>

<p>He addresses the interpretation of mixed strategies in section 3 of <a href=""http://www.jstor.org/stable/2938166"">this</a> paper. </p>

<p>A few possible interpretations aside from deliberate randomization:</p>

<ol>
<li>Purification: A mixed strategy is a plan of action based on information not specified in the model.</li>
<li>A fictitious long run story.</li>
<li>Population averages, so imagine the player's being pulled from some population distribution where different types play different pure strategies. The  population distribution is the mixed strategy distribution.</li>
</ol>

<p>An interesting quote regarding player $i$'s mixed strategy reflecting uncertainty among $-i$'s regarding what $i$ will do:</p>

<blockquote>
  <p>Mixed strategy can alternatively be viewed as the belief held by all other 
  players concerning a player's actions. A mixed strategy equilibrium is then an 
  n-tuple of common knowledge expectations, which has the property that all the 
  actions to which a strictly positive probability is assigned are optimal, given the 
  beliefs. A player's behavior may be perceived by all the other players as 
  the outcome of a random device even though this is not the case. Adopting this 
  interpretation requires the reassessment of much of applied game theory. In 
  particular, it implies that an equilibrium does not lead to a prediction (statistical 
  or otherwise) of the players' behavior. Any player i's action which is a best 
  response given his expectation about the other players' behavior (the other 
  n - 1 strategies) is consistent as a prediction for i's action (this might include 
  actions which are outside the support of the mixed strategy). This renders 
  meaningless any comparative statics or welfare analysis of the mixed strategy 
  equilibrium and brings into question the enormous economic literature which 
  utilizes mixed strategy equilibrium. </p>
</blockquote>
","239"
"Intuition behind risk premium","1046","","<p>In <a href=""http://ocw.mit.edu/courses/economics/14-01sc-principles-of-microeconomics-fall-2011/unit-6-topics-in-intermediate-microeconomics/uncertainty/"" rel=""nofollow noreferrer"">Lecture 20</a> of MIT's Microeconomics course, a situation is proposed where a 50/50 bet will either result in losing \$100 or gaining \$125 with a starting wealth of \$100. It is stated that a person would be willing to insure themselves for \$43.75 (the difference between \$100 and \$56.25). What is the intuition behind this?</p>

<p>Thanks in advance!</p>

<p><img src=""https://i.stack.imgur.com/IxebN.jpg"" alt=""From MIT""></p>
","<p>The name for the amount $56.25 is <strong>certainty equivalent</strong>.</p>

<p>The expected utility for the individual from taking the bet is calculated as follows:
$$E[U]=\frac12U(100+125)+\frac12U(100-100)=75$$
Suppose the individual can pay an amount of money $x$ so that she can avoid taking the bet (which leads to expected utility $75$). What's the maximum amount of money $x$ she's willing to pay? Well, she would pay up to a point where she's indifferent between taking and not taking the bet.</p>

<p>If she takes the bet, expected utility is $75$. If she pays, her utility is $U(100-x)$. We want her to be indifferent, so that $U(100-x)=75$. Reading off from the blue curve in your graph (the curve describing $U$), we see that 
$$U(56.25)=75$$
which means $100-x=56.25$, or $x=43.75$. </p>

<p>So we can interpret 43.75 as the maximum amount of money that an individual is willing to pay in order to avoid the (risky) bet. </p>
","3121"
"Did previous researchers fail to detect the hot hand simply because of a statistical fallacy?","1044","","<p>Many basketball fans/players believe that having made several shots in a row,  the next shot is more likely to go in. This is sometimes called the hot hand.</p>

<p>Starting (I think) with <a href=""http://wexler.free.fr/library/files/gilovich%20(1985)%20the%20hot%20hand%20in%20basketball.%20on%20the%20misperception%20of%20random%20sequences.pdf"" rel=""nofollow"">Gilovich, Mallone, and Tversky (1985)</a>, it was ""shown""  that this was in fact a fallacy. Even if several shots in a row have gone in, the next shot is no more likely to go in than your average shooting percentage would dictate. </p>

<p><a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2627354"" rel=""nofollow"">Miller and Sanjurjo (2015)</a> argue that the hot hand does in fact exist and previous researchers had simply fallen prey to a fairly basic statistical fallacy. Their argument is something like this:</p>

<p>Flip a coin four times. Compute the probability that H follows H. To give a few examples: HHTT would have probability 1/2, HTHT would have probability 0/2, TTHH would have probability <s>0/1</s> 1/1, and both TTTT and TTTH would be N.A.</p>

<p>Miller and Sanjurjo's punchline is that the expected value of this probability is not 0.5, but ≈0.4. And the error made by previous researchers was to incorrectly assume that the expected value of this probability is 0.5. So if for example these previous researchers conducted the above coin-flipping experiment and found the average probability to be say 0.497, they incorrectly concluded that there was no evidence of a hot hand (not significantly different from 0.5), when in fact there was very strong evidence of a hot hand (significantly different from 0.4).</p>

<p>My question is this: <strong>Are Miller and Sanjurjo correct that previous researchers failed to detect the hot hand simply because of this mistake?</strong> I have only skimmed one or two papers on this so I wanted to get some confirmation from someone here who might know this literature better. This seems like a surprisingly silly error to have persisted for three decades or more.  </p>
","<p>(This answer was completely rewritten for greater clarity and readability in July 2017.)</p>

<p>Flip a coin 100 times in a row. </p>

<p>Examine the flip immediately after a streak of three tails. Let $\hat{p}(H|3T)$ be the proportion of coin flips after each streak of three tails in a row that are heads. Similarly, let $\hat{p}(H|3H)$ be the proportion of coin flips after each streak of three heads in a row that are heads. (<em>Example at bottom of this answer.</em>)</p>

<p>Let $x:=\hat{p}(H|3H)-\hat{p}(H|3T)$.</p>

<p>If the coin-flips are i.i.d., then ""obviously"", across many sequences of 100 coin-flips,</p>

<p>(1) $x&gt;0$ is expected to happen as often as $x&lt;0$.</p>

<p>(2) $E(X)=0$.</p>

<p>We generate a million sequences of 100 coin-flips and get the following two results:</p>

<p>(I) $x&gt;0$ happens roughly as often as as $x&lt;0$.</p>

<p>(II) $\bar{x} \approx 0$ ($\bar{x}$ is the average of $x$ across the million sequences).</p>

<p>And so we conclude that the coin-flips are indeed i.i.d. and there is no evidence of a hot hand. This is what GVT (1985) did (but with basketball shots in place of coin-flips). And this is how they concluded that the hot hand does not exist.</p>

<hr>

<p><strong>Punchline: Shockingly, (1) and (2) are incorrect.</strong> If the coin-flips are i.i.d., then it should instead be that</p>

<p>(1-corrected) $x&gt;0$ occurs only about 37% of the time, while $x&lt;0$ occurs about 60% of the time. (In the remaining 3% of the time, either $x=0$ or $x$ is undefined — either because there was no streak of 3H or no streak of 3T in the 100 flips.)</p>

<p>(2-corrected) $E(X) \approx -0.08$.</p>

<p>The intuition (or counter-intuition) involved is similar to that in several other famous probability puzzles: the Monty Hall problem, the two-boys problem, and the principle of restricted choice (in the card game bridge). This answer is already long enough and so I'll skip the explanation of this intuition.</p>

<p><strong>And so the very results (I) and (II) obtained by GVT (1985) are actually strong evidence in favor of the hot hand.</strong> This is what Miller and Sanjurjo (2015) showed.</p>

<hr>

<p><strong>Further analysis of GVT's Table 4.</strong></p>

<p>Many (e.g. @scerwin below) have — without bothering to read GVT (1985) — expressed disbelief that any ""trained statistician would ever"" take an  average of averages in this context. </p>

<p>But that is exactly what GVT (1985) did in their Table 4.
See their Table 4, columns 2-4 and 5-6, bottom row. They find that averaged across the 26 players, </p>

<blockquote>
  <p>$\hat{p}(H|1M) \approx 0.47$ and $\hat{p}(H|1H) \approx 0.48$, </p>
  
  <p>$\hat{p}(H|2M) \approx 0.47$ and $\hat{p}(H|2H) \approx 0.49$, </p>
  
  <p>$\hat{p}(H|3M) \approx 0.45$ and $\hat{p}(H|3H) \approx 0.49$. </p>
</blockquote>

<p>Actually it is the case that for each $k=1,2,3$, the averaged $\hat{p}(H|kH)&gt;\hat{p}(H|kM)$. But GVT's argument seems to be that these are not statistically significant and so these are not evidence in favor of the hot hand. OK fair enough.</p>

<p>But if instead of taking the average of averages (a move considered unbelievably stupid by some), we redo their analysis and aggregate across the 26 players (100 shots for each, with some exceptions), we get the following table of weighted averages.</p>

<pre><code>Any                     1175/2515 = 0.4672

3 misses in a row       161/400 = 0.4025
3 hits in a row         179/313 = 0.5719

2 misses in a row       315/719 = 0.4381
2 hits in a row         316/581 = 0.5439        

1 miss in a row         592/1317 = 0.4495
1 hit in a row          581/1150 = 0.5052
</code></pre>

<p>The table says, for example, that a total of 2,515 shots were taken by the 26 players, of which 1,175 or 46.72% were made.</p>

<p>And of the 400 instances where a player missed 3 in a row, 161 or 40.25% were immediately followed by a hit. And of the 313 instances where a player hit 3 in a row, 179 or 57.19% were immediately followed by a hit. </p>

<p>The above weighted averages seem to be strong evidence in favor of the hot hand.</p>

<p>Bear in mind that the shooting experiment was set up so that each player was shooting from where it had been determined he/she could make roughly 50% of his/her shots. </p>

<p>(Note: ""Strangely"" enough, in Table 1 for a very similar analysis with the Sixers' in-game shooting, GVT instead present the weighted averages. So why didn't they do the same for Table 4? My guess is that they certainly did calculate the weighted averages for Table 4 — the numbers I present above, didn't like what they saw, and chose to suppress them. This sort of behavior is unfortunately par for the course in academia.)</p>

<hr>

<blockquote>
  <p><strong>Example</strong>: Say we have the sequence $HHHTTTHHHHH…H$ (only flips #4-#6 are tails, the remaining 97 flips are all heads). Then $\hat{p}(H|3T)=1/1=1$ because there is only 1 streak of three tails and the flip immediately after that streak is heads. </p>
  
  <p>And $\hat{p}(H|3H)=91/92 \approx 0.989$ because there are 92 streaks of three heads and for 91 of those 92 streaks, the flip immediately after is heads.</p>
</blockquote>

<hr>

<p>P.S. GVT's (1985) Table 4 contains several errors. I spotted at least two rounding errors. And also for player 10, the parenthetical values in columns 4 and 6 do not add up to one less than that in column 5 (contrary to the note at the bottom). I contacted Gilovich (Tversky is dead and Vallone I am not sure), but unfortunately he no longer has the original sequences of hits and misses. Table 4 is all we have. </p>
","6499"
"Does the money's ""Store of value"" function actually exists?","1039","","<p>I'm aware of the following four functions of money:</p>

<ol>
<li>Medium of exchange.</li>
<li>Measure of value (in dollars, pounds, etc.)</li>
<li>Standard for exchanging goods (guaranteed by the Fed)</li>
<li>A Store of value (as an asset).</li>
</ol>

<p>AFAIK, the last one didn't exist according to Classical Economists, but only John Maynard Keynes brought it later in his theory.</p>

<p>I want to understand whether this function really exists? I'm more inclined to agree with the Classical Economists - </p>

<p>I've created a simple analogy to understand this. Suppose there is a small village where there are N residents who trade only in barter. Now, you introduce a new bank in the village called Banko and a currency called pebbles. (For simplicity, lets assume that Banko is both a central bank and also lends/borrows money).</p>

<p>Now in order to leave barter and migrate to currency system, the villagers will have to either sell their goods to Banko, or borrow pebbles from them. So, there is a ""give and take"" or <em>exchange</em> of pebbles against goods.</p>

<p>But at the end of the day, if you consider the <strong>overall macro-economic position</strong>, the pebbles made no difference in <em>value</em> at all.  The villager's <em>NET ENDOWMENT</em> is same as it was before, the pebbles just facilitate transactions and used to count their assets now.</p>

<p>So, my question is, if money doesn't make any difference to the REAL value of goods and services, how can it be considered an asset?</p>
","<p>What is <em>value</em>? Ultimately, value flows from the utility people get from consuming goods and services.</p>

<p>Now, suppose, in your example world, I am a farmer and it is Autumn so I have the product of a large harvest. Here are three things I could do with it:</p>

<ul>
<li>Consume (and thereby enjoy the value of) my entire harvest immediately. But this would leave me hungry in the winter.</li>
<li>Store some food for later: Put some of the grain I produced into a silo and take it out of the silo to eat in the winter.</li>
<li>Sell some of my food to the bank in return for pebbles. Then, later in the winter, use those pebbles to buy back some food when my supply has run out.</li>
</ul>

<p>Notice that points 2 and 3 are essentially equivalent (they result in the same distribution of consumption across time). In the former, I am directly storing food. In the latter, I am using the pebbles to <em>store the value</em> associated with the food until I want to claim that value back.</p>

<p>Although the store of value is really just an abstract implementation of the physical storage of the goods generating that value, this distinction becomes important in more sophisticated economies. Storing value rather than storing the goods that generate that value is attractive for a few reasons.</p>

<ol>
<li><p>Many goods and services are hard to store. For example, as an economics professor it is impossible for me to ""store"" lectures during the autumn for use in the summer when I can't find any students to teach. How do I avoid starving during these long, studentless summer months? I take the (hopefully positive) value my lectures produce during the autumn and store this value in money. I can then claim this value back during the summer when I need it.</p></li>
<li><p>Storage of physical stuff takes up a lot of space and is expensive. Storage of money is much less so. Similarly, transporting stuff is expensive. With a bank card it becomes unnecessary to transport money at all. </p></li>
<li><p>Storage is often wasteful because it involves stuff sitting around doing nothing when it could be generating utility for someone.</p></li>
</ol>
","3327"
"GNP, GDP, GNI, GNDI and their relationships?","1034","","<p>GDP - Gross Domestic Product</p>

<p>GNP - Gross National Product</p>

<p>GNI - Gross National Income</p>

<p>GNDI - Gross National Disposable Income</p>

<p>We know that GNI=GNP, and that <a href=""http://www.economicshelp.org/blog/3491/economics/difference-between-gnp-gdp-and-gni/"" rel=""nofollow"">GNP=GDP+Net income from factor ownership abroad.</a></p>

<p>What I don't understant is how according to IMF Balance of Payments terminology, we have that <a href=""https://www.imf.org/external/pubs/ft/bop/2007/pdf/chap14.pdf"" rel=""nofollow"">GNDI=GDP+net primary and secondary income from abroad</a>, when we know that <a href=""https://stats.oecd.org/glossary/detail.asp?ID=1175"" rel=""nofollow"">GNDI = GNI+net current transfer from abroad</a>? 
Wouldn't this be tantamount to say that GNP=GDP?</p>
","<p>GNI is simply a new name for GNP.  It is GDP plus net primary income from abroad (i.e. with primary income paid abroad treated as negative). Primary income is described in <a href=""https://www.imf.org/external/pubs/ft/bop/2007/pdf/chap11.pdf"" rel=""nofollow"">Chapter 11 of the IMF BOP manual</a></p>

<p>GNDI is GNI plus net secondary income from abroad (and similarly secondary income paid abroad is treated as negative).  Net secondary income from abroad is the same thing as is meant by net current transfers from abroad: see <a href=""https://www.imf.org/external/pubs/ft/bop/2007/pdf/chap12.pdf"" rel=""nofollow"">Chapter 12 of the IMF BOP manual</a></p>
","13249"
"Are billboards beneficial for the economy? Why?","1032","","<p>Billboards cost money to make and don't really seem to significantly benefit anyone other than billboard-makers. A company c putting up billboards presumably increases profits from the resulting increased number of customers, but don't competing businesses' billboards decrease c’s profits by decreasing its number of customers? I don’t see why the total amount of consumption would change, so wouldn't the total amount of business remain roughly constant? So, are billboards economically beneficial or not? Why?</p>
","<p>While advertising can be zero sum, here are two additional dimensions you might want to consider. </p>

<p>Billboards, like other forms of advertising, can inform. In this way Ford can talk about their new 8 seat minivan while GM talks about the more fuel efficient engine of their latest model. This can result in happier customers who value their product better and are willing to pay higher prices for this more ideal product. </p>

<p>Billboards, in ways not paralleled by other most other forms of advertising, have a negative externality akin to pollution. When the NY Times decides to increase their number of advertisements slightly they bear the costs in customer unhappiness, giving them an incentive to adjust until the private costs and benefits of a marginal ad are equated. But not so with the billboard. The billboard is typically adjacent to public space, so if a nasty billboard ruins the scenery or obscures another billboard the billboard owner doesn't internalize those costs. Since the private benefits of ad revenue continue to accrue to the owner, this leads to too many billboards even if some level of billboard production would be socially desirable. </p>
","4707"
"Are monotonic and continuous preferences necessarily rational?","1027","","<p>Let $\succsim$ be a strictly monotonic and continuous preference relation, and let $X=\mathbb{R}^{n}$ be the consumption set.</p>

<p>Is rationality of $\succsim$ implied by these conditions? </p>

<p>I think transitivity is implied by continuity. However, completeness is troubling, as there are elements $x,y \in X$ that cannot be ordered with respect to $\leq$ or $\geq$, and so we cannot use monotonicity to show that $\succsim$ is complete.</p>

<p>I have thought of constructing a sequence $x_{n}$ with $x_{1}=x$ such that $x_{n} \to y$ and either $x_{n}\succsim x_{n+1}$ or $x_{n+1} \succsim x_{n}$. Then by transitivity and continuity we could show that $x$ and $y$ can be ordered with respect to $\succsim$, but I do not think it is possible to construct such a sequence. </p>

<p>Any help would be appreciated, but please give hints and not full solutions.</p>
","<p>Consider a preference relation in $\mathbb{R}^2$ such that $x=(x_1,x_2)\succsim (y_1,y_2)=y$ $\iff$ $x_1\geq y_1$ and $x_2\geq y_2$. </p>

<p>1) You might like to argue whether this preference relation is strictly monotonic and continuous. </p>

<p>2) Is the relation defined above complete?</p>

<p>Then, as a side dish, you might also reconsider your claim that continuity is the cause of transitivity.</p>

<p>Note: I just wrote this particular one with the purpose of providing a thought experiment. More in a way to challenge your understanding. I am not sure whether this example provides an answer to your question or not.</p>
","8346"
"Does unit elasticity has to be at exactly the middle of the demand curve?","1026","","<p>Can unit elasticity be anywhere else on the demand curve other than the midpoint?</p>
","<p>When the demand function is linear, $q = a-bp$, the only point were elasticity is unity is located in the midpoint of the demand curve (straight line). This is geometrical.</p>

<p>The demand line will cross the vertical $p$-axis at $p=a/b$ and the horizontal $q$ axis at $q=a$. For unitary elasticity (in absolute terms) we want</p>

<p>$$\frac{|dq/dp|}{q}\cdot p = \frac{bp}{a-bp}=1 \implies p=\frac {a}{2b} \implies q=\frac a2$$</p>

<p>So at unitary elasticity the corresponding price lies in the middle of the feasible price domain, and the corresponding quantity lies in the middle of the feasible quantity domain.</p>

<p>The related diagram is</p>

<p><a href=""https://i.stack.imgur.com/8t6BY.png""><img src=""https://i.stack.imgur.com/8t6BY.png"" alt=""enter image description here""></a></p>

<p>The length $[AB]$ is equal to the length $[CD]$, and the length $[BC]$ is equal to the length $[DE]$. But this implies that the triangles $[ABC]$ and $[CDE]$ have two of their sides equal, so necessarily they will have also their third side equal. So $[AC] = [CE]$, which implies that the point of unitary elasticity $C$ is the midpoint of the demand line. Obviously, no other point can have unitary elasticity here.</p>
","8982"
"What are some good graduate-level econometrics books for someone with a strong mathematics background?","1023","","<p>Related: <a href=""https://economics.stackexchange.com/questions/110/book-recommendations-on-empirical-methods-in-economic-research-and-econometrics"">Book recommendations on empirical methods in economic research and econometrics?</a></p>

<p>I would like to focus mainly on <em>graduate texts in Econometrics</em>. From the question above, I gather that Wooldridge's text is nice.</p>

<p>In terms of ""strong math background,"" I did my undergrad in Statistics, consisting of two semesters each of linear algebra, real analysis, and abstract algebra, along with a measure-theoretic probability course.</p>

<p>What are some econometrics texts that you would recommend for me? I learned some intro econometrics in a course which taught from Studenmund but was extremely bored. </p>
","<p>""Adult"" Wooldridge is great intro to various microeconometrics topics.</p>

<p>For time series, Hamilton's Time Series and Lutkepohl's Introduction to Multiple Time Series Analysis are both nice, though Hamilton is a bit dated and Lutkepohl is more focused.</p>

<p>As far as more foundational, rigorous material, Herman Bierens has a short Introduction to the Mathematical and Statistical Foundations of Econometrics. Gourieroux and Monfort have a whole flock of graduate econometrics texts, but to quote an anonymous reviewer, they are ""in the French tradition of excellent precision and terrible pedagogics,"" though they have their champions.</p>
","496"
"Transfer payments and IS multiplier","1014","","<p>Where do transfer payments (unemployment subsidies, etc.) enter in the multiplier formula for the IS curve? </p>

<p>The usual multiplier is of the form $\frac{1}{1-c(1-t)-m}$, where $c$ is the marginal propensity(m.p.) to consume, $m$ is m.p. to import, and $t$ is the tax rate. I've tried to see $t$ instead as net transfers rate, i.e. transfer payments minus taxes. But I'm not sure if it's the right way to think about this...</p>

<p>Any help would be appreciated.</p>
","<p>Notice that you only  consume out of your <em>disposable</em> income, that is, adding transfers and removing taxes. Thus, from that formula of the multiplier, yes, it should be there, in the $(1-t)$.</p>

<p>As (assuming) $C=cY^D=c(1-t)Y$ and thus, $MPC=\partial C/\partial Y = c (1-t)$, then $Y-Y^D=tY=\text{Taxes}-\text{Transfers}$, with $t$ ""condensing"" all the information.</p>
","12086"
"What is the difference between gross, operating, net profit and EBIT(DA)?","1011","","<p>What is the difference between the following accounting measures, if any?</p>

<ul>
<li>Gross profit</li>
<li>Operating profit</li>
<li>Net profit/income</li>
<li>EBIT</li>
<li>EBITDA</li>
</ul>
","<p>So, here goes:</p>

<h3>Gross Profit = Revenue - COGS (Cost of Goods Sold)</h3>

<p>If you bought an orange for a dollar and sold it for two, you have one dollar of Gross Profit</p>

<h3>Operating Profit = Gross Profit - Labor - SG&amp;A</h3>

<p>If you're business paid someone \$100 to sell 200 oranges (like above), you would have \$200 in Gross profit, and \$100 in Operating Profit (assuming no other overhead like licenses, etc) for that business line. Operating Profit can be for a firm, business line, or whole company. Depreciation and Amortization can be included here for assets and debts in service to the entity or business line in question.</p>

<p>Typically Operating Profit tells whether a business line, unit, or company is profitable (independent of interest and taxes as explained below in the EBIT section). </p>

<p>Operating Profit and EBIT are not completely interchangeable in common parlance, though, as EBIT is typically used only for a company and Operating Income is often used both for Companies, and individual product lines within the company.</p>

<h3>EBITDA is Earnings Before Interest, Tax, Depreciation, and Amortization</h3>

<p>If the same business paid \$10 to incorporate, that would come out here, so your company's EBITDA would be \$90.</p>

<h3>EBIT includes Depreciation and Amortization</h3>

<p>If you'd also used your \$100 office (independent of the orange selling operation or it would have also been in the orange selling Operating Profit line) for 1/100 of it's operating life, you would have \$1 in depreciation. Bringing your EBIT down to \$89. EBIT is almost always a company level statistic, and rolls up all Depreciation, Amortization, and costs other than Interest and Taxes.</p>

<p>The reason people analyze EBIT, is that it gives you a feeling for if the company could be profitable if moved to a different tax jurisdiction, or if its WACC (weighted average cost of capital) were changed through recapitalization.</p>

<h3>Net Profit = EBIT - Interest - Taxes</h3>

<p>So if you'd paid \$1 in interest on a \$100 loan to buy the oranges in the first place, you're pre-tax income would be \$88, which you would report to the appropriate tax agency, assuming a 35% corporate tax rate, you'd pay \$30.80 in taxes, leaving you a Net profit of \$57.20.</p>

<p>This is usually the ""bottom line"" of an income statement.</p>
","12580"
"Inflation without Increase in Money Supply?","1009","","<p>Is it possible to have inflation without increase in the supply of money? </p>

<p>For example, if workers demanded higher wages, and goods went up in price, but the money supply in circulation did not increase. Or is this an impossible paradox?</p>
","<p>It all depends on what you mean by inflation and by money supply. Technical questions and answers need specific definitions, otherwise everyone ends up talking at cross-purposes.</p>

<p>Is it possible to have an increase in general price levels without any changes to the amount of money in circulation? <strong>Yes</strong>: if the velocity of circulation of money increases, and the amount of goods and services available to buy does not increase by as much.</p>

<p>Is it possible to have an increase in general price levels without any changes to the amount of money in circulation or the velocity of circulation? <strong>Yes</strong>: if the amount of goods and services available to buy, decreases, so that there's more money chasing fewer goods.</p>

<p>Is it possible to have an increase in general price levels without any changes to the amount of money in circulation or the velocity of circulation, and with no decrease in the amount of goods and services available to buy? <strong>Yes</strong>, if the demand curve changes so that the same amount of money is now used to buy a smaller quantity of stuff at higher prices.</p>

<p>Is it possible to have an increase in general price levels without any changes to the amount of money in circulation or the velocity of circulation, and with no change in the amount of goods and services bought? <strong>No</strong>, because the velocity of circulation is by definition total transaction value divided by the amount of money in circulation, so if velocity, quantity and money supply are constant, then prices must be too, because total transaction value equals prices times quantity.</p>
","9768"
"Cyclicality of Real Wages? Counter, pro or acyclical?","1006","","<p>Is the real wage counter or pro- cyclical? I've read in some textbooks that the real wage is mildly pro-cyclical, but I've also found some papers stating that it's acyclical.</p>

<p>So, which is it? Also, if the real wage is pro-cyclical, does that mean that there's some sort of price rigidity, i.e., the economy is not always on the Price-Setting curve? </p>
","<h3>Are Wages Procyclical?</h3>

<p>Here's the entry from Table 1 in King and Rebelo (2000; Resuscitating Real Business Cycles). The variable of analysis is log-wages, detrended with HP filter. It has a std, relative std, first-order autocorrelation and correlation with output of <code>0.68</code>, <code>0.38</code>, <code>0.66</code>, <code>0.12</code>. </p>

<p>This leads the authors to conclude that </p>

<blockquote>
  <p>The real wage is much less volatile than output.</p>
</blockquote>

<p>You can see that for their long US period, <code>0.12</code> is a positive number, but pretty close to zero. This is why different authors take this number as either acyclical or weakly procyclical. </p>

<h3>Price rigidity required for procyclical wages?</h3>

<p>Assume that some sort of fluctuation in TFP ""drives"" the business cycle. Furthermore, if markets are competitive, the wage rate should be set by the marginal product:</p>

<p>$$ w = AF_L(K, L)$$</p>

<p><em>If</em> $L$ stays constant over the business cycle (e.g. with inelastic labor supply), this setup will generate wages $w$ that vary with $A$, and hence any change in $A$ will result in a one-for-one change in $w$ and in $Y$: $Y$ and $w$ are perfectly correlated, while $L$ is fixed.</p>

<p>This is pretty much the prediction of the RBC model, and it is the opposite of what we observe in the data: $L$ is volatile, while $w$ is fixed. If you'd assume that $L$ responds strongly to changes in $A$, $w$ might be pretty constant over the business cycle. This is what we observe in reality. </p>

<p>And most of the labor-side of RBC research is to come up with ways that force $L$ to respond so much.</p>

<p><em>King and Rebelo (2000) should be a key paper of any introductory reading list for macroeconomics and I strongly recommend reading it.</em></p>

<h3>The case of less competition</h3>

<p>If there is literally <strong>zero competition</strong>, then firms will at all times only pay the household his outside-option value, making him indifferent between working and not working. If that outside option is constant over the business cycle (for which we have to some extent theoretical and empirical arguments), wages will be acyclical.</p>

<p>However, to the extend that there is no perfect monopsony, firms have to compete for workers and offer higher wages whenever workers are worth more. Hence, wages will be procyclical even if, to some extent, firms are not perfectly competitive on the labor side. The more competitive they are, the more pro-cyclical wages should be.</p>

<h3>Alternatives and extensions to the neoclassical model</h3>

<p>The above model was just a simple one to generate a case in which pro-cyclicality of wages can be generated without price stickiness. There is much more to the subject than an answer here can provide. Here's some more references:</p>

<ul>
<li>Barro (1977): Long-term contracting, sticky prices, and monetary policy. *Wages are long-term contracts, hence if firms are less risk-averse than workers, firms will insure workers against wage changes over the business cycle and we can observe (optimally) constant wages </li>
<li>Beadry and DiNardo (1991) is a follow-up on that discussion</li>
<li>Haefke et al (2013, JME) is also a very recent follow-up</li>
<li>Bewley (1999): Why wages don't fall in a recession</li>
<li>Shimer and Hall (two separate papers, both in the same 2005, AER) are the standard references on whether the more modern and reasonable frictional DMP model can match labor (and wage) volatility over the business cycle.</li>
</ul>
","10013"
"Why did the Fed raise interest rates between 2004 and 2006?","1001","","<p>Between June 2004 and August 2006, the Fed <a href=""https://research.stlouisfed.org/fred2/graph/?g=4enx"" rel=""nofollow noreferrer"">raised interest rates again and again</a>, because they were <a href=""http://money.cnn.com/2005/09/20/news/economy/fed_rates/"" rel=""nofollow noreferrer"">""...growing more uncomfortable about inflation""</a>.</p>

<p>Looking at the graph below, inflation did increase, but not in any totally insane way (note that it clearly didn't respond to the rate rises!):</p>

<p><a href=""https://i.stack.imgur.com/kOP4q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kOP4q.png"" alt=""Interest rates""></a></p>

<p>Given that high interest rates are bad for mortgage-holders (particularly those with high loan-to-value ratios), you'd think quindrupling rates within 18 months would be <em>bound</em> to lead to a wave of defaults.</p>

<p>Were there accusations at the time that the Fed was blindly following its inflation targeting rule without thinking about the consequences in the rest of the economy?</p>

<p>Or was it about something other than inflation?</p>
","<p>Good question! </p>

<p>It seems that one of the reasons was precisely that inflation did not respond. They kept raising interest rates,  hoping it would respond at some point. In fact, nominal interest rates have to increase <em>more</em> than expected inflation for the real interest rates to go up, so it made sense.</p>

<p>The other reason is also related to the question. It seems that they were aware that a relatively long period of low interest rates was potentially fueling ""asset price bubbles"",  such as in housing, but also in asset backed securities, corporate bonds and equities. These also did not seem to respond quickly to the rate changes. </p>

<p>Of course, apparently, they did not realize that it was dangerous moment to increase rates quickly. It would have potentially been a good idea to raise the rates very very slowly, so that leveraged agents had a chance to de-lever as the prices of their assets slowly came down... Alternatively they could have slowly tightened the regulation on lending instead of raising the rates at all. This last point seems to be the key to avoiding a new crisis: having a good too to increase and decrease economy wide leverage distinct from interest rates.</p>
","11691"
"Partial differential equations in economics","988","","<p>Where, in economics, are <strong>partial differential equations</strong> used?</p>

<p>I'm particularly interested in micro theory applications, but would also be keen to know of other applications.</p>
","<p>Here are a couple of suggestions. There are some PDEs in some recent continuous-time models, for instance in:</p>

<ul>
<li>A Continuous-Time Version of the Principal-Agent Problem, by Sannikov, Review of Economic Studies (2008)</li>
<li>Persistent private information, by Williams, Econometrica (2011)</li>
</ul>

<p>I would not be surprised if Yuliy Sannikov used PDEs in some of his other papers (although I have nothing precise in mind).</p>

<p>You can refer to the review by Achdou et al. (Partial differential equation models in macroeconomics, Philosophical Transactions of the Royal Society, 2014) for other references.</p>
","10582"
"(Preference Relation/Set) Continuous $\succsim$ imply closedness of upper and lower contour sets","977","","<p><strong><em>[ADDED/MODIFIED] : I have put my proof where the commodity space is simply $\mathbb{R_+}$(e.g. nonnegative reals) for simplicity below. Please share your 2 cent. I have put words to aid my own understanding...</em></strong></p>

<p>I am trying to understand that an equivalent way of stating ""a preference relation that is continuous on $X$ is continuous"" is to say ""the upper and lower contours sets are closed"". What I don't understand is when MWG in Micro Book in Chapter 3 says the following :</p>

<p><strong>The continuity of $\succsim$ on X implies that for any sequence of points $\{y^n\}$ with $x\succsim y^n$ $\forall n$ and $y^n$ converging to $y$, we have $x\succsim y$. And, this implies the lower contour $L(x)=\{y\in X:x\succsim y\}$ set is closed.</strong></p>

<p><strong><em>My questions is: how does the above statement imply the lower contour set is closed?</em></strong></p>

<blockquote>
  <p><strong>[New Attempt] Proof:</strong></p>
  
  <p>(1) Recall <strong>Definition 3.C.1(Modified for $\mathbb{R}$)</strong>:</p>
  
  <p>The preference relation $\succsim$ on $X\subset\mathbb{R_+}$ is continuous if it is preserved under limits. That is, for any sequence of pairs $\{(x^n, y^n)\}^\infty_{n=1}$ with $x^n \succsim y^n$ for all $n$, $x = \lim_{n \rightarrow \infty} x^n$, and $y = \lim_{n \rightarrow \infty} y^n$, we have $x \succsim y$.</p>
  
  <p><strong>(In words, if you have a sequence of reals $x^n$ and $y^n$ where each term in $x^n$ is greater or equal to that of in $y^n$ and $x^n\rightarrow x$, $y^n\rightarrow y$, then you have $x\succsim y$. Notice here, to facilitate understanding, I basically equated the preference relation as the in\equality on reals, thus the expression ""greater or equal"". An example is $x=2,y=1$. Essentially, look at the equivalence class of 2 and 1 on real line with the restriction that it is not any sequence converging to these numbers but need to narrow down to the group of convergent sequences where each term in $x^n$ is greater or equal to that of in $y^n$.)</strong></p>
  
  <p>(2) The above definition implies the following: for any sequence of pairs $\{(x^n, y^n)\}^\infty_{n=1}$ with $x\succsim y^n$ $\forall n$, where $x^n=x$ $\forall n$ with $y^n$ converging to $y$, we have $x\succsim y$.</p>
  
  <p><strong>((1) certainly implies (2), because again think of the example, $x^n=2, 2, 2, \dots$ and $y^n$ being any member of the equivalence class of 1 with the restriction each term has to be less or equal to 2. How does the set of the sequences $y^n$ satisfying this condition actually look like on the real line? Each term has to be less or equal to 2 but we are in the nonnegative commodity space $\mathbb{R_+}$, so we have a set of sequences bounded in the interval $[0,2]$ but convergent to the number 1. This example is still valid for any pair of sequences of reals $x^n\geq y^n$ where $y^n$, the sequence of reals is a bounded sequence in $[0,x]$ converging to any a point $y\in[0,x]$ while $x^n=x,x,x,\dots$, we have $x\geq y$.)</strong></p>
  
  <p>(3) Define the lower contour set to be $L(x)=\{y\in X:x\succsim y\}$. Then, (2) implies $L(x)$ is closed.</p>
  
  <p><strong>(In (2), we attained that for any pair of sequences of reals $x^n\geq y^n$ where $y^n$, the sequence of reals is a bounded sequence in $[0,x]$ converging to any a point $y\in[0,x]$ while $x^n=x,x,x,\dots$, we have $x\geq y$. The lower contour set is exactly a collection of real numbers $y$ such that it is less or equal to some $x$ on the real line. Then for any real number $y\in[0,x]$, you have a sequence of reals bounded by $0$ and $x$ where it converges to that $y$.Then, $L(x)$ contains all its limit points. Hence, it is closed.)</strong></p>
</blockquote>

<p>[Old Attempt]
My instinct was to show the lower contour set is closed is equivalent to showing the set contains all its limit points. And how do you do this? Well, in this case, it is to show whether, say the lower contour set, contains its boundary points. These points in collection is just the indifference set $I(x)=\{y\in X:y\sim x\}$.</p>

<p>Then, I want to show $I(x)\subset L(x)$.</p>

<p><strong><em>Proof</em></strong>
: (1) Suppose $x\in I(x)$.</p>

<p>(2) By definition, $x\succsim y$ and $y\succsim x$ $\iff x\sim y$. Hence, $I(x)=\{y\in X:y\succsim x\}\cap\{y\in X:x\succsim y\}$.</p>

<p>(3) Hence, $x\in L(x)$ and $I(x)\subset L(x)$. Q.E.D.</p>

<p>Is my approach incomplete and how should I make sense of MWG's claim above? Please help. Thank you!!</p>
","<p>Looking more closely at your question, I think things should not be overly complicated. From Mas-Colell et.al.</p>

<p><strong>Definition 3.C.1:</strong></p>

<blockquote>
  <p>The preference relation $\succsim$ on X is continuous if it is preserved under limits. That is, for any sequence of pairs $\{(x^n, y^n)\}^\infty_{n=1}$ with $x^n \succsim y^n$ for all $n$, $x = \lim_{n \rightarrow \infty} x^n$, and $y = \lim_{n \rightarrow \infty} y^n$, we have $x \succsim y$</p>
</blockquote>

<p>The book then goes on to state that showing the lower contour set and upper contour set are closed, is equivalent.</p>

<p>As you note, a closed set is a set that contains all its limit points. That means that any convergent sequence of points $\{x^n\}^\infty_{n=1} \rightarrow x$ converges inside the set.</p>

<p>Because of the way the lower and upper contour sets are constructed, you can think of all the convergent sequences in the upper contour set as $\{x^n\}^\infty_{n=1}$ and all the convergent sequences of points in the lower contour set as $\{y^n\}^\infty_{n=1}$. In this case, all $x \succsim y$.</p>

<p>But it's not the same way for discontinuous preferences! Just try and draw discontinuous preferences where the contour sets are closed.</p>

<p><a href=""https://i.stack.imgur.com/ExF1F.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ExF1F.png"" alt=""enter image description here""></a></p>

<p>(enjoy that masterpiece)</p>

<p>Any convergent sequence to that open boundary there is trouble.</p>
","12411"
"Effect of minimum wage on higher levels of pay","977","","<p>Suppose the minimum wage increases to \$$x$. Is there any evidence on the effect (if any) this is likely to have upon the wage profile of workers higher in the hierarchy, who are already paid more than \$$x$?</p>

<p>My question is inspired by the following comment from the Financial Times (<a href=""http://www.ft.com/cms/s/0/611460a8-2584-11e5-9c4e-a775d2b173ca.html?siteedition=uk#axzz3fKj3NZf0"" rel=""nofollow"">paywalled link</a>):</p>

<blockquote>
  <p>As an employer with an annual payroll of around £650k pa the impact of the introduction of the minimum wage in 1997 led us to pay our lowest paid staff ( casual bar staff back then on about £3ph ) the increased minimum wage so they at least benefited. Everyone else higher in the hierachy ( full timers, supervisors, asst managers, managers) all suffered because at every opportunity ( as people left and needed to be replaced) we tried to replace these higher paid staff with the same caliber person but on lower wages. And we were successful at dong this; and we had to be because we could not afford our overall wage bill to increase. So in 2000 I was paying a General Manager 35k a year. Now I can find and pay a general manager 25k pa and thats a massive nominal decline over 15 years. So the real impact of the minimum wage introduction in the real world of small husiness was to pay the lowest casual staff a little more but most of the higher paid staff ended up being paid less .</p>
</blockquote>

<p>Is there any evidence to support the claim that the described response is a widespread phenomenon?</p>
","<p>This phenomenon is sometimes called ""wage compression"" because the range of wages is compressed by the minimum wage laws. 
One paper on this subject is <a href=""http://www.jstor.org/stable/145206"">The Impact of the Minimum Wage on Other Wages</a></p>
","6456"
"How infinite Nash equilibria are possible in a game?","977","","<p>I was studying games when one of the players seems to be indifferent between two or more pure strategies because he gets the same payoff with each strategy. We say that there are infinite Nash equillibria in the game but I am unable to calculate it and get an intuitive idea of how is it happening. 
For example in the following game 
$$\begin{array}{c|a|c} &amp; L_2 &amp; R_2&amp; \\ \hline L_1 &amp; (3,1) &amp; (0,1) \\ \hline R_1 &amp; (0,1) &amp; (4,1) \\ \hline \end{array}$$                 </p>

<p>Seemingly, P2 should not even bother about anything even if he is playing pure strategy or randomizing. But here if we assume that P2 plays L with probability q and P1 plays L with probability p then making them indifferent we see that we cannot calculate p but q comes out to be 4/7. How is it possible or what is the interpretation ? If I am doing it wrong then what is the correct way to determine equilibria in this case ?</p>

<p>Another example is </p>

<p>$$\begin{array}{c|a|c} &amp; L_2 &amp; R_2&amp; \\ \hline L_1 &amp; (1,1) &amp; (0,0) \\ \hline R_1 &amp; (0,0) &amp; (0,0) \\ \hline \end{array}$$   </p>

<p>How many Nash's equilibria are possible in this ?</p>
","<p>Well the intuition is quite straightforward: as you have mentioned yourself, player 2 is indifferent between playing any action in pure strategies, <em>or</em> randomizing in any possible way. So, for a mixed strategy equilibrium to exist, player 2 needs to play L w/ probability 4/7. If this is the case, it is <em>irrelevant</em> what Player 1 player---player 2's outcome is the same. As a result, in pure strategies the Equilibria are L,L and R,R and, in Mixed strategies, q=4/7 and p can take any value between 0 and 1. Hence, there exist infinite possible Nash Equilibria (p just has to obey the fundamental laws of probability). </p>
","8424"
"Reduced Form of an econometric model, identification problem and test","976","","<p>Looking for some help to understand the following problem and how to use the reduced form in econometrics</p>

<p>Consider a model for the health of an individual:
$$health = b_0 + (b_1)age + (b_2)weight + (b_3)height + (b_4)male + (b_5)work +
(b_6)exercise + u$$</p>

<p>assume that all variables in the equation with the exception of exercise are uncorrelated with u. </p>

<p>A)Write down the reduced form for exercise, and state the conditions under which the parameters of the equation are identified.</p>

<p>B)How can the identification assumption in part c be tested?</p>

<hr>

<p>Is it correct to assume:</p>

<p>$$exercise = b_0 + (b_1)age + (b_2)weight + (b_3)height + (b_4)male + (b_5)work +
  u$$ as the reduced form?</p>

<p>and is the condition for identification of parameters simply </p>

<p>$E(exercise|u)=0$</p>

<p>and how can I test it? But moreover what is it good for?</p>
","<p>This is the very standard question on Instrumental Variables of Single-Equation Linear models. Given the primitives of your question, the only endogenous variable is <em>exercise</em>. In order to answer this particular question, you need an exogeous variable, <strong>z</strong>, that satisfies two conditions:</p>

<ol>
<li>cov(z,u)=0. </li>
<li>There must be a relationship between the endogenous variable and this exogenous variable you are proposing but that it wasn't part of the true postulated model (the structural model). In other words,
$$
exercise=\beta_0+\beta_1 age +\beta_2 weight + \beta_3 height + \beta_4 male + \beta_5 work + \phi z + \varepsilon_{exercise}
$$
with $\phi\ne 0$, $\mathbb{E}\,( \varepsilon_{exercise})=0$ and orthogonal to all your explanatory variables (other than exercise) <strong>and</strong> to z. </li>
</ol>

<p>Before moving on, a remark. By <strong>structural model</strong> I mean, following Wooldridge and Goldberger convention, the postulated model. That is, the model that states the causal relationship between <em>health</em> and your covariates. This is a key difference and a disagreement with previous answers.</p>

<p>Now, back at the problem at hand, condition 2 is what in the simultaneous-equations literature call <strong>the reduced form equation</strong>, which is nothing but a linear projection of the endogenous onto all exogenous variables, including z. </p>

<p>Now, plug the reduced form into your postulated model and you'll get</p>

<p>$$
health=\alpha_0 + \alpha_1 age + \alpha_2 weight + \alpha_3 height + \alpha_4 male + \alpha_5 work + \delta z  + \nu 
$$
where $\alpha_i = b_i + b_6\beta_i,\: \forall i \in \{1,\dots,5\}$, $\delta=b_6\phi$ and $\nu = u+b_6\varepsilon_{exercise}$. By the definition of linear projection, $\nu$ is uncorrelated with all explanatory variables and thus OLS of this last equation will produce consistent estimates for $\alpha_i$ and $\delta$, not the underlying $b_i$ in the true model.</p>

<p>Identification requires a bit of manipulation in matrix form but essentially it reduces to the so-called <strong>rank condition</strong>. Define $\mathbf{b}=(b_0,\dots,b_6)'$ and $\mathbf{x}=(1, age, \dots, exercise)'$ so that your structural model is $health=\mathbf{x}'\mathbf{b}+u$. Now define $\mathbf{z}\equiv(1,age,\dots,work,z)'$. By condition 1 (cov(z,u)=0 so that E(z,u)=0),
$$
\mathbb{E}(\mathbf{z}u)=0
$$
If you multiply bot sides of the structural model by $\mathbf{z}$ and take expectations you have
$$
\mathbb{E}(\mathbf{z}\mathbf{x}')\mathbf{b}=\mathbb{E}(\mathbf{z}y)
$$
Rank condition states that $\mathbb{E}(\mathbf{z}\mathbf{x}')$ is full column rank. In this particular example and given conditions on z this is equivalent to $rank(\mathbb{E}(\mathbf{z}\mathbf{x}')=6$. Therefore we have 6 equations in 6 unknowns. Hence there exists a unique solution for the system i.e. $\mathbf{b}$ is identified and equals to $[\mathbb{E}(\mathbf{z}\mathbf{x}')]^{-1}\mathbb{E}(\mathbf{z}y)$, as desired.</p>

<p>Remarks: Condition 1 is useful to get the moment condition but the reduced form model with $\phi$ is crucial for the rank condition. Both conditions are usual.</p>

<p>At this point it should be clear why do we need this. In the one hand, without z OLS estimator of the true model will produce inconsisten estimators not only for $b_6$ but for all $b_i$. In the other hand (and somewhat related), our parameters are uniquely identifies so we are certain that we are estimating the true causal relationship as stated in our true model.</p>

<p>In regard to testing, condition 2 (z and <em>exercise</em> are partially correlated) can be tested directly and you should always report that step contrary to the comment in a previous answer. There is a huge literature in relation to this step, specially the weak-instrument literature.</p>

<p>Second condition cannot be directly tested nonetheless. Sometimes you might invoke economic theory to justify or provide alternative hypotheses thats support the use of z.</p>
","4558"
"Calculating Nash Equilibrium prices for Bertrand duopolists","968","","<p>I am attempting to solve the following problem. </p>

<p>Suppose that firms' marginal and average costs are constant and equal to c and that inverse market demand is given by $P = a - bQ$ where $a,b &gt; 0$.</p>

<p>Calculate the Nash Equilibrium prices for Bertrand duopolists, which choose prices for their identical products simultaneously.</p>

<p>Now I attempted to solve this problem and got $P_1 = P_2 = \frac{a+c}{2}$ where $P1, P2$ are prices. </p>

<p>My professor lists the answer as $P_1 = P_2 = c$.</p>

<p>Can someone please tell me where I messed up? Thanks!</p>
","<p>The important thing to remember here is that Bertrand duopolists compete over price, not quantity. This means that in the game each player sets a price and the quantity sold is then determined by the demand curve. In this game the firm with the lowest price sells to the entire market and if both firms have the same price they each sell to half of the market. Now, we have to think about the logic that goes into determining equilibrium. It is easy to see that neither firm will ever set a price lower than $c$ because setting a price lower than marginal cost will give the firm negative profit. So we have to start that it must be the case that $p_1, p_2 &gt; c$. Now, suppose that $p_1 &gt; p_2 &gt; c$. This cannot happen because firm 1 has an incentive to set a price below that of firm 2 and above $c$ so they will take the whole market. The same logic can be applied to the case where $p_2 &gt; p_1 &gt; c$. Now, consider the case where $p_1 &gt; p_2 = c$. In this case firm 1 has the incentive to set there price equal to $c$ and split the market with firm 2, so this cannot be a Nash equilibrium. Again, we can apply the same logic to the case where $p_2 &gt; p_1 = c$. So, the only candidate left for Nash equilibrium is scenario where $p_1 = p_2 = c$. This result is very interesting considering that with one firm we get a profit maximizing monopoly result but by adding just one additional firm we get the same pricing as perfect competition as long as the firms are playing the Bertrand price competition game.</p>
","12233"
"How much leverage has the Federal Reserve taken on today (Jan 2016)?","958","","<p><a href=""http://nymag.com/daily/intelligencer/2015/12/big-short-genius-says-another-crisis-is-coming.html?mid=twitter-share-di"" rel=""nofollow"">http://nymag.com/daily/intelligencer/2015/12/big-short-genius-says-another-crisis-is-coming.html?mid=twitter-share-di</a></p>

<blockquote>
  <p>What makes you most nervous about the future? Debt. The idea that
  growth will remedy our debts is so addictive for politicians, but the
  citizens end up paying the price. The public sector has really stepped
  up as a consumer of debt. <strong>The Federal Reserve’s balance sheet is
  leveraged 77:1</strong>. Like I said, the absurdity, it just befuddles me.</p>
</blockquote>

<p>How did Michael Burry arrive at the 77:1 figure? Is this close to reality? How could the Fed be leveraged when they can simply print money to pay down debt in the first place?</p>
","<p>Page 4 of this document has the balance sheet as of November 2015: <a href=""http://www.federalreserve.gov/monetarypolicy/files/quarterly_balance_sheet_developments_report_201511.pdf"" rel=""nofollow"">http://www.federalreserve.gov/monetarypolicy/files/quarterly_balance_sheet_developments_report_201511.pdf</a></p>

<p>Their assets are 4489 liabilities are 4431. Thus Equity is 58, L/E = 76 (approx).</p>

<p>It would not matter even if Fed had infinite leverage ratio. However, as far as I know congress has agreed to keep Fed solvent (so the ratio can't go negative). Although, the institution is not even solvent, as some of it's assets are marked mark to model, thus having much lower fair value than presented in the balance sheet.</p>

<p>The balance sheet reflects created money (growth in base money) and not debt. Created money generates inflation, but significant amount of bank credit was destroyed which also constituted money people transacted with. Thus the newly created Fed money has just replaced the bank credit and there has been no significant inflation, as the M2 money supply has only raised slightly. Some of the currency has also been exported overseas as USA continues to have a balance of payment / trade deficits.</p>

<p>Based on the quote, it seems the author has confused two issues. If you want to investigate the debt and liabilities of the government, you need to look at the government debt and it's other liabilities (not merely the Fed). He is correct that the debt is at a quite high historical level (only during world war 2 was it higher), while other liabilities (such as social security and medicare liabilities) I believe are at an unprecedented historical level.</p>
","10035"
"Correlation between salary level and housing prices in a town","954","","<p>Is there a measurable correlation in a town between salary level and housing prices?</p>

<p>Or, to put it differently: is it politically meaningful to drive up salaries by new investments if the result is unaffordable housing?</p>

<p>UPDATE: I do not want to edit the original question as others wrote their reply with that in mind, but it is right to suggest that it would have been better to ask about causality, not correlation.</p>
","<p>The graph below plots average house prices against average incomes for various US cities. The relationship is strong in the cross-section, especially if you ignore Honolulu.</p>

<p><img src=""https://i.stack.imgur.com/6oxFt.jpg"" alt=""housing prices in 2009 against wage levels for 2008""></p>

<p><a href=""http://www.creativeclass.com/_v3/creative_class/2009/07/29/housing-and-the-crisis-part-iv/"" rel=""nofollow noreferrer"">Richard Florida, Housing and the Crisis, Part IV</a></p>

<p>Is it also true dynamically, that is, are changes in income associated with changes in house prices (not just levels)? Van Nieuwerburgh and Weill (2010) say yes:</p>

<blockquote>
  <p>We set up and solve a spatial, dynamic equilibrium model of the
  housing market based on two main assumptions: households with
  heterogenous abilities flow in and out metropolitan areas in response
  to local wage shocks, and the housing supply cannot adjust instantly
  because of regulatory constraints. In our equilibrium, house prices
  compensate for cross-sectional productivity differences. We increase
  productivity dispersion in the calibrated model in order to match the
  30-year increase in cross-sectional wage dispersion that we document
  based on metropolitan-level data. <strong>We show that the model
  quantitatively matches the observed 30-year increase in dispersion of
  house prices across US metropolitan areas</strong>. It is consistent with
  several other features of the cross-sectional distribution of house
  prices and wages.</p>
</blockquote>

<p><a href=""http://restud.oxfordjournals.org/content/77/4/1567.short"" rel=""nofollow noreferrer"">Why Has House Price Dispersion Gone Up?</a> </p>
","3144"
"Taylor Rule: Relationship between interest rate and inflation","950","","<p>Q. According to the Taylor Rule, what should the central bank do to stabilize the economy after an increase in oil price?</p>

<p>My points:</p>

<ul>
<li>Increase in oil prices (1970's) raises the price of production for producers and hence shifts the AS curve to the left.</li>
<li>With lower AS and a constant demand the price for goods is raised and inflation increases.</li>
<li>Taylor rule suggests that in order to counter the effect of inflation and lower it back down to its target (usually 2%), for every percentage point that inflation is above its target, the Fed funds rate should be raised by 0.5%. For example if inflation is at 8% and the target is 2%, 8-2=6% above target so Fed funds rate should be raised by 6x0.5 = 3%.</li>
</ul>

<p>I think I am correct in saying this but if am not please let me know. What I don't understand is why raising interest rates will actually help?</p>

<p>A higher Fed funds rate means banks will have to charge higher interest to its customers which will surely discourage consumption?</p>

<p>I understand the relationship between inflation and Real interest rate:</p>

<p>i = r + pi (Fisher Equation)</p>

<p>I'm just finding it hard to explain why increased interest will lower inflation in practice, i.e. what this means for consumers.</p>

<p>Does anyone have any pointers?</p>

<p>Thanks again in advance</p>
","<p>It's true that in response to an oil shock, the Taylor rule would recommend increasing the interest rate to reduce inflation. In practice it would mean that as interest increases, consumption falls. This could be from less credit financed spending, or because the opportunity cost of holding money has increased, therefore people invest more in illiquid assets (bonds in an IS-LM context) and therefore consume less. As consumption falls, aggregate demand falls, therefore putting pressure off prices causing a reduction in inflation.</p>
","7111"
"On the relationship between income distribution and GDP","948","","<p>I was thinking about the following simple example when I wondered what the theoretical effects wealth equality or inequality may have on GDP:</p>

<p>Suppose there is a society with three individuals who have enough money to cater for all their needs, and there is an additional 600 units of disposable income left over.</p>

<p>Let us assume that $S_i$ is the disposable income allocated to person $i$ and let us first assume person $i$ will then spend an amount proportional to $\sqrt{S_i}$ (This assumption is incorrect, but I'm just using it as an example of a non-linear income to expenditure relationship example, which I will compare below with a linear assumption), that is, disposable expenditure would be given by $k\sqrt{S_i}$ for some constant k.</p>

<p>Now if all the excess income was allocated equally among the three members, the total excess expenditure is $k(\sqrt{200} + \sqrt{200} + \sqrt{200}) = 42.43k$.</p>

<p>However if all of the excess income is allocated to a single individual, the total excess expenditure is $k\sqrt{600} = 24.49k$</p>

<p>Thus given the assumption that expenditure is proportional to the square root of disposable income, a lower GDP should be observed in economies with increased inequality of disposable income.</p>

<p>However if expenditure is proportional to the square of disposable income, then it can easily be shown with a similar argument that wealth distribution will increase the GDP in this simple model.</p>

<p>According to modern economics principles, in simple terms how does distribution of disposable income affect GDP?</p>

<p><em>Note:  I'm not interested in the politics behind equality, such as riots and revolutions etc that might result from severe inequality, but merely the financial/economic principles.</em></p>
","<p>You assume that higher spending causes higher GDP. This is not necessarily true. </p>

<p>Saving income will increase GDP through investments (unless you're in a Keynesian trap). Think about the most standard growth model, where the <em>future</em> (and steady state) GDP increases strictly in the savings rate.</p>

<p>Hence, whatever increases the savings rate (in your toy model, higher inequality), potentially increases future GDP. This was an argument brought forward in Barro (2000). Version with linear savings rate are in Bertola et al (2006) </p>

<p>Of course, this is the neoclassical answer. There are many reasons why high inequality decreases growth/GDP which work through political economy models or similar. I'll list some of them despite you not asking explicitly for them, perhaps it's of use for future visitors:</p>

<ul>
<li><strong>Fiscal Policies</strong>: Equality leads to less necessary government redistribution and hence more incentives for investments (Meltzer and Richard, 1981; Corcoran and Evans, 2010; Persson and Tabellini, 1994)</li>
<li><strong>Crime</strong>: Inequality reduces opportunity costs for illegal activities that harm GDP (Alesina and Perotti, 1993; Barro 2000)</li>
<li><strong>Imperfect Credit Markets</strong>: Fixed investment costs or similar may lead to higher growth in unequal societies (Barro 2000)</li>
<li><strong>Saving Incentives</strong>: With ""<em>not much to lose</em>"", poor people face moral hazard in unequal societies, a mechanism that decreases growth with inequality (Banerjee and Newman, 1991)</li>
<li><strong>Fertility-Education</strong>: Equality in human capital leads to smaller fertility rates, and hence lower GDP. The Argument is too long to be summed up here; see Perotti (1996) and Croix and Doepke (2003)) </li>
</ul>
","512"
"Marginal buyer/seller as determinant of price","939","","<p>In competitive markets without frictions, the marginal buyer/seller determine the price. To what extent is this argument true in markets where a fraction of the sellers are constrained? </p>

<p>Think about the labor market. Some workers are optimally supplying labor given their marginal rate of substitution and the wage rate. Some workers are borrowing-constrained such that they have to supply their full labor endowment. </p>

<p>Assume perfect competition on the labor demand side. Under which conditions can we determine the wage rate using first-order condition of the firms and the first type of workers?</p>
","<p>If I have understood correctly, the question asks what should we know so that we can determine the wage using only information on the unconstrained workers. Here is a toy static model:  </p>

<p>Let's say we have $N_u$ unconstrained workers and $N_c$ constrained workers. Each has a total labor endowment $t$. Worker population is denoted $N_c+N_u = N$.
The unconstrained workers will solve a utility maximization problem</p>

<p>$$\max u(c,\ell_u)\;\; \text{s.t.}\;\; c_u = w\ell_u,\;\; u_c&gt;0, u_l&lt;0$$
Subscripts in functions denote derivatives.
The above will give</p>

<p>$$\ell_u^s: wu_c+u_l = 0 \Rightarrow \ell_u^s = h(c,w)$$</p>

<p>The constrained workers will supply each $t$. So total labor supply will be</p>

<p>$$L^s = N_ct + N_uh(c,w) = (N-N_u)t + N_uh(c,w),\;\; h_w&gt;0$$ </p>

<p>(note that some simple utility function forms lead to the supply of labor being independent of the wage. We assume this is not the case here. Also, $h_w&gt;0$ assumes away backward-bending of the individual supply curve).</p>

<p>Since we assume perfect competition (and price taking behavior) on the labor demand side, the firms do not explore possible benefits from the existence of two types of workers. They just go on and equate the marginal product of labor to the market wage</p>

<p>$$\ell^d: MP_L = w \Rightarrow \ell^d = g(w, k_j,T), \;\; g_w &lt;0$$</p>

<p>where $k_j$ is firms capital, and $T$ is technology.
If there are $m$ firms we will have the equilibrium condition</p>

<p>$$L^s = L^d \Rightarrow (N-N_u)t + N_uh(c,w)= mg(w, k_j,T)$$</p>

<p>or writing $n_u = N_u/N$</p>

<p>$$(1-n_u)t + n_uh(c,w)= \left(\frac mN\right)g(w, k_j,T) \tag{1}$$</p>

<p>So if we know the proportion of unconstrained workers, and the total worker population, we can determine the wage from $(1)$, using the first-order conditions related to labor demand, and conditions related to the unconstrained workers.  </p>

<p>If we further assume a Cobb-Douglas production function (constant returns to scale) for the firms, then labor demand will be linear in capital, and so $g(w, X) = \xi(w,T)k_j$. Then $(1)$ becomes</p>

<p>$$(1-n_u)t + n_uh(c,w)= \xi(w,T)\frac {K}{N} \tag{2}$$</p>

<p>Here we need to know only the proportion of unconstrained workers, and the capital per worker.  </p>

<p>Is this what the question asked?</p>
","302"
"How does depreciation affect the cash flow in a tax-paying company?","927","","<p>I came across a question in first year's finance book.The question is: </p>

<p>For a tax-paying firm, an increase in ______will cause the cash flow from assets to increase.</p>

<p>A. Change in net working capital
B. Production costs
C. Depreciation
D. Taxes
E. Net capital spending</p>

<p>C is the right answer, however I am not clear why depreciation increase the cash flow. Thanks for your help.</p>
","<p>Depreciation is tax-deductible. The firm in question pays taxes. If depreciation increases, then taxes paid decrease. If taxes paid decrease, then cash flow increases. <em>ceteris paribus</em></p>
","8152"
"Guess and Verify","926","","<p>In dynamic programming, the method of undetermined coefficients is sometimes known as ""guess and verify.""  I've periodically heard there are canonical guesses one might make.</p>

<p>In particular, I've seen </p>

<p>$V(k) = A + B\ln(k)$</p>

<p>$V(k) = \frac{Bk^{1-\sigma}}{1-\sigma}$</p>

<p>The former applies to log utility while the latter is related to CRRA preferences.  <em>What other canonical guesses exist, and are these generally tied to the particular form of the return function?</em></p>

<p><strong>Edit</strong>: For those not familiar with dynamic programs, what we're trying to do here is come up with closed-forms for the coefficients (<em>e.g.</em> $A$ and $B$).  To over-simplify, the functional equation typically takes the generic form $V(k) = \max\bigl\{F(k,u) +\beta V\bigl(g(k,u)\bigr)\bigr\}$, where $g(\cdot,\cdot)$ describes the evolution of the state variable $k$.  Essentially, the value of being in state $k$ today depends on today's return function $F(k,u)$ and some discounted value of whatever $k$ is going to be tomorrow $\beta V\bigl(g(k,u)\bigr)$.  $u$ represents whatever other non-state variables you think influence the return.</p>

<p>Sometimes it's possible to get a closed-form solution for $V(k)$ (...note: we don't just solve for $V(k)$ since the right-hand side is a maximized quantity).  This typically involves knowing something about the return function $F(k,u)$ and then making a guess about the functional form of $V(k)$.  We can then iterate to see if our guess yields a closed-form solution for $V(k)$.  In particular, this would include closed-forms for the coefficients in the guess (hence the method of undetermined coefficients).</p>
","<p>Another somewhat canonical form is the value function for risk-sensitive preferences when consumption follows a random walk with drift (there are also versions including capital -- see Backus Ferriere Zin 2014).</p>

<p>$$c_t = \mu + c_{t-1} + \sigma_c \varepsilon_{t}$$</p>

<p>Begin with preferences given as Epstein-Zin with a certainty equivalence function of the form $\mu_t(x) = E_t[x_{t+1}^\alpha]^{\frac{1}{\alpha}}$:</p>

<p>$$V_t = \left( (1 - \beta) C_t^{\rho} + \beta \mu_t(V_{t+1}) \right)^{\frac{1}{\rho}}$$</p>

<p>then letting $\rho \rightarrow 0$ gives us</p>

<p>$$V_t = C_t^{1 - \beta} \left[\mu_t(V_t) \right]^{\beta}$$
$$V_t = C_t^{1 - \beta} \left[E_t[V_t^{\alpha}]^{\frac{1}{\alpha}} \right]^{\beta}$$</p>

<p>Taking logs gives us risk-sensitive preferences as presented in Hansen Sargent 1995, Tallarini 2000, etc...</p>

<p>Define $U_t = \log(V_t)/(1-\beta)$ and $\theta = \frac{-1}{(1-\beta) \alpha}$ then we see that:</p>

<p>$$U_t = \log(C_t) - \beta \theta \log \left[ E_t \left[ \exp \left( \frac{-U_{t+1}}{\theta} \right) \right] \right]$$</p>

<p>The form of this value function can be guessed as:</p>

<p>$$U_t = \gamma_0 + \gamma c_t$$</p>

<p>References:</p>

<ul>
<li>David Backus, Axelle Ferriere, and Stanely Zin. Risk and Ambiguity in Models of Business Cycles. Carnegie-Rochester-NYU Conference. 2014.</li>
<li>Lars Ljunqvist and Thomas J. Sargent. Recursive Macroeconomic Theory, 3rd Edition. 2013.</li>
<li>T.D. Tallarini Jr. Risk-sensitive real business cycles. Journal of Monetary Economics. 2000.</li>
<li>L.P. Hansen and T.J. Sargent. Discounted linear exponential quadratic gaussian control. IEEE Trans Automatic Control. 1995.</li>
</ul>

<p>Additional Comment: The two cases you present are more or less covered by the guess $V(k) = A + B \frac{k^{1-\sigma}}{1 - \sigma}$ since this reduces to logs as $\sigma \rightarrow 1$. The guesses are certainly tied to the particular form of the return function as the value function is related to the one period return (reward) function repeatedly obtained throughout an infinite history (if consumption were constant then it would reduce to a geometric sum).</p>
","6524"
"Continuity Axiom in Expected Utility Theory","923","","<p>Take the following definition of continuity.</p>

<blockquote>
  <p>The preference relation $\succsim$ over the space of lotteries
  $\mathcal L$ is continuous if for any $L,L',L''\in\mathcal L$, the
  sets $$S_1=\{\alpha\in[0,1]:\alpha L+(1-\alpha)L'\succsim L''\}$$ and
  $$S_2=\{\alpha\in[0,1]:L''\succsim \alpha L+(1-\alpha)L'\}$$ are both
  closed.</p>
</blockquote>

<p>Is it necessarily true that $S_1\cup S_2=[0,1]$? If so, why?</p>
","<p>It is.<br>
Prior to continuity, which is a <em>property</em> of the preference relation,  the preference relation $\succsim$ itself has been <em>defined</em> to be a binary relation that is characterized by transitivity, and, to begin with,  by <em>completeness</em>.<br>
  Then if $S_1\cup S_2 \neq [0,1]$, it means that there exist some values of $\alpha$ somewhere in $[0,1]$, call them $\tilde \alpha$ for which  </p>

<p>neither </p>

<p>$$\{\tilde \alpha L+(1-\tilde \alpha)L'\succsim L''\}$$</p>

<p>nor </p>

<p>$$\{L''\succsim \tilde \alpha L+(1-\tilde \alpha)L'\}$$</p>

<p>In words, for these $\tilde \alpha$'s, the pair cannot be ordered <em>at all</em>. But this contradicts the completeness foundation that is needed to even obtain a <em>preference</em> relation (as of course used in our theory. Psychologists I guess would disagree). </p>

<p>Also, note that completeness is defined over all conceivable pairs, even if, in a specific situation, we chose to restrict the space of lotteries to something smaller. Whether the lotteries under consideration belong to the specified lottery space, is really irrelevant. The person having the preferences has to be able to order them in any case, even as a ""hypothetical"" scenario (although strictly speaking, for a specific problem we have the ""luxury"" to impose completeness only as regards the lotteries available, while ""remaining agnostic"" as regards completeness if we expand the lottery space. Still this ""weakening"" on the imposition of the completeness axiom, does not really bring any gain).</p>
","8251"
"Relation between linear utility function and U=max{x,y}","921","","<p>I'm studying general equilibrium theory, and in the study guide I came across a utility function of the type $U=\max\{x,y\}$, which I'm not that familiar with. I study mainly from two books: Intermediate microeconomics by Varian and Nicholson's Microeconomic Theory and couldn't find any details about the nature of this kind of utility function in either. </p>

<p>My teachers over the semesters have mentioned some details about it as a curious fact, so I know the choice of the consumer is driven by the relative price of the goods, in this case x and y, so he'll choose to consume the cheaper good, and if the relative prices are equal he'll be indifferent towards both. Also I know the indifference curves have the shape of an inverted L.</p>

<p>What is not clear to me is how is it related to the Perfect Substitutes utility function since both seem extremely similar to me, but the indifference curves are very different. </p>

<ul>
<li><p>Is the utility function $U=\max\{x,y\}$ a more general case?</p></li>
<li><p>More importantly, when the relative prices are the same, how can we illustrate consumer's choice in that inverted L indifference curve, doesn't it turn linear?</p></li>
</ul>
","<p><strong>The optimal choice set for a max function and a perfect substitutes function with equal relative prices share some solutions [i.e, boundary solutions], but in general, the indifference curves, and hence non-boundary solutions, are different.</strong></p>

<h1>Main Idea</h1>

<p>For both a max(x1 x2) and perfect_sub(x1 x2) utility function, the point, say, <code>m/p1</code> (or <code>m/p2</code>) would maximize utility. So both utility functions share boundary solutions. But think about the IC of <code>m/p1</code> for a perf_subs consumer and think about the IC of <code>m/p1</code> for a max consumer. You see the points that the two consumers think are 'just as good' as that <code>m/p1</code> point are very different.</p>

<p>That is, the same boundary bundle might be a solution to both utility functions, but the other solutions will differ. </p>

<h1>Logic</h1>

<p>The reason is that U = perfect_subs is a (not-strictly) convex utility function, whereas U = max isn't. That is: the consumer is either indifferent between, or actually prefers, less extreme combinations to more extreme combinations for the former. As for the latter? Well, they just care about the max; they like extreme combinations (e.g, [C = (<code>m/p1, 0</code>)]) </p>

<p>That's why for U = perfect_subs with relative prices the same, both A = <code>(100,0)</code> and B = <code>(ß(x1), (1-ß)x2)</code> have the same utility. That is,B lies on a straight line IC connecting (100, 0) to (0, 100). Whereas for U = max(x1 x2), B would not be on the same IC as A (unless ß is 0 or 1, in which case, we're back to talking about boundary solutions!) </p>

<p>The word, <code>max</code> is confusing here. Essentially, the perfect_subs (x1 x2) consumer wants to maximize total goods. The max(x1 x2) consumer just cares about maximizing the larger quantity in his {x1, x2} bundle. </p>

<h1>Tl;DR</h1>

<p><strong>To be more concrete: If A = <code>(100,0)</code> and B = <code>(75, 25)</code>, a perf_subs consumer is indifferent between A and B; a max consumer is not.</strong> </p>
","15767"
"Why life expectance is growing faster than retirement age? - source needed","918","","<p><strong>Need sources of information about</strong> ""Why is life expectancy growing faster than retirement age?"" </p>

<p>Is there any literature about ""why the increased quality of life and medicine in rich countries doesn’t increase the ability to work for older people?""</p>
","<p>Loss-aversion and political tactics.</p>

<p>A lot of the elderly are no longer physical broke down - which was the original reason for retirement. But, if you can retire in good health, it is completely rational for the individual to do this, and to vote for the politicians who will provide this for you. </p>

<p>Or, as a danish mayor once put it: </p>

<blockquote>
  <p>""When you first throw something into the monky cage, it is hard to
  get it back again""</p>
</blockquote>

<p>Aka, when you first give people major entitlements and life improvements, it is next to political impossible to take them away. </p>
","5626"
"Why is perfect price inelasticity of demand not considered an exception to the law of demand?","916","","<p>Assume a case of perfect price inelasticity of demand. </p>

<p><a href=""https://i.stack.imgur.com/PAXFR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PAXFR.png"" alt=""Graph depicting perfect price inelasticity""></a>
<br> 
In such a case, </p>

<blockquote>
  <p>PED = 0</p>
</blockquote>

<p>The quantity demanded does not respond to changes in price, i.e. it remains constant, even when price increases or decreases (instead of falling or rising, as it should if it conformed to the inverse relation defined by the law of demand).</p>

<p>Thus, shouldn't perfect price inelasticity also be considered as an exception to the law of demand, just as Giffen goods and Veblen goods are?</p>
","<p>Because although some goods have perfect inelasticity over some interval, they are not perfectly inelastic over the whole demand curve - over the rest of the curve, quantity and demand will be strictly inversely related. And the law of demand doesn't have a ""strictly"" in there. Price and quantity are inversely related, but not <em>strictly</em> so, which (in the mathematical sense) means that parts of the demand curve are allowed to be perfectly inelastic.</p>
","8262"
"Does immiserizing growth exist outside of theory?","914","","<p>For a course in international trade, our professor touched on the idea of <a href=""http://en.wikipedia.org/wiki/Immiserizing_growth"">immiserizering growth</a>.  He emphasized that immiserizing growth was a <strong>theoretical</strong> outcome from specialization of trade and did not provide the class with examples on the global market.<br>
What are some real world examples of immizerizing growth?</p>
","<p>The concept of <strong>immiserizing growth</strong> describes a situation where a mainly exporter country that grows, finds itself worse-off because the terms of trade (relative prices) change too much against it.  </p>

<p>Immiserizing growth has generated some theoretical interest in the past, and various situations have been determined under which such a phenomenon may arise, enhancing the original contributions by<br>
<a href=""http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9957.1955.tb00960.x/full"" rel=""nofollow"">Johnson, Harry G. 1955. ""Economic Expansion and International Trade,"" Manchester School 23, pp. 95-112</a><br>
and<br>
<a href=""http://www.jstor.org/stable/2295990"" rel=""nofollow"">Bhagwati, Jagdish. 1958. ""Immiserizing Growth: A Geometrical Note,"" Review of Economic Studies 25, (June), pp. 201-205.</a></p>

<p>I do not know of any real-world example though. On the contrary some studies have been conducted which have estimated the critical values for the variables of a real-world economy, in order for it to face the possibility of immiserizing growth-and these thresholds are not observed in practice.  </p>

<p>As an example, <strong>Ramon Lopez (1991)</strong>, in <a href=""https://ideas.repec.org/p/wbk/wbrwps/665.html"" rel=""nofollow"">""Microeconomic Distortions: Static Losses and their Effect on the Efficiency of Investment""</a>, studying the economy of Chile for the period 1974-1989, estimated that, under full employment, the critical tariff rate for the prospect of immiserizing growth to arise would be $185$%, while with unemployment, it would be $260$%, which are too high compared to observed tariff rates.</p>

<p>The real concern about International Trade is its <em>distributional effects inside each country</em>, i.e. whether it creates ""misery"" for <em>part</em> of the population, while benefiting some other part. This is also ""immiserizing growth"" (for some of the citizens) but not in the sense meant by the scholars that originally coined the term. </p>
","418"
"How exactly does money supply causes inflation?","904","","<p>I think there's consensus among economists that a growth in money supply (I'm not thinking in any particular type of money supply) causes inflation (CPI), at least, in the long run.
What I'm interested in is the exact mechanism for that phenomenon. How ""printing more bills"" makes the price of, say, milk in the local supermarket raise? How does the people who set prices know that there's more money in circulation than before so it's time for a raise?</p>

<p>Thank you in advance.</p>
","<p>The view that money growth causes inflation may have been a consensus view during the (old) Monetarist era, but it is unclear whether that still holds. </p>

<p>(One somewhat related question here discusses whether inflation can occur without money supply growth - <a href=""https://economics.stackexchange.com/questions/9767/inflation-without-increase-in-money-supply"">link</a>)</p>

<p>As seen in the data around Quantitative Easing, we certainly see deviations between money supply growth and inflation ""in the short term.""</p>

<p>In the ""long run"" (which is what you asked about), it is unclear what causes what. Other than in Monetarist models (which are arguably no longer consensus), the money supply is determined by a portfolio allocation by the household sector. That is, people hold money instead of interest-bearing bonds for whatever reasons. What policymakers control is the policy rate of interest. Therefore, money growth is an outcome of the policy environment, like the inflation rate. In other words, faster nominal GDP growth (and hence inflation) tends to cause faster money supply growth.</p>

<p>However, if we want to assume that policy makers are controlling the money supply, and that money growth indeed causes inflation, modern theories would probably lean on the following two mechanisms.</p>

<ol>
<li>Money does not just appear; it is a government liability, and the growth of government liabilities implies fiscal deficits. That is, loose fiscal policy raises demand, and causes inflation.</li>
<li>Expectations. If people are convinced that money supply growth causes inflation, they will watch the published money supply numbers. (In the United States, money numbers are published weekly, and were followed closely during the early 1980s. Currently, I doubt that 10% of bond traders under the age of 30 know what day of the week money numbers are published on.) They will raise prices based on what they think the money supply is doing now, and what they forecast it will be doing. I am not expert on Market Monetarism (the modern offshoot of ""old Monetarism"") but I believe that they emphasise this effect; although they might phrase things differently.</li>
</ol>
","16901"
"statistical discrimination VS taste based discrimination","900","","<p>Given the progress in the literature on economics of discrimination. What is the reason for still believing in the dichotomy taste-based VS statistical discrimination. I think the first theory is just a specific case of statistical discrimination, where information on discriminated workers' productivity is weighted by the discrimination coefficient (which basically is just a scaling factor). Any attempt to disentangle the two types of discrimination is pointless. Or?</p>
","<p>You will find below two good and recent surveys on the literature on economics of discrimination and they all point out a clear difference between taste-based and statistical discrimination. We can imagine a situation where the employer's information about workers' productivity is perfect, such that there is no statistical discrimination, and still observe a racial wage discrimination for example because the employer has a taste for discrimination. Knowing the source of discrimination seems crucial to fight against discrimination and its consequences.</p>

<p>Charles, K. K., and J. Guryan (2011): “Studying Discrimination: Fundamental
Challenges and Recent Progress,” Annual Review of Economics,
3(1), 479–511.</p>

<p>Lang, K., and J.-Y. K. Lehmann (2012): “Racial Discrimination in the
Labor Market: Theory and Empirics,” Journal of Economic Literature,
50(4), 959–1006.</p>
","10518"
"Perfect competition: Finding short run equilibrium price?","888","","<p>I am trying to self teach myself some Economics, I am using an old textbook given to me by a friend, which does not contain an answer key. I have run into the following problem and I was wondering if anyone could guide me (I don't want the answers, I just want to understand the method).</p>

<p>The firms in a perfectly competitive industry have a cost function given by:</p>

<p>$c(w_{1},w_{2},Y)= Y^{2} (w_{1}, w_{2})^{\frac{1}{2}} + 8$</p>

<p>Where $(w_{1},w_{2})=(4,25)$</p>

<p>The market demand in this industry is $D(p)=40-p$</p>

<p>The number of firms in this industry are $30$, I'm not sure if this ties in with this half of the question or not.</p>

<p>Anyways, what I have done so far is computed the total cost function:</p>

<p>$TC= 10Y^{2} +8$</p>

<p>From this point, how can I proceed onwards to find the short run equilibrium price?</p>

<p>I would appreciate it if anyone could offer some advice.</p>

<p>Thanks.</p>
","<p>These kinds of questions depend heavily on the market structure that you assume. Most importantly, when firms have (some degree of) market power, they usually take the demand function as given and try to solve something of the kind</p>

<p>$$ \max_p D(p)\cdot (p-c(D(p)))$$</p>

<p>However here, when there is no market power, firms take the price as given and solve for the optimal quantity of production $q$:</p>

<p>$$ \max_q q\cdot (p-c(Q))$$</p>

<p>Then, we get the supply of any single firm, given the price $S(p)$ from solving this problem. To clear the perfectly competitive market, we remember that there are $30$ firms and solve:</p>

<p>$$p: D(p) - 30\cdot S(p) = 0$$</p>
","3298"
"In the short run, why do higher interest rate lower inflation?","887","","<p>A common interpretation is ""Higher interest rates put less borrowing power in the hands of consumers and businesses. And when they spend less, firms are not selling everything and prices naturally falls."" In the perspective of AS-AD model, this is caused by a downward shift of the demand curve. </p>

<p>However, I suppose it will cause a supply curve shift as well. Today, most production is funded by short-term borrowing and relied on people paying them for the goods and then pay back the loans. So when the interest rate goes up, the production costs go up, and hence causing a negative supply shock as well. </p>

<p>But reality seems to confirm the fact that higher interest rate lower inflation. Why is that? Is that because the supply shock is not as significant as the demand shock? If so, why is that?</p>
","<blockquote>
  <p><strong>In the short run, why do higher interest rate lower inflation?</strong></p>
</blockquote>

<p>As you say:</p>

<blockquote>
  <p>""Higher interest rates put less borrowing power in the hands of consumers and businesses. And when they spend less, firms are not selling everything and prices naturally falls.""</p>
</blockquote>

<p>There's also the effect on the velocity of money and the money supply that less borrowing brings to provide further downward pressure on prices.</p>

<p>I also think your concerns about supply falling in the short term are unfounded. Firms are slow to adjust their production/supply due to greater borrowing costs. Instead, they will attempt to keep up production and clear their inventories by lowering prices in the hopes that the next season will show them a success and bail them out. Any such effect from interest rates would be a much longer-run effect.</p>
","9460"
"What are the effects of the increase/decrease in stock options after an IPO?","872","","<p><strong>Research :</strong> </p>

<p>As far as I can understand :</p>

<ul>
<li><p>Stock options are used to increase the capital of companies to realize some projects</p></li>
<li><p>Shares are divided into two categories : </p>

<p>o    Free float (which is the part of shares important for my next question)<br>
o    Locked-in stock   </p></li>
</ul>

<p>For the free float, it’s easy to understand. Public investors can earn money by playing with stock prices.
For the company it’s harder for me to understand.
    When a company wants capital to run projects, she can do an IPO. The initial price depending on the financial situation.</p>

<p><strong>Question :</strong>  What are the effects of the increase/decrease of stock prices after that IPO ? </p>

<p>For exemple : Initial stock price was 20 dollars and public investors paid 20 dollars which got into the capital of the companies. If stock price is now 25dollars, company won’t earn 5dollars more. So what’s the point for the company to be devalued after an IPO if she got the amount of capital she wanted ?</p>

<p><strong>Attempt :</strong> </p>

<p>I saw only 2 easy solutions :<br>
-   If company wants to increase capital a second time, she needs to have a big value on the market to reduce the dilution of control.<br>
-   If company is too much devalued, she can be acquired by concurrents.<br>
If company doesnt decrease too much and doesnt want to increase capital again, she has no point regarding the increase/decrease of her stock prices, right ? </p>
","<p>Exactly.  The main issue is if they want to raise capital a second time. The secondary market does not affect the company itself, but it affects its investors. And as investors are important, they need to be treated well.  Another problem related to this is that several employees in the company have stock options, so it really affects them.</p>

<p>What companies can do also is buy their own stocks if the price dropped considerably. This is not something that happens right after the IPO because it would make no sense to return the money to the markets right after you received it.</p>

<p>So, to sum up, the direct effects for the company are on the primary market (when the company makes the IPO), the secondary market is between public investors that have little to do with the company.</p>
","316"
"What is an example of a choice which is not necessitated by scarcity?","871","","<p>I am first year economics student and for the past month we have had it constantly drilled into us that all choices have an opportunity cost and thus they are all necessitated by scarcity. Thus when I saw this quesiton in my homework I was baffled. </p>

<p>I don't need an exact answer to this, but a hint would be great. My current line of thinking is leaning towards infinite resources like the sun, but I simply can't work it out. Thanks.</p>
","<p>The basic idea behind scarcity and opportunity cost is fundamental to economics. Basically, if resources are infinite, you have everything.</p>

<p>In my opinion, there are no infinite resources because a lifetime is finite. In one way or another, it can be argued all choices are necessitated by scarcity.</p>

<p>Eating chips means at that time, you cant be eating a burger. That is your opportunity cost.</p>

<p>This may be the point of your homework question, to make you realise that scarcity is a key driving force behind decision making.</p>
","4541"
"What is the difference between aggregate supply and GDP?","866","","<p>Usually when I read online, I see the following repeated frequently: aggregate demand is equal to GDP. I understand that aggregate expenditures is the aggregate demand at a particular price level, and that sometimes AE will exceed GDP (causing growth in GDP) and vice versa, according to the Keynesian cross model.</p>

<p>Obviously at equilibrium, AS = AD = GDP. But I've never seen anywhere that aggregate supply in general is equal to GDP. Yet this definition makes more sense to me.</p>

<p>One definition that I've seen for aggregate supply is ""the total supply of goods and services produced within an economy at a given overall price level in a given time period"" (<a href=""https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=3&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwje9bLVv7DOAhUrxYMKHVuLC-0QFgg2MAI&amp;url=http%3A%2F%2Fwww.investopedia.com%2Fterms%2Fa%2Faggregatesupply.asp&amp;usg=AFQjCNGoD7SoeccO0KOawQH1AJ2NYQ9r2w&amp;sig2=Ov5Atfc-geUEjCe7qs_3hg"" rel=""nofollow"">source</a>). Another that I've seen is ""the total supply of goods and services that firms in a national economy plan on selling during a specific time period"" (Wikipedia).</p>

<p><strong>Which of these definitions is correct?</strong> If it's the latter, I can see some obvious differences (it doesn't include inventories, for example). <strong>But if it's the former, that seems to be the same as GDP</strong>: ""the monetary value of all goods and services produced within a nation's geographic borders over a specified period of time."" To rephrase, <strong>how is the concept of aggregate output distinguished from aggregate supply?</strong> I guess the first two questions should naturally answer this last one, since aggregate output is GDP.</p>
","<p>Per my understanding, AS and GDP are the same thing. However, the term AS is more often used in the context of ""curves"" to describe the relationship between inflation rate and the supply side.</p>
","12981"
"What is a rational consumer?","865","","<p>There is a lot of debate on whether or not consumers and investors are rational. Unfortunately, I haven't seen much qualification for what is called a <strong>rational consumer</strong>.  What are the requirements that must be met for us to consider a consumer to be rational?</p>
","<p>In consumer theory, <strong>preferences</strong> are called rational if they are transitive and complete. Some nomenclature: An alternative A is weakly preferred to another alternative B, if you either like A more than B or you are indifferent between the two. Transitive means that whenever an alternative A is weakly preferred to alternative B, and B is weakly preferred to C, then A is weakly preferred to C. Complete means that for any two elements A and B of the set of possible alternatives, either A is weakly preferred to B, B is weakly preferred to A, or both. In short, preferences are rational when they are defined for all possible alternatives, and when they don't contradict each other in obvious ways.</p>

<p>Rational <strong>expectations</strong> are a different beast and are specific to different models. Agents in a model have rational expectations if they use the model to form expectations about the future. This means that expectations are consistent with the model/theory in question, and it also means that every rational expectations model has a different ""theory"" about how people form their expectations. Rational expectations are as much a concept to solve dynamic models as they are an assertion on people's behavior. They are commonly used because they make sure that people are not systematically wrong about their beliefs, and they keep models' properties from being driven by more arbitrary assumptions on how people form expectations. </p>

<p>I don't think there is a lot of thought going into alternatives to rational preferences and most people are content with making the assumption that preferences are rational. There is a big literature in macro and finance on relaxing rational expectations assumptions. A lot of people work with models of bounded rationality, in which agents use a simpler approximation to the true model to form expectations.</p>
","17739"
"Why doesn't Costco simply raise prices and nix the membership fee?","865","","<p>I know little about the field of economics. I realize this question may be too rudimentary for this forum but I am sure someone here can explain this.</p>

<p>My question concerns <strong>Costco</strong>, which is a wholesale retailer that sells groceries, as well as electronics, clothes, and home goods. <strong>To even enter the store, one must have a Costco membership.</strong>  </p>

<p>My question is simple: What purpose does the Costco membership fee serve? More specifically, why doesn't Costco get rid of the the whole ""paid membership"" idea, open its doors to anyone and everyone, and raise its prices to make up for the lost revenue? </p>

<p>Costco basically offers two different memberships, the standard membership with an annual fee of \$55 and the Executive membership costing \$110. The primary benefit of the Executive membership is that members receive 2% cash back on every Costco purchase (which is in addition to whatever cash back your credit card is earning for you). Thus, it only makes sense to purchase the Executive membership if one's yearly spending at Costco exceeds \$2,750 per year.</p>

<p>This is Costco's defense:</p>

<blockquote>
  <p>""Costco's membership fee provides a means of covering part of our operating costs and overheads thereby reducing our prices on the products we sell. This way the more members we have, the lower our prices and the more you buy, the more you save.""</p>
</blockquote>

<p>If Costco did not require a membership fee, Costco would generate more revenue from a significant increase in customers. Costco could raise prices slightly on every item to compensate for the loss.</p>

<p>If Costco is indeed making the smart decision economically by requiring a membership fee, then why don't more stores adopt this model?</p>
","<p>I agree with @Alecos Papadopoulos that this is probably a marketing/product differentiation trick. You attract a specific type of consumers with a specific mindset.</p>

<p>Another theoretical explanation also exists: <br>
This could be a version of second degree price discrimination. Costco may maximize its profits by selling at different prices to bulk buyers and small quantity consumers. If it would simply set two prices no one would make purchases at a higher price. By collecting a club card fee and then charging a lower price Costco can make sure that only bulk buyers will choose this option, thus achieving price discrimination.</p>
","8232"
"Why protectionism is bad?","865","","<p>can you please explain from the economic point of view, why protectionism is bad? If sometimes it is sensible to protect some industries to avoid unemployment, loses of some professionals, death of the industry and decreasing independence? What do you think? tnx</p>
","<p>To add to the other comments here - when you allow for free trade to prosper countries/regions tend to specialize in what they are good at producing/creating (idea of comparative advantage).  This leads to better products created more efficiently.  Note that this idea has no care for unemployment rates in certain countries, it simply states that as a whole we are all better off.</p>

<p>You may have heard that some people (often unskilled laborers) are ""left behind"" by globalization, particularly in developed nations such as the US (think auto industry).  To think like an economist these people ought to re-appropriate their efforts to developing a skill that is useful in their new environment.  However, that isn't always plausible for many people, which is where you can argue that government should step in and help them learn new and useful skills (preferable to protecting an inefficient industry).</p>

<p>Protectionism tends to dampen productivity and efficiency thus often leading to inferior goods that cost more to the consumer.</p>
","12755"
"Books for microeconomics and macroeconomics for selected topics","861","","<p>I am a mathematics undergraduate trying to self-learn some economics. I have no background in economics. I wish to know from which chapters of Hal Varian's ""Intermediate Microeconomics"" (7th edition) should I study for the following topics:</p>

<pre><code>Microeconomics: Theory of consumer behaviour, theory of production,
market structure under perfect competition, monopoly, price discrimination,
duopoly with Cournot and Bertrand competition (elementary problems) and
welfare economics.

Macroeconomics: National income accounting, simple Keynesian Model of
income determination and the multiplier, IS-LM Model, models of aggregate
demand and aggregate supply, Harrod-Domar and Solow models of growth,
money, banking and inflation.
</code></pre>

<p>Regarding the macroeconomics part, I still do not know which book to follow and which chapters to read. It would help me a lot, if someone can guide me in this. Since the headings of the chapters differ from the names of these topics, I am unsure which portions to read without any expert's help.</p>

<p>P.S.: I am unsure if this is the right place for me to ask such a question.</p>
","<p>From Varian (7th edition):</p>

<ul>
<li>Consumer behavior: at least chapters 1–6; preferably also chapters 7, 8, and 12.</li>
<li>Perfect competition and Theory of production: chapters 15, 16, and 18-23.</li>
<li>Monopoly price discrimination: chapter 25 (you might want to look at chapter 24; it seems a bit odd to study price discrimination without first looking at a non-discriminating monopolist).</li>
<li>Bertrand/Cournot duopoly: chapter 27.</li>
<li>Welfare economics is a bit tougher, because this could mean a number of things. I would suggest chapters 31 and 33 (and maybe chapters 32, 34 and 36).</li>
</ul>
","3105"
"How can I learn about economics?","857","","<p>I'm a civil engineering student and I'm interested in economics and I would like to learn everything about it. I would like to learn everything from banks to the stock markets and everything there is to learn about. I always read articles about stocks and the market but I feel really ignorant. Can you recommend me some introductory books or some learning ressources? 
Thank you in advance.</p>
","<p>I would recommend Tim Harford's ""The Undercover Economist"" for an easy way to get some exposure to how economists think, without having to go through all of the dry academic mathematics etc.</p>

<p>To get a sense of the shape of the economics discipline, you might also like to look at ""Economics: A Very Short Introduction"" by Partha Dasgupta.</p>

<p>Lastly, if you really want to get into the discipline and you want a slightly more formalised/academic treatment then any good introductory textbook should do. N. Gregory Mankiw's ""Economics"" is a popular choice.</p>

<hr>

<p>The above describes how you might go about learning about economics. But <strong>from your question, it seems more like you are more interested in learning about finance</strong>, which is the discipline that encompasses the study financial markets, etc. I learnt finance from a book called ""Introduction to Finance"" by Lawrence J. Gitman and Jeff Madura, but there doesn't seem to be a recent edition so perhaps someone else can recommend a more recent introduction to the subject.</p>
","5079"
"Infinite Horizon Transversality Condition","855","","<p>This question is an extension of <a href=""https://economics.stackexchange.com/questions/11531/endogenous-growth-balanced-growth-path-with-crra-utility"">Endogenous Growth: Balanced Growth Path with CRRA Utility</a>

however, this question asks about a specific concept used in that question, and I think it would be helpful to have a question dedicated to this concept. </p>

<p>We will use the model in this question:</p>

<blockquote>
  <p>$\textbf{Model:}$
  $$K_t=\frac{1}{n}\sum_{t=1}^nk_t$$
  In this model, $k_t$ is chosen by agents, and $K_t=\bar{k}_t$ (the average of all $k_t$).</p>
  
  <p>Now, agents want to dynamically maximize utility (under certain constraints) and they have CRRA (constant relative risk aversion) utility, so the maximization looks like:
  $$\sum_{t=0}^\infty\beta^t\bigg(\frac{c_t^{1-\gamma}}{1-\gamma}\bigg)$$
  $$s.t.\;Y_t=k_t^\alpha(E_tL)^{1-\alpha}$$
  $$c_t+i_t=Y_t$$
  $$k_{t+1}=(1-\delta)k_t+i_t$$
  $$c_t,i_t\geq0$$</p>
  
  <p>$E_tL$ is effective labor and the rest of the variables are typical  (I can give their definitions if requested).</p>
  
  <p>One last addition to the model is that there are two equilibrium constraints:
  $$E_t=\frac{K_t}{L}$$
  $$k_t=K_t$$ </p>
</blockquote>

<p>In the answers section, I was instructed to use transversality conditions and inada conditions in order to show that a balanced growth path is optimal. Below is my derivation of the transversality condition:</p>

<p>First, we must derive the finite horizon transversality condition. We do this by solving:
$$\underset{\{k_t\}_{t=0}^{T+1}}{max}\;\sum_{t=0}^{T}\beta^tU(\frac{}{})$$
$$s.t.\;k_{T+1}\geq0$$
With our model that means:
$$\underset{\{k_t\}_{t=0}^{T+1}}{max}\;\sum_{t=0}^{T}\beta^t\bigg(\frac{((1+1-\delta)k_t-k_{t+1})^{1-\gamma}}{1-\gamma}\bigg)$$
$$s.t.\;k_{T+1}\geq0$$</p>

<p>Our Lagrangian is:
$$\ell(\frac{}{})=\sum_{t=0}^{T}\beta^t\bigg(\frac{((1+1-\delta)k_t-k_{t+1})^{1-\gamma}}{1-\gamma}\bigg)+\lambda k_{T+1}$$</p>

<p>In order to get the transversality condition, we differentiate with respect to $k_{T+1}$ and use the constraint.</p>

<p>FOC:
$$\frac{\beta^T}{((1+(1-\delta))k_T-k_{T+1})^\gamma}=\lambda \qquad (1)$$
$$\lambda k_{T+1}=0 \qquad (2)$$ 
$$\lambda , k_{T+1}\geq 0 \qquad (3)$$
Solving this system, we get $\textbf{the finite horizon transversality condition is:}$
$$\bigg(\frac{\beta^T}{((1+(1-\delta))k_T-k_{T+1})^\gamma}\bigg)k_{T+1}=0$$
Now, in order to get the infinite horizon transversality condition, we maximize the discounted utility function again, but we set the limit of finite horizon transversality condition as $T\rightarrow \infty$ equal to 0 as the constraint.</p>

<p>This means that we have to solve:
$$\underset{\{k_t\}_{t=0}^\infty}{max}\;\sum_{t=0}^\infty\beta^t\bigg(\frac{((1+(1-\delta))k_t-k_{t+1})^{1-\gamma}}{1-\gamma}\bigg)$$
$$s.t.\; \underset{T\rightarrow\infty}{lim}\;\bigg[\bigg(\frac{\beta^T}{((1+(1-\delta))k_T-k_{T+1})^\gamma}\bigg)k_{T+1}\bigg]=0$$ </p>

<p>This is where my question comes. How do we solve this? Can we use a lagrangian? If so, how do we take first order conditions in the presence of the limit? Any help would be greatly appreciated!</p>
","<p>Your confusion comes from the fact that you treat the Transversality condition as a <em>constraint</em>, while it is a <em>condition for optimality</em>. So the formulation at the end of your question is wrong. What you do is you solve your model as usual, and <em>then</em> check if the solution (here the balanced growth path) satisfies the Transversality condition.</p>

<p>The Transversality condition (TVC) is</p>

<p>$$\lim_{t \rightarrow \infty} \beta^t u'(c_t)k_{t+1} =0$$</p>

<p>In your model, $u'(c_t) = c_t^{-\gamma}$ and $c_t = (2-\delta)k_t - k_{t+1}$</p>

<p>So the TVC becomes indeed</p>

<p>$$\lim_{t \rightarrow \infty} \frac {\beta^tk_{t+1}}{[(2-\delta)k_t - k_{t+1}]^{\gamma}} =0$$</p>

<p>What we want is to check whether the (unique) balanced growth path satisfies the Transversality condition. On the balanced growth path we have $k_{t+1} = (1+g)k_t$ where $g$ is a constant determined by the exogenous parameters of the model and the optimizing conditions. So when on the balanced growth path, the TVC becomes</p>

<p>$$\lim_{t \rightarrow \infty} \frac {\beta^t(1+g)k_t}{[(2-\delta)k_t - (1+g)k_t]^{\gamma}} = \lim_{t \rightarrow \infty}\frac {(1+g)}{(1-\delta-g)^{\gamma}}\beta^t k_t^{1-\gamma}=0$$</p>

<p>The constants are unimportant, so we want that</p>

<p>$$\lim_{t \rightarrow \infty}\beta^t k_t^{1-\gamma}=0$$</p>

<p>holds. Note that if $\gamma \geq 1$ (which is the consensus in the literature) the condition does hold, since capital goes in the denominator, and we're done. </p>

<p>For the case $\gamma &lt;1$, we want the expression to hold at the limit only, i.e. <em>eventually</em> . ""Eventually"" implies that, if $k^*_s$ is the level of capital at time $s&lt;t$ when the economy arrives at the balanced growth path, we will have $k_t = k_s^*\cdot (1+g)^{t-s}$. Then the TVC becomes</p>

<p>$$\lim_{t \rightarrow \infty}\beta^t \big[k_s^*\cdot (1+g)^{t-s}\big]^{1-\gamma}=0$$</p>

<p>Again, shed things that do not depend on $t$, to get</p>

<p>$$\lim_{t \rightarrow \infty}\beta^t (1+g)^{(1-\gamma)t}=0 \implies \lim_{t \rightarrow \infty}\big[\beta (1+g)^{(1-\gamma)}\big]^t=0$$</p>

<p>So the TVC will hold if and only if</p>

<p>$$\beta (1+g)^{(1-\gamma)} &lt;1$$</p>

<p>In the other question the OP has obtained</p>

<p>$$1+g = [\beta(\alpha+1-\delta)]^{\frac{1}{\gamma}}$$</p>

<p>Substituting, we want</p>

<p>$$\beta \Big([\beta(\alpha+1-\delta)]^{1/\gamma}\Big)^{(1-\gamma)} &lt;1$$</p>

<p>This can be simplified a bit, and it is a restriction on the parameters that must hold in order for the balanced growth path to satisfy the Transversality condition (when $\gamma &lt;1$). For baseline values of the other parameters one can see that the condition is not likely to be satisfied.</p>
","11866"
"Does a strong US Dollar hurt American Manufacturing?","853","","<p>I am reading this article about the strengthening of the US Dollar when I came across this paragraph: </p>

<p>""But there are reasons to be cautious. A strong dollar will squeeze American manufacturers, which have otherwise benefited from falling energy prices and rising wages in China. That will weigh on growth in the United States and further suppress inflation, which is already well below the Fed’s target.""</p>

<p>Am I understanding it correctly that because the Dollar is getting stronger that it will hurt American Manufacturers?</p>

<p>Source article: <a href=""http://www.msn.com/en-us/money/markets/the-dollar-keeps-rising-for-good-or-evil/ar-BBoJUq2?li=BBnb7Kz&amp;ocid=iehp"">http://www.msn.com/en-us/money/markets/the-dollar-keeps-rising-for-good-or-evil/ar-BBoJUq2?li=BBnb7Kz&amp;ocid=iehp</a></p>
","<p>Most manufactured products are sold domestically, but even so a strong dollar will (usually) cause a decline in sales and profitability of US manufacturers. The reason for this is that a strong dollar makes foreign products relatively cheaper, not just manufactured products, but all products. Therefore it becomes cheaper for person to buy, say a foreign-made washing machine compared to an American-made washing machine.</p>

<p>What news articles like this don't mention is that a weak dollar hurts Americans because it makes everything they buy, like gasoline, more expensive, not just manufactured goods.</p>

<p>The exception to the rule is during wartime. For example, as a result of World War II the United States dollar became stronger AND manufacturing profitability increased at the same time. But this was because competitors in Europe had all their factories in ruins, which is not the case today obviously.</p>
","10411"
"Calculating nominal GDP","848","","<p>I would like to understand one detail of how nominal GDP of a country in a given year is calculated. It seems to me that the GDP in each country is first calculated in the national currency and then is converted to dollars. Is this correct?</p>

<p>If yes, how can one make this conversion if a currency can weaken of strengthen itself significantly with respect to dollar within a year?</p>

<p>Here is the list of such GDP's per country per year in US dollars:
<a href=""http://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)"">http://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)</a></p>

<p>For example take Russia, GDP in 2013 was 2,096,774 million dollars and in 2014 it is 2,057,000 million dollars.</p>

<p>Now, we know that the rouble weakened significantly in 2014, (almost twice). So it looks like Russian GDP in dollars should have dropped significantly as well. But it had not done so. Why?</p>
","<p>There is no need to complicate things here - just try to find <strong>annual exchange rate</strong> used by IMF. Worldbank's data are <a href=""http://data.worldbank.org/indicator/PA.NUS.FCRF?order=wbapi_data_value_2014+wbapi_data_value+wbapi_data_value-last&amp;sort=asc"" rel=""nofollow"">here</a>. LCU stands for Local Currency Units<br>You may see a drop of <code>Rub/$</code> rate from 31.84 to 38.38. (Drop of Ruble, of course.)
<br>National statistics provides input figures for international accounts. <br>According to Rosstat, Russian <strong>nominal</strong> <a href=""http://www.gks.ru/wps/wcm/connect/rosstat_main/rosstat/ru/rates/46880c804a41fb53bdcebf78e6889fb6"" rel=""nofollow"">GDP</a> grew in the Y2014: </p>

<ul>
<li>Y2013 - 66,190 bil. <code>Rub</code>, </li>
<li>Y2014 - 71,406 bil. <code>Rub</code>. 
<br></li>
</ul>

<p>Using  NGDP dollar evaluation from your post, annual exchange rate for Y2013 is 31.5 <code>Rub/$</code>; in Y2014 rate is 34.7 <code>Rub/$</code>, which makes some sense. <br>But indeed <code>Rub/$</code> rate was somewhat closer to 38.5 (<a href=""http://www.ozforex.com.au/forex-tools/historical-rate-tools/yearly-average-rates"" rel=""nofollow"">see here</a>). So, IMF figure for the Y2014 from your wiki reference seems to be more correct: bil. <code>$</code>1,857,461 for Russian NGDP. (do not forget about Crimea correction to appreciate the difference).<br>
So, in fact Russian nominal GDP did drop significantly in current dollar terms in the Y2014. 
<br>Imho, PPP is not applicable for your question as Russian GDP by <a href=""http://en.wikipedia.org/wiki/List_of_countries_by_GDP_(PPP)"" rel=""nofollow"">PPP</a> is of different magnitude. </p>
","6019"
"Why is the short run average cost curve not a tangent to the long run average cost curve at the lowest point on the short run average cost curve?","847","","<p>The diagram from the Varian textbook shows that the SRAC curve is tangent to the LRAC curve at a point which is not the bottom of the SRAC curve. It would be really helpful if someone could explain this.</p>

<p><a href=""https://i.stack.imgur.com/4lQBF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4lQBF.png"" alt=""enter image description here""></a></p>
","<p>The diagram is fine as an illustration of a possible relation between the long run average cost curve and <em>one particular</em> short run average cost curve.</p>

<p>Long run in the context of a firm's cost functions means that all inputs are free to vary, so it makes sense to refer to <em>the</em> long run cost curve.  Short run means that one or more inputs (eg capital equipment) are fixed.  Since these inputs could be fixed at different levels, there are many different short run cost curves. The long run cost curve is the <em>envelope</em> of these curves. Unless it has been specified at what level they are considered fixed (which could implicitly be whatever is their current level), it makes no sense to refer to <em>the</em> short run average cost curve.</p>

<p>In most cases, the minimum point of a short run cost curve will be above the long run cost curve.  This should not be surprising: it just means that, for the relevant output, it's possible to obtain lower costs if all inputs are free to vary than if only some are free to vary.</p>

<p>There will however be one short run cost curve corresponding to the levels of fixed inputs at which the long run cost curve is at its minimum.  The lowest point of that particular short run cost curve <em>will</em> be tangent to the long run cost curve (and incidentally the short and long run marginal cost curves will also pass through the same point).</p>

<p>A diagram showing multiple short run average cost curves, with one having its lowest point tangent to the lowest point of the long run cost curve may be found in Nicholson W (9th edn 2005) <em>Microeconomic Theory</em>.  For an online source see <a href=""http://www.policonomics.com/long-run-cost-analysis/"" rel=""nofollow noreferrer"">here</a>.</p>
","14914"
"The Savage sure thing principle and Subjective utility representation","839","","<p>I have tried reading and understanding Savage's proof of the subjective utility representation, it is too complicated. Is anyone aware of a shorter/more elegant proof of this?
It is not a problem if we assume a finite prices set. </p>

<p>The original is in Savage, L.J. 1954. <em>The Foundations of Statistics</em>. New York: John
   Wiley and Sons.</p>

<p>A good summary can be found at
<a href=""http://www.econ2.jhu.edu/people/Karni/savageseu.pdf"" rel=""nofollow"">http://www.econ2.jhu.edu/people/Karni/savageseu.pdf</a>.</p>

<p>The Savage proof is known to be very elaborate, and long. It uses the sure thing principle as its main axiom. I was wondering if there is a more ""modern"" proof, that is both elegant and shorter. Or a nice challenge would be to try to prove collaboratively using some modern mathematics, like mixture spaces, (I am aware of <a href=""http://www.econ.ucsb.edu/~tedb/Courses/GraduateTheoryUCSB/anscombeaumann.pdf"" rel=""nofollow"">Anscombe-Aumann</a>).</p>
","<p>In Kreps' (1988) book <a href=""http://rads.stackoverflow.com/amzn/click/0813375533"" rel=""nofollow""><strong>""Notes on the Theory of Choice""</strong></a>, the issue is dealt with in <strong>chapter 9 ""Savage's Theory of Choice Under Uncertainty""</strong>, after discussing subjective probability in chapter 8. As usual, Kreps' style helps: he has the ability to seamlessly inject his -always formal- approach with very down-to-earth comments and examples that are strong in intuition (and he does it better than Savage, I might add). But also, here <em>""formal"" does not translate into ""complete exposition""</em>: he explicitly refrains from formally <em>proving</em> parts of the whole apparatus, mentioning that ""this is a two-page proof"", and ""this is another two-page proof"", and ""if you want to prove this, good luck"". For these parts he falls back on Fishburn's (1970) <a href=""http://books.google.gr/books/about/Utility_theory_for_decision_making.html?id=lyUoAQAAMAAJ&amp;redir_esc=y"" rel=""nofollow""><strong>""Utility Theory for Decision Making""</strong></a> book, <strong>chapter 14</strong> <strong>""Savage's Expected Utility Theory""</strong>. And Fishburn is <em>formal</em> alright (more symbols than words in a page).  </p>

<p>My impression is that combining these two sources can be beneficial.</p>
","527"
"What would happen if the world switched to a single currency?","836","","<p>What would happen if all countries suddenly stopped using local currencies and adopted a global currency (like the Euro, but for everyone)?</p>
","<p>The Euro was always conceived by most Economists as a political goal, not an economic one. </p>

<p>Prologue: There is the theory of <a href=""http://en.wikipedia.org/wiki/Optimum_currency_area"" rel=""nofollow"">Optimum Currency Area</a>s (OCA) which characterizes properties that a larger area would need to have if it were to operate on a single unit of currency. Since the announcement of the Euro around 1990, there were many papers that looked into whether the European Area actually satisfied the broader range of these criteria, and they mostly agreed that it did not. </p>

<p>Ex-post, we can now see this playing out as the ECB has a hard time setting up an inflation rate that is improving conditions of countries that are hit very badly by the crisis such as Greece and Spain, and countries which are not, such as France and Germany.</p>

<h2>Intuition behind OCA</h2>

<p>Basically, a country gives up the tool of monetary policy when it subordinates into such a currency union. In order to properly use monetary policy for a set of different economies (countries), you need these to be very similar in nature: If all countries react similarly to a housing bubble / oil shock / etc, you can easily improve outcomes for all countries with the same monetary tool. If the countries respond differently, it is much harder to do so.</p>

<h2>Single currency for non-OCA</h2>

<p>To the extent that <em>all countries</em> in the world are very different in nature, your experiment is similar to the gold standard (see <a href=""http://en.wikipedia.org/wiki/Bretton_Woods_system"" rel=""nofollow"">Bretton Woods system</a>). We think about that system mostly as a failure. While there is no hard data on the causal relationship, countries that abandoned the gold standard earlier tended to do better. We observed similar trends for countries that abandoned the dollar standard earlier. As a short intuition, among other explanations, when you abandon monetary policy and fix your exchange rate, you make yourself more vulnerable to inflation/deflation of other regions.</p>
","4955"
"In what sense are ""new-Keynesian"" models ""new"" and in what sense are they ""Keynesian""?","828","","<p>Hopefully, the title of this question is quite descriptive. Whilst I have a broad understanding of the research agenda of macroeconomics, I don't have a very good picture of how it is divided into various schools and traditions. Is there a way to briefly summarise what exactly New Keynesian macro is and how it relates to the rest of what is going on in macroeconomics?</p>
","<p>In essence New-Keynesians adapt micro to macro theory. This is in contrast to new classicals which adapt macro theory to orthodox neoclassical market-clearing microfoundations. New-Keynesians adapt the rational expectations hypothesis but accept that market may fails due to wage and price stickiness and Friedman's natural rate hypothesis. The New-Keynesians, the RBC school and New Classicals focus on issues relating to aggregate supply and have been the dominating schools since the 1970's, especially the new-Keynesians have dominated the last one to two decades. On the other hand ""old""-Keynesians and the orthodox monetarists mainly focused on issues relating to aggregate demand and these dominated economic thinking pre-1970's. </p>

<p>As an example of the differences between New-Keynesian New Classicals and the RBC school consider an increase in money: This increase will have real effect in a New-Keynesian model due to these market imperfections. In a new classical model on the other hand money will only have real effects if they are unanticipated (Lucas' Island model) while in a RBC model the increase will only feed into higher prices due to perfect clearing markets and rational expectations. </p>

<p>Note that it has been argued by N. Gregory Mankiw that the New-Keynesian school could just as well have been called New-Monetarist.</p>

<p>For an excellent reference on the different schools, what they represent and their differences see Snowdon and Vane: ""Modern Macroeconomics: It's Origins, Development and Current State""</p>
","196"
"Relationship between short-run marginal cost(SRMC) and long-run marginal cost(LRMC)","828","","<p>While reading Intermediate Microeconomics from Hal Varian, I fell short in understanding the relationship between SRMC and LRMC. I can see how in SR, when fixed factor is chosen at LR optimizing condition, then </p>

<pre><code>                         c(y) = cs (y,k(y))
</code></pre>

<p>where, k is the fixed factor.</p>

<p>But at pg. 394 of 8th edition, in Appendix to Ch. 21 (Cost Curves), author writes, 
""...the long-run marginal cost will consist of two pieces:
how costs change holding plant size fixed plus how costs change when plant size
adjusts. But if the plant size is chosen optimally, this last term has to be zero!"". This is what I am unable to understand, how the 'second' term is zero!</p>

<p>Please, help me understand both intuitively and through calculus.</p>
","<p>First, fix an output level $y^*$. Now you solve the (long run) cost-minimization problem conditional to this output level. We obtain the cost function $c(y)$ and the conditional demand function $k(y)$.</p>

<p>Suppose we are at a cost-minimizing size of plant, $k(y^*)=:k^*$, for this output level. If costs decreased when you increase plant size, then it would pay to increase plant size. This contradicts our choice of plant size. Likewise, if cost increases when you increase plant size, then it would pay to decrease plant size. Again, this contradicts our choice of plant size. So, $$\left(\frac{\partial c(y)}{\partial k}\right)_{y=y^*,k=k^*}=0.$$</p>

<p>The calculus treatment is already given in the mentioned page. Let me know if there is still something that bugs you.</p>
","4965"
"competitive equilibrium, Walrasian equilibrium, Walrasian auction","826","","<p>There are several sellers holding some indivisible goods, and several potential buyers with different valuations for these goods.  I need to calculate the Walrasian equilibrium in this scenario, but first I need to understand what exactly <em>is</em> a Walrasian equilibrium. So I am looking for a short, formal, operational definition of this term.</p>

<p>Wikipedia just links to a page about <a href=""https://en.wikipedia.org/wiki/General_equilibrium_theory"" rel=""nofollow"">General equilibrium theory</a>, which is very long and verbal, but I couldn't find there a formal definition of a Walrasian equilibrium.</p>

<p>This page also hints that a Walrasian equilibrium is similar to <a href=""https://en.wikipedia.org/wiki/Competitive_equilibrium"" rel=""nofollow"">Competitive equilibrium</a>, but I didn't understand whether they are identical or different, and if they are different - what is the relation between them?</p>

<p>There is also a page about a <a href=""https://en.wikipedia.org/wiki/Walrasian_auction"" rel=""nofollow"">Walrasian auction</a>, but again, I am not sure what is the relation between this and a Walrasian equilibrium?</p>

<p>The definition in the <a href=""http://economics.about.com/od/economicsglossary/g/walrasiane.htm"" rel=""nofollow"">about.com dictionary</a> looks promising: ""An allocation vector pair (x,p), where x are the quantities held of each good by each agent, and p is a vector of prices for each good, is a Walrasian equilibrium if (a) it is feasible, and (b) each agent is choosing optimally, given that agent's budget. In a Walrasian equilibrium, if an agent prefers another combination of goods, the agent can't afford it.""   But, they do not define what they mean by ""feasible"".</p>

<p>I would very much appreciate an orderly explanation of the relation between all these different terms.</p>
","<p>Yes, <em>Walrasian equilibrium</em> and <em>competitive equilibrium</em> are used interchangably. Both refer to a set of allocations and prices such that</p>

<blockquote>
  <ol>
  <li><p>Taking prices as given, every agent weakly prefers their allocation to any other possible allocation they might receive (i.e., in an indivisible goods market, they do not want to buy some goods that they are not allocated in equilibrium, nor do they wish they didn't have to buy some goods that they are allocated in equilibrium).</p></li>
  <li><p>The market clears: the entire endowment of goods is allocated, and no good is allocated more than once. (This is the feasibility requirement).</p></li>
  </ol>
</blockquote>

<p>Note that in the case where the market has distinct seller and buyer roles (e.g. an auction), 1. and 2. jointly require that any unsold goods have a price of zero.</p>

<p>The term <em>Walrasian auction</em> is something rather unrelated. The standard classical model of supply and demand in a perfectly competitive market (i.e. the first thing you see in Econ 101) predicts price and quantity are set when supply is equal to demand. But how do we get there? Leon Walras proposed a thought experiment in which a hypothetical auctioneer called out prices and people made offers until the market converged on the prefect competition equilibrium. This hypothetical process is known as a Walrasian auction or, sometimes, Walrasian tâtonnement.</p>
","3029"
"How is price elasticity determined in practice?","823","","<p><a href=""http://en.wikipedia.org/wiki/Price_elasticity_of_demand"">Price elasticity of demand</a> and <a href=""http://en.wikipedia.org/wiki/Price_elasticity_of_supply"">Price elasticity of supply</a> are two of the most important concepts of microeconomics, but they're generally explained from a hypothetical standpoint, and little effort is given to explaining how they are measured, or how they fluctuate (specifically the scale of fluctuation, not the contributing causes).</p>

<p>Can anyone explain this, and/or point to studies that document the fluctuation of $PE_{d}$ and $PE_{s}$ over time?</p>
","<p>In many practical instances, price elasticity of demand (PED) is calculated in a back of the envelope fashion, just as taught in the textbooks! Firms can adjust their price by some small amount and observe the demand response. For relatively small changes in price and quantity, little accuracy is lost by assuming that the demand function is locally linear, so that the change in price and demand jointly give an estimate for $$\frac{dQ}{dp}.$$ Since $p$ and $Q$ are already known, this is enough to calculate the PED:
$$\eta=\frac{dQ}{dp}\frac{p}{Q}.$$</p>

<p>This method yields only a point estimate of elasticity at the current price. However, one can get an incredibly long way with just this estimate thanks to the so-called Lerner condition: that a firm with marginal cost $c$ facing a price elasticity of $\eta$ maximises profit when $$\frac{p-c}{p}=-\frac{1}{\eta}.$$ Once the price elasticity of demand is estimated in the above fashion, this formula can be used to infer if the firm's price is above or below its profit-maximising level (allowing a firm to correct towards that level). Alternatively, this kind of analysis is often used as a heuristic in competition policy (antitrust) because, by estimating the right hand side of the Lerner formula, competition authorities can get an estimate for the left hand side (i.e. for how much power the firm has to price above marginal cost).</p>

<p>One drawback of this approach is that, at least in its simplest implementation, it does not control for factors such as how a change in the price of a product affects the demand of other products sold by the same firm (and thus overall profit).</p>

<p>You can see a nice informal discussion of Amazon's book pricing based on this kind of back of the envelope work <a href=""http://www.digitopoly.org/2014/07/30/amazon-makes-its-case-against-hachette/"">here</a>.</p>

<p>For more formal purposes, and when data is readily available, the process is often similar but slightly more careful in the estimation of demand. An excellent example of this kind of work can be found in Ellison &amp; Ellison's 2009 <em>Econometrica</em> Paper, <a href=""http://economics.mit.edu/files/7205"">Search, Obfuscation, and Price Elasticities on the Internet</a>. They proceed by estimating the firm's demand function econometrically (rather than via the heuristic method described above), and then calculate the implied PED from this estimated demand. Using an equation analogous to the Lerner condition, they are able to infer how far from the competitive case the market is, and attribute this discrepancy to search obfuscation.</p>

<p>In practice, for economists working outside of a firm, the main difficulty is often obtaining the data necessary to estimate the PED (Ellison &amp; Ellison had excellent data thanks to collaboration with a firm in the market).</p>
","63"
"Why does a decrease in interest rate reduces the velocity of money circulation?","813","","<p>I have seen sources that claim high interest rates increase the velocity of money circulation, but haven't really seen any concrete explanation for this. This is how I think it works: High interest rates -> high opportunity cost of holding money -> Demand for money decreases -> people dont want to hold money and will spend it -> higher velocity of income.</p>

<p>On the other hand,wouldn't a high interest rate make saving more attractive and thus reducing the velocity of income circulation?</p>

<p>EDIT: Sources that apparently claim this are referred to below:</p>

<p>This source does not explicitly state the relationship but somewhat explains the causes: <a href=""http://thismatter.com/money/banking/money-demand-money-velocity.htm"" rel=""nofollow noreferrer"">http://thismatter.com/money/banking/money-demand-money-velocity.htm</a></p>

<p>A wikipedia page that seems reasonably credible states this relationship, but I am unable to fully understand their explanation:
<a href=""https://en.wikipedia.org/wiki/Velocity_of_money"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Velocity_of_money</a></p>

<p>This exam question from Cambridge International Examinations that explicitly states the relationship (the correct answer is D)</p>

<p><a href=""https://i.stack.imgur.com/j9Wal.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/j9Wal.jpg"" alt=""enter image description here""></a></p>
","<p>You are absolutely right. Since higher interest rates increase the opportunity cost, you wan't to get rid of it faster (at the margin).</p>

<p>The core of the argument is that the cost stems not only from the amount of money holdings, but also from the duration. Say you are constrained about the amount of money holdings you need in your daily life, but you can still make sure the money is not idle for too long. </p>

<p>For the second part of your question, you are mixing up concepts. The interest rate influences the Consumption/Savings Decision, but it is the same decision problem as in a (model) world without money, i.e. it is a choice between real variables, whereas money velocity is a monetary question.</p>
","15161"
"Weak axiom of revealed preference and choice coherence - how to show they are equivalent","811","","<p>$B$ and $B'$ are elements of the family of subsets of $X$</p>

<p>WARP<br>
For every pair $x,y \in B \cap B' $ and if $x \in c(B)$ , then if $y \in c(B'), x$ must $\in c(B').$</p>

<p>Choice Coherence<br>
For very pair $x,y \in B \cap B'$ and if $x \in c(B)$ and $y  \notin c(B)$, then $y$ must $\notin c(B').$</p>

<p>Are these two equivalent. If yes, how can we prove it?</p>
","<p>Yes, they are equivalent. Here is a formal proof by contradiction.</p>

<p><strong>WARP $\Rightarrow$ Choice coherence</strong></p>

<p>Suppose that WARP holds but that choice coherence is not true. There exists $B,B'$, $x,y \in B \cap B'$ such that $x \in c(B)$, $y \notin c(B)$ and $y \in c(B')$. </p>

<p>But WARP applied to the conditions $y \in c(B')$ and $x \in c(B)$ implies $y \in c(B)$. This is a contradiction.</p>

<p><strong>Choice coherence $\Rightarrow$ WARP</strong></p>

<p>Suppose now that choice coherence is true but that WARP is falsified. There exists $B,B'$, $x,y \in B \cap B'$ such that $x \in c(B), y \in c(B')$ and $x \notin c(B')$. </p>

<p>But choice coherence applied to the conditions $y \in c(B')$, $x \notin c(B')$ yields $x \notin c(B)$. This is a contradiction.</p>
","5896"
"""omission bias"" vs ""action bias"" -- how can they be reconciled?","809","","<p>I'm having trouble reconciling these two biases. They seem to be the exact opposite of each other. Yet humans are allegedly pre-disposed to both. </p>

<p>How can they be reconciled?</p>

<hr>

<p><a href=""https://en.wikipedia.org/wiki/Omission_bias"" rel=""nofollow"">Omission Bias</a>: </p>

<blockquote>
  <p>The omission bias is an alleged type of cognitive bias. It is the tendency to judge harmful actions as worse, or less moral than equally harmful omissions (inactions) because actions are more obvious than inactions.</p>
</blockquote>

<p><a href=""http://ambiguityadvantage.blogspot.com/2008/02/action-bias-in-decision-making-problem.html"" rel=""nofollow"">Action Bias</a> (academic source: <a href=""http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.335.9458&amp;rep=rep1&amp;type=pdf"" rel=""nofollow"">Bar-Eli et al., 2007</a>) </p>

<blockquote>
  <p>Simply put this means that just about everyone, when faced with ambiguous situations, especially those circumstances associated with risk, gets the feeling that they need to take some action regardless of whether this is a good idea or not.</p>
</blockquote>
","<p>According to the reference cited, <strong>omission bias</strong> arises when the <strong>norm</strong> for a particular situation is <em>inaction</em> whereas <strong>action bias</strong> arises when the norm is <em>action</em>. Make sense?</p>

<p>An example of <strong>Action Bias</strong> in Finance would be the observation that managers often make unprofitable investments instead of the alternative (i.e. return money to investors either as dividends or share buybacks) [1] because for these managers the norm is to find and invest in new projects. </p>

<p>As far as <strong>Omission Bias</strong> goes, one of the most famous examples arises in this <a href=""https://en.wikipedia.org/wiki/Trolley_problem"" rel=""nofollow"">thought experiment</a>.</p>

<p>[1] An example of this is described by Michael C. Jensen in 'The Agency Costs of Free Cash Flow: Corporate Finance and Takeovers' [American Economic Review, Vol. 76, No. 2 (May, 1986)].</p>
","9962"
"Homogeneity of degree zero and normalization","802","","<p>One of the first assumption is that the demand function is homogeneous of degree zero. The reason and the proof is easy. </p>

<p>It should also be easy why this implies we can normalize the price of one good to 1, but I cannot see exactly what's going on.
A counterexample would be of great help i.e. a function with homogeneity different from zero showing that the normalization is not possible/leads to wrong conclusions.</p>
","<p>Demand $x(p, m)$ is the solution to the utility maximization problem:</p>

<p>$\max\limits_{x\in\mathbb{R}^n_+} \ \ u(x) \\ \text{s.t.} \ \  p\cdot x \leq m$</p>

<p>where $p\in\mathbb{R}^n_{++}$ is price vector, and $m$ is the income.</p>

<p>When we multiply both sides of the constraint in problem above by $\lambda &gt; 0$, and look at the revised problem we get</p>

<p>$\max\limits_{x\in\mathbb{R}^n_+} \ \ u(x) \\ \text{s.t.} \ \  \lambda p\cdot x \leq \lambda m$</p>

<p>Since this operation does not affect the constraint, the solution remains unaffected i.e. demand satisfy $x(\lambda p, \lambda m) = x(p,  m) $ which shows that demand is homogeneous of degree 0 in $(p, m)$. So, this is always true for demand function. Given that $p_1 &gt; 0$, we can take $\lambda  = \frac{1}{p_1}$, and find $x\left(\frac{p}{p_1}, \frac{m}{p_1}\right)$ to get $x(p, m)$. </p>

<p>It is helpful to note that for any function $f(p)$ that is homogeneous of degree $k &gt; 0$, it is the case that $f(\lambda p) = \lambda^k f(p) \neq f(p)$ for $\lambda \neq 1$.</p>
","15686"
"Pure exchange economy with two consumers and non differentiable utility functions","795","","<p>We have a pure exchange economy, two consumers $A,B$ and two goods $x,y$. The utility functions are as follows $$u_A=\min\{x_A,y_A\}\qquad u_B=\min\{x_B,\sqrt{y_B}\}$$
The endowments are $$\omega_A=(30,0)\qquad \omega_B=(0,20)$$</p>

<p>I want to derive the equilibrium price and the equilibrium allocation. Now, I can understand that if the vector of prices $\mathbf{p}&gt;&gt;\mathbf{0}$ the equilibrium does not exist because the offer curves do not intersect (and this is evident once you have drawn the Edgeworth Box). My problem is that I don't know how to approach the case in which one of the two prices is zero. How should I study this situation? Should I derive formally the two offer curves as functions of prices?</p>
","<p>I would suggest that ask yourself the following questions (hopefully, this should help you figure out how to solve the problem) : </p>

<ul>
<li>If good $z \in (x,y)$ was free, what would be the demand for both agents?</li>
<li>Is the conjunction of these demands feasible given the endowments? (this should allow you to rule out one of the cases)</li>
<li>If the demands are feasible, which price(s) for the other good would support such demands? What could be the equilibrium(a) allocation(s)?</li>
</ul>

<p>Notice that if good $z$ is free, one of the agents is not able to consume the other good, and she is therefore indifferent between consuming any quantity of good $z$.</p>

<p>Hope this helps.</p>
","334"
"Sequential vs. trembling hand perfect equilibrium","795","","<p>For any game, trembling hand perfect equilibria are a subset of sequential equilibria.
What is a simple example where a sequential equilibrium is not a trembling hand perfect equilibrium?
Is it possible to create a normal form example?</p>

<p>Links:</p>

<p><a href=""http://www.econ.yale.edu/~dirkb/teach/pdf/kreps/1982%20sequential.pdf"" rel=""nofollow"">Kreps-Wilson: Sequential Equilibria</a></p>

<p><a href=""http://www.math.mcgill.ca/vetta/CS764.dir/perfect.pdf"" rel=""nofollow"">Selten: Reexamination of the Perfectness Concept for
Equilibrium Points in Extensive Games</a></p>
","<p>Yes. In a normal form game, every Nash equilibrium is also a sequential equilibrium. But not every Nash equilibrium is trembling hand perfect. Consider the game in which each of two players has two strategies, A and B. Both players get payoff 0 except in one case: they achieve positive payoffs if they both choose A. Then (A,A) and (B,B) are two Nash equilibria of this game. Both are therefore also sequential equilibria. However, (B,B) is not trembling hand perfect. If there is even the smallest tremble in player 2's choice, player 1 has a strict preference for A. Only (A,A) is trembling hand perfect. The generalization of this is that Nash equilibria in which some players play weakly dominated strategies are not trembling hand perfect. </p>
","4719"
"Find utility function given indifference curve?","792","","<p>Given an indifference curve, how do you go about finding a utility function? </p>

<p>For example, given $z= \frac{k^\frac{1}{\delta}}{x^\frac{\alpha}{\delta}y^\frac{\beta}{\delta}}$ (defined by $U(\cdot) = k$), find a utility function. To do this, would I have to assign an arbitrary number for the utility and rewrite the function? I'm confused about what to do and can't find anything in my textbook about it. Thanks </p>
","<p>VCG's comment about isolating $k$ is the correct approach.</p>

<p>Given $U(\cdot) = k$ and
$$z = \frac{k^\frac{1}{\delta}}{x^\frac{\alpha}{\delta}y^\frac{\beta}{\delta}}$$
raise each side to the $\delta$ power:
$$z^\delta = \frac{k}{x^\alpha y^\beta}$$
and isolate $k$
$$k = x^\alpha y^\beta z^\delta$$</p>

<p>Since $k$ is now a function of each of the goods in your equation, it makes sense as a function form for utility.</p>

<p>$$U(x, y, z) = x^\alpha y^\beta z^\delta$$
So we arrive at the Cobb-Douglass utility form.</p>
","13495"
"Consumer Surplus question","789","","<p>The demand for rail travel is $Q^d = 600 - 2P$ where quantity is thousands of train journeys per quarter and $P$ is in £ per journey. How much would the consumer surplus change if rising cost of electricity led the train companies to raise price from £70 to £100. </p>

<p>Calculating the choke price, $600 = 2P$. Thefore $P = 300$.</p>

<p>At £70, $Q^d = 460$. Therefore Consumer surplus is $(460-300)/2*460 = £36,800$</p>

<p>At £100, $Q^d = 400$. Therefore consumer surplus is $(400-300)/2*400 = £20,000$</p>

<p>Difference is $£16,800$.</p>

<p>I've got the answer wrong, but i'm sure where, any help is appreciated. </p>
","<p><img src=""https://i.stack.imgur.com/7jyya.png"" alt=""enter image description here""></p>

<p>Image courtesy <a href=""http://economicsonline.co.uk/"" rel=""nofollow noreferrer"">http://economicsonline.co.uk/</a></p>

<p>Consumer surplus is the sum (integral) of differences between the price each consumer would have payed and the price they got to pay. You need to find out the area of the green zone on the above graph, in the case of your model.</p>
","5738"
"DSGE models (Dynare) are only based on simulations and approximations? (without data)","788","","<p>I'm beginner in <code>DSGE</code> models. Are they only based on simulations and approximations? Don't we have any real data-sets (for example interest rate, labor force, etc) to estimate the equations? I opened some <code>.Mod</code> files and I can only see equations, variable names and other functions. If yes, why do we have this structure in <code>DSGE</code> models and why can't we use real data-sets in these models?</p>
","<h1>Short answer</h1>

<p>It doesn't seem like you've tried very hard to find estimation using Dynare (<a href=""https://www.google.com/webhp?sourceid=chrome-instant&amp;ion=1&amp;espv=2&amp;ie=UTF-8#q=Dynare+estimation"">google results</a> of ""Dynare estimation""). Dynare is in fact capable of doing estimation and typically people use some sort of data to estimate the parameters that govern their model.</p>

<h1>Longer Answer</h1>

<h2>What is a DSGE model?</h2>

<p>A DSGE model is a series of equations (and variables and parameters) that describe a ""model"" economy. Once you write everything down and take into consideration the optimizing decisions made by the agents, it is simply a system of stochastic difference (differential) equation that you can imagine writing in some form along the lines of:</p>

<p>$$ E_t F(y_{t+1}, y_t, y_{t-1}, u_t) = 0$$</p>

<h2>What does Dynare do?</h2>

<p>The majority of introductory examples only use Dynare to solve the model and run some simple simulations. In addition to being able to solve the model, Dynare is also capable of doing Bayesian estimation of the parameters that make up the model by feeding in data.</p>

<h3>Solves and simulates the Model</h3>

<p>Dynare takes this system of equations (and the given parameter values) and solves them using perturbation methods. One of the outputs of the solution is a law of motion for all of the variables in the economy -- i.e. one can write something along the lines of</p>

<p>$$y_{t+1} = F(y_t, u_{t+1})$$</p>

<p>This law of motion allows you to generate model analogues of the data that you are interested in -- i.e. capital, labor, consumption etc...</p>

<h3>Estimates the model</h3>

<p>Once Dynare has a law of motion and has obtained simulated moments, it can compare the output of the model to data that you have provided. Dynare uses Bayesian estimation (though it is possible it does other types, but I'm not familiar with it) to estimate parameters which means that you need to provide it with a prior for each variable that you would like to estimate. It then uses a simple Metropolis Hastings algorithm to obtain estimates for the distribution over parameter values.</p>

<h2>References</h2>

<p>I would recommend you read both of the following references.</p>

<ul>
<li>Tommaso Mancini Griffoli. <em>Dynare User Guide: An introduction to the solution &amp; estimation of DSGE models</em>. 2007-2008. <a href=""http://www.dynare.org/documentation-and-support/user-guide/Dynare-UserGuide-WebBeta.pdf/view"">found here</a></li>
<li>Stefanie Flotho. <em>DSGE Models - solution strategies</em>. December 2009. <a href=""https://www.macro.uni-freiburg.de/publications/research_flotho/dsge_models"">found here</a></li>
</ul>
","6567"
"Is economic growth measured in real GDP or in real GDP per capita?","787","","<p>As an example, take a country where real GDP (measured in base year dollars) increases every year, but where the real GDP per capita (also measured in base year dollars) fluctuates, increasing and decreasing in equal measure. In this example, does the country experience economic growth every year? That is, does economic growth reflect the consistent increasing of RGDP or does it reflect the sometimes increasing, sometimes decreasing RGDP per capita?</p>
","<p>Usually GPD growth rates are publicly talked about in real terms but not per capita, see for example <a href=""http://data.worldbank.org/indicator/NY.GDP.MKTP.KD.ZG"" rel=""nofollow"">World Bank</a> where, above the relevant table we read</p>

<blockquote>
  <p><em>Annual percentage growth rate of GDP at market prices based on constant local currency. Aggregates are based on constant 2005 U.S.
  dollars. GDP is the sum of gross value added by all resident producers
  in the economy plus any product taxes and minus any subsidies not
  included in the value of the products. It is calculated without making
  deductions for depreciation of fabricated assets or for depletion and
  degradation of natural resources.</em></p>
</blockquote>

<p>Real GDP levels are also used in empirical research papers and books -for example, in <a href=""https://mitpress.mit.edu/books/lectures-macroeconomics"" rel=""nofollow"">Blanchard &amp; Fischer</a>, the first figure in the book is real GNP (not per capita).</p>

<p>A technical issue regarding per capita magnitudes is that population is not measured quarterly, or yearly (in fact it is usually measured per decade). So any attempt to provide quarterly or yearly ""GDP per capita"" figures would require extrapolating the population from sparser data. While this is not necessarily catastrophic as regards accuracy, it requires more resources to be devoted to its calculation.</p>

<p><em>Per capita</em> concepts certainly appear more often in theoretical research papers. The main reason is that theoretical models look also for possible ""steady-states"" (as attractors of the economy's evolution). Since GDP in levels exhibits a long-run upward trend, the next step is to consider ""GDP per capita"" (to ""take out"" the effect of population growth), and then the next step is to consider efficiency-indexed growth, like ""GDP per labor efficiency unit"", in order to look for the model's steady-state.</p>
","8739"
"Government expenditure multiplier in the new-Keynesian model?","780","","<p>Does a temporary increase in government expenditure increase output in the standard new-Keynesian DSGE model? Is it possible to draw any intuitive parallels between the impact of government expenditure in these model and in the IS-LM model?y</p>
","<p>The ""standard"" New Keynesian model could be many things, but suppose that we're dealing with the basic log-linearized 3-equation model (intertemporal Euler equation, New Keynesian Phillips curve, and monetary policy rule) exhibited, for instance, in Gali's textbook.</p>

<p>In most variants of this simple model, a temporary increase in government expenditure will almost always increase output, but the intuition is different from the Old Keynesian IS/LM model. The extent of the increase depends on the monetary policy rule. </p>

<p>If the monetary policy rule targets inflation of exactly zero (assuming trend inflation is also zero), then it turns out that there is no difference between the effects of government expenditure in the NK model and the effects in a purely real model; by successfully targeting zero inflation, we effectively negate the effect of the NK model's nominal frictions. Since the underlying real model produces an increase in output when government spending increases (ignoring effects of possible distortionary taxation used to fund this spending), we get this in the NK model with inflation targeting as well, but it's not very exciting. It's a purely classical story: all else equal, consumers work harder when their consumption is lower, and thus consumption does not drop one-for-one with increases in government spending.</p>

<p>If the monetary policy rule happens to target a constant real interest rate, then in the basic NK model the ""multiplier"" is exactly 1: the constant path for the real interest rate leaves consumption unchanged, and the increase in output exactly equals the increase in spending. If the monetary policy rule targets a constant nominal interest rate during the stimulus, then there is an additional effect because future stimulus spending produces expected inflation that lowers the real interest rate and boosts consumption. This is the source of ""multipliers"" >1 in the basic NK framework. See Woodford's <a href=""http://www.columbia.edu/~mw2230/G_ASSA.pdf"">2011 AEJ macro paper</a> for more details on this.</p>

<p>None of this comports with the traditional Keynesian 1/(1-MPC) multiplier. This is for a couple reasons, but most important is the fact that the basic NK model features fully Ricardian consumers who intertemporally smooth consumption and anticipate future taxes levied to pay for current spending. <a href=""http://econ.upf.edu/docs/papers/downloads/911.pdf"">Gali, Lopez-Salido and Valles's 2007 JEEA</a> comes much closer to the traditional story by adding ad-hoc ""non-Ricardian"" households.</p>
","576"
"Benefits of a cartel among firms","773","","<p>Suppose I have $n&gt;2$ firms selling differentiated products. These firms form a cartel for the price. The cartel has size $n_c$. Let $\pi_{i,m}$ be the payoff of a firm $i$ outside the cartel and $\pi_{j,c}$ be the payoff of a firm $j$ inside the cartel. </p>

<p>I would like to know whether there exists a set of assumptions (a reference to a paper in the literature describing that set of assumptions and relative proofs is sufficient) under which </p>

<p>For any <strong>firm $j$ outside the cartel</strong>:</p>

<p>(i) entering the cartel is weakly convenient in terms of        profits for any $n_c$, i.e. $\pi_{j,m}(n_c-1)\leq \pi_{j,c}(n_c)$ $\forall n_c$</p>

<p>(ii) the higher is $n_c$ the higher is the profit increase from entering the cartel for any $n_c$, i.e. $\pi_{j,c}(n_c)-\pi_{j,m}(n_c-1)\leq \pi_{j,c}(n_c+1)-\pi_{j,m}(n_c)$ $\forall n_c$</p>

<p>For any <strong>firm $i$ inside the cartel</strong>:</p>

<p>(i) the profit is increasing in $n_c$, i.e. $\pi_{i,c}(n_c-1)\leq \pi_{i,c}(n_c)$ $\forall n_c$</p>

<p>(ii) the higher is $n_c$ the higher is the profit increase from letting someone else entering the cartel, i.e. $\pi_{i,c}(n_c)-\pi_{i,c}(n_c-1)\leq \pi_{i,c}(n_c+1)-\pi_{i,c}(n_c)$ $\forall n_c$</p>

<p>All inequalities could hold also strictly.</p>
","<p><a href=""http://doi:10.1016/j.econlet.2014.08.036"" rel=""nofollow"">Cartel size and collusive stability with non-capitalistic players</a> lists the reasons why it's highly unlikely that your question finds an answer for profit-seeking firms (see Friedman, 1971 for a threshold on cartel stability)</p>

<blockquote>
  <p>It is widely accepted from both the theoretical IO literature (e.g., Tirole, 1988) and policy reports (e.g., Ivaldi et al., 2003) that high market concentration is a facilitating factor for (tacit as well as explicit) collusion. In addition to coordination being likely more difficult in larger groups, the intuition that the incentive to collusion shrinks with too many competitors is fairly simple: as the number of firms grows larger, the individual share of cartel profits shrinks monotonically and therefore implicit collusion becomes harder to sustain (cf. Tirole, 1988, ch. 6).</p>
</blockquote>

<p>So you may find ""toy"" answers for $n=4$ or the like but probably not for reasonably big $n$.</p>

<p>However, the same paper also proves that</p>

<blockquote>
  <p>An increase in cartel size makes implicit collusion among labour-managed firms easier to sustain.</p>
</blockquote>

<p>which is exactly what you're stating in your question.</p>

<p>As the authors sum up,</p>

<blockquote>
  <p>In words, the critical threshold for $LM$ firms is decreasing and convex in n and tends to zero as n becomes arbitrarily large. On the other hand, the critical threshold for profit-seeking firms is increasing and concave in n and tends to one as n becomes arbitrarily large. To complete the description of the critical thresholds w.r.t. n, we may also observe that</p>
</blockquote>

<p>So according to this reference, an answer to the question is <strong>yes, on the condition that the firms studied are not profit-seeking but $LM$-firms</strong>.</p>

<hr>

<p>Note: A $LM$-firms is an enterprise that operates under the ultimate control 
of those who work in it, which as for consequences, among others, that the firm aims at maximising profit per worker rather than profit.</p>
","5594"
"What is the calculable effect of counterfeiting on an economy?","761","","<p>I'm curious whether one can numerically calculate the effect that counterfeiting has on an economy.</p>

<p>As I understand it, counterfeiting essentially amounts to theft of the wealth of everybody holding units of that currency. For example, say you have an economy with 100 units of currency currently circulating. Bob creates 100 fake units of currency. If he does nothing but leave them in his safe, then the economy is unaffected. However, if he spends all of them, he will get goods and services in exchange for nothing of value. This is the theft. Him introducing his 100 fake units into the economy doubles the money supply, which will eventually more or less lead to a doubling in the price of everything (but not necessarily). </p>

<p>So now, if Dave had 10 units of currency his purchasing power was X. However, after the counterfeiting and doubling of the money supply and thus more or less doubling of prices, his purchasing power is X/2. Likewise for anybody who was holding that currency.</p>

<p>So, is it correct to say that in an economy with X currency units, counterfeiting and spending Y fake units is equal to theft of Y/(X+Y) of the wealth of the economy?</p>

<p>e.g. Given 100 legit units and counterfeiting and spending 200 units, 2/3rds of the wealth was stolen?</p>

<p>If not then what is the effect?</p>
","<p><i>So, is it correct to say that in an economy with X currency units, counterfeiting and spending Y fake units is equal to theft of Y/(X+Y) of the <b>wealth</b> of the economy?</i></p>

<p>(Emphasis added.)</p>

<p>No.  It is correct to say that spending Y fake units is equal to the theft of Y/(X+Y) of the <b>money holdings</b> of the economy, which is not at all the same thing.</p>
","574"
"""Demand for money"" - definition","755","","<p>What is the definition of ""demand for money"". The definition given by Wikipedia appears gibberish to me. And just to double check - what are the units of demand for money? Is it measured in ""dollars""? or perhaps ""dollars per unit time""? Or a ratio between two things?</p>

<p>If I understand it correctly, the level of demand for any produce (other than money) is the rate of flow of money that is currently being used to purchase that produce. So for example, if there is 1 million dollars per day being spent on VW cars, then you can say, ""the demand for VW cars is $1m per day"". Clearly the meaning of the word ""demand"" in the expression ""demand for money"" can't be the same thing - can it?</p>

<p><strong>EDIT:</strong> Some definitions sound an awful lot as though a person's demand for money is exactly equal to the amount of money they currently have (and its units would therefore simply be ""dollars""). Please include in your answer, an indication of whether or not your definition is identical to a person's current holding of money.</p>

<p><strong>EDIT:</strong> Looking at the suggested answers and doing some more reading, I get the feeling that the word ""demand"" in economics is actually not a single number, but a set of numbers, or a curve. In the case of normal goods (call them Widgets), then the x axis will be price and on the y axis will be ""Widgets sold per unit time"" (the unit of time could be days, years etc). Please advise if you think I have this bit wrong.</p>
","<p>Following on manofbear's answer. </p>

<p>Assume we are at date $t$ and hold your budget constraint fixed to $w$. The ""amount of money you currently possess"" is your equilibrium demand. Call that $x_t = x(p_t,w)$. If interest rates $1/p_{t+1}$ soar tomorrow, holding money gets costly for you, because the price of holding money $p_{t+1}$ increases. Therefore, you are willing to reduce the ""amount you currently possess"" $x_t = x(p_t,w)$ to $x_{t+1} = x(p_{t+1},w)$, some demand level characterized by your own demand function. It may however be that the bank is closed tomorrow and you'll be forced to stay out-of-equilibrium until Monday.</p>

<p>If you assume instantaneous equilibrium adjustments, your demand is clearly what you possess.</p>
","11645"
"Alternatives to Pigouvian tax","755","","<p>Two common drawbacks of Pigouvian subsidy mentioned in the literature are related to monetisation and measurement of social cost (Baumol) and reciprocity of social cost (Coase).</p>

<p>What alternatives to Pigouvian taxes are proposed in the literature? Have any of such alternative measures been implemented in practice?</p>
","<p>The most obvious answer is Coasian bargaining. What Coase showed in his famous ""<a href=""http://www.econ.ucsb.edu/~tedb/Courses/UCSBpf/readings/coase.pdf"">The Problem of Social Cost</a>"" is that if there are no transaction costs and if utility is transferable then it suffices to allocate property rights—i.e. to give one party the right either to engage in the externality-causing activity or to prohibit it. The two parties will then engage in bargaining with the result that the socially efficient level of the activity is undertaken. The idea is that if an activity has private value $v$, but imposes external social cost $c$ on others then</p>

<ul>
<li><p>if the private individual has the right to participate in the activity then others would collectively be willing to pay up to $c$ to persuade him not to. This offer will be accepted only if $c&gt;v$ so the activity takes place only if it is optimal.</p></li>
<li><p>if others have the right to prohibit the activity then the private individual would pay up to $v$ for them not to do so. This offer will be accepted only if $v&gt;C$ so again the activity takes place only when it is optimal.</p></li>
</ul>

<p>This example assumes a negative externality, but the same approach works in the case of a positive externality. For example, if the private benefit is $v$ (which may be negative if the activity is very costly) but there is an external benefit of $u$ then third parties would collectively be willing to pay up to $u$ to encourage the private individual to engage in the activity. Thus, the activity takes place only if $v+u&gt;0$---i.e. exactly when it is efficient.</p>

<p>This solution is an important element of <a href=""http://en.wikipedia.org/wiki/Carbon_emission_trading"">carbon trading</a> schemes, which are one of the main ways that countries are attempting to tackle the problem of anthropogenic global warming.</p>

<p>The Coasian solution has the attractive feature that it is relatively decentralised (there is no need for a central planner to accurately determine the size of the externality). Although this solution appears to work very well, it has a couple of important drawbacks:</p>

<ul>
<li><p>The zero transaction cost assumption is strong. This is particularly true when an activity imposes a small externality on a large number of people so that there is potentially the need for a large number of bilateral payments.</p></li>
<li><p>If the externality falls on a large number of individuals then paying a subsity creates a public good problem: each individual could try to free ride and hope that a large enough subsidy is paid by others.</p></li>
</ul>

<p>The Coasian solution therefore works best when either</p>

<ol>
<li>the externality falls mostly on a single 'large' agent who can therefore engage in Coasian bargaining without the fear of free riding and only incurring transaction costs once.</li>
</ol>

<p>or </p>

<ol start=""2"">
<li>agents are able to use contracts, their government, or some other device to act collectively as if there were the single large agent in 1.</li>
</ol>
","365"
"Reading list: history of economic thought / political economy","755","","<p>Can you all please suggest books that I can read to get started in the fields of political economy and the history of economic thought? </p>

<p>While my major in Mathematical Economics has given me a good grounding in the theoretical models of economics and the empirical methods used to test them in the real world, I feel that my knowledge of political economy and economic history is sadly lacking. I would like to get a more holistic understanding of the discipline(s) and would greatly appreciate your advice.</p>
","<p>As a first read in these fields I would recommend J K Galbraith's <a href=""http://www.amazon.co.uk/History-Economics-Past-Present-Penguin/dp/0140153950/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1434222976&amp;sr=1-1&amp;keywords=Galbraith%20History"" rel=""nofollow"">A History of Economics</a>. It covers, in a concise and highly readable way, major developments in economic thought from ancient times until around 1980, making links with major economic and political events.</p>

<p>A much more detailed book on the history of economic theory is Ekelund &amp; Hebert's <a href=""http://www.amazon.co.uk/History-Economic-Theory-Method/dp/147860638X/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1434223031&amp;sr=1-1&amp;keywords=ekelund%20%26%20hebert"" rel=""nofollow"">A History of Economic Theory and Method</a>. This is not light reading but through use of formulae and diagrams would probably make some clear links with economic models you have studied and describe the historical context in which they were developed.</p>
","6105"
"Transformation Function","751","","<p>In Mas-Colell microeconomics textbook I have found that profit maximization problem (as well as many further optimization tasks) could be represented with application of some transformation function (p.135):</p>

<p>$\begin{cases}Max\text{ }p*y\\s.t.\text{ }F(y)\leq0\end{cases}$</p>

<p>Where y is production vector and <strong>F(.)</strong> is a <strong>transformation function</strong>. </p>

<p>The only information I have found about this function states that $F:R^L\to R$ and that production set of a firm could be represented as $Y=\{y\in R^L:F(y)\leq0\}$. Also if $F(y)=0$ it is named <strong>transformation frontier</strong> (p.562)</p>

<p>So I am interested in what concrete are these transformation function and transformation frontier. Intuitively it must be related to some feasibility restrictions but I whant to have some full and strickt explanation.</p>

<p>Will be very greatfull for help!</p>
","<p>I'm sort of confused what you are asking, but the basic idea behind the transformation is that $y$ is a vector of inputs AND outputs for a firm. Things that are inputs are expressed in negative quantities. So when you are maximizing $\vec{p} \cdot \vec{y}$ for maximal profit, you are paying $p_1 y_1 + \cdots$ for the input(s), and gaining $p_n y_n + \cdots$ for the output(s).</p>

<p>The transformation function simply describes how the input(s) are transformed to make the output(s). The transformation frontier is analogous to the production possibilities frontier, if you are familiar with that, just shifted over to reflect that inputs expressed as negative quantities.</p>
","10924"
"Linear Expenditure System of Demands, Derivation Help","750","","<p>This problem I am working on comes out of--surprise--the Mas-Colell book for graduate micro (3.D.6). I think I have correctly used the FOC of the Lagrangian of the utility maximization problem to derive the consumer's Walrasian demand. My answer does not match the book. We are given that</p>

<blockquote>
  <p>$u(x) = (x_1-b_1)^\alpha (x_2-b_2)^\beta(x_3-b_3)^\gamma$</p>
  
  <p>(and then from the first part we can say that $\alpha + \beta + \gamma = 1 $ WLOG.)</p>
</blockquote>

<p>The solutions say that we take a monotonic transformation:</p>

<p>$\ln(u(x)) = \alpha \ln(x_1-b_1) + \beta \ln(x_2-b_2) + \gamma \ln(x_3-b_3)$</p>

<p>and then I set up the Lagrangian of this:</p>

<p>$ \mathcal{L} = \alpha \ln(x_1-b_1) + \beta \ln(x_2-b_2) + \gamma \ln(x_3-b_3) - \lambda(p_1x_1 + p_2x_2 + p_3x_3 - w)$</p>

<p>and the FOCs are:</p>

<p>$\frac{\alpha}{x_1-b_1} - \lambda p_1 = 0$</p>

<p>$\frac{\beta}{x_2-b_2} - \lambda p_2 = 0$</p>

<p>$\frac{\gamma}{x_3-b_3} - \lambda p_3 = 0$</p>

<p>Solve for the x's:</p>

<p>$x_1 = \frac{\alpha}{\lambda p_1} + b_1$</p>

<p>$x_2 = \frac{\beta}{\lambda p_2} + b_2$</p>

<p>$x_3 = \frac{\gamma}{\lambda p_3} + b_3$</p>

<p>Which leads us to:</p>

<p>$$x(p,w) = (b_1, b_2, b_3) + \left(\frac{\alpha}{\lambda p_1},\frac{\beta}{\lambda p_2},\frac{\gamma}{\lambda p_3}\right)$$</p>

<p>This is not what the book got, so I used Walras law to get the desired result:</p>

<p>$p \cdot x = w$</p>

<p>$\implies w - (b \cdot p) = \frac{1}{\lambda}(\alpha + \beta + \gamma)= \frac{1}{\lambda}$</p>

<p>$$\implies x(p,w) = (b_1, b_2, b_3) + (w - (b \cdot p))\left(\frac{\alpha}{p_1},\frac{\beta}{p_2},\frac{\gamma}{p_3}\right)$$</p>

<p>which is the book's solution.</p>

<p>So my questions are:</p>

<blockquote>
  <p>Did I do the derivation right? How should I know to take a log transformation of the original utility function? Is there any particular information that is supposed to tip me off?</p>
</blockquote>
","<p>I am not sure I understand your question. $\lambda$ is a Lagrange multiplicator which has a value in the optimum. It is not a parameter and hence you cannot leave it in your solution.
<br> When solving the Lagrangian the optimal solution has the form $(x,\lambda)$ and in addition to your conditions
$$x_1 = \frac{\alpha}{\lambda p_1} + b_1$$
$$x_2 = \frac{\beta}{\lambda p_2} + b_2$$
$$x_3 = \frac{\gamma}{\lambda p_3} + b_3$$
it also has to fulfill
$$
(p \cdot x - w) \lambda = 0.
$$
If $\lambda \neq 0$ this also means $p \cdot x = w$. $\lambda$ cannot be equal to zero because it is in the denominator of your optimal solution for $x$:
$$x(p,w) = (b_1, b_2, b_3) + \left(\frac{\alpha}{\lambda p_1},\frac{\beta}{\lambda p_2},\frac{\gamma}{\lambda p_3}\right)$$
and hence you were correct to use the Walras law or budget constraint.</p>

<p>For more on optimality conditions see the <a href=""https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions#Necessary_conditions"" rel=""nofollow"">Karush-Kuhn-Tucker theorem</a>.</p>

<p>About $b_1, b_2$ and $b_3$: I think this is supposed to be a bliss point.</p>
","8634"
"How to choose instruments for GMM estimation?","749","","<p>I have a linear regression with one dependent variable and ten INdependent variables. I want to estimate this relationship using GMM, but I need at least ten instruments. </p>

<p>Can I use the same dependent variables as instruments for the regression? If not, how would I go about choosing instruments in such a case?</p>

<p>EDIT: my research studies reported generalized trust levels in 77 nations and has covariates such as lnGDP2013 lnPopulationSize2014 dummy variables for history of legal institutions from: Germany, Scandinavia, Britain, France, Germany, a dummy variable for whether or not a nation was involved in the transatlantic slave trade and a dummy variable for whether or not a nation was colonized by Europe in the last 300 years. </p>

<p>I have transformed the dependent variable from a percentage TRUST = Percentage of people who answered that 'most people can be trusted' when surveyed to ln(TRUST/1-TRUST) which gives residuals whose estimated kernel density is roughly normal.</p>

<p>In addition I have a few other covariates such as probability of two individuals chosen from a nation being of the same ethnic group.</p>

<p>EDIT2: I've parsed the model down so I am using GMM to explain the impact of whether or not a nation send or received slaves during the transatlantic slave trade on reported generalized trust levels using Africa as an instrument for whether or not a nation sent or received slaves. I can argue that being an African nation in and of itself should not having a dampening impact on trust but would be correlated with the likelihood that a nation was involved in the transatlantic slave trade. </p>
","<p>As jmbejara says, better to be more specific, but let me guess.</p>

<p>You have a linear model $y = \beta_0 + \beta_1 x_1 + \cdots + \beta_{10} x_{10} + u$, where $x_1, x_2, \ldots, x_{10}$ are endogenous. Then, yes, you need at least ten instruments.</p>

<p>Can you use the same dependent variables as instruments for the regression? No, you can't. Instruments should be exogenous (uncorrelated with $u$) and relevant (strongly correlated with the endogenous regressors). But if some of the regressors are (believed to be) exogenous, then you use those exogenous ones as instruments. But you still need <em>extra</em> instruments for endogenous regressors. The rule is that you need at least $k$ extra instruments if there are $k$ endogenous regressors.</p>

<p>Finding good instruments (exogenous and relevant) is usually difficult. I suspect it would be really hard to find 10 instruments for a regression unless you have good economic justification.</p>

<p>That said, again it would be better to see your specific problem.</p>
","14302"
"Benveniste-Scheinkman condition gives derivative that still depends on the value function","742","","<p>What I mean by the title is often, if we have a value function like
$$V(K,I) = \max_{K',I'} F(K') +\beta V(K',I')$$
the First order conditions will give us something that depends on the derivative of the value function, say $V_1(K',I')$. We deal with this by using the B-S condition to find $V_1(K,I)$, then advance it one period?</p>

<p>What about when $V_1(K,I)$ still depends on $V_1(K',I')$, though? (see $(*)$ below for an example, if you wish to skip the setup)</p>

<p>Here is an example. Note that subscripts denote derivatives, the number in the subscript being the input with respect to which we are taking the derivative. <strong>The exception to this is</strong> negative subscripts, such as $I_{-1}$, where the subscript denotes being one period in the past (in the case of $-1$). A prime denotes being one period in the future (t+1), and two primes denotes being two periods in the future.</p>

<p>Back to the problem: We have value function
$$V(K,I_{-1}) = \max_{I,K'',C}u(C) + \beta V(K',I) \\
\text{ s.t. } C+I \leq f(K) \\
\text{ and  } I =K'' - (1-\delta)K'
$$
So basically we have a simple model with investment that takes two periods to build. $f(K)$ is our production function.</p>

<p>The FOC's give
$$
u_1(c) = \lambda_1 \text{, $\lambda_1$ is the multiplier on the first constraint }\\ 
\lambda_2 = 0 \text{ multiplier on second constraint is zero} \\
\beta V_2(K',I) = -\lambda_1
$$
Now to get $V_2$ we use the B-S condition, which gives
$$V_2(K,I_{-1}) = \beta V_1(K',I)$$
because $K' = I_{-1} + (1-\delta)K$ from the second constraint. Use the BS condition again and get
$$V_1(K,I_{-1}) =f_1(K) + (1-\delta)V_1(K',I) \tag{*}$$, again, because $K' = I_{-1} + (1-\delta)K$</p>

<p><strong>The previous equation is my question</strong> To reiterate, we use B-S condition to find the derivative of the value function, but in $(*)$ the B-S condition depends on what we are trying to find. How do we handle this?</p>

<p>I feel like $V_1(K'I)$ may just be $1$, or $0$, but then that makes $V_2$ be $\beta$ or $0$, which seems wrong...</p>
","<p>I guess I will provide a basic answer for now, since I somewhat figured this out, and hopefully either someone posts a more complete answer, or I add more to this later.</p>

<p>Basically, we can use forward or backward iteration. For example, for forward iteration (given that we know the value of $V_1$ at $t=0$, call it $V_{initial}$), then we can use this to find the value of $V$ at time $t$ simply by using the equation over and over again. Or we can work backwards, if for some reason forward iteration doesn't work (at this moment I'm not sure why/how this is different then forward). I don't think the solution is too neat, but it works.</p>

<p>Or, if we are at a steady state, then $V_1(K,I_{-1}) = V_1(K'_I)$, so we can simply rearrange the equation and solve.</p>

<p>Again, this isn't a great answer, but it is correct.</p>
","9648"
"Why does demand curve shift in, in a monopolistic competitive market?","742","","<p>In a monopolistic competitive market, demand curves shift in, if more firms enter the market. I can't seem to wrap my head around it. Demand remains the same, supply has increased. Shouldn't entry of more firms change the supply curve, rather than demand curve? </p>
","<p>Demand for <em>existing</em> firms' product shifts in because the entering firms attract some of the users.</p>
","12823"
"Price ratio determined by endowments only?","739","","<p>Am I right to say in an Exchange Economy with two consumers with identical preferences, the equilibrium price (WEA) of the two goods would be determined by availability of two goods, i.e, total endowment? 
Whereas if their preferences are not identical, this is not true, the equilibrium(WEA) would be determined by utility functions and endowments together?</p>
","<p>No you are not. Preferences determine the equilibrium, even if they are identical, because they determine the <em>value</em> of the endowments.</p>

<p>Consider two agents, one (""A"") having ice cream only, and one (""B"") having lava only.</p>

<p><strong>Case 1: Both hate lava</strong></p>

<p>Assume lava burns tongues and is useless (typical Economist). Then, the initial endowments of <em>B</em> have zero value, as no one wants them. The equilibrium allocation equals the initial allocation.</p>

<p><strong>Case 2: Both find lava useful</strong></p>

<p>Now, imagine lava being useful for lava lamps (whatever). They still have identical preferences, but now they attach some positive value to lava. The value of <em>B</em>'s initial endowment has changed, and hence he can trade at least some of it for ice cream. The equilibrium allocation no longer equals the initial allocation.</p>
","6792"
"Why don't Burgers cost 5 cents?","734","","<p>In <a href=""http://consultingbyrpm.com/blog/2016/01/pareto-big-macs.html"">this blog post</a>, economist Bob Murphy raises a puzzle involving the principle that in a competitive market, the price equals the marginal cost:</p>

<blockquote>
  <p>There’s a general principle from intro to microeconomics that says in
  a competitive industry, in equilibrium P=MC. So how would we actually
  apply that in practice to the fast food industry? At the point at
  which the burgers are already made and sitting on the back warmer,
  what’s the marginal cost to the firm of the worker picking up the
  burger and handing it to a customer? 5 cents? So, in an efficient fast
  food industry, burgers should be priced at 5 cents. Don’t you dare say
  that the firm needs to charge at least enough to cover average costs,
  because (as David points out) that involves a sunk cost fallacy…
  Something is obviously not right in the above. But I’m curious to see
  how you guys would unpack it. If you want to say, “I don’t trust them
  there textbooks with their funny graphs!” OK fine, but ideally I’d
  like you to solve it within the world of standard textbook micro,
  since presumably that can be done.</p>
</blockquote>

<p>What he's saying is that once the burger is already made, the cost of making the burger is a sunk cost, and thus the marginal cost of the burger is just the cost of the tiny labor involved in picking it up and selling it to the customer.</p>

<p>So why is it that in the fast food industry, the price of a burger takes into account the cost of making the burger and not just the cost of handing it over to the customer?  Is it because the fast food industry is far away from the conditions of perfect competition, or can this be explained using a perfect competition model?</p>
","<p>This question really forces one to think about the role that <em>quantity</em> plays in the competitive equilibrium. The two main points that, I think, explain the way this works are:</p>

<ul>
<li>The market quantity is <em>endogenous</em></li>
<li>In competitive equilibrium, the <em>market clears</em></li>
</ul>

<p>I think the thing that is perhaps causing confusion here is that, recalling that it is a true statement that ""P = MC"" in competitive equilibrium is not sufficient enough to understand the way in which markets function. It is imperative to recall <em>why</em> this is true: because so long as burger sellers maximize profit and burger eaters maximize utility, then <em>quantity will adjust to make it true</em>. </p>

<p>In other words, ""P = MC"" is not a transcendental tautology that simply must be true under all conceivable circumstances; it is the end result of the rational actions of buyers and sellers interacting within the framework of a market mechanism.</p>

<p>The original question only appears to be a puzzle if you attempt to abstract away from quantity, and allow yourself to imagine that it's not important how those burgers came to be sitting under the heat lamp in the first place.</p>

<p>A fully proper answer to this question would require being explicit about the objective functions of both the suppliers and consumers in this market, but I think that the following shorthand might suffice to illustrate the point:</p>

<p>In the original question, there are really two distinct notions of ""marginal cost."" The first is that of the marginal cost to produce the burgers. The second is the somewhat different concept of the marginal cost of delivering the completed burgers to the customer (ie, taking them out from under the heat lamp and handing them to the customer). Being sloppy in our use of language, and unintentionally blurring the line between these two distinct costs is, I think, another way to describe the ultimate source of confusion in this example. Let's just be clear, using clear notation.</p>

<p>Call ""MC1"" the marginal cost of <em>producing</em> each burger. Let's say for the purposes of illustration that each burger costs $2 to make.</p>

<p>Call ""MC2"" the marginal cost of handing a completed burger to the customer. As in the example, let's assume that this is equal to 5 cents per burger.</p>

<p>Hopefully it does not require too much convincing to establish that, in competitive equilibrium, burger sellers will end up collectively supplying exactly the amount of burgers, Q, for which it is true that the prevailing price of a hamburger is exactly equal to MC1. </p>

<p>It's <em>also true</em> that, in this equilibrium, each burger seller can sell all the burgers that they have chosen to produce at a price of P = MC! = $2/burger, since the market clears.</p>

<p>Now, at this point, each burger seller has <em>already</em> chosen a quantity of burgers to produce. So even though it's true that, once the burgers have been made, their production cost is a sunk cost, and <em>from that point</em>, the marginal cost of delivering the completed burgers to a customer is only equal to MC2 = $0.05, it will still be the case that <strong>no seller has any incentive to charge any less than P = MC1.</strong></p>

<p>Again, this is true because, in the competitive equilibrium characterized by P = MC1 and quantity Q, the market clears. This means that each and every seller of burgers can sell 100% of their stock of completed burgers at a price of MC1 ($2/burger). No seller has anything to gain by offering an even slightly lower price to the market, let alone offering a price as low as MC2.</p>

<hr>

<p>EDIT: To expound on the above a little...</p>

<p>Perhaps it's helpful to reinforce the role of the (endogenous) equilibrium quantity Q by looking at a graph.</p>

<p>It is certainly true that, <em>for the quantity of burgers that the restaurant has chosen to produce</em> (aka, for the number of burgers that are already sitting under the heat lamp), the marginal cost of delivering those already-made burgers to the customer is MC2 = 5 cents/burger. </p>

<p>But the paragraph above does not fully characterize the full marginal cost function, whose domain extends beyond the equilibrium quantity ("" Q* "" below). For any burgers <em>beyond</em> Q*, in order to deliver an additional burger to a customer, an additional burger must be <em>produced</em> first. So the marginal cost of any burgers beyond Q* is NOT 5 cents per burger, its $2/burger (strictly speaking, you would have to allow that it costs USD 1.95 to cook the burger and then 5 cents to hand it to the customer).</p>

<p>Recognizing this discontinuity in marginal cost, we can see that the actual marginal cost function looks something like this:</p>

<p><a href=""https://i.stack.imgur.com/37ZJI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/37ZJI.png"" alt=""enter image description here""></a></p>

<p>And furthermore, the location of that discontinuity is endogenous as well, since it will always coincide with the quantity chosen by a rational seller (ie, the quantity where the marginal cost of <em>production</em> crosses the demand curve). So even if you wish to take the position that the cost of producing the first Q* burgers is sunk, and should be ignored, it is still impossible to separate the marginal cost of production from the strategic analysis of the problem.</p>

<p>And, of course, to finalize the characterization of the competitive equilibrium, we need to include the demand curve. As you can see, this situation reflects the strategic incentives of the burger seller, where the quantity chosen by the seller is exactly the (only possible) quantity for which P = MC <em>and</em> quantity demanded equals quantity supplied (ie, the market clears).</p>

<p><a href=""https://i.stack.imgur.com/7cr6e.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7cr6e.png"" alt=""enter image description here""></a></p>

<p>As described above, the competitive equilibrium is characterized by the intersection of the demand and MC curves, at a quantity Q*, and a price of MC1 = $2.00/burger.</p>

<p>As above, the seller sells all Q* of their burgers at this price, and so has absolutely zero incentive to charge a lower price of MC2 = 5 cents/burger.</p>
","10416"
"Where to start learning economics as a mathematician?","728","","<p>I study pure mathematics at university and I'm looking to get into economics, with pretty much no background knowledge about it.</p>

<p>Are there good sources to learn from with a decent mathematical background in mind, or should I just start learning from ""normal"" sources, like watching video lectures from introductory courses, which don't assume much mathematical knowledge? Preferably, I'd like to embrace economics without those limitation.</p>
","<p>McCloskey's <em>Applied Theory of Price</em> is somewhat legendary as a model of clarity. It is, sadly, no longer in print. However, a PDF is available here: <a href=""http://www.deirdremccloskey.com/docs/price.pdf"">http://www.deirdremccloskey.com/docs/price.pdf</a>. The level of mathematical sophistication in this book (like in most good economics!) is not that high, but the book gives a deeper look at the important concepts than is to be found in most extant introductory undergraduate texts.</p>

<p>If you really want a more mathematically formalised treatment then you are going to have to turn to graduate-level econ books. For microeconomics, the classic text of choice is <em>Microeconomic Theory</em> by Mas-Colell et al.</p>

<p>If you do go down the more formal route, I would urge you not to give up on simpler treatments altogether; they're great for building intuition. More than a decade of experience in economics has taught me that good intuition built through simple models is often far more valuable than a less intuitive understanding of a more sophisticated model.</p>
","4638"
"What statistical techniques can be used for measuring price elasticity","722","","<p>I know that linear regression is used for calculating price elasticity. If my objective is to estimate the parameters of a causal relationship, can i use machine learning techniques like Random Forest or lets say ARIMA with regressors? Has anyone done this before? I tried searching in jstor.org but didn't find any.</p>
","<p>There are typically two ways to go about estimating causal relationships in the data: by using exogenous variation in the ""right-hand-side"" variable, or by using structural estimation. </p>

<p>Unless there's an experiment or a quasi-experiment of some sort, the technique economist's apply is instrumental variable (IV) estimation. The idea is that to find the causal impact of x on y in a situation in which x is partly determined by y itself or by a third variable that also affects y, is to find a source of variation that only has a direct effect on x. </p>

<p>Machine learning techniques are not typically used to estimate causal relationships. Instead, they are often used for forecasting. </p>

<p>Mixing the two: machine learning and causal inference is a focus of current research, but apparently there are no solid, off-the-shelf methods to use. Intuitively, the issue is that in the example above, you will need all of x to produce the best forecast of y, but you want only the exogenous par of x to get a sense of the causal relationship between x and y. </p>
","11097"
"Identifying Nash equilibria in extensive form game","717","","<p>Is there a systematic way of identifying all (pure strategy) Nash equilibria (not just the subgame perfect ones) in an extensive form game? In the following Entrant v Resident example, there are three NEs, two of which ($(OF,F),(OA,F)$) are not subgame perfect. What I've been doing is to convert the extensive form to normal form, and then find NEs there. While reliable, this method is time consuming, and gets complicated as the number of actions/players increases. For example, I suspect that it'd be much easier to spot NEs in a four-player extensive game (each with two action, say) than its normal form equivalent. </p>

<p>I'd be interested to know if there's any procedure that we can use to find pure NEs in a reasonably simple extensive form game.</p>

<p><a href=""https://i.stack.imgur.com/x8oxN.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/x8oxN.png"" alt=""enter image description here""></a></p>
","<p>As far as I know, No. </p>

<p>While I am not sure why you would want to find non-subgame perfect Nash equilibria in an extensive form game, I am sure you would need to convert it to normal form to do it. Extensive form of a sequential game carries more information than normal form, specifically which moves do not exist within the sequence. In a normal form representation of the sequential game you have to show every possible move available to every player, even the moves that do not exist. So basically when you convert a sequential game from extensive form to normal form, it becomes another game where you then look for Nash equilibria. </p>

<p>If you are doing a two player game where each player gets one move, you can do it in your head just by looking at the game tree, but if the game is any more complex, you would need to do it step by step, first converting it into a normal form.</p>
","9266"
"How to derive cubic cost function from a problem of constrained optimization?","709","","<p>The cubic total cost function usually take the form</p>

<p>$TC(q)=a+bq+cq^{2}+dq^{3} \qquad a,b,d&gt;0, c&lt;0$ and $c^{2}&lt;4bd$</p>

<p>I know that from a constraint maximization problem </p>

<p>$min\quad wL+vK$ </p>

<p>subject to </p>

<p>$q_{0}=f(k,l)$</p>

<p>i can express it with the lagrangean function </p>

<p>$\mathcal{L}=wl+vk+\lambda(q_{0}-f(k,l))$</p>

<p>with some algebra for the case of a Cobb-Douglas production function $q_{0}=k^{\alpha}l^{\beta}$ i can reach </p>

<p>$TC=q^{\frac{1}{\alpha+\beta}}w^{\frac{\beta}{\alpha+\beta}}v^{\frac{\alpha}{\alpha+\beta}}\left(\frac{\alpha+\beta}{\alpha^{\frac{\alpha}{\alpha+\beta}}\beta^{\frac{\beta}{\alpha+\beta}}}\right)$</p>

<p>I could give values to $\alpha$ and $\beta$ to obtain a cubic function, but not the one I described in the preamble. It could also fix some other factor such as the size of the factory, but would not work.</p>

<p>Any idea? </p>

<p>Thanks in advance</p>
","<p><strong>A note on the parameter constraints:</strong>
$$TC(q)=a+bq+cq^{2}+dq^{3} = a + q(b+cq+dq^{2})$$
It appears that what we want is that for the second degree polynomial to not take negative values. This would require for it to not have real and positive roots. Since $c&lt;0$, then if there are real roots one of them will be positive. This would imply that for an interval of positive values of $q$ the 2nd degree polynomial will take on negative values, and marginal cost will turn negative. So we need the discriminant to be negative, and so $c^2 - 4bd &lt; 0 \implies c^2 &lt; 4bd$. I don't see whey they write ""$3$"" instead of ""$4$"".  </p>

<p>-__________________________________</p>

<p>As for obtaining such a cost function rigorously from a production function:<br>
The reference is <strong><a href=""https://books.google.gr/books/about/The_Structure_of_Economics.html?id=DuW6AAAAIAAJ&amp;redir_esc=y"" rel=""nofollow"">Silberberg. E (1990), ""The Structure of Economics"" (2nd ed)</a></strong>, ch. 9.  </p>

<p><strong>A)</strong> <strong>When the production function is homogeneous of degree</strong> $r$, then the cost function has the form</p>

<p>$$C(q,\mathbb w) = q^{1/r} \cdot h(\mathbb w)$$</p>

<p>where $h(\mathbb w)$ is a function of prices (of input factors), and it is homogeneous of degree one (or ""linearly homogeneous"").</p>

<p><strong>B) When the production function is homothetic</strong>, which can be represented as a monotonic function of a homogeneous of degree one function, then the cost function remains multiplicatively separable in output and prices for some function $J(q)$:</p>

<p>$$C(q,\mathbb w) = J(q)\cdot h(\mathbb w)$$</p>

<p>But again, since homotheticity is a monotonic transformation of homogeneity of degree one, $J(q)$ should not be expected to take any polynomial form like the one you seek.  </p>

<p>So none of the usual functional specifications for production functions will give a cost function like the one you want to arrive at.  And indeed in papers with such cost functions I have never seen a derivation of the underlying production function.  </p>

<p>If any positive result comes up, I will return.</p>
","6044"
"Is market failure constant? What properly defines it?","708","","<p>My textbook defines market failure as when ""the production or consumption of a good or service causes additional positive or negative externalities on a third party not involved in the economic activity"". That being said, I'd like to ask, Don't all activities produce externalities? For example, the production of oil will always have negative externalities, no matter how the government intervenes. Thus the market will always fail.</p>

<p>Now perhaps I misunderstood. Perhaps it means whenever there are any <strong>net</strong> externalities (positive - negative), the market fails. Please tell me if this is right. </p>

<p>Furthermore, from what I've read, I've gathered that the market fails whenever <strong>social cost $\neq$ social benefit</strong>. But this is a different definition from the one I previously mentioned (the one only dealing with externalities). </p>

<p>Please tell me what market failure actually represents. Does it take into account social costs and benefits? Or only external costs and benefits? And if it only takes into account externalities, will some markets fail continuously (like consumption of oil)?</p>
","<p>I have to intervene to say that market failure and externality are not the same thing. So I do not think it is at all correct to define market failure as</p>

<blockquote>
  <p>when ""the production or consumption of a good or service causes additional positive or negative externalities on a third party not involved in the economic activity"".</p>
</blockquote>

<p>Externalities are but one example of market failure. <strong>Market failure is more properly defined as any situation in which a market, left to operate without any intervention, fails to produce the efficient (welfare-maximising) allocation.</strong> </p>

<p>Sources of market failure include</p>

<ul>
<li>Externalities: if there is a negative externality then there will tend to be too much of an activity from a social perspective—resulting in inefficiency.</li>
<li>Market power: if the market is not perfectly competitive then firms will tend to increase price above marginal cost to increase their profit. This results in consumers not buying the good even though they are willing to pay more than its cost of production—which is inefficient.</li>
<li>Information asymmetries: If one party in a transaction has an informational advantage over the other then s/he will try to exploit it to the counterparty's detriment. This, in turn will lead to transactions taking place where it would be efficient for them not to (or to mistrust and the failure to realise efficient transactions).</li>
<li>Missing markets: sometimes efficient trades don't occur because the market simply doesn't exist. For example, there is no market to insure against the risk that an unborn child will be born disabled and requiring a lifetime of care even though many parents and their children would like such insurance (an argument often used to for the existence of state-provided social security schemes). </li>
</ul>

<hr>

<p>To address your actual questions:</p>

<p>""Don't all activities produce externalities""? Yes, but many of these externalities are priced. For example, if I buy an apple then you can no longer consume that apple, which is an externality. However, this does not result in a market failure because the price mechanism in a competitive market ensures that I get an apple and you don't only if I am willing to pay more for that apple than you are. So the apples go to the people who value them the most, which is the efficient thing to do. Since we are doing the efficient thing, there is no market failure. </p>

<p>So, when should we worry about externalities? We should check whether the net effects can cancel each other out. For example, suppose that the private benefit of some action was lower than the social benefit, but that the private cost was also lower than the social cost by exactly the same amount. Then the net effect would be that MPB=MPC at exactly the same quantity where MSB=MSC. The private individual would then take the socially optimal action and there would be no market failure. <strong>A market failure only occurs if the externality is such that MPB=MPC at a quantity different to that where MSB=MSC.</strong> Only then will the behaviour of the private individual (whose optimal action is to equalise private marginal benefit and private marginal cost) differ from that which is socially optimal.</p>

<hr>

<p>A note on <em>marginal</em> benefit and cost:</p>

<p>When performing this kind of analysis, We typically assume that the objective is to maximise to total social welfare (green line), which is defined as the difference between the total accumulated benefit of the activity (blue line) and the total accumulated cost (red line):</p>

<p><a href=""https://i.stack.imgur.com/vYiai.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vYiai.png"" alt=""total social benefit and cost""></a></p>

<p>The <em>marginal</em> social benefit is <em>the benefit society gains if we increase consumption by one unit</em>. In other words, the MSB is given by the slope of the TSB curve. Similarly, the MSC (defined as the extra cost bourne by society if consumption increases by one unit) is equal to the slope of the TSC curve.</p>

<p>Now, we observe something interesting: the total welfare curve obtains its maximum at exactly the point where the slopes of the TSB and TSC curves are equal:</p>

<p><a href=""https://i.stack.imgur.com/Fo840.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Fo840.png"" alt=""marginal social benefit and cost""></a></p>

<p>In other words, welfare is maximised when MSB=MSC. This is not a coincidence for this particular graph, but rather is a far more general property.</p>

<p>This is actually quite intuitive. Suppose that MSB > MSC. If we increased consumption by one unit then society would get MSB units of extra benefit and MSC units of extra cost. Since MSB > MSC, this results in an increase in total social welfare. Similarly, if MSB &lt; MSC then we could reduce consumption by one unit and society would save more in costs than it would loose in benefits. So neither $MSB&gt;MSC$ nor $MSB&lt;MSC$ can be consistent with maximised social welfare. Only when MSB=MSC do we find that there is no way to increase welfare by increasing or reducing consumption.</p>
","9990"
"What is the correct way to calculate a selling price from margin and a cost?","707","","<p>There seems to be two formula to calculate a selling price.</p>

<p>The first formula that I came upon would be</p>

<pre><code>Cost * (1+Margin) = Selling price
Example : 10 * (1+0.25) = 12.5
</code></pre>

<p>However, a lot of people uses the following :</p>

<pre><code>Cost / (1 - Margin) = Selling price
Example : 10 / (1-0.25) = 13.33...
</code></pre>

<p>This gives a very different number.</p>

<p>As far as I know, the margin and selling prices can be anything you want for most products.</p>

<p>Also note that the second formula fails if you have a margin of more dans 100%.</p>

<p>My question is why is the second formula the most popular ? Is it only a gimmick to get a bigger price?</p>

<p>Am I missing something subtle at work here ?</p>

<p>Also, what should I do if the wanted margin is more than 100% ?</p>

<p>Thanks!</p>
","<p>The ""<strong>margin</strong>"" is a <em>portion of the selling price</em>. It is defined as</p>

<p>$$\text {margin} \equiv \frac {P-C}{P}$$</p>

<p>From the above <em>definition</em>, we see that the margin cannot exceed $100\%$.</p>

<p>If one has the cost and he wants to calculate the price in order to have a specific margin, one must calculate</p>

<p>$$P(\text {margin}^*) = \frac {C}{1-\text {margin}^*}$$</p>

<p>The first formula written in the question is wrong, because it uses ""margin"", but it would become correct if instead one used the concept of ""markup"".</p>

<p>The ""<strong>markup</strong>"" is defined as the percentage increase of cost in order to determine the selling price:</p>

<p>$$\text {markup} \equiv \frac {P-C}{C}$$</p>

<p>It is easy to obtain that the relation between them is</p>

<p>$$\text {margin} = \frac {\text {markup}}{1+\text {markup}}$$</p>
","6093"
"Numerical analysis in economics","704","","<p>Recently, I have become interested in numerical analysis withinin macroeconomics. In particular, I have been trying to learn algorithms such as ""backwards iteration"", the ""shooting method"" etc, in order to numerically solve an optimal control model, more specifically a growth model. </p>

<p>Could you give me some references for introductory and intermediate numerical analysis textbooks ? </p>
","<p>Read the theory and then try coding. But you're lucky, because I was eager to develope and implement the forward shooting algorithm myself and thus provide it.</p>

<h2>Optimal Growth</h2>

<p>(See <a href=""http://www.princeton.edu/~moll/ECO503Web/Lecture3_ECO503.pdf"" rel=""nofollow"">Ben Moll</a> for details.)</p>

<p>Optimal growth model in continuous time reads
\begin{align}
&amp;\max_c\int^\infty_0 e^{-\rho t}u(c)dt\\
\text{s.t.}~~~&amp; \dot k = f(k) - \delta k - c\\
&amp;c\in[0,f(k)]\\
&amp;k(0) = k_0
\end{align}
where 
\begin{align}
f(k)&amp;=Ak^\alpha\\
u(c)&amp;=\frac{c^{1-\sigma}}{1-\sigma}.
\end{align}
From the first order conditions we derive a system of differential equations 
\begin{align}
\dot k &amp;= f(k) - \delta k - c\\
\dot c &amp;= \frac{c}{\sigma}(f'(k) - \delta - \rho)
\end{align}</p>

<p>Fixed points given at
\begin{align}
\dot k &amp;= 0 \quad \Longrightarrow\quad \tilde k = \left(\frac{\alpha A}{\delta+\rho}\right)^\frac{1}{1-\alpha}\\[2mm]
\dot c &amp;= 0 \quad \Longrightarrow\quad \tilde c = f(\tilde k) -\delta \tilde k
\end{align}</p>

<p>Since the system is saddlepoint stable there is only one trajectory converging to the unique steady state. Initial stock is given and thus optimal $k^*(0) = k_0$. We aim to solve for $c^*(0)$. </p>

<p>The idea of shooting is to guess $c(0)$ and then iterate over time. If the time paths lead to the steady state we are done, otherwise we have to try a different guess. First of all we need to discretize the differential equations. (Computer works with discrete steps. However, if you like to work with the differential equations try Matlab's boundary value solver <code>bvp4c()</code>. This works out quite easy. Since we have no clue what the solver is doing, we'd like to solve the equations ""manually"".) The forward difference of some function $\dot x$ is defined as
\begin{align}
\dot x(t) :\approx \frac{x(t+1)-x(t)}{\Delta t}
\end{align}</p>

<p>which gives
\begin{align}
k(t+1) &amp;= \Delta t(f(k(t)) - \delta k(t) - c(t)) + k(t)\\[2mm]
c(t+1) &amp;= \Delta t\frac{c(t)}{\sigma}(f'(k(t)) - \delta - \rho) + c(t).
\end{align}</p>

<p>Since the probability of guessing the correct $c^*(0)$ tends to be zero, we need to apply an algorithm which converges towards the true value. </p>

<h2>Shooting</h2>

<p>The following code snipped is written in Matlab and presents the main idea. </p>

<pre><code>c_lo = 0;
c_hi = A*k(1)^a;
i = 0;
dist_k = tol + 1;
dist_c = tol + 1;
while (i &lt; I) &amp; (dist_k &gt; tol | dist_c &gt; tol);
c(1) = (c_lo + c_hi)/2;
    for t = 1:T-1;
        k(t+1) = del_t*(A*k(t)^a - d*k(t) - c(t)) + k(t);
        c(t+1) = del_t*c(t)/s*(a*A*k(t)^(a-1) - p - d) + c(t);
        if c(t+1) &gt; A*k(t+1)^a
           c(t+1) = A*k(t+1)^a;
        elseif c(t+1) &lt; 0 
               c(t+1) = 0;
        end
    end
    if k(T) &gt; k_ss &amp; c(T) &lt; c_ss
        c_lo = c(1);
        elseif k(T) &lt; k_ss &amp; c(T) &lt; c_ss
        c_hi = c(1);
        elseif k(T) &lt; k_ss &amp; c(T) &gt; c_ss
        c_hi = c(1);
    end
dist_k = abs(k(T) - k(T-1));
dist_c = abs(c(T) - c(T-1));
i = i + 1;
end
</code></pre>

<ul>
<li>Due to time constraint I can't provide a detaild explanation. I hope it's self-explaining. I may answer specific questions which show some effort.  </li>
</ul>

<h2>Boundary Value Problem</h2>

<p>As I mentioned above we can easily solve the system by applying Matlab's boundary value problem solver <code>bvp4c</code>. Using $\tilde c = c(T)$ as a terminal condition we have two ODEs and two boundary conditions.</p>

<pre><code>% differential equations with y(1) = k, y(2) = c
dy = @(t,y) [A*y(1)^a - d*y(1) - y(2); ...     % dk/dt;
             y(2)/s*(a*y(1)^(a-1) - p - d)];   % dc/dt
% boundary conditions
bc = @(y0,yT) [y0(1) - k0;     % initial condition
               yT(2) - c_ss];  % terminal condition

solinit = bvpinit(linspace(0,T,10), [k0 c0]);   % initital guess
sol = bvp4c(dy, bc, solinit);                   % call solver
t = linspace(0,T)';  % time axis
y = deval(sol,t)';   % call solution values
k = y(:,1);    % transform variables
c = y(:,2);    % transform variables
</code></pre>
","7128"
"What is considered a ""final product"" for gross domestic product?","698","","<p>Given a territory and a time range, the gross domestic product is the sum of all the values added. The term “value added” is open to interpretation. Since the value added of a product or service is its total value minus the value of the intermediate product and services used to produce it, it follows that in an identical scenario, the GDP will vary according to what is classified as final products. Yet in reports, a single number is quoted as if it was <strong>the</strong> GDP.</p>

<p>For instance, a factory will need cleaning. Is the service of cleaning a factory considered a final product or intermediate consumption needed to produce whatever the factory produces?. What about the plant's paint, electricity, training of workers and so on?. People need to eat in order to work and produce, and more so the more they work (hence food may be classified as intermediate consumption), and need medical care to live (and hence produce) just like car factories need steel. I have seen these things sometimes taken to be final consumption. The consumption of decoration from a restaurant is a requirement (since people go to a restaurant in part, due to the <em>style</em>) and by that reasoning, it is intermediate consumption, but a luxury in one's house (therefore final consumption). When doing the accounting at an high level (city, state or national), how do the accountants know what part of the paint consumed take as intermediate consumption and what part to take as final consumption?.</p>

<p>The boundary between intermediate and final consumption seems blurry. How, and where is the line drawn. Could you please cite a (preferentially publicly available) relevant document from an organization in charge of computing a GDP about the methodology regarding the intermediate-final consumption?.</p>
","<p>Since you're asking a question about the value-added approach to calculating GDP, the answer that follows talks about the value-added approach. It's worth noting, however, that GDP can (and is) also calculated through two other approaches: the expenditure approach and the income approach. In the US, the value-added approach is used primarily in the GDP-by-industry accounts.</p>

<p><strong>The boundary between intermediate and final consumption seems blurry. How, and where is the line drawn?</strong></p>

<p>Products and services provided to consumers are considered to be final products. Products and services provided to businesses are treated as intermediate inputs. See point 4 on page 3 in this <a href=""http://www.bea.gov/national/pdf/nipa_primer.pdf"" rel=""nofollow"">NIPA primer</a>.</p>

<p><strong>When doing the accounting at an high level (city, state or national), how do the accountants know what part of the paint consumed take as intermediate consumption and what part to take as final consumption?</strong></p>

<p>A simplified answer (ignoring issues like capital consumption and inventories) is that at the national level, business revenue is totaled, and then business expenses (other than labor costs) are subtracted. </p>

<p>So if a restaurant sells \$100 worth of dinners, pays a farmer \$50 for the food, and pays a designer \$10 for designing the restaurant, the totals look like this:</p>

<p>Restaurant: \$100-(\$50+\$10)=$40</p>

<p>Designer: \$10</p>

<p>Farmer: \$50 </p>

<p>Total: \$40+\$10+\$50 = \$100</p>

<p>As you can see in this example, by subtracting business expenses from revenue, double-counting is eliminated.</p>

<p>At the state level in the US, GDP is actually <a href=""http://bea.gov/regional/pdf/gsp/GDPState.pdf"" rel=""nofollow"">allocated from the national level</a> using a variety of techniques. Metro area GDP is <a href=""https://bea.gov/scb/pdf/2007/11%20November/1107_gdpmetro.pdf"" rel=""nofollow"">allocated from the state level to counties</a> based on income by industry and then aggregated. As a result, the value-added approach is simply not used to calculate state and local GDP in the US.</p>

<p><strong>Is the service of cleaning a factory considered a final product or intermediate consumption needed to produce whatever the factory produces?</strong></p>

<p>Intermediate consumption.</p>

<p><strong>What about the plant's paint, electricity, training of workers and so on?</strong></p>

<p>Intermediate consumption.</p>

<p><strong>The consumption of decoration from a restaurant is a requirement (since people go to a restaurant in part, due to the style) and by that reasoning, it is intermediate consumption, but a luxury in one's house (therefore final consumption).</strong></p>

<p>Intermediate consumption.</p>

<p><strong>People need to eat in order to work and produce, and more so the more they work (hence food may be classified as intermediate consumption), and need medical care to live (and hence produce) just like car factories need steel. I have seen these things sometimes taken to be final consumption.</strong></p>

<p>If you refer to the example above, you will see why they're treated as final consumption. The household sector is not treated as a business; if it were, the value-added approach would not work. Wages paid to workers would be subtracted as intermediate inputs, and workers' consumption of whatever they consume would also be subtracted as intermediate inputs, and everything would sum to zero.</p>

<p>If a restaurant sells \$100 worth of dinners, pays a farmer \$50 for the food, pays a designer \$10 for designing the restaurant, and pays workers \$20 for making the food, the totals look like this:</p>

<p>Restaurant: \$100-(\$50+\$10+\$20)=$20</p>

<p>Designer: \$10</p>

<p>Farmer: \$50 </p>

<p>Households: \$20-\$100=\$-80</p>

<p>Total: \$20+\$10+\$50-\$80 = $0</p>

<p>What we've discovered above is called the circular flow of goods and services.</p>

<p>A simpler example can make this obvious: let's say that there exist two businesses in an economy. One grows cabbage, the other raises pork. The cabbage guy gets hungry for some pork, and buys \$10 worth of pork, while the pork guy decides he wants some cabbage and buys some of that for \$10. Under the value-added approach, \$20 of market output has been produced. If we said, ""Hey, wait, but people need to eat food to live!"" and did not count the food production, then we'd end up concluding that \$0 of market output had been produced. That would be incorrect.</p>
","4578"
"Why would a cash-rich company borrow money?","698","","<p>I have read that Apple Computer issues corporate bonds.</p>

<p>Considering that it has $200 billion in cash, and the company complains it has been unable to spend its enormous amount of cash, why would they be issuing corporate bonds?</p>
","<p>You are right that it seems strange why a cash-rich company is borrowing. In the case of Apple, the money that they are borrowing is being used to pay dividends to shareholders. The reason why they aren't using their \$200 billion is because doing so would cost them tens of billions of dollars in taxes. The current US tax code taxes corporations at 35% when they bring money they made overseas back to the US (this is called <strong>repatriation</strong>). So while, Apple has \$200 billion on the surface, \$180 billion of that is sitting overseas and can't be used to pay shareholders. It is cheaper for them to borrow money to pay dividends, than incur the huge tax costs associated with repatriation.</p>

<p>In general, however, borrowing is also attractive to firms today since interest rates are so low. If you can borrow at 4%, and expect to earn a return of 8% on that capital, taking on debt seems like a good deal. Therefore firms flush with cash still may borrow if they feel the return they can earn on the borrowed money is greater than the cost of interest. </p>

<p>Check out this article from Bloomberg for more information on the Apple case: <a href=""http://www.bloomberg.com/news/articles/2015-07-22/tim-cook-s-181-billion-headache-apple-s-cash-held-overseas"">Bloomberg Article</a></p>
","8970"
"What does an individual's demand function describe?","695","","<p>Now, this seems a super easy and straightforward question, right? From wikipedia: </p>

<blockquote>
  <p>The demand curve is the graph depicting the relationship between the price of a certain commodity and the amount of it that consumers are willing and able to purchase at that given price. </p>
</blockquote>

<p>To me, this reads as follows: for an individual, the demand function answers, for all values of $p$, the question: ""if the price is $p$ per unit, how many units $q(p)$ would the individual buy?""</p>

<p>As an example, let's consider my personal demand curve $q = 10-p$ for a certain good. I would interpret that, also with the above definition, as follows: if the price is 10/unit or more, I purchase nothing. If it is 7/unit, I'll purchase 3 units. </p>

<p>The big point here is that this seems to imply, that I'd pay 7/unit for <em>each</em> of the 3 units. <strong>Is that correct?</strong> Things would be different if I were faced with a situation in which I had to pay more for the first 2 units. In that case, I might decide to buy less than 3 units. And I wouldn't be contradicting my demand function. At least, not, if it were as I interpreted the definition.</p>

<p>Alternative: it seems less close to the text, yet much more convenient to the mathematics, to interpret the demand function in the following way. The demand function answers, for all values of $q$, the question: ""if an individual already has $q-1$ units, how much would he be willing to pay for unit $q(p)$?"" (or, as an integral, ""if an individual already has an amount $q$, how much would $p(q)$ be, with $p(q)dq$ the amount he's willing to pay for an additional amount $dq$?"").</p>

<p>Thanks! </p>
","<p>In the discussions with Kun it seems we've found a satisfying answer. </p>

<p><strong>TL;DR</strong>: it is as I suggested in the last paragraph of my question.</p>

<p><strong>Long answer</strong>:</p>

<p>This is becoming a bit of an overkill for a question that could be looked up in a couple of minutes, but it's an interesting exercise to see if we can up with the correct answer ourselves.</p>

<p>What are we trying to accomplish again?</p>

<p>We have</p>

<ul>
<li>An infinitely divisible good</li>
<li>A consumer with demand function $q = Q(p)$ for this good, with corresponding inverse demand function $p=P(q)$. These are described by a curve (the demand curve) in the $q,p$-plane.</li>
</ul>

<p>We are trying to establish if a point $(q,p)$ on the demand curve describes</p>

<ul>
<li><p>A.  the price per unit $p$ that the consumer is willing to pay, for each unit, for a the total quantity $q$, or</p></li>
<li><p>B.  the price per unit $p$ that the consumer is willing to pay for an additional amount $\text{d}q$, given a possession of $q$ units.</p></li>
</ul>

<p>Let our thesis be that it is the latter, and let's see if we run into a contradiction.</p>

<h2>Consumer surplus</h2>

<p>Let's take the simple straight line $p+q=25$, where a constant unit-price of 5 prescribes a demand of 20:</p>

<p><a href=""https://i.stack.imgur.com/X0ynR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/X0ynR.png"" alt=""a simple demand curve""></a></p>

<p>The area between the demand curve, $p=5$ and $q=0$, is called the Consumer Surplus CS, and we can calculate it by integration:
$$\int_5^\infty Q(p)~\text{d}p=\int_5^{25} (25-p)~\text{d}p$$
This is the same as
$$\int_0^{20} (P(q)-5)~\text{d}q=\int_0^{20} \big((25-q)-5\big)~\text{d}q$$
The latter shows the area might be interpreted as the difference between what the consumer is willing to pay and what he is paying -- at least, if our thesis is valid and interpretation (b) holds.</p>

<p>We find that the CS in this case is 200.</p>

<p>Our thesis can help to interpret this. If the price is 5, the consumer keeps on buying until the additional quantity he could buy does not bring that additional utility of 5. That happens to be at a quantity of 20. Because he was able to buy <em>all</em> units at a price of 5, this represents an advantage: he would have paid more for an additional unit when he still had fewer units. E.g. when he still only had 15 units, he would have paid 10 per unit for additional quantity.</p>

<h2>Total Willingness To Pay</h2>

<p>The total willingness to pay TWTP for a quantity $q$ (i.e., the maximum accepted price for that quantity) can be calculated as the sum of the willingness to pay for each subsequent unit until $q$ (i.e., the maximum accepted price per unit for additional units):
$$TWTP(q) = \int_0^{q} WTP(q')~\text{d}q'$$</p>

<p>So, in order to calculate how much our buyer would maximally have paid (in total) for those 20 units, we must add the maximum prices for each individual unit. If our thesis is correct and interpretation (b) holds, this is exactly the inverse demand function $P$, so that
$$TWTP = \int_0^{20} P(q')~\text{d}q'$$
This Total Willingness To Pay for 20 units happens to be 300 in our case.</p>

<p>Now, under normal circumstances the buyer does not <em>need</em> to pay that amount for 20 units, but rather $5\cdot20=100$. The difference between the two is the CS of 200. This is the area above the $p=5$ line, which is what we would expect.</p>

<p>Should we have perfect price discrimination, the seller of the good would know the buyer's demand curve, and sell him each unit of the good at exactly the maximum price he'd be willing to pay for it; gradually dropping the price with the buyer's marginal utility: $p=25-q$. That way, the seller is able to capture all of the CS, and the buyer would thus pay 300 for the 20 units.</p>

<h2>If our thesis is wrong</h2>

<p>This interpretation only works if our thesis is correct and the inverse demand function $P$ describes the willingness to pay for each additional unit. If it describes the willingness to pay per unit for that <em>and all previous</em> units, i.e. interpretation (a), things are different. In that case, the TWTP for $q$ units is simply the multiplication of $q$ and $P(q)$:
$$TWTP(q) = q\cdot P(q)$$
In order to figure out how much would be bought at non-uniform pricing, we need to find the willingness to pay for each unit. That WTP is, as can be seen from the first equation, the derivative of the TWTP, so, in this case:
$$WTP(q)=\frac{\text{d}}{\text{d}q}qP(q)=\frac{\text{d}}{\text{d}q}(25q-q^2)=25-2q$$
So, the first quantity is sold at a unit price of 25, just like before. This makes sense, as the buyer does not have any units yet, so the marginal price equals the average price. Then, however, under perfect price discrimination, the price of the good should drop twice as fast as we have previously calculated. That is due to the fact that the additional unit $\text{d}q$, that the seller is trying to sell, does not have a marginal utility given by its price (as is the case in interpretation (b)) but by the increase in total price.<sup>1</sup>
Moreover, in this situation, the seller sells his last unit for a price of 5, which is when he has sold only 10 units (compared to 20 if interpretation (b) is correct). The buyer has then spent $\int_0^{10} (25-2q)~\text{d}q=150$, which is his TWTP, but for 10 units. This too makes sense: the demand curve prescribes a maximally accepted (average) unit price of 15 - which is exactly what is being paid.</p>

<p>What we cannot see anywhere, is the figure of 200 which is the area above the $p=5$ line. In fact, the Consumer Surplus that was 200 in the case of interpretation (b), is actually 0 in the case of interpretation (a) -- simply because of the way the inverse demand function is defined to be the maximum average unit price: if we have a uniform price, the price is the average price, and the buyer will have an incentive to buy more as long as his willingness to pay is higher than the price. Exactly when he buys the quantity $q$ that, on his demand curve, corresponds to the offered price $p$, is the average price he's willing to pay equal to the offered price. Because the average price he's willing to pay, times the quantity, is the total price he's willing to pay for that quantity, and because that also equals the price he <em>is</em> paying at that point in the curve, his CS is 0.</p>

<h2>Conclusion</h2>

<p>In order to have a sensible interpretation of the area between the demand curve, $p=5$ and $q=0$, called the Consumer Surplus CS, we need to interpret the inverse demand function to mean: ""<em>the price per unit $p$ that the consumer is willing to pay for an additional amount $\text{d}q$, given a possession of $q$ units</em>"" (b).
The common interpretation (a) as ""<em>the price per unit $p$ that the consumer is willing to pay, for each unit, for a the total quantity $q$</em>"" is incorrect. It's easy to see, however, why it is often interpreted that way. Firstly, it is a simpler interpretation that's easier to visualise, and secondly, in everyday situations -- which all have uniform pricing -- it still predicts the correct quantity to be traded.</p>

<hr>

<p><strong>Footnotes:</strong></p>

<p>1:  This gives us another way to come to the formula. Consider the buyer, which buys a quantity $q$ when the average price per unit is $P(q)$. As he buys a quantity $q+\text{d}q$ when the price per unit is $P(q+\text{d}q)$, the total cost increases by $P(q+\text{d}q) - P(q)$, which means that is the utility of the additional unit $\text{d}q$. So, the marginal utility per unit is $\frac{(q+\text{d}q)\cdot P(q+\text{d}q)-q\cdot P(q)}{\text{d}q}$. Using the inverse demand function $P(q)=25-q$, this is turns out to be $25-2q$.</p>
","10711"
"Deriving formulas from Gali's book on the New Keynesian model","688","","<p>I've found this <a href=""http://bergholt.weebly.com/uploads/1/1/8/4/11843961/the_basic_new_keynesian_model_-_drago_bergholt.pdf"" rel=""nofollow"">link</a> with all the derivations from Gali's book on New Keynesian model.
In page 13, eq. $(3.7)$, the author derives the optimal price-setting rule  $P_t^*$ by a representative firm that solves an intertemporal profit maximization problem. Equation $(3.7)$ contains two infinite series. The author then does a log-linearization on both and proceeds to the solution. Log-linearization is a local approximation, right? Then how can we be sure that the two series, with these approximations will converge?</p>
","<p>Mathematically speaking, we are not sure. The infinite sums mentioned is of the form</p>

<p>$$E_t\sum_{k=0}^{\infty}\gamma^kX_{t+k},\;\; 0&lt;\gamma&lt;1$$</p>

<p>The fact that there is the declining factor, $\gamma^k$, provides some comfort that the sum converges, but from examples like <a href=""https://en.wikipedia.org/wiki/Harmonic_series_%28mathematics%29"" rel=""nofollow"">the harmonic series</a> we know that even if $\lim_{k\rightarrow \infty}\gamma^kE_tX_{t+k} =0$, the sum may not converge.  </p>

<p>Some times authors provide rigorous conditions for convergence, but I believe it is more important not to be trapped by our own tools: the use of infinite horizon is, of course, non-realistic. The only reason we use it is that it makes the mathematics more tractable. So in reality we model a problem with possibly long but finite horizon. In such a case, there is no issue of convergence. By extending the problem to the infinite horizon we silently assume that this won't destroy convergence, since it is an <em>artificial</em> extension.</p>

<p>The ultimate economic argument for convergence, is that it is meaningless to talk about economic magnitudes going to infinity. Even for prices, where it is tempting to think that they do not have an upper bound <em>per se</em>, we must remember that <em>prices as a component of an economic system do have ultimate bounds</em>.  </p>

<p>With prices flying to heaven, the economy goes to hell (if you excuse the christian iconography), because the price system stops functioning as a signal mechanism to co-ordinate decisions in a decentralized framework. But in the real world, when such explosions ""start to happen"", the <em>society</em> that encloses the economy in question, will intervene in one way or the other, in order to end the phenomenon. The historical experience from war-time hyperinflations and from other price-bubbles verifies this.  </p>

<p>Ideally, we would want a single model to encompass both possibilities and also model the possible ""extraordinary reaction"" to the explosive case: herein infinite PhDs lie.</p>

<p>Returning to the specific situation from the link, note that the price in eq. $(3.7)$ is determined by the <em>ratio</em> of two such infinite sums. Even from a mathematical point of view, this is a bit more favorable, because even if each sum separately diverges, their ratio may converge. But again, my point is, ""don't let the mathematics make you forget the economics"" of the situation.</p>
","4861"
"How is freelancing viewed under Marxism?","685","","<p>How does Marxism view freelance workers? Since a freelancer is the owner of their means of production, are they still viewed as exploited by the bourgeoisie? Could freelancing exist in a Marxist society?</p>
","<p>Marx addresses this about two-thirds of the way through Section 1 of the <em>Manifesto</em>. In the standard English edition of 1888, it reads:</p>

<blockquote>
  <p>The lower strata of the middle class - the small tradespeople,
  shopkeepers, and retired tradesmen generally, the handicraftsmen and
  peasants - all these sink gradually into the proletariat, partly
  because their diminutive capital does not suffice for the scale on
  which Modern Industry is carried on, and is swamped in the competition
  with the large capitalists, partly because their specialized skill is
  rendered worthless by new methods of production. Thus the proletariat
  is recruited from all classes of the population.</p>
</blockquote>

<p>So his basic argument is that, sure there might be small business owners (freelancers in this example), but that because of 1) inability to compete against large firms ostensibly taking advantage of economies of scale and 2) rapid development of technology, they become obsolete and are driven to the proletariat.</p>
","6186"
"Long Run Equilibrium of Oligopolies","684","","<p>The long run equilibrium of a perfectly competitive market is well established. My question is - are the concepts of a long run equilibrium in a perfect competition extendable (analogous or otherwise) to an oligopoly, specifically considering the the Cournot model and the Bertrand model. </p>

<p>Suppose I want to find the equilibrium number of firms $ N $ in a Cournot model, for example - will the approach be similar to that of a perfect competition? </p>
","<p>The 'long run' assumption is not about whether the firms already on the market are price takers (perfect competition) or oligopolists but whether entry to the market is free. If entry to the market is free then in the long run profits tends toward zero, as a profitable market makes it tempting for more firms to enter.</p>

<p>If you have special asymmetric conditions where some entrants have different cost functions than the new ones the zero profit condition may not hold even in the perfect competition case.</p>
","13960"
"What benefits does Bitcoin (i.e. cryptocurrency) offer?","679","","<p>I really, really like moderate inflation. I live in Sweden where the interest rates just went negative because we are on the brink of deflation, and the rate of inflation we have now is far too low. We have huge problems attracting foreign attention and the swedes don't want to take out loans to invest since paying them back ten years down the road hurts just as bad as paying them now (and there's a real risk it might take more to pay them back later, if we go into deflation). It's a real head ache that's all the talk in our financial world.</p>

<p>Getting a hold of Bitcoin is very, very hard and expensive. The value of it has deflated dramatically from when it was introduced, and despite occasional crashes, it could very well just keep climbing in value. It also has a cap, which to me looks like it would unleash a deflationary spiral that would only end once we find a new currency (like the Great Depression was alleviated when we stopped using the gold standard).</p>

<p>But, I'm a computer scientist and I just can't stop finding bit coin supporters everywhere. It has thousands of evangelical missionaries using blogs and magazines to tout it as a means to liberate us from the bankers. I don't know, can't computer scientists be just as corrupt? It looks like dot coms with access to good cryptographic algorithms and server farms who can work in parallel could game the system even more, and once they've swept up all the bit coins they would wield more power than nation states.</p>

<p>Am I missing something? What does bit coin bring to the table that is worth disregarding deflation? Does it bring positive GDP growth? Ease of investment? Monetary power to the people? How? And, I keep coming back to this, wouldn't all these positives be completely wiped out once the 30s come knocking deflation style?</p>

<p>Why does this currency have so many supporters? Are everyone mad?</p>
","<p>I'd say that some benefits of Bitcoin and other cryptocurrencies (i.e. ""altcoins""), include:</p>

<ol>
<li><strong>Decentralization</strong> -- which is advantageous for those who are skeptical of monetary policy, runs on banks, etc.</li>
<li><strong>Anonymity</strong>, or at least the perception thereof -- with increasingly comprehensive monitoring of transactions (particularly non-cash transactions), those seeking relatively anonymous methods of exchange have traditionally been out of luck in the realm of digital transactions. Bitcoin has widely been regarded as a ""digital cash"", providing some measure of relative anonymity in online transactions, though this is a decreasingly accurate perception as government databases cataloging transactions grow in sophistication (and some of these databases, such as that of the FBI's, have been opened up to public developers via coding marketplaces like Kaggle). Some altcoins, such as Anoncoins, add measures to enhance the benefit of relative anonymity.</li>
<li><strong>Portability</strong> -- they can be easily stored and transported offline (paper-based hashes or QR codes), on portable media, over the Internet, with or without the aid of a ""wallet"" or bank-like service.</li>
<li><strong>Region Neutrality</strong> -- unlike fiat currency or Easter-only currencies such as Perfect Money, cryptocurrencies seem to have less bias based on location or language.</li>
</ol>
","4443"
"How does reducing government spending increase the money supply?","675","","<p>According to the following question, it seems as though cutting back on government spending increases the money supply (the answer is C).</p>

<p><a href=""https://i.stack.imgur.com/ZqnNd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZqnNd.png"" alt=""enter image description here""></a></p>

<p>The only possible explanation I can think of is that in the second fiscal year, the government continues to spend, but this time it spends less while not changing tax revenue (""In the absence of offsetting factors""), hence the MS still grows but the following fiscal year's deficit has reduced.</p>
","<p>The government cuts public spending but continues to ""run a deficit <em>by borrowing from the central bank</em>.""<br>
This is the polite way to say ""increase yearly the money supply by an amount equal to the government's deficit"".  </p>

<p>So the money supply will <em>also increase</em> in the second year, albeit by a smaller amount than before. But increase it will.</p>
","16039"
"Pareto optimality with externalities","671","","<p>I'm reading the book ""Economics of natural ressources and the environment"" written by D. Pearce and R. Turner. They explain that the competitive equilibrium is not a Pareto optimum in case of (positive or negative) externalities. The example they use is a firm that has an activity Q and this activity creates some pollution. They illustrate it in figure 4.1 (figure below). MNPB stands for ""marginal net private benefits"" and MEC ""marginal external cost"". MEC is thus the extra damage done by pollution arising from the activity measured by Q.</p>

<p>The firm will try to maximize its benefit, i.e. reach an activity of Q$^\pi$. Q$^*$ is the level of activity to have a social optimum. I understand the reasoning so far.</p>

<p>What I do not understand is why Q$^\pi$ is not Pareto optimum. If we had to reach Q$^*$ from Q$^\pi$, the firm would loose some of its utility so Q$^\pi$ should be Pareto optimal.</p>

<p>I feel like I do not understand the exact meaning behind the notion of the Pareto optimality.</p>

<p><a href=""https://i.stack.imgur.com/B7riS.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/B7riS.jpg"" alt=""hello""></a></p>

<p>Source of image: ""Economics of natural ressources and the environment"", D. Pearce and R. Turner, Harvester, New York, 1990.</p>
","<blockquote>
  <p>I feel like I do not understand the exact meaning behind the notion of
  the Pareto optimality.</p>
</blockquote>

<p>It's not you.  There are different senses of the phrase ""Pareto Optimal,"" and you have to figure out from context which one is being used.  The dictionary definition of Pareto Optimal is something like ""An allocation from which any feasible change which makes any agent better off makes at least one agent worse off.""  The word to keep your eye on is ""feasible.""  </p>

<p>In particular, it makes a big difference whether or not you consider side-payments feasible.  In your example, if it is impossible to make side payments from ""society"" (i.e. whomever is harmed externally by the production of the good) to the producer, then $Q^\pi$ is Pareto Optimal.  Of course, with no side payments, every point between $0$ and $Q^\pi$ is Pareto Optimal.</p>

<p>Almost always, however, we implicitly assume that side payments are possible.   In that case, the point $Q^\pi$ is not optimal.  Why not?  Well, we could move from $Q^\pi$ to $Q^*$.  This would make the producer worse off by $C$ and ""society"" better off by $C+D$.  Now, if it is feasible to make ""society"" pay the producer some amount between $C$ and $C+D$, then we can say that moving from $Q^\pi$ to $Q^*$ while compensating the producer at least $C$ at the expense of ""society"" makes everyone better off.  The fact that you can move off of $Q^\pi$ while making everyone better off means that $Q^\pi$ is not optimal.</p>

<p>This actually leads into a common criticism of Pareto Optimality.  Normally, we just assume side payments are feasible.  In fact, you get so habituated to making the assumption that it becomes invisible to you.  So, you start to think (for example) that ""free trade is Pareto Optimal"" is a good argument for free trade.  And that's untrue.  The necessary side-payments are probably not feasible and are not actually made in practice.</p>
","14876"
"What is a homothetic function?","670","","<blockquote>
  <p>Suppose we have the following equations for the MRS of a utility function. $$U(x, y)$$
  Which of the following corresponds to a homothetic utility function?</p>
  
  <ol>
  <li><p>$$MRS (x, y) = \frac{x^2+y^2}{xy}$$</p></li>
  <li><p>$$ MRS(x, y) = 2(x + y)$$</p></li>
  </ol>
</blockquote>

<p>The answer is 1. But why the second equation is not homothetic?</p>
","<p>If a utility function is homothethic,
$-\frac {\frac {\partial u}{\partial x} (tx)} {\frac {\partial u} {\partial y} (ty)} = -\frac {\frac {\partial u}{\partial x} (x)} {\frac {\partial u} {\partial y} (y)} $</p>

<p>In other words, the MRS must be homogenous of degree zero.</p>

<p>Hence, for $MRS(tx,ty)=2(tx+ty)=2t(x,y)=t MRS(x,y)$ is homogenous of degree 1</p>

<p>While $MRS(tx,ty)=\frac{(tx)^{2}+(ty)^{2}}{(tx)(ty)}=\frac{t^{2}(x+y)}{t^{2}(xy)}=\frac{x^{2}+y^{2}}{xy}=MRS(x,y)$ is homogenous of degree 0.</p>
","13917"
"What are is the reasoning behind the sharp fall of oil prices starting in mid 2014?","667","","<p>Things I have considered: </p>

<ul>
<li><p>Poor economic conditions around the world could have caused an unpredicted decrease in demand. The resulting surplus has begun driving prices down. </p></li>
<li><p>This could be exacerbated by a decade of record-high prices that spurred massive investment that changed supply capacity. I know part of this could also be a result of technological innovation that, over the last few years, has changed supply capacity. Add to this the relatively recent discovery of new pockets of oil/natural gas here that producers have begun exploiting. </p></li>
<li><p>Consumer's expect prices to continue falling and so they forgo purchasing fuel if possible. This slowdown in demand can actually help fuel that expected price drop. This could contribute to a steady downward pressure, I think. </p></li>
<li><p>Geopolitical relations between America, Saudi Arabia, Russia and Iran. I know that Saudi Arabia and co. could slash production in an attempt to remove the excess supply and drive prices of oil up again. </p></li>
<li><p>America is now a (the?) leading oil producer world wide and the USA do not import nearly as much oil as it once did. The fact that the USA are using oil extracted and refined domestically has obvious implications etc. An interesting question is how OPEC's recent announcement to not cut production and instead let prices stay low might affect domestic production where things like horizontal drilling and fracking drive up the cost of extraction. </p></li>
</ul>

<p>I would really appreciate a substantiated walkthrough of what has caused this very sharp turn around in oil prices. I know the last decade was a time of record highs...so why now the massive landslide in the value of oil?</p>

<p>I should say I am hoping to hear from economists who perhaps have some specialized knowledge here. I do have an undergrad degree in economics and I have read and am familiar with most of the general arguments.  I am looking for a well substantiated and thorough answer that will deepen my understanding of this issue.</p>
","<p>My understanding of the recent drop in oil price is due to recent changes in US drilling. They are now the worlds largest oil producer. <a href=""http://www.economist.com/blogs/economist-explains/2014/12/economist-explains-4"">This article</a> by the economist does a good job explaining.</p>

<p>My answer (borrowed very heavily from the economist.)</p>

<ul>
<li><p>Demand is low because of weak economic activity, increased efficiency, and a growing switch away from oil to other fuels.</p></li>
<li><p>America has become the world’s largest oil producer, creating a lot of spare supply. </p></li>
<li><p>The Saudis and their Gulf allies have decided not to sacrifice their own market share to restore the price. They could curb production sharply, but the main benefits would go to countries they detest such as Iran and Russia. Saudi Arabia can tolerate lower oil prices quite easily. It has \$900 billion in reserves. Its own oil costs very little (around $5-6 per barrel) to get out of the ground.</p></li>
</ul>

<p>For further reading, the NY times has a <a href=""http://www.nytimes.com/2015/01/13/business/energy-environment/oil-prices.html?_r=0"">decent article</a> explaining it a little more.</p>

<p>edit:
I think it is safe to assume that OPEC has market power. They can get oil far cheaper than their competitors (as referenced above).</p>

<p>With that in mind,
The below reference provides a model which explains what we are experiencing here. Cournot competition seems a perfect model to use.</p>

<ul>
<li>Naoum-Sawaya, J. and Elhedhli, S. (2010). Controlled predatory pricing in a multiperiod Stackelberg game: an MPEC approach. J Glob Optim, 50(2), pp.345-362.</li>
</ul>

<p>A key quote from the above article: <strong>""After reducing or eliminating competition, the predatory firm
can raise its price and compensate the loss by earning monopoly profits in the long run""</strong>.</p>

<p>This second provides a very brief overview of OPEC and their behaviour.</p>

<ul>
<li>OPEC reflects on its history. Salisbury, Peter, Middle East Economic Digest.</li>
</ul>

<p>I couldn't find an empirical study comparing a Stackleberg model to the OPEC cartel but I do not doubt that this has been done to death.</p>
","2984"
"Slope of a production function","666","","<p>Let $F(K,L)$ be a production function with variables $K$ for capital and $L$ for labor.</p>

<p>The slope of the $F(\overline K,L)$ ($K$ taken constant) is defined as the marginal product of labor ($MPL$) such that:</p>

<p>$$MPL=F(K,L+1)-F(K,L)$$</p>

<p>Most production functions have a positive decreasing slope due to diminishing marginal product and therefore are not straight lines. How is the $MPL$ formula still valid? Isn't that the same formula to find a gradient $m$ of a line (i.e. $\frac{y_{2}-y_{1}}{x_{2}-x{1}}$)? If we take any function whose representation isn't a line, its slope at a certain point is equal to the slope of the tangent at the point and not the formula for the gradient $m$.</p>

<p>Also, supposing the given formula for $MPL$ is true, shouldn't we also have $MPL=\frac{\partial F}{\partial L}$?</p>
","<p>The (partial) derivative of a continuous function is defined as
\begin{align}
\frac{\partial F(\overline K, L)}{\partial L} := \lim_{\Delta L \to 0}\frac{F(\overline K, L + \Delta L) - F(\overline K, L)}{\Delta L}.
\end{align}
Now if $L \in \mathbb{N}$, then you have a lower bound for the increment $\mathbb{N} \ni \Delta L \geq 1$. Otherwise the definition above is not well defined for $\Delta L = 0$.
Such that we finally arrive at the approximation
 \begin{align}
\frac{\partial F(\overline K, L)}{\partial L} \approx \frac{F(\overline K, L + 1) - F(\overline K, L)}{1}.
\end{align}</p>
","13303"
"Why couldn't the Karush-Kuhn-Tucker optimization find the solution?","666","","<p>I have the following utility maximization problem:
$$\max (xy)$$
$$(x+y-2)^2 \leq 0$$
Conditions:
$$y-2\lambda (x+y-2) =0$$
$$x-2\lambda (x+y-2) =0$$
$$\lambda(x+y-2)^2=0$$</p>

<p>When I set $\lambda&gt;0$, I get:
$$(x+y-2)^2=0 \Rightarrow (x+y-2) = 0$$
$$y-2\lambda (x+y-2) = y = 0$$
$$x-2\lambda (x+y-2) = x = 0$$</p>

<p>But the obvious solution is $x=y=1$.</p>

<p>When I set $$\lambda=0$$ that's not a case with a valid solution either. Is the constraint too low? What is the explanation to this?</p>

<p>I would greatly appreciate your help.</p>
","<p>As @user32416 pointed out the first order stationarity conditions are not enough. Specifically it seems that you violate <a href=""https://en.wikipedia.org/wiki/Slater%27s_condition"" rel=""nofollow"">Slater's condition</a>, which states that ""the feasible region must have an interior point"". There are no $x,y$ for which 
$$(x+y-2)^2 &lt; 0.$$</p>

<p>If you rephrase the problem to
$$\max (xy)$$
$$x+y-2 = 0$$
$$x,y \geq 0$$
Slater's condition is met (for linear conditions no interior points are necessary) and you can apply Karush-Kuhn-Tucker.</p>
","8791"
"Difference between 'ideal variety' and 'love of variety' - International trade","664","","<p>What really is the difference between the ""ideal variety"" (Lancaster) of a differentiated product approach and the ""love of variety"" (Dixit and Stiglitz) approach?</p>
","<p>Basically, the difference is that in the <strong>love of variety</strong> approach the entry of new varieties in the market does not ""crowd"" variety space. So, differentiated varieties may exhibit a high or low degree of substitutability, but this is invariant to the number of products in the market. Hence, consumers ""love"" variety, in the sense that increased variety improves welfare.</p>

<p>In the Lancaster <strong>ideal variety</strong> approach, entry of new varieties causes ""crowding"". Goods become more substitutable as more varieties enter the market. So, the marginal utility of new varieties falls as the market size grows.</p>

<p>These two approaches have different implications for welfare of small and large countries as discussed in <a href=""http://www.krannert.purdue.edu/faculty/hummelsd/research/iv_final.pdf"" rel=""nofollow"">Hummels and Lugovskyy</a>. </p>
","9319"
"von-Neumann-Morgenstern v. Bernoulli Utility Function","664","","<p>A great deal of time is spent distinguishing the big $U$ (von-Neumann-Morgenstern)v. small $u$ (Bernoulli Utility Function). The v.NM function maps from the space of lotteries to real number as it represents the preference defined on the lottery space while the Bernoulli is defined over sure amounts of money.</p>

<p>Why is this distinction so important in the theory of expected utility? Also, what does this distinction enable us to achieve that is important in the expected utility theory? What is the most intuitive way to understand the expected utility theory is constructed in this way?</p>
","<p>Bernoulli utility represents preference over <strong>monetary outcomes</strong>. In a way, this is no different from the typical utility functions defined over consumption bundles. </p>

<p>vNM utility, in contrast, represents preference over <strong>lotteries of monetary outcomes</strong>. Thus, the argument of vNM utility is an object related to, but categorically distinct from, the object that is an argument of Bernoulli utility.  </p>

<p>For example, Bernoulli utility function allows us to compare the utilities from having $\$5$ to having $\$7$, while vNM utility allows us to compare utilities from the lottery $(0.2\otimes\$5,0.8\otimes\$7)$ --- having $\$5$ with $20\%$ and $\$7$ with $80\%$ --- to the lottery $(0.6\otimes\$5,0.4\otimes\$7)$ --- having $\$5$ with $60\%$ and $\$7$ with $40\%$. </p>

<p>In this sense, the distinction between Bernoulli and vNM utility functions are necessary (as they are applied to different objects) rather than important (since they both represent some kind of preference in the end), as @denesp says in his comment.</p>

<p>Moreover, if we only consider degenerate lotteries, i.e. the probabilities are either $0$ or $1$, then vNM and Bernoulli utilities coincide. 
That is, the Bernoulli utility of having $\$5$ is exactly the same as the vNM utility of having $\$5$ with $100\%$. Therefore, distinguishing Bernoulli from vNM utility functions enables us to examine the effects of <em>uncertainty</em> apart from the mere quantity of ""stuff"" (be it goods or money). </p>

<p>Lastly, defining utility over money also allows us to study people's attitudes towards risk. </p>
","16546"
"How will the Brexit affect the Euro and the Pound?","661","","<p>The question is the title: How will the brexit affect the euro and the pound?</p>

<p>It looks like GBP is facing a <strong>tough</strong> situation. It is at its <em>lowest</em> value since 1985. Has GBP dropped permanently(or for a really long time)?</p>

<p>But, what will this mean for the EUR? IMO the EUR will also fall heavily, because a big country from the EU has called quits. This can potentially destroy needy countries(read: Greece).</p>

<p>What do you think about it? Will the Pound and/or the Euro rise or fall(compared to the USD)?</p>
","<p>I think you are right to assume that both the EUR and the GBP are going to fall. </p>

<ol>
<li><p>Fall in investment, uncertainty about the future, trouble exporting, and facing the high probability of loss of at least a part of the banking sector will in the short term probably trigger at least a small recession in the UK, accompanied by consumer price inflation due to higher import prices due to a weakend pound. A looming Scottish independence referendum is also not beneficial in this situation. Since the British Government is likely forced to intervene with a stimulus program of some kind, they will have to finance it, which means more debts financed by QE. Expecting QE, investors and speculators will flee into ""save"" currencies, like the CHF or the JPY. The last part, while apparently not yet finished, has basically already happened.  </p></li>
<li><p>BrExit will shift vote majority inside of what remains of the EU from North to South. Which means countries like France, Portugal, Italy, Spain and Greece will push for a weaker currency (aka. more QE to buy government bonds) to finance their ever mounting debt burden. </p></li>
<li><p>With BrExit, a lot of Eastern European workers currently working in Britain might, and eventually will, have to return to their respective homelands by the time their visas expire. Since job prospects and pay in Poland, Slovakia, Romania + Bulgaria are admittedly miserable and I would try to escape it, too, this ""innovative specialists"" will undoubtedly seek employment in the rest of the remaining EU, which might trigger the domino effect by being the spark that ignites an already more than full powder chamber, especially when it comes true that BrExit means less growth in an already troubled Euro-area - and there is little reason to believe that it won't. </p></li>
<li><p>2) in turn is bad for the northern European states, like Denmark, Sweden, Austria, the Netherlands, Germany, etc. as it means they are going to finance the South's debts against their will with their ""assets"", aka mostly future pensions. Also, Brexit will increase the remaining states contribution to the EU budget, for example the German contribution to the EU budget will rise by appx. USD 2*10<sup>9</sup> (half of which will flow into agricultural subsidies, not anything productive or innovative or growth-stimulating). This 2 billions will have to be cut somewhere else, where that money would also be needed, such as education - and where that money actually would boosts both, future industrial innovation and growth. This and popular pressure due to unemployment as a result of EU-inflicted migration might make Northern States push for an EU-exit as well, especially in Sweden, Germany and the Netherlands, where the EU is, despite the suggestions of some official polls, even less popular than in Britain. And with elections in Germany moving closer, and the ""Euro-sceptical"" AFD on there rise, the Merkel government is not going to stay there for all that much longer. </p></li>
<li><p>Insecurity about the economic and political future, as well as perceived or actual political and/or economic instability is going to do the rest for the EUR. No sane investor likes these things. </p></li>
</ol>
","12534"
"Quasilinear Utility: Pareto Optimality Implies Total Utility Maximization?","658","","<p>I read that if we have quasilinear utility for all consumers, then any pareto optimal allocation maximizes the sum of utility levels of all consumers. That is:</p>

<p>$\textbf{What we know:}$
$$1)\quad u^i(m^i,x^i)=m^i+\phi^i(x^i)\; \quad \forall i=1,...,I$$
$$2)\quad\phi^i(\;)\;\text{is continous and strictly increasing (but not necessarily differentiable)}$$
$$3)\quad \text{An allocation,}\,x\, \text{satisfies}\;\neg\,\exists\,\hat{x}\; s.t. \;\hat{m}^i+\phi^i(\hat{x}^i)\geq m^i+\phi(x^i)\;\forall i$$
$$\text{and} \quad \hat{m}^i+\phi^i(\hat{x}^i)&gt; m^i+\phi(x^i)\,\text{for some}\,i$$</p>

<p>$\textbf{What to show:}$
$$x\;\text{solves}\;max\sum_{i=1}^Im^i+\phi^i(x^i)$$</p>

<p>Can anyone provide a proof of this? Any help would be greatly appreciated!</p>

<p>$\textbf{Edit:}\,$I don't know if this is the right path, but by the strict increasing property of $\phi(\,)$, preferences satisfy local non-satiation, which implies they satisfy the first welfare theorem. Now, If I could figure out whether all pareto optimal allocations are competitive equilibria with quasilinear utility, I may be on to something!  </p>
","<p><strong>Edit:</strong> Edge cases suck; see comments. See also MWG Chapter 10 section C, D.</p>

<hr>

<p>Suppose $(\vec x^*, \vec m^*)$ solves</p>

<p>$$\max \sum^I_{i=1} m_i + \phi_i(x_i)$$</p>

<p>but is not Pareto optimal.</p>

<p>$$\begin{align}
\implies \exists \ (x_i', m_i') \quad \text{s.t.} \quad &amp; u_i(x_i', m_i') \geq u_i(x_i^*, m_i^*) \quad \forall \ i = 1,\cdots,I \\
&amp; u_i(x_i', m_i') &gt; u_i(x_i^*, m_i^*) \quad \text{for some} \ i
\end{align}$$</p>

<p>$$\implies \sum^I_{i=1} m'_i + \phi_i(x'_i) &gt; \sum^I_{i=1} m^*_i + \phi_i(x^*_i)$$</p>

<p>which is a contradiction. If we have a solution to the utility maximization problem, it must be Pareto optimal.</p>

<p>(Note that this comes form continuous and increasing properties of $\phi(\cdot)$)</p>

<hr>

<p>Suppose $(\vec x^*, \vec m^*)$ is a feasible Pareto optimal allocation, but does not solve</p>

<p>$$\max \sum^I_{i=1} m_i + \phi_i(x_i)$$</p>

<p>Because we treat $m_i$ as numeraire and $\phi_i(\cdot)$ is strictly increasing, we know $u_i(\cdot)$ is locally non-satiated. The Pareto allocation should be just feasible.</p>

<p>$$\exists \ (x_i', m_i') \quad \text{s.t.} \quad \sum^I_{i=1} m'_i + \phi_i(x'_i) &gt; \sum^I_{i=1} m^*_i + \phi_i(x^*_i)\\
\implies \boxed{ \sum^I_{i=1} \phi_i(x'_i) &gt; \sum^I_{i=1} \phi_i(x^*_i)}$$</p>

<p>If this is true because this alternative allocation simply gives an individual more of $x$, for all else equal, then the alternative allocation is infeasible. So we'd have a contradiction.</p>

<p>If this is true because in the alternative allocation, someone else is allocated more $x$ and just one other person is allocated less, then the original allocation would not be Pareto optimal. Suppose it was. If you took the original allocation and shifted $x$ in the way of the new allocation, then you would need a corresponding trade in the numeraire good, $m$, to keep whoever is losing $x$ at least at the same utility level. But <strong>trades in just the numeraire good can never change summed aggregate utility</strong>. From the original allocation, if you can trade $m$ for $x$ and make someone better off without hurting anyone, you weren't at a Pareto optimum, and if you can't trade $m$ for $x$ to make someone better off, you can't increase summed aggregate utility, which means the original allocation was a solution to the maximization problem.</p>

<p>This logic applies no matter how you rearrange $x$ between multiple people.</p>

<p>$\square$</p>
","12342"
"list of math intense graduate level microeconomics books?","657","","<p>List of math intense graduate level microeconomics books?</p>

<p>Except Reny's book, krep's books, varian's book and mas-collell's book</p>

<p>books from subfields are acceptable, however by math intense i mean most of the books pages contain some level of math</p>

<p>Please categorize the book</p>
","<p>For game theory:</p>

<p><em><a href=""https://mitpress.mit.edu/index.php?q=books/game-theory"" rel=""nofollow"">Game Theory</a></em> by Fudenberg and Tirole</p>

<p><em><a href=""https://books.google.ca/books?id=jhEU8f6J0IQC&amp;dq=mailath%20samuelson%20repeated%20games%20and%20reputations&amp;source=gbs_navlinks_s"" rel=""nofollow"">Repeated Games and Reputations : Long-Run Relationships</a></em> by Mailath and Samuelson</p>

<p><em><a href=""https://mitpress.mit.edu/index.php?q=books/theory-learning-games"" rel=""nofollow"">The Theory of Learning in Games</a></em> by Fudenberg and Levine</p>

<p><em><a href=""https://mitpress.mit.edu/books/evolutionary-game-theory"" rel=""nofollow"">Evolutionary Game Theory</a></em> by Weibull</p>
","6201"
"How to estimate parameters in a utility function?","654","","<p>Utility function is $U = X^aY^b$.</p>

<p>It is a Cobb-Douglas function, and there are data for $X$ and $Y$.</p>

<p>I would like to know how to estimate $a$ and $b$.</p>
","<p>as @ts_highbury mentioned above you can take the natural logarithm on both sides of Cobb-Douglas equation $$\ln(U) =a\ln(X)+b\ln(Y)$$ after that ""obviously"" you can notice the equation became linear in parameters (i.e linear equation), so you can use a various types of estimation methods but most famous also easy one is the Least squares method.</p>

<p>P.S: be careful in interpreting the results after taking the natural logarithm or you can just take the exponentiation on both side of the linear Cobb-Douglas equation (after taking natural logarithm) and you will have the original form of Cobb-Douglas equation.</p>
","13053"
"Extensive form: backward induction & subgame perfect nash equilibria?","648","","<p><img src=""https://i.stack.imgur.com/rAd0k.jpg"" alt=""enter image description here""></p>

<p>I've been given the SPNE through backward induction, I just want to understand how to interpret the equilibria properly.</p>

<p>The SPNE: $(agi,de)$ and $(bgi,df)$</p>

<p>For instance, how would I interpret $(agi,de)$?</p>

<p>Please let me know if the following would be an accurate interpretation of the above:</p>

<ul>
<li>If A chooses <em>a</em> first, then B will play <em>d</em>.</li>
<li>In the event that we end up on the right hand side of the extensive form, B will select <em>e</em> and A will subsequently select <em>g</em>. However, if given the opportunity, A will select <em>i</em>.</li>
</ul>

<p>This is supposed to be a complete contingent plan of action for both players (i.e. if it were in matrix form then we would be looking at all possible strategies for all players).</p>

<p>I find the first part quite easy, i.e. If A selects <em>a</em>, then B will select <em>d</em> which can be represented by $(a,d)$. However, I am getting confused when I have to account for all possible strategies that could be played $\rightarrow$ $(a \color{blue}{gi},d \color{blue}{e})$.
I would appreciate it if you could offer some advice.</p>
","<p>Until the last paragraph your interpretation is correct.
$(a,d)$ is not a strategy profile, it is merely a 'history', a way that the game can play out. </p>

<p>A strategy of a player is a function that chooses an action in each of her decision nodes. As you can see in your graph Player A has three decision nodes while B has two. Hence any strategy of player A will consist of three elements, while any strategy of B will consist of two elements. So $(agi,de)$ is indeed a strategy profile. The corresponding history, what will happen if the players play these strategies, is $(a,d)$. The corresponding payoff is (1,2).</p>

<p>I am unsure what you mean by having to account for all possible strategies.
Do you want to see what it means when an equilibrium is not subgame perfect?
That would be $(ahj,de)$. No player can gain by unilaterally switching to another strategy, but if we were to reach player A's second or third decision node his action would not be optimal. But $(ahj,de)$ can be an equilibrium because the history given by this strategy profile never reaches these nodes.</p>

<p>Do you want to find all the equilibria that are not subgame perfect? In that case you should write down all possible strategies:
There are 2^3 strategies for A, 2^2 strategies for B. Make a matrix using these as row and column labels. (Not sure if you really want to do this, as it is rather large.) Then you calculate the history and payoff for each strategy profile, creating a payoff matrix. In this you will find many equilibria. The ones that are not $(agi,de)$ and $(bgi,df)$ are not subgame perfect.</p>
","5119"
"Why could interest rates go up if Brexit happens?","648","","<p>I was reading this article, <a href=""http://www.theguardian.com/business/2016/apr/15/george-osborne-says-brexit-will-drive-up-interest-rates"" rel=""nofollow"">George Osborne says Brexit would drive up mortgage rates</a>:</p>

<blockquote>
  <p>George Osborne has issued a stark warning that mortgage rates will
  rise if Britain leaves the European Union.</p>
  
  <p>The chancellor said he thought it was likely interest rates, and
  therefore the cost of home loans, would rise if Britons vote to leave
  the EU in the referendum on 23 June. But Brexit campaigners accused
  Osborne of panicking and resorting to intimidating voters. </p>
  
  <p>Asked if he thought the cost of mortgages would increase on a British
  exit from the 28-nation bloc, Osborne said: “The short answer is yes.
  I think that is likely, but I’m not in charge of interest rates.”</p>
</blockquote>

<p>I was wondering what is the transmission mechanism for explaining why interest rates would have to go up if Brexit happens? Moreover, is there any historical example and precedent for this happening?</p>
","<p>What would happen in the event of a ""Leave"" vote in the referendum? Well, the pound would quickly fall in value against its major trading partners - and some falls have already happened as the ""Leave"" vote appears to increase in probability. That makes imports more expensive, which is directly inflationary. Which pushes the Bank of England (the UK's Central Bank) to raise interest rates in response.</p>

<p>On top of that there are second-order effects which would pull in the other direction, but over a longer time period: there's the directly deflationary effect of the significant increase in unemployment. And the increased risk of further disintegration of the EU, with all the consequential risks to peace and prosperity that that would bring.</p>

<p>And as Alexis L. points out, the UK leaving the EU adds significant risk to the UK's currency; and that corresponds to a need for a higher return on the currency: that return is the interest rate. That's because if interest rates are too low, then people would keep selling the pound sterling, and it would keep dropping in value, pushing up inflation (requiring higher interest rates), and harming UK companies that rely on exports (creating political pressure to do something about the exchange rate - and that ""something"" is higher interest rates).</p>
","11598"
"Currency Devaluation and the causes of the Tequila Crisis","645","","<p>I was reading about some of the famous crisis that happened in the past and i came across ""the tequila crisis"" in mexico during 1994-96.</p>

<p>As a background, The Tequila crisis (also known as the Mexican Peso Crisis or December mistake crisis) was a currency crisis sparked by the Mexican government's sudden devaluation of the peso against the U.S. dollar in December 1994, which became one of the first international financial crises ignited by ""capital flight"", as investors pulled out of Mexico.</p>

<p>The extended issuance of Tesbonos, a mexican bond also contributed to the crisis</p>

<p>What are the mechanisms for a currency devaluation in a case like this?</p>
","<p>The Mexican government has a complicated history of currency intervention, which can be read about in a detailed timeline <a href=""http://intl.econ.cuhk.edu.hk/exchange_rate_regime/index.php?cid=17"" rel=""nofollow"">here</a>.</p>

<p>However, in 1994 the devaluation was caused by the end of government intervention. Up until that date the Mexican government had a set range of USD values that the peso could float within, so a sort of flexible peg to the USD. In December of 1994 the government decided to allow the peso to float freely and the peso was devalued naturally through market forces.</p>
","6079"
"Why did the Federal Reserve change the data about USA GDP?","644","","<p>This is the data published on <strong>20 March 2013 FOMC meeting</strong>:
(<a href=""http://www.federalreserve.gov/monetarypolicy/fomcprojtabl20130320.htm"">http://www.federalreserve.gov/monetarypolicy/fomcprojtabl20130320.htm</a>)</p>

<blockquote>
  <p><strong>20 March 2013,</strong></p>
  
  <p><strong>Change in real GDP (actual):</strong></p>
  
  <blockquote>
    <ul>
    <li>year 2008: <strong>-3.3%</strong></li>
    <li>year 2009: <strong>-0.1%</strong></li>
    <li>year 2010: <strong>+2.4%</strong></li>
    <li>year 2011: +2.0%</li>
    <li>year 2012: <strong>+1.6%</strong></li>
    </ul>
  </blockquote>
</blockquote>

<p>This is the data published on <strong>18 September 2013 FOMC meeting:</strong>
(<a href=""http://www.federalreserve.gov/monetarypolicy/fomcprojtabl20130918.htm"">http://www.federalreserve.gov/monetarypolicy/fomcprojtabl20130918.htm</a>)</p>

<blockquote>
  <p><strong>18 September 2013,</strong></p>
  
  <p><strong>Change in real GDP (actual):</strong></p>
  
  <blockquote>
    <ul>
    <li>year 2008: <strong>-2.8%</strong></li>
    <li>year 2009: <strong>-0.2%</strong></li>
    <li>year 2010: <strong>+2.8%</strong></li>
    <li>year 2011: +2.0%</li>
    <li>year 2012: <strong>+2.0%</strong></li>
    </ul>
  </blockquote>
</blockquote>

<p>As you can see, the GDP data for year 2008, 2009, 2010 and 2012 that published on 20 March 2013, and the data that published on 18 September 2013 is different.</p>

<p><strong>Why did the Fed change the data?</strong></p>
","<p>@BB King's answer is good, but I want to make one point very clear:</p>

<p><strong>The Fed did not change the data.</strong></p>

<p><em>The Bureau of Economic Analysis revised the data</em> as a part of its 2013 comprehensive revision process, which it engages in every five years using data from the most recent <a href=""http://www.census.gov/econ/census/"">Economic Census</a>.</p>

<p>It may be worth noting that the BEA, which is the agency that is responsible for estimating US GDP, is housed in the US Department of Commerce, and as such is wholly independent of the Federal Reserve.</p>

<p>The changes made in the 2013 comprehensive revision are <a href=""http://www.bea.gov/scb/pdf/2013/09%20September/0913_comprehensive_nipa_revision.pdf"">discussed here</a>, with a table showing annual changes on page 16. Note that the annual numbers shown in the article do not align with the numbers shown in the Fed's table because the BEA publishes percent change in <em>annual</em> real output, while the numbers used by the Fed in your links are showing the percent change in <em>4th-quarter</em> real output, which can affect how the timing of changes appears. As a result, the major slowdown that occurred in 2008 Q4, for example, shows as a large drop in 2008 4th-quarter output and a small change in 2009 4th-quarter output using the quarterly comparison shown by the Fed, while it shows up as a small decrease in overall 2008 output and a large decrease in overall 2009 output using the annual numbers shown in the BEA's table.</p>
","8385"
"Why are some economists remarkably productive?","643","","<p>I'm a first year PhD student and I randomly go to different professors' websites to admire their works. Usually an economist has around 20 published papers when he/she reaches professorship. But there are a few outliers, like Andrew Lo, Darrell Duffie, Kenneth Singleton and Paul Samuelson, who have like a few hundred of papers published. Are they simply more productive than others? Is the number of publications (of course above a certain standard of quality) a good indicator of the economist's ability?</p>
","<p>A short answer to your question is both yes and no. You have to first define productivity: productivity, in my opinion, cannot simply mean publishing the <em>number</em> of articles, but rather, their impact. A typical way of modelling the impact of authors is by looking at their h-index. There are many other ways of measuring productivity as well- <em>where</em> the articles are published is important as well. The top 5 journals in economics are (in no particular order): Econometrica, AER, QJE, JPE and ReStud. Articles published in these journals are generally of high quality. However, there are many articles that are published in these journals that do not always have the desired impact. Many a time, articles ranked in lower journals have a high impact. Consequently, it is extremely difficult to measure productivity. To me, the h-index is a good measure.</p>
","8530"
"Is DARA utility implying CRRA most of the time?","641","","<p>The Wikipedia page on <a href=""https://en.wikipedia.org/wiki/Risk_aversion"" rel=""nofollow"">risk aversion</a> states that a ""Constant Relative Risk Aversion implies a Decreasing Absolute Risk Aversion, but the reverse is
not always true"". Let me decompose this statement in two parts:</p>

<p>1/ ""Constant Relative Risk Aversion implies a Decreasing Absolute Risk Aversion."" </p>

<p>A simple example is the log utility function, $u(c) = \ln(c)$, with $c&gt;0$ satisfies the DARA because the utility function is positively skewed $\left(u'''=\frac{2}{c^3} &gt;0\right)$ and implies a Relative Risk Aversion equals to $1 \left(=-c\frac {u''(c)}{u'(c)}\right)$. </p>

<p>2/ ""but the reverse is not always true"".</p>

<p>I am wondering if this is the most frequent case? Or if most of the time DARA utility functions also exhibit CRRA?</p>

<p>I would be grateful if you can illustrate your answer with some utility functions.</p>
","<p>Using the results derived <a href=""https://economics.stackexchange.com/a/468/61""><strong>in this answer</strong></a> we have the following relations for any utility function: </p>

<p>(Absolute Risk Aversion = $A(c)$, Relative Risk Aversion = $R(c)$) : 
$$A(c) = -\frac {u''(c)}{u'(c)},\;\;\; R(c) = cA(c), \;\; A(c) = \frac 1c R(c)$$</p>

<p>and so </p>

<p>$$\frac {\partial A(c)}{\partial c} = \frac {\partial [(1/c)R(c)]}{\partial c}= -\frac 1{c^2} R(c) + \frac 1{c}\frac {\partial R(c)}{\partial c}  \tag{1} $$</p>

<p>and </p>

<p>$$\frac {\partial R(c)}{\partial c} = \frac {\partial [cA(c)]}{\partial c}=A(c) + c\frac {\partial A(c)}{\partial c} \tag{2} $$</p>

<p>Remembering that these measures are mainly discussed for utility functions where $u''&lt;0$, and so they are seen as algebraically positive, we can deduce which relations hold with certainty and which do not.</p>

<p>Now $ARA$ satisfies as an identity</p>

<p>$$u''+ A(c)u' \equiv 0 \implies u''' + A'u' + A u'' = 0 \implies u''' = -A'u' + A (-u'')$$</p>

<p>The $DARA$ family is characterized by $A' &lt;0$ so we obtain that (sufficient)</p>

<p>$$DARA \implies u'''&gt;0$$</p>

<p>So assuming $DARA$ what we gain in knowledge is that $u'''&gt;0$.  </p>

<p>In turn $RRA$ satisfies as an identity</p>

<p>$$cu''+ R(c)u' \equiv 0 \implies u''+ cu''' + R'u' + R u'' = 0$$</p>

<p>$$ \implies c u''' = -R'u' + (-u'')(1+R)$$</p>

<p>Assuming $DARA$, we have $u'''&gt;0$ and so what we know is that</p>

<p>$$ -R'u' + (-u'')(1+R) &gt; 0 \implies (-u'')(1+R) &gt; R'u'$$</p>

<p>$$\implies R(1+R) &gt; c\cdot R'$$</p>

<p>This is the constraint that $DARA$ imposes on $RRA$. We see that the inequality can be satisfied with $R'$ negative or zero, and even positive, up to a degree.</p>
","10873"
"How to solve Bertrand Equilibrium with a non-constant MC?","639","","<p>I know that Bertrand Oligopolies will charge a price equal to marginal cost. But if marginal cost is, say, </p>

<blockquote>
  <p>2Q or 4Q^2</p>
</blockquote>

<p>(i.e. not constant) then how does one determine where, on the MC curve, the equilibrium lies?</p>

<p>If there are 5 Bertrand firms, then do I just find where MC intersects the Demand Curve and divide the quantity by 5, and then set price equal to MC at that quantity?</p>

<p>Conceptually this sounds reasonable, but I'm not sure that this is correct. If these firms charge this price then it seems to me that one of them will under produce to charge a lower price until (if MC is 2Q for instance) price and quantity = 0. So that no firms will produce because if they do then someone will charge a cent less till we reach 0 again.</p>
","<p>The main issue seems to be that you assume that under Bertrand competition a firm is free to set a price and a quantity as well. But under Bertrand competition firms set prices and then have to meet the demand whatever level it takes. Below is a detailed discussion.</p>

<hr>

<p>I will assume that cost functions are the same for all firms and also that the marginal cost function is non-decreasing. (You do not explicitly state these conditions but seem to assume them as well.) I will also assume that demand is non-increasing in price.</p>

<p>In this case, your candidate for the equilibrium is when all firms set the price $p^*$, where all firms produce
$$
q^* = \frac{D(p^*)}{5}
$$
and where
$$
p^* = MC(q^*).
$$
Is this really an equilibrium, or could a firm profit by deviating to a slightly lower price $p'$?</p>

<p>If say firm 1 were to deviate to $p' &lt; p^*$ while the other firms still charge $p^*$ then all consumers would seek out firm 1. Since $p' &lt; p^*$ and demand is non-increasing in price
$$
D(p') &gt; D(p^*).
$$
Firm 1 has to fulfill this alone, so
$$
q_1 = D(p') &gt; D(p^*) = 5 \cdot q^*.
$$
Because marginal cost is non-decreasing you also have
$$
MC(q_1) &gt; MC(q^*).
$$
So now firm one charges a price lower than $p^* = MC(q^*)$ but it has to produce so much that the marginal cost is larger than $p^*$, hence it earns negative profits, hence deviation from $p^*$ was not profitable.</p>
","13041"
"Optimal decision for perfect substitutes utility function ?","637","","<blockquote>
  <p>Given $u(x_1,x_2)=4x_1+14x_2$ and $m=\frac{1}{2}x_1+\frac{3}{2}x_2$, I shall choose the optimal decision among:</p>
  
  <p>$a)(2m,\frac{2m}{3})$</p>
  
  <p>$b)(2m,0)$</p>
  
  <p>$c)(\frac{m}{2},0)$</p>
  
  <p>$d)(0,\frac{2m}{3})$</p>
  
  <p>The correct answer is $(d)$</p>
</blockquote>

<p>But not sure how to find this, what I did:
 $$m=\frac{1}{2}x_1+\frac{3}{2}x_2 \Leftrightarrow x_2=\frac{2m}{3}-\frac{1}{3}x_1 $$
 And the marginal rate of substitution is $-\frac{2}{7}$,so we have :</p>

<p><a href=""https://i.stack.imgur.com/n8o0G.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/n8o0G.png"" alt=""enter image description here""></a></p>

<p>Obviously $a)$ isn't the right one and $c)$ doesn't seem to be the best one... but really don't know 'how to think', some explaination would be great.
Thanks in advance</p>
","<p>Answer a is not possible since it reduces to </p>

<p>$m = \frac{1}{2} 2m +  \frac{3}{2}\frac{2m}{3} = 2m$</p>

<p>which has no sense. Idem for answer c, $m\neq\frac{1}{4}m$.</p>

<p>Remains answers b or d.</p>

<p>For answer b, we have </p>

<p>$u(2m,0)=8m$</p>

<p>and for answer d,</p>

<p>$u(0,\frac{2m}{3}) = \frac{28}{3}m = (9+\frac{1}{3})m$</p>

<p>As you can see, $ (9+\frac{1}{3}) &gt; 8$.</p>

<p>In the general case, to find the maximum of your utility function given a monetary constrain, you can formalize and maximize the following <a href=""https://en.wikipedia.org/wiki/Lagrange_multiplier"" rel=""nofollow noreferrer"">Lagrangian</a> function</p>

<p>$L(x_1,x_2,\lambda)=u(x_1,x_2)+\lambda(m-p_1 x_1 - p_2 x_2)$</p>

<p>where $p_1$ and $p_2$ are prices. In your case, those are $\frac{1}{2}$ and $\frac{3}{2}$ respectively.</p>

<h3> Suite </h3>

<p>As usual, <strong><em>the story behind equations is of first importance</em></strong>.</p>

<p>Remember that $x_1$ and $x_2$ are two perfect substitutes. This means that the individual will spend all her income either in $x_1$ or in $x_2$, and will chose the good which provides her with the highest utility. And this is actually the story that the use of the Lagrangian function tells you. </p>

<p>As you mentioned in your comment below, you get <em>first order conditions which seem to be contradictory. But they are not</em>. Indeed, the two goods will never be bought simultaneously. Which means that you will get either $\lambda = 8$ or $\lambda = \frac{28}{3}$ in a <em>mutually exclusive</em> manner.</p>

<p>Recall what $\lambda$ is : it is a shadow price. In other words, it expresses how much your objective function, $u(x_1,x_2)$, will increase, if your constrain, $m$, increases by $1$.</p>

<p>Thus, if $m$ increases by $1$, and the individual spends all her income in $x_1$, $u$ will increase by $8$.
If she spends all her income in $x_2$, $u$ will increase by $\frac{28}{3}$.</p>

<p>Which good will the individual chose ?</p>
","15694"
"What would happen if China called in its debt?","637","","<p>I was talking with a friend of mine the other day about Trump putting the 35% tax on all overseas manufacturing. Couldn't this hurt those countries that have plants where US manufacturing comes from? I think, and correct me if I'm wrong, the tax is to encourage businesses to bring their manufacturing back to the US?</p>

<p>I'm not sure how accurate <a href=""http://www.davemanuel.com/us-national-debt-clock.php"" rel=""nofollow noreferrer"">this site</a> is but here is the Top 10 of countries the USA owes money to:</p>

<ol>
<li><p>China, Mainland, $1244.0 billion dollars</p></li>
<li><p>Japan, $1133.2 billion dollars</p></li>
<li><p>All Other, $416.0 billion dollars</p></li>
<li><p>Cayman Islands, $260.2 billion dollars</p></li>
<li><p>Ireland, $259.8 billion dollars</p></li>
<li><p>Brazil, $249.5 billion dollars</p></li>
<li><p>Switzerland, $228.7 billion dollars</p></li>
<li><p>Luxembourg, $221.8 billion dollars</p></li>
<li><p>United Kingdom, $216.5 billion dollars</p></li>
<li><p>Hong Kong, $192.7 billion dollars</p></li>
</ol>

<p>Looking over <a href=""http://www.itimanufacturing.com/chinese-manufacturing-news/five-companies-overseas-manufacturing/"" rel=""nofollow noreferrer"">this link</a> (which is a little old but I couldn't find anything newer), looks like most of oversea manufacturing by US companies is done in China.</p>

<p>What if China said it wants its money back? Is that possible? </p>
","<p>You have to understand how international debt works. These are not loans, but bonds. China buys a US bond for e.g. 98 USD. This bond is a promise by the US treasury to pay 100 USD one year from now. China owns a lot of this type of bonds. Once the bond hits maturity, China is paid 100 USD and the thing it typically does with these 100 USD is it buys the same type of bond again. If it decides it no longer wants to hold US debt, it can do one of two things:</p>

<p>First, it could decide to sell all it's bonds at market prices to someone who's willing to buy them. This would be a terrible idea for the Chinese, since they'll lose a lot of money in this kind of fire sale. Second, it could just stop rolling over the debt and invest its foreign reserves in other kinds of bonds.</p>

<p>In any case what will not happen is that the US suddenly has to pay back all it's debt at once. It will become more expensive for the US to refinance it's debt, since the demand for treasuries will go down, but this is more of a long run problem. Also, it is not trivial to find an alternative asset market that can absorb an investment of 1200 billion dollars without prices going through the roof.</p>
","15159"
"Transition Matrix: Discrete -> Continuous Time","634","","<p>I have the code corresponding to Tauchen (1986) (Python equivalent of <a href=""http://www2.hhs.se/personal/floden/Code.htm"">this</a>), which generates a discrete approximation of a discrete time AR(1) process.</p>

<p>For example, if you set up grid size as 3, it gives you a vector of productivities</p>

<pre><code>[A_1, A_2, A_3,]
</code></pre>

<p>and a matrix of transition probabilities</p>

<pre><code>A_11, A_12, A_13
A_21, A_22, A_23
A_31, A_32, A_33
</code></pre>

<p>Where row <code>i</code>, column <code>j</code> gives you the probability of transitioning from <code>i</code> to <code>j</code>, and it satisfies that the sum of each row is approximately one.</p>

<p>I am wondering how I can transform this to a continuous time equivalent of the transition matrix; a set of poisson probabilities controlling the flow rates between the states. </p>

<p>All I remember in this regard is that we can get the linear approximation to the poisson probabilities using</p>

<p>$$Prob(i \to j) = \lim_{\Delta\to0} \exp(-\lambda_{ij}\Delta) \approx 1-\lambda_{ij}\Delta  $$</p>

<p>But I can't see how that helps me transforming that former matrix to the $\lambda$s... I'm looking forward to any suggestion.</p>
","<p>Suppose $B$ is an $n\times n$ matrix of Poisson transition rates, where $B_{ij}\geq 0$ for $i\neq j$ denotes the rate at which state $i$ transitions to state $j$, and $B_{ii}\leq 0$ gives the rate at which state $i$ transitions to all other states. Each row of $B$ sums to 0. </p>

<p>Then if $p(t)$ denotes the probability distribution at time $t$, by definition of $B$ we have the ODE
$$\dot{p}(t) = Bp(t)$$
We know what the solution to this kind of ODE looks like: $p(t)=e^{Bt}p(0)$, where $e^{Bt}$ is the <a href=""http://en.wikipedia.org/wiki/Matrix_exponential"" rel=""nofollow"">matrix exponential</a> of $Bt$. So, if we want $B$ to generate the Markov transition matrix $A$ after $t=1$, we need to have $e^B=A$.</p>

<p>In principle, to get $B$, we need to invert the matrix exponential, taking the <a href=""http://en.wikipedia.org/wiki/Logarithm_of_a_matrix#The_logarithm_of_a_non-diagonalizable_matrix"" rel=""nofollow"">matrix logarithm</a> of $A$. The problem is that each matrix has many matrix logarithms - the logarithm in one-dimensional complex space has infinitely many branches, and this is compounded when we're talking about matrices in $n$-dimensional space. Most of these logarithms will not be satisfactory Poisson transition matrices: maybe they won't be real, or the entries won't have the right signs. Yet it is possible that more than one of them will be: in some cases there is more than one Poisson $B$ corresponding to a Markov $A$, just as in some cases there is <em>no</em> Poisson $B$ corresponding to $A$. It's messy.</p>

<p>Fortunately, there is a situation where life is relatively simple, and it almost certainly includes your own case: <em>when all the eigenvalues of $A$ are positive, distinct reals</em>. In this case, there is only one logarithm of $A$ that will be real, and it's easy to compute: you just diagonalize the matrix as $A=V\Sigma V^{-1}$ and take the real logarithm of the eigenvalues, getting $B=V\Omega V^{-1}$, where $\omega_{ii} = \log(\sigma_{ii})$. Indeed, you don't need to do this yourself: if you use the command $\text{logm}(A)$ in Matlab (presumably Python too), it will give you precisely this $B$.</p>

<p>Given this $B$, all you have to do is to verify that it's actually a Poisson matrix. The first requirement, that the rows all sum to zero, is satisfied automatically due to the construction of $B$.** The second requirement, that the diagonal elements are negative and the off-diagonal elements are positive, does not always hold (I think), but it's easy for you to check.</p>

<p>To see this in action, I'll consider an $A$ for a 3-state Markov process that resembles a discretized AR(1).
$$A = \begin{pmatrix}0.5 &amp; 0.4 &amp; 0.1 \\ 0.2 &amp; 0.6 &amp; 0.2 \\ 0.1 &amp; 0.4 &amp; 0.5\end{pmatrix}$$
Now, if I type $B=\text{logm}(A)$ into Matlab, I get
$$B = \begin{pmatrix}-0.86 &amp; 0.80 &amp; 0.06 \\ 0.40 &amp; -0.80 &amp; 0.40 \\ 0.06 &amp; 0.80 &amp; -0.86\end{pmatrix}$$
This is indeed a valid Poisson transition matrix, as we can easily check that the rows sum to zero and have the right signs - so this is our answer.</p>

<p>The case with positive eigenvalues is pretty important, since it spans all cases where there is not some kind of oscillatory behavior in the Markov chain (which would require negative or complex eigenvalues), presumably including your discretized AR(1).</p>

<p>More generally, the $\text{logm}$ command on Matlab will give us the <em>principal</em> matrix logarithm, an analogue of the principal scalar logarithm that takes all eigenvalues to have imaginary part between $-\pi$ and $\pi$. The problem is that this is not necessarily the logarithm we want, and by looking at it we might miss a Poisson $B$ that does generate $A$. (That's why the positive eigenvalue case, where we didn't have to worry about this, was so nice.) Still, even in these other cases it can't hurt to try and see if it works.</p>

<p>By the way, this problem of seeing whether there is a $B$ that generates some Markov matrix $A$ has been studied extensively. It is called the <em>embeddability problem</em>: see some overview and references in <a href=""http://arxiv.org/pdf/1001.1693v1.pdf"" rel=""nofollow"">this excellent survey article by Davies</a>. I'm not an expert on technical aspects of the problem, though; this answer is based more on my own hackish experience and intuition.</p>

<p>I feel obligated to close by seconding ecksc's comment and saying that there might be better, more direct ways to convert a discretely fitted AR(1) into a finite-state continuous time process - rather than just taking the matrix obtained via the Tauchen method and making it continuous. But I don't personally know what that better way is!</p>

<hr>

<p>**Explanation (though I'm rusty): $A$ has a unique Perron-Frobenius eigenvalue of 1, and since $A$ is stochastic the right eigenvector of this eigenvalue is the unit vector $e$. This is still the right eigenvector, now with an eigenvalue of 0, when we take the matrix logarithm.</p>
","5624"
"What Is the Economic Meaning of ""Structural Reforms""","632","","<p><a href=""https://twitter.com/SriKGlobal/status/759011830014447616"" rel=""nofollow"">I see tweets like this a lot</a>:</p>

<blockquote>
  <p>Poor 2q growth shows its not just a ""1q curse"". Cannot ever cause eco recovery thru just #QE, low interest rates.  #StructuralReforms</p>
</blockquote>

<p>They seem to be saying essentially that structure should be the focus, not interest rates.  What is an economic structural reform?</p>
","<p>Economic variables can be ""real"" or ""nominal"". So when policymaker discus influencing the economy, they look at implications of influencing these economic variables.</p>

<p>An example of a nominal variable is the price level influenced by money supply. Money is directly created by the government and can take on any value per se and is not ""real. E.g. if we multiply all prices and bank notes by 10 nothing in the economy changes. </p>

<p>Real variables are for example output, productivity etc.</p>

<p>However it turns out that these nominal variables can influence the real ones. Increasing the money supply can increase output (at least temporarily). This is also easy to implement, so monetary policy is often used to fight a recession. Note that lowering the interest rate and icnreasing the money supply are two sides of the same coin and both part of monetary policy.</p>

<p>An alternative to monetary policy (based on nominal variables) would be ""real"" economic reforms. One form of ""real"" policy is a ""structural reform"". In this case you would try to increase output by changing something in the real side of the economy. For example lowering (wage) costs through changes to labor protection laws. Fiscal policy (government spending or tax cuts) is another form of ""real"" policy, however it is not a structural break. </p>

<p>To fully understand structural reforms we must introduce the concept of output potential. This is the output that would normally occur in absence of disturbances. It only depends on the underlying structure of the economy. These are factors such as costs (e.g. ease of doing business), labor market flexibility and other things that influence output in general in ""real"" terms. The economy generally comes back to that level and fluctuates around it in the medium run. (Note this level may be growing over time, e.g. by 1-2% each year).</p>

<p>However, sometimes it happens that our economy is operating below its ""natural"" potential. In this case we can employ monetary and fiscal policy to get back to that natural level. We can also push the economy beyond the natural level, but we will eventually come back, so this is not a good idea since the side effect that brings is typically more inflation.</p>

<p>If the crisis is cause because we are simply below potential, we do not need structural reforms. However if we are in a crisis because the potential or ""natural"" output has risen, then we need ""structural reforms"". An often cited recent example is the Greek crisis where Greece's wage rate increased a lot over time making its exports too expensive, meaning the economy did not have its past potential to export anymore. In this case many economists suggested ""structural"" reforms (law changes) that would lead to lower wages.</p>

<p>Monetary and Fiscal policy are often used to correct short-term problems or deviations from output potential. Structural reforms are supposed to change the (medium to long term) output potential itself.</p>

<p>The type of policy best suited often depends on the type of crisis at hand and its underlying causes.</p>
","12903"
"Is net neutrality not important in a competitive market of internet providers?","628","","<p>In my understanding, allowing ISP to throttle sites that use a lot of traffic is just price discrimination. The ISP will charge sites like Netflix, which will then pass the cost to Netflix consumers. So basically people who use a lot of data will get charged more--seems perfectly fine to me.</p>

<p>I understand the argument that in practice, the ISP won't build new infrastructure but simply put up roadblock to slow down the current speed. However, this seems like a problem only in the oligopolistic market of US internet providers. In a competitive market, putting up roadblock will cause an exodus to competitors.</p>

<p>So, am I correct in thinking that preserving Net Neutrality is not important in a competitive telecom market? Instead of fighting to preserve Net Neutrality, may be the correct fight is to encourage more ISP to enter the market.</p>
","<p>Yes, if there were more competition then net neutrality would not be such a big issue. Any throttling would cause an ISP to lose customers to competitors.</p>

<p>Competition is a main assumption behind why markets work. However, in this case an ISP has <a href=""http://en.wikipedia.org/wiki/Market_power"" rel=""noreferrer"">market power</a> which breaks the assumption. The market power allows them to easily put smaller ISPs out of business. </p>

<p>Here is a link to a rather long article on how ISPs get this market power. Essentially, the reason is that starting an ISP is entering an economy of scale, which requires a large amount of capital to start: <a href=""http://arstechnica.com/business/2014/04/one-big-reason-we-lack-internet-competition-starting-an-isp-is-really-hard/"" rel=""noreferrer"">http://arstechnica.com/business/2014/04/one-big-reason-we-lack-internet-competition-starting-an-isp-is-really-hard/</a></p>
","4698"
"Leontief function marginal product of labor/capital","626","","<p>Find marginal product of labor of a Leontief production function.  For example,
$$f(L, K) = min\{\frac{L}{a}, \frac{K}{b}\}$$</p>

<p><strong>MY ATTEMPT</strong></p>

<p>Now as I understand it the marginal product of labor, $MP_L$ of this function cannot be found in the ""normal"" way because this function is not differentiable.  However, by definition, marginal product of labor means the extra output when one puts in an additional unit of labor.  We assume capital stays constant.</p>

<p>Say, we produce originally $q$ units of output.</p>

<p>Thus, if $\frac{L}{a}+\Delta L &lt; \frac{K}{b}$ where we are increasing the quantity of labor, then we are on the vertical portion of the isoquant (Labor on the horizontal axis, Capital on vertical).  Thus, we would increase our output by $q+\Delta L$.</p>

<p>If $\frac{L}{a}+\Delta L&gt;\frac{K}{b}$, we would still be producing $q$ units.</p>
","<p>Since you are interested in labour, let's assume for simplicity that the stock of capital is fixed at $\bar{K}$. Then, the optimal choice of capital and labour is given by:</p>

<p>$$\frac{L^*}{a}=\frac{\bar{K}}{b}$$</p>

<p>Therefore, optimal labour is:</p>

<p>$$L^* = \frac{a}{b}\bar{K}$$</p>

<p>The marginal product of labour depends on how <strong>actual labour</strong> relates to <strong>optimal labour</strong>:</p>

<ul>
<li><p>Case 1: $L = L^*$. In the standard Leontief diagram, with $L$ in the horizontal axis and $K$ in vertical axis, this is any point <strong>on</strong> the optimal path (which function starts at the origin and has slope $\frac{b}{a}$). In this case, $\dfrac{dQ}{dL}=0$.</p></li>
<li><p>Case 2: $L &gt; L^*$. This is when the factors' combination is <strong>below</strong> the $\frac{b}{a}$ path. In this case, $\dfrac{dQ}{dL}=0$.</p></li>
<li><p>Case 3: $L &lt; L^*$. This is when the factors' combination is <strong>above</strong> the $\frac{b}{a}$ path. The solution here depends on how far $L$ is from $L^*$:</p>

<ul>
<li><p>Case 3a: $L^*-L &gt; 1$. This is perhaps the most likely case. Here, the change in labour leaves still with low levels of labour. In this scenario, $MP_L = \dfrac{1}{a}$. This results comes from comparing output before the change in labour: $Q_0=\dfrac{L_0}{a}$ versus after the change: $Q_1=\dfrac{L_0 +\Delta L}{a}$. From here, we conclude that $\dfrac{dQ}{dL}=\dfrac{1}{a}$. Notice that in this case, there is still room for increasing output by increasing labour (i.e. we are still within Case 3).</p></li>
<li><p>Case 3b: $L^*-L = 1$. Here, the change in labour leaves us <strong>on</strong> the optimal path. The change is just as in Case 3a. The differences is that increasing labour further leaves without increases in output. We are then back to case 1.</p></li>
<li><p>Case 3c: $L^*-L &lt; 1$. Here, the change in labour is more than what we actually require. Thus, we move from being in Case 3 to being in Case 2. The change is therefore not $\dfrac{1}{a}$, but equal to $\dfrac{1}{a} \times (L^*-L)$. In other words, the change is proportional to the exact amount of labour input we need to be in the optimal path.</p></li>
</ul></li>
</ul>

<hr>

<p>A graphical example can be seen below:</p>

<p><a href=""https://i.stack.imgur.com/g15af.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/g15af.png"" alt=""enter image description here""></a></p>

<p>For any labour equal or above $L_0$, further increases in $L$ does not change $q_0$. However, when we are above the optimal path (meaning $K&gt;\bar{K}$), the extra marginal worker does add to production. You can see that depending on how far this point is from the optimal, the three scenarios of Case 3 arise.</p>

<p>If interested (in my personal quest in favour of Open Economics), here is the R code of the graph:</p>

<pre><code>plot(c(0,5), c(0,5), type = ""n"", xlab = ""Labour"", ylab = ""Capital"", yaxt='n', xaxt='n', bty='l', mgp=c(1,1,0))
segments(0, 0, 4.7, 4.7,lwd=2)
text(4.9, 4.8, expression(frac(b,a)),cex = 1.3)
points(2, 2, type=""p"", pch=19, col=""black"", bg=NA, cex=1.5)
segments(2, 2, 2, 5,lwd=2.5)
segments(2, 2, 4.7, 2,lwd=2.5)
text(4.9, 2,  expression(q[0]),cex = 1.3)
text(2.4, 1.75, expression(paste(""("",L[0],"","",bar(K),"")"")),cex = 1.3)
points(3.5, 2, type=""p"", pch=19, col=""black"", bg=NA, cex=1.5)
text(3.5, 2.3, expression(L&gt;L[0]),cex = 1.3)
points(2, 3.5, type=""p"", pch=19, col=""black"", bg=NA, cex=1.5)
text(2.4, 3.5, expression(K&gt;bar(K)),cex = 1.3)
</code></pre>
","15765"
"How does a country devalue its currency?","625","","<p>I recently read an article in the New York Times that talked about China devaluing its currency (which I believe is held to a peg against the US Dollar). My question is: specifically what tools does a central bank of a country employ to devalue its currency artificially and what effects does it have on its foreign trade?</p>
","<p>Typically, a devaluation is achieved by selling the domestic currency in the foreign exchange market and buying other currencies. Suppose China sells one trillion Renminbi and buys 157 billion US dollars. From the point of view of the market, it is as if the supply of Renminbi just increased. As in any competitive market, an increase in supply will cause the price (i.e. the exchange rate) to fall: one Yuan will be worth less than before.</p>

<p>Devaluations are good for a country's balance of trade. Companies based in China ultimately care about how many Yuan they end up with. Suppose that the value of the Renminbi is 10 Yuan = \$1US. That means that a Chinese product priced at 10 Yuan would cost an American \$1 to buy. Now suppose that the value of the Renmimbi falls by half: 10 Yuan = \$0.50. Now the same product, still priced at 10 Yuan, will only cost an American 50 cents. It's as if everything China exports just got cheaper! This fall in the apparent price of Chinese exports will make people in other countries want to buy more Chinese products so that China will experience an increase in its exports. The argument also works in reverse: to a Chinese person, the devaluation makes it look as if American products got more expensive, so Chinese will demand fewer American (and British, and German, etc.) products and China will import less. Together, these two effects mean that China's balance of trade (i.e. the difference between exports and imports) will improve as a consequence of the devaluation.</p>
","6883"
"Wouldn't an unconditional basic income lead to an inflation that negates its effect?","619","","<p>There are several version and denomination for a basic income. In this question, I will call unconditional basic income the situation were all citizens of a country receive regularly a lump-sum of money, independently of their age, their employment status and job,etc. I will assume that, at the moment the basic income is  instituted, it is larger than the poverty threshold. I am also assuming that the basic income is not a substitute of other welfare subsidies.</p>

<p>The concept is gaining popularity these days, and for many reasons, economical or philosophical.</p>

<p>My understanding of offer and demand is that, if people can pay more for a product and are willing to do so, then prices will increase. So, it seems that, after the introduction of the basic income, there will be mechanically a large inflation.  In a short time, people with no job and that relied mostly on the welfare system will be poor again. Worse, people with low income will be closer to the new poverty threshold.</p>

<p><strong>My questions</strong>:<br>
1) What natural mechanical effects prevent an over-inflation after the introduction of a substantial basic income? By natural, I mean any direct or indirect effects of the sole introduction of the basic income.</p>

<p>2) If an inflation cannot naturally be avoided, what measures are usually suggested together with the introduction of the basic income?</p>

<p><em>Edit</em>: my question is close but not an exact duplicate of <a href=""https://economics.stackexchange.com/questions/10387/will-a-guaranteed-minimum-income-not-eventually-just-be-crowded-out-by-inflation"">this question</a>. In the example of the other question, $A$ would receive $30$ and $B$ would receive $90$ for an unconditional basic income of $30$. If the two questions are equivalent, please explain. </p>
","<p>Theoretically basic income might have a tendency to increase inflation. But that largely depends on how much is the basic income provided. Usually, the idea of basic income itself means that it is 'basic' and is just sufficient for a subsistence. With such an income level, the problem of inflation does not crop up really. 
However, basic income might have other serious problems with crowding out due to large government spending and the disincentive to work and hence loss of productivity. </p>

<p>Even if we suppose, there is a large basic money disbursement which can cause inflation, then I think it should not be unconditional. Usually, such plans are in the form of guaranteed employment programs, buying of ration from designated stores and many more measures. However, I still feel these measures are not for tackling inflation rather the disincentive to work.</p>
","14388"
"Are Cobb-Douglas preferences homothetic?","603","","<p>Our lecture defined a preference to be <em>homothetic</em>, if the following is true:</p>

<p>$$(x_1, x_2)  \thicksim (y_1, y_2) \Leftrightarrow (kx_1, kx_2) \thicksim (ky_1, ky_2)$$</p>

<p><em>Cobb-Douglas</em> preferences can be displayed as some utility function of the following form: </p>

<p>$$u(x_1, x_2) = x_1^a \cdot x_2^b$$
Therefore:
$$(x_1, x_2)  \thicksim (y_1, y_2) \\ 
\Leftrightarrow x_1^a \cdot x_2^b = y_1^a \cdot y_2^b \\
\Leftrightarrow k^ax_1^a \cdot k^bx_2^b = k^ay_1^a \cdot k^by_2^b \\
 \Leftrightarrow (kx_1, kx_2)  \thicksim (ky_1, ky_2)$$</p>

<p>With this argumentation the <em>Cobb-Douglas</em> preferences <strong>should be homothetic</strong>. </p>

<p>The <a href=""https://en.wikipedia.org/wiki/Homothetic_preferences"" rel=""nofollow noreferrer"">wikipedia article</a> about <em>Homothetic preferences</em> however defined a preference to be <em>homothetic</em>, if they can be represented by a utility function  and the following is true:</p>

<p>$$ u(kx_1, kx_2) = k \cdot u(x_1, x_2)$$
And I am pretty sure, that this is <strong>not true</strong> for <em>Cobb Douglas</em> preferences:</p>

<p>$$ u(kx_1, kx_2) = (kx_1)^a (kx_2)^b = k^{a+b} x_1^a x_2^b \neq k \cdot u(x_1, x_2)$$</p>

<p>So what am I missing here? Are the definitions not equivalent? Did I calculate something wrong?</p>
","<p>Note that the <a href=""https://en.wikipedia.org/wiki/Homothetic_preferences"" rel=""nofollow noreferrer"">wikipedia article</a>  is very specific:</p>

<blockquote>
  <p>[...] defined a preference to be <em>homothetic</em>, if they <strong>CAN</strong> be represented by <strong>A</strong> utility function [...]</p>
</blockquote>

<p>You chose a specific utility function to represent your Cobb-Douglas preferences. However there are other infinitely many others. All monotonic transformations of your utility function represent the same preference. Take
$$
\hat{u}(x_1,x_2) = \left(u(x_1,x_2)\right)^{\frac{1}{a+b}} = x_1^{\frac{a}{a+b}} \cdot x_2^{\frac{b}{a+b}}.
$$
As $\hat{u}$ is a monotonic transformation of $u$, it represents the same preference. It is straightforward to check that $\hat{u}$ fullfils the condition set forth in the wiki article. So there is indeed such a utility function, that also represents the preference, hence the preference is homothetic. </p>
","17627"
"Practical examples of fair division algorithms being used","598","","<p>Consider the problem of fairly sharing a homogeneous cake between two people. It is well-known that a fair division can be achieved through the divide and choose procedure: player 1 cuts the cake into two pieces and player 2 chooses a piece.</p>

<p>This problem can be generalized to non-homogeneous cake, more than two players, etc.</p>

<p>My question is: are there any concrete examples of people using the fair division procedures (such as divide and choose) that emerge as the solution to such problems in practical applications?</p>
","<p>The easiest generalization, of envy free sharing of a heterogeneous cake between two cake eaters is quite common. My family growing up frequently used the you divide and I choose method for sharing a lone piece of dessert. Depending on what you'd accept for ""concrete example"", <a href=""https://en.wikipedia.org/wiki/Divide_and_choose"" rel=""nofollow"">Abraham and Lot use this method to divide the land of Canaan</a>.  A  two-stage fair division problem was used in the partitioning of Germany after World War II. <a href=""http://mindyourdecisions.com/blog/2008/06/10/how-game-theory-solved-a-religious-mystery/"" rel=""nofollow"">The Talmud has examples of fair division rules</a>, which though are only thought experiments, are thought to have been applied in the Jewish diaspora over inheritance matters. </p>

<p>I would also argue that the <a href=""http://www.slate.com/articles/business/moneybox/2012/10/nobel_prize_in_economics_lloyd_shapley_and_alvin_roth_win_for_deferred_acceptance.html"" rel=""nofollow"">marriage / matching problems of Lloyd Shapley and Alvin Roth</a> are a form of fair division, and one that scales to very large numbers of players and applies only to multiple, indivisible ""cakes. Their methods have been used extensively in real world problems of school, job, and kidney assignment.    </p>
","8512"
"A country borrowing from the rest of the world","597","","<p>Well I'm having a some difficulty in understanding completely what the following sentence means and I would like to be sure. </p>

<p>«(...) a country running a trade deficit is buying more from the rest of the world than it is selling to the rest of the world. In order to pay for the difference between what it buys and what it sells, the country must borrow from the rest of the world. <em>It borrows by making it attractive for foreign financial investors to increase their holdings of domestic assets</em>- in effect, to lend to the country.»</p>

<p>How does this borrowing(in italic) work? I'm not understanding the italic part. Does the country A sells bonds in domestic currency, receives foreign currency, when the foreign investor buys the domestic currency of A to buy the domestic bond of A?</p>

<p>Also why should the current account plus the capital account be equal to zero (up to a statistical discrepancy)? </p>
","<p>The idea is that the world economy is closed and value only comes from production. It is maybe best to forget about money for a moment here. Since money derives its value directly from production, anything we say about production applies to money as well.</p>

<p>Since the world economy is closed a country that is producing less than it consumes must ""borrow goods"" from other countries to consume (otherwise it cannot consume more than it produces by definition). We can't have the whole world consuming more than it produces, so someone else must be consuming less, i.e. ""lends"". This is the case of a trade deficit, i.e. positive net imports. If a country ""borrow goods"" it effective also borrows money. </p>

<p>A currency's value (purchasing power) is proportionate to the number of goods in that economy, since all money must be able to buy all goods by definition and legally. (If only 1 loaf of bread and only 1 dollar exist, the dollar has a purchasing power of 1. If (only) 2 dollars exist then each dollar has a purchasing power of 0.5).</p>

<p>How this may work is that the exporting country lends money to the importing country in order to be able to buy more than it sells. In a barter economy this happens directly without money, the extra goods given are loans (as goods in equal value have not been receieved). Since money is not ""real"" in an economic sense, the same must happen with money. This happens, since each currency's value is related to production and the importing country is producing less (as it doesn't have enough to spare), while the exporting country is producing more (it has more than enough), therefore the respective currency values reflect this.</p>

<p>Very often an importing company will take out a credit from the exporting company and this reflects itself at the country level. Even if money isn't actually lent, it happens through adjustment in exchange rates and interest rates.</p>

<p>Since money's value depends on production value, this is also the  reason the current acount + the capital account must be equal to 0. For any goods bought or sold, money must be paid. Its like saying the value of goods you receive at the store must equal the value of money you give to the cashier. If you get more goods than you have money for you'll simply owe the cashier. Internationally (but alson domestically) you only have money in value of what you produce. Therefore if you produce less than you consume, you don't have enough money (production=money) to pay the cashier for the goods you consume.</p>

<p>Further, the current account is constructed similarly as an account from accounting. It sums up to 0 by (that) construction. Goods leave, money enters, they must have the same value. For more on this you can also consult any introductory accounting book.</p>
","8190"
"How successful will OPEC's predatory dumping strategy be?","597","","<p>Since the fracking industry in the US has started to grow rapidly, I have heard increasing reports that OPEC is attempting some form of predatory dumping in the hopes of making the fracking industry in the US unprofitable.<br>
How successful do economists predict that OPEC's dumping strategy will be?  For example, does OPEC have a large profit margin and the fracking industries a small profit margin (making fracking an unprofitable enterprise quite easily under some form of predatory dumping) or are the profit margins close enough to make any predatory dumping infeasible in the short-run?</p>
","<p>This is the cost curve of oil production (North American shale at $65):</p>

<p><img src=""https://i.stack.imgur.com/q3xd7.jpg"" alt=""enter image description here"">
<a href=""http://www.slate.com/blogs/moneybox/2014/12/11/oil_falls_below_60_a_barrel_who_s_in_trouble.html"" rel=""nofollow noreferrer"">Source</a></p>

<p>And this is the cost curve of major American projects:</p>

<p><img src=""https://i.stack.imgur.com/7lUQs.png"" alt=""enter image description here"">
<a href=""http://www.businessinsider.com/citi-breakeven-oil-production-prices-2014-11"" rel=""nofollow noreferrer"">Source</a></p>

<p>While ""Citi's Ed Morse highlighted this chart, showing that for most US shale plays, costs are below $80 a barrel.""</p>

<p>And clearly, many of these new projects would lead to losses with oil prices at $60:</p>

<p><img src=""https://i.stack.imgur.com/MxJuf.jpg"" alt=""enter image description here"">
<a href=""http://www.businessinsider.com/citi-breakeven-oil-production-prices-2014-11"" rel=""nofollow noreferrer"">Source</a></p>

<p>The problem with predatory pricing (if it's purposeful) is that OPEC itself depends on high oil prices to ensure balanced budgets in their (mostly dictatorial) regimes. Their sovereign funds are large enough to survive a brief (2-3 years) period of low oil prices, but in the long run, dumping endangers their rulers' positions:</p>

<p><img src=""https://i.stack.imgur.com/sbdjQ.png"" alt=""enter image description here""></p>

<p><img src=""https://i.stack.imgur.com/O9nYS.png"" alt=""enter image description here"">
<a href=""http://www.slate.com/blogs/moneybox/2014/12/11/oil_falls_below_60_a_barrel_who_s_in_trouble.html"" rel=""nofollow noreferrer"">Source</a></p>

<p>You can't kill American oil production this way—it would return after these two-three years anyway.</p>

<p>The \$60-80 band leaves space for most American projects, while oil below \$60 kills too many OPEC members. So, it does not seem to be a good dumping strategy.</p>
","1788"
"Labor-Leisure Framework","597","","<p>I have a question I'm trying to make sense of. </p>

<h2>Question</h2>

<p>Suppose you have 24 hours per day that you can allocate between leisure and working. </p>

<p>(i) Draw the budget constraint between “leisure hours” on the horizontal axis and “wage income” on the vertical when the wage rate is \$3 per hour. Mark an optimum point A that is meaningful. Draw a new budget constraint when the wage rate falls to \$2 per hour. Show a new optimum point B.</p>

<p>(ii)    On your indifference curve diagram, decompose the effect of the wage decrease into a “substitution effect” and an “income effect” (What is the direction of the substitution effect, that is, what happens to leisure or work? Assuming leisure if a “normal good”, what is the direction of the income effect?) What can you say about the “net effect” of the wage decrease on your leisure choice? Also provide economic explanations of your decomposition results.</p>

<hr>

<h1>$$\text{MY WORK}$$</h1>

<hr>

<p><strong>Part (i)</strong></p>

<p><a href=""https://i.stack.imgur.com/s8PHJ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/s8PHJ.png"" alt=""enter image description here""></a></p>

<p>I have chosen 10 hours as a ""meaningful"" point. Is this how you would correctly draw the new budget constraint of \$2/Hr? Should I move point $B$ further up the red budget line? Or is the figure okay?</p>

<hr>

<p><strong>Part (ii)</strong></p>

<ul>
<li>decompose the effect of the wage decrease into a “substitution effect” and an “income effect” (What is the direction of the substitution effect, that is, what happens to leisure or work?)</li>
</ul>

<p>Not too sure about this one. </p>

<ul>
<li>Assuming leisure is a “normal good”, what is the direction of the income effect?</li>
</ul>

<p><em>The move from A to B represents a pure change in income (A and B are tangencies with parallel budget lines). The assumption that leisure is a normal good means the income effect is leftward.</em></p>

<ul>
<li>What can you say about the “net effect” of the wage decrease on your leisure choice? Also provide economic explanations of your decomposition results.</li>
</ul>

<p>Again, not sure how to express this in terms of my figure. </p>

<hr>

<h1>$$\text{THANK YOU}$$</h1>
","<p>This was the graph I ended up using. </p>

<p><a href=""https://i.stack.imgur.com/Okil2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Okil2.png"" alt=""enter image description here""></a></p>
","13291"
"When can one safely talk about decreasing marginal utility?","595","","<p>One thing I hear a lot is talk of decreasing marginal utility—the idea being that additional units of a good become progressively less attractive the more units of that good one has already.</p>

<p>However, this always made me a little uncomfortable because of the ordinality of utility. If we take the trivial case of a world in which there is only one good with utility $u(x)$ satisfying $u'(x),\ u''(x)&lt;0$ (decreasing marginal utility) then it is clearly possible to construct an increasing function $f$ such that $(f\circ u)$ is linear in $x$. Moreover, since utility functions are invariant to monotone-increasing transformations, $(f\circ u)$ is a utility function that represents the same preferences as $u$ (but now has constant marginal utility). Thus, in a world with a single good it seems that it never makes sense to talk about diminishing marginal utility.</p>

<p>My question is this: consider a market with $L&gt;1$ goods. Is there a formal condition under which we can safely talk about decreasing marginal utility? That is to say, is there a class of preferences such that <strong><em>every</em></strong> valid utility representation, $u(\mathbf{x})$, has $u_{ii}(\mathbf{x})&lt;0$ for some $i$?</p>

<p>Alternatively, is there some simple proof that, for $L&gt;1$, the existence of a utility representation with $u_{ii}(\mathbf{x})&lt;0$ for some $i$ necessarily implies that all utility representations have $u_{ii}(\mathbf{x})&lt;0$?</p>
","<p>The concept of ""marginal utility"" (and therefore of decreasing such) has meaning only in the context of <em>cardinal</em> utility.</p>

<p>Assume we have an ordinal utility index $u()$, on a single good, and three quantities of this good, $q_1&lt;q_2&lt;q_3$, with $q_2-q_1 = q_3-q_2$.<br>
Preferences are well behaved and satisfy the benchmark regularity conditions, so</p>

<p>$$u(q_1)&lt; u(q_2) &lt; u(q_3)$$</p>

<p>This is <em>ordinal</em> utility. Only the ranking is meaningful, not the distances. So the distances $u(q_2) - u(q_1)$ and $u(q_3) - u(q_2)$ <em>have no behavioral/economic interpretation</em>. If they don't, neither do the ratios</p>

<p>$$\frac {u(q_2) - u(q_1)}{q_2-q_1},\;\; \frac {u(q_3) - u(q_2)}{q_3-q_2}$$</p>

<p>But the limits of these ratios as the denominator goes to zero would be the definition of the derivative of the function $u()$. So the derivative is devoid of economic/behavioral interpretation, and so comparing two instances of the derivative function would not produce any meaningful content.  </p>

<p>Of course this does not mean that the derivatives of $u()$ do not exist as mathematical concepts. They can exist, if $u()$ satisfies the conditions needed for differentiability. So one can ask the purely mathematical question ""under which condition the  function representing ordinal utility has <strong>strictly negative second derivative</strong>"" (or negative definite Hessian for the multivariate case), trying not to interpret it as ""decreasing marginal utility"" with economic/behavioral content, but as just a mathematical property that may play some role in the model he examines.  </p>

<p>In such a case, we know that:<br>
1) If preferences are convex, the utility index is a quasi-concave function<br>
2) If preferences are strictly convex, the utility index is strictly quasi-concave</p>

<p>But quasi-concavity is a <em>different kind of property</em> than concavity: quasi-concavity is an ""ordinal"" property in the sense that it is preserved under an increasing transformation of the function.  </p>

<p>On the other hand, <strong>concavity is a ""cardinal"" property, in the sense that it won't necessarily be preserved under an increasing transformation.</strong><br>
Consider what this implies: assume that we find a characterization of preferences such that they can be represented by <em>a</em> utility index which is concave as a function. Then we can find and implement some increasing transformation of this utility index, that will eliminate the concavity property.</p>
","376"
"Calibration of utility function parameters controlling labor disutility","591","","<p>Consider the very basic utility function</p>

<p>$$ u(c, n) = \log (c) - \alpha \frac{n^{1 + \frac{1}{\nu}}}{1 + \frac{1}{\nu}}$$</p>

<p>Where $c$ is consumption and $n$ is working hours. As the Frisch elasticity here is given by $\nu$, I would calibrate $\nu$ to be between 0.5 and 1. </p>

<p>However, I'm wondering what to do with $\alpha$: What do I calibrate that against?</p>
","<p>$\alpha$ handles the conversion between the units in which labor is measured and the the units in which consumption is measured. </p>

<p>Consider the leisure part of the utility function:
$$ - \alpha \frac{n^{1 + \frac{1}{\nu}}}{1 + \frac{1}{\nu}}$$
We can rewrite it like this:
$$ - (\alpha^{\frac{1}{1 + \frac{1}{\nu}}})^{1 + \frac{1}{\nu}} \frac{n^{1 + \frac{1}{\nu}}}{1 + \frac{1}{\nu}} = -  \frac{(n\cdot (\alpha^{\frac{1}{1 + \frac{1}{\nu}}}))^{1 + \frac{1}{\nu}}}{1 + \frac{1}{\nu}} $$
Define $\gamma = (\alpha^{\frac{1}{1 + \frac{1}{\nu}}})$
and rewrite the utility function in terms of $\gamma$ instead of $\alpha$
$$ u(c, n) = \log (c) -  \frac{(\gamma \cdot n)^{1 + \frac{1}{\nu}}}{1 + \frac{1}{\nu}}$$</p>

<p>Written this way, I see $\gamma$ and therefore $\alpha$ as serving as a unit shifter. How many seconds of leisure makes you indifferent over one dollar less consumption? Say it were 60 seconds. What unit is $n$ measured in? Should we put in $n=1$ for minutes, $n=60$ for seconds, or $n=\frac{1}{60}$ for hours? $\nu$ can't answer that question because it controls the shape and curvature but not the scale of the utility function with respect to $n$. However, $\gamma$ can. If the ""true"" measure of $n$ is in hours and we guess wrong and choose seconds then $\gamma$ should be $\frac{1}{3600}$ and conditional on $\nu$ this implies $\alpha$.
In calibration the true units of $n$ it need not map cleanly to one of our time units. $n$ might be properly measured in units of 15.5 seconds or $\pi$ minutes, but the functional form is flexible enough to handle these cases regardless of if you input the labor in the calibration in any of the more standard units of hours, minutes, or seconds. </p>

<p>As for how to calibrate this, you have to see the bundles of labor/ leisure and consumption chosen by households for given sets of prices. This, combined with the demand functions that follow from this utility setup, should give you the required calibration. The paper A Model of Housing in the Presence of Adjustment Costs: A Structural Interpretation of Habit Persistence (<a href=""https://www.jstor.org/stable/29729980?seq=1#page_scan_tab_contents"" rel=""nofollow"">Flavin and Nakagawa (2008)</a>, <a href=""http://econweb.ucsd.edu/~mflavin/pdfs/AERhabit.pdf"" rel=""nofollow"">free copy here</a>) shows the way to do this in a different (housing / non-housing consumption instead of consumption / leisure) problem. Their $\gamma$ parameter acts much like $\alpha$ does here. </p>
","5910"
"Has the natural rate of unemployment decreased with modern travel and the Internet?","586","","<p>The natural rate of unemployment is a combination of structural unemployment and frictional unemployment.<br>
Structural unemployment is caused by a surplus of labor at a given wage in a given area.<br>
Frictional unemployment is caused by workers searching for or transitioning between jobs.<br>
However, modern travel (airplanes, automobiles, etc.) would reduce structural unemployment and frictional unemployment by allowing for faster movement of excess labor to transfer to areas with a shortage of labor; similarly, the Internet (specifically search engines, online jobs fairs, etc.) would reduce frictional unemployment by allowing for workers to search for and find jobs more easily.  </p>

<p>Does this imply that the natural rate of employment decreased with modern travel and the Internet?</p>
","<p>To me, it seems that it has increased, not decreased, due to the factors you mention. Yes, transportation and information networks enable workforce movement. But they also enable movement of goods and information - and because goods and information are more mobile than humans, they profit more, and the results of their portability outpaces the results of the workforce's increased mobility. </p>

<p>When goods were hard to move, a local demand had to be met by local suppliers. If a manufacturer lost a deal, it went to a local competitor instead, and the workforce could adapt easily. Now, if a manufacturer loses a deal, it goes to a competitor 5000 km away. Take for example the Ruhr area: it's still the most densely populated area in Germany, even though the steel industry which attracted workforce in the mid-20th century is gone. The Germans literally shipped one of their steel mills around the globe to China - but the workers stayed. </p>

<p>So, because the workforce cannot adapt to structural changes with the speed at which they are happening, the structural unemployment is higher than before networks which enabled such changes. But the increased speed of change also means more frictional unemployment. A large part of the adaptation which is happening requires people to change jobs. Also, your observation of an increased commute radius contributes to frictional unemployment too - when a person is unhappy with his job, he has more opportunities in his now increased commute area, and is more likely to change jobs. </p>

<p>There are lots of indirect effects too. The Internet and the transport networks enable changes in culture (e.g. today people move out of their birth town early, so may be more willing to relocate again later), business models (e.g. movie streaming) and market structure (today's trend towards ever larger corporations is enabled through, among other things, efficient information and people movement, which reduces overhead costs of giant companies, and global knowledge - I doubt that 50 years ago, an American chain for mediocre coffee in fancy large cups would have been able to establish itself in Europe. Nowadays, the culture export means that the trendy European teenager recognized the brand before they had one of the shops in their location). And they go both ways - a giant corporation may actually be more stable, and afford to keep workforce during short-term demand slumps which would have capsized a tiny manufacturer. </p>

<p>Whatever globalization (spearheaded by more exchange of information and goods, and even people on their respective networks) may bring in the future, it currently seems to create more unemployment - not because it's a bad thing in itself, but because in a more dynamic market, there is less job stability. </p>
","1828"
"Osborne, Nash equilibria and the correctness of beliefs","582","","<p>In Osborne's <em>An Introduction to Game Theory</em> Nash equilibrium is described as follows (p. 21–22):</p>

<blockquote>
  <p>First, each player chooses her action according to the model of
  rational choice, given her beliefs about the other players' actions.
  Second, every player's belief about the other players' actions is
  correct.</p>
</blockquote>

<p>It seems to me that this definition is not completely equivalent to the usual definition of the Nash equilibrium as a strategy profile where each player's strategy is a best response to the strategies of the others.</p>

<p>The usual definition says nothing about beliefs and therefore allows for the possibility that beliefs might be incorrect.</p>

<p>To take a trivial possibility, consider the Prisoner's Dilemma. Suppose each player believes that the other player will not confess. Since confessing is a dominant strategy each player would still confess. So the actions constitute a Nash equilibrium even though the players' beliefs are completely the opposite of the actual equilibrium actions.</p>

<p>Am I right in this understanding that Osborne's definition characterizes something other than Nash's equilibrium?</p>
","<p>Introducing the language of beliefs here is slightly strange, given that beliefs do have a very specific meaning in other parts of game theory.</p>

<p>Indeed, Osborne's description is reminiscent of a Bayes Nash Equilibrium. We could introduce the notion of beliefs into the normal form of a complete information game as follows: suppose that with probability $a_i$ each player, $i$, is a ""strategic"" <em>type</em> who will play according to (Nash) equilibrium, and with probability $1-a_i$ he will select some strategy uniformly at random (because, say, he is indifferent across all actions). We thus have a Bayesian game where thinking about beliefs is more natural.</p>

<p>The Bayes Nash solution concept then says that $i$'s strategy must be optimal given the expected play induced by the other players' strategies <em>and</em> the beliefs over their types implied by $\{a_j\}_{j\neq i}$. If we look at the limit as $a_i\rightarrow 1$ for all $i$ then the Bayes Nash equilibrium of this game will coincide with the solution concept described by Osborne.</p>

<hr>

<p>I guess the reason Osborne wrote it like this is a pedagogical one, given that this is an introductory text. When we introduce students to static games, we tell them that player $i$ best responds to the actions of the other players. Students naturally want to know ""how can they respond to a strategy chosen simultaneously without knowing what that strategy will be?"" This is, in many senses, a philosophical question. Common answers are</p>

<ul>
<li>If the game is one that is played often then (putting aside issues of
other outcomes that can be sustained in repeated games) we can think
of Nash as being an equilibrium in the sense that if we converge
there we can develop a norm whereby people continue to play that
equilibrium indefinitely (and expect others to do the same).</li>
<li>If the game is really one-shot then we usually invoke the idea that players are going to try to predict what others will do—and our equilibrium notion embeds the idea that these predictions must be correct.</li>
</ul>

<p>It seems that the predictions in the second point correspond to the ""beliefs"" invoked by Osborne. However, it is important to stress that these predictions/""beliefs"", are merely an informal/intuitive tool for helping us to conceptualise what is going on in an equilibrium and are not part of the definition of such an equilibrium. The concept of Nash equilibrium itself is completely agnostic on the notion of beliefs (as you note in a comment, it is defined only over actions), which is why, when Osborne goes on to <em>formally</em> define Nash equilibrium, he does so without invoking the idea of beliefs at all.</p>
","222"
"What is the effect of Quantitative Easing on the US budget deficit?","581","","<p>Is the deficit getting larger because of QE? </p>
","<p>No, the deficit is not getting larger due to QE. Certainly not directly, because that's impossible, and also not indirectly, either.</p>

<p>Quantitative easing is a policy of purchasing government bonds with the intent of decreasing yields while injecting cash into the economy. It affects only the demand for government bonds, not the supply of bonds created by government borrowing. </p>

<p>This shouldn't be a surprise, as the monetary authority (the central bank) and the fiscal authority (Congress) are independent of one another. Congress cannot (without rewriting the Federal Reserve Act) directly control monetary policy, nor can the Fed force the government to borrow more.</p>

<p>Indirectly, Congress could choose to borrow more as a result of QE, due to lower yields on government debt, as the lower debt payments make it cheaper to do so. However, there's not much evidence that this is the case. </p>

<p>The deficit has fallen since 2009 (when it significantly increased due to passage of a <a href=""https://en.wikipedia.org/wiki/American_Recovery_and_Reinvestment_Act_of_2009"" rel=""nofollow"">large-scale stimulus program</a> consisting primarily of tax cuts but also including direct federal spending, in response to the financial crisis and recession), both <a href=""https://fred.stlouisfed.org/series/FYFSD"" rel=""nofollow"">in nominal term</a>s and <a href=""https://fred.stlouisfed.org/series/FYFSDFYGDP"" rel=""nofollow"">as a percent of GDP</a>. As a percentage of GDP (which is the appropriate long-term comparison, as taxable income is the best indication of a nation's ability to repay a debt), the deficit returned to a normal historical range by 2014.</p>

<p>So it's difficult to conclude even that QE encouraged spending, thereby increasing the deficit indirectly. Given two facts— that the Federal Reserve's QE programs started in earnest in 2009 and continued until late 2014, and that the federal deficit steadily fell during this time— it would be very strange indeed to conclude that QE had increased the deficit.</p>
","13457"
"Competitive equilibrium in an exchange economy with lexicographic preferences","580","","<p>I am really stuck with this problem and not able to approach it. Any help will be much appreciated.</p>

<p>I tried to draw edgeworth box with initial endowment point. I do know that for competitive equilibrium, tangency condition must be met such that both utility curves are tangent at equilibrium point. But here, i am not able to identify utility curves. Please help.</p>

<p>Consider an exchange economy with two agents,1 and 2 and two goods X and Y. Agent 1's endowment is (0,10) and Agents 2's endowment is (11,0). Agent 1 strictly prefers bundle (a,b) to (c,d) if,either a>c or {a=c and b>d}. Agent 2 strictly prefers bundle (a,b) to (c,d) if min{a,b} > min{c,d}. For both agents, we say that bundle (a,b) is indifferent to bundle (c,d) if, neither (a,b) nor (c,d) is strictly preferred to each other.</p>

<p>Q. This exchange economy has:
a)one competitive equilibrium allocation.
b)two competitive equilibrium allocations.
c)infinite number of equilibrium allocations.
d) no competitive equilibrium allocations.</p>

<p>Answer : a</p>
","<p>The preferences of agent $A$ cannot be represented by any utility function and the prefeences of $B$ not by a differentiable utility function, so forget calculus approaches.</p>

<p>Since $A$ has strictly monotone preferences, we must have $p_1&gt;0$ and $p_2&gt;0$ for every equilibrium. Also, $A$ is always willing to give up any amount of good $2$ to get more of good $1$. So he will spend his wealth on good $1$ with consumption of good 1 equal to $10 p_2/p_1$. Also, we know that $B$ must consume both goods in equal amounts, so you just have to plug the equality $x_1^B=x_2^B$ in the budget constraint (justification <a href=""https://economics.stackexchange.com/a/5618/1442"">here</a>). Then you have the demand for both goods and can calculate their excess demands. Since only relative prices matter, you can normalize by, say, setting $p_1=1$. Since both agents will spend their whole wealth, <a href=""http://en.wikipedia.org/wiki/Walras&#39;_law"" rel=""nofollow noreferrer"">Walras' law</a> applies, and in order to find an equilibrium, you just have to find prices under which the excess demand for one of the goods (your choice) is zero. If you find a unique solution, you have found a unique equilibrium (note that demand is unique given prices).</p>
","5872"
"Solution to the Bellman equation is a fixed point","576","","<p>I have recently started studying dynamic optimization. I cannot quite wrap my head around the fact that the value function of the Bellman equation is a fixed point of a contraction mapping.
As far my understanding is rather naive: if the problem is finite, say:
$$\sum_{t=0}^T \beta^tu(c_t)$$
we construct the Bellman equation from the end, as if we knew the maximum possible value of the sequence in advance. Starting from the last period $T$, we just repeat the maximization by adding an optimal term reflecting current period utility $u(c_t)$, until we arrive to the period $0$. From here I can clearly see how contraction mapping works.
But the infinite case is not so easy for me to comprehend: I can only suppose, that, by iteration of the Bellman operator $(Bv)(x)$, we perform a ""calibration"" of the policy function until we find the value function (i.e. the maximum possible utility given our transversality conditions) $(Bv)(x)=v(x)$. Am I, at least, thinking in the right direction, or this idea should be understood in a different way?
Thank you in advance.
(Also, this is my first question on .stackexchange ever, and if there are any issues with presentation of my question, please, let me know)</p>
","<p>I am by no means an expert on this, but maybe this helps. Here is a simple example for a bellman equation</p>

<p>$V(y) = \max_x u(x,y) + \beta V(y')$</p>

<p>$s.t. \, y' = f(x,y)$</p>

<p>This is a functional equation in an unknown function V. A solution to this problem is a function V that satisfies the equation above. If you look at the equation, it's pretty clear that the solution has to be a fixed point of the operator on the RHS of the bellman equation: if you take the correct V and an arbitrary y and calculate</p>

<p>$\max_x u(x,y) + \beta V(y')$</p>

<p>$s.t. \, y' = f(x,y)$</p>

<p>you will get $V(y)$. The operator that is the RHS of the Bellman equation operates on functions, and the solution is a fixed point in some space of functions.</p>

<p>It's a different question whether this fixed point exists and how to find it. Here, you appeal to the contraction mapping theorem: under typical assumptions on u and provided $\beta&lt;1$, the maximization step above is a contraction mapping for any guess of V. This means that there exists a unique fixed point V, and you can find it by successive iteration.</p>
","15175"
"Editing formula for finding Marshallian Demand with Cobb-Douglas utility function","572","","<p>Suppose a utility function $u=x_1^ax_2^b$ with $a+b=1$. The following formula finds the values for $x$:</p>

<p>$x_1 = \frac{am}{p_1}\\
x_2 = \frac{bm}{p_2}$  </p>

<p>But what if the utility function looks like $u=cx_1^adx_2^b$ so has additional factors bevore $x_i$? Can the formula above be edited accordingly?</p>
","<p>$u=cx_1^adx_2^b$ is equivalent to $u=(cd)x_1^ax_2^b$
the values of $c$ and $d$ do not impact the optimal bundles. I'll provide complete working on your other question (<a href=""https://economics.stackexchange.com/questions/4997/marshallian-demand-for-cobb-douglas"">Marshallian Demand for Cobb-Douglas</a>).</p>
","5029"
"Condorcet's paradox: Is the majority rule transitive?","569","","<p>From this <a href=""http://en.wikipedia.org/wiki/Majority_rule#Other_properties"" rel=""nofollow"">wikipedia link</a> I would say that the majority rule is not transitive. Also I'm not sure I understand exactly what is transitivity in this situation... With a usual preference relation $x\succsim y$ and $y\succsim z$ then $x\succsim z$. </p>

<p>However, from the wikipedia, we could get a paradox ? </p>
","<p>As you stated, transitivity is that overall $x \succeq y$ and $y \succeq z$ implies $x \succeq z$. I will show an example where majority rule isn't transitive and hopefully it will answer your question.</p>

<p>Imagine that we live in a world with three people: Person 1, Person 2, and Person 3. Each of these people have preferences over three outcomes $x$, $y$, and $z$. Every decision in this world is made according to majority rules, i.e. The outcome chosen is the one preferred by at least two of the individuals.</p>

<p>Now imagine that the three people have preferences according to:</p>

<ul>
<li>Person 1: $x \succeq y \succeq z$</li>
<li>Person 2: $y \succeq z \succeq x$</li>
<li>Person 3: $z \succeq x \succeq y$</li>
</ul>

<p>The majority rule decision making implies that we rank the pairs according to the following:</p>

<ul>
<li>$ x \succeq y$ because Person 1 and Person 3 prefer $x$ to $y$</li>
<li>$ y \succeq z$ because Person 2 and Person 3 prefer $y$ to $z$</li>
<li>$ z \succeq x$ because Person 2 and Person 3 prefer $z$ to $x$</li>
</ul>

<p>Notice that this is exactly a violation of transitivity.</p>
","5806"
"Why is Price Vector Orthogonal to Vector connecting two bundles on Budget Hyperplane","563","","<p><strong>Here is my revised version/understanding why price vector is orthogonal to any vector from a bundle on the budget hyperplane to another bundle on the hyperplane: (see below for original question)</strong></p>

<blockquote>
  <p>Want to show geometrically that budget hyperplane is the relative terms of exchange. This is a fancy way of saying it represents the 'ratio' of the prices between any two commodities. For simplicity sake, look at $L=2$. We have two options for a ratio: either $\frac{p_1}{p_2}$ or $\frac{p_2}{p_1}$. What would it be? The way the price vector is constructed is <strong>p</strong>$=(p_1,p_2)$, so when you draw this vector from any point on the budget line that is negatively sloped in the case of $L=2$, the vector is essentially the slope (e.g. rise over run) of $\frac{p_2}{p_1}$. So obviously, if the negatively sloped budget line is supposed to represent the price ratio, then it has to be the case $\frac{-p_1}{p_2}$. In fact, this is so from the Walrasian budget set definition where $w=x\cdot p$.</p>
</blockquote>

<p>When we look at a typical Walrasian budget set in $\mathbb{R^+_2}$, why is the price vector orthogonal to the consumption vector (e.g. any two on the slope) on the budget hyperplane? This goes back to Chapter 2 of MWG.
<br> I understand the analytical explanation using dot product. </p>

<blockquote>
  <p>$p\cdot x=p\cdot x'=w$ for $x,x'\in\{x\in\mathbb{R^+_2}:p\cdot x=w\}$.
  <br> Hence, $p\cdot\Delta x=0$.</p>
</blockquote>

<p>But I am having a tough time understanding two things:</p>

<blockquote>
  <p>(Q) Why does this orthogonality between price and consumption vector on hyperplane relate back to the slope of the budget line determining the relative rate of exchange between two commodities? How do you make sense between intuition and geometric interpretation?</p>
</blockquote>

<p>Thanks for your 2 cent!</p>
","<p>Note that $p$ is not orthogonal to consumption vectors on the budget line, but it is orthogonal to a any vector $v$ that satisfies $x+v=x'$ with $x,x'$ in the budget line. MWG are drawing vectors starting from some $x$.</p>

<p>About the slope: In the budget line you can see that the slope for any $x$ is $D_x (p.x)=p$ (that is the line that is drawn from $x$). That line or vector can be represented with the function $x_2=(p_2/p_1)*x_1$ (note that if $x_1=p_1$, $x_2=p_2$). The slope is $p_2/p_1$.</p>

<p>On the other hand, all vectors on the budget line satisfy $x_2=(-p_1/p_2)*x_1+w/p_2$. The slope here is $(-p_1/p_2)$. This slope is the rate of exchange. Both slopes imply that the two functions (the vector $p$ and the budget line) are orthogonal. Or maybe it's better to say that the orthogonality between the budget line and the vector $p$ imply that $dx_2/dx_1=-p_1/p_2$, that is, the last term captures the rate of exchange. </p>
","12530"
"Consumption function with negative intercept?","562","","<p>I am doing an assignment where I calculate the consumption function of a certain country from empirical data and I am getting a negative intercept. How can this be interpreted because usually, isn't the intercept always positive?</p>
","<p>I assume that you ran a linear regression to find the $C(Y)$ function and by negative intercept you mean $C(0)&lt;0$. This does not contradict anything because what you have is an estimate of the $C(Y)$ function based on empirical data that was probably centered around some non-zero value of $Y$. So it is quite possible that the function's estimate is incorrect far from the observed range of $Y$, especially if you were using a linear regression which is a very basic functional form.</p>

<p>If the actual $C(Y)$ consumption function, not the estimate, were such that $C(0) &lt; 0$ then indeed we would have a contradiction. But as long as you are clear that what you have is an estimate for $C(Y)$ this problem does not arise.</p>
","10295"
"Impact of Import Quota onto Revenues","557","","<p>I'm learning about quotas from my textbook but I've found one thing that doesn't make sense to me at all and I think it may be a mistake in the book.
The context: $P_w$ is the price of wheat on the world market. So far the domestic government has allowed free trade but now they set an import quota of $Q_3 - Q_1$.</p>

<p><img src=""https://i.stack.imgur.com/BsMwE.png"" alt=""enter image description here""></p>

<p>The text accompanying the graph says:</p>

<blockquote>
  <p>Domestic producers now supply $0Q_1$ and $Q_3Q_4$ tons of wheat at a
  price of $P_{quota}$. Their revenue rises from $a$ to $a+c+d+f+i+j$.</p>
</blockquote>

<p>What I can't understand is why they included $f$ in the last sentence. In my opinion their revenue rises from $a$ to $a+c+d+i+j$. Domestic producers first sell $0Q_1$ quantity for price $P_w$ so they make profit of $a$ and then they sell quantity $Q_3Q4$ for price $P_{quota}$ which gives area of the rectangle: $c+i+j+d$.  I have no idea what that $f$ is doing there. Can anyone explain?</p>
","<p>There is no mistake. The solution: it is assumed that there is only one price at the domestic wheat market. Hence domestic producers will not sell at price $P_w$ and price $P_{Quota}$ as well. This makes sense: Suppose you are a domestic producer and you are aware that the price that results from the quota system is $P_{Quota}$. Knowing this you would not sell your goods for the lower $P_w$.</p>
","6582"
"Econometrics: Is elasticity meaningful in my, or any, regression?","556","","<p>A few months ago I interned at this organization; and, as a going away present, I decided to spend my last week, with whatever off time I had, to investigate the factors that affect teacher salaries. One problem that I ran into with teacher salaries was that the distribution for the given state was skewed. I had a lot of observations that clung to the lower end of the wage spectrum. I tried resolving this by incorporating a Comparable Wage Index into my dependent variable (teacher wages), but the results I found were completely out of date for the scope of my project. I instead decided to log my dependent variable. This was nice because now my wages had a normal distribution and it just looked perfect in the histogram. When I started testing down, I got to the point where I was left with one last independent variable, property tax returns. The problem with my normative wages was also apparent in my property tax return observations. I had a huge skew of property tax return numbers towards the lower end of the spectrum. So, I logged this variable as well and it still passed the null hypothesis test just fine.</p>

<p>I am not sure if this is precisely correct, but by comparing the change of one logged variable to another logged variable gave me the elasticity. Assuming that this is correct, my regression equation (something like LogWages = B0 + B1(LogPropertyTaxReturns)) shows the elasticity between the two variables. Is this meaningful though? If my goal was to see which variable most affected teacher salaries in any given county of my state, then is showing the elasticity between the two variables helpful? We want to raise the counties with the lowest teacher salaries up higher to increase their living standards, but I fear that I've extrapolated so far away from the real observations that my concluding regression equation is meaningless. </p>

<p>Edit: One of my bigger fears is that I should have used a non-linear model to show the relationship. I feel that forcing both the dependent and independent variable to cooperate in a this linear regression is misleading in some way.</p>
","<p>The answer to the question is yes, it is indeed meaningful (at least mathematically speaking). If you estimate the linear equation</p>

<p>$$ W = \beta_0 + \beta_1 PTR, $$</p>

<p>then $\beta_1=\frac{\partial W }{\partial PTR}$, meaning that $\beta_1$ represents the marginal change of $PTR$ over $W$. Now, if you estimate</p>

<p>$$ log(W) = \beta_0 + \beta_1 log(PTR), $$</p>

<p>then $\beta_1=\frac{\partial W}{\partial PTR}\cdot\frac{PTR}{W}$, which is the very definition of elasticity.</p>

<p>Generally speaking, linear transformations only affect the interpretation given to the coefficients, but the validity of the regression itself (in broad economic terms) is given by the model's assumptions and the economic phenomena being analyzed.</p>
","29"
"Simulating a Hamilton-Jacobi-Bellman","556","","<p>Say I have solved an HJB of the form:</p>

<p>$\rho V(k) = \max_c g(c) + V'(k)(z - c)$</p>

<p>I have calibrated $\rho$ to monthly parameters. I would like to simulate the development of $k$. I start with $k(0)$. However, unlike in discrete-time, I'm not sure what happens next.</p>

<p>Is $k(1) = k(0) + (z-c(0))$, with $k(1)$ being the value of $k$ for the next month? Or do I need to somehow integrate along the lines of $k(1) = \int_0^1 (z-c(t))dt + k(0)$? There's many references on solving these things, but I couldn't find any references on simulating it.</p>
","<p>Expanding on jmbejara's answer and your question about integration, there are really three steps here:</p>

<ol>
<li>Solve the HJB equation $\rho V(k) = \max_c g(c)+V'(k)(z-c)$. (You're already done this.)</li>
<li>Obtain the policy function $c(k)=\text{argmax}_c g(c)+V'(k)(z-c)$. (You presumably already did this while solving the HJB.)</li>
<li>Substitute $c(k)$ into the law of motion for $k$ and numerically solve that differential equation for $k(t)$:$$\dot{k}=z-c(k)$$</li>
</ol>

<p>It sounds like you already had (1) and (2) and were just unsure about what exactly to do in (3). If you're working in a deterministic environment (and from the HJB it looks like you are), no discretization on your part is necessary: you can just use a canned ODE solver from Matlab or any other software package to numerically solve the differential equation above for $k(t)$.</p>

<p>To be a little more specific: </p>

<ul>
<li>If the HJB is simple and you have an analytical solution for $V(k)$, and thus can easily compute $c(k)$ as well, that's great. You can just plug $c(k)$ into the law of motion for $k$ and tell your software package of choice to solve it and obtain the trajectory of $k(t)$.</li>
<li>If you had to numerically solve the HJB, then that's great because it means that you probably have already used some kind of numerical ODE solution technique and will be familiar with it. On the minus side, it means that when you initially obtain $V(k)$ and $c(k)$, you'll only get it for a grid of $k$, rather than having some kind of formula you can apply everywhere - which is a problem, because you'll need to be able to determine $c(k)$ at any point $k$ in a continuum if you're going to numerically solve the $\dot{k}$ differential equation for $k(t)$. The simplest way around this, to my knowledge, is to fit a spline to (or use some other approximation method on) the discrete grid of $(k_{grid},c(k_{grid}))$ values that you have. Then you can obtain an approximate value of $c(k)$ anywhere that's covered by the spline, and it will be extremely accurate assuming that your ODE is well-behaved and you have a dense grid.</li>
</ul>

<p>Things get more complicated in a stochastic environment, but your case looks deterministic. (And to be clear, I'm just a dabbler here: numerical methods are not my area of expertise. But this is what I know.)</p>
","1612"
"Does risk aversion cause diminishing marginal utility, or vice versa?","555","","<p>Let $A$ be the set of possible states of the world, or possible preferences a person could have. Let $G(A)$ be the set of ""gambles"" or ""lotteries"", i.e. the set of probability distributions over $A$. Then each person would have a preferred ordering of the states in $A$, as well as a preferred ordering of the lotteries in $G(A)$. The von Neumann-Morgenstern theorem states that, assuming your preference ordering over $G(A)$ obeys certain rationality axioms, your preferences can be represented by a utility function $u: A → ℝ$. (This function is unique up to multiplication of scalars and addition of constants.) That means that for any two lotteries $L_1$ and $L_2$ in $G(A)$, you prefer $L_1$ to $L_2$ if and only if the expected value of $u$ under $L_1$ is greater than the expected value of $u$ under $L_2$. In other words, you maximize the expected value of the utility function.</p>

<p>Now just because you maximize the expected value of your utility function does not mean that you maximize the expected value of actual things like money. After all, people are often risk averse; they say ""a bird in the hand is worth two in the bush"". Risk aversion means that you value a gamble less than expected value of the money you'll gain. If we express this notion in terms of the von Neumann-Morgenstern utility function, we get the following result through Jensen's inequality: a person is risk averse if and only if their utility function is a concave function of your money, i.e. the extent to which you're risk averse is the same as the extent to which you have a diminishing marginal utility of money. (See page 13 of <a href=""http://www.stanford.edu/~jdlevin/Econ%20202/Uncertainty.pdf"" rel=""nofollow noreferrer"">this PDF</a>.)</p>

<p>My question is, which direction does the causation run? Do the values of the von Neumann-Morgenstern utility function reflect the intensity of your preferences, and is risk aversion due to discounting the preferences of future selves who are well-off compared to the preferences of future versions of yourself who are poorer and thus value money more (as Brad Delong suggests <a href=""http://delong.typepad.com/sdj/2011/08/1049-million.html"" rel=""nofollow noreferrer"">here</a>)? Or does the causation run the other way: does your tolerance for risk determine the shape of your utility function, so that the von Neumann-Morgenstern utility function tells you nothing about the relative intensity of your preferences?</p>
","<p>I think I've found an answer to my question, in <a href=""http://gdurl.com/sSNT"" rel=""nofollow noreferrer"">this excerpt</a> from Nobel laureate John C. Harsanyi's 1994 paper ""Normative validity and meaning of von neumann-morgenstern utilities"", presented at the Ninth International Congress of Logic, Methodology and Philosophy of Science.  Harsanyi starts by proving the same lemma that Alecos proved in his answer, namely that if $u$ is a vNM utility function of an individual, then $u(10) - u(5) &lt; u(5) - u(0)$ if and only if they would prefer a guaranteed 5 dollars compared to a 50% of 10 dollars and a 50% chance of 0 dollars.  In the comments section I said that was insufficient to demonstrate that the vNM utility function represented intensity of preferences, because what if the individual's actual pleasure and pain was accurately described by some other utility function $v$, which is a monotonic transformation but not an affine transformation of $u$?  In that case couldn't $v$ fail to satisfy the expected value property, and couldn't $v(10) - v(5) = v(5) - v(0)$?</p>

<p>Harsanyi has a clever argument dealing with this issue. Let $L_1$ be the lottery where you get 5 dollars guaranteed, let $L_2$ be the lottery where you have a 50% chance of 10 dollars and a 50% chance of 0 dollars, and let $L_3$ be the lottery where you have a 50% chance of 10 dollars and a 50% chance of 5 dollars.  Then obviously the person prefers $L_3$ to both $L_1$ and $L_2$.  And Harsanyi argues that $L_3$ is preferred to $L_1$ less strongly than $L_3$ is preferred to $L_2$ if and only if $v(10) - v(5) &lt; v(5) - v(0)$.  That's because in the choice between, $L_3$ vs $L_1$, 50% of the time they get 5 dollars, and 50% of the time they have to make a choice between 10 and 5.  Similarly in the choice between $L_3$ and $L_2$, 50% of the time they get 10 dollars, and 50% of the time they have to make a choice between 5 and 0.  </p>

<p>Now here comes the master stroke: $L_1$ is preferred to $L_2$ if and only if $L_3$ is preferred to $L_1$ less strongly than $L_3$ is preferred to $L_2$.  Therefore, $L_1$ is preferred to $L_2$ if and only if $v(10)-v(5) &lt; v(5) -v(0)$.  And thus we reach the grand conclusion that $u(10) - u(5) &lt; u(5) - u(0)$ if and only if $v(10)-v(5) &lt; v(5) -v(0)$.</p>

<p>Thus Harasanyi reaches the conclusion that the vNM utility function represents preferences intensities.  So the answer to my question seems to be that diminishing marginal utility in the vNM utility function reflects genuine diminishing marginal utility when it comes to intensity of preferences, and thus (assuming the vNM axioms are true) diminishing marginal utility really is the cause of risk aversion.</p>

<p>By the way, on a side note I wonder whether we could identify the set of all functions $v$ that satisfy the constraint that $u(x) - u(y) &lt; u(z) - u(w)$ if and only if $v(x)-v(y) &lt; v(z) -v(w)$ (and similarly for greater than and equal to).  (EDIT: I asked about this on Mathematics.SE <a href=""https://math.stackexchange.com/q/1238576/71829"">here</a>.)</p>
","5164"
"Deriving the Modigliani--Miller Theorem","552","","<p>In the Wikipedia article on the <a href=""https://en.wikipedia.org/wiki/Modigliani%E2%80%93Miller_theorem#Without_taxes"" rel=""nofollow noreferrer"">Modigliani--Miller theorem</a>, it states two propositions. (It gives the cases of with and without taxes. Here I'll just focus on the case without taxes.)
The first proposition is that the value of an unlevered firm is the same as a levered firm. Given the assumptions, this is clear from the discussion:</p>

<blockquote>
  <p>To see why this should be true, suppose an investor is considering buying one of the two firms U or L. Instead of purchasing the shares of the levered firm L, he could purchase the shares of firm U and borrow the same amount of money B that firm L does. The eventual returns to either of these investments would be the same. Therefore the price of L must be the same as the price of U minus the money borrowed B, which is the value of L's debt.</p>
</blockquote>

<p>However, here I am asking about ""Proposition II:""</p>

<blockquote>
  <p>$$r_E(Levered) = r_E(Unlevered) + \frac DE (r_E(Unlevered) - r_D),$$
  where</p>
  
  <ul>
  <li>$r_E$ ''is the required rate of return on equity, or cost of equity,''</li>
  <li>$r_D$ ''is the required rate of return on borrowings, or cost of debt,''</li>
  <li>and $\frac{D}{E}$ ''is the debt-to-equity ratio.''</li>
  </ul>
</blockquote>

<p>The article states that the ""formula is derived from the theory of weighted average cost of capital (WACC)."" (See a related question <a href=""https://economics.stackexchange.com/questions/2932/deriving-and-explaining-the-weighted-cost-of-capital"">here</a>.) My question is this: how can we arrive at this result from WACC?</p>
","<p>The first equation can be written as:</p>

<p>$$ r_E(Levered) = \frac{E+D}{E}r_E(Unlevered) - \frac{D}{E}r_D $$</p>

<p>Then, isolating the unlevered return gives:</p>

<p>$$ r_E(Unlevered) = \frac{E}{E+D}r_E(Levered) + \frac{D}{E+D}r_D$$</p>

<p>And this is the WACC.</p>
","2940"
"When Does a Shift to the Right Happen in the Demand and Supply Curves Simultaneously?","552","","<p>If, for example, Health Canada issues a public statement that states eating pizza is good for your overall physical health, would this result in both a shift in the demand curve for pizza to the right, and a shift in the supply curve of pizza to the right?</p>

<p>If not, could you give more information on when this would actually happen?</p>
","<p>To answer your first question: No, it shifts out only the demand curve but not the supply curve. However, the quantity supplied increases.</p>

<p>To understand why the advertisement does only shift out the demand curve but not the supply, you have to understand two important concepts: </p>

<p>(1) Shift of the demand curve = Increase of demand;
(2) Movement along the demand curve = Increase of quantity demanded.</p>

<p>Similarly with supply:</p>

<p>(1) Shift of supply curve = Increase of supply;
(2) Movement along the supply curve = Increase of quantity supplied.</p>

<p>Now what happens, if you advertise for pizza? The demand as well as the quantity supplied increase. To see this, consider the following. More people demand pizza so the demand curve shift out and the demand increases. At the same time, the supply curve does not move. BUT, the outwards shift of the demand curve intersects the supply curve further to the right, and hence, the quantity supplied increases.</p>

<p>Shifts of the demand curve can be caused, for example, when people's income increases or decreases. Demand increases usually increase the quantity supplied.</p>

<p>Shifts of the supply curve can be caused, for example, through the the use of better technology that lowers producers marginal production costs. Supply increase usually increases the quantity demanded. </p>

<p>Increases or decreases of quantity demanded or quantity supplied can be caused through price changes.</p>

<p>A simultaneous increase of demand and supply can be cause if consumers get a higher income and firms get a better technology at the same time.</p>
","8421"
"Risk Premium in the Expected Utility Theory","548","","<p>Consider an agent with utility function $u$, initial wealth $\omega$, and a random variable $x$. By definition of the risk premium $R$, we have </p>

<p>$$ Eu(w+x) = u(w+E(x)-R). $$</p>

<p>The classical derivation of the risk premium is as follows:</p>

<p>A Taylor series expansion of <strong>order 2</strong> in the neighborhood of $(\omega + E(x))$ of the left-hand side (LHS) gives</p>

<p>$$u(\omega+x) \approx u[\omega+E(x)] + u'[x-E(x)] + \frac{1}{2} u''[x-E(x)]^2,$$</p>

<p>A Taylor series expansion of <strong>order 1</strong> in the neighborhood of  $(\omega + E(x) - R)$ of the right hand side (RHS) gives</p>

<p>$$u(\omega + E(x)-R)  \approx  u(\omega+E(x)) - u'R.$$</p>

<p>Taking expectation of the first series expansion and combining the results of the two series with the definition of the risk premium yields</p>

<p>$$u(\omega + E(x)) + u'E[x-E(x)] + \frac{1}{2} u''E[x-E(x)]^2  \approx   u(\omega+E(x)) - u'R.$$</p>

<p>This implies</p>

<p>$$R \approx - \frac{1}{2} \frac{u''}{u'} E[x-E(x)]^2.$$</p>

<p>My understanding of this derivation is that we can take a 2- or higher-order expansion of the LHS if we want the risk premium to be related not only to the variance of $R$ but also to higher moments of $R$. </p>

<p>However, is there any (economic) rational for the first-order expansion of the RHS? And for its different neighborhood evaluation?</p>
","<blockquote>
  <p><em>Is there any (economic) rational for the first-order expansion of the RHS? And for its different neighborhood evaluation?</em></p>
</blockquote>

<p>As for your first question:<br>
This is a purely mathematical tactic in order to obtain an (approximate) equation for $R$. The expansion of first order on the RHS is motivated by this fact, i.e. to bring $R$ alone ""in the surface"".  The reason why the LHS is subjected to a second-order expansion is in order for something to be left (the variance term). Higher-order expansions of the LHS can certainly be applied.</p>

<p>As for your second question, you are making a mistake. The center of expansion for the RHS expansion is the same as that for the LHS expansion, namely $w-E(x)$ (or equivalently, around $R=0$). It is meaningless (and it fails) to expand a function around its exact argument. Specifically we have</p>

<p>$$u\left(w+E(x)-R\right) \approx u\left(w+E(x)\right) + u'\cdot [(w+E(x)-R)-(w+E(x))] = u\left(w+E(x)\right) - u'\cdot R$$</p>

<p>Finally, why not consider a second-order expansion on the RHS? We would then get</p>

<p>$$u\left(w+E(x)-R\right) \approx u\left(w+E(x)\right) + u'\cdot [(w+E(x)-R)-(w+E(x))] \\+\frac 12 u''\cdot [(w+E(x)-R)-(w+E(x))]^2 $$</p>

<p>$$= u\left(w+E(x)\right) - u'\cdot R + \frac 12 u''\cdot R^2$$ </p>

<p>Then we would obtain a quadratic polynomial in $R$,</p>

<p>$$\frac 12 u''\cdot R^2 - u'\cdot R - \frac 12 u''\sigma^2_x = 0$$</p>

<p>$$\ R^2 - \frac {2u'}{u''}\cdot R - \sigma^2_x = 0$$</p>

<p>This has roots</p>

<p>$$R_1,R_2 = \frac {(2u'/u'') \pm \sqrt{(2u'/u'')^2+4\sigma^2_x}}{2}$$</p>

<p>$$\implies R = \frac{u'}{u''} + \sqrt{\left( \frac{u'}{u''}\right)^2+\sigma^2_x}$$</p>

<p>You can totally validly use this expression for $R$, but I guess you understand why the simpler one is used instead.</p>
","9070"
"Electricity as inelastic good","546","","<p>Could be electricity considered as an inelastic good?</p>

<p>I am interested in the electricity delivered to final consumers in member countries of Nordpool Spot (Norway, Sweden, Finland, Denmark, Estonia, Latvia and Lithuania). I found that market prices in Nordpool Spot is not correlated with electricity consumption, therefore I explain this by considering, in this case, electricity as an inelastic good.</p>

<p>Is this reasoning correct?</p>
","<p>It is. And it is not.</p>

<p>Electricity markets are generally not set up for the demand-side to do much active participation at all. So the short-run demand curve as seen in, for example, Nordpool Spot, is almost perfectly inelastic. Not quite, because there are some large industrial demands that exhibit some elasticity, and are exposed to the spot market. But a very large chunk of demand isn't exposed to the spot market at all; and a lot of the demand that is exposed, is highly inelastic - particularly to half-hour-by-half-hour changes.</p>

<p>That tells us a lot about the structure of the markets, and only a little about the actual underlying demand curve.</p>

<p>Until there's a lot of demand-side response (DSR), we've only got stated-preference studies and DSR pilots to go on, to estimate what the demand curve would look like in a well-functioning market: the evidence we have (e.g. from the Olympic Peninsula study), suggests there's quite a lot of potential demand elasticity out there, just waiting to be harnessed. Note that when short-run demand elasticity has been observed, it manifests in two ways: some demand will move <em>between</em> half-hours that aren't too far apart, when the price differentials incentivise it. Some other demand will just vanish altogether when prices rise.</p>

<p>If you want to try to distinguish the elasticity signal from all the noise in the existing market, then you need to take demand and prices for a particular half-hour slot on Tuesdays-Thursdays in one particular season across several years; and look at how weather-adjusted demand varies with price, while adjusting for any long-term trends.</p>
","10306"
"Existence of solution to maximization problem","546","","<p>I'm a first year grad student and we're learning about the utility maximization problem and the producer's problem now. We have been assuming that a solution to these problems exists. But every now and then there's an exercise problem asking us to show that a solution exists. I have encountered once that ""A maximization problem on a compact set has a solution"". I wonder if there's any good reference on this? We're using MGW's Microeconomic Theory as our textbook; I thought I could find something in the appendix but I failed.  </p>
","<p>It is most likely that the statement is in the form of 'A utility maximization problem on a compact set has a solution when the utility function is continuous.' In the one dimensional case, this is a direct corollary of the extreme value theorem. A reference to this theorem can be found at <a href=""https://en.wikipedia.org/wiki/Extreme_value_theorem"">https://en.wikipedia.org/wiki/Extreme_value_theorem</a> </p>

<p>However, discontinuity of the utility function may break this result. Consider the following function.
$$
u(x) =  \begin{cases} x \mbox{ if $x\in[0,\frac{1}{2})$,} \\ \frac{1}{4} \mbox{ if $x \in [\frac{1}{2},1].$   } \end{cases} 
$$
It should be immediate to recognize that this function does not have attain a maximum for any $x\in [0,1]$ even though we have a compact set.</p>

<p>A book that I had used before is <a href=""http://rads.stackoverflow.com/amzn/click/0521497701"">here</a> which deals with optimization problems of the sort of an economist would encounter in a rigorous way. Also, <a href=""http://rads.stackoverflow.com/amzn/click/0393957330"">this book</a> provides a more intuitive way of establishing the main results, which would be a better start.</p>
","8549"
"Australian Dollar Devaluation","540","","<p>I am a layman in economics. I am curious about the current devaluation of Australian Dollar in comparison with the US Dollar. Could someone please explain, in simplest words possible:</p>

<ol>
<li>What causes currency devaluation? Is it a variety of factors or are there some common factors in all currency devaluations? </li>
<li>What does this devaluation mean for people living in Australia, people living in US, and people living in other countries, say China? I understand that one of the consequences for Australians is that their exports become cheaper, so foreign countries have more incentive to buy Australia products. For Australians, this could potentially mean more incentive to produce/work/innovate, and to decrease their imports. In other (naive) words, tighten their belts, rely more on themselves and less on the external world. This, logically, seems like a positive sign and should have good consequences. Does this interpretation have any element of truth in it? And is there another, completely opposite, possible outcome of this devaluation?</li>
<li>What are good (smart) ways for the Australian government and policy makers to respond to this? </li>
<li>How does devaluation translate in ""standard of living"". I was looking at the historical exchange rate of AUD and USD <a href=""http://www.oanda.com/currency/historical-rates/"" rel=""nofollow"">here</a> since 2000. Interestingly, in March 2001, the AUD was almost half of USD, and in July 2011, it was more than 1 USD! Surely, it does not mean that the standard of living in Australia in March 2001 was twice as bad as it was in July 2011 (in comparison with US), does it?</li>
</ol>

<p>I understand that forex rates involve an interconnection of many factors. But, I want to be educated about how much we know about it, and how much of what we know is actually useful for us.</p>
","<p>This question is heavily reliant on the context of when it was asked. A lot has happened since February with respect to the Australian Dollar.</p>

<ol>
<li><ul>
<li><p>A currency devaluation can be caused by quite a few factors. In the case of Australia, the devaluation is occurring with respect to the USD. The AUD remains strong but the US is currently experiencing a surge in consumer confidence. There is also a few larger factors at play. The USD is seen as basically the safest investment one can make. In recent history, govt bonds have been less attractive. As a result, Australian Sovereign bonds have been more attractive as they are very safe. In short, the AUD devaluation has more to do with the strength of the US than any domestic weakness (although Australian economic performance has been underwhelming).</p></li>
<li><p>Another key factor relates to the resources boom in Australia. This has primarily been driven by an increase in demand from China instead of an increase in mineral output. The resources book has been a key driver of economic growth. In March/April, the iron ore price took a big hit, partly due to weakening demand from China. As a result of the change in price, the value of Australia's exports dropped very quickly. This directly reduces our Terms of Trade. Manufacturers are pretty happy about this and it is expected they will pick up some of the slack from the stagnating mining sector.</p></li>
</ul></li>
<li><p>This devaluation has a few flow through consequences. Exporting to the US is cheaper. Importing from the US in particular is more expensive. A good way to think about it is if you are Australian and are thinking about travelling to the US for a holiday, you would be pretty upset. Your trip just got a lot more expensive very quickly. If you own a hotel and you cater to a lot of American tourists, you will be very happy. It will be cheaper for them to come. This change is good for our exporters, including natural resources, manufacturers and services.</p></li>
<li><ul>
<li><p>The RBA typically responds to these issues very well. Their main instrument of monetary policy is the interest rate.</p></li>
<li><p>There isn't much need for a monetary policy response to the devaluation of the dollar. The RBA targets inflation rate which is preferred to Exchange Rate Targeting by many governments.</p></li>
<li><p>With respect to a fiscal policy response, The IMF has a working paper on <a href=""https://www.imf.org/external/pubs/ft/wp/2012/wp1252.pdf"" rel=""nofollow"">Fiscal Policy and the Real Exchange rate</a>. It doesn't answer it perfectly, but it is definitely worth a read. The key point is that the effect depends critically on (i) the composition of public spending, (ii) the underlying financing policy, (iii) the intensity of private
capital in production, and (iv) the relative productivity of public infrastructure</p></li>
</ul></li>
<li><p>There should be very low immediate pressure on the standard of living. It gets more expensive to import into Australia, but Australian produced products are more competitive in the international marketplace.</p></li>
</ol>
","3262"
"Quasiconvexity of the indirect utility function","539","","<p>In Mas-Colell, Whinston, and Green's Microeconomics they define the <em>indirect utility function,</em> $v(p,w)$ as</p>

<p>$$ v(p,w) := u(x^*) $$</p>

<p>Where $x^* \in x(p,w)$ solves the utility maximization problem.</p>

<p>They state a property of $v(p,w)$ is quasiconvexity, i.e. the set</p>

<p>$$ \{(p,w): v(p,w) \leq \bar{v} \} $$</p>

<p>is convex for any $\bar{v}$.</p>

<p>Just the page before they said that convexity of preferences implies that $u(\bullet)$ is <em>quasiconcave</em>, so my question is why when we look at the max of $u$, it's quasiconcave property inflects (can't think of a better word) to quasiconvexity?  </p>
","<p>The functions and their variables are different, so there is no ""inflection"" or flipping.</p>

<p>The utility function $u$ which maps from the space of goods $X$ to $\mathbb{R}$ is convex and quasiconcave.</p>

<p>The indirect utility function $v$ which maps from the space of prices to $\mathbb{R}$ is quasiconvex.</p>

<p>Intuitively: <br>
$u$: If you average two consumption bundles your utility is not lower than the average of the utility of the two bundles. Rather than eating just meat one day and just vegetables the other day you prefer to mix these everyday.</p>

<p>$v$: If the price vector is $p$ one day and $p'$ the other day you may be better off than if it was $\frac{p + p'}{2}$ every day. It is easy to check that anything you can buy under the second price regime you can also buy under the first. However there might be consumption bundles that you can only buy under the first price regime.</p>
","13478"
"Why isn't the ""annihilator"" matrix a zero matrix?","539","","<p>I am struggling to understand why M is not null since:
$$\mathbf M=I−X(X′X){^-}^1X′=I−XX{^-}^1X'{^-}^1X′=I-I=[0] $$
What's wrong with that reasonning?</p>
","<p>The inverse of some matrix $X$, $X^{-1}$, is defined for square matrices only (i.e. when $X$ has the same number of rows and columns). In the typical econometric applications, the data matrix $X$ usually has far more rows (observations) than columns (regressors). Formally speaking, the matrix $X$ in your definition of $M$ has dimension $n\times k$ but $n\ne k$ (actually $n\gg k$), and so it's not a square matrix. </p>

<p>Therefore the second equality in your derivation is not valid; in particular, $(X'X)^{-1}\ne X^{-1}(X')^{-1}$, because $X^{-1}$ and $(X')^{-1}$ are not defined.</p>
","11706"
"Is the capital-output ratio in developing countries low or high?","534","","<p>For a developing economy, I've seen sources claiming that the capital-output ratio (more commonly known as ICOR) is high (e.g. <a href=""http://ahsankhaneco.blogspot.com/2012/04/basic-major-and-common-characteristics.html"" rel=""nofollow noreferrer"">here</a> and <a href=""https://www.quora.com/What-is-capital-output-ratio"" rel=""nofollow noreferrer"">here</a>), while other sources claiming that it's low, like below (the answer is A):</p>

<p><a href=""https://i.stack.imgur.com/NNUkR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NNUkR.png"" alt=""enter image description here""></a></p>

<p>I suppose I can come up with reasons why the ICOR or a developing country might be low: low rate of saving -> little investment on capital -> low returns -> low ICOR. Then again, the ICOR is a ratio, so even if both nominal investment and output are low, there is no guarantee that they're values are therefore low relative to each other, if anything the ICOR can easily be high, as explained in the two sources that claim the ICOR is high for such economies.</p>
","<p>The key to the answer is good data on Capital. There is a project (<a href=""http://www.worldklems.net/data.htm"" rel=""nofollow noreferrer"">KLEMS</a>), which is computing harmonised (i.e. comparable) information on capital, labour, energy, etc for many countries. At the moment it has information mainly on developed countries, but data for more developing countries are coming up. </p>

<p>For example, this is a calculation of the capital-output ratio for the case of the UK:</p>

<p><a href=""https://i.stack.imgur.com/kPcpx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kPcpx.png"" alt=""enter image description here""></a></p>

<p>For the case of developing countries, here is a figure:</p>

<p><a href=""https://i.stack.imgur.com/LgbyI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LgbyI.png"" alt=""enter image description here""></a></p>

<p>(source <a href=""http://www.oecd-ilibrary.org/development/economic-outlook-for-southeast-asia-china-and-india-2014/policy-priorities-for-growing-beyond-the-middle-income-trap-in-emerging-asia_saeo-2014-9-en"" rel=""nofollow noreferrer"">here</a>)</p>

<p>It seems that developing countries might have lower capital-output ratios. However, this is ultimately an empirical question which requires a proper analysis. I suggest you use the KLEMS data to make your own, harmonised study.</p>
","16237"
"Proving existence of utility function","532","","<p>In Advanced Microeconomic theory by Jehle and Reny there is a proof of the theorem which states the existence of utility function.</p>

<p>In order to prove the existence of a utility function $u(\mathbf{x})$ which represents binary relation $\succeq$ if it is complete, transitive, continuous, and strictly monotonic, it is suggested to consider a mapping</p>

<p>$u: \mathbb{R_+^n} \to \mathbb{R}$  such that $u(\mathbf{x})e\sim \mathbf{x}$ is satisfied, where $\mathbf{x}$ is a bundle, $u(\mathbf{x})$ is some number and $\mathbf{e}$ is a bundle which contains one of every good.</p>

<p>So <strong>first</strong> we need to show that there always exists such number $u(\mathbf{x})$. 
To do this consider two sets:</p>

<p>$A \equiv \{t \geq 0 \mid t\mathbf{e} \succeq \mathbf{x}\}$</p>

<p>$B \equiv \{t \geq 0 \mid t\mathbf{e} \preceq \mathbf{x}\}$</p>

<p>if $t^* \in  A \cap B$, then $t^*\mathbf{e} \sim \mathbf{x}$, so we need to show that $A \cap B$ is nonempty.</p>

<p>The continuity of $\succeq$ implies that both A and B are closed in $\mathbb{R_+}$. By strict monotonicity, $t \in A$ implies $t' \in A,$ $\forall$  $ t'\geq t$. So $A=[\underline{t}, \infty)$. 
Similarly $B=[0, \overline{t}]$</p>

<p>For any $t \geq 0$, completeness of $\succeq$ implies that either $t\mathbf{e} \succeq \mathbf{x}$ or $t\mathbf{e} \preceq \mathbf{x}$, 
i.e., $t \in A \cup B$</p>

<p>$\mathbb{R_+} = A \cup B = [0, \overline{t}] \cup [\underline{t}, \infty)$.</p>

<p>So in order to $A \cap B$ be nonempty it should be that $\underline{t} \leq \overline{t}$.</p>

<p>But is it always like this? I can't see why the last inequality should hold always.</p>
","<p>Το take this one out of the Unanswered queue:</p>

<p>The completeness property of the preference relation, implies that <strong>for all non-negativ</strong>e $t$ we will be able to form and declare the preference relation. Hence</p>

<p>$$A \cup B = \mathbb{R_+}$$</p>

<p>By monotonicity we have $B=[0, \overline{t}],\;\; A=[\underline{t}, \infty)$.</p>

<p>Ad absurdum, assume that $\overline{t} &lt; \underline{t}$. Then there exists an open interval $(\overline{t},\underline{t})$ that does not belong to the union of $A$ and $B$. But then we arrive at $A \cup B \neq \mathbb{R_+}$ which contradicts the implications of the completeness property. </p>

<p>So we conclude that $\overline{t} \geq \underline{t}$, which implies that the intersection $A \cap B$ is non-empty (even if it may contain a single element, when $\overline{t} = \underline{t}$).</p>
","17198"
"How often do banks borrow from the Federal Reserve?","527","","<p>Though I've seen plenty of articles talk about in what circumstances banks borrow from the Fed, I haven't seen any quantification on that note. On average, what percent of the money that banks lend out is money from the Fed? Alternatively, how much money is borrowed from the Fed every year and how quickly is that money generally paid back? </p>
","<p>When banks borrow from the Federal Reserve they can do so through the discount windows:</p>

<blockquote>
  <p>The discount window helps to relieve liquidity strains for individual
  depository institutions and for the banking system as a whole by
  providing a reliable backup source of funding. Much of the statutory
  framework that governs lending to depository institutions is contained
  in section 10B of the Federal Reserve Act. The general policies that
  govern discount window lending are set forth in the Federal Reserve's
  Regulation A. As described in more detail below, depository
  institutions have access to three types of discount window
  credit--primary credit, secondary credit, and seasonal credit. All
  discount window loans must be collateralized to the satisfaction of
  the lending Reserve Bank.
  <a href=""https://www.federalreserve.gov/newsevents/reform_discount_window.htm"" rel=""nofollow noreferrer"">Discount Window Lending</a></p>
</blockquote>

<p>The FRB has published discount window lending activity since 2010. Though this data is published with a two year lag, it may be of use. You can download that data at from their website at the link above. </p>

<p>There is price discrimination at the window:</p>

<blockquote>
  <p>In the United States, there are actually several different rates
  charged to institutions borrowing at the Discount Window. In 2006,
  these were: the primary credit rate (the most common), the secondary
  credit rate (for banks that are less financially sound), and the
  seasonal credit rate. The Federal Reserve does not publish information
  regarding institutions' eligibility for primary or secondary credit
  Wikipedia: <a href=""https://en.wikipedia.org/wiki/Discount_window"" rel=""nofollow noreferrer"">Discount window</a> </p>
</blockquote>

<p>It is somewhat rare to use the window. There are about 8,000 banks in the United States and about four to five hundred banks use the window in a typical quarter (according to that data). 
<a href=""https://i.stack.imgur.com/bIzdD.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bIzdD.jpg"" alt=""Number of Banks falling steadily as bank assets rise""></a></p>

<p>The amounts borrowed are very small. The largest amount borrowed was about 47 million in the latest report. It was borrowed by First National Bank and Trust of Rochelle, a bank with <a href=""https://www.bestcashcow.com/banks/the-first-national-bank-trust-company-of-rochelle-14583"" rel=""nofollow noreferrer"">270 million in assets</a>, so those window loans amount to 18 percent of assets. </p>

<p>But that is not representative of most banks. The second heaviest borrowing bank on the list is Xenith Bank which borrowed less than two percent of assets. More generally, <a href=""http://libertystreeteconomics.newyorkfed.org/2014/01/why-do-banks-feel-discount-window-stigma.html"" rel=""nofollow noreferrer"">there is stigma for discount window lending</a>. The overall stigma is that since only those frozen out of capital markets use the window, users of the window must be in serious trouble. As shown above, 90 percent or more of banks don't use it in a given quarter. </p>
","11711"
"Demand curve from logit model","526","","<p>Is it possible to derive a demand curve from a discrete choice multinomial model. For instance, a logit model would give the probability of purchasing each good. But can I translate that into a demand curve.            </p>
","<p>We cannot obtain ""demand"" in the usual sense, because demand is a random variable. The ""best"" we can do is first, to obtain the Conditional Expectation of individual demand (conditional on the variables that determine the probability of whether the consumer will demand/buy).<br>
Let a situation where consumers decide to buy or not to buy a single (for simplicity) item of a good $A$. We can model this underlying utility framework by</p>

<p>$$u_i(A) = \alpha p_i+\mathbf x_i'\beta +e_i$$</p>

<p>with $i$ denoting the consumer, $p_i$ is the good's price, <em>faced by consumer $i$</em>, $\mathbf x_i$ containing various other variables pertinent to the case, and $e_i$ representing a ""random"" preference shock, assumed, say, to follow the standard logistic distribution, conditional on the $x$'s.
The consumer will demand/buy, $q^d_i=1$, if (by convention) $u_i(A)&gt;0$, so we can model the conditional probability of buying by </p>

<p>$$E(q_i^d =1\mid p, \mathbf x_i) = \Lambda(\alpha p_i+\mathbf x_i'\beta)$$</p>

<p>Then the conditional expectation of Market demand is </p>

<p>$$Q_d = \sum_{i=1}^nq^d_i = \sum_{i=1}^n\Lambda(\alpha p_i+\mathbf x_i'\beta)$$</p>

<p>This is still a random variable, and with unknown parameters. To obtain something one dimensional, given a sample of size $n$ on $\mathbf x_i$ and on relevant transactions (and so on $p_i$), one can estimate $\hat \alpha, \; \hat \beta $, say by maximum likelihood. Then we can obtain some concept of ""average market demand curve"" by using the sample means of the $x$'s as</p>

<p>$$\hat Q_d(p\,; \mathbf {\bar x}) = \sum_{i=1}^n\Lambda(\hat \alpha p+ \mathbf {\bar x'}\hat \beta) = n\cdot \Lambda(\hat \alpha p+ \mathbf {\bar x'}\hat \beta)$$</p>

<p>where here the price $p$ is not indexed anymore, and we vary it to obtain a curve.  </p>

<p>As a toy numerical example, assume there are $100$ consumers, that ${\bar x'}\hat \beta =1$, and  $\hat \alpha = -2$. Then $\hat Q_d(p\,; \mathbf {\bar x_i})$ will look like</p>

<p><a href=""https://i.stack.imgur.com/qI6rz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qI6rz.png"" alt=""enter image description here""></a></p>

<p><strong>MULTINOMIAL LOGIT</strong> </p>

<p>In a multinomial logit where we examine the choice to buy ""this <em>or</em> this <em>or</em> this"" (mutually exclusive choices $k=1,..,K$), we end up with (after the usual normalization)</p>

<p>$$\hat E(q^d_{ik} \mid p_{ik}, \mathbf x_{ik}) = \frac {\exp\{\hat \alpha p_{ik} + \mathbf x'_{ik}\hat \beta\}}{1+\sum_{k=2}^K\exp\{\hat \alpha p_{ik} + \mathbf x'_{ik}\hat \beta\}}$$</p>

<p>Then we can obtain $K$ demands (each conditional on the rest) using (say, for good $1$)</p>

<p>$$\hat Q^{(1)}_d(p_1) = \frac {n\cdot \exp\{\hat \alpha p_1 + \mathbf {\bar x}_{1}'\hat \beta\}}{1 + \sum_{k=2}^{K}\exp\{\hat \alpha \bar p_{k} + \mathbf {\bar x}_k'\hat \beta\}} $$</p>

<p>Note that here we have to average the prices of the other goods also.</p>
","8212"
"Are There Giffen Inputs?","525","","<p>I am studying for my candidacy exams and I came across this question on a previous exam. The question is in the TFD (True, False, Debatable) section of the exam. The claim is:</p>

<blockquote>
  <p><strong>There are no Giffen inputs in production.</strong></p>
</blockquote>

<p>I think this question is a very fascinating one, and should spark some interesting discussion. My intuition tells me that this is false because if there are Giffen goods on the consumer side then surely there are Giffen goods on the producer side. However, I cannot think of a concrete counterexample to the claim. In consumer theory, they claim that Giffen goods occur when the good is so important to the consumer that when the price increases, they decide to just buy that good and not buy any other goods. For example, economists believe that one of the only real life Giffen good situations is potatoes in the Irish potato famine. They claimed that potatoes were such a staple in the Irish diet that when the prices rose, the Irish people decided not to buy other foods (such as meat) and dedicated all of their food budget to potatoes. </p>

<p>Are there any situations where we might see a firm/industry act in a similar way? What do you guys think? Are there any Giffen inputs in production?</p>
","<p>I believe the answer is <strong>true</strong>.</p>

<p>Giffen goods are goods where the income effect overpowers the substitution effect.</p>

<p>$$\begin{align}
\max_{\vec x} \ \ \ &amp; U(\vec x) \\
&amp; \text{s.t.} \ \ \ \vec p \cdot \vec x \leq I
\end{align}$$</p>

<p>To start, if you think about the consumer's problem (for example utility maximization, here), a change in a good's price affects both relative substitutability of goods through the marginal rate of substitution AND it affects purchasing power through the budget constraint.</p>

<hr>

<p>Let us consider a profit maximizing firm with a constraint on how much they can spend. For simplicity let us use a single output technology, with differentiable production function $f(\vec z)$. Let $\vec z$ be a vector of inputs (expressed as negative values), $\vec w$ a vector of input prices, and $p$ the output price.</p>

<p>$$\begin{align}
\max_{\vec z} \ \ \ &amp; pf(\vec z) + \vec w \cdot \vec z \\
\text{s.t.} &amp; \ \ \ \vec w \cdot \vec z \leq B \\
&amp; \ \ \  z_i \leq 0 \\
\end{align}$$</p>

<p>Normally we would have a constraint on production, but instead we have a ""budget"" constraint. What happens if we form the Lagrangian here?</p>

<p>$$\mathcal{L} = pf(\vec z) - \vec w \cdot \vec z - \lambda(\vec w \cdot \vec z - B) + \vec\mu \cdot \vec z$$</p>

<p>Take first order conditions:</p>

<p>$$\frac{\partial \mathcal{L}}{\partial z_i} = pf_{z_i}(\vec z) - w_i - \lambda w_i + \mu_i = 0 \tag{1}$$</p>

<p>$$\frac{\partial \mathcal{L}}{\partial f(\vec z)} = p = 0 \tag{2}$$</p>

<p>$$\frac{\partial \mathcal{L}}{\partial \lambda} = \vec w \cdot \vec z - B = 0 \tag{3}$$</p>

<p>At an interior solution where the budget constraint binds, we should have the optimum $\vec z^*$ to solve the FOCs</p>

<p>$$p \frac{\partial f(\vec z^*)}{\partial z_i} = w_i$$</p>

<p>but instead you solve out (1):</p>

<p>$$p \frac{\partial f(\vec z^*)}{\partial z_i} = - \frac{\mu_i}{1 + \lambda}w_i$$</p>

<p>and (3) does not provide any help to solve the Lagrangian multipliers. (2) is nonsense.</p>

<p>A better constraint would be something like $y - f(\vec z) \leq 0$, where $y$ represents the scalar of output.</p>

<p>Without an ""income effect"", there isn't much to study Giffen behavior. Producer theory doesn't use a budget constraint to solve these sorts of problems. Increasing input price will always decrease use of that input except with corner solutions, where there might be no change. <strong>So there can't be a Giffen input.</strong></p>
","12254"
"Does a monotonic transformation of a homothetic utility function imply the preference relation on the set of consumption bundles is still homothetic?","525","","<p>Does a monotonic transformation of a homothetic utility function imply the preference relation on the set of consumption bundles is still homothetic?   </p>

<p>Obviously, if a utility function on a set of  consumption bundles is homothetic, then the preference relation is homothetic. </p>
","<p>Yes.
We know that a monotonic transformation of a utility function still represents the same preferences and as the old utility function represented homothetic preferences the new one does, too.</p>

<p>As an easy example you could look at Cobb-Douglas utility functions of the form $u(x,y) = a\left(x y\right)^\alpha$. For $\alpha = \frac12$ the utility function is homogeneous of degree 1, but for every $\alpha,a&gt;0,$ the preference relation is homogeneous of degree 1.</p>

<p>We never used homothetic as a property of the utility function to answer your question (as it works for every utility function).
A homothetic utility function is, to the best of my knowledge, not very clearly defined, I have see two different versions:</p>

<ol>
<li>Homothetic as different name for homogeneous of degree 1</li>
<li>A homothetic utility function is a utility function that represents
a homothetic preference relation.</li>
</ol>

<p>Which means, with definition 2 Cobb-Douglas utility functions with equal weights are always homothetic, with definition 2 only some of them are:
$$u(tx,ty) = (tx)^\frac12 (ty)^\frac12 = t xy = t u(x,y)$$
and some are not
$$u(tx,ty) = (tx) (ty) = t^2 xy \neq t u(x,y)$$</p>
","4954"
"Production function and isoquant slope","518","","<p>Given the company's production function $f(L,K)=L^{1/3}K^{3/4}$, find slope of the isoquant passing through $(L,K)=(20,40)$ is equal to $-4/5$ (K is on the vertical axis). </p>

<p>I need to state whether the statement above is true or false. In my opinion that is true because i need to calculate $MRTS_{LK}$ which is obviously equal to $-4/5$, but the answer in my textbook is: $-8/9$. Thus my question is am i doing something wrong or just the answer in my textbook is wrong?</p>
","<p>The book is right. The proper way to go about this is of course to work out the theory and the math before plugging in any specific numbers. Fixing the quantity produced, we have 
$$ \bar Q = L^bK^a \implies K = (\bar Q)^{1/a}L^{-b/a}$$</p>

<p>Then, since capital is on the vertical axis</p>

<p>$$\frac {dK}{dL} = -\frac{b}{a}(\bar Q)^{1/a}L^{(-b/a)-1} $$</p>

<p>Note that we do <em>not</em> differentiate $\bar Q$ since we <em>want</em> it to be fixed, for different combinations of inputs.</p>

<p>Inserting the production function expression</p>

<p>$$\frac {dK}{dL}= -\frac{b}{a}[L^bK^a]^{1/a}L^{(-b/a)-1}$$</p>

<p>$$\implies \frac {dK}{dL}= -\frac{b}{a}\frac{K}{L}$$ </p>

<p>Then, plug in the specific numbers: $b=1/3, a=3/4, K = 40, L = 20$ so</p>

<p>$$\frac {dK}{dL} = -\frac{1/3}{3/4}\frac{40}{20} = -\frac{4}{9}\cdot 2 = -\frac{8}{9}$$</p>
","6957"
"Financial Economics Textbooks","516","","<p>I have an interest in financial economics, and I plan to take the graduate sequence, however I did not take an undergraduate course in that field. I would really appreciate it if someone could recommend a textbook for financial economics. I would prefer the book involved calculus, so I can get the fundamentals of problems (such as asset pricing) I may see in the future.</p>

<p>Two books which have been recommended to me are: ""The Economics of Financial Markets"" by Roy E. Bailey and ""Principles of Financial Economics"" by LeRoy and Werner. Are either of these worth reading?</p>
","<p>The recommended books are decent. From these two I'd go with Bailey first and if you're comfortable with that, then LeRoy &amp; Werner. The latter requires some background in linear algebra and optimization theory.</p>

<p>If you want to study some econometric applications for financial economics, you might try:</p>

<ul>
<li>Cuthbertson &amp; Nitzsche: Quantitative Financial Economics: Stocks, Bonds and Foreign Exchange </li>
<li>Campbell, Lo &amp; MacKinlay: The Econometrics of Financial Markets</li>
</ul>
","11208"
"If the Engel Curve of a Cobb-Douglas utility function is positive and linear, than does that mean it is neither a necessity nor a luxury good?","514","","<p>Since the concavity of the Engel Curve determines whether it is a necessity or luxury (i.e. how fast quantity demand changes in relation to changes in income), and since the second derivative of a Cobb-Douglas Engel Curve is 0, does that mean it is neither category?</p>

<p>Edit:  In simple terms, if an Engel Curve is a straight positively-sloped line, it is obviously a normal good.  But if the curve is represented by a function like so:</p>

<p>$I = 10 * P_x * x.$</p>

<p>Then the curve is ambiguously sloped.  If the price of $x$ ($P_x$) happens to be greater than 1/10 then the good is a luxury, and vice versa for a good with $P_x &lt; 1/10$.  But if it's ambiguous like this, then the second derivative (which indicates concavity and therefore what direction the curve is increasing/decreasing in) then is it impossible to tell?</p>

<p>For reference, this Engel Curve was derived from the Cobb-Douglas utility function:</p>

<p>$U(x,y) = x^{(1/10)}y^{(9/10)}.$</p>
","<p>Recall the following equivalent definitions for luxury goods and necessities: </p>

<ul>
<li>A good $x$ is considered a necessity if $e_{(x,I)}&lt;1$.</li>
<li><p>A good $x$ is considered a luxury good if $e_{(x,I)}&gt;1$. </p>

<p>As you can see, these definition do not encompass all possible scenarios, so any specific good does not have to be either a luxury or a necessity. </p></li>
</ul>

<p>In the case of a Cobb-Douglas utility function $U(x,y)=x^\alpha \cdot y^\beta$ we get $x^* = \frac {\alpha I}{P_x}$. One can easily verify that $e_{(x,I)}=1$. In other words, the demand does for $x$ does not change with $I$. This means that in this case, $x$ is neither a luxury good nor a necessity.</p>
","12200"
"More direct way to derive indirect utility function from expenditure function","514","","<p>I have this general form for a expenditure function $e(p,u)=f(u)\cdot g(p)$ where $f(u)$ is increasing monotonic. How can I derive a functional form for an indirect utility function from this expenditure function?</p>
","<p>Make e (p, V (p, r))=r, hence f (V (p, r)) g (p)=r. Then use the inverse function theorem:
V (p, r)=h (r/g (p))
Where h is the inverse of f.</p>
","13621"
"Steady state Solow model with exogenous technological change","514","","<p>Consider the following question:</p>

<p><a href=""https://i.stack.imgur.com/folLf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/folLf.png"" alt=""enter image description here""></a></p>

<p>So, assume the standard function for production:</p>

<p>$$Y_t = A_t K^\alpha_tL^{1-\alpha}$$</p>

<p>where $L$ is fixed.</p>

<p>Then, the growth rate of output is: </p>

<p>$$g_Y \approx g_A + \alpha g_K $$</p>

<p><strong>Case without technological change</strong></p>

<p>In the standard Solow model with constant $A$, $g_A=0$. In the steady state, $sY=dK$ (investment equal depreciation), and $g_Y = g_K = 0$, consistent with the above equation.</p>

<p><strong>Case with exogenous technological change</strong></p>

<p>Here, $g_A=2\%$ (as per the question). But then, there is clearly no steady state, as the marginal product of capital is permanently increasing, thereby expanding capital. In the standard diagram, this means a shift of the function $sY_t$ upwards every period, meaning an ever increasing ""steady state"", which is never achieved. <strong>Hence, to me the question does not make sense.</strong></p>

<p>Finally, here is the official answer:</p>

<p><a href=""https://i.stack.imgur.com/z3U0q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/z3U0q.png"" alt=""enter image description here""></a> </p>

<p>Now, to me this answer is wrong. How can $Y$, $A$, and $K$ growth at the same rate? The equation of growth written above denies this! </p>

<p><strong>Is the question and/or answer wrong? Am I missing something? Am I wrong?</strong></p>
","<p>To simplistically answer your question, use the following:
$Y = K^\alpha (AL)^{1 - \alpha}$</p>

<p><strong><em>In order to prove all three can be equal:</em></strong>
We will assume that technological progress is labor augmenting (Harrod Neutral) or ""labor saving"", while holding the following true:</p>

<ul>
<li>Returns to capital are roughly constant over time.</li>
<li>Capital share of income is roughly constant over time.</li>
</ul>

<p>The Harrod Neutral is associated with a capital-output ratio that is constant (K/Y) in our ""steady state"".</p>

<p><em>Capital Accumulation</em>
In the basic Solow model, (1).
$$ \frac{\dot{k}}{k} \equiv s\frac{y}{k}-(d+n)$$</p>

<p>For growth rate per capita capital to be constant, y/k = Y/K must also be constant. (Characteristic of the Harrod Neutral)</p>

<p><em>We Need To Define The Balanced Growth Path With Technological Progress</em>
Taking the original production equation:
$Y = K^\alpha (AL)^{1 - \alpha}$</p>

<p>and dividing by AL (number of effective labor units) we are given our production function representing effective labor.
$$ \tilde{y} \equiv \tilde{k}^\alpha$$</p>

<p><em>Doing The Same For Capital Accumulation</em>
Follow steps below:
$$\frac{\tilde{\dot{k}}}{k} = \frac{dln(k/AL)}{dt}$$</p>

<p>$$ \frac{dlnK}{dt} - \frac{dlnA}{dt} - \frac{dlnL}{dt} $$</p>

<p>$$\frac{\dot{K}}{K} - \frac{\dot{A}}{A} - \frac{\dot{L}}{L} = \frac{\dot{K}}{K} - g - n$$</p>

<p>then using this to finding our Capital Accumulation equation below:</p>

<p>$$\frac{\dot{K}}{K} = S \frac{{Y}}{K} - d$$
$$\frac{\tilde{\dot{k}}}{\tilde{k}} = s\frac{Y}{K} - d - g - n$$
And, $$\frac{Y}{K} = \frac{Y}{AL} \frac{AL}{K} = \frac{\tilde{y}}{\tilde{k}}$$</p>

<p>Then, 
$$\frac{\tilde{\dot{k}}}{\tilde{k}} = s\frac{\tilde{y}}{\tilde{k}} - d - g - n$$</p>

<p>$$\tilde{\dot{k}} = s \tilde{y} - (d+g+n)\tilde{k}$$</p>

<p>Finally, combining our production function with capital accumulation we get an equation (6) that represents the Solow model with tech changes.
$$\tilde{\dot{k}} = s \tilde{k^\alpha} - (d+g+n)\tilde{k}$$</p>

<p>So our steady state is when (7) is true.
$$\tilde{\dot{k}^*} = 0$$</p>

<p>If we set this to be true for our steady state (denoted by *) levels of capital and output per effective labor. (8 and 9)
8: $$\tilde{k^*} = [\frac{s}{d+n+g}]^\frac{1}{1-\alpha}$$
9: $$\tilde{y^*} = [\frac{s}{d+n+g}]^\frac{\alpha}{1-\alpha}$$</p>

<p>In the steady state: (10)
Capital (and income) per capita grow at the rate of exogenous technological growth.</p>

<p>$$\tilde{k} = K/AL$$
$$k = K/L$$ 
$$k = A\tilde{k}$$</p>

<p>$$\tilde{k} = \tilde{k}^* = [\frac{s}{d+n+g}]^\frac{1}{1-\alpha}$$
$$k(t) = A(t)\tilde{k}^*$$
$$lnk(t) = lnA(t) + ln\tilde{k}^*$$
$$\frac{\dot{k}}{k} = \frac{\dot{A}}{A}$$</p>

<p>If you graph out
$$\tilde{\dot{k}} = s \tilde{k^\alpha} - (d+g+n)\tilde{k}$$</p>

<ul>
<li>Any savings rate changes, s, change the savings curve and therefore change $$\tilde{k^*}$$</li>
<li>Population or depreciation changes, n and d respectively, rotates the straight line, (d+g+n)k.
<strong><em>Changes in these affect the growth rate of per capita capital and per capita income only outside the steady-state.</em></strong></li>
<li>exo-tech growth changes the graph sort of like n and d by changing the level of $$\tilde{k^*}$$</li>
</ul>

<p>This exo-tech growth changes the growth rate of per capita capital and per capita income in the steady state (along balanced growth paths).</p>
","15349"
"Does control system engineering have a place in economics?","512","","<p>Do central banks use some form of engineering-style PID control systems/feedback loops to implement monetary policy? </p>

<p>I'm an electrical engineering student taking microeconomics/macroeconomics and a lot of it, at least in terms of government policy to control inflation and interest rates, seems applicable to control systems engineering. However, I can't find a great deal of hard literature about it. </p>

<p>Just as a for instance, one could use PID control to set an output, say inflation rate, to follow a specific course or remain steady given certain inputs, say GDP or interest rates or productivity, and given external disturbances, say Brexit. And even if the controller can't prevent catastrophes altogether, it can dampen the response so that sudden and jerky crashes are smoothed out.</p>

<p>Why or why not does economic policy use established control theory? If it does, what applications can this be seen?</p>

<p>Thanks in advance!</p>
","<p>Economists have been exploring control theory applications to macro economics for decades. For example, <a href=""http://www.nber.org/chapters/c10438.pdf"" rel=""noreferrer"">here is a 40 year-old research paper written in 1976 on the topic</a>.</p>

top of page 2 (also numbered 171)

<blockquote>
  <p>In the past decade, a number of engineers and economists have asked the question: ""If modern control theory can improve the guidance of airplanes and spacecraft, can it also help in the control of inflation and unemployment?""</p>
</blockquote>

<p>Non-linear adaptive human behavior, uncertainty and governmental decentralization of control (i.e., democracy) are the main reasons I believe control theory has not become a more common tool for policy makers. Economics is simply not an exact science. Whereas engineering is more so. So control theory is more useful in the engineering discipline.</p>
","12713"
"Central Bank liabilities and assets - Money and Bonds","511","","<p>I'm reading a book on macroeconomics, and on a chapter on the money market, when explaining how the central banks(CB) determine the interest rate, there is a balance sheet for the CB. In it, under the assets we have bonds, and under liabilities we have currency and bank reserves. My question is which bonds are these? Do these bonds belong to the same country that the CB belongs to? Isn't in this case the bond of the CB a liability/debt that will have to be repaid in the future? Because if so, it seems that we're just exchanging one liability (bond) for another (money).</p>

<p>Or are these bonds from any entities other than the CB itself?</p>

<p>Any help would be appreciated.</p>
","<blockquote>
  <p>My question is which bonds are these? Do these bonds belong to the same country that the CB belongs to?</p>
</blockquote>

<p>This will vary a lot from central bank to central bank. Most of the assets of the US Federal Reserve are indeed government securities, but the European Central Bank is prohibited from buying such securities (because of the crisis, it now buys limited amounts of them, but the legal grounds are shaky).</p>

<p>Since 2009, central bank balance sheets have changed quite a bit. In 2008 the Federal Reserve did not hold any mortgage backed securities. Now, they comprise about 40% of the Fed's total assets.</p>

<p>Take a look at the Fed's balance sheet in Table 1 of the <a href=""http://www.federalreserve.gov/monetarypolicy/files/quarterly_balance_sheet_developments_report_201508.pdf"" rel=""nofollow"">August 2015 report</a>.</p>

<blockquote>
  <p>Because if so, it seems that we're just exchanging one liability (bond) for another (money). Or are these bonds from any entities other than the CB itself?</p>
</blockquote>

<p>Yes, they are from other entities. For example, US Treasury bonds are about half of the Fed's balance sheet. These bonds are issued by the Department of the Treasury and must be pay back to the Fed on maturity, using money collected from taxes or the proceeds from new bond issues.</p>
","7016"
"How Does Keynesian Theory Address Supply Shocks, Like the California Drought?","511","","<p>From what I understand about Keynesian theory, when we're facing deflation, lowering interest rates or increasing government spending/lending (when consumers are cutting back) helps stimulate economic growth through consumption (GDP = C + I + <code>G</code> + NE).  While a few loud voices (Schiff, the ZH guy, Martin Armstrong, etc) have been screaming about hyperinflation, Krugman has been right that we haven't seen it, even with the Federal Reserve's QEs.  It does seem like QE has helped move the economy along, even though I know this depends on a person's point of view; ie: Austrian economists won't agree.</p>

<p>What happens in the case of a major drought causing food prices to rise, as in double, triple or quadruple (<a href=""http://www.calculatedriskblog.com/2015/01/year-4-it-never-rains-in-california.html"" rel=""nofollow"">See this post by Bill McBride.</a> and now <a href=""http://www.calculatedriskblog.com/2015/02/year-4-it-never-rains-in-california.html"" rel=""nofollow"">this post</a>)?  Is the Keynesian solution here to raise interest rates => wouldn't that be a double whammy on the poor in that it would be more difficult to get a job and food prices would be rising?  What is the Keynesian solution to supply shock problems, like a major drought, impacting basic necessities, such as food prices?</p>

<p>To be more specific because of the comment, I am looking for the Keynesian solution to a supply shock, or major crises that involve a supply shock - such as a drought that causes food prices to rise?</p>
","<p>In what follows, I'm going to be very hand wavy - take with a grain of salt.</p>

<p>If you think about it, a <strong>demand shock</strong> is like a scenario of multiple equilibria (given the fixed levels of wages and prices):</p>

<ul>
<li>If everyone is employed, everyone has a lot of income, can spend that on goods, and the demand for goods implies a large demand for labor, making everyone employed</li>
<li>If few people are employed, total spending is smaller, so is demand for goods and labor, corresponding to only fewer people employed</li>
</ul>

<p>The Keynesian solution can be thought of as <em>forcing the first case to happen rather than the second</em>.</p>

<p>If you really have a <strong>supply shock</strong>, that is, lack of a factor important to production, there is no indeterminacy here. There just isn't that much (oil) available, increasing its price. The RBC spokesperson of your favor would say</p>

<blockquote>
  <p>The high price stems from scarcity; both the high price, the low production and high unemployment are efficient.</p>
</blockquote>

<p>In the standard problem, rigidity of wages and prices create inefficiency, they can be dealt with. Here, there is no such inefficiency, and no inherent <em>solution</em> to a supply side shock. </p>
","3411"
"What are examples of inversely (negatively) correlated stock prices in economics?","509","","<p>I’m looking for example of two goods/wealth that demonstrate inverse/negative correlation. For example if price of <code>A</code> rises then price of <code>B</code> falls. May be it is oil or gold prices along with some other wealth. Or may be some share prices (stocks) of some two companies. I can’t find example of such negatively correlated prices data.</p>
","<p>U.S. equity market returns and U.S. Treasuries returns exhibit strong negative correlation (roughly -35%) over all time frequencies for sufficiently long time horizons.  We attribute this inverse correlation to the fact that Treasuries are ""safe-haven"" assets, while equities increase in price as risk premiums decline.</p>

<p>Your question mentions price data.  Your correlations will improve if you look at log-prices or returns.</p>

<p>There are many other examples of positive and negative correlations in finance, though many can prove ephemeral: utilities stocks and interest rates, long interest rates and life insurers, gold miners and gold prices, airlines and oil prices, and so on.</p>
","14446"
"In the US, do high wages in regions like New York and California offset the high cost of living?","508","","<p>It's well understood that the cost of living in New York City vastly exceeds the cost of living in, say, rural Louisiana.  It is also well understood that wages in New York City vastly exceed those in rural Louisiana.  My question is: who comes out ahead?</p>

<p>To clarify, let me offer a thought experiment (not sure if this is valid or not, I'm no economist).  Imagine we have two individuals: one in rural Louisiana with a low cost of living and low wage (""Lou"" for short), the other in New York City with a high cost of living and a high wage (""Nue"" for short).  Imagine that both Lou and Nue earn exactly the median household income for their respective region.  They live in virtually identical homes (paying the local rent).  They drive virtually identical cars.  They have the same number of children.  They have the same healthcare plan, and so on.  Now imagine that each day Lou and Nue both go to the mall, and buy the exact same items as one another (paying the local price).  Let's imagine they are spending very quickly, far more quickly than either can afford.  Who runs out of money first, Lou or Nue?</p>

<p>A follow up question: is there a single number which tracks this quality I'm trying to describe?  It seems like median income divided by local CPI would just about do it, but that's purely based on my own untrained intuition.</p>
","<p><strong>TL;DR</strong> Wages offset the high cost of living in most states.  In NY and CA specifically, wages are insufficient to offset the high cost of living.  In New York City specifically, wages do not even come close to offsetting the high cost of living.</p>

<p>Having now researched this a bit, I can give a very concrete answer to the Lou/Nue hypothetical, and I think a pretty decent answer to the general idea.  Let me just say up front, <em>I am not</em> an economist, I'm taking a best guess based on the data published by real economists.  These are layman's conclusions, and, as BKay pointed out, can't possibly capture the complexity of the real world.  That said...</p>

<p>Nue runs out of money first.  Here's why:</p>

<p><a href=""http://www.bea.gov/scb/pdf/2011/05%20May/0511_price_parities.pdf"" rel=""nofollow noreferrer"">The regional price parity (RPP) in NYC is 136</a>.  That means, a purchase which costs \$100 for an average American will cost \$136 for an average resident of NYC.  <a href=""http://project.wnyc.org/median-income-nabes/"" rel=""nofollow noreferrer"">The median income in NYC is \$50,711</a>.  This is 97% the national median income.  This means that a days work which pays \$100 for an average American pays \$97 dollars for an average resident of NYC.</p>

<p>The regional price parity in Louisiana is 91.  A purchase which costs \$100 for an average American will cost \$91 for an average resident of Louisiana.  The median income in Louisiana is \$40,462.  This is 77% the national average.  This means that a days work which pays \$100 for an average American pays \$77 dollars for an average resident of Louisiana.</p>

<p>In addition to Lou and Nue, also let us consider Medie.  Medie earns exactly the national median income, and her cost of living is exactly the national average, i.e. RPP = RWP = 100.  (Sidebar: to the extent that such a person exists, they probably live in Pennsylvania, which comes the closest to conforming to both wage and price averages).  So let's compare a hypothetical wage and price for Medie, Lou, and Nue:</p>

<p>Medie earns \$100 per day<br>
Apples cost \$1 each in Medie's home town<br>
Medie can buy <strong>100 apples per day</strong></p>

<p>Lou earns \$77.81 per day<br>
Apples cost \$0.91 each in Lou's home town<br>
Lou can buy <strong>85 apples per day</strong></p>

<p>Nue earns \$97.63 per day<br>
Apples cost \$1.36 in Nue's home town<br>
Nue can buy <strong>71 apples per day</strong></p>

<p>Note, this effect only holds for New York City proper.  If you compare New York State with Louisiana, they are dead even.</p>

<p>To answer the question more generally, all other things being equal it pays to be in a <strong>high wage, high cost of living</strong> state, though there is major regional variation.  To try and answer this more fully, let's look at the data BKay supplied above, and expand the hypothetical from the original question.  Regional Price Parity data is fairly easy to come by (i.e., ""for every dollar spent by an average american, how many dollars must a person from region X spend to get the same result?"").  Regional Median Wage data is also pretty easy to come by.  From the Regional Median Wage we can trivially calculate Regional Wage Parity (i.e. ""for every dollar <em>earned</em> by an average American, how many dollars can a person in region X expect to earn?"").  This is a term I'm making up, so I know it's not exactly scientific, but I think it give a good gestalt for the situation.  This gives us:</p>

<p>$$
\frac{Regional Wage Parity}{Regional Price Parity} = HowMuchStuffYouCanBuy
$$</p>

<p>""How much stuff you can buy"" is really the figure that this question is trying to get at.</p>

<p>The state with the highest ""apples per day"" value is New Hampshire (126) followed by Virginia (123).  As I said, New York and Louisiana do the worst.  DC and Georgia conform exactly to the national average.  Here are these value's graphed:</p>

<p><img src=""https://i.stack.imgur.com/Y6TWk.png"" alt=""How many apples can you buy""></p>

<p>Note, while local wages seem to predict well for this ""how many apples"" measure, prices <em>do not</em> seem to predict at all.  Goes to show, cheap != affordable.</p>

<p><img src=""https://i.stack.imgur.com/DNo41.png"" alt=""prices""></p>

<p>Here's the raw data I used for this if you want to play around with it:</p>

<pre><code>+----------------------+-----------------------+----------------------+------------------+
|        State         | Regional Price Parity | Regional Wage Parity | How Many Apples? |
+----------------------+-----------------------+----------------------+------------------+
| Louisiana            | 91.40%                | 77.81%               |               85 |
| New York             | 115.40%               | 99.14%               |               86 |
| New Mexico           | 94.80%                | 83.12%               |               88 |
| Mississippi          | 86.40%                | 77.30%               |               89 |
| Arkansas             | 87.60%                | 78.39%               |               89 |
| Montana              | 94.20%                | 84.35%               |               90 |
| Kentucky             | 88.80%                | 80.21%               |               90 |
| North Carolina       | 91.60%                | 83.45%               |               91 |
| Florida              | 98.80%                | 90.60%               |               92 |
| Tennessee            | 90.70%                | 83.27%               |               92 |
| South Carolina       | 90.70%                | 83.53%               |               92 |
| West Virginia        | 88.60%                | 81.89%               |               92 |
| Nevada               | 98.20%                | 91.10%               |               93 |
| Alabama              | 88.10%                | 83.07%               |               94 |
| California           | 112.90%               | 109.39%              |               97 |
| Arizona              | 98.10%                | 95.31%               |               97 |
| Hawaii               | 117.20%               | 115.16%              |               98 |
| Maine                | 98.30%                | 97.09%               |               99 |
| Ohio                 | 89.20%                | 88.24%               |               99 |
| Delaware             | 102.30%               | 101.61%              |               99 |
| District of Columbia | 118.20%               | 118.01%              |              100 |
| Georgia              | 92.00%                | 92.23%               |              100 |
| Indiana              | 91.10%                | 91.93%               |              101 |
| Michigan             | 94.40%                | 96.26%               |              102 |
| Oklahoma             | 89.90%                | 91.71%               |              102 |
| Idaho                | 93.60%                | 95.86%               |              102 |
| Pennsylvania         | 98.70%                | 101.48%              |              103 |
| Illinois             | 100.60%               | 103.93%              |              103 |
| Texas                | 96.50%                | 100.33%              |              104 |
| Vermont              | 100.90%               | 105.73%              |              105 |
| Oregon               | 98.80%                | 103.97%              |              105 |
| Kansas               | 89.90%                | 96.16%               |              107 |
| Rhode Island         | 98.70%                | 106.07%              |              107 |
| Missouri             | 88.10%                | 95.00%               |              108 |
| New Jersey           | 114.10%               | 124.36%              |              109 |
| Alaska               | 107.10%               | 118.71%              |              111 |
| South Dakota         | 88.20%                | 98.39%               |              112 |
| Wisconsin            | 92.90%                | 104.50%              |              112 |
| Washington           | 103.20%               | 116.72%              |              113 |
| Wyoming              | 96.40%                | 109.30%              |              113 |
| Colorado             | 101.60%               | 116.78%              |              115 |
| Iowa                 | 89.50%                | 103.26%              |              115 |
| Massachusetts        | 107.20%               | 123.79%              |              115 |
| Nebraska             | 90.10%                | 105.34%              |              117 |
| Connecticut          | 109.40%               | 128.66%              |              118 |
| Utah                 | 96.80%                | 115.15%              |              119 |
| North Dakota         | 90.40%                | 107.59%              |              119 |
| Minnesota            | 97.50%                | 117.62%              |              121 |
| Maryland             | 111.30%               | 134.28%              |              121 |
| Virginia             | 103.20%               | 126.95%              |              123 |
| New Hampshire        | 106.20%               | 133.56%              |              126 |
+----------------------+-----------------------+----------------------+------------------+
</code></pre>

<p>Sources:<br>
<a href=""http://www.census.gov/hhes/www/income/data/statemedian/"" rel=""nofollow noreferrer"">Wage data</a> (Direct <a href=""http://www.census.gov/hhes/www/income/data/incpovhlth/2013/stateonline_13.xls"" rel=""nofollow noreferrer"">XLS Download</a>)<br>
<a href=""http://www.bea.gov/scb/pdf/2014/06%20June/0614_real_personal_income_and%20_regional_price_parities_for_states_and%20metrpolitan_areas.pdf"" rel=""nofollow noreferrer"">Price Data</a> (PDF)</p>
","4599"
"Is stock investment an example of demand curves that slope upwards?","508","","<p>The law of demand implies that when the price of a good rises, people buy less of it. This makes the demand curve slope monotonically downwards. A textbook exception is the so-called <a href=""http://en.wikipedia.org/wiki/Giffen_good"" rel=""nofollow"">Giffen good</a> that by definition behaves in the opposite way.</p>

<p>But take a stock on the rise; might there not at least be one tendency for people to buy more of it under some circumstances, because it looks promising, in spite of any opposite tendencies? Is or isn't this another case where a demand curve may slope upwards?</p>
","<p>The observation that ""as stock prices rise people tend to buy more of it, so here the ""law of demand"" holds in reverse"", is one of the more widespread misconceptions related to economic thinking.  </p>

<p>To expand on @StevenLandsburg comment, the ""demand curve"" (or ""schedule"") describes a static relation between the <em>quantity</em> of a good and its <em>price</em>. Its <em>quality</em> (in the general sense of features, qualities) remains <em>constant</em>, as we trace the demand curve.</p>

<p>In our case we think of the stock as the good, and we have also its price. Now what happens when the price goes up? <em>Are we talking about the same good</em>? Definitely no. The price raise itself signals that <em>we now have a better good</em> (higher discounted future profits). But then we have a <em>different</em> good.
So the pairs $(p_1, q_1)$ and $(p_2, q_2)$ <em>do not really belong to the same demand schedule</em>. So the ""law of demand"" is irrelevant here as a tool to describe the situation (we could picture it as a <em>shift of the whole demand schedule outwards</em>)</p>

<p>If one wants to try to think ""intuitively"" about the law of demand and stocks, then one can consider the following thought experiment:<br>
<strong>Assume that you can buy the same stock on the same day at two different prices</strong> (it can happen, the world is not really one single market, even for stocks -and transactions can happen also outside of the stock market).<br>
Assume that you cannot choose the seller, which will be determined randomly. But you have to commit beforehand about the number of pieces that you will buy. And you know the two prices.  </p>

<p>What are you going to do?
<strong>Commit to buy <em>more</em> pieces if you are dealt the <em>expensive</em> seller, and <em>fewer</em> pieces if you are dealt the <em>cheaper</em> seller?</strong> Sounds ridiculously obvious, isn't it?</p>
","469"
"Solow Model, Growth rate of K/L and Y/L in steady state","505","","<p>I have been given the following setup:</p>

<p>$$ Y=K^\theta (AL)^{1-\theta }$$</p>

<p>Where Y = Output, K = Capital, L = Labour and A = Productivity.</p>

<p>$$ \frac{\dot{L}}{L} = n $$
$$ \frac{\dot{A}}{A} = g $$</p>

<p>The Capital Accumulation Equation has also been given as:</p>

<p>$$ \dot{K} = sY - \delta K $$</p>

<p>Using this, I have calculated expressions for capital per worker and output per worker in the steady state as:</p>

<p>$$ \frac{K}{L} = A(\frac{s}{n+g+\delta })^{\frac{1}{1-\theta }} $$</p>

<p>$$ \frac{Y}{L} = A(\frac{s}{n+g+\delta })^{\frac{\theta }{1-\theta }} $$</p>

<p>The next questions asks: <strong>Calculate the growth rates of capital per worker and output per worker that will hold as the economy moves along a steady state growth path.</strong></p>

<p>This is confusing because I was under the impression that growth of capital and labour is the steady state is 0, and then therefore growth of K/L and Y/L should also be 0. However this seems wrong and I believe the answer should be g. Can anyone help please?</p>
","<p>If $Y = C \cdot X$ where $C$ is constant and $\frac{\dot{X}}{X} = g$ then we can solve for $\frac{\dot{Y}}{Y}$ as follows:
$$ \frac{d}{dt} Y = \frac{d}{dt} C \cdot X = C \cdot \frac{dX}{dt} = C \cdot \dot{X} \Rightarrow$$
$$ \frac{\dot{Y}}{Y} = \frac{C \cdot \dot{X}}{ C \cdot X} = \frac{\dot{X}}{X} = g$$</p>

<p>Therefore, as you concluded, they both grow at rate $g$.</p>
","10183"
"Decreasing Costs, Increasing Returns to Scale, & C''(q)","504","","<p>Given a profit-maximizing firm with production function $f(x_1,x_2)$, I understand that we can formulate a firm's cost function $C(q)$ by using the contingent demand functions $x_1^c$ and $x_2^c$. We can then use this cost function to see whether a firm has decreasing costs, namely if $C(tq)&lt;tC(q)$. If the second derivative of the cost function, C''(q), is less than zero, does that also imply that this firm faces decreasing costs and thus increasing returns to scale? </p>
","<p>Second derivative of cost function is actually the first derivative of marginal cost function. i.e. 
$$
\frac{\partial^2C(q)}{\partial q^2} =\frac{\partial}{\partial q}\frac{\partial C(q)}{\partial q}=\frac{\partial}{\partial q}MC(q)
$$
Now if $\frac{\partial^2C(q)}{\partial q^2}&lt;0$, this means that marginal cost is decreasing in output. If marginal cost is decreasing then that implies that firm's average cost is decreasing and hence it exhibits increasing returns to scale. </p>
","8890"
"how is new money actually introduced in the United States?","504","","<p>I'm aware that the fed controls the supply of money by contracting and expanding through permanent and temporary open market operations. Consisting of purchasing Treasury securities or through repos. These are sold primarily to primary dealers I  derstand but also to other organizations.</p>

<p>Can someone explain how the interest that is paid is set during auctions? Additionally it seems that the securities alone can not introduce money but through the interest paid on them?</p>
","<p>The Treasury auction process is described here: <a href=""https://www.treasurydirect.gov/instit/auctfund/work/work.htm"" rel=""noreferrer"">Treasury Direct</a></p>

<p>Bidders can either enter competitive or non-competitive bids. Non-competitive bids are limited in size; the price is set by the competitive bids, which generally come from Primary Dealers (that are obliged to bid).</p>

<p>As a simplified example of the bidding process, assume that the government announces an auction for $2 million in 30-year bonds. (Note that this example ignores bidding size limits.)</p>

<p>There are three bids:</p>

<ul>
<li>a bid for \$1 million at 4% from A</li>
<li>a bid for \$1 million at 4.25% from B</li>
<li>a bid for \$1 million at 4.50% from C.</li>
</ul>

<p>The government looks at the bids (starting with the lowest yields) until the amounts cover the amount to be issued. The highest winning bid yield is used for all. In this case, that means that A and B get filled with a $1 million in bonds at 4.25%, and C gets nothing.</p>

<p>The connection to money is somewhat complicated. The issuance of the bonds reduces the money supply - the bidders have to pay for the bond. The coupon and principal payments will increase the money supply.</p>
","20306"
"Are sales taxes regressive?","502","","<p>There are competing definitions of regressive taxes out there:</p>

<p><strong>On <a href=""https://en.wikipedia.org/wiki/Regressive_tax"">Wikipedia</a>:</strong> </p>

<blockquote>
  <p>A regressive tax is a tax imposed in such a manner
  that the tax rate decreases as the amount subject to taxation
  increases.</p>
</blockquote>

<p><strong>In a textbook I use (Case, Fair, and Oster's <em>Principles of Economics</em>):</strong></p>

<blockquote>
  <p>A regressive tax is a tax whose burden, expressed as a percentage of income, decreases as income increases.</p>
</blockquote>

<p>By the Wikipedia definition, a sales tax would technically be a proportional tax as the rate is fixed regardless of how the base (consumption) changes.</p>

<p>However, by the textbook definition, and assuming that households with lower income consume a greater percentage of that income than households with higher income (i.e. have lower savings rates), a sales tax with a fixed rate would be regressive.</p>

<p>You might be inclined to suggest that the textbook was defining it specifically for income taxes where the Wikipedia article is defining it generally. Actually, though, the authors of the text make it clear they mean their definition to be general. They say that they define it in terms of income because ""all taxes are ultimately paid out of income."" I think that statement is a bit imprecise, but whatever. They go on to show an example that demonstrates that sales taxes are regressive (conditional on lower-income households saving less).</p>

<p>I agree with them on an intuitive level that sales taxes are regressive. But then why has Wikipedia decided on a definition that is independent of income, with one consequence being that sales taxes are proportional?</p>
","<p>It depends on the definition you want to use. You can define a regressive tax as the wiki says, in which case a sale tax would not match. </p>

<p>But the goal of definition of different class of taxation is to assess the impact on person being taxed. Without considering income the above definition becomes moot. Sure the tax is proportional (fixed share of tax on any price) but it's effect on those who pay it is different.</p>

<p>The first definition is derived , I believe, in the context of income taxes in which the income is being taxed and the definition matches it's intuitive notion. 
Some taxation system are subject to the requirement that the system as a whole should be progressive, I.e the total tax burden should increase with income. In this context is natural to think that sale taxes are regressive, while they don't match the formal definition.</p>
","12655"
"What are main methods for econometrics of Macroeconomics?","502","","<p>I have a background in Finance and have become pretty interested in Macroeconomics as a graduate student. However the time is limited and I want to focus on econometrics part of Macroeconomics. In that case, could someone please give me tell me what are the main econometrics methods I should learn in Macroeconomics？In Finance we focus on models like ARMA and GARCH, how about Macroeconomics? I've learned VAR before. I also heard about the simultaneous equations, are those for Macro? What are methods that econometricians came up to handle Lucas's Critique? What might be a good book to learn Macro econometrics?</p>

<p>Thanks in advance!</p>
","<p>There are many different econometric methods used in macroeconometrics, but the basic ones are advanced versions of least squares methods and Generalized Method of Moments (GMM). Structural VARs, ARCH/GARCH models and several others are widely used as well.</p>

<p>Since you're already familiar with econometric methods, you might try glancing through Fair's ""Macroeconometric Modeling"" (<a href=""http://fairmodel.econ.yale.edu/mmm2/mm.pdf"" rel=""nofollow"">http://fairmodel.econ.yale.edu/mmm2/mm.pdf</a>). You don't necessarily have to read it completely, but I found it a really useful document in understanding how to build and use macroeconometric models.</p>

<p>Based on your background and interest, I'd recommend Favero's ""Applied Macroeconometrics"" and De Jong's and Chetan's ""Structural Macroeconometrics"" as general books on the subject.</p>
","10374"
"How encouragement design works practically?","501","","<p>I'm trying to understand the encouragement design but I have some doubts. For example, if I want to introduce a voucher for teachers that can be used for professional development(the treatment) and I want to estimate its impact on student performance(dependent variable) obviously I have some problems, since not all the individuals in the treatment group will actually use the voucher. How can I introduce the encouragement design in this case? for example is it right if I send (randomly in the treatment group) some invitations to some professional developments program and I use their participation to these invitations as instrumental variable? And what's the difference with intention to treat?</p>
","<p>The fact that you can only encourage but not force the teachers to participate puts you squarely in the world of Local Average Treatment Effect (LATE) and Intention to Treat analysis.</p>

<p>Essentially if you use the voucher as a instrumental variable, you will get an estimate of the effect of the voucher on ""the sort of person who you can encourage to take a class by giving them a voucher"".</p>

<p>Read the Instrumental Variables section in Mostly Harmless Economics, to get a good easy to understand explanation of exactly the situation you are interested in.</p>
","5117"
"Real-life applications of repeated games theory","497","","<p>What are some scenarios in which the theory of repeated games have been applied?</p>

<p>I am looking, for example, for scenarios in which a government, a firm or a person accepted a decision which relied upon a result such as the <a href=""https://en.wikipedia.org/wiki/Folk_theorem_%28game_theory%29#cite_note-fisher-2"">Folk theorem</a>.</p>
","<p>I believe insights from repeated game theory have been used in designing the assignment scheme for security patrols in many occasions. </p>

<p>In this matter, the main research projects with close connections to applications that I know of are  </p>

<p>(a) <a href=""http://teamcore.usc.edu/projects/coastguard/"" rel=""nofollow"">PROTECT for the US Coast Guard</a></p>

<p>(b) <a href=""http://teamcore.usc.edu/projects/TRUSTS/"" rel=""nofollow"">TRUSTS for the Los Angeles Sheriff's Department</a></p>

<p>(c) <a href=""http://teamcore.usc.edu/projects/fam/"" rel=""nofollow"">IRIS for the Federal Air Marshal's Service</a></p>

<p>(d) <a href=""http://teamcore.usc.edu/ARMOR-LAX/"" rel=""nofollow"">LAX for the Los Angeles Airport Police</a></p>

<p>(e) <a href=""http://teamcore.usc.edu/GUARDS/"" rel=""nofollow"">GUARDS for the Transportation Security Administration</a></p>

<p>which all revolve around the <a href=""http://teamcore.usc.edu/projects/security/"" rel=""nofollow"">teamcore research group at the University of Southern California</a>. </p>

<p>Examples of papers involving members of the group and repeated games (usually repeated Stackelberg security games) include:</p>

<ul>
<li><a href=""http://dl.acm.org/citation.cfm?id=2773374"" rel=""nofollow"">Defender Strategies In Domains Involving Frequent Adversary Interaction</a></li>
<li><a href=""http://www.ntu.edu.sg/home/boan/papers/ALA15_Debarun.pdf"" rel=""nofollow"">Learning Bounded Rationality Models of the Adversary in
Repeated Stackelberg Security Games</a></li>
<li><a href=""https://teamcore.usc.edu/papers/2015/AAMAS15-HAIDM-CRC-DebarunKar.pdf"" rel=""nofollow"">Conducting Longitudinal Experiments with Behavioral
Models in Repeated Stackelberg Security Games on
Amazon Mechanical Turk</a></li>
<li><a href=""http://dl.acm.org/citation.cfm?id=2773329"" rel=""nofollow"">A Game of Thrones"": When Human Behavior Models Compete in Repeated Stackelberg Security Games</a></li>
</ul>
","8298"
"What is the impact of fracking on oil prices?","496","","<p>I read an <a href=""http://www.foxnews.com/opinion/2014/10/21/real-reason-gas-prices-are-falling/"">article</a> about the recent fall of gas prices in the US claiming that the fall in gas prices was due to the expansion of fracking within the US.  The article said that, over the past few months, the oil harvested from fracking had come onto the market reducing the price of gas at road-vehicle refueling stations.<br>
Obviously, I realize that an increase of supply with a constant demand will decrease prices.  But, is there any way to validate the article and conclude that the decrease in oil prices was due to fracking?  The article I read did not go into detail on how they reached their conclusion.  </p>
","<p>The best way to get into the various factors at play on this is to look at the Oil Import/Export &amp; Consumption figures for the USA, which the EIA provides in glorious detail (click on the expand button to see the individual charts):</p>

<p><a href=""http://www.eia.gov/countries/country-data.cfm?fips=US#pet"" rel=""nofollow"">US Oil Consumption - Import/export</a></p>

<p>It´s not the case as some have claimed that the US has become a net exporter, but Oil imports have significantly declined from their peak in 2006, and the situation with natural gas is equally dramatic. Interestingly though, there has also been a drop in consumption, which I would speculate is partly due to the 2006 recession, and may be a contribution from other energy sources, and may also be increasing energy efficiency developments triggered by the high oil price.</p>

<p>As Brythan quite correctly points out below, this doesn't include the time series data for production/consumption in the rest of the world, which can be found here:</p>

<p><a href=""http://www.eia.gov/cfapps/ipdbproject/iedindex3.cfm?tid=5&amp;pid=5&amp;aid=2&amp;cid=ww,&amp;syid=2009&amp;eyid=2013&amp;unit=TBPD"" rel=""nofollow"">World Oil Production</a></p>

<p>we can see that total world production has increased by around 6,000 barrels a day since 2005, about 4,000 of which would be the US production increase.</p>

<p>Since the US is still the largest consumer of oil on a per country basis (approximately 2x the Chinese who are currently #2), the combination of this with the drop in imports by the US can be expected to have a significant knock on effect on the price of oil, reducing it globally.</p>

<p>Over the long term it really depends on what you are prepared to believe about the increasing efficiency of solar power, how long the new fields remain competitive, and what other sources of fracking may be available outside the USA, which can be exploited, as to what will happen to the price of oil. Certainly for the next few years though, and ceteris paribus of course, I´d expect oil prices to stay down.</p>
","400"
"World bank data - GDP per capita current US\$ vs constant 2005 US\$","496","","<p>I'm looking at two charts from world bank on GDP per capita for Croatia and Russia - and this is what I get:</p>

<p><a href=""https://i.stack.imgur.com/oPSew.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/oPSew.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/56PS5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/56PS5.png"" alt=""enter image description here""></a></p>

<p>Now, from what I gathered, the first chart should represent nominal gdp and the second one real gdp (in 2005 US$).</p>

<p>Shouldn't the charts look similar, only with different absolute values? I thought that, for example, you could get 2014 real values simply by adjusting nominal values for total inflation between 2005 and 2014. If that inflation was 25%, then 2014 real = 2014 nominal / 1.25 (in 2005 US$).</p>

<p>How come that in the first chart GDP per capita is almost the same in 2014, and in the second one Croatia's GDP per capita is more than 50% larger?</p>
","<p>The two charts are consistent in the basic sense that the 2005 values are the same in both, with Croatia about $\$10200$ and Russia about $\$5300$. What happens in other years depends on exchange rates and inflation in the three countries concerned (Croatia, Russia and the United States). </p>

<p>The current USD-based figures are calculated much as you would expect: take the GDP per capita in local currency (kuna in Croatia, rubles in Russia) and covert these to dollars at the exchange rates applying in the different years.</p>

<p>Your question would make sense if the constant USD-based figures were calculated by taking the current USD-based figures and deflating them for price changes in the US since 2005. So the Croatian and Russian numbers current USD-based figures would have been deflated by the same ratios, and if they were to meet in a particular year in one series then they would meet in the same year in the other series.</p>

<p>But they were not calculated that way.  </p>

<p>Instead the constant USD-based figures were calculated by taking the GDP per capita in local currency each year, and were deflated by price changes locally since 2005 to give GDP per capita in constant local currency units, and then converted to dollars using the 2005 exchange rates. Because exchange rates did not match varying relative local price changes in Croatia and Russia compared with the United States, this produces a different result.</p>

<p>There is a way to approach this question to reduce the problem, but that would involve <em>purchasing power parities</em> (PPP) looking at what money can actually buy in different countries rather than market exchange rates, and the statistical invention of the <em>international dollar</em> (not an actual currency) to handle price changes year-to-year. It results in different data again and can lead to different rankings between countries (famously, China would appear to be relatively much richer). Here it would suggest Russia having significantly higher GDP per capita than Croatia since 2011 on a PPP basis, the opposite of your second chart due to the the ruble seeming to have been undervalued in the market exchange rates compared with the kuna in terms of what it can apparently buy locally.     </p>
","16599"
"What Math is used in Development Economics?","495","","<p>I would like to ask what kind of math is used in Development Economics?  </p>

<p>I have one more semester in my Master of Math programme before hopefully entering a PhD in Economics and am considering specializing in this; so I would like to know what I should take or review next semester.  Are the topics listed on the wiki-page for Mathematical Economics applicable?  Being differential equations, linear algebra, optimization, and analysis.  Or would statistics or data science be more applicable?  </p>

<p>Thank you</p>
","<p>This does depend on whether you're looking to do applied econometric work, in which case statistics is definitely the way to go or something theoretical, in which case a good understanding in the maths you listed will go a long way. Of course it's always better if you understand both - since you're doing a master's in math, you should already be quite fluent with the math required, so I'd go with econometrics.</p>

<p>There's a growing amount of literature available, but if you have time to spare, I'd give the topics in Nafziger's ""Economic Development"" a glance: <a href=""http://tabesh.edu.af/Books/economic/Economic%20Development.pdf"" rel=""nofollow"">http://tabesh.edu.af/Books/economic/Economic%20Development.pdf</a></p>
","9660"
"conditional factor demand functions for capital and labor","494","","<p>I don't how to put maths in here so using an image:
<a href=""https://i.stack.imgur.com/GRsOO.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GRsOO.jpg"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/LKHnW.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LKHnW.jpg"" alt=""enter image description here""></a></p>
","<p>$$(\frac{r}{w} \frac{1-\alpha}{\alpha})*K$$
$$\equiv (\frac{r}{w} \frac{1-\alpha}{\alpha})[\frac{y}{a}(\frac{w}{r} \frac{\alpha}{1-\alpha})^{1-\alpha}]$$
$$\equiv (\frac{r}{w} \frac{1-\alpha}{\alpha})^{\alpha-1+1} \frac{y}{a}$$</p>

<p>$$\equiv (\frac{r}{w} \frac{1-\alpha}{\alpha})^{\alpha} \frac{y}{a}$$</p>

<p>Is that what you're looking for?  Just notice that between steps two and three, I inverted the part of K in parentheses and changed the exponent to account for the inversion. </p>
","14607"
"Price Elasticity of Demand for Positive Price Increases","493","","<p>What does it mean when the price elasticity of demand  %Qd/%P is greater than one?  Typically I hear that it means the demand is elastic since if, say, the price decreases by 1% the demand for the good increases by more than 1%.  But what happens if %P is +1% and %Qd still increases by more?  Sure, this is elastic, but does it give us any more information?  I can't see why %Qd/%P > 1 makes sense in this case.</p>
","<p>Except of the purely descriptive aspect, ""elastic demand"", or more accurately, regions of the demand schedule where demand elasticity with respect to price is higher than unity, <em>in absolute terms</em>, is linked to the basic monopoly theory, since the monopolist maximizes profits at a point of the demand schedule where ""demand is elastic"".</p>

<p>Define the demand point-elasticity with respect to price as</p>

<p>$$\eta = \frac {\partial Q }{ \partial P}\cdot \frac {P}{Q} \Rightarrow \frac {\partial Q }{ \partial P} = \eta \cdot \frac {Q}{P} \tag{1}$$</p>

<p>Note that algebraically, the elasticity is a <em>negative</em> number, with the sign indicating the direction of influence, since $\partial Q / \partial P &lt;0$.</p>

<p>The profit function of a monopolist is</p>

<p>$$\pi = P\cdot Q(P) - C(Q(P)) \tag{2}$$</p>

<p>The first-order condition for a maximum with respect to price is</p>

<p>$$\frac {\partial \pi}{\partial P} = 0 \Rightarrow Q + P\frac {\partial Q }{ \partial P} - MC\cdot \frac {\partial Q }{ \partial P} = 0 \tag{3}$$</p>

<p>Inserting $(1)$ into $(3)$ we have</p>

<p>$$Q + P\cdot \eta \cdot \frac {Q}{P} - MC\cdot \eta \cdot \frac {Q}{P} = 0$$</p>

<p>$$\Rightarrow 1 + \eta - \eta \cdot \frac {MC}{P} =0$$</p>

<p>$$\Rightarrow - \eta \cdot \frac {MC}{P} = -\eta -1 $$</p>

<p>$$\Rightarrow  |\eta| \cdot \frac {MC}{P} = |\eta| -1$$</p>

<p>$$\Rightarrow P^* =  \frac {|\eta|}{|\eta|-1} MC \tag{4}$$</p>

<p>$(4)$ is essentially an implicit relation since $\eta$ is a function of price also, <strong>but it provides a specific insight</strong>: Since we naturally expect that price will be positive, we see that we must have $|\eta| &gt;1$: the price will <em>necessarily</em> be set at a level where ""demand is elastic"", i.e. at a point on the demand schedule where the point price elasticity of demand is higher than unity, <em>in absolute terms</em>.</p>
","1728"
"Duality of cost minimization and profit maximization","491","","<p>The firm tries to maximize profits $\Pi$
\begin{align}
\max_{K,L}\{\Pi(K,L) = F(K,L) - RK - wL\} 
\end{align}
where $F$ is the linear homogeneous production function, $R$ the rental rate of capital $K$ and $w$ the rental rate (wage) of labor $L$. FOCs are given by
\begin{align}
\Pi_K &amp;= 0 \Leftrightarrow R = F_k\\
\Pi_L &amp;= 0 \Leftrightarrow w = F_L.
\end{align}
Footnote 1 of page 33 in <a href=""http://press.princeton.edu/chapters/s2_8764.pdf"" rel=""nofollow noreferrer"">Acemoglu (2009)</a> tells us that the FOCs can also derived by cost minimization. </p>

<p><a href=""https://i.stack.imgur.com/IdkiB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/IdkiB.png"" alt=""enter image description here""></a> </p>

<p>With (2.6) and (2.7) being $w=F_L$ and $R=F_K$ respectively.
The firm tries to minize costs 
\begin{align}
&amp;\min_{K,L}\{RK + wL\}\\
\text{s.t.}~~&amp; F(k,L) = Y 
\end{align}
where $Y$ is some output level. Set up Lagrangian
\begin{align}
\mathcal{L} = RK + wL + \lambda(F(K,L) - Y)
\end{align}</p>

<p>FOCs are given by
\begin{align}
\mathcal{L}_K = 0&amp; \Leftrightarrow R + \lambda F_K = 0\\
\mathcal{L}_L = 0&amp; \Leftrightarrow w + \lambda F_L = 0\\
\mathcal{L}_\lambda = 0&amp; \Leftrightarrow F(K,L) - Y = 0
\end{align}</p>

<ul>
<li>I don't see, how we can conjecture $R = F_K$ and $w = F_L$ from those conditions?</li>
</ul>
","<p>If $F(K,L)$ is a homogeneous function of degree one then so is
$$
\Pi(K,L) = F(K,L) - R \cdot K - w \cdot L.
$$
This follows straight from the definition of homogeneity. (A definition of homogeneous function can be found <a href=""http://people.hss.caltech.edu/~kcb/Notes/EulerHomogeneity.pdf"" rel=""nofollow"">here</a>.) This means that if a maximal profit exists it is zero. Otherwise you could increase all inputs by say 100%, thereby increasing both revenues and costs and thus profits by 100%. So $\Pi(K^*,L^*) = 0$.</p>

<p>By <a href=""http://people.hss.caltech.edu/~kcb/Notes/EulerHomogeneity.pdf"" rel=""nofollow"">Euler's Homogeneous Function Theorem</a> we have $\forall K,L$:</p>

<p>\begin{align}
\Pi(K,L) &amp;= \Pi_K(K,L) \cdot K + \Pi_L(K,L) \cdot L  \\
\Pi(K,L) &amp;= (F_K(K,L) - R) \cdot K + (F_L(K,L) - w) \cdot L.
\end{align}</p>

<p>Since $\Pi(K^*,L^*) = 0$, we have
$$
-(F_K(K^*,L^*) - R) \cdot K^* = (F_L(K^*,L^*) - w) \cdot L^*
$$
We know that $K^*,L^* \geq 0$, so if we can show that the signs of 
$(F_K(K^*,L^*) - R)$ and $(F_L(K^*,L^*) - w)$ match we will have proven them to be equal to zero. Otherwise one side of the equation would be negative and the other positive. From cost minimization you have
\begin{align}
R + \lambda F_K &amp; = 0\\
w + \lambda F_L &amp; = 0.
\end{align}
If $\lambda &gt;1$ then
\begin{align}
F_K(K^*,L^*) - R &amp; &lt; 0\\
F_L(K^*,L^*) - w &amp; &lt; 0,
\end{align}
if $\lambda =1$ then
\begin{align}
F_K(K^*,L^*) - R &amp; = 0\\
F_L(K^*,L^*) - w &amp; = 0.
\end{align}
and if $\lambda &lt;1$ then
\begin{align}
F_K(K^*,L^*) - R &amp; &gt; 0\\
F_L(K^*,L^*) - w &amp; &gt; 0,
\end{align}</p>

<p>so the signs do indeed match, hence
\begin{align}
F_K(K^*,L^*) - R &amp; = 0\\
F_L(K^*,L^*) - w &amp; = 0.
\end{align}</p>
","8811"
"Floating exchange rate and cost-push inflation?","491","","<p>I have a trouble understanding the following text from my textbook. I bolded the fragments that don't make sense to me.</p>

<p>""Disadvantages of a floating exchange rate:
A floating exchange rate regime may worsen existing levels of inflation. If a country has high inflation relative to other countries then this will make its exports less competitive and its <strong>imports relatively less expensive</strong>. The exchange rate will then fall, in order to rectify the situation. However, this could lead to <strong>even higher</strong> import prices of finished goods, componetns, and raw materials, and thus cost-push inflation, which may further fuel the overall inflation rate.""</p>

<p>If there's high inflation, exports become less competitive and imports become <strong>less expensive</strong> - that's obvious. But why do they say that it would make imports' prices <strong>even higher</strong>? Why ""<strong>even</strong>"" and why ""<strong>higher</strong>""? They've said that imports are cheaper after inflation, so imported raw materials, etc. should be cheaper as well so the costs of productions should be cheaper too and don't cause cost-push inflation but totally opposite.</p>
","<p>The passage quoted is (at least) sloppy as regards language, in that it writes first ""relatively <em>less</em> expensive"", and then uses ""<em>even</em> more"", which would be correct if previously it had described a ""more"" expensive rather than a ""less"" expensive situation.  </p>

<p>What happens here is that, under the assumption that Purchasing Power Parity holds (or tends to hold), we have</p>

<p>$$\pi = \pi^* - \dot S/S$$</p>

<p>Where $\pi$ is local inflation, $\pi^*$ is ""foreign"" inflation, and $\dot S/S$ is the growth rate of ""local"" exchange rate (units of foreign currency per unit of local currency). </p>

<p>Then, if $\pi &gt; \pi^* \implies \dot S/S &lt;0 \implies \dot S &lt;0$, at least as a tendency, and the local currency will, eventually, depreciate.</p>

<p>For clarity, assume that we start from a situation where both inflation rates are zero. Then, local positive inflation happens, for some local reason.  </p>

<p>Initially, <em>before</em> the exchange rate starts to adjust, local exports become more expensive for the foreigners (as the answer by @user3522240 describes), while imports (whose nominal price in terms of foreign currency has not changed, due to zero foreign inflation) become <em>relatively</em> less expensive, with ""relatively"" referring to the <em>relative contribution</em> of imported resources to local costs of production, compared to the cost of local resources. Imports do not become ""cheaper"" in nominal terms, in either currency. Only their <em>percentage</em> contribution to total costs becomes smaller.</p>

<p>But since eventually, we assume that the exchange rate will depreciate, weakening the local currency, the nominal cost of imports in terms of local currency will increase. But this will now increase the total cost of production in terms of local currency, and it will tend to <em>add</em> inflation to the already existing, locally generated, inflation rate, as firms will attempt to pass this imports-linked increase in costs to consumers.</p>

<p><strong>APPENDIX</strong><br>
The Purchasing Power Parity in terms of inflation rates is derived as follows: Denote $P$ the local price level and $P^*$ the foreign price level. Then PPP is expressed as</p>

<p>$$P\cdot S = P^*$$</p>

<p>Differentiate with respect to time,</p>

<p>$$\dot PS + P\dot S = \dot P^*$$</p>

<p>Manipulate (and use the PPP relation)</p>

<p>$$\implies  \frac {\dot P}{P}S + \frac {P}{P}\dot S = \frac {\dot P^*}{P^*}\frac {P^*}{P} \implies \pi S + \dot S = \pi^* S$$</p>

<p>Divide by $S$ and re-arrange to obtain</p>

<p>$$\pi = \pi^* - \dot S/S$$</p>
","6608"
"Medium run conclusions from Okun's Law and Expectations-Augmented Philips Curve","491","","<p>In Blanchard's Macroeconomics, page 211, 5th edition, the author using the following three mathematical equalities</p>

<ul>
<li><p>Okun's law : $u_t-u_{t-1}=-\beta(g_{yt}-\bar{g_y})$, where
$\bar{g_y}$ is defined as the output growth rate when the
unemployment rate is constant, $g_{yt}$ output growth rate from year
t-1 to t.</p></li>
<li><p>expectations-augmented Philips curve, </p></li>
<li><p>and assuming a functional form  for the aggregate demand relation
that allows to deduce  $g_{yt}=g_{mt}-\pi_t$, where $g_{mt}$ is nominal
money growth rate</p></li>
</ul>

<p>makes a reasoning on what happens in the medium-run when the central bank maintains a constant growth rate of nominal money, concluding that although changes in the growth rate of nominal money doesn't change unemployment rate, it does change the inflation rate one-for-one. One of the first assumptions of the reasoning is that in the medium run the unemployment rate is constant. But why can we assume this?</p>

<p>In previous chapters, we had assumed that output would change one-for-one with employment, and that the labour force was constant. Then, when the expected price level were equal to the actual price level, the economy would be in natural output level, and that would imply from previous two assumptions that unemployment rate would also be the natural one. However, in this chapter, when the author was deriving the Okun's law, we explicitly assumed that labour force was no longer constant, and that employment would respond less than one-for-one to output, and that changes in employment are not negatively reflected one-for-one in the unemployment. 
Also, in same page 211, it's the author's conclusion that the unemployment rate in the medium-run is the natural unemployment rate. So, we cannot assume what we're trying to conclude... </p>

<p>Therefore, why can we assume that the unemployment rate must be constant in the medium run?</p>

<p>Any help would be appreciated. </p>
","<p>At least in the 3d edition, Blanchard writes:</p>

<blockquote>
  <p>""In the medium run, the unemployment rate <em>must</em> be constant (my emphasis).
  The unemployment rate cannot be decreasing or increasing forever.""</p>
</blockquote>

<p>This is an inherent characteristic of <em>the definition</em> of the ""medium run"": that in it, some <em>core</em> magnitudes are constant. In some models, <em>levels</em> are constant (eg. aggregate consumption, aggregate capital stock, etc). In other models, <em>growth rates</em> are constant, and the model ""has a steady-sate in growth rates"". This means that <em>levels</em> grow indefinitely of course, but it is not wise (or useful, or meaningful) to project economic concepts to ""infinite future"". </p>

<p>Now for unemployment, it makes no sense to <em>not</em> be constant in equilibrium (at this simple level of exposition). In more sophisticated models, one could have the unemployment rate approaching asymptotically a constant (zero or not) without ever actually reaching it, but this is usually mathematical gadgetry with not much of economic intuition. (And in futuristic models, one could have unemployment approaching asymptotically unity, as machines and Artificial Intelligence take over all jobs). </p>

<p>Can this constant-by-conception-in-the-medium-run unemployment rate $u^* =const.$ be something else than the ""natural rate of unemployment"" $u_n$?</p>

<p>The natural rate of unemployment is  <em>defined</em> through the Phillips Curve, as that rate of unemployment at which realized inflation equals expected inflation (see previous chapters). Note that it is not assumed a priori that the natural rate of unemployment will be strictly positive -it could very well be zero. It is actual data that tells us that inflation stabilizes at strictly positive rates of unemployment. Then it is constant when inflation is a constant, and Blanchard discusses why inflation will also be a constant in the medium run. So it obtains that in the medium run $u_t = u_n =const.$.  </p>

<p>Since the current unemployment rate stabilizes when inflation becomes constant, which happens in the medium run, the constants <em>must</em> coincide. If $u^* \neq u_n$ inflation will not be constant and we would violate another condition for the characterization of the medium run.</p>

<p>And Blanchard writes correctly</p>

<blockquote>
  <p>""In the medium run the unemployment rate <strong><em>must</em></strong> be equal to the
  natural rate of unemployment"". </p>
</blockquote>

<p>So it does <em>not</em> assume what he wants to prove. The natural rate of unemployment is defined separately and with its own logic to be a constant, from the medium-run unemployment rate which is constant based on other arguments than those related to the natural rate of unemployment. </p>

<p>I hope this helps.</p>
","8176"
"Can the stock market show indefinite exponential growth?","490","","<p>In a comments on a <a href=""https://money.stackexchange.com/questions/81126/why-should-we-expect-stocks-to-go-up-in-the-long-term"">question on money.SE</a>, the following dialog took place:</p>

<blockquote>
  <p>Eventually there will not be enough matter to represent all the money, so we know for certain that the answer is ""No"" for a long enough term. </p>
</blockquote>

<p>--yters</p>

<blockquote>
  <p>What do you mean by ""represent?"" Do you mean that we won't be able to build computer chips that can store a digital representation of someone's stock income? Do you mean that we will no longer be able to cash out our stock portfolio into a fixed commodity like gold, at a fixed dollar price? The former seems wrong to me, and the latter irrelevant.</p>
</blockquote>

<p>-- BenCrowell</p>

<blockquote>
  <p>@BenCrowell: the stock market is not abstract, it depends on investors expectations on the real economy. Its obvious that the economy cannot grow forever, as the planet (and its resources) are finite.</p>
</blockquote>

<p>-- Martin Argerami</p>

<p>I'm not convinced by the argument that Martin Argerami claims is obvious. It seems to me to rest on a false assumption that value is measured by resources, e.g., that a dollar's ""true"" value is measured by how many milligrams of gold it can buy. But I'm not an economist. Would anyone like to take a shot at explaining who is right?</p>
","<p>May I rephrase your question into the broader question <strong>""Can economic growth continue indefinitely?""</strong></p>

<p>(In response to objections that eventually the sun will burn out or the universe will suffer heat death, I take <strong>indefinite</strong> to mean ""lasting for an unknown or unstated length of time"" (<a href=""https://en.oxforddictionaries.com/definition/indefinite"" rel=""nofollow noreferrer"">OED</a>). So I am thinking of 100s, 1000s, or even 10000s of years ahead. But I am <strong>not</strong> thinking of billions of years ahead or the ""infinite future"".)</p>

<p>Non-economists commonly believe the answer to be ""no"", giving some reason along the lines of ""resources are finite!"" </p>

<p>But the economist's answer to this is <strong>""Yes, of course economic growth can continue indefinitely.""</strong> And so to answer also your narrower question, <strong>""Yes, of course the stock market can show indefinite exponential growth.""</strong> (By ""can"", I mean that this is at least conceivable. Whether it <em>will</em> is a different matter altogether. After all the world might end tomorrow in a nuclear apocalypse.)</p>

<p>I think we can distinguish between <strong>two common fallacies</strong> at work here.</p>

<hr>

<p><strong>Fallacy #1. ""Economic growth is about making ever more ""stuff"", digging ever more gold and other natural resources out of the ground, burning ever more energy, etc.""</strong> (This caricature is perhaps why many non-economists and especially environmentalists are averse to economists and the idea of economic growth.) The fallacy typically continues, ""Resources/the universe is finite. Therefore economic growth must also be finite."" </p>

<p>But this is wrong. <strong>Economic growth is about improving human well-being, broadly conceived.</strong></p>

<p>It is true that for a long time (the past few centuries), improvements in human well-being were largely through improvements in <strong>material</strong> well-being and highly-correlated with making ever more stuff and burning ever more energy. After all, it was not two centuries ago that the vast majority of mankind lived at bare subsistence level. (Indeed, even today, many people still do.) </p>

<p>But going forward, it is perfectly conceivable that we make ever less ""stuff"", dig ever less ""stuff"" out of the ground, and burn ever less energy, and yet still become ever more well-off. This is actually already happening today in the rich countries (see e.g. falling energy use, briefly analyzed below).</p>

<p>Since the 1930s and 1940s, we've measured economic growth mostly by GDP growth. But economists have always recognized that GDP is a very flawed measure of well-being. Economists are working on alternatives that better capture the notion of improvements in human well-being or equivalently, economic welfare. I do not expect that in 100 years, the current concept of GDP without fundamental modifications will still be used to as the primary measure of economic well-being.</p>

<p>(Footnote: Perhaps in the future, we will also include non-human well-being in our conception of economic growth. But for now, we still restrict attention mostly to human well-being.)</p>

<hr>

<p><strong>Fallacy #2. ""Bad things (like the consumption of food or resources) will grow rapidly or even exponentially. In contrast, offsetting good things (like technology) can at best grow arithmetically. Therefore, there are necessarily limits to growth.""</strong></p>

<p>This fallacy is not new. Here's an example of doom-and-gloom predictions from each of the past three centuries, all of which proved to be wrong. </p>

<ul>
<li><a href=""https://en.wikipedia.org/wiki/An_Essay_on_the_Principle_of_Population"" rel=""nofollow noreferrer"">Malthus (1798): <em>An Essay on the Principle of Population</em></a>. </li>
</ul>

<p><a href=""http://www.crf-usa.org/bill-of-rights-in-action/bria-26-2-the-debate-over-world-population-was-malthus-right.html"" rel=""nofollow noreferrer"">2010 commentary</a>:</p>

<blockquote>
  <p>Malthus began with two “fixed laws of our nature.” First, men and
  women cannot exist without food. Second, the “passion between the
  sexes” drives them to reproduce.</p>
  
  <p>He explained that, if unchecked, people breed “geometrically” (1, 2,
  4, 8, 16, etc.). But, he continued, the production of food can only
  increase “arithmetically” (1, 2, 3, 4, 5, etc.). “The natural
  inequality of the two powers of population and of [food] production in
  the earth,” he declared, “form the great difficulty that to me appears
  insurmountable [impossible to overcome].”</p>
  
  <p>Malthus concluded: “I see no way by which man can escape from the
  weight of this law.” In other words, if people keep reproducing in an
  uncontrolled geometric manner, they will eventually be unable to
  produce enough food for themselves. <strong>The future, Malthus argued,
  pointed not to endless improvement for humanity, but to famine and
  starvation.</strong> </p>
</blockquote>

<ul>
<li><a href=""https://www.google.com.sg/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;ved=0ahUKEwjdiu_hsdjUAhUIQ48KHWh9Ay8QFggrMAE&amp;url=https%3A%2F%2Ffee.org%2Ffiles%2FdocLib%2F547_32.pdf&amp;usg=AFQjCNGsuk7ZKFTBl0KCkGd0LOT_o4eHuQ"" rel=""nofollow noreferrer"">The Great Horse Manure Crisis of 1894</a>:</li>
</ul>

<blockquote>
  <p>Writing in the Times of London in 1894, one writer estimated that in 50 years every street in London would be buried under nine feet of manure. Moreover, all these horses had to be stabled, which used up ever-larger areas of increasingly valuable land. And as the number of horses grew, ever-more land had to be devoted to producing hay to feed them (rather than producing food for people), and this had to be brought into cities and distributed—by horse-drawn vehicles. <strong>It seemed that urban civilization was doomed.</strong></p>
</blockquote>

<ul>
<li>In 1972, exactly such a book title was published: <a href=""https://en.wikipedia.org/wiki/The_Limits_to_Growth"" rel=""nofollow noreferrer""><em>The Limits to Growth</em></a>:</li>
</ul>

<blockquote>
  <p><strong>Our attempts to use even the most optimistic estimates of the benefits of technology in the model did not prevent the ultimate decline of population and industry, and in fact did not in any case postpone the collapse beyond the year 2100</strong> (p. 145.).</p>
</blockquote>

<p>This was a highly-influential best-seller that has <a href=""https://www.clubofrome.org/news/publication-of-the-limits-to-growth/"" rel=""nofollow noreferrer"">sold over 16M copies in over 30 languages</a>.</p>

<p>Take their example of gold. On p. 56, they calculate that if gold use continued growing exponentially AND there was 5 times as much gold available as there were known gold reserves (they thought this was a very optimistic assumption), <strong>gold would be depleted in 29 years, or in 2001</strong>. </p>

<p>Surprisingly, 2001 came and went and gold continued to be mined. Indeed, more than ever. Gold mining graph (<a href=""https://upload.wikimedia.org/wikipedia/commons/6/6d/World_Gold_Production_1900-2014.png"" rel=""nofollow noreferrer"">source</a>):</p>

<p><a href=""https://i.stack.imgur.com/07HhR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/07HhR.png"" alt=""enter image description here""></a></p>

<p>Roughly every 5 years since 1972, <em>The Limits to Growth</em> folks (AKA the Club of Rome) have released a new update to their 1972 book, each time explaining why they had been correct all along (of course) and sometimes pushing back their predictions about when the eventual collapse will set in. In their <a href=""http://rads.stackoverflow.com/amzn/click/193149858X"" rel=""nofollow noreferrer""><em>30-Year Update</em></a>, they make no mention whatsoever of gold. </p>

<p>The following is the <a href=""https://books.google.com/books?id=X_TjAAAAMAAJ&amp;q=%22The%20authors%20load%20their%20case%20by%20letting%20some%20things%20grow%20exponentially%22&amp;dq=%22The%20authors%20load%20their%20case%20by%20letting%20some%20things%20grow%20exponentially%22"" rel=""nofollow noreferrer"">response</a> by two critics to <em>The Limits to Growth</em>, also quoted by Robert Solow in a <em>Newsweek</em> article:</p>

<blockquote>
  <p>The authors load their case by letting some things grow exponentially
  and others not. Population, capital and pollution grow exponentially
  in all models, but technologies for expanding resources and
  controlling pollution are permitted to grow, if at all, only in
  discrete increments.</p>
</blockquote>

<p>(Footnote: Doomsday-mongering was especially fashionable in the West around the 1970s. See also the famous <a href=""https://en.wikipedia.org/wiki/Simon%E2%80%93Ehrlich_wager"" rel=""nofollow noreferrer"">Simon-Ehrlich wager</a> at around the same time.</p>

<p>Predictions at the polar extremes capture the public's attention. <a href=""https://en.wikipedia.org/wiki/Ray_Kurzweil"" rel=""nofollow noreferrer"">Ray Kurzweil</a> comes to mind as someone who makes similar predictions, but at the polar opposite.</p>

<p>In contrast, the median economist is cautiously optimistic, believing merely that slow but steady, sustained growth is possible. No doomsday, no stagnation, but no <a href=""https://en.wikipedia.org/wiki/Technological_singularity"" rel=""nofollow noreferrer"">impending Singularity</a> either. Not exactly a position that sells many books.)</p>

<hr>

<p>In 2012, a physics professor wrote a somewhat-influential blogpost: <a href=""https://dothemath.ucsd.edu/2012/04/economist-meets-physicist/"" rel=""nofollow noreferrer"">Exponential Economist Meets Finite Physicist</a>, exhibiting both of the above fallacies. That someone as intelligent as a physics professor could commit both fallacies shows that economists must do a far better job at educating the public.</p>

<p>There is plenty that is wrong in that blogpost and perhaps I will do a sentence-by-sentence dissection elsewhere, but this is probably not the proper avenue. Here I'll merely point out one obvious factual error that's of particular relevance. He claims as fact that</p>

<blockquote>
  <p>energy growth has far outstripped population growth, so that
  <strong>per-capita energy use has surged dramatically over time</strong>—our energy
  lives today are far richer than those of our great-great-grandparents
  a century ago [economist nods]. So <strong>even if population stabilizes, we
  are accustomed to per-capita energy growth: total energy would have to
  continue growing to maintain such a trend [another nod].</strong></p>
</blockquote>

<p>As <a href=""http://freakonomics.com/2014/01/24/can-economic-growth-continue-forever-of-course/"" rel=""nofollow noreferrer"">Tim Harford</a> points out, this is FALSE. In recent decades, energy growth per person in many countries has actually been falling, even as GDP per capita has risen. Graph (data from <a href=""http://data.worldbank.org/indicator/EG.USE.PCAP.KG.OE"" rel=""nofollow noreferrer"">World Bank, June 1st 2017 update</a>):</p>

<p><a href=""https://i.stack.imgur.com/Z4tHu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Z4tHu.png"" alt=""enter image description here""></a></p>

<p>In every rich country, per-capita energy use peaked years ago and has been falling ever since. In fact, in some countries, it peaked DECADES ago (peaked in 1978 in the US, in 1979 in Germany, and in 1973 in the UK).</p>

<p>(One would've hoped that a physics professor backed up his factual claims with something more than a fictitious and bumbling economist who repeatedly nods.)</p>

<p>See also falling energy intensity (energy use per unit of GDP) (<a href=""https://www.eia.gov/todayinenergy/detail.php?id=27032"" rel=""nofollow noreferrer"">source</a>):</p>

<p><a href=""https://i.stack.imgur.com/XEtPO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XEtPO.png"" alt=""enter image description here""></a></p>

<p>The highest per-capita energy use ever attained was the US in 1978. My prediction is that global average human well-being will keep improving, but global per-capita energy use will never hit the US 1978 peak (at least not until we start populating other planets and stars). </p>
","17307"
"Understanding the construction of stochastic processes","484","","<p>I've seen stochastic processes modeled/constructed in the following way. </p>

<blockquote>
  <p>Consider the
  probability space $(\Omega, \mathcal F, Pr)$ and let $\mathbb S$ be the (measurable)
  transformation $\mathbb S: \Omega \rightarrow \Omega$
  that we use to model the evolution of the sample point $\omega$ over time.
  Also, let $X$ be the random vector $X: \Omega \rightarrow \mathbb R^n$.
  Then, the stochastic process $\{ X_t: t=0,1,...\}$ is used to model
  a sequence of observations via the formula
  $
X_t(\omega) = X[\mathbb S^t(\omega)]
$
  or
  $
X_t = X \circ \mathbb S^t.
$</p>
</blockquote>

<p>How should I understand the sample points $\omega \in \Omega$ and
the transformation $\mathbb S$ in this construction? (Could $\omega$ be something
like a sequence of shocks in certain cases?) </p>

<p>For more concreteness,
how would I write these two processes in this notation? </p>

<p><strong>Process 1:</strong>
$$
X_{t+1} = \rho X_t + \varepsilon_{t+1} \tag{1}
$$
where $X_0 = 0$.</p>

<p><strong>Process 2:</strong>
$$
X_{t+1} = \varepsilon_{t+1} \tag{2}
$$</p>
","<p>This construction you describe is not fully general. In fact it characterizes strictly stationary time series. You see that it's shift-invariant. This operator $S$ is essentially a shift operator.</p>

<p>For comparison, here's the usual definition of, let's say discrete-time, processes:</p>

<p><strong>Definition</strong> A stochastic process is a sequence $\{ X_t \}$ of Borel measurable maps on a probability space $( \Omega, \mathcal{F}, \mu )$.  </p>

<p>Now for what you're describing, you have a <em>fixed</em> Borel measurable map $X: \Omega \rightarrow \mathbb{R}^n$. It's the underlying measure that is evolving according to $S$. The map $S$ induces a new ""push-forward measure"" (in measure-theoretic parlance) on $\Omega$ by just taking preimages: define a measure $\mu_S$ by</p>

<p>$$
A \in \mathcal{F} \stackrel{\mu_S}{\mapsto} Pr(S^{-1}(A)).
$$</p>

<p>So the random vector $X: ( \Omega, \mathcal{F}, \mu_S) \rightarrow \mathbb{R}^n$ is $X \circ S$ by construction. They induce the same push-forward measure on $\mathbb{R}^n$. Do this with $S^t$ for each $t$ and you have your time series.</p>

<p>As for your question about $\omega$, inspecting the proof for the other direction should clarify this---i.e. any strictly stationary time series must necessarily take this form for some $( \Omega, \mathcal{F}, Pr)$, $X$, and $S$. </p>

<p>The basic point is that, from a general point of view, a stochastic process is a probability measure on the set of its possible realizations. This is seen in, for example, Wiener's construction of Brownian motion; he constructed a probability measure on $C[0, \infty)$. So in general, an $\omega$ is a sample path and $\Omega$ consists of all possible sample paths.  </p>

<p>For example, take the two processes you named above. They are strictly stationary, if let's say the innovations are Gaussian. (Any covariance-stationary time series driven by Gaussian innovations is strictly stationary.) The construction would then start by taking $\Omega$ to be the set of all sequences, $\mathcal{F}$ the $\sigma$-algebra generated by coordinate maps, and $Pr$ the appropriate measure. For the white noise process (2), $Pr$ is just a product measure on an infinite product. </p>

<p><strong>Reference</strong> This characterization/construction by shift of strictly stationary time series is mentioned in White's <em>Asymptotic Theory for Econometricians</em>.</p>
","4847"
"Difference between double auction and continuous double auction?","481","","<p>What is the difference between double auction and continuous double auction?  Sometimes I feel that they were types of two-sided auction but sometimes I feel as if they were two separate concepts. </p>
","<p>So, if a distinction is made, as continuous double auctions are usually just called double auctions, then the difference has to do with frequency.  It is easier to have an example.</p>

<p>The New York Stock Exchange is an example of a continuous double auction.  Within its trading hours, you can bid in either direction as much or as often as you want and so can everyone else.</p>

<p>The best example of an ordinary double auction was the Arizona Stock Exchange which closed in 2001.  It only permitted two bids per day, at the open of US trading and at the close.  It sought to solve an institutional liquidity problem.  Certain types of institutions are at risk if they cannot clear their orders at or as near to as possible a particular moment in time.  Mutual funds, for example, usually only have one valuation per day and if there need to be a lot of transactions from redemption or purchase activity, then the least risk is to have the trade near that time.  Most are at the open or close.</p>

<p>The Arizona exchange found the single price that cleared the largest number of trades.  You paid a fee to participate.  There was no bid-ask spread.  So possibly hundreds of customers would place their limit orders at the same time as buyers or sellers.  What they did in practice was create single supply curve and a single demand curve and the price paid/received was the intersection of the two curves. </p>
","14879"
"How do interest rates affect the distribution of wealth?","478","","<p>How do interest rates, on local and global scales of an economy, affect the distribution of wealth?</p>
","<p>Good question! But difficult to answer.</p>

<p>A) Typically, economists think of most interest rates as being set by markets. Under that assumption, you can't change rates by themselves because the market would bring them back to a value that equilibrates demand and supply of savings. Economists try to model how everything is in equilibrium with ""general equilibrium"" models. Of course, in reality, the fed does set an interest rate...</p>

<p>B) In the ""life cycle model"" of an individual's life, people borrow when they are young and need to study and create businesses, save when they are middle aged and draw down their savings when they are old. In that context, young people suffer from a high rate and old people gain from a high rate. However, its often the case that people invest in long-term bonds and so it's not really clear that they benefit from <em>an increase</em> in interest rates, because it pushes down the price of their bonds (and their houses too).</p>

<p>C) If instead the idea is to figure out what happens when the equilibrium interest rate is low, then it's good to try to imagine the scenarios when it is indeed low. Economists think that the real interest rate is low when economic growth is low and when there is little demand for capital from firms or a lot of supply of capital by savers. These two things have happened together many times, but they don't have to. For example, a disaster that wipes out a very productive asset, like port infrastructure, will lead to a lot of investment but not a lot of net growth. Similarly, an extra supply of savings should lead firms to invest more and should lead the economy to grow. But now in 2016, we are in a low growth, relatively low investment scenario.</p>

<p>D) It doesn't seem like the interest rate is the biggest determinant to the wealth distribution out there. Some evidence to think this way is that capital  markets have become very open, making interest rates very similar everywhere, but inequality remains very different across countries: Commonwealth + Europe+ Japan (low) vs. Russia,+ US +China + Latin America +Africa(high). The distribution of income seems to depend more on the link between political power and economic power that is the norm in many countries, some because of corruption, others by design. It also seems to be more dependent on the quality public education and other public services.</p>

<p>Some similar ideas are discussed in a sort of reasonable Forbes article here: <a href=""http://www.forbes.com/sites/jeffreydorfman/2015/05/12/the-feds-low-interest-rates-are-increasing-inequality/2/#65fdfe4679cc"" rel=""nofollow"">http://www.forbes.com/sites/jeffreydorfman/2015/05/12/the-feds-low-interest-rates-are-increasing-inequality/2/#65fdfe4679cc</a></p>
","11404"
"Code finding all stable matchings in one-to-one problem","475","","<p>Do you know of any publicly available code in python or R (or any other free high level language) that returns <strong>all</strong> the stable matchings for any one-to-one matching problem?</p>

<hr>

<p><strong>Note</strong>: This is related but different from <a href=""https://economics.stackexchange.com/questions/1638/available-code-for-computing-solutions-to-matching-algorithms"">Available code for computing solutions to matching algorithms?</a>. </p>

<p>In this other question, I asked for code implementing famous mechanisms such as the deferred acceptance mechanism. Some of these mechanisms find <strong>one</strong> stable matching among others. Here I am looking for code that finds <strong>all</strong> stable matchings.</p>

<p>I have inspected the packages recommended in the answers I got to <a href=""https://economics.stackexchange.com/questions/1638/available-code-for-computing-solutions-to-matching-algorithms"">Available code for computing solutions to matching algorithms?</a> and did not find anything that would do the job.</p>
","<p>Patrick Prosser has some great java code at <a href=""http://www.dcs.gla.ac.uk/~pat/roommates/distribution/"" rel=""nofollow"">http://www.dcs.gla.ac.uk/~pat/roommates/distribution/</a> which, among other things, can compute <em>all</em> the stable matchings in roommate problems.</p>

<p>The code is for roommates problems, but Patrick's code allows preferences over roommates to include unacceptable roommates. To implement a two-sided market, just make sure any roommates on one side of the market views any other roommate on the same side of the market as unacceptable, and you're good to go.</p>

<p>If (like myself) you are not used to java, you might struggle a little to get the code working. <a href=""https://martinvdlinden.wordpress.com/2016/04/01/finding-all-stable-matchings-in-roommate-and-marriage-problems/"" rel=""nofollow"">Here</a> is a little tutorial for Mac OS, which worked for me as of today.</p>
","11357"
"convexity of the profit function for profit maximization","475","","<p>the profit function is convex in prices and wages (output and input prices respectively). How does this interact with profit maximization since convexity implies tangents always lie below the curve I would have thought convexity would be necessary for minimization rather than maximization. </p>
","<p>It is true that we are usually interested in minimizing convex functions over convex sets. But I think you have two confusions:</p>

<ol>
<li>The profit function is the result of a profit maximization problem. Not the objective function in the maximization problem. A profit function $\pi^*(p, w, r)$ identifies maximum profit given the price levels (p, w, r).</li>
<li>In the profit maximization problem, the objective function $\pi = pf(k, l) - wl - kr$ is concave in $k$ and $l$, the choice variables of the maximization problem.</li>
</ol>
","14058"
"Intuition behind Engel Aggregation and Cournot Aggregation","474","","<p>Could anyone provide a possibly intuitive and friendly explanation to the Engel Aggregation $(\sum s_i \eta_i = 1)$ and Cournot Aggregation$(\sum s_i \epsilon_{ij} = -s_j)$? Here, $s_i = \frac{p_i,x_i}{I} \ge 0$ is the income share, $\epsilon_{ij}, \eta_i$ are price and income elasticities, respectively. I was not sure how this theory of aggregation of consumer demand tell us about the consumption behavior. Thank you in advance for your help! </p>
","<p>These expressions can be easily derived formally by taking the derivatives of Walras' law w.r.t $I$ (Engel aggregation) and $p_j$ (Cournot aggregation). 
The Engel aggregation means that not all goods are luxuries ($\eta_i&gt;1$), or necessities ($\eta_i&lt;1$), or inferior goods ($\eta_i&lt;0$). The Cournot aggregation says that the budget share $s_j$ of the good $j$  is small when the good $j$ has many substitutes ($\epsilon_{ij}&gt;0$), and big when it has many complements ($\epsilon_{ij}&lt;0$), or their respective budget shares are large. </p>
","18903"
"Is evolutionary game theory a useful modelling tool?","474","","<p>Has evolutionary game theory ever been used to successfully describe an ecosystem or a reasonably closed subsystem of the economy? A frequently used example is about <a href=""http://news.ucsc.edu/2010/02/3544.html"">side-blotched lizards</a> but I don't know of any others. And has it ever been proven that in this case the main factor is really relative fitness of strategies and not some other factor, such as the dynamics of gene recombination?</p>
","<p>You're looking at it from a particularly biological point of view. I know nothing of side-blotched lizards, but I can say that evolutionary game theory is often used for equilibrium selection. In games with more than one equilibrium (whether it be Nash or otherwise), evolutionary game theory can allow us to select a particular equilibrium that is a better prediction than others in that a population is, in some sense, <em>more likely</em> to reach it and stay there than it is to reach and stay at other equilibria. Have a look at <em><a href=""http://rads.stackoverflow.com/amzn/click/0262195879"">Population Games and Evolutionary Dynamics</a></em> by William H. Sandholm if you want to see more of how economists use evolutionary game theory. What your question gets at is really more about creating a model with evolution to describe an ecosystem rather than evolutionary game theory, though the two are not unrelated.</p>
","5567"
"Why is modest inflation a good thing?","474","","<p>I have been reading a BBC news article about inflation in the UK, which is saying that inflation has recently become negative (<a href=""http://www.bbc.co.uk/news/business-33147660"" rel=""nofollow"">http://www.bbc.co.uk/news/business-33147660</a>). The article suggests that this is a bad thing. However, I would have thought that positive inflation is generally a bad thing, because it creates instability, resulting in people spending all their money rather than saving it. Certainly, I know that hyperinflation can cause a huge deal of trouble. Can somebody explain why positive inflation (in modest quantities) is necessarily a good thing?</p>
","<p>I am copying and pasting from an answer I wrote at <a href=""https://economics.stackexchange.com/questions/166/from-an-economics-perspective-what-are-the-ramifications-of-a-currency-with-fix/168#168"">From an economics perspective, what are the ramifications of a currency with fixed money supply?</a></p>

<blockquote>
  <p>A moderate degree of currency inflation serves a number of useful functions in the economy. The most obvious are:</p>
  
  <ul>
  <li>It induces people to spend their money before it loses its value. In
  a deflationary environment there is an incentive to put money under
  your mattress and spend it in a year when it has greater purchasing
  power. If everbody does this then the lack of demand will lead to a
  decrease in overall economic activity (i.e. a recession).</li>
  <li>It provides a weapon against downward nominal rigidities. For example, workers are generally reluctant to accept a nominal pay cut, even if market conditions are such that the current wage is above the equilibrium level. Inflation means that their employer can simply increase wages at less than the inflation rate so that the real wage is decreasing.</li>
  <li>It erodes the real value of nominally denominated debt. Now, this is obviously only a pseudo-advantage because (whilst it benefits debtors) it harms creditors. However, this kind of erosion of debt may be desirable if national economic stability is threatened by high debt levels. Also, since debtors are usually poorer on average than creditors, it can reduce inequality, which may be a normative objective for the government.</li>
  </ul>
  
  <p>Without inflation you miss out on these benefits. The first benefit might not seem like a big deal if you think you can simply set the rate of inflation at zero percent. But it is very hard to hold inflation constant at some target level so attempting to hit zero inflation will almost certainly result in occasional lapses into deflation, with the attendant negative economic consequences.</p>
</blockquote>
","6963"
"Finding equilibrium of perfect competition in the short run with a cost function","472","","<p>I am having a lot of problems trying to find the equilibrium price when we are given a cost function and demand function, but no supply function.</p>

<blockquote>
  <p>All firms have the following production function: $Q = \sqrt{K \cdot L}$</p>
  
  <p>Wages are w = 9, and the rental rate of capital is r = 36.</p>
  
  <p>In the short run, capital is fixed at 𝐾̅ = 3 units. Market Demand is given by P = 360 – 2Q </p>
  
  <p>There are 9 firms in the market, find P*, Q*, and Total Surplus</p>
</blockquote>

<p><strong>In solving the production function with a fixed K:</strong></p>

<p>$MPL$ = K$^{1/2}$ \cdot L$^{1/2}$</p>

<p>$MPL$ = ${1/2} \cdot $K$^{1/2}$ $\cdot$ $L^{-1/2}$</p>

<p>= 1/2 \cdot (K$^{1/2}$ $\cdot$ L$^{1/2}$)</p>

<p><em>Substituting 3 for K:</em></p>

<p>= 1/2 \cdot ($\sqrt{3}$ \cdot $\sqrt{L}$)</p>

<p>$\sqrt{3}$/2 =  $\sqrt{L}$</p>

<p>$\sqrt{L}$ = .8660254</p>

<p>$L^*$ = .75</p>

<p><strong>Where C = wL + rK</strong></p>

<p>C(Q) = w($L^*$) + r($K^*$)</p>

<p>C(Q) = (9*.75) + (36*3)</p>

<p>C(Q) = 114.75</p>

<p>C(Q) @ 9 Firms =  (114.75 * 9) = 1032.75 (I think???)</p>

<p>But this doesn't have a slope, so how does this make sense? Obviously you would normally find the equilibrium through Qd = Qs, but what do I equal Qd to now?</p>
","<p>In these problems, you are generally dealing with identical firms - all of whom will supply the market according to their marginal cost curve.  If we were solving for a long run equilibrium the first thing we would do is get the supply curve - which can be done by finding the optimal mix of capital and labor via:</p>

<p>MPL/W = MPK/r</p>

<p>This will get you L = 4K.</p>

<p>In this situation you can skip to:
$$
Q = \sqrt{3}\sqrt{L}\\
L = Q^{2}/3
$$</p>

<p>Plug those into $C(Q) = Kr + Lw$</p>

<p>$$
C(Q) = 108 + 3Q^{2}\,
$$</p>

<p>The fixed cost is \$108 (but that is sunk in the short run, so the firm will ignore it), the variable cost is $3Q^{2}$, making the marginal cost $6Q$.  For the market, this will be $\frac{Q}{1.5}$ (the horizontal sum of all firms' production)</p>

<p>Marginal revenue in this market is just the price since we assume it is perfect competition, so setting market supply = demand gives you
$$
360 - 2Q = \frac{Q}{1.5}\\
Q = 135\,
$$</p>

<p>$Q/n = q$  tells us that each of the 9 firms must produce 15 units for the market to supply 135 total units.  According to the demand curve, the market price is \$90 when 135 units are sold.</p>

<p>Total surplus can be found by calculating the area of two triangles:</p>

<p>$$
CS = (1/2)135*(360-90) = \$18,225\\
PS = (1/2)135*(90) = \$6,075\\
TS = \$24,300\,
$$</p>
","6018"
"Calculating the impact of a per-unit Subsidy given to Consumers?","469","","<p>I am somewhat confused about the concept of calculating the prices payed by consumers and producers after a subsidy has been applied. </p>

<p>For example, say a good is being traded at 100 dollar at the market equilibrium. If the government were to give a 50 dollar subsidy to the consumer, would the price the consumer actually pays now (post-subsidy) be greater than 50$ due to differing elasticities? Would some of that subsidy be translated over to the price the producer receives? Or, would the price the consumer pays always be the (Equilibrium Price - Subsidy)? </p>

<p>Is the price reduction for the consumer (as a result of the subsidy) a function of the elasticity of demand or would the subsidy always fully fall on the consumer?</p>
","<p>This is a great question which economists have a pretty good answer to. Let's first suppose the market is in an equilibrium with no intervention at price $P^*$. </p>

<p>If there is a tax of value $t$ we have a new equilibrium with a consumer price $P^*_c$ and producer price $P^*_s$. These prices surely do not equal each other any more, and the difference of the two is not necessarily equal to the value of the tax. </p>

<p>You can think of a subsidy as a negative tax. </p>

<p>The change in consumer price due to a <em>marginal</em> tax or subsidy is called the <strong>pass through rate</strong>, $\rho$. For a sufficiently small tax, the relationship is $P^*_c=P^*+\rho\cdot t$. </p>

<p>Clearly, if the pass-through rate is one the consumer completely pays for the tax. If it is zero, the consumer does not at all pay for the tax. It is not impossible for $\rho$ to be negative or greater than one. </p>

<p>In <strong>perfectly competitive markets</strong> the pass through rate depends on the elasticity of demand, $\varepsilon_D$, and the elasticity of supply, $\varepsilon_S$. $$\rho=\frac{1}{1+\frac{\varepsilon_D}{\varepsilon_S}}$$</p>

<p>From this we can see that the pass through rate is larger when demand is more inelastic, and smaller when supply is more inelastic. This is where we get the adage ""the more inelastic side of the market bares the burden of a tax.""</p>

<p>For pass through to be equal to one, we either need (a) perfectly inelastic demand or (b) perfectly elastic supply. A lot of the time (b) can be satisfied by assuming constant marginal cost of production. </p>

<p>For imperfectly competitive situations, the pass through rate depends on firm conduct as well as the curvature of demand. I suggest Weyl and Fabinger ""Pass through as an economic tool"" 2013, Journal of Political Economy, publication for the details. </p>
","13581"
"Apply Ito's Lemma to exponential martingale","468","","<p>$\newcommand{\dd}{\, \mathrm{d}}$
Consider the exponential martingale,
$$
\xi_t^\lambda = \exp \left\{ - \int_0^t \lambda_s \dd z_s - \frac 12 \int_0^T \lambda_s^2 \dd s \right\},
$$
that is used in the statement of Girsanov's theorem (this martingale represents the Radon-Nykodym derivative $\frac{\dd \mathbb Q^\lambda}{\dd \mathbb P}$.).</p>

<p>Exercise 2.4 in Munk's book <em>Financial Asset Pricing Theory</em> deals with applying Ito's lemma to this process.</p>

<p>Suppose
$$
X_t = \frac 12 \int_0^t \lambda _s^2 \dd s + \int_0^t \lambda_s \dd z_s.
$$
Part (a) asks us to argue that $\dd X_t = \frac 12 \lambda_t^2 \dd t + \lambda_t \dd z_t.$ Part (b) asks, ""Suppose that the continuous-time stochastic process
$\xi = (\xi_t)$ is defined as $\xi_t = \exp\{-X_t\}$. Show that $\dd \xi_t = -\lambda_t \xi_t \dd z_t$.""</p>

<p>Informally, we can argue part (a) by applying Ito's lemma,
\begin{align*}
\dd X_t &amp;= \left( \frac 12 \lambda_t^2 + \lambda_t \dd z_t\right) \dd t + \lambda_t \dd z_t \\
  &amp;= \frac 12 \lambda_t^2 \dd t + \lambda_t \dd z_t,
\end{align*}
and arguing that $\dd z_t \cdot \dd t = 0$.</p>

<p>How do we solve part (b)?</p>
","<p>If we apply Ito's lemma,
then
\begin{align*}
\dd \xi_t &amp;= -\xi_t \dd X_t + \frac 12 \xi_t (\dd X_t)^2\\
  &amp;= -\xi_t \left(\frac 12 \lambda_t^2 \dd t + \lambda_t \dd z_t\right) + \frac 12 \xi_t \lambda_t^2 \dd t \\
  &amp;= -\xi_t \lambda \dd z_t.
\end{align*}</p>
","9546"
"What benefits do OPEC countries obtain by cutting oil supply?","468","","<p>It is unclear to a economic novice like me why OPEC is not cutting down production and raising oil prices. I have read several journalists commenting upon this on the internet but perhaps an economist can explain this current fact better. </p>
","<p>The OPEC scenario is quite well described by a market with <a href=""http://en.wikipedia.org/wiki/Cournot_competition"">Cournot Competition</a>. That is, while collusion would lead the highest total profits to the sum of the participants, each invididual participant would gain by increasing his production a little bit.</p>

<p>Without observing the quantity of each participant and proper enforcement, that's the outcome the model predicts - and reality concurs.</p>
","1626"
"Have there been instances where economists have advocated a trade embargo?","465","","<p>Due to Comparative Advantage, it is generally accepted among economists that free-trade is the best policy for a country and increases the standard of living for the citizens of that country and the country with which it trades.  </p>

<p>I have heard, however, that there are certain instances where it would be more beneficial (on the whole for that particular country) for the country to restrict trade with other nations.  Have there been instances like this where economists have advocated a trade embargo with another nation?  </p>
","<p>Free trade is, on the whole, one of the few otherwise controversial policy topics on which economists have near-perfect consensus. Historically, this consensus has long been strong in the English tradition (Hume, Smith, Ricardo, Mill), albeit less strong elsewhere. Famously, 1028 American economists signed an unsuccessful petition in 1930 begging Herbert Hoover not to approve the <a href=""http://www.wsj.com/articles/SB118593352401884265"" rel=""noreferrer"">Smoot-Hawley tariff</a>. If the <a href=""http://www.igmchicago.org/igm-economic-experts-panel/poll-results?SurveyID=SV_0dfr9yjnDcLh17m"" rel=""noreferrer"">IGM Economic Experts panel</a> is any guide, consensus remains firm today.</p>

<p>That said, off the top of my head, various cases in which <em>some</em> modern economists have departed from advising free trade include:</p>

<ul>
<li><strong><a href=""http://en.wikipedia.org/wiki/Import_substitution_industrialization"" rel=""noreferrer"">Import substitution</a></strong> and related protectionist <a href=""http://en.wikipedia.org/wiki/Developmentalism"" rel=""noreferrer"">development philosophies</a> in the early postwar era. These were never (as far as I know) advocated by many economists in the neoclassical tradition, but they certainly had support among influential other figures, notably <a href=""http://en.wikipedia.org/wiki/Ra%C3%BAl_Prebisch"" rel=""noreferrer"">Raúl Prebisch</a>; enough that they were put into action in many parts of the developing world, especially Latin America. The mainstream verdict on import substitution is that it was a costly failure, although there are notable heterodox dissenters like Ha-Joon Chang. <a href=""http://rodrik.typepad.com/dani_rodriks_weblog/2007/05/should_economis.html"" rel=""noreferrer"">Dani Rodrik</a> also has a slightly less heterodox record of free trade skepticism.</li>
<li>Cases of <strong>market power</strong>. Here, economists do not necessarily advocate departing from free trade in practice; but they do recognize that (in principle) it can be <em>individually</em> optimal for countries with either some monopoly or monopsony power to try to manipulate the terms of trade in their favor via trade restrictions (potentially either import or export tariffs). Many large, developed countries probably have some market power of this kind, and specialized commodity suppliers do as well. This observation is the basis of some <a href=""http://www.princeton.edu/~erossi/courses_files/Gatt.pdf"" rel=""noreferrer"">economic theories of trade agreements</a>, which are modeled as devices for countries to coordinate on a Pareto optimal free trade regime and overcome their individual desire to manipulate the terms of trade.</li>
<li><strong>Aggregate demand management</strong> when monetary tools are limited (due to the zero lower bound). Paul Krugman <a href=""http://krugman.blogs.nytimes.com/2009/02/01/protectionism-and-stimulus-wonkish/"" rel=""noreferrer"">has discussed how</a> protectionist clauses in stimulus plans could in principle be globally optimal, by allowing countries to retain more of the benefits of their own stimulus and thereby encouraging them to do more. Another case is where countries facing the zero lower bound could impose tariffs on unconstrained countries, in an attempt to redirect expenditure to demand-constrained economies. That said, Krugman still (mostly) favors free trade and doubts that the benefits of such a policy would overcome the cost to the global free trade regime.</li>
<li><p><strong>Distributional consequences</strong>. This is a common refrain in popular critiques of free trade: many pundits argue that even if trade is beneficial in some aggregate sense, its adverse distributional impact (e.g. hurting the already-suffering manufacturing workforce) negates the overall benefit. Indeed, in models where gains from trade arise from differing factor endowments, the whole point is that some factor (the domestically scarce but internationally not-so-scarce one) will lose; this is the idea behind the <a href=""http://en.wikipedia.org/wiki/Stolper%E2%80%93Samuelson_theorem"" rel=""noreferrer"">Stolper-Samuelson theorem</a>. </p>

<p>Traditionally, most economists have argued that it is better to have free trade and address any distributional or insurance objectives through the overall tax-and-transfer system. Whether not this conclusion holds in a formal model, however, depends on exactly what instruments are available to the government; it's conceivable that trade barriers would be an optimal second or third-best policy in some cases. The left-wing heterodox economist Dean Baker has <a href=""http://paecon.net/PAEReview/issue45/Baker45.pdf"" rel=""noreferrer"">strenuously argued</a> along these lines (though he has certainly not offered a formal model). More in the mainstream, an <a href=""http://www.princeton.edu/~ies/IESWorkshopS2011/HansonPaper.pdf"" rel=""noreferrer"">early version</a> of <a href=""http://economics.mit.edu/files/6613"" rel=""noreferrer"">Autor, Dorn, Hanson (AER 2013)</a> made a suggestive stab in this direction with a back-of-the-envelope calculation showing that the deadweight loss from transfers induced by Chinese trade was a substantial fraction of the theoretical gains from trade - though this calculation was rough and evidently removed from the published version. Notably, Autor was one of the few IGM panelists with an ""uncertain"" reply about the benefits from trade. </p></li>
</ul>
","1721"
"What happens to effective consumption and capital in the Ramsey/Cass-Koopmans(RCK) model when technological growth decreases?","465","","<p>Is the conclusion that both decline correct? Both long and short run.</p>

<p>Let $g_x$ denote growth rate of $x$, $g_c$ the growth rate of $\hat c$. In the model there is no depreciation so,</p>

<p>$$ g_c = \frac 1{\theta}[r - \rho - \theta g_x] $$</p>

<p>$$\dot {\hat k} = f(\hat k) - \hat c - (n+g_x)\hat k$$ </p>

<p>At steady state growth of $\hat k$ and $\hat c$ are both $0$. When that is the case:</p>

<p>$$\hat c^* = f(\hat k^*) - (n+g_x)\hat k^*$$</p>

<p>Also since $r = f'(k)$</p>

<p>$$f'(\hat k^*) = \rho + \theta g_x$$</p>

<p>Somehow based on these equations I reach the opposite conclusion, i.e. that $\hat c^*$ and $\hat k^*$ will increase rather than decrease if $g_x$ is reduced.</p>
","<p>When the (exogenous) rate of technological change/efficiency is smaller, the corresponding steady-state levels of consumption and capital per unit of effective labor, <em>increase</em>.  </p>

<p>For capital, we have</p>

<p>$$f'(\hat k^*) = \rho + \theta g_x \implies \frac {\partial}{\partial g_x}f'(\hat k^*) = \theta &gt;0$$</p>

<p>So if $g_x \downarrow \implies f'(\hat k^*) \downarrow \implies \hat k^* \uparrow$ due to decreasing marginal product of capital.</p>

<p>For steady-state consumption per unit of effective labor we have</p>

<p>$$\hat c^* = f(\hat k^*) - (n+g_x)\hat k^*$$</p>

<p>$$\implies \frac {\partial \hat c^*}{\partial g_x}= f'(\hat k^*) \frac {\partial \hat k^*}{\partial g_x} - \hat k^* - (n+g_x) \frac {\partial \hat k^*}{\partial g_x}$$</p>

<p>$$=[f'(\hat k^*) - n - g_x]\cdot \frac {\partial \hat k^*}{\partial g_x} - \hat k^* $$</p>

<p>The term in brackets is assumed positive, i.e. we have already assumed</p>

<p>$$f'(\hat k^*) = \rho + \theta g_x &gt; n + g_x \implies \rho &gt; n + (1-\theta)g_x$$</p>

<p>in order to exclude infinite utility. </p>

<p>Moreover, evidently $\frac {\partial \hat k^*}{\partial g_x} &lt;0$ so in all</p>

<p>$$\frac {\partial \hat c^*}{\partial g_x} &lt;0$$</p>

<p>Therefore, if $g_x \downarrow \implies \hat c^* \uparrow $.</p>

<p>See <a href=""http://down.cenet.org.cn/upfile/8/200751171644184.pdf"" rel=""nofollow"">Barro &amp; Martin</a>, ch. 2 page 102, where they discuss the  $g_x \uparrow$ case (in p. 101 they discuss the constraint on the parameters).</p>

<p><strong>Comment:</strong> This result may appear counter-intuitive, but a deeper examination of the model shows that if $g_x$ is lower, <em>utility per capita</em> is lower. Using ""consumption per unit of effective labor"" is a modeling tactic, what interests us is what happens per individual. So no, the model does <em>not</em> argue in favor of lower productivity/technology.</p>
","4661"
"Why the name for isoelastic utility?","465","","<p>If $u(x)=\frac{x^{1-\mu}}{1-\mu}$, then the elasticity defined as $\frac{\partial u}{\partial x}\frac{x}{u}=1-\mu$.</p>

<p>However, when we define $u(x)=\frac{x^{1-\mu}-1}{1-\mu}$ (usual def. for isoelastic utility), we have $\frac{\partial u}{\partial x}\frac{x}{u}=(1-\mu)\frac{x^{1-\mu}}{x^{1-\mu}-1}$. And this doesn't seem to give a constant elasticity. So, why do we call this utility isoelastic?</p>

<p>Any help would be appreciated.</p>
","<p>Iso-elastic utility is defined as a function $U(w)$ where for all $k \gt 0$ you have $$U(kw)=f(k)U(w)+g(k)$$ for some functions $f(k)$ and $g(k)$ independent of $w$, i.e. an affine transformation of the original utility function</p>

<p>This is <em>iso-</em> because this kind of utility function leads to identical (or at least proportionate) decisions: it means that the optimal risk/reward behaviour at given level of wealth $w$ is also optimal for another level of wealth $kw$ if you multiply all the original investments by $k$.  For example, if at some wealth level you would put a third of it into a particular risky investment and two-thirds into a particular safe investment, then with an iso-elastic utility function you would do the same with at any wealth level   </p>

<p>Both your formulations are iso-elastic in this sense, since they only differ by a constant $\frac{1}{1-\mu}$ and so lead to identical distribution decisions.  The difference between them is that the first has $u(0)=0$ and $u(1)=\frac{1}{1-\mu}$ while the second has $u(1)=0$, and since that difference has no real-life implications it might be unreasonable to claim the two utility functions had different properties  </p>

<p>Those who use the second formulation often associate it with a logarithmic utility function as the limit function as $\mu \to 1$.  This limit cannot be done without subtracting the $\frac{1}{1-\mu}$ (no longer a constant, since $\mu$ is changing), so they take the second formulation for arithmetical convenience</p>
","14753"
"Real world example of using difference quotient vs. derivative","464","","<p>When would you use the difference quotient in an economic model rather than the derivative to assess the change in some endogenous variable?  Real world examples seem to be lacking in textbooks on basic mathematical economics. </p>
","<p>You can see the applications in microeconomics. A tiny example could be on elasticity of demand. </p>

<p>Let's say </p>

<p>$$ D = \frac{tC}{P+t} $$</p>

<p>where $P, t, C$ are respectively price, tax and constant. If you like to see the effect of tax change on demand you can use the difference quotient ;</p>

<p>$$\Delta D = \frac{(t + \Delta t C)}{P + t + \Delta t} - \frac{tC}{P + t}$$</p>

<p>I skip the intermediary calculations. This one yields ;</p>

<p>$$\frac{\Delta P}{\Delta t} = \frac{P.C}{(P+t)^{2}+\Delta t.(P+t)}$$</p>

<p>Hope that it helps.</p>
","7012"
"Should Costs of Travel to Buy Goods be Regarded as Transaction Costs?","463","","<p>Within the approach of New Institutional Economics associated with Oliver Williamson and others, emphasis is placed on <em>transaction costs</em> as a key factor in explaining why different forms of economic organisation arise in different circumstances.  Transaction costs have been defined, eg <a href=""https://www.auburn.edu/~johnspm/gloss/transaction_costs"">here</a>, as including search and information costs, bargaining and decision costs, and policing and enforcement costs.</p>

<p><em>Question</em>: Suppose I go to a supermarket that I know well, buy branded packaged goods of kinds that I have bought many times before, and transport the goods home.  Should the cost of my travel to the supermarket and transporting the goods home, in this situation in which any elements of search, information gathering, etc are minimal, be regarded as a transaction cost?</p>
","<p>Since it was mentioned in an another answer let's clear this first: whether the transportation (and its time and monetary costs) should be associated with the intended consumption of the good you are going to purchase, or it can be considered as consumption on its own, depends on your subjective view of it: do you derive any form of pleasure by the trip itself? If yes, at least part of it should be considered consumption <em>per se</em>.</p>

<p>The consensus among economists appears to be that most of such travel is not considered by the consumers as utility-enhancing per se (although trends like ""family-shopping on Saturday"" may say a different story), and so it should be interpreted in a different way. </p>

<p>In the field of Industrial Organization, the good's distance from the consumer has been often treated as an aspect of <em>product differentiation</em>. </p>

<p>You could certainly treat it as a ""transaction cost"", by suitably define the scope of the concept. Personally I prefer to think of it as an <em>access</em> cost. I hit upon this concept in a little side-research I did in hedonic-price analysis.</p>

<p>If you start to think about it, all packaging and transportation costs <em>from the supplier to the shop</em> are also ""access costs"" from the point of view of the consumer. They don't provide any <em>direct</em> utility to him -they are obligatory costs that end up increasing the price, so that the consumer is able to acquire the good and enjoy the services/utility of the good itself.</p>

<p>Think computers: only the materials themselves and the technology embodied in them provide utility to you (plus maybe the brand). But the price includes all shorts of overheads, like the access costs I mentioned, or marketing costs (that can be seen as information costs or as the price to pay for competition and the innovation and product variety that brings along), etc. </p>
","9361"
"Dealing with Missing Data when Testing the CAPM","456","","<h1>Question</h1>

<p>How should I deal with missing data when trying to test the CAPM? Specifically, there are some stocks that are newly listed and/or delisted at any time. I don't want to exclude assets for which I don't have complete data because this would create a kind of survivor bias.  I know that CRSP provides delisting returns that should, but how do I manage the missing data in practice? For example, in the unconstrained model, the procedure looks like this:</p>

<p><img src=""https://i.stack.imgur.com/6GpYT.png"" alt=""enter image description here""></p>

<p>(More details about the procedure are given below.) Now, if I wanted to take a bunch of random stocks at some point in time and look at them over some time period, what should I do with the values ($Z_it$) for these stocks that aren't listed at time $t$. Should I use the de-listing returns where appropriate and then fill in zeros everywhere else? But this would do weird things to the beta of the stock. Should I try to constrain the beta (the factor loadings) of the stocks to be zero in all the places where the stock is unlisted? This would require me to change the model (requiring a model that somehow allows for time varying factor loadings). How do people usually handle this problem? Is there an easy way (even if it is slightly more incorrect)?</p>

<h1>Some Detail about the Estimation Procedure</h1>

<p>For concreteness, suppose I wanted to test the CAPM using the time series regression framework outlined in chapter 6 of Campbell, Lo, and MacKinley (The Econometrics of Financial Markets). Some of the assumptions are listed in this image:
<img src=""https://i.stack.imgur.com/37Btm.png"" alt=""enter image description here""></p>
","<p>Easiest fix: if you're worried about it you should <strong>value weight your results</strong>. This is suggest by, for instance, <a href=""http://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1995.tb05171.x/abstract"" rel=""nofollow"">Kothari, Shanken and Sloan (1995)</a>. Firms that are delisted tend to have extremely small market cap, so value weighting gives them very little impact on summary statistics. Delisted returns should also be used, although I'm not sure how much impact they'll have. I've seen the delisted return stuck into the month after a stock ceases to be traded.</p>

<p>In finding $\beta$'s, I tend to see the regression used only on those dates for which the stock return is observed. The correction really comes in value weighting summary statistics afterwards. Whether all this is ""correct"" or just the practice I've seen is not something I'm sure about.</p>

<p><strong>Edit:</strong> here's a <a href=""http://www.jstor.org/stable/2329566"" rel=""nofollow"">different perspective</a>.</p>
","558"
"What utility functions are equivalent to additive functions?","456","","<p>Call a utility function $u(x,y)$ <em>additive</em> if there exist functions $v_x,v_y$ such that:
$$u(x,y)=v_x(x)+v_y(y)$$</p>

<p>Consider the function $u(x,y)=xy$. It is not additive, but, it can transformed using a positive-monotonic-transformation (PMT) to the function: $u'(x,y)=\log u(x,y) = \log{x}+\log{y}$, and the function $u'$ is additive.</p>

<p>My question is: what conditions on a function $u(x,y)$ guarantee that it can be transformed using a PMT to an additive function?</p>

<p>I.e, if I see a function $u(x,y)$, how can I know whether it represents a preference relation which can also be represented by an additive utility function?</p>
","<p>Ted Bergstrom has <a href=""http://www.econ.ucsb.edu/~tedb/Courses/GraduateTheoryUCSB/separabilitynotes.pdf"" rel=""nofollow"">Lecture Notes on Separable Preferences</a> that seem to have what you are looking for. For example:</p>

<blockquote>
  <p><strong>When are preferences additively separable?</strong> </p>
  
  <p>The most useful necessary and sufficient condition for preferences to be additively
  separable is that every subset of the set of all commodities is
  separable. The proofs that I know of for this proposition are a bit
  more elaborate than seems appropriate here. A somewhat more general
  version of this theorem can be found in a paper by Gerard Debreu (Topological methods in cardinal utility).
  Debreu’s paper seems to be the first satisfactorily general solution
  to this problem. Other proofs can be found in (Foundations of Measurement) and (Utility theory for decision making).</p>
</blockquote>
","6916"
"The reasons why rouble is collapsing","455","","<p>What can you people say about the reasons why rouble is collapsing?
Which one is the main?</p>
","<p>The answer is very clear when you look at Russia's monetary statistics. The Central Bank of the Russian Federation has a very good site, and you can see them here:</p>

<p><a href=""http://www.cbr.ru/eng/statistics/credit_statistics/MS.asp?Year=2014"" rel=""nofollow noreferrer"">Russian Money Supply (M2)</a></p>

<p>or courtesy of the St. Louis Federal Reserve:</p>

<p><img src=""https://i.stack.imgur.com/1CJKu.png"" alt=""Russian money Supply""></p>

<p>They provide the annual expansion rate which is nice. Historically, Russia's money supply has always been an extreme outlier compared to other European countries. Compared to the USA's money supply, which roughly doubles every 10 years, Germany which was down at 1.3x/decade last time I checked, Russia's typically increases by 20x a decade.</p>

<p>The open research question is why currencies tend to collapse suddenly, rather than over time, but the underlying reason is always found in their relative expansion rates. I would suspect that this particular episode has also been triggered by the recent drop in oil prices, since that will put additional pressure on oil exporters like Russia, due to the drop in income from exports.</p>
","530"
"Thesis-advisor/student pairs that won the nobel prize","455","","<p>I am trying to compile a list of winners of the Nobel memorial prize in economics whose thesis advisor also won the prize.</p>

<p>So far I have</p>

<p><code>Eric Maskin (advisor) / Jean Tirole (student)</code></p>

<p>Are there other pairs?</p>
","<p>This seemed like a fun exercise, so using just the info on <a href=""https://en.wikipedia.org/wiki/List_of_Nobel_Memorial_Prize_laureates_in_Economics"" rel=""nofollow noreferrer"">Wikipedia</a>, I was able to compile this:</p>

<p><a href=""https://i.stack.imgur.com/2uT9x.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2uT9x.png"" alt=""Nobel Advisors and Students""></a></p>

<p><strong>Honourable mentions</strong>, who I classify as economists who have at least two students who have won the Nobel include:</p>

<ol>
<li>Wilson (Roth and Holmstrom)</li>
<li>Lovell (Prescott and Mortensen)</li>
<li>Tucker (Nash and Shapley)</li>
<li>Cassel (Myrdal and Ohlin)</li>
</ol>

<p>Another interesting fact worth mentioning is that, while Krugman’s advisor, Dornbusch, did not win the Nobel, Dornbusch’s supervisor, Mundell, did. A similar comment applies so Lovell, who was Leontief's student, and had two students who won the Prize.</p>

<p>More interesting observations: predictably, for the vast majority of these pairs, the advisor won the prize before the student. Exceptions are Leontief and Samuelson; Fama and Scholes; and Hurwicz and McFadden.</p>

<p><strong>Other triplets:</strong> </p>

<ol>
<li>Miller-Fama-Scholes</li>
<li>Leontief-Samuelson-Merton</li>
<li>Leontief-Solow-Akerlof/Diamond/Stiglitz</li>
<li>Leontief-Schelling-Spence</li>
</ol>

<p>We even have a <strong>quadruplet</strong>: Kuznets-Friedman-Markowitz-Sharpe.</p>
","19029"
"Simulating Real Business Cycle","453","","<p>Basically I need to replicate Hartley's 'A User's Guide to Solving Real Business Cycle Models' (<a href=""http://www.econ.ucdavis.edu/faculty/kdsalyer/LECTURES/Ecn235a/Linearization/ugfinal.pdf"" rel=""nofollow noreferrer"">http://www.econ.ucdavis.edu/faculty/kdsalyer/LECTURES/Ecn235a/Linearization/ugfinal.pdf</a>). Specifically, I want to simulate the dynamical system implied by the model which is specified as follows:</p>

<p><img src=""https://i.stack.imgur.com/2LuOx.png"" alt=""enter image description here""></p>

<p>where $c$ is consumption, $h$ is labour supply, $k$ is capital, $z$ is the autoregressive technological process, $y$ is the output and $i$ is investment.</p>

<p>I simulate it using the following logic: say at time $t$, everything is at steady state and all the values are 0, from which we have $k_{t+1}$. Then, at $t+1$ by giving a shock to the system through $\varepsilon$, i solve for $c_{t+1}$ and $h_{t+1}$ (as I have the 'shocked' $z_{t+1}$ and previously obtained $k_{t+1}$. Then, I plug those two to retrieve the rest, namely - $y_{t+1}, i_{t+1}, k_{t+2}$ and repeat the process.</p>

<p>Unfortunately, I get an explosive process which doesn't make sense:</p>

<p><img src=""https://i.stack.imgur.com/weeDr.png"" alt=""enter image description here""></p>

<p>I also include R code that is used to simulate this:</p>

<pre><code>n&lt;-300

data.simulated &lt;- data.table(t = 0, zval = 0, cval = 0, hval = 0, kval = 0, yval = 0, ival = 0)
data.simulated &lt;- rbind(data.simulated, data.table(t = 1, kval = 0), fill = TRUE)

for (ii in 1:n){

  ##initial shocks
  eps &lt;- rnorm(1, mean = 0, sd = 0.007)
  zt1 &lt;- data.simulated[t == ii - 1, zval]*0.95 + eps
  kt1 &lt;- data.simulated[t == ii, kval]

  ##solve for ct, ht
  lmat &lt;- matrix(c(1, -0.54, 2.78, 1), byrow = T, ncol = 2)
  rmat &lt;- matrix(c(0.02 * kt1 + 0.44 * zt1, kt1 + 2.78 * zt1), ncol = 1)

  solution &lt;- solve(lmat, rmat)
  ct1 &lt;- solution[1, ]
  ht1 &lt;- solution[2, ]

  ##now solve for yt1 and kt2 and it1
  yt1 &lt;- zt1 + 0.36 * kt1 + 0.64 * ht1
  kt2 &lt;- -0.07 * ct1 + 1.01 * kt1 + 0.06 * ht1 + 0.1 * zt1
  it1 &lt;- 3.92 * yt1 - 2.92 * ct1

  ##add to the data.table the results
  data.simulated[t == ii, c(""zval"", ""cval"", ""hval"", ""yval"", ""ival"") := list(zt1, ct1, ht1, yt1, it1)]
  data.simulated &lt;- rbind(data.simulated, data.table(t = ii + 1, kval = kt2), fill = TRUE)
}


a &lt;- data.simulated[, list(t, cval, ival, yval)]
a &lt;- data.table:::melt.data.table(a, id.vars = ""t"")
ggplot(data = a, aes(x = t, y = value, col = variable)) + geom_line()
</code></pre>

<p>Sy my question is simple - is the system specified in the paper is inherently unstable and ergo the results, or did I make a mistake somewhere?</p>
","<p><strong>Explosiveness</strong></p>

<p>The paper contains an error, which causes the explosive dynamics in your simulation (although presumably the underlying computations in the paper were correct). The equilibrium condition derived from eigenvalue decomposition is contained in the third row of matrix $Q^{-1}$ on page 12 of the paper, with variables ordered as $(c,k,h,z)$ (I'll drop tildas, so all lowercase variables are to be understood as log-deviations). Comparing with eqn. (16) on p. 13, we see that coefficients for $k$ and $h$ are switched, and so the correct condition is</p>

<p>$$
c_t = 0.54 k_t + 0.02 h_t + 0.44 z_t
$$</p>

<p><strong>Simulation</strong></p>

<p>First, we can express consumption and labor as linear function of state variables (no need to solve the system at each step of the simulation). The intertemporal and intratemporal equilibrium conditions can be written as</p>

<p>$$
\begin{bmatrix}1 &amp; -0.02 \\ 2.78 &amp; 1 \end{bmatrix} \begin{bmatrix} c_t \\ h_t\end{bmatrix} = \begin{bmatrix} 0.54 &amp; 0.44 \\ 1 &amp; 2.78 \end{bmatrix} \begin{bmatrix} k_t \\ z_t\end{bmatrix}
$$ </p>

<p>so after multiplying by an inverse we get</p>

<p>$$
\begin{bmatrix} c_t \\ h_t\end{bmatrix} = \begin{bmatrix} 0.53 &amp; 0.47 \\
-0.47 &amp; 1.47 \end{bmatrix} \begin{bmatrix} k_t \\ z_t\end{bmatrix}
$$</p>

<p>Next, transition for states can be written as</p>

<p>$$
\begin{bmatrix} k_{t+1} \\ z_{t+1} \end{bmatrix} = \begin{bmatrix} -0.07 &amp; 0.06 \\ 0 &amp; 0 \end{bmatrix} \begin{bmatrix} c_t \\ h_t\end{bmatrix} + \begin{bmatrix} 1.01 &amp; 0.1 \\ 0 &amp; 0.95 \end{bmatrix} \begin{bmatrix} k_t \\ z_t\end{bmatrix} + \begin{bmatrix} 0 \\ \epsilon_{t+1}\end{bmatrix}
$$</p>

<p>which can be reduced by substuting for control variables to</p>

<p>$$
\begin{bmatrix} k_{t+1} \\ z_{t+1} \end{bmatrix} = \begin{bmatrix} 0.94 &amp; 0.16 \\ 0 &amp; 0.95 \end{bmatrix} \begin{bmatrix} k_t \\ z_t\end{bmatrix} + \begin{bmatrix} 0 \\ \epsilon_{t+1}\end{bmatrix}
$$</p>

<p>Now the simulation should be trivial, here's a Matlab/Octave example:</p>

<pre><code>T = 200;
X = zeros(2,T);
for i=2:T
    X(:,i) = [0.94 0.16; 0 0.95] * X(:,i-1) + [0; 0.007*randn()];
end
Y = [0.53 0.47; -0.47 1.47] * X;
figure
plot(1:T, [X; Y])
legend('k','z','c','h')
</code></pre>

<p><img src=""https://i.stack.imgur.com/MPNc9.png"" alt=""Simulation""></p>

<p>Of course in practice, you should probably recompute the whole solution, including the eigenvalue decomposition, so that you would be able to change parameters, etc.</p>
","4786"
"What exactly is the difference between the PPP (""purchasing power parity"") and LOOP (""law of one price"")?","453","","<p>For PPP &amp; LOOP: e = EP/P* = 1
So both are valid if goods in the US and EU cost the same in $ for example.
But then, what exactly is the difference between both?</p>
","<p>PPP uses the price level, the price of the consumer basket. The price level can be identical without all prices being identical. An example:</p>

<p>Consider a consumer basket with just two goods and assume the weight of both goods in the basket is one half. If $p_1 = p_2 = 4$ then the price of the consumer basket is
$$
P = \frac{1}{2} \cdot p_1 + \frac{1}{2} \cdot p_2 = 4.
$$
However you get the same price level if you have $p_1 = 3,  p_2 = 5$.</p>

<p>So you can have two countries with identical price levels but differing prices. The converse of course is not possible. Thus LOOP implies PPP but PPP does not imply LOOP.</p>
","13973"
"When is a utility representation differentiable?","453","","<p>We know that if we start with a connected, separable product space $V_1\times,...,\times V_n$ and a complete, transitive, and continuous preference relation $\succsim$ on this product space, that there exists a continuous! utility representation $u:V_1\times,...,\times V_n\rightarrow \mathbb{R}$. However, continuity $\neq$ differentiability. Thus, I am curious under which conditions there even exists a differentiable utility function.</p>

<p>My first idea would be to at least restrict the product space to $\mathbb{R}^n$, but there may be counterexamples. For example, if $n=1$ and $u$ is the Weierstrass function, $u$ is continuous, but not differentiable.</p>

<p>Since in Economics we constantly work with differentiable utility, I am wondering which assumptions are necessary to ensure differentiability.</p>
","<p>A continuous, transitive, complete, convex, and locally non-satiated preference on an open convex subset $V$ of some $\mathbb{R}^l$ has an $r$-times continuously differentiable utility representation with no critical points if and only if the space $I=\{(x,y)\in V\times V\mid x\sim y\}$ is a $C^r$-manifold.</p>

<p>This result is essentially Proposition 2.3.9. in the book ""The Theory of General Economic Equilibrium: A Differentiable Approach"" by Andreu Mas-Colell. Actually, the result there replaces convexity of $V$ and the preference relation to be represented by the weaker condition that all indifference curves are connected.</p>

<p>I'm not aware of any more elementary approach to the problem.</p>
","18327"
"Book Recommendation for Microeconometrics of Discrete Data","452","","<p>I am looking for a few good books pitched at different levels to help analyse discrete data.</p>

<p>Specifically: Specification, Estimation and the application of econometric methods to model discrete choices by individuals, households or firms.</p>
","<p>Personally, for choice analysis, I like</p>

<ol>
<li><a href=""http://eml.berkeley.edu/books/choice2.html"" rel=""nofollow"">Discrete Choice Methods with Simulation</a> by Ken Train (pdf)</li>
<li><a href=""http://www.cambridge.org/es/academic/subjects/economics/econometrics-statistics-and-mathematical-economics/applied-choice-analysis-primer"" rel=""nofollow"">Applied Choice Analysis: A Primer</a> by Hensher and Greene (2nd edition, book)</li>
<li><a href=""http://pages.stern.nyu.edu/~wgreene/DiscreteChoice/Readings/OrderedChoiceSurvey.pdf"" rel=""nofollow"">Modeling Ordered Choices</a> by Hensher and Greene (pdf)</li>
<li><a href=""http://www.stata.com/bookstore/regression-models-categorical-dependent-variables/"" rel=""nofollow"">Regression Models for Categorical Dependent Variables Using Stata</a> by Long and Freese (3rd edition, book)</li>
</ol>

<p>(1) is a fairly short, readable classic. (2) is much more introductory, with lots of intuition, though it devotes a lot of space to the nlogit software. (3) has the same features as (2), but for a more focused set of topics. (4) is also pretty introductory and focuses on using Stata. It is perhaps the least ""economisty"" of the four, but still quite good.</p>

<p>For count data, I like Cameron and Trivedi's <a href=""http://www.econ.ucdavis.edu/faculty/cameron/racd2/"" rel=""nofollow"">count data book</a>, followed by <a href=""http://www.springer.com/us/book/9783540776482"" rel=""nofollow"">Winkelmann's</a>.</p>

<p>The books you have listed are good, particularly Wooldridge, but they cover much more ground than just discrete data at the expense of depth. </p>
","4535"
"Continuous preferences definition","452","","<p>Suppose consumption set $X=R_{+}^N$. According to the definition preferences are continuous if for any $x\in X$ sets $(y\in X:x\succeq y)$ and $(y\in X:y\succeq x)$ are closed. It is clear that preferences represented by utility function $u(k_{1},k_{2})=k_{1}+k_{2}$ are continuous. But now lets take some bundle x=(1,1). Then set $(y\in X:y\succeq (1,1))$ is not closed as it approaches infinity. My question is how to handle with this contradiction?</p>
","<p>It appears that you are conflating a ""closed interval"" with a ""closed set"". Certainly, (multidimensional) closed intervals are closed sets, but the concept of a closed set is wider. </p>

<p>A closed set is, well, only closed, and not necessarily bounded. </p>

<p>I understand that the everyday-meanings of the terms ""closed"" and ""bounded"" can indicate that ""being closed is a stronger property than being bounded"" (i.e. that being closed implies being bounded), but this is not true in mathematics. Neither property implies the other.  </p>

<p>Yes, a set can be bounded and yet it may not be closed. Standard example: Consider the set of <em>rational</em> numbers  in $[1,3]$ . This is a bounded set. Now consider the sequence of rational numbers</p>

<p>$$x_{n+1} = \frac {x_n}{2} +\frac {1}{x_n},\;\; x_0 = 3$$</p>

<p>The sequence remains in the $[1,3]$ interval, but its <em>limit</em> is $\sqrt 2$, which is not rational. So this set of rationals in $[1,3]$ is bounded but it is not closed, because it does not contain a limit point of a sequence that can be constructed in it, stay in it, except its limit point.</p>

<p>So, what ""closed set"" means then in mathematics? There are various ways to look at it:</p>

<p>A closed set is a set whose complement is open.<br>
A closed set is a set that coincides with its ""closure"".<br>
A closed set is a set that contains all its limit points.</p>

<p>Try them out mentally and stick with what is more intuitive to you.</p>
","11095"
"What textbook can I use to understand engineering economics?","452","","<p>I'm an Engineering Physics student and this semester I took the course ""Engineering Economics"" as a requirement to complete the management sciences credits in my program, I need a good textbook to understand engineering economics, thanks. </p>
","<p>These are the recommended books for our Engineering Economics university course:</p>

<p><strong>Main Textbook</strong></p>

<p>N. M. Fraser and E. M. Jewkes, Engineering Economics: Financial Decision Making for Engineers, 5th edition, Pearson, Toronto, Ontario, 2013</p>

<p><strong>Supplementary Resources</strong></p>

<p>D. G. Newnan, J. Whittaker, T. G. Eschenbach and J. P. Lavelle, Engineering Economic Analysis, 3rd
edition, Don Mills, Toronto, Ontario, 2014.</p>

<p>J. A. White, K. E. Case and D. B. Pratt, Principles of Engineering Economic Analysis, 5th edition, Hoboken,
NJ, USA, 2010.</p>

<p>I found the main textbook easy to follow. Hope this helps!</p>
","10749"
"Pareto set and contract curve","451","","<p>I am having some troubles in distinguishing, from a theoretical point of view, between contract curve and Pareto set. </p>

<p>I have looked around books and internet, and I have found that contract curve should be a subset of Pareto set, i.e. the locus of Pareto efficient allocations that can occur as a result of mutually beneficial trading between agents.</p>

<p>Am I right or there is something I did not understand properly? Someone can give me a formal definition of the two objects (if there is some differences)? </p>
","<p>Let $N$ denote the set of consumers. Given a set of possible allocations $A$, an allocation $a$ is Pareto-optimal if no allocation $a'$ exists for which
$$
\forall i \in N: a \preceq_i a'
$$
and
$$
\exists j \in N: a \prec_j a'.
$$
So Pareto-optimality exists without any notion of property rights, you don't need to know the initial endowment is, who has what in the beginning. Given an initial endowment $\omega$ an allocation $a$ is individually rational for consumer $i$ if
$$
 \omega \preceq_i a.
$$
An allocation is in the contract curve if and only if it is individually rational for all consumers and is also Pareto-optimal. If the allocation $a$ is not individually rational for a given consumer $i$, he would not sign the contract which would take him there from $\omega$.</p>

<p>Thus the contract curve is indeed a subset of all Pareto-optimal allocations. Unless the initial endowments are given, it is not possible to determine the contract curve.</p>
","11451"
"What statistics and linear algebra book do i need before reading Hayashi's econometrics","451","","<p>What statistics and linear algebra book do I need before reading <a href=""http://fhayashi.fc2web.com/hayashi_econometrics.htm"" rel=""nofollow"">Hayashi's Econometrics?</a></p>

<p>Basics linear algebra book seems too simple for the linear algebra part, and 
Casealla's statistical inference is missing out detail/too basic for the statistical part</p>
","<p>The <strong>Linear algebra</strong> part should not worry you, it is just basic linear algebra plus familiarizing yourself a bit with <a href=""http://en.wikipedia.org/wiki/Matrix_calculus"">differentiation of vectors and matrices</a> (and for some chapters, visualizing the <a href=""http://en.wikipedia.org/wiki/Kronecker_product"">Kronecker product</a>).  Hayashi goes some length into writing out explicitly large matrices, which is virtually with no-precedent (see eg. pages 267, or 288), something that eventually facilitates understanding -as long as you don't back out from a matrix half a page large, but you really <em>look</em> at it.</p>

<p>What you should really go slow over upon is Hayashi's <strong>notation</strong>, which is non-standard in many places. So <em>don't expect to understand through familiar notation</em>. Be prepared for that and ""read"" carefully every symbol and its role. Many people's discomfort with this book is due to the notation, but they don't realize it.  </p>

<p>As for the <strong>Statistics part</strong>: In Econometrics, since we deal almost always with non-experimental, observational data, a large part of Statistics (originating usually in Biostatistics) do not really enter (our) picture. For example, apart from proving that under certain conditions the OLS estimator is best linear unbiased, you won't see much regarding the issues of minimum variance estimation or sufficient statistics. We don't even discuss the Exponential Family of distributions and the concept of Generalized Linear Models. Also, in statistical Hypothesis testing the Fisherian spirit prevails (oozing through the Neyman-Pearson apparatus), meaning, among other things, that issues like the ""power of the test"" are not so often considered.</p>

<p>Moreover ""frequentist Econometrics"", which is what Hayashi presents, are considerably lighter than Bayesian Econometrics in terms of the Algebra of Random Variables and probability theory.</p>

<p>What really matters is a good familiarity with <em>basic</em> Asymptotic Theory and Stochastic Processes (for the Time Series part). Although Hayashi in most cases just states results, providing references for the proofs, nevertheless it would be good to feel comfortable with asymptotic results and properties, because in most cases, <em>it will be all your estimators will possess</em>. For this part, I will once more advocate A. Spanos' book, <a href=""http://www.cambridge.org/lt/academic/subjects/economics/econometrics-statistics-and-mathematical-economics/probability-theory-and-statistical-inference-econometric-modeling-observational-data"">Probability Theory and Statistical Inference - Econometric Modeling with Observational Data</a>. It is a valuable book, Hayashi or not Hayashi. It is Statistics with the Econometrics graduate student in mind.  </p>

<p>In case you want some more specific Time Series material, Hamilton's <a href=""http://press.princeton.edu/titles/5386.html"">Time Series Analysis</a> remains a standard reference.</p>

<p>Finally, regarding <strong>Unit-root Econometrics and Co-Integration</strong>, the subject is inherently advanced, and I think Hayashi has done a good job in collecting and presenting the very basics.</p>
","1691"
"What determines the outcome of a price war, and why isn't that outcome reached instantaneously?","450","","<p>Mary is making a hefty profit manufacturing and selling widgets. Jim has some money laying around and he is trying to figure out if he shouldn't start manufacturing some widgets too. </p>

<p>In this example assume that the marginal cost to produce a widget is zero (time, money, etc are all close enough to zero to be indistinguishable), but the cost of making a widget manufacturing plant is quite high. </p>

<p>Also assume that the market for widgets is fairly centralized. There are two bins with widgets in them and consumers can purchase their widgets from either bin. They cannot be resold, however. There are laws against that for whatever reason, and they are ruthlessly enforced. You may only sell widgets that you manufacture yourself.</p>

<p>What does Jim decide? And if he decides to enter the widget business, what is the eventual price per widget and how long does it take to reach that price?</p>

<p><strong>More (but not too) formally:</strong> 
Our situation can be modeled by a few different games,</p>

<p>Case 1: assume the rules of the price war are</p>

<p>players take turns setting a new, lower price from $\mathbb R$ or passing. When both players pass, the prices are locked and the market is allowed to run for t.</p>

<p>in this case the optimal strategy to set your price to whatever price your opponent sets, if the prices are already equal, then pass.</p>

<p>Case 2: </p>

<p>The market is allowed to run for time t after each player sets a (lesser or equal) price, they take turns setting prices, and they choose prices from $\Bbb Z$.</p>

<p>Here the optimal strategy is in fact no different. if the price starts at $p1$, and the sharing strategy is $S$, then there exists some $t$ such that for all $t'$>$t$ $$EV(S,S,t)=\frac{t*p}{2} &gt;tk(p-1) &gt; EV(S,S',t)$$ for all $p,k,S'$</p>

<p>Case 3: </p>

<p>Both players set prices in each timestep t without the information of the price their opponent sets in that time step, and the market is run. </p>

<p>In this case, no pure strategy is guaranteed to exist, because the information is not perfect. I don't know what the Nash equilibrium would end up being, nor do I know that there is any reason to suspect that it converges (as t -> 0) to the same price as the previous two cases, despite the game seeming to do so.  </p>

<p>So I guess the question becomes, why does competition even exist at all in this market, and since all of these scenarios seem to converge towards the reality. ?</p>
","<p><strong>Answer to question</strong></p>

<p>If we take your assumptions literally, Jim will decide not to enter the widget business. For suppose he did incur the cost of entry and that Mary is selling at price $p_m$. Jim can only sell to consumers if his price $p_j\leq p_m$. The best price for Jim is $p_m-\epsilon$ (where $\epsilon$ is some very small, positive amount). But this would leave Mary with no sales, so she will have an incentive to reduce her price to $p_j-\epsilon$. This is the price war you describe and it will result in both parties reducing their price to marginal cost (i.e. zero—this is known as <a href=""https://en.wikipedia.org/wiki/Bertrand_competition"" rel=""nofollow"">Bertrand competition</a>).</p>

<p>Since there are no frictions in your model, this will all happen very quickly. Moreover, because a price of zero implies zero profits, Jim has no incentive to incur the cost of entry in the first place, so he will instead opt to stay out of the market.</p>

<hr>

<p><strong>Effect of relaxing assumptions</strong></p>

<p>This is obviously quite a stylised result owing to the stark assumptions of the model. But it makes a good foundation for thinking about some more realistic settings. For example:</p>

<ul>
<li><p>If Mary's factory has a marginal cost $c_m$ and Jim has a patent on a new technology that implies cost $c_j&lt;c_m$ then Jim can profitably set a price below the lowest price Mary is willing to set. Good news: if someone invents a more efficient technology they can enter the market and displace the older, less efficient technology.</p></li>
<li><p>Suppose that the factory has a monthly fixed maintenance cost. If Mary is a small, credit-constrained independent firm and Jim is a huge conglomerate with large reserves of cash then Jim can enter and practice <a href=""https://en.wikipedia.org/wiki/Predatory_pricing"" rel=""nofollow"">predatory pricing</a>. If he is patient enough, he can enter the market, set $p_j=0$, and wait for Mary to run out of money. She will then leave the market and Jim becomes a profitable monopoly. This kind of anti-competitive behaviour is illegal in most jurisdictions (yes, there are laws against setting too low a price!).</p></li>
<li><p>Suppose that Mary's widgets are blue and Jim's are pink. Consumers have an idiosyncratic preference for either blue or pink widgets. Then both firms can set a positive price and sell to the consumers who like their colour more. The more are products <em>differentiated</em> the more there is scope for both firms to exist profitably in the industry and Jim may find it worthwhile to enter. This is why firms talk so much about differentiation and unique selling points. There are various ways to model this in economics. <a href=""http://www.people.fas.harvard.edu/~zlai/teaching/AppliedIO_Note3_HotellingSalop.pdf"" rel=""nofollow"">Here is an example</a>.</p></li>
</ul>

<hr>

<p><strong>More formally, $p_j=p_m=0$ is the unique pure strategy Nash equilibrium</strong></p>

<p>To be slightly more formal, let us check that $p_m=p_j=0$ is indeed a (Nash) equilibrium of the subgame in which both firms simultaneously set $p\in\mathbb{R}$ with the lowest priced firm capturing the entire (finite) demand. Neither party can profit by deviating to $p&lt;0$ as this yields negative profits. A deviation to any $p&gt;0$ results in the rival firm having a lower price so demand (and profits) are zero---again not profitable. Thus, there is no profitable deviation and $p_i=p_m=0$ is <em>an</em> equilibrium.</p>

<p>Is there another pure strategy equilibrium with some $p&gt;0$? The answer is no. Consider the three possibilities and observe how a profitable deviation can be constructed for each:</p>

<ul>
<li>$p_m&gt;p_j$. In this case $j$ could increase his price to some $p_j'\in(p_j,p_m)$ without losing any demand. Such a $p_j'$ exists by the connectedness of the real line.</li>
<li>$p_m=p_j=p$. In this case at least one of the firms must be capturing less than all of the consumers. But by deviating to $p'=p-\epsilon$ it can capture all consumers. If we write $D$ for demand before the deviation and $D'&gt;D$ for demand afterwards then the change in profits is $D'(p-\epsilon)-Dp$. By the connectedness of the real line, there exists an $\epsilon$ sufficiently small that this is positive.</li>
<li>$p_m&lt;p_j$. This case is symmetric to $p_m&gt;p_j$.</li>
</ul>

<p>Thus, the only pure strategy equilibrium of this one-shot game is $p_j=p_m=0$.</p>

<hr>

<p><strong>If we repeat the game then we can sustain other (collusive) equilibria</strong></p>

<p>What if we repeat the game infinitely many times? Suppose the two firms have an implicit understanding (an explicit agreement would be illegal) that they will both set $p=p^*$ for some $p^*&gt;0$. Moreover, it is understood that if one firm deviates from this behaviour today, then both firms will revert to playing the static equilibrium ($p_j=p_m=0$) forever. Firms discount the future at rate $\delta$. For simplicity, suppose that demand is constant: $D(p)=1$ (not crucial).</p>

<p>If a firm plays in accordance with this understanding (and expects its rival to do likewise) then its profit is</p>

<p>$$\sum_{t=0}^\infty\frac{1}{2}\delta^t p^*=\frac{p^*}{2(1-\delta)}.$$</p>

<p>If a firm cheats and sets $p^*-\epsilon$ ($\epsilon$ small) then it captures the whole demand today, but expects to be punished forever thereafter, so profit is $p^*$. Thus, both firms wish to comply with their implicit understanding if
$$\frac{p^*}{2(1-\delta)}&gt;p^*\iff \delta&gt;\frac{1}{2}$$
(i.e. if they are sufficiently patient).</p>

<p>So, if we repeat the game and firms are very patient, <em>we can sustain any price in equilibrium</em>. But note that these equilibria require not only that firms are patient, but also that a) there is no threat of future entry that could destabilise the equilibrium; b) firms are able to coordinate on a $p^*$ without ever making an (illegal) explicit agreement; and c) firms are able to constantly and accurately monitor rivals behaviour in order to detect cheating.</p>
","8400"
"Why didn't the money printing by the US Federal Reserve since 2008 lead to inflation?","449","","<p><a href=""http://www.telegraph.co.uk/finance/comment/liamhalligan/8484530/Americas-reckless-money-printing-could-put-the-world-back-into-crisis.html"" rel=""nofollow"">http://www.telegraph.co.uk/finance/comment/liamhalligan/8484530/Americas-reckless-money-printing-could-put-the-world-back-into-crisis.html</a></p>

<blockquote>
  <p>America's reckless money-printing could put the world back into crisis
  Last week, Ben Bernanke suggested that the US base interest rate will
  stay close to zero for an ""extended period"". It's been there since
  December 2008.</p>
</blockquote>

<p>Today, the opposite has happened. Deflationary forces are strong in the U.S. Europe is even worse given the negative yield. Why has deflation prevailed despite money printing by central bankers?</p>
","<p>Because you can't push on a piece of string.</p>

<p>As in the Great Depression of the 1930s, we've collectively got massive personal debt, depressing demand, moving us towards deflation, which pushes up debt, and so it goes.</p>

<p>We've also known since the 1930s that monetary expansion in and of itself cannot stimulate demand under these conditions: it can only create space for demand to expand into.</p>

<p>Add in the international fashion for fiscal contraction, a demand-suppressant, and that's how we get QE without broad-money expansion and without inflation.</p>

<p>We do have <em>potential</em> inflation. And at some point that potential will be realised. But not while there's this huge overhang of personal debt. It might get worn down over a long period of deflation, through defaults. Some other inflationary shock might inflate some of the debt away. And enlightened policy-makers might engage in a large exercise in personal-debt cancellation.</p>
","9129"
"Is the Cobb-Douglas Utility Function Locally Non-Satiated at (0,0)?","448","","<p>My understanding of local non-satiation is that increasing your allocation of one good by a marginal amount increases utility. Suppose your utility takes the following form:
$$U(x,y)=x^\alpha y^\beta$$
and your initial endowment is $(0,0)$. Now, if you increase either good without increasing the other, your utility does not increase. Does this mean that your utility is not locally non-satiated?</p>
","<p>No.</p>

<p>Cobb-Douglas utility is monotonic and monotonicity implies L.N.S.</p>

<p>The issue here is that you're only considering edge cases. You've correctly reasoned that edge points are not more desirable that the origin. However, LNS simply claims that there exists a more desirable bundle within the open epsilon ball of your allocation under consideration (and this is true for all allocations). So given any epsilon, an open epsilon ball centered at the original will necessarily contain an allocation where both elements are strictly positive.</p>

<p>To see this, pick an epsilon and draw the epsilon ball around the origin. It should become fairly obvious what's going on. </p>

<p>Hope that helps.</p>
","12427"
"Given a Utility function, U(x,y), why is multiplying U(x,y) * x not a monotonic transformation?","447","","<p>If $x$, is a commodity and it is s.t. $x \geq 0$ (it is always nonnegative) how will multiplying it times a utility function $U(x,y)$ NOT yield a simple monotonic transformation?</p>
","<p>Because $x$ is not a constant, and therefore multiplying $U(x,y)$ by $x$ does not necessarily preserve the ordering between bundles.</p>

<p>For instance, consider the function $U(x,y)=x+y$, and the bundles $(x_0,y_0)=(2,0)$ and $(x_1,y_1)=(1,2)$. We have
\begin{equation*}
U(x_0,y_0)=2 &lt; U(x_1,y_1)=3
\end{equation*}
but
\begin{equation*}
x_0 U(x_0,y_0) = 4 &gt; x_1 U(x_1,y_1) = 3
\end{equation*}
Hence multiplying $U$ by $x$ changes the preferences, therefore is not a monotonic transformation.</p>

<p>As a side note, multiplying the utility function by a constant provides a monotonic transformation if the constant is positive, and not only nonnegative as you assumed (if the constant is zero the orderings are obviously not preserved).</p>
","10551"
"Robinson Crusoe Production Economy","446","","<p>Robinson Crusoe’s preferences over coconut consumption, C, and leisure, R, are represented by the utility function U(C, R) = CR. There are 48 hours available for Robinson to allocate between labor and leisure. If he works L hours, he will produce the square root of L of coconuts. He will choose to work. </p>

<p>The answer is 16 and I known this but confused to its working out. Can some give me a step by step?</p>
","<p>The utility function is $U(C,R)=CR$ and the time is restricted: $48=R+L$. Now we know that $C=\sqrt L$. $C$ can be replaced by $\sqrt L$. Therefore the langrarian is</p>

<p>$\mathcal L=\sqrt L\cdot R+\lambda (48-L-R)$</p>

<p>The (partial) derivatives are the following. They have to be set equal to zero.</p>

<p>$\frac{\partial \mathcal L}{\partial L}=\frac12 L^{-0.5} R-\lambda=0$</p>

<p>$\frac{\partial \mathcal L}{\partial R}= L^{0.5} -\lambda=0$</p>

<p>Putting $\lambda$ on the RHS</p>

<p>$\frac12 L^{-0.5} R=\lambda \quad (1)$</p>

<p>$L^{0.5} =\lambda \quad (2)$</p>

<p>Dividing (1) by (2):</p>

<p>$\frac12\cdot \frac{R}{L} =1 \Rightarrow R=2L$</p>

<p>The expression for R can be insert in the time restriction</p>

<p>$48=2L+L$</p>
","11274"
"Complete Markets in Continuous Time","445","","<p>In the standard discrete time economies with a finite number of states, $n$, a complete markets economy is simply an economy with $n$ independent assets (Think Ljunqvist and Sargent Chapter 8).  This is because $n$ independent assets is sufficient to span the set of states tomorrow.</p>

<p>I had a discussion with a professor last week in which he stated that one of the conveniences of continuous time when thinking about asset pricing is that within a continuous time economy one can get complete markets simply with a risk-free bond and a risky asset (independent) for each Brownian motion in the economy.</p>

<p>He explained it as we talked, so I think I mostly understand it, but was wondering if someone would mind writing down the details?</p>

<p>I will probably spend a day or two this week on it (depends on some of the properties of the differential calculus), so if no one else answers the question then hopefully I can provide a satisfactory answer.</p>
","<p>I am the last person that should be answering continuous time questions like these, but if there's no one else I guess I'll give it a shot. (Any correction of my dimly remembered continuous-time finance is very welcome.)</p>

<p>My impression has always been that this is best interpreted as a consequence of the <a href=""http://en.wikipedia.org/wiki/Martingale_representation_theorem"">martingale representation theorem</a>. First, though, I'll loosely establish some notation. Let the probability space be generated by the $n$ independent Wiener processes $(Z_t^1,\ldots,Z_t^n)$. Let there be $n+1$ assets, where the value of the $i$th asset at $t$ is given by $S_t^i$. Assume that asset $i=0$ is a riskfree bond $dS_t^0=r_tS_t^0dt$,  while assets $i=1,\ldots,n$ are each risky and are driven by the corresponding $Z_t^i$:
$$dS_t^i=\mu_t^idt+\sigma_t^idZ_t^i$$
Assume there is a strictly positive SDF process $m_t$ normalized to $m_0=1$, such that $m_tS_t^i$ is a martingale for each $i$ (basically the definition of SDF) and where
$$dm_t=\nu_t dt+\psi_t\cdot dZ_t$$
(I use $\cdot$ as the dot product, which will be convenient.)</p>

<p>Finally, let the $n+1$-dimensional vector $\theta_t$ be our portfolio at time $t$, such that net worth $A_t$ is given by $A_t=\theta_t\cdot S_t$. Assume that $A_0$ is fixed and that further we have
$$dA_t=\theta_t\cdot dS_t$$
Now I'll state the objective, which captures the essence of complete markets. Suppose that the world ends at time $T$, and that we want net worth $A_T$ to equal a certain stochastic $Y$, which can depend on the full history up until time $T$. Suppose that $A_0=E_0[m_TY]$, so that in a world with complete markets we could (at $t=0$) use our initial wealth $A_0$ to purchase the time $t=T$ payout $Y$. In the absence of these direct complete markets, the question is whether there is <strong>nevertheless some strategy for the portfolio</strong> $\theta_t$ that will allow us to obtain $A_T=Y$ in all states of the world. And the answer, in this setting, is yes.</p>

<p>First, one can calculate $d(m_tA_t)=\theta_t\cdot d(m_tS_t)$. Thus $m_tS_t$ being a martingale implies that $m_tA_t$ is a martingale. Thus we have $A_T=Y\Longleftrightarrow m_TA_T=m_TY$ iff
$$m_tA_t=E_t[m_TY]$$
for all $t\in[0,T]$. Note that this is true for $t=0$ by assumption; hence to get equality it is only necessary to prove that the increments are always equal on both sides.</p>

<p>Now the martingale representation theorem comes in. Since $E_t[m_TY]$ is a martingale, we can write
$$E_t[m_TY]=E_0[m_TY]+\int_0^t \phi_s\cdot dZ_s$$
for some predictable process $\phi_s$. So we need to be able to show $d(m_tA_t)=\phi_t\cdot dZ_t$. Writing
$$d(m_tA_t)=\sum_i (m_t\theta_t^i \sigma_t^i +A_t\psi_t^i)dZ_t^i$$
we see that we need $m_t\theta_t^i\sigma_t^i +A_t\psi_t^i=\phi_t^i$ for each risky asset $i=1,\ldots,n$, which we can invert to give the needed portfolio choice $\theta_t^i$:
$$\theta_t^i=\frac{\phi_t^i-A_t\psi_t^i}{m_t\sigma_t^i}$$
The riskless asset portfolio choice $\theta_t^0$ can then be backed out from $A_t=\theta_t\cdot S_t$.</p>

<p>The intuition here is simple: we need to always have $A_t$ adjust to maintain the equality $m_tA_t=E_t[m_TY]$, but both the expectation on the right and the SDF $m_t$ on the left are moving in response to the driving processes $dZ_t^i$. Hence we need to pick a portfolio $\theta_t$ such that $dA_t$ precisely offsets these movements and the equation continues to hold. And we can always do this as long as locally, our assets span all the risks $dZ_t^i$ -- which can happen more generally, even for $n$ correlated assets as long as their increments are locally linearly independent. (The case here of $n$ risky assets each drien by an independent Brownian motion is a special one.)</p>
","1651"
"static/dynamic optimization","444","","<p>The interesting paper <a href=""https://www.dropbox.com/s/huhv6uzfnlvojbi/Calvo%2C%20Obstfeld%20-%201988%20-%20Optimal%20Time-Consistent%20Fiscal%20Policy%20with%20Finite%20Lifetimes.pdf?dl=0"" rel=""nofollow"">Calvo and Obstfeld (1988)</a> uses two-stage optimization on an OLG model which then reduces to a standard representative agent framework. </p>

<p>First stage optimization consists on a static optimization which makes the optimal allocation between different cohorts vertically(c.f equation (9) in the paper.) Authors solve this first stage problem as:</p>

<p>$$\mathcal{L}=u\left[c\left(t-n,t\right)\right]\Delta\left(n\right)P\left(n\right)e^{\rho n}+\lambda\left[C\left(t\right)-\int_{0}^{\infty}c\left(t-n,t\right)P\left(n\right)d\left(n\right)\right]$$</p>

<p>where $C\left(t\right)=\int_{0}^{\infty}c\left(t-n,t\right)P\left(n\right)dn$. </p>

<p>$n, P(n), \Delta\left(n\right)$ are given in the paper and not relevant for my question at this moment. </p>

<p>Normally, in this paper, the dynamics of capital accumulation are given as follows:</p>

<p>$$\dot{K}\left(t\right)=Y\left[K\left(t\right)\right]-C\left(t\right)$$</p>

<p>In fact, my question is trivial but I could not be sure.</p>

<p>Is the part with bracket in Lagrangian comes from $\dot{K}=0$ which gives us the equality $Y\left[K\left(t\right)\right]=C\left(t\right)=\int_{0}^{\infty}c\left(t-n,t\right)P\left(n\right)dn$ ?</p>

<p>As the Lagrangian is for a ""static"" problem, I think it makes sense but I can not be sure if this is the case.</p>

<p>Any suggestion or hints are welcome. </p>
","<p>That's a coincidence, because they assume nondepreciating capital. If $\delta&gt;0$ was positive we'd have
\begin{align}
\dot K = Y - C - \delta K
\end{align}
which gives
\begin{align}
\dot K = 0  \quad \Rightarrow\quad C = Y - \delta K.
\end{align}</p>

<p>But the static optimization would still read
\begin{align}
&amp;U(C(t)):=\max_{c(t-n,n)}\int^\infty_0 u(c(t-n,n))dn \\
&amp;s.t.\quad \int^\infty_0 u(c(t-n,n))dn \leq C(t) 
\end{align} 
Actually they define an indirect utility function with subject to a resource constraint. In every period (thus static) the sum of individual consumption cannot exceed aggregate consumption. </p>
","6786"
"What prevents a bank from simply going into their computer system and adding some zeros to their bank account?","444","","<p>This question has been bothering me for a long time and I’m hoping that someone here can help to answer it.</p>

<p>I will use Greece as an example, but my question could really be applied to any country or even a bank:</p>

<p>While a government in the Eurozone, the Greeks for example, might have an actual building in which Euro coins are minted and Euro banknotes printed, these are most likely tightly regulated, with lots of physical checks to ensure that the Greek government doesn’t just print more whenever they want to.</p>

<p>I understand that physical money typically makes up a small portion of the actual money supply, so I assume that “printing them selves out of debt” regardless of whether it would be legal, isn’t an actual option for them.</p>

<p>However, what prevents the Greek national bank from simply going into their computer system and adding some zeros to their bank account? What system prevents any bank anywhere from doing the same? Does the bank of international settlements in Basel keep some kind of record of the total global money supply? How is this kind of fraud prevented?</p>

<p>I’m very curious to hear the answer!</p>
","<p>Double entry book keeping.</p>

<p>If we take the example given here, of the Greek Central Bank (bank nerd trivia - interestingly the GCB is a commercial bank, listed on the Greek Stock Exchange), arbitrarily adding 000's to its deposit account.</p>

<p>This cannot be done as stated. The double entry book keeping accounting system on which all banking is based, requires that two ledgers are simultaneously updated, one with a credit and one with a debit. So if the GCB credits its own deposit account (which in practice would be a liability income account of some kind), there has to be a matching debit on another ledger. Those are the rules.</p>

<p>Typically deposit accounts increase their value either by people depositing cash in them (see below), by direct transfer from another deposit account, or by receiving a loan.</p>

<p>For example, if the government prints physical cash then this can be deposited at the central bank:</p>

<pre><code>[debit cash account, credit GCB bank deposit account]
</code></pre>

<p>and this is how the US TARP intervention was performed. The federal reserve then used the money to buy loans from the US Banks. Note that a debit to an asset account increases its value, and a credit reduces it, whilst on the liability (right hand side), a debit reduces the account, and a credit increases it.</p>

<p>If the European central bank makes the Greek Central bank a loan then on the Greek side, the book keeping is:</p>

<pre><code>[debit cash, credit interbank loan]
</code></pre>

<p>The GCB has received cash, and now has a debt that it owes the ECB among its liabilities.</p>

<p>The one thing it can't do is just arbitrarily increase the value of a single account, one of the main reasons for double entry book keeping is in fact to prevent that. </p>

<p>Bank fraud and the various forms of banking system abuse that do occur typically involve manipulations of banking operations within the framework of double entry book keeping. So while DEB. prevents accounts from having zero's tacked on the end, it doesn't prevent Mr. Smith the bank manager, lending his very good friend Mr. Brown a large sum of money that Mr. Brown has no intention of repaying. </p>
","6473"
"What is the advantage and disadvantage of fiscal illusion policy in terms for the financial market?","442","","<p>What is the advantage and disadvantage of fiscal illusion policy for the financial market?</p>

<p>Fiscal illusion suggests that when government revenues are not completely transparent or are not fully perceived by taxpayers, then the cost of government is seen to be less expensive than it actually is.</p>
","<p>Too long, didn't read: the market does not care.</p>

<p><strong>Colombia's Pension Reform: Fiscal and Macroeconomic Effects</strong>, by Klaus Schmidt-Hebbel, states black on white (p 22) that </p>

<blockquote>
  <p>issuing explicit domestic debt for paying off implicit government debt does not have first-round macroeconomic and financial effects</p>
</blockquote>

<p>on the condition that the financial markets see through the debt swap. Fiscal illusion aimed at tax payers does not have any impact on tax payers, but the same Schmidt-Hebbel notes that the market could be fooled too.</p>

<p><a href=""https://ideas.repec.org/p/nbr/nberwo/1358.html"" rel=""nofollow"">Peek and Wilkox</a> looked into it and conclude that there is no data showing that fiscal illusion ever had an impact on interest rates, which leads me to conclude that, despite KSH's prudence, there is <strong>no</strong> (first hand) <strong>effect of fiscal illusion</strong> on the financial market. Of course, it can have secondary advantages such as leading the market to assume more political stability by raising popularity, or leading the market to distrust you, but these are corollaries of the effects of fiscal illusion on the people rather than pros and cons of fiscal illusion to the market.</p>
","5671"
"Mathematical derivation of the Production Possibility Frontier","441","","<p>What are the mathematical basics of production possibility frontier? How can I derivate it? Can I have an example for it?</p>
","<p>The question is broad, but I believe there is plenty of literature that defines this concept in similarly broad terms.
The following is adapted from the Wikipedia on <a href=""https://en.wikipedia.org/wiki/Pareto_efficiency"" rel=""nofollow noreferrer"">Pareto Efficiency</a>,
which is the mathematical basis of the <a href=""https://en.wikipedia.org/wiki/Production%E2%80%93possibility_frontier"" rel=""nofollow noreferrer"">Production Possibilities Frontier.</a></p>

<p>There may be better definitions out there, but this one should probably work in a lot of cases:</p>

<p>The <em>Production Possibilities Frontier</em>, $P(Y)$, may be more formally described as follows. Consider a system with function $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$, where $X$ is a compact space of feasible decisions (including allocations of time and endowment goods) in the metric space $\mathbb{R}^n$, and $Y$ is the feasible set of criterion vectors (say, final goods and services) in $\mathbb{R}^m$, such that $Y = \{ y \in \mathbb{R}^m:\; y = f(x), x \in X\;\}$.</p>

<p>We assume that the preferred directions of criteria values are known so that more of any good in $Y$ is better. A point $y^{\prime\prime} \in \mathbb{R}^m$ strictly dominates another point $y^{\prime} \in \mathbb{R}^m$, written as $y^{\prime\prime} &gt; y^{\prime}$, means that for each element index $i$, $y''_i \geq y'_i$ and there is at least one element $j$ such that $y_j'' &gt; y_j'$. The Pareto frontier is thus written as:</p>

<p>$P(Y) = \{ y^\prime \in Y: \; \{y^{\prime\prime} \in Y:\; y^{\prime\prime} &gt; y^\prime, y^{\prime\prime} \neq y^\prime \; \} = \emptyset \}. $</p>
","17648"
"Deriving the supply curve","440","","<p>In deriving the supply curve how does one create the supply curve like the one we see in textbooks (upward sloping, possible curve), if we are only given a single quantity and price at a moment in time? For example, in the oil industry we are told that the US is supplying x barrels of oil, how can we derive the rest of the curve since we don't know what the price is at x-y barrels...</p>
","<p>Cvarza, the supply curve is theoretically derived. </p>

<p>The supply curve of the industry is the horizontal sum of the curves of firms. The supply curve of a firm is the portion of the marginal cost curve with a positive slope. That is, firms act to equal marginal cost to marginal revenue. If the marginal cost is decreasing, that means the firm can increase (marginally) the production (and its profits) till the equilibrium point.</p>

<p>As reference, i recommend the chapter about firms supply in Varian's undergradute book.
As a graduate reference, MasCollel is strongly recomended.</p>
","9352"
"Utility function used to indicate bliss point","440","","<p>How does one create a utility function to indicate existence of a bliss point? what do the goods marshillian demands look like in such a situation? </p>
","<p>An answer that meets all the current demands of the question:</p>

<p>Let $(x_b,y_b)$ be the blisspoint. Let
$$
U(x,y) = \left\{
\begin{array}{cc}
1 &amp; \mbox{ if } (x,y) = (x_b,y_b) \\
0 &amp; \mbox{ if } (x,y) \neq (x_b,y_b).
\end{array}\right.
$$
The demand function for $x$ in this case is
$$
D_x(I,p_x,p_y) = \left\{
\begin{array}{cc}
x_b &amp; \mbox{ if } p_x \cdot x_b + p_y \cdot y_b \leq I \\
\left[0,\frac{I}{p_x}\right] &amp; \mbox{ if } p_x \cdot x_b + p_y \cdot y_b &gt; I.
\end{array}\right.
$$</p>
","13783"
"Binding constraints at second-best optimum","438","","<p>I am dealing with ex-ante asymmetric information problems, i.e. adverse selection and in particular I cannot understand what's the intuition behind the fact that only two out of four constraints imposed in the second-best maximization problem are binding. </p>

<p>To be precise, when there is asymmetric information with two types of agents, the optimum is found maximizing the utility under two <strong>individual rationality</strong> (or participation) constraints and two <strong>incentive compatibility</strong> constraints. In order to simplify the computations, it can be proven that the IC for the high type agent and the IR for the low type agent are binding, whereas the other two constraints are redundant. </p>

<p>I have seen the proof and it is pretty clear but what I cannot understand is the economic intuition behind the proof; Is there someone that has this kind  of intuition?</p>
","<p>I think its not a complex issue: </p>

<p>a) You need to keep the high type agent from pretending to be the ow type agent, so you give him an extra compensation from showing his high type. But this nice deal pays him more than necessary to keep him in the game so his IR is more than satisfied, i.e. not binding. </p>

<p>b) Similarly, you will make it painful to show that you are a low type, so that the high type doesn't go there, but you can;t make it so painful that the low type doesn't want to play so you pay him the minimum amount that he will take, i.e. his IR is binding, but  he would never choose to show himself as the high type anyway because with his low type, the incentives don't work in his favor, so the IC is not binding.</p>
","11679"
"Economic consequences of a lingua franca","437","","<p>Although I'm specifically interested in the likely economic consequences of implementation of an official world auxiliary language, since this is only theoretical, I'd like to know what have been some economic consequences, whether positive or negative, for those nations that endorsed a lingua franca and thereby opened themselves up to segments of the rest of the world (or conversely, I'd be interested in the long-term economic consequences for a country which, perhaps for anti-colonial reasons, rejected a more internationally spoken language in favor of a local one).</p>

<p>For this question, I'm less interested in lingua francas whose effect was primarily domestic. For example, with Modern Hebrew being chosen in Israel, or perhaps Mandarin Chinese in China to a lesser extent, the ability to speak a new official and universally taught common language did not open up the country precipitously to opportunities for communication with other countries.</p>

<p>Note that I'm not asking here about the economic costs of implementing such a language change.</p>

<p>No doubt, and as with free trade, all things being equal, a lingua franca would increase economic opportunities, whether in collaboration possibilities, education opportunities, etc., but, also as with free trade, a lingua franca might precipitously expose a country to competition in certain (intellectual) fields and thereby create resentment within certain industries which in turn led to protectionism. What experiences have been documented on this topic?</p>

<p>(Note: I can't create a ""language"" tag for this post, due to my being new here, so ""free-trade"" was the closest tag I could think of.)</p>

<p>(And just for interest's sake, I've asked re: political consequences at <a href=""https://politics.stackexchange.com/questions/7732/external-political-consequences-of-a-lingua-franca"">https://politics.stackexchange.com/questions/7732/external-political-consequences-of-a-lingua-franca</a> )</p>
","<p>These two papers seem relevant. The large Indian wage premium for English language fluency suggests that there would be significant returns at the margin to providing services through trade instead of locally, but they are limited by the supply of foreigners with the right language skills.  However, these premiums are largest among the skilled workers, suggesting that the benefits of a universal language would also accrue disproportionately (in absolute wage premia) to the most skilled.   </p>

<blockquote>
  <p>Recent studies have shown that trade liberalization increases skilled
  wage premiums in developing countries. This result suggests
  globalization may benefit elite skilled workers relatively more than
  poor unskilled workers, increasing inequality. This effect may be
  mitigated, however, if human capital investment responds to new global
  opportunities. A key question is whether a country with a more
  elastic human capital supply is better positioned to benefit from
  globalization. I study how the impact of globalization varies across
  Indian districts with different costs of skill acquisition. <strong>I focus on
  the cost of learning English, a relevant qualification for high-skilled
  export jobs. Linguistic diversity in India compels individuals to
  learn either English or Hindi as a lingua franca.</strong> Some districts have
  lower relative costs of learning English due to linguistic
  predispositions and psychic costs associated with past nationalistic
  pressure to adopt Hindi. I demonstrate that <strong>districts with a more
  elastic supply of English skills benefited more from globalization:
  they experienced greater growth in both information technology jobs
  and school enrollment.</strong> Consistent with this human capital response,
  they experienced smaller increases in skilled wage premiums.</p>
</blockquote>

<p><a href=""http://www.cgdev.org/doc/events/1.18.08/shastry_ITandEducation_0108.pdf"" rel=""nofollow"">Human Capital Response to Globalization: Education and Information Technology in India</a></p>

<blockquote>
  <p>India's colonial legacy and linguistic diversity give English an
  important role in its economy, and this role has expanded due to
  globalization in recent decades. It is widely believed that there are
  sizable economic returns to English-language skills in India, but the
  extent of these returns is unknown due to lack of a microdata set
  containing measures of both earnings and English ability. In this
  paper, we use a newly available data set - the India Human Development
  Survey, 2005 to quantify the effects of English-speaking ability on
  wages. <strong>We find that being fluent in English (compared to not
  speaking any English) increases hourly wages of men by 34%, which is
  as much as the return to completing secondary school and half as much
  as the return to completing a Bachelor's degree. Being able to speak a
  little English significantly increases male hourly wages 13%. There is
  considerable heterogeneity in returns to English. More experienced and
  more educated workers receive higher returns to English.</strong> The
  complementarity between English skills and education appears to have
  strengthened over time. Only the more educated among young workers
  earn a premium for English skill, whereas older workers across all
  education groups do.</p>
</blockquote>

<p><a href=""http://w.cream-migration.org/publ_uploads/CDP_02_10.pdf"" rel=""nofollow"">The Returns to English-Language Skills in India</a></p>

<p>Here is a natural experiment that provides an example of the negative effect of the opening of labor markets on the existing population the new workers will compete with (in this case, the arrival of Russian mathematicians on Western mathematicians' wages and job prospects). </p>

<blockquote>
  <p>The fall of the Iron Curtain in late 1991 ended nearly 70 years of
  isolation of Soviet mathematicians from the world mathematical
  community. Suddenly free to travel and emigrate, approximately 1000
  Soviet mathematicians, mostly highly productive researchers, relocated
  to other countries. Three-hundred-thirty-six scientists came to the
  United States.</p>
  
  <p>During the decades of scant contact with foreign colleagues, Russian
  mathematicians, for political reasons that Borjas and Doran explain,
  concentrated on certain fields that tended to get much less attention
  in the West. American mathematicians, meanwhile, had moved ahead in
  areas that Russians largely ignored. When the émigrés arrived in
  America, therefore, they had a great impact on certain mathematical
  fields but much less on others.</p>
  
  <p>These differential impacts allow Borjas and Doran to compare what
  happened in fields heavily and lightly affected by the influx and to
  analyze what a large infusion of new talent and ideas does to a field
  of research. Combining information from several large databases, they
  track the productivity and affiliations of the Russian and American
  mathematicians. Their inquiry concentrates on two major effects; the
  “knowledge shock” from all of the new approaches and insights suddenly
  available to American mathematics, and the “labor market shock” from
  all the new people suddenly on the American mathematics job market.</p>
  
  <p>What they found does not support what Borjas calls the conventional
  “rubbing-off” theory, which holds that if “we get all these highly
  skilled immigrants, … somehow there’s a rubbing-off effect that makes
  you and me more innovative.”</p>
  
  <p>Since the fields with heavy Russian influence had “incredibly bright
  new mathematicians coming in, with all these new theorems, all these
  new techniques flooding the market, you would expect that people
  working in those areas are going to learn quite a lot from them,”
  Borjas says. “At the same time, the number of academic jobs where
  mathematical research is actually done is really not increasing all
  that much. So something has to give.”</p>
  
  <p>That something, the study found, was the career prospects and
  productivity of many of the mathematicians already here. “When you
  increase the number of very smart people in a field by a substantial
  amount,” Borjas says, “… not everybody benefits. The typical
  pre-existing American mathematician actually lost out.”</p>
  
  <p><strong>That’s because “a generation of American mathematicians at the very
  peak of their mathematical efficiency by luck just happened to
  graduate at the same time these Russians [were] coming in,” Borjas
  explains. The people of that young generation lost the most. Faculty
  members protected by tenure kept their jobs, but mathematicians who
  had not yet attained it found themselves facing sharply heightened
  competition, which produced an “unprecedented 12 percent unemployment
  rate for new American mathematics PhDs” and “a dramatic decrease in
  the probability of obtaining a position in research universities,” the
  article says. The overall unemployment rate for college graduates,
  meanwhile, was dropping rapidly, from 3.2% to 2.2% between 1992 and
  1996. Many of the young mathematicians in heavily affected fields ended up moving to lower-ranking institutions or leaving academic
  mathematics altogether.</strong></p>
  
  <p>The situation “drove a lot of American mathematicians into Wall
  Street,” Borjas says. There, in their new role as “quants”
  (quantitative analysts), they turned their talents to inventing
  intricate financial instruments. Ironically, one of Borjas’s
  colleagues has joked, the migration from the formerly communist
  country probably helped to fuel the 2008 economic crisis that nearly
  <a href=""http://sciencecareers.sciencemag.org/career_magazine/previous_issues/articles/2012_03_02/caredit.a1200024"" rel=""nofollow"">> brought down American capitalism.
  Taken for Granted: Foreign Invasion</a> </p>
</blockquote>
","3272"
"Understanding the shape of a Marginal Cost Curve","435","","<p>My class IB has just discussed allocative efficiency and hence consumer and producer supply. They explained the concepts with a diagram like this:
<a href=""https://i.stack.imgur.com/KHOo8.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/KHOo8.png"" alt=""enter image description here""></a></p>

<p>It all made perfect sense to me until it was mentioned that the supply curve can also be seen as a marginal cost curve. If this is the case, I don't understand why it is only sloping upwards. I know that marginal cost curves (at least at short-term) look something like... <a href=""https://i.stack.imgur.com/5wQEF.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/5wQEF.png"" alt=""This""></a>
But the curve in the first diagram is different.</p>

<p>Is is an oversimplification of a real marginal cost diagram, or am I missing something?</p>
","<p>I'll offer a less algebraic alternative to Alecos's answer. In short, yes and no.</p>

<h3>The ""no"" part</h3>

<p>Normally the MC and AC curves would look like the following, with MC intersecting AC from below AC's minimum point. Suppose price $P_0$ were below this point. Then the firm would sell at a quantity below $Q_1$. But what does this imply for the firm's profit? On average, the firm would make $P_0$ per unit sold, but the cost per unit must be higher than $P_0$, i.e. at $AC_0$ if the firm is selling at $Q_0$. This means the firm would be making a loss (negative profit) and no profit maximizing firm would try to operate at this point; they'd be better off shutting down and get zero profit instead.</p>

<p>Therefore, a firm's supply curve should be the fraction of its MC curve that's above the AC curve, which is always upward sloping. The quantity $Q_1$ where a firm would start producing is sometimes referred to as the <a href=""https://en.wikipedia.org/wiki/Minimum_efficient_scale"" rel=""nofollow noreferrer""><em>minimum efficient scale</em></a> of production.</p>

<h3>The ""yes"" part</h3>

<p>In your demand-supply diagram, the supply curve starts from the origin. Imagine this is just as having the red-dash line in the following diagram ""approximating"" the part of the MC curve that is below AC --- filling the gap, so to speak. </p>

<p><a href=""https://i.stack.imgur.com/oEJdx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/oEJdx.png"" alt=""enter image description here""></a></p>
","19063"
"Pure exchange economy: Given an initial endowment are multiple equilibria possible?","434","","<p>Consider a pure exchange economy with two goods ($x_1,x_2$) and two consumers $A,B$. Both users have an initial endowment, $(\omega_1^A,\omega_2^A)$ and $(\omega_1^B,\omega_2^B)$ respectively. A price ratio $p^*$ is an equilibrium price ratio if after both users maximize their utility given their budget, that is $\forall i\in \left\{A,B\right\}$ they solve the problem
\begin{align*}
\max_{x_1^i,x_2^i} \ &amp; U(x_1^i,x_2^i) \\
\\
\mbox{s.t. } &amp; p \omega_1^i + \omega_2^i = p x_1^i + x_2^i,
\end{align*}
the maximizing bundles $(x_1^A,x_2^A),(x_1^B,x_2^B)$ are such that the markets are in equilibrium, meaning
\begin{align*}
x_1^A + x_1^B &amp; = \omega_1^A + \omega_1^B \\
\\
x_2^A + x_2^B &amp; = \omega_2^A + \omega_2^B.
\end{align*}</p>

<p>Suppose that $U$ fulfils the usual conditions of convexity, monotonicity (or local non-satiation, pick whichever you like) and continuity. Given an initial endowment is it possible to have two different equilibrium price ratios? The ideal answer would give a simple example, but non-constructive proofs are also okay. I am especially interested in examples where both equilibria are interior points of the Edgeworth-box.</p>

<p>A graphical representation of the problem:</p>

<p><a href=""https://i.stack.imgur.com/C67NF.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/C67NF.png"" alt=""enter image description here""></a>
Green is the set of Pareto-optimal points, red and blue are indifference curves, thin lines are budget lines.</p>
","<p>Yes. The <a href=""https://doi.org/10.1016/0304-4068(74)90032-9"" rel=""noreferrer"">Debreu version</a> of the Sonnenschein-Mantel-Debreu theorem guarantees that excess demand has to satisfy very little restrictions if there are as many consumers as commodities.</p>

<p>An explicit example of multiple equilibria in a $2\times 2$-exchange economy can be found in</p>

<blockquote>
  <p>Shapley, L. S., and M. Shubik. “<a href=""http://www.jstor.org/stable/1828711"" rel=""noreferrer"">An Example of a Trading Economy with
  Three Competitive Equilibria.</a>” Journal of Political Economy, vol.
  85, no. 4, 1977, pp. 873–875.</p>
</blockquote>

<p>In the example, both consumers have even quasi-linear preferences, which are (necessarily for nonuniqueness) linear in different commodities.</p>
","19291"
"What are the empirical techniques to show causation?","432","","<p>A simple linear regression only shows correlation between two variables. To establish causation, two commonly taught methods are IV regression and natural experiments. What are the other methods people use to establish causation?</p>
","<p>Natural experiments are usually a setting for causal inference rather than a causal inference tool per se. You often need to employ something like difference-in-difference or instrumental variables anyway even when you have a natural experiment.</p>

<h2> Here a list of statistical causal inference approaches (Approach: Lay description)</h2> 

<ul>
<li><a href=""https://en.wikipedia.org/wiki/Instrumental_variable"">Instrumental Variables</a>: Randomly assigned variable X influences Z only through Y </li>
<li><a href=""https://en.wikipedia.org/wiki/Difference_in_differences"">Difference in Differences</a>:  If two groups have a common trend and only one group is treated then the change in the difference between the groups is the treatment effect</li>
<li><a href=""https://en.wikipedia.org/wiki/Regression_discontinuity_design"">Regression Discontinuity</a>: If a hard threshold determined treatment, look at difference right around that threshold</li>
<li><a href=""https://en.wikipedia.org/wiki/Propensity_score_matching"">Propensity score matching</a>: Create a control group by matching untreated observations that were likely to be treated (but not in fact treated) with treated observations with a similar probability of treatment. </li>
<li><a href=""http://www.statsols.com/mahalanobis-distance-matching-method/"">Manhalobis distance matching</a>:   Create a control group by matching untreated observations that look similar to treated. Another notable distance measure is <a href=""http://gking.harvard.edu/cem"">Coarsened Exact Matching</a>.  </li>
<li><a href=""https://web.stanford.edu/~jhain/synthpage.html"">Synthetic control</a>: When you have only one treated observation, create a composite of untreated observations that individually are imperfect controls but collectively act as a good control.</li>
<li>Synthetic Cohorts - Treat repeated observations of groups like a panel of individuals and employ panel techniques. </li>
<li>Selection bias modeling like <a href=""https://en.wikipedia.org/wiki/Heckman_correction"">Heckman correction</a>: Assume a parametric form for selection bias and remove it, so the corrected regression results can be interpreted causally.</li>
<li><a href=""http://www.nber.org/papers/w14083.pdf"">Sample weighting more broadly</a> - fix bias resulting from endogenous participation and un-modeled heterogeneity by weighting sample units to look more like the true population of interest.</li>
</ul>
","6282"
"What is Production Possibility Frontier (PPF) diagram drawn on consumption-leisure?","431","","<p>When explaining basic macroeconomics model involving consumption-leisure tradeoff, often diagram showing production possbility frontier (PPF) is drawn with leisure on x-axis and consumption on y-axis. But what exactly is the meaning of this production possibility frontier? </p>

<p>Production Possibility Froniter diagram is often drawn on two-goods basis (for example, like butter on x-axis and milk on y-axis) but I am confused on what PPF might be on consumption-leisure basis.</p>

<p>Reference: <a href=""http://newmonetarism.blogspot.com/2014/02/rbc-and-nk-in-nutshell.html"" rel=""nofollow"">http://newmonetarism.blogspot.com/2014/02/rbc-and-nk-in-nutshell.html</a></p>
","<p>Edited because wrnog answer, did not took the time to read the page.</p>

<p><strong>Without maths</strong></p>

<p>So your PPF would just be the link between leisure and consumption set by technology : the amount of leisure you choose give the time you can spend working, so the wage you earn and therefore the consumption you have (since there is no saving, all you earn is what you consume).</p>

<p><strong>With a bit of math</strong> </p>

<p>You have a fixed amount of time, which we normalize to $1$. You can spend it either in leisure F (fun) or in work L (labour) so that 
$$1=L+F$$
Then you get a wage $w$, that is related to $L$ in some way : $w=\psi(L)$, and you consume $C=w=\psi(L)$, so that $L=\psi^{-1}(C)$</p>

<p>Then your PPF is 
$$F+\psi^{-1}(C)=1 $$
It is a relation between leisure $F$ and consumption $C$ set by technology (the way wages are fixed).</p>

<p>Then the program is to maximize the agent utility $U(C,F)$ subject to this contraint. You can visualize it by the common tangent between iso-utility curves and your PPD.</p>
","3031"
"Why is the production possibility set convex?","431","","<p>I'm studying International Trade and came across this question: Suppose a specific factor model where the global production of something is given by $Q_{w}=Q_{1}(.) + Q_{2}(.)$, with $Q_{1}, Q_{2}$ strictly increasing on all arguments and also strictly concave. So $Q_{w}$ will also be concave. As so, the superior sets of the level curves should be convex. But what I see is that the <em>inferior</em> set in this case is convex.</p>

<p>What am I not understanding here?</p>
","<p>Perhaps you are confusing two things.</p>

<p>If $Q_1$ and $Q_2$ denote the production of goods 1 and 2 in a single country and you are in the space defined by them given $L_1 + L_2 = L$ then it is indeed the inferior set (the production possiblity set defined by the feasible $(Q_1,Q_2)$ pairs) that is convex. Formally this means that for all feasible $L_1,L_2,L_1',L_2'$ labor allocations you have
\begin{eqnarray*}
\mu \cdot Q_1(L_1) + (1-\mu) \cdot Q_1(L_1') &amp; \leq &amp; 
Q_1(\mu \cdot L_1 + (1- \mu) \cdot L_1') \\
\\
\mu \cdot Q_2(L_2) + (1-\mu) \cdot Q_2(L_2') &amp; \leq &amp; 
Q_2(\mu \cdot L_2 + (1- \mu) \cdot L_2').
\end{eqnarray*}
As this is equivalent to saying $Q_1$ and $Q_2$ are concave this is true given the condition that you describe. In this situation the function $Q_1 + Q_2$ has no meaning at all. What are we adding up? Ducks and cars? What will be the unit of measurement here?</p>

<p>But if $Q_1$ and $Q_2$ represent the production of a single good in countries 1 and 2 given the  amount of labor allocated and the space is $L_1, L_2$, the curves being levels of $Q_w$, then it is the upper level curves that are convex. You can see this straight away because the marginal products of $L_1$ and $L_2$ are decreasing hence their rate of teachnical substitution is 'decreasing' as well. Formally:</p>

<p>By definition the function $Q_w(L_1,L_2)$ is concave if for all $L_1,L_2,L_1',L_2'$ and for all $\mu \in [0,1]:$
\begin{eqnarray*}
\mu \cdot Q_w(L_1,L_2) + (1-\mu) \cdot Q_w(L_1',L_2') &amp; \leq &amp; 
Q_w(\mu \cdot L_1 + (1- \mu) \cdot L_1',\mu \cdot L_2 + (1- \mu) \cdot L_2').
\end{eqnarray*}
We know that the functions $Q_1$ and $Q_2$ are concave, meaning
\begin{eqnarray*}
\mu \cdot Q_1(L_1) + (1-\mu) \cdot Q_1(L_1') &amp; \leq &amp; 
Q_1(\mu \cdot L_1 + (1- \mu) \cdot L_1') \\
\\
\mu \cdot Q_2(L_2) + (1-\mu) \cdot Q_2(L_2') &amp; \leq &amp; 
Q_2(\mu \cdot L_2 + (1- \mu) \cdot L_2').
\end{eqnarray*}
Adding these up we get
\begin{eqnarray*}
\mu \cdot \left(Q_1(L_1) + Q_2(L_2)\right) + (1-\mu) \cdot \left(Q_1(L_1') + Q_2(L_2')\right) \leq \\
\leq 
Q_1(\mu \cdot L_1 + (1- \mu) \cdot L_1') + Q_2(\mu \cdot L_2 + (1- \mu) \cdot L_2').
\end{eqnarray*}
And since 
$$
Q_w(L_1,L_2) = Q_1(L_1) + Q_2(L_2)
$$
we have
\begin{eqnarray*}
\mu \cdot \left(Q_1(L_1) + Q_2(L_2)\right) + (1-\mu) \cdot \left(Q_1(L_1') + Q_2(L_2')\right) \leq \\
\leq  
Q_1(\mu \cdot L_1 + (1- \mu) \cdot L_1') + Q_2(\mu \cdot L_2 + (1- \mu) \cdot L_2') \\
\\
\mu \cdot \left(Q_w(L_1,L_2)\right) + (1-\mu) \cdot \left(Q_w(L_1',L_2')\right) \leq \\
\leq 
Q_w(\mu \cdot L_1 + (1- \mu) \cdot L_1',\mu \cdot L_2 + (1- \mu) \cdot L_2').
\end{eqnarray*}
which is what we set out to prove. </p>
","11017"
"Perfect competition questions","429","","<p>I have problems with deciding whether those statements are true or false.</p>

<ol>
<li>In a short/long run price of equilibrium on a perfectly compettive market might be either lower or higher then average total cost of one company operating on this market.</li>
<li>In a short run total amount of companies in perfectly competitive branch of industry, changes when their economic gains are equal to zero.</li>
</ol>

<p>Appreciate your help with some further comments about that. </p>

<p>PS. anticipating your questions i am preparing to an exam, that is why i am looking for an answer to those questions. </p>
","<p>I'm not going to answer the questions for you, but here is some food for thought, you should be able to conclude yourself.</p>

<h3>Ad 1</h3>

<p>We know that in the long run equilibrium, there are zero profits: If they'd be positive, firms would enter, if they'd be negative, firms would leave. Can we conclude something about a firm's profits if it has average total costs smaller (larger) than the price?</p>

<h3>Ad 2</h3>

<p>What induces change in the total amount of companies in such a branch? Is having zero-profits one of these reasons?</p>
","5013"
"Intrinsic value of non-voting shares which don't pay dividends","428","","<p>What is the intrinsic value of a company's non-voting stock shares which don't pay dividends?</p>

<p>My understanding is stock ownership has value in the form of controlling the company or receiving a portion of the profits.  Where does value derive from when neither of these is present?</p>
","<p>Just because a share doesn't <em>presently</em> pay dividends, doesn't mean it <em>never</em> will. The gamble is that eventually, it <em>will</em> pay dividends. So the share's value is the market's estimate of the net present value of a future cashflow discounted by two factors: one, the discount rate to reflect that this is a <em>future</em> cashflow not a <em>present</em> one; and two, the probability the cashflow will start later, or never.</p>
","9571"
"What is the relationship between S&P500 and the US dollar","428","","<p>In the recent past, both the S&amp;P 500 and the USD (against other currencies) have appreciated a lot.</p>

<p>From what I understand, if USD goes up against other companies, the major companies of the S&amp;P 500 suffer because many of them earn foreign revenue in foreign currencies.</p>

<p>So, the S&amp;P500 and the USD should have an inverse relationship with each other.
So how come both S&amp;P 500 and the USD have risen so sharply this year?</p>
","<p>You're doing the traditional mistake of people not familiar with Econometrics: You mistake correlation and causality.</p>

<p>You look at a change in the USD, assume it to be exogenous, and then predict an impact onto the S&amp;P. </p>

<p>However, changes in the USD are not exogenous. For example, an increase in US productivity (compared to the productivity of firms in other countries) will both increase the S&amp;P and valuate the USD.</p>

<p>For what you're trying to do, you need to separate different effects, which is virtually impossible - or look for random variation in the USD, of which I'm also unfamiliar with.</p>
","5216"
"Spatial Durbin model in Stata - How it is estimated?","427","","<p>Can someone explain to me how the estimation of the spatial Durbin model is made in Stata ? The documentation of XSMLE command (for spatial panels) says that for dynamic cases the estimator are based upon the article of <a href=""http://www.sciencedirect.com/science/article/pii/S0304407608000808"" rel=""nofollow noreferrer"">Yu et. al. (2008)</a>. But I have not found references in the article to the estimation process of the Spatial Durbin model.</p>
","<p><a href=""http://www.stata.com/meeting/germany13/abstracts/materials/de13_mortari.pdf"" rel=""nofollow noreferrer"">Here</a> is a detailed worked example of how to use the <code>xsmle</code> command, including an example of the Spatial Durbin model. As the document says, it is estimated using Maximum Likelihood. The model can be of Random Effects or Fixed Effects. </p>

<p>Key screenshots below:</p>

<p><a href=""https://i.stack.imgur.com/IaitK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/IaitK.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/tw3bq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tw3bq.png"" alt=""enter image description here""></a></p>

<p>You need to use <code>model(sdm)</code> in the options to get the spatial Durbin model. To get the dynamic version of the model, add <code>dlag</code> to the options.</p>
","17556"
"Computing Boston and TTC in Python","426","","<p>This is somewhat of a follow up question to <a href=""https://economics.stackexchange.com/questions/1638/available-code-for-computing-solutions-to-matching-algorithms"">Available code for computing solutions to matching algorithms?</a>.</p>

<p>In the above question, I got great answers, but all of them were for <code>R</code>.</p>

<p>I am now programming a lab experiment in <a href=""http://www.otree.org/"" rel=""nofollow"">otree</a>, which means I am working with Python.</p>

<p>It is fairly easy to find code in <code>python</code> solving matching problems using the Deferred Acceptance mechanism, but I wondered if anyone knew of <code>python</code> code for some of the other common mechanisms in the  literature. Specifically, I am looking for <code>python</code> code for</p>

<ul>
<li>The Boston mechanism (aka. Immediate acceptance)</li>
<li>The Top-trading cycle algorithm</li>
</ul>

<p>In the best of the worlds, these codes would </p>

<ul>
<li>Be compatible with the school choice model (i.e. many-to-one matching problem in which agents in one side of the ""market"" can be matched to many agents on the other side)</li>
<li>Allow for constrains on the lenght of the preference list agents can report (see <a href=""http://www.sciencedirect.com/science/article/pii/S002205310900057X"" rel=""nofollow"">http://www.sciencedirect.com/science/article/pii/S002205310900057X</a>)</li>
</ul>

<p>However, I would already be very happy with <code>python</code> code for Boston and TTC, even if the two last features are not implemented.</p>
","<p>I ended up putting together some code to compute the assignment under Boston and deferred acceptance. It can be found at <a href=""https://github.com/vanderlindenma/school_choice_python"" rel=""nofollow"">https://github.com/vanderlindenma/school_choice_python</a>.</p>

<p>The code there uses and modifies former code from Jeremy Kun, stable-marriage, (2014), GitHub repository, <a href=""https://github.com/j2kun/stable-marriages"" rel=""nofollow"">https://github.com/j2kun/stable-marriages</a>, described in one of Jeremy's blog posts at <a href=""http://jeremykun.com/2014/04/02/stable-marriages-and-designing-markets/"" rel=""nofollow"">http://jeremykun.com/2014/04/02/stable-marriages-and-designing-markets/</a>.</p>

<p>I hope to expend on the code that’s currently available and add more functionalities soon. Any participation is welcome.</p>
","8835"
"Is the economy a zero-sum game?","425","","<p>Theoretically speaking, if all the Earth's inhabitants were to save money and invest, is it possible for everybody to get, let's say, a 4% yearly return for everyone?</p>

<p>Is the economy a zero sum game (where if someone gains, others lose) or not?</p>
","<p>Yes, it's possible, as long as the money is invested in ways that increase production by 4%. The economy is certainly not a zero sum game -- if it was, then it couldn't grow.</p>
","1751"
"Where to start with social networks?","425","","<p>I'm working on my master's thesis in industrial organization and I have a model that is based on social networks. I have had two courses about social networks (one more focused on basic industrial organization questions in networks and the other more about basic graph theory) but as I work more on the model I feel I'm not really using the network in solving the questions that arise and leaving it more as a descriptive structure, and I fear it is mostly due to ignorance.</p>

<p>Can anyone refer to a good book, class notes or papers that might help me learn more deeply the implications of the network structure and/or the pros and cons of modeling a problem as a network? For example on how the network structure might be helpful when trying to determine existence of equilibrium.</p>
","<p>The best introduction is, in my opinion, the book by Matthew Jackson. It has a pretty nice introduction (even if you know nothing about social networks) and chapters about many of the applications of graph theory in economics.</p>

<ul>
<li>Jackson, M. O. (2008). Social and economic networks (Vol. 3).
Princeton: Princeton University Press.</li>
</ul>

<p>It sounds like you try to model a game on a network (i.e., using game theory with players on a network without changing the network). If this is true, then the following paper might be even more relevant:</p>

<ul>
<li>Galeotti, A., Goyal, S., Jackson, M. O., Vega-Redondo, F., &amp; Yariv,
L. (2010). <a href=""http://cadmus.eui.eu/bitstream/handle/1814/7864/ECO-2008-07.pdf"">Network games</a>. The review of economic studies, 77(1),
218-244.</li>
</ul>
","5157"
"Indirect utility from expenditure function","424","","<p>I have the expenditure function: $$e(p,u)=\left(p_1^{\rho/{\rho-1}}+p_2^{\rho/{\rho-1}}\right)^{{\rho-1}/\rho}u$$
where $u$ is the utility, $p_1,p_2$ prices and $\rho$ a parameter. How do I derive the indirect utility function?</p>
","<p>Mas-Colell, Whinston, Green chapter 3, especially p. 75 explains this. One possible way is $v(p,w)=e(p,v(p,w))$ where $v$ is the indirect utility function, $p$ the price vector and $w$ the wealth.</p>
","5141"
"Do free-trade economies typically offer any protection for domestic markets?","423","","<p>The aimed-for outcome of the protectionist could be said to be the shielding of domestic markets from competition with an ""unfair"" advantage. For example, an emerging economy might have non-existent workers' rights enabling lower production cost.</p>

<p>However, discussions surrounding naive protectionist policies typically descend into ""define a biscuit"" type arguments. In short: the difficulty in defining the boundaries of tariffs quickly turns arguments to farce.</p>

<p>But there must be other, better ways to achieve the desired outcome. I have read that in the early 2000s Germany ""protected"" its intra-EU car sales by ensuring EU emissions regulations were closely aligned with the emissions of their own diesel engine technology making market entry by (for example) American cars with big petrol engines more difficult. Whether this is apochryphal or not, the point remains.</p>

<p>Do free-trade economies typically endeavour to protect themselves in ANY way, or does ""free mean free"" in the minds of these legislatures?</p>
","<p>I think the (or at least, a) relevant concept is that of <strong>non-tariff barriers to trade</strong>. Wikipedia <a href=""https://en.wikipedia.org/wiki/Non-tariff_barriers_to_trade"" rel=""noreferrer"">has a nice summary</a>.</p>

<p>Let me quote a couple of sections from the article:</p>

<blockquote>
  <p>Non-tariff barriers to trade (NTBs) or sometimes called ""Non-Tariff Measures (NTMs)"" are trade barriers that restrict imports or exports of goods or services through mechanisms other than the simple imposition of tariffs. The SADC says, ""a Non-Tariff Barrier is any obstacle to international trade that is not an import or export duty. They may take the form of import quotas, subsidies, customs delays, technical barriers, or other systems preventing or impeding trade."" According to the World Trade Organisation, non-tariff barriers to trade include import licensing, rules for valuation of goods at customs, pre-shipment inspections, rules of origin ('made in'), and trade prepared investment measures.</p>
</blockquote>

<p>-</p>

<blockquote>
  <p>According to statements made at United Nations Conference on Trade and Development (UNCTAD, 2005), the use of NTBs, based on the amount and control of price levels has decreased significantly from 45% in 1994 to 15% in 2004, while use of other NTBs increased from 55% in 1994 to 85% in 2004. [...] The need to protect sensitive to import industries, as well as a wide range of trade restrictions, available to the governments of industrialized countries, forcing them to resort to use the NTB, and putting serious obstacles to international trade and world economic growth. Thus, NTBs can be referred as a new of protection which has replaced tariffs as an old form of protection.</p>
</blockquote>

<p>So regulatory and similar barriers to trade have become widespread—often as a way to circumvent restrictions on protectionism. </p>
","15511"
"Why was Modigliani-Miller so relevant and innovative when it came out?","421","","<p>The <a href=""https://en.wikipedia.org/wiki/Modigliani%E2%80%93Miller_theorem"" rel=""nofollow"">Modigliani-Miller theorem</a>*, a foundation of modern corporate finance, basically states that, in a no-frictions world, two identical firms have the same enterprise value, regardless of their financial structure.</p>

<p>Given a firm A, whose liabilities are 50% equity, and 50% debt, and a firm B which is financed 100% by equity, the value of firm A and the value of firm B are the same.</p>

<p>Isn't it just obvious? What am I missing?</p>

<p>* -
Modigliani, F.; Miller, M. (1958). ""<a href=""http://www.jstor.org/stable/1809766"" rel=""nofollow"">The Cost of Capital, Corporation Finance and the Theory of Investment</a>"". American Economic Review 48 (3): 261–297. JSTOR 1809766.</p>
","<p>People, particularly business leaders, seem to remain confused about this issue even today. At the core of is the question <em>Is equity finance expensive?</em>. We certainly observe in the data that the realized returns on firm debt are much lower than the realized returns on firm equity. <em>Does this mean that firms have too much equity?</em></p>

<p>If equity capital always costs 9 percent per year and debt always 3 percent then a firm would be worth more if management kept equity to a minimum and used as much debt as possible. But in the real world there are lots of complications that might make debt cheaper than equity. Monitoring costs are real, default is costly, tax wedges are large, equity is riskier, and contracts are incomplete. It may be that factoring in these costs, which are hard to measure, provides a complete explanation for the differences in return between debt and equity. Or maybe not. If observable characteristics fail to explain this difference does this mean that firms should take on more debt? Or does it mean that these characteristics are poorly measured?</p>

<p>Modigliani-Miller provide a clear way of thinking about this question. In the absence of frictions, as you shrink the amount of equity and offset it with more debt the required returns adjust to leave the firm's cost of capital unchanged. But even so, there is no problem with return on debt being lower than the return on equity. So in and of itself, there is nothing to learn from the lower cost of debt compared with equity. This is a surprisingly robust result:</p>

<blockquote>
  <p>The two Modigliani-Miller theorems hold good, irrespective of
  individual differences between shareholders' valuations of risk,
  leverage effects, durability of loans, etc. The logic of the theorems
  rests in fact upon the assumption of perfect markets, namely that a
  shareholder can always, through his own borrowing or lending, compose
  his asset portfolio as he sees fit and that he can, without costs,
  give it the composition he desires with respect to risk, leverage,
  etc. If for instance the risk level of a firm's assets is increased,
  the shareholders can neutralize this by lowering the risk of other
  assets in their portfolios.</p>
</blockquote>

<p><a href=""http://www.nobelprize.org/nobel_prizes/economic-sciences/laureates/1985/press.html"" rel=""nofollow"">Press Release: 15 October 1985 THIS YEAR'S ECONOMICS PRIZE AWARDED FOR PIONEERING STUDIES OF SAVING AND OF FINANCIAL MARKETS</a> </p>

<p>This is an extremely valuable insight. The explanation is also clear and powerful. So good and powerful that it is hard to see the world any different once you hear it. In one of the Sherlock Holmes stories, Holmes says ""The world is full of obvious things which nobody by any chance ever observes."" In TV tropes this is called <a href=""http://tvtropes.org/pmwiki/pmwiki.php/Main/SeinfeldIsUnfunny"" rel=""nofollow"">Seinfeld Is Unfunny</a>:</p>

<blockquote>
  <p>It wasn't old or overdone when they did it. But the things it created
  were so brilliant and popular, they became woven into the fabric of
  that show's genre. They ended up being taken for granted, copied and
  endlessly repeated. Although they often began by saying something new,
  they in turn became the status quo.</p>
</blockquote>

<p>Additionally, it is hard to remember from the perspective of the present how devoid of theory was corporate finance in the period before Modigliani and Miller. Here's a quote from an award ceremony speech related to the Nobel award:</p>

<blockquote>
  <p>Until the latter part of the 1950s, no viable theory of corporate
  financing of investment, debt, taxes, and so forth had been developed.
  It was not till Modigliani and Miller presented their theorems that
  more stringent theorizing began to appear in this field. By treating
  financing decisions within the framework of a theory of
  financial-marketplace equilibrium, Modigliani and Miller provided the
  general guidelines for continued research in this area.</p>
</blockquote>

<p><a href=""http://www.nobelprize.org/nobel_prizes/economic-sciences/laureates/1985/presentation-speech.html"" rel=""nofollow"">Award Ceremony Speech: Presentation Speech by Professor Ragnar Bentzel of the Royal Academy of Sciences</a> </p>
","6937"
"How to prove convexity + quasilinear preferences imply concave utility?","420","","<p>Let $\succsim$ be a strictly convex and quasilinear preference relation. It's defined over, say, $\mathbb{R}^2_{+}$ and is quasilinear on good 1.</p>

<p>So, $U(x_{1},x_{2}) = x_{1} + f(x_{2})$. How to prove that $f$ is a strictly concave function?</p>

<p>I'm solving problem 15.B.8 from MWG and I can't even understand what the solutions manual did! </p>

<p>Thanks a lot in advance for any hints and ideas!</p>
","<p>Consider any $x_2'$ and $x_2''$ in $\mathbb{R}_+$. Without loss of generality, let $x_2'' &gt; x_2'$. We can choose $x_1'=f(x_2'')-f(x_2') &gt; 0$ so that $U(0,x_2'')=U(x_1',x_2')$. Let $\lambda(x_1',x_2')+(1-\lambda)(0,x_2'')$ be a convex combination of $(x_1',x_2')$, and $(0,x_2'')$. Since $\succsim$ is strictly convex and $U(0,x_2'')=U(x_1',x_2')$,
        \begin{eqnarray*} 
	&amp;&amp; U(\lambda(x_1',x_2')+(1-\lambda)(0,x_2''))  &gt;  U(x_1',x_2') \\
	&amp;\Rightarrow &amp; U(\lambda x_1'+(1-\lambda)0,\lambda x_2'+(1-\lambda)x_2'')  &gt;  \lambda U(x_1',x_2')+(1-\lambda)U(0,x_2'')\ldots(\because U(0,x_2'')=U(x_1',x_2')) \\
	&amp;\Rightarrow &amp;  \lambda x_1'+(1-\lambda)0 + f(\lambda x_2'+(1-\lambda)x_2'') &gt;  \lambda (x_1'+f(x_2'))+(1-\lambda)(0 + f(x_2''))\\
	 &amp;\Rightarrow &amp;  \lambda x_1'+(1-\lambda)0 + f(\lambda x_2'+(1-\lambda)x_2'') &gt;  \lambda x_1'+(1-\lambda)0 + \lambda f(x_2')+(1-\lambda)f(x_2'') \\
	 	 &amp;\Rightarrow &amp;  f(\lambda x_2'+(1-\lambda)x_2'') &gt;   \lambda f(x_2')+(1-\lambda)f(x_2'')\end{eqnarray*}
Therefore, $f(\cdot)$ is strict concave.</p>
","16260"
"Why is food less expensive in India than the United States?","420","","<p>India has 4x the population, less land, and far worse technology and infrastructure than the United States. Shouldn't food cost in the US be less expensive? I've never been to India, but it seems like food costs far less there from what I see on TV (10 cents a meal). Why is this? </p>
","<p>I think your intuition is right that food is cheap there. The Economist Big Mac price index suggests that <a href=""http://www.economist.com/content/big-mac-index/"" rel=""nofollow noreferrer"">India has some of the cheapest big macs in the world</a>. More generally, the index indicates that there is a strong relationship between GDP per capita (a proxy for labor costs) and Big Mac prices:
<img src=""https://i.stack.imgur.com/vIMpM.png"" alt=""Big MaC index April 2015""></p>

<p>Labor is a significant part of the costs of making food (<a href=""http://smallbusiness.chron.com/common-food-labor-cost-percentages-14700.html"" rel=""nofollow noreferrer"">25-35 percent in America</a>). Transportation is a significant part of the cost of food grown far away (<a href=""http://data.worldbank.org/indicator/IC.EXP.COST.CD"" rel=""nofollow noreferrer"">world bank data indicates that even exports fees alone can be substantial</a>). But when food is grown locally and prepared locally, the total costs are significantly determined by local labor costs. In addtion, Indian restaurants probably also serves much smaller portions than in rich countries, particularly the United States. They may also make use of less expensive ingredients generally, more stables and seasonal vegetables and less dairy and meat.   </p>
","4921"
"Proving there exists no arbitrage opportunities given 3 states and 2 assets","419","","<p>Assume there are 3 states of the world: w1, w2, and w3. Assume there are two assets: a risk-free asset returning Rf in each state, and a risky asset with Return R1 in state w1, R2 in state w2, and R3 in state W3. Assume the probabilities are 1/4 for state w1, 1/2 for state w2, and 1/4 for state w3. Assume Rf=1.0 and R1= 1.1, R2=1.0 and R3= 0.9.</p>

<p>(a) Prove that there are no arbitrage opportunities.
(b) Describe the one-dimensional family of state price vectors (q1,q2,q3)></p>

<p>For (a), I believe this is equivalent to showing there exists a state price vector.</p>

<p>I know p=Xq, but since we are only given two assets X doesn't have an inverse so I don't know how to compute q. Further, we are not given p. How do I show a state price vector exists?</p>
","<p>First, you are in fact given $p$. You can think of return as a security that costs 1 in current period and pays off $R$ in the next period. The price vector and the payoff matrix are thus
$$
p = \begin{bmatrix} 1 \\ 1 \end{bmatrix}, \  X = \begin{bmatrix} 1.1 &amp; 1.0 &amp; 0.9 \\ 1.0 &amp; 1.0 &amp; 1.0 \end{bmatrix}
$$ 
and we need to find positive vector $q$ of state prices such that $p = Xq$. Because the system is undetermined, there can be many such vectors, but as long as some of them are positive, we can be sure there's no arbitrage. To actually do the computation, one way would be to treat $q_3$ as a parameter, solve for $q_1, q_2$ as functions of $q_3$, then try to find $q_3 &gt; 0$ such that implied values of $q_1,q_2$ are positive. But in this case it's easy to see that $q = (\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$ does the job.</p>
","4555"
"What does a supply+demand curve look like for fare evasion?","419","","<p>Consider the demand curve for fare evasion on a train. The price (I suppose) would be the average amount of money paid per ride in fines, and the quantity would be the average number of fare evaders caught. The supply curve would quantify the target number of fare evaders to catch.</p>

<p><img src=""https://i.stack.imgur.com/z7pZy.png"" alt=""Typical supply and demand curve""></p>

<p>Normally technological advances push the supply curve rightward. This would correspond with more people getting caught. </p>

<p><img src=""https://i.stack.imgur.com/0KPJy.png"" alt=""enter image description here""></p>

<p>But this obviously isn't right. If it were easier to catch fare evaders, you'd intuitively expect that the average price in fines per ride for a rider would be higher, thus, quantity would go down.</p>

<p>What does the supply/demand curve really look like for fare evasion and what would be the effect of a rightward supply curve shift?</p>
","<p>The way to get the demand curve is by deriving the utility function.</p>

<p>First, the utility function needs to be defined.</p>

<p>$E(u)=(u(0)(r)+u(200)(1-r))$</p>

<p>In this case, the expected utility is the utility of spending \$0 on the fare vs the utility if you get a \$200 fine. in this case, r is the probability of getting away with it.</p>

<p>If this is greater than the utility of paying the fare, the fare will be evaded.</p>

<p>$E(u)=(u(0)r+u(200)(1-r))\geq {u(5)}$</p>

<p>The exact utility function can take many forms. Popular choices are Decreasing Absolute Risk Aversion (DARA), Constant Absolute Risk Aversion (CARA) or others. <a href=""http://en.wikipedia.org/wiki/Risk_aversion"" rel=""nofollow"">Wikipedia</a> is OK on this.</p>

<p>The next steps in this analysis are to decide on a utility function.
You will need inputs on risk of getting caught and fines.</p>

<p>After defining the utility function you will be able to derive the demand curve.</p>

<p>You will also need to define the supply curve. If the fare is something like a train ride, you may be able to set up the marginal cost=0. That allows you to only worry about the fixed cost.</p>

<p>A useful resource will be the wiki article mentioned earlier. This <a href=""http://rads.stackoverflow.com/amzn/click/0195073401"" rel=""nofollow"">Mas Collel</a> book is a very popular graduate text. I think it treats risk aversion relatively well, although I did find it not incredibly accessible.</p>
","5000"
"Effect of a good's inputs on elasticity of supply","418","","<p>I am trying the answer the question: </p>

<blockquote>
  <p>If a good is produced using inputs for which there are no substitutes, the good's</p>
  
  <ul>
  <li>A. Elasticity of supply is likely to be small</li>
  <li>B. Elasticity of supply is likely to be large</li>
  <li>C. Elasticity for demand will be small</li>
  <li>D. Elasticity of demand will be large</li>
  </ul>
</blockquote>

<p>I am unsure of the correct answer. I don't think it would be (C) or (D) as the question notes that what goes into the good is likely substitutes, not the good itself. That leaves (A) and (B) I don't however see how these would effect the elasticity of supply. Elasticity of supply is defined as % change in quantity supplied divided by % change in price. I am failing to see how the price of a substitute would affect what is in the numerator or denominator. How is the quantity supplied of a product and the price at which it is sold dependent on the fact the substitutes are unavailable? Producers could adjust either quantity or price in order to make up for the substitute-less good. I would greatly appreciate some insight. </p>
","<p>Consider the extreme case: all available quantity of the no-substitute input is already employed.  </p>

<p>To trace the supply function, let's assume that we are already at some price level, and let's increase the price of the final good: will quantity supplied increase? No, <em>because it cannot do so</em> -there is no available additional input to use for this increase. In this extreme case the price elasticity of supply of the final good is <em>zero</em>, due to the situation in the inputs market.</p>

<p>Assume now that a little quantity of the no-substitute input is still unemployed. Being unique, we expect that it will command a high price if it is demanded for employment. So increasing quantity supplied of the final good, bears a high cost in terms of steeply increasing production costs. In this case, the price elasticity of supply of the final good is not zero, but ""small""...</p>

<p>...compared to the case where the inputs needed for production are generally available and so the cost to employ them is smaller than in the previous case. Here we expect that under the same as before final-good price increase, final-good suppliers will find it profitable to increase their quantity supplied more than in the former case -so here the price elasticity of supply of the final good will be ""large""(er).</p>
","8545"
"I need something like “how to calculate equilibrium price for complete idiots”","418","","<p>My grandfather raises, sells and resells livestock and I want to help him by calculating when and for what price to (re)sell or buy livestock. As far as I understand(although I have a hunch that I need something more), I need to calculate the so-called ""equilibrium price"". I know only school level of mathematics(I know how to plot functions, find a derivative, find a primitive function).</p>
","<p>First, the equilibrium price is, at a very basic level, just the market price for livestock. If you have a perfectly competitive market (a lot of suppliers) and all livestock is about the same, then the market price should be about the best your grandfather can do.</p>

<p>That being said, there are lots of reasons why perfect competition breaks down. This can come from number of sellers (just a few for a buyer to pick from), unobserved product heterogeneity (some livestock is better than others, but can't always see it just by looking), and more. Preferences over different types of products also interact with these other issues (if there's only one person selling and he knows how much a buyer is willing to pay, he can charge exactly that amount, etc.).</p>

<p>This is where the profit-maximizing price issue comes in to play. Your grandfather wants to charge the price that maximizes his profit</p>

<p>$\pi = p*q(p) - c(q)$</p>

<p>with $q$ the demand function (how much he can sell at price $p$) and $c$ the cost function (how much it costs, including what is being given up, to ""produce"" -- whatever that means in this market -- $q$ units of the good). (Quick note: I'm abusing notation a little in the profit function, but I'm doing it to make the point). The profit maximizing price is just the price level at which the first order condition of $\pi$ is equal to zero (assuming $\pi$ satisfies some regularity conditions). This will end up in the solution that he should produce/charge such that the marginal revenue is equal to marginal cost.</p>

<p>Taking advantage of this in practice requires having a really good measure of both $q$ and $c$. Although difficult for economists, $c$ is usually straight forward for firms themselves to get because they can actually calculate their own costs. The difficult part for everyone is estimating $q$. It takes a lot of data and a really good model of the market, taking into account all the issues previously discussed.</p>

<p><a href=""https://economics.stackexchange.com/questions/5218/how-does-google-price-the-items-on-google-play/5437#5437"">This answer</a> discusses how this might be done by really big firms. Note that one of the main methods they use is experimentation. Large firms can do this easily and often. For smaller firms -- like your grandfather's, I'd expect -- some of the best data your grandfather might have is, like @denesp pointed out in a comment, his experience. If he's been at it for a while, the data that he has gathered over time selling in this market has likely given him a pretty good feel for what he can charge for what and to whom.</p>

<p>To give an example of this type of experience in practice, an economist friend of mine as an undergrad used his father's hardware business as the motivation behind a paper he was writing. He decided that he would use the store's data to estimate preferences and improve profits. He ended up pitting his estimates against his father's experience-based pricing and, try as he might, could not outperform his father's method.</p>

<p>This is not to say that you can't use models and estimation to improve profits. It does indicate, however, that this is not a simple problem and can require a lot of pretty sophisticated methods to outperform the natural market evolution that would be in many ways already internalized by your grandfather.</p>
","6174"
"A graphic calculator for simple microeconomics problems","417","","<p>I can do simple calculations in micro-economics, such as: given the utility function of a consumer, calculate his demand curves; given utility functions of two consumers and initial endowment, calculate the competitive equilibrium; etc. However, the calculations become tedious and I am looking for a software that can do them automatically. For example, I am looking for a software where I can:</p>

<ul>
<li>Define utility functions, e.g. $u_1(x,y) = x^2 y$, $u_2(x,y) = x y^2$;</li>
<li>Define initial endowments $(x_1,y_1)$ and $(x_2,y_2)$;</li>
<li>Find and plot all the Pareto-efficient allocations;</li>
<li>Find and plot all the envy-free allocations;</li>
<li>Find a competitive equilibrium.</li>
</ul>

<p>Is there a software that can do this? Or maybe a package for a general symbolic math software?</p>
","<p>I wrote some silly program where you just fix endowment $e=(e_1,e_2)$ and utility functions $u=(u_1(x_1,y_1),u_2(x_2,y_2))$. The example provides an illustration for your utility functions and $x_1+x_2=1$ and $y_1+y_2=1$. I've drawn 100 indifference curves on an equally spaced grid of given utility levels $\bar u_1\in[u_1(0,0),u_1(1,1)]$ (blue) and $\bar u_2\in[u_2(0,0),u_2(1,1)]$ (red). The black line is the contract curve.</p>

<p>I added a second figure with some initial endowment $e_1 = (0.25, 0.75)$, $e_2 = (0.75, 0.25)$ and core.</p>

<p><a href=""https://i.stack.imgur.com/o2OAf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/o2OAf.png"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/scZkI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/scZkI.png"" alt=""enter image description here""></a></p>

<pre><code>e1 = [0.25 0.75];
e2 = [0.75 0.25];

X = 0.0:0.01:(e1(1)+e2(1));
Y = 0.0:0.01:(e1(2)+e2(2));

syms x1 y1 x2 y2 u1_bar u2_bar

u1 = x1.^2*y1;
u2 = x2*y2.^2;

I1_fun = matlabFunction(solve(u1_bar == u1, y1, 'PrincipalValue', true));
I2_fun = matlabFunction(solve(u2_bar == u2, y2, 'PrincipalValue', true));

u1_x = diff(u1, x1);
u1_y = diff(u1, y1);

u2_x = diff(u2, x2);
u2_y = diff(u2, y2);

u2_x = subs(u2_x, [x2,y2], [X(end) - x1, Y(end) - y1]);
u2_y = subs(u2_y, [x2,y2], [X(end) - x1, Y(end) - y1]);

contract_curve = matlabFunction(solve(u1_y/u1_x == u2_y/u2_x, y1));

u1_min = double(subs(u1, [x1,y1], [X(1), Y(1)]));
u1_max = double(subs(u1, [x1,y1], [X(end), Y(end)]));
u1_Array = linspace(u1_min, u1_max, 100);
I1_Array = zeros(length(X), length(u1_Array));

for i = 1:length(u1_Array)
I1_Array(:,i) = I1_fun(u1_Array(i), X);
end

u2_min = double(subs(u2, [x2,y2], [X(1), Y(1)]));
u2_max = double(subs(u2, [x2,y2], [X(end), Y(end)]));
u2_Array = linspace(u2_min, u2_max, 100);
I2_Array = zeros(length(X), length(u2_Array));
for i = 1:length(u2_Array)
I2_Array(:,i) = I2_fun(u2_Array(i), X);
end

hold on
[AX, H1, H2] = plotyy(X, I1_Array, 1-X, I2_Array)
set(AX(:),'YLim',[0 1]);
set(AX(:),'YTick',[0:0.1:1])
set(H1(1:length(u1_Array)), 'Color', 'b'); 
set(H2(1:length(u2_Array)), 'Color', 'r');
set(AX(2),'YDir','reverse')
axis(AX,'square') 
%str1 = '\bullet e=(e_1,e_2)';
%text(e1(1),e1(2),str1)
plot(X, contract_curve(X), 'k', 'linewidth', 2)
hold off
</code></pre>
","9382"
"How is momentum justified as a common risk factor?","415","","<h1>Momentum as a common risk factor?</h1>

<p>This question is partly a follow-up to another question found <a href=""https://economics.stackexchange.com/questions/107/examples-of-factors-in-the-icapm"">here</a>. In this other question it was noted in momentum is difficult to explain as a common risk factor in factor pricing models like the intertemportal capital asset pricing model (I-CAPM) or arbitrage pricing theory (APT). In these models, it is assumed that exposure to one of these factors represent exposure to some sort of undesirable risk. In this question, I'm trying to understand how to interpret exposure to momentum as exposure to some form of common risk. In particular, I'd like to know</p>

<ol>
<li>Who was the firm to include momentum as a risk factor? What was the explanation?</li>
<li>It seems like momentum is often attributed to behavioral over- or under-reaction. (This could be irrational or maybe even rational-overreaction, I suppose---right?) Is there an interpretation that rationalizes momentum? (I mean one that gives an explanation where exposure to momentum is a bad thing.)</li>
</ol>

<h2>For some reference:</h2>

<p><a href=""http://www.bauer.uh.edu/rsusmel/phd/jegadeesh-titman93.pdf"" rel=""nofollow noreferrer"">Jegadeesh and Titman (1993)</a> review some explanations of momentum,
including overreaction to information, relation to size effect and systematic risk, short-term price pressure, lack of liquidity, delayed stock price reaction to common factors</p>

<p>The paper argues that the ""relative strengths"" premium (the strategy of buying past winners) is not due to exposure to systematic risk, cannot be attributed to ""lead-lag effects that result from delayed stock price reactions to common factors,"" but that the evidence seems to be consistent with delayed price reactions to firm-specific information.</p>

<blockquote>
  <p>Stocks in 
  the winners portfolio realize significantly higher returns than the stocks in 
  the losers portfolio around the quarterly earnings announcements that are 
  made in the first few months following the formation date. However, the 
  announcement date returns in the 8 to 20 months following the formation 
  date are significantly higher for the stocks in the losers portfolio than for the 
  stocks in the winners portfolio. </p>
  
  <p>The evidence of initial positive and later negative relative strength returns 
  suggests that common interpretations of return reversals as evidence of 
  overreactlon and return persistence (i.e., past winners achieving positive 
  returns in the future) as evidence of underreaction are probably overly 
  simplistic.</p>
</blockquote>
","<p>The Jegadeesh and Titman (1993) paper is usually considered Original Source, though I'm sure you could find something earlier that looks similar if you looked hard enough.</p>

<p>I don't think there is a satisfactory explanation. Momentum is <a href=""http://www.kentdaniel.net/papers/published/cfr_12.pdf"" rel=""nofollow"">not correlated with macroeconomic variables</a>, it <a href=""http://faculty.chicagobooth.edu/john.cochrane/teaching/35904_Asset_Pricing/Fama_French_multifactor_explanations.pdf"" rel=""nofollow"">does not seem to reflect</a> persistent exposure to other (known) sources of risk, and is driven <a href=""http://rnm.simon.rochester.edu/research/MOM.pdf"" rel=""nofollow"">almost entirely by the 7 to 12 months before stocks are chosen</a> as part of a momentum portfolio. This all makes it extremely difficult to put a solid theoretical model to it that doesn't have a behavioral aspect.</p>

<p>Recently (mid 2009), there was a momentum crash in the market. <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2371227"" rel=""nofollow"">Daniel and Moskowitz</a> argue that momentum has rare ""panics"" periods like this, where crashes occur for momentum. So during normal periods investors may be being compensated for this risk. The question becomes ""what are these crashes caused by?"" The authors make the case that following a period of declining stock values, momentum portfolios will be long a lot of low market beta stocks, and short a lot of high beta stocks. If there is a sudden rebound in the market, momentum strategies will experience a crash. So this is at least suggestive of a direction for more formal modeling, but they ultimately suggest a behavioral interpretation may be necessary as well.</p>

<p>If you have not seen it, <a href=""http://www.annualreviews.org/doi/pdf/10.1146/annurev-financial-102710-144850"" rel=""nofollow"">Jegadeesh and Titman (2011)</a> review the evidence for momentum in more detail, and explore behavioral explanations for momentum, of which I have little knowledge.</p>
","244"
"Intuition behind Comparative Advantange","414","","<p>I already read and ask NOT about pp 52-54, <em>Principles of Microeconomics</em>, 7 Ed, 2014, by N Gregory Mankiw. I understand such numerical examples that corroborate Comparative Advantage, but how can I intuit comparative advantage? I wish to quash my need to revisit these numerical examples to recollect this idea. i start with definitions from pp 52 and 53 (supra):</p>

<blockquote>
  <p><strong>absolute advantage</strong> = the ability to produce a
  good using fewer inputs
  than another producer</p>
  
  <p><strong>comparative advantage</strong> = the ability to produce
  a good at a lower
  opportunity cost than
  another producer</p>
</blockquote>

<p>I read <a href=""http://internationalecon.com/Trade/Tch40/T40-0.php"">this</a> by <a href=""http://economics.columbian.gwu.edu/steven-m-suranovic"">Prof Steven M. Suranovic</a> and understand the gardening example, but still lack intuition. </p>

<blockquote>
  <p>First, ... comparative advantage is <a href=""http://oecdinsights.org/2011/10/11/comparative-advantage-doing-what-you-do-best/"">clearly counter-intuitive</a>. ... Secondly, the theory is easy to confuse with ... the theory of absolute advantage. The logic behind absolute advantage IS quite intuitive. This confusion between these two concepts leads many people to think that they understand comparative advantage when in fact, what they understand is absolute advantage.</p>
  
  <p>However, instead of assuming, as Adam Smith did, that England is more productive in producing one good and Portugal is more productive in the other; [David] Ricardo assumed that Portugal was more productive in both goods. Based on Smith's intuition, then, it would seem that trade could not be advantageous, at least for England. </p>
</blockquote>
","<p>A classic example is to consider the question</p>

<blockquote>
  <p>Why doesn't Tiger Woods mow his own lawn?</p>
</blockquote>

<p>Woods is an excellent golf player. But he also may be excellent at mowing. Still, if he devotes time to mow the lawn he sacrifices time playing golf, in which he is much more productive.</p>

<p>A gardener who is skilled at mowing lawns but not at playing golf sacrifices less in order to mow, so even though Tiger Woods may be better at it (i.e. has an <em>absolute</em> advantage), the gardener has a <em>comparative</em> advantage. Both benefit if the gardener is paid for the time that he mows the lawn by Tiger Woods who in the time he saves can earn more by concentrating on golf.</p>
","4478"
"What kind of economic freeware exists for economics students?","412","","<p>Can anyone recommend some free software for students studying economics for use in senior projects, theses, or dissertations?</p>
","<p>I never understood why discussion about specialized software should be off-topic in the specialty's website. And of course I don't agree. So:</p>

<p>Before diving into <a href=""http://www.r-project.org/""><strong>R</strong></a>, which indeed appears to be the dominant (and rich) freeware for statistical computing, one can try <a href=""http://gretl.sourceforge.net/""><strong>Gretl</strong></a>. It is an Econometrics freeware, with a lot of functionality, a very good Random Number Generator, and has both menu-driven implementation but also code-writing by the user. It is easier for beginners - but it is serious stuff. The <a href=""http://en.wikipedia.org/wiki/Gretl"">wikipedia page</a> for Gretl lists some reviews about Gretl.  </p>

<p>The other kind of ""economics"" (not mathematics) software apart from econometrics packages would be specialized simulation software, for say Dynamic Stochastic General Equilibrium Models, or micro-applications.  For DSGE, one such is <a href=""http://www.dynare.org/""><strong>Dynare</strong></a>.  A lot of DSGE-code for various other software can be found at <a href=""http://www.dsge.net/"">International Network for DSGE Modeling, Monetary and Fiscal Policy</a>.</p>
","421"
"Purchasing Power Parity (PPP) and Law of One Price (LOP)","410","","<p>If PPP were to be satisfied in reality, does that mean the Law Of Price is satisfied for all goods in a basket of goods used to generate the price levels of the country? Or, since PPP uses only average price of basket, is there possibility of ""accidentally"" PPP is satisfied without holding LOP for each good?</p>
","<p>If PPP holds, so does the LOP.</p>

<p>The law of one price (LOP) is an economic concept which posits that ""a good must sell for the same price in all locations"". The law of one price constitutes the basis of the theory of purchasing power parity and is derived from the no arbitrage assumption.</p>
","5115"
"Destroying the dollar","409","","<p>Let's destroy the USD dollar: I am the government of a small, economically and geopolitically unimportant country that has its own currency and a local central bank. I order the local central bank (at gun point, if need be) to lend me <em>dollars</em>. Is there a <em>technical</em> problem to do this? No, this is just an exchange of papers and electronic messages -we can write on them anything we want, especially with a gun in our head. We can attach to these electronic records any three-letter code we want, so why not ""USD""?  </p>

<p>Now I have a bank account with a balance of gazillions and gazillions of dollars- and USD ones, the heavy stuff.  </p>

<p>I can pay off my public debt, make every citizen rich (or just those that I like), import all the luxuries in the world, buy as much energy as I want, whatever. After all, I will be paying in <em>USD dollars</em> right? I will be wire-transferring from a bank account, an electronic signal that will contain some digits and the code ""USD"" attached.  </p>

<p><strong>So let's hear it from the experts: what kind of checks has the international community in place in order to effectively avoid such a situation?</strong></p>

<p>And what if, as the most long-lasting counterfeiters know, we were to do this <em>modestly</em>, just a little at the time to help a tad with the local government budget, but without ""showing-off riches"" to the rest of the world??</p>
","<p>I think you misunderstand what ""electronic money"" is - moving electronic money around isn't simply a matter of sending the right ""codes"" - it is ultimately about asking the central bank of that currency to move money around.</p>

<p>Sure you can open up excel and write in it ""I have \$100"" but that isn't USD, much as writing \$100 on a piece of paper doesn't make it a \$100 bill.</p>

<p>In order to lend you dollars I actually have to have some dollars to lend you.  That means I need a reserve account with one of the 12 Federal Reserve banks.  <strong>There are no electronic USD that are not ultimately in a Federal Reserve Account</strong>.</p>

<p>The ""ultimately"" in that sentence is there because banks can (and do) form hierarchies.  Only the largest (""Tier 1"" banks, sometimes called ""clearing banks"") actually have a reserve account with the central bank in a given currency.  Other, Tier 2, banks will simple hold accounts with Tier 1 banks.  Smaller local banks may even be Tier 3.  When it comes to foreign currency dealing, you could be even further down the chain (i.e. a small bank in Australia may be Tier 4 for USD)</p>

<p>Because of this hierarchy a certain amount of electronic banking can be done without moving reserves.  A transfer only needs to progress up the hierarchy until it gets to a common bank between the two customers.</p>

<p>So for example:</p>

<ul>
<li><p>A payment between two accounts at the same bank, can be done on that bank's systems.</p></li>
<li><p>A payment from an account at a Tier 2 bank, to a different Tier 2 bank might be done using a shared Tier 1 bank.  The Tier 2 bank's are ""customers"" of the Tier 1 bank, and so the Tier 1 bank can do the transaction on their system.</p></li>
<li><p>A payment between customers that ultimately fall under two different Tier 1 banks <strong>must</strong> be done by at a Federal Reserve bank.</p></li>
<li><p>The US adds an extra complication, because there are 12 Fed Reserve banks - if two Tier 1 banks don't bank with the same Fed Branch, then the Fed Reserve System also has to go ""one step higher"" and the New York Fed acts as the very top bank: ""<a href=""https://economics.stackexchange.com/q/194/119"">How do reserves move between the 12 federal reserve banks?</a>"" explores exactly how that is done.</p></li>
</ul>

<p>So the problem in your scheme is you couldn't get your central bank ""into"" this pyramid of banks.  </p>

<p>Your central bank's computer can show $1tr on screen but the only way to transfer to another bank, would be to instruct YOUR Fed bank to take money out of YOUR fed reserve account and put it into the other bank's account.  Your central bank can't make reserve dollars.</p>

<hr>

<p><strong>Aside:</strong>  An alternative way of looking at this, for those familiar with how BitCoins work, is to note that the important feature of electronic money is to prevent double spending.  BitCoin does this with the BlockChain; the USD equivalent of the block-chain is held on the Fed Reserve computers.  You can't just declare yourself to have billions of bitcoins - to spend them you have to get your transactions onto the BlockChain.  With electronic USD you have to get your transactions onto the Fed ledger.  Only the Fed has a copy of this and their say is final.  There would be no way for your central bank to change the Fed ledgers.</p>
","6170"
"How does the core relate to strong equilibrium?","409","","<p>An allocation is in the core if there's no coalition that blocks it.</p>

<p>A strong equilibrium (<a href=""http://www.ma.huji.ac.il/raumann/pdf/Acceptable%20Points%20in%20General.pdf"" rel=""nofollow"">Aumann, 1959</a>) is a Nash equilibrium in which no coalition, taking the actions of its complements as given, can cooperatively deviate in a way that benefits all members of the coalition.</p>

<p>How are these distinct? I usually don't think of the core as a solution concept, but I'm struggling to disentangle it from strong equilibrium.</p>
","<p>Strong Nash equilibrium is different from core mainly because of communication. In a Strong Nash, unlimited private communication is allowed. The core is a concept that is linked to <a href=""http://en.wikipedia.org/wiki/Coalition-proof_Nash_equilibrium"" rel=""nofollow"">Coalition-proof Nash equilibrium</a> rather than Strong Nash. People can freely communicate but <strong>cannot make binding commitment</strong> before deciding.</p>

<p>In <a href=""http://link.springer.com/article/10.1007%2FBF01213445#page-1"" rel=""nofollow"">some games</a>, both happen to be the same, but in generality, the core is a concept derived from Coalition-proof Nash equilibrium rather than from Strong Nash Equilibrium.</p>
","5705"
"How can there be an electronic bank run?","407","","<p>I read that at 2008 there was an electronic bank run.</p>

<p>From what I undestand bank runs occur due to the fractional reserve banking system. The actual real money you can hold on your hand are a fraction of the total money in banks. So if everyone goes to ATM and gets the money in their hand, it means that the bank runs out of the ""real money"" and people can't withdraw these ""real money"".</p>

<p>So if the same number of people, instead of withdrawing from the ATMs, do electronic transactions that eg get their money from a bank to another bank (or any other institution) how can there be a bank run? It just doesn't make sense to me.</p>
","<p>What you describe is the ""traditional"" bank-run.  </p>

<p>The 2008 incident you refer to, was called an ""electronic bank run"", because the problem was not caused by people trying to get tangible paper money in their hands in excess of the actual paper money available to the banks.  </p>

<p>The problem was that through electronic banking and electronic wire-transfer orders ""funds were redirected out of the U.S. money markets"" as one account of the incident puts it.  </p>

<p>So why is this a problem? </p>

<p>Because under ""fractional banking"", <em>electronic money functions exactly as paper money</em>. You work, and your employer pays your salary through a wire transfer. You go buy something and you pay with your debit card, where you transfer electronic money from your account to the shop's account.  </p>

<p>In other words, electronic money, once created, <em>is as much actual purchasing power as paper money is.</em> It is <em>wealth</em>.</p>

<p>But this means that this ""electronic bank run"" was <em>impoverishing</em> the US banking system. But since the transfers were electronic, by necessity they went out of the US economy also -to some bank accounts in other countries.  It was <em>wealth going out of the US economy</em>, not just paper money going out of the banks but still <em>in</em> the economy -and at a speed and volume unimaginable in the old days, due to the wonders of the internet and digital technology.  </p>

<p>So essentially, it is a totally <em>different</em> kind of problem (and more serious) than the ""traditional"" bank run, so it should perhaps have been characterized by using another term.</p>
","3286"
"Solow model: Partial derivative of y with respect to n","407","","<p>I am trying to find the derivative of $y$ with respect to $n$. All I need to do is take the partial derivative $\frac{\partial y}{\partial n}$ of the function: $sf(k) = (n+g+\delta)k$  Here is what I get using the chain rule, but it's wrong:</p>

<p>$$sf'(k)  \frac{\partial k}{\partial n} = (n+g+\delta)\frac{\partial k}{\partial n}$$</p>

<p>To solve $\frac{\partial y}{\partial n}$ some more steps are required, but as far as I know the equation is already wrong. From what I have seen the right side should be augmented by k and then it would be right. Any ideas where the derivation went wrong?</p>
","<p>You need to use the <a href=""http://en.wikipedia.org/wiki/Implicit_function_theorem"">implicit function theorem</a>. The long-run relationship implies</p>

<p>$$
0 = F(n,k) = s f(k) - (n+g+\delta)k,
$$</p>

<p>and this implicitly defines function $k(n)$. The derivative is then</p>

<p>$$
\frac{d k(n)}{d n} = -\frac{\partial F / \partial n}{\partial F / \partial k} = \frac{k}{s f'(k) - (n+g+\delta)},
$$</p>

<p>which can be evaluated once one has solved for particular long-run (n,k) combination. To finally obtain derivative of output $y = f(k)$ wrt. $n$, simply use chain rule:</p>

<p>$$
\frac{d y}{d n} = f'(k(n)) \frac{d k(n)}{d n}.
$$</p>
","4455"
"Can a game with a unique pure strategy Nash equilibrium also have a mixed strategy equilibria?","406","","<p>Consider an arbitrary 2x2 simultaneous game with complete information. Say that the model has only one pure-strategy Nash equilibrium. For example (first pay-off refers to Player 1): </p>

<pre><code>                    Player 2
           +---+-------+-------+
           |   |   A   |   B   |
           +---+-------+-------+
Player 1   | A | (1,2) | (2,1) |
           | B | (3,3) | (1,1) |
           +---+-------+-------+
</code></pre>

<p>Here, (3,3) is the only pure-strategy Nash equilibrium. The reason there is just one is, apparently, because one of the players have a dominant strategy (Player 2 always prefers A). If we change this, we would get two pure-strategy equilibria.</p>

<p>Abstracting from the fact that the pure-strategy equilibrium is also a mixed strategy one with probability 0/100%, <strong>does any simple game with just one pure-strategy equilibrium have no mixed strategy equilibrium?</strong> Is there a formal proof of this?</p>

<p>I educated guess is that there is no mixed strategy equilibrium. The ""proof"" I can think of is a best response plot. Basically, one player has a dominant strategy which means that for any probability, her response is a vertical/horizontal line at 0 or 1 (depending how probability is defined). Thus, regardless of how the other player's best response line looks like (i.e. where the indifference probability is), it will only cross the other player's line in one point. That point is the pure-strategy equilibrium.</p>

<p>PS: the adjective ""simple"" is to avoid more complex game scenarios like repetition, cooperation, incomplete information, etc. </p>
","<p>In general:
<br> If you draw the numbers of the payoff matrix from continuous i.i.distributions then with probability 1 the game will have an odd number of equilibrium points. (Meaning the sum total of pure and mixed equilibria.) 
See <a href=""https://mindyourdecisions.com/blog/2014/10/07/game-theory-tuesdays-why-most-games-have-an-odd-number-of-nash-equilibria/"" rel=""nofollow noreferrer"">here</a> or <a href=""https://link.springer.com/article/10.1007/BF01737572"" rel=""nofollow noreferrer"">here</a>.</p>

<p>If your game is 2x2 this means that with probability 1 it will have 1 or 3 equilibria. It can only have 2 equilibria if the game is 'degenerate', which would rely on the existence of weakly dominated strategies. An example is</p>

<pre><code>                   Player 2
           +---+-------+-------+
           |   |   A   |   B   |
           +---+-------+-------+
Player 1   | A | (1,1) | (0,0) |
           | B | (0,0) | (0,0) |
           +---+-------+-------+
</code></pre>

<p>Here both (A,A) and (B,B) are Nash-equilibria. There are no other equilibria, as A is better than B if the opponent plays A with non-zero probability. 
<br> (B,B) is not a trembling-hand perfect equilibrium, but that would be an additional requirement.</p>

<p>As the existence of weakly dominated strategies is necessary for exactly 2 NE and in a 2x2 game that makes mixed equilibria impossible, this means that you cannot have exactly 1 pure and 1 mixed NE.</p>
","17367"
"Is there a difference between buying a currency and selling the currency to be converted to?","402","","<p>I'm not an economist. I'm looking to exchange my CAD to EUR. I watched the rates on a exchange office, and I found something strange:</p>

<pre><code>We buy:                   We sell:
1 EUR = 1,4946 CAD (1)    1 EUR = 1,3280 CAD (2)
1 CAD = 0,6691 EUR (3)    1 CAD = 0,7530 EUR (4)
</code></pre>

<p>How can there be 4 different rates? I understand why CAD -> EUR is different of EUR -> CAD with the supply and demand. When the exchange office buys 1 CAD, it sells EUR too. I supposed it was to make things easier, so I checked it:</p>

<pre><code>1 EUR = 1,3280 CAD (2)
=&gt; 1,3280 CAD = 1 EUR

1 CAD = 0,6691 EUR (3)
1,3280 * 1 CAD = 1,3280 * 0,6691 EUR
=&gt; 1,3280 CAD = 0.8886 EUR
</code></pre>

<p>Here, we found that it's indeed, more interesting for the customer to accept a sell than buying (from the office point of view for the words buy/sell).
But is the difference, normal? And why?</p>
","<p>Buy and sell rates are different because the currency vendor wants to make a profit and is also taking some risk with the exchange. It is possible that she cannot unload all the CADs they buy from you immediately and then perhaps in the future they will depreciate. (Perhaps they will appreciate. It is uncertain, hence there is risk.)</p>

<p>The same applies to buying and selling euros.</p>

<p>Usually there is some middle rate $x$ EUR/CAD. The vendor will deviate 1-2% from this in the direction favorable to her, depending on the direction of the deal (buying EURs with CAD or the other way around). You can look up something close the middle rate on <a href=""http://xe.com"" rel=""nofollow noreferrer"">XE</a>. Currently this is about 1.394 CAD/EUR. Your vendor seems to sell at a premium that seems higher than normal to me, so perhaps see if you can find another currency merchant.</p>
","14938"
"Is this non-separable utility?","400","","<p>On <a href=""http://www.econ.umn.edu/~vr0j/ec8503-10/daolufrisch.pdf"" rel=""nofollow"">this presentation</a>, the last slide is titled ""Non Separable Utility"", and the preferences given are</p>

<p>$$ \frac{\left(c^\gamma (1-n)^{1-\gamma}\right)^{1-\sigma}}{1-\sigma}$$ </p>

<p>However, I can log-transform them as </p>

<p>$$ \log\left[ c^{\gamma(1-\sigma)} (1-n)^{(1-\gamma)(1-\sigma)} (1-\sigma)^{-1}\right]$$</p>

<p>which are clearly separable. Did I miss something?</p>
","<p>You are right, these preferences are separable. A way to see it is to notice that
\begin{equation*}
U(c,n) \geq U(c',n) \Rightarrow U(c,n') \geq U(c',n')
\end{equation*}
for any $n,n'$, and 
\begin{equation*}
U(c,n) \geq U(c,n') \Rightarrow U(c',n) \geq U(c',n')
\end{equation*}
for any $c,c'$.
They are even additively separable, as your log-transformation shows.</p>
","6995"
"Why is the yen getting stronger even with negative interest rates?","399","","<p>Checking this <a href=""http://www.xe.com/currencycharts/?from=JPY&amp;to=USD&amp;view=1W"" rel=""nofollow"">graph</a> we can see that 1 Yen is worth increasingly more dollars this past week. </p>

<p>I wonder why is this, specially when the BoJ has imposed negative nominal interest rates.</p>

<p>It seems a bit strange...</p>
","<p>Negative interest rates are not incompatible with appreciation of the local currency. As pointed out by the economist (<em><a href=""http://www.economist.com/blogs/economist-explains/2016/02/economist-explains-6"" rel=""nofollow"">Why investors buy bonds with negative yields</a></em>), some investors buy bonds to place bets on currencies. Thus, it does not matter so much that the interest rate is negative.</p>

<p>Thus, the variation of the yen reflects other trends. It is very tricky to point out at one event or idea in particular, but here are a few possible drivers of the appreciation of the Yen:</p>

<ul>
<li><p>The dollar is weakening, following the <a href=""http://www.economist.com/blogs/economist-explains/2016/02/economist-explains-6"" rel=""nofollow"">release of the minutes</a> of the Fed meeting which showed that the central bank does not intend to raise interest rates in April.</p></li>
<li><p>Japan is <a href=""http://www.bloomberg.com/news/articles/2016-04-06/japan-is-fast-approaching-the-quantitative-limits-of-quantitative-easing"" rel=""nofollow"">running out of options</a> to put downward pressure on the yen. The central bank already buys everything in sight, and thus would have difficulties to increase the money supply. The feeling that central banks are loosing grip is very tangible since a few months (if not years)</p></li>
<li><p>G20 countries <a href=""http://www.bloomberg.com/news/articles/2016-02-27/brexit-and-refugees-join-g-20-worry-list-in-draft-communique"" rel=""nofollow"">recently agreed</a> to not proceed to competitive devaluations of their currency. Therefore, investors might expect that Yen won't go down easily, and that the most logical path is unpward.</p></li>
<li><p>Japan's Prime Minister Shinzo Abe seems to hesitate to proceed to <a href=""http://www.bloomberg.com/news/articles/2016-01-27/japan-s-wreckage-from-past-tax-rises-spurs-debate-on-2017-plan"" rel=""nofollow"">planned increase in sale tax</a>. The first increase had a desastrous short-term effect on the economy, and most firms have a pessimistic outlook (<a href=""http://www.reuters.com/article/us-japan-economy-pmi-idUSKCN0WO064"" rel=""nofollow"">latest PMI 49.1</a>). Therefore, it becomes more and more likely that the government will delay the increase in sale tax, and potentially also try to stimulate the economy further.</p></li>
</ul>

<p>These are all guesses. It might be that one or more of the above guesses actually moved the Yen. Or maybe it didn't and something else is happening. Maybe investors aren't as rational as we think they are and they just bet on the Yen because of their gut without logical reasons.</p>
","11527"
"How to measure Tobin's q?","397","","<p>How do people calculate Tobin'q empirically? </p>

<p>Does anyone use it to make investment decisions? In particular, the version I learnt has no company debt involved with only capital under consideration, will this affect empirical research? </p>
","<p>If you are interested in Tobin's (average) q,  you might find useful <em>A Simple Approximation of Tobin's q</em> (<a href=""http://www.jstor.org/stable/3665623?seq=1#page_scan_tab_contents"" rel=""nofollow"">Chung and Pruitt (1994)</a>). That paper has a highly accurate approximation for Tobin's Q using Compustat. While the JSTOR copy I linked to is pay-walled, other versions appear not to be. </p>
","8683"
"Deriving intertemporal budget constraint from flow constraint","395","","<p>I am trying to learn how to solve difference equations in order to derive intertemporal budget constraints. Consider the government's flow budget constraint:</p>

<p>$$\frac{B_{t}-B_{t-1}}{p_{t}} + \frac{M_{t}-M_{t-1}}{p_{t}} + s_{t} -i_{t-1}\frac{B_{t-1}}{p_{t}} = 0$$ </p>

<p>where $s_{t}$ is real taxes net of government consumption. I re-write the above as</p>

<p>$$\frac{R_{t}B_{t-1} + M_{t-1}}{p_{t}} = \frac{B_{t} + M_{t}}{p_{t}} + s_{t}$$ </p>

<p>where $R_{t}$ is the gross nominal interest rate.</p>

<p>Now I am quite lost. I think what is confusing me is that I have $t-1$ <strong>and</strong> $t$ terms on the left-hand side. The examples I have tried before are usually on the form $a_{t} = a_{t+1} + b_{t} +(...)$ which I then solve ""forward"" by substituting for $a_{t+1}$ over and over again until I see a pattern developing. But in this case I can't really re-write the LHS in a proper manner. </p>

<p>Any thoughts on how I should proceed? And if there are any books that go through difference equations I would be very interested in some names as I am self teaching myself so far.</p>

<p>EDIT: Thanks to @luchonacho I have obtained the following:</p>

<p>$B_{t} = \frac{B_{t+T}}{R_{t+1}R_{t+2}...R_{t+T}} + \frac{D_{t+T}}{R_{t+1}R_{t+2}...R_{t+T}} ...\frac{D_{t+1}}{R_{t+1}}$ since we are in an inifite period world I write this as""</p>

<p>$B_{t} = \lim_{T\to\infty}  \frac{B_{t+T}}{R_{t+1}R_{t+2}...R_{t+T}} + \sum\limits_{j=1}^{\infty} \frac{D_{t+j}}{\prod_{s=1}^{j} R_{t+s}}$</p>

<p>I might have messed up the summation/product notation but this is one of the expressions I have seen for the intertemporal constraint. However, another common way I have seen it written is as follows:</p>

<p><a href=""https://i.stack.imgur.com/1MzQt.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1MzQt.png"" alt=""enter image description here""></a></p>

<p>Ignore the right-hand side as it assumes a functional form of the utility function. I am interested in obtaining an expression with both $B_{t-1}$ and $M_{t-1}$ on the LHS. Is there a way I can go from the expression I obtained above to the one with both $B_{t-1}, M_{t-1}$? I am interested in deriving this because I want an expression for the valuation of all government liabilities. </p>
","<p>Take your second equation, move it forward one period, and rearrange. You get:</p>

<p>$$ B_t = \frac{p_{t+1} s_{t+1} + \Delta M_{t+1}}{R_{t+1}}  + \frac{B_{t+1}}{R_{t+1}} $$</p>

<p>Then, define the <em>nominal primary deficit</em> as $D_{t+1} = -(p_{t+1} s_{t+1} + \Delta M_{t+1})$. The above transforms into:</p>

<p>$$ B_t = -\frac{D_{t+1}}{R_{t+1}} + \frac{B_{t+1}}{R_{t+1}} $$</p>

<p>which has the format you are looking for. To find the infinite-period intertemporal budget constraint, simply proceed with forward substitution.</p>

<p>The notation I've used (regarding the deficit) is taken from <a href=""http://press.princeton.edu/titles/9743.html"" rel=""nofollow noreferrer"">Wickens</a>, Chapter 5. The above is roughly equal to equation (5.11) in the book. There, the author has a more general expression, which includes inflation, GDP growth, and debt-to-GDP ratio. Your example is a simplification of his. I suggest you go through <a href=""http://press.princeton.edu/chapters/c9743.pdf"" rel=""nofollow noreferrer"">Section 5.4</a> of the book, which it gives a very detailed analysis of the Government budget constraint (it also gives the solution you are looking for, in case you want to compare).</p>

<hr>

<p>To find the final expression you are looking for (after edit), take your second equation and replace $B_t$ with the infinite-period intertemporal budget constraint:</p>

<p>$$\frac{R_{t}B_{t-1} + M_{t-1}}{p_{t}} = \frac{B^*_{t} + M_{t}}{p_{t}} + s_{t}$$ </p>

<p>where $B^*_t$ is the result of the forward substitution exercise.</p>
","17837"
"Intertemporal Utility Maximization","394","","<p>Suppose an economic agent’s life is divided into two periods, the
first period constitutes her youth and the second her old age. There
is a single consumption good, C, available in both periods. The
agent’s utility function is given by</p>

<p>$$U(C_{1},C_{2}) = \frac{C_{1}^{1-\theta }-1}{1-\theta }+\frac{1}{1+\rho}\frac{C_{2}^{1-\theta }-1}{1-\theta }$$</p>

<p>with $0&lt;θ &lt; 1,ρ &gt; 0$, and where the first term represents utility from consumption during youth. The second term represents discounted utility from consumption in old age, $1/(1+ ρ )$ being the discount factor.</p>

<p>During the period, the agent has a unit of labour which she supplies
inelastically for a wage rate $w$ . Any savings (i.e., income minus
consumption during the first period) earns a rate of interest $r$,
the proceeds from which are available in old age in units of the only
consumption good available in the economy. Denote savings by $s$. The
agent maximizes utility subjects to her budget constraint.</p>

<p>$i)$ Show that $θ$ represents the elasticity of marginal utility with
respect to consumption in each period.</p>

<p>$ii)$ Write down the agent’s optimization problem, i.e., her problem
of maximizing utility subject to the budget constraint.</p>

<p>$iii)$ Find an expression for s as a function of $w$ and $r$.</p>

<p>$(iv)$ How does s change in response to a change in $r$? In
particular, show that this change depends on whether $θ$ exceeds or
falls short of unity.</p>

<p>$(v)$ Give an intuitive explanation of your finding in $(iv)$</p>

<hr>

<p>I am not being able to solve this problem. I proved the first part $i$.</p>

<p>$$C_{2}= (w-C_{1})(1+r)$$</p>

<p>So, $ii)$ Optimization Problem = </p>

<p>$$\frac{C_{1}^{1-\theta }-1}{1-\theta }+\frac{1}{1+\rho}\frac{C_{2}^{1-\theta }-1}{1-\theta }+\lambda (w-C_{1}-(w-C_{1})(1+r))$$</p>

<p>$iii) s=w-C_{1}$ How do we express this int terms of $w$ and $r$?</p>

<p>Any help with this sum will be appreciated.</p>
","<p>What you have is basically the Fisher Two-Period Optimization Problem. <a href=""http://www.econ2.jhu.edu/people/ccarroll/public/LectureNotes/Consumption/2PeriodLCModel/"" rel=""nofollow noreferrer"">(Fisher)</a></p>

<p>For iii)
You first need to find the Euler equation, which tells you how to optimally trade off first-period and second-period consumption.</p>

<p>For starters, your optimization problem is set up incorrectly: 
$$\frac{C_{1}^{1-\theta }-1}{1-\theta }+\frac{1}{1+\rho}\frac{C_{2}^{1-\theta }-1}{1-\theta }+\lambda (w-C_{1}-\frac{C_{2}}{1+r})$$</p>

<p>You find the Euler equation by deriving and equating the first-order conditions of both consumption terms.</p>

<p>$$\frac{1}{1+r} C_{1}^{-\theta }= \frac{1}{1+\rho}C_{2}^{-\theta }$$</p>

<p>Then just solve for $C_{1}$, substitute $C_{2}=s(1+r)$, and plug into $s=w-C_{1}$, which gives:</p>

<p>$$
s=w-(1+r)^{\frac{\theta-1}{\theta}}(1+\rho)^{\frac{1}{\theta}}s \\
s=\frac{w}{1+(1+r)^{\frac{\theta-1}{\theta}}(1+\rho)^{\frac{1}{\theta}}}
$$</p>

<p>The derivative, giving the response to a change in $r$, is:
$$
\frac{\partial s}{\partial r}= -\frac{(\theta -1) w ( 1+\rho)^{1/\theta } (1+r)^{1/\theta }}{\theta  \left((\rho +1)^{1/\theta }+r (\rho +1)^{1/\theta }+(r+1)^{1/\theta }\right)^2}
$$</p>

<p>The derivative for $0&lt;\theta&lt;1$ is positive, indicating that a higher return on saving will lead to an increase in the amount saved. Preference for first period consumption is still low enough, so that the consumer is willing to save more to consume it later. Here the substitution effect dominates the income effect.</p>

<p>When $\theta&gt;1$, the derivative is negative, meaning that preference for first period consumption is so high that the consumer is willing to lower savings for current period consumption. Here the income effect dominates the substitution effect.</p>
","15348"
"One-shot deviation principle for infinite repeated games and dynamic programming","394","","<p>In a context that future return is discounted by a constant parameter, <a href=""http://en.wikipedia.org/wiki/One-shot_deviation_principle"">one-shot deviation principle</a> holds for both repeated games and dynamic programming.</p>

<p>Because, in repeated games, a one-shot deviation refers to one history, so on equilibrium path, a one-shot deviation could produce a play that differs on more than one stages from the original equilibrium path.</p>

<p>Is it true for the sequence of state variables and control variables in dynamic programming? In other words, can a one-shot deviation generate an aforementioned sequence that differs for more than one stage?</p>
","<p>A deviation (one-shot or not) can certainly generate a sequence that differs from the optimal one for an arbitrary number of periods. </p>

<p>You could treat a dynamic programming problem as a repeated game between one player and chance. The one-shot deviation principle should then carry over from repeated games to dynamic programming.</p>
","5136"
"What does 'one dollar, one vote' mean?","393","","<p>Can you tell/ describe me what the phrase <em>'one dollar, one vote'</em> means? But you have to use basic English or kid's English. :-)</p>

<p>I found the phrase in one economics book (Introduction to Economics by Stephen L. Slavin, page 4, 1989) and I do not know what it means. I am from eastern Europe. </p>

<p>Thanks for help.</p>
","<p>It appears to suggest applying the way shareholders vote in a company to the political setting of democracy: each citizen will have as many votes as his/her monetized wealth. So the rich will have <em>officially</em> ""more say"" in what gets decided or who gets elected in public office.</p>

<p>Certainly, the general consensus is that economic power does play a role in affecting political outcomes anyway. This approach would make that an official, institutional rule.</p>
","15720"
"What is the difference between Stochastic game and Bayesian game ?","393","","<p>I was studying definitions of Stochastic and Bayesian game and it appears that Stochastic game is a generalized form of Bayesian game. Could anybody please explain the fundamental differences between Stochastic game and Bayesian game and imperfect information and incomplete information games ? </p>
","<p>In a Bayesian game, information is incomplete. To cope, players have beliefs about the state of the game. In a sense, each player strategizes as if the game was as he or she believes. So each player operates in his or her own world. And if every player plays a Nash equilibrium in one's own world, that's a Bayesian Nash equilibrium.</p>

<p>In a stochastic game, the information about the current state of the game may indeed be public. At a given time step, the next state is determined by the current state, the strategy profile played at that time step, and some stochastic process (like a Markov chain, for example). </p>

<p>We can have a stochastic Bayesian game where information is incomplete and there is a stochastic switching device like a Markov chain.</p>
","9048"
"For a given set of consumption bundles, how do we know there are bundles that the consumer is indifferent between?","391","","<p>In my professors lecture notes (it's more like a book), he states four properties of preferences relations:</p>

<ul>
<li>monotonicity</li>
<li>transitivity </li>
<li>continuity</li>
<li>completeness </li>
</ul>

<p>He then goes on to discuss utility levels and indifference curves. He describes indifference curves as level sets and that consumption bundles that the consumer is indifferent between lie on the same indifference curve. </p>

<p><strong>My Question:</strong></p>

<p>For a given set of consumption bundles, how do we know there are <em>any</em> bundles that the consumer is indifferent between? I don't see how we can define indifference curves without knowing that. </p>
","<p>We can obtain the result that Indiference Sets are <em>not</em> singletons, i.e. that consumption bundles that are equivalent under the preference relation <em>must</em> exist, by using a Consumption Set $X$ defined over $\mathbb R_+^n$, i.e. over <em>real</em> vectors, together with the property of Continuity of preferences (alternative-weaker prerequisites may exist though).  </p>

<p>An equivalent way to state the property of Continuity of preferences (see for example Mas-Collel et al, ch 3.C), is that $\forall x \in X$ the upper contour set $UCS$ and the lower contour set $LCS$ are both <em>closed</em>, i.e they include their boundaries. The contour sets are sets that include consumptions bundles ""at least as preferred as $x$"" (upper) and ""at most as preferred as $x$"" (lower). In order for them to ""include"" their boundary"", <em>a boundary must exist in the first place</em>. But their boundary is the Indifference Set, the set containing all bundles as preferred as $x$.  </p>

<p>So your question essentially boils down to <strong>Is it possible that the boundary of the upper or lower contour sets of $x$, sets that are defined over real vectors, is a single point?</strong></p>

<p>I believe that envisioning this in two-dimensions will show that it is impossible, but let's prove it.</p>

<p><em>Ad absurdum</em>, assume that this holds for some $x \in X$. Then for <em>any</em> other consumption bundle in $X$, say $x'$, we will have either $x'&gt;_{pr} x$ or $x'&lt;_{pr} x$. In other words, any other point in $X$ will belong either in $UCS_x$ or in $LCS_x$, <em>but not in both</em>.  </p>

<p>So consider two such points , $x''&gt;_{pr}x&gt;_{pr}x'$. Assume that $x'=\{\mathbf y_{(n-1)}, y_n\}$, $x''=\{\mathbf y_{(n-1)}, y_n+\epsilon(k)\}$, i.e. that they differ in only one of the goods in Goods Space, $\epsilon(k)&gt;0$.  </p>

<p>Transform now these two points into two <em>sequences</em> of points, $\{x''_k\}$ and $\{x'_k\}$, indexed by $k= 1,...$ and by constructing the sequence $\{\epsilon_k\}$ such that $\{\epsilon_k\} &gt;0\; \forall k$ but also $\lim_{k\rightarrow \infty} \epsilon_k = 0$. The consumption space as defined permits these constructions.  We note of course that $\{x'_k\}$ is a constant sequence since its value does not change  as $k$ changes, but that's perfectly legal. </p>

<p>Consider now the sequence of pairs, for each $k$, $\{(x''_k, x'_k)\}_{k=1}^{\infty}$, and it holds that</p>

<p>$$ x''_k &gt;_{pr} x'_k\;\;\;\forall k  \tag{1}$$
$$\lim_{k\rightarrow \infty} x''_k = x'$$
$$\lim_{k\rightarrow \infty} x'_k = x'$$</p>

<p>Under Continuity of preferences we should obtain
$$ (1) \implies \lim_{k\rightarrow \infty} x'' &gt;_{pr} \lim_{k\rightarrow \infty} x'$$
but this is obviously not possible since these limits are identical.
So by assuming that there exists an $x$ in the Consumption Set to which no other bundle is equivalent in terms of the preference relation, we have violated the Continuity property.  </p>

<p>Alternatively, since the bundles are defined over real vectors, and both $UCS$ and $LCS$ are closed due to the Continuity property, then every Cauchy sequence in each of them that converges has its limit <em>in</em> them. So the sequence $\{x''_k\}$ has its limit in $UCS_x$, while the sequence $\{x'_k\}$ must have its limit in $LCS_x$. But this limit is the same as shown above, and equal to $x'$. But the only common point of these two sets is $x$. So it must be the case that $x'=x$. But this cannot hold since we have started by assuming $x&gt;_{pr} x'$.  </p>

<p>An example where indifference sets are singletons is the case of <em>Lexicographic Preferences</em>. And Lexicographic Preferences are not continuous.</p>
","4980"
"Deriving and explaining the weighted cost of capital","390","","<p>The Wikipedia article for the <a href=""https://en.wikipedia.org/wiki/Weighted_average_cost_of_capital"" rel=""nofollow"">""weighted cost of capital""</a> (WACC) defines the WACC
as ""the rate that a company is expected to pay on average to all its security holders to finance its assets."" What exactly does this mean? Does this mean that this is supposed to be the expected returns on the company's stocks as well as the expected return on the company's bonds? Also, how are the two equations, <a href=""https://en.wikipedia.org/wiki/Weighted_average_cost_of_capital#Calculation"" rel=""nofollow"">given in the Wikipedia article</a>, derived? For convenience, the two equations are the following. The first is
$$
\text{WACC} = \frac{\sum_{i=1}^N r_i \cdot MV_{i}}{\sum_{i=1}^N MV_i}, \tag{1}
$$
where $N$ is the number of sources of capital (securities, types of liabilities); $r_i$ is the required reate of return for security $i$; and $MV_i$ is the market value of all outstanding securities $i$. The second is
$$
\text{WACC}  = \frac{D}{D+E}K_d + \frac{E}{D+E}K_e \tag{2},
$$
where $D$ is the total debt, $E$ is the total shareholder’s equity, $Ke$ is the cost of equity, and $Kd$ is the cost of debt. </p>

<p><strong>EDIT:</strong>
Thanks for the answers below. ""Derivation"" was too strong of a word to use, which was clear after the explanations given. It was just a little unclear what the objects were in practice. The discussions below clarified things. Also, I found this paragraph from a website linked in one of the answers helpful:</p>

<blockquote>
  <p>To understand WACC, think of a company as a bag of money. The money in the bag comes from two sources: debt and equity. Money from business operations is not a third source because, after paying for debt, any cash left over that is not returned to shareholders in the form of dividends is kept in the bag on behalf of shareholders. If debt holders require a 10% return on their investment and shareholders require a 20% return, then, on average, projects funded by the bag of money will have to return 15% to satisfy debt and equity holders. The 15% is the WACC.</p>
</blockquote>
","<p>If you are asking ""Is the WACC the amount that the company expects to earn on the stocks and bonds that it holds.."" then the answer is no. </p>

<p>The WACC, in very simple terms, is the amount of money a company pays to obtain financing for projects. These types of financing are clearly listed in the wikipedia article and clearly extend beyond stocks and bonds issued by the company. </p>

<p>A company can calculate the WACC to determine whether or not undertaking a project will be profitable. That is, a company can determine that it must earn some minimum return on a project before that project becomes profitable. </p>

<p>You, as a consumer, possibly have experience with cost of capital. Consider the interest paid on a car loan. That interest is the cost you incur for financing the purchase of your vehicle by borrowing funds from a financial intermediary. </p>

<p>As far as derivation goes - I'm not sure how to simplify these formulas much more. However, you can think simply about the first as the ratio of the interest paid out on sources of financing and the total market value of those sources of financing (so...some ration &lt; 1) and the second is a more simple case of the first. </p>

<p><a href=""http://www.investopedia.com/walkthrough/corporate-finance/5/cost-capital/wacc.aspx"" rel=""nofollow"">http://www.investopedia.com/walkthrough/corporate-finance/5/cost-capital/wacc.aspx</a></p>

<p>I think this website gives a decent walkthrough of the concept. Hope this helps some. </p>
","2933"
"What are some good repositories for economic data","387","","<p>Economic data is a very broad concept. It can include discrete preference relation data-sets as well as extensive time series data.</p>

<p>But it is important that theories are tested against data, and the earlier this happens in the development of an economic model, or of a new economic hypothesis, the more beneficial will be to the researcher, providing early signals on how good or bad a match with the real world his theoretical endeavors are. Economics being a Social Science, it is also important to have plentiful of different data sets, since testing a theory on just one data set does not provide strong enough evidence of the model's usefulness or uselessness.</p>

<p>So I am posting this question with the hope that it will be gradually enhanced with answers and it will become a point of reference for Economic data of all sorts for this community.</p>

<p>My offering: The World Bank for example has very useful information on trade lanes. Other repositories:</p>

<p>-<a href=""http://www.feweb.vu.nl/econometriclinks/#data"" rel=""nofollow"">Data links hosted at the
Econometrics
Journal</a></p>

<p>-<a href=""http://qed.econ.queensu.ca/jae/"" rel=""nofollow"">Data archive of the
Journal
of
Applied
Econometrics</a></p>

<p>-<a href=""http://www.econometricsociety.org/suppmatlist.asp"" rel=""nofollow"">Supplemental material for
Econometrica</a></p>
","<p>Be more specific on what you need.
<a href=""https://www.quandl.com/"">Quandl</a> would be a pretty general source which hasn't been mentioned yet.
For macro data the St. Louis Fed is pretty good and thorough. Eurostat for European data. <a href=""http://www.historicalstatistics.org/"">historicalstatistics.org</a> for historical data.</p>
","4683"
"Return on Assets vs Return on Investment","386","","<p>1) Is Return on Investment same as Return on Assets? 
There are so many different definition in books so I am now confused...</p>

<p>2) Is ROA = Profit <strong>before</strong> taxes/Total Assets or Profit <strong>after</strong> taxes/Total Assets</p>

<p>3) I know to find ROI for some investment or project, but is it possible to find ROI for company from income statement and balance sheet?</p>
","<ol>
<li>No. </li>
</ol>

<p>Return on assets = net income/assets.</p>

<p>ROI = an informal term roughly corresponding to return on starting capital, or net income/starting capital. Starting capital is any money invested in the business.</p>

<p>Let's say you take out a 500k mortgage on a home with a 50k downpayment. That means 550k of assets. Net of everything you make a $10000 profit from rental income or whatever.</p>

<p>Your ROA is 10k/550k because even though you don't own the home free and clear, the house is still an asset. </p>

<p>ROI is a more informal term comparing how much you invested versus the return. In this example ROI is 10k/50k because you only paid 50k for the home.</p>

<ol start=""2"">
<li>ROA uses net income, which means after tax.</li>
</ol>
","11396"
"Why was Swiss National Bank in red by keeping fix exchange rate to Euro?","384","","<p>When I read news about the action of Swiss National bank of not keeping fix ration to Euro any more, I read in all articles, that it was too expensive for Swiss National Bank to keep the fixed exchange rate. I don't really understand how can it be expensive. Swiss N.B was printing Swiss Franc and selling it for Euro? Right? How can be expensive printing and having Euro for free?</p>
","<p>From a central bank's point of view, printing money isn't free.  Each 1 CHF created costs exactly 1 CHF - that is, it appears on the bank's balance sheet as a liability.  They owe that 1 CHF to someone (the person they bought the Euros off - a bank).  And whenever you owe someone money, there is always the ultimate belief that you can pay it back.  Lose that and the bank fails, and the currency fails.</p>

<p>With central banks this isn't clear cut, since the money can only be ""paid back"" by destroying it, but the trust in fiat money relies on the solvency of the central bank.  A sort of, ""so long as you could pay it back, I'll never ask you to"".</p>

<p>The SNB had been buying so many Euros (and other currencies) that it was sitting on foreign reserves worth about 85% of Swiss GDP.  In the process it did make a lot of profit, but that can only go on so long.</p>

<p>In theory, if the SNB could have held out forever, then it could have beaten the ECB, and when the Euro eventually strengthened, unwound its position as a profit.  But that would have involved the SNB conducting massive quantitative easing in the mean time, in order to supply the world with sufficient CHF to meet demand.  Given that Switzerland is somewhat smaller than the Eurozone, it would have been a battle it was destined to lose.</p>

<p>Given that they knew they would likely lose eventually, it is better to lose now, when you only have 85% of GDP in Euros, than to lose later on when you have 850% of GDP in Euros!</p>

<p>Of course having a central bank that is completely screwed, would weaken the CHF, but they only want moderate weakness, no complete destruction of the currency!</p>
","3071"
"What is the difference betwene a partial default and having debts partially written off?","381","","<p>From <a href=""http://www.telegraph.co.uk/finance/economics/11381533/Angela-Merkel-rules-out-debt-cancellation-for-Greece.html"" rel=""nofollow"">The Daily Telegraph</a>:</p>

<blockquote>
  <p>The new Syriza-led government has demanded some form debt write-off on the country's €317bn liabilities, two-thirds of which are owned to official creditors in the form of the EU and the IMF. </p>
</blockquote>

<p>From <a href=""http://www.bbc.com/news/world-europe-31016261"" rel=""nofollow"">BBC News</a>:</p>

<blockquote>
  <p>New Greek PM Alexis Tsipras says his country will not default on its debts.</p>
</blockquote>

<p>A <a href=""https://en.wikipedia.org/wiki/Default_%28finance%29"" rel=""nofollow"">default</a> is, according to Wikipedia:</p>

<blockquote>
  <p>In finance, default is failure to meet the legal obligations (or conditions) of a loan, for example when a home buyer fails to make a mortgage payment, or when a corporation or government fails to pay a bond which has reached maturity.</p>
</blockquote>

<p>Which leads me to the question:</p>

<p>What is the difference between <em>some form of debt write-off</em> (demanded by the Greek government) and a partial default (denied by the Greek government)?</p>
","<p><strong>""Some form of debt write-off""</strong> means usually, <strong>mutually agreed</strong> (between creditor and debtor) elimination of a portion or the whole of debt.  </p>

<p><strong>""Partial default"":</strong> I had the contractual obligation to pay EUR $100$ on Monday, but I paid only EUR $80$. Technically speaking, this is not always (or immediately) considered a ""default"", but a ""credit incident"" (alternatively it is characterized as ""default on a payment"" and not ""default on the loan""). </p>

<p>Then <em>the reason why</em> I haven't paid the remaining EUR $20$ is crucial: Do I recognize my obligation but I am unable to fulfill it because of financial inability? Or do I <em>deny</em> my obligation, questioning the validity of the underlying contract of the debt from which the obligation to pay the remaining EUR $20$ came?</p>

<p>In the first case, the issue is whether this financial inability is deemed as ""temporary"" or ""permanent"". If it is deemed ""permanent"" (usually by a court decision), then in some countries the debt is officially written off by necessity, while in other countries the creditors retain the right to seek payment whenever the debtor acquires assets in the future (so the creditors may be monitoring you). If it is deemed ""temporary"", then the issue is to make an attempt to restructure the debt.  For Public Debt, the inability is never officially considered ""permanent"" so the issue is always to restructure (which of course may include a <strong>mutually agreed</strong> partial write-off, which essentially means a recognition that there exists a ""partial"" permanent inability to pay).</p>

<p>We could call the second case, where we question/deny the validity of our obligation, a ""unilateral debt write-off"", which of course is rarely if ever accepted by the creditors, and so whether it should be called a ""write-off"" is questionable in turn.</p>
","3225"
"Did the Marshall Plan cause Western Europe's economic expansion after WWII?","380","","<p>It is widely accepted, that the Marshall Plan had a major role in the economic recovery of Western Europe after the end of the Second World War.
The reality is that the total economic support was less than 7% of the <a href=""http://knoema.com/HSWE/historical-statistics-of-the-world-economy-1-2008-ad?tsId=1000910"">1946 GDP (PPP) of the region</a>. How could that have any statistical significance?</p>

<p>In the period between 1943 and 1945, the GDP (PPP) of Western Europe fell by more than 19%. So, was that caused because there was no Martial Plan then? :)</p>

<p>Before the Keynesians jump on the multiplier effect bandwagon, I would point out, that the US quantitative easing after the 2008 economic crisis was 3.5 trillion USD, which is 20% of the 2013 US nominal GDP.</p>
","<p>Barry Eichengreen is one of my favourites for this period. So, I am just going to let him explain it.</p>

<p>From : <a href=""http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.1592&amp;rep=rep1&amp;type=pdf"" rel=""nofollow"">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.1592&amp;rep=rep1&amp;type=pdf</a></p>

<blockquote>
  <p>Our central conclusion is that the Marshall Plan did matter. But it
  did not matter in the way that the “folk wisdom” of international
  relations assumes. Milward (1984) is correct in arguing that Marshall
  Plan aid was simply not large enough to significantly stimulate
  Western European growth by accelerating the replacement and expansion
  of its capital stock. Nor did the Marshall Plan matter by financing
  the reconstruction of devastated infrastructure, for as we show below,
  reconstruction was largely complete before the program came on
  stream. </p>
  
  <p>The Marshall Plan did play a role in alleviating resource
  shortages. But this channel was not strong enough to justify the
  regard in which the program is held. By 1948 and the beginning of
  Marshall Plan aid bottlenecks were scarce, and markets were good at
  alleviating their impact. Rather, the Marshall Plan significantly sped
  Western European growth by altering the environment in which economic
  policy was made. In the immediate aftermath of World War II
  politicians who recalled the disasters of the Great Depression were
  ill-disposed to “trust the market,” and eager to embrace regulation
  and government control. Had European political economy taken a
  different turn, post-World War II European</p>
  
  <p>Wartime relief, post-World War II UNRRA aid, and pre-Marshall Plan
  “interim aid” may well have significantly speeded up the
  reconstruction process. ... recovery might have been hobbled by clumsy
  allocative bureaucracies that rationed scarce foreign exchange and
  placed ceiling prices on exportables to protect the consumption of
  urban working classes. Yet in fact the Marshall Plan era saw a rapid
  dismantling of controls over product and factor markets in Western
  Europe. It saw the restoration of price and exchange rate stability.
  To some degree this came about because underlying political-economic
  conditions were favorable (and no one in Europe wanted a repeat of
  interwar experience). To some degree it came about because the
  governments in power believed that the “mixed economies” they were
  building should have a strong pro-market orientation. Marshall Plan
  aid gave them room to maneuver in order to carry out their intentions:
  without such aid, they would have soon faced a harsh choice between
  contraction to balance their international payments and severe
  controls on admissible imports. </p>
  
  <p>To some degree it came about because
  Marshall Plan administrators it pressured European governments to
  decontrol and liberalize even when they wished to do otherwise. In
  post-World War II Western Europe the conditions imposed, formally and
  informally, for the receipt of U.S. aid encouraged the reductions in
  spending needed for financial stability, the relaxation of controls
  that prevented markets from allocating resources, and the opening of
  economies to trade. Marshall Plan “conditionality” pushed governments
  toward versions of the “mixed economy” that had more market
  orientation and less directive planning in the mix. While postWorld
  War II European welfare states and governments are among the most
  extensive in proportion to economic life in history, they are built on
  top of, and do not supplant or bypass, the market allocation of goods
  5 and factors of production. The Marshall Plan should thus be thought
  of as a large and highly successful structural adjustment program.</p>
</blockquote>
","8315"
"Elasticity of demand equals -1 but income decreases!","380","","<p>In my textbook it's stated that:</p>

<pre><code>When E &lt; -1, demand is elastic and raising price will result in smaller income,
             while lowering price will result in bigger income.
When E = -1, demand is neither elastic nor inelastic and change in price won't
             result in change in income.
When E &gt; -1, demand is inelastic and raising price will result in bigger income,
             while lowering price will result in smaller income.
E = delta Q / delta P.
</code></pre>

<p>This is the exercise I found confusing:</p>

<pre><code>Old price: 5
New price: 6
Old quantity: 25
New quantity: 20
Calculate elasticity
</code></pre>

<p>This is my solution:</p>

<pre><code>Delta P = (new price - old price) / old price = (6 - 5) / 5 = 0.2
Delta Q = (new quantity - old quantity) / old quantity = (20 - 25) / 25 = -0.2
Elasticity = delta Q / delta P = -0.2 / 0.2 = -1
</code></pre>

<p>This is why I am confused:</p>

<pre><code>Old income = old price * old quantity = 5 * 25 = 125
New income = new price * new quantity = 6 * 20 = 120
Old income does not equal new income even though elasticity is -1!
</code></pre>

<p>What am I doing wrong? Am I misunderstanding the textbook?</p>

<p>Edit: the answer provided is <code>E = 1.22</code> but I have no idea where it comes from.</p>
","<p>We discourage numeric questions as they are unlikely to be useful for future visitors but this is a very good example of why using non-marginal quantities can be misleading.</p>

<p>The exact definition of the price elasticity of demand is
$$
\epsilon(p) = \frac{d D(p)}{d p} \cdot \frac{p}{D(p)}.
$$
(In your notation $D(p) = Q$.) <br>
By straightforward calculation you can show
\begin{eqnarray*}
\max_p &amp; &amp; p \cdot D(p) \\
\\
p \cdot \frac{d D(p)}{d p} + D(p) &amp; = &amp; 0 \\
\\
p \cdot \frac{d D(p)}{d p} &amp; = &amp; - D(p) \\
\\
\frac{p}{D(p)} \cdot \frac{d D(p)}{d p} &amp; = &amp; - 1 \\
\\
\epsilon(p)  &amp; = &amp; - 1.
\end{eqnarray*}
Whether a <em>marginal</em> price change increases or decreases revenue when $\epsilon(p)  \neq - 1$ can be seen from a similar calculation.</p>

<p>Note that the reasoning used above only stated that $D(p)$ reached its local maximum. It is possible that several local maxima exist and the global maxima is elsewhere.</p>

<p>So $\epsilon(p)  = - 1$ implies that the revenue cannot be increased by small (marginal) changes in $p$. So far I have used the concept of point elasticity. But your textbook uses arc elasticity, which measures non-marginal changes:
$$
\frac{\Delta Q}{Q} / \frac{\Delta p}{p}
$$
Some reasons to do this:</p>

<ol>
<li>Arc elasticity can be measured empirically, point elasticity can only be approximated.</li>
<li>In case of small changes the two should be reasonably close.</li>
<li>Point elasticity requires some knowledge of calculus.</li>
</ol>

<p>There are however also some problems with this: </p>

<ol>
<li>No guarantuees are made by the $\epsilon(p)  = - 1$ condition for non-marginal price changes.</li>
<li>What base you should use for arc elasticity is not clear at all. You used
$$
\frac{Q_{new} - Q_{old}}{Q_{old}} \cdot \frac{p_{old}}{p_{new} - p_{old}}.
$$
Why is the old quantity and price the reference for the rate of change? Why is it not the new quantity and price
$$
\frac{Q_{new} - Q_{old}}{Q_{new}} \cdot \frac{p_{new}}{p_{new} - p_{old}}
$$
or the average of the two
$$
\frac{Q_{new} - Q_{old}}{\frac{Q_{new} + Q_{old}}{2}} \cdot \frac{\frac{p_{new} + p_{old}}{2}}{p_{new} - p_{old}}?
$$</li>
</ol>

<p>These bases give you different values for arc elasticity. The second base gives you $1.2\dot{2}$ so it seems to be the one your textbook expects. I guess it is best if you see the difference between point elasticity that is used by the rule and arc elasticity. Other than this you have to ask your professor what definiton of elasticity she/he expects you to use.</p>
","10692"
"Continuous rational and monotone preference relation implies $x\succsim0$?","379","","<p><strong><em>I updated my proof to a general version as follows: please share your thoughts &amp; 2cent. Thanks</em></strong></p>

<p>Show a monotone continuous complete preorder on $\mathbb{R^L_+}$ has  $y\geq x\rightarrow y\succsim x$.</p>

<blockquote>
  <p><strong><em>Point of Clarification</em></strong>
  <br/> $X=\mathbb{R^L_+}$
  <br/> Preorder means the usual reflexivity and transitivity.
  <br/> Complete means for any $x,y\in X$, have $x\succsim y$ or $y\succsim x$
  <br/> Continuous means the relation is preserved under limits.
  <br/> Monotone means for any $x,y\in X$, if $y\gg x$, then $y\succ x$.
  <br/> $\succ$ and $\sim$ are respectively asymmetic and symmetric parts of $\succsim$</p>
</blockquote>

<p><strong><em>Outline of Proof</em></strong>
<br/> Go through two cases: (1) $y\gg x$. Easily get the result by definition. (2) Some components are equal while else y is strictly greater x. Use continuity where you add a sequence of small positive $\epsilon$ to y, making it a sequence $y^n_\epsilon$ where for every n, $y^n_\epsilon\gg x$ $\forall n$.</p>

<blockquote>
  <p><strong><em>Proof</em></strong>
  <br/> Suppose $\succsim$ is a monotone, continuous, complete preorder on $X=\mathbb{R^L_L}$.
  <br/> Case (1) $y\gg x$ (i.e. $y_i&gt;x_i$ $\forall i\in B=\{1,\dots,L\}$).
  <br/> By definition, $y\succ x$, which implies $y\succsim x$.
  <br/> <br/> Case (2) $y_j=x_j$ for some $j\in B$. For $\forall k\not=j,k\in B, y_k&gt;x_k.$
  <br/> For some $\epsilon&gt;0$, let the sequence $\epsilon^n\in\mathbb{R^L_+}$ such that $\epsilon_j=\epsilon$, $\epsilon_k=0$.
  <br/> Denote the sequence $y^n_\epsilon=y+\epsilon^n$.
  <br/> Then, for any $\epsilon&gt;0$ and $\forall n$, $y^n_\epsilon\succ x$, hence $y^n_\epsilon\succsim x$.
  <br/> By continuity of $\succsim$, $$\lim_{\epsilon \to 0} {y^n_\epsilon} = y$$
  <br/> Hence, $y\succsim x$. $\blacksquare$</p>
</blockquote>

<p><br/> <strong><em>OLDER VERSION</em></strong></p>

<p><em>My question is what is the valid reasoning behind that continuous rational and monotone preference relation implies $x\succsim0$. I have put a proof below and would appreciate if you share your 2 cent on the validity/rigor of the proof. Thanks!</em></p>

<p>Suppose $x\in\mathbb{R^+_L}=\{x\in\mathbb{R^L}:x_l\geq0$ $\forall l=1,\dots,L\}$.</p>

<p><strong>Claim</strong>: For every $x\in\mathbb{R^+_L}$, monotonicity implies $x\succsim0$.</p>

<p><strong>Proof</strong>:</p>

<p>(1) Suppose $x=(0,\dots,0)$.
Then, $x\sim0$ is possible.</p>

<p>(2) Suppose $x\gg y$. Then, by Definition of monotone preference, $x\succ y$ is possible.</p>

<p>(3) Suppose $\exists$ some $j$ such that $x_j&gt;0$ and $1\leq j\leq L$.Then, I have the following process of elimination:</p>

<ul>
<li>$x\succsim0$ is possible.</li>
<li>$x\succsim0$ and $0\succsim x$ $\iff x\sim0$ is possible.</li>
<li>$x\succsim0$ but not $0\succsim x$ $\iff x\succ0$ is possible.</li>
<li>$0\succsim x$ but not $x\succsim 0$ $\iff 0\succ x$ is impossible.</li>
</ul>

<p>The single preference relation that is common in all three scenarios is $x\succsim0$.
Hence, for every $x\in\mathbb{R^+_L}$, monotonicity implies $x\succsim0$. Q.E.D</p>
","<p>If we take the definition of monotonicity to be if $x\geqq y$  then $x \succeq y$, you can simplify the proof (though it looks right). </p>

<p>Note $\mathbf{0}\leq x$ for all $x\in \mathbb{R}_+^l$. So by the definition of monotonicity (essentially replacing $y$ with $\mathbf{0}$ above), $x\succeq \mathbf{0}$. I don't think continuity is required (check lexicographic preferences to see it is not necessary for the stated result). </p>
","12479"
"Monetary policy takes medium run time to take effect. Why study it in short run?","378","","<p>Well I'm reading a <a href=""http://www.amazon.co.uk/gp/product/0273766333?keywords=blanchard%20macroeconomics&amp;qid=1440701025&amp;ref_=sr_1_1&amp;sr=8-1"" rel=""nofollow"">book</a> on the IS-LM model. 
At the end of the chapter, page 125 in my edition, the author presents one <a href=""http://faculty.wcas.northwestern.edu/~lchrist/research/fofa/flowoffunds.pdf"" rel=""nofollow"">paper</a> showing some graphs where the monetary policy (monetary contraction - increasing 1% of the federal funds rate) influencing output, but with its greatest impact only being felt after 4 quarters, and continues well into the 8th quarter.
At the same time, when the impact of the monetary policy is the greatest, is when the price level also begins to noticeably change.</p>

<p>According to the author, since in the IS-LM model we've assumed that the price level is given, the fact that the price level only begins changes at 4th quarter, is a good support for our assumption. </p>

<p>Well, my question then is, why should we study the monetary policy as if it had the same time to impact as fiscal policy in the short-run, when the graphs support more the medium-run impact? Or is it a matter of magnitude of the policy at hand?(The Central Bank can move the interest rate with a lot more leeway than just a 1%)</p>
","<p>It is one point in time, when the effects of a policy can be measured. It may be an earlier, point in time when these effects start their workings.<br>
Assume that monetary policy does affect output, and prices take some time to respond. Assume that we observe that output and prices appear to respond at the same point in time. But hey, if prices change, why after all, output responds?</p>

<p>In normal times with not much productive factors lying idle, expanding output means new investments. This takes time, to actually complete these investments and make them productive. Decisions on investments are made ""now"", but actual final production increase appears ""later"". In the first stage one should expect an increase of output only in those sectors whose services are required to build machinery etc, and it is only in the second stage that we will see final output increase. This can account for why ""monetary policy's greatest impact is only felt after 4 quarters"".</p>

<p>This of course makes actual empirical macroeconomic models much more complicated than what we see in textbooks. The ""size"" of the policy also matters of course. But the message is there: price sluggishness may make monetary policy effective on output.  </p>

<p>In my opinion, at the textbook level, segmenting time in a more accurate way would not be fruitful for educational purposes -it would create a more complicated picture which, although truer to the real world, it would weaken the lesson of ""what to look for"" -when eventually one will be confronted with the latter.  </p>
","8165"
"Examples of Factors in the ICAPM","377","","<p>The <a href=""http://en.wikipedia.org/wiki/Intertemporal_CAPM"" rel=""nofollow"">intertemporal capital asset pricing model</a> (ICAPM) is different from the <a href=""http://en.wikipedia.org/wiki/Capital_asset_pricing_model"" rel=""nofollow"">CAPM</a> in that in the ICAPM, utility is conditioned on some set of state variables. The ICAPM results in a multifactor pricing model of the market if investor care about hedging against changing investment opportunities and exposure to these factors. Are there any canonical examples of these factors? </p>

<p>I know that the Fama-French multifactor models (e.g., <a href=""http://en.wikipedia.org/wiki/Fama%E2%80%93French_three-factor_model"" rel=""nofollow"">the three factor model</a>) are often justified on grounds of the ICAPM (or APT -- arbitrage pricing theory). What are the underlying risk factors that justify this model? Are there any other examples of underlying risk factors that show up a lot?</p>
","<h1>ICAPM Factors</h1>

<p>People have chosen different ways to pick factors. <a href=""http://rady.ucsd.edu/faculty/directory/valkanov/pub/classes/mfe/docs/ChenRollRoss_JB_1986.pdf"" rel=""nofollow"">Chen, Roll and Ross</a> are a classic example of attempts to find reasonable ICAPM factors. Fama-French factors are often explained as <em>correlated</em> with underlying ICAPM factors. Other researchers have chosen to look for factors without assuming outwardly observable exposures by analyzing returns using factor analysis or principal components.</p>

<h1>Explanations of Fama-French</h1>

<p>I don't know if there are ""commonly accepted"" explanations for the Fama French factors. This is not to say that there aren't explanations, there are a lot of them. Just no one seems to agree on which ones are ""best"". Candidates include both consumption based explanations AND production based models, each of which relates Fama-French factors to underlying economic variables. Cochrane has a nice summary of the performance of both in pricing Fama-French portfolios <a href=""http://faculty.chicagobooth.edu/john.cochrane/research/papers/financial_and_real_proofs_aug_07.pdf"" rel=""nofollow"">here</a>.</p>

<h1>Additional factors commonly used</h1>

<p><a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2287202"" rel=""nofollow"">Fama and French</a> are now talking about a five-factor asset pricing model which also includes profitability and investment, similar to <a href=""http://rnm.simon.rochester.edu/research/OSoV.pdf"" rel=""nofollow"">Novy-Marx</a>'s paper and work by <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1418117"" rel=""nofollow"">Chen, Novy-Marx and Zhang</a> which more directly relates to production asset pricing. <a href=""http://www.bauer.uh.edu/rsusmel/phd/jegadeesh-titman93.pdf"" rel=""nofollow"">Momentum</a> is also a consistent candidate, although it's a real pain to put any kind of explanation to. There are tons of others. <a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2249314"" rel=""nofollow"">This paper</a> lists many of them, as well as calling the significance of some of them into question.</p>
","144"
"LIBOR rates: Are these monthly or yearly interest rates?","377","","<p>If I have, for instance, a Libor security with maturity of one month, with interest rate $r$. Is $r$ the amount to be paid after one month, or is it the annualized interest rate?</p>

<p>(My gut tells me that it is the annual interest rate, but I have not found a source to confirm this.)</p>

<p>And if it is the annualized rate, how is the (actual) interest payment that is due after one month calculated? Is it $1+r/12$ or is it of the form $e^{r/12}$</p>
","<p>To answer the first part, it's an ""annualised"" interest rate convention - like all other quoted interest rates. For example, if a one-month money market rates are unchanged at 4%, you would receive approximately 4% in interest after a year, or roughly 1/3% a month. (Note that those numbers are ignoring compounding, further details below.)</p>

<p>As for the calculations, things are complicated. The high level answer is that a monthly interest rate is roughly $r/12$, with $r$ being the quoted rate. This is a simple interest rate.</p>

<p>The true calculations are complicated by the nature of LIBOR. Technically, LIBOR (London Interbank Offer Rate) is a polled rate of ""large"" banks in a number of currencies. There are similar ""fixes"", such as Euribor (Euro area), TIBOR (Japan), CDOR (Canada). The polled rate is based on the money market convention in each currency for a certain class of interbank borrowing.</p>

<p>Interest rate calculations depend upon the daycount convention, and the calendar used. If we borrow on June 1st, one month later is normally July 1st. What happens if July 1st is a weekend or holiday? There are standard comventions in each currency that determine which days are holidays, and how to move the due date relative to such dates (before/after).</p>

<p>There are a wide variety of day count conventions that are used across markets. I believe that act/365 (GBP) or act/360 (other currencies) are standard. (Based on this ICE LIBOR document: <a href=""https://www.theice.com/publicdocs/IBA_LIBOR_FAQ.pdf"" rel=""noreferrer"">link</a>.) Anyone who needs to know the exact calculations should refer their queries to their banking counterparties, as there can be a large number of small modifications to the generic description I give below.</p>

<p>In act/360, the amount of interest is given by the quoted rate times the fraction (actual number of days in the lending period)/360. For act/365, the interest is given by the quoted rate times (the number of days in the period/365).</p>

<p>Therefore, if the one-month maturity period is 30 days in the future, and the currency uses an act/360 convention, the fraction used for the one-month rate is 30/360 = 1/12. However, it is clear that the true annual compounding rate will vary from compounding $(1+r/12)^{12}$ since months are not exactly 30 days, and the number of days in the year is either 365 or 366.</p>
","17039"
"Will a Free Software Society ever become a reality?","376","","<p>I have gone through this <a href=""https://economics.stackexchange.com/questions/5369/how-does-gnu-software-development-sustain-economically"">question</a> regarding the economic sustenance of the GNU Software and I think it is the foundation of my question.<br></p>

<p>Below is a small excerpt from the <a href=""http://www.gnu.org/philosophy/free-sw.en.html"" rel=""nofollow noreferrer"">GNU Website</a> which states the four principles
the Free Software Foundation lays its foundation on.</p>

<ul>
<li>The freedom to run the program as you wish, for any purpose (freedom 0).</li>
<li>The freedom to study how the program works, and change it so it does your computing as you wish (freedom 1). Access to the source code is a precondition for this.</li>
<li>The freedom to redistribute copies so you can help your neighbor (freedom 2).</li>
<li>The freedom to distribute copies of your modified versions to others (freedom 3). By doing this you can give the whole community a chance to benefit from your changes. Access to the source code is a precondition for this.</li>
</ul>

<p>A program is free software if the program's users have the above four essential freedoms.<br></p>

<p>I believe the above principles will :</p>

<ul>
<li>lead to better transparency regarding how the software works.</li>
<li>fuel new ideas, which will lead to better customized software.</li>
</ul>

<p>I couldn't ,however, think of the economic hindrances for :<br></p>

<ol>
<li>Setting up a Free Software Society.</li>
<li>If set up, the survival of such a society.</li>
</ol>

<p>A society where <strong>all</strong> the players abide by the above FSF principles is
what I call a <strong>free software society</strong>. Well, this is my terminology indeed.</p>

<p>Any suggestions are appreciated.</p>
","<p>Your questions asks:</p>

<blockquote>
  <p>A society where <strong>all</strong> the players abide by the above FSF principles</p>
</blockquote>

<p>It won't ever happen for all players. As a counter-example, consider an engineer who invents software that can predict when a jet engine needs maintenance. It's worth millions to the airlines, who will happily pay him for the software. He has no incentive at all to release this software as open-source. The same principle applies to all sorts of specialist software.</p>

<p>In contrast, open-source works well for common building blocks. For example, there are all sorts of companies who need an operating system for their product - cloud providers, home network kit, super computing, all sorts. While they could build their own, it is much more efficient to have a common pool, like the Linux kernel. This environment means that companies can put paid engineers on open-source projects, and still run a profitable business.</p>
","9344"
"What properties must a utility function have such that we can define level sets and thus indifference curves?","375","","<p>I asked on Math SE a bit about level sets <a href=""https://math.stackexchange.com/q/1221262/197705"">here</a>. </p>

<p>Based on what I learned, it seems like we usually assume a level set $L(f)$ and its function $f$ defined on $\Bbb{R}^n$ have the following properties:</p>

<ol>
<li>$f$ is continuous </li>
<li>Thus, the curves in the level set are closed curves. (not sure why) </li>
<li>All closed curves are ""converging"" to a point. (not sure why) </li>
<li>This point will be a maximum for the function: the derivative in the point will be zero, since if it was not then the point would be a 1-manifold, which is absurd. </li>
<li>$\nabla f \neq 0$ on the rest of the points </li>
</ol>

<p>I don't understand how we know a preference relation on a consumption bundle has a utility function representation such that these properties hold. According to my professor, we use level sets to describe indifference curves. </p>

<p>Therefore, if indifference curves are described by a level set, that level set must have the properties listed above. Note, for economics, we are considering a function $U(\mathbf{x})$, where $\mathbf{x}=(x_1,...,x_n)$, and the level set $L(U)$. Also, note $U: \Bbb{R}^n\rightarrow \Bbb{R}$. </p>

<p><strong>My Question:</strong></p>

<p>In economic terms, what assumption do we have to make to ensure, $U$, $L(U)$ have these properties to create a level set used for indifference curves? </p>

<p>Ideally, it would be great to have an enumerated list of the assumptions (ie 1,2,3). </p>
","<p>Look take a rational preference $\succeq$ defined on X, endow X with some metric (thus a assume it is a metric space). Assume also X is separable (e.g. $\mathbb{R}^n$  satisfies this conditions but is more general). 
Now we let $\succeq$ be (i) rational (complete, transitive), (ii) continuous (it means that if $x^n\rightarrow x$ , $y^n\rightarrow y$ and $x^n \succeq y^n$ $\forall n$, then $x \succeq y$. Under this assumptions, then it can be represented by a continuous utility function. 
1. u is continuous by the above conditions. 
2. Curves in the level set are closed. It follows from the fact that the indifference relation is a closed set and the continuous utility representation: take $x^n  \sim  y\quad \forall n$ by continuity of the preferences $x \sim y$, now this implies that $u(x^n)$ is a sequence on the level curve $u(x^n)=u(y)$ for fixed y and by above $u(x)\rightarrow u(y)$ thus making it closed.
The other properties are deeper in the sense that one needs more assumptions, for instance to have the gradient of u it has to be differentiable, uniqueness of the extremum needs some sort of convexity of the level curves and so on.   </p>
","5620"
"When Optimal Control fails (?)","375","","<p>In order to ""ask my question"", I have to solve a model first. I will omit some steps but still, this will unavoidably make this post <em>very</em> long -so this is also a test to see whether this community likes such kind of questions.  </p>

<p>Before starting, I clarify that this may look totally like a standard neoclassical growth model in continuous time, <em>but it is not</em>: It is concerned with a single individual, which does not ""represent"" anybody else in the economy around him, an economy which is not modeled. The framework here is <strong>""application of Optimal Control to the maximization problem of a single individual"".</strong> This is about the Optimal Control solution framework and method itself.</p>

<p>We solve the intertemporal utility maximization problem of a small businessman that owns the capital in his firm, while he purchases labor services in a perfectly competitive labor market, and he sells his product (fresh doughnuts) in a perfectly competitive goods market. We set the model in continuous time without uncertainty (socioeconomic conditions are steady), and with infinite horizon (the businessman envisions many future copies of him in a row):</p>

<p>$$\max_{c,\ell,k}\int_0^{\infty}e^{-\rho t}\ln c\,\text{d}t\\ \text{s.t.}\;\; \dot k = f(k,\ell) - w\ell - \delta k - c\\
\lim_{t\rightarrow \infty}e^{-\rho t}\lambda(t) k(t) = 0$$</p>

<p>where $c$ is the businessman's consumption, $\ln c$ is instantaneous utility from consumption, $\rho&gt;0$ is the rate of pure time preference, $k$ is the firm's capital, $\delta$ is the capital depreciation rate, and $f(k,\ell)$ is the production function of the business. Initial level of capital is given, $k_0$. The businessman's own occupation with the business is subsumed into capital. The production function is standard neoclassical (constant returns to scale, positive marginal products, negative second partials, Inada conditions). The constraints are the law of motion of capital, and the Transversality condition using the current value multiplier.  </p>

<p>Setting up the current value Hamiltonian </p>

<p>$$\hat H = \ln c +\lambda[f(k,\ell) - w\ell - \delta k - c]$$</p>

<p>we calculate the first-order conditions</p>

<p>$$\frac {\partial \hat H}{\partial c} = 0 \Rightarrow \frac 1c =\lambda \Rightarrow \frac {\dot c}{c} = -\frac {\dot \lambda}{\lambda}$$ </p>

<p>$$\frac {\partial \hat H}{\partial \ell} = 0 \Rightarrow \lambda [f_{\ell} -w]=0 \Rightarrow f_{\ell} =w$$  </p>

<p>$$\frac {\partial \hat H}{\partial k} = \rho\lambda - \dot \lambda \Rightarrow \lambda [f_{k} -\delta]=\rho\lambda - \dot \lambda$$</p>

<p>and combining them we obtain the law of evolution of consumption of our businessman , </p>

<p>$$\dot c = \big(f_k-\delta -\rho \big)c \tag{1}$$</p>

<p>From the optimal rule for labor demand $\ell: f_{\ell} =w$ (static) and the constant returns to scale implication ($f = f_kk + f_{\ell}\ell$) we obtain $f-w\ell = f_kk$. Inserting this into the law of motion of capital we obtain</p>

<p>$$\dot k = f_kk -  \delta k - c \tag {2}$$</p>

<p>Equations $(1)$ and $(2)$ form a system of differential equations. The steady-state values for the consumption and the capital of the businessman are </p>

<p>$$c^* = f_k^*k^* -  \delta k^*,\;\;\; k^*: f^*_k = \delta +\rho \tag{3}$$</p>

<p>$$ \Rightarrow c^* = \rho k^* \tag{3a}$$</p>

<p>...which is a pretty familiar expression.</p>

<p>$k^*$ is sometimes called the ""modified golden rule"" level of capital. The Jacobian of the system evaluated at the steady state values has a negative determinant <em>for any value of the model parameters</em>, which is a necessary and sufficient condition for the system to exhibit saddle-path stability.  </p>

<p>The maximum of the $\dot k =0$ locus is at the point, $\tilde k$ (sometimes called the ""golden rule"" level of capital)</p>

<p>$$\tilde k : f_{kk}(\tilde k)\tilde k + f_k(\tilde k) - \delta = 0\Rightarrow f_k(\tilde k) = \delta - f_{kk}(\tilde k)\tilde k \tag{4}$$</p>

<p>The $\tilde k$ value is important as a benchmark: it is the level of capital where $\dot k =0$ and $c$ is at a <em>maximum</em> (not <em>optimal</em> or <em>steady state</em>).</p>

<p>The $\dot c=0$ loci crosses the horizontal axis of the phase diagram (that measures capital) at the steady-state capital level $k^*$.</p>

<p>If $k^* &gt; \tilde k$, which requires $f_k^* &lt; f_k(\tilde k)$ due to negative second partials, we will have ""over-accumulation of capital"" (too many doughnuts): the businessman could enjoy more steady-state consumption with a lower level of capital.
Using $(3)$ and $(4)$ we have</p>

<p>$$f_k^* &lt; f_k(\tilde k) \Rightarrow \delta + \rho &lt; \delta - f_{kk}(\tilde k)\tilde k$$</p>

<p>$$\Rightarrow \rho &lt;  - f_{kk}(\tilde k)\tilde k \tag {5}$$</p>

<p>Inequality $(5)$ is the condition for sub-optimal steady-state level of capital. And the thing is, <em>we cannot rule it out</em>.  It simply requires that the businessman is ""sufficiently patient"", with a sufficiently small rate of pure time preference, but still positive.</p>

<p><strong>Here starts the problem:</strong> overaccumulation of capital is effectively excluded in the representative agent model. It is possible in overlapping generation models, but as an unintended consequence at the macroeconomic level, one of the earliest examples that the macro-economy may be micro-founded and still behave differently than the micro-world.  </p>

<p>But our model falls in neither category: it is a partial equilibrium model of a <em>single</em> agent in an implicitly heterogeneous environment -and general equilibrium here won't alter the results: this person represents only himself. 
So the problem is that if $(5)$ holds, then <strong><em>the Optimal Control solution will be obviously sub-optimal</em></strong>, because here we have a single person, a single will, a single mind: by looking at the solution our businessman will say, ""hey, this method is worthless, if I follow its advice I will end up with a sub-optimally high level of capital"".  </p>

<p>And I am not satisfied to simply say ""well, Optimal Control is not suitable for this problem, try another method"", because I cannot see <em>why</em> we should consider it unsuitable. But if it is suitable, then the method should signal that something is wrong, it should at some point <em>require</em> that $(5)$ does <em>not</em> hold, in order to be able to offer a solution (if it so happens that $(5)$ does not hold, everything looks swell). </p>

<p>One could wonder ""maybe the Transversality condition is violated if $(5)$ holds?"" -but it doesn't look that it does, since $\lambda(t)k(t) = k(t)/c(t)$, which goes to a positive constant, while $e^{-\rho t}$ goes to zero, requiring only that $\rho&gt;0$.</p>

<p><strong>My questions:</strong>  </p>

<p>1) Can somebody offer some insight here?  </p>

<p>2) I would be grateful if somebody solved this using Dynamic Programming and reported the results.</p>

<p><strong>ADDENDUM</strong><br>
From a mathematical point of view, the crucial difference of this model is that the <em>optimized</em> law of motion of capital, eq. $(2)$ includes <em>not</em> the whole output $f(k)$ as in the standard model, but only the returns to capital $f_kk$. And this happens because we have separated property rights over the output, which in the ""individual business maximization problem"" framework, is to be expected.</p>
","<p>I believe the problem is that the steady state may not exist, and the system instead exhibits steady growth (depending on parameters).</p>

<p>The reason is because the model is equivalent to the standard consumption-saving problem with exogenous and constant interest rate. To see that, first consider the first order condition for labor choice $f_2(k,\ell) = w$ (here, $f_i$ is partial derivative of $f$ wrt. $i$th argument). Using the definition of constant returns, marginal product of labor is
$$
\frac{\partial }{\partial \ell} f(k,\ell) = \frac{\partial }{\partial \ell} \left[ f \left( \frac{k}{\ell},1 \right) \ell \right] = f_1 \left( \frac{k}{\ell},1 \right) \frac{-k}{\ell} + f \left( \frac{k}{\ell},1 \right)
$$
which is a function of capital-labor ratio only. If wage is constant, labor FOC determines uniquely the optimal $k/\ell$ ratio as a function of wage $w$ and other parameters. Since marginal product of capital
$$
\frac{\partial }{\partial k} f(k,\ell) = \frac{\partial }{\partial k} \left[ f \left( \frac{k}{\ell},1 \right) \ell \right] = f_1 \left( \frac{k}{\ell},1 \right)
$$
also depends on $k/\ell$, it will be constant along optimal path. Denote this value of marginal product $r^*$, and denote the return net of depreciation $r = r^* - \delta$. Equations (1) - (2) for dynamics of capital and consumption are then
$$
\begin{split}
\dot c_t &amp;= (r - \rho) c_t \\
\dot k_t &amp;= r k_t - c_t 
\end{split}
$$
and the specific solution which satisfies transversality condition should be $c_t = \rho k_t$ with $k_0$ given, i.e. a constant part of wealth is consumed at each moment. Both capital and consumption grow at rate $(r-\rho)$, so there is no steady state unless the return on capital (which here depends on exogenous wage rate $w$) equals rate of time preference.</p>
","1678"
"What is the difference between a loan and an investment?","374","","<p><a href=""https://www.rte.ie/news/business/2017/0907/902980-imf-loan-repayments/"" rel=""nofollow noreferrer"">IMF</a>, <a href=""https://www.premiumtimesng.com/business/business-news/227111-world-bank-approves-200-million-loan-nigeria-boost-agriculture.html"" rel=""nofollow noreferrer"">WB</a>, <a href=""https://www.cnbc.com/2017/09/27/asian-development-bank-approves-50-million-loan-to-boost-rooftop-solar-in-sri-lanka.html"" rel=""nofollow noreferrer"">ADB</a>, <a href=""http://news.xinhuanet.com/english/2017-09/17/c_136616122.htm"" rel=""nofollow noreferrer"">IDB</a>, <a href=""http://business.inquirer.net/237611/asian-infrastructure-investment-bank-aiib-metro-manila-flood-control-china-loan-project-infra"" rel=""nofollow noreferrer"">AIIB</a> are known to give <strong>loans</strong>. On the other hand, China is said to be <a href=""https://tribune.com.pk/story/1381733/cpec-investment-pushed-55b-62b/"" rel=""nofollow noreferrer""><strong>investing</strong></a> in Pakistani project termed as <strong><a href=""https://en.wikipedia.org/wiki/China%E2%80%93Pakistan_Economic_Corridor"" rel=""nofollow noreferrer"">CPEC</a></strong>.</p>

<p>What is the difference between these two terms in these two particular cases?</p>
","<p>A loan is an agent lending funds to another agent. This money can be used for investment spending, or it can be used for personal consumption expenditures. It can be used to buy fixed assets like real estate, which may or may not be ""investment"" depending on how you use the terminology. In the case of the IMF, the role of the institution is to ensure financial stability by providing funds to countries in an emergency; for example, a country which becomes insolvent and is unable to service its sovereign debt is likely to seek help from the IMF. The IMF would then provide a bailout loan along with a stabilization program aimed at improving the country's public finances. This is not investment, in the sense that it does not grow the country's capital stock; it just allows it to meet its obligations to past creditors.</p>

<p>Investment is an expenditure which will yield revenue in the future, and hopefully amortize itself through that revenue. In the case of a household, investment can take the form of acquiring financial assets; in the case of an economy, investment often refers to actions which improve the country's productivity. This can be the construction of new factories, higher wages at state subsidized education institutions, higher research and development spending by the private sector, etc.</p>

<p>The reason the two are related is that quite a lot of investment is done through borrowing. A corporation can borrow to ramp up capital expenditures, a country can borrow on international capital markets to invest more in infrastructure, an individual can take out a mortgage to acquire a house. All of these can be legitimately described as ""investment"".</p>

<p>China is said to be investing in Pakistan (and quite a lot of other countries) under its Belt and Road Initiative because of two reasons: these expenditures are aimed at boosting domestic productivity in those countries, and China expects to reap benefits from its program. The potential benefits for China are plentiful. China is still very much an export-oriented economy and a global manufacturing hub. Strong growth in underdeveloped countries is likely to increase demand for Chinese goods, allowing the Chinese economy to experience faster growth. China also hopes to get direct revenue from its investment operations under this program, and they have the additional goal of expanding their political clout. Contrast this with the case of the IMF, whose founding goal is to ensure financial stability and to prevent crisis contagion and panic. The two forms of lending are evidently quite different in their desired goals.</p>
","18533"
"When does the Divine Equilibrium refinement coincide with that of Perfect Sequential Equilibrium?","373","","<p>In signaling games, it seems that the Cho Kreps refinement (intuitive criterion) is the go to refinement for eliminating bad sequential equilibria. <a href=""http://econweb.ucsd.edu/~jsobel/Papers/EquilibriumSelectionSignalingGames.pdf"">Divine equilibrium</a> and <a href=""http://www.sciencedirect.com/science/article/pii/0022053186900220"">perfect sequential equilibrium</a> are also interesting refinements though. It seems more common that these are compared to Cho Kreps. Are there any interesting examples comparing the differences between perfect sequential and divine equilibrium? I've never seen the two concepts discussed together. </p>
","<p>Some input:  </p>

<p>In <a href=""http://www.jstor.org/stable/1885060"" rel=""nofollow"">Cho, I. K., &amp; Kreps, D. M. (1987). Signaling games and stable equilibria. The Quarterly Journal of Economics, 179-221</a>, Banks &amp; Sobel's Divine (and Universally Divine) equilibrium concepts are presented in Section IV.4 as a stand-alone concept.
On the other hand Grossman &amp; Perry's Perfect Sequential Equilibrium concept is just mentioned in Section IV.5 which has the title ""Never a weak best response"".</p>

<p>In the <a href=""http://www.jstor.org/stable/1913604%20."" rel=""nofollow"">Banks, J. S., &amp; Sobel, J. (1987). Equilibrium selection in signaling games. Econometrica, 647-661.</a> paper on Divine Equilibrium, page 654 (near the end of Section 3), we read <em>""(...) This condition is more restrictive than universal divinity because (...)""</em> , ""this condition"" being ""never a weak best response"".</p>

<p>So it appears that Perfect Sequential Equilibrium (PSE) is a stronger equilibrium filtering criterion than Divine Equilibrium. This accords with</p>

<p><strong>Theorem 2 of Banks &amp; Sobel : Every signaling game has a divine equilibrium</strong><br>
to be contrasted with Section 4. of the <a href=""http://www.sciencedirect.com/science/article/pii/0022053186900220#"" rel=""nofollow"">Grossman, S. J., &amp; Perry, M. (1986). Perfect sequential equilibrium. Journal of economic theory, 39(1), 97-119</a>. paper introducing PSE, where they show by means of an example that <strong>a Perfect Sequential Equilibrium may fail to exit</strong>.</p>

<p>A paper that applies both concepts is <a href=""http://www.sciencedirect.com/science/article/pii/016771879290014P#"" rel=""nofollow"">Beggs, A. W. (1992). The licensing of patents under asymmetric information. International Journal of Industrial Organization, 10(2), 171-191.</a>. In Section 3.2 a result is derived by an appeal to the PSE concept. Then the authors note that, <em>given</em> an additional condition, they could obtain the same result by an appeal to Divinity. This agains shows that PSE, when it exists, is stronger than Divine equilibrium. Here too an example is offered for a case when the PSE does not exist.</p>
","202"
"Writing the core as the intersection of pareto efficient outcomes of all coalitions","373","","<p>I have been reviewing general equilibrium models and was trying to find an efficient method for computing the core of a cooperative game. I was taught this topic in a very poor way so I believe I still have some conceptual errors. </p>

<p>Here is a thought I had:</p>

<p>Suppose we are in an economy with three consumers, $A$, $B$, and $C$, with utility $u_{i}(x)$ defined over bundles $x \in \mathbb{R}^{2}$ and endowments $\omega_{i}$ for $i = A, B ,C$. I want to compute the core for this economy.</p>

<p>I know the core must satisfy:
\begin{align}
u_{A}(x_{A}) &amp;\geq u_{A}(\omega_{A})\\
u_{B}(x_{B}) &amp;\geq u_{B}(\omega_{B})\\
u_{C}(x_{C}) &amp;\geq u_{C}(\omega_{C})\\
\end{align}
i.e. the core must be individually rational. So let $$D =\{ x \in \mathbb{R}^{2} : x \text{ is individually rational for $A$, $B$ and $C$} \}$$ I also know that the core is a subset of the pareto efficient outcomes, so let $$E =\{ x \in \mathbb{R}^{2} : x \text{ is pareto efficient} \}$$ Now here is the part I am not sure about: I know that the core is also not blocked by any two-person coalition. I think this means that any core allocation is pareto efficient for any two-person game. Thus I define: 
\begin{align}
F_{1} =\{ x \in \mathbb{R}^{2} : x \text{ is pareto efficient in the cooperative game with only $A$ and $B$ } \}\\
F_{2} =\{ x \in \mathbb{R}^{2} : x \text{ is pareto efficient in the cooperative game with only $A$ and $C$ } \}\\
F_{3} =\{ x \in \mathbb{R}^{2} : x \text{ is pareto efficient in the cooperative game with only $B$ and $C$ } \}
\end{align} </p>

<p>Here are my questions:</p>

<ol>
<li>Is the above analysis correct?</li>
<li>Can I write the set of core allocations $\mathcal{C}$ as $$\mathcal{C} = D \cap E \cap F_{1} \cap F_{2} \cap F_{3}\text{?}$$</li>
<li>Can this method of solving be generalized to a game with $n$ players and $m$ goods?</li>
</ol>

<p>Let me know if anything is not clear!</p>
","<ol>
<li>Most of what you write is correct, but the definitions of the $F_i$ sets is imprecise. The problem is that in the core $A$ and $B$ may get goods that do not match their initial endowments. In this case it is not true that the core allocation $x$ is Pareto-efficient in the restricted 2-person economy of $A$ and $B$, because $x$ is not even an allocation in that game.</li>
</ol>

<hr>

<p>Edit: (An example)</p>

<p>Consider the initial endowments
$$
\omega_{A} = (1,1),  \omega_{B} = (1,1), \omega_{C} = (2,2)
$$
and an allocation $x$
$$
x_A = (2,2), x_B = (2,2), x_C = (0,0).
$$
$A$ and $B$ cannot Pareto-improve on $x$. But $x$ is not a Pareto-efficient allocation in their 2-person economy, because it is not a feasible allocation of their economy:
$$
x_A + x_B \neq \omega_{A} + \omega_{B}
$$</p>

<hr>

<p>A better definition for the sets $F_i$  would be something like:</p>

<p>Let us denote the set of feasible allocations of the 2-person economy of $A$ and $B$ by $Y_{A,B} \subset \mathbb{R}^{2}$. Then
$$
F_{1} =\{ x \in \mathbb{R}^{2} : \nexists y \in Y_{A,B} \text{ such that } u_{A}(y_{A}) \geq u_{A}(x_{A}), u_{B}(y_{B}) &gt; u_{B}(x_{B}) \}
$$
There are still some issues with cases when $A$ is better off and $B$ is not worse off, but if the utility functions are continuous then this should not cause a problem.</p>

<p>You can define $F_{2}$ and $F_{3}$ in a similar manner.</p>

<p>A remark: $E$ is not 'special', it is the set of allocations that cannot be improved upon by the three player coalition. This is equivalent to Pareto-efficiency.</p>

<ol start=""2"">
<li><p>Yes. Why not? This is exactly what the core is.</p></li>
<li><p>I would not call it solving, because usually you do not get a unique solution, and in extreme cases you may get no solution. But yes, every economy ($n$ players, $m$ goods) has a core, and it is defined in this way. (As indicated, unless some conditions are met the core may be empty. A competitive equilibrium is always an element of the core, so if that exists, the core is non-empty.)</p></li>
</ol>
","9848"
"Equi-marginal Principle","372","","<p>Hi the textbook i am studding from simply states that 'the rule for rational consumer behaviour is know as the equi-marginal principle. This states that a consumer will get the highest utility from a given level of in come when the ratio of the marginal utilities is equal to the ratio of prices'. I was hoping someone could maybe give me a bit more intuition behind this. Maybe it is self-explanatory... maybe not.</p>
","<p>Suppose there are two goods $X$ and $Y$. A consumer has lots of $Y$ and very little $X$, and as a result his marginal utility of $Y$ is a lot lower than the marginal utility of $X$ (it helps here to think about a convex utility function such as $U=XY$). We could make him better off if we could convert some of those $Y$'s into $X$s (again, this follows from the convexity of utility, a standard assumption. Intuitively, people want more of everything but still prefer balanced consumption bundles to extremes). The question then becomes, ""how many $X$s can we buy for each unit of $Y$ we give up?"" The answer is that each $Y$ can buy $\frac{P_X}{P_Y}$ units of $X$.Thus, we convert $X$ into $Y$ until the slopes of the marginal utilities equals the price ratio, at which point additional conversion would result in a larger loss from less $Y$ than gain from more $X$.</p>

<p>A more general way of looking at this is through calculus. For a constrained function that is continuously differentiable, the slopes at any interior maxima and minima must be parallel to the slope of the constraint. In this case, the function is the utility function, $\frac{P_X}{P_Y}$ is the slope of the constraint.</p>
","5434"
"Portfolio choice problem of a CARA investor with n risky assets","372","","<p>Ok, I am working on a problem that consists of the following:</p>

<p>I am looking to solve the portfolio choice optimization problem (maximizing utility with a known utility function) in the case where all of the underlying random variables are multivariate normal.</p>

<hr>

<p><strong>Problem:</strong></p>

<p>define $\phi$ as the amount invested in each of $n$ risky assets, such that the budget constraint is:</p>

<p>$\Sigma_{i=1}^{n}\phi_i=w_0$ for some initial wealth, $w_0$</p>

<p>Show that the optimal portfolio is:</p>

<p>$\phi=\frac{1}{\alpha}\Sigma^{-1}\mu+[\frac{\alpha w_0-1'\Sigma^{-1}\mu}{\alpha 1'\Sigma^{-1}1}]\Sigma^{-1}1$</p>

<p>where each of the 1's is an $n$-dimensional column vector of 1's.</p>

<hr>

<p><strong>Work/Attempt</strong></p>

<p>Ok, these are the things I know:</p>

<p>I am dealing with CARA utility, which gives me a utility function of the form:</p>

<p>$u(w)=-e^{-\alpha w}$ where $w$ is my random end-of-period wealth which I believe to be distributed as</p>

<p>$w$~$N(\mu,\sigma^2)$ with $\mu=\phi'\mu$ (a vector of expected returns scaled by the amount invested in each), and $\sigma^2=\phi'\Sigma\phi$ where $\Sigma$ is the covariance matrix of the $n$ risky assets.</p>

<p>So, to find the expected utility of this function, I use the fact that the expectation of an exponential of normals is the exponential of the mean plus half the variance, to arrive at:</p>

<p>$E(u(w))=-e^{-\alpha\phi'\mu+\frac{\alpha^2\phi'\Sigma\phi}{2}}$</p>

<p>Factoring out a negative alpha, and equating the remaining part of the exponential as the certainty equivalent of a random wealth (I might not be explaining that well, but I am almost certain this is the correct path), I can maximize utility by maximizing the utility of the certainty equivalent, which is done by maximizing the certainty equivalent itself.</p>

<p>All that to say, I need:</p>

<p>$\frac{\partial}{\partial\phi}\phi'\mu+\frac{\alpha\phi'\Sigma\phi}{2}=0$</p>

<p>From there I can't seem to get anything even remotely close to the result I am supposed to show. I have</p>

<p>$1'\mu+\alpha\Sigma\phi=0$</p>

<p>which seems to mirror the first term in the result, but I am lost as to where the rest comes from.</p>

<p>Any help would be appreciated. I'm not sure if my mistake is in the multi-dimensional partial derivative, or if it is in obtaining the function that needs to be maximized. The book I am using has a similar problem for a single risky asset which I can work through just fine, but the exclusion of a risk-free asset (which would seem to simplify the wealth constraint) makes it more confusing to me.</p>
","<p>The problem is equivalent to maximizing</p>

<p>$$
\max_\phi \left( \phi ' \mu - \frac{1}{2} \alpha \phi ' \Sigma \phi \right)
$$</p>

<p>subject to</p>

<p>$$
\mathbf{1}' \phi = w_0.
$$</p>

<p>(boldface 1 is column vector of ones, ' stands for transposition).</p>

<p>The lagrangian is</p>

<p>$$
L(\phi, \lambda) = \phi ' \mu - \frac{1}{2} \alpha \phi ' \Sigma \phi - \lambda \left( \mathbf{1}' \phi - w_0 \right),
$$</p>

<p>and its jacobian wrt. $\phi$ is</p>

<p>$$
\mathrm{D}_\phi L(\phi, \lambda) = \mu' - \alpha \phi ' \Sigma - \lambda \mathbf{1}'.
$$</p>

<p>First order conditions require that the jacobian is equal to zero (in each element), plus the original budget constraint, which together (after transposing the jacobian) yields a system of linear equations in $(\phi,\lambda)$:</p>

<p>$$
\begin{split}
\Sigma \phi + \mathbf{1} \lambda &amp;= \frac{1}{\alpha}\mu \\
\mathbf{1}' \phi &amp;= w_0
\end{split}
$$</p>

<p>We can solve for $\phi$ as a function of multiplier $\lambda$:</p>

<p>$$
\phi = \frac{1}{\alpha} \Sigma^{-1} \mu - \lambda \Sigma^{-1} \mathbf{1} 
$$</p>

<p>Plugging this into the budget constraint and some algebra yields an expression for $\lambda$:</p>

<p>$$
\lambda = \frac{\frac{1}{\alpha}\mathbf{1}' \Sigma^{-1} \mu - w_0}{\mathbf{1}' \Sigma^{-1} \mathbf{1}},
$$</p>

<p>and substituting this into the expression for $\phi$ should yield the result as given in the question.</p>
","3276"
"price space as a dual of commodity space","372","","<p>I often see papers in economic theory mentioning a duality between the price space and the commodity space. I think they refer to <a href=""https://en.wikipedia.org/wiki/Dual_space"" rel=""nofollow"">duality of vector spaces</a>. I.e, the commodity space is a vector space, a price system is a linear functional over the commodity space (assigning a value to each bundle), and so the space of all possible price systems  is the dual of the commodity space.</p>

<p>Is there a standard reference that explains this duality in more detail?</p>
","<p>If you want to see a nice usage of duality in economics, in <a href=""http://rads.stackoverflow.com/amzn/click/0195073401"" rel=""nofollow"">Mas-Colell, Whinston, and Green</a>  there's a nice section on duality in the second or third chapter when talking about Hicksian demand. The treatment is pretty straightforward if the consumption space is real and has a finite dimension. I think understanding that basic usage of duality is illustrative of its general utility.</p>

<p>If the idea is to understand what duality is and how it operates, I think <a href=""http://www.springer.com/gp/book/9780387972459"" rel=""nofollow"">Conway</a> is a great book. </p>

<p>(Just undergrad here, hope I'm not mixing up topics). </p>
","5122"
"Consumer optimum in an economy with a continuum of commodities","371","","<p>Consider an economy with a continuum of commodities, with one commodity for each point in $[0,1]$.</p>

<p>Suppose a consumer wants to maximise
$$U = \int_0^1 c_i^\theta\,di\qquad 0&lt;\theta&lt;1$$
subject to
$$\int_0^1 p_i c_i\,di = M$$
where $c_i$ is the amount of the $i$-th commodity consumed, $p_i$ its price and $M$ the consumer's money income.</p>

<p>This kind of problem arises for example in applying the Dixit-Stiglitz model to macroeconomics or international trade.</p>

<p>The solution to this problem is supposedly
$$c_i = Ap_i^{1 \over {\theta-1}}$$
where $A$ is a constant chosen to ensure that the budget constraint is satisfied.</p>

<p>I am not very satisfied with derivations of this result which use Lagrange multipliers in analogy with the case of a finite number of commodities. What would be a completely mathematically rigorous method of deriving the above result?</p>

<p>It seems clear that there isn't a unique solution since arbitrarily changing the values of $c_i$ for a finite number of values of $i$ will leave the integrals in the utility function and budget constraint unchanged. I am expecting that a completely rigorous derivation would also correctly pinpoint this degree of nonuniqueness.</p>

<p>EDIT: In response to the comments by @BKay, @Ubiquitous. My problem with starting out with economies with $n$ commodities and taking the limit as $n \to \infty$ is that this needs to be accompanied by an argument which shows that the limit of optima is an optimum of the limit problem. I would appreciate a reference to a result which shows this either for this particular problem or a general result which is applicable to this problem.</p>

<p>In response to @AlecosPapadopoulos. The proofs of the Langrange multiplier method that is taught in math for economics courses is usually for a finite number of choice variables. I would appreciate a reference to where the method is justified for a continuum of choice variables. Also, the nonuniqueness I mention above shows that the method cannot be exactly right. Then what exactly are the qualifications required for its validity?</p>
","<p>The completely rigorous thing would be to write the Euler lagrange equation of this calculus of variations problem, this will give you a strong solution that is what you have or a weak solution that is written with respect to a distribution. </p>
","220"
"If I don't pay a debt, then the creditor takes my goods. Why, then, do Greek creditors not take Greece?","371","","<p>Normally, when you don't pay a debt, your creditors take your goods (house, car, etc...).</p>

<p>If Greece cannot pay its debt, can its creditors take Greek goods (structures, cities, industries, lands, etc...)? Can Germany, or other organizations, become owners of Greece?</p>

<p>Maybe that's a silly question, but for a non-expert it sounds logical.</p>
","<p>In general, there are three kinds of debt:</p>

<ol>
<li>Secured debt, like a mortgage or a repurchase agreement. With a mortgage, for example, the debt is secured by a lien on the home, and if the debtor does not pay, the creditor can seize the home.</li>
<li>Unsecured debt, like a credit card or corporate bond. Governments will generally allow creditors to liquidate many of the assets of an insolvent individual or firm to meet unsecured obligations, subject to (often significant) limits. For individuals, things like retirement accounts and primary residences are often off-limits for debt collection.</li>
<li>Sovereign debt. Sovereigns typically issue debt under their own law, and countries generally don't set up their legal systems in such a way as to allow other countries to take their things. However, when sovereigns issue debt under foreign countries' law, as <a href=""http://www.forbes.com/sites/timworstall/2012/05/16/the-value-of-foreign-law-in-investing-greece-pays-out-on-english-bonds/"">Greece has done with some UK-law bonds</a>, payouts tend to be higher, and overseas property is in fact <a href=""http://www.businessinsider.com/ghana-court-says-argentine-ship-left-illegally-2014-10"">occasionally seized</a>. However, seizing the domestic property of a defaulted sovereign is effectively impossible, as one of the benefits of being a sovereign is that you control your own territory— attempting to seize another nation's ""structures, cities, industries, lands, etc."" (setting aside the fact that most structures, cities, industries, and land in Greece are not owned by the government) is what is known as an act of war.</li>
</ol>
","6417"
"Indifference curves passing thru few points","371","","<p>Tommy Twit’s mother measures the departure of any bundle from her favorite bundle for Tommy by the sum of the absolute values of the differences. Her favorite bundle for Tommy is (2, 7), that is, 2 cookies and 7 glasses of milk. Tommy’s mother’s indifference curve that passes through the point (c, m) = (4, 5) also passes through</p>

<p>a.
the points (4, 7), (2, 5), and (2, 9).</p>

<p>b.
the point (2, 7).</p>

<p>c.
the points (2, 3), (6, 7), and (4, 9).</p>

<p>d.
the point (6, 3).</p>

<p>e.
None of the above.</p>

<p>How to solve this question? I thought that it is enough to find a line passing through two points given however then the equation would be $y=9-x$ however the points given does not fit to the equation. Correct answer given in a questionbank is <strong>C</strong>. I have no additional info regarding this question and i have to admit yes it is badly stated.</p>
","<p>The first sentence means that Tommy's mother's utility function over a bundle $(x,y)$ equals
\begin{equation*}
u(2,7)-u(x,y)=|x-2|+|y-7|
\end{equation*}
since she measures the disutility of this bundle with respect to the most preferred one by the ""sum of the absolute values of the differences"".</p>

<p>Therefore the utility that she associates with the point $(4,5)$ equals
\begin{equation*}
u(4,5)=u(2,7)-(2+2)=u(2,7)-4
\end{equation*}</p>

<p>You are asked to find the indifference curve that passes through the point $(4,5)$, i.e. the set of bundles $(x,y)$ that satisfy
\begin{equation*}
u(x,y)=u(4,5)
\end{equation*}
which you can write
\begin{equation*}
u(2,7)-u(x,y)=u(2,7)-u(4,5)=4
\end{equation*}</p>

<p>The question is therefore: which of the options a), b), c), d) (if any) contain only bundles $(x,y)$ such that $u(2,7)-u(x,y)=4$? You simply have to compute $u(2,7)-u(x,y)$ for all the proposed bundles, given the formula above, and check whether the value equals 4 or not.</p>
","10253"
"New-Keynesian Model: Log-linearizing the firm's FOC","371","","<p>In Gali's book (chapter 3), the FOC of a firm is given by:</p>

<p>$$(\sum_{k=0}^\infty \theta^k E_k(Q_{t,t+k} Y_{t+k|t} (P_t^*/P_{t-1} - \alpha MC_{t,t+k} \beta_{t-1,t+k}))) = 0 $$</p>

<p>Basically, the first order condition for maximizing a firm's profit. $0&lt; \theta &lt;=1$, $\alpha$ is markup over competitive price. MC is marginal cost. And $beta = P_{t+k}/P_t$. </p>

<p>At the zero inflation steady state (the point we're supposed to linearize this around),</p>

<p>$P_t^*/P_{t-1} = 1$ 
$beta = P_{t+k}/P_t = 1$
$P^*=P_{t+k}$ 
Thus Y is constant. $Y_{t+k|t} = Y$ and so is MC. 
Q is stocastic discount factor and equals $B^k$ around steady. 
Similarly, Marginal cost (MC) is the reciprocal of the markup. i.e. $MC = 1/\alpha$</p>

<p>I need to expand this lovely expression. The problem I'm having is that if I do an expansion around the steady state, everything seems to be cancelling out, leaving me without anything that looks like the intended solution to the problem. </p>
","<p>$$(\sum_{k=0}^\infty \theta^k E_k(Q_{t,t+k} Y_{t+k|t} (P_t^*/P_{t-1} - \alpha MC_{t,t+k} \beta_{t-1,t+k}))) = 0 $$</p>

<p>Log linearize around the zero inflation steady state.</p>

<p>$$p_t^* - p_{t-1} = (1 - \beta\theta) \sum_{k=0}^\infty (\beta\theta)^k E_t(\widehat{mc}_{t+k|t} + p_{t+k} - p_{t-1}) $$</p>

<p>Where $$\widehat{mc}_{t+k|t} \equiv {mc}_{t+k|t} - mc$$
In other words,
$$p_t^* = \gamma + (1 - \beta\theta) \sum_{k=0}^\infty (\beta\theta)^k E_t(\widehat{mc}_{t+k|t} + p_{t+k}) $$
where $\gamma \equiv log \frac{\epsilon}{\epsilon + 1} $</p>

<p>If I remember correctly, this model uses Calvo pricing, so inflation is just from wage stickiness. So if you set $\theta = 0$ (no price stickiness)
$$p_t^* = \gamma + mc_t + p_t$$</p>

<p>See what you can work with from there.</p>

<p>Edit: If you're wondering how this is done, then ""An Old Man in the Sea""'s resource in the comments is helpful, in sections 3.2 and 3.3. It will show how to do the First-Order Taylor Expansion to derive the result.</p>
","4843"
"Formula for the unconditional variance of the sum of observations from an autoregressive time series","370","","<p>I have notes that say that we can make the following calculations. I'm a little confused about some of the calculations that are being made. What assumptions would I need to get the following results? Or are there errors? Specifically, I am confused by equation (1) below. In particular, this is strange to me because if I let $\rho = -1$, then equation (1) sometimes gives negative variance. (Perhaps the calculation is undefined when $\rho = -1$?)</p>

<p>Let $r_{t,t+n} = \sum_{i=1}^n r_{t+i}$. Suppose that $r_t$ is an AR(1) process (say with errors given by a mean zero Normal distribution with variance $\sigma^2$) where
$$
\text{Cov}(r_t,r_{t+j}) = \rho^j \sigma^2
$$
and thus
$$
\text{Corr}(r_t, r_{t+j}) = \rho^j.
$$</p>

<p>The notes that I have say that $\text{Var}(r_{t,t+2}) = 2(1 + \rho) \sigma^2$ and that
$$
\text{Var}(r_{t,t+n}) = \left( n + 2 \sum_{i=1}^{n-1} \rho^i (n-i) \right) \sigma^2. \tag{1}
$$</p>

<p>(FWIW, this question deals with cumulative (log) returns.)</p>
","<p>Ok. I made some small computation errors and got confused here. The notes make sense with the following notational assumptions. If I write out the AR(1) process as follows (ignoring drift)
$$
r_{t+1} = r_t + \epsilon_{t+1},
$$
then we have $\text{Cov}(r_t, r_{t+j}) = \frac{\rho^j}{1 - \rho^2} \sigma_\epsilon^2$, where
$\sigma^2_\epsilon := Var(\epsilon)$. The point that I should have caught on to in the notes was exactly the point that the variance is <em>unconditional</em> and so 
$\text{Var}(r_t) = \sigma^2 = \frac{1}{1 - \rho^2} \sigma_\epsilon^2$ is the unconditional variance (the time series is stationary only when $|\rho| &lt; 1$, so beware when using $\rho = -1$ as mentioned above). Given this definition, everything works. First, note that
$$
\text{Cov}(r_t, r_{t+j}) = \frac{\rho^j}{1 - \rho^2} \sigma_\epsilon^2 = \rho^j \sigma^2,
$$
as noted above. Then also notice that
\begin{align}
\text{Var}(r_{t,t+n}) &amp;= \text{Var}\left (\sum_{i=1}^n r_{t+i} \right) \\
 &amp;= \sum_{j=1}^n \sum_{i=1}^n \text{Cov}(r_{t+1}, r_{t+j}) \\
 &amp;= \sum_{j=1}^n \sum_{i=1}^n \rho^{|i - j|} \sigma^2 \\
 &amp;= \left (n + 2 \sum_{i=1}^{n-1} \rho^j (n - i) \right) \sigma^2.
\end{align}
So, it all works out.</p>
","2981"
"L-infinity and weak-star topology","370","","<p>While reading economics papers, especially those related to economy with land, I often encounter the terms $L^\infty$ and the ""weak* topology"". They seem like very basic terms, but I couldn't find a basic explanation of them. Here is a typical paragraph which I am trying to decipher (it is from page 4 at the introduction of <a href=""http://www.sciencedirect.com/science/article/pii/0022053188900087"">A foundation of location theory</a>):</p>

<hr>

<p>Let:</p>

<p>$$[0,\frac{1}{n}]\cup[\frac{2}{n},\frac{3}{n}]\cup[\frac{4}{n},\frac{5}{n}]\cup...\cup[\frac{n-2}{n},\frac{n-1}{n}]$$</p>

<p>$(n=1,2,...)$ represent a sequence of commodities of increasing utility. If the indicator functions of these sets are embedded in $L^\infty$ with the weak* topology, then the limit is $\frac{1}{2}1_{[0,1]}$, half the indicator function on the interval $[0,1]$. This, indeed, is a natural limit that is not in the commodity space.</p>

<hr>

<p>So my questions are:</p>

<ul>
<li>What is $L^\infty$?</li>
<li>What is the ""weak* topology""?</li>
<li>What is the meaning of ""embedded in $L^\infty$""?</li>
</ul>

<p>NOTE: I have some basic (undergraduate) knowledge of topology. I have heard about ""weak topology"" but never heard of ""weak* topology"". I will be very thankful for a simple, intuitive explanation that will help me continue reading!</p>
","<p>$L^{\infty}$: the (Banach, usually) space of bounded measurable functions modulo the equality almost everywhere. Like all function spaces not involving holomorphic functions, it's really a space of equivalence classes.</p>

<p>weak-$^*$ topology: the topology on the dual $X^*$ of any topological vector space $X$ induced by the $(X, X^*)$-pairing. </p>

<p>""embedded in $L^{\infty}$"": a (say) topological vector space $Y$ is said to be embedded in $L^{\infty}$ if there is an injective continuous linear map from $Y$ to $L^{\infty}$. </p>

<p>(This is the usual meaning. In your paragraph, ""embedded"" just means viewing those indicator functions as representatives of their classes. The weak-$^*$ topology on $L^{\infty}$ is given by the identification $L^{\infty} = (C_0)^*$.) </p>
","5248"
"How to create a Budget line in excel or R","369","","<p>Im interested in programming a budget line or PPF which is responsive to changes in relative prices, and income effect.</p>

<p>I know the equation for the budget line is $$m\geq p_1x_1+p_2x_2$$
Lets say we have an Income of $m=100$ and prices $p_1=1$ and $p_2=2$.</p>

<p>How would I go about programming this into an excel spreadsheet or R?</p>
","<p>Another R code that does it...</p>

<pre><code>m &lt;- 100
p &lt;- c(1, 2) 
curve(m/p[2] - p[1]/p[2]*x, from = 0, to = m/p[1], lwd = 2,
      xlab = expression(x[1]),
      ylab = expression(x[2]))
</code></pre>

<p><a href=""https://i.stack.imgur.com/eQ6K3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eQ6K3.png"" alt=""enter image description here""></a></p>
","16547"
"What is the difference between an Ordinary Demand equation and an Engel curve equation?","367","","<p>I mean, an Ordinary Demand Equation measures changes in quantity of X due to changes in price Px.  Engel Curve measures changes in quantity of X due to changes in income M.  But ODE has M in it's equation, and is simply just an algebraic variant of the Engel curve!</p>
","<p>Engel curve assumes the price is constant, and demand curve assumes income constant. There is only demand function, no engel curve equation or demand equation.</p>
","10680"
"Does concavity of the utility function has any bite?","366","","<p>A utility function in general has only ordinal meaning, any monotone transformation preserves the order isomorphism of the underlying preference ordering. However, there are several econometrics papers, that estimate demand with concavity shape restrictions on the utility. 
Is this justified? 
My first thought is that yes, that the key idea is that there exists a concave utility representation, and this generates the dataset, however it worries me the identification issue since there is infinitely many of these utilities not all of them concave. 
In short, does it make sense to require concavity restrictions on the utility function in econometric work?</p>
","<p><a href=""https://economics.stackexchange.com/questions/370/when-can-one-safely-talk-about-decreasing-marginal-utility/""><strong>This post</strong></a> shows clearly why in the world of ""standard"" ordinal utility, concavity of a utility function cannot obtain an economically meaningful interpretation, although it may be useful as a mathematical property.</p>

<p><strong><em>But ""standard"" ordinal utility is not compatible with Econometrics</em></strong>, because Econometrics deal inherently with situations where there exists uncertainty, and in a framework with uncertainty we move from ""fully ordinal utility"" to <strong>Expected Utility theory, where properties like concavity have economically meaningful content -they express attitude towards risk</strong> (as well as ""preference intensity"", as <a href=""https://economics.stackexchange.com/questions/5142/does-risk-aversion-cause-diminishing-marginal-utility-or-vice-versa/""><strong>this laborious post</strong></a> shows).  </p>

<p>The concavity assumption/restriction is made because there is universal consensus that the vast majority of people exhibit risk aversion in their economic behavior.</p>
","5228"
"What does Hayek mean at the end of the first paragraph of The Use of Knowledge?","365","","<p>I reproduce here the first paragraph of Hayek's well-known essay <a href=""http://object.cato.org/sites/cato.org/files/articles/hayek-use-knowledge-society.pdf"" rel=""nofollow"">The Use of Knowledge in Society</a>:</p>

<blockquote>
  <p>What is the problem we wish to solve when we try to construct a rational economic order? On certain familiar assumptions the answer is simple enough. If we possess all the relevant information, if we can start out from a given system of preferences, and if we command complete knowledge of available means, the problem which remains is purely one of logic. That is, the answer to the question of what is the best use of the available means is implicit in our assumptions. The conditions which the solution of this optimum problem must satisfy have been fully worked out and can be stated best in mathematical form: put at their briefest, they are that <strong>the marginal rates of substitution between any two commodities or factors must be the same in all their different uses.</strong> [emphasis added]</p>
</blockquote>

<p>I have bolded the part that I don't quite grasp, not being a trained economist. Can anyone explain this in layman's terms? (I understand marginalism quite well, so no need to go in depth on that, though it could help others understand better. Of course, perhaps I don't understand marginalism as well as I thought.)</p>
","<p>Your marginal rate of substitution between (say) eggs and wine is the number of eggs you'd be willing to trade for one additional bottle of wine.  This marginal rate of substitution can reflect your preferences (if you're a consumer) or the state of technology (if you're a producer who can, for example, substitute three eggs for one wine in your production process).</p>

<p>Suppose your MRS is three eggs per wine and my MRS is two eggs per wine.  Then there's an opportunity for a mutually beneficial trade:  You give me two and a half eggs, and I'll give you a wine.  You thought the wine was worth three eggs, and you got it for two and a half --- that's a win.  I thought the wine was worth two eggs, and I sold it for two and a half --- that's also a win.</p>

<p>Whenever your MRS differs from my MRS, there's an opportunity for a mutually beneficial trade.  </p>

<p>Therefore, if our MRS's differ, it means that an opportunity for mutually beneficial trade has been missed.  </p>

<p>So in order for resources to be used efficiently --- that is, in such a way that all opportunities for mutually beneficial trade have been exploited --- the MRS between any two commodities must be the same for you as it is for me or anyone else, regardless of how we're using those resources.</p>
","3266"
"How could Pablo Escobar earn so much money?","364","","<p>I read it's about 30 billion. But I read there were 6 million users in 1985. Let's say he gets 10 percent of the sales price, it means each person paid 50000 dollars for cocaine. It sounds way too much. Any calculations how they reached this amount?</p>
","<p>Not sure an economist can answer this particular question about Escobar's wealth and not only because all the given estimates are uncertain. A more interesting question for an economist (or at least for me) would be: What is Escobar's (a drug firm) mark-up? Or what is the economic size of the international market for cocaine?</p>

<p>The most serious source of information I was able to find is the <a href=""http://www.unodc.org/documents/data-and-analysis/WDR2012/WDR_2012_web_small.pdf"" rel=""nofollow noreferrer"">2012 World Drug Report</a> of the United Nations Office on Drugs and Crime (UNDOC). UNODC estimates suggest that</p>

<ol>
<li>The total retail market for cocaine amounts to some US $85 billion in 2009 (p.70). </li>
<li>Columbian production proxied in terms of hectares is around 89% (based on 2009's estimates (68,000+73,000)/158,800 - Table 12).</li>
</ol>

<p>So, if you assume that all Columbian production is produced by Escobar's cartel his total benefit is about USD $75 billion for the year 2009. </p>

<p><strong>Edit</strong>: However, we cannot assume that Escobar's cartel got 89% of the retail value (thanks to @Alecos Papadopoulos for this point). The USD 75 billion is the equivalent of the ""box office"" for a movie - but the producers of the movie (i.e. Escobar's cartel) do not get all the box office. </p>

<p>Then, the question is what is the proportion retained by the Escobar's cartel? I have no clue! However, <a href=""http://pricetheory.uchicago.edu/levitt/Papers/LevittVenkateshAnEconomicAnalysis2000.pdf"" rel=""nofollow noreferrer"">Levitt and Vetakesh QJE paper</a> document that ""earnings within the (drug) gang are enormously skewed (..) with high-level gang members earning far more than their legitimate market alternative."" So, by extrapolating from this result and assuming that the drug market is vertically integrated and controlled by the Escobar's cartel, we may speculate that the latter (and Escobar himself) may get a big part of the box office.</p>

<p>In this report, you may also find more reliable estimates about </p>

<ol>
<li>The total number of cocaine users: 16 million (Table 7)</li>
<li>and the estimates per region.</li>
<li>Purity-adjusted prices per gram in those regions</li>
</ol>

<p>So if you find some data on consumer's average consumption and Escobar's production you may get a better estimate of his wealth.</p>
","14370"
"Suitable terminology for the inverse elasticity?","364","","<p>In many microeconomic applications (e.g. monopoly price-setting) the <strong>inverse elasticity</strong> appears. Explaining such relations to laymen is often awkward because inverse proportionality is not as intuititve as direct proportionality. </p>

<p>In physics, there are often separate terms for inverses of important concepts (e.g. electrical resistance and conductance are each other's inverse).</p>

<p><strong>Question</strong>: is there a commonly used term for the inverse elasticity? If not, what would be a suitable term that is easily grasped by laymen?</p>
","<p><a href=""http://en.wikipedia.org/wiki/Lerner_index"" rel=""nofollow"">Lerner Index.</a>  The term is pretty ambiguous in use.  Sometimes people mean, by Lerner Index, ""price-cost margin,"" and sometimes people mean ""minus the inverse of the demand elasticity.""  But that works to your favor here.  It can mean what you want it to, so use it that way.</p>
","3216"
"Effect of specific tax on demand and supply","362","","<p>There are intersecting supply and demand curves. A tax is levied on suppliers. Say the tax is a fixed tax (for example, VAT) and not an ad valorem tax. </p>

<p>Why can we not just move along the demand curve by the value of the tax (as producers just increase the price by the value of the tax)? So for any given point on the demand curve, just increase the price by the given value of the tax and that is the new demand - why does it not work like this? </p>

<p>Whilst I agree a parallel shift of the supply curve by the value of the tax makes sense I do not understand where is the flaw in the earlier method?</p>
","<p>The answer has to do with the fact that (under typical assumptions) producers experience increasing marginal costs as output rises. This makes the supply curve upward-sloping. </p>

<p>Suppose firms simply increased the price by the amount of the tax. Consumers would then buy fewer units of the good, resulting in less profits for producers. However, marginal costs are also lower at the lower level of production, meaning that firms could profitably produce at a lower price than that. So they lower the price and increase production a bit to partially offset the losses caused by the tax (note, the price remains above where it would be without the tax, and production still less than without the tax).</p>
","5416"
"What are good books about monopolies and market failures?","361","","<p>Is there a good undergraduate level book specifically about economic monopolies and market failures?</p>
","<p>Your question is quite broad in the sense that various forms of market failure cover a significant portion of all of microeconomics. I presume you have already looked in a general undergraduate micro book such as Varian's <em><a href=""http://books.wwnorton.com/books/webad.aspx?id=4294979440"" rel=""nofollow"">Intermediate Microeconmics</a></em>, which provide coverage of many of these topics.</p>

<p>More detailed coverage of market power and monopoly can be found in Church and Ware's <em><a href=""http://works.bepress.com/cgi/viewcontent.cgi?article=1022&amp;context=jeffrey_church"" rel=""nofollow"">Industrial Organization: A Strategic Approach</a></em>. Discussion of market failures caused by public goods and externalities can be found in  Hindriks and Myles' <em><a href=""https://mitpress.mit.edu/books/intermediate-public-economics"" rel=""nofollow"">Intermediate Public Economics</a></em>. For market failoures originating in information asymmetries, a good source might be Bolton and Dewatripont's <em><a href=""https://mitpress.mit.edu/books/contract-theory"" rel=""nofollow"">Contract Theory</a></em>.</p>
","9341"
"Are lotteries auctions?","360","","<p>I heard one professor of my university say that ""<em>lottery is a kind of auction. So we can predict it! Then we could get a lot of money!</em>"" </p>

<p>Since he is in the mathematics department, and I know little about that matter, I couldn't answer to my gut feeling which told me that he was wrong.</p>

<p>So, from the Economist's perspective, is it true? Is a lottery some kind of an auction?</p>
","<p>Generally, and surprisingly, <strong>yes</strong>, lotteries are similar to auctions. What do I mean by that?</p>

<p>In an auction, you increase the likelihood of winning by increasing your bid. In many auctions, if you increase the bid sufficiently much, that probability will go to one.</p>

<p>A similar thing is true for lotteries: the more tickets you buy, the higher is the likelihood of success. It is not a one-for-one correspondence, but it holds. And again, by predicting other people's actions (are they more likely to bid/gamble on week days or week ends), you can increase your chances of winning the lottery.</p>

<p><strong>However</strong>, this means that you can increase your chances of winning, not that you will make a net surplus (""get a lot of money""). In the same way as sometimes, you can bid ""too high"" and make a net loss in an auction, you can pay a too high price for the (expected) win. In a lottery, this is quite often the case.</p>
","7066"
"Interest rates, inflation and liquidity effect","360","","<p>I am currently reading <a href=""https://pdfs.semanticscholar.org/f3d0/574627d15fe55315fb81537a351545bb84c7.pdf"" rel=""nofollow noreferrer"">Alvarez, Lucas, Weber (2001)</a> where the authors argue that changes in money supply is more important for affecting inflation, than changes in the interest rate. However, I am confused about this part:</p>

<blockquote>
  <p>To be useful in thinking about the role of interest rates and open market operations
  in the control of inflation, a model of monetary equilibrium needs to deal with
  the fact that most coherent monetary theories <strong>do not have anything like a downward
  sloping demand for nominal bonds: With a complete set of financial markets, it is
  just not true that when the government buys bonds, the price of bonds increases</strong>. We
  may believe that such a “liquidity effect” occurs in reality (though it is hard to see
  it in the data) and may regard it as a deficiency that so much of monetary theory
  ignores it, but the fact remains that one cannot take take a Sidrauski (1967), Brock
  (1974), or Lucas and Stokey (1987) model off the shelf and use it to think about
  increases in money reducing interest rates.</p>
</blockquote>

<p>How come when the government purchases bonds, the price of said bond doesn't increase? The authors argue that with an unsegmented market, this does will not happen (i.e there will be no liquidity effect). However, when markets are segmented there is a liquidity effect. The market is segmented in to two groups, traders (have access to the bond market and goods market) and non-traders (only trade in the goods market).</p>

<p>They do develop a model and I more or less understand the mathematics behind it. They show the phenomenon mentioned above using their model. However, I don't quite understand the intuition behind it. Why is there no liquidity effect when markets are unsegmented? Why don't bond prices rise with government purchases?</p>
","<p>The reason why supply effects would not occur is the result of market efficiency assumptions: all financial assets have the same expected returns. Within the bond market, that would imply that the ""term premium"" is zero. </p>

<p>If the term premium is zero, then:</p>

<ul>
<li>The value of the 1-period ""bond"" is the result of the central bank reaction function. (The policy rate.)</li>
<li>The value of a 2-period bond is determined by the 1-period yield, and the unbiased expectation of the 1-period yield, 1-period forward.</li>
<li>(Build up rest of curve similarly.)</li>
</ul>

<p>They added market segmentation as a way of allowing bonds to trade away from the predicted ('efficient"") value, that is, allow a non-zero term premium. Once we allow for a non-zero term premium, supply effects can be seen in predicted bond pricing.</p>

<p>The term premium interacts with supply as a positive term premium will induce bond investors to increase the holdings of bonds relative to the allocation that would happen if the term premium were zero. That is, changes in the term premium is needed to balance the market. </p>
","16415"
"Does the Marshallian demand function always include prices and income?","359","","<p>I have the following utility function:</p>

<p>$$U(x_i)=x_1x_2+x_3$$</p>

<p>with budget constraint:</p>

<p>$$p_1x_1+p_2x_2+p_3x_3\leq I$$</p>

<p>I use the Kuhn-Tucker method to find the optimal choices of the Utility maximization problem.
My equations are:</p>

<p>$$x_2-\lambda p_1+M_1=0$$
$$x_1-\lambda p_2+M_2=0$$</p>

<p>$$1-\lambda p_3+M_3=0$$</p>

<p>$$p_1M_1=0$$
$$p_2M_2=0$$
$$p_3M_3=0$$
$$p_1x_1+p_2x_2+p_3x_3-I=0$$</p>

<p>$$(M_1,M_2,M_3,\lambda \geq 0)$$</p>

<p>When I set $M_1=M_2=M_3=0$ (Lagrangian case), I got the optimal solutions for $x_1,x_2$ as:</p>

<p>$$x_1=\frac{p2}{p3}$$ and $$x_2=\frac{p_1}{p_3}$$</p>

<p>How could I construct a Marshallian demand function in this case? The optimal solutions haven't got the I (income) variable.</p>

<p>Is it correct to define a Marshallian demand function for good $x_1$ as:
$x_1(p,I)=\frac{p_2}{p_3}$?</p>

<blockquote>
  <p>Marshallian demand function (named after Alfred Marshall) specifies
  what the consumer would buy in each price and income or wealth
  situation, assuming it perfectly solves the utility maximization
  problem</p>
</blockquote>
","<p>These are proper Marshallian demand functions, even though Income does not appear in them. This is due to specific form of the utility function (and the candidate solution of all goods being purchased at strictly positive quantities). It emerges that there is no income effect for goods $x_1$ and $x_2$ - optimal uncompensated demand does not depend after all on the level of income, but only on the relative prices.  </p>

<p>The reason why Marshallian demand is defined as it is, is to make clear that it does not include any kind of ""income compensation"" as Hicksian demand does. But this does not preclude a case like yours, which again, depends on the form of the utility function.  </p>

<p>Thinking economically, what goods can you think of whose demand may realistically not depend on the level of income but only on relative prices? Answering this question would be useful in order to map the mathematical expression of the utility function to real-world economic phenomena.</p>

<p>Also, note that the specific utility function points to <em>""quasi-linear""</em> frameworks, where the good that enters additively, essentially functions as Income itself.</p>
","8523"
"Existence of utility representation of a rational but discontinuous preference","359","","<p>This is related to <a href=""https://economics.stackexchange.com/questions/18222/do-discontinuous-preferences-imply-no-continuous-utility-function"">Do discontinuous preferences imply no continuous utility function?</a></p>

<p>I think the title of the above-linked question is phrased in such a way that obscures a subtly different but more interesting question which the OP also hinted at in the body. I'd like to ask that explicitly here. </p>

<blockquote>
  <p><strong>Does there exist a rational but <em>discontinuous</em> preference relation that is representable by a (potentially discontinuous) utility function?</strong></p>
</blockquote>

<p>In other words, if $\succsim$ satisfies completeness and transitivity but <em>violates continuity</em>, can we still find a utility function to represent it?</p>

<p>From known results, the answer does not seem obvious. </p>

<ul>
<li>We know that <strong>continuous utility representation exists if and only if preference is complete, transitive, and continuous</strong>. But this doesn't tell us what happens when preference is not continuous.</li>
<li>We know that <strong>utility representation does not exist for some discontinuous preference</strong> (e.g. the lexicographic preference). But can this conclusion be generalized? </li>
</ul>

<p>Finally, I want to note that the requirement for $\succsim$ to violate continuity means we're ruling out finite (and countable?) domains.</p>
","<p>I think a basic problem is that any utility function defines a preference, and discontinuous utility functions can be used to define discontinuous preferences. Hence there are many discontinuous preferences that can be represented by utility functions.
An example:</p>

<p>Let $U(x,y)$ be a continuous utility function that maps from $\mathbb{R}^2$ to $(0,1)$. This latter may seem arbitrary, but the strictly monotononicaly increasing function $\frac{x}{x+1}$ maps from $\mathbb{R}_{++}$ to $(0,1)$, so it should be fine. Also define a closed set $H \subset \mathbb{R}^2$. Let
$$
\hat{U}(x,y)
=
\left\{
\begin{array}{ll}
U(x,y) &amp; \mbox{if} (x,y) \notin H \\
\\
U(x,y)+1 &amp; \mbox{if} (x,y) \in H.
\end{array}
\right.
$$
Obviously $\hat{U}(x,y)$ is not continuous and neither are the preferences defined by it. (The boundary of $H$ is prefered to anything outside $H$.) But the way these preferences were generated seems fairly general. So a large class of discontinuous preferences exists for which there is a utility representation.</p>

<p>Future question: How 'large' is this class, what measure can be used?</p>
","18234"
"If the Number of Workers in an Economy Doubled, Would Productivity Fall to Half its Former Value?","356","","<p>I am assuming that the production function for the economy has constant returns to scale, and all other inputs stay the same.</p>

<p>These are the steps I have made to try to answer this question:</p>

<p>1) Y/L = Productivity</p>

<p>2) Therefore, if Y=3 and L=2 (There were 2 workers in the economy), so Productivity = 3/2</p>

<p>3) L doubled, so now L=4</p>

<p>4) Now Productivity is equal to 3/4. </p>

<p>5) Productivity has therefore fallen by half of its former value.</p>

<p>Am I right in stating this? If not, can you please explain to me where I am going wrong?</p>
","<p>Since you say holding other variables as they were and double $L(t)$ I assume you have a production function that may include capital $(K(t))$, including this and assuming a Cobb-Douglas production function:</p>

<p>$$ Y(K(t), L(t)) = K(t)^{\alpha} L(t)^{1-\alpha} \; \; 0&lt; \alpha &lt; 1 $$ </p>

<p>Doubling $L(t)$ gives, (and omitting $t$ from the writing for clarity):</p>

<p>$$ Y(K, 2L) = K^{\alpha} (2 L)^{1-\alpha} $$</p>

<p>$$ = 2^{1-\alpha} Y(K,L) $$</p>

<p>$$ \Rightarrow \frac{Y(K, 2L)}{2L} = \frac{2^{1-\alpha} Y(K,L)}{2L} $$</p>

<p>$$ \frac{Y(K,L)}{2^{\alpha} L} &lt; Y/L $$</p>

<p>So yes in this sense as you described doubling labour decreased productivity.  </p>

<p>You mention $Y$ having constant returns to scale, this implies if you double <em>both</em> $K$ and $L$ then $Y$ will double as well, then productivity will stay the same</p>
","10943"
"How is the interest on fractional reserve money creation paid?","355","","<p>In fractional reserve banking commercial banks <a href=""https://en.wikipedia.org/wiki/Money_creation"">create money</a> when they make loans. When these loans are paid back the account is zeroed, the created money disappears, but the bank is still entitled interest. Where does the money to pay the interest come from? Does the central bank necessarily have to inflate the currency to pay it? Does money in circulation generally cover it?</p>
","<p>Repayment of interest does require an expansion of the money supply, but not in a way that is inflationary. </p>

<p>Consider first the way that commercial banks make loans. The whole purpose of loans is to borrow against future output— so if you imagine a firm that wants to purchase a machine that will allow it to produce more stuff— and thus have greater future income— the firm may go to a commercial bank and ask to take out a loan. The commercial bank will price that loan at a premium to the risk-free interest rate that reflects the risk of the loan, so that in expectation (taking into account that some loans will be repaid only in part or not at all), banks making riskier loans will be repaid at a slightly higher rate than ones making safer loans.</p>

<p>So firms will be offered an interest rate, and if that rate is less than their expected return on their investment, they'll make the investment. Notably, in this case, they're only borrowing money and investing <em>because their future output will be higher</em>. So when all of this works out (that is, when there isn't a credit bubble in which people are borrowing against future output that won't materialize), future output $Y$ (i.e., GDP) will be higher by an amount that is  the amount of additional money $M$ required to repay the interest on the loans.</p>

<p>$$ \% \Delta Y \geq \% \Delta M $$</p>

<p>Now if you recall the relationship between the money stock $M$, output $Y$,  the price level $P$, and money velocity $V$:</p>

<p>$$ PY=MV \rightarrow P=\frac{MV}{Y} $$</p>

<p>It's easy to see that if $V$ is constant, then:</p>

<p>$$ \% \Delta P = \frac{\% \Delta M}{\% \Delta Y}$$</p>

<p>Which, when combined with the observation that $ \% \Delta Y \geq \% \Delta M $, implies that an expansion of the money supply that is <em>merely</em> sufficient to allow for repayment of interest would actually be <em>deflationary</em>. This should make perfect sense: in expectation, output must increase by more than the amount captured by banks in the form of interest, otherwise firms in the real economy would never bother investing in fixed capital. So the money supply will in all likelihood increase by an amount strictly greater than the level required to repay interest, yet without any increase in inflation.</p>

<p>Loans to consumers are similar, so I won't give them a full treatment. Consumers are borrowing against their own future output, and foreclosures are generally priced in to the interest rate on a loan.</p>

<p>You'll note that I left out the case where in the aggregate, future output is less than that required to repay outstanding loans. This is intentional, as it's worth treating as a separate question.</p>
","8325"
"Take-it-or-leave-it PBE","355","","<p>I've found an interesting question looking at perfect-bayesian-equilibrium. I haven't seen a question where beliefs are not discrete.</p>

<p>There is a single potential buyer of an object which has zero value to
the seller. This buyer’s valuation v is uniformly distributed on [0, 1] and is
private information. The seller names a price $p_1$ which the buyer accepts or
rejects. </p>

<p>If he accepts, the object is traded at the agreed price and the buyer’s
payoff is $v − p_1$ and the seller’s is $p_1$. </p>

<p>If he rejects then the seller makes another
price offer, p2. If the buyer accepts this, his payoff is $\delta_(v − p_2)$ and the seller’s
is $\delta p_2$, where $\delta = 0.5$. </p>

<p>If he rejects, both players get zero (there are no further
￼￼￼offers).</p>

<p><strong>Find a Perfect Bayesian Equilibrium.</strong></p>

<p>My usual approach is to fix beliefs, but I don't quite know how to do this with continuous beliefs. Any advice?</p>
","<p>After posting a bad solution yesterday I believe I got a better one:</p>

<p>The strategy of the buyer consists of two functions, $(f_1(v,p_1),f_2(v,p_1,p_2))$ where both functions map to $\left\{A,R\right\}$ (where $A$ stands for Accept, $R$ for Reject).
The strategy of the seller is $(p_1,p_2(f_1(v,p_1)))$. You get the solution via backward induction. In PBE $f_2(v,p_1,p_2)$ maps to $A$ if and only if $v \geq p_2$. (There is inconsequential leeway at equality.) In PBE the seller believes that there is a set $H$ of types for which the buyer refused her offer $p_1$. Then
$$
p_2^* = \arg\max_{p_2} p_2 \cdot Prob(f_2(v,p_1,p_2) = A | f_1(v,p_1) = R).
$$
The buyer will accept offer $p_1$ if and only if
$$
v - p_1 \geq \delta \cdot (v - p_2). 
$$
From this you get
$$
v \cdot (1 - \delta) \geq p_1 - \delta \cdot p_2. 
$$
The left hand side of this equation is increasing in $v$, so types with high valuation will Accept. This means that in PBE the set $H$ is such that 
$$
H = [0, \bar{v}). 
$$
From this we get the optimal $p_2$ given $\bar{v}$:
$$
p_2^* = \arg\max_{p_2} p_2 \cdot Prob(v \geq p_2 | v \in [0, \bar{v})) = \frac{\bar{v}}{2}.
$$
In PBE $\bar{v}$ is a function of $p_1$: 
$$
\bar{v} \cdot (1 - \delta) = p_1 - \delta \cdot \frac{\bar{v}}{2}, 
$$
so
$$
\bar{v} = \frac{p_1}{1 - \frac{\delta}{2}}.
$$
We have determined all the PBE strategies but $p_1$. 
The expected payoff of the seller is
$$
p_1 \cdot \left( 1 - \frac{p_1 - \delta \cdot p_2(\bar{v}(p_1))}{1 - \delta} \right) + \frac{1}{2} \cdot p_2(\bar{v}(p_1)) \cdot \left( \frac{p_1 - \delta \cdot p_2(\bar{v}(p_1))}{1 - \delta} - p_2(\bar{v}(p_1)) \right),
$$
where
$$
p_2(\bar{v}(p_1)) = \frac{\bar{v}(p_1)}{2} = \frac{\frac{p_1}{1 - \frac{\delta}{2}}}{2} = \frac{p_1}{2 - \delta}.
$$
Substituting this we get
$$
p_1 \cdot \left( 1 - \frac{p_1 - \delta \cdot \frac{p_1}{2 - \delta}}{1 - \delta} \right) + \frac{1}{2} \cdot \frac{p_1}{2 - \delta} \cdot \left( \frac{p_1 - \delta \cdot \frac{p_1}{2 - \delta}}{1 - \delta} - \frac{p_1}{2 - \delta} \right),
$$</p>

<p>You have to maximize this w.r.t. $p_1$. With $\delta = 0.5$ I got
$$
p_1^* = \frac{9}{20}, \hskip 20pt \bar{v} = \frac{3}{5}, \hskip 20pt p_2^* = \frac{3}{10}.
$$</p>
","5460"
"How is money created on net?","351","","<p>I have the impression that everyone has more net money than in the past. By net money I means cash + money lent to others - money borrowed from others. If this is true, where does the extra net money come from? Is it right to say that originally all the extra net money comes to the world as interest paid by the central bank for the reserve deposit of commercial banks?</p>

<p>I read that commercial banks create money by making loans. But when one person borrows money from banks, his net money doesn't increase. And when people make transactions, money just goes from one to another. How does it come that finally everyone has more net money than before?</p>

<p>Edit:</p>

<p>I have a second thought that my impression is simply wrong. It's only true to say that generally everyone is wealthier than in the past. If we look at the richest businessmen in the world, their ""net money"" as defined above can often be hugely negative, but they are still wealthy since they possess a lot of other things like buildings, factories etc.</p>

<p>And besides those business men, the ""net money"" of the government is also hugely negative(almost every country's government has a large public debt). So if the ""net money"" of the popluation as a whole remains more or less constant(in the spirit of ""loans + cash == liability deposits"" mentioned by @Lumi), a few entities having hugely negative ""net money"" make others's net money increase, so one could have the impression that the ""net money"" of the majority of the population has increased.</p>
","<p>No, it's not correct to say that extra cash money comes into the world as interest paid on the reserve accounts of commercial banks.</p>

<p>In today's banking world, physical cash money is printed on demand. That is to say, the commercial banks estimate how much money they need to satisfy demand from ATM's and customer cash withdrawals and buy that amount from the central bank. In turn the central bank buys the cash from the treasury. The money they use to buy it with, is the electronic liability deposit account, that sits on the other side of the double entry book keeping used by banks. </p>

<p>It is of course possible for politicians to intervene in this process, and then this happens:</p>

<p><a href=""http://www.npr.org/2011/06/28/137394348/-1-billion-that-nobody-wants"" rel=""nofollow"">US Physical Coin surplus</a></p>

<p>As to the equation: net money = cash + money lent to others - money borrowed from others.</p>

<p>This is incorrect as written, since as usual in economic discussions on money, we have the confusion introduced by the banking system as to what exactly is money? Money lent or received from others can be physical cash, but it can also be money created as a liability deposit account as a result of a bank loan. Because a loan itself is just a contractual agreement to repay money over time, it's also not strictly correct to say that money lent to other must equal money borrowed from others, since there's no notion of time in that statement, or repayment over time.</p>

<p>If we take the larger definition of money, i.e. the total sum of cash and bank liability deposits, then this is more or less continuously growing as banks generally lend at a faster rate than loans are repaid. (Check your central bank's web site to see what's currently happening to your countries money supply, there are considerable variations in this.) </p>

<p>While it's true in a banking system where banks are only allowed to make customer loans that loans + cash == liability deposits, most banking systems today also allow banks to sell loans using securitzed lending, or covered loans. This actually allows banks to originate more loans than money, and as a result at the same time as we have a growth in the general money supply - due to banks generally lending at a faster rate than loan repayment occurs, there will be slightly faster increase in the total amount of bank originated debt.</p>

<p>So in some sense of net money that includes all the money supply, i.e. bank deposits and cash, it is debt that is growing faster than money, and not the other way around. </p>
","6266"
"How do reserves move between the 12 federal reserve banks?","350","","<p>In single central banks systems (e.g. Bank of England) then the final ledger for electronic money transfer is the adjustment of reserve account balances.</p>

<p>In the Federal Reserve System, there are 12 banks providing reserve accounts responsible for the banking in their region.  How do these 12 ledgers operate such that money can transfer from one region to another?  Is there an overall ledger?</p>

<p><strong>Edit to clarify in response to answer:</strong></p>

<p>An electronic transfer from bank A to bank B in Sterling results in an RTGS transfer between the banks' reserve accounts.  The Bank of England debits one reserve account and credits the other - so that the total reserve balance remains constant.</p>

<p>In the federal reserve system, what happens when money transfers from bank A in region 1 to bank B in region 2?  Does the federal reserve bank in region 1 simply reduce the reserve balance of bank A without an offsetting transaction on its balance sheet anywhere?  Is there an overall ledger that manages the ""total reserve"", or is it simply a technical constraint of RTGS that the same amount of money is destroyed at one bank as is created at the other?</p>
","<p>This is surprisingly subtle. </p>

<p>When, for instance, when bank A in the Richmond Federal Reserve district sends $1000 in reserves to bank B in the Minneapolis Federal Reserve district, reserves are taken out of bank A's account at the Richmond Fed and placed into bank B's account at the Minneapolis Fed. </p>

<p>Now, bank A's reserves are a liability on the books of the Richmond Fed, while bank B's reserves are a liability on the books of the Minneapolis Fed. Without any offsetting change, therefore, the process would result in the Richmond Fed discharging a liability and the Minneapolis Fed gaining a liability - and if this continued, regional Fed assets and liabilities could become highly mismatched. </p>

<p>The principle, then, is that there should be an offsetting swap of assets. It would be too complicated to swap actual assets every time there is a flow of reserves between banks in different districts. (There's over <a href=""https://www.frbservices.org/operations/fedwire/fedwire_funds_services_statistics.html"">$3 trillion in transactions every day on Fedwire, the Fed's RTGS system</a> - and if even a fraction of those are between different districts, the amounts are really enormous.) Instead, in the short run the regional Feds swap accounting entries in an ""Interdistrict Settlement Account"" (ISA). In the example above, the Minneapolis Fed's ISA position would increase by \$1000, while the Richmond Fed's ISA position would decrease by \$1000, to offset the transfer of liabilities.</p>

<p>So far, this is all very similar to the controversial TARGET2 system in the Euro area, in which large balances between national banks have recently been accumulating. The American system is different, however, because ISA entries are <em>eventually</em> settled via transfers of assets. Every April, the average ISA balance for each regional Fed over the past year is calculated, and this portion of the balance is settled via a transfer of assets in the System Open Market Account (the main pile of Fed assets, run by the New York Fed). Hence, if in April the Minneapolis Fed has an ISA balance of +\$500, but over the past year it had an average balance of +\$2000, its balance is decreased (by \$2000) to -\$1500, and it has an offsetting gain of \$2000 in SOMA assets. </p>

<p>As this example shows, since it is <em>average</em> balances over the past year that are settled, not the <em>current</em> balances, ISA balances do not necessarily go to zero every April. Historically, they were fairly tiny anyway, but since QE brought dramatic increases in reserves, these balances have <a href=""http://research.stlouisfed.org/fred2/series/D2WAISAL"">sometimes been large and irregular</a>. In the long run, though, the system prevents any persistent imbalances from accumulating.</p>

<p>(Note: the process in April is a little bit more complicated than I describe, since some minor transfers of gold certificate holdings are also involved. Basically, gold certificates are transferred between regional Feds to maintain a constant ratio of gold certificates to federal reserve notes; the transfers of SOMA assets are adjusted to account for this. <a href=""https://www.richmondfed.org/publications/research/economic_quarterly/2013/q2/pdf/wolman.pdf"">Wolman's recent piece for the Richmond Fed</a> is one of the few sources that describes the system in detail.)</p>
","1613"
"Is craigslist part of the Shadow Economy?","349","","<p>Is craigslist part of the Shadow Economy? Many if not most of the purchases that take place there are done without taxation.</p>
","<p>If we take the definition of shadow economy to be illicit economic activity existing alongside the traditional economy and further pin down illicit to mean any sort of economic activity that violates laws governing our conduct (civil, economic etc.) then the short answer is - yes. </p>

<p>Why? Many reasons. I think the easiest to verify and perhaps most obvious is that the majority of gigs, services, temporary labor positions, etc. on Craigslist are paid in cash. Here I make an assumption: most of the people doing these jobs for cash are not reporting these extra earnings. Thus, they are generating a supplemental income that goes untaxed. </p>

<p>I read a bit of (non-academic) research about how these sorts of sites often provide a lifeline to illegal immigrants precisely because they facilitate economic illicit activity (I will update this post with the link if I can dig it up).</p>

<p>Why else? Again I speculate (but reasonably). Craigslist, I think, is often used to move stolen property. Because transactions are largely anonymous and conducted on a cash basis and with little or no record of sale, CL is a safe place for petty criminals to liquidate stolen assets. This also clearly aligns with our given definition. </p>

<p>You could probably think of other reasons to support the claim that CL fuels (alternatively: is part of) the shadow economy in America. Then again, I think these two examples make it clear (if you are willing to accept the assumptions throughout the post). </p>
","8422"
"Does learning economics lead to richness?","348","","<p>I have started to learn economics from Adam Smith's ""Wealth of nations"" because I think that learning economics (or narrow fields of it) will allow me to become rich.</p>

<p>Does knowing economics allow me to make money?</p>
","<p>First things first, we must dispel the misconception that you will find in economics some magic formula to ""beating the stock market"" or some other way to make easy money. I explain why why <a href=""https://economics.stackexchange.com/a/9192/108"">here</a>.</p>

<p>Learning economics <em>can</em> help you to become more wealthy in several prosaic ways:</p>

<ul>
<li><p>In the same way that learning to be a doctor or lawyer can make you rich. If you have useful skills then people will pay you to use your skills to help them. Professional economists are employed in the government, academia, and the private sector and are generally well-paid.</p></li>
<li><p>Learning economics will also teach you to be a more logical and systematic thinker, which is likely to make you better at all kinds of intellectual tasks—including those not directly connected to economics. Again, this is likely to improve your future earnings potential.</p></li>
<li><p>Many ordinary people do truly stupid things with their money. Economics will <em>not</em> generally teach you about these things (better to read about personal finance, as Arthur Tarasov suggested), but it will teach you to be more savvy in matters of money and help you to avoid the pitfalls.</p></li>
</ul>

<p>Note that none of these three things are specific to economics. You would do just as well to learn medicine and read a beginner's guide to investing. Some advice in my capacity as an 'old guy' rather than an economist: if you want to become rich then find a career that pays good money and <em>that you will enjoy</em> and work hard at it.</p>

<hr>

<p>Final remark: If you really want to learn economics then reading Adam Smith is probably a pretty bad way to start. That is like trying to learn English by reading Shakespeare. Much better to start with a modern introduction to the subject (I am fond of ""Intermediate Microeconomics: A Modern Approach"" by Hal Varian).</p>
","9592"
"Does there always exist a consumption bundle at which the indirect utility function is the inverse of the expenditure function?","348","","<p>Two questions:</p>

<ol>
<li>Given $v(\vec{p},m)$ and $e(\vec{p},\bar{U})$, is there only a single point at which these are inverses of each other?  </li>
<li>Does an inverse always exist for a given price vector $\vec{p}$, income $m$ and $\bar{U}$, $v$ and $e$? </li>
</ol>

<p>These are points my mates and I are arguing about as we prepare for our midterm. </p>

<p>Also, I prefer rigorous answers so if you can, feel free to be as thorough as you want.  </p>
","<p>Regarding question 1:</p>

<p>From the assumption that the consumer has a single income value $m$, there can only be one value for $m$. So by the notion that $e$ and $v$ are inverses, there can only be one value $e$ for which $m$ corresponds to and thus only one $u$. So there is only one point. </p>

<p>Regarding Question 2: </p>

<p>If we have (1) a utility function that is continuous and locally non-satiated and (2) if $m &gt; 0$ and (3) if both UMP and EMP exist, then they are equivalent. And $e$ and $v$ are inverses. </p>

<p>Claim 1: Solving UMP solves EMP. </p>

<p>Proof:  </p>

<p>Suppose bundle $c^*$ solves the UMP but not EMP. Let $c'$ solve EMP. Then (1) amount spent on $c^*$ greater then that on $c'$ and so $u(c') \geq u(c^*) $ because obviously spending more means worse off or same utility. But (2) by local nonsatiation a consumption there exists a bundle $c''$ close enough to $c'$ such that amount spent on $c''$ is less than amount spent on $c^*$ and $u(c'') &gt; u(c^*)$. (3) Contradiction because we assumed $c^*$ solves UMP. </p>

<p>Claim 2: Solving EMP solves UMP. </p>

<p>Proof: </p>

<p>Suppose bundle $c^*$ solves EMP but not UMP. Let $c'$ solve UMP. Then (1) $u(c') &gt; u(c^*)$ even though we spend the same amount on each. That is, $c^*$ doesn't solve UMP since less utility for same $m$.   Because amount spent positive, we can find $t$ where $0&lt;t&lt;1$ such that amount spent on $tc'$ is lower than that spent on $c^*$ yet $u(tc') &gt; u(c^*)$ because $c^*$ does not solve the UMP. (3) Contradiction because we said $c^*$ solved EMP.</p>

<p>Summary: </p>

<ol>
<li>If solutions exist either to UMP or EMP, then solutions exist for the other and they are inverse functions. </li>
<li>If an inverse exists, it must be a point. </li>
</ol>
","5383"
"Verifying the constant elasticity of the demand model Q= aP^b","348","","<p>""It is well known"" that the elasticity of $Q$ relative to $P$ is the constant $b$ in the equation $Q(P)=aP^b$. We can verify it using the convenient definition of elasticity $= \frac{dQ}{dP} \frac{P}{Q}$, we can verify it in Wikipedia.</p>

<p>Based on this, when I create a spreadsheet with parameters $b=-2$, $a=100$ and P ranging from 1-5 by 1 I expected to recover an elasticity of -2, where elasticity =  % change in Q/ % change in P.  This is not the case. Instead the elasticity  varies substantially as the % change in P varies.</p>

<p>I'm forced to conclude that 'constant elasticity' does not mean a fixed value regardless of the magnitude of the price change, but only invariant with regards to the value of price OR that I have a spreadsheet error.</p>

<p>I've pasted an image of the spreadsheet results below.  Obviously, without seeing the formulas, no one can verify that I don't have an error, but I'm hopeful that someone will give this a spin for themselves and get very different numbers and then I'll know my failure to verify the constant elasticity in this function is a spreadsheet error.</p>

<p><a href=""https://i.stack.imgur.com/lE83p.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lE83p.png"" alt=""spreadsheet image""></a></p>
","<p>The problem with your calculations is that you have very big changes in price   </p>

<p>If you made price increases of $1\%$ in price, you would find the quantity fell by about $2\%$ as shown in the table below leading to an elasticity of about $-2$  </p>

<p>If you made the price changes even smaller, the calculated elasticity would get even closer to $2$, and in a sense you are looking for the limit of elasticity as the price change approaches $0$, which will indeed be the constant $b=-2$</p>

<pre><code> a       b      P       Q=a*P^b pct change Q    pct change P   elasticity

100     -2      1       100.00          
100     -2      1.01     98.03      -1.97%          1%          -1.97
100     -2      2        25.00          
100     -2      2.02     24.51      -1.97%          1%          -1.97
100     -2      3        11.11          
100     -2      3.03     10.89      -1.97%          1%          -1.97
100     -2      4         6.25          
100     -2      4.04      6.13      -1.97%          1%          -1.97
100     -2      5         4.00          
100     -2      5.05      3.92      -1.97%          1%          -1.97
</code></pre>
","13658"
"Calculating monetary base from given data","347","","<p>I need to some data for Pakistan's monetary base. Searching through the website of State Bank of Pakistan (SBP), I found the following pdf on <a href=""http://www.sbp.org.pk/departments/stats/PakEconomy_HandBook/Chap-4.1.pdf"" rel=""nofollow noreferrer"">Monetary Statistics</a>.</p>

<p>I wanted to ask that can I calculate monetary base from the given values.</p>

<p>Following is a list of values given in pdf in case pdf is not opening for you.</p>

<ol>
<li>Currency in Circulation</li>
<li>Other Deposits with SBP</li>
<li>Currency in Tills of Scheduled Banks</li>
<li>Banks' Deposits with SBP</li>
</ol>

<p>Regards</p>
","<p>Looking into monetary base definition:</p>

<blockquote>
  <p>Monetary base is the total amount of a currency that is either circulated in the hands of the public or in the commercial bank deposits held in the central bank's reserves.</p>
</blockquote>

<p>So this means that M0 is actually the monetary base. So I really don't have to calculate anything.</p>
","14762"
"Relationship between interest rate and rental price of capital","346","","<p>In Daron Acemoglu's Introduction to Modern Economic Growth (2009), P.32, it is stated that given assumption of exponential depreciation at the rate $\delta$ and normalization of price of final good to be 1, $r(t) = R(t) - \delta$ where $r(t)$ is interest rate, $R(t)$ is rental price of capital and $\delta$ is depreciation rate. The reason, which I agree, is that:</p>

<blockquote>
  <p>A unit of final good can be consumed now or used as capital and rented to firms. In the latter case, a household receives $R(t)$ units of good in the next period as rental price for its savings, but loses $\delta$ units of its capital holdings, since $\delta$ fraction of capital depreciates over time. Thus the household has given up one unit of commodity dated t-1 and receives $1 + r(t) = R(t) + 1-\delta$ units of commodity dated t.</p>
</blockquote>

<p>But, on P.330, when talking about overlapping generations model where $\delta = 0$, it is stated in equation (9.3): $1 + r(t) = R(t)$. Shouldn't it be $r(t) = R(t)$? I cannot find this is a typo like from <a href=""http://www.econ.ku.dk/okocg/VV/VV-2015/Lectures%20and%20lecture%20notes/Errata-to-Acemoglu-book-VV-2015.pdf"" rel=""nofollow noreferrer"">http://www.econ.ku.dk/okocg/VV/VV-2015/Lectures%20and%20lecture%20notes/Errata-to-Acemoglu-book-VV-2015.pdf</a>. Do I miss something? </p>
","<p>The equation is exactly the same,</p>

<p>$$r(t) = R(t) - \delta$$</p>

<p>Now, set $\delta =1$ per assumptions, to obtain</p>

<p>$$r(t) = R(t) - 1 \implies 1+r(t) = R(t)$$</p>

<p>which reasonably continues to say that the accepted rental rate of capital $R(t)$, covers the depreciation rate plus $r(t)$ which is also the <em>net</em> return to capital.</p>
","16207"
"Who owns German debt?","345","","<p>I know that Germany has huge external debt. I don't know how to find out which entities own this and especially which country they belong to.</p>
","<p>This is at the same time 1) a little old and 2) provides a deeper and more general answer that what you might be looking for, but I would still encourage you to go through it. </p>

<p><a href=""http://www.its.caltech.edu/~melliott/papers/financial_networks.pdf"" rel=""nofollow"">http://www.its.caltech.edu/~melliott/papers/financial_networks.pdf</a></p>

<p>with a preview in</p>

<p><a href=""https://www.youtube.com/watch?v=mjS81EoBQOU"" rel=""nofollow"">https://www.youtube.com/watch?v=mjS81EoBQOU</a></p>

<p>(starting around 1'07)</p>

<p>and a complete didactic overview at</p>

<p><a href=""https://class.coursera.org/networksonline-003/lecture/211"" rel=""nofollow"">https://class.coursera.org/networksonline-003/lecture/211</a></p>

<p>and</p>

<p><a href=""https://class.coursera.org/networksonline-003/lecture/215"" rel=""nofollow"">https://class.coursera.org/networksonline-003/lecture/215</a></p>

<p>Among other things, you will learn that -- for most purposes -- it does not matter that much how much or in which country Germany (or any other country for that sake) has debts, but that the whole network or obligations is really what matters.</p>
","8222"
"Quasi-linear utility functions","344","","<p>I have the following quasi-linear utility function given: $u_0 = f(x_1) + x_2$ (with $f'&gt;0$,$f''&lt;0$). </p>

<p>I know that the indifference curves are vertically parallel, which means that the slope is independent of the consumption of $x_2$. I suppose that there is no income effect, but how can i show this?</p>

<p>Cheers</p>
","<p>You can show this concerning the optimization problem with the objective function $U_0 = f(x_1) + x_2$ and the budget restriction $M - p_1 x_1 - p_2 x_2 = 0$. Using the Lagrangian, this leads you to
$$
f'(x_1) = \frac{p_1}{p_2} \quad \text{or} \quad f'^{-1}(\frac{p_1}{p_2}) = x_1^{*} = D_1(p)
$$
You can see that in this special case the optimum quantity of $x_1^{*}$ (Marshallian demand function) does not depend on the income $M$
$$
\frac{\partial D_1}{\partial M} = 0,
$$
The income effect is therefore zero, and you will not consume a different amount of $x_1^{*}$ if the income $M$ varies.</p>

<p><strong>Some further considerations:</strong> Based on the Marshallian $D_i(p, M) = x_i^{*}$ and Hicksian $H_i(p, u) = x_i^{*}$ demand function, you can show some interesting properties of this particular utility function using the Slutsky equation:
$$
\frac{\partial D_i}{\partial p_i} = \frac{\partial H_i}{\partial p_i} - x_i^{*} \frac{\partial D_i}{\partial M}
$$
This shows that the derivative of the Marshallian demand function with respect to price equals the derivative of the Hicksian demand function with respect to price minus the optimal $x_i^{*}$ times the derivative of the Marshallian demand function with respect to income. In this special case, the Marshallian demand function equals the Hicksian demand function, as $\frac{\partial D_i}{\partial M} = 0$.</p>
","14080"
"What are the economic perspectives regarding the game of salary negotiations?","344","","<p>Apologies if I use non-economic language to explain what I suspect is a practical application of economics. I have no formal education in economics whatsoever but hoping you guys/girls might be able to help. :)</p>

<p>I'm the managing director of a company in which we run appraisals every 6 months. Each time we negotiate salary I have in my mind's eye this picture...</p>

<p><a href=""https://i.stack.imgur.com/MVUe8.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/MVUe8.png"" alt=""enter image description here""></a></p>

<p>Assuming the 'correct' salary for an employee is 70k, there's an incentive to offer slightly more. <em>'Slightly more'</em> because there's some error in estimating the market rate and the costs of getting this wrong are high. I've added a staff churn costs of £20k/yr for getting this wrong based on loss of knowledge, morale, recruitment costs and what I refer to as a 'change incentive' for the replacement employee. The change incentive is the amount you must offer a new employee beyond their current rate (market rate?) to discount the loss of familiarity and to take on the risk of joining a new employee.</p>

<p><strong>Belief 1 - Underpaying employees is much more costly over the long term</strong> once staff churn is taken into account.</p>

<p><strong>Belief 2 - the employee has better information about their value</strong> - based on them being nearer the information about their skills, positive contributions and self interest in the literal sense.</p>

<p><strong>Belief 3 - salary expectation in job adverts are positively skewed</strong> to discount against the risk and transaction costs to the employee of change. Nobody switches to an identical salary unless it's a sideways move. Anecdotally, I've heard advice to change jobs every few years in order to raise your salary faster. Humans tend to be unnecessarily risk adverse and you can give yourself a competitive edge by overcoming this bias.</p>

<p><strong>Belief 4 - primary information source for market value are job adverts and job offers.</strong> These overvalue for the reasons in belief 3.</p>

<p><strong>Belief 5 - Protracted and/or aggressive salary negotiation is costly in itself.</strong> If there's a big discrepancy it can create feelings of being undervalued.</p>

<p><strong>Belief 6 - Employees will be content and thus likely to remain with the company if they feel they are receiving the market rate.</strong></p>

<p>Assumptions: the company is otherwise a pleasant place to work.</p>

<p>In my particular industry, I'd consider low staff churn rates and high staff morale as being a distinct and powerful competitive advantage. The figure of 20k churn cost is probably conservative.</p>

<p>In England, where I live, the cultural norm is for the company to either start the negotiation or more commonly simply state what the pay rise is going to be. This is followed by a period of watching how much they squeak squirm with dissatisfaction. Given the beliefs above and an industry where staff churn is costly, I'm inclined to lean in the other direction and either let them begin the negotiation or even more radically, simply request what their salary should be; as is common for sellers of other types of good. Salary negotiation seems to me to be unique in that the buyer of the good (their labour) dictates the price and then watches to see if the supply vanishes (resigns).</p>

<p>Is it an optimal strategy in salary negotiations to let the employee decide? </p>
","<p>I will provide a simple game-theoretic modelling of the situation.
A new year starts and a company wants to make a wage-increase offer to an existing employee. Let $e$ be the employee's current efficiency and the corresponding wage $h(e)$ (which, represents an increase over previous wage). Let $v$ be the premium observed in the market for new hires (so if the employee goes to another employer he will earn $h(e) + v$). Let $c$ be <em>churn</em> costs (recruitment plus loss of efficiency etc) to the current employer, if the employee leaves and needs to be replaced. </p>

<p>This is a sequential game so we have to use the extensive form. </p>

<p><strong>A) Firm offers a wage</strong>  </p>

<p>First, the case where the firm ($F$) offers a wage and the employee ($E$) decides what to do:</p>

<p><a href=""https://i.stack.imgur.com/59wLU.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/59wLU.jpg"" alt=""enter image description here""></a></p>

<p>The first outcome refers to the firm's cost, the second to the employee's wage. We have assumed that if the employee is offered the new hire premium it stays with the firm.
Let $p_l$ be the probability that the employee will leave if he is offered $h(e)$ only. The firm faces the following expected costs:</p>

<p>$$EC [h(e)] \equiv EC_{A1}= (1-p_l)h(e) + p_l[h(e)+v+c] = h(e)+p_l[v+c]$$</p>

<p>$$EC [h(e)+v] \equiv EC_{A2} = h(e)+v$$</p>

<p>Then in order for the firm to nevertheless offer $h(e)$ it must be the case that</p>

<p>$$EC_{A1} &lt; EC_{A2} \implies h(e)+p_l[v+c] &lt; h(e)+v$$</p>

<p>$$\implies p_l &lt; \frac {v}{v+c}$$</p>

<p>and it should offer $h(e) + v$ if the inequality points to the other direction. </p>

<p>Let's move now to the OP idea, to tell the employee to ask for a wage. Here we have</p>

<p><strong>B) Employee asks for a wage</strong>  </p>

<p><a href=""https://i.stack.imgur.com/GpbWt.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GpbWt.jpg"" alt=""enter image description here""></a></p>

<p>Here too the first outcome is the firm's cost. We have allowed for the possibility that the employee asks only the efficiency wage. This is crucial.</p>

<p>Since we are in the ""decision about the process structure"" phase, we assign some probability $p_e$ that the employee may actually ask for just the efficiency wage. This is important.<br>
It is also important to note that, assuming that the employee has asked for $h(e) + v$, while the criterion for whether the firm should accept or counter-offer only $h(e)$ has exactly the same expression as before, <em>we are looking at a different probability</em>. Here the firm must decide whether the employee is ""bluffing"" (he does not have an offer from another firm), or not. This is a different probability than the previous one. Here, the firm has additional information (for better or for worse), and so it has to make a difference assessment. Call the probability of <em>not</em> bluffing $p_c$.  </p>

<p>We have that </p>

<p>$$p_l &lt; p_c$$ </p>

<p>because the former is a conditional probability of the same event (""the employee leaves""), while the latter is the unconditional probability. Keep this inequality for later.  </p>

<p>Assume that the firm has estimated somehow (""if the employee asks for $h(e)+v$ there is $p_c$ probability that he will leave if I counter offer $h(e)$ only).
If this is estimated, then the firm already knows what it will do if the employee asks for the new hire premium -and it will depend on the specific values of the various quantities here.  </p>

<p>So <em>given</em> an estimate for $p_c$ we are looking at two possible expected costs for the firm<br>
<strong>B.1.</strong> The firm will counteroffer $h(e)$
here the expected cost is</p>

<p>$$EC_{B1} = p_eh(e) + (1-p_e)\cdot [(1-p_c)h(e) + p_c(h(e)+v+c)]$$</p>

<p>$$=  h(e) + (1-p_e)p_c(v+c)$$</p>

<p><strong>B.2.</strong> The firm will accept $h(e)+v$</p>

<p>$$EC_{B2} = p_eh(e) + (1-p_e)(h(e) +v) = h(e) + (1-p_e)v$$</p>

<p><strong>WHAT STRUCTURE TO CHOOSE?</strong></p>

<p>Now we want somehow to compare the two structures and select the one that is more profitable for the firm. This requires to examine various cases characterized by the relation between the various probabilities.</p>

<p><strong>CASE 1 :</strong> $p_e = 0 , p_l &lt; p_c &lt; v/(v+c)$</p>

<p>Here the firm will offer $h(e)$ in structure $A$ (so expected cost $EC_{A1}$), and will counter-offer $h(e)$ in structure $B$ (so expected cost $EC_{B1}$). 
Given the assumed values of the probabilities we have that </p>

<p>$$EC_{A1} = h(e)+p_l[+v+c] &lt; h(e) + p_c(v+c) = EC_{B1}$$</p>

<p>an so we should stick with the traditional structure $A$ where the firm offers first a wage.</p>

<p><strong>CASE 2 :</strong> $p_e = 0 , p_l  &lt; v/(v+c) &lt; p_c$</p>

<p>Here the firm will offer $h(e)$ in structure $A$ (so expected cost $EC_{A1}$), but will accept $h(e)+v$ in structure $B$ (so expected cost $EC_{B2}$). 
Given the assumed values of the probabilities we have that</p>

<p>$$EC_{A1} = h(e)+p_l[v+c] &lt;  h(e) + v =EC_{B2}$$</p>

<p>and again we should stick with structure $A$.</p>

<p><strong>CASE 3 :</strong> $p_e = 0 ,  v/(v+c) &lt; p_l  &lt; p_c$
Here we compare $EC_{A2}$ with  $EC_{B2}$
$$EC_{A2} = h(e)+v  = EC_{B2}$$</p>

<p>No winner here, but overall we see that 
<strong>the incentive to adopt structure $B$ hinges on whether the employee may after all ask only for $h(e)$.</strong> ($p_e&gt;0$ is necessary but not sufficient condition to adopt structure $B$).</p>

<p><strong>CASE 4 :</strong> $p_e &gt; 0 , p_l &lt; p_c &lt; v/(v+c)$</p>

<p>Here too we compare $EC_{A1}$,with $EC_{B1}$ but with $p_e&gt;0$ so</p>

<p>$$EC_{A1} = h(e)+p_l[v+c] &lt; &gt;h(e) + (1-p_e)p_c(v+c) = EC_{B1}$$</p>

<p>We stick with structure $A$ if $p_e &lt; (p_c -p_l)/p_c$, and we adopt structure $B$ if the inequality runs the other way.</p>

<p><strong>CASE 5 :</strong> $p_e &gt; 0 , p_l  &lt; v/(v+c) &lt; p_c$</p>

<p>Here we compare  $EC_{A1}$, with $EC_{B2}$ but with $p_e &gt; 0$ </p>

<p>$$EC_{A1} = h(e)+p_l[v+c] &lt;  h(e) + (1-p_e)v = EC_{B2}$$</p>

<p>as one can verify. So here we stick with structure $A$.</p>

<p>Finally</p>

<p><strong>CASE 6 :</strong> $p_e &gt; 0 ,  v/(v+c) &lt; p_l  &lt; p_c$</p>

<p>Here we compare $EC_{A2}$ with  $EC_{B2}$
$$EC_{A2} = h(e)+v &gt; h(e) + (1-p_e)v = EC_{B2}$$</p>

<p>and we should go with structure $B$.</p>

<p><strong>VERBAL SUMMARY</strong>  </p>

<p>1) If we expect that employees will always ask for the new hire premium if they get to ask first, then we should stick with the structure where the firm offers first a wage.  (Cases (1,2,3)</p>

<p>2) If there exists a positive probability that the employees may just ask for $h(e)$ then :<br>
2a) If the firm will stand by $h(e)$ in any case and structure, we should keep the structure where the firm offers first a wage if $p_e &lt; (p_c -p_l)/p_c$ (Case 4)<br>
2b) If the firm will go for $h(e) + v$ in any case and structure, we should choose the structure where employees ask first (Case 6).<br>
2c) If the firm will play differently in the two situations, we should keep the structure where the firm offers first a wage. (Case 5). </p>

<p>As is usually the case reality is more complex than that: negotiations may have more rounds, and the firm and the employee may not even agree on $h(e)$ although such disagreement is less common than ""accepted wisdom"" would have it.  </p>

<p>But the general feeling I get from all the above analysis is that the main reason I would consider implementing a structure where employees ""ask first"" is if I thought that there exists a high enough probability that they won't ask for the new hire premium -and still, if at the same time I think that they won't try to bluff (i.e. I expect $p_c$ to be close to unity), again it would be likely preferable to stick with the traditional model.</p>
","14473"
"Doesnt convexity prevent thick indifference curves aswell?","343","","<p>It is standard in many micro textbooks when analyzing the relationship between preference axioms and the shape of the utility function (and consequently the shape of indifference curves), to attributed the ""non-thickness"" of indifference curves to ""local non-satistion"".
While it is easly seen (and proven) that LNS preferences dont admit thick IC, my question is the following:</p>

<p>Thick IC violate aswell strict convexity (notice that weak convexity appears to ""survive""), so, isnt convexity alone another property that prevents thickness? Put it differently, can we find non monotonic, convex preferences that dont admit thick IC? </p>

<p>If any proof or reference to relevant literature would be very usefull.</p>
","<p>My approach would be to define thick indifference curves in terms of a stronger form of local non-satiation:</p>

<blockquote>
  <p><strong>Definition (thick indifference curves)</strong> Preferences are said to have thick indifference curves if there exists at least one bundle $A\in\mathbb{R}^l$ and an open ball
  $\mathscr{B}(A)$ around $A$ such that $A'\sim A$ for <em>every</em>
  $A'\in\mathscr{B}(A)$.</p>
</blockquote>

<p>Let's set up a definition for strict convexity to be sure we are on the same page:</p>

<blockquote>
  <p><strong>Definition (strict convexity)</strong> Preferences obey strict convexity if</p>
  
  <p>$$A\sim B\implies \lambda A+(1-\lambda) B\succ A\sim B$$</p>
  
  <p>for $A,B\in\mathbb{R}^l$ and any $\lambda\in(0,1)$.</p>
</blockquote>

<p>Now we can state the desired result:</p>

<blockquote>
  <p><strong>Proposition</strong> If $\succsim$ is strictly convex then $\succsim$ does not have thick indifference curves.</p>
</blockquote>

<p><strong>Proof</strong> Suppose that $\succsim$ has thick indifference curves. Then there exists an $A$ such that $A'\sim A$ for all $A'\in\mathscr{B}(A)$. Thus, fix two bundles $A$ and $B$ such that $A\sim B$ and $B\in\mathscr{B}(A)$. We know that 
$$\lambda A+(1-\lambda) B \in \mathscr{B}(A).$$
Thus, if the indifference curve is thick around point$A$ we must have $\lambda A+(1-\lambda) B\sim A\sim B$. But this contradicts the strict concavity hypothesis. QED</p>

<hr>

<p>That should do the job for strict convexity. As frage_man already pointed out, the proposition fails to hold generally under weak convexity. Indifference everywhere is a very elegant example why.</p>
","13134"
"Is a 'Brexit' really that bad?","340","","<p>There seems to be a lot of fear that a Brexit will have a very bad impact on both the European and the British economy. Why would this be, does a Brexit imply that there will be less trade between EU-countries and Great-Brittain, why is this? </p>
","<h1>tl;dr: Uncertainty &amp; trade tariffs</h1>

<hr>

<h1>detail</h1>

<p>The economics have been assessed by a large number of economic specialists, including the very well-respected and independent <a href=""http://www.ifs.org.uk/uploads/publications/comms/r116.pdf"" rel=""nofollow noreferrer"">Institute for Fiscal Studies</a>.</p>

<p>What would Brexit (meaning the UK leaving the EU) mean? </p>

<h3>uncertainty</h3>

<p>Well, firstly it means years of uncertainty, while replacement trading arrangements are negotiated - typically that takes somewhere in the region of 10 years. The Doha Round of trade talks has been going on <a href=""https://www.wto.org/english/tratop_e/dda_e/dda_e.htm"" rel=""nofollow noreferrer"">since 2001</a>.</p>

<p>Uncertainty requires higher rewards to balance the risks, and that means lower inward investment, and fewer long-term deals.</p>

<h3>trade tariffs</h3>

<p>Free access to the European market depends on accepting some specific rules that the Brexit campaign consider to be unacceptable, such as the free movement of labour. And it requires membership either of the EU, or of the European Free Trade Area (EFTA). On leaving the EU, UK membership of the EFTA would require EU approval, and the German Finance Minister Schäuble has made it clear that he considers that that would not happen. So one thing that the Brexit campaign and the EU heavyweights should agree on is that the UK would <em>not</em> be a member of the European Economic Area, and that means trade tariffs. A Brexit would be an existential threat to the EU project, so it will be in the interest of its remaining members to make exit as painful as possible, to preserve the unity of the remaining 27. And EU27 trade with the UK is a very small proportion of EU27 total trade, so it's a cheap price to pay.</p>

<hr>

<h1>summary of all effects</h1>

<p>The IFS summarises the effects, and the vast majority of specialists predict negative effects at least out to 2030. Here's their summary, from p18 of the report linked above:
<a href=""https://i.stack.imgur.com/v1yEw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/v1yEw.png"" alt=""enter image description here""></a></p>

<p>It's worth noting that it's not only UK's trade with the EU that would be harmed. The UK has trade deals with much of the world <strong>because</strong> it is a member of the EU. Without that membership, it would need to negotiate its own bilateral trade deals: such negotiations will also typically take a decade. So the UK's trade with non-EU countries would be reduced too. And there's the reduced economic efficiency of having a much smaller pool of talent to draw on for the workforce. So the numbers in the table above may (depending on the scope of individual studies) include those effects, as well as the EU-trade effect.</p>
","12358"
"Papers that use R vs Stata","340","","<p>Is there any way to tell if a paper used R instead of Stata or Matlab for the estimation? I know it doesn't matter for the quality of the paper, but I'd just be interested to see how many papers use one software over the other. </p>

<p>I'm thinking an easy way might be by looking at the figures- ggplot means R, for example. </p>

<p>Again, not really an economics question, but it's about economics papers. </p>
","<p>The main economic journals are slowly starting to require authors to make their data <strong>and</strong> the code of their analysis available as part of the online appendix. When this is the case, it is easy to figure out which software was used.</p>

<p>One example are recent publications in the American Economic Review. For instance,</p>

<ul>
<li>Calsamiglia, Caterina, Guillaume Haeringer, and Flip Klijn. 2010. ""Constrained School Choice: An Experimental Study."" American Economic Review, 100(4): 1860-74. <a href=""https://www.aeaweb.org/articles.php?doi=10.1257/aer.100.4.1860"" rel=""nofollow noreferrer"">https://www.aeaweb.org/articles.php?doi=10.1257/aer.100.4.1860</a></li>
</ul>

<p>the online appendix of which contains the complete STATA code of the statistical analysis.</p>

<p>If the code is not available at the journal's webpage, other alternatives involve :</p>

<ul>
<li>Checking the website of the authors. </li>
<li>Contacting the authors themselves to ask if they could send you their code.</li>
</ul>

<p>None of these methods are great if you're trying to gather a sizable or representative dataset of software used in econ papers, but for anecdotal data, they should do the trick.</p>
","5430"
"The Case for Basic Income in developed and underdeveloped countries","338","","<p>From what I can tell, the idea of the <a href=""http://en.wikipedia.org/wiki/Basic_income"">basic income guarantee</a> is very popular in some circles as an excellent alternative to a lot of modern welfare systems.</p>

<p>Has anybody developed a theoretic or empirical model in which minimum income is tested? In this model, what are the necessary and sufficient conditions for such a model to be preferred to a more traditional alternative?</p>

<p>If anyone has suggested readings on the topic, that would be appreciated as well.</p>
","<p>Thanks to densp for identifying <a href=""http://www.bignam.org/Publications/BIG_Assessment_report_08b.pdf"" rel=""noreferrer"">this paper</a>.</p>

<p>It refers to a major pilot project undertaken in Namibia</p>

<p><strong>Background:</strong></p>

<p>The Basic Income Grant (BIG) pilot project took place in the Otjivero-Omitara area, about 100 kilometres east of Windhoek. All residents below the age of 60 years receive a Basic Income Grant of N$100 per person per month, without any conditions being attached. The grant is being given to every person registered as living there in July 2007, whatever their social and economic status.</p>

<p>Before the pilot project, the area was characterised by unemployment, hunger and poverty. </p>

<p><strong>Conclusions:</strong></p>

<ul>
<li><p>Since the introduction of the Basic Income Guarantee (BIG), household poverty has dropped significantly. Using the food poverty line, 76% of residents fell below this line in November 2007. This was reduced to 37% within one year of the BIG. </p></li>
<li><p>There was a dramatic increase in economic activity. The rate of those engaged in income generating activities (above the age of 15) increased from 44% to 55%. Thus the BIG enabled recipients to increase their work both for pay, profit or family gain as well as self-employment. The grant enabled recipients to increase their productive income earned, particularly through starting their own small business, including brick-making, baking of bread and dress-making. The BIG contributed to the creation of a local market by increasing households' buying power. This finding contradicts critics' claims that the BIG would lead to laziness and dependency.</p></li>
<li><p>Huge reduction in child malnutrition from 42% to 17% in 6 months.</p></li>
<li><p>Increase in school attendances (non attendance due to financial reasons dropped 42%)</p></li>
<li><p>Drop in crime (theft down 42%)</p></li>
<li><p>Estimated cost for a nationwide program in Namibia would be 2-3% of GDP. Not cheap, not unaffordable either.</p></li>
</ul>

<p>All thing considered, the author of this report seemed pretty happy with the outcome. There were some issues impacting the data. Since it was a localised study, there was a fair bit of migration towards the treatment area. The long term impacts are not yet known as well.</p>

<p><strong>Additional resources:</strong></p>

<p>Haarmann, Claudia; Haarmann, Dirk; Jauch, Herbert; Mote Hilma et al 2008. Towards a Basic Income Grant for all. Basic Income Grant Pilot Project. First Assessment Report, September 2008. Windhoek</p>

<p>Kameeta, Zephania; Haarmann, Claudia; Haarmann, Dirk; Jauch, Herbert 2007. Promoting employment and decent work for all - Towards a good practice model in Namibia. - Research Paper - Presentation to the United Nations Commission for Social Development. Windhoek </p>

<p>Haarmann, Claudia; Haarmann, Dirk (ed.) 2005. The Basic Income Grant in Namibia. Resource Book. Windhoek</p>
","6729"
"Could a Cap-and-Trade and a Carbon Tax both work together as a system to reduce carbon emissions?","337","","<p>For example, the European Union currently has a Carbon Emissions Trading Scheme in progress the ETS which acts to cap the amount of carbon dioxide released by large corporations. However, let us imagine, for example that the UK implements a carbon tax, which taxes fossil fuels as they enter the UK (at well, mine or port of entry) based on the amout of CO2 they will emit (at an escalating cost per ton of CO2). </p>

<p>Could these two systems feasibly act and coexist together, or would it simply be double taxing? </p>
","<p>The combination of the two policies could work and would have some advantages over either alone, and for a given reduction in emissions the overall cost burden on industry and consumers would <em>not</em> be doubled.  However, the cap on emissions would weaken the effect of gradual escalation of the tax rate.</p>

<p>The model represented in the following diagram is a simplification in several respects (which will be considered below) but is a helpful starting-point.  It assumes a single homogeneous fossil fuel, with emissions depending solely on the quantity of fossil fuel consumed.  Hence the horizontal axis represents quantity of fossil fuel <em>and</em> quantity of emissions.</p>

<p><img src=""https://i.stack.imgur.com/0GFKD.png"" alt=""Emissions Reduction Model""></p>

<p>Supply is shown as highly elastic (nearly horizontal) because the UK buys large amounts of its fossil fuels, especially coal, on competitive international markets.  In the absence of policy intervention, equilibrium is at point A with consumption and production (assuming no change in stocks) at $Q_A$, which also represents emissions.  Note however that while consumption and emissions relate to the UK, production includes amounts produced elsewhere and imported to the UK.</p>

<p>The effect of the carbon tax is to raise the supply curve vertically by the amount of the tax. In the absence of other measures, the new equilibrium is at B.  Production, consumption and emissions fall to $Q_B$.  The cost burden of the tax is mainly shared between users of fossil fuels and consumers of goods produced using fossil fuels, the shares depending on elasticities in particular markets. A share of the burden would also take the form of a fall in the price received by fossil fuel producers, but this would be small given the elastic supply curve.  The tax revenue could be used by the government in various ways with various distributional effects.</p>

<p>The effect of adding cap-and-trade, assuming an effectively enforced cap at $Q_C$ below $Q_B$, is to limit consumption, production and emissions to $Q_C$.  Thus the part of the demand curve to the right of $Q_C$ becomes redundant.  Equilibrium is brought about via the market for emissions permits, which will determine a permit price such that supply (post-tax) and constrained demand are in equilibrium at C.  Distributional effects depend heavily on the mechanism for the initial allocation of permits.   The ‘corporate welfare’ point in BKay’s answer relates most clearly to the case of free allocation.  This can be avoided if allocation is by auction, with the revenue accruing to the government with, again, distributional consequences depending on how it is used.</p>

<p>Within this model we can infer the following:</p>

<ol>
<li><p>The tax and the cap both reduce production of fossil fuel and emissions.  It is not a case of separate policies to achieve separate objectives.</p></li>
<li><p>The cap provides certainty that emissions will not exceed a pre-determined level (whereas a carbon tax alone cannot give this certainty because its effect depends on the position of the demand curve which cannot be known with certainty).  The tax provides certainty that there will be <em>some</em> reduction in emissions, as compared with their level in the absence of policy (whereas cap-and-trade alone cannot give certainty in this respect because of the risk that poor forecasting or industry lobbying will result in the cap being set at too high a level, ie above $Q_A$).  In this respect the combination of policies overcomes limitations of either policy alone.</p></li>
<li>If a firm has to buy its permits at the market price, as well as bear a share of the burden of the tax, it might be perceived that it is subject to double taxation.  However, the effects of the tax and the permit price are additive, so that the total cost to the firm, for a given reduction in emissions, is no more than the cost under either policy alone.</li>
<li>With a fixed cap in place, gradual escalation of the tax rate will not normally produce further reductions in production or emissions.  It will move $Q_B$ gradually towards $Q_C$, increasing the share of emissions reduction due to the tax and reducing the share due to cap-and-trade, but will not shift $Q_C$.  Only if the tax rate were so high, or the cap so lenient, that $Q_B$ were below $Q_C$ (in which case the cap would have no effect) would escalation reduce production and emissions.  To achieve further progressive reductions in emissions within this policy framework, it would be essential gradually to reduce the cap.</li>
</ol>

<p>Let’s now consider some ways in which the above conclusions need to be modified because of departures from the model’s assumptions.  Firstly, cap-and trade, because it depends on measurement of actual emissions, is for practical reasons normally limited to large users or specific industrial sectors, certainly excluding household use. By contrast, a carbon tax levied at point of entry on the carbon content of the fuel is a simple and effective way of bringing <em>all</em> consumption of fossil fuels within the scope of policy.   In practice, therefore, users within the scope of cap-and-trade would be at (their individual equivalent of) $Q_C$, while those outside its scope would be at $Q_B$.  This difference in coverage could result in emissions reduction not being achieved in the most efficient way, eg by creating a greater incentive for expensive measures by large firms than for simple measures in the home.  In this respect the combined policy would be inferior to a carbon tax alone, but superior to cap-and-trade alone.  A further consequence is that escalation of the tax will always reduce emissions by users outside the scope of cap-and-trade.</p>

<p>Secondly, fossil fuels are not homogeneous.  For example, emissions can be reduced by switching from coal to natural gas in electricity generation.  The combined policy (like either policy alone) would not only reduce production of fossils fuels but also encourage this type of switching.</p>

<p>Thirdly, the assumption that emissions depend solely on consumption of fossil fuel, though currently fairly accurate, may become less so in future.  Currently the main ways in which carbon emissions can be reduced are improved fuel-efficiency, switching to alternative energy sources, and energy-saving measures such as improved insulation.  However, the implementation of carbon capture and storage (see <a href=""http://saskpowerccs.com/ccs-projects/boundary-dam-carbon-capture-project/"" rel=""nofollow noreferrer"">here</a>) may be beginning to weaken the link between consumption and emissions. It is desirable therefore that policy should include an element based on actual measured emissions.  In this respect either the combined policy or cap-and-trade alone are superior to a carbon tax based solely on carbon content.</p>
","4572"
"Oddness of equilibrium points","337","","<p>I have seen that generically any finite games have odd number of equilibria. So for $2\times 2$ games can we say that generically they must have $3$ equilibria? If not can you give an example of games which have $5$ or $7$ equilibria? Many thanks!</p>
","<p>It depends on what you mean by generically. The Prisoner's Dilemma has exactly one equilibrium. If you generate the payoffs in your $2 \times 2$ game by drawing payoffs from continuous i.i.d.'s then there is a non-zero probability (seems to me that the exact number is 25%) that you will get a game similar to the Prisoner's Dilemma, i.e. a game with strictly dominant strategies for both players.</p>

<p>There is also a 'smaller' class of games with even number of equilibria, you can read about them here:</p>

<p><a href=""http://mindyourdecisions.com/blog/2014/10/07/game-theory-tuesdays-why-most-games-have-an-odd-number-of-nash-equilibria/"" rel=""nofollow"">http://mindyourdecisions.com/blog/2014/10/07/game-theory-tuesdays-why-most-games-have-an-odd-number-of-nash-equilibria/</a></p>

<blockquote>
  <p>The Oddness Theorem (Wilson 1971) states that nearly all finite games have an odd number of Nash equilibria. In this post, we’ll explain what the theorem means in practical terms.</p>
</blockquote>

<p>You can also have a game with an infinite number of equilibria. (E.g. a $2 \times 2$ game with all zeros.)</p>

<p>However if the number of equilibria is finite you cannot have more than three in a $2 \times 2$ game.</p>
","12613"
"Is it appropriate to change the base year of the real GDP to a more recent one?","336","","<p>I have a dataset containing Venezuela's nominal GDP, real GDP, GDP deflator and population from 1997 to 2013. I am interested in calculating real GDP per capita, but the base year of the GDP deflator is 1997=100, which is the current base year used by Venezuela's Central Bank in all the national accounts.  </p>

<p>Would it be correct to change the deflator's base year to 2010=100 in order to recalculate real GDP?  </p>

<p>Or should I just use real GDP reported by the Central Bank even though the base year is outdated?</p>
","<p>Changing the base year of a time series is fine if you know what you're doing, check, for example the question: <a href=""https://economics.stackexchange.com/questions/5025/how-do-i-change-the-base-year-of-real-gdp-using-the-gdp-deflator-and-nominal-gdp?rq=1"">How do I change the base year of real GDP using the GDP deflator and nominal GDP?</a> </p>

<p>I'd, personally, use the real GDP series - you won't gain anything substantial with the mathematical conversion. It might be an useful exercise if you, for example, were to compare GDP growth in two different countries and would like the base year to be the same.</p>
","10109"
"Is the loan principal ever delivered in pieces over time?","336","","<p>Not sure if this is the right place for this question but it's more of a theoretical finance question than a personal finance question.</p>

<p>So a loan has a principal amount that is given to the borrower in a lump sum, and the borrow then pays back that amount plus some interest. For example, let's say that George loans \$100 to Fred at 10% interest over 10 months. Fred then pays back at \$11 a month and is debt free at the end 10 months.</p>

<p>Is it ever the case that George lends the money in increments instead of a single lump sum? That is, George pays Fred \$20 a month for five months, while at the same time Fred pays back at \$11 a month for 10 months. </p>

<p>I ask because this would be less useful to Fred but less risky to George.</p>
","<p>Handing out the principal amount of debt gradually, in increments, is standard practice in investment loans extended by a bank to a corporation.  </p>

<p>The rationale is clear : the corporation wants to make an investment, say a new factory. The whole plan is laid out and the cash flows of the pre-operational, construction period are also detailed, based on forecasts or specific agreements with the suppliers (contractors etc) that will be involved. The bank checks and accepts all these, but it also wants to see the corporation deliver (both the corporation's part in the financing but also as regards the actual build up of the investment).  </p>

<p>So specific milestones are agreed between the two parties, and to each milestone a round of financing is agreed (these milestones become contracutal obligations, legally binding). Milestones usually include specific technical phases of the build up to be accomplished (say, the building's foundations are complete, or the power infrastructure has been installed, etc). </p>

<p>In this way risk is reduced without hurting the necessary cash flow for the project. It also reduces the interest burden for the firm.</p>
","10335"
"Why labour, capital, and output levels cannot be pinned down in perfect competition?","334","","<p>Consider a firm producing with the following technology:</p>

<p>\begin{equation}
	Y = AL^{\alpha}K^{\beta}
\end{equation}</p>

<p>Assuming that factors are paid their marginal contribution to output, it can be shown that the optimal factor choice for this firm is:</p>

<p>\begin{equation}\label{eq:k-l ratio}
	\frac{L^*}{K^*} = \frac{\alpha}{\beta}\frac{r}{w}
\end{equation}</p>

<p>(this comes from finding each factor's payment, and combining them)</p>

<p>Thus, the furthest we can go in terms of characterising the equilibrium in this economy/firm relates to the optimal capital-labour <strong>ratio</strong>. In effect, nothing can be said about the <strong>level</strong> of inputs and outputs, $L^*$, $K^*$, or $Y^*$.</p>

<p>This is not the case if there is just one input. For instance, if $Y=AL^\alpha$, then </p>

<p>$$L^*=\left(\alpha A\frac{p}{w}\right)^{1-\alpha}$$</p>

<p>The reason is not related to the degree of returns to scale, as this is not constrained. It is not related to elasticity of substitution either, as in the case of a CES, it is also the capital-labour ratio which is solved for. Here, the solution is </p>

<p>$$ \frac{L^*}{K^*} = \left(\frac{\alpha}{1-\alpha}\frac{r}{w}\right)^\sigma $$</p>

<p>So, the question is, <strong>why can we not pin down the <em>level</em> of optimal inputs and output?</strong> Is this because we have treated factor prices as exogenous, so we are missing the supply side of each factor market?</p>
","<blockquote>
  <p>Thus, the furthest we can go in terms of characterising the equilibrium in this economy/firm relates to the optimal capital-labour <strong>ratio</strong>. In effect, nothing can be said about the <strong>level</strong> of inputs and outputs, $L^*$, $K^*$, or $Y^*$.</p>
</blockquote>

<p>I don't think this is true. You combined two equations into one, and thereby lost information. The optimization problem is</p>

<p>\begin{equation}
	\max_{K,L} p\cdot AL^{\alpha}K^{\beta} - w \cdot L - r \cdot K
\end{equation}
Taking derivatives w.r.t. $L$ and $K$ yields two first order conditions and the only two unknowns are $L$ and $K$.
$$
\alpha \cdot p\cdot AL^{\alpha-1}K^{\beta} = w
$$
$$
\beta \cdot p\cdot AL^{\alpha}K^{\beta-1} = r.
$$
As you noted this implies the cost minimization equation of
$$
\frac{L^*}{K^*} = \frac{\alpha}{\beta}\frac{r}{w},
$$
but why go that way? You could get
$$
L = \left(\frac{r}{\beta \cdot p\cdot A K^{\beta-1}}\right)^{\frac{1}{\alpha}}
$$
and plug this into the first equation, yielding
$$
\alpha \cdot p\cdot A\left(\frac{r}{\beta \cdot p\cdot A K^{\beta-1}}\right)^{\frac{\alpha-1}{\alpha}}K^{\beta} = w.
$$
And then
$$
K^{\frac{\alpha\beta - (\alpha-1)(\beta-1)}{\alpha}} =
K^{\frac{\alpha + \beta - 1}{\alpha}}
= \frac{w}{\alpha \cdot p\cdot A\left(\frac{r}{\beta \cdot p\cdot A}\right)^{\frac{\alpha-1}{\alpha}}}.
$$
Clearly this is not very pretty but it is very solvable.</p>

<p>Note: I did not go into second order conditions but this is only a maximum if $\alpha + \beta &lt; 1$.</p>
","16015"
"Does different Base Year in Price Index affected conversion of nominal value to the real value?","333","","<p>I do not have any economics background, but currently I have some data sets regarding price index. I have some doubts regarding if my way of conversion is correct?</p>

<p>I have 4 data set. So let it be DS1, DS1 PI, DS2 and DS2 PI.</p>

<p><strong>Note that DS1 PI and DS2 PI are both different variables price index.</strong></p>

<p>DS1 is price index in Base Year 2012, while DS2 is in Base Year 2014. </p>

<p>I am using DS1 to convert the nominal value of attribute 1 to a real value. This adjustment is done to convert all DS1 variables to the current real value at May 2015. The formula is shown below.</p>

<p>$$Adjusted Price 1 =\frac{DS1 Variables}{DS 1 PI} \times DS1 PI_{May 2015}$$</p>

<p>Similarly, I am doing the same thing for DS2.</p>

<p>$$Adjusted Price 2 =\frac{DS2 Variables}{DS 2 PI} \times DS2 PI_{May 2015}$$</p>

<p>Then, I would make a comparison between these 2 adjusted price variables. So my question is since the base year are different, would the adjustment to May 2015 be correct? </p>

<p>Both of the adjusted/real price are now in the same current value and would be comparable. It does not matter if the base year are different in this case?</p>

<p>Sorry if the question is confusing. I would appreciate your help in this matter.</p>

<p>Thanks.</p>
","<p>This question might be better suited for a statistics group, but if I understand you correctly you're going to compare two prices from different price indeces and see if there's a difference in the growth? There's really nothing wrong with the reasoning, but you should take the results you get with a grain of salt as you'll be comparing two indeces with different samples.</p>

<p>The different base year is not a problem as long as the variables you're dividing are from the same dataset. When price indices are renewed, the sample is often changed, so this is why you should be aware what you're doing when comparing between different base years.</p>
","8166"
"Can econometrics test for correlation or causality between prices and corruption?","331","","<p>This week there was news that some prices are rising. I heard that in some countries where corruption is high the prices are also higher. I wonder if there is causaility or just both at same. It would be interesting to find some material to support if the claim is true. Is there some study e.g. comparing prices levels for energy and testing whether corruption levels in an economy (bribing, black market, unregulated markets) influences prices?</p>
","<p>Some related studies:</p>

<p><strong><a href=""http://www.sciencedirect.com/science/article/pii/S016517659900230X"" rel=""nofollow"">Al-Marhubi, F. A. (2000). Corruption and inflation. Economics Letters, 66(2), 199-202.</a></strong><br>
The analysis is based on cross-country data consisting of 41 countries from Asia and Latin America for which data is available on four alternative indices of corruption (two from Transparency International, one is the Business International index, and the fourth from another economics study). Note that numerically, these are essentially <em>non-corruption</em> indicators -they range from $0=$ <strong>maximum corruption</strong> to $10=$  <strong>no corruption</strong>. The panel covers the period 1980-1995. Four alternative OLS regressions were run (each with one corruption indicator present), with heteroskedasticity-robust standard errors. In all cases a statistically significant positive correlation between corruption and inflation was found.  </p>

<p><strong>How large a correlation (to judge its <em>economic</em> significance also)?</strong>  The dependent variable was the <em>logarithm</em> of inflation. The value of the coefficient on the corruption variable was on average $-0.22$. Given how the indicators are defined, the minus sign says that  less corruption = less inflation. The actual value roughly says that $1/5$ of inflation was associated with corruption. So if the inflation was, say $10$%, <strong>2 percentage points can be attributed to corruption</strong>. Not small.</p>

<p><strong><a href=""http://onlinelibrary.wiley.com/doi/10.1111/j.1468-0343.2004.00132.x/abstract"" rel=""nofollow"">Braun, M. &amp; Di Tella R., (2004). Inflation, inflation variability, and corruption. Economics &amp; Politics, 16(1), 77-100.</a></strong><br>
They examine the <em>reverse relationship</em>: inflation facilitates corruption. They present a theoretical model, and also empirical evidence. For the theoretical model they write:</p>

<blockquote>
  <p><em>""(...)high variability of inflation can make over-invoicing by
  procurement officers and under-invoicing by salespersons easier
  because it makes auditing more expensive to the principal"".</em></p>
</blockquote>

<p>So here there is a <em>causative</em> theoretical argument as to why unstable prices increase corruption.</p>

<p>Their data relates to 75 countries and for the period 1980-1994:</p>

<blockquote>
  <p>Algeria, Argentina, Austria, Bahamas, Bahrain, Bangladesh, Belgium,
  Bolivia, Botswana, Burkina Faso, Cameroon, Canada, Chile, Colombia,
  Costa Rica, Cote d’Ivoire, Cyprus, Denmark, Dominican Republic,
  Ecuador, Egypt, El Salvador, Ethiopia, Finland, France, Gambia,
  Germany, Ghana, Greece, Guatemala, Haiti, Honduras, Hungary, India,
  Indonesia, Israel, Italy, Jamaica, Japan, Jordan, Kenya, Korea
  (South), Luxembourg, Madagascar, Malaysia, Malta, Mexico, Morocco,
  Myanmar, Netherlands, Niger, Nigeria,Norway, Pakistan, Paraguay, Peru,
  Philippines, Portugal, Senegal, Singapore, South Africa, Spain, Sri
  Lanka, Suriname, Sweden, Switzerland, Thailand, Togo, Trinidad and
  Tobago, Turkey, United Kingdom, USA, Uruguay, Venezuela, Zimbabwe.</p>
</blockquote>

<p>Here the dependent variable is the corruption index. They use the <strong>International Country
Risk Guide (ICRG)</strong>, that ranges from $0$ to $6$. Here too, a higher score means <em>less</em> corruption. They regress it (among various controls), on <em>inflation variance</em> (since what they want to test is whether an unstable price system introduces noise into transactions that facilitates corruption). They find statistically significant regression coefficients with values around $0.5$. They even find that inflation variability correlates more strongly with corruption, than inflation itself. Lots of references.</p>

<p><strong><a href=""http://core.kmi.open.ac.uk/download/pdf/9312682.pdf"" rel=""nofollow"">Dreher, A., &amp; Herzfeld, T. (2005). The economic costs of corruption: A survey and new evidence. Public Economics, 506001.</a></strong><br>
A more general study on the costs of corruption, looking also at inflation. For their empirical study (71 countries, 1975-2001), they also use the ICRG index. They regress the level of inflation on this index, and they find a <em>positive</em> sign on the coefficient. Since the index is as described above, a non-corruption index, higher values mean less corruption. So what they find is that <em>less</em> corruption is correlated with <em>higher</em> inflation. Irrespective of whether this can stand reason, their findings are also incredibly large: if you move up the ladder by one point in the ICRG scale (less corruption), the corresponding inflation will be <strong><em>10 percentage points</em></strong> higher(i.e. if it was, say, 5%, it will become 15%). This is too large to be believable even if the direction of association is to be accepted. Despite this, this is a survey, so <em>lots</em> of references.  </p>

<p><a href=""http://www.sciencedirect.com/science/article/pii/S0165176511002631"" rel=""nofollow""><strong>Blackburn, K., &amp; Powell, J. (2011). Corruption, inflation and growth. Economics Letters, 113(3), 225-227.</strong></a><br>
This is a theoretical model. as the authors write:</p>

<blockquote>
  <p><em>""We present a model in which the embezzlement of tax revenues by public
  officials leads the government to rely more on seigniorage to finance
  its expenditures. This raises inflation which depresses investment and
  growth via a cash-in-advance constraint.""</em></p>
</blockquote>

<p>So here we have a <em>causative</em> theoretical argument about why increased corruption causes increased inflation.</p>

<p><a href=""http://www.sciencedirect.com/science/article/pii/S0264999311002562"" rel=""nofollow""><strong>Bittencourt, M. (2012). Inflation and economic growth in Latin America: some panel time-series evidence. Economic Modelling, 29(2), 333-340.</strong></a><br>
Four Latin American countries (Argentina, Bolivia, Brazil, Peru) for the period 1970-2007. As the authors note, these four countries account for $\approx 70$% of total GDP and population in South America (for 2009). The dependent variable on their regressions is the growth rate, while both inflation and a composite ""political situation"" variable are included as regressors. The ""political situation"" variable again increases with increased transparency and controls on power, and so it can be expected to correlate <em>negatively</em> with corruption (i.e. the higher its value, the less corruption). For our purpose we need to look not at the regression results but at the correlation matrix of the regressors: there we see that the political situation variable is negatively correlated with inflation, with correlation coefficient $-0.142$ (so again, more corruption is associated with more inflation).</p>

<p>Overall, it appears that scholars have empirically detected a positive correlation between the level of corruption and the level of inflation, and also offered theoretical insights on how this can come about, although one theoretical model argues in favor of a causal effect from inflation to corruption, while the other from corruption to inflation. Since both arguments seem reasonable, one could think that it may be the case of a vicious feedback spiral.</p>
","1596"
"Could debt cause inflation instead of deflation?","331","","<p>It is well known that <strong>debt</strong> can cause <strong>deflation</strong>, especially during <strong>crisis</strong>: to repay their debts agents sell their goods which causes a fall in prices.</p>

<p>But if there is no crisis and agents ""have the time"" to repay their debt, would it be possible to have the opposite mechanism, <strong>inflation</strong>: to repay their debts (and make their investments profitable) agents would sell their products for an higher price causing a raise in prices?</p>

<p>In the general case it seems difficult because this could destroy market shares if there is competition.</p>

<p>But in some cases I wonder if it could:</p>

<ul>
<li>monopolys (especially state monopolys, and this would be a kind of hidden tax),</li>
<li>competition but with all competitors in debt so that all have to sell at higher prices to survive,</li>
<li>...</li>
</ul>
","<p>Yes it can.</p>

<p>If debt originates from the banking system, then it potentially has a side effect of money creation. Whether or not money is actually created when a bank loan is made depends on the banking system's regulatory framework, and the lending policies of its banks, and these can vary widely. </p>

<p>However if there is net excess of bank lending over bank loan repayment and loan default, then money creation is occurring, and the additional money can and indeed usually does, result in inflation.</p>
","6641"
"Economics and Euclidean geometry","329","","<p>I am looking for economics papers which use concepts, techniques and theorems from geometry. I am mainly interested in Euclidean geometry, the kind of material that is taught on high-schools (e.g. proving theorems about triangles, squares, circles, etc.). But, other kinds of geometry are also interesting.</p>

<p>I looked at some papers about land economics, thinking that it geometry can be useful there (after all, the word ""geometry"" means ""measurement of land""). But, the papers I found used mostly advanced measure theory and topology. I am looking for more basic geometric methods. </p>
","<p>Another example is <a href=""http://onlinelibrary.wiley.com/doi/10.1111/1097-3923.00006/abstract"" rel=""nofollow noreferrer"">Economies with Public Goods: An Elementary Geometric Exposition</a> by William Thomson, which relies extensively on the geometry of equilateral triangles. </p>

<p>In general, William Thomson is known for making a heavy and interesting usage of geometry in his papers. See for instance a recent working paper of his : <a href=""http://rcer.econ.rochester.edu/RCERPAPERS/rcer_584.pdf"" rel=""nofollow noreferrer"">Compromising between the proportional and constrained equal awards rules</a> (although this one might be further from basic high-school euclidean geometry than what you're looking for). </p>

<p>Other somewhat similar examples include papers relying on the geometry of simplices. An example I came across recently is</p>

<ul>
<li><a href=""http://www.jstor.org.proxy.library.vanderbilt.edu/stable/41106883?seq=3#page_scan_tab_contents"" rel=""nofollow noreferrer"">A graphical analysis of some basic results in social choice,  Estelle Cantillon and Antonio Rangel, Social Choice and Welfare Vol. 19, No. 3 (2002), pp. 587-611</a> </li>
</ul>

<p>but there are many others, starting with the exposition of the expected utility theorem in Mas-Collel, Whinston and Green.</p>

<p>I am also tempted to point at the following recent paper, although it definitely uses geometric tools which go far beyond high-school euclidean geometry:</p>

<ul>
<li><a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1974922"" rel=""nofollow noreferrer"">A Geometric Approach to Mechanism Design,   Jacob K. Goeree and  Alexey I. Kushnir Carnegie Mellon University Tepper Business School, 2013,  University of Zurich Department of Economics Working Paper No. 56</a></li>
</ul>

<p>I don't have a specific paper for it (any intro to econ textbook would do), but I would also add the classical graphical measure of consumer and producer surpluses in ECON 101. (Especially for linear demand and consumer curves where is simplifies to measuring the area of a triangle. Can't do much more ""measurement of land"" than that)</p>
","8283"
"What are the economic ramifications of rent control?","329","","<p>What effect do they have on renters?  Landlords? Are there examples of rent control working, improving living conditions for renters?  </p>

<p>I.e. What are the main arguments for/against rent control (purely economic, not emotional or moral).</p>
","<p>Well, rent control is the classic example used in many economics textbooks when talking about price ceilings. A price ceiling is a maximum price one can pay for a good, and is set by a governing body. There are many cons to price ceilings and not many pros.</p>

<p>$\textbf{Pros:}$</p>

<p>1) Because tenants of the property know that apartments are in short supply, they will have an incentive to take good care of the place in order to stay on the renter's good side because they may not be able to get another apartment if they get kicked out of this one.</p>

<p>2) Tenants who get apartments will have lower rent costs and will therefore be able to spend/save more of their money. If they choose to spend it, that can boost the local economy because more money will be spent in local businesses.</p>

<p>$\textbf{Cons:}$ </p>

<p><a href=""https://i.stack.imgur.com/ezAjq.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ezAjq.gif"" alt=""enter image description here""></a> </p>

<p>The graph above depicts a binding rent control. By this, I mean that the rent controlled price is below the equilibrium price. In this example, the rent controlled price is $1,000$ and the equilibrium price is $1,500$. What this causes is a shortage of apartments. Looking at this graph, we can see that at the price of $1,000$, $Q_D=2,100,000$ and $Q_S=1,900,000$. Using this, we can see that the shortage will be: 
$$Q_D-Q_S=2,100,000-1,900,000=200,000\;apartments$$</p>

<p>What this means in words is that there are more people who want apartments than there are people who are willing to supply apartments. What might be the side effects of this?</p>

<p>1) Rationing: There are a couple of ways rationing may occur, but in the market for apartments the only way which makes sense is rationing through discrimination by sellers biases. What this means is that the renter may give the apartment to someone who doesn't value it as much as another person based on their biases.</p>

<p>2) Illegal activities: One thing which may occur due to rent control is under-the-table deals. Basically, people may pay the seller some money under the table to ensure that they get an apartment.</p>

<p>3) Homelessness or relocation: We need to look at what we mean by the quantity of apartments demanded is greater than the quantity of apartments supplied. What this means is that people who want/need to buy apartments will not be able to (in our example 200,000 people at least). What are the two outcomes of this? The first outcome would be homelessness because people cannot get apartments, and they may have nowhere else to go. The reason why this is not desirable is pretty obvious (we don't want people to have to live on the streets). The second outcome would be relocation of current residents. What this means is that people will need to move out of the area. This will hurt the local economy because less people will be spending their money in local businesses.  </p>

<p>One last thing to keep in mind is that over time this shortage will get worse. In the short run, the sellers may not be able to take the apartment off the market. However, in the long run, sellers may decide to sell the apartment complex, which will cause the supply of apartments to decrease even more. This will exacerbate the problems I listed above.</p>

<p>$\textbf{Edit:}$ Another problem caused by rent controls was mentioned (quite astutely) by $\textbf{AdamBailey}$. He pointed out that landlords may not make enough money to maintain his or her rental properties, and over time the quality of such rental properties may depreciate drastically. This shows that, not only will the quantity of apartments decrease, but the quality may decrease as well. This is another perfect example of how rent controls can hurt those that it is trying to help. </p>
","11309"
"Change in the way unemployment is calculated in the US?","328","","<p>In the last 8 years has their been a change in the way unemployment is calculated? Is there a nuance that has changed in the polling info? Many of my right wing comrades claim the Obama administration has changed the calculation in some way to make it seem as though the number is lower than what it should be?</p>
","<p>The most likely explanation for discrepancies that political partisans like to pick at is that presidents like to cite different measures of unemployment. The BLS has <a href=""http://www.bls.gov/news.release/empsit.t15.htm"" rel=""nofollow"">6 alternative categories of labor under-utilization</a>. The U-6 measure of unemployment with seasonal adjustment stands at 9.7%. Although the official rate may be under 5% as in the BLS's <a href=""http://www.bls.gov/news.release/pdf/empsit.pdf"" rel=""nofollow"">September 2016 release here</a>, many people may not feel like the economy is much better, and partisans can argue over which measure of employment or labor force participation rate is most useful.</p>

<p>Most politicians are not part of insidious, cynical political schemes, as the media may make them out to be. Just that when incidents happen, we hear about it non-stop, and it reinforces the public's view that political workers are untrustworthy as a whole, allowing for weird specious claims from the left and right. Take your friends' words with a grain of salt, and when you hear any president make a claim about the unemployment rate, you can look up the BLS's numbers yourselves and see how they are measured and which one the president is citing.</p>

<p>It is also worth noting that the BLS regularly updates how they measure unemployment.</p>
","13378"
"Why has increased productivity over the last 100 years not affected how much people work?","328","","<p>If we are generally richer and more productive due to better technology and other factors, why do we still work so much? </p>

<p>I understand that there are various incentives to work (e.g. implicit status awards) that aren't linked with productivity in the abstract. But in a very simple model, if we can do more with less input, why are we still doing as much as we can?</p>
","<p>Let's work such a very simple model. We have a Robinson Crusoe island economy, an isolated individual that lives totally alone. In order to consume something Crusoe must work. Assume for even more simplicity that capital is not needed (say, fruit-gathering by hand). Crusoe does not like to work but he would rather sit relaxed and enjoy the good weather in his island. Apart from the biological necessity to eat something, Crusoe also likes the taste of fruits he gathers. Fruits cannot be stored.</p>

<p>So we have a, daily utility function of the form</p>

<p>$$U = U(c, \ell),  \;\; \ell + L = T$$</p>

<p>$$U_c &gt;0,\;\; U_{\ell}&gt;0,\;\; U_{cc} &lt;0, \;\; U_{\ell \ell} &lt;0,\;\; U_{c\ell} =U_{\ell c} \geq 0$$</p>

<p>The last assumption on the cross-partial seems like the more reasonable one.
$\ell$ is leisure and $L$ is amount of work, and $T$ the maximum amount of time that Crusoe can work (say, $16$ hours). We also have a  ""fruit-gathering"" function</p>

<p>$$Q = f(L) = AL^a$$</p>

<p>We can reasonably assume that we have decreasing marginal product of labor (due to the body getting tired going up and down all these trees), so $0&lt;a&lt;1$.  </p>

<p>Since fruit cannot be stored and capital is absent, the only optimization problem that makes sense here is a static one, meaning $c=f(L)$.  </p>

<p>Then we want to max over $L$ the function $U[f(L), T-L]$. </p>

<p>The f.o.c. is </p>

<p>$$\frac {\partial U[f(L), T-L]}{\partial L}\equiv G = U_c[f(L), T-L]\cdot f'(L) - U_{\ell}[f(L), T-L] = 0$$</p>

<p>and the s.o.c is</p>

<p>$$ \partial G/\partial L = U_{cc}\cdot f'(L) - U_{c\ell}\cdot f'(L) + U_c\cdot f''(L) - U_{\ell c}f'(L) +U_{\ell \ell} &lt;0$$</p>

<p>Given our assumptions, this expression is everywhere negative, so we have our maximum.  </p>

<p>We want to examine what happens as $A$ in the fruit-gathering function increases. Using the implicit function theorem we have, around the solution,</p>

<p>$$\frac {dL}{dA} = -\frac {\partial G/\partial A}{\partial G/\partial L}$$</p>

<p>We know that the denominator is negative, so together with the minus sign in front becomes positive. Therefore</p>

<p>$$\text{sign}\left\{\frac {dL}{dA}\right\} = \text{sign}\big\{\partial G/\partial A\big\}$$</p>

<p>$$= U_{cc}\cdot[ \partial f/\partial A ]\cdot f' +[\partial f'/\partial A]\cdot U_c  - U_{\ell c}\cdot [\partial f/\partial A] $$</p>

<p>This expression is of ambiguous sign, which is a first indication that things may not be that straightforward after all.  </p>

<p>To validate the conjecture of the OP we would need to obtain,</p>

<p>$$\text{sign}\left\{\frac {dL}{dA}\right\} &lt; 0 \implies U_{cc}\cdot[ \partial f/\partial A ]\cdot f' +[\partial f'/\partial A]\cdot U_c  - U_{\ell c}\cdot [\partial f/\partial A] &lt; 0$$</p>

<p>$$\implies U_{\ell c}\cdot [\partial f/\partial A] &gt;  U_{cc}\cdot[ \partial f/\partial A ]\cdot f' +[\partial f'/\partial A]\cdot U_c$$</p>

<p>$$\implies U_{\ell c} &gt;  U_{cc}\cdot f' +\frac {\partial f'/\partial A}{\partial f/\partial A}\cdot U_c$$</p>

<p>Using the first order condition, we can substitute for $U_c = U_{\ell}/f'$, so</p>

<p>$$\text{sign}\left\{\frac {dL}{dA}\right\} &lt; 0 \implies  U_{\ell c} &gt;  U_{cc}\cdot f' +\frac {\partial f'/\partial A}{\partial f/\partial A}\cdot [U_{\ell}/f']$$</p>

<p>Now</p>

<p>$$\frac {\partial f'/\partial A}{\partial f/\partial A} \cdot \frac {1}{f'} = \frac {(a/L)L^a} { L^a} \cdot \frac {1}{(a/L)AL^a}$$</p>

<p>$$= \frac {1}{f} = \frac {1}{c}$$</p>

<p>So</p>

<p>$$\text{sign}\left\{\frac {dL}{dA}\right\} &lt; 0 \implies  U_{\ell c} &gt;  U_{cc} \cdot f'+ U_{\ell}/c$$</p>

<p>and re-arranging while multiplying throughout by $c/U_c$ and using the f.o.c. again, we get </p>

<p>$$\text{sign}\left\{\frac {dL}{dA}\right\} &lt; 0 \implies  f'\cdot (RRA_c-1) &gt; - U_{\ell c}\cdot c/ U_c$$</p>

<p>where $RRA_c$ is the coefficient of relative risk aversion related to consumption. </p>

<p>So we see that if $RRA_c\geq 1$, which is the usual assumption, this inequality is certain to hold and so indeed higher productivity will lead to less time spent working... so why reality does not conform with our theoretical results?  </p>

<p>But it does. Historically, the amount of time spent working has been declining . The problem with the OP's question is that the phrase ""we do as much as we <em>can</em>"" is contaminated by framework effects: if what happens around me is people working, say, $10$ hours a day, $5$ days a week, and I work $11$ hours a day, $6$ days a week, I tend to think that, since I exceed the standard around me, ""I do what I <em>can</em>"", being oblivious to the fact that people used to work $16$ hours a day, $7$ days a week, with perhaps a few days per year off at best. So no, we do not really ""do as much as we can"".</p>
","10941"
"General equilibrium regarding on U= max(ax,ay) + min(x,y)","327","","<p>Please kindly instruct me on solving the following in a general equilibrium framework with standard budget constraint,
$$ u^{1}\left ( x  \right )= max\left [ \frac{x_{1}}{10}, \frac{x_{2}}{10}\right ]+ min\left [ x_{1},x_{2} \right ] $$
, with $e^{1} = (10,10)$</p>

<ol>
<li>What would this consumer demand at prices $p = (\frac{3}{4}; \frac{1}{4})$?</li>
</ol>

<p>Given the other two consumer utilities</p>

<p>$$u^{2}\left ( x  \right )= x_{1}^{\frac{2}{5}}x_{2}^{\frac{3}{5}} $$</p>

<p>$$u^{3}\left ( x  \right )= x_{1}^{\frac{3}{5}}x_{2}^{\frac{2}{5}}$$
, with $e^{2} = (4,6)$ , $e^{3} = (4,4)$ </p>

<ol start=""2"">
<li>Find one Walrasian equilibrium (and determine both equilibrium prices and the equilibrium allocation).</li>
</ol>

<p>I have completely no idea how to start with it...</p>

<p>Thank you!</p>
","<p>Let us name three consumers A, B and C, and two goods X and Y. Equilibrium price vector $(p_x, p_y=1)$ and allocation $((x_A, y_A), (x_B, y_B), (x_C, y_C))$ satisfy the following:</p>

<p>Optimality Conditions (Allocation must solve the utility maximization problem of the three consumers, i.e. it must lie on the demand functions)</p>

<ul>
<li>$(x_A, y_A) = \begin{cases} \left(\frac{10p_x+10}{p_x}, 0\right)  &amp; \text{if } p_x \leq \frac{1}{10}  \\ \left(10,10\right) &amp; \text{if } \frac{1}{10} \leq p_x \leq  10 \\ \left(0, 10p_x+10\right) &amp; \text{if } p_x \geq 10\end{cases} $</li>
<li>$(x_B, y_B) = \left(\frac{2(4p_x + 6)}{5p_x}, \frac{3(4p_x + 6)}{5}\right)$ </li>
<li>$(x_C, y_C) = \left(\frac{3(4p_x + 4)}{5p_x}, \frac{2(4p_x + 4)}{5}\right)$</li>
</ul>

<p>Feasibility Conditions</p>

<ul>
<li>$x_A + x_B + x_C = 18$</li>
<li>$y_A + y_B + y_C = 20$</li>
</ul>

<p>Solving the above gives price vector $(p_x, p_y) = (1.2, 1)$ that supports the allocation $((x_A, y_A), (x_B, y_B), (x_C, y_C)) = ((10, 10), (3.6, 6.48), (4.4,3.52))$ in equilibrium.</p>
","15641"
"Do discontinuous preferences imply no continuous utility function?","326","","<p>I am trying to think of a preference relation that can be represented by a utility function but such that there does not exist a continuous utility function. </p>

<p>I know that you can represent continuous preferences with a discontinuous utility function, but I am not sure if the opposite is true. I am struggling to show that NO such continuous utility function exists.</p>

<p>My thoughts are that if you can define something with discontinuous preferences then maybe you can use this to imply that there do not exist any continuous utility functions. Note that Lexiographic preferences will not work because I am interested in a preference that can be represented by a utility function (albeit discontinuous).</p>
","<p>The easiest way to prove it is using the 'old' definition of continuity. 
$\succ$ is continuous iff whenever $x\succ y$, there exists neighborhoods of $x$ and $y$, $B_x, B_y$, such that all $z\in B(x)$ and $z'\in B(y)$, $z\succ z'$.</p>

<p>Suppose $x\succ y$. Because $u$ represents $\succ$, $u(x)&gt;u(y)$. Let $2\epsilon=u(x)-u(y)$. Because $u$ is continuous, there exists some $\delta&gt;0$ such that for all $z\in B_{\delta}(x)$, $u(z)&gt;u(x)-\epsilon$. Similarly, for all $z'\in B_{\delta}(y)$, $u(z')&gt;u(y)+\epsilon$. But then for all $z\in B_{\delta}(x)$ and $z'\in B_{\delta}(y)$, $z\succ z'$ as required.</p>
","18228"
"Zero Economic Profit and opportunity cost?","326","","<p>In microeconomics textbook, there is always this notion of zero economic profit in perfect competition. We know that when people gets negative economic profit, they often leave the market. What I wonder is if there exists some NPOs that competes in everyday markets (such as food markets because it sounds like doable), earning say zero accounting profit, meaning negative economic profit. If there do exist, why aren't they driving other for profit competitiors out? Is this because not much people are investing or what?</p>
","<p>Theoretically it is possible but only if the non profit organization operates at a cost which is lower than all other existing as well as expected new players as in a free market anybody with a much lower cost can enter and offer a price lower than the NPO and still earns a profit. And what about other NPOs in the same field. If they have a lower cost they will certainly offer a lower price. Secondly the NPO should accepted by the consumers. Practically speaking the market has many more complexities such as existence of brands and the information that price suggests. A lower price means lower quality which may not be accepted by the consumers. For example I may start manufacturing and selling mobile handsets at zero profit but still I might not drive Apple out of the market. Also, the world is not much perfect. To start I would have to install a capacity that can produce at a cost lower than the existing players and then offer a lower price to drive them out.</p>

<p>But still you can have examples of apparent monopolies in markets say for example 'online information'. What do you think Wikimedia is ? It is an NPO.</p>
","9473"
"Relation between Nash equilibrium , subgame perfect equilibrium, backward induction, perfect Bayesian equilibrium","325","","<p>My claims are</p>

<p>1- Backward induction solution is Nash equilibrium solution.</p>

<p>2- Not all Nash equilibria are sequentially rational</p>

<p>3- All Backward induction solutions are sequentially rational</p>

<p>4- SPNE solutions are Nash equilibria </p>

<p>5- SPNE solutions are sequentially rational if game has at least one 
proper sub game. If only has improper sub game then it may not be sequentially rational.</p>

<p>6- PBE solutions are Nash equilibrium and SPNE</p>

<p>7- PBE solutions are sequentially rational no matter what.</p>

<p>8- WPBE solutions are Nash equilibria. And sequentially rational no matter what.</p>

<p>Are these true? What do you think? Anything want to add?</p>
","<p>1- Backward induction solution is Nash equilibrium solution. <strong>TRUE</strong></p>

<p>2- Not all Nash equilibria are sequentially rational. <strong>TRUE</strong>; <em>NE allows for sequentially irrational behavior off equilibrium path.</em></p>

<p>3- All Backward induction solutions are sequentially rational. <strong>TRUE</strong></p>

<p>4- SPNE solutions are Nash equilibria. <strong>TRUE</strong></p>

<p>5- SPNE solutions are sequentially rational if game has at least one proper sub game. <strong>FALSE</strong> <em>(Counterexample below: the game has one proper subgame; $(XC,L)$ is an SPNE but involves a sequentially irrational strategy $L$ by player 2).</em> If only has improper sub game then it may not be sequentially rational. <strong>TRUE</strong> <em>(Treat the subgame after $X$ as a game of its own.)</em></p>

<p><a href=""https://i.stack.imgur.com/hNpdo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hNpdo.png"" alt=""enter image description here""></a></p>

<p>6- PBE solutions are Nash equilibrium and SPNE. <strong>UNCERTAIN / TRUE (in most cases)</strong>; <em>it actually depends on how exactly you define PBE (there are many definitions). See <a href=""http://econweb.ucsd.edu/~jwatson/PAPERS/WatsonPBE.pdf"" rel=""nofollow noreferrer"">Watson (2017)</a> for more details.</em></p>

<p>7- PBE solutions are sequentially rational no matter what. <strong>TRUE</strong></p>

<p>8- WPBE solutions are Nash equilibria. And sequentially rational no matter what. <strong>TRUE</strong></p>
","16705"
"How do penny auctions make money?","324","","<p>What are <em>penny auctions</em>? Given the great discounts they claim (up to 95%), how do they make money?</p>
","<p>In a penny auction, each bid raises the going price of an object by just one penny. However, placing such a bid is costly <em>whether or not you win</em>. Usually it costs one dollar to place a bid -- sometimes this is obfuscated by making you purchase bids (or bidding credits) before you participate. In any case, if the opening bid of an auction for something is 0.01, and the auction ends with the price at just 10, then one thousand bids have been placed and therefore the site has made 1,000 on top of what the item actually sells for (10). So if the item has a value of 500, then they would represent that as 98% discount even though they actually made a profit of 510, simply because they ignore the bidding costs (their primary source of profit).</p>

<p>Now, if you happen to be the person who makes the winning bid, and you have not bid previously, then obviously you would be getting a very good deal -- in the example above, you would be paying 11 for an item that might be worth 100 or more. However, it is difficult (and out of your control) to be the winning bidder. After every bid, time is allowed for other bidders to outbid you, in which case you lose the money you spent on the bid.</p>

<p>With all of this in mind, participating in penny auctions is essentially gambling. Sites that market these discounts and obfuscate the cost of bidding are highly misleading. I personally believe they should be banned. Note that these <em>penny auction</em> sites should not be confused with standard auction sites like Ebay. In standard auction sites, you pay only if you win -- you do not pay simply to make a bid.</p>
","10575"
"Positive Monotonic Transformations and Nested Functions","324","","<p>Suppose there is an economic agent with the utility function $u(x,y)$. A second agent has the utility function $h(g(f(u(x,y))))$.</p>

<p>Am I correct in thinking that if $f'(x)&gt;0$, $g'(x)&gt;0$, and $h'(x)&gt;0$, then  $h(g(f(u(x,y))))$ must also be positive and therefore  $h(g(f(u(x,y))))$ is a positive monotonic transformation of $u(x,y)$? </p>

<p>If not, how come?</p>
","<p>The value of $h(g(f(u(x,y))$ is not necessarily positive but the transformation $u \rightarrow h \circ g \circ f \circ u$ is indeed a positive monotone transformation.</p>

<p>To see this, take any $(x,y,z,w)$. We have the following chain of equivalences:
\begin{align}
u(x,y) \geq u(z,w) &amp; \Leftrightarrow f(u(x,y)) \geq f(u(z,w)) \text{ since } f \text{ is increasing} \\
&amp; \Leftrightarrow g(f(u(x,y)) \geq g(f(u(z,w)) \text{ since } g \text{ is increasing} \\
&amp; \Leftrightarrow h(g(f(u(x,y))) \geq h(g(f(u(z,w))) \text{ since } h \text{ is increasing}
\end{align}
Thus, the transformation $u \rightarrow h \circ g \circ f \circ u$ preserves the ordering, i.e. it is a positive monotone transformation.</p>

<p>Another way to see it is to assume that all functions are differentiable and notice that
\begin{equation*}
\frac{d (h \circ g \circ f )(x)}{dx}= f'(x) g'(f(x)) h'(g(f(x))
\end{equation*}
which is positive since $f'&gt;0,g'&gt;0,h'&gt;0$.</p>
","16086"
"Why is a fire service considered to be a non-rival service, while a highway is considered to be a rival good?","324","","<p>We consider highways to be an example of an impure private good because while it is non-excludable, it is a rival good. That is, another person's consumption (usage) of the highway affects my usage of it. </p>

<p>In that same sense, wouldn't a fire station also be rival, at least in theory?</p>

<p>For example, if a fire stations has five trucks for a locality, and 6 fires break out at separate places, why can't we consider this service as a rival service?</p>
","<p>One common definition of a non-rival good (see <a href=""https://en.wikipedia.org/wiki/Rivalry_(economics)"" rel=""nofollow"">here</a> and (A)) is a good for which the consumption of additional units involves zero marginal social costs of production. On this definition the service provided by a fire service would <em>always</em> be rival, because (even with plenty of capacity in terms of fire engines and staff) each visit to attend a fire involves some extra cost (eg vehicle fuel).</p>

<p>More loosely, a good may be said to be rival if consumption by one person prevents simultaneous consumption by others (this can also be found <a href=""https://en.wikipedia.org/wiki/Rivalry_(economics)"" rel=""nofollow"">here</a>), implying that a good is non-rival where that is not the case.  In this looser sense, infrastructure such as highways and services such as the fire service might be held to be non-rival in circumstances where capacity is large enough that consumption by some rarely prevents or interferes with consumption by others.</p>

<p>For those who adopt this looser definition, the difference between a highway network and a fire service, which may lead to the former but not the latter being characterised as a rival good, relates I think to the likely level of supply or capacity.  Given high levels of vehicle use with peaks at certain times (rush hours), and given the costs of road-building and other demands on land use, it isn't likely to be practicable to provide enough highways in the right places to make traffic jams a rarity.  On the other hand, given that a fire at any one location is a rare event, and given normally a high degree of independence between fires at different locations, it should be possible to provide sufficient capacity in a fire service that the scenario of fewer fire engines than fires will rarely occur.</p>

<p>Reference</p>

<p>(A) Nicholson W (9th edn 2005)  Microeconomic Theory: Basic principles &amp; Extensions p 596.</p>
","12521"
"Why does entitlements leads to lower US productivity?","323","","<p>In a recent Bloomberg interview, Alan Greenspan suggested that entitlements leads to lower productivity, can you please explain it?</p>

<p>What does 'capital stocks' mean? </p>

<p>Does he means that because we are spending a lot on health we don't have money to invest in other things? </p>

<p>Thank you</p>

<blockquote>
  <p>ALAN GREENSPAN:  Well, it's unfortunately very simple but not a good story.  It's turning out that we're using more and more people at the
  margin to produce less and less.  Productivity, which is output for
  man hours as we conventionally measure it, is running at a very low
  rate of increase.  And that's the critical variable in the economy
  over both the short-term and the long-term. </p>
  
  <p>So what we are confronted with right now is a very serious problem
  caused by the fact that capital investment is falling far short of the
  requirements necessary to keep the capital stock growing, and
  therefore productivity.  It is not working. </p>
  
  <p>LIU:  So how do we reverse that?  What exactly is behind that,
  Chairman? </p>
  
  <p>GREENSPAN:  Well, I've on many occasions indicated that the best way
  to standard this is to track it backwards.  There's a very tight
  relationship between the stock of nonresidential, private stock and
  output per hour.  They move together parallel all the time for very
  good reasons.  But that capital stock requires capital investment. 
  And capital investment, in turn, is being crowded out by a very
  substantial increase in government expenditures.  Basically,
  entitlements -- because both parties, both the Republicans and the
  Democrats, don't want to talk about it largely because it is
  considered the third rail of American politics.  You touch it and you
  lose. </p>
  
  <p>LIU:  Well, so that makes perfect sense.  So it might come down to
  cutting some costs, right, to cost controls, Chairman.  Top of your
  list, I know you've mentioned entitlement spending.  You know, you've
  got Medicare, Social Security.  The No. 1 thing that you think that we
  need to cut our costs on is what?</p>
  
  <p>GREENSPAN:  Well, the basic issue is the entitlements and the reason
  it's a problem is that people put money in their own funds and their
  employers' funds plus interest and that is what they perceive they et
  back , and therefore they are entitled to it because it is their
  money. </p>
  
  <p>The only problem is that's not what we are doing.  We're not creating
  enough funding for the Social Security trust funds, and the same thing
  goes for Medicare Part A.  And we're not funding this.  So long as we
  are not funding this, we are dollar for dollar crowding out capital
  investment.</p>
</blockquote>
","<blockquote>
  <p>""Well, the basic issue is the entitlements and the reason it's a
  problem is that people put money in their own funds and their
  employers' funds plus interest and that is what they perceive they et
  back , and therefore they are entitled to it because it is their
  money.""</p>
</blockquote>

<p>He's saying people think that they receive the income that they are putting into the program.  For example, a common perception that people have about social security is that it is simply a forced savings program: I put in \$50, that \$50 is put into a vault somewhere, then pulled out later, and given back to me for my retirement.</p>

<p>That's not how it works. I put in \$50, and we spend it immediately on someone's current retirement, or a number of other pre-approved (and sometimes seemingly unrelated) programs. We then hope that some new young person puts in another \$50 in time for my retirement.</p>

<p>This is particularly a problem as that the number of retirees is going to grow while the number of young people putting money into social security is going to shrink. In fact, this is a problem if productivity declines in any way, and the amount going in is limited or restricted, or fails to grow.</p>

<p>Questions 1/3: He is not saying that entitlements cause lower productivity in this statement-> he is saying entitlements will have problems -because- of lower productivity (probably from lower population, as has been popular to discuss for quite some time).</p>

<p>Question 2: Capital stock is the collection of tools available for production.  (Hammers, technical know-how, computers, assembly lines.)</p>
","4788"
"Converting current to constant USD values for trade data (UN Comtrade)","322","","<p>I am using WB (country GDP) data in combination with UN Comtrade (bilateral trade) data. I need to divide bilateral trade by GDP so as to find out which % of a country's GDP comes from bilateral trade. 
The problem is WB has values in constant 2010 USD while UN Comtrade in current USD. </p>

<p>How can I transform the current USD values in constant 2010 USD values? </p>
","<p>Use the <a href=""http://data.worldbank.org/indicator/FP.CPI.TOTL?locations=US"" rel=""nofollow noreferrer"">World Bank data</a> on US inflation to deflate the UN Comtrade dataset, so that it is also in constant prices.</p>

<p>Select Download, at the right side of the page, and you can get the dataset in csv or other formats.</p>

<p>To deflate the trade data, simply divide the values of bilateral trade by the value of each years CPI index, and then multiply them by the value of CPI in 2010 (the base year, which is 100 in this case). Alternatively, rebase the CPI index, by dividing all values by 100, so that CPI in 2010 is equal to 1. Then, divide the trade data by this new index. Both approaches are equivalent.</p>
","16386"
"What are good mathematics books to learn decision theory?","322","","<p>I am looking for a set of mathematics books to understand proofs in decision theory. Examples would be proofs of utility representations and social choice (im-)possibility results. I found many textbooks on both decision theory and social choice, some of which contain proofs which contain references to mathematical results.</p>

<p>However, I could not find a collection of mathematical results commonly used in these fields. Usual ""Mathematics for Economists"" textbooks fall short. What is the standard reference/textbook researchers use to find the results they employ?</p>
","<p>I do not know about social choice, but for utility representations I think the two most cited books are ""Convex analysis"" by Rockafellar and ""Infinite Dimensional Analysis: A Hitchhiker's Guide"" by Alliprantis and Border. They contain most (if not all) results on convex analysis and functional analysis used by economists.</p>
","8865"
"My Challenge in Econ 101 explanation of Marginal Benefit = Marginal Cost","320","","<p>In Econ 101 textbooks, there are lots of examples and emphasis on marginal analysis leading to the greatest equation of all, $MB=MC$.</p>

<p>My challenge is the following and wonder if anyone had a similar issue or a way to get over it:</p>

<p>One of the textbooks examples use consuming pizza or water. First unit brings you the biggest joy. Then it diminishes. So student would understand each additional unit of pizza wouldn't bring the same amount (e.g. initial v. when you are full) utility. But then there comes a time where you are quite full and feel satisfied. At this point, additional unit of consumption would probably make you feel sick or vomit, so it is not ""worth the money"" to spend on.</p>

<blockquote>
  <p>The trouble with this example is that it illustrates at margin, benefit is not constant. There comes a time when you would stop consuming. But this doesn't really shed light on why $MB=MC$? How can I do a better job explaining that this ""equality"" is embedded in all these stories? Is it perhaps the stuffed/eat-until-vomit is a corner solution example?</p>
</blockquote>

<p>For pedagogical reason, if you are better at explaining these concepts, please share how you would go about this with an example both interor and corner solution in ECON 101 textbook situation.</p>

<p><strong><em>My strategy was from example to the graph and to show why the equality should hold leading to connecting the dots on the first order conditions of utility maximization... But this equality is hard to really spell it out on 101 level, that's my challenge.</em></strong></p>

<p>Thanks!</p>
","<p>I suggest this graphic illustration.</p>

<p>You can first plot your utility U as a function of the quantity x of pizza eaten. Utility is expressed in \$.
Plot a positive concave function starting form the origins (0 pizza leads to 0 utility), going up to a maximum (at $x=4$ let's say) and then slightly decreasing after $x=4$.
The decreasing part means that you are loosing utility by eating too much pizza.
Now assume a unit of pizza costs \$1. </p>

<p>You can now plot a second graph illustrating the first order condition.
Plot first a decreasing curve corresponding the marginal utility (a straight line if you have chosen a quadratic form to the utility function) starting from $(x,y)=(0,5)$ (or any positive $y$), going down and crossing the X-axis at $x=4$ and being negative after $x=4$.
Then, plot the horizontal line $y=1$. The intersection of these two curves gives the optimal quantity of pizza to eat, $x^*$, given the cost.</p>

<p>For $x&lt;x^*$, you should eat more pizza because the marginal unit of pizza eaten worth more than it costs. For $x&gt;x^*$, you have eaten too much pizza comparing to what it costs you.
You can insist on two other points. First, imagine you do not pay as you eat pizza but you are invited at a party and food is free. In this case, the actual $MC$ is 0.
You will then eat until the point you get sick, meaning $x=4$. In other words, you eat as long as the marginal utility of eating is positive.
Second, back to the case in which a pizza costs \$1, you can show that $x^*&lt;4$. It means that you stop eating before the point you get sick.
You stop eating before because you have no interest in eating a marginal share of pizza that yields you \$0.5 of utility for instance but costs you \$1.</p>

<p><strong>Edit</strong>
In the example I give, the marginal cost of eating pizza is monetary, meaning money that you pay. The marginal benefit is the marginal utility received from eating pizza (possibly negative), it encompasses both the ""good feeling"" of alleviating your hunger but also the ""bad feeling"" of eating fat and damaging your body. If you want to define $MC$ as the sum of ""bad feeling"" and monetary cost, and $MB$ as the positive feeling, you need to specify how both feelings increase/decrease when you eat pizza. This is more demanding in terms of hypotheses than using the utility-based approach, and maybe too ad-hoc.</p>
","12589"
"When a relevant variable unnamed on either axis changes, can the curve NOT shift?","320","","<p>Source: pp 40-41, <em>Principles of Microeconomics</em>, 7 Ed, 2014, by N Gregory Mankiw</p>

<blockquote>
  <p>her demand curve would shift to the left (to curve D3).
  In economics, it is important to distinguish between <em>movements along a curve</em>
  and <em>shifts of a curve</em>. ...<br>
  ♦ There is a simple way to tell when it is necessary to shift a curve: When a relevant
  variable that is not named on either axis changes, the curve shifts. ♦ ...</p>
</blockquote>

<p>Is the last sentence of the excerpt (within $\mathbb{R^2}$) above really true ? (I surrounded it with lozenges ♦) </p>

<p>What if ceterus paribus, a fixed number $&gt; 1$, of relevant variables changes? Can they counteract each other, or even equilibrize all the changes so that the curve stands unmoved? </p>
","<p>The scenario of counteracting changes in relevant variables is theoretically possible, but unlikely in practice.</p>

<p>As an example that might come fairly close, consider the supply curve of oil in a small developing country which imports all its oil and subsidizes its sale, the subsidy being at a flat rate per unit.  The country will be a price taker for oil, so its domestic supply curve will be horizontal at the world price less the subsidy.  Now suppose the world price falls, and the government takes the opportunity to reduce the subsidy by a similar amount.  Either change on its own would shift the supply curve (the former down, the latter up), but together they could largely counteract each other.  Even in this case, however, it is implausible that the supply curve would never shift at all.  For one thing, the world price of oil is constantly changing, and it would be impracticable to adjust the subsidy so frequently.  For another, there would inevitably be time-lags in adjustments.</p>

<p>So although you correctly identify a theoretical exception to the statement by Mankiw, it is unlikely to be of much practical significance.</p>
","4523"
"If all indifference curves are parallel lines, then preference has linear representation","319","","<p>Given a continuous preference relation $\succeq$ over $X=\mathbb{R}^2_{+}$ where all sets:
$$
I_x\equiv\{y\in X:y\sim x\}
$$
are lines on $X,\forall x\in X$, and are parallel to $I_y,\forall y\notin I_x$. </p>

<p><strong>How can I show that $\succeq$ has a linear representation?</strong></p>

<p>It seems intuitive that if every indifference curve is a line, then the utility itself must be a line, but I'm not sure how to go back to it. Would someone be willing to help me?</p>

<p>Thanks! Any helpful tips are appreciated! :D</p>
","<p>The indifference curves are constructed by viewing the utility function as an equation (for a fixed utility index value per curve).  So from</p>

<p>$$U = U(x_1,x_2)$$ </p>

<p>where the left side is just a symbol, we move to</p>

<p>$$\bar U = U(x_1,x_2)$$
where now the left side is a specific number.</p>

<p>Take the total differential on both sides to obtain</p>

<p>$$0 = U_1dx_1 + U_2dx_2 \implies \frac {dx_2}{dx_1} = -\frac {U_1}{U_2}$$</p>

<p>Any straight line in the two-dimensional plane has a constant slope so also</p>

<p>$$\frac {dx_2}{dx_1} =c$$</p>

<p>Same for $y$-bundle. Etc.</p>
","7107"
"Moral Hazard with risk neutral agent","319","","<p>We have a principal-agent model with hidden actions in which the principal is risk averse and the agent is risk neutral; Assume also there are two levels of output, $x$ and $x'$ (with $x'&gt;x$) and two actions $a,a'$. Define $p(a),p(a')$ the probabilities of $x'$ under actions $a,a'$ respectively. Also, the agent disutility from action $a'$ is $-1$. The wages associated to $x,x'$ are $w,w'$ respectively.  </p>

<p>My problem is that I am not sure how to show that the optimal contract requires $x'-w' =x-w$, i.e. that the agent, being risk neutral, takes on all the variability associated with the project. </p>

<p>I formalize the problem (assume the principal wants to induce $a'$, otherwise my question is trivial)</p>

<p>$\max\limits_{\{w,w'\}} u(x'-w')p(a') + u(x-w)(1-p(a'))$  </p>

<p>st </p>

<p>$w'p(a') + w(1-p(a')) - 1 \geq 0 $</p>

<p>$w'p(a') + w(1-p(a')) - 1 \geq w'p(a) + w(1-p(a))$</p>

<p>In particular, when I try to solve the problem by maximizing the principal expected payoff subject to the ""standard"" Individual rationality (with $\lambda$ multiplier) and incentive compatibility (with $\mu$ multiplier) constraints (I assume the principal is interested in the more costly action $a'$) I end up with two equations which are not consistent with the aforementioned result. In particular: </p>

<p>$ u'(x-w) = \lambda + \mu [1- \frac{(1-p(a))}{(1-p(a'))}]$</p>

<p>$ u'(x'-w') = \lambda + \mu [1- \frac{p(a)}{p(a')}]$</p>

<p>It is evident that $x-w = x'-w'$ holds iff $p(a) =p(a')$ which is not the case in this problem (here we have that $p(a') &gt;p(a)$). Another possibility would be to assume that the Incentive compatibility constraint is slack (hence $\mu = 0$); however I cannot understand why that should hold, when the principal wants to induce the most costly action $a'$ (help here)</p>

<p>I have read online that another approach would be to assume that the principal ""sells"" the project to the agent and the agent, after having chosen which level of effort maximizes its expected utility, pays back a fixed amount to the principal (call it $\beta_{a}, \beta_{a'}$)</p>

<p>So we would have something like: </p>

<p>$w'p(a') + w(1-p(a')) - 1 -\beta_{a'} \geq 0 $
if the agent chose to undertake high effort and 
$w'p(a) + w(1-p(a)) -\beta_a \geq 0 $ otherwise.</p>

<p>But then how to go from there? How to insure that the agent is going to choose the action $a'$? How are the fixed amounts determined? Why are they optimal?</p>
","<p>This answer shows three things:</p>

<ol>
<li>We do not need the Lagrangian approach to solve your maximization problem.</li>
<li>We do not need the assumption that $x'-x=\frac{1}{p(a')-p(a)}$ either.</li>
<li>The condition $x'-w'=x-w$ is not necessarily satisfied for the optimal contract.</li>
</ol>

<p>Fix indeed the payment $w$. The problem can be written
\begin{equation*}
\max_{w'}{u(x'-w')p(a')}
\end{equation*}
given the constraints
\begin{align*}
&amp; w'p(a') \geq 1 - w[1-p(a')] \\
&amp; w'[p(a')-p(a)] \geq 1+w[p(a')-p(a)]
\end{align*}
It is clear that the principal has interest to set the lowest possible value for $w'$ given this set of constraint, since the objective function is decreasing in $w'$. Therefore he will set
\begin{equation}
w' = \max\{\frac{1-w[1-p(a')]}{p(a')},\frac{1+w[p(a')-p(a)]}{p(a')-p(a)}\}
\end{equation}</p>

<p>As @Alecos_Papadopoulos did, it makes sense to assume that the agent is protected by limited liability, i.e. that his payments are nonnegative. Otherwise the problem does not necessarily have a solution: the principal could always benefit from decreasing $w$ and increasing $w'$ so as to keep the individual rationality constraint satisfied. But the contract $(w=-\infty,w'=+\infty)$ is obviously not a satisfactory solution. Therefore I restrict attention to the case where $w \geq 0$ and $w' \geq 0$.</p>

<p>The condition $w \geq 0$ implies
\begin{equation*}
\dfrac{1+w[p(a')-p(a)]}{p(a')-p(a)} \geq \dfrac{1-w[1-p(a')]}{p(a')}
\end{equation*}
and therefore
\begin{equation*}
w' = \dfrac{1+w[p(a')-p(a)]}{p(a')-p(a)}
\end{equation*}</p>

<p>Plugging this equation into the objective function, the principal's problem becomes</p>

<p>\begin{equation*}
\max_{w \geq 0}{u(x'-\frac{1}{p(a')-p(a)}-w)p(a')+u(x-w)(1-p(a'))}
\end{equation*}
This objective function is decreasing in $w$. Therefore he simply sets $w=0$ and $w'=\dfrac{1}{p(a')-p(a)}$. As a conclusion, the equality $x'-w'=x-w$ has no reason to be satisfied unless one assumes that $x'-x=\dfrac{1}{p(a')-p(a)}$, i.e. that
\begin{equation*}
p(a') x' + (1-p(a'))x -1= p(a)x' + (1-p(a))x
\end{equation*}
This latter equation means that the social surplus resulting from $a'$ equals the surplus resulting from $a$: it is a very particular case where the cost of effort for the agent is exactly compensated by the increase in expected output for the principal. In all other cases, we have $x'-w' \ne x-w$.</p>

<p>I think the reason why the agent does not take on all the risk is because his actions are not observable, and therefore not contractible upon. This property would be true in a risk-sharing economy with unconstrained allocations. But the allocation is here distorted by the need to incentivize the agent to exert a high effort.</p>
","10198"
"Growth rate of variables on a balanced growth path (BGP)","318","","<p>Normally, in the very basic endogeneous model of growth. It is said that all variables grow at a constant rate. 
Let's take the basic capital accumulation ; </p>

<p>$$\dot{K}=Y-C$$</p>

<p>If I write this in following way ;</p>

<p>$$g_{K}=\frac{\dot{K}}{K}=\frac{Y}{K}-\frac{C}{K}$$</p>

<p>Normally, at balanced growth path (BGP), $g_{K}$ grows at a constant value (an arbitrary constant)</p>

<p>In this case, this means that variation of $g_{K}$ according to time at BGP should be equal to zero.</p>

<p>So ; </p>

<p>$$\frac{dg_{K}^{BGP}}{dt}=\left(g_{Y}-g_{K}\right)-\left(g_{C}-g_{K}\right)=0$$</p>

<p>which implies at BGP ;</p>

<p>$$g_{Y}=g_{K}=g_{C}$$</p>

<p>Is this reasoning correct ? </p>

<p>Because in fact, it seems me weird to differentiate a growth rate $g_{K}$ according to time.</p>
","<p>The concept of ""balanced growth path"" in economics incorporates three characteristics at the same time (related to the main macroeconomic aggregates):  </p>

<p>1) Growth rates are constant  (reflecting a notion of equilibrium/stability)  </p>

<p>2) Growth rates are strictly positive  (otherwise the economy would eventually vanish)  </p>

<p>3) Growth rates are equal to each other (hence there is ""balance"" and no macroeconomic aggregate becomes negligible relative to another)</p>

<p>To obtain the first characteristic you have to impose that the derivative of the growth rate with respect to time is zero. Nothing weird about that, just a valid mathematical operation.</p>
","12753"
"Is economics a science based more on statistics (observations) rather than rigorous reasoning?","317","","<p>The world is now more complicated than ever. We are all building upon the shoulders of our forerunners. We cannot understand where everything came from and how everything has evolved, and hence we don't understand how everything interacts. But the building blocks of the world today interact with each other intensively and sometimes unnoticeably. And clearly, it is hard to follow every lead to calculate every interaction's influence. I mention this because in macroeconomics many effects can cause secondary effects and these secondary effects may also cause tertiary effects, so it seems to me like an unending loop.</p>

<p>Thus it seems to me that in macroeconomics we use statistics to find associations and then try to explain certain associations using intuitive notions (maybe a dominant underlying reason) given the results. It seems to me that results in macroeconomics cannot be rigorously argued like the ones in mathematics or even physics. Rather these results are merely approximations learned from the past which are not confirmed each time like the laws in physics, let alone mathematical theorems.</p>

<p>So is what I am saying correct or is it simply that I do not understand macroeconomics enough?</p>
","<p>At the very foundation of sciences like Physics, rest relations and properties that they just <em>are</em>, no explanation can be given, but they have been found directly or indirectly to continue to hold, or at least to change at an inconsequential rate compared to the time-span (or space-span) of humans.  </p>

<p>Moreover, although Physics laws are also idealizations of reality (and they hold under ""normal circumstances"", too, as regards for example temperature or pressure), it has been found that <strong>a)</strong> ""normal circumstances"" abound, <strong>b)</strong> these idealized versions suffer negligible variation in the real world for any of (or most) practical purposes and <strong>c)</strong> what happens under ""special circumstances"" is also stable, a complementary law in essence.</p>

<p>For Mathematics, the foundations are also arbitrary, but not being of this world but purely mental concepts, they can be whatever we define them to be -no reality will come crushing in to refute them (it is a different matter when we want to map abstract Mathematics to the real world).  </p>

<p>In the Social Sciences, to which Economics belongs, the foundations contain relations and properties that have been found to change over time and over space, at rates much higher than physical properties change, and certainly within the time-span and space-span of humans. Plus, the observed variation around their idealized formulation is much larger.  </p>

<p>This is what makes Social Sciences much more treacherous and harder than the Hard Sciences, and this is why progression towards more universally valid results is so much slower, or even, the arrival at a bouquet of results for which we will know with enough certainty to which observed relations do they correspond.</p>

<blockquote>
  <p><em>""It seems to me that results in macroeconomics cannot be rigorously
  argued like the ones in mathematics or even physics.""</em></p>
</blockquote>

<p>Results in Economics can be <em>fully rigorously argued</em>, ever since Economics adopted mathematical symbolism to express itself. The issue is not with the process of argumentation, but with the premises one starts from.</p>
","6141"
"Inflation, cause or result of monetary emission?","315","","<p>The argentine economist Fernanda Vallejos, while trying to protect the government because of the inflation, the following:</p>

<blockquote>
  <p>Inflation is not the result but the cause of monetary emission. As
  there's inflation (<em>because of other reasons not important here</em>),
  people need more money and the central bank needs to print more money.</p>
</blockquote>

<p>How can you argue against that?  As it seems to be the opposite of modern theory on inflation.</p>

<p><em>Context:</em> This is in Argentina, where it has an important deficit, monetary emission and inflation are around 40%.</p>
","<p>The problematic part of the statement, is the ""<em>because of other reasons not important here</em>"" part . In other words: ""ignore general equilibrium"" -which is an unacceptable statement to make when discussing government policy and actions.  </p>

<p>Consider the naive quantity theory of money:</p>

<p>$$PQ = VM \tag{1}$$
$P$ is the price level, $Q$ is output produced (measured in <em>quantity</em>), $M$ is money supply, and $V$ is ""velocity of money"", an indicator of the ""transactions technology"" in the economy, how fast money circulates around to settle transactions.  </p>

<p>Assume now that we are talking for a ""small"" country that needs to import basic factors of production like raw materials or energy. ""Small"" here means ""with no market power"". Such a country is a price-taker in the international market. More over, substitution possibilities for these factors are usually small to non-existent.</p>

<p>Competitive markets or not, the economy's output will be distributed to factors of production and for our purposes, it doesn't matter whether there will be ""capital rents"" <em>and</em> ""profits"", or only capital rents. Use for convenience three factors of production and write</p>

<p>$$PQ = rK + wL + p_fE \tag {2}$$</p>

<p>where $r$ and $w$ are nominal, and $p_fE$ is the nominal cost of imported factors. Denote $s_f$ the <em>foreign</em> exchange rate (units of local currency per one unit of foreign currency), $c_f$ the price of the imported factors in <em>foreign</em> currency, so $p_f = c_fs_f$.
Use this and substitute $(2)$ in $(1)$</p>

<p>$$rK + wL +c_fs_fE= VM \tag{3}$$</p>

<p>If something happens to the international market and $c_f$ goes up to $c_f' &gt; c_f$, this will tend to increase the left hand side. This ""something"" in the international production factors market does not relate to the level of domestic output $Q$, or to domestic money transactions technology, $V$. More over, at least in the short run, factor substitutions will not happen, wages do not move that easily, and firms will maintain their output level while increasing selling prices, to cover the increased production costs. And since the reasons for the increase affect more-or less the whole economy, it is not that likely that competition will stop firms from doing so: they all want to cover their increased costs, they all know that the cost-rise is general and comes from abroad, so they don't need to actually collude in order to sustain a price increase. ""Common knowledge"" suffices.  </p>

<p>So in order to preserve the equality in $(3)$ it appears that we must have</p>

<p>$$rK + wL +c_f's_fE = VM',  \;\; M' &gt; M\tag{3}$$</p>

<p>You see? This is the phenomenon called ""imported inflation"". Whatever the reasons were for the price increase (the ""not important"" reasons), inflation was not caused by the expansion of the money supply (that's indeed true), and what else the government could do than raise the money supply to service the higher nominal level of output?</p>

<p>Of course what the story above does not say, is that foreign factors of production will want a ""money"" that they accept, and most likely this won't be the local currency of this small country. And by increasing the money supply the exchange rate $s_f$ will suffer (increase), because $s_f = h(M), \;\; h' &gt;0$, increasing in this way further the costs of imported factors in terms of local currency, and making the increase in the money supply equivalent to ""shoot oneself in the foot"". And this is only one more step towards the road to general equilibrium.</p>

<p>The essence here is that<br>
a) it is <em>trivial</em> that there are many other factors that may tend to affect prices upwardly, except money supply expansion  </p>

<p>b) in the presence of these other influences, increasing the money supply is not necessarily the appropriate government response.</p>
","343"
"Neoclassical economic profit and growth theory versus marxian","315","","<p>Marxists have a very specific ""profit"" and ""economic growth"" theory. According to marxists, profit doesn't come from technology, whose cost will be reflected in the price of whatever commodity the technology owning businessman is selling. Instead, the businessman profits by paying workers low enough for their labor so that they can squeeze a profit (e.g. profit comes from living labor not dead labor (technology)). Some of this profit will in turn be used to invest in more technology which will cause capital growth (capital valorization in marxist speak).</p>

<p>What's the neoclassical parallel to this? It seems in neoclassical models, the market is in equilibrium so the prices reflect marginal costs and there's no ""economic profit"". What seems to happen is that technological advancement ""happens"" and this in turn creates economic growth and a new steady state/equilibrium. However, is technological innovation here merely an accident, or does it have a logic in the same way marxian ""growth"" has (e.g. capitalists accrue profit through living labor and then invest it in technology)?</p>
","<p>If there is perfect competition, then yes, you will get zero economic profit, but even then, technology does no poof out of nowhere. Otherwise, you might find very different results.</p>

<hr>

<p>Let's think of the nature of competition through product differentiation. (We'll get into technology later.) Imagine two firms making their own widgets in Cournot competition, but instead of the normal price function $P = X - q_1 - q_2$, we have</p>

<p>$$P = X - q_i - d\cdot q_{-i}$$ where $-i$ denotes the other firm that is not firm $i$, and $d \in (0,1)$, $1$ being no product differentiation, and $0$ being completely different products sold by the two companies.</p>

<p>If $d = 0$, then the firms aren't really competing since their products are completely different and are acting as monopolists, making economic profit. If $d = 1$, then the firms are competing through regular Cournot and still making profit (probably).</p>

<p>In Bertrand, we can consider product differentiation as part of determining how much of the market you will steal away by undercutting price. The way a normal Bertrand model works is that you set price and then produce (as opposed to Cournot, where you set production, which affects the price). If you have a lower price, and there is no product differentiation, you steal away the whole market, so each firm will push price down to the price under perfect competition, where both firms split the market.</p>

<p>With product differentiation though, you don't lose the whole market when you are undercut, since your product is still a bit different. With full differentiation $(d=0)$ then you get the same result where each firm act as monopolists.</p>

<hr>

<p>Under each of these models, technology doesn't ""just happen"", but is reflected through lowering the marginal costs of the firm, which is essential for the firm to be competitive against its rivals. The less technologically advanced the firm is, the more of the market they will lose out on. Economic profit here can be used to invest into research and development or just straight up ""technology"" to reduce the cost of capital usage over time or other such things like that.</p>

<p>Even in perfect competition with no economic profit, the reason there is no economic profit will partly be because firms have to constantly update their technology to remain competitive, regardless of how differentiated the products are (as long as $d &gt; 0$).</p>
","8966"
"How to estimate empirically a demand curve","314","","<p>Suppose I have a small business that sell ice creams.
An Icecream cost 2$, and every day I have different values of sales.</p>

<pre><code>Day 1: 50 sales
Day 2: 70 sales
Day 3: 30 sales
Day 4: 50 sales
</code></pre>

<p><strong>How to I estimate the demand curve?</strong></p>

<ul>
<li>Should I change every day the price of the icecream and see how many sales I get? (the variation could be caused by many other factors)</li>
<li>Should I do a linear regression on the sales data?</li>
</ul>
","<p>A demand curve relates Quantity demanded to Price. If ice creams are always $2 then your data won't help you estimate a demand curve. Try offering some daily specials to create some price variation. No, people won't respond exactly the same way to a ""discounted regular price"" as they will to a lower everyday price, but still you will begin to gather the information you need tobuild a demand curve. And yes, you will need to offer higher prices, as well.</p>
","17339"
"In which situation does the demand and supply curve both shift?","314","","<p>In which situation does the demand and supply curve both shift? My professor told me for the demand curve,  the income of the consumers changes etc. will shifted the demand curve; For the supply curve, the changes technology etc will shift the supply curve.</p>

<p>So is this statement true: Only the types of situation with some factors causes the demand curve shift along with some other separate factors causes the supply curve shift may had both curve shift simultaneously, but in fact there is no single one factor that could shift both curve simultaneously.</p>
","<p>No, this case is not true. </p>

<p>A factor which both shifts supply and demand curves at the same time is an <strong>increase or decrease in population</strong>.</p>

<p>This both adds consumers (increase in demand) to the economy and increases the workforce (increase in labor force, thus producing more and increasing quantity supplied).</p>
","18139"
"Kuhn Tucker Conditions with fewer non-negativity constraints than number of variables","314","","<p>I have a following type of problem:</p>

<p>$Maximize\,\, F(s,x,y,z)$<br>
$s,x,y,z$    </p>

<p>s.t. (i) $g(x,y,z) \le I$<br>
(ii) $x \ge 0$<br>
(iii) $y \ge 0$<br>
(iv) $s &gt; 0$</p>

<p>That is there is no non negativity constraint on variable $z$. I have read about the Kuhn-Tucker method in the books but in all those cases the problem is fourmulated such that the non-negativity constraints apply to all the choice variables. How would my K-T optimality conditions change if I have no non-negativity constraint on $z$?</p>

<p>My sense is that other than the regular K-T conditions for $x$ and $y$ and Lagrange multiplier, $\lambda$, we would have (a) $\frac{\partial \Large{L}}{\partial z} = 0$ (i.e. no inequality here) and NO such condition as (b) $z\,.\frac{\partial \Large{L}}{\partial z} = 0$ (which is obviously true given (a)). My entire confusion is because I have not seen such a formulation in books where K-T conditions are discussed and just want to be sure about my steps.  </p>

<p>What would the conditions be in case of $s$, where the inequality is strict?  </p>

<p>Here I would think that with strict inequality the problem is not well defined. The constraint set is not compact (not closed).</p>

<p>Thanks a lot in advance.</p>
","<p>Non-negativity constraints have nothing special and are not critical for the general validity of the Karush-Kuhn-Tucker approach. First, realize that we could have $x \geq a &gt;0$ and then we could write $x-a \geq 0$ and view this ""non-negativity"" constraint as just one more inequality constraint on the solution.</p>

<p>When a decision variable is weakly bounded, the new phenomenon that emerges is that we <em>may</em> have the partial derivative non-zero (strictly negative, for the maximization case), if at the solution this decision variable lies on the boundary.</p>

<p>If it is unbounded, than we <em>must</em> have the first-order derivative equal to zero. As another question pointed out, this may create issues in certain contexts, but it does not invalidate the approach.</p>

<p>As for your second question, indeed strict inequalities may create problems, but don't jump immediately to a ""not well-defined"" heavy statement. The problem will arise only if (stars denote the optimal solution)</p>

<p>$$\frac {\partial F(s^*,x^*,y^*,z^*)}{\partial s^*} &lt;0$$</p>

<p>which would ""push"" the solution vector towards the unreachable zero-lower boundary for $s$. To avoid that, we require that at the solution the first-order derivative w.r.t to $s$ equals zero, and see whether we can indeed obtain a solution vector. If we can, it means that the $s&gt;0$ constraint does not even ""tend to"" be binding, so you can ignore it.</p>
","12563"
"What are the alternatives to currency devaluation?","313","","<p>What are (or are there) alternatives to currency devaluation? Phrased differently, what are the mechanisms that a country could use to make its products more competitive and to boost exports, when:</p>

<ul>
<li><p>it is under a currency board? </p></li>
<li><p>it has an <em>external</em><sup>1</sup> central bank ?</p></li>
</ul>

<hr>

<p><sup>1. When the local central bank is not allowed to print its own money. For example in the Eurozone , the capital stock of the European Central Bank is owned by the local central banks of all 28 EU member states, however the ECB alone administers monetary policy.</sup></p>
","<p>The only alternative is what is often called <em>""internal devaluation""</em>. This basically means reducing the actual (domestic) prices of goods in a country.</p>

<p>This is what is often called as increased <em>""competitiveness""</em>. It is most often achieved through cutting wages or slowing down wage growth. This is because wages are most often a huge cost factor and the price of capital (which is often bought internationally) is harder to reduce just like that. However there is also the phenomenon known as <em>""downward nominal rigidity""</em>, which means people don't accept lower nominal wages, so it's very difficult to lower wages. Much harder than increasing them. In fact, in practice, it's easier to increase inflation to reduce real wages than actually reducing the number printed on your check at the end of the month. However in this case, we want deflation (reduction in prices) to boost exports, so the whole matter gets more complicated.</p>

<p>Technically a devaluation only makes all your domestic goods cheaper abroad. This can also be achieved by just reducing your prices of course. However, as we saw, this is difficult. Also there is a coordination problem, as each industry would have to adjust (thousands of prices must adjust) for the same effect as the exchange rate adjusting (one price adjusts).</p>

<p>Milton Friedman used to compare this to daylight savings. We could all just agree to push all our appointments and activities by an hour for some time, which is hard (this would be <em>internal devaluation</em>). Or just change the time for the same effect (exchange rate devaluation).</p>

<p>A surge in quality is technically also an alternative, but not possible always and especially not short-term.</p>
","9939"
"Collusion and number of firms","312","","<p>How would you answer the following question?</p>

<p>You work for a CEO of a large firm. He says to you, <strong>""In my experience collusion is less likely to be sustained as the number of firms in the market increases. Demonstrate this using a model of Bertrand Competition.</strong>""</p>
","<p>Iet's say we have n identical firms and an infinite horizon of time.</p>

<p>The n firms sustaining the collusion, will find optimal to fix the same price $p_m$ where $p_m$ is the price of the monopoly level and we define $\frac{\Pi^m}{n}$  as the profits each firm is obtaining by sustaining the collusion in each moment t.</p>

<p>Now, of course each firm can betray the others by fixing a price lower than $p_m$, namely $p_m-ε$, where ε is small, and by doing so, the firm will capture the entire demand because in this market the firms are doing the Bertrand competition. In other words, the firm by betraying the others, will get almost π_m at the time T=t. We will also assume that in all t > T no firms will make any profits, because they will punish the firm, by fixing the price in Bertrand competition.</p>

<p>The firm will defect if:</p>

<p>$π_m/n + δπ_m/n + δ^2π_m/n.... &lt; π_m+0+0....$</p>

<p>Where δ is the discount factor.</p>

<p>This can rewritten as:</p>

<p>$(\frac{π_m}{n})(\frac{1}{(1-δ)}) &lt; π_m$</p>

<p>We can now see that if n, the number of firms, increases then the profits by sustaining the collusion will decrease, so the above inequality will be more likely to be true. This means that a firm has less incentives to sustain a collusion when there are too many participants, because the profits will be divided among too many firms and the punishment will be seen as less heavy.</p>
","24"
"Why some countries are wealthier than others?","311","","<p>Twin-peak of economic growth is one of the concepts discussed in economics. Most of explanations for poverty traps are baseed on the lack of infrastructures and public goods.
How could be another main reasons to explain this important issue ? </p>

<p>Any academic reference is appreciated.</p>
","<p>While a lack of infrastructure and public goods may explain poverty in a short-term perspective, it is widely considered that institutions are the key factor in the long term (how could infrastructure and public goods be provided without suitable institutions?).</p>

<p>As well as Acemoglu &amp; Robinson, referred to in FooBar's answer, two important writers on this topic are <a href=""http://en.wikipedia.org/wiki/Hernando_de_Soto_Polar"" rel=""nofollow"">Hernando de Soto</a> and <a href=""http://en.wikipedia.org/wiki/Douglass_North"" rel=""nofollow"">Douglass North</a>.</p>

<p>De Soto's book <a href=""http://rads.stackoverflow.com/amzn/click/0465016154"" rel=""nofollow"">The Mystery of Capital</a> argues that people in poor countries are often constrained by the absence of institutions providing effective property rights over capital.  Thus the land farmed by a villager may be informally recognised by other villagers as being his land, but his lack of formal property rights over the land means that he cannot use it as security for a loan to buy farm equipment, and cannot sell it if he wants to start a different business or move to a city.  As a result his economic options are heavily constrained.</p>

<p>North, in his paper <a href=""http://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.5.1.97"" rel=""nofollow"">Institutions</a>, emphasizes the importance for economic development of institutions which:</p>

<ol>
<li>facilitate trade and specialisation, both within countries and
internationally, by lowering transactions costs between people in
circumstances where the informal constraints of village life do not
apply;</li>
<li>facilitate mobility of capital, by developing a legal framework for 
financial instruments and removing legal obstacles (eg usury laws);</li>
<li>facilitate the spreading of risk, reducing the consequences of bad
luck for individuals and firms.</li>
</ol>

<p>While such institutions are largely taken for granted in developed countries, North suggests that their growth is not an inevitable development, and indeed that the historical norm is the absence of such a development (p 98 of Institutions).</p>
","5406"
"What does a central bank guarantee against its currency?","309","","<p>During the Bretton Woods system, currencies were issued against gold. In contemporary times, what is the real thing against which currency is issued? What does the fiat currency actually guarantee?  </p>
","<p>Most central banks do not provide guarantees on their currency to the public.  In fact it can be argued that historically they were never fully guaranteed as most central banks issued more receipts for gold (or other assets) than they had, so the receipts were never fully redeemable in the aggregate.  </p>

<p>The American Fed was stressed during the great depression and had to go off the gold standard for the public in 1933.  The international gold standard was retained and dollars were redeemable for gold for a while.  This too was ""overbooked"" and when the rightly suspicious French started to mass redeem dollars for gold, the Americans had to get off the international gold standard as well in 1971.</p>

<p>Today the dollar is not redeemable for anything.  You can exchange paper dollars for coins or electronic dollars, but that is just changing the form of the same thing (the monetary base).</p>

<p>Because you can go to jail if you don't pay your taxes in dollars, it can be said Americans are forced to purchase dollars and thus provide extrinsic value to the dollars though public tender laws (granted still different from intrinsic value but still important).</p>

<p>Pegged currencies are a different matter and are the closest modern equivalent to perhaps what you are asking.  With a peg, a country must acquire a certain amount of an external currency to maintain a peg.  It could be thought of indirectly that the country maintaining the peg is guaranteeing a redemption of their local currency to an external one.  The idea is to somewhat stabilize the local banking systems which need a lot of artificial stability to survive.  Granted this doesn't work well as pegs often do run out of ""reserves"" and suffer ""runs"" just like a gold standard.</p>
","9536"
"Why (neoclassical) economic models have no profits, unlike the real world?","307","","<p>Consider a simple neoclassical model of an economy populated by firms with a constant returns to scale production function, using homogeneous labour and capital. Firms are equal, and are price takers in all markets. Thus, firms pay factors their value marginal product. In the long run, any <em>economic</em> profit is wiped out by changes in the price of the good, due to the menace of entry of new firms.</p>

<p>In this setting, no income remains after paying out competitive wages to workers (L) and competitive return to the capital hired for production (K). This is, for firm $i$, </p>

<p>$$pY_i = L_iw + K_ir $$</p>

<p>Now, in real markets, even in competitive ones, firms do make profits, even if these profits are not <strong>abnormal</strong>. Part of these profits might be distributed as dividends.</p>

<p>In the trivial economic model however, the ownership of the firm is not explicitly modeled. Firms do not pay dividends. </p>

<p>Why is this? Why is ownership not relevant? Are profits uninteresting? That is what the capitalistic firms cares about! I'm puzzled.</p>
","<p>Accounting (after tax) profits are net of depreciation and of interest paid on loans, or of any capital/equipment actually rented by the firm. So conceptually, they map to ""net returns on <em>own</em> capital"".  </p>

<p>Not necessarily ""equilibrium"" or ""competitive"", because such characterizations are some steps further down the modelling road, in making assumptions on the market structure and on the goals of economic agents. </p>

<p>It has been a historical habit in economics to use the word ""profit"" to describe ""the existence of returns to capital above the competitive-level"" (hence for example ""monopolist makes a profit""). </p>

<p>In other words, Economics uses the word ""profit"" with a different meaning than the one used in Accounting and in Business, that's all.   </p>
","15919"
"Moral Hazard or Adverse Selection?","306","","<p>I pay the doctor before he conducts the surgery.</p>

<p>Can anyone explain to me whether this statement shows moral hazard or adverse selection?</p>
","<p>The problem you are facing has probably both: <strong>Moral Hazard and Adverse Selection</strong>.</p>

<p>We have <strong>hidden action</strong> by the doctor (you can't really observe his level of effort during the surgery), therefore we have Moral Hazard.</p>

<p>Additionally, you (probably) can not know beforehand of the doctor is a good or bad doctor, so his type (good or bad) is unknown. So, there is <strong>hidden information</strong> and therefore possibly Adverse Selection.
One example could be that a good doctor would never work for the amount you pay, so the doctor you hire is of the bad type.</p>

<p><em>Remark: I did not define good/bad doctor here, as it could be many different things; a bad doctor could just be a lazy doctor or a badly trained doctor.</em></p>
","5454"
"Total Differential of a Utility Function Subject to a Budget Constraint","306","","<p>I am trying to fully understand the process of maximizing a utility function subject to a budget constraint while utilizing the Substitution Method (as opposed to the Lagrangian Method). I am following the work of Henderson and Quandt's <em>Microeconomic Theory</em> (1956).</p>

<p>My confusion lies with obtaining the total differential of the generalized utility function after substituting in the budget constraint. For example, suppose you have the following utility function:</p>

<p>$$U=f(q_1,q_2)$$
Subject to:
$$y^0=p_1q_1+p_2q_2$$</p>

<p>The total differential of this utility function is:</p>

<p>$$dU=f_{q_1}dq_1+f_{q_2}dq_2$$</p>

<p>where $f_{q_1}$ and $f_{q_2}$ are the partial derivatives of $U$ with respect to $q_1$ and $q_2$, and $dq_1$ and $dq_2$ are the changes in $q_1$ and $q_2$.  

<p>Substituting the budget constraint into the utility function results in:
$$U=f(q_1,\frac{y^0-p_1q_1}{p_2})$$</p>

<p>I am struggling to calculate the total differential of the above function. Would the total differential just be the partial derivative of $U$ with respect to $q_1$ multiplied by the change in $q_1$? Below is my attempt:</p>

<p>$$U=f(q_1,\frac{y^0}{p_2}-\frac{p_1}{p_2}q_1)$$
$$dU=f_{q_1}dq_1-\frac{p_1}{p_2}dq_1$$</p>

<p>The next step in the book (after skipping the above total differential) is:
$$\frac{dU}{dq_1}=f_1+f_2(-\frac{p_1}{p_2})=0$$</p>

<p>Obviously, my intermediate calculation is incorrect (probably in multiple ways). Can someone identify and clarify my mistakes in progressing from the substituted utility function to the above equation? I understand that this process is used to equate the marginal rate of substitution to the goods price ratio and I am aware of its interpretation. My question lies simply with the mathematical derivation.</p>
","<p>In the second term of the intermediate calculation we must find the partial derivative of the entire second parameter of the $f$ function.  Hence
$$dU = \frac{\partial f}{\partial{q_1}}dq_1+\frac{\partial f}{\partial (\frac{y_0-p_1q_1}{p_2})}d(\frac{y_0-p_1q_1}{p_2})$$.  Obviously this is a substitution of $q_2$ into the original total differential derivation you had.  My point is that you tried to do the partial differential of $f$ with respect $q_2$ by assuming that this would equal $$\frac{dq_2}{dq_1}$$ when this may not always be the case.  For the final equation that you have may want to consider the chain rule.  The way you have it, we have defined $$U=f(q_1, q_2)$$ and $$q_2(q_1)=\frac{y_0}{p_2}-\frac{p_1}{p_2}$$  Then according to the chain rule you have $$\frac{dU}{dq_1}=\frac{\partial f}{\partial q_1}\frac{dq_1}{dq_1}+\frac{\partial f}{\partial q_2}\frac{dq_2}{dq_1}$$  Then we evaluate $$\frac{dq_1}{dq_1}=\frac{d}{q_1}q_1=1$$  Then we get $$\frac{dU}{dq_1}=\frac{\partial f}{\partial q_1}+\frac{\partial f}{\partial q_2}\frac{dq_2}{dq_1}$$  Then, $$\frac{dq_2}{dq_1}=-\frac{p_1}{p_2}$$ Finally we end up with $$\frac{dU}{dq_1}=f_1+f_2(-\frac{p_1}{p_2})$$</p>
","15810"
"What exactly is Foreign Currency Indexation?","306","","<p>As I understand it, foreign currency indexation (FCI) is when a government pegs its currency to another (usually the dollar), and their central bank buys or sells dollars to maintain a stable exchange rate between the two. </p>

<p>The material I have to read for my class mentions FCI in the context of the Mexican tesobonos and other domestic debt that was issued linked to another currency. </p>

<p>I am unable to find a resource online or otherwise that can distinguish between the two possible answers I'm given to the question ""What is FCI"":
1. When a country issues debt in another country's currency
2. When a country buys foreign currency to lower the value of its currency</p>

<p>One seems incorrect because I don't see how the option hits at the fact that the currency is being pegged to the dollar (or another stable currency), and two seems wrong because it does not account for the other side of the equation (selling to increase which I would assume is functionally correct).</p>

<p>Any input or suggestions?</p>
","<p>A currency can be indexed but so can a bond. An indexed bond is one where the coupons and principal are indexed to another currency (the U.S dollar in the case of Tesobonos) at the spot rate in effect at the time of issuance. So you actually pay in the local currency but how much you pay depends on the prevailing exchange rates when payment is due. </p>

<p>A bond can be indexed without a currency being indexed. It is typically a way, much like a foreign currency denominated debt issuance, to remove local inflation and exchange risk from debt issuance. </p>
","3240"
"Nobel prize for empirical work","304","","<p>Did any recipients of the economics Nobel prize receive their prize for work that was primarily or substantially empirical (rather than theoretical) in nature?</p>
","<p>In 2011, Tom Sargent and Chris Sims were jointly awarded the Nobel Memorial prize for empirical work.</p>

<blockquote>
  <p>The Royal Swedish Academy of Sciences has decided to award The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel for 2011 to Thomas J. Sargent and Christopher A. Sims ""for their empirical research on cause and effect in the macroeconomy.""</p>
</blockquote>

<p>Dr. Sargent's contribution was related to the use of structural macroeconometrics in policy and analysis and Dr. Sims' contribution was to the use of vector autoregressions (VAR) to analyze temporary changes in policy and other factors.</p>

<p>Source: <a href=""http://www.nobelprize.org/nobel_prizes/economic-sciences/laureates/2011/press.html"" rel=""nofollow"">Nobel Prize Website</a></p>
","5890"
"Is indefinite exponential economic growth possible?","303","","<p>Economic growth is frequently expressed as a % of GDP.  Proponents of a <a href=""https://en.wikipedia.org/wiki/Steady_state_economy"" rel=""nofollow noreferrer"">steady-state economy</a> postulate that perpetual exponential economic growth is impossible and that any system relying on it is inherently unstable. Is this true?</p>

<p>Is indefinite exponential economic growth possible?</p>

<p>(See also: <em><a href=""https://economics.stackexchange.com/q/455/332"">Are there fundamental reasons why (exponential) economic growth is highly desirable?</a></em>)</p>
","<p>As Steven Landsburg pointed out, indefinite anything isn't possible given the eventual heat death of the universe.</p>

<p><a href=""http://en.wikipedia.org/wiki/Self-replicating_spacecraft#Von_Neumann_probes"">Von Neumann posited machines capable of indefinite growth in population</a> (and theoretically production and consumption), so in theory, it would be possible for a time.</p>

<p><a href=""http://adsabs.harvard.edu/full/1983QJRAS..24..113S"">Sagan's Response</a> however argued if such things existed that we would have already observed them, and that they would destroy whole galaxies <em>en masse</em>.</p>

<p>That's probably the closest answer you can get to a question like this.</p>
","473"
"Pure Strategy SPNE","303","","<p>Quick question here: </p>

<p>I am evaluating an extensive-form game with five subgames. Four of the five subgames are easily handled. However, the fifth subgame is making me second guess myself. </p>

<p>My question: </p>

<p>Can there be a pure strategy subgame perfect N.E. in an extensive form game if there is a subgame where a player is indifferent between actions? </p>

<p>So, this fifth subgame is a node followed only by payoffs. The player deciding between playing L and R will generate an equivalent payoff whether he plays L or R. So, he is indifferent. Since this player is indifferent at this node, it makes me think I cannot define a SPNE in pure strategies. </p>

<p>Also, I know that a SPNE in pure strategies must be a backward induction solution. Well, since this node is considered first during backward induction, it seems to nix a backward induction solution to the game. </p>

<p>Is this correct? Can anyone clarify? </p>
","<p>Every finite full information game has a subgame perfect equilibrium.</p>

<p>A strategy profile is not an equilibrium if at least one of the players has a 'better move'. If they only have one that is exactly as good as their current move they have no incentive to change.</p>

<p>About backward induction: <br>
It is not nixed in such cases. If a player is indifferent between two choices you mark both branches as both choices are subgame perfect. You can also see from this that by following subgame perfect strategies you will reach from the root to the end so a SPNE exists.</p>

<p>Indifference between some actions on the part of a player is a necessary but not sufficient condition of having multiple SPNE in a finite full information game.</p>
","10560"
"The 'Economic Man' (Reference Request)","303","","<p>We are writing a paper about the 'economic man.' By this, we mean that the choices he makes epitomize a rational economic thinker. However, we also acknowledge the fact that there are other, non-economic reasons that people make decisions such as religion. What (if any) literature addresses the idea that even with other considerations, a person will still act rationally in the economic sense. Preferably we would like to have a theoretical model that encases these other choice considerations. Also, we would love to hear whether there are any case studies on this idea.</p>
","<p><a href=""https://en.wikipedia.org/wiki/Amartya_Sen"">Amartya Sen</a>, a 1998 Nobel Laureate, has a well cited article on the subject: </p>

<ul>
<li><a href=""http://www.jstor.org/stable/2264946"">""Rational Fools: A Critique of the Behavioral Foundations of Economic Theory""</a>, <em>Philosophy &amp; Public Affairs</em>, 1977.</li>
</ul>

<p>Some other related references: </p>

<ul>
<li><p>Persky, Joseph. 1995. “Retrospectives: The Ethology of Homo Economicus”. <em>The Journal of Economic Perspectives</em> 9: 221-231. </p></li>
<li><p>Hargreaves-Heap, Shaun and Martin Hollis. 1987. “Economic Man”. In <em>The New Palgrave: A Dictionary of Economics</em>, vol. 2, ed. John Eatwell, Murray Milgate, and Peter Newman. New York: The Stockton Press.</p></li>
<li><p>Sen, Amartya K. 1987. “Rational Behavior”. In <em>The New Palgrave: A Dictionary of Economics</em>, vol. 4, ed. John Eatwell, Murray Milgate, and Peter Newman. New York: The Stockton Press.</p></li>
<li><p>Sen, Amartya K. 2002. <em>Rationality and Freedom</em>. Cambridge, Massachusetts: Belknap Press of Harvard University Press. </p></li>
<li><p>Simon, Herbert A. 1979. <em>Models of Thought</em>. New Haven: Yale University Press.</p></li>
</ul>

<p>I should add that Sen is particularly good with giving people credits. So the bibliography section of his books/articles will surely have many more useful sources on this topic.</p>
","10726"
"How do I calculate consumer surplus and producer surplus from this?","302","","<blockquote>
  <p>Calculate the consumer surplus, producer surplus and total surplus in the market equilibrium.</p>
</blockquote>

<p>Market for beef and home demand and home supply:</p>

<p>$$ Q_d(p) = 50 - p $$</p>

<p>and</p>

<p>$$ Q_s(p) = p $$</p>

<p>With $p$ representing the price of 1 kg of beef</p>

<p>I understand that consumer surplus is consumer's willingness amount to pay minus consumer actual paying price.</p>

<p>But how do I derive from only information from above?</p>
","<p>In equilibrium, we have supply equal to demand. So $Q_{s} = Q_{d} \implies 50 = 2p$, so $p^{*} = 25$ is the equilibrium price. Consumer surplus is defined as:</p>

<p>$$\int_{p^{*}}^{p_{max}} Q_{d}(p) dp$$</p>

<p>Here, $p_{max} = 50$, as $Q_{s} = 0$ when $p = 50$. So evaluate the integral. </p>

<p>Producer surplus is similarly defined as:</p>

<p>$$\int_{0}^{p^{*}} Q_{s}(p) dp$$</p>
","12700"
"Solow Growth Model. Steady State. Can someone explain please?","301","","<p>my lecturer is doing a rather poor job explaining what he's written down, so I'm wondering if someone would be able to explain the following graph for me?
<a href=""https://i.stack.imgur.com/O4i0J.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/O4i0J.png"" alt=""Solow Model Steady State Diagram""></a></p>

<p>This is a part of the Solow-Swann Growth Model lecture for Macroeconomics, and he's talking about the equilibrium that this model predicts, k stands for capital per worker, s is savings rate, z is technology, d is depreciation rate, n is population growth rate. My confusion is with the Y axis. How does an axis represent two equations..?</p>
","<p>An axis is characterized not by the variable it measures, but by the unit of measurement. So an axis can measure any number of variables, as long as they are measured in the same measurement unit.</p>

<p>In your case, the unit of measurement is ""units of output"", and both $(n+\delta)k$ and $sf(k)$ are measured in it (capital is measured in units of output, in case you wonder).</p>
","11220"
"Macro Economics Question: How will this curve shift?","300","","<p>I am studying for a Macroeconomics Test on the Money Market and was wondering how the Demand Curve for Money would shift when there are changes in Taxation, Income, and Price Levels? (i.e. it would move to the left / right because...)</p>

<p>Here is the graph and slide I am referring to:</p>

<p><img src=""https://i.stack.imgur.com/Zq68u.png"" alt=""enter image description here""></p>

<p>If anyone can help explaining this I would really appreciate it!</p>
","<p>You can look at IS-LM models in order to understand the intuituion more deeply. 
In this graphic, IS curve shifts to left when there exists a demand-sided economic policy like government spendings etc. This will for sure increase the demand of people in economy, which will increase price levels.  If the price level increases, with the same quantity of money circulated in economy, the interest rate will increase. (you can see it on the graph) So, a central bank must control these kind of policies with a monetary policy in order to stabilize its inflation. </p>

<p>The same logic in increase of income. This will increase demand, which will increase price levels and agents will need more quantity of money in order to realize their transactions. </p>
","5296"
"What is the difference between preferences lacking ""completeness"" and being indifferent?","300","","<p>If two preferences are complete, at least one must have a relationship to the other.  If neither has a relationship, doesn't that mean that the consumer doesn't care which one he/she purchases?</p>
","<p>As alluded to in the comments the distinction is roughly:</p>

<ul>
<li>Indifference: The decision maker <em>knows</em> she will receive the same utility from the consumption of $x$ or $y$.</li>
<li>Incompleteness: The DM <em>does not know</em> her preference between $x$ and $y$. (Note, this could stem from a lack of information, or because no preference exists)</li>
</ul>

<p>So, from a conceptual vantage, the difference is that indifference is the existence of knowledge, whereas incompleteness is a lack of knowledge. While interesting in a foundational/philosophical sense, the distinction is subtle and likely not the reason economists have spent so much thought on the subject. However, the difference has behavioral implications! and this is important for economics.</p>

<p>For example, imagine various choices between ""pizza"", ""hot dog"", or ""hot dog and $\$0.05$"". Perhaps, the decision maker has never had pizza or hot dogs and therefore finds them incomparable. As such, from the choice set $\{p,h\}$ she would choose either (since neither option is known to be inferior<sup>[1]</sup>). So $C(\{p,h\}) = \{p,h\}$.  Now, the decision maker also likes money, so although she does not know her preference for a hot dog, she will always choose more money to less, all else equal: $C(\{h, h+5\}) = \{h+5\}$. But her indecisiveness regarding the two foods might not be resolvable for 5 cents, so, it is reasonable that $C(\{p, h, h+5\}) = \{p, h+5\}$. But this violates the weak axiom of revealed preference. Such a choice function cannot be rationalized by a complete and transitive relation.</p>

<p>Notice if the decision maker was actually indifference between $h$ and $p$ then, $C(\{p, h, h+5\}) = \{h+5\}$. In summary: incompleteness can cause ""thick"" indifference curves, and this can violate the basic tenets of rational choice theory.</p>

<hr>

<p>[1] There are other interpretations of choice under incompleteness, for example, allowing the choice function to return an empty set. </p>
","12635"
"Mathematical analysis of Marginal Cost","299","","<p>Marginal cost is the cost associated with producing one more unit of output.         Mathematically speaking, marginal cost is equal to the change in total cost divided by the change in quantity.</p>

<p>$\ MC(q_{1},q_{2})=\frac{TC(q_{2})-TC(q_{1})}{q_{2}-q_{1}}$</p>

<p>Marginal cost can either be thought of as the cost of producing the last unit of output or the cost of producing the next unit of output. Because of this, it's sometimes helpful to think of marginal cost as the cost associated with going from one quantity of output to another, as shown by q1 and q2 in the equation below.</p>

<p>To get a true reading on marginal cost, q2 should be just one unit larger than q1.</p>

<p>That said, as we consider smaller and smaller changes in quantity, marginal cost converges to the derivative of total cost with respect to quantity.</p>

<p>$\ MC(q_{1},q_{2})=\frac{dTC}{dQ}$</p>

<p>What if we need to calculate marginal cost as we go from one output point to a much bigger one? </p>

<p>For example, if the TC of producing 3 units of output is \$15 and the TC of producing 9 units of output is \$21, the marginal cost, simply put, is \$1.</p>

<p>Once we are considering a change in TC values due to a variation of quantity produced higher than 1 unity, are we applying the concept of average rate of change to measure the MC value?  </p>
","<p>I think you're getting things backwards. Marginal cost (at a certain quantity $q_0$) really only makes sense as the derivative of the total cost function with respect to quantity at point $q_0$:
$$
MC(q_0)=\frac{dTC(q_0)}{dq}.
$$
The <strong>interpretation</strong> of marginal cost as ""the cost of producing the last unit of output or the cost of producing the next unit of output"" is based on the (linear) approximation 
$$
\widehat{MC}^+(q_0)\approx\frac{TC(q_0+1)-TC(q_0)}{(q_0+1)-q_0}\quad\text{or}\quad
\widehat{MC}^-(q_0)\approx\frac{TC(q_0)-TC(q_0-1)}{q_0-(q_0-1)}
$$
This interpretation is usually introduced in undergraduate textbooks because of its <em>intuitive</em> appeal, not for its mathematical rigor. Imagine trying to explain the concept of marginal cost as <em>the cost associated with an infinitesimal amount of change in quantity</em> to a freshman who probably has no idea what ""infinitesimal"" means, let alone the concept of derivative. </p>

<p>A first problem related to interpreting marginal cost as the cost associated with the previous or the next unit of output is that producing the two units (the previous and the next) may imply different costs. This is illustrated by the formulas $\widehat{MC}^+$ and $\widehat{MC}^-$. Suppose total cost is quadratic, i.e. $TC(q)=q^2$. Then it can be easily verified that $\widehat{MC}^+(q_0)\ne \widehat{MC}^-(q_0)$, for any admissible $q_0$. This is problematic because we want the marginal cost (at a particular $q_0$) to be unique. </p>

<p>Second, and this relates to your question at the end, the concept of ""unit"" is somewhat arbitrary. And this arbitrariness makes measures such as $\widehat{MC}^+$ and $\widehat{MC}^-$ unstable as well. To illustrate, continue with the quadratic total cost example. When the unit of quantity is kg, the ""marginal cost"" at $1$kg--as you would refer to the cost associated with producing one extra unit--is $$\widehat{MC}^+(1)=2^2-1^2=3.$$
But what if we suddenly want to change the unit of quantity to gram (g)? Then the ""marginal cost"" at $1$kg, or $1000$g, would change as well:
$$
\widehat{MC}^+(1)=(1.001)^2-1^2=0.002001.
$$
To avoid such instability caused by changes in units of measurement, marginal cost is defined as a derivative, not as a difference. </p>

<p>If you want to measure the change in total cost due to change in some arbitrary quantity, simply apply the first formula in your question. But keep in mind that this cost is <strong>not</strong> marginal cost as an economist would understand it.</p>
","9965"
"What's quantitative easing?","299","","<p>From what I understand after reading mainstream media, quantitative easing <strong>increases the supply of money in the economy without direct government spending</strong> (fiscal policy). </p>

<p>It seems to have all the benefits of monetary policy (decreasing interest rates), but <em>can still be done with rock-bottom interest rates</em>.</p>

<p>Is my understanding correct? What's the downside I'm missing?</p>
","<p>You write ""qualitative easing"", but I think you refer to quantitative easing. I'll just do both.</p>

<h3>Quantitative Easing</h3>

<p>Quantitative easing corresponds to the central bank (CB) expanding its balance sheets by ""buying"" assets. This is typically done in secondary markets. It mainly injects liquidity into the system. To the extend that there is an additional buyer of assets now, the price of assets/investment (interest rates) decreases. However, the quantitative impact <em>should</em> be negligible: Through its demand, the CB increases value and liquidity in the markets it is operating. The scale of its operations should be too small however to affect the aggregate interest rate.</p>

<h3>Qualitative Easing</h3>

<p>Qualitative easing is a relatively new expression and refers to the riskiness of the stocks that the CB is investing into. In contrast to quantitative easing, which is about the magnitude of assets on the CB's balance sheets, qualitative easing is about the riskiness on the CB
s balance sheets, and hence the decrease in aggregate risk (on the banks' balance sheets).</p>

<h2>Downsides</h2>

<h3>Independence of a central bank</h3>

<p>When the CB holds assets, it is interested in their value. This may lead it to do policies that go against its primary directive (e.g. inflation stability). <em>Even if it does not do so</em>, effectiveness of a central bank comes from its capacity of controlling expectations. It is sufficient for households/firms to <em>expect</em> the central bank to do ""<em>bad</em>"" policies in order to decrease the effectiveness of the CB.</p>

<h3>Number of Goals</h3>

<p>I don't have sources on this, but I seem to remember that central banks with one clear goal (i.e. monetary stability) are more effective than those with a basket of goals (i.e. monetary stability, GDP growth, decrease of unemployment rate). A general criticism can be that QE are not operations that help with the important margin, monetary stability - and that the central bank should focus on that instead.</p>

<p>Note that these are not just esoteric points. In fact, the academics and central bankers at the ""Rethinking Macro Policy"" conference agreed that (<a href=""http://blog-imfdirect.imf.org/2015/05/01/ten-take-aways-from-the-rethinking-macro-policy-progress-or-confusion/?hootPostID=1de7242883b321b5960fb910a4dce832"">quoting Blanchard</a>)</p>

<blockquote>
  <p>Throughout the conference, e.g., in Gill Marcus’ talk, and actually throughout the various meetings which took place during the IMF meetings in the following days, policy makers remarked and complained about the heavy burden placed on monetary policy in this crisis, and the danger of a political backlash against central banks. Even as the crisis recedes, it is clear that central banks will end up with substantially more responsibilities—whether they are given in full or shared—for financial regulation, financial supervision, and the use of macro prudential tools. </p>
  
  <p>While even the use of the policy rate has distributional implications, these implications are much more salient in the case of regulation or macro prudential tools, such as the loan-to-value ratio. The general consensus was that these distributional implications could not be ignored, and that while central banks should retain full independence with respect to traditional monetary policy, this cannot be the case for regulation or macro prudential tools.</p>
</blockquote>
","5212"
"Differentiate a positive externality and the absence of a negative externality. Tax or subsidize?","298","","<p>I hope this isn't overly semantic, but I'd like to gain some clarification on the use positive (or negative) externality. </p>

<p>I usually shoot down suggestions for examples of positive externalities like organic agriculture. We can grant that organic agriculture is better than conventional, but that doesn't mean it is producing additional external benefits. Instead, organic agriculture might feature fewer negative externalities compared to the status quo. </p>

<p>I've even seen examples like smoking being a positive externality because smokers die sooner and save governments money on Social Security (perhaps that accounting might be questionable, but let's grant it for the sake of argument). Again, my semantic preference would be to label this as the absence of status quo negative externality.</p>

<p>If the semantics aren't interesting, might there still be something interesting on the tax vs. subsidize side? Returning to the agriculture example, taxing the negative externalities associated with conventional agriculture seems smarter than subsidizing organic. This seems like a case where it's more efficient to regulate the end and not the means. But what market characteristics might make subsidizing specific not-negative-externality-producing things more efficient?</p>
","<p>A negative externality arises when the private net marginal benefit (i.e. the marginal benefit minus the marginal cost) of an activity exceeds the net social benefit. In such cases, the self-interested private decision maker will increase their participation in the activity even though it is socially inefficient for them to do so.</p>

<p>A positive externality arises when the private net marginal benefit (i.e. the marginal benefit minus the marginal cost) of an activity are smaller than the net social benefit. In such cases, the self-interested private decision maker will not increase their participation in the activity even though it is socially efficient for them to do so.</p>

<p>This is a semantic distinction to the extend that if one thinks activity $A$ has a negative externality then one can define a new activity $B$, which is simply the ""act of not doing $A$"" so that $B$ has a positive externality. On this basis, one can argue that every externality is positive or that every externality is negative. For example, many people think that education has a positive externality because educated people make better citizens (e.g they make more informed voting decisions that benefit others). As a matter of semantics, one could argue that this is, in fact, not a positive externality and that what is really going on is that people who do <em>not</em> educate themselves are exerting a negative externality on those who do by virtue of their ignorance.</p>

<p>Whilst there is some merit to this reasoning, I do not find it helpful. Often, when we study the effects of behaviour, we are interested in comparing those effects to some baseline or benchmark in which the behaviour is absent. When communicating economics to others, it is usually the case that some benchmarks are more intuitive that others. We could, for example, rewrite all of consumer theory in terms of ""the dis-utility people experience from not having goods"" and look at the ""problem of non-consumption dis-utility minimisation"". Doing so would be formally equivalent to the more conventional approach of consumption utility maximisation (only the language changed), but would probably be less intuitive for people trying to understand the economics.(*) At least to me, it is more intuitive to think that people actively choose to undetake some level of education and exert a positive externality on others than to think that everyone receives infinite education by default and the choice of abstaining results in a negative externality.</p>

<p>Besides education, another example that I think fits most intuitively into the positive externalities box is network effects. If I buy a telephone then all of my phone-owning friends are made better off because now they can use their telephone to call one more person that they couldn't reach before. It seems weird to think of the negative externality of not owning a phone.</p>

<p>In terms of taxes versus subsidies: to get to the socially optimal intensity we need to ensure that the private net marginal benefit is zero precisely when the social net marginal benefit is zero. In the case of a negative externality this can be done either by increasing the private marginal cost (via a tax) for the activity or by increasing the private marginal benefit of <em>not</em> participating in the activity via a subsidy. For example, we could either subsidize low carbon firms or tax heavy polluters. As far as aligning incentives are concerned, the two are equivalent. In most practical cases, the more important consideration is likely to be that of budget constraints and politics:</p>

<ul>
<li>In the case of a tax: can the person you are taxing afford to pay the tax and can the tax be levied without seeming vindictive (for example, I think that taxing people without a university degree would be a no-no on these grounds).</li>
<li>In the case of a subsidy: can the government raise enough popular support and funding for a subsidy without leaving people with the impression the some parties are receiving unfair government hand-outs?</li>
</ul>

<p>In most cases, thinking about these political and financial constraints makes it clear whether a subsidy should be used. Sometimes a combination of both is used. For example, in the UK the government both taxes petroleum consumption and subsidises electric car ownership.</p>

<hr>

<p>(*) Nevertheless, economists do often find it useful to convert the utility maximisation problems into their dual expenditure minimisation problems, which is somehow similar. This technique, though, is usually reserved for more advanced students who already have a well-developed intuition for the economics.</p>
","165"
"Does it make sense to 'deflate' a sectoral price index in a regression analysis?","297","","<p>For instance, if one is running a regression with deflated prices for a given year and one of the independent variables is a price index for a given sector, does it make any sense to 'deflate' this variable or somehow extract the content that might be related to the general economy (assuming I am deflating with a more agregated variable, like a consumer price index)? One might think of demand estimation or supply estimation, if that helps.</p>

<p>My first thought was that I shouldn't bother, but now I'm thinking of running an auxiliary regression with the agreggated price index and the sectoral price index as a dependent variable and save the residuals -- does that make sense?</p>

<p>Edit: Added some more intuition, as follows:</p>

<p>Think of an equation of a residual demand such as $q_t$$=$$\beta p_t$+$\epsilon_t$, where $q_t$ are the quantities, $p_t$ is the price and $\epsilon_t$ is an estochastic error. But since $Cov(p_t,\epsilon_t)≠0$ -- the price $p_i$ is inherently endogenous in a demand function because of the existence of another equation defining price and quantities, the supply equation --, one should estimate demand adequately through instrumental variables estimation. Eligible instruments for demand are supply shifters, such as the company cost. But one could also use some sort price index of a sector as an instrument, a sector that sells inputs to the company out of which you are estimating the residual demand. The thing is that this price index might be related to the price index that you are using for deflating your variables. In that situation, how do you extract these fluctuations related to the general economy out of your price index being used as an instrument?</p>
","<blockquote>
  <p>In that situation, how do you extract these fluctuations related to
  the general economy out of your price index being used as an
  instrument?</p>
</blockquote>

<p>Regress the sectorial price index on the general price index, and use as instrument in the demand equation the ""residuals plus estimated constant"" from the previous regression.  </p>

<p>These residuals will be by construction orthogonal to the general price index which indeed could be also a demand shifter, something that would invalidate the sectorial price index as an instrument.</p>

<p>As is the case with any time-series data, one should also deal with possible issues of non-stationarity, co-integration etc.</p>
","5649"
"Solving a maximization problem by substitution when the constraint is in implicit form","297","","<p>I am trying to understand how the first order conditions for an interior solution of a maximization problem were derived using the <em>substitution</em> method. </p>

<p>The problem is:
$$\max\limits_{x\ge0,y\ge0}P(a-x)+(1-P)(b-y)$$
subject to
$$Pf(x)+(1-P)f(y)=c$$
where: $a,b,c&gt;0$, $P\in (0,1)$, $f:[0,+\infty]\to[0,+\infty]$, increasing and strictly concave over its domain.</p>

<p>I can see how this is solved using a lagrangian to find from the first order conditions that $f'(x^*)=f'(y^*)$. Strict concavity of $f$ then implies $x^*=y^*$. But I'm at a loss as to how we can solve it by substituting the constraint in the objective function. Since $f$ is invertible, if $y$ did not appear in the constraint I would find $x$ from the constraint by inverting $f$ and substitute it in the objective function. Doing this here leads to complications that seem unnecessary for this simple problem. There has to be a simpler way that I cannot figure out: what is it? Thanks!</p>
","<p>Here are two methods. First method: the substitution can be made by inverting $f$. Since $f$ is strictly increasing and continuous, $f^{-1}$ is well-defined. The constraint can therefore be written
\begin{equation*}
x = f^{-1}\Big(\dfrac{c-(1-P)f(y)}{P}\Big)
\end{equation*}</p>

<p>The objective becomes
\begin{equation*}
\max_{y \geq 0}{P \Big[a-f^{-1}\Big(\dfrac{c-(1-P)f(y)}{P}\Big)\Big]+(1-P) (b-y)}
\end{equation*}</p>

<p>The derivative of this expression with respect to $y$ equals
\begin{align*}
&amp; (1-P) f'(y) (f^{-1})^{'}(\dfrac{c-(1-P)f(y)}{P})-(1-P) \\
= &amp; (1-P) \dfrac{f'(y)}{f^{'} \circ f^{-1}(\dfrac{c-(1-P)f(y)}{P})}-(1-P) \\
&amp; = (1-P) (\dfrac{f'(y)}{f'(x)}-1)
\end{align*}
And thus $f'(y^{*})=f'(x^{*})$ at the optimum.</p>

<p>Second method: since $f$ is invertible, we can do a change in variables and define $w=f(x)$ and $z=f(y)$. The problem then becomes
\begin{equation*}
\max_{w \geq 0, z\geq 0}{P(a-f^{-1}(w))+(1-P)(b-f^{-1}(z))}
\end{equation*}
subject to 
\begin{equation*}
P w +(1-P)z=c
\end{equation*}
Substituing $w=(c-(1-P)z)/P$ in the problem delivers
\begin{equation*}
\max_{z\geq 0}{P(a-f^{-1}(\dfrac{c-(1-P)z}{P})+(1-P)(b-f^{-1}(z))}
\end{equation*}
Differentiating with respect to $z$ yields the same solution.</p>
","16217"
"Optimal Random Bids","296","","<p><a href=""http://fivethirtyeight.com/features/can-you-win-this-hot-new-game-show/"">This question comes from this website that I peruse often.</a></p>

<blockquote>
  <p>Two players go on a hot new game show called “Higher Number Wins.” The two go into separate booths, and each presses a button, and a random number between zero and one appears on a screen. (At this point, neither knows the other’s number, but they do know the numbers are chosen from a standard uniform distribution.) They can choose to keep that first number, or to press the button again to discard the first number and get a second random number, which they must keep. Then, they come out of their booths and see the final number for each player on the wall. The lavish grand prize — a case full of gold bullion — is awarded to the player who kept the higher number. Which number is the optimal cutoff for players to discard their first number and choose another? Put another way, within which range should they choose to keep the first number, and within which range should they reject it and try their luck with a second number?</p>
</blockquote>

<p>This is either a very weird auction problem with symmetric players (I also assume the players are risk-neutral) or a very odd lotteries/game-theory game.</p>

<p>How would you approach this question mathematically speaking and what answer do you get for it? There's no prize for <em>me</em> getting the right answer to the site's riddle, I'm just curious. My intuition tells me that the optimal cutoff is 0.5, since you have a 50-50 chance of being higher or lower than your opponent's number, regardless of whether he/she repicks their random number or not, but I am not sure.</p>
","<p>First I will just show that the 0.5 (or $\frac{1}{2}$) cut-off point does not work as a symmetric equilibrium, then you can decide for yourself if you want to think about the problem or read the complete answer.</p>

<p>Let us denote the cut-off points by $c_x,c_y$. Suppose both players use the strategy $c = \frac{1}{2}$. Let us denote the numbers of player $x$ and $y$ respectively by $x_1$ and $y_1$ and their potential second number by $x_2$ and $y_2$. Suppose $x_1 = \frac{2}{3}$. By keeping this the probability that player $x$ wins is
$$
P\left(\frac{1}{2} \leq y_1 &lt; \frac{2}{3} \right) + 
P\left(y_1 &lt; \frac{1}{2}\right) \cdot P\left(y_2 &lt; \frac{2}{3}\right) =
\frac{1}{6} + \frac{1}{2} \cdot \frac{2}{3} = \frac{1}{2}.
$$
This also means that $\frac{2}{3}$ is <strong>the median of this distribution</strong>.</p>

<p>Now suppose $x_1 = \frac{1}{2}$. By keeping this the probability that player $x$ wins is
$$
P\left(y_1 &lt; \frac{1}{2}\right) \cdot P\left(y_2 &lt; \frac{1}{2}\right) =
\frac{1}{2} \cdot \frac{1}{2} = \frac{1}{4}
$$
But if he would discard $x_1 = \frac{1}{2}$ he has probability
$$
P\left(x_2 &gt; \frac{2}{3}\right) = \frac{1}{3}
$$
of winning. $\frac{1}{3} &gt; \frac{1}{4}$ so keeping $x_1 = \frac{1}{2}$ (and its environs) is not optimal therefore it cannot be an equilibrium move. </p>

<hr>

<p>SPOILER ALERT</p>

<p>If player $y$ has a cut-off $c_y$ and player $x$ draws $x_1 = c_y$ and keeps it the probability that player $x$ wins is
$$
P(y_1 &lt; c_y) \cdot P(y_2 &lt; c_y ) = c_y \cdot c_y = c_y^2.
$$
If player $x$ where to discard $x_1$ the probability that he wins is
\begin{eqnarray*}
P(y_1 \geq c_y) \cdot P(x_2 &gt; y_1) + P(y_1 &lt; c_y) \cdot P(x_2 &gt; y_2) &amp; = &amp; 
(1 - c_y) \cdot \left(1- \frac{1 + c_y}{2} \right) + c_y \cdot \frac{1}{2}
\end{eqnarray*}
Suppose there is a symmetric equilibrium, that is $c_x = c_y = c$. <br>
 (I don't think other equilibria exist but I didn't prove it.) <br> Since probability of winning is continuous in the value of $x_1$, the cut-off value $c$ is such that if $x_1 = c$ then the probability of winning is equal when $x_1$ is kept and when it is discarded. This means that
\begin{eqnarray*}
P(y_1 &lt; c) \cdot P(y_2 &lt; c) &amp; = &amp; P(y_1 \geq c) \cdot P(x_2 &gt; y_1)
+ P(y_1 &lt; c) \cdot P(x_2 &gt; y_2) \\
\\
c \cdot c &amp; = &amp; (1 - c) \cdot \left(1 - \frac{1+c}{2}\right) + c \cdot \frac{1}{2} \\
\\
c^2 &amp; = &amp; \frac{1}{2} - c  + \frac{c^2}{2} + \frac{c}{2} \\
\\
\frac{1}{2} \cdot c^2 + \frac{c}{2} - \frac{1}{2} &amp; = &amp; 0 \\
\\
c &amp; = &amp; \frac{\sqrt{5} - 1}{2}.
\end{eqnarray*}</p>
","10980"
"Solving an OLG model, value function iteration vs. projection (chebyshev polynomial)","295","","<p>I can't decide between using value function iteration or projection on chebyshev polynomials.</p>

<p>I'm inclined to use projection, however I need to compute (for welfare analysis) the value of the value function at some specific age.</p>

<p>Using the decision rules computed by projection and derived from FOCS is it possible to compute the expected lifetime discounted utility?</p>
","<p>You could solve for the value function ex-post from the Bellman equation. For simplicity, consider a deterministic dynamic programming problem (in OLG model, you'd have age as another state variable, but I'll abstract from that). If $x$ is state and its next-period value $x'$ is control, $U(x,x')$ is one-period utility and you have somehow obtained decision rule $x' = g(x)$, it must be the case that the value function satisfies</p>

<p>$$
V(x) = U(x,g(x)) + \beta V(g(x))
$$</p>

<p>This is a functional equation in $V()$ that could also be solved by projection method. Alternatively, you could iterate on the Bellman equation (on some grid over state space) just like in VFI, but skipping the optimization step (since you already know the optimal choice), and eventually the value function should converge.</p>
","1913"
"Why hasn't Quantative Easing created a surge in inflation, or hyperinflation?","294","","<p>From what I understand, Quantitative Easing (QE) is the buying, by the Central Bank, of bonds and other financial assets with high-powered money (or money created by the CB for this purpose).</p>

<p>If I remember correctly this ad-hoc creation of money was the main ingredient for hyperinflation.</p>

<p>So, why hasn't there been a surge in inflation?</p>
","<p>High-powered money is another term for the monetary base or MB.  MB represents all money created by the government.  However, that is not all the only source of money.  Banks are allowed to create money too.  Which is why higher aggregates like M2 and M3 are greater than MB.</p>

<p>Because bank money is greater than government money, it (and not MB) is more of a primary determinant to monetary inflation.  Pretend there is an economy of blue dollars and yellow dollars.  The blue are created by the government and the yellow by banks.  There are many more yellow dollars than blue dollars.  So when the supply of blue dollars goes up it doesn't matter as much because of the number of yellow dollars.</p>

<p>Bank money was being destroyed in the crisis which was actually creating deflationary pressures.  The collapse in higher monetary aggregates was offset somewhat by the surge in the monetary base.  </p>

<p>Now typically base money is used to create and leverage higher aggregates, but this was not the case during the crisis.  Because of liquidity concerns, banks curtailed monetary creation so this is why inflation did not happen.</p>
","10607"
"Game theory - Definition problem - Strategy vs Action","292","","<p>A one definition is given by :</p>

<blockquote>
  <p>Strategy is one of the possible actions of a player</p>
</blockquote>

<p>But I'm having a trouble. When working with games, We specify a strategy set $S$ and a strategy $s \epsilon S$. For instance consider a typical normal form game, battle of sexes for instance. We have $2$ strategies for each player so the set $S$ has two elements. According to the definition here what would be the actions? What is a ""possible action""?</p>

<p>I'm asking this because in the definition of Bayesian games we are given an Action set instead of a strategy set. Can anyone clear things up to me?</p>
","<p>I had the same question few weeks ago. I attach the link below that may help you, but here is the approach I took to solidify the difference.</p>

<p><a href=""https://economics.stackexchange.com/questions/15747/when-action-and-strategy-differ-in-game-theory/15749#15749"">When action and strategy differ in game theory</a></p>

<p>Don't associate the distinction between action and strategy with whether the game is in normal form or extensive form or sequential or not. This can cause more confusion. </p>

<p>When you want to define strategy, always think of ""contingency"".</p>

<p>Action is a set of possible things you can do when you are called upon to move. For example, suppose you want to sell a used car as dealer. As seller, what is it that you CAN DO when you are ""called upon to move""? Simple: offer high price or low price.</p>

<p>But you immediately realize things can get complicated if, say, dealer has more information on the car's condition. You might suspect that car behind the dealer is a good used card or lemon. Although you still get to offer high price or low price at the end of the day, as player of the game, you must set a contingency plan when the car is good or lemon.</p>

<p>Harsanyi introduces ""nature"" to do exactly this. The condition of car is simple: good or lemon. This is described as the state space of the game. Both players, seller and buyer, understand the ex-ante probability distribution over this state space, meaning you and potential buyer know the probability you get good car or lemon. Therefore, as dealer, you would have action space $A_1=\{H,L\}$ indicating offering high or low price. However, your strategy space would be $S_1=\{(H,h),(H,l),(L,h),(L,l)\}$ where first entry of the pair is your action when the car is good and second entry is your action when the car is lemon. It is a game plan laid out for you in every possible scenario.</p>

<p>One good exercise may be to see if you can construct the strategy set for buyer if she doesn't observe the condition (i.e. state) of the car the nature draws.</p>
","16578"
"Nash Equilibrium of modified Keynes' beauty contest","292","","<p>Recently I conducted a small game among students of our institute. The game was based on Keynes' beauty contest game. The participants had to guess a number between 0 to 100 and the participant whose guess was closest to 2/3rd of the average of all guesses would win the game. </p>

<p>The twist was this: We also awarded money to the winner in each round. The money was a multiple say, 5x of the final number (2/3rd of the average). </p>

<p>What will be the Nash Equilibrium of this modified game. The solution to the original problem is of course everybody choosing 0. Will the equilibrium shift in the above described game. Consider n to be greater than 30. 
Any help would be appreciated. </p>
","<p>Assume the players have to choose integers, otherwise a best response may not exist. Let the payoff of winning be $\alpha\cdot[\frac23\text{ of the average}]$, $\alpha&gt;0$. Consider the two player (A and B) case, and let's verify whether choosing above $0$ is optimal. </p>

<p>Suppose A chooses $x&gt;0$. Then B can guarantee a win by choosing $x-1$, since $\frac23(x-\frac12)$ is closer to $x-1$ than to $x$. However, if B chooses $0$, A choosing $x=1$ is a best response (A gets zero anyway). So we will have a NE where not both players choose $0$, and the one who chooses $0$ gets positive payoff.</p>

<p>This equilibrium can be generalized to the $n$-player case. Let $n-1$ players choose $0$ and the remaining one choose $1$. In this equilibrium, those who choose $0$ would share the positive payoff (each gets $\frac{\alpha}{n-1}\cdot\frac23\cdot\frac1{n}$). They are best responding because choosing any $x&gt;0$ would imply zero payoff. The one who chooses $1$ is also best responding since he gets zero anyway. (Of course this is not the only equilibrium. There is also one where everyone chooses $0$, which is obvious.)</p>

<p>Admittedly, the above equilibrium relies crucially on the assumption that players are only allowed to choose integers. But this is due to the fact that payoff is a function of the choices (compared to a fixed amount in the original version of the problem). Suppose players are allowed to choose any real number in $[0,100]$. Then if A chooses $x&gt;0$, B would best respond by choosing $x-\epsilon$, where $\epsilon=\min\{y:y&gt;0\}$ (B would win of course, but she also wants to maximize her earning by making her choice as close to A's as possible). 
However, such an $\epsilon$ does not exist. Therefore, the only equilibrium is for everyone to choose $0$. </p>

<p>The intuition is this: however large the winning is, you don't get it if you don't win. But winning requires that you choose small. So the incentive to win overwhelms the incentive to win big.</p>
","14177"
"Convexity of Walrasian Demand","291","","<p>A follow up to my <a href=""https://economics.stackexchange.com/questions/8633/linear-expenditure-system-of-demands-derivation-help/8634"">previous question</a>:</p>

<blockquote>
  <p>Given $u(x) = (x_1-b_1)^\alpha (x_2-b_2)^\beta(x_3-b_3)^\gamma$</p>
</blockquote>

<p>and ending up with from a maximization that</p>

<p>$$x(p,w) = (b_1, b_2, b_3) + (w - (b \cdot p))\left(\frac{\alpha}{p_1},\frac{\beta}{p_2},\frac{\gamma}{p_3}\right)$$</p>

<p>How do I show that $x(p, w)$ is convex? I already showed that it is homogeneous of degree zero and satisfies Walras' Law. The book from Mas-Colell says that the solution is obvious, but I have not gotten anywhere with it. My setup for showing convexity is that I want to show:</p>

<p>$$x(tp + (1-t)p', tw + (1-t)w') &lt; tx(p,w) + (1-t)x(p',w')$$</p>

<p>But I'm not finding anyway to simplify this expression to show it is true. Any help would be appreciated, as I feel like I am missing something very obvious.</p>
","<p>I am not sure whether the question asks about the function being convex, or simply the demand correspondence/function being a convex set. The latter is often asked and if that is the case here is an answer.</p>

<p>This is a general answer to your question which may be more useful to you and future readers than a specific one.</p>

<p>The following theorem holds in general:</p>

<p>Theorem: If preferences are convex, then the marshallian demand x(p,w) is a convex set for every p>>0 and $w \ge 0$.
Note: p>>0 here means that every element of the price vector is strictly positive.</p>

<p>Proof:</p>

<p>The Budget set $B(p,w) \equiv \{ x \in \mathbb{R}_+^n:px \le w \} $ is a convex set.</p>

<p>If two points $ x, x' \in x(p,w )$, then x ~ x' (the consumer must be indifferent between the two as they are both part of x(p,w), i.e. his best choice. If one of them would be better than the other, then only the best one would be part of x(p,w) as the marshallian demand is derived from maximization.)</p>

<p>For all $\alpha \in [0,1]$ we have that $\alpha x + (1-\alpha)x' \in B(p,w)$ by convexity of B(p,w). Furthermore, $\alpha x + (1-\alpha)x'\succeq x$ by the convexity of preferences. Therefore $\alpha x + (1-\alpha)x'\in x(p,w)$
Q.E.D.</p>

<p>Your preference relation is convex, so the theorem applies and your set x(p,w) is convex. Note that a preference relation is (strictly) convex if and only if the utility function  is (strictly) quasiconcave. Your utility function as far as I can see is concave, which implies it is quasiconcave, which implies convex preferences.</p>

<p>Further note that if preferences are strictly convex, then x(p,w) is single-valued for every p>>0 and $w \ge 0$. Hence in that case x(p,w) would be a convex set as a point is a convex set.</p>
","8642"
"because bitcoins do not generate earnings, then (it is a ponzi scheme)?","290","","<p>What does the author mean with:</p>

<blockquote>
  <p>Since Bitcoins do not generate any actual earnings, they must
  appreciate in value to ensure that people are willing to hold them.</p>
</blockquote>

<p>Why <strong>must</strong> they appreciate in value?  Is the assumption that people <strong>must</strong>  hold bitcoin?  Why is it necessary or required to hold bitcoin?</p>

<p>Or, is the author saying ""eh, what goes up must come down.""  Instead, the article seems argue that bitcoin will go to a ""value"" of zero:</p>

<blockquote>
  <p>...Bitcoins are the most demonstrably valueless financial asset ever
  created...</p>
</blockquote>

<p>Isn't one of the criticisms to using gold as a currency that it's then tied up as a currency and not being <strong>used</strong> functionally?  Does the inherent valuelessness of bitcoin, or any other cryptocurrency, make it suitable for transactions?</p>

<p>Sure, bankers hold currency, but few individuals actually hold currency directly.  Generally money is spent or invested in quick order.  Which seems not directly related to adoption of bitcoin (or other cryptocurrency) for <em>transactions</em>.</p>

<p>What is the reasoning behind the notion that <em>because</em> bitcoin has no intrinsic value therefore it's not suitable as currency?  Or, to put another way, if no one ""held"" US dollars, but simply used them to spend or invest, would that invalidate it as a currency for buying chickens? </p>

<p><a href=""http://nationalinterest.org/commentary/the-bitcoin-bubble-bad-hypothesis-8353?page=2"" rel=""nofollow"">http://nationalinterest.org/commentary/the-bitcoin-bubble-bad-hypothesis-8353?page=2</a></p>
","<blockquote>
  <p>What is the reasoning behind the notion that because bitcoin has no intrinsic 
  value therefore it's not suitable as currency? Or, to put another way, if no one 
  ""held"" US dollars, but simply used them to spend or invest, would that 
  invalidate it as a currency for buying chickens?</p>
</blockquote>

<p>The author addresses the difference between bitcoin and fiat currency (such as greenbacks):</p>

<blockquote>
  <p>Because of their power to tax, governments can make money by fiat, simply by 
  declaring their willingness to accept that money in repayment of tax debts.</p>
</blockquote>

<p>I'll be honest and admit that I hadn't heard that argument before and off the cuff, it makes sense.  Because the government can impose taxes and require they be paid in dollars, the demand for dollars will exist at least as long as the government has the power to tax.</p>

<p>I find this part of the argument to be pretty weak:</p>

<blockquote>
  <p>As with any kind of asset used as currency, from gold to tobacco to U.S. 
  dollars, Bitcoin is valuable as long as people are willing to accept it. But 
  in all of these examples, willingness to hold the asset depends on the fact 
  that it has value independent of that willingness. Tobacco can be smoked or 
  chewed, gold can be used to fill teeth or make jewellery...</p>
</blockquote>

<p>The problem here is that the demand of gold for jewelry and other industrial purposes is minuscule and can't come anywhere close to justifying the price of gold (even in down markets.)  If we believe this argument, the price of gold is going to go down so far that it might as well be zero.</p>

<p>The argument that I find convincing for why gold has been used as money for so long is that it's physical properties make it extremely suitable for that purpose.  It's not consumable (e.g. you don't put it in your pipe and smoke it.)  It is extremely stable: the list of fluids that will dissolve it is extremely short, it doesn't rust or sublimate.  It is easy to smelt.  It's heavy; making small amounts easy to measure.  It's purity is relatively easy to determine.  </p>

<p>It created a universal standard against which the value of other things could be measured so that people didn't have to determine how many chickens was a cow worth.  Even if you were bartering, the relative value of the items could be determined based on their price in gold.  As evidence of this it is said that the discovery of the <a href=""https://en.wikipedia.org/wiki/Touchstone_(assaying_tool)"" rel=""nofollow"">touchstone</a> sparked the explosion of trade in the ancient world.  Nowadays very few people accept gold as payment so the demand for gold seems to be mostly fear-driven.  People believe that if fiat currencies falter or fail, gold will return to it's position as the universal measuring stick of value.  Only time will tell whether they are right.</p>

<p>Where does bitcoin fit into this?  It seems to me part the demand for bitcoin comes from illegal activity.  As long as hackers continue to demand ransoms in bitcoin, it's a bit like fiat currency.  It's not a measure of value.  It's value is measured in terms of fiat currencies like dollars.  Bitcoin meets a need: a digital equivalent of cash.  Technically it is traceable but it more or less fits that need.  The biggest concern for bitcoin should be is that there's nothing inherent about it that makes it unique.  Unlike gold, another competing system could be created at any time.  There's been talk of a bitcoin 'fork'.  If someone were to come up with a better system (say something that is impossible to trace) it might very well drop to zero.</p>
","12840"
"How do you determine the strict core in a matching game?","289","","<p>So I have a game in which home owners prefer certain other's homes.  The owners are A, B, C, and D with a, b, c, and d referring to their respective homes.  They each prefer homes according to the ranking </p>

<pre><code>A: bdac
B: cadb
C: dbca
D: acbd
</code></pre>

<p>I've read an article by Shapley about an algorithm to find one assignment in the strict core, but I'm asked to ""determine the strict core"" which I assume means finding <em>all</em> assignments in the strict core.  How does one do that?  </p>

<p>In case it's of any use, I'll describe the algorithm in the Shapley article.  Make a graph of people's top preferences and select ""top cycles"", then delete the people who were in top cycles and do it again.  Repeat the process until everyone has occurred in a top cycle and every cycle represents a permutation of people and houses that will be in the strict core.  </p>
","<p>When preferences are strict, the strong core is unique and the top-trading cycle procedure (TTCP) is the unique mechanism yielding the strong core allocation. Here are the highlights.</p>

<p><strong>Lemma 1</strong>: Let $x$ be the allocation generated by the Top-Trading Cycle Procedure. Then $x$ is in the strong core. </p>

<p><strong>Lemma 2</strong>: Let $P$ be the set of players, $\Omega = \{ \omega^{i} = i : i \in P \}$ be the set of initial allocations, and $\succ^{i}$ be the set of strict preferences. We have $(P, \Omega, (\succ^{i})_{i=1}^{|P|})$ as the instance of the house allocation problem. The strong core is unique.</p>

<p><strong>Proof</strong>: Suppose to the contrary that there exist two allocations $x, y$ in the strong core and suppose $x$ is the allocation returned by the TTCP. As $x \neq y$, $S = \{ i : x_{i} \neq y_{i} \}$ has at least two elements. Observe that if there is a player $i \in S$ such that $x_{i} \succ^{i} y_{i}$, then $x_{i}$ can form a weakly improving coalition with the other players in $x_{i}$'s cycle whose allocations are the same in $x$ and $y$. As preferences are strict, every player in $S$ strictly prefers either $x$ or $y$. We construct a weakly improving coalition to block $y$.</p>

<p>Let $i \in S$ such that $y_{i} \succ^{i} x_{i}$. Let $i$ be matched in iteration $k$ of the TTCP. Since $y_{i} \succ^{i} x_{i}$, we have that player $i$ prefers some other house $j$ to $x_{i}$ and that $j$ was assigned in a previous iteration by the fact that $x$ belongs to the strong core. And so using the allocation $y$ displaces the player who received house $j$ under the TTCP. As preferences are strict, each player who received a house when $j$ was allocated under the TTCP can form a weakly improving coalition to block $y$. And so the fact that $S \neq \emptyset$ implies that $y$ is not in the strong core. QED.</p>

<p>I actually have a blog entry going into more detail about this: <a href=""https://michaellevet.wordpress.com/2015/06/01/algorithmic-game-theory-house-allocation-problem/"" rel=""nofollow"">https://michaellevet.wordpress.com/2015/06/01/algorithmic-game-theory-house-allocation-problem/</a></p>
","6839"
"Solution Method for Infinite-Horizon Maximization Problem","289","","<p><em>Full disclosure</em>: this problem was part of a final exam that none of our class could really solve definitively. Below the general form is a specific utility function we worked with that I'll try to replicate my work for. Any help on the solution method would be good; specifically, it seems Euler's equations/steady states would be better for this particular form of question rather than using a Bellman, but any guidance on either method would be appreciated.</p>

<hr>

<p>Suppose a representative agent is solving</p>

<p>$$
\begin{align}
&amp; \max_{\left\{ c_t, w_t \right\}^\infty_{t=0}} \sum_{t=0}^\infty \beta^t u(c_t) \\
&amp; \text{s.t.} \\
&amp; w_t = Rw_{t-1} - c_t \\
&amp; c_t \geq 0 \\
&amp; w_t \geq 0 \\
\end{align}
$$</p>

<p>For all $t$, and $w_{-1}$. Additionally, $0 &lt; \beta &lt; 1$, $R &gt; 1$. </p>

<p>$c_t$ is consumption at time $t$, and $w_t$ is wealth at the end of time $t$. $\beta$ is a discount factor.</p>

<p>Let 
$$u(c_t) = \phi \mathrm{e}^ {\theta c_t^p}$$
where $\phi, \theta, p$ are constant parameters.</p>

<blockquote>
  <p>My first question is what values of the constants $\phi, \theta$, and $p$ are needed to ensure that $u(c_t)$ are strictly increasing and strictly concave in $c_t$, for all values of $c_t$. <strong>Later on the problem asks us to assume those above conditions.</strong></p>
</blockquote>

<p>So taking the first and second derivative of $u(c_t)$ gives us:</p>

<p>$$
\begin{align}
u'(c_t) &amp; = \phi \theta p c_t^{p-1}\mathrm{e}^ {\theta c_t^p} \\
u''(c_t) &amp; = \phi \theta p(p-1) c_t^{p-2}\mathrm{e}^ {\theta c_t^p} + \phi \theta ^2 p^2 c_t^{(p-1)^2}\mathrm{e}^ {\theta c_t^p} \\
&amp; = \phi \theta p c_t^{p-1} \mathrm{e}^{\theta c_t^p}\left[ \frac{p-1}{c_t} + \theta p c_t^{p-1} \right] \\
\end{align}$$</p>

<p>So $u'(c_t) &gt; 0$ in order to satisfy the strictly increasing constraint. $u''(c_t) &lt; 0$ must be true for strict concavity. I suggested that $\phi, \theta &gt; 0$ and $p = 1$ for this to be true. I'm not sure how this ugly second derivative can be simplified to find the appropriate conditions.</p>

<hr>

<p>After doing this, we had to express Bellman's equation and Euler's equation for the problem.</p>

<p><strong>Bellman:</strong></p>

<p>$$\boxed{V(w) = \max_\tilde{w} \left[ \phi \mathrm{e}^{\theta (Rw - \tilde{w})^p} + \beta V(\tilde{w})\right]}$$</p>

<p><strong>Euler:</strong></p>

<p>$$\boxed{\sum_{t=0}^\infty \beta^t (Rw_{t-1} - w_t)^p = \cdots \beta^t (Rw_{t-1} - w_t)^p + \beta^{t+1}(Rw_t - w_{t+1})^p + \cdots }$$</p>

<hr>

<p>Finally, we got to say that $\beta \cdot R = 1$. We were then asked to find the value function and optimal decision rules for our choice variable(s). I used the Bellman to try to solve the problem, where I guessed the function form of the value function:</p>

<p>$$V(\tilde{w}) = F \mathrm{e}^{M\tilde{w}} + H$$</p>

<p>where $F, M, H$ are undetermined coefficients. After substituting this into the Bellman and putting in appropriate arguments, taking the derivative to get an optimal choice, substituting the optimal choices back into the Bellman, I got stuck trying to solve for $F, M, H$ in a way that would give me a sensible consumption choice at the end.</p>

<p>The little trick with $\beta R = 1$ is supposed to make consumption constant across all periods, so I assume that the point of getting the Euler's equation is so we can solve it using steady states and make life easier, but my algebra there hasn't borne any fruit either it seems.</p>

<blockquote>
  <p>For the dynamic programming method, have I set the functional form of the value function correctly? If not, what should be the guess? And finally, how does all the nasty algebra work out?</p>
  
  <p>For the steady states method, what does the path of wealth look like? Does it end up constant as well? (I suppose that question applies for the Bellman approach as well.)</p>
</blockquote>

<p>(If it's pedagogically interesting or useful--or if you don't trust that I'm not begging for homework help--I can show my work for both methods.)</p>

<p>Please let me know if anything is unclear.</p>
","<p>Your first question (regarding constraints on the parameters) can be answered through first and second derivative analysis. In order to satisfy strictly increasing, we need $u'&gt;0$ and to satisfy strictly concave, we need $u''&lt;0$. What does this actually mean?</p>

<p>$$u'(\frac{}{})=\phi p\theta c_t^{p-1}e^{\theta c_t^p}&gt;0$$
Since we know that $c_t^{p-1}e^{\theta c_t^p}&gt;0$ automatically, this reduces to:
$$\phi p\theta&gt;0$$
Next:
$$u''(\frac{}{})=\big[\phi p\theta (p-1) c_t^{p-2}+\phi p\theta c_t^{p-1}\big]e^{\theta c_t^p}&lt;0$$
Because we know that $e^{\theta c_t^p}&gt;0$ and $\phi p\theta c_t^{p-1}&gt;0$, this must mean: 
$$\phi p\theta (p-1)c_t^{p-2}&lt;0$$</p>

<p>By virtue of $(1)$ and the fact that $c_t^{p-2}&gt;0$, we know that:
$$p-1&lt;0$$
or
$$p&lt;1$$
Now,  what we can do is think about it critically. If $p=0$ then utility does not change when consumption changes. This is clearly untrue. If $p&lt;0$ then utility decreases when consumption increases which also seems incorrect. Therefore, our condition for $p$ is:
$$0&lt;p&lt;1$$
Now, what does this mean for $\phi \;\text{and}\; \theta$? It means: 
$$either\quad\phi , \theta&gt;0\quad or\quad \phi ,\theta&lt;0$$
Now, this looks like a typical exponential utility function, so we know that in these cases, both the coefficient for the exponent and the coefficient in the power will be negative (I will not bother proving this as I am sure it is somewhere in literature). Therefore we have the following three conditions for the parameters:
$$0&lt;p&lt;1$$
$$\theta &lt;0$$
$$\phi &lt;0$$</p>

<p>Now, the next step is to show that we do in fact have constant consumption. Taking our Euler Equation approach, we substitute in the constraint and take two terms in the sum,
$$...+\beta^t\phi e^{\theta (Rw_{t-1}-w_t)^p}+\beta^{t+1}\phi e^{\theta(Rw_t-w_{t+1})^p}+...$$
Differentiating w.r.t $w_t$ and doing some simplifying, we get:
$$(Rw_{t-1}-w_t)^{p-1}e^{\theta(Rw_{t-1}-w_t)^p}=\beta R(Rw_t-w_{t+1})^{p-1}e^{\theta(Rw_t-w_{t+1})^p}$$
Substituting consumption back in, we get:
$$c_t^{p-1}e^{\theta c_t^p}=\beta Rc_{t+1}^{p-1}e^{\theta c_{t+1}^p}$$
Now, since it is specified that $\beta R=1$ in the problem, we can see that the only way this equality holds is if $c_t=c_{t+1}=c^\star$</p>

<p>What does this mean for wealth? Will wealth also be constant? Well, let's conduct a thought experiment and suppose not. Suppose wealth increases each period ($w_{t+1}&gt;w_t\;\forall t$). This implies that as $t\rightarrow \infty$, we will see wealth grow to be infinite as well, which is wasteful and would not satisfy the transversality condition. Now suppose wealth is decreasing ($w_{t+1}&lt;w_t\;\forall t$). We can clearly see that eventually we will not have enough wealth to sustain constant consumption. Therefore we can see that $w_t=w_{t+1}=w^\star$. Now, what are the relationship between these two? Well, going back to our condition for wealth, we can see
$$w^\star=Rw^\star-c^\star$$
Rearranging, we get:
$$c^\star=(R-1)w^\star$$ </p>

<p>Because we have steady state wealth, we know that $w^\star=w_0$</p>

<p>Now, knowing that we have steady state consumption, we know our utility function will be the same value for every period (discounted by $\beta$). So our value function simply becomes:</p>

<p>$$V(w)=\frac{\phi e^{((R-1)w_0)^p}}{1-\beta}$$ </p>

<p>Therefore, we do not need to use the method of undetermined coefficients to find the value function.</p>
","12185"
"How to interpret ""desired significance level""?","287","","<p>I was studying threats to internal validity from Stock and Watson's Introduction to Econometrics 2nd edition, chapter 14 Assessing studies based on multiple regression.</p>

<p>The textbook says ""hypothesis tests should have the <strong>desired significance level</strong> (the actual rejection rate of the test under the null hypothesis should equal its desired significance level). and confidence intervals should have the <strong>desired confidence level</strong>.</p>

<p>How should I interpret this short paragraph?</p>

<p>What I think it means is that the hypothesis tests should have appropriate/not-too-off-tract significance level. But what is desired confidence level? And why does these conditions have to do with threats to internal validity?</p>

<p>Pardon my poor understanding...</p>

<p>Thanks in advance for your help!</p>
","<p>I am not sure what you mean by ""appropriate significance level.""</p>

<p>Basically how sure you want to be is your choice. A frequently used analogy is the presumption of innocence. You are considered guilty only if this is proven beyond <strong>reasonable</strong> doubt. But what exactly is reasonable?
This is for you to decide. If you require very strong evidence then the probability of making a false positive conclusion (Type I error) decreases. But this will increase the probability of making a false negative conclusion (Type II error).
In the presumption of innocence analogy: If you change the law in a way that will require more evidence for a conviction, you will send fewer innocent people to jail (Type I), but you will also let more guilty ones go (Type II).</p>

<p>The significance level is the probability of a Type I error occuring.</p>

<p>In some situations you can perform a cost benefit analysis. In quality control you may be able to determine the cost of the damage caused by a malfunctioning part and then compare this to the cost of throwing away a properly functioning part. Using these you can actually calculate a cost minimizing significance level. However in other situations this is not feasible, or sometimes not even desirable. Then you have to make your own decision about the significance level.</p>

<p>In econometrics the most frequently used significance levels are 0.1%, 1% and 5%. My understanding is that this is a rule of thumb and there is actually no calculation behind it. (I could be wrong.) <br>
Given some data you might say that ""the findings are significant on the 5% level but not on the 1% level,"" or you can simply give the p-value, this is what is usually done.</p>
","5219"
"Would a world-wide currency be a good idea?","286","","<p>While every country has it's own political ideals, enforcing laws and rules, in an ever more globalized world, I believe the idea of fragmented economy is limiting big growth opportunities while creating a lot of unnecessary problems and bureaucracy around the world. So would changing to a globalized currency model be a good idea?</p>

<h2>The model</h2>

<p>A single currency would require an entiity whose would control it and be responsible for it. While we could create a new one, we might as well just use an already existing entity to be responsible for it, like the United Nations. Picking the UN to regulate this currency world wide (or at least to the big list of <a href=""http://www.un.org/en/members/"" rel=""nofollow noreferrer"">State nations that are part of it</a>), would give us the opportunity to add an extra layer to the government layers on top of the Nation layer, similar to what the European Union does.</p>

<p><img src=""https://i.stack.imgur.com/g0VbY.png"" alt=""enter image description here""></p>

<p>This would allow the United Nations not only to suggest rules, like the <a href=""http://www.un.org/en/documents/udhr/index.shtml"" rel=""nofollow noreferrer"">Human Rights</a>, but to enforce them as law to its member states.</p>

<h2>The need</h2>

<p>As mentioned before, we are living in a world more globalized every day. Some people work to different countries other than the ones they live in through the internet. This creates a currency exchange problem, where he is removing currency power from the country he's working for and giving it to the country he lives in, effectivelly lowering the first's value and raising the second's value. A single currency could solve this problem and also getting out of the way the whole exchange problem from the middle, and in some cases, the international bank transfer bureaucracy.</p>

<p>A single currency with an enforing entity controling entity could use this power to help countries in the desperate need to grow, I'm thinking about places like Zimbabwe, Niger and Ethiopia. By retrieving in the form of taxes a percentage of each nation's Gross Domestic Product (let's say, 3%?), summing it all up, then averaging it by the number of member states, and then redistributing this to each country, we would be in fact spreading resources from wealthy parts of the world to the poorest in a fair way. Everyone contributes as they can so a few gets back. To avoid countries which could use this system to just sit back doing nothing, waiting for the money to come in, their governments are obligated to use this money to invest in the country's industries (or whatever are the country's activities which make money)</p>

<p>Of course, this is just a simple idea which I didn't develop, it can have much more potential and bring it's own problems, that's why I'm posting it here, so we can discuss about them. Also I'm sorry for my weird english and terms used, it's not my main language and I'm not an economics student, but I hope it's understandable.</p>
","<p>I agree with the members that have voted to close, but I felt obliged to point out an important confusion in the question. The OP writes</p>

<blockquote>
  <p><em>""A single currency with an enforcing entity controlling entity could use this power to help countries in the desperate need to grow,... By
  retrieving in the form of taxes a percentage of each nation's Gross
  Domestic Product... and then redistributing this to each country, we
  would be in fact spreading resources from wealthy parts of the world
  to the poorest in a fair way.""</em></p>
</blockquote>

<p>It appears therefore that the OP focuses on issues of global income/wealth inequality, and he thinks that, under a common currency, redistribution would be easier... </p>

<p>...The OP fails to see that, <em>in order to have a global currency</em>, it would take a ""geopolitical will"" from the parties involved, which, if it existed, the contribution of a common currency as a ""redistribution facilitator"" would be negligible.  </p>

<p>One important reason of why we do not have a global common currency, has to do with the fact that we do not feel that much ""connected"", truly ""parts of a single whole"". Hence, wealth redistribution to the extent imagined by the OP <em>is not something universally desired</em>. Because if such a sense of being part of a single whole was the dominant flavor of human existence, the desire to redistribute would flow rather naturally from it, and then it could actually happen whether we had a common currency or not.</p>

<p>Now I am voting to close also.</p>
","5500"
"Weak axiom of Revealed Preference application","285","","<p>The following is a problem I am dealing with related to Weak Axiom of Revealed Preference. I have given my solution below to the situation. What I am not getting is how is WARP not violated?</p>

<p>A law firm looking to hire to fill three positions gets applications from Andrew, Barbara and Celia.</p>

<p>The law firm's set of alternatives is the set of possible hiring decisions:</p>

<p>$ X = \{ \phi, \{a\}, \{b\}, \{c\}, \{a,b\}, \{b,c\}, \{a,c\}, \{a,b,c\}  \} $</p>

<p>For any $Y \subset \{a,b,c\}$, define the power set of Y as</p>

<p>$ 2^{Y} \equiv \{Z | Z \subset Y \}$.</p>

<p>$ 2^{Y}$ is the set of hiring decisions that the firm can make when it receives applications from the lawyers in Y.</p>

<p>The law firm's budget sets $ B \in \mathcal{B} $ are the sets of hiring decisions it can make after receiving applications from some combination of Andrew, Barbara and Celia :</p>

<p>$\mathcal{B} = \{2^{Y} |Y \subset \{a, b, c \} \}$</p>

<p>1) When it receives applications from Andrew and Barbara, it will choose to hire Barbara (and not Andrew):-</p>

<p>$ C(2^{\{a,b\}}) = \{b\} $</p>

<p>2) When it receives applications from Barbara and Celia, it will choose to hire Celia (and not Barbara):</p>

<p>$ C(2^{\{b,c\}}) = \{c\} $</p>

<p>The following is the problem I am confused in :
Q) What restrictions does the weak axiom place on the firm's hiring
decision $C(2^{\{a,b,c\}})$ when it receives applications from Andrew, Barbara and Celia?</p>

<p>My Solution: </p>

<p>According to Mas-Colell et al (Definition 1.C.1) , the Weak Axiom of Revealed Preference says that if x is ever chosen when y is available then there can be no budget set containing both alternatives for which y is chosen and x is not.</p>

<p>So based on my understanding of WARP, in my situation above, when Andrew and Barbara apply the firm chooses Barbara , i.e. 
$ Barbara \succsim_R Andrew$
and when Barbara and Celia apply, the firm chooses Celia i.e. :
$ Celia \succsim_R Barbara $</p>

<p>Here we see that since Barbara is not chosen over Celia , WARP is violated. Because WARP would imply that Barbara is chosen everywhere when Barbara is a choice in the set. So when Andrew , Barbara and Celia apply, and WARP violates the above relation given , the firm would hire only Andrew.</p>

<p>What I am not getting is how is WARP not violated?</p>
","<blockquote>
  <p>Because WARP would imply that Barbara is chosen everywhere when Barbara is a choice in the set.</p>
</blockquote>

<p>This is not true. Instead WARP would say that <strong>it is not possible for Andrew to be chosen whenever both Andrew and Barbara are in the choice set</strong>, which is different than your claim above.</p>

<p>Just because $b$ is chosen from the set $\{a,b\}$ doesn't mean that $b$ should <em>always</em> be chosen, e.g. from the set $\{b,c\}$. It just means that $b$ is revealed-preferred to $a$, but it doesn't mean that $b$ is preferred to all other possible alternatives (in particular, $c$). For example, the preference $c\succ b\succ a$ is perfectly consistent with the revealed choice pattern of the firm.</p>

<p>Write out the two conditions explicitly: 
$$
\begin{align}
C(\color{red}{\varnothing},\color{red}{\{a\}},\{b\},\color{red}{\{a,b\}})&amp;=\{b\}\tag{1}\\
C(\color{red}{\varnothing},\color{red}{\{b\}},\{c\},\color{red}{\{b,c\}})&amp;=\{c\}\tag{2}
\end{align}
$$
$(1)$ just says that whenever the four choices --- hire no one, hire $a$ only, hire $b$ only, hire both --- are present, the firm hires $b$ only. 
Likewise, $(2)$ says whenever the four choices --- hire no one, hire $b$ only, hire $c$ only, hire both --- are present, the firm hires $c$ only. 
These two are consistent with WARP (for $(1)$, the x in your quoted definition is $a$ and y is $b$; for $(2)$, x is $b$ and y is $c$). </p>

<p>For restrictions on $C(2^{\{a,b,c\}})$, writing it out explicitly, we get 
$$
C(\color{red}{\varnothing},\color{red}{\{a\}},\color{red}{\{b\}},\color{black}{\{c\}},\color{red}{\{a,b\}},\color{black}{\{a,c\}},\color{red}{\{b,c\}},\color{black}{\{a,b,c\}})=\{\{a\},\{a,c\},\{a,b,c\}\}
$$
where the elements colored in red are revealed to be inferior according to $(1)$ and $(2)$.</p>
","18505"
"Demand estimation with a lagged dependent variable","284","","<p>Suppose I have the following structural equation for demand estimation in time-series:</p>

<p>$$q_t=\beta_0+\beta_1\hat{p_t}+\beta_2incom_t+\beta_3q_{t-1}+\epsilon_t$$</p>

<p>Where $q_t$ stands for the quantity of the product, $\hat{p}$ stands for the instrumented price with supply shifters, $incom_t$ stands for income, $q_{t-1}$ stands for the lagged quantity and $\epsilon_t$ are the random residuals. All the betas are estimated coefficients -- say, through two-stage least squares. All variables are log-transformed too.</p>

<p>Suppose also that the lagged variable seems to solve the problem of autocorrelation between the residuals and its coefficient is also significant. Suppose also that the model passes through all the necessary tests for a viable two-stage least squares estimation -- the sargan test is ok, the instruments are strong in the first stage etc.</p>

<p>Knowing this, what are the possible problems of having a lagged variable in your estimation? Does it change any interpretation of the elasticity ($\beta_1$)? I understand that I could also have some sort of long-run inferred elasticity if I set $q_t=q_{t-1}$ after estimating the coefficients of the equation (Am I wrong?).  </p>
","<blockquote>
  <p>Does it change any interpretation of the elasticity ($β_1$)?</p>
</blockquote>

<p>You walk into the firm where you work as an analyst, and the Sales Director calls and asks ""I want to raise the price $10\%$ today. How will demand be affected <em>in percentage terms</em>?</p>

<p>Well, you don't expect income to have changed from one day to the next, and what was demanded yesterday -it was yesterday. So the only <em>variable</em> (for today) in the equation is price, and the best you can say is ""I expect a $(10 \times \hat \beta_1) \% $ effect"".</p>

<p>So it is the short term price elasticity of demand, <em>irrespective</em> of the fact that the <em>level</em> of demand is determined by other factors also, lagged demand included.</p>

<blockquote>
  <p>I understand that I could also have some sort of long-run inferred
  elasticity if I set $q_t=q_{t−1}$ after estimating the coefficients of the
  equation.</p>
</blockquote>

<p>Yes, either in an old fashioned ""deterministic"", $q_t=q_{t−1}$ way, or in a stochastic, $E(q_t) = E(q_{t−1})$ ""mean-stationary"" way.</p>

<p><strong>Assume now that demand is already mean-stationary according to your analysis , and you get the same question from the Sales Director as before. Will your answer change compared to the previous one?</strong></p>

<p><strong>ANSWER</strong>  </p>

<blockquote class=""spoiler"">
  <p>  <strong>The answer to the Sales Director should not change</strong>, because <em>you can</em> <em>condition</em> on the given and known past, for a more accurate (= focused on the specific situation) answer so you use $\hat E(q_t \mid p_t, I_t, q_{t-1}) = \hat \beta_0+ \hat \beta_1\hat{p_t}+\hat \beta_2I_t+\hat \beta_3q_{t-1}$ and not the unconditional (estimated) relation $\hat E(q_t) = \hat \beta_0+ \hat \beta_1E[\hat{p_t}]+\hat \beta_2E[I_t]+\hat \beta_3E[q_{t-1}]$,which would lead to the long-run (unconditional) elasticity.  But if he was to ask, say, <em>""I want to introduce the product to a new market where the consumers are comparable in income to what we already have. What demand-responsiveness to price should I have in mind?""</em>, then the best you could do is provide the long-run elasticity.</p>
</blockquote>
","5990"
"HP Filter Smoothing Parameter","284","","<p>Mueller (2015, <a href=""http://ftp.iza.org/dp6849.pdf"" rel=""nofollow"">working paper</a>) says that an HP filter with smoothing parameter 900,000 (for monthly data) corresponds to a smoothing parameter of 100,000 for quarterly data.</p>

<p>How does one do this exact calculation? If I were to calculate the corresponding annual parameter, how would I proceed?</p>
","<p><a href=""http://www.researchgate.net/profile/Morten_Ravn/publication/24095763_On_adjusting_the_Hodrick-Prescott_filter_for_the_frequency_of_observations/links/0deec524affb7f23af000000.pdf"" rel=""nofollow"">Morten O. Ravn and Harald Uhlig (2002)</a></p>

<blockquote>
  <p>This paper complements these insights using two different analytical
  approaches. The first approach uses the time domain  and  focuses  on 
  the  ratio  of  the  variance  of  the cyclical component to the
  variance of the second difference of the trend component: this ratio
  is often used for calculating the smoothing parameter. For a
  particular benchmark stochastic process, <strong>it is shown that time
  aggregation changes this ratio by the fourth power of the observation
  frequency</strong>. The second approach uses the frequency domain and
  investigates the transfer function of the HP filter, thereby obtaining
  a general result. Again, a change-of-variable argument shows that one
  should adjust the HP parameter with approximately  the  fourth  power 
  of  the  frequency  change.  Both approaches therefore yield a value
  of approximately $1600 / 4^4 = 6.25$ for annual data, which is close
  to the value of 10 given by Baxter and King (1999).</p>
</blockquote>

<p>Source: Notes On Adjusting the HP-Filter for the Frequency of Observations</p>

<p>Mueller's result is not obvious to me given this rule. By that rule of thumb, a monthly parameter  given an quarterly parameter of 900,000 is $900,000 / 3^4 \approx 11,111$ (because there 3 months in a quarter). It also gives a yearly parameter of $900,000 / 12^4 \approx 43$ (12 months in a year).</p>

<p>The following quote seems to support Mueller.</p>

<blockquote>
  <p>On suboptimality of the Hodrick–Prescott filter at time series
  endpoints Hodrick and Prescott (1997) proposed, on somewhat subjective
  grounds, a value λ = 1600 for quarterly data. However, it is desirable
  to adjust this value when observations of different frequencies are
  subject to the filter. Backus and Kehoe (1992) suggested an adjustment
  of the value by <strong>multiplying the standard value of 1600 with the square
  of the frequency of observations relative to quarterly data</strong>. For
  example, the relative frequency is 3 for monthly data and 1/4 for
  annual data. Hence, the corresponding values of the smoothing
  parameter is $\lambda$ = 100 and 14,400 for annual data and monthly data,
  respectively. This suggestion has been also used in commercial
  packages such as EVIEW. We shall use these values throughout the
  paper. With regard to the choice of the smoothing parameter, it is
  worth noting that, in research that has gone largely unnoticed in this
  field, Akaike (1980), while further allowing a seasonal component in
  the decomposition, proposed precisely the HP approach together with a
  data-dependent Bayesian procedure for the choice of $\lambda$.</p>
</blockquote>

<p>So just as $1,600 (quarterly) \rightarrow 3^2 \cdot 1,600 =  14,400 (monthly)$ so to would $100,000 (quarterly) \rightarrow 3^2 \cdot 100,000 =  900,000 (monthly)$</p>

<p><a href=""http://www.sciencedirect.com/science/article/pii/S0164070404000710"" rel=""nofollow"">Misea, Kimb, and Newboldc (2005)</a></p>

<p>But the cited Backus and Kehoe (1992) result seems to be superseded by the Ravn and Uhlig (2002) result, so this may not reflect the state of the art thinking on this matter. </p>
","9642"
"Lee and Saez (2012): Pareto-Improvement?","284","","<p>I'm interested in the following quote that came up in <a href=""https://economics.stackexchange.com/a/430/43"">this earlier answer</a>. </p>

<blockquote>
  <p>Second, when labor supply responses are along the extensive margin
  only, which is the empirically relevant case, the co-existence of a
  minimum wage with a positive tax rate on low-skilled work is always
  (second-best) Pareto inefficient.A Pareto improving policy consists of
  reducing the pre-tax minimum wage while keeping constant the post-tax
  minimum wage by increasing transfers to low-skilled workers, and
  financing this reform by increasing taxes on higher paid workers.
  Importantly, this result is true whether or not rationing induced by
  the minimum wage is efficient or not.</p>
</blockquote>

<p>How are higher paid workers not worse off, given the increased taxes they have to pay?</p>
","<p>(Note that this answer implicitly makes reference to the specific model in Lee and Saez.)</p>

<p><strong>Short answer:</strong> the increased taxes on high-skilled workers exactly offset the higher real wages they obtain from a decline in the minimum wage for low-skilled workers.</p>

<p><strong>Longer answer:</strong> Suppose that I'm the government, and I decide to lower the minimum wage $\bar{w}$. The direct effect will make low-skilled workers currently earning the minimum wage worse off, while making high-skilled workers better off. (The fall in low-skilled wages means an increase in high-skilled wages.) </p>

<p>Furthermore, a lower minimum wage means that fewer low-skilled workers will be rationed out of the labor market. These workers will be better off.</p>

<p>As the government, I want to turn this into a Pareto improvement - which it currently isn't, because workers who are already earning the minimum wage are hurt by the decrease. I try the simplest possible offset: I adjust taxes so that everyone's after-tax wage rate is <em>exactly</em> the same as before. The combination of this tax rate change and the minimum wage decrease means that everyone's welfare is unchanged, <em>except</em> for some low-skilled workers who were previously unemployed and now can work. These workers are better off - hence overall we have a Pareto improvement. Great!</p>

<p>There's only one catch: I didn't verify that this policy was feasible for the government. Maybe the proposed change in tax rates would violate the government's budget constraint. </p>

<p>This is where some slightly more involved logic comes in, and it's useful to think about the infinitesimal case for simplicity. Before the policy change, output is produced by a mix of low- and high-skilled workers, who I'll call the ""old"" workers. The minimum wage increase leads to additional low-skilled workers entering the mix; I'll call them the ""new"" workers. These new workers produce additional output and earn income. At the margin, though, (pretax) wage equals marginal product - so when an infinitesimal number of new workers is added, they increase output by exactly as much as they draw away in earnings, and the total earnings of the <em>old</em> workers are unchanged. There's a redistribution in earnings among the old workers, toward the high-skilled and away from the low-skilled, but this is just a zero-sum redistribution, and the government can use taxes to reverse a zero-sum redistribution while maintaining a balanced budget - so this part is fine.</p>

<p>All we need to worry about now is the budgetary impact of the <em>new</em> low-skilled workers. But this is simple: we're initially taxing low-skilled work at some rate $\tau_1$, and the net budgetary effect of more low-skilled entry will be positive (even after the infinitesimal decrease in $\tau_1$ that's part of the reform) as long as $\tau_1&gt;0$. New workers are good for the budget as long as their tax rate is positive.</p>

<p>So that wraps it up: we see that there is a potential Pareto improvement involving a decrease in the minimum wage and an offsetting change in tax rates, and this policy change is feasible as long as the initial tax rate on minimum wage work is positive: $\tau_1&gt;0$. Lee and Saez emphasize this point (in conjunction with their other results) to demonstrate that in their model, the minimum wage can only be rationalized as a policy that's complementary to a labor subsidy $\tau_1\leq 0$. They really like this purported complementarity, and it's one of the most popular current arguments in favor of minimum wages.</p>

<p>(I happen to think that the way they prove this complementarity, which relies on the assume-a-can-opener assumption of efficient labor market rationing, is incredibly silly. But that's a different part of the paper, not directly related to your question here.)</p>
","1610"
"Can geography explain differences in economic development between present day economies?","283","","<p>Just wondered if anyone considered this. Do simple geographic factors explain differences in economic development?</p>

<p><a href=""https://i.stack.imgur.com/heeja.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/heeja.gif"" alt=""enter image description here""></a></p>
","<p>Dani Rodrik, Arvind Subramanian, Francesco Trebbi have a paper on ""<a href=""http://faculty.arts.ubc.ca/ftrebbi/research/institutionsruleJEG.pdf"">Institutions Rule: The Primacy of Institutions over Geography and Integration in Economic Development</a>"", Journal of Economic Growth, June 2004, 9(2): pp.131-165.</p>

<p>They estimate the respective contributions of institutions, geography, and trade in determining income levels around the world, using recently developed instruments for institutions and trade. They results indicate that the quality of institutions trumps' everything else. They add that once institutions are controlled for, <strong>measures of geography have at best weak direct effects on incomes, although they have a strong indirect effect by influencing the quality of institutions</strong>.</p>
","10863"
"Formal definition of perfect information","283","","<p>I am looking for the formal definition of 'perfect information' in game theory.</p>

<p>Please direct me to a book or preferably an online paper where I can find it.</p>

<p>On a related note:<br>
The <a href=""https://en.wikipedia.org/wiki/Perfect_information"">Wikipedia page for the term</a> is not very useful. It only offers an informal definition:</p>

<blockquote>
  <p>In game theory, an extensive-form game has perfect information if each player, when making any decision, is perfectly informed of all the events that have previously occurred</p>
</blockquote>

<p>Given this definition the simultaneous move examples seem strange. The games mentioned (e.g. iterated prisoner's dilemma) could easily be altered to have sequential moves where the second mover is simply not aware of the first move. This game would have the same extensive form but would no longer fit the informal definition.</p>
","<h1>Osborne and Rubinstein (1994)</h1>

<p>Osborne and Rubinstein's textbook <a href=""http://gametheory.tau.ac.il/arielDocs/""><em>A Course in Game Theory</em></a> defines (extensive) games with perfect information in three versions.</p>

<ul>
<li><p>Basic version (Def. 89.1): perfect information is the same as requiring information sets be singletons (though they don't put it this way). In the author's language, perfect information is modeled as a player function $P:H\to N$, mapping each non-terminal history $h\in H$ of previous moves to a single member in the set of players $N$. A history here is $h=(a^k)_{k=1,\dots,K}$, where $a^k$ is the action taken by the player who moves in the $k$th round, and $K$ is possibly infinite.</p></li>
<li><p>Extended version 1 (<strong>perfect information with chance-moves</strong>, Sect. 6.3.1): perfect information (for players) here is basically the same as before, be the definition incorporates uncertainty in the game due to chances</p></li>
<li><p>Extended version 2 (<strong>perfect information and simultaneous moves</strong>, Sect. 6.3.2): perfect information here is modeled as a player function $P$ mapping each non-terminal history to a <strong>set</strong> of players, where </p>

<blockquote>
  <p>[a] history in such a game is a sequence of vectors; the components of
  each vector $a^k$ are the actions taken by the players whose turn it
  is to move after the history $(a^\ell)_{\ell=1}^{k-1}$. The set of
  actions among which each player $i \in P(h)$ can choose after the
  history $h$ is $A_i(h)$; the interpretation is that the choices of the
  players in $P(h)$ are made simultaneously.</p>
</blockquote></li>
</ul>

<hr>

<h1>Myerson (1991)</h1>

<p>Myerson's <a href=""https://books.google.ca/books/about/Game_Theory.html?id=1w5PAAAAMAAJ&amp;redir_esc=y""><em>Game Theory: Analysis of Conflict</em></a> similarly defines (on page 185) an extensive form game with perfect information as information sets being singletons <em>within each information state</em>. </p>

<hr>

<h1>Fudenberg and Tirole (1991)</h1>

<p>Fudenberg and Tirole's <a href=""https://mitpress.mit.edu/books/game-theory""><em>Game Theory</em></a> textbook defines perfect information informally (on page 72) as follows </p>

<blockquote>
  <p>We say that multi-stage game has <em>perfect information</em> if, for every stage $k$ and history $h^k$, exactly one player has a nontrivial choice set --- a choice set with more than one element --- and all the others have the one-element choice set ""do nothing.""</p>
</blockquote>
","15413"
"Roy's identities for Stone-Geary utility functions","283","","<p>I'm having trouble showing Roy's identity for the following Stone-Geary utility function:</p>

<p>$$U(x)=\prod_{i=1}^n\left(x_i-\gamma_i\right)^{\beta_i}$$</p>

<p>where $\sum \beta_i=1$ and $\gamma_i$ is the minimal consumption of $x_i$.</p>

<p>I showed that the Marshallian demand (which I confirmed using multiple sources) is</p>

<p>$$x_i=\gamma_i+\frac{\beta_i\left(I-\sum_{j=1}^np_j\gamma_j\right)}{p_i}$$</p>

<p>Therefore, the indirect utility function is </p>

<p>$$V(x)=\prod_{i=1}^n\left(\frac{\beta_i \left(I-\sum_{j=1}^np_j\gamma_j \right)}{p_i} \right)^{\beta_i}$$</p>

<p>I applied a monotone transformation to simplify the indirect utility function:</p>

<p>$$W(x)=\sum_{i=1}^n\beta_i\left(\left(\ln(\beta_i)+\ln \left(I-\sum_{j=1}^np_j\gamma_j \right)\right)-\ln(p_i)\right)$$</p>

<p>Therefore,</p>

<p>$$\frac{\delta W}{\delta p_i}=\frac{-\beta_i\gamma_i}{I-\sum_{j=1}^np_j\gamma_j}-\frac{\beta_i}{p_i}$$</p>

<p>$$\frac{\delta W}{\delta I}=\frac{\beta_i}{I-\sum_{j=1}^np_j\gamma_j}$$</p>

<p>$$-\frac{\delta W / \delta p_i}{\delta W / \delta I}=\gamma_i+\frac{I-\sum_{j=1}^np_j\gamma_j}{p_i}$$</p>

<p>Basically, as you can see, something doesn't add up: the $\beta_i$ is missing from the numerator. Thus, Roy's inequality is not verified. Where did I mess up?</p>

<p>(Note: I've also tried without the transformation. This is a much more tedious process but it yielded the same answer; the $\beta_i$ was still missing)</p>
","<p>Monir is correct to point out in the comments that $\ln$ is not a linear transformation. It is an increasing transformation, however, and so should not matter as long as</p>

<p>$$ \sum_{i=1}^n p_i \gamma_i &lt; I$$</p>

<p>In any case, your mistake is in the derivatives you find. Here are the correct expressions:</p>

<p>$$\frac{\partial W}{\partial p_i} = -\gamma_i \sum_{j=1}^n \frac{\beta_j}{I - \sum_{k=1}^n p_k \gamma_k} - \frac{\beta_i}{p_i} = -\frac{\gamma_i}{I - \sum_{j=1}^n p_j \gamma_j} - \frac{\beta_i}{p_i} $$</p>

<p>$$ \frac{\partial W}{\partial I} = \sum_{j=1}^n \frac{\beta_j}{I - \sum_{k=1}^n p_k \gamma_k} = \frac{1}{I - \sum_{j=1}^n p_j \gamma_j} $$</p>

<p>Roy's identity then gives you the Marshallian demand you've initially, and correctly, derived.</p>
","15430"
"Has the ""dismal theorem"" practical implications?","282","","<p>The so-called ""dismal theorem"" asserts that we do not appropriately account for catastrophic scenarios which have very small probability of occurrence. It has been studied in details by Martin's Weitzman, notably in his article <em>""<a href=""http://scholar.harvard.edu/files/weitzman/files/additivedamages.pdf"" rel=""nofollow noreferrer"">Additive Damages, Fat-Tailed Climate Dynamics, and Uncertain Discounting</a>""</em>.</p>

<p>The articles of Martin Weitzman rely on a large dose of mathematics, and my skills do not allow me to get everything, nor of course to question the reasoning and deductions of Weitzman. His conclusion is broadly that ""The take-away message here is that reasonable attempts to constrict bad-tail fatness can leave us with uncomfortably big numbers"" (p19)</p>

<p>I would like to know if there are actually any practical implications from this dismal theorem. In particular concerning climate change. I thought so until @Dole <a href=""https://economics.stackexchange.com/questions/10050/is-the-international-economic-system-too-chaotic-to-work-towards-carbon-emissi"">pointed out</a> that the dismal theorem could also be used to justify trillions of dollars in investment in a anti-asteroid defense system. I would appreciate any insight on the conditions to apply this theorem, if it can ever be used. Any relevant literature would also help me.</p>
","<p>My conclusion based on reading his paper is that the utility function of an individual or society can't be of the CRRA form presented in the paper. That would indeed lead to scenarios where you could not get out of the bed in the morning, as minimizing the tiniest probability of an enormous risk would warrant infinite sum of money.</p>

<p>I will attempt to explain the mathematics of the paper. First the utility as a function of consumption is of the form:</p>

<p>$$ U(c) = -c^{1-a}, \space a&gt;1$$</p>

<p>This is also called a constant relative risk aversion utility function. Constant relative risk aversion with regards to consumption means that a person prefers a bundle of 1 utils over uncertain bundles with expected value of 1 utils. The same applies to 2 utils to the same degree proportionally. Note that the utility is $-\infty$ when consumption reaches 0. </p>

<p>Now, if you want to calculate the exact utility that a person receives you simply multiply the probability of each bundle with the utility it grants:</p>

<p>$$P_1*U(C_1)+P_2*U(C_2)... = \sum_{n=1}^{\ b}P_n U(C_n)$$</p>

<p>Where P denotes a probability of a given bundle and U(c) is the utility.</p>

<p>Finally, consider a case where there is a possibility of a bundle that has consumption value of 0, with probability greater than zero:</p>

<p>$$ P_x U(c_x) = -\infty $$</p>

<p>It does not matter what the probabilities and utilities of other bundles are as you can't recover from minus infinite utility.</p>

<p>The same principle applies to continuous probability distributions, so just replace the sum sign with an integral and consider case where it doesn't reach 0 probability when c=0.</p>

<p>You may be interested in readin Nordhaus's response:
<a href=""http://aida.wss.yale.edu/~nordhaus/homepage/documents/weitz_011609.pdf"" rel=""nofollow"">http://aida.wss.yale.edu/~nordhaus/homepage/documents/weitz_011609.pdf</a> (By the way, he uses the exact same case scenario as I did).</p>
","10070"
"Greece default and why are US States not seen defaulting?","281","","<p>Reading various articles, it is clear that Greece is in the situation simply due to the fact that they have indulged in overspending on their national budget for over a decade, and with the 2008 financial crisis this have have worsen as they have lost additional revenue.</p>

<p>Every US state and city is also responsible for their own budgets, and making sure that they are kept in balance -- while a handful of US cities have gone bankrupt, there have not been any news about US state getting into a crisis of the same scale as Greece has.</p>

<p>Is there a difference between how a national budget is run in the Euro Zone versus how a US State budget is run with respect to oversight where a US State cannot get insolvent to the same degree as Greece before the US Fed steps in?</p>

<p>What are the lessons from the US model which would need to be implemented in the Euro Zone to prevent another Euro Zone member to end up in a similar situation?</p>

<p><strong>EDIT</strong></p>

<p>Specifically; Are there any specific laws in the US which allows the Feds to step in before a state defaults?</p>
","<p>Every of the United States except Vermont is required by law to balance their budgets. 45 states have some sort of constitutional balanced budget provision and another 4 have it by statute. <a href=""http://www.ncsl.org/research/fiscal-policy/state-balanced-budget-requirements-provisions-and.aspx"" rel=""nofollow noreferrer"">(Source)</a></p>

<p>According to <a href=""https://books.google.com/books?id=h6DWIXi3CdYC&amp;pg=PA67"" rel=""nofollow noreferrer"">Inman (2003)</a>, such balanced budget provisions were mostly adopted after <a href=""https://en.wikipedia.org/wiki/State_bankruptcies_in_the_1840s"" rel=""nofollow noreferrer"">the state defaults of the 1840s</a>:</p>

<blockquote>
  <p>Following the defaults of state debts during the 1840s, the European
  bond market was naturally reluctant to lend to U.S. states. The states
  responded by agreeing to debt repayment schedules for their
  outstanding debt and then by promising never to default again.</p>
  
  <p>The promise took the form of a constitutional or statutory commitment
  to run balanced budgets on the current accounts--that is, not to play
  the default-bailout game. The nondefaulting states and new states
  entering the Union after 1850 found it important to signal their
  commitment to balanced budgets; they too passed balanced budget rules.
  Today, all U.S. states--except Vermont, whose fiscal prudence is
  legendary--have either constitutional or statuory balanced budget
  rules aimed at constraining state and local deficit behaviors.</p>
</blockquote>

<p>States have apparently paid some respect to their own balanced budget rules, given that no state has defaulted since the Great Depression: <a href=""http://learnbonds.com/6364/state-bond-defaults/6364/"" rel=""nofollow noreferrer"">this source</a> lists all state bond defaults.</p>

<p>(I am not aware of any federal legislation requiring states to balance their budgets. I suspect, but am not sure, that it would be difficult if not unconstitutional for the federal government to try to foist some balanced budget requirements on the states.)</p>

<p>Most sovereign states in contrast do not have balanced budget rules, though some European countries have adopted such rules in the past few years (<a href=""https://en.wikipedia.org/wiki/Balanced_budget_amendment"" rel=""nofollow noreferrer"">Wikipedia</a>). </p>

<p>P.S. A <a href=""https://money.stackexchange.com/questions/4849/why-cant-a-us-state-default-but-a-eu-state-can"">very similar question</a> was asked over at money.SE a few years ago.</p>
","6933"
"In the eyes of a normal citizen, what difference does it make if my country has debt or no debt?","281","","<p>I got curious about this because I happened to pass by a list of countries with zero debt. Country debt seems like a major thing, but for a non-economics major like me, I don't exactly understand the implications of a country having debt.</p>

<p>More tax? Less progress? Exports are more necessary? </p>

<p>What difference does it make, for a normal citizen, if his/her country has debt or no debt?</p>
","<p>1)  Debt matters because it smoothes (or unsmoothes) taxes over time, which matters because the deadweight loss from taxation is (roughly) proportional not to the tax rate, but to the square of the tax rate.</p>

<p>2)  Because family sizes are not homogeneous, government debt (which transfers the tax burden to future generations) can redistribute the tax burden across families.  (Think, for example, about a taxpayer with no kids, or a family that has just immigrated.)</p>

<p>3)  Government debt makes it easier to borrow --- it's better to pay 3% to government bondholders than 18% to your credit card company.  This is possible because the penalty for not paying your taxes is considerably more severe than the penalty for not paying your credit card bill.  (In effect, government debt resurrects the institution of the debtor's prison.)</p>

<p>4)  There are of course issues with misperceptions, where debt can make people feel either richer or poorer than they really are, depending on whether they underestimate or overestimate their future tax burdens, and so can affect consumption paths in either direction.</p>
","1931"
"Game Theory Question","280","","<h2>                                    |</h2>

<h2>|     |Adv| ---------|N\A|</h2>

<h2>Adv| 300,300     | 900,0          |</h2>

<h2>N\A| 0,900     | 700,700           |</h2>

<p>Player 1= Pepsi</p>

<p>Player 2= Coke</p>

<p>A) Solve for the pure strategy Nash equilibrium</p>

<p>B) Is this game a prisoner's Dilema?</p>

<p>C) Is there a cooperative equilibrium? If so, what is it?</p>

<p>D) Does coke have a dominant strategy? Does Pepsi?</p>

<h2>My Attempt</h2>

<hr>

<h2>|     |Adv| ---------|N\A|</h2>

<h2>Adv| (300),(300)     | (900),0          |</h2>

<h2>N\A| 0,(900)     | 700,700           |</h2>

<p>A) Nash Equilibrium: (Adv, Adv)</p>

<p>B) Not sure how to answer this</p>

<p>C) Yes. If they both got in contact and made the option to not advertise </p>

<p>D) </p>

<p>I would appreciate some help!</p>
","<p>Here are a couple hints for the two that you haven't answered:</p>

<p>The prisoner's dilemma is characterized by the inability to sustain the Pareto optimal payoff as a Nash Equilibrium due to the existence of a profitable deviation for both players. Each player has a dominant strategy to ""Defect"" and so the unique Nash Equilibrium is one where both players ""Defect"". Does that hold here?</p>

<p>A (possibly mixed) strategy $a$ (weakly) dominates another strategy $b$ for a given player $i$ if player $i$ (weakly) prefers playing $a$ to $b$ for any strategy vector of the other players. In your case, there is just one other player, $j$, and so $i$ simply has to prefer $a$ to $b$ for any strategy played by player $j$. </p>

<p>You just need to see if that holds for your two players.</p>
","16440"
"What does efficient and inefficient innovators mean?","280","","<p>I have been reading through <a href=""http://www.economist.com/blogs/graphicdetail/2015/09/global-innovation-rankings?fsrc=scn/tw/te/pe/ed/theinnovationgame"" rel=""nofollow noreferrer"">this article</a> about Innovation Indexes.</p>

<p>In this, I have come across the terms: ""Efficient Innovators"" and ""Inefficient Innovators"" in this plot:</p>

<blockquote>
  <p><a href=""https://i.stack.imgur.com/Va9Y0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Va9Y0.png"" alt=""enter image description here""></a></p>
</blockquote>

<p>So, what do they mean? And how are they calculated/determined?</p>
","<p>My understanding of this chart is based on the <a href=""https://www.globalinnovationindex.org/userfiles/file/reportpdf/gii-full-report-2015-v6.pdf"" rel=""nofollow"">Global Innovation Index 2015</a> report. Definitions are not explicit however. </p>

<p>They compute an Innovation Efficiency Ratio as the ratio of the ""Output Sub-Index"" score  over the ""Input Sub-Index"" score (definitions of these scores are presented in Figure 1). It is designed to assess the effectiveness of innovation systems and policies. In other words, this ratio shows how much innovation output a given country is getting for its inputs. Based on Table 1, all the countries with a ratio over the median (.71) appear to be considered as ""efficient innovators"". </p>

<p>For instance, Angola and Côte d'Ivoire do not show significant innovation input and  output  results,  yet  their  efficiency ratios appear high because their outputs outweigh their inputs on a low level.</p>
","12350"
"When do trades between two countries not result in gains for either of them?","280","","<p>So are there any circumstances where two countries trade with each other and they both do not gain anything? is it possible? and if you could also explain why that is the case? I have looked around and haven't really been able to find any answers.</p>

<p>Thanks in advance</p>
","<p>If I understand well your point, you want to know whether 2 agents (say countries) can make transaction if they don't each gain from that trade.</p>

<p>In general, agents optimize some function, called the objective, with respect to some constraints, and 2 agents trading with each other will keep trading until both marginal utilities are equal (first-order conditions of the maximization problem). So to answer your question, an agent won't trade if that trade does not increase her utility. Having said that, in a world where there are some additional constraints (in addition of the budget constraints), or some externalities you can end-up in situations where agents trade while it is not strictly speaking beneficial for them. Specifically, there may be some rules that require some externalities to be strictly lower than some values, and that would yield to trade that indeed reduce the utility of the agent. </p>

<p>As an example, let's think about a country that is endowed with a technology which produce some output and some externalities, say pollution. Then without going through the specifics of such a model, if (once the equilibrium is reached) a new rule says that the amount of pollution that a country can produce needs to be lower than some value (which is assumed to be higher than what was originally produced), the country may need to trade with some other country (with higher cost, but lower pollution) to fulfill the requirement, then resulting in less utility than previously but the require amount of pollution.</p>

<p>To sum-up, in general (free market, with perfect competition, etc.) this won't be the case, but such situations could arise in the presence of additional rules (or externalities that need to be internalized or additional constraints to the maximization program).</p>
","8902"
"Flexible lab experiment in otree","279","","<p>I am building a lab experiment through <a href=""http://www.otree.org/"" rel=""nofollow"">otree</a>, ``a Django-based framework for implementing multiplayer decision strategy games."" </p>

<p><strong>Basics about otree's forms</strong></p>

<p>Here is an example of how otree gets the players to report their choices (based on the ""matching_pennies"" game which is part of the templates provided by otree).</p>

<p>In a file named <code>model.py</code>, one finds the following code</p>

<pre><code>class Player(otree.models.BasePlayer):

[...]

penny_side = models.CharField(choices=['Heads', 'Tails'])

[...]
</code></pre>

<p>Then in <code>views.py</code> one finds</p>

<pre><code>class Choice(Page):

form_model = models.Player
form_fields = ['penny_side']
</code></pre>

<p>Finally, the form is displayed to the end user through <code>choice.html</code> by inserting</p>

<pre><code>{% formfield player.penny_side with label=""I choose:"" %}
</code></pre>

<p><strong>What I would like to do</strong> </p>

<p>is create a flexible experiment in which the number of choices that players have to make varies with a parameter <code>x</code>. That is, I want the whole framework to generate <code>x</code> possible choices by just setting a parameter <code>x</code>, and not having to go update all the files manually. This is in order to make my life easier if we ever change the experimental design, and to make the code useful to others with different experimental design (I plan to release it on Github at some point).</p>

<p>It seems like it should be fairly easy to do with a couple of loops, but I am having trouble using lists given the way <code>otree</code> is structured. </p>

<p>From what I understand,  I only see one <em>very nasty</em> way to have the number of choices depend on a parameter <code>x</code>. I first give each choice a different name in <code>model.py</code>, e.g.</p>

<pre><code>class Player(otree.models.BasePlayer):

[...]

for i in range(x):
        exec(""""""choice%d = models.IntegerField(
        choices= ['Heads','Tails'])"""""" %i)

[...]
</code></pre>

<p>then pass the name of all those choices along to <code>view.py</code>, e.g.</p>

<pre><code>class Choice(Page):

all_forms = list()
for i in range(x):
    all_forms.append('choice%d' %i)

form_model = models.Player
form_fields = all_forms
</code></pre>

<p>and finally, find a way to loop through all the forms in Choice.html; something like (I know the code below does not work, just to give the gist of it)</p>

<pre><code>{% for p in range(x)  %}

{% formfield player.choice{{p}} with label=""I choose:"" %}

{% endfor %}
</code></pre>

<p><strong>My question are:</strong></p>

<ul>
<li>This is all very dirty, and looks overly complicated : lists have been invented to avoid this kind of crazy naming process. Do you see a way to make this work with lists instead?</li>
<li>If that's the only way to hack into otree and have the number off choices depend on a parameter <code>x</code>, so be it. But I am still unable to figure out a way to generate the desired set of forms via a loop in Django (obviously the example above does not work, for many reasons.).</li>
</ul>
","<p>I found an answer to the second part of the question here <a href=""https://github.com/oTree-org/otree-docs/issues/2"" rel=""nofollow"">https://github.com/oTree-org/otree-docs/issues/2</a>.</p>

<p>It turns out that in <code>oTree</code>,  the variable <code>form</code> which is passed to the template is iterable. Thus one the following code does the job:</p>

<pre><code>{% for field in form %}
        {% formfield field %}
    {% endfor %}
</code></pre>

<p>Regarding the first part of the question, I contacted a programmer working at oTree. He confirmed that, in its current version, oTree can only define a fixed number of field. He advised to define in <code>model.py</code> a large maximal number of fields and then use <code>get_form_fields</code> in views.py to dynamically return a list with desired subset of fields.</p>

<p>Notice that if you want to create a really large maximal number of fields, the trick presented in the question using <code>loop</code> and <code>exec</code> remains — I believe — the easiest way to proceed.</p>
","8304"
"Interpretation of %p.a. notation","278","","<p>Does anyone know the meaning of the notation x%p.a.?</p>

<p>I'm reading a text on seigniorage, and the authors have used that notation to state the usual empirical limit to the seigniorage revenues just before the inflation rates effects outweigh the money growth effect.</p>
","<p>It's a proportional rate - 5% p.a. means 5% <em>per annum</em>, i.e. 5% per year</p>
","12135"
"Why lower the deposit rate if it is already negative?","278","","<p>The European Central Bank (ECB) has been lowering the interest rate on its deposit facility, first to -0.1% in June 2014, then to -0.2% in September and eventually to -0.3% in December 2015.</p>

<p>But what difference does it make whether it is -0.1% or -0.3%, as long as it is negative? I would expect anyone to withdraw all their money immediately as soon as the interest rate gets negative, for you would always be better off just keeping it for yourself, even if the interest rate is just -0.0001%.</p>

<p>I do understand the intention of the ECB, but I do not understand why lowering the already negative interest rate further should make it more effective.</p>
","<p>You are assuming that the supply of deposits is zero when the price (the rate) is zero but it definitely is not. There are several reasons for this. </p>

<ol>
<li>While you can withdraw cash from the bank it is unwieldy, costly, and unsafe to have large amounts of cash lying around. Therefore, if there were no other alternatives, heavy spenders would still want some wealth in deposit system even if rates were quite negative. Consider, for example, that it is common for depositors to pay account fees that greatly exceed interest earnings. </li>
<li>These costs are actually very low as goes. -0.1 percent a year is ten cents per \$100 of average balance, and since these costs are proportional to average balances which themselves are small relative to total spending, the value of transaction services provided by these accounts is probably large relative to total negative interest rate costs. </li>
<li>Assuming non-bank storage costs are high relative to negative rates it isn't the nominal negative rates (the advertised rate) that matters but rather the real rates (relative to inflation). Under these circumstances, you should be indifferent between 2 percent deposit rates under 4 percent inflation and -1 percent deposit rates under 1 percent inflation. So a rate can drop and the supply of funds can be unchanged if it is accompanied by a drop in inflation. </li>
</ol>

<p>An in the case of the EMU / ECB / Euro, that may well be what happened. Inflation fell for the five months after June 2014, which may explain why nominal rates had to fall: to keep the tightness of monetary policy unchanged or at least to keep real rates unchanged.</p>

<p><a href=""https://i.stack.imgur.com/Q8AHq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Q8AHq.png"" alt=""Harmonized Index of Consumer Prices: All Items for Euro area (17 countries) 2014-2015""></a></p>
","10422"
"Natural real interest rate and output gap","276","","<p>I am a bit confused about the concept of natural real interest rate. I've read that it is the level of real interest rate consistent with the output being at its potential or natural level and with the inflation being static. Is that true?</p>

<p>Furthermore, I do not understand how natural real interest rate is able to affect output and natural level of output (then, the output gap) in the usual New Keynesian framework. I mean the dynamic is curve is defined as
\begin{gather}
x_t=E_t\{x_{t+1}\}-\frac{1}{\sigma}\{i_t-E_t\{\pi_{t+1}\}-r^n_{t}\}
\end{gather}
where $x_t=y_t-y^n_t$, i.e. the output gap and $r^n_{t}$ is the natural real interest rate. ($\frac{1}{\sigma}$ comes from a CRRA household utility with elasticity $\sigma$).</p>

<p>Thus it seems that an increase in the natural real interest rate leads to an increase in current output gap, but how is this true? Does it mean that natural level of output increases more than output?</p>
","<p>Regarding you first question, the answer is 'yes', at least in your model. For if the real interest rate, $r_t=i_t-E_t\pi_{t+1}$, is equal to its natural level $r^n_t$, then in your model $x_t=E_tx_{t+1}$ and $x_t=0$ for all $t$ is a solution which is <em>consistent</em> with the dynamic equation. (Note that other solutions are consistent with the dynamic equation in the case $r_t=r^n_t$ for all $t$, such as $x_t=1$ for all $t$.) </p>

<p>According to my experience, the natural level of real interest rate is usually defined as the level of real interest consistent with output being at its 'natural', 'long-run', 'equilibrium' or 'potential' level, given stable inflation, absence of shocks to demand, etc. I.e., natural real interest rate, $r^n_t$, is such that whenever $r^t=r^n_t$ and certain stability/regularity conditions are fulfilled, then $x_t=0$. <a href=""http://www.frbsf.org/economic-research/publications/economic-letter/2003/october/the-natural-rate-of-interest/#subhead1"" rel=""nofollow noreferrer"">Read a FRBSF Economic Letter for more information.</a> </p>

<p>We may also view the natural level of real interest rate as the real interest rate at which the output gap $x_t$ is following its trend $E_tx_{t+1}$, i.e. $x_t=E_tx_{t+1}$. This definition is similar to the one given by <a href=""https://en.wikipedia.org/wiki/Knut_Wicksell"" rel=""nofollow noreferrer"">Knut Wicksell</a>. </p>

<p>Regarding your two last questions, I may say the following. In your model, a <em>ceteris paribus</em> increase in $r^n_t$ increases $x_t$ by $\frac{1}{\sigma}$. (Just take the partial derivative with respect to 
 $r^n_t$ on both sides in the dynamic equation, holding everything else constant.) This means that either output, $y_t$, is increasing, or the natural level of output, $y^n_t$, is increasing. However, if such <em>ceteris paribus</em> changes cannot be made, then taking the partial derivative holding all else constant is not meaningful. Indeed, in new keynesian models, the natural real interest rate is often a function of $y^n_t$, and in such cases we cannot increase the natural real interest rate without affecting the natural level of output. One such case is when $r^n_t=\rho+\sigma(E_ty^n_{t+1}-y^n_t).$</p>

<p>More concrete examples may be provided, I will see if I can find some.</p>
","14884"
"What is some intermediate or advanced macroeconomics textbook use general approach and focus on general topics?","276","","<p>What is some intermediate or advanced macroeconomics textbook that use general approach, cover major formulas, math intense and focus on general topics similar to Romer's and Branson's Macroeconomics book?</p>

<p>Instead of being use more specific approach like Macroeconomic Theory: A Dynamic General Equilibrium Approach?</p>

<p>Foundations of Modern Macroeconomics by Ben and Lectures on Macroeconomics by Blanchard are both good, what else are out there and how would you compare those two of four i mentioned with your choices in your answer? I know that a graduate economics textbook that teach general topics tend to be easier.</p>
","<p>Have you had a look at Dornbusch and Fischer's Macroeconomics? I would say that is a great book for both Introductory and Intermediate Macroeconomics. It emphasises on basic concepts (I used a really old edition but it still worked for me!) does a review after each section, the formulas are crystal-clear (I may be speaking only of myself though and I apologize in advance), brings up mathematical verification only occasionally, and there is nothing that the diagrams do not explain.</p>

<p>In addition, I used Greg Mankiw's Macroeconomics (still do) to run through topics- it covers most concepts and does not intimidate the reader at any point, but it is not so heavy on the math. </p>

<p>I do not have much idea as to what topics are covered under advanced Macroeconomics, but do take a look at these.</p>
","5668"
"GHH Preferences: FOC","275","","<p><a href=""https://en.wikipedia.org/wiki/Greenwood%E2%80%93Hercowitz%E2%80%93Huffman_preferences"" rel=""nofollow"">Wikipedia</a> states GHH preferences to have the general form</p>

<p>$$V(c, l) =  U(c - G(l))$$</p>

<p>with $U$ increasing concave, and $G$ increasing convex.</p>

<p>In interior solution w.r.t. $l$ requires</p>

<p>$$ U'(c - G(l))(\frac{dc}{dl} - G'(l)) = 0$$ </p>

<p>As wikipedia says, this is given by </p>

<p>$$ \frac{dc}{dl} = G'(l)$$</p>

<p>However, what about the peculiar case where $c = G(l)$? Could someone elaborate a bit on the intuition </p>
","<p>The first-order condition would be satisfied under the assumption $c=G(l)$ if $U'(0)=0$. But this latter requirement is incompatible with the assumptions: indeed, $U'$ is nonincreasing (by the concavity of $U$) which yields $U'(x) \leq 0$ for any $x \geq 0$, which contradicts the fact that $U$ is increasing. </p>

<p>If $U'(x)&gt;0$ for all $x$, the only possibility to meet the first-order condition is indeed $\dfrac{dc}{dl}=G'(l)$.</p>
","6998"
"The Cash Flow Sensitivity of Cash","275","","<p>I am struggling with calculating the Cash Flow Sensitivity of Cash from the Almeida et al. (2004) working paper. (<a href=""http://u.osu.edu/weisbach.2/files/2015/01/ACWJFinance-ui65te.pdf"" rel=""nofollow noreferrer"">http://u.osu.edu/weisbach.2/files/2015/01/ACWJFinance-ui65te.pdf</a>) </p>

<p>I am trying to apply his formula on one specific company case and additionally make some conclusions, whether the company has financially constraints or not.</p>

<p>I am trying to apply equation (8) on page 1787. However, I understand the main variables like  change of CashHoldings, CashFlow, Q and the Size but I do not understand the factors in front of them like a0, a1, etc. Therefore, I am not able to apply this equation.</p>

<p><img src=""https://i.stack.imgur.com/NCisy.png"" alt=""enter image description here""></p>

<p>On page 1793 the authors also provide a more simplified definition of the cash flow sensitivity of cash. ""These estimates suggest that for each dollar of additional cash flow, a constrained firm will save around 5-6 cents""(p.1793).</p>

<p>If I stick to this definition I can not see the necessity to apply any equation. Following this definition I simply could calculate the cash flow sensitivity of cash with the data of changes in cash holdings and cash flows of the certain company. Is this right?</p>

<p>Moreover, does anybody know how to calculate the cash flow sensitivity of cash with the given equation (8)?</p>

<p>􏰀</p>
","<p>This is a standard regression equation, in the context of an econometric approach. The authors postulate a <em>theoretical relationship</em> between the variable ""Change in Cash Holdings"", which is treated as the ""dependent variable"", while ""Cash Flow"" and the rest are the explanatory variables/regressors.  </p>

<p>The ""factors in front of them"" are the <em>regression coefficients</em>, which are unknown, and which are to be estimated through a regression estimation approach, like Ordinary Least Squares or any other technique deemed appropriate, using a sample of observations, which could be either ""cross-sectional"" (one balance sheet for each company, many companies), ""time series"" (many consecutive balance sheets for one company), or ""panel data"" (many consecutive balance sheets for many companies).  </p>

<p>Each coefficient represents the <em>partial marginal effect</em> of a change in the regressor on the dependent variable, holding the other regressors constant.</p>

<p>There is also a ""stand alone"" coefficient, $\alpha_0$: this is the ""constant term of the regression"". Attached to it there is an implied ""explanatory variable"" that takes the value $1$ throughout the sample. It captures the average value of the dependent variable after the average effect of the regressors has been subtracted. The $\varepsilon$ at the end is the regression error, and it is unknown -an estimation of it will be given by the series of residuals obtain as the difference between the estimated value of the dependent variable and the actual one. </p>

<p>In Table 2 p. 1794 ""The Baseline Regression Model"" in the paper contains the numerical estimates the authors obtained for the $\alpha$'s for the specific regression equation, based on a panel data set, it appears, and for a number of variants.</p>

<p>According to the authors, immediately below eq. $(8)$ <strong>they identify the ""Cash Flow Sensitivity of Cash"" with the unknown coefficient $\alpha_1$.</strong> As already mentioned in the question (and as can be seen in Table 2), they find that the estimated value of $\alpha_1$ is $0.05-0.06$.</p>

<p>As described immediately above eq. $(8)$, ""Cash Flow"" here is essentially Operating Profits plus Interest Costs minus Dividends. Then the interpretation is that ""<em>on average</em>, for every dollar increase in thus defined ""Cash Flow"", the Cash Holdings of a company increase by 5-6 cents"" (the authors use, perhaps misleadingly, the verb ""save"" instead of ""increase"". ""Hoard"" would also be accurate).</p>

<p>""Applying"" a regression equation to a specific firm, means, use time-series data on that firm, run the regression as specified and obtain firm-specific estimates for the coefficients. You essentially ""accept"" the theoretical validity of the regression specification, and you attempt to find the values of the coefficient pertinent to a specific firm (remember, the obtained estimates by the authors are averages over data from thousands of firms). You can then compare these estimates with the estimates obtained by the authors and see whether the firm under examination is close to average or not. </p>
","5130"
"Why would a government bail out private banks?","275","","<p>If the private banks never learn from history and keep giving credits to it's clients for overpriced acquisitions, and then they enter default why would the government give them free money or buy those banks?</p>

<p>If I buy overpriced apples to sell them in my fruit shop and I fail to sell them, the government will not bail me out and pay my debts.</p>

<p>Just as my company running the fruit shop should go bankrupt, those banks should go bankrupt, other private investors should buy their assets and start doing better banking business, removing that incompetent staff who buy (or give credits for buying) overpriced things (in this case: houses).</p>

<p>On a first thought, that's my conclusion. And also on a second and third thought.</p>

<p>The whole point of default and bankruptcy should be to allow those competent businesses to survive and those incompetent to leave the sector and do something else. And that looks like a fundamental piece of a working capitalist system that encourages the players to be competitive. Therefore the bailout of private banks looks like a bonus for incompetence. Sponsoring incompetents doesn't look like a good option for making the banking sector work well and totally not suitable for restoring confidence of customers in such banks.</p>

<p>Example: If Compaq is selling bad computers and Gateway is selling good computers, then Compaq should go bankrupt instead of getting government subsidies in order to keep being incompetent. Their owners can try to do something else, like for example Barbie toys, maybe they can do it better than making computers. Gateway will buy their assets and they will survive and grow because they are competent.</p>

<p>I would like to know the arguments used by the governments for bailing out the banks, like for example in Spain where they gave <a href=""http://www.theguardian.com/business/2012/jun/11/question-answer-spain-banking-bailout"" rel=""nofollow"">100 billion Euro</a> for the private banks.</p>
","<p>Because the banks are not loaning their own money but that of depositors. One may also argue that the depositors should know the risks and if their bank makes bad investments it is partly their fault so they cannot complain should they lose their deposits. But a functioning banking system is essential to the current economic system. The bankruptcy of a big bank would cause panic and banks runs, which because of fractional reserve banking would probably result in the insolvency of other banks, banks that perhaps made good investments but ones that cannot immediately be liquidated. After the closing of the banks considerably less savings would be deposited in financial institutions. This will hinder consumption because credit/debit card traffic would cease and getting investment funds would also be considerably more difficult.</p>

<p>So the governments have considered the damage the bankruptcy of a bank would cause to their economy and decided it is better to bail them out. (""Too big to fail."") Of course since banks have a very large revenue stream they can also afford lobbying for intervention as well, but this does not mean that the intervention is not beneficial to the public. Furthermore, if you lose your deposits you may very well (wrongly) blame the government, so a bail-out is also politically prudent.</p>

<p>If you are interested in what could be done I recommend reading about the <a href=""https://en.wikipedia.org/wiki/Glass%E2%80%93Steagall_Legislation"" rel=""nofollow"">Glass-Steagall act</a>.</p>

<p>If you are not satisfied with my answer there are any number of conspiracy theories that offer unconvincing alternative explanations.</p>
","6681"
"Meaning of Additively Separable, Linear in X","274","","<p>Often I see both in micro and macro two common terminology :</p>

<ol>
<li><p>Additively separable. </p></li>
<li><p>Linear in price or linear in probability. </p></li>
</ol>

<p>I understand exactly as they sound  by looking at the functional form of the object. </p>

<p>But can someone provide why these structures or assumptions are sensible or unreasonable and why they are ""convenient"" or ""useful""? The context can be anything consumer, producer, choice under uncertainty, game theory or GE. But trying to see why it is repeatedly coming up and why it is important or mathematically useful in many parts both in micro and macro. </p>
","<p>A function is additively separable in its arguments if it has the form</p>

<p>$$f(x,y) = g(x) + h(y)$$</p>

<p>This means that the cross partials are zero, and so there is no ""cross"" effect of the one argument over the <em>marginal</em> effect that the other has on the value of the function. Since marginal effects are at the very heart of Economics (<a href=""https://economics.stackexchange.com/a/49/61"">see here</a>), assuming additive separability greatly simplifies the analysis. In dynamic problems, where the <em>intertemporal</em> utility function is assumed to be additively separable, it permits us to transform an infinite horizon problem into a recursive two-period one.</p>

<p>Functions that can be transformed into something additively separable (by usually considering their logarithms), are sometimes called ""multiplicatively separable"". The most famous example here is the Cobb-Douglas production function:</p>

<p>$$Q = K^aL^{1-a} \implies \ln Q = a\ln K + (1-a)\ln L$$</p>

<p>As for linearity, it is a <em>unique</em> (structurally) relationship, while non-linear relationships are many, perhaps too many.
A mathematician once said that ""the whole field of Analysis, is essentially the study of linear approximation of non-linear relations"". </p>

<p>Again, mathematical tractability is the drive here, supported by the fact that a linearity assumption is a ""first-order"" approximation to the true relation (see Taylor expansion).</p>
","16036"
"Unemployment and the Frisch-Elasticity","274","","<p>There is the long debate on the Frisch-Elasticity being the driver of unemployment over the business cycle.</p>

<p>One argument against the voluntary-unemployment mechanism of RBC models is that if we distinguish two subgroups of the population with different Frisch-elasticities, the one with the higher elasticity should respond stronger to wage fluctuations.</p>

<p>Women have a bigger elasticity than men, yet their employment fluctuates less over the business cycle.</p>

<p>Is there a counterargument to this that salvages the neoclassical model of voluntary unemployment? I'm specifically referring to this argument that builds on heterogeneity in the elasticity, not on the Micro vs Macro estimation discussion.</p>
","<p>I'm not sure that there is any <em>convincing</em> answer, but most answers I've seen take the form ""some other form of cyclical heterogeneity offsets the differences in Frisch elasticities across groups"".</p>

<p>For instance, the most cyclical industries have historically been construction and durable goods manufacturing, both of which predominantly employ males. (See <a href=""http://www.bls.gov/opub/mlr/2014/article/pdf/the-rise-in-women-share-of-nonfarm-employment.pdf"">this BLS report</a> for the effect of industry cyclicality on the gender composition of the labor force in the most recent recession.) If industry effects are strong enough, they may overwhelm males' much lower intertemporal substitutability of labor supply and cause male employment to be more cyclical.</p>

<p>Note that although this explanation sounds plausible at first glance, it raises many other quantitative problems for business cycle models. For instance, the explanation only works if labor supply cannot easily be reallocated across sectors; otherwise the needed reduction in manufacturing and construction employment could take place via men there switching to other sectors, and then women in those sectors exiting employment.</p>

<p>This is reasonable enough: in the short run, labor supply probably isn't too elastic across sectors. But once we acknowledge this fact, the quantitative puzzle of low employment in business cycles becomes much more severe. For instance, if most employees in construction are stuck in construction in the short term (so that it makes sense to think about labor supply elasticities for the construction sector on its own), then the puzzle of how construction employment <a href=""http://research.stlouisfed.org/fred2/graph/?g=U8E"">fell by 30% while real wages actually inched up in the recent recession</a> becomes extremely hard to resolve in any frictionless labor model. </p>

<p>So ultimately, yes, this is very difficult to resolve on its own; the obvious industry-oriented explanation introduces new and even more insurmountable problems.</p>
","1575"
"Equivalence of inada conditions and non-negativity constraints?","272","","<p>In a standard constrained utility maximization problem with an agent's preferences defined over good(s), does the imposition of Inada conditions on the utility function preclude us from adding non-negativity constraints while setting up the Lagrangean? The latter seem redundant because the Inada conditions will guarantee an interior solution.
Thanks!</p>
","<p>In a standard growth model, people don't put non-negativity constraints as you have mentionned. Theoretically, concavity of the Hamiltonian (or Lagrangian in discrete time) is the sufficient condition for the optimality of the program.
Just for some additional details, the non-negativity constraints are so usefulin some subfields of economics, like in environmental economics. 
For example, if you want to put a ceiling for stock of pollution in atmosphere as $\overline{P}$. You can use it if you want that economy do not pass beyond this critical threshold. So, basically you can make as </p>

<p>$$max \int_{0}^{\infty} u(c,P)  e^{-\rho t} dt $$</p>

<p>s.t</p>

<p>$$\dot{K}=F(K)-c\\
\dot{P}=\epsilon K - \delta P$$</p>

<p>where $\epsilon$ is the emission rate from the use of capital and $\delta$ is the decay rate of pollution.</p>

<p>$$\mathcal{H} = u(c,P) + \lambda (F(K)-c) - \mu (\epsilon K - \delta P) + \alpha (\overline{P} - P) $$</p>

<p>The constraint $\alpha$ is a non-negativity constraint which will ensure that pollution level will not pass beyond the threshold $\overline{P}$. As long as the pollution level is below the threshold, $\alpha$ will be non-binding (and will be equal to zero).</p>

<p>Hint : You can look at the Kuhn-Tucker conditions in order to understand better the role of non-negativity constraint.</p>
","7011"
"Violation of completeness axiom (simple everyday examples)","272","","<p>Simple everyday examples of violations of transitivity are not difficult to come up with, but I'm having trouble thinking of some for the completeness axiom.</p>

<p>One possible formulation of the completeness axiom in plain English: </p>

<blockquote>
  <p>Given any two alternatives A and B, exactly one of the following is true: (1) I strictly prefer A to B; (2) I strictly prefer B to A; (3) I am indifferent between A and B.</p>
</blockquote>

<hr>

<p>One example that I was hoping could work (but didn't) came from the book/movie <em>Sophie's Choice</em>, where Sophie is made to choose between the following two alternatives:</p>

<blockquote>
  <p>A: Send her son to the gas chambers (and her daughter to the children's camp).</p>
  
  <p>B: Send her daughter to the gas chambers (and her son to the children's camp).</p>
</blockquote>

<p>She is initially very reluctant to express a preference for either alternative. So one possible interpretation is that she is exactly indifferent between A and B. Another is that she does not obey the completeness axiom.</p>

<p>However, she is then pressed further and told that if she doesn't choose, she'll simply be given alternative C: ""Send both children to the gas chambers."" </p>

<p>Faced with this alternative C that is clearly inferior to both alternatives A and B, she then does indeed choose one of the alternatives (B: Send her daughter to the gas chambers), hence strongly suggesting that she does indeed obey the completeness axiom. </p>

<p>The above is of course merely my interpretation of the story in <em>Sophie's Choice</em>. Maybe someone can give an alternative interpretation where the above turns out to be an example of the completeness axiom being violated.</p>

<p>(One possibility might be along these lines: Sophie's preference relation is incomplete over {A,B}. When faced only with A and B, she doesn't prefer A to B, doesn't prefer B to A, and isn't indifferent between A and B. However, when given an additional option C that is vastly inferior to A or B and which she must default to in the absence of a choice, she now prefers B to A.)</p>

<hr>

<p>For those who seem to believe the completeness axiom is inviolable and are  unaware that ""within economic theory, criticism of the axioms of transitivity and completeness have quite a long history"" (<a href=""http://www.hup.harvard.edu/catalog.php?isbn=9780674013803"" rel=""nofollow noreferrer"">Putnam, 2002</a>, p. 163), please see the following three examples of economists criticizing the axiom of completeness:</p>

<p>Von Neumann and Morgenstern (1953, <em>Theory of Games and Economic Behavior</em>, 3rd edition, p. 630):</p>

<blockquote>
  <p>The axiom (3:A)—or, more specifically, (3:A:a)—expresses the completeness of the ordering of all utilities, i.e. the completeness of the individual's system of preferences. It is very dubious, whether the idealization of reality which treats this postulate as a valid one, is appropriate or even convenient.</p>
</blockquote>

<p>Aumann (1962, p. 446):</p>

<blockquote>
  <p>Of all the axioms of utility theory, the completeness axiom is perhaps the
  most questionable. Like others of the axioms, it is inaccurate as a description of real life; but unlike them, we find it hard to accept even from the normative viewpoint.</p>
</blockquote>

<p>Anand (1987, p. 190):</p>

<blockquote>
  <p>Whilst completeness is one of the first assumptions used in any"" formal""
  theory of rational choice, it is probably less acceptable as an axiom of
  rationality than either transitivity or independence.</p>
</blockquote>
","<p>Let $X$ be the number of possible baskets of goods that one can buy from a Walmart Superstore. Even if there were only 1,000 distinct items and we could only buy at most one of each item, that'd be $2^{1000}$ possible baskets. (Note that $X \gg 2^{1000}&gt;10^{300}\gg10^{100}&gt;$ ""any estimate of the number of particles in the universe"".)</p>

<p>Even as a normative matter, it is debatable whether a perfectly rational being ""should"" have a complete preference ordering over these $X$ baskets.</p>

<p>But as a positive matter, many (if not all) human beings will not have a complete preference ordering over these $X$ baskets. </p>

<hr>

<p>(Continued discussion of example.)</p>

<p>... Certainly not in their heads. And not on paper either.</p>

<p>Suppose we sat a bunch of human beings down. Ask each to go through a mere ten million of the $\left(\begin{array}{c}
X\\
2
\end{array}\right)$ possible pairwise comparisons of baskets.</p>

<p>Insist that for each pair of baskets, she must choose to agree with exactly one of the following statements: (i) I strictly prefer the first basket to the second; (ii) I strictly prefer the second to the first; (iii) I am exactly indifferent between the two.</p>

<p>Give her as much time as she needs to be absolutely sure and absolutely honest about each choice. (The flippant economist asked to do this exercise may simply and dishonestly claim that he's indifferent between all baskets, just so he doesn't violate the completeness axiom. But let's assume our subjects are all absolutely honest and carefully consider each choice.)</p>

<p>Then repeat the same exercise (i.e. go through all ten million pairwise comparisons again).</p>

<p>We will certainly discover some inconsistencies. That is, we'll certainly find for example that for some pair of baskets of goods $y$ and $z$, someone said $y \succ z$ the first time round but $z \prec y$ the second time round.</p>

<p>Now, the economist may say that: (1) she made a mistake; or (2) her preferences changed between the first and second runs of the exercise.</p>

<p>But I think there is a simpler and broader explanation that subsumes both of these explanations: This individual simply doesn't have a complete preference ordering over the $X$ Walmart baskets. </p>

<hr>

<p>More examples from other economists/decision theorists/philosophers. The first two are similar to the above.</p>

<p><a href=""https://link.springer.com/article/10.1007/BF00126305"" rel=""nofollow noreferrer"">Anand (1987)</a>:</p>

<blockquote>
  <p>Surely the interpretation that a consumer has, in his or her head (or on paper) a complete ordering of all possible pairs of choice objects is unacceptable. A shopping list for seven items with a choice between two brands for each would require 91 pairwise comparisons.</p>
</blockquote>

<p>On a similar note, <a href=""http://onlinelibrary.wiley.com/doi/10.1002/nav.3800010420/full"" rel=""nofollow noreferrer"">Thrall (1954, p. 183)</a>:</p>

<blockquote>
  <p>From the practical point of view, if the number of judgments needed is finite but large, there is still the time difficulty. By the time the judge has reached the 1,000,000th choice, his standards of comparison are almost certainly not the same as initially.</p>
</blockquote>

<hr>

<p><a href=""https://www.jstor.org/stable/1909888"" rel=""nofollow noreferrer"">Aumann (1962)</a>:</p>

<blockquote>
  <p>Or he might be willing to make rough preference statements such as, ""I prefer a cup of cocoa to a 75-25 lottery of coffee and tea, but reverse my preference if the ratio is 25-75""; but he might be unwilling to fix the break-even point between coffee-tea lotteries and cocoa any more precisely. Is it ""rational"" to force decisions in such cases?</p>
</blockquote>

<hr>

<p>The last class of examples is of the <em>Sophie's Choice</em> variety. Not surprisingly, these examples are pursued largely by philosophers who argue (contra economists) that there is a real distinction between <em>indifference</em> and <em>incomparability</em> (or <em>incommensurability</em>, though naturally philosophers split hairs over whether these two terms are the same).</p>

<p><a href=""https://www.jstor.org/stable/40104582"" rel=""nofollow noreferrer"">Putnam (1986)</a></p>

<blockquote>
  <p>I may be quite sure that if I choose the hedonistic-sensual may of life, I would prefer to have a beautiful and responsive lover to a plain and unresponsive one. Call these choices x and y, and let z be the ascetic-religious life. If I regard the two ways of life as ""incomparable"", then I might insist that, prior to my making my existential choice, ~xPz&amp; ~zPx, and also ~yPz&amp; ~zPy</p>
</blockquote>

<p>See also <a href=""http://www.hup.harvard.edu/catalog.php?isbn=9780674013803"" rel=""nofollow noreferrer"">Putnam (2004)</a>. </p>

<p><a href=""http://www.oxfordscholarship.com/view/10.1093/0198248075.001.0001/acprof-9780198248071"" rel=""nofollow noreferrer"">Raz (1986, pp. 341-2)</a> similarly compares a teaching and a legal career.</p>

<hr>

<p>Another perhaps distinct line of research is that initiated by Slovic and Lichtenstein (<a href=""https://www.scienceopen.com/document?vid=df1aa6fc-c92e-434a-aad0-dcf0dcbd823e"" rel=""nofollow noreferrer"">1971</a>, etc.) and goes by the name of ""Preference Reversals"". These could arguably also be examples of incomplete preferences. The following example is from <a href=""https://www.aeaweb.org/articles?id=10.1257/jep.4.2.201"" rel=""nofollow noreferrer"">Tversky &amp; Thaler (1990, JEP Anomalies article)</a>:</p>

<blockquote>
  <p>Imagine, if you will, that you have been asked to advise the Minister of
  Transportation for a small Middle Eastern country regarding the choice of a highway safety program. At the current time, about 600 people per year are killed in traffic accidents in that country. Two programs designed to reduce the number of casualties are under consideration. Program A is expected to reduce the yearly number of casualities to 570; its annual cost is estimated at \$12 million. Program B is expected to reduce the yearly number of casualities to 500; its annual cost is estimated at \$55 million. The Minister tells you to find out which program would make the electorate happier.</p>
  
  <p>You hire two polling organizations. The first firm asks a group of citizens which program they like better. It finds that about two-thirds of the respondents prefer Program B which saves more lives, though at a higher cost per life saved. The other firm uses a ""matching"" procedure. It presents respondents with the same information about the two programs except that the cost of Program B is not specified. These citizens are asked to state the cost that would make the two programs equally attractive. The polling firm reasons that respondents' preferences for the two programs can be inferred from their responses to this question. That is, a respondent who is indifferent between the two programs at a cost of less than \$55 million should prefer A to B. On the other hand, someone who would be willing to spend over \$55 million should prefer Program B. This survey finds, however, that more than 90 percent of the respondents provided values smaller than \$55 million indicating, in effect, that they prefer Program A over Program B.</p>
  
  <p>This pattern is definitely puzzling. When people are asked to choose between a pair of options, a clear majority favors B over A. When asked to price these options, however, the overwhelming majority give values implying a preference for A over B. Indeed, the implicit value of human life derived from the simple choice presented by the first firm is more than twice that derived from the matching procedure used by the other firm.</p>
</blockquote>
","18419"
"Infinitely repeated game: prisoners' dilemma","271","","<p>I have done most of the legwork, but I have fallen short at the final hurdle.
Could you please correct my mistake(s)?</p>

<p><img src=""https://i.stack.imgur.com/Wvla4.jpg"" alt=""enter image description here""></p>

<p>Given the condition $x&gt;0$ I need to consider the infinitely repeated game where the above strategic form is the stage game. The discount factor: $\delta=\frac{1}{2}$.</p>

<p>I need to find a further condition on the game, such that we have a subgame perfect equilibrium in which both players ""cooperate"" in each period.</p>

<p><strong>What I have done so far</strong></p>

<p>The profile of strictly dominated strategies $(u,r)$ constitutes the cooperative strategy where $x&gt;0$ and $x \ne 1$.</p>

<p>The prescription (cooperative strategy) will therefore be $(u,r)=(x+1,x+1)$</p>

<p>The grim trigger is $(d,l) = (x,x)$</p>

<p><strong>Payoff from obeying the prescription:</strong></p>

<p>$(x+1) + \delta(x+1) + \delta^2(x+1) +\delta^3(x+1)+... = \frac{x+1}{1-\delta}$</p>

<p><strong>Payoff from deviating</strong> (<em>here comes the mistake</em>)<strong>:</strong></p>

<p>$2x + \delta x + \delta^2 x +\delta^3 x +... =\color{red}{\frac{2x-\delta(x+1)}{1-\delta}}$</p>

<p>The part in red should apparently be:</p>

<p>$$\frac{(2-\delta)x}{1-\delta}$$</p>

<p>I don't understand why I am wrong, could you please explain?
My understanding was that if a player deviates in period 1 in order to obtain $2x$ then both players would have to play the grim trigger profile $(d,l)$ from period 2 to perpetuity. As a result, the players would be missing out on $\delta(x+1)$.  The payoff numerator would therefore be $\color{red}{2x - \delta(x+1)}$ instead of $\color{blue}{(2-\delta)x}$.</p>

<p>Given that the correct numerator is $\color{blue}{(2-\delta)x}$, I can easily finish the question:</p>

<p>$$\frac{x+1}{1-\delta} \ge \frac{(2-\delta)x}{1-\delta}$$</p>

<p>Therefore, we would have a subgame perfect equilibrium <strong>iff</strong> $x \le 2$.</p>

<p>The problem is that my mistake lies in:</p>

<blockquote>
  <p>$2x + \delta x + \delta^2 x +\delta^3 x +...$
  $=\color{red}{\frac{2x-\delta(x+1)}{1-\delta}}$</p>
</blockquote>

<p>But, I'm not sure why. I would like to know why I am wrong and why $\color{blue}{(2-\delta)x}$ is the correct numerator.</p>

<p>Thanks.</p>
","<p>the payoff from play the trigger strategy will be:
$$ \sum_{i=0}^{\infty}(x+1) \delta^i=\frac{x+1}{1-\delta}$$ </p>

<p>if I deviate and I play $l$ or $d$ the payoff will be
$$ 2x + \sum_{i=1}^{\infty}x \delta^i = 2x+ x\frac{\delta}{1-\delta}=\frac{2x(1-\delta) + x\delta}{1-\delta}= \frac{x(2-\delta)}{1-\delta}$$</p>

<p>then, the condition is $$ \frac{x+1}{1-\delta} \geq \frac{x(2-\delta)}{1-\delta}$$</p>

<p>I hope that this will help you ;)</p>
","5177"
"Money supply M0 and M1 data for students","271","","<p>Its my first time on economics xchange. I am a student of M.Phil. Economics 1st semester. I am writing a term paper and I need some data.</p>

<p>I am looking for money supply M0 and M1 data for top 50 countries (preferably in USD) for the year 2000. My university has a subscription of <a href=""http://www.tradingeconomics.com/"" rel=""nofollow noreferrer"">http://www.tradingeconomics.com/</a>. But that is only accessible in the university's library.</p>

<p>I am back home for vacations. So I wanted to ask if anyone knows of a resource where this might be available for students free or at a low cost. Or if someone of you can provide this data. Thanks.</p>
","<p>Well, I didn't give up. Found these resources. They are free/cheap for data.</p>

<hr>

<p><strong>For trade maps (between countries)</strong></p>

<p><a href=""http://www.trademap.org/Index.aspx"" rel=""nofollow noreferrer"">http://www.trademap.org/Index.aspx</a></p>

<hr>

<p><strong>This site is amazing. With more than 1k topics, you can almost get data for any topic by country/year. You can view the data on screen for free. But exporting the data would require a membership (currently at $29/month)</strong></p>

<p><a href=""https://knoema.com/atlas/topics/Economy"" rel=""nofollow noreferrer"">https://knoema.com/atlas/topics/Economy</a></p>

<hr>

<p><strong>This site also has an amazing database and covers a wide variety of topics. But I was unable to find data for M0 and M1</strong></p>

<p><a href=""http://databank.worldbank.org/data/reports.aspx?source=world-development-indicators#s_i"" rel=""nofollow noreferrer"">http://databank.worldbank.org/data/reports.aspx?source=world-development-indicators#s_i</a></p>

<hr>

<p><strong>An easy to use currency converter with the ability to find exchange rates back to January, 1990</strong></p>

<p><a href=""https://www.oanda.com/currency/converter/"" rel=""nofollow noreferrer"">https://www.oanda.com/currency/converter/</a></p>

<hr>

<p>I hope this helps somebody.</p>
","14656"
"Mix of two ads types","270","","<p><strong>Question still unanswered</strong></p>

<p>Ads in the boring business magazine are read by 300 lawyers and 1,000 M.B.A.s. Ads in the consumer publication are read by 250 lawyers and 300 M.B.A.s. If Harry had \$4,200 to spend on advertising, if the price of ads in the boring business magazine were \$700, and if the price of ads in the consumer magazine were \$350, then the combinations of recent M.B.A.s and lawyers with hot tubs whom he could reach with his advertising budget would be represented by the integer values along a line segment that runs between the two points</p>

<p>a.
(3, 600, 0) and (0, 7, 200).</p>

<p>b.
(3, 000, 3, 600) and (1, 800, 6, 000).</p>

<p>c.
(0, 3, 600) and (1, 800, 0).</p>

<p>d.
(3, 600, 4, 200) and (1, 800, 7, 200).</p>

<p>e.
(2, 400, 0) and (0, 6, 000).</p>

<p>My attempt was to find a budget line which is $700b+350c=4200$, where b stand for business magazines and c for consumer ones. But i do not know how this would translate into the answers that are given.</p>
","<p>Here is my method, which is less rigorous but perhaps quicker, and I believe allows you to see the answer more easily, at least in this case. It may not be true in every case.</p>

<p>Since the line segment will represent <strong>all</strong> combination of lawyers and M.B.A's that we can reach, it must include the extremes. That is, it must include the cases where we maximize the number of lawyers that we reach, and when we maximize the number of M.B.A's that we reach. In fact, these will be the endpoints (since if we are not maximizing one of these we have to be somewhere in-between). Because of this we can do the following:</p>

<p>1) Figure out how many lawyers we can reach, if we focus on only reaching lawyers. Well, the business magazine lets me reach $300$ lawyers for every $\$700$ I spend. The consumer magazine lets me reach $250$ lawyers for every $\$350$ I spend <strong>or equivalently</strong> $500$ lawyers for every $\$700$ I spend. <strong>This is important</strong> because we are comparing $\$700$ worth of one magazine to $\$700$ worth of another: we are making a $1:1$ comparison, which is necessary.</p>

<p>What the above paragraph tells us is that, if I want to reach as many lawyers as possible, I should spend all my money on the consumer magazine ($500&gt;300$). With a budget of $\$4200$ I can buy $4200/350 = 12$ ads. $12$ ads lets me reach $12*250 = 3000$ layers. So the most lawyers I can reach is $3000$. Additionally, $12$ consumer ads lets me reach $12*300=3600$ M.B.A's, hence one point (one extreme) is 
$$
(3000,3600)
$$</p>

<p>To get the other point, find out how you can reach the most M.B.A's.</p>

<p>One thing to note: The fact that things like $(0,3,600)$ are options should perhaps prompt you to consider maximizing the lawyers reached and maximizing the number of M.B.A's reached (since a $0$ indicates reaching none of one group). Not that doing so will be correct, but if you are stuck such a hint might lead you to the correct answer.</p>

<p>Cheers.</p>
","10262"
"Envelope Paradox","269","","<p>There are two envelopes. One contains $x$ money and the other contains $2x$ amount of money. The exact amount ""$x$"" is unknown to me, but I know the above. I pick one envelope and I open it. I see $y$ money in it, obviously where $y \in \{x, 2x\}$.</p>

<p>Now I am offered to keep or switch envelopes.</p>

<p>The expected value of switching is $(\frac{1}{2} \cdot 2y + \frac{1}{2} \cdot \frac{1}{2}y) = \frac{5}{4}y$.
The expected value of keeping my envelope is $y$.</p>

<p>It seems that I should always switch envelopes. My two questions:</p>

<blockquote>
  <p>Is this reasoning correct?</p>
  
  <p>Is it any different if I am not allowed to open the envelope and see the $y$ amount of money, and then I am given the option to switch indefinitely?</p>
</blockquote>
","<p>Here is an ""expected utility maximization/ game theoretic"" approach to the matter (with a dash of set-theoretic probability). In such a framework, the answers appear clear.</p>

<p><strong>PREMISES</strong></p>

<p>We are told in absolute honesty that, for $x$ a strictly positive monetary amount, the following two tickets were placed in a box :  $\{A=x, B= 2x\}$ with assigned identification number $1$ and $\{A=2x, B= x\}$ with assigned identification number $0$. Then a draw from a Bernoulli  $(p=0.5)$ random variable was executed, and based on the result and the event that has occurred, the amounts $x$ and $2x$ were placed in envelopes $A$ and $B$. We are not told what the value of $x$ is, or what amount went to which envelope. </p>

<p><strong>First CASE: Choose an envelope with the option to switch without opening it</strong></p>

<p>The first issue is <em>how do we choose an envelope</em>? This has to do with preferences. So <em>assume</em> that we are expected utility maximizers, with utility function $u()$.</p>

<p>We can model the probabilistic structure here by considering two dichotomous random variables, $A$ and $B$ representing the envelopes, and the amount in them. The support of each is $\{x, 2x\}$. But they are not independent. So we have to start with the joint distribution. In table form, the joint distribution, and the corresponding marginal distributions are</p>

<p>\begin{array}{| r | r |  }
  \hline                       
\text{A} \;/ \;\;\text{B} \rightarrow  &amp; x &amp; 2x &amp; \text {Marg A} \\
  \hline 
  \hline                       
  x &amp; 0 &amp; 0.5 &amp; 0.5\\
  \hline                     
2x &amp; 0.5 &amp; 0 &amp; 0.5 \\
\hline
\text{Marg B} &amp; 0.5 &amp; 0.5 &amp; 1.00 \\
  \hline  
\end{array}</p>

<p>This tells us that $A$ and $B$ have identical marginal distributions.</p>

<p>But this means that it doesn't matter how we choose envelopes, <em>because we will always get the same expected utility</em>, </p>

<p>$$0.5 \cdot u(x) + 0.5\cdot u(2x)$$</p>

<p>What we are facing here is a compound gamble (how to choose an envelope) over two identical gambles (each envelope). We can choose $A$ with probability $1$, $0$, or anything in-between (and complementarily for $B$). It doesn't matter. We will always get the same expected utility. Note that our attitude towards risk doesn't play a role here.</p>

<p>So we do choose an envelope, say $A$, and we are looking at it. What is now our expected utility? <em>Exactly the same as prior to choosing</em>. Picking an envelope in whatever way, does not affect the probabilities of what's inside.</p>

<p>We are allowed to switch. Say we do, and now we are holding envelope $B$. What is now are expected utility? <em>Exactly the same as before</em>. </p>

<p>These are the two possible states of the world for us: choose $A$ or choose $B$. Under any choice, both states of the world imply the same value to our chosen/assumed driving force (i.e. maximize expected utility). </p>

<p><strong>So here, we are indifferent to switching.</strong>, and in fact we could also randomize.</p>

<p><strong>2nd CASE: OPENING THE ENVELOPE with the option to switch after</strong>  </p>

<p>Assume now that we have picked $A$, opened it, and found inside the amount $y \in \{x, 2x\}$. Does this change things?  </p>

<p>Let's see. I wonder, what is</p>

<p>$$P(A = x \mid A \in \{x, 2x\}) = ?$$ </p>

<p>Well, $\{x, 2x\}$ is the sample space on which random variable $A$ is defined. Conditioning on the whole sample space, i.e. on the trivial sigma-algebra, does not affect neither the probabilities, nor the expected values. It is as though we wonder ""what is the value of $A$ if we know that all possible values may have been realized?"" No effective knowledge has been gained, so we are still at the original probabilistic structure.  </p>

<p>But I also wonder, what is </p>

<p>$$P(B = x \mid A \in \{x, 2x\}) = ?$$ </p>

<p>The conditioning statement, properly viewed as a sigma-algebra generated by the event $\big \{A \in \{x, 2x\}\big\}$, is the whole product sample space on which the random vector $(A,B)$ has been defined. From the table of the joint distribution above, we can see that the probability allocation of the joint is equivalent a.s to the probability allocation of the marginals (the ""almost surely"" qualification due to the presence of two events of measure zero). So here too we essentially condition the probabilities for $B$ on its whole sample space. It follows that our action to open the envelope did not affect the probabilistic structure for $B$ also.</p>

<p>Enter game theory, alongside decision making. We have opened the envelope, and we have to decide whether we will switch or not. If we don't switch we get utility $u(y)$. If we switch, then we are in the following two possible states of the world </p>

<p>$$y = x, u(A) = u(x) \implies u(B) = u(2x)$$
$$y = 2x, u(A) = u(2x)\implies u(B) = u(x)$$</p>

<p>We do not know which state actually holds, but per the above discussion, we do know that each has probability $p=0.5$ of existing.  </p>

<p>We can model this as a game where our opponent is ""nature"" <em>and where we know that nature plays with certainty a randomized strategy</em>: with $p=0.5$ $y=x$ and with $p=0.5$, $y=2x$. But we also now that if we do not switch, our payoff is certain. So here is our game in normal form, with our payoffs:</p>

<p>\begin{array}{| r | r |  }
  \hline                       
\text{We} \;/ \;\;\text{nature} \rightarrow  &amp;y= x &amp; y=2x  \\
  \hline                       
  \text{Switch} &amp; u(2x) &amp; u(x) \\
  \hline                     
\text{Don't Switch} &amp; u(y) &amp; u(y)  \\
  \hline
\end{array}</p>

<p>We should resist the temptation to substitute $u(x)$ and $u(2x)$ for $u(y)$. $u(y)$ is a <em>known</em> and certain payoff. The payoffs for the ""Switch"" strategy are not actually known (since we do not know the value of $x$). So we <em>should reverse the substitution</em>. If $y=x$ then $u(2x) = u(2y)$, and if $y=2x$ then $u(x) = u(y/2)$. So here is our game again:</p>

<p>\begin{array}{| r | r |  }
  \hline                       
\text{We} \;/ \;\;\text{nature} \rightarrow  &amp;y= x &amp; y=2x  \\
  \hline                       
  \text{Switch} &amp; u(2y) &amp; u(y/2) \\
  \hline                     
\text{Don't Switch} &amp; u(y) &amp; u(y)  \\
  \hline
\end{array}</p>

<p>Now all the payoffs in the matrix are known. Is there a pure dominant strategy?  </p>

<p>The expected payoff of strategy ""Switch"" is</p>

<p>$$E(V_S) = 0.5\cdot u(2y) + 0.5 \cdot u(y/2)$$</p>

<p>The expected payoff of strategy ""Don't Switch"" is</p>

<p>$$E(V_{DS}) = u(y)$$</p>

<p>We should switch if</p>

<p>$$E(V_S) &gt; E(V_{DS}) \implies 0.5\cdot u(2y) + 0.5 \cdot u(y/2) &gt; u(y)$$</p>

<p>And <em>now</em>, attitude towards risk becomes critical. It is not difficult to deduce that <strong>under risk-taking and risk neutral behavior, we should Switch.</strong></p>

<p>As regards <strong>risk-averse behavior</strong>, I find an elegant result:   </p>

<p>For ""less concave"" (strictly above) utility functions than logarithmic (say, square root), then we should still Switch.</p>

<p><strong>For logarithmic utility $u(y) = \ln y$, we are indifferent between switching or not.</strong></p>

<p>For ""more concave"" than (strictly below)  logarithmic utility functions, we should <em>not</em> Switch.</p>

<p>I close with the diagram of the logarithmic case</p>

<p><a href=""https://i.stack.imgur.com/CUfRW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CUfRW.png"" alt=""enter image description here""></a></p>

<p>Assume $y=4$. Then $y/2 =2, 2y = 8$. The line $Γ-Δ-Ε$ is the line on which the expected utility from ""Switch"" will lie. Since nature plays a $50-50$ strategy, it will actually be at point $\Delta$, which is the middle point of $Γ-Δ-Ε$. At that point with logarithmic utility, we get exactly the same utility from ""Don't Switch"", i.e. $\ln(4)$ for this numerical example.</p>
","10133"
"Why isn't the Fed funds rate greater than interest rate on loans to the pubic","269","","<p>First of all, fed funds rate is the rate banks borrow reserves' from each other. Interest rate on loans is the rate the bank charges to public for its loan. From one line of logic, we think of the rate bank charges to public should clearly be greater than the interest rate itself bear to borrow since banks are making a margin. And empirical data clearly support it.</p>

<p>However, another line of logic does not quite support it. We know the banks borrow reserve money in fed funds market, which is clearly better than the money it lends to the public in the following sense: one unit of fed funds can support 10 units of additional deposit if the reserve-deposit ratio is 10%. So the banks with this addtional 1 unit of reserve, can theoretically make 10 more units of loans and therefore creating 10 more units of deposit. So reserve is better money. Hence, theoreticaly, the fed funds rate should at leastbe higher than the rate banks make loans to the public, if not 10 folds.</p>

<p>My question being whether there is a logical fallacy in my understanding and if not, what kind of reality deviated it from theory.</p>
","<p>I think you are missing the credit risk attached to any loan. You, as an individual borrower, are far more likely not to reimburse your loan than a bank. Thus the loan is far less risky.</p>

<p>Central bank money could only be qualified as ""better"" (even that does not mean much) because it is issued by the Central bank, deposits are issued by commercial bank, so you bear the risk that your bank fail, but it happens that in most country individual deposits are insured by some state agency. So I cannot really see why central bank money would be better than deposits.</p>

<p>Nowadays, the amount of reserves that a bank must hold does not actually play a big role in the economy (as opposed to what most of economic textbooks and economic professors are teaching in undergrad schools). The most important part is the interest rate that is paid on those reserve, which is fixed by the central bank and which act as an opportunity cost for the bank when it decides to lend to an individual rather than holding reserves.</p>

<p>However I see your point, but the fact is that this way of thinking is misleading. Banks create (in theory) as many loans as they want, because there are no physical constraints, if you want, that prevent them to do so. The only constraint is a regulatory constraint that states that in order to remain solvent (in order to be able to repay the depositors) banks should invest x% of the assets in reserves. Those reserves would be held on a central bank account in central bank money, and the return on those reserves will be the fed fund rate decided by the central bank (the same way a commercial bank decide how much interest it will pay on your savings account). So it is true that one more unit of reserves gives the right to issue more than one unit of loans but this does not mean that one money is better or worse than another. It's is just a matter of regulation.</p>

<p>It may be hard to get, but the point is really that central bank money is safer so cheaper than deposits, no matter what regulatory constraints apply to banks.</p>

<p>You may want to read this <a href=""http://web.stanford.edu/~kumhof/banks-lf-fmc.pdf"" rel=""nofollow"">paper</a> which may be a bit complicated but you should get the intuition. This two docs may be simpler (with nice pictures) : <a href=""http://www.bankofengland.co.uk/publications/Documents/quarterlybulletin/2014/qb14q1prereleasemoneyintro.pdf"" rel=""nofollow"">doc 1</a>, <a href=""http://www.bankofengland.co.uk/publications/Documents/quarterlybulletin/2014/qb14q1prereleasemoneycreation.pdf"" rel=""nofollow"">doc 2</a>.</p>
","9317"
"Deriving Simple Tax Multiplier with Calculus (Macro Ugrad)","267","","<p>It looks like I am making a calculus mistake here, and I am really banging my head against the wall.</p>

<p>Here is my work:</p>

<p>[img]<a href=""https://i.imgur.com/e19Fmrx.jpg[/img]"" rel=""nofollow noreferrer"">http://i.imgur.com/e19Fmrx.jpg[/img]</a></p>

<p>I know I should be getting $dY/dT=-(MPC)/(1-MPC)$, where $MPC=dC/dY$
If this is at all helpful here is a picture of page 295 in 7th edition of Macroeconomics By Mankiw that briefly describes the process. </p>

<p>[img]<a href=""https://i.imgur.com/VKPbZbz.jpg[/img]"" rel=""nofollow noreferrer"">http://i.imgur.com/VKPbZbz.jpg[/img]</a></p>

<p>It is confusing to me that he uses $C'$ for both terms on right-hand side when $C$ is composed of two arguments, so I decided to use Leibniz notation to see what is going on.</p>

<p>Thanks for help! 
Chris</p>
","<p>So here $C$ is a function with the argument $Y-T$, like $C=f(Y-T)$</p>

<p>So differentiate the equation: $dY=C' * (dY-dT)$</p>

<p>The result immediately follows like in the book. </p>

<p>The reason you don't do the partial derivative is that C has only one argument - while Y and T are in there, it only takes in 1 input. </p>
","13289"
"Historical US Housing Data Availability","265","","<p>Papers like <a href=""http://www.columbia.edu/~sn2294/papers/housing.pdf"">Ng and Moench (2011)</a> and <a href=""http://www.sciencedirect.com/science/article/pii/S0304393206002315"">Negro and Otrok</a> (2007) use historical housing data to estimate latent variables that correspond to some ""true"" or ""truer"" measure of house prices or housing activity. I've put together a table of series one could use as inputs in such an exercise. However, as we can see in the table below, very little data is available before the mid-1970s. I would like to expand this list with U.S. historical data (free or to purchase) that help to characterize real and financial housing activity as far back as possible.  What other series am I missing?</p>

<pre><code>+------------------------------------------------------+--------------+--------------+------------+
|                        Series                        |    Source    |  Frequency   | Start Date |
+------------------------------------------------------+--------------+--------------+------------+
| Median Sales Price of Single-Family Existing Homes   |  NAR         |  Monthly     |  Jan1968   |
| Median Existing Home Prices                          |  NAR         |  Monthly     |  Jan1999   |
| Median Sales Price of Single-Family New Homes        |  CENSUS      |  Monthly     |  Jan1963   |
| Average New Home Prices                              |  CENSUS      |  Monthly     |  Jan1975   |
| S&amp;P National Home Price Index                        | S&amp;P          |  Quarterly   |  Q1-1987   |
| Freddie Mac House Price Index                        |  FHLMC       |  Quarterly   |  Q1-1975   |
| FHFA Purchase-Only Index                             |  FHFA        |  Monthly     |  Jan1991   |
| FHFA Home Prices                                     |  FHFA        |  Quarterly   |  Q1-1975   |
| CoreLogic National House Price Index                 |  CoreLogic   |  Monthly     |  Jan1976   |
| Housing Starts                                       |  CENSUS      |  Monthly     |  Jan1959   |
| Existing Home Sales                                  |  NAR         |  Monthly     |  Jan1999   |
| New One-Family Houses Sold                           |  CENSUS      |  Monthly     |  Jan1963   |
| Housing Units Authorized by Permit                   |  CENSUS      |  Monthly     |  Jan1960   |
| Housing Units Under Construction                     |  CENSUS      |  Monthly     |  Jan1970   |
| Housing Completions                                  |  CENSUS      |  Monthly     |  Jan1968   |
| Private Residential Fixed Investment (PRFI)          |  BEA         |  Quarterly   |  Q1-1947   |
| Wilshire REIT Total Return Index                     |  Wilshire    |  Monthly     | Jan1978    |
| Ziman-CRSP Residential REIT Value Weighted Index     |  CRSP-Ziman  |  Monthly     | Jan1980    |
| Ziman-CRSP Residential REIT Equally Weighted Index   |  CRSP-Ziman  |  Monthly     | Jan1980    |
+------------------------------------------------------+--------------+--------------+------------+
</code></pre>

<p>Commercial real estate data is not ideal, particularly data that is contaminated with mine and oil and water well construction. Regional data is fine but national data is preferred.  </p>
","<p>I feel this barely qualifies as an answer, but doesn't Shiller have house prices data on his webpage? Currently <a href=""http://www.econ.yale.edu/~shiller/data.htm"" rel=""nofollow"">here</a>.</p>

<p>Specifically:</p>

<blockquote>
  <p>Historical housing market data used in my book, Irrational Exuberance [Princeton University Press 2000, Broadway Books 2001, 2nd edition, 2005], showing home prices since 1890 are available for download and updated monthly: <a href=""http://www.econ.yale.edu/~shiller/data/Fig3-1.xls"" rel=""nofollow"">US Home Prices 1890-Present</a>.</p>
</blockquote>

<p>I don't have much experience with this data directly, and am only aware of it through  Khandani, Merton, Lo (2013) (""Refinancing Ratchet Effect""), where they use this and many other data sources to construct a (very long) housing dataset for their simulation analysis.</p>

<p>Details of Case Shiller Series Construction methodology (from the end-notes of the 2006 edition for chapter 2):</p>

<blockquote>
  <p>Even though there were no regularly published home price indexes
  before the 1960s, some economists were constructing indexes of home
  prices that cover most of the years since 1890. We found home price
  indexes from 1890 to 1934 and from 1953 to the present that used in
  their construction some device to attempt to hold the quality of the
  home constant.</p>
  
  <p>The nominal home price index 1890–1934 is from Leo Grebler, David M.
  Blank, and Louis Winnick, Capital Formation in Residential Real
  Estate: Trends and Prospects (Princeton, N.J.: National Bureau of
  Economic Research and Princeton University Press, 1956). It is a
  repeated-measures index based on a survey of homeowners in twenty-two
  U.S. cities, who were asked to give the value of their home in 1934
  and the date and price of the purchase of that home. Since it is based
  on repeated measures of individual homes, the series is protected, in
  contrast to the simple median price, from any bias from changes in the
  mix of houses sold or of the increasing size and quality of newer
  homes. Its shortcoming is that it depends on memories of the surveyed
  homeowners for the earlier purchase price.</p>
  
  <p>The nominal home price index that we constructed for 1934–53 is a
  simple average over five cities of median home prices advertised in
  newspapers. The cities are Chicago, Los Angeles, New Orleans, New
  York, and Washington, D.C. My students collected the data from
  microfilmed newspapers at the Yale University library, collecting
  approximately thirty prices for each city and year, except that for
  the fifth city, Washington, D.C., 1934–48, data came from a median
  price series from E. M. Fisher, Urban Real Estate Markets:
  Characteristics and Financing (New York: National Bureau of Economic
  Research, 1951). The median series for 1934–53 does not make any
  attempt to correct for home quality change, as do the indexes we use
  for the other subperiods. Improvement in home size and quality gives
  median home price an upward bias, and this is why I avoided using
  median price outside the 1934–53 interval.</p>
  
  <p>The nominal home price index for 1953–75 is the home purchase
  component of the U.S. Consumer Price Index (CPI). The Bureau of Labor
  Statistics collected data on home prices for those years for homes
  that are held constant in age and square footage. In the 1980s they
  discontinued this index when they switched to a rental equivalence
  basis for housing in the CPI. They made this change to correct what
  was considered a conceptual flaw in the housing component of the CPI:
  the CPI is supposed to be a price of consumption goods and services,
  not of investment assets. For our purposes, however, the old home
  purchase component is acceptable. There are, however, some
  shortcomings in the home purchase component, notably that it is based
  only on homes with certain government-subsidized mortgages, and the
  procedure that the Bureau of Labor Statistics used to correct for
  changes in the ceiling on these mortgages was not optimal. See J. S.
  Greenlees, “An Empirical Evaluation of the CPI Home Purchase Index
  1973–8,” American Real Estate and Urban Economics Association Journal,
  Carnegie-Rochester Conference Series on Public Policy, 17 (1982):
  203–38.</p>
  
  <p>The nominal home price index for 1975–87 is the U.S. home price index
  published by the U.S. Office of Housing Enterprise Oversight (OFHEO),
  which is available on their Web site. It is a repeat sales index, and
  thus controls for quality change. The nominal home price index for
  1987–2004 is the repeat-sales U.S. home price index produced by Fiserv
  CSW, Inc., successor to Case Shiller Weiss, Inc.</p>
  
  <p>Since 1987, the CSW and the OFHEO series have shown very similar
  patterns through time, though the sharpness of the increase is
  slightly more pronounced in the CSW series, an observation we
  attribute to the fact that our series is based only on actual sales,
  while the OFHEO series also uses both actual sales and appraised
  values as if they were sales. Appraised values are somewhat sluggish
  to respond to new market conditions.</p>
</blockquote>
","1660"
"Pros and Cons of Elasticity of Demand Represented as an Absolute Value","265","","<p>I've been reading quite a bit about elasticity of demand. There seems to be an argument among texts as to whether elasticity of demand should be represented as negative or as an absolute value. The argument for one method over the other depends on the text, but generally boils down to ""because this is how we do it."" I'm looking for a more meaningful discussion about this topic.</p>

<p>What are the pros and cons of using the negative? Of the absolute value?</p>
","<p>Elasticity of demand is almost always assumed to be negative. It is assumed that there is an inverse relationship between price and quantity demanded. If you want to buy 2 hamburgers for <code>$5</code> each you aren't suddenly going to want to buy 3 hamburgers if they now cost <code>$10</code> each. If this isn't the case it means that consumers aren't rational which blows up 99% of the models economics has to offer.</p>

<p>Because the elasticity of demand is always negative it can be assumed that if I say X is the elasticity of demand I mean X is negative because elasticity of demand is always negative. If I say -X is the elasticity of demand you can still assume that it is negative because a) I said it explicitly, and b) it is always true.</p>

<p>At this point it's just a matter of preference and doesn't matter either way, I just wanted to explain why it really doesn't matter since someone who understands what elasticity of demand means will understand that it will always be negative in almost all scenarios.</p>

<p>Personally, I think that explicitly saying that the elasticity of demand is negative is a better choice since I can imagine some fringe scenarios where a product being expensive leads to that product being sold more often, (I think of caviar as an example for these types of products, where consumers buy it precisely because its expensive) but for most economic models the assumption holds.</p>
","16378"
"Independence axiom of lottery when $\alpha \ge 1$","263","","<p>When studying preference over lotteries we learned the independence axiom which goes like this:</p>

<blockquote>
  <p>The preference relation $\succsim$ on the space of simple lotteries $\mathscr{L}$ satisfies the independence axiom if for all $L$，$L^\prime$，$L^{\prime \prime} \in \mathscr{L}$ and $\alpha \in (0,1)$ we have </p>
  
  <p>$$L \succsim L^\prime \iff \alpha L + (1 - \alpha) L^{\prime \prime} \succsim \alpha L^{\prime} + (1 - \alpha) L^{\prime \prime} $$</p>
</blockquote>

<p>What if $\alpha \ge 1$?  I guess that will be a quick extension for the case of $\alpha \in (0,1)$ but I don't know how to show it. </p>
","<p>To understand why $\alpha$ <em>must</em> be constrained in $(0,1)$, one has to contemplate the meaning of the expression</p>

<p>$$\alpha L$$</p>

<p>when $L$ is a ""lottery"". How is a lottery denoted mathematically? Authors do not agree on that: for example, the way <strong><a href=""http://rads.stackoverflow.com/amzn/click/0273731912"" rel=""nofollow"">Jahle and Reny</a></strong> define a lottery (a ""gamble"" in their terminology), a lottery can be written as a vector whose elements are bivariate vectors themselves:</p>

<p>$$L=\{(p_1,w_1),...,(p_n, w_n)\}$$</p>

<p>where $p_i$ are probabilities, and $w_i$ are quantitative outcomes. </p>

<p>But <strong><a href=""http://rads.stackoverflow.com/amzn/click/0195073401"" rel=""nofollow"">MasColell, Whinston and Green</a></strong>, define a lottery as a vector <em>containing only the probabilities</em>:</p>

<p>$$L=\{p_1,...,p_n\}$$</p>

<p>and so the ""Lottery Space"" is a vector space, including vectors each containing only probabilities.</p>

<p>But in both cases, the authors make clear that an expression like $\alpha L$, when the time comes to translate it into a mathematical operation, denotes a <em>multiplication</em> of only the <em>probabilities</em> linked with $L$ by <em>another probability</em>, $\alpha$. This is implementing the reduction of compound lotteries to simple ones. <strong>JR</strong> describe it as ""the decision maker cares only about <em>effective</em> probabilities of each outcome"". <strong>MWG</strong> call it the ""consequentialist premise"", that allows them to work only with simple lotteries.</p>

<p>So it is not valid to consider $\alpha$ outside $(0,1)$, because it is defined as a probability (the open bounds are used in order to avoid triviality in the statement of the Independence axiom).  </p>

<p>Also, the above imply that $\alpha$ does not directly interact with the quantitative outcomes of the lottery/gamble...  </p>

<p>...which points to a (perhaps interesting, perhaps not) research direction: What can we say (if anything), if we start tweaking the <em>outcomes</em> linked with a lottery? Will ""attitude towards risk"" get in the way and prevent us from drawing any general conclusions? Or not?</p>
","8695"
"Given the supply and demand function what is the difference?","262","","<p>Given some unspecified demand and supply functions.</p>

<p>I need to calculate quantity and price after taxation, but what is the difference between having a tax of 20% of total revenue and 20% of profits ($\pi$)? I mean how to calculate this tax in those two cases? And what precisely should be changed when calculating Q and P after tax of those two types is imposed on.</p>

<p>Whether tax of 20% of total revenue creates simply consumer price on a level of $1.2(\text{producerprice})$ or is it something different? In case of profits is it $0.8(\text{supplyfunction})$?
**hope this question now satisfies required format **</p>
","<p>Deriving those functions, you can find $p^*$ and $Q^*$, which, multiplying both, should give you equilibrium profits. Now, if you take that tax rate (20%, I reckon?), you can calculate taxes over profits and the tax-free price.</p>

<p>To find the equilibrium price $p^*$, you need to have those two functions in a system and solve for $p$. Then, just replace it on both functions and you should have equilibrium quantities.</p>

<p>Now, I'm assuming demand absorves all quantities produced by companies, no production restrictions and that this market is one in perfect competition. If this last paragraph changes, then my solution will not be correct.
To answer your question - what is the difference -, well, in this case, it is none because we are not considering production costs. If we did, you can see that both values would change.</p>

<p>Nevertheless, to calculate taxes, you need to work around with the system. That will give you total revenues, cost and tax free. Applying 20% leads to net earnings, because you do not have any production costs associated with the problem - something commonly done in Economics. That or consider a variable $c$ of costs.</p>

<p>This kind of exercises are also good to understand what are the effects of  costs on revenues/profits. There's actually a financial term for that but I cannot recall :) </p>
","10467"
"How much would it take to end global extreme poverty?","262","","<p>E.g., according to <a href=""http://www.visionofearth.org/economics/ending-poverty/how-much-would-it-cost-to-end-extreme-poverty-in-the-world/"">this page</a>, Jeffrey Sachs estimated that it would take $175bn/year for 20 years to do so.</p>

<p>What are some other estimates?</p>
","<p><em>The Economist</em> (Oct 8th, 2016, <a href=""http://www.economist.com/news/finance-and-economics/21708245-world-should-be-both-encouraged-and-embarrassed-latest-global-poverty"" rel=""nofollow noreferrer"">online</a>, <a href=""https://drive.google.com/open?id=0B6d27XgslBsBc0FQLTJ1bmkyTDg"" rel=""nofollow noreferrer"">PDF</a>) attempts to answer this question.</p>

<p>It defines the <strong>global poverty gap</strong> as the amount we'd have to <strong>transfer</strong> to the world's extreme poor (defined as those living below $\$1.90$ a day, at 2011 PPP), in order to lift them to the $\$1.90$ a day threshold. </p>

<p>The evolution of this global poverty gap from 1990-2013 is graphed below. As should be evident, at the current rate of decline in global extreme poverty, the world is on track to hit the World Bank's goal of completely eliminating extreme poverty by 2030. </p>

<p><a href=""https://i.stack.imgur.com/Yz5mgm.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Yz5mgm.jpg"" alt=""enter image description here""></a></p>

<p>Nonetheless, even if there were no further progress and global extreme poverty stayed frozen at 2013 levels, </p>

<h2>a transfer of US\$78b a year would suffice to completely eliminate extreme poverty.</h2>

<p><em>The Economist</em> adds an important caveat:</p>

<blockquote>
  <p>In reality, of course, money cannot be directed so precisely
  to the poor, nor transferred cost-free. In some countries, the infusion
  of money might also push up prices and currencies, making
  the endeavour more expensive. Nonetheless, this thought experiment
  illuminates the diminishing size of the problem. The world
  can afford to end poverty. Indeed, it might end poverty before it
  figures out how to measure it accurately.</p>
</blockquote>

<p>$$$$</p>

<p>P.S. Note though that the reduction in global extreme poverty has been largely due not to transfers or aid of the sort envisioned by Jeffrey Sachs, but to economic progress, most notably in China. </p>

<p><a href=""https://i.stack.imgur.com/4jpV6m.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4jpV6m.jpg"" alt=""enter image description here""></a></p>
","13791"
"How do central banks regulate the money supply to avoid inflation?","261","","<p>It is a tricky problem. Historically, poor control money supply led to inflation. Out of control money supply led to hyperinflation. Central banks seem to do a wonderful job in recent years with modern economies seeing low inflation despite quantitative easing.</p>

<p>How do they do it?</p>
","<p>The answer provided by Mick is pretty good, but I'll put my own spin on this.</p>

<p><strong>1st: What is inflation?</strong>  </p>

<p>Roughly speaking it is when the ratio of money to the things money buys increases.  A bumper food crop can reduce inflation.  Crop failure can increase it.  But certainly the most volatile component of inflation is the supply of money itself.  Economists love to exaggerate the importance of the former (productivity) to cover-up the mess they are making with the latter (money supply).</p>

<p><strong>2nd: What is the supply of money?</strong>  </p>

<p>A difficult answer, as money is whatever we accept.  But the most common forms of money however are classified into large aggregates by economists. </p>

<ul>
<li>MB: Aka the monetary base in the USA (all money created by the
government...coins, dollar bills, us notes fed deposits)</li>
<li>M1: Bank demand depots (promises of MB) plus cash outside of the banking system</li>
<li>M2: M1 + interest bearing deposits and other checking substitutes</li>
</ul>

<p>Because private banks can get away with promising more money then they have...and we accept this...then banks actually create money.  And because the higher aggregates like M2 are much larger than MB, it is plain to see that banks are more important variables to the money supply equation and the supply of government money (aka MB).</p>

<p><strong>3rd: How does the Fed regulate the money supply?</strong></p>

<p>It is confusing because the Fed directly dictates the amount of base money in the economy, but also indirectly dictates how much bank money is in an economy.</p>

<p>The primary means by which MB changes include discount loans to banks, buying and selling repos from big banks, and special bailouts.</p>

<p>The primary means by which the Fed controls the supply of bank money is through the open market.  The idea is if the banks have more base money, they will be able to pyramid more deposits on top of that, and vice versa.  To facilitate this the Fed will buy repos from a primary dealer (""special banks"") with fabricated money.  The primary dealer than resells the new reserves to lesser banks which then allows them to create more bank money.  </p>

<p>Historically, controlling the supply of bank deposits through a reserve ratio was a technique used (and also capital requirements), but these techniques are not considered fashionable among entrenched interests.   </p>

<p><strong>Has the Fed been doing a good job?</strong></p>

<p>This is a complicated question.  QE did not create massive inflation because the banking sector was in collapse and a large amount of bank deposits had been destroyed (meaning we had less money).  Whether private for-profit interests should have had privileged access to government resources is a very good question.  Certainly the problem of 2008 was created by the banks themselves. Simply put, they made promises to depositors and creditors they couldn't keep.  Banks operate by mismatching short term/low yield debt to long term/high yield debt.  This is a very profitable but risky practice in which banks are not held proportionately responsible when things go wrong.</p>

<p>Classifying inflation is also very tricky because of international trade.  The dollar is a popular currency overseas, so foreigners help sponge up the damage from inflation.  Trade also obfuscates inflation. If you double say the number of dollars, not all prices will increase proportionately.  International commodities can be brought in multiple currencies, whereas local products (like healthcare and college education) can't and can only be purchased with dollars so they increase much more rapidly.  </p>

<p>For a fascinating look at the politics of CPI/inflation, checkout: <a href=""http://www.shadowstats.com/article/no-438-public-comment-on-inflation-measurement"" rel=""nofollow noreferrer"">http://www.shadowstats.com/article/no-438-public-comment-on-inflation-measurement</a></p>

<p>The most paramount question unasked is if the Fed is seeding the conditions by which another future crisis will happen, to which I fear the answer is yes.</p>
","14623"
"Constant Elasticity of Substitution: Special Cases","260","","<p>Take an $n$-commodity constant elasticity of substitution utility function,</p>

<p>$$U = \left[\sum^n_{i=1} \alpha_i x^\rho_i \right]^\frac{1}{\rho}$$</p>

<p>How do we show the following:</p>

<ul>
<li>Show that as $\rho \rightarrow 0$ that this utility function represents preferences for Cobb-Douglass utility. $U(x) = \prod^n_{i=1} x_i^{\alpha_i}$</li>
<li>Show that as $\rho \rightarrow - \infty$ that this utility function has the indifference curves as in Leontief utility. $U(x) = \min\left\{x_1,...,x_n\right\}$</li>
</ul>
","<p>We know that if $u$ represents $\succeq$ on $X$, then for any strictly increasing function $f: \mathbb{R} \rightarrow \mathbb{R}$, then $v(x) = f(u(x))$ represents $\succeq$ on $X$</p>

<p>($X$ in this case is $\mathbb{R^n}$)</p>

<p>Consider $v(x, \rho) = \ln(u(x, \rho)) - \frac{\ln\left[\sum^n_{i=1}\alpha_i \right]}{\rho}$, which is strictly increasing.</p>

<p>$$v(x, \rho) = \frac{\ln\left[\sum^n_{i=1} \alpha_i x^\rho_i \right]}{\rho} - \frac{\ln\left[\sum^n_{i=1}\alpha_i \right]}{\rho} = 
\frac{\ln\left[\sum^n_{i=1} \alpha_i x^\rho_i \right] - \left [\ln\sum^n_{i=1}\alpha_i \right]}{\rho}$$</p>

<p>The limit of this as $\rho \rightarrow 0$ is indeterminate, $\frac{0}{0}$. So we can use L'Hopital's Rule and take the derivative with respect to $\rho$ of the numerator and denominator.</p>

<p>$$\lim_{\rho \rightarrow 0} \frac{\ln\left[\sum^n_{i=1} \alpha_i x^\rho_i \right] - \left [\ln\sum^n_{i=1}\alpha_i \right]}{\rho} = 
\lim_{\rho \rightarrow 0} \frac{1}{\sum^n_{i=1} \alpha_i x_i^\rho} \cdot \left(\sum^n_{i=1} \alpha_i x_i^\rho \ln x_i\right)$$</p>

<p>by the Chain Rule.</p>

<p>$$= \lim_{\rho \rightarrow 0} \frac{\sum^n_{i=1} \alpha_i x_i^\rho \ln x_i}{\sum^n_{i=1} \alpha_i x_i^\rho} = \frac{\sum^n_{i=1} \alpha_i \ln x_i}{\sum^n_{i=1} \alpha_i} = \frac{1}{\sum^n_{i=1} \alpha_i} \cdot \ln\left(\prod^n_{i=1} x_i^{\alpha_i}\right)$$</p>

<p>Consider $w(x, \rho) = \mathrm{e}^{(\sum^n_{i=1} \alpha_i) \cdot v(x, \rho)}$, which is another monotonic transformation, strictly increasing. So $w$ still represents the same preference as $u$.</p>

<p>$$\lim_{\rho \rightarrow 0} w(x, \rho) = \mathrm{e}^{(\sum^n_{i=1} \alpha_i) \cdot \lim_{\rho \rightarrow 0} v(x, \rho)} = \prod^n_{i=1} x_i^{\alpha_i}$$</p>

<p>which is a Cobb-Douglas function. </p>

<p>$\square$</p>

<hr>

<p>To show the second point, it is sufficient to show that</p>

<p>$$\lim_{\rho \rightarrow -\infty} u(x) = \left\{x_k \ \forall j \neq k \mid x_j \geq x_k \right\}$$</p>

<p>$$u(x) = \left[\sum^n_{i=1} \alpha_i x^\rho_i \right]^\frac{1}{\rho} = x_k \left[(\sum^n_{i=1, i \neq k} \alpha_i x^\rho_i) + \alpha_k \right]^\frac{1}{\rho}$$</p>

<p>$(\frac{x_j}{x_k})^\rho \rightarrow 0$ as $\rho \rightarrow -\infty$ if $x_j &gt; x_k$</p>

<p>$(\frac{x_j}{x_k})^\rho \rightarrow 1$ as $\rho \rightarrow -\infty$ if $x_j = x_k$</p>

<p>So </p>

<p>$$\lim_{\rho \rightarrow -\infty} x_k \left[(\sum^n_{i=1, i \neq k} \alpha_i x^\rho_i) + \alpha_k \right]^\frac{1}{\rho} = x_k$$</p>

<p>since $1/\rho \rightarrow 0$ and a constant to the zeroth power is 1.</p>

<p>Construct a similar argument for any $k$. Thus $\lim_{\rho \rightarrow -\infty} u(x) = \min \left\{x_1,...,x_n \right\} $</p>

<p>$\square$</p>
","8770"
"Help with Income Elasticity Exercise in Becker's Economic Theory","260","","<p>On page 18 of his book <em>Economic Theory</em>, Gary Becker provides the reader with the following exercise (no answers given):</p>

<p><strong>Exercise Statement:</strong></p>

<p><em>Write the formula $\sum_j K_jN_j = 1$ where $N_j$ is the market income elasticity of demand for the $j$th good and $K_j$ is the fraction of total market income spent on $j$, in terms of the $\eta_{ij}$ and $k_{ij}$, where these are the income elasticities and shares of the $i$th person for the $j$th good. First derive the $N_j$ in terms of the $\eta_{ij}$. Is $N_j$ a simple average of the $\eta_{ij}$, or do higher income persons have a greater weight than lower income persons?</em> </p>

<p><strong>My Question:</strong></p>

<p>What does $\sum_j K_jN_j = 1$ represent? </p>

<p>My first intuition was I understand why the sum of all $K_j$ shares would add up to a whole. The sum of all shares equals the total income which could be 1. So $K_j$ would then just be a percentage of the whole. But what then would $K_jN_j$ represent? This is where I got stuck. </p>

<p>EDIT: </p>

<p>Okay here's my first stab at the problem: </p>

<p>We know $\eta_{ij}$ represents the income elasticity of individual $i$ with respect to the $j$th good. So by definition, the income elasticity is defined as 
\begin{equation} 
\eta = \frac{\partial Q}{\partial I} \frac{I}{Q}
\end{equation} </p>

<p>We also know the fraction of total market income individual $i$ spends on good $j$ is $k_{ij}$. I reason that this should be just the amount spent on the good divided by the total income of individual. So it should be 
\begin{equation} 
k_{ij} = \frac{p_jq_j}{I}
\end{equation} </p>

<p>I still don't see how this should come out to $1$ though. Unless we are thinking that elasticities cancel out, such that for every $\eta_i$, $\exists$ $\eta_j = \frac{1}{\eta_i}$ such that $\eta_i\eta_j=1$. </p>
","<p>Just to show that indeed, $\sum_j K_jN_j = 1$, we have the following:</p>

<p>$K_j$ is the fraction of total expenditure directed to good $j$. Total expenditure is also market income (denote it by $I_m = p_1Q_1+...+p_nQ_n$). so</p>

<p>$$K_j = \frac {p_jQ_j}{I_m}$$</p>

<p>$N_j$ is the <em>market</em> income elasticity of demand for good $j$. So
$$N_j = \frac {\partial Q_j}{\partial I_m}\cdot \frac {I_m}{Q_j}$$</p>

<p>Therefore</p>

<p>$$K_jN_j = \frac {p_jQ_j}{I_m}\cdot \frac {\partial Q_j}{\partial I_m}\cdot \frac {I_m}{Q_j}$$</p>

<p>Simplify,</p>

<p>$$K_jN_j = p_j\frac {\partial Q_j}{\partial I_m}$$</p>

<p>Silently, we assume that prices are not affected. So we can insert the price into the partial derivative</p>

<p>$$K_jN_j = \frac {\partial (p_jQ_j)}{\partial I_m}$$</p>

<p>Then</p>

<p>$$\sum_j K_jN_j = \sum_j\frac {\partial (p_jQ_j)}{\partial I_m} = \frac {\partial }{\partial I_m}(p_1Q_1+...+p_nQ_n) = \frac {\partial I_m}{\partial I_m} = 1$$</p>

<p>By weighting the income demand elasticity for each good by the expenditure-weight it has on the whole economy, we essentially arrive at a tautology, saying ""if total market expenditure increases by 100 Euros, then ... total market expenditure will increase by 100 euros"". What Becker wants is to decompose this tautology into something a bit more insightful, as regards differences in individual incomes.</p>
","4669"
"Critiques to Mankiw, Romer, Weil (1992) paper on Economic Growth","259","","<p>I'm searching for bibliography on the critiques to the <a href=""http://eml.berkeley.edu/~dromer/papers/MRW_QJE1992.pdf"" rel=""nofollow"">Mankiw, Romer, Weil (1992)</a> paper.</p>

<p>If possible, could you give references to each critique?</p>

<p>Any help would be appreciated.</p>
","<p>Here are three:</p>

<p><a href=""http://www.nber.org/chapters/c11037.pdf"" rel=""nofollow"">Klenow, P., &amp; Rodriguez-Clare, A. (1997). The neoclassical revival in growth economics: Has it gone too far?. In NBER Macroeconomics Annual 1997, Volume 12 (pp. 73-114). MIT Press.</a></p>

<p><a href=""http://www.ecostat.unical.it/aiello/Didattica/economia_Crescita/CRESCITA/CrescitaKlenow-rodriguez-Clare-JME-1997.pdf"" rel=""nofollow"">Klenow, P. J., &amp; Rodriguez-Clare,A. (1997). Economic growth: A review essay. Journal of monetary economics, 40(3), 597-617.</a></p>

<p>They pose certain conceptual issues as regards entangled causalities (in the economics' sense, not in the econometrics' sense).</p>

<p>All are freely downloadable.</p>

<p><a href=""http://www.nber.org/chapters/c11063.pdf"" rel=""nofollow"">Bernanke, B. S., &amp; Gürkaynak, R. S. (2002). Is growth exogenous? taking Mankiw, Romer, and Weil seriously. In NBER Macroeconomics Annual 2001, Volume 16 (pp. 11-72). MIT Press.</a></p>

<p>This paper argues that one of the most important implications of any Solow framework is that long-run growth depends only on exogenous technological progress, and that MRW do not test in the right way this implication (the authors do it their way and reject this implication).</p>

<p>But I don't think you will find papers with deep <em>statistical-econometric</em> testing/validation of the model.</p>
","11198"
"Why must there be an equilibrium in the money market?","259","","<p>Probably this question is a bit(or very) stupid.</p>

<p>I'm self-teaching by reading a book on macro, and the author states that in the Money Market, when the output increases the demand for money also increases, and given a certain money supply, the interest rate must go up to maintain the equilibrium. So, in this case, the Central bank(CB) would just sell bonds => diminish price of bonds=> increase interest rate. 
My question is, why should this equilibrium be maintained? Isn't there a situation, when people may want more money to acquire/trade, but the CB just won't sell bonds?</p>

<p>Any help would be appreciated</p>
","<p>In your textbook, it says that <em>given a certain money supply</em>, the interest rate must increase if the demand for money increases.</p>

<p>The money supply is determined by the central bank, which can buy bonds (which takes bonds out of circulation and increases the supply of money in circulation), or sell bonds (putting bonds in circulation but decreasing the supply of money in circulation). It can also, as in your example, do nothing.</p>

<p>If the demand for money increases, then market participants are willing to either ""buy"" more money at a given price (where the ""price"" of money is the interest rate), or pay a higher price for a given amount of money. This is true of all goods— and so long as demand isn't either perfectly elastic or perfectly inelastic, both are true.</p>

<p>So since in your example the money supply is fixed (i.e., the supply curve is perfectly inelastic), if the demand for money increases, the interest rate will increase. The interest rate increasing as a result of increased demand for money isn't dependent on the central bank doing anything, it's dependent on the central bank doing nothing.</p>

<p>In practice, central banks usually target a particular interest rate. When they do so, they can't directly observe the demand for money, but they can observe the equilibrium price (i.e., the interest rate). So what they do is engage in open-market operations— buying [or selling] bonds to increase [or decrease] the supply of money, in turn decreasing [or increasing] the interest rate until it is close to their target.</p>
","7047"
"Is there a model for how much a philosopher produce in his lifespan?","258","","<p>Is there a model for how much a philosopher produce in his lifespan?</p>

<p>If not, state the economical reason for why we pay the philosopher.</p>
","<p>Here is a somewhat creative (and very imprecise) answer:</p>

<p>Let's assume that Philosophy creates no direct value for society (which seems implicit in your question). However, Mathematics and various other scientific disciplines to some extent originated from Philosophy. Most recently, Linguistics originated as a field of Philosophy. Based on this we can estimate the marginal product of a philosopher. You will need two numbers:</p>

<p>A: Take the marginal value of each invention generated by these fields. For example, speech recognition on your cell phone would not have been possible without Linguistics and thus Philosophy. You can estimate the marginal value of speech recognition by your willingness to pay for a phone with or without speech recognition. Do this for all products and services of an economy. (You can also take market prices and make some strong assumptions about the economy, such as competitive markets, etc.). Using time discounting, you can estimate the value of having a product one year earlier.</p>

<p>B: You must now assign the marginal contribution of a philosopher to the invention of linguistics to the speech recognition software. The marginal contribution seems to be infinite, since without linguistics there would be no speech recognition. However, you may simply assume that each additional Philosopher speeds up the process of the invention of linguistics by an equal amount. Thus, if you would have hired one more philosopher, the time needed to invent Linguistics would have been N/(N+1) the time N philosophers needed to actually invent linguistics.</p>

<p>Combining the information from A and B for all products gives you the marginal product of each philosopher. Note that this is only a rough answer and one would still need to carefully formulate the assumptions. However, it gives you a rough idea of how you could go about finding the marginal product of an otherwise unproductive philosopher.</p>
","10910"
"What would be the disadvantages of a TTIP?","258","","<p>Well the question kind of says it all, what I would like to know is,if a TTIP between America and EU is put in place even though not only Europe and America will benefit from it but also other countries who export to Europe and America because of the augmentation of demand, would there be any drawbacks for consumers? I know that some companies will find it hard to compete with others but then again what could that cause for us consumers ?
Sorry for my bad English its been a long time. </p>
","<p>TTIP is a combination of trade agreements and property rights / legal changes.</p>

<h3>Trade Liberalization</h3>

<p>Most of the current debate in European countries is not so much about trade - we all know trade liberalization yields welfare gains. In the first-order, these are split between consumers and firms: Consumer get a larger variety / cheaper goods, and (surviving) firms can reach more customers. </p>

<p>These are <em>efficiency gains</em>, and could be split up anyhow between these two groups. To the extent that surviving firms get some of these welfare gains, workers of these firms might get some of the benefits. I'm trying to be very cautious here, because on this last bit, I don't think we have sufficient empirical evidence - and theory will support different results based on the wage setting mechanism.</p>

<p>Of course, there will be firms that lose, and workers that will be fired - which is why the US has set up (I think under WIA) Trade Adjustments Assistance for workers who lost their jobs due to trade. This is one way of sharing the welfare gains of trade with those who lose.</p>

<h3>Copyright and Regulation</h3>

<p>The issue with TTIP is mostly the legal power that firms get. US american firms could sue France for french regulation at US courts. This downside is off topic here. However, the angst here is that is not welfare gains for each single country. Countries with stronger regulations will lose. Even for the world as a whole, it is unclear whether this yields efficiency gains, or whether firms just reap surplus from countries/governments.</p>
","5152"
"Intuition of the Kolmogorov Equations","257","","<p>So I understand the derivation of the Kolmogorov Forward and Backward Equations, but I don't quite understand the intuition.  Here is from Stokey, 2008:</p>

<p>""The backward equation involves time $t$ and the initial condition $x$, with
the current state $y$ held fixed. A similar PDE, the Kolmogorov forward
equation (KFE), involves $t$ and $y$, with the initial state $x$ fixed. The forward
equation is useful for characterizing the limiting distribution, if one exists.""</p>

<p>In what situations do the two arrise?  For instance, if I know the current state and am interested in a probability distribution over possible initial states, I use the backward equation.  If I know the current state and am interested in the probability distribution over the state in the future, I use the forward equation.  Is this correct?</p>

<p>On a more technical note, how does one define boundary conditions for these PDE's?  Are the boundary conditions a result of the derivation?  Perhaps Stokey is not the best reference on this topic...</p>
","<p>I will try to answer to your last question. I did not read the paper but in models with higher dimensions, it is always difficult to find an analytical solution. 
If there exists an analytical solution (for a very basic model with a one-state variable), it is possible to derive the initial conditions for your control and state variable from your differential equations.</p>

<p>However, in systems where there does not exist an analytical solution, you are supposed to solve it numerically, in which case you must give a numerical value for one of your variables (or more until you find steady state values for all your variables.)</p>

<p>After, you can find the steady-state values of your variables in which case, your initial conditions should not be so far from the steady state level (otherwise, there would be some convergence problems in your model if you don't choose the appropriate initial values, close to steady state. It is another issue.)</p>
","8198"
"Math basics for Macro&Micro economics and econometrics","257","","<p>I have just been admitted to a graduate school for studies in economics and I major in public administration during my undergraduate time. I have learnt linear algebra, single variable calculus, probability theory and mathematical statistics by myself(Otherwise I will not be admitted). After all I am a amateur in economics, and I have another 5 months to go before register to the graduate school. </p>

<p>So, I think I'd better to equip myself with solid mathematical knowledge to deal with the courses in the first year, which are showed in the title.</p>

<p>ps. The books I will use in these courses are:</p>

<blockquote>
  <p><em>Microeconomic Theory</em>, Andreu Mas-Colell </p>
  
  <p><em>Advanced Macroeconomics</em>, David Romer</p>
  
  <p>And there is no prescribed textbook for econometrics.</p>
</blockquote>

<p>Any ides are going to be appreciated, and if I didn't make a clear expression of my question, please tell me to edit my question.</p>
","<p>I recommended familiarity with the following topics: </p>

<ul>
<li>partial differentiation and optimization of multivariate functions </li>
<li>study fixed point theorems. Kakutani and Brower are good ideas. </li>
<li>Set theory is very important </li>
<li>analysis (especially sequences, sub-sequences, convergence of sequences, etc.) </li>
<li>Topology (basics is good enough. For example, understanding the open ball for local non-satiation)</li>
<li>Contraction mapping theorem (For Bellman equations in Macro) </li>
<li>Value functions / Bellman equations </li>
<li>Envelope Theorem </li>
<li>Be very comfortable with calculus (so...do some review if you aren't) </li>
<li>Familiarize yourself with the simplex </li>
<li>basic ideas of function properties like concavity, convexity, quasi-concavity, quasi-convexity, continuous, differentiable, discontinuity etc. </li>
<li>Take a look at point-to-set mappings </li>
</ul>

<p>Edit: </p>

<ul>
<li>I'll add for point to set mapping that upper, lower-hemicontinuity and hemicontinuity are necessary as well</li>
<li>Taylor expansions around a point c for multivariate and log functions</li>
<li>glance over methods of log-linearization </li>
<li>This isn't too hard but very important: binary relations over finite and infinite sets. To be a bit more specific - completeness, transitivity etc. 
I also recommend being familiar with cyclicity etc. </li>
<li>The separating and supporting hyperplane theorems </li>
</ul>

<p>This may sound silly, but also make sure you are ridiculously comfortable with algebra. Sometimes I feel like the unending onslaught of algebra is the thing that slows me down the most during exams etc. </p>

<p>Edit: I'd like to recommend a book for math prep that covers almost everything I've listed: The Foundations of Mathematical Economics by Michael Carter </p>

<p>It's a solid book with good exercises and readily available solutions to confirm your answers.</p>

<p>Alright - I tried to give you some specific things rather than provide the broad strokes. I figure it is easy enough to know that you should study a subject and so I've tried to highlight what I remember being the important little bits of math that we use most often. </p>

<p>Good luck with graduate school.</p>
","11619"
"Can a risk-averse agent's Certainty Equivalent be lower than the lowest possible outcome of a gamble?","256","","<p>Suppose there is an agent who faces the following gamble g: </p>

<ul>
<li>50\$ with probability 1/3</li>
<li>100\$ with probability 1/3</li>
<li>150\$ with probability 1/3</li>
</ul>

<p>Clearly, the E[g] = 100\$. Since agent is risk averse, we would expect that U(E[g]) &lt; U(CE) , where CE is the certainty equivalent. Now, my question is, is it hypothetically possible that the agent's Certainty Equivalent of this gamble will be below 50\$, or is it necessarily true that it will be somewhere between 50\$ and 100\$?</p>
","<blockquote>
  <p><em>""Since agent is risk averse, we would expect that $U(E[g]) &lt; U(CE)$ ,
  where $CE$ is the certainty equivalent.""</em></p>
</blockquote>

<p>This is wrong. I presume the Expected Utility Property holds here, so, if we denote the gamble by $G$, a discrete uniform random variable taking three values according to the setup, we have</p>

<p>$$U(CE) \equiv \sum_{i=1}^3p_iU(g_i) = E[U(G)] &lt; U[E(G)]$$</p>

<p>the inequality to the right due to Jensen's Inequality and the assumption that $U()$ is concave. This also gives us</p>

<p>$$ CE &lt; E(G)$$</p>

<p>which should be intuitive: a risk-neutral person would demand $E(G)$, the expected value of the gamble, in order not to take it. A risk-averse person would require <em>less</em>, to leave the gamble.</p>

<p>Having cleared this, the OP asks: <strong>Is it possible that $CE &lt; \min G$?</strong></p>

<p>The answer is : <strong>No.</strong> Assume that the gamble outcomes are ordered, so $\min G = g_1$.</p>

<p><strong>Ad absurdum</strong>, assume that $CE &lt; g_1$ holds. Then we will have</p>

<p>$$U(CE) &lt; U(g_1)$$</p>

<p>Using the definition of $CE$ we replace the left-hand side</p>

<p>$$\sum_{i=1}^3p_iU(g_i) &lt; U(g_1) \implies p_2U(g_2) + p_3U(g_3) &lt; (1-p_1) U(g_1)$$</p>

<p>$$\implies p_2U(g_2) + p_3U(g_3) &lt; p_2U(g_1) + p_3U(g_1)$$</p>

<p>$$\implies p_2[U(g_2)-U(g_1)] + p_3[U(g_3)-U(g_1)] &lt; 0$$</p>

<p>But this is impossible since $g_1 = \min\{g_1,g_2, g_3\}$ and so</p>

<p>$U(g_2)-U(g_1) &gt;0$ and $U(g_3)-U(g_1) &gt;0$.</p>

<p>So assuming $U(CE) &lt; U(g_1)$ led us to an impossible situation, and therefore  it cannot hold. </p>

<p>Intuitively, the <em>worst</em> outcome of being in the gamble is to receive the minimum payoff -so for a rational agent, even if it is risk-averse, it would be irrational to accept less than the worst outcome, since then it would <em>certainly</em> do worse than being in the gamble. Note that ""aversion to risk"" does <em>not</em> mean ""take away <em>all</em> risk at <em>all</em> costs"". </p>
","4738"
"Causes of income inequality in the US","256","","<p>I read an article in BusinessWeek that talked about income inequality in the US.</p>

<p>The article attributed the difference to the Intel chip that came in 1971. Since that time big hi-tech companies have grown in US, which caused income growth among wealthy people and also didn't lead to a relatively large growth in jobs because a lot of work was outsourced to places like China.</p>

<p>To what extent is this explanation valid in the US... or is it insignificant in accounting for the income differences between the rich and the poor?</p>
","<p>The reason you bring forward belongs to <em>technological directed change</em>, which is regarded one of the main explanations for wage growth differentials. Keep in mind it's not exactly the way you're phrasing it: The growth in tech companies rewards people who are skilled well for their kind of jobs (as opposed to ""<em>wealthy people</em>"").</p>

<p>Card and DiNardo have a <a href=""http://eml.berkeley.edu/~card/papers/skill-tech-change.pdf"">nice summary article on the issue</a>:</p>

<blockquote>
  <p>The recent rise in wage inequality is usually attributed to skill-biased technical change (SBTC), associated with new computer technologies. We review the evidence for this hypothesis, focusing on the implica- tions of SBTC for overall wage inequality and for changes in wage differentials between groups. A key problem for the SBTC hypothesis is that wage inequality stabilized in the 1990s despite continuing ad- vances in computer technology; SBTC also fails to explain the evo- lution of other dimensions of wage inequality, including the gender and racial wage gaps and the age gradient in the return to education.</p>
</blockquote>
","5444"
"Intuition behind the linkage principle","255","","<p>An important result in auction theory is Milgrom &amp; Weber's <em>linkage principle</em>, which, roughly, holds that the expected revenue from an auction is higher is the seller commits ex ante to reveal as much information about the good for sale as possible.</p>

<p>I am trying to understand why this should be true even if bidders are risk-neutral and care only about the expected difference between their value and the price paid.</p>

<p>Is anyone able to provide some intuition for this result?</p>
","<p>The linkage principle does not depend on risk-aversion, because risk-neutral bidders simply bid according to the expected value they assign to the auctioned object. Having private information not revealed to other bidders, will generate information rents, reduce competition among bidders and lead to lower seller revenue.</p>

<p>Daniel Quint (U. Wisconson, eBay) has some <a href=""http://www.ssc.wisc.edu/~dquint/econ805%202009/lectures/econ%20805%20lecture%209.pdf"" rel=""nofollow""><strong>lectures notes</strong></a> where he works out the Milgrom-Weber result in detail, and also gives the following intuitive explanation: </p>

<blockquote>
  <p>One way to think about this is that bidder’s expected payoff can be
  thought of as his “information  rents,” that is, the extra surplus he
  is able to get by having private information. But in auction formats
  where information is revealed which is correlated with his private
  information, his private information becomes “less private” in a
  sense, so he gets a smaller surplus, and therefore more goes to the
  seller. In the logical limit – where information revealed over the
  course of the auction fully reveals the highest type – the seller
  could simply make a take-it-or-leave-it offer to extract full surplus.</p>
</blockquote>
","3062"
"Newly issued shares are sold on the stock market?","255","","<p>When a company issues new shares in order to raise it's capital, can it sell those shares on the stock market? Or they have to be sold outside of the stock market?</p>

<p>I mean in general, rules can differ from one country to another.</p>
","<p>A company will typically employ an investment bank to act as an underwriter when it wishes to issue new stock. The investment bank essentially agrees to buy the issued stocks from the issuing company and its job is then to sell them to investors.</p>

<p>Investment banks employ a sales force who try to persuade large investors (such as pension funds) to commit to buy the stocks before the date of issue. If the investment bank does a good job then all of the issued stocks will be allocated to a buyer in advance. If the investment bank fails to fails to find enough buyers then it is stuck with the unsold stock and must try to sell them to the public in the stock market.</p>
","6867"
"Present value of a payment","255","","<p>Suppose I've just won 1'000'000 dollars in a game show. At the end of the program they tell me that they will pay me the prize as following: they will deposit in my bank 50'000 dollars every year for twenty years with a constant annual interest rate of 6% (this to prevent me from wasting too quickly the one million dollars I've just won). The present value of my prize is given by:$$V_t=z\frac{1-\left [ \frac{1}{(1+i)^n} \right ]}{1-\left [ \frac{1}{(1+i)} \right ]}$$</p>

<p>with $z=50'000$, $i=0.06$ and $n=20$ I get  that: $$V_t\approx 50'000 \left (\frac{0.688}{0.566}  \right )\approx 608'000$$</p>

<p>My book says that is a really great prize, but I'm not a millionaire at this point. I would have been a millionaire if they'd paid me the one million dollars right at the end of the program. But I can't understand why it looks like I'm less rich. Suppose I won't spend money they'll give me, in twenty years I'll have: $$1'000'000\cdot(1+0.06)=1'060'000$$
Which is obviously greater than 1'000'000. Could you please explain me what's the reasoning that there is behind the present value of 608'000 dollars? Thanks for any help you can provide.</p>
","<p>You got the last sum wrong. In twenty years if you invest the million at 6 percent you'll have:</p>

<p>$1,000,000 \cdot (1 + .06) ^ {20} = 3,200,000$</p>

<p>I think the easiest way to to understand this result is with a table. This table asks what is the present value of each payment, the value of each year of payment in the year of the award (t=0). The far right column sums those payments to calculate the net present value of payments from time = 0 to time = t. You can see that the row 19, far right column number is the desired net present value of \$608k. </p>

<pre><code>+------+-------------+-------------+-----------+--------------+------------------+
| Year | Value of $  | Value of $  | Payment   | Value at 0   | Cumulative value |
| (t)  | in year 0   | in year t   | in year t | of payment   | of payments      |
|      | at time t   | at time 0   |           | in year t    | through t at 0   |
+------+-------------+-------------+-----------+--------------+------------------+
| 0    |  1.00       |  1.00       |  50,000   |  50,000      |  50,000          |
+------+-------------+-------------+-----------+--------------+------------------+
| 1    |  1.06       |  0.94       |  50,000   |  47,170      |  97,170          |
+------+-------------+-------------+-----------+--------------+------------------+
| 2    |  1.12       |  0.89       |  50,000   |  44,500      |  141,670         |
+------+-------------+-------------+-----------+--------------+------------------+
| 3    |  1.19       |  0.84       |  50,000   |  41,981      |  183,651         |
+------+-------------+-------------+-----------+--------------+------------------+
| 4    |  1.26       |  0.79       |  50,000   |  39,605      |  223,255         |
+------+-------------+-------------+-----------+--------------+------------------+
| 5    |  1.34       |  0.75       |  50,000   |  37,363      |  260,618         |
+------+-------------+-------------+-----------+--------------+------------------+
| 6    |  1.42       |  0.70       |  50,000   |  35,248      |  295,866         |
+------+-------------+-------------+-----------+--------------+------------------+
| 7    |  1.50       |  0.67       |  50,000   |  33,253      |  329,119         |
+------+-------------+-------------+-----------+--------------+------------------+
| 8    |  1.59       |  0.63       |  50,000   |  31,371      |  360,490         |
+------+-------------+-------------+-----------+--------------+------------------+
| 9    |  1.69       |  0.59       |  50,000   |  29,595      |  390,085         |
+------+-------------+-------------+-----------+--------------+------------------+
| 10   |  1.79       |  0.56       |  50,000   |  27,920      |  418,004         |
+------+-------------+-------------+-----------+--------------+------------------+
| 11   |  1.90       |  0.53       |  50,000   |  26,339      |  444,344         |
+------+-------------+-------------+-----------+--------------+------------------+
| 12   |  2.01       |  0.50       |  50,000   |  24,848      |  469,192         |
+------+-------------+-------------+-----------+--------------+------------------+
| 13   |  2.13       |  0.47       |  50,000   |  23,442      |  492,634         |
+------+-------------+-------------+-----------+--------------+------------------+
| 14   |  2.26       |  0.44       |  50,000   |  22,115      |  514,749         |
+------+-------------+-------------+-----------+--------------+------------------+
| 15   |  2.40       |  0.42       |  50,000   |  20,863      |  535,612         |
+------+-------------+-------------+-----------+--------------+------------------+
| 16   |  2.54       |  0.39       |  50,000   |  19,682      |  555,295         |
+------+-------------+-------------+-----------+--------------+------------------+
| 17   |  2.69       |  0.37       |  50,000   |  18,568      |  573,863         |
+------+-------------+-------------+-----------+--------------+------------------+
| 18   |  2.85       |  0.35       |  50,000   |  17,517      |  591,380         |
+------+-------------+-------------+-----------+--------------+------------------+
| 19   |  3.03       |  0.33       |  50,000   |  16,526      |  607,906 (award NPV)|
+------+-------------+-------------+-----------+--------------+------------------+
</code></pre>

<p>Now that we see how this \$608 number is calculated, how should we interpret it? The classic answer is to ask ""what someone would pay you for your prize?"" For simplicity, let's ignore risk or assume that the 6% number fully encapsulates the risk. Imagine an investor who is risk neutral, has deep pockets, but critically, <strong>has the same investment choices as the game show</strong>. What would they pay you for your prize? What if there were many such investors such that they were competing away all the profits to pay you exactly what they thought that investment was worth.? What's the absolute maximum they'd pay? They would pay \$607,906.</p>

<p>Why? Because say they invested \$607,906 at 6% per year with the plan of selling anything left over? What would happen to their balance over time?</p>

<pre><code>+---------------+--------------+--------------+--------------------+
| Starting      | Interest (t) | Cash Out (t) | Ending Balance (t) |
|   Balance (t) |              |              |                    |
+---------------+--------------+--------------+--------------------+
| 607,906       | 0            | 50,000       | 557,906            |
+---------------+--------------+--------------+--------------------+
| 557,906       | 33,474       | 50,000       | 541,380            |
+---------------+--------------+--------------+--------------------+
| 541,380       | 32,483       | 50,000       | 523,863            |
+---------------+--------------+--------------+--------------------+
| 523,863       | 31,432       | 50,000       | 505,295            |
+---------------+--------------+--------------+--------------------+
| 505,295       | 30,318       | 50,000       | 485,612            |
+---------------+--------------+--------------+--------------------+
| 485,612       | 29,137       | 50,000       | 464,749            |
+---------------+--------------+--------------+--------------------+
| 464,749       | 27,885       | 50,000       | 442,634            |
+---------------+--------------+--------------+--------------------+
| 442,634       | 26,558       | 50,000       | 419,192            |
+---------------+--------------+--------------+--------------------+
| 419,192       | 25,152       | 50,000       | 394,344            |
+---------------+--------------+--------------+--------------------+
| 394,344       | 23,661       | 50,000       | 368,004            |
+---------------+--------------+--------------+--------------------+
| 368,004       | 22,080       | 50,000       | 340,085            |
+---------------+--------------+--------------+--------------------+
| 340,085       | 20,405       | 50,000       | 310,490            |
+---------------+--------------+--------------+--------------------+
| 310,490       | 18,629       | 50,000       | 279,119            |
+---------------+--------------+--------------+--------------------+
| 279,119       | 16,747       | 50,000       | 245,866            |
+---------------+--------------+--------------+--------------------+
| 245,866       | 14,752       | 50,000       | 210,618            |
+---------------+--------------+--------------+--------------------+
| 210,618       | 12,637       | 50,000       | 173,255            |
+---------------+--------------+--------------+--------------------+
| 173,255       | 10,395       | 50,000       | 133,651            |
+---------------+--------------+--------------+--------------------+
| 133,651       | 8,019        | 50,000       | 91,670             |
+---------------+--------------+--------------+--------------------+
| 91,670        | 5,500        | 50,000       | 47,170             |
+---------------+--------------+--------------+--------------------+
| 47,170        | 2,830        | 50,000       | 0                  |
+---------------+--------------+--------------+--------------------+
</code></pre>

<p>That is, they'd have exactly enough money to make the required \$50,000 payments in every period with nothing left over. </p>
","3095"
"Regarding a consumption aggregator: How do I differentiate under the integral sign?","255","","<p>Let $\varepsilon&gt;1$ and let $$C_t\equiv\left(\int_0^1C_t(i)^{(\varepsilon-1)/\varepsilon} \, di\right)^{\varepsilon/(\varepsilon-1)}$$ denote a consumption basket in time period $t$, where $C_t(i)$ is consumption of good $i\in [0,1]$. In e.g. new Keynesian models we want to differentiate $C_t$ with respect to $C_t(i)$ for some $i\in [0,1]$ so as to solve a utility optimization problem. In my lecture notes, and in many texts on this subject, it is said that $$\frac{\partial C_t}{\partial C_t(i)} = \frac{\varepsilon}{\varepsilon-1} C_t^{1/\varepsilon} \frac{\varepsilon-1}{\varepsilon} C_t(i)^{-1/\varepsilon}.$$ Does anyone know how this differentiation is accomplished? This is my question I want answered. Below I will outline how I have thought about this question.</p>

<p>I am prone to thinking that it is wrong. For using the chain rule I would say that the answer is the following. $$\frac{\partial C_t}{\partial C_t(i)} = \frac{\varepsilon}{\varepsilon-1} C_t^{1/\varepsilon} \left(\frac{\partial}{\partial C_t(i)} \int_0^1C_t(i)^{(\varepsilon-1)/\varepsilon} \, di\right),$$ which, when asssuming that the function is such that we may differentiate under the integral sign, I get $$\frac{\partial C_t}{\partial C_t(i)} = \frac\varepsilon {\varepsilon-1} C_t^{1/\varepsilon} \left(\int_0^1 \frac{\varepsilon-1} \varepsilon C_t(i)^{-1/\varepsilon} \, di\right).$$ Now, using the mean value theorem for integrals it would be possible to say that $$\int_0^1 C_t(i)^{-1/\varepsilon} \, di = C_t(j)^{-1/\varepsilon}(1-0)$$ for some $j\in (0,1)$, and insert this result above and then get a similar result to what was shown in my lecture notes. However, this would lead us to considering another good $j$ not necessarily equal to good $i$.</p>

<p>The reader may think that I am confusing the symbol '$i$' in the integral, for the same symbol used when differentiating with respect to $C_t(i)$, and that I should, when differentiating, consider a good $i_0$, and then perform the following differentiation: $$\frac{\partial C_t}{\partial C_t(i_0)} = \frac{\partial }{\partial C_t(i_0)} \left(\int_0^1 C_t(i)^{(\varepsilon-1)/\varepsilon} \, di\right)^{\varepsilon/(\varepsilon-1)}.$$ This may be so, but I do not know how to get the desired result from this, and if I take this approach, I would say that the derivative is equal to $0$ (!) as the integral is just a real constant if $t$ is fixed, which it is.</p>

<p>It is sometimes said that we may differentiate the integral just mentioned by looking at the integral as beeing a sum. What they mean by this, I do not know. Maybe they represent the integral as the limit of a Riemann sum, which it is, and write $$\frac{\partial }{\partial C_t(i_0)} \int_0^1 C_t(i)^{(\varepsilon-1/\varepsilon} \, di = \frac{\partial }{\partial C_t(i_0)} \lim_{n\to\infty} \sum_{k=1}^n C_t(\xi_k)^{(\varepsilon-1)/\varepsilon}(i_k-i_{k-1}),$$ with $i_0=0&lt;i_1&lt;\cdots &lt; i_{n-1}&lt;i_n=1$ and $i_{k-1}\leq\xi_k\leq i_k$ for each $k=1,2\ldots,n$. When the authors write that we should look at the integral as beeing a sum, this must be it. But differentiating this sum with respect to $C_t(i_0)$ would in the best cases (i.e., when we can do differentiation inside the limit) be equal to $\lim_{n\to\infty}\frac{\varepsilon-1} \varepsilon C_t(i_0)^{1/(\varepsilon-1)} \cdot (i_\alpha - i_{\alpha-1})$ for some $\alpha\in\{1,2,\ldots,n\}$ such that $i_{\alpha-1}\leq i_0\leq i_\alpha$; the problem now is that $\lim_{n\to\infty}\frac{\varepsilon-1} \varepsilon C_t(i_0)^{-1/\varepsilon}\cdot (i_\alpha - i_{\alpha-1})=0$, which is consistent with modern advanced real analysis (to my knowledge) in the sense that if we just increase or decrease the value of $C_t(i)$ at one $i=i_0$, then the value of the integral will not change, and hence the derivative should be $0$ (i.e., no change in the value of the integral for a change in $C_t(i_0)$).</p>

<p>Note: These problems occur when studying e.g. the so called ""Dixit-Stiglitz aggregator"". </p>
","<p>Using your formalism above, you can think (heuristically) of the integral as $$ \sum_{i=1}^nC_t(i)^{(\epsilon-1)/\epsilon} $$</p>

<p>If we differentiate this with respect to $C_t(j)$, we get</p>

<p>$$ \frac{\epsilon - 1}{\epsilon} C_t(j)^{-1/\epsilon} $$</p>

<p>Which is exactly what we needed. To do this rigorously, you need a notion of taking derivatives on function spaces. Look up the <a href=""https://en.wikipedia.org/wiki/G%C3%A2teaux_derivative"" rel=""nofollow noreferrer"">Gâteaux</a> and <a href=""https://en.wikipedia.org/wiki/Fr%C3%A9chet_derivative"" rel=""nofollow noreferrer"">Fréchet</a> derivatives.</p>
","14116"
"Violating WARP or not?","254","","<p>If the only information we had about Goldie were that she chooses the bundle (6, 6) when prices are (6, 7) and she chooses the bundle (10, 0) when prices are (5, 5), then we could conclude that</p>

<p>a.
the bundle (6, 6) is revealed preferred to (10, 0) but there is no evidence that she violates WARP.</p>

<p>b.
Goldie violates WARP.</p>

<p>c.
the bundle (10, 0) is revealed preferred to (6, 6) and she violates WARP.</p>

<p>d.
neither bundle is revealed preferred to the other.</p>

<p>e.
the bundle (10, 0) is revealed preferred to (6, 6) but there is no evidence that she violates WARP.</p>

<p><strong>My attempt:</strong>
Obvious conclusion to this question is that (6,6) bundle is preferred to (10,0) bundle when prices are (6,7) but when the prices are (5,5) everything is the other way round thus it violates the WARP whereas the correct answer as stated in the questionbank is A why is that?</p>
","<p>When she chooses the bundle (6,6) when the prices are (6,7), she spends 
\begin{equation*}
6*6+6*7=78
\end{equation*}
The total price of the bundle (10,0) given this price system is 
\begin{equation*}
10*6+0*7=60&lt;78
\end{equation*}
Therefore she could afford the bundle (10,0) if she wanted to. The fact that she chooses (6,6) reveals that she prefers (6,6) to (10,0).</p>

<p>Given the price system (5,5), when she chooses the bundle (10,0) she spends
\begin{equation*}
10*5+0*5=50
\end{equation*}
And the price of the bundle (6,6) would be
\begin{equation*}
6*5+6*5=60
\end{equation*}
Therefore (6,6) is not necessarily affordable if her budget is comprised between 50 and 59. This is why (10,0) is not revealed preferred to (6,6) in that case, and thus there is no evidence that she violates WARP.</p>
","10260"
"Are there any states that don't have debt?","253","","<p>I've not been able to find any states that don't have debt to other states.  This, to me at least, seems really strange.  Are there any nation states that are not in debt to other states, if so which ones, and if not why can't everyone just settle the debts?</p>

<p>(Wasn't sure if I should ask this on the Politics Stack Exchange or here, please let me know if this is out of scope and I'll ask there.)</p>
","<p>The classic answer here would be Libya and Brunei, but I think Libya now has debt.</p>

<p>Brunei is a strange case in that it uses a joint currency with Singapore dollar, controlled by the monetary authority of Singapore, so in effect you can use Singapore debt as a substitute for Brunei dollar investment.</p>

<p>Not having any debt, and having a free currency is generally a bad idea, since you cannot control interest rates. Furthermore, if you can afford not to have debt, then people will be begging to lend to you at such favorable rates it would be foolish not to borrow a bit.</p>

<p>On the other hand there are many counties with no net debt. Singapore and Norway don't need to borrow but do so to provide bonds for the financial markets. They then invest the money they borrow. Norway can borrow so cheaply they can buy US treasuries and make a profit.</p>
","1863"
"Calculating Time to Balanced Growth Path","252","","<p>$\textbf{Model:}$
$$\underset{\{c_t,k_t\}}{max}\;\sum_{t=0}^\infty\beta^t\frac{c_t^{1-\gamma}}{1-\gamma}$$
$$s.t.\;c_t=Rk_{t-1}-k_t$$
$$c_t,k_t\geq0$$
At time $t$, $c_t$ is consumption and $k_{t-1}$ is the capital used in production. $0&lt;\beta&lt;1,\;\gamma&gt;0,\;\gamma\neq1$</p>

<p>$\textbf{(a)}$ Compute a balanced growth path in which consumption and capital grow at constant rates.</p>

<p>Solving this using the Euler equation, we get
$$\frac{c_{t+1}}{c_t}=\big(\beta R\big)^{\frac{1}{\gamma}}$$
We know that capital must grow at the same rate as consumption in a balanced growth path, so
$$\frac{k_{t+1}}{k_t}=\big(\beta R\big)^{\frac{1}{\gamma}}$$
This means that:
$$c_t=\bigg(\frac{R}{(\beta R)^{\frac{1}{\gamma}}}-1\bigg)k_t$$
$\textbf{(b)}$ What restrictions are necessary for both capital and consumption to grow at a positive rate on the balanced growth path?</p>

<p>For this question, it seems like all we need is $R&gt;1$</p>

<p>Now, my question is the following: How long will it take for consumption and capital to reach the balanced growth path? In general, how would one calculate time to balanced growth path? Or is it more based on economic intuition?</p>

<p>$\textbf{Edit:}$ According to another student, the professor said this will never reach a balanced growth path. However, the professor never stated why. Can someone give me a reasoning as to why this would never reach a balanced growth path?</p>
","<p>a) Your calculations are correct, but in order for consumption to be positive, so for
$$
c_t=\bigg(\frac{R}{(\beta R)^{\frac{1}{\gamma}}}-1\bigg)k_t &gt; 0,
$$
you will need to additional conditions. The first is the obvious $k_t &gt; 0$. If there is nothing to gain interest on, there will be no growth and no consumption. The second is the more nuanced
$$
\frac{R}{(\beta R)^{\frac{1}{\gamma}}}-1 &gt; 0.
$$
This is actually a necessary condition for the existence of an optimal solution.  The inequality may be reformulated as
$$
\beta \cdot R^{1 - \gamma} &lt; 1.
$$
If this does not hold, then given any consumption path the consumer would gain by pushing off all consumption one period further. Since there is no infinitely distant timeperiod, no optimum exists.</p>

<p>b) On reaching the balanced consumption path: <br>
Perhaps there is a trick with the indeces. $c_0$ seems ill defined unless there is a $k_{-1}$. If consumption only starts at $t = 1$, the above conditions are satisfied and the consumer is rational then
$$
\forall t: \ c_t=\bigg(\frac{R}{(\beta R)^{\frac{1}{\gamma}}}-1\bigg)k_t
$$
defines the optimal consumption path as I assume $k_0$ is given and
$$
\forall t: \ k_t = k_0 \cdot (\beta R)^{\frac{t}{\gamma}}.
$$
Hence 
$$
\forall t: \ c_t=\bigg(\frac{R}{(\beta R)^{\frac{1}{\gamma}}}-1\bigg) \cdot k_0 \cdot (\beta R)^{\frac{t}{\gamma}}.
$$
It is straightforward to check that this path is feasible (if the conditions set out in a) are met) and balanced.</p>

<hr>

<p>A note on reaching the balanced consumption path: This concept usually exists when there is some conflict between balancedness and optimality or when the consumer is boundedly rational. (E.g. Solow model.) Here this does not seem to be the case. However when such conflicts arise there is usually a never-ending (Is this the correct spelling of this word? Please correct if wrong.) convergence towards the balanced path. The distance decreases in every period but never becomes 0.</p>
","12539"
"Show that an equilibrium in strictly dominant strategies is a unique Nash equilibrium","252","","<p>I am new to game theory and I came across this line, "" A strategy profile (s1, . . . , sn) in which every si is dominant for agent i (strictly, weakly, or very weakly) is a Nash equilibrium.""</p>

<p>But why is that? And how would an equilibrium form in strictly dominant strategies? Do they both just yield the same best payoff?</p>

<p>Any help would be appreciated!</p>
","<p>It will be useful to spell out the relevant definitions.</p>

<p>Let $A_i$ be the set of possible actions for player $i$, $A_{-i}$ be the set of possible joint actions of all players except for player $i$, $A$ be the set of possible joint actions of all the players. For $a=(a_i,a_{-i})\in A$, let $u_i(a)$ denote the payoff to player $i$ from action $a_i$, given that the other players play $a_{-i}$.</p>

<p>Definition 1: An action $a_i\in A_i$ is weakly dominant for player $i$ if for every $a_{-i}\in A_{-i}$, $u_i(a_i,a_{-i})\ge u_i(\overline{a_i},a_{-i})$ for every $\overline{a_i}\in A_i$, i.e. no matter what the other players do, action $a_i$ yields a payoff at least as high as any other action available to player $i$. [Strict dominance given by $&gt;$ instead of $\ge$.]</p>

<p>Definition 2: An action $a_i\in A_i$ is a best response to action $a_{-i}\in A_{-i}$ if $u_i(a_i,a_{-i})\ge u_i(\overline{a_i},a_{-i})$ for every $\overline{a_i}\in A_i$, i.e. If I fix other players' actions to some particular joint action, then $a_i$ yields a payoff to player $i$ at least as high as any other action available to player $i$.</p>

<p>Claim 1: If an action $a_i\in A_i$ is strictly or weakly dominant, then it is a best response for any joint action $a_{-i}\in A_{-i}$. [This follows from Definitions 1 and 2 immediately.]</p>

<p>Definition 3: A joint action $a\in A$ is a Nash equilibrium if for each player $i$, action $a_i$ is a best response to $a_{-i}$.</p>

<p>Claim 2 (your question): A strategy profile (i.e. joint action) $s=(s_1,...,s_n)\in A$ in which each $s_i$ is a (strictly or weakly) dominant strategy is a Nash equilibrium.</p>

<p>Note that Claim 2 is a consequence of Claim 1.</p>
","10807"
"Are there fundamental reasons why (exponential) economic growth is highly desirable?","251","","<p>One of the most widely published measures of the economy is the <a href=""https://en.wikipedia.org/wiki/Economic_growth"" rel=""nofollow noreferrer"">economic growth</a> as a % of the GDP; i.e. the degree to which an economy <a href=""https://en.wikipedia.org/wiki/Exponential_growth"" rel=""nofollow noreferrer"">grows exponentially</a>.  In my understanding, when the rate of economic growth is declining or close to 0%, this is considered undesirable and acts are undertaken to avert <a href=""https://en.wikipedia.org/wiki/Recession"" rel=""nofollow noreferrer"">recession</a>.</p>

<p>In a situation where population is not growing, why do we want the economy to grow?  In other words, is there something inherently wrong with a <a href=""https://en.wikipedia.org/wiki/Steady_state_economy"" rel=""nofollow noreferrer"">steady state economy</a>?</p>

<p>See also: <em><a href=""https://economics.stackexchange.com/q/460/332"">Why is economic growth measured exponentially rather than linearly?</a></em></p>
","<p>Because according to utility theory: more is better- or at least not worse (nonsatiation- or free disposal).</p>

<p>Your question seems to actually be: why is growth good? </p>

<p>Firstly, It's axiomatic. Utility theory very formally assumes the law of nonsatiation/free disposal.  Things that result in the death of the cosmos are bad not because we are dead, but because we cannot consume and improve our happiness afterwards. Evidince: We observe that consumption improves happiness.</p>

<p>Second, in cases of limited resources, we have situations where optional growth paths are negative-But this is only because it allows for increased overall consumption. </p>
","4979"
"What effect would destroying large amounts of physical currency have on government finances","251","","<p>India has recently recalled high denomination notes and asked people to deposit the physical currency in old notes in their bank accounts. People who have unaccounted wealth are resorting to <a href=""http://m.ndtv.com/india-news/sacks-full-of-burnt-500-and-1-000-rupee-notes-in-uttar-pradesh-1623440"" rel=""nofollow noreferrer"">destroying</a> the currency rather than run the risk of declaring this to the tax-men. <a href=""http://m.firstpost.com/india/rs-500-rs-1000-note-ban-20-notes-may-not-be-exchanged-people-burn-some-in-up-3098006.html"" rel=""nofollow noreferrer"">Some people</a> estimate upto 20% of notes may not be returned totalling about  3 trillion rupees.</p>

<p>In a cash based economy what possible consequences can destruction of such large amounts of currency cause? I think that reduction in money volume may lead to negative inflation but the question is more about the impact destruction of currency will have on government finances.
Does it make the government richer or poorer? </p>

<p>Note that this question isn't about demonitization per se.</p>

<p><strong>EDIT:</strong></p>

<p><a href=""http://indianexpress.com/article/business/banking-and-finance/withdrawal-of-rs-500-rs-1000-notes-black-money-pm-modi-old-notes-4379516/"" rel=""nofollow noreferrer"">A newspaper report</a> this morning says that the government expects a ""windfall"" due to cash not being returned by people. It states that any money not returned to central bank (In India that is the RBI), is a reduction in liability of RBI and therefore an equal amount can be paid by RBI to the government.</p>

<p>Is this how monetary policy works?</p>

<p>I was always under the impression that central bank buys government bonds in return for currency. Any physical reduction in currency means government cannot buy the same bonds back from central bank (as it doesn't have the hard cash) and therefore the government should become ""poorer"" (due to inability to decrease its debt in forms of bonds issued to central bank). The report states that government will get ""richer"" as central bank's liability is decreased and it can pay that amount to government as dividend.
Can someone clarify how this process is likely to work?</p>
","<p>In most modern economies, the central bank certainly has the authority to print money, when it does so to implement its legally defined objective. Let's consider what the implications of this 'elimination' of cash are.</p>

<p><strong>The Balance Sheet</strong></p>

<p>From the asset management side of the central bank, currencies are always a liability - because, amongst other things, they can be deposited in an account with the central bank, which will usually accumulate interest payments. Historically, many central banks used to allow currency to be exchanged for gold.</p>

<p>Central banks must always be concerned with their balance sheet. The reason why they cannot simply issue and distribute it to the masses (known as helicopter money) comes down to this management of liabilities - there is a real constraint here for these institutions. Issue too much currency, and commercial banks might not think you will be able to pay interest on their deposits. Or more aptly, they may believe the only way you can pay this interest is by printing money, decreasing the value of money and  potentially leading to inflation or a runaway zimbabwe situation</p>

<p>So the destruction of currency reduces the financial liabilities of a central bank, benefitting its balance sheet.</p>

<p><strong>Impact on the Economy</strong></p>

<p>Now we can look at the implications for the economy. Shown below is the fisher equation, a simple but valuable representation for money interacts with the economy.</p>

<p>$MV = PY$</p>

<p>This indicates that real output (the right hand side) is equal to the amount of currency in circulation, multiplied by how quickly that currency is circulated around. So if a central bank wanted to keep prices and output constant, it would want to eliminate any changes to the money supply. Otherwise, as you have intuited, there may be a decrease in output or the price level.</p>

<p>But we have to consider if this is really currency in circulation. Are people really using these large denomination notes in actual transactions, or just as a store of wealth? If this currency was unused to begin with then maybe there won't be much of a real impact.</p>

<p>We must also consider that central bank's typically interact with commercial banks only, and are typically most immediately concerned with maintaining their target interest rate with those commercial banks.</p>

<p><strong>How might this play out in practice?</strong></p>

<p>First, these protesters having burned some of their money and so may replace it by withdrawal from their accounts with commercial banks. These commercial banks distribute this physical currency out to consumers, and have less remaining to loan to between themselves. Since for them, loanable funds are more scarce, there will be upward pressure on interest rates.</p>

<p>To maintain the target interest rate, we will then see the central bank response, purchasing bonds from the commercial banks in exchange for cash. Thus the balance of money is restored.</p>

<p>But perhaps this destruction of money was great enough that it has made consumers considerably poorer. Now their bank balance is reduced, they may not want to spend as much. Over the short term, this would be expected to drive down prices and output.</p>

<p>If the central bank sees this play out, or is worried enough to anticipate it, it would likely reduce its interest rate target. With a lower cost to borrowing, we have increased spending in the economy, inflation of asset prices that make people feel richer and hopefully, a restoration of balance.</p>

<p>This is a hypothetical, and relatively simple policy analysis. A less conventional central bank could throw replacement money out of a helicopter, but this seems unlikely to happen in practice.</p>

<p><strong>How does this effect the government?</strong></p>

<p>It will likely benefit them. As I discussed, currency is a liability for central banks. So now some of it is gone, they can print more without having to demand any kind of asset in return. The article you have edited into your question argues that the central bank may print and give money to the government. Normally, because money is a liability, they would have to demand government debt in return. But because the balance sheet already incorporates this currency (which is just replacing what has been destroyed) it need not demand government bonds --- so the government can spend without incurring any debt.</p>
","14271"
"Autonomous or non-autonomous optimal control system?","250","","<p>I have a following system with endogeneous discounting.
$c,k$ and $h(k)$ are consumption, capital and endogeneous discount function based on physical capital. (the properties of this function are not relevant with the question, so I don't write them in order to take less space in this post. The production function is increasing and concave as usual.)</p>

<p>$$\underset{\left\{ c_{t}\right\} }{max}\int_{t=0}^{\infty}\left[u\left(c_{t}\right)\right]e^{-\triangle}dt$$</p>

<p>My state variables are </p>

<p>$$\begin{align}
\dot{k_{t}}=f\left(k_{t}\right)-c_{t}\\
\dot{\triangle}_{t}=\rho + h\left(k_{t}\right)
\end{align}$$</p>

<p>I note $\triangle=\int_{0}^{t} (\rho + h\left(k_{t}\right))dt$</p>

<p>I write the present-value Hamiltonian as </p>

<p>$$\mathcal{H}^{present}=u\left(c\right)e^{-\triangle}+\tilde{\lambda_{1}}\left[f\left(k\right)-c\right]+\tilde{\lambda_{2}}\left[\rho + h\left(k\right)\right]$$</p>

<blockquote>
  <p>In this model, my doubt is that if the system is autonomous or not because when I integrate $\dot{\triangle}$, I have $\triangle=
\rho t+ \int_{0}^{t}h\left(k_{t}\right)dt$, which depends explicitly on time $t$. So, evidently, this differential equation is non-autonomous.</p>
</blockquote>

<p>Is this system really non-autonomous ? </p>

<p>What I try to do, in order to have an autonomous system is to define variables. Let's say $\lambda_{1}=\tilde{\lambda_{1}}e^{\triangle}$ and $\lambda_{2}=\tilde{\lambda_{2}}e^{\triangle}$. In this way, I write the current-value Hamiltonian ;</p>

<p>$$\mathcal{H}^{current}=u\left(c\right) +\lambda_{1}\left[f\left(k\right)-c\right]+\lambda_{2}\left[\rho + h\left(k\right)\right]$$</p>

<p>I am really stuck at this point. For the moment, the system seems to be autonomous as the Hamiltonian does not depend explicitly on time here but I can not really be sure.</p>

<p>Hints or suggestions are all welcome.</p>
","<p>The OP's answer is correct in its conclusion, but he applies a strange argument at the end to arrive there.  </p>

<p>Applying brute-force differentiation, the present value Hamiltonian is</p>

<p>$$\mathcal{H}=e^{-\triangle} U\left( c\right)
+\lambda _{1}^{}\left[ f(k)-c\right] +\lambda _{2}\left[ \rho
+h(k)\right] $$</p>

<p>and so </p>

<p>$$\frac {d\mathcal{H}}{dt} = -\dot \triangle e^{-\triangle}U\left( c\right)+
e^{-\triangle} U'(c)\dot c + \dot \lambda_1\left[ f(k)-c\right]  + \lambda_1\left[ f'(k)\dot k-\dot c\right] + \dot \lambda _{2}\left[ \rho
+h(k)\right]+\lambda _{2}h'(k) \dot k$$</p>

<p>Re-arranging, and using $\rho +h(k) = \dot \triangle$ we get</p>

<p>$$\frac {d\mathcal{H}}{dt} = -\dot \triangle e^{-\triangle}U\left( c\right)+ [e^{-\triangle}U'(c)-\lambda_1]\dot c   + [\lambda_1f'(k)+\lambda _{2}h'(k)]\dot k + \dot \lambda _{2}\dot \triangle + \dot \lambda_1\left[ f(k)-c\right] $$</p>

<p>Along the optimal path, we have $e^{-\triangle}U'(c)=\lambda_1$ so the second term above vanishes. Also optimally we have $\dot{\lambda}_{1}=- \frac{\partial \mathcal{H}}{\partial k}$ and observe that $\frac{\partial \mathcal{H}}{\partial k} = [\lambda_1f'(k)+\lambda _{2}h'(k)]$. Substituting we get</p>

<p>$$\frac {d\mathcal{H}}{dt} = -\dot \triangle e^{-\triangle}U\left( c\right)+ \frac{\partial \mathcal{H}}{\partial k}\dot k + \dot \lambda _{2}\dot \triangle  - \frac{\partial \mathcal{H}}{\partial k}\left[ f(k)-c\right] $$ </p>

<p>$$=\frac{\partial \mathcal{H}}{\partial k}[\dot k - f(k)+c] + \dot \triangle \cdot\big[\dot \lambda _{2} - e^{-\triangle}U\left( c\right)\big] $$</p>

<p>The first term is zero, from the law of motion of capital. Moreover, another necessary condition for the optimal path, given how the problem has been formulated,  is $\dot{\lambda}_{2}=- \frac{\partial \mathcal{H}}{\partial \triangle}$.  so we arrive at</p>

<p>$$\frac {d\mathcal{H}}{dt} =-\dot \triangle \cdot\left[ \frac{\partial \mathcal{H}}{\partial \triangle} + e^{-\triangle}U\left( c\right)\right]$$</p>

<p>Now
$$\frac{\partial \mathcal{H}}{\partial \triangle} = -e^{-\triangle} U\left( c\right)$$
so we obtain </p>

<p>$$\frac {d\mathcal{H}}{dt} =0$$</p>

<p>This directly proves that the problem is autonomous.</p>

<p>More generally, irrespective of whether the problem is autonomous or not, we have that along the optimal path</p>

<p>$$\frac {d\mathcal{H}}{dt} =\frac {\partial \mathcal{H}}{\partial t}$$</p>

<p>So <em>if</em> it is autonomous, then we get the zero-derivative result.</p>
","8513"
"Verification of understanding of the substitution and income effect of normal, inferior and Giffen goods?","250","","<p>My understanding is as follows:</p>

<p>Normal Goods: Income and Substitution effects are both positive.</p>

<p>Inferior Goods: Income effect negative, substitution effect positive. Substitution effect outweighs income effect and so although when the price of an inferior good F decreases (real income increases) and leads to an increase in the quantity of F consumed, this increase is small relative to the decrease in its price due to the substitution effect's magnitude being bigger than that of the income effect.</p>

<p>Giffen Goods:Income effect negative, substitution effect positive. Unlike inferior goods, income effect outweighs the substitution effect.</p>

<p>Please verify whether my understanding, as described above, is accurate. </p>

<p>Additionally, is it correct to assert that the positivity/negativity of the substitution/income effect of a change in price of a good remains the same regardless of whether said good's price increases or a decreases, e.g. regardless of whether the price of a normal good N increases or decreases, its income and substitution effect will always be 'positive'?</p>
","<p>[Edited: I think that <em>Theoretical Economist</em> is right in highlighting that I'm perpetuating the confusion between the mathematical formalism, and one way of getting to the intuitive understanding. It also comes down to language referring to the <em>slope</em> of the curve versus effects that are positive or negative depending on moving up or down that negatively-sloped curve. So I clarified the table and text consistently against a price rise and Slutsky.]</p>

<p>I think your intuition is correct, but the derivatives have slopes in the other direction in Slutsky's equation. And it's Slutsky's equation that's ultimately given us this theoretical framework, so let's stick with that here ;)</p>

<p>To be clearer, let's discuss for a Price RISE:</p>

<pre><code>Normal Good:   Demand- = Substitution-- Income-  [Same direction]

Inferior Good: Demand- = Substitution-- Income+  [S &gt; I]

Giffen Good:   Demand+ = Substitution-- Income++ [I &gt; S, weirdly]
</code></pre>

<p>I start my understanding of this with the demand curve. Under the “usual” laws of supply and demand, the demand-curve is backward-sloping, so as the price rises, we demand <em>less</em> of it. This is the Ecos101 curve we're familiar with; and it applies both to normal and inferior goods. But for Giffen goods, the demand curve has a <em>positive</em> slope... As the price rises, we actually demand <em>more</em> of it. Usually, examples of luxury goods are given as Giffen goods. The argument runs that as price is an indicator of quality and wealth of the purchaser, people actually by more of these goods as the price rises. The actual empirical evidence for the existence of Giffen goods in the real world, though, is slim and hotly debated... Sorry Apple!</p>

<p>So we understand the demand curves are backwards for normal/inferior, but upwards for Giffens. Why?</p>

<p>It was Slutsky who best disentangled demand curves as comprising an <em>income</em> effect and a <em>substitution</em> effect through a synthesis Marshall and Hicks' respective demand curves. (These are the uncompensated and compensated curves per the comments below.)</p>

<p>Per Slutsky's equation, <em>Theoretical Economist</em> is correct: The substitution effect can only ever be negative / downward-sloping. That leaves only the income effect to explain the differences between the three types of goods.</p>

<p>The link is that as the price of a good rises, in effect income falls. For normal goods, as effective income falls, we demand <em>less</em> of the good. For inferior goods, as income falls, we demand <em>more</em> of the good. Typical examples of inferior goods include staple foods. The idea is that as we get poorer, we cannot afford “rich” foods like meats, exotic fruits, chocolate, and so on; but must ""downgrade"" to cheaper foods.</p>

<p>Giffen is where things can get counter-intuitive. As the price of a Giffen good rises, even though effectively our income falls, we demand the good <em>so much more</em> that it outweighs the (always-negatively-sloped) substitution effect to yield the total positive demand.</p>

<p>I hope that's both more formal and clearer to understand.</p>

<hr>

<p>Regarding your final question, the intuitive understanding around the increase/decrease in substitutions based on price rises/falls can be confusing against the fact that the <strong>slope</strong> of the substitution term in Slutsky is always negative.</p>

<p>From a mathematical perspective, the slope of substitution is always negative, but we can move ""up"" or ""down"" that curve to produce ""positive"" or ""negative"" changes... More or less substitution of a good.</p>

<p>For the second part of your question about the constancy of these effects; goods can apparently change between being normal/inferior. So if we do as we typically do in economics classes and draw out demand curves and indifference curves as straight lines, it holds.</p>

<p>But in reality, we know that demand curves are not immutable, straight lines, but can (a) curve and (b) change under exogenous variables. Think of the example of an asset bubble. For a while, the asset may actually look like a Giffen good: The price rises, people demand more as they jump on the bandwagon. Suddenly, the bubble bursts, and that asset is “demoted” to being a normal good (just as everyone’s income is decreasing... oops!)</p>
","15613"
"Does dollar cost averaging actually have any advantage over one time investment?","249","","<p>Some banks promote savings plans by stating that investing a fixed amount of money in regular time intervals minimizes the average buying price or the downside risk (dollar cost averaging). Since the regular saving amount is fixed, they claim that, when the stock price is low more shares will be bought, and when the price is high fewer shares will be bought, so in total, you will buy more shares when they are cheap and fewer when they are expensive, hence investing more efficiently.</p>

<p>Although this seems to be a valid argument, intuitively (at least for me) it still feels rather like some sort of fallacy than a sound investment strategy, however I cannot show exactly why. So my question is whether there is an actual <em>mathematical proof</em> that dollar cost averaging has a definite advantage over one time investment (or the opposite)? To be precise, is it really possible to somehow reduce risk and keep the same expected return (or raise expected return and keep the same risk) using this stragegy?</p>
","<p>The seminal academic criticism of dollar cost averaging on many specifications of economic conditions is <a href=""http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=4470800&amp;fileId=S0022109000005408"">A Note on the Suboptimality of Dollar-Cost Averaging as an Investment Policy (Constantinides (1979))</a>. You might also be interested in these papers:</p>

<blockquote>
  <p>Dollar Cost Averaging is an investment system that is widely advocated
  by brokerage firms and mutual funds. In its best known form, an
  investor seeking to put a lump sum into risky assets is counseled to
  invest the money over a period of time in equal installments in order
  to avoid the devastating effect of a market fall immediately after a
  single, lump-sum investment. Using graphical analysis, historical
  stock market returns, and Monte Carlo simulations, this article
  demonstrates that no such benefit accrues to a Dollar Cost Averaging
  Strategy. Two alternative strategies, optimal rebalancing and buy and
  hold achieve better performance in all three analyses.</p>
</blockquote>

<p><a href=""http://%20www.sciencedirect.com/science/article/pii/1057081092900155"">Nobody gains from dollar cost averaging analytical, numerical and empirical results (Knight and Mandell (1993))</a></p>

<blockquote>
  <p>Some studies find the dollar-cost averaging investment strategy to be
  sub-optimal using a traditional Sharpe ratio performance ranking
  metric. Using both the Sortino ratio and the Upside Potential ratio,
  we empirically test four investment strategies for alternative asset
  investments. We find the relative ranking of dollar-cost averaging
  remains inferior to alternative investment strategies. (JEL G1, G11,
  N2)</p>
</blockquote>

<p><a href=""http://link.springer.com/article/10.1007/BF02827219"">An empirical examination of the effectiveness of dollar-cost averaging using downside risk performance measures (Leggio and Lien (2003))</a> </p>

<blockquote>
  <p>The widespread practice of dollar-cost averaging (DCA) amongst the
  investing public, has puzzled most financial economists, ever since
  Constantinides demonstrated the dynamic inefficiency of this
  strategy under very general conditions. This enduring phenomena has
  forced researchers, such as Statman , to suggest behavioral
  explanations for DCA's popularity, predicated on the prospect theory
  of Kahneman and Tversky .</p>
  
  <p>In this paper we reexamine the payoff structure of DCA via
  continuous-time financial mathematics and then ask the question: Is it
  possible to reconcile the theory and practice of dollar-cost
  averaging?</p>
  
  <p>To answer this question, we take a slightly different approach to the
  issue by using the tools of stochastic calculus and Brownian bridges.
  We demonstrate that engaging in a dollar-cost averaging strategy is
  akin to purchasing a zero strike arithmetic Asian option on the
  underlying security. In other words, people who engage in dollar-cost
  averaging are implicitly purchasing a path-dependent contingent claim.
  We then prove that the expected return from this exotic option — i.e.
  the DCA strategy — conditional on knowing the final value of the
  security will uniformly exceed the return from the underlying security
  for all sufficiently large volatilities.</p>
  
  <p>This leads us to argue that investors may be dollar-cost averaging
  because they have ""target prices"" for the underlying asset price. The
  strategy of dollar-cost averaging would then exceed the returns from
  lump-sum investing, based on their subjective conditional expectation.
  In fact, the more volatile the underlying security, the greater is the
  benefit to dollar-cost averaging — conditional on knowing the final
  value — which is consistent with common practice.</p>
</blockquote>

<p><a href=""http://www.worldscientific.com/doi/abs/10.1142/S0219024903001888"">A CONTINUOUS-TIME REEXAMINATION OF DOLLAR-COST AVERAGING (MILEVSKY and POSNER (2003))</a></p>

<blockquote>
  <p>Dollar Cost Averaging is a strategy for purchasing equity securities
  that is widely recommended by professional investment advisors and
  commentators, but which has been virtually ignored by academic
  theorists and textbook writers. In this paper we explore whether the
  strategy is but another instance of irrational behavior by individual
  investors, or whether it is an investment heuristic that has survival
  value in an environment in which security prices exhibit mean
  reversion behavior that has only belatedly been recognized by academic
  theorists. Our evidence supports the view that the uninformed
  individual investors who follow this strategy in purchasing individual
  stocks to add to an existing portfolio are better off than if they
  followed the ‘rational’ strategies traditionally recommended by
  academics.</p>
</blockquote>

<p><a href=""http://rof.oxfordjournals.org/content/9/4/509.short"">Dollar Cost Averaging (Brennan, Li and Torous  (2005))</a> </p>
","10820"
"Preference ordering relation","248","","<p>≳ is a preference ordering if it is reflexive , transitive and complete.
In Mathematics relations are said to be in a equivalence relation if they are 
reflexive, symmetric and transitive.</p>

<p>Can we call preference ordering a equivalence relation?
And if so what is the significance of preference relation being a equivalence relation in further studies of microeconomics.?</p>
","<p>No reflexivity, transitivity and completeness does not imply symmetry. For example: Consider the preference relation $\succsim$ over $\mathbb{R}^2_+$ defined as:</p>

<blockquote>
  <p>$(x,y)\succsim (x',y')$ if and only if $xy \geq x'y'$</p>
</blockquote>

<p>Such preferences have a utility representation $u(x, y) = xy$, and therefore they are reflexive, transitive and complete. However, these are not symmetric because $(1,2)\succsim (1,1)$ but $(1,1)\not\succsim (1,2)$.</p>

<p>But we can define the indifference relation $\sim$ from the weak preference relation $\succsim$ in this way:</p>

<blockquote>
  <p>$(x,y)\sim (x',y')$ if and only if [$(x,y)\succsim (x',y')$ and $(x',y')\succsim (x,y)$] </p>
</blockquote>

<p>It can be easily shown that the indifference relation derived from the reflexive, transitive and complete weak preference relation in the way described above will be an equivalence relation. It is important because this relation partitions the entire commodity space into indifference classes, where two consumption vectors belong to a class if and only if the individual is indifferent between the two. These classes are also known as indifference curves. This further helps in solving related problems.</p>
","15182"
"Derive demand function from utility function with constant elasticity","247","","<p>Consider a $n$-good industry with a representative consumer with utility function for the differentiated goods given by,</p>

<p>$
U=\left(\sum^n_{i=1}q_i^\beta\right)^\theta
$</p>

<p>Suppose that the representative consumer is endowed with income $I$.</p>

<p>a. Derive the inverse and direct demands;</p>

<p>My solution: I am writing the lagrange as:</p>

<p>$
L=\left(\sum^n_{i=1}q_i^\beta\right)^\theta+\lambda(I-\sum^n_{i=1}p_iq_i)
$</p>

<p>FOC:</p>

<p>$
\theta \left(\sum^n_{i=1}q_i^\beta\right)^{\theta-1}\beta q_i^{\beta-1}-\lambda p_i=0
$</p>

<p>So the inverse demand function is:</p>

<p>$
p_i=\frac{\theta \left(\sum^n_{i=1}q_i^\beta\right)^{\theta-1}\beta q_i^{\beta-1}}{\lambda}
$</p>

<p>Is this right? Because the $\lambda$ seems a little bit strange. If yes, how do I isolate $q_i$, when there is this sum symbol to derive the demand function?</p>
","<p>You stopped a bit too early. </p>

<p>Let me re-write the FOC for good $i$ as follows:</p>

<p>$$ \lambda=\frac{\theta \left(\sum^n_{i=1}q_i^\beta\right)^{\theta-1}\beta q_i^{\beta-1}}{p_i}
$$</p>

<p>As this is identical across goods, equalise for good $i$ and good $j$, where, after simplification, you get:</p>

<p>$$ \frac{q_i^{\beta-1}}{p_i} = \frac{q_j^{\beta-1}}{p_j} $$</p>

<p><strong>This relation hold for any pair of goods</strong>. This means you can re-write the demand for any good in terms of $q_i$ and relative prices. Then, you can use the budget constraint to obtain the final demand for good $i$, in terms of income $I$ and all the prices. </p>

<p>Hopefully this information is enough for you to move forward and solve the problem.</p>
","16589"
"Why are elasticities defined as logarithmic derivatives?","246","","<p>In my economics class, we often compute the elasticity of $Y$ with respect to $X$,
$$\eta = \frac{\partial \log Y}{\partial \log X}.$$
You can compute this from the slope of a line fit to a log-log plot. </p>

<p>Why is it more natural to consider this quantity than the much simpler quantity
$$\eta' = \frac{\partial Y}{\partial X}$$
which is just as easy to measure? There seems to be some implicit assumption that $\eta$ is perhaps 'more applicable', maybe that it's less sensitive to the value of $X$ than $\eta'$ is, so it's more useful for extrapolation. For example, I've seen a demand curve extrapolated by assuming that $\eta$ is constant, yielding a power law. But why not assume $\eta'$ is constant, yielding a line? Neither seems particularly more natural to me.</p>

<p>Why is $\eta$ a more useful quantity than $\eta'$ in economics?</p>
","<p>One extremely function throughout economics is the Cobb-Douglas functional form (eg. $y = bx_1^a x_2^b$). This won't just show up in utility functions, but also production functions or growth functions (like in the Solow Swan model).</p>

<p>Taking the log-log form here has a few implications. First, it drops $a$ and $b$ from exponents to linear coefficients, which gives you a form $lny = b+alnx_1+blnx_2$. This is important, because you can run a linear regression on this functional form, but not the original one. You can see an example of that in <a href=""http://eml.berkeley.edu/~dromer/papers/MRW_QJE1992.pdf"" rel=""nofollow"">this paper</a>. </p>

<p>It also has applications in empirical microeconomics; you can test to see if a firm has increasing, decreasing or constant returns to scale if you find $a+b &gt; or &lt; 1$. This can have important implications; it can answer some questions like ""should we break up these big companies?""</p>

<p>Second it makes the math nicer in some cases. This can actually be useful in some cases; in Maximum likelihood estimation having a more mathematically friendly functional form can save you hours of computation time finding maxima.</p>
","13912"
"Why does the definition of MRS follow from the implicit function theorem?","246","","<p>TRAIN OF THOUGHT 1: </p>

<p>From what I understand, $MRS$ is calculated as </p>

<p>$$dU = U_x dx +  U_y dy =0$$ 
which by rearrangement yields 
$$\frac{dy}{dx}= -\frac{U_x}{U_y}$$</p>

<p>So suppose I have $$U(x,y) = \ln x +\ln y$$ Then 
$$ \frac{dy}{dx}= -\frac{1/x}{1/y} = -\frac{y}{x}$$</p>

<p>Okay. So I have a function $y$ in terms of $x$.</p>

<p>TRAIN OF THOUGHT 2: </p>

<p>Now consider my $U(x,y)$ again. Let $$\mathbf{a} = \begin{bmatrix}
1\\
1
\end{bmatrix}$$ 
and $$U(\mathbf{a})=0$$
We have $$DU(x,y) = \begin{bmatrix}
\frac{1}{x} &amp; \frac{1}{y}
\end{bmatrix} $$
and $$\frac{\partial U}{\partial y} (\mathbf{a}) = \begin{bmatrix}\frac{1}{y}\end{bmatrix}= 1$$ which is nonsingular since $\det(1) = 1$ and so by the Implicit Function Theorem, $$U = 0$$ defines $y$ implicitly as a function of $x$ in a neighborhood of $\mathbf{a}$.  </p>

<p><strong>My Question:</strong></p>

<p>How are these two trains of thought connected? The first is stated in terms of differentials. But the second is not. So I am confused why the definition of $MRS$ follows from the implicit function theorem. </p>
","<p>It's actually pretty straight forward. The implicit function theorem for two variables is given as follows (as long as some regularity conditions hold):</p>

<p>For $F(x, y) = 0$,</p>

<p>$
\frac{dy}{dx} = -\frac{\partial F / \partial x}{\partial F / \partial y}
$</p>

<p>In the case of <em>MRS</em>, we want the marginal change in $x$ associated with a marginal change in $y$ required to maintain a certain level of utility, $c$, such as (conveniently) $c=0$. So, starting with</p>

<p>$U = U(x, y) = 0$,</p>

<p>we have</p>

<p>$\frac{dy}{dx} = -\frac{U_x}{U_y}$</p>

<p>Note that $c=0$ is just a simplification for exposition. For a general $c$, you can just subtract it from either side of the equation and you get the same result since $c$ disappears in the derivative.</p>
","5637"
"Solving Kaplan and Menzio: Shopping Time","245","","<p>Kaplan and Menzio's <a href=""http://se.shufe.edu.cn/upload/htmleditor/File/140522081313.pdf"" rel=""nofollow noreferrer"">shopping time model</a> is a search&amp;matching unemployment model where we, for a steady state equilibrium, need to determine to variables:</p>

<ul>
<li>$J$: Value of a worker </li>
<li>$u$: unemployment rate</li>
</ul>

<p>Their <em>steady state</em> values ($\dot J, \dot u = 0$) are given by the following system of equations:</p>

<p>$$ 
J = \frac{(1-\gamma)(S(u) + y_e - y_u)}{\rho + \delta}\\
u = \frac{\delta}{\delta + \lambda(J)}
$$</p>

<p>Furthermore, ""profits from the good with price dispersion"" and wages, respectively, are given by (equations (6), (7) on page 12)</p>

<p>$$
S(u) = A(u) + B(u)*w(u)\\
w(u) = y_u + \gamma*(S(u) + y_e - y_u)
$$</p>

<p>Where $A(u), B(u)$ are some placeholders for a bunch of constants and parameters, that may depend on $u$. I plug out the wages and solve as </p>

<p>$$
\tilde S(u) = \frac{A(u) + B(u)(y_u + \gamma(y_e - y_u)}{1 - B(u)\gamma}
$$</p>

<p>Then, using the authors' calibration and this version of $\tilde S(u)$, I can solve for both $J$ and $u$. Here it is:</p>

<p><img src=""https://i.stack.imgur.com/GgtM7.png"" alt=""My computation""></p>

<p>Given their calibration, they get two interesting steady state equilibria on the $(u, J)$ space: $(0.053, 11.3)$ and $(0.081, 9.5)$. My $u(J)$ graph seems to be correct as it goes through both these loci. The $J(u)$ line, however, seems to be ""too small"" given $u$. </p>

<p>The only object somewhat difficult to compute is $S(u)$. I have verified that my step of replacing actually works: I computed $w(u)$ using $\tilde S(u)$ and verified that $S(u, w(u)) == \tilde S(u)$ (up to a numerical approximation). </p>

<p>I am not asking for someone to find my mistake, but rather where to look for it: I have checked anything I could come up with and am somewhat stuck. For the interested, here is my Python code:</p>

<pre><code># solves simple shopping time model
# only on the steady state equilibria

import numpy as np
import matplotlib.pyplot as plt

# all parameters for monthly
class Parameters(object):
    def __init__(self):

        self.psi_u = 0.27 # search twice, unemployed
        self.psi_e = 0.02 # search twice, employed &lt; psi_u
        self.gamma = 0.74 # bargaining power
        self.alpha = 1 # BJ exponent in utility

        self.r = 15.7 # reservation price, home transformation
        self.c = 1 # production technology firm

        self.y_u = 4.91 # efficiency home
        self.y_e = 1 # efficiency firm

        self.rho = 0.003 # depreciation rate
        self.delta = 0.024 # separation rate

        self.phi = 1.24 # matching function efficiency
        self.k = 8.02 # search costs of labor for firm


def b(u, Param):
    return 1 + Param.psi_e + u*(Param.psi_u - Param.psi_e)
def s(u, Param):
    return 1 - u
def sigma(u, Param):
    return s(u, Param)/b(u, Param)
# seller meets buyer
def muOfU(u, Param):
    return np.minimum(1/sigma(u, Param), 1)
# buyer meets seller
def nuOfU(u, Param):
    return np.minimum(sigma(u, Param), 1)


def lambdaOfJ(J, Param):
    result = ( ((J/Param.k)**(Param.phi) - 1 )**(-1) + 1 )**(-float(1)/Param.phi)
    result[np.isnan(result)] = 0
    return result

# not needed atm, replaced within lambdaOfJ (instead of lambdaOfTheta)
def thetaOfJ(J, Param):
    #eta(theta)J = k
    #etaInverse = (eta^(-phi) - 1)^(1/phi)
    x = Param.k/J
    return (x**(-Param.phi) - 1)**(1/Param.phi)



def STilde(u, Param):


    A1 = muOfU(u, Param)*u*(1+Param.psi_u)/b(u, Param)
    A2 = 1 - 2*Param.psi_u*nuOfU(u, Param)/(1+Param.psi_u)
    A3 = Param.alpha*Param.y_u*(Param.r-Param.c)/Param.r
    A = A1*A2*A3

    B1 = muOfU(u, Param)*(1-u)*(1+Param.psi_e)/b(u, Param)
    B2 = 1 - 2*Param.psi_e*nuOfU(u, Param)/(1+Param.psi_e)
    B3 = Param.alpha*(Param.r-Param.c)/Param.r

    B = B1*B2*B3

    result = (A + B*(Param.y_u + Param.gamma*(Param.y_e - Param.y_u) ))/(1 - B*Param.gamma)
    return result

def S(u, wages, Param):
    A1 = muOfU(u, Param)*u*(1+Param.psi_u)/b(u, Param)
    A2 = 1 - 2*Param.psi_u*nuOfU(u, Param)/(1+Param.psi_u)
    A3 = Param.alpha*Param.y_u*(Param.r-Param.c)/Param.r
    A = A1*A2*A3

    B1 = muOfU(u, Param)*(1-u)*(1+Param.psi_e)/b(u, Param)
    B2 = 1 - 2*Param.psi_e*nuOfU(u, Param)/(1+Param.psi_e)
    B3 = Param.alpha*(Param.r-Param.c)/Param.r

    B = B1*B2*B3

    result = A + B*wages
    return result



def w(u, Param):
    return Param.y_u + Param.gamma*(STilde(u, Param) + Param.y_e - Param.y_u)

#result2 = A + B*w(u, Param)

def JSteadyState(u, Param):

    A = (1-Param.gamma)*(STilde(u, Param) + Param.y_e - Param.y_u )
    B = Param.rho + Param.delta
    return A/B

def uSteadyState(J, Param):

    B = Param.delta + lambdaOfJ(J, Param)
    return Param.delta/B


Param = Parameters()


# compute J(u) and u(J)
uGrid = np.linspace(0.001, 0.2, 100)
J = JSteadyState(uGrid, Param)

JGrid = np.linspace(5, 20, 1000)
u = uSteadyState(JGrid, Param)


# verify computation of S(u)
# wages given STilde:
wages = w(uGrid, Param)
# S given u, STilde
SOriginal = S(uGrid, wages, Param)
SWithTilde = STilde(uGrid, Param)

print max(abs(SWithTilde - SOriginal)) # 8.881784197e-16

# plot J(u) and u(J)
plt.plot(u, JGrid, label='u(J)')
plt.plot(uGrid, J, label='J(u)')
plt.legend()
plt.xlabel('u')
plt.ylabel('J')
plt.show()
</code></pre>
","<p><strong>UPDATE</strong><br>
After e-mail communication with one of the authors G.W.Kaplan, I recalibrated the value of the vacancy-posting cost parameter $k$ in order to obtain a cross of the two nullclines for $u=0.05$. This is achieved for $k=7.41$ (rounded). Moreover, with this value of $k$, I get a second (but not a third) steady state. A close up diagram :</p>

<p><img src=""https://i.stack.imgur.com/kWwjw.png"" alt=""enter image description here""></p>

<p>This still is not what Figures 1 and 2 of the paper show. The shape of the $J$-nullcline remains the issue. It should have an initial concave part and then a convex part in order to give us <em>three</em> steady states. But I won't dig it any further than that.</p>

<hr>

<p><strong>The $u$-nullcline</strong>  </p>

<p>On p.8 the authors define $\lambda(\theta) \equiv M(1,\theta)$ (I believe they should have written for clarity, $\lambda(\theta) \equiv M/u =  M(1,\theta)$) . On p. 25 they specify the matching function as $M(u,v) = uv(u^\phi + v^\phi)^{-1/\phi}$. Therefore we have</p>

<p>$$\lambda(\theta) = \theta(1 + \theta^\phi)^{-1/\phi}$$</p>

<p>This means that whenever $\theta = 0 \implies \lambda(\theta) =0$.</p>

<p>On p.14, eq. $(8)$ the give $k&gt; J \implies \theta = 0$.
In the calibration stage, $k=8.02$. The $u$-nullcline is defined as</p>

<p>$$u_{SS} = \frac {\delta}{\delta + \lambda[\theta(J))]}$$</p>

<p>All these together imply that
$$J &lt; 8.02 \implies u_{SS} = 1$$</p>

<p>Using the other relations specified, after a little algebra, we get 
$$J&gt;k=8.02 \implies \lambda[\theta(J)] = \left(1-(k/J)^{\phi}\right)^{1/\phi}$$</p>

<p>which is indeed your code, a bit less convoluted. And indeed the $u$-nullcline never crosses with the $J$-nullcline. For values of $u$ near unity see below. For low values of $u$ we obtain</p>

<p>\begin{array}{| r | r |}
  \hline 
\hline                       
  \text {u} &amp; \text {Jss} &amp; \text{uSS(in J units)} \\
  \hline                      
0.03 &amp; 12.25 &amp; 23.06 \\
0.04 &amp; 11.53 &amp; 14.13 \\
0.05 &amp; 10.86  &amp; 11.75 \\
0.06 &amp; 10.23 &amp; 10.66 \\
0.07 &amp; 9.64 &amp; 10.03\\
0.08 &amp; 9.09 &amp; 9.62\\
0.09 &amp; 8.57 &amp; 9.34\\
0.10 &amp; 8.09 &amp; 9.14\\
  \hline  
\end{array} </p>

<p>The $u$-nullcline stays always above the $J$-nullcline. I also ""pushed"" the $J$-nullcline by the factor $(1+\rho)$, i.e. the discrete version of the equation. But $\rho=0.003$, too small a mark-up, and so again there was no crossing. 
<strong>Therefore it appears that what went into the simulations of the authors is at some point(s) different from what the equations and the calibrated parameters (Table 2) appearing in the paper give us.</strong> Or, we are missing something.</p>

<p><strong>The $J$-nullcline</strong><br>
I checked the OP's code line by line, including the values of the calibrated parameters. I did not find any discrpeancy with what the paper gives. I then copy-pasted the code for the $J$-nullcline into Gretl, tweaking it only to match the local language.
<strong>A note:</strong> the way various magnitudes are defined in the paper, we have</p>

<p>$$\psi_u &gt; \psi_e \implies b &gt;1 \;\forall u \implies \sigma = s/b &lt; 1, \;\forall u$$</p>

<p>$$\implies \text {muOfU}\equiv \mu(\sigma(u)) = \min(1/\sigma, 1) = 1,\; \forall u$$</p>

<p>$$\implies \text {nuOfU}\equiv \nu(\sigma(u)) = \min(\sigma, 1) = \sigma, \; \forall u$$ </p>

<pre><code>**GRETL script**  
solves simple shopping time model
 only on the steady state equilibria
     nulldata 100  
      genr series u = index/100   
        genr scalar  psi_u = 0.27 # search twice, unemployed
        genr scalar  psi_e = 0.02 # search twice, employed &lt; psi_u
        genr scalar  gamma = 0.74 # bargaining power
        genr scalar  alpha = 1 # BJ exponent in utility

        genr scalar  r = 15.7 # reservation price, home transformation
        genr scalar  c = 1 # production technology firm

        genr scalar  y_u = 4.91 # efficiency home
        genr scalar  y_e = 1 # efficiency firm

        genr scalar  rho = 0.003 # depreciation rate
        genr scalar  delta = 0.024 # separation rate

        genr scalar  phi = 1.24 # matching function efficiency
        genr scalar  k = 8.02 # search costs of labor for firm

        genr series b =1 + psi_e + u*(psi_u - psi_e)
        genr series s = 1-u 
        genr series sigma = s/b
        genr series sigmareci = 1/sigma
        genr list  mlist = sigmareci const
        genr list  nlist  = sigma const
        genr series muOfU = min(mlist)  # seller meets buyer
        genr series nuOfU = min(nlist)  # buyer meets seller


# def STilde:

    genr series A1 = muOfU*u*(1+psi_u)/b
    genr series A2 = 1 - 2*psi_u*nuOfU/(1+psi_u)
    genr scalar A3 = alpha*y_u*(r-c)/r
    genr series A = A1*A2*A3

    genr series B1 = muOfU*(1-u)*(1+psi_e)/b
    genr series B2 = 1 - 2*psi_e*nuOfU/(1+psi_e)
    genr series B3 = alpha*(r-c)/r

    genr series  B = B1*B2*B3

    genr series STilde = (A + B*(y_u + gamma*(y_e - y_u) ))/(1 - B*gamma)

# def JSS

genr series JSS = (1-gamma)*(STilde + y_e - y_u ) / (rho+delta)
</code></pre>

<p>I obtained the values</p>

<p><img src=""https://i.stack.imgur.com/QedFo.png"" alt=""enter image description here""></p>

<p>and the graph</p>

<p><img src=""https://i.stack.imgur.com/JIlSb.png"" alt=""enter image description here""></p>

<p>From the above we can see that the $J$-nullcline, although it starts increasing, it never approaches again the value $8$, which is $\approx$ the low asymptote for the $u$-nullcline. </p>
","4807"
"Instrumental variables for minimum wage","244","","<p>I was wondering if there is a classic instrument for minimum wage as there is for schooling or other variables. If so, how does it fares with respect to most established designs like spatial differences <a href=""http://davidcard.berkeley.edu/papers/njmin-aer.pdf"">http://davidcard.berkeley.edu/papers/njmin-aer.pdf</a> or recent spatial regression discontinuity designs.<br>
Assume even that one has panel data is it enough to control for its deep lags. 
This is a reference question but if you have your own ideas feel free to post. </p>
","<ul>
<li><a href=""http://ftp.iza.org/dp1136.pdf"" rel=""nofollow"">This Discussion Paper</a> (PDF) suggests the use of political variables as an instrument for minimum wage.</li>
</ul>

<p>See abstract (emphasis mine):</p>

<blockquote>
  <p>Following the early 1980s apparent consensus, there has been a controversial debate in the literature over the direction of the minimum wage employment effect. Explanations to non-negative effects range from theoretical to empirical identification and data issues. An explanation, however, that has not been sufficiently explored is that a non-negative effect might be an upward biased estimate of a truly negative effect, resulting from the simultaneous determination of the minimum wage and employment. <strong>This paper estimates the employment effect of the minimum wage using a number of political variables – not previously used in the literature – as excluded exogenous instruments to control for the endogeneity of the minimum wage variable.</strong> The data used is an under-explored Brazilian monthly household survey from 1982 to 2000. Robust results indicate that an increase in the minimum wage has very small adverse effects on employment.</p>
</blockquote>

<ul>
<li><a href=""https://economics.uchicago.edu/workshops/Rubinstein%20Yona%20Using%20Federal%20Minimum%20Wages%20Paper.pdf"" rel=""nofollow"">This article</a> (PDF) (Which I like better anyway) uses the differences in the changes on minimum wages wrt to the federal minimum wages. It is worth noting that this paper has a pretty good reference list and useful introduction as well. I'd start here looking for further reading.</li>
</ul>

<p>See abstract (emphasis mine):</p>

<blockquote>
  <p>The magnitude of the impact of minimum wages on employment is a hotly debated topic in policy and academic circles. In this paper, we use cross-state differences in the impact of adjustments in federal minimum wages on effective minimum wages in each state - the maximum of federal and state minimum wages - to reassess this question and explain biases in past research. <strong>A rise in the federal minimum wage will have a larger impact on a state's effective minimum wage in states in which federal minimum wages are binding</strong>. Using CPS data for 1977-2007, we find notable wage impacts and large corresponding disemployment effects, yet only when we utilize the differential influences of federal minimum wages to instrument for state wage floors. State effective minimum wages are procyclical. Accounting for the endogenous determination of effective minimum wages at the state level turns out to be materially important for drawing accurate inferences about the impact of minimum wages on employment</p>
</blockquote>
","8565"
"Why does Venezuela have such a high Big Mac Index?","243","","<p>Venezuela is ranked #2 in the 2014 Big Mac Index at \$7.15 per Big Mac. You can see the graph <a href=""http://knoema.com/EBMI2015Jan/the-economist-big-mac-index-july-2015"" rel=""nofollow"">here</a>.  However, Venezuela is not a very rich country, having a gross domestic product of \$11,789 per capita. </p>

<p>There are at least 20 McDonalds in Caracas, so there is a fairly large supply. With a small gross domestic product the quantity demanded should be smaller by high prices. Even if the market for Big Mac-like products is a monopoly in Venezuela, I still think the price shouldn't be that high.</p>

<p>Another thing that is remarkable is that after 2014, the price had a rapid decrease. Maybe the transformation from a monopoly market to a monopolistic competition market caused it rapid decrease in price in June 2015?</p>

<p>In short the questions:</p>

<ul>
<li>How could the price of a Big Mac be so high? </li>
<li>What caused it rapid decrease in price?</li>
</ul>
","<p>It is worth noting that Venezuela has had <a href=""http://www.xe.com/currency/vef-venezuelan-bolivar#additionalinfo"" rel=""nofollow"">currency controls</a> in place for quite some time now, so the locals cannot get dollars at the world exchange rate.</p>

<blockquote>
  <p>On January 2010, the government of Venezuela created a two-tiered official exchange rate system. Imports designated as ""non-essential"" receive a rate of 4.3 bolivares per dollar, and ""essential"" goods are exchanged at a rate of 2.6. There is also a third and unofficial exchange rate in the black market valued at around 6.8 bolivares per dollar (March 2010).
  The Venezuelan government decides what ""essential"" goods qualify for the 2.6 rate. They include imports for sectors related to food, health, education, equipment, and technology; remittances to relatives settled abroad; students' academic expenses abroad; expenses related to health, sport, culture, and scientific investigations; payments to retired and resident pensioners abroad; and currency conversions related to diplomatic activities.</p>
</blockquote>

<p>The dollar value of a Big Mac at the official Venezuelan exchange rate is less than \$7.15.
<br>(If my deeming it non-essential is correct it would be around \$2.50.)</p>

<hr>

<p>Truth be told I am surprised they still have McDonald's restaurants in Venezuela, because long time president Chavez chastized US companies strongly and frequently and I think everyone associates McDonald's with the US. </p>
","9901"
"Strict preference relations and utility representations","242","","<p>Suppose I have a rational preference relation $\succsim$ on some consumption set $X$. </p>

<p>Suppose also that there is a utility function $u:X \to \mathbb{R}$ representing $\succsim$. </p>

<p>Definition: A function $u: X \to \mathbb{R}$ is a utility function representing preference relation $\succsim$ if, for all $x, y  \in X$, $$x \succsim y \iff u(x) \geq u(y)$$</p>

<p>Is it possible to prove that $x \succ y \iff u(x) &gt; u(y)$ without a continuity condition on $\succsim$?</p>

<p>My intuition says no, but am having difficult finding a suitable counter example. Any help is appreciated.</p>
","<p>Yes it is: <br>
If direction
$$
x \succ y \Rightarrow x \not \precsim y \Rightarrow u(x) &gt; u(y).
$$
Only if direction: <br>
For all $x, y  \in X$, 
$$
x \succsim y \iff u(x) \geq u(y)
$$
implies
$$
x \sim y \iff u(x) = u(y).
$$
Also
$$
u(x) &gt; u(y) \Rightarrow u(x) \geq u(y) \Rightarrow  x \succsim y ,
$$
$$
u(x) &gt; u(y) \Rightarrow u(x) \not = u(y) \Rightarrow  x \not\sim y.
$$
and
$$
x \succsim y \mbox{ AND } x \not\sim y \Rightarrow x \succ y.
$$</p>
","8699"
"Government's intervention question","241","","<p>Given that demand for a good X is equal to $q_D=393-2p$ and market supply is $q_S=p/4-12$. Find equilibrium price and quantity, consumer and producer surplus and draw a diagram illustrating the situation. Given that:</p>

<p>a) $T=2q$, every single item sold is taxed.</p>

<p>b) $T=20\% TR$ total revenue is taxed</p>

<p>Obviously i have calculated the equilibrium price and quantity before taxation that is $p=180,q=33$.But i have no idea how to caculate those two values after taxation.</p>
","<p>I apologise for the poor formatting and such, this is one of my first posts so please let me know if anything needs improvement (including, possibly, the correctness of my answer!).</p>

<p>For part a.), I'm assuming that a per unit tax of $2q$ is levied on the consumer in this market. The inverse demand function and inverse supply function are given by $p = \frac{393}{2} - \frac{q}{2}$ and $p = 4q + 48$ respectively. Thus, a per unit tax of $T = 2q$ will result in the inverse demand function being $p + 2q = \frac{393}{2} - \frac{q}{2} \iff p = \frac{393}{2} - \frac{5q}{2}$. Equating supply and demand, we find that the new equilibrium quantity is $q = 22.846$, the price that consumers pay is $185.077$ and the price producers receive is $139.385$.</p>

<p>For part b.), I'm assuming that a tax of $20$% of revenue is levied on the producer in this market. The inverse demand function and inverse supply function are given by $p = \frac{393}{2} - \frac{q}{2}$ and $p = 4q + 48$ respectively. Thus, a tax of $20$% of revenue will result in the inverse supply function being $p - 0.2p = 4q + 48 \iff p = 5q + 60$. Equating supply and demand, we find that the new equilibrium quantity is $q = 18.2$, the price that consumers pay is $187.4$ and the price producers receive is $120.8$.</p>

<p>I hope this makes sense (and is correct)! Feedback would be great!</p>
","10144"
"Inflation reasons beyond Friedman","241","","<p>I think everyone know this Friedman quote nowadays:</p>

<blockquote>
  <p>Inflation is always and everywhere a monetary phenomenon in the sense
  that it is and can be produced only by a more rapid increase in the
  quantity of money than in output</p>
</blockquote>

<p>However, things are not that simple. The US had emitted lots of money and has very little inflation. In some cases there's also a spiral effect. Some heterodox economists talk about lack of supply of goods too. And emission still applies only to the mid &amp; long term.</p>

<p>To sum up, the questions would be:</p>

<p>1) Can businesses be an important cause of inflation or is it a pure monetary effect?</p>

<p>2) In not-so-developed countries, there might not be much competition.  Can that generate inflation?</p>

<p><strong>Edited.</strong> <em>Original question:</em> Can anyone help me understand when that quote is true and when other factors should be considered too?</p>
","<blockquote>
  <p>The US had emitted lots of money and has very little inflation.</p>
</blockquote>

<p>Are we talking about quantitative easing here?  It depends how broadly you are willing to define inflation.  Quantitative easing has caused asset price increases, just not consumer price inflation.  Look at stock prices, which are about 50% overvalued according to some well regarded investors (e.g. <a href=""http://investcorrectly.com/20141126/us-market-overvalued-buffett-indicator-market-cap-us-gnp/"" rel=""nofollow"">Warren Buffett</a>).  </p>

<p>A common complaint about quantitative easing is that it is overly focused on investments and not focused enough on people (Wall Street over Main Street).  It has been successful at propping up stock prices to the point that they have returned to their 2008 levels, when they were regarded as being in a bubble.  Quantitative easing is heavily focused on investment assets.  It doesn't seem to be getting money into the hands of consumers.  Household incomes are still low.  </p>

<p>In short, I don't believe that the current US recession has disproved Friedman's statement.  The Federal Reserve has eschewed its traditional open market operations in favor of quantitative easing, which has affected investments without increasing the money supply available to consumers.  A better question might be why quantitative easing is widely regarded as expanding the money supply when it doesn't seem to actually do that--at least not the kind of money supply whose expansion causes consumer price inflation.  </p>

<p>Note:  I'm sure that there is theoretical work disagreeing with Friedman's statement.  I haven't tried to cover that.  I was caught up in the questionable assertion that the US money supply has expanded without causing inflation.  I suspect that this is too new for a consensus to have arisen. This is my thoughts on one possible explanation.  </p>
","340"
"Price difference of substitute goods when the supply increases?","241","","<p>In a competitive market, there are 3 types of goods: X, Y and money (m). X and Y are <a href=""https://en.wikipedia.org/wiki/Substitute_good"" rel=""nofollow"">substitute goods</a>, and the utility functions are quasi-linear with respect to money, i.e:</p>

<p>$$U(x,y,m) = u(x,y) + m$$</p>

<p>The supply of X and Y is  determined exogeneously, and the prices $p_x$ and $p_y$ are then determined such that the system is in equilibrium (i.e. demands for X and Y equal their supply).</p>

<p>Now the supply of X is increased, and a new equilibrium is achieved with new prices $p_x'$ and $p_y'$. What can we say about the new prices?</p>

<ul>
<li>Certainly $p_x'&lt;p_x$, since we must have new consumers buying the newly available units of X.</li>
<li>Certainly $p_y'\leq p_y$, since X and Y are substitutes (when the price of X decreases, the demand for Y weakly decreases so the price of Y also weakly decreases).</li>
<li>My main question is: <strong>what happens to the price difference $p_x-p_y$?</strong> I did some anecdotal simulations, and it seems that $p_x'-p_y'\leq p_x-p_y$. I.e, even if there is a decrease in the price of Y, the decrease in the price of X is weakly larger.</li>
</ul>

<p>Is this observation correct?</p>

<p>What really happens to the price difference when the supply increases?</p>
","<p>To use a simple example, assume that consumer $i$ maximizes</p>

<p>$$U(x_i,y_i,I_i) = \alpha\ln x_i +(1-\alpha)\ln y_i + (\bar I_i-p_xx_i -p_yy_i)\\
s.t. \bar I_i \geq p_xx_i +p_yy_i$$</p>

<p>In other words, it may spend all his income on the two goods (but not more), or he may keep some for other goods, not modeled here. Due to the inequality in the constraint we need to use a Karush-Kuhn-Tucker non-negative multiplier, rather than the usual Lagrange multiplier.
Assuming a fixed income, the lagrangean function is</p>

<p>$$\Lambda = \alpha\ln x_i +(1-\alpha)\ln y_i + (\bar I_i-p_xx_i -p_yy_i) +\lambda_i(\bar I_i-p_xx_i -p_yy_i)$$</p>

<p>Assuming income is fixed, the first order conditions are</p>

<p>$$\frac {\alpha}{x_i} - (1+\lambda_i)p_x \leq 0,\;\; \frac {1-\alpha}{y_i} -  (1+\lambda_i)p_y  \leq  0$$</p>

<p>$$\lambda(\bar I_i-p_xx_i -p_yy_i) = 0 ,\; x_i\cdot \left(\frac {\alpha}{x_i} -  (1+\lambda_i)p_x\right)=0, \; y_i\cdot \left(\frac {1-\alpha}{y_i} -  (1+\lambda_i)p_y\right) =0$$</p>

<p>it follows that at the optimum both goods will be demanded in positive quantities, which in turn requires that the first-derivatives be set equal to zero. This gives us</p>

<p>$$\frac {\alpha}{p_xx_i} = \frac {1-\alpha}{p_yy_i} \implies x_i^D=\frac {\alpha}{1-\alpha}\frac {p_y}{p_x}y_i^D \tag{1}$$</p>

<p>from which we can obtain the optimal relation for the Expenditure $E_i$ on the two goods</p>

<p>$$E_i^* = \frac {1}{1+\lambda_i^*} , \;\; E_i^* \leq \bar I_i$$</p>

<p>Since $\lambda_i \geq 0 \implies  \max E_i^* \leq 1$ so if it so happens that $\bar I_i &gt;1$ then not all income will be spent on the two goods, the constraint won't be binding and so $\lambda_i^* =0 $. (Is $\max E_i^* \leq 1$ a strange result?) On the other hand if $\bar I_i \leq 1$ then we will necessarily have $E_i^* = \bar I_i$, and $\lambda_i^* = (1-\bar I_i)/\bar I_i$.</p>

<p>In either case, optimal relation $(1)$ remains valid. So, assuming identical consumers with respect to preferences (not necessarily with respect to Income), aggregating $(1)$ we obtain the market-level relation</p>

<p>$$ X^D=\frac {\alpha}{1-\alpha}\frac {p_y}{p_x}Y^D \tag {2}$$</p>

<p>At equilibrium, we have $X^D = X^S,\; Y^D = Y^S \tag{3}$.</p>

<p>Equations $(2)$ and $(3)$ hold for any supply. 
We now change the supply of $X$ but leave the supply of $Y$ unchanged. Indexing  the initial situation by $0$ and the second situation by $1$, they are described by</p>

<p>$$ X^D_0=\frac {\alpha}{1-\alpha}\frac {p_{y0}}{p_{x0}}Y^D_0,\;\;X^D_0 = X^S_0,\;\; Y^D_0 = Y^S_0 \tag {4}$$</p>

<p>$$ X^D_1=\frac {\alpha}{1-\alpha}\frac {p_{y1}}{p_{x1}}Y^D_1,\;\;X^D_1 = X^S_1&gt;X^S_0,\;\; Y^D_1 = Y^S_1= Y^S_0\tag {5}$$</p>

<p>Then we have</p>

<p>$$X^D_1 - X^D_0 = \frac {\alpha}{1-\alpha}\frac {p_{y1}}{p_{x1}}Y^D_1 - \frac {\alpha}{1-\alpha}\frac {p_{y0}}{p_{x0}}Y^D_0   $$</p>

<p>and using the various relations</p>

<p>$$\implies X^S_1 - X^S_0 = \frac {\alpha}{1-\alpha}\frac {p_{y1}}{p_{x1}}Y^S_1 - \frac {\alpha}{1-\alpha}\frac {p_{y0}}{p_{x0}}Y^S_0 &gt;0   $$</p>

<p>$$\implies \frac {\alpha}{1-\alpha}Y^S_0\cdot \left[\frac {p_{y1}}{p_{x1}}-\frac {p_{y0}}{p_{x0}}\right] &gt;0$$ </p>

<p>$$\implies \frac {p_{y1}}{p_{x1}}-\frac {p_{y0}}{p_{x0}} &gt;0 \implies \frac {p_{y1}}{p_{y0}}&gt;\frac {p_{x1}}{p_{x0}} \tag{6}$$</p>

<p>$(6)$ tells us that the price of $Y$, if it falls, it will fall certainly less than the price of $X$, but <em>in proportional terms</em>.  </p>

<p>It appears that in this benchmark example, we cannot say anything about the price changes in terms of <em>levels</em>, as the OP asks about.  </p>

<p>If the levels of the two prices are very different we can easily have a smaller proportional fall for $p_y$, while at the same time a higher fall in monetary units. Set for example $p_{y0} = 100, p_{x0} = 1$, and assume that the price of $Y$ falls only by $10$% while the price of $X$ falls by $20$%.  </p>

<p>In turn the levels of prices depends on the magnitude of the supply of the two goods also, which are treated as exogenous here.</p>
","4764"
"Prove that a continuous $\succsim$ is quasilinear","241","","<p>This question is closely related to <em>Mas-colell, Whinston, Green: Microeconomic Theory</em>, <strong>Question 3.C.5b</strong></p>

<blockquote>
  <p>Let $\succsim$ be a strictly monotone, continuous, and rational
  preference relation on $(-\infty, \infty)\times \mathbb{R}^{L-1}_{+}$.
  Furthermore, suppose $\succsim$ is quasilinear in good $L$. Let us
  write $x \in X$ as $x=(y,x_{L})$ where $y \in  \mathbb{R}^{L-1}_{+}$. </p>
  
  <p>It can be shown that if $v(y,x_{L})$ is a utility function that represents $\succsim$, then there
  is a unique $x_{L}(y) \in \mathbb{R}$ such that  $v(y,x_{L}(y))=0$. </p>
  
  <p>Let $\phi(y)=-x_{L}(y)$ and show the utility function of the form
  $u(x) = x_{L} + \phi(y)$ represents $\succsim$.</p>
</blockquote>

<p><strong>Proof:</strong></p>

<p>To show that $u(x)$ represents $\succsim$ I need to show that for every $x,x' \in X$, $x'\succsim x \iff u(x') \geq u(x)$.</p>

<p>However, I have found an example that may not be satisfied: suppose that $x$ and $x'$ are such that $x=(y,x_{L})$ and $x'=(y',x'_{L})$, with $x\precsim x'$, $(y,z_{L}) \precsim (y',z_{L})$  $\forall z_{L}$ and $(z,x'_{L}) \precsim (z,x_{L})$  $\forall z$.</p>

<p>These preferences imply:</p>

<p>$(y,x_{L}') \precsim (y,x_{L}) \precsim (y',x_{L}') \precsim (y',x_{L})$</p>

<p>To show that $u(x)$ is consistent with this I need to show that this preference implies:</p>

<ol>
<li>$u(y, x_{L}') \leq u(y,x_{L}) \leq u(y',x_{L}') \leq u(y',x_{L})$</li>
</ol>

<p>and not</p>

<ol start=""2"">
<li>$u(y, x_{L}') \leq u(y',x_{L}') &lt;  u(y,x_{L}) \leq u(y',x_{L})$</li>
</ol>

<p>However I can find no reason why 2. presents any sort of contradiction! I have been thinking about this for two days, and am sure by now I am making some logical errors. Either the example I have come up with is not valid, or it must imply some sort of contradiction!  Any comments will help. And please hints only, no full solutions.  </p>
","<p>First off it seems to me you are proceeding in a manner more complicated than necessary. (Perhaps this is intentional because you wish to face a harder exercise.) Since it is given that $v(x)$ represents $\succsim$ you only have to show
$$
\forall x,x' \in X: v(x') \geq v(x) \iff u(x') \geq u(x).
$$
I think this would be a lot simpler than what you are currently doing.</p>

<p>On to your question:
<br> The function $u(x)$ is very well defined, as
$$
u(y,x_{L}) =  x_{L} + \phi(y) = x_{L} - x_L(y) 
$$
and we know that $v(y,x_L(y)) = 0$ describes the indifference curves of $\succsim$. The conditions you describe would violate this assumption because from
$$
(y,x_{L}) \precsim (y',x_{L}')
$$
it follows that
$$
v(y,x_{L}) \leq v(y',x_{L}').
$$
We can assume $v(y,x_{L}) = 0$, this is an affine transformation of any $v(y,x_{L})$. So $x_L(y) = x_{L}$.
<br> (I am not crazy about the notation, feel free to edit my post as long as it remains consistent with the question.)
<br>
 Then we also have $0 \leq v(y',x_{L}')$, and because of monotonicity this means
$x_L(y') &lt; x_{L}'$.
<br> Then
$$
u(y',x_{L}') &lt; u(y,x_{L})
$$
cannot hold as
$$
u(y,x_{L}) = x_{L} + \phi(y) = x_{L} - x_{L}(y) = 0
$$
and
$$
u(y',x_{L}') = x_{L}' + \phi(y') = x_{L}' - x_{L}(y') &gt; 0,
$$
because of what we have shown earlier, $x_L(y') &lt; x_{L}'$.</p>
","8343"
"Is technical analysis somehow a valid method for investment?","240","","<p>I personally think technical analysis (TA) is not useful at all but I still see lot of courses about technical analysis, and even people using it.  They have the advantage of being easy to learn and they claim themselves as following the ""behavioral economics"" theory.</p>

<p>Is the traditional &amp; simple TA somehow valid?  I'm asking about the one that uses moving averages, graphs, momentum lines to try to predict market moves.  </p>

<p>The behavioral economics theory is valid and 2 people won Nobel prizes because of that, so I'm not arguing its validity, but its consequences or usefulness as an investment method.</p>

<p>Please take into account not only a highly efficient market (eg, the US), but other smaller and less efficient markets (I'm from Argentina).</p>
","<p>The Lo, Mamaysky and Wang paper <a href=""http://www.nber.org/papers/w7613"" rel=""nofollow"">Foundations of Technical Analysis: Computational Algorithms, Statistical Inference, and Empirical Implementation</a> is probably the best investigation of this question. He found there were some patterns that seemed to be useful, notably the Head and Shoulders pattern. </p>
","186"
"What makes the Balance of Payments (BoP) to imbalance?","240","","<p>Theoretically the capital account balance should fully offset the current account balance and the BoP should be zero for any economy. What causes the imbalance or discrepancy in the overall BoP ? What makes countries run BoP surplus or deficits ?</p>
","<ul>
<li>According to the IMF's <a href=""https://www.google.com.sg/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiU-8rH77zLAhWUCI4KHdoPAp4QFgggMAE&amp;url=https%3A%2F%2Fwww.imf.org%2Fexternal%2Fpubs%2Fft%2Fbop%2F2007%2Fbopman6.htm&amp;usg=AFQjCNEhf7GCYEHLcXZvW59zx5EjmGhfDg&amp;sig2=0EZIgynIhAKXPeJtIGTsZw"" rel=""nofollow"">BPM6</a>, which should be taken as the ""most"" standard, it is impossible for the BOP to be out of balance.</li>
</ul>

<p>In the IMF BPM6, BOP simply refers to a statistical statement (think of it as a piece of paper or an Excel spreadsheet) that records, in summary form, all of the country's international transactions. The BOP never refers to a number. Hence, there is no such thing as a BOP surplus or a BOP deficit. </p>

<p>The three accounts in the BOP are the Current Account (CA), the Capital Account (KA), and the Financial Account (FA). In theory, it is always necessarily the case that: CA + KA + FA = 0. (In practice, we have to add an ""errors &amp; omissions"" term.)</p>

<p>Hence the name <em>balance</em> of payments. The above balance of payments identity must always hold.</p>

<p>Unfortunately, not everyone follows the IMF's recommendation. This causes a lot of confusion. </p>

<ul>
<li>Some countries break up the BOP in a different way and DO refer to the BOP as a number.</li>
</ul>

<p>For example, Singapore takes out ""changes in official reserves"" (ΔR) from the Financial Account and combines what is left of the FA with the CA into a single account called the Capital &amp; Financial Account (KFA). </p>

<p>And so for Singapore, the BOP identity can be written as: CA + KFA + ΔR = 0. </p>

<p>And <strong>very confusingly</strong>, Singapore then defines BOP = CA + KFA = -ΔR. Hence, in Singapore, a BOP surplus refers to when there is an increase in official reserves (yes, strangely enough, ΔR &lt; 0 ⇔ official reserves increase). And a BOP deficit is when there is a decrease in official reserves. </p>

<p>Singapore's presentation of the BOP is actually not so unusual. The IMF BPM6 for example does suggest it as a possible alternative presentation of the BOP (see end of p. 224 and start of p. 225). However, I think it's pretty unusual to define the BOP as a number equal to -ΔR, as Singapore does.</p>

<ul>
<li>Journalists frequently speak, mistakenly, of a BOP deficit, when they really mean a trade deficit (or, what is slightly different, a CA deficit). </li>
</ul>

<p>This obviously adds a lot of confusion to an already confused situation.</p>
","11077"
"Converting word definitions of Pareto-Optimal into math symbols","238","","<p>I'd like to have a mathematical version of the following two definitions just because I remember symbols better than words. But I lack the math prowess to convert them from words to symbols. Can someone assist me? </p>

<p>Def 1:</p>

<p>A feasible allocation is <strong>weakly Pareto-optimal</strong> if there is no alternative (feasible) allocation such that <em>everyone</em> prefers the alternative to the original. </p>

<p>Def 2: </p>

<p>A feasible allocation is <strong>strongly Pareto-optimal</strong> if there is no alternative (feasible) allocation such that at least one person prefersthe alternative, and everyone else is indifferent. </p>
","<p>Let $\Omega$ be the set of all feasible allocations with an element $\omega \in \Omega$.  Consider $I$ agents such that the utility of agent $i$ is described by $u_i(\omega)$.</p>

<p>Definition 1: $\omega \in \Omega$ is weakly Pareto-optimal if $\nexists \omega' \in \Omega$ such that $\forall i$ $u_i(\omega') &gt; u_i(\omega)$.  Weak Pareto-optimality is basically just saying that for any other allocation, $\omega'$, in the set of feasible allocations that not everyone can strictly prefer the alternative.</p>

<p>Definition 2: $\omega \in \Omega$ is strongly Pareto-optimal if $\nexists \omega' \in \Omega$ such that $\forall i$ $u_i(\omega') \geq u_i(\omega)$ with strict inequality for at least one $i$.  Strong Pareto-optimality is a little stronger in the sense that your allocation must be strictly preferred by some to all other allocations and everyone else can be indifferent.</p>

<p>I hope that is helpful.</p>
","3117"
"Equivalence of Definitions of Continuity of Preferences","238","","<p>We have two definitions of the continuity of preferences:</p>

<blockquote>
  <p><strong>Def 1:</strong> $\succcurlyeq$ is continuous if for any sequences $\{x^n\} \subset X$ and $\{y^n\} \subset X$, then $n \in \mathbb{N}$ such that,</p>
  
  <ul>
  <li>$\forall n, \quad x^n \succcurlyeq y^n$</li>
  <li>$\lim_{n \rightarrow \infty} x^n = x, \quad \lim_{n \rightarrow \infty} y^n = y \quad (\text{where $x, y \in X)$}$</li>
  </ul>
  
  <p>then $x \succcurlyeq y$</p>
</blockquote>

<p>and</p>

<blockquote>
  <p><strong>Def 2:</strong> $\succcurlyeq$ is continuous if whenever $x \succ y$, $\exists \ B_x, \ B_y$, open balls around $x, y$, such that $\forall \ x' \in B_x, \ y' \in B_y$, then we have $x' \succ y'$.</p>
</blockquote>

<p>Show that the following definitions are equivalent to each other.</p>
","<p>We want to show that for $\succcurlyeq$ on $X$, <strong>Def 1 $\iff$ Def 2</strong></p>

<p>$\boxed \Longrightarrow$</p>

<p>Assume that $\succcurlyeq$ is continuous by <strong>Def 1</strong>.</p>

<p>Let us say $x \succ y$. Denote our open-balls as $B(x, r)$, an open ball around $x$ of radius $r$. Suppose $\forall n, \ \exists \ x^n \in B(x, \frac{1}{n}), \ y^n \in B(y, \frac{1}{n})$ such that $y^n \succcurlyeq x^n$. But then we have constructed $\{x^n\} \rightarrow x$ and $\{y^n\} \rightarrow y$, and by <strong>Def 1</strong>, $y \succcurlyeq x$, which is a contradiction.</p>

<p>$\boxed \Longleftarrow$</p>

<p>Assume that $\succcurlyeq$ is continuous by <strong>Def 2</strong>.</p>

<p>Let us take sequences ${x^n} \subset X$ and ${y^n} \subset X$ where $\forall n, \quad x^n \succcurlyeq y^n$ and $\lim_{n \rightarrow \infty} x^n = x, \quad \lim_{n \rightarrow \infty} y^n = y \quad (\text{where $x, y \in X)$}$ for $n \in \mathbb{N}$,</p>

<p>BUT $x \succcurlyeq y$ is false instead of true. We want to show this leads to a contradiction.</p>

<p>If $x \succcurlyeq y$ is false, (so $y \succ x$) then $\exists B_x, B_y$ such that $\forall y' \in B_y, x' \in B_x$, we have $y' \succ x'$. Because $\{x^n\} \rightarrow x, \{y^n\} \rightarrow y$, there exists $N$ large enough such that $\forall n&gt;N$, we have $y^n \in B_y, x^n \in B_x$.</p>

<p>Thus $\forall n &gt; N$, we have $y^n \succ x^n$, which contradicts $\forall n, \ x^n \succcurlyeq y^n$.</p>
","13417"
"How is labor disutility modeled in Arrow-Debreu model?","238","","<p>In DSGE models, utility function contains labor disutility components. But I cannot not see how labor disutility is incorporated in Arrow-Debreu-Mackenzie model. </p>
","<p>In the Arrow-Debreu model, households are endowed with some commodities, producers can use feasible production plans to transform commodities, and households ultimately consume commodities - which they choose optimally given their preferences subject to budget constraints. </p>

<p>These commodities can include (potentially time and state-contingent) labor services provided by households. In this framework, provision of labor can simply be viewed as a form of negative consumption, which decreases utility but provides earnings that can be spent elsewhere. Indeed, the <a href=""http://cowles.econ.yale.edu/P/cp/p00b/p0087.pdf"" rel=""nofollow noreferrer"">original Arrow-Debreu paper</a> mentions this interpretation several times. For instance, on page 268 when they describe households in the model (which they call ""consumption units""):</p>

<p><img src=""https://i.stack.imgur.com/BZifZ.png"" alt=""enter image description here""></p>
","1878"
"Why doesn't the price of gold drop as mining occurs that produces more gold?","238","","<p>According to my common knowledge, the price should drop when supply increases. Why doesn't the price of gold drop slowly as more gold is produced from mining?</p>
","<p>You cannot reason directly from a price change. Prices may increase because supply has fallen or demand has changed. In general we can't distinguish between the two unless we know something about the demand and supply curve in particular and not just prices and quantities. </p>

<p>For example, when demand increases (the demand curve shifts to the right but supply curves are held fixed) this increases demand for gold at all prices. Which means that equilibrium quantity increases (more gold is produced) as well.  </p>

<p><a href=""https://i.stack.imgur.com/zHuF3.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zHuF3.jpg"" alt=""enter image description here""></a>.  </p>

<p>But that gold doesn't decrease prices. The only reason more gold was produced was because prices were higher. If prices fell in response to higher quantity produced the producers (who have the same supply function by assumption) would not produce more. So in response to a demand shock for gold prices increase in order to clear the market for gold. Otherwise there is not enough gold at the old prices. </p>
","7102"
"An agent's expected utility depends only on mean and variance","237","","<blockquote>
  <p>Consider an agent with the expected utility function $U(L) = \sum_{s=1}^{S}\pi_s U(Y_s)$ over the lottery $L = (Y_s, \pi_s)$ where $\pi_s$ is the probability of state $s$, $Y_s$ are state $s$ payoffs, and $U(y_s) = -\frac{1}{2}(\alpha - Y_s)^2$ for $Y_s &lt; \alpha$ is the utility index
  over payoffs. Show that this agent's expected utility depends upon only
  the mean and variance of the state-contingent payoffs.</p>
</blockquote>

<p>I do not really understand what the question is asking of me to show. Any suggestions or comments are greatly appreciated. Specifically, is the question asking me to find $$E[U(s_s)]$$ and $$Var[U(Y_s)]$$ if so how do we do that when we don't really have any defined distribution for $Y_s$? Also what does even mean that the mean the agent's expected utility depends upon only the mean and variance of the state-contingent payoffs. Does not make sense to me, I do not have much of an economics background as a graduate student in Applied Mathematics. </p>
","<p>\begin{eqnarray*} \displaystyle U(L) &amp; = &amp;\sum_{s=1}^{S}\pi_s U(Y_s) = \sum_{s=1}^{S} \left(-\frac{1}{2}\pi_s(\alpha - Y_s)^2\right) = -\frac{1}{2}\sum_{s=1}^{S} \left(\pi_s(\alpha^2 + Y_s^2-2\alpha Y_s)\right) \\ &amp;=&amp; -\frac{1}{2}\left(\alpha^2\sum_{s=1}^{S} \pi_s + \sum_{s=1}^{S} \pi_sY_s^2-2\alpha \sum_{s=1}^{S} \pi_sY_s\right) = -\frac{1}{2}\left(\alpha^2 + \mathbb{E}(L^2)-2\alpha \mathbb{E}(L)\right) \\ &amp;=&amp; -\frac{1}{2}\left(\alpha^2 + \mathbb{E}(L^2) - (\mathbb{E}(L))^2 + (\mathbb{E}(L))^2 -2\alpha \mathbb{E}(L)\right) \\ &amp;=&amp; -\frac{1}{2}\left(\alpha^2 + \mathbb{V}(L)  + (\mathbb{E}(L))^2 -2\alpha \mathbb{E}(L)\right) \end{eqnarray*}</p>

<p>So utility from the lottery only depends on expected value - $\mathbb{E}(L)$ and variance - $\mathbb{V}(L)$ of the state-contingent payoffs.</p>
","15171"
"Competitive equilibrium in Leontief economies","237","","<p>Consider an economy in which all consumers have, possibly different, <a href=""https://en.wikipedia.org/wiki/Leontief_utilities"" rel=""nofollow noreferrer"">Leontief utilities</a>. Since preferences are not strictly convex, it is not guaranteed that a competitive equilibrium exists. I found some papers that discuss the computational problem of deciding whether a Leontief economy has a competitive equilibrium, but I am interested in general existence results:</p>

<p>A. What conditions on Leontief economies guarantee that a competitive equilibrium exists?</p>

<p>B. In particular, if the initial endowments are equal (each of $m$ agents receives a fraction $1/m$ of each good), is a competitive equilibrium guaranteed to exist?</p>
","<p>Strict convexity of preferences is not needed in existence results for competitive equilibria. Leontief preferences are quite well-behaved. They are continuous, convex, and strongly monotonic.   If all endowments are strictly positive, the existence of a competitive equilibrium in an exchange economy (or a production economy satisfying standard conditions) exists by the first result of the original <a href=""https://web.stanford.edu/class/msande311/arrow-debreu.pdf"" rel=""nofollow noreferrer"">Arrow-Debreu paper</a>.</p>

<p>Arrow-Debreu actually do not just require convexity, they make, as pointed out by denesp in a comment, the convexity assumption (III.c) on utility functions that $u(x)&gt;u(x')$ and $0&lt;t&lt;1$ implies $u(tx+(1-t)x')&gt;u(x')$. Plain convexity suffices for existence, but Leontief preferences do also satisfy condition (III.c).:  Assume $\min\{\alpha_i x_i\}&gt;\min\{\alpha_i x_i'\}$. Then
$$\min\big\{\alpha_i (tx_i+(1-t)x_i')\big\}&gt;\min\big\{\alpha_i tx_i\big\}+\min\big\{\alpha_i(1-t) x_i'\big\}$$ $$=t\min\{\alpha_i x_i\}+(1-t)\min\{\alpha_i x_i'\}&gt;\min\{\alpha_i x_i'\}.$$ </p>
","19284"
"Uses of convex analysis in Economics","236","","<p>I'm taking kind of a crash-course in convex analysis to complement my mathematical skills and was wondering if anyone knew about nice ways in which this kind of tools were used in Economics.
To be more precise, some of the things I've seen so far are not strictly in the area of convex analysis but are very related, like dual spaces, weak topology, subdiferentials and Hahn-Banach theorem.</p>

<p>The only example I know of is the duality between the UMP and EMP in consumer theory (and of course the firm maximization and cost minimization problems). I also think that Hahn-Banach is used in the proof of the first welfare theorem.</p>

<p>Has anyone here used this kind of mathematical concepts in their work or has seen any interesting recent usage of them?</p>
","<p>A partial answer: convex analysis is extensively used in axiomatic decision theory, at least in its recent developments. Most of these papers focus on individual behavior. You can have a look for instance at the following papers on ambiguity-averse preferences:</p>

<ul>
<li>""Maxmin Expected Utility with Non-Unique Prior"" (Gilboa &amp; Schmeidler)</li>
<li>""Ambiguity Aversion, Robustness, and the Variational Representation of Preferences"" (Maccheroni, Marinacci &amp; Rustichini)</li>
<li>""A Smooth Model of Decision-Making under Ambiguity"" (Klibanoff, Marinacci &amp; Mukerji)</li>
<li>""Ambiguity in the Small and in the Large"" (Ghirardato and Siniscalchi)</li>
</ul>

<p>Here is a paper that applies convex analysis to a model of trade under ambiguity aversion: ""Subjective Beliefs and Ex-Ante Trade"" (Rigotti, Shannon &amp; Strzalecki).</p>

<p>Beyond models of ambiguity aversion, virtually all recent work in axiomatic decision theory makes use of convex analysis, and applies its tools to study various phenomena: regret aversion (Sarver, Ergin), cost of thinking (Ortoleva), random choice (Gul, Pesendorfer)... Please tell me if you want more precise suggestions.</p>

<p>For the mathematical part, a very good reference is <em>Convex Analysis</em> by Rockafellar (1970). It is cited by most of the papers above ;-).</p>
","5703"
"What are some theoretical explanations for deviations from the efficient market hypothesis?","236","","<p>According (the semi-strong form of) the efficient market hypothesis, the price of an asset should reflect all publicly available information about the 'fundamental value' of that asset. The reasoning is that if there is some public information that suggests the price is below the fundamental value then people will have an incentive to act on this information and buy more of the asset. This increase in demand will cause the price of the asset to rise, closing the original price-value discrepancy.</p>

<p>This reasoning seems intuitively plausible, but significant price-corrections during the recent recession seem to suggest that markets had systematically priced in a manner inconsistent with underlying fundamentals. What academic theories (i.e. published or in working papers) have been advanced (and by whom) to explain why the efficient market hypothesis might fail? Is there much of an empirical consensus on the validity of the efficient market hypothesis in the literature?</p>
","<p>There is a position that the efficient market hypothesis is essentially untestable. That's because purported tests of efficient markets are actually joint tests of two claims</p>

<ol>
<li>Market X is efficient</li>
<li>An efficient markets looks / behaves like Y</li>
</ol>

<p>A rejection of a market X as not behaving like Y could be because <b>market X is efficient</b> but it is <b>false that efficient markets behave like Y</b> or that <b>X is not an efficient market</b>. The earliest citation I know on this issue is <a href=""http://m.e-m-h.org/Jens78.pdf"" rel=""nofollow"">Jensen (1978)</a>. There are numerous reasonable examples of how this can occur. Consider violations of the Consumption-CAPM. (<a href=""http://www.nber.org/papers/w0564"" rel=""nofollow"">Grossman and Shiller (1981)</a>). A rejection of the C-CAPM can occur simply because you have failed to identify the proper stochastic discount factor or market portfolio. Or consider a superficially reasonable assumption that returns should not be predicable if markets are efficient. But if there is aggregate (non-diversifiable) risk and there are limits to the ability to move income through time (like in a Lucas-tree economy) then when aggregate output is relatively low assets will be relatively cheap even if that low output was entirely predictable. </p>

<p>I suspect these problems will perpetually impair consensus on the validity of the efficient market hypothesis. A related but unasked question is ""Is it useful to assume that markets are efficient?"" On this matter, there does seem to be a strong consensus that:</p>

<ol>
<li>Prices in big, liquid markets are often very good and hard to beat</li>
<li>For models where asset prices or financial wealth are inputs to asking other questions, assuming markets are efficient is a good starting point and often good enough.</li>
</ol>

<p>All that about untestability said, people try to test market efficiency all the time. Most of these tests fall into the family of ""market anomalies"". Essentially, someone comes up with an investment portfolio strategy that provides a arbitrage opportunity. Here arbitrage has a precise meaning that differs from common usage in finance. An arbitrage requires no cash outflow now or in the future and there is at least one state of the world in the present or future where it generates strictly positive value. The existence of such an anomaly seems plausible evidence that markets are not efficient. However, in practice, it isn't clear that the famous anomaly papers papers actually demonstrate this. What they more typically demonstrate is that fluctuations in some representative but flawed measure of the market portfolio do not explain all returns and therefore that one <b>might</b> be able to construct zero up-front cost a portfolio with no market risk exposure that nevertheless pays out in some states. But such portfolios almost always have negative outcomes as well as positive ones and so are not strictly speaking arbitrages. </p>

<p>An alternative explaination is that there are other risks that are priced besides the market. That's why the rightfully famous and careful <a href=""https://ciber.fuqua.duke.edu/~charvey/Teaching/IntesaBci_2001/FF_Common_risk.pdf"" rel=""nofollow"">Fama and French (1993)</a> is called <i>Common risk factors in the returns on stocks and bonds</i>. But when we really dig into the weeds of what sorts of ""risk factors"" generate returns, some don't mesh to any clear source of economic risk. That <a href=""http://onlinelibrary.wiley.com/doi/10.1111/jofi.12119/abstract"" rel=""nofollow"">firms with heavy recession exposures should command higher returns</a> make sense. That <a href=""http://www.jstor.org/stable/4479164"" rel=""nofollow"">firms should outperform in some months and not others</a> is much harder to understand through the lens of risk and some prefer to think of as evidence of market inefficiency.</p>

<p>As for why the efficient market hypothesis might fail, there seem to be a few key stories often combined into ""<a href=""http://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1997.tb03807.x/full"" rel=""nofollow"">the limits of arbitrage</a>"". A few examples follow. Informed traders may lack the capital to take large enough positions so that market prices can reflect their information. Markets may not exist to hedge some risks. If risk factors A and B cannot be traded separately and you have a signal on just A it may be impossible to get risk factor A priced properly. Market participants may be risk adverse and not want concentrated exposures in unusual, under-priced risks, and so not have an incentive to make markets efficient. Transaction costs of trade may prevent the profitable exploitation of information.</p>
","90"
"Problem with defining liquidity","235","","<p>I have heard multiple times that a consistent definition of liquidity does not exist. The two wikipedia articles describing liquidity (<a href=""https://en.wikipedia.org/wiki/Market_liquidity"">Market liquidity</a> and <a href=""https://en.wikipedia.org/wiki/Accounting_liquidity"">accounting liquidity</a>) lack a discussion of this apparent problem within economics. Could someone perhaps provide a reference to a discussion of the problem of defining liquidity and maybe provide a brief summary of the issue?</p>
","<h1>Etymology and Introduction</h1>

<p>As a concept to measure the interchangeability of assets and money, liquidity is a new word. It first appears in 1923 in a use by Hawtrey (The Oxford English Dictionary (1989)). The underlying idea however is much older. Menger (1892) calls a good more or less saleable according to the facility to which it can be disposed of at current purchasing prices with less or more diminution. He is talking about the origin of money, and not the disposition of financial assets, but this concept of saleability is very much like the modern concept of liquidity. This sense of saleability goes back at least as far as Jehan Palsgrave's usage in 1530 (The Oxford English Dictionary (1989)). Although the absence of liquidity is now commonly referred to as ""illiquidity"", Marschak (1938) offers ""frozen"" as an alternative that did not catch on.</p>

<p>Hicks (1962) says that the use of the word liquidity in a financial sense was popularized by Keynes and the Macmillan Report in the 1930's (Macmillan Committee of HMSO (1931)). In The General Theory, Keynes says that liquidity justifies money trading at a premium over bills or bonds and causes the existence of an interest rate. Hicks teases from Keynes' Treaty on Money (Keynes (1930)) that one calls an asset more liquid than another if it is ""more certainly realizable at short notice without loss."" </p>

<p>This quote is more ambiguous than it may seem at first glance. Hicks offers several interpretations. The first, which he flatly rejects, define liquidity as the difference between the price the owner carries on his books for an asset and the price they could sell it for on the market. The second, is an interpretation of marketability. Hicks defines a security as marketable if it is sold just as well after negotiation, search and advertising as it is without it. That is, we can compare the liquidity of two assets by the relative sacrifice one makes from a rapid sale. He claims this interpretation is ""more appealing"" but still not what Keynes meant. He understands Keynes's definition of liquidity to require perfect marketability, but even perfectly marketable assets can be more or less liquid. The difference here is in the moments of the asset's price. Among marketable financial assets, we can regard them as more or less liquid by using a utility function to manage the trade-offs between maximizing the desirable odd moments (e.g., positive mean and skew) and minimizing undesirable even moments (e.g., variance and leptokurtosis) of asset returns.</p>

<h1>Definitions of Liquidity</h1>

<p>A treatment of market liquidity is critical if we are to realistically model the behavior of markets of financial assets that are traded with transaction costs. The liquidity literature primarily follows three meanings of liquidity. The first and oldest class of measures of liquidity relate the size of loss to the amount of notice. That is, what is the fraction of the best possible price that a seller can net as a function of time allotted to conduct a loss minimizing sale? Keynes's definition is a specific example where he is interested only in short notice. For example, compare trying to sell a round lot (100 shares) of IBM stock today with doing the same with a home. The IBM shares will sell without diminution. The home will sell at an enormous discount because of product heterogeneity, heterogeneous buyers, and the skipping of time consuming risk avoidance techniques (e.g., title search and property inspection). A classic statement of this sense of liquidity comes from Hirshleifer (1968). He calls liquidity ""as asset's capability over time of being realized in the form of funds available for immediate consumption or reinvestment -- proximately in the form of money."" Admati and Pfleiderer (1988) also care about liquidity in this first sense. They see exogenous liquidity events (say a change in margin requirements) causing a ""demand for immediacy"" (a term also found in Grossman and Miller (1988)), that is, the willingness to sell rather than wait when doing so costs the seller. According to Greenbaum (1971), who called this the L1 definition of liquidity, the earliest work on this sense of liquidity was in Tobin's unpublished manuscript. Pierce (1966) elaborates this notion and explores this measure in the context of commercial bank portfolio management.</p>

<p>The second meaning understands liquidity as the expected time to sale without diminution. Returning again to the example of selling the lot of IBM stock and a home, the expected time to getting the best price on your shares of IBM is almost zero (at least during business hours and with access to a computer or phone) whereas, on average, the home would take a few months to sell optimally. Lippman and McCall (1986) explore this sense of liquidity. They take an agent as choosing a stopping rule $\tau^* \in T$ of all possible stopping rules to maximize expected net receipts (under that stopping rule) of $E [R(\tau^*)]$. They define liquidity as $E [\tau^*]$, the expected time to sale under the optimal stopping rule. Krainer and LeRoy (2002) also suggest this expected time to sale under an optimal selling rule a measure of liquidity.</p>

<p>The third definition of liquidity involves the uncertainty of an asset's value. As discussed above, Hicks (1962) sees this as the critical attribute of liquid assets. Proponents of this definition argue that it is of little importance if you can sell an asset on short notice and with small loss if the asset itself is worth little when you need it. That is reasonable as long as investors are risk averse. Tobin (1958) introduces this sense of liquidity in a framework of risk averse investors and uncertainty of future interest rates. Tobin's paper resolved the paradox (to economists) that consoles (perpetual bonds) have higher expected rates of return than cash investments. Lagos (2008) is able to explain much of the risk-free-rate and equity-premium puzzles in an economy with riskless, liquid assets and risky, illiquid ones when agents hold assets for the liquidity services.</p>

<p>Deaton (1991) equates a model's liquidity constraints with limitations on borrowing future income. In that sense, liquid assets are more effective in moving income though time. Holmstrom and Tirole (1998) also explore this meaning of liquidity as a way of storing wealth between periods in search of recommendations for efficient market making of financial assets and optimal provision of liquidity services by the government. Hovakimian, Opler, and Titman (2001) continue to explore this inter-temporal liquidity concept in economies with human capital that creditors cannot seize or make claims upon. He experiments with two an extra features, either no short selling of physical capital or limited borrowing by agents.</p>

<p>The concept of liquidity is a mixture of the attributes of liquidity discussed above. Households without liquid assets want to borrow with their illiquid assets as collateral. They cannot do so. Creditors are unwilling to lend because in the event of default, lenders will have to sell collateral with serious discount from the true value, with long waiting times for finding a good selling price, or with unfavorable co-movement (e.g., covariance or other forms of joint distribution) with other asset holdings. This idea of liquidity as having wealth when you need it is similar to the CAPM insight of weighting future returns by the marginal utility. Krainer and LeRoy (2002) argue that the CAPM holds for illiquid assets as well as liquid ones, but that observing the relevant shadow prices is difficult. However, the ambiguity of asset values in the presence of illiquidity (explored later) ensures that these shadow prices will not be unique. The general idea is that illiquidity can drive a a wedge between the discounted expected risk adjusted returns and the price for which you can sell an asset. As such, the traditional CAPM model is not entirely appropriate. An area for future investigation is expanding the CAPM to make this distinction. Holmstrom and Tirole (2001) was one attempt to so, but focused on firm decisions and not investor valuations.</p>

<h1>Can the Alternative Definitions of Liquidity be Reconciled?</h1>

<p>Here is an example of the wedge between expected returns and price that also highlights that an asset can be liquid in one sense and yet is illiquid in another. Imagine an investor with a US Treasury bond with a 14% coupon in a market where newly issued bonds have a coupon of 7%. Selling these highly appreciated bonds (which traded far above par) would require paying significant capital gains taxes, while holding them involves minimal credit risk and the interest would be state and local tax exempt.  Therefore, to sell would be expensive for the owner and therefore illiquid in sense 1. Nevertheless, these securities could surely be sold rapidly though the secondary US Treasury Bond market and there would be little benefit to waiting and therefore highly liquid in sense 2. It is certainly the case that assets that are liquid in one sense are often liquid in the others too. But as this example shows, that need not be so.</p>

<p>Therefore we cannot collapse these three definitions into a single numerical measure of liquidity capturing all the desired attributes. Even if we could, Hicks (1962) and Admati and Pfleiderer (1988) have concluded that liquidity is an ordinal property. Marschak (1938) suggests measuring the distinct properties of liquidity separately. Pierce (1966) disagrees that such an ordering is possible, at least with respect to sense 1 of liquidity. He says that ""apart from those assets that are perfectly liquid and those for which sale prior to maturity is impossible, assets cannot be uniquely ranked by degrees of liquidity."" His example is an asset A that is easy to  sell well with short searches (but no better after long ones) and an asset B that sells more poorly than A for short searches and better than A for long ones. Pierce also notes (in describing the weakness of his notion of liquidity) that ""the price per unit often depends on the number of units sold."" This allows for another example of the crossing behavior, where one asset may be more liquid at small quantities but less liquid for large ones. </p>

<p>Admati and Pfleiderer (1988) argue that liquidity of the third type actually encourages liquidity of the first type. They argue that commodities with successful futures markets have demand for immediacy because price volatility and risks of delaying sales are large (illiquid in sense 3). Such markets also help spread the fixed costs of market making (waiting around for buyers and sellers to want to trade, as well as infrastructure) across a large number of market participants.  In contrast, home sellers are less concerned
with short-term price volatility and instead prefer an extended search for potential buyers.</p>

<h1>Alternative Definitions</h1>

<p>Krainer and LeRoy (2002) argue that liquidity is a feature of markets and not of assets. They offer as a first example that a Ford automotive factory is illiquid but Ford stock is liquid. A second example is a pool of mortgages which is more illiquid than than the underlying mortgages. However, perhaps it suffices to refer to an asset's liquidity as its liquidity in the most liquid market an agent can trade it in. Tobin calls reversibility ""the value of the asset to its holder expressed as a percentage of is contemporaneous cost to the buyer"" (Tobin and Golub (1998)). Hahn (1990) sees asset liquidity as being closely related ""to the cost reversing a decision taken earlier."" His example is that for economic agents, the cost of selling an asset in period 2 will factor into the decision to invest in it in period 1. This meaning of reversibility is a mixture of sense 1 and sense 2 of liquidity. If waiting for suitable trading opportunities is the expensive part of reversing a trade then reversibility is primarily the second sense of liquidity. However, if transaction costs are the expensive part of reversal then the first sense of liquidity will be the relevant one. Marschak (1938) develops a concept of plasticity that is essentially this concept of reversibility. He considers plasticity as a
more general concept than saleability that includes flexibility. Greenbaum (1971) is an early reference that notes the interrelatedness of reversibility and liquidity.</p>

<p>Jones and Ostroy (1984) see an essential attribute of liquidity in the related measure of flexibility. Financial investments that leave agents with a larger set of intermediate and final choices are more flexible. Lippman and McCall (1986) are similarly interested in liquidity as flexibility. They show in a simple search model that if the investor opportunity set changes over time, even risk neutral investors will demand a more
liquid asset because it improves the expected returns of their portfolio. Hahn (1990) also sees liquidity as tied to the ""speed of response to new information,"" but it is hard to see if this is a cause of liquidity or caused by it. Intuition suggests the former. Few market participants, high transaction costs and other direct causes of illiquid markets all make it more difficult to trade on new information. Further, the trees model
of Lucas (1978) shows that prices can move even in the absence of trade. Frequent trade is not synonymous with liquidity. </p>

<p>The frequency of order arrival is a determining factor of liquidity in markets with market makers. This implies that markets need not be liquid to have fast adjusting prices. Flexibility can be about more than investment opportunities. If agents are borrowing constrained and goods can be purchased only with liquid assets, then agents must hold some liquid assets to purchase goods for immediate consumption, even though doing so does not maximize their portfolio return. If consumption opportunities vary over time then agents will hold relatively more ready assets to take advantage of fleeting consumption opportunities. If agents were not so constrained, then they could simply borrow against their illiquid assets (repaying debts as the returns arrived or when prudent sale was possible) to consume as they like. This is also true for investment flexibility. If investors could borrow against their illiquid assets then they would not need liquid holdings to take advantage of future investment opportunities. The necessity of holding liquid assets for consumption purposes is one motivation for the money-in-the-
utility function (MIU) literature. The MIU framework puts money, an asset without consumption value nor any investment return, into the utility function as a reduced form representation of all the ways that money (as the most liquid asset) makes consumption easier and more efficient. </p>
","1581"
"Representing these lexicographic preferences by non-continuous utility function?","235","","<p>I have the following preferences and I am wondering whether I could represent them by a utility function:</p>

<p>$R_1 \succ R_2$ &lt;-> $R_1\leq Q$ and $R_2 &gt; Q$,</p>

<p>$R_1 \succ R_2$ &lt;-> $R_1 \leq Q$ and $R_2 \leq Q$ and $R_1&gt;R_2$,</p>

<p>$R_1 \sim R_2$ &lt;->  $R_1 &gt; Q$ and $R_2 &gt; Q$</p>

<p>R is positive and real-valued, Q is kind of the ""threshold"" of R for the first criterion (below Q everything prefered to above Q). These are lexicographic preferences, right?</p>

<p>Can't I represent these preferences by the utility function:</p>

<p>$U(R)=a+bR$ for $R\leq Q$ and positive a,b </p>

<p>$U(R)=0$ otherwise ?</p>

<p>Because now </p>

<p>$U(R_1)&gt;U(R_2)$ &lt;-> $R_1 \succ R_2$ </p>

<p>$U(R_1)=U(R_2)$ &lt;-> $R_1 \sim R_2$</p>

<p>So, is it finally possible to represent lexicographic preferences by anon-continuous utility function?</p>

<p>Thanks a lot for help!</p>

<p>Felix</p>
","<p>As @HRSE pointed out, your terminology is a bit misleading, and these preferences are not exactly what we refer to when we use the word 'lexicographic'. You might be tempted to consider every $R&gt;0$ as a two-dimensional vector $R=(\mathbb{1}_{R \leq Q},R)$ and to apply the lexicographic order on these vectors, but I would say it is a bit unnatural since the two dimensions of the vector are not independent (you cannot vary the second freely without affecting the first).</p>

<p>That said, the usual observation that lexicographic preferences can be represented by a utility function (but not by a continuous utility function) applies to your case as well. The common feature of both situations is that preferences satisfy standard rationality requirements (weak order) but are discontinuous. You can refer to this question for a formal discussion of these issues:</p>

<p><a href=""https://economics.stackexchange.com/questions/6889/lexicographic-preference-relation-cannot-be-represented-by-a-utility-function"">Lexicographic preference relation cannot be represented by a utility function</a></p>
","10630"
"What are the recent advancements in building a unified theory of bounded rationality?","235","","<p>It seems that bounded rationality models focus on explaining a particular psychological bias, in a very specific way. In particular, its seems that the state of the art consensus is that one size does not fit all. The prevalence of framing effects makes this issue very difficult, but is there any way to think of a general approach to modelling bounded rationality.
Is it regret minimization, or random choice, or rational inattention?</p>
","<p>The term bounded rationality was introduced by <a href=""http://en.wikipedia.org/wiki/Herbert_A._Simon"" rel=""nofollow"">Herbert Simon</a>. He wrote</p>

<blockquote>
  <p>""The term, bounded rationality, is used to designate rational choice
  that takes into account the cognitive limitations of both knowledge
  and cognitive capacity. Bounded rationality is a central theme in
  behavioral economics. It is concerned with the ways in which the
  actual decision-making process influences decisions.""</p>
</blockquote>

<p>This passage seems to focus only on incomplete information, limited information processing time, limited knowledge -and not on any ""psychological biases"" like framing effects and the like. But the passage is complemented by a last phrase</p>

<blockquote>
  <p>""Theories of bounded rationality relax one or more assumptions of
  standard expected utility theory""</p>
</blockquote>

<p>which suddenly opens the content of the term to anything. So ""bounded rationality"" has come to signify ""deviations from strict rationality in <em>any way</em>"", making it rather impossible to arrive at a general, all-encompassing, or even most-encompassing, modeling approach, that at the same time, will be specific enough so as to be operational.</p>
","147"
"Contract curve for firms with linear utility functions","234","","<p>I am attempting to find a contract curve for a production economy with two linear utility functions. </p>

<p>Normally, I would find the point where the Marginal Rate of Technical Substitution were equal for the two firms. However, in this case, this does not seem to work (I end up getting an equation of two numbers).</p>

<p>How must I proceed?</p>

<p>Is it all places where both functions are equal?</p>
","<p>1.) An economy with two agents who both have linear preferences will always have Pareto optimal points along either the right and bottom edges or the left and top edges of the Edgeworth box. Edges are dictated by the ratio of MRSa,MRSb.</p>

<p>2.) The contract curve is the locus of Pareto Optimal points. </p>
","11795"
"How to justify an instrumental variable?","234","","<p>I am hoping for some tips on what I could do for a term paper in applied econometrics. We are running a 2sls where I want to use a firm's location as an IV. How can I go about justifying it is a valid instrument? More specifically, how would you suggest I can argue the exclusion restriction holds for my instrument. I am thinking of a verbal argument of about a page tops, since I have limited space left. Any suggestions would be greatly appreciated. Thank you. </p>

<p>PS: My endogenous variable is a dummy for whether the business owner is a member of a political party, and my outcome variable is a leverage ra</p>
","<p>The general approach </p>

<blockquote>
  <p>""there are many things that are in the error term which may correlate
  with the covariate of interest but don't even come to mind"",</p>
</blockquote>

<p>is a total dead-end, <em>because exactly the same thing could be argued for any instrument you might choose</em>.  It would be my suggestion to not use such vague and general arguments in your paper.</p>

<p>On the other hand, the endogeneity issue is <em>not</em> about whether the suspect regressor is correlated with some other variable. Each and everyone variable in the world can be said to be corrleated with at least one other variable. <em>The issue is whether this other variable is also correlated with the dependent variable</em>.</p>

<p>To consider the example offered in a comment by the OP, ""past work for the government"" may be correlated with ""party membership"" indeed. But is ""past work for the government"" correlated with the OP's dependent variable? Namely, does it really live inside the error term of the regression?</p>

<p>Selection of instruments is one of the few instances in econometric work where the verbal argument dominates. As the answer by @ColeTrumbo excellently put it, </p>

<blockquote>
  <p><em>""To motivate a good IV, you need a good story.</em>""</p>
</blockquote>
","10932"
"Bayes-Nash equilibrium and correctness of beliefs","233","","<p>Define a Bayesian game as follows: $$G = \left\langle I, \left(A_i,T_i,(p_{t_i})_{t_i \in T_i}, u_i \right)_{i \in I} \right\rangle$$</p>

<ul>
<li>$I$ is the set of players </li>
<li>$A_i$ is the action set for player $i$, </li>
<li>$T_i$ is the set of possible types for player $i$, </li>
<li>$p_{t_i} \in \Delta(T_{-i})$ is player $i$'s beliefs regarding the types of the other players. $(T_{-i}=\times_{j \ne i}T_j)$</li>
<li>$u_i : A \times T \rightarrow \mathbb{R}$ is player $i$'s utility function</li>
</ul>

<p>Then a Bayes-Nash equilibrium is defined as follows:</p>

<blockquote>
  <p>A (pure) Bayes-Nash equilibrium is a profile of choice functions (or
  strategies) $(\sigma_i:T_i \rightarrow A_i)_{i \in I}$ such that,
  $\forall i \in I, \forall t_i \in T_i, \forall a_i \in A_i$,</p>
  
  <p>$$\sum_{t_-{i}}p_{t_i}(t_{-i}) \cdot u_i(\sigma_i(t_i),
  \sigma_{-i}(t_{-i}); t_i, t_{-i}) \geq \sum_{t_-{i}}p_{t_i}(t_{-i})
  \cdot u_i(a_i, \sigma_{-i}(t_{-i}); t_i, t_{-i})  $$
  where, for every $t_{-i}, \sigma_{-i}(t_{-i}) = (\sigma_j(t_j))_{j\ne i}$.</p>
</blockquote>

<p><strong>And now my question:</strong> Am I correct that this implies that, in a BNE, every player (or rather, every type of every player) best responds given their beliefs about the types of other players, but that there is nothing in a BNE that pins down the beliefs a player (or type of player) has on the types of other players? That is to say, in a BNE, a player (or type of player) could have a degenerate belief (putting full probability on some $t_j^*$ for player $j$) in an equilibrium in which $t_j \ne t_j^*$? Put more simply, can a type of player's beliefs about the type of another player be wrong in a BNE?</p>
","<p>I think your definition is incorrect, or at least incomplete.** Usually, in a Bayesian game, there is assumed to be a prior distribution on $T$ (where $T = \times_i T_i$). This distribution is called the ""common prior"" and it is assumed to be common knowledge that types are drawn according to this distribution. In this case, each player $i$'s belief $p_i$ is given by Bayesian updating on $T_i$ and this prior; and in BNE player $i$ must be best-responding to this belief.</p>

<p>The assumption of a common prior and Bayesian update rule (which is what gives this solution concept its name, after all) mean that players <em>cannot be wrong, merely underinformed</em>. In other words, a player with posterior belief $p_i$ is correct about the distribution of types of other players conditioned on her own, even though she does not know which realizations they have.</p>

<p>** <strong>Edit</strong>. Osborne and Rubenstein's text mentions that it is possible to define a more general game in which each player has a different prior distribution (there is no common prior). So your definition does match their most general definition. I suppose that in such a case two players may hold incompatible views, hence you could say that someone must be incorrect. That all being said, the vast majority of Bayesian games assume a common prior.</p>
","9799"
"Intertemporal consumption question","233","","<p>This question is driving me nuts. </p>

<p>Suppose, an individual lives for two periods. In each period she consumes only one good,which is rice. In period 2, she can costlessly produce 1 unit of rice, but inperiod 1 she produces nothing. However, in period 1 she can borrow rice at
an interest rate $r$ > 0. That is, if she borrows $z$ units of rice in period 1,
then in Period 2, she must return $z(1 + r)$ units of rice. Let $x_1$ and $x_2$ denote her consumption of rice in period 1 and period 2, respectively; $x_1$, $x_2$ ≥ 0. Her utility function is given by $$U(x_1, x_2) = x_1 + βx_2$$, where β is the discount factor, 0 &lt; β &lt; 1. Note that there are only two sources through which rice can be available; own production and borrowing.</p>

<p>Now suppose that there are N agents in the above two period
economy. The agents are identical (in terms of production and utility
function) except that they have different discount factors. Suppose that
β follows uniform distribution in the interval [ 1/2, 1]. Assuming r ≤ 1, what would be the demand function for rice in period 1?</p>

<p>My approach is integrating $\beta$ from 1/2 to $\frac{1}{1+r}$, and my answer comes out to be $\frac {N(1-r)} {1+r}$, but I dont think that's right. </p>
","<p>Due to the linearity of the utility function the utility maximization problem for individual $i$ has either one of the two corner solutions, or it is indeterminate.  </p>

<p>The individual $i$ has to solve the following problem</p>

<p>$$\max_{x_{1i},x_{2i}}[ x_{1i} + \beta_i x_{2i}]$$</p>

<p>$$s.t. x_{2i} = 1-(1+r)x_{1i}, \;\;x_{1i} \geq 0,\;\;x_{2i} \geq 0 $$
Solvency is also imposed -i.e. the individual cannot borrow in the first period more than what he can repay in the second period (including interest).</p>

<p>One can deduce that</p>

<p>$$\text {""flatter"" budget constraint:}\;\; -(1+r) &gt; -\beta_i^{-1}   \implies \{x_{1i}^* = (1+r)^{-1},\;\;x_{2i}^* = 0\} $$</p>

<p>$$\text {""steeper"" budget constraint:}\;\; -(1+r) &lt; -\beta_i^{-1}  \implies  \{x_{1i}^* = 0,\;\;x_{2i}^* = 1\}$$</p>

<p>..""steeper"" and ""flatter"" with respect to the utility (linear) indiference map, and with $x_{2i}$ in the vertical axis.</p>

<p><img src=""https://i.stack.imgur.com/uBRC0.png"" alt=""enter image description here""></p>

<p>Working the implied inequalities we re-write the solution as</p>

<p>$$\beta_i &lt; \frac 1{1+r} \implies \{x_{1i}^* = (1+r)^{-1},\;\;x_{2i}^* = 0\}$$</p>

<p>$$\beta_i &gt; \frac 1{1+r} \implies \{x_{1i}^* = 0,\;\;x_{2i}^* = 1\}$$</p>

<p>In the $N$-identical individuals case, and with $\beta_i, i=1,...,N$ being a random variable we can only talk about expected demand in the first period, denote it $E(d_{1i})$ for the individual and $E(D_1) = N\cdot E(d_{1i})$ on aggregate.</p>

<p>We have</p>

<p>$$E(d_{1i}) = \frac 1{1+r} \cdot \Pr\left[\beta_i &lt; \frac 1{1+r}\right] + 0 \cdot \Pr\left[\beta_i &gt; \frac 1{1+r}\right] $$</p>

<p>The second term vanishes.</p>

<p>Given the assumptions on the distribution of the $\beta$'s its density function over the domain is $f(\beta_i) =2$ and so the remaining probability is (as long as $r \leq 1$)</p>

<p>$$\Pr\left[\beta_i \leq \frac 1{1+r}\right] = \int_{1/2}^{(1+r)^{-1}}2{\rm d}\beta_i = 2\left(\frac 1{1+r}-\frac 12\right) = \frac {1-r}{1+r}$$</p>

<p>and so we have</p>

<p>$$E(D_1) = \frac N{1+r}\cdot \frac {1-r}{1+r} = \frac {1-r}{(1+r)^2}N$$</p>

<p>which is decreasing in $r$.</p>

<p>If $r$ hits unity, <em>expected</em> demand will be zero -because<br>
<strong>a)</strong> It would place a solvency ceiling to loan demand to be not higher than $1/2$ so that with interest rate $100\%$ all production of the second period would then be needed to repay the loans. This means that with $r=1$, maximum consumption (and utility) in the first period will not exceed $1/2$.<br>
<strong>b)</strong> the discount factor being greater or equal than $1/2$, implies that by taking zero loan in the first period, one would enjoy the full unitary production of the second period, with utility higher than $1/2$. So for non-zero demand for loans in the first period, it <em>must</em> be the case that this demand can exceed $1/2$. When $r\geq 1$ it cannot, hence the zero expected demand. </p>

<p><strong>Note:</strong> if instead of a ""stochastic distribution"" of the $\beta$'s we think of a ""uniform allocation"" of them in the $[1/2,1]$ interval, then we can think of expected demand as deterministic demand.</p>
","5946"
"Examples of a good student's project with minimal economical knowlege","232","","<p>I have to provide a theme for students for a project like a bachelor's thesis. Students know all the basic math like calculus, linear algebra, ODE etc, but nothing fancy like PDE and stochastic calculus. Plus they supposed to have some very basic courses in economy. What could the possible themes be? </p>

<p>From one hand it should be something  really of a serious project, so a student can make by himself one thing then another and so on, and from the other hand it probably should not require lots of purely economic concepts (preferably only  basic ones). </p>

<p>Could it be  (given the absence of deep economical training) something in mathematical modelling or analysis of some economical processes? I want to catch the gist of it, so the more examples the better. Please, if possible, not only a theme's name but a few words what a student is expected to do. Sorry if it's too broad a description, but I have a very vague idea that a good project of this sort would constitute.</p>
","<p>This question is quite broad, but I'll give 3 ideas I would have liked to do, and is of appropriate difficulty, while in undergrad.</p>

<ol>
<li>Review a seminal paper - <a href=""https://en.wikipedia.org/wiki/List_of_important_publications_in_economics"" rel=""nofollow"">Wikipedia has a list of important publications in economics</a>.  They could write a 10-20 page paper and give a deep analysis of what the authors did and why.  I.e. if there is a derivation they could explain why it is solved that way, if it is the only way, or if there is another way and suggest these alternatives.</li>
<li>Construct a new policy function - Let them argue their intuition in constructing a new policy function (e.g. why do you take log consumption?) and solve for the constrained optimization problem.  They should know how to use the method of Lagrangian optimization, but the courageous student could set theirs up as a Bellman equation.</li>
<li>At my school it was perfectly acceptable for a Bachelor's thesis to do a real world project instead of write a paper.  They could make some kind of event, I had a classmate present on the UN Millennium Development Goals and had a video message from Jeffrey Sachs.  They could find somebody (or a few people) local to come and speak.  Also they may have access to a small budget from their school, or can elicit donations from local restaurants, and can provide food (college students love free food)!</li>
</ol>
","13698"
"Under what conditions does market failure occur?","231","","<p>Edit: Is it possible to broadly categorize the ways in which market failures occur into relatively few categories? If so, what are they?</p>
","<p>Any situation where markets fail to clear leads to market failure. Some common reasons for this are:</p>

<ul>
<li><p>Externalities, or agents not being responsible for costs or benefits of their actions</p></li>
<li><p>Information assymetry, or agents operating with different information</p></li>
<li>Irrationality, or agents doing random things for no reason</li>
<li>Principal agent problems, where someone entrusted with others funds uses them wastefully</li>
<li>Productive inefficiency, or firms failing to produce goods effectively given the allocated capital (think using Gatorade to water plants)</li>
<li>Allocative inefficiency, where firms are not provided the appropriate capital</li>
<li>Economies of scale, or the problem of capitalist firms failing to grow large enough to establish a service</li>
<li>Destructive competition- eg, private militaries blowing each other up</li>
<li>Shortsighted management of natural resources </li>
<li>Monopoly</li>
<li>Moral hazard, adverse selection, and other problems in contract theory </li>
</ul>
","10874"
"Negative Externality with Tax and Free TRade","229","","<p>I am unsure of how to think about this negative externality question when there is both tax and free trade. </p>

<p>A country is producing plastic, but it has a negative externality cost of 4 dollars/bottle. The demand is $Q_D=12-P$ and the supply is $Q_S=P$. If a 4 dollars/bottle tax is enacted and the country is opened up to free trade with a world price of 4 dollars, what would the total social surplus be? Based on my calculations, it would be 24 dollars, just the same as when the country has no tax and is open to free trade. Is this correct thinking? Or am I not thinking about the tax and free trade correctly? Thanks.</p>
","<p>Rearranging your demand and supply equations gives us:
$$P=Q_s\quad and\quad P=12-Q_D$$</p>

<p>Adding the tax on the supply side gives us:
$$P=Q_s+4$$</p>

<p>Solving for equilibrium, we get $P=8$ and $Q=4$</p>

<p>However, we did not necessarily need to solve for this equilibrium because the Supply curve shifted left, and the new intercept is at $P=4$. This implies that no plastic will be produced domestically because the world price will be lower at any positive level of production. </p>

<p>To solve for total surplus, we need only solve for consumer surplus because no production will occur domestically. We need to solve for $Q_D$ when $P=4$.
$$4=12-Q_D\implies Q_D=8$$
$$\implies TS=CS=\bigg(\frac{1}{2}\bigg)*8*8=32$$</p>

<p>Is this the same as when there is no trade and no tax?</p>

<p>$$P=Q_s\qquad P=12-Q_D$$</p>

<p>Equilibrium yields $P=Q=6$
$$TS=CS+PS-DWL$$
$$TS=CS=\bigg(\frac{1}{2}\bigg)*6*6$$</p>

<p>To calculate $DWL$, we split the cost into private cost and social cost. When we do this
$$PC=Q\qquad SC=Q+4$$</p>

<p>The values we need to calculate the $DWL$ triangle end up being $Q=4$, $P_{PC}=4$ and $P_{SC}=8$</p>

<p>$$DWL=\bigg(\frac{1}{2}\bigg)*4*4=8$$</p>

<p>$$\implies TS=18+18-8=32$$</p>

<p>Your intuition was correct that the total surplus is the same in both cases.</p>
","11063"
"Number of observations in different panel data regressions","228","","<p>Given a balanced two-period panel data, with lets say 1000 observations on 500 individuals.</p>

<p>When you estimate a pooled OLS regression and first-differences regression is there a standard in the economics literature on how you should report number of observations. </p>

<p>It seems most natural for me to report 500 observations in the case of first-differences.</p>

<p>This might seem trivial. But better follow any standard if it exists.</p>
","<p>It is reasonable to show both observations and number of units of analysis. For instance, take <a href=""http://economics.mit.edu/files/5677"" rel=""nofollow noreferrer"">this example</a> of an article in the American Economic Review:</p>

<p><a href=""https://i.stack.imgur.com/6aAAI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6aAAI.png"" alt=""enter image description here""></a></p>

<p>There is the row <strong>Observations</strong>, and the row <strong>Countries</strong>. The latter is the unit of analysis. As the data is a longitudinal panel, there are multiple observations per country. As the panel is unbalanced, the number of observations is generally not a multiple of the number of countries (e.g. for Pooled OLS (column 1), $945/150=6.3$).</p>
","15764"
"Price dispersion in online retail","228","","<p>There are a number of online booksellers that are popular in India right now. The prices they charge for the same book often differ by as much as 10% (See this price comparison site to check <a href=""http://www.indiabookstore.net/"">http://www.indiabookstore.net/</a>)</p>

<p>Since these are homogenous goods and anyone who can access one of the stores can as easily assess another I wonder how we might explain this price dispersion. I have not done a systematic study but it is my impression that it is not the case that there is an ordering of prices between stores which is the same for different books.</p>

<p>I was wondering whether there are any economic models which can explain this dispersion. In particular are there models which can be tested by using panels of price data. </p>

<p>[I confess I am fishing for a research topic.]</p>
","<p>Yes, this has actually been quite an active area for research within the consumer search literature. As a starting point, I would recommend looking at the following:</p>

<ul>
<li><p><strong><a href=""https://www.aeaweb.org/articles.php?doi=10.1257/aer.91.3.454"">BAYE, M. R., AND J. MORGAN (2001): “Information Gatekeepers on the Internet and the Competitiveness of Homogeneous Product Markets”, <em>American Economic Review</em>, 91(2), 454–474.</a></strong> These authors have a model that is interesting because it explains the persistence of price dispersion, even in environments like price comparison sites where one would ordinarily think that all consumers will buy from the lowest-priced merchant. The intuition is closely related to that of <a href=""http://people.ischool.berkeley.edu/~hal/Papers/model-of-sales.pdf"">Varian's classic model of sales</a>, if you know that. The idea is that some firms price low to sell to the consumers on the price comparison site, whilst others price high to sell to less-informed consumers who do not use the price comparison site and therefore do not compare as many prices.</p></li>
<li><p><strong><a href=""http://www.bus.indiana.edu/riharbau/repec/iuk/wpaper/bepp2004-03-baye-morgan-scholten.pdf"">BAYE, M. R., J. MORGAN AND P. SCHOLTEN (2004): “Price Dispersion in the Small and in the Large: Evidence From an Internet Price Comparison Site”, <em>Journal of Industrial Economics</em>, 52(4), 463–496.</a> (older working paper link).</strong> This is interesting because they test various models (including the one mentioned above) against data from a price comparison site.</p></li>
<li><p><strong><a href=""https://www.aeaweb.org/articles.php?doi=10.1257/aer.102.6.2955"">De Los Santos, B., A. Hortaçsu, and M. R. Wildenbeest (2012): ""Testing Models of Consumer Search Using Data on Web Browsing and Purchasing Behavior."" <em>American Economic Review</em>, 102(6), 2955-80.</a></strong> Not directly related to the question, but an interesting take on a similar issue. There are two classic models of consumer search: sequential and fixed-sample. In sequential search, consumers visit a merchant, evaluate its offer and decide whether to search again; repeating his process until they find an offer they are willing to accept. In fixed-sample search consumers first decide the number $n$ of merchants they will visit; they then visit precisely $n$ merchants and buy the best offer among them. Given dispersed prices, sequential search is optimal and the fixed-sample strategy is not. These authors test the two models against data from online retailers and find evidence to suggest that consumers use a strategy closer to the fixed-sample end of the spectrum.</p></li>
</ul>

<p>A couple of extra references to finish up:</p>

<ul>
<li><strong><a href=""http://faculty.haas.berkeley.edu/rjmorgan/Information%20Search%20and%20Price%20Dispersion.pdf"">BAYE, M. R., J. MORGAN AND P. SCHOLTEN (2006): “Information, Search, and Price Dispersion”, in T. HENDERSHOTT (ed.) <em>Handbook of Economics and Information Systems</em>, Elsevier Science, 323–371</a></strong> A nice survey of theories of search and price dispersion that can give you an idea of what work has been done on these general phenomena (and possibly some ideas of what can be empirically tested?).</li>
<li><strong><a href=""http://economics.mit.edu/files/7205"">ELLISON, G., AND S. F. ELLISON (2009): “Search, Obfuscation, and Price Elasticities on the Internet”, <em>Econometrica</em>, 77(2), 427–452</a></strong> A study of how firms can obfuscate the search process to maintain market power in a frictionless context like a price comparison site. Ellison and Wolitzky also have a nice theoretical paper on this phenomenon in the <em>RAND Journal of Economics</em>.</li>
</ul>
","255"
"Question on real exchange rate","227","","<p>If the Phillipine peso falls in value against the USD by 5% in a year, but the domestic inflation rate in the Phillipines is 10%, compared to 2% in the USA, the nominal exchange rate has fallen (by 5%), but the real exchange rate has risen by 3%.</p>

<p>Could anyone help me explain why ""the real exchange rate has risen by 3%.""?</p>
","<p>Note that I am not 100% sure. But in my understanding, we have </p>

<p><strong>Year 1</strong></p>

<ul>
<li>Price for a product in the US :  $p_{US}=v$ \$</li>
<li>Exchange rate: $x$ pesos for $1$\$</li>
<li>Price of the product in the Philipines: $p_{Ph})=v.x$ pesos</li>
</ul>

<p><strong>Year 2</strong></p>

<ul>
<li>Price for the same product in the US : $p^\prime_{US} = (1+\alpha_v)v$ \$. The price increased due to the inflation $\alpha_v$.</li>
<li>Nominal exchange rate: $(1+\alpha_x)x$ pesos for $1$\$. A drop in value means you need more pesos for one USD.</li>
<li>Inflation in the Philipines: $p^\prime_{Ph} = \frac{P_{Ph}}{1+\alpha_p}$. Due to the inflation, the acquisitive power of the pesos is reduced.</li>
<li>Price of that product : $p^\prime_{Ph}=[(1+\alpha_v)v].[(1+\alpha_x)x].[\frac{1}{1+\alpha_p}] = \frac{(1+\alpha_v).(1+\alpha_x)}{1+\alpha_p}.v.x$</li>
</ul>

<p><strong>Variation</strong></p>

<ul>
<li>The effective variation compared to the previous year is thus, $\frac{(1+\alpha_v).(1+\alpha_x)}{1+\alpha_p}$, which corresponds to a <em>rise</em> in effective exchange rate of </li>
</ul>

<p>$$\frac{1+\alpha_p}{(1+\alpha_v).(1+\alpha_x)}-1=2.7\%$$</p>
","6724"
"What does Battigalli really mean by ""Players can not choose strategies, they can only choose actions.""?","227","","<p>In this <a href=""https://www.youtube.com/watch?v=0CDGhY2Ock8"" rel=""nofollow"">video</a> (from 7: 30 to 9: 00)on Youtube, Battigalli mentions the state of world for a simple three-legged centipede game, which, in his own word, is </p>

<blockquote>
  <p>""$\ldots$a description of everything matters, which in traditional theory, must include strategies that characterize Ann and Bob. I don't use the word 'Ann chooses a strategy'. The reason is very simple. The object of choice is action, not stategy. Players can not choose strategies, they can only choose actions. If Ann can choose strategies $(C, C^\prime)$, they are playing a different game.""</p>
</blockquote>

<p>What does Pierpaolo Battigalli really mean? If the actions for a player chooses has been specified, then it automatically specify a pure strategy. By this methodology, he seems to want to distinguish a game structure with commitment and a game without, but how?</p>

<p><strong>Added:</strong> <a href=""http://crm.sns.it/media/course/3659/battigalli.pdf"" rel=""nofollow"">Here</a> is the slides used in the video, and <a href=""ftp://ftp.igier.unibocconi.it/wp/2011/375.pdf"" rel=""nofollow"">here</a> is the corresponding paper.</p>
","<p>The idea is precisely that players do not chose action<strong>s</strong>, but only chose one action at the time at every node at which they play, based on their beliefs about the way other players <strong>and themselves</strong> will play at future nodes in the game (where beliefs are conditional on the history that led to that node).</p>

<p>The interpretation is letting players choose full-fetched strategies is equivalent to letting players rely on a computer program to plays the game in their place. That is, they can commit via this computer program to playing a given action at each node.</p>

<p>Such games with commitment devices are in essence very different from games in which the actual players have to repeatedly chose an action at each of their decision nodes. When actual players play at nodes, players have to form beliefs about the way other players and themselves will play at future nodes, <strong>and these beliefs may depend on the history that led to future nodes</strong>. </p>

<p>For instance, in a Stackelberg game, the leader could believe that the follower will be rational (i.e., utility maximizing) if the leader plays ""Low production"", but will be irrational (i.e., non utility maximizing) if the leader plays ""High production"". Maybe the leader anticipates that the follower will be angry if the leader plays ""High production"", and that, blinded by her anger, the follower then then want to retaliate. </p>

<p>If the follower could have committed through a strategy, the game would have been completely different. Maybe the follower could have committed not to retaliate before she gets angry, and she cannot help her desire to retaliate anymore. But here the idea is that the <em>actual</em> follower has to choose an action later in the game given what the leader chose at the root node. Therefore, the behavioral rule through which the follower chooses an action at a node (e.g., utility max vs. non utility max), and the beliefs of the leader about these procedures may depend on the history that led to that node too. </p>

<p>This opens the way for many new outcomes of the game that would not have emerged from classical game theory. From a conceptual point of view, it also switches the focus from solution concepts to epistemic and behavioral assumption (i.e., from classical game theory to epistemic game theory). Instead of identifying a set of reasonable outcomes (e.g., Nash equilibrium outcomes) and look at the strategies that match these outcomes, one identifies reasonable properties of players' behaviors and beliefs (about each others' beliefs and behaviors), and derives the conclusions of these epistemic and behavioral assumptions for the outcome <strong>as the game unfolds</strong>.</p>

<p>Now, this is just to give some meat and intuition to Battigalli's framework, and it is does not do justice to the richness of the framework (in part because I don't know much about his work other that the video you linked to). If you haven't done it yet, I strongly recommend that you watch the whole video. I think Battigalli does a great job at making his framework accessible. He also present helpful and intuitive examples to connect his epistemic approach to ""classical"" game theory by identifying simple conditions on players beliefs and behaviors that allow to recover classical solutions to games such as backward induction.</p>
","5510"
"Price elasticity when relationship between sales, price and other factors is not linear","226","","<p>For commercial deployment, price elasticity is calculated through linear regression which assumes that there is a linear relationship between price and sales. I have a)price and b)social media ratings for my product. I know that social media ratings influence consumer decision to purchase or not purchase something. As per assumption of linear regression if social media rating is low we need to reduce price to improve sales. However, beyond a point price cuts will not help in increasing sales. This is a violation of linearity.</p>

<p>So my question is what if </p>

<p>1) Relationship is not linear even after log transformation of the data?</p>

<p>2) How can i know about the point at which i need to stop from cutting price further.</p>

<p>To give a background, i have already read this <a href=""https://economics.stackexchange.com/questions/17/econometrics-is-elasticity-meaningful-in-my-or-any-regression?rq=1"">Econometrics: Is elasticity meaningful in my, or any, regression?</a> However, it didn't seem to answer my second question, which is will my sales continue to increase if i keep dropping price although i have a low social media rating?</p>

<p>My background: I am a statistician and my economics knowledge is all i read in college. I am working a revenue optimization problem</p>
","<p>There is a confusion between a ""linear relationship between two variables"" and an ""econometric equation that is linear in the unknown parameters to be estimated"".</p>

<p>The first has to do with what happens in reality, and it implies that the marginal relation is constant. The second may be obtained even if the actual relation is not linear, but non-linear <em>in specific ways</em> that permit to obtain it by a suitable transformation of the data. </p>

<p>To illustrate this, for the OP's case, the actual (deterministic part of the) relation may be</p>

<p>$$X_d = AR^aP^{-b} \tag{1}$$</p>

<p>Demand $X_d$ for the product is a positive non-linear function of social ratings $R$ and a negative non-linear function of its own price $P$. The marginal effect of price for this relation is not-constant</p>

<p>$$ \frac {\partial X_d}{\partial P} = -\frac{b}{P}X_d &lt;0$$</p>

<p>By assuming $(1)$ we have already made a series of assumptions about the interplay of the variables involved. This specification permits us to obtain ""an econometric equation that is linear in the unknown parameters to be estimated"" since by taking logs we have</p>

<p>$$\ln X_d =\ln A +a\ln R +(-b)\ln P \tag{2}$$</p>

<p>So while the marginal effect of price on demand is not linear and not constant, the <em>elasticity</em> of demand with respect to price is constant, and equal to $-b$ (the sign indicating direction of influence).</p>

<p>But is $(1)$ an adequate way to represent the actual relation? </p>

<p>So the proper way to proceed here is to  </p>

<p><strong>1)</strong> To the best of our knowledge, using evidence and logical arguments, we determine the qualitative interrelations between the variables involved: is the effect positive/negative? Is the relation of their levels linear/non-linear? Is it monotonic or, say ""inverted-U"", etc.</p>

<p><strong>2)</strong> We construct a mathematical form that reflects qualitatively the conclusions/assumptions arrived at in step 1. For example, if we believe that an ""inverted-U"" relationship exists between levels of $Y$ and $Z$, this could be modeled by $Y = a + bZ + cZ^2$ with $c&lt;0$</p>

<p><strong>3)</strong> If the mathematical expression we obtain in step 2 is not linear in the unknown parameters of interest, we check whether it can be transformed into one that it is. Of course, there are estimation methods for non-linear relationships, non-linear least-squares being the easy example. But experience has taught us that our estimation techniques are better when they estimate equations linear in the unknown parameters, this is why we always try to arrive at such a specification, even if we may accept in the process certain approximating steps to what we have obtained in step 2 (and not just exact transformations).</p>
","10762"
"What is the justification for it being a problem if loans are not paid back?","226","","<p>As far as I could understand, the loan system applied by banks which is based on a fractional reserve system works as follows:</p>

<p><strong>Assumptions</strong>:</p>

<ol>
<li>The bank has initially 1000$. </li>
<li>The fractional reserve is currently 10%. </li>
<li>For simplicity, we assume that all deposits are made only on this bank, instead of having multiple banks. It has been argued in many places that, for the overall view of the money system, that this is a justfied assumption.</li>
</ol>

<p>The following happens now:</p>

<p><strong>1)</strong> Guy A makes a loan for 900\$. The bank keeps 100\$ (more than 10%, thus ok).</p>

<pre><code>Total loans owned by bank: 900$
Total deposits owned by bank: 100$
</code></pre>

<p><strong>2)</strong> Guy A pays guy A', which deposits the money on the bank again.</p>

<pre><code>Total loans owned by bank: 900$
Total deposits owned by bank: 1000$
</code></pre>

<p><strong>3)</strong> Guy B makes a loan for 800\$. The bank keeps 100$ as a new reserve (more than 10%, thus ok).</p>

<pre><code>Total loans owned by bank: 1700$
Total deposits owned by bank: 200$
</code></pre>

<p><strong>4)</strong> Guy B pays guy B', which deposits the money on the bank again.</p>

<pre><code>Total loans owned by bank: 1700$
Total deposits owned by bank: 1000$
</code></pre>

<hr>

<p>This repeats itself a couple of times, until we arrive at:</p>

<pre><code>Total loans owned by bank: 5000$
Total deposits owned by bank: 1000$
</code></pre>

<p>From the deposits, 500\$ are reserves of the bank, which belong to the bank, and 500\$ are money which is owned by the last guy that got money from another guy.</p>

<hr>

<p>Ok, so this is, as far as I understood, the beginning of the ""loan process with a fractional reserve system"", with a couple of loans. The bank has still enough reserves, so it did everything ok.</p>

<hr>

<p>Now let's assume that Guy A comes to the bank and says ""Hi, I'm sorry, I can't give you the money back, I'm broke"".</p>

<hr>

<p>Currently, the following thing happens: The bank says ""ok, so you must give us your security to cover our loss"" (for example the car).</p>

<hr>

<p><strong>Question</strong>: Why does this happen, what is the <strong>justification</strong> for taking the car from Guy A? Since the bank never lost anything...?</p>
","<p>It appears that the OP confuses  <em>money</em> with <em>property rights</em>  </p>

<p>A) It writes ""deposits owned by the bank"" which is simply wrong, since deposits are liquid assets belonging to the persons that deposited them. The bank leases the funds from them and then sublets them to the debtors.<br>
B) Looking also at an OP's  comment to another answer, indeed the bank may create the money, but it creates the money as a medium of exchange and representative of value -it does not keep the property rights on the <em>money itself</em> it creates.<br>
 C) Finally we should not forget that the bank is a distinct legal entity from its own shareholders.</p>

<p>Stopping at the four explicit amounts the OP gave (after person $B$ pays person $B'$ and person $B'$ deposits the money in the bank), the bank's balance sheet is as follows:</p>

<p>\begin{array} {| r | r | r |}
  \hline 
\hline                       
  \text {ASSETS} &amp; \text {USD} &amp; \text{LIABILITIES} &amp; \text{USD}\\
  \hline                      
\text{Loans} &amp; 1,700 &amp; \text{Shareholders Capital} &amp; 1,000\\
\text{Cash} &amp; 1,000 &amp; \text {Deposits} &amp; 1,700\\
\hline
\text {TOTAL ASSETS} &amp; 2,700 &amp; \text{TOTAL LIABILITIES} &amp; 2,700\\
  \hline  
\end{array}</p>

<p>A Balance Sheet is just an inventory at a specific point in time, of Cash and Rights to Collect in the future (""Assets"") and Obligations to Pay (also in the future) (""Liabilities""). </p>

<p>It is important to understand the ""Liabilities"" (obligations to pay) side.
The initial USD $1,000$ with which the bank started, represent an ""obligation to pay"" for the bank towards its own shareholders. Second the bank is obliged to pay at any time USD $1,700$ total to persons $A'$ and $B'$ that deposited <em>their wealth</em> to the bank. The fact that the depositing transaction could happen because the bank in a previous instance has created the <em>money</em>, does not give the bank a <em>property right</em> on that money, just because it was its ""creator"".</p>

<p>That the bank has at the moment $1,000$ in Cash as when it started doing business, relates to the bank's ""liquidity"" situation. This is not unimportant, and in fact it is an index of financial health on its own right. But it has to do only with the <em>short term</em> horizon. For the <em>long-term</em> horizon though, it is <em>property rights</em> that matter. And so it is not the only financial criterion for the economic health of a bank.</p>

<p>So assume that person $A$ comes in and say ""I cannot pay my loan of USD $900$"". Certainly, in the <em>short-term</em>, this won't affect the liquidity of the bank -it will still have the USD $1,000$ that it now has. But if the bank writes-off the debt, it will do so against the Shareholders capital invested. So after the write-off the balance sheet will be</p>

<p>\begin{array} {| r | r | r |}
  \hline 
\hline                       
  \text {ASSETS} &amp; \text {USD} &amp; \text{LIABILITIES} &amp; \text{USD}\\
  \hline                      
\text{Loans} &amp; 800 &amp; \text{Shareholders Capital} &amp; 100\\
\text{Cash} &amp; 1,000 &amp; \text {Deposits} &amp; 1,700\\
\hline
\text {TOTAL ASSETS} &amp; 1,800 &amp; \text{TOTAL LIABILITIES} &amp; 1,800\\
  \hline  
\end{array}</p>

<p>Assume things with debtor $B$ go smoothly, the bank will eventually (in the <em>long-term</em>) collect his loan, and it will be able to give to persons $A'$ and $B'$ their deposits back... so where is the problem? Well, the problem is that it will give to its shareholders only USD $100$ back instead of the initial USD $1,000$ investment.  </p>

<p>And who might care?  </p>

<p>First, we live in societies built upon the principle of private property rights. The shareholders have a right to defend their property rights, and the bank acting as their representative attempts to defend them by not simply writing-off the debt (but demanding another asset -the car- in its place), even if such a write-off may affect the property rights only of the shareholders, and not of the people that keep their wealth to the bank as deposits.  </p>

<p>But again, does this creates a problem to the economy <em>now</em>? In terms of actual <em>existing liquidity</em> the answer is <em>no</em>. But the <em>Present</em> is affected by what we project for the <em>Future</em>. After the write-off, the future of the shareholders and of the bank looks worse, because their current wealth is less. And this will affect negatively what the bank and the shareholders will and can do in terms of their involvement in the <em>economic activity</em> <em>now</em>.<br>
So to the question ""who cares?"" the second answer is ""the whole economy"".</p>
","3046"
"Linearity in Pricing and Duality, UMP EMP","225","","<p>I have read the statement below and don't quite understand what it means. This is probably because I don't have full understanding of duality with support function in math, but just to foster understanding... The statement is:</p>

<blockquote>
  <p><strong>""The utility maximization problem(UMP) has a non-linear utility objective and a linear price constraint. The expenditure minimization problem is exactly the other way around: a linear price objective and a non-linear utility constraint. This is at the heart of the idea of the meaning of dual - to recast the problem with the objective as a constraint and the constraint as the objective. An important observation to make is linearity in pricing in them. This linearity, either in objective or constraint, is the cornerstone in enabling us to use the duality theorem.""</strong></p>
</blockquote>
","<p>Consider the standard utility maximization problem:</p>

<p>$$\begin{align}\max_{\vec x} &amp; \quad U(\vec x) \\
&amp; \quad \vec p \cdot \vec x \leq Y
\end{align}$$</p>

<p>Here utility is your objective function, and the price inequality is the constraint. You solve for the optimal bundle via a Lagrangian.</p>

<p>Now consider its dual problem.</p>

<p>$$\begin{align}\min_{\vec x} &amp; \quad p \cdot \vec x \\
&amp; \quad U(\vec x) \geq \bar U
\end{align}$$</p>

<p>Now the objective function is expenditure, and a desired minimum utility is the constraint.</p>

<p>The utility that you gain from the maximization solution, if that is set to be $\bar U$, then the solution bundle to the minimization problem will be the same. This holds if you solve the bundle for the minimization problem first.</p>

<p>From this result (which you can verify for yourself) eventually comes the ever useful Roy's Identity.</p>

<p>$${x^m_i}^* = - \frac{\frac{\partial V}{\partial p_i}}{\frac{\partial V}{\partial Y}}$$</p>

<p>Where $V(\vec p,Y)$ is the indirect utility function.</p>

<hr>

<p>If you are confused about the meaning of support function, recall its definition. (I will use the one from Mas-Colell)</p>

<blockquote>
  <p>For any nonempty closed set $K \subset \mathbb{R}^L$, the support function of $K$ is defined for any $\vec p \in \mathbb{R}^L$ to be
  $$\mu_k(\vec p) = \inf \{\vec p \cdot \vec x: \quad \vec x \in K \}$$</p>
</blockquote>

<p>which is just a description of a set's minimum value. What does the (familiar) set here look like?...</p>
","12569"
"Consequences to lending and value of national currency from a negative interest rate and 140-year mortgages in Sweden","224","","<p>According to an <a href=""https://uk.finance.yahoo.com/news/sweden-sets-interest-rate-below-135817353.html"" rel=""nofollow"">article at Yahoo Finance</a>, the Swedish central bank dropped its zero interest rate to -0.1 percent a couple of days ago (the article is dated to Thursday, February 12th, 2015).</p>

<p>Now, already in 2013 <a href=""http://www.btinvest.com.sg/property/overseas/sweden-targets-lengthy-mortgage-repayments-20130312/"" rel=""nofollow"">this article from Business Times</a> reported that Swedish households were repaying their mortgages so slowly that it will take 140 years on average. It seems that the mortgage repayment system in Sweden is such that while a bank may set a theoretical limit on how soon the mortgage should be repaid, the individual is free to make interest-only repayments as long as they see fit. So the 140-year average length is not caused by lenders granting 140 year loans, but by the individuals simply paying them back at a rather slow pace.</p>

<p>If mortgage debts are already being paid on a rather low rate, can reducing the interest rate to below zero actually help the economy? Wouldn't this kind of decision just speed up a crash?</p>

<p>As to the Forex rate for the Swedish krona, can it be expected that this situation pushes down the value of the krona?</p>

<p><strong>Update:</strong>
My reason for asking this question is because of the assumption that the Central Bank interest rate controls the rate at which other banks lend money to individual customers. Thus the central bank would set the interest rate low so as to lower the interest rates of loans in the country, and through this, to stimulate lending. This is what for example USA did during the first decade of this century.</p>

<p>I would have thought that stimulating lending in a situation where mortgages are being paid back at an extremely low rate would be a recipe for a house price bubble and subsequent crash(?)</p>
","<p>There is some concern about the interest rates (currently at -0.5%) fueling a housing bubble in Sweden. <a href=""https://fixedincome.fidelity.com/ftgw/fi/FINewsArticle?id=201607060607DOWJONESDJONLINE000271"" rel=""nofollow noreferrer"">This article at Fidelity</a> states:</p>

<blockquote>
  <p>In a bid to track the ECB, Sweden has cut its interest rate below
  zero, a radical move that involves charging banks to hold some types
  of deposits with the aim of encouraging them to lend.</p>
  
  <p>Similar trends have emerged in other small, open economies, such as
  those of Denmark and Switzerland, which also have subzero rates.</p>
  
  <p>In Sweden, the central bank governor has warned that the low rates
  could be creating a housing price bubble.</p>
</blockquote>

<p>A reason why this risk exists in particular for Sweden is because the regulation has allowed the borrower to pay only the interest on common mortgage types, and since the interest rates have been very low for many years, the sizes of these payments have been low.</p>

<p>These mortgages are referred to as ""Swedish style mortgages"" in <a href=""http://www.riksbank.se/Documents/Rapporter/Working_papers/2015/rap_wp298_150430.pdf"" rel=""nofollow noreferrer"">this report</a> published by the Swedish Central Bank (dated April 2015).</p>

<p>Overall the situation has stimulated borrowing and fueled the growth of the overall indebtedness of the households. Above report states on p. 4 that:</p>

<blockquote>
  <p>Sweden, in particular, has seen household indebtedness rise from 90%
  of disposable income in 1995 to 172% in 2014</p>
</blockquote>

<p>Current situation is still as described as on page 14 in the <a href=""http://www.imf.org/external/pubs/ft/scr/2014/cr14262.pdf"" rel=""nofollow noreferrer"">Sweden - Selected Issues</a> paper published by the IMF (dated August 2014), shown in below image.</p>

<p><a href=""https://i.stack.imgur.com/MAHzP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MAHzP.png"" alt=""increase of unamortized mortgages in Sweden until 2012""></a></p>

<p>On p.15 this IMF report states that:</p>

<blockquote>
  <ol start=""17"">
  <li>If progress under the current voluntary approach remains limited, a binding maximum amortization period for new mortgages would be
  helpful. Swedish banks are working to raise amortization through
  voluntary means. However, the picture remains largely unchanged. The
  share of new mortgages granted in 2013 that has an amortization plan
  has remained broadly constant from 2012. And, of the existing mortgage
  stock, a significant 40 percent of households either increased or did
  not decrease their debt in 2013. For the remaining 60 percent of
  households, it would take 100 years to fully pay down their debt if
  they continued to amortize at current speeds.</li>
  </ol>
</blockquote>

<p>In fact they attempted to regulate the mortgages last year but according to <a href=""http://www.thelocal.se/20150423/swedish-watchdog-scraps-new-mortgage-rules"" rel=""nofollow noreferrer"">this article</a> it looks like the proposed changes were rejected by an appeals court. The article states that</p>

<blockquote>
  <p>Under the original plans, customers would have been asked to pay two
  percent of the value of their mortgage every year until they had
  repaid 30 percent of the loan. They would then have been required to
  pay at least one percent a year until they hit the 50-percent mark.</p>
  
  <p>But the watchdog backtracked after an administrative court of appeal
  in Jönköping in southern Sweden suggested that the proposed changes
  were not supported by Swedish law.</p>
</blockquote>

<p>I am not sure however if they were able to pass that law later in some modified form.</p>

<p>Understandably the current level of indebtedness poses a large risk for the banks in the event of a downturn on the housing markets. However the already existing debt levels (as discussed in <a href=""http://www.riksbank.se/Documents/Rapporter/Ekonomiska_kommentarer/2014/rap_ek_kom_nr01_140507_eng.pdf"" rel=""nofollow noreferrer"">this report</a>) in comparison to disposable income may make it difficult to implement drastic changes to the regulations.</p>

<p>The reason for the interest-rate cut you asked about seems to have been to avoid further deflation. One of the consequences of this has been, according to <a href=""http://www.ft.com/cms/s/0/8961b57c-3872-11e6-a780-b48ed7b6126f.html#axzz4DrvAVL4L"" rel=""nofollow noreferrer"">this article</a>, an overall increase in house prices. So while at least two of the symptoms of a housing bubble (high prices and high levels of household debt) are present in Sweden, there are also factors that play against a US-style mortgage crisis, such as:</p>

<ul>
<li>The ability of households to make interest-only mortgage payments
without penalty for an extended period.</li>
<li>Large amounts of recent immigrants (refugees from mainly the middle
east) that will require housing. In addition to this Sweden already
had low levels of new construction even before the latest influx of
immigrants.</li>
<li>The relatively small size of the country; people tend to not move
geographically as far away as in USA for reasons such as employment and may stay at a particular address longer.</li>
</ul>

<p><strong>Update:</strong> According to <a href=""http://www.telegraph.co.uk/personal-banking/mortgages/sweden-cuts-maximum-mortgage-term-to-105-years-the-average-is-14/"" rel=""nofollow noreferrer"">this article</a>, Sweden did change the maximum length of a mortgage to 105 years earlier this year.</p>
","12647"
"What did the Swiss National Bank use to purchase EUR while pegging the Franc to the Euro?","224","","<p>To peg its currency (CHF) to the Euro (EUR), the Swiss National Bank (SNB) made purchases of EUR to the tune of several hundred billion.  By reducing the supply of EUR, the SNB made the EUR relatively valuable, achieving the peg.</p>

<p>But how did the SNB fund its EUR purchases?  My original assumption was that the SNB simply printed CHF to buy EUR.  Is this correct?</p>

<p>The reason I ask is (a) I have not been able to find explicit documentation of this and (b) a colleague suggested that the SNB may have been using other means to purchase EUR, such as tapping into gold reserves or other kinds of reserves.</p>
","<p>This quotation by Michael Bordo, Owen F Humpage, and Anna J Schwartz (2012) was the richest description I could find on how the SNB achieved the floor:</p>

<blockquote>
  <p>In March 2008, the Swiss National Bank eased monetary policy in
  response to expectations of deflation, deteriorating economic
  conditions, financial-market distress, and a Swiss franc appreciation
  that resulted from the global financial crisis. In conjunction with
  this action, the Bank aggressively bought euros in the
  foreign-exchange market in 2009. Throughout March and April 2009, the
  Swiss National Bank did not seem to sterilise its substantial
  foreign-exchange purchases; the Swiss monetary base rose by more than
  the value of foreign assets on the Bank’s books. In response, the
  Swiss franc depreciated. By April 2009, however, the Swiss monetary
  base had more than doubled from a year earlier, and the Bank – now
  concerned about latent inflation – began to sterilise the liquidity
  resulting from its huge interventions. The Swiss interventions
  continued through June 2010, but the Swiss monetary base either grew
  by less than the Swiss National Bank’s holdings of foreign assets, or
  the monetary base actually declined. The Bank was clearly sterilising
  the operations, and the franc appreciated by nearly 10% between April
  2009 and June 2010. On balance, from May 2010 to August 2011, the
  Swiss monetary base contracted and the franc appreciated, reaching an
  historic high on a real trade-weighted basis.</p>
  
  <p>In early August 2011, the Swiss National Bank announced a series of
  new measures to inject liquidity into financial markets with the
  objective of stemming the Swiss franc’s appreciation. The operations
  included foreign-exchange swaps in which the Bank sold francs spot and
  repurchased them forward. The franc depreciated sharply, but undertook
  a stunning reversal late in the month. The Swiss National Bank then
  announced that it was prepared to buy foreign exchange in unlimited
  quantities to maintain a floor of SF 1.20 vis-à-vis the euro. The
  Bank’s holdings of foreign exchange increased substantially, but the
  Swiss monetary base increased by even more. Since September, the Swiss
  National Bank has maintained an exchange-rate floor, by giving up
  control of its monetary base in conformity to the fundamental
  trilemma.</p>
</blockquote>

<p><a href=""http://www.voxeu.org/article/notes-currency-wars-trilemma-international-finance"" rel=""nofollow"">Foreign-exchange intervention and the fundamental trilemma of international finance: Notes for currency wars</a>  </p>

<p>If they are not controlling their monetary base they probably be doing standard currency interventions. That is, they credit their own accounts at banks with CHF, then using those credited accounts to purchase Euro denominated assets. Or perhaps, they enter into spot Euro-CHF FX transactions and use the proceeds to buy Euro denominated assets. If they were selling gold then they'd sell gold for dollars and buy euros with dollars. That might modestly move the Euro-USD  exchange rate but would affect the Euro-CHF rate only indirectly. But the Swiss monetary base shouldn't be increasing.</p>
","3109"
"What have been the main developments in macroeconomics and financial economics since the 2008 financial crisis?","224","","<p>In the aftermath of 2008 economists were, fairly or not, blamed for a failure to foresee the coming crisis. Ideas such as ""<a href=""https://en.wikipedia.org/wiki/Great_Moderation"" rel=""noreferrer"">The Great Moderation</a>"" and market efficiency were openly ridiculed as hubristic. </p>

<p>Now, almost a decade later, seems like a good time to take stock and ask: What have been the main developments in macroeconomics and financial economics research that have emerged in response to the financial crisis?</p>

<ul>
<li>are there lines of research that have been discredited or essentially abandoned?</li>
<li>are there new topics that have received much more attention?</li>
<li>are the new approaches to modelling (or approaches that have come to be used more than previously)?</li>
<li>have any big new ideas emerged in our understanding of recessions / financial crises?</li>
</ul>

<p>Or perhaps there is good reason to think that everything was fine before and so nothing has to change.</p>
","<p>Well, in macroeconomics, namely in DSGE modelling, VOXEU has recently published a <a href=""http://voxeu.org/content/dsge-models-conduct-policy-use-intended"" rel=""nofollow noreferrer"">report on its uses by Central Banks (CBs)</a>, and future lines of improvement, which academics have been tackling but still hasn't found its way into CBs policy analysis. There's no space to explain all the new topics, nor do I think it's the intention of this question. So, I'll just enunciate the topics, with some references. More can be found in reading the report. Also, I'll focus on the theoretical considerations, i.e., it's known that, empirically, the the VAR obtained by solving the DSGE model can be considered as misspecified (<a href=""http://www.econ.vt.edu/wp-content/uploads/2016/09/Spanos13-DSGE-model-validation-2016.pdf"" rel=""nofollow noreferrer"">see here</a>). This is a WP, but you can easily find many articles on this subject, increasingly so since the crisis)</p>

<ul>
<li>Financial Frictions (<a href=""https://www.aeaweb.org/articles?id=10.1257/aer.104.1.27"" rel=""nofollow noreferrer"">an example</a>)</li>
<li>Forward Guidance(extending low-rates period), due to the presence of a ZLB (<a href=""https://www.brookings.edu/bpea-articles/the-zero-bound-on-interest-rates-and-optimal-monetary-policy/"" rel=""nofollow noreferrer"">see here</a>; this was already being studied before the crisis.)</li>
<li>(Incomplete Markets) Heterogeneity across households in
the transmission of monetary and fiscal policy (<a href=""https://www.ecb.europa.eu/pub/pdf/scpwps/ecbwp1899.en.pdf"" rel=""nofollow noreferrer"">see here</a>). I would also add firm heterogeneity (<a href=""https://www.bundesbank.de/Redaktion/EN/Downloads/Publications/Discussion_Paper_1/2017/2017_08_31_dkp_25.pdf?__blob=publicationFile"" rel=""nofollow noreferrer"">example here</a>)</li>
<li>Systemic fragilities, i.e., economy more prone to crisis due to increasing leverage (<a href=""http://www.econ.nyu.edu/user/gertlerm/GertlerKiyotakiAERJuly2015.pdf"" rel=""nofollow noreferrer"">an example</a>)</li>
<li>Allowing for structural (long-run) changes, instead of a simple sequence of short-run shocks, this allows for fluctuations of for example the natural rate of interest (<a href=""http://www.frbsf.org/economic-research/files/wp2016-11.pdf"" rel=""nofollow noreferrer"">see here</a> and <a href=""https://www.google.pt/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0ahUKEwjt947V16_XAhUMthQKHbuqA3UQFggmMAA&amp;url=https%3A%2F%2Fwww.aeaweb.org%2Fconference%2F2017%2Fpreliminary%2Fpaper%2Fk3Qr4Qz2&amp;usg=AOvVaw1Pu9VhqKiL-W03g27elqq4"" rel=""nofollow noreferrer"">here</a>). </li>
</ul>

<p>Finally, one critique, with which I agree, and Romer has written very funny and interesting '<a href=""https://paulromer.net/wp-content/uploads/2016/09/WP-Trouble.pdf"" rel=""nofollow noreferrer"">WP</a>' on, is the degree of exogeneity, through shocks, that is needed to explain the economy.</p>

<p>Behavioural economics (2017 Nobel prize winner was from this area) may supply us with an answer. It allows to endogenize some of the shocks. Here's an <a href=""http://voxeu.org/article/behavioural-economics-also-useful-macroeconomics"" rel=""nofollow noreferrer"">article on VOXEU</a> with many references, and analysis of an example of how it's done. </p>

<p>Edit: To complement Kitsune answer, I find this image from the wikipedia page really good. In a very succint way, it explains the difference between macro and micro prudential perspectives.</p>

<p><a href=""https://i.stack.imgur.com/jWe1O.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jWe1O.png"" alt=""enter image description here""></a></p>
","19184"
"Whom would you consider to be the father of rational choice theory?","224","","<p>Whom would you consider to be the father of <strong>rational choice theory</strong>?
My suggestions that would qualify for major publications:
Arrow (1959), Economica
Homans (1961)
Becker (1976)
Sugden (1991), Economic Journal </p>

<p>Plus, would you agree that <strong>inter-temporal choice theory</strong> was derived from rational choice theory? Or vice versa?</p>
","<p>The answer is <strong>there is no single father of rational choice theory</strong>. The reason is that rational choice theory is not so much a theory but rather a coherent framework (others would call it a paradigm) resting on the key foundations of methodological individualism and instrumental rationality / self interest.</p>

<p>Both of these aspects played important roles in the marginal revolution in the late 19th century. Important names here are, of course, <em>Walras</em>, <em>Jevons</em>, <em>Menger</em> and <em>Marshall</em> although none of them can be regarded single father of Economics in the modern sense.</p>

<p>Some decades later, <em>Robbins</em> (1932, p. 15) famously defined Economics as</p>

<blockquote>
  <p>the science which studies human behaviour as a relationship between ends and scarce means which have alternative uses.</p>
</blockquote>

<p>This definition nicely summarizes much of the framework rational choice theory is embedded in. It contains instrumental rationality, in so far as that humans have goals (denoted as preferences) but only limited resources (constraints) and they choose so as to maximize their utility. It also hints at methodological individualism because it places human behaviour at the center of its investigation. Note, however, that Robbins again only summarized a research paradigm that was already well developed. (He says so himself on the same page.)</p>

<p>Still, I guess it is fair to say that rational choice theory as we know it today took off after WW2. Here different names come to mind, depending on which focus you want to have. <em>Arrow/Debreu</em> for general equilibrium theory, von <em>Neumann/Morgenstern</em> if you want to stress expected utility (and game theory). A bit later, <em>Becker</em> is a good choice if you want to stress that rational choice theory is an approach that is driven by its methodology (rational behavior, methodological individualism) and need not investigate an economic topic at all. </p>

<p>But yeah, asking for a single father of rational choice theory would really stress things a bit too far.</p>
","14907"
"Deriving indifference curves","223","","<p>I have been trying to work this out for quite a while now, but I can't seem to understand how to solve these kind of questions. Any help (or hint) would be highly appreciated. </p>

<p>Professor Goodheart's colleague Dr. Kremepu gives 3 midterm exams. He drops the lowest and gives each student her average score on the other two exams. Polly Sigh is taking his course and has a 60 on her first exam. Let $x_2$ be her score on the second exam and $x_3$ be her score on the third exam. If we draw her indifference curves for scores on the second and third exams with $x_2$ represented by the horizontal axis and $x_3$ represented by the vertical axis, then her indifference
curve through the point ($x_2; x_3$) = (50; 70) is:</p>

<ol>
<li>L-shaped with a kink where $x_2 = x_3$.</li>
<li>three line segments, one vertical, one horizontal, and one running from (70; 60) to (60; 70).</li>
<li>a straight line, running from (0; 120) to (120; 0).</li>
<li>three line segments, one vertical, one horizontal, and one running from (70; 50) to (50; 70).</li>
<li>a V-shaped curve with its point at (50; 70).</li>
</ol>
","<p>The Utility function here is the average score that Polly gets i.e.</p>

<p>$U(x_2,x_3)=\frac{max\{x_2,x_3,60\}+max^2\{x_2,x_3,60\}}{2}\\$</p>

<p>Where: $max^2\{.\}$ stands for second highest number.
Now this utility function can be rewritten as:</p>

<p>$U(x_2,x_3)= \begin{cases}\frac{x_2+x_3}{2}, &amp; \text{ if } x_2,x_3\geq 60,\\ \frac{60+x_3}{2}, &amp; \text{ if } x_2&lt;60, x_3&gt;x_2,\\ \frac{60+x_2}{2}, &amp; \text{ if } x_3&lt;60,x_3&lt;x_2,\\ \frac{60+k}{2}, &amp; \text{ if } k&lt;60,x_3=x_2=k.\\ 
\end{cases}$</p>

<p>Plotting its level curve i.e. the IC for utility level $c$ would be a horizontal line from point $(0,2c-60)$ to $(60,2c-60)$, a vertical line from point $(2c-60,0)$ to $(60,2c-60)$ and a line from $(60,2c-60)$ to $(2c-60,60)$.</p>

<p>So if $(x_2,x_3)=(50,70)$ option 2 satisfies the IC's description.</p>
","5196"
"Raising interest rates to prevent inflation","223","","<p>I am reading a book about the Mundell-Fleming Model and I have encountered a part which says:</p>

<blockquote>
  <p>The Fed raised U.S. interest rates several times during 1994 to prevent U.S. inflation.</p>
</blockquote>

<p>Isn't it the other way round? I thought that rising interest rates causes the investment to decrease and so the money demand to decrease. When money demand decreases, price level increases. Am I wrong?</p>
","<p>The increase in interest rates make borrowing more expensive and therefore businesses and people will borrow less. Therefore, investment and consumption decrease. Through the multiplier effects, this will cause a reduction in real GDP. This will also increase the unemployment rate. Therefore, people who sell these goods and services will reduce their prices. As a result, the overall price level will fall and the inflation rate is reduced. I understand that explanation where the money demand decreases cause a probable eventual reduction in the interest rates. However, this assume that the money supply is fixed. Now, you must understand how the Fed controls the interest rates. It controls the interest rates by controlling the money supply. It reduces the money supply by selling bonds into the economy. Therefore, the money supply shift to the left and initially, the interest rates soar. The demand and supply analysis:</p>

<ol>
<li><p>First we must define some basics: We are going to use the supply and demand graph with the interest rates as the y axis and the money in x axis. Now since we know that there is a fixed amount of money in the economy and the Fed is controlling it, we know that the supply of money is strictly vertical and the demand for money is downward-sloping (with a certain elasticity)</p></li>
<li><p>The mechanism of the money diagram: In a fixed money supply, if there is an increase in demand of money, the demand curve will shift to the right. Now if there is a a positive inflation rate, there is an increase in demand of money with every inflation rate and therefore the demand curve will shift to the right.</p></li>
<li>The fed aims to  reduce inflation by increasing interest rates. They do this by reducing the amount of money in the economy and thus shifting the supply curve of money to the left. You are right when the total quantity of money in the equilibrium point will be reduced. However, I think that you are confused why the interest rates will not go down. This is because the Fed aims to <em>reduce</em> positive interest rates and <em>not</em> cause a <em>negative</em> inflation rate. In argument (2) I have explained that with a positive inflation rate, the money demand curve will always be shifting to the right. Therefore, the Fed <em>only wants</em> to reduce the speed of that shift.</li>
</ol>

<p>Now you wonder why the Fed wants to reduce the inflation rate. This is because it is always desirable to have a steady price level. A high inflation rate causes some cost to the economy that it does not want. You need to google or search in the wikipedia for the negative effects of high inflation rates.</p>
","6008"
"How much would the EU budget reduce by after Brexit?","222","","<p>Would it reduce the budget of some €133bn by the gross amount after the rebate but before any spending from the EU into the UK (€17bn, about 12.5% according to Table 6, Page 11 of <a href=""http://eur-lex.europa.eu/budget/data/DB/2017/en/GenRev.pdf"" rel=""nofollow noreferrer"">the 2017 draft budget</a>) or by the net amount, which is some lower figure, (perhaps 6% ?) of the budget?</p>

<p>Assuming no changes due to other countries contributing more, etc. as a result of the UK leaving. It's purely about discerning what proportion of the budget is contributed by the UK's contribution, not what the actual change to the budget will be.</p>
","<p><strong>Part A: how much does the UK contributes to the EU Budget</strong></p>

<p>This depends on whether you use fiscal year or calendar year estimates. The figures for the 2015/2016 fiscal year are <a href=""http://researchbriefings.parliament.uk/ResearchBriefing/Summary/CBP-7886"" rel=""nofollow noreferrer"">here</a>. The key is the following graph:</p>

<p><a href=""https://i.stack.imgur.com/DixEJ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DixEJ.png"" alt=""enter image description here""></a></p>

<p>The calendar year estimates are <a href=""https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/483344/EU_finances_2015_final_web_09122015.pdf"" rel=""nofollow noreferrer"">here</a>. The following Table summarizes the data:</p>

<p><a href=""https://i.stack.imgur.com/nma45.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nma45.png"" alt=""enter image description here""></a></p>

<p>Naturally, <strong>the net contribution is what matters</strong> for analysis the case of ""EU budget without UK"". However, as both report point out, the UK receives other contribution, which come from an ""allocation of funds via competition"". Think of the EU having a fund for, say, improvement in infrastructure. Countries apply to this fund, and some countries get it. Well, as the first report says, the UK got £1bn extra through that mechanism in the 2015/16 year. Should this be counted as part of the exercise? Probably not, because those extra funds would have been allocated to another country anyway. </p>

<p>So, given that the total budget of the EU in 2015 was €141,280 million, and taking an <a href=""https://www.statista.com/statistics/412806/euro-to-gbp-average-annual-exchange-rate/"" rel=""nofollow noreferrer"">average EUR/GBP</a> of 0.73, the percentage of contribution of UK to EU budget in 2015 was:</p>

<p>$$ \frac{8,473}{141,280 \times 0.73} = 8.2\% $$</p>

<p>Regarding <strong>2017</strong>, table in page 11 shows only the <strong>gross payments</strong>, including the rebate, but not the public rector receipts. As such, the effective contribution of the UK is not going to be 12.5% as the document notes, but lower. Given historical levels of receipts, you could estimate that the contribution of the UK to the EU budget would be perhaps around 9%. In any case, as far as I know, this cannot be known <em>ex-ante</em>, reason why it is not included in the official budget document.</p>

<p><strong>Part B: how would the EU budget change after Brexit</strong></p>

<p>Since this relates to a future event, it is impossible to tell. This is for several reasons:</p>

<ul>
<li>Budget are negotiated annually among all members, and contributions vary accordingly. As such, if countries expect less revenues, they might either lower expenditures, <strong>or</strong> increase demand for contributions to other countries. For instance, immediately after the Brexit vote, speculation arose that <a href=""http://www.telegraph.co.uk/news/2016/06/24/germanys-contribution-to-eu-annual-budget-could-rise-by-2bn-afte/"" rel=""nofollow noreferrer"">Germany would cover any hole left by the UK</a>.</li>
<li>An important component of budget (31% in 2014) does not come from individual countries contributions. As such, how these evolve affects particularly how much countries contribute.</li>
<li>Brexit might induce an adjustment on the so-called <a href=""https://en.wikipedia.org/wiki/Budget_of_the_European_Union#Correction_mechanisms"" rel=""nofollow noreferrer"">correction mechanisms</a>.</li>
<li>Countries contribution vary over time depending on many national circumstances, including the size of their economy, which then depends on economic growth, uneven across the EU.</li>
<li>The UK is expected to pay the EU before it leaves, known as a ""divorce"" or ""exit"" bill, which depends on the outcome of negotiations. </li>
<li>It depends on what deal the UK and EU have after Brexit. A Norway style of deal means the UK would have to pay to the EU.</li>
</ul>

<p>In conclusion, it is simply impossible to tell. The calculations you make are a simple <em>ceteris paribus</em> exercise of removing the UK from the _current EU budget. That might be illustrative, but given the huge uncertainty on the issue, it's probably a rather brute calculation. </p>
","15220"
"Saddle path equilibrium on financial market with rational expectations","222","","<p>In his <a href=""http://college.holycross.edu/eej/Volume4/V4N3_4P153_159.pdf"" rel=""nofollow noreferrer"">1978 paper</a> introducing the Tobin tax Tobin states that :</p>

<blockquote>
  <p>As a technical matter, we know that a rational expectations
  equilibrium on markets of this kind is a saddle point. That is, there
  is only a singular path that leads from disequilibrium to equilibrium.
  If the markets are not on that path, or if they don't jump to it from
  wherever they are, they can follow any of a number of paths that lead
  away from equilibrium - paths along which, nonetheless, expectations
  are on the average fulfilled.</p>
</blockquote>

<p>He seems to consider this result as common knowledge among the economists and gives no reference. To which result or paper is he referring ? Do you have an idea of what he means with ""markets of this kind"" ?</p>
","<p>Suppose you have a dynamic system 
$$ x_{t+1} = Ax_{t} $$
with a stationary point (or steady state as used in growth or RBC literature), say, $x^*$, i.e. $x^{*} = Ax^{*}$.</p>

<p>Now, consider the following question. Starting from an initial value $x_0$, how many paths are there leading to the stationary point $x^*$? If there is an unique path going from $x_{0}$ to $x^{*}$, then your model is well behaved in the sense that you can track the vector of variables, $x_t$, along the transition without worrying which path you are actually on. This is the saddle-path stability case that you are referring to. On the other hand, if the answer is not affirmative, it means that you have at least two routes from $x_0$ to $x^{*}$. There is another case: no matter where you start from you eventually end up at the stationary point $x^{*}$, in which case your model is said to be indeterminate. </p>

<p>So you can think of saddle-path stability as a desirable feature that you would like that your model to manifest in order to analyze the problem at hand. For example, standard RBC models all posses this property. </p>

<p>There are some mathematical conditions that ensure the saddle-path stability. </p>

<p>For the details and more, check out the section 7.8 (The q-Theory Investment and Saddle-Path Stability) in Introduction to Modern Economic Growth (Acemoglu, 2009).</p>

<p><a href=""https://i.stack.imgur.com/d04hZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/d04hZ.png"" alt=""enter image description here""></a></p>

<p>Ok, I'll try to explain intuitively for the Ramsey model (but it's not rigorous). Suppose that from the first order conditions, you can conclude that the equilibrium is unique and furthermore you can express consumption as a function of capital stock, that is $c_{t} = g(k_t)$, for some (smooth) function $g$. If that is the case, for a given initial capital stock $k_0$, you know how the economy is going to evolve. That is, if we denote the vector of variables by $x_t = (c_t, k_t)$, you know $\{ x_{t}\}_{t=0}^{\infty}$; because </p>

<p>$t=0: \quad$ $k_0$ is given, and $c_0 = g(k_0)$, </p>

<p>$t=1: \quad$ $k_1 = (1-\delta)k_0 + f(k_0) - c_0$, and $c_1 = g(k_1)$, 
(here $f$ is the production function and $\delta$ is depreciation)</p>

<p>$\vdots $</p>

<p>$t=\tau: \quad$ $k_{\tau} = (1-\delta)k_{\tau -1} + f(k_{\tau -1}) - c_{\tau -1}$, and $c_{\tau} = g(k_{\tau})$, </p>

<p>so on .... </p>

<p>Now, suppose the economy loses some of its capital stock for some reason while it was on $x^*=(k^*, c^*)$ and the new capital stock is, say, $k_{\tau}$. </p>

<p>Where will the economy be with this new capital stock? </p>

<p>Well, we have just claimed that there is a corresponding consumption $c_{\tau}=g(k_{\tau})$, and therefore the economy will jump to the point $x_{\tau}=(k_{\tau}, c_{\tau})$ on impact the shock and then move toward back to steady state $x^*$. You can think of $x_{\tau}$ as the red point in the figure. </p>

<p>Finally, a few remarks on the intuition behind the mathematical conditions ensuring saddle-path stability. </p>

<p>1) Note that, in the model we have actually two  variables $c_t$ and $k_t$, but we have assumed  that one of them can be  expressed in terms of the other, so the number of free variables is reduced to one, which is $k_t$ here. Basically, in order to be able to do this, you want to have a smooth curve mapping capital stock to consumption, i.e. $g: \mathcal{R} \to \mathcal{R}$ is a smooth curve (1-dimensional manifold). </p>

<p>2) Once the economy is at $x_{1}$ after the shock, you want it go back to $x^*$ and this is related to the number of eigenvalues that are less than one in absolute value.  </p>

<p>For precise statements (in a general environment) see Acemoglu as I mentioned before.  </p>

<p>Regarding rational expectations(RE): it is a solution concept and RE alone does not imply saddle-path stability. </p>
","15493"
"Barro's (2009) rare disaster model in the AER: How to derive equation (10)?","221","","<p>In Barro (2009) <em><a href=""http://piketty.pse.ens.fr/files/Barro2009.pdf"" rel=""noreferrer"">Rare disasters, asset prices and welfare costs</a></em> Barro develops a Lucas tree model with Epstein-Zin preferences. </p>

<p>My question concerns the paper's equation (10). In this equation Barro states that under the optimal solution utility $U_t$ is proportional to consumption $C_t$ rased to the power of $1-\gamma$, where $\gamma$ is the coefficient of relative risk aversion, i.e. </p>

<p>$U_t=\Phi C_t^{1-\gamma}$ </p>

<p>While I understand the logic of this result, I do not understand how he derives the constant $\Phi$, which is shown in footnote 7 of the mentioned paper:</p>

<blockquote>
  <p>Alberto Giovannini and Philippe Weil (1989, appendix) show that, with
  the utility function in equation (9), attained utility, $U_t$ , is
  proportional to wealth raised to the power $1-\gamma$. The form in
  equation (10) follows because $C_t$ is optimally chosen as a constant
  ratio to wealth in the i.i.d. case. The formula for $\Phi$ is, if
  $\gamma \neq 1$ $\theta \neq 1$, $$\Phi  =
 (\frac{1}{1-\gamma})\{\rho+(\theta-1)g^* - (1/2)\gamma(\theta
 -1)\sigma^2 - (\frac{\theta-1}{\gamma-1})p[E(1-b)^{1-\gamma} - 1 - (\gamma  - 1)Eb] \}^{(\gamma-1)/(1-\theta)}$$</p>
</blockquote>

<p>Barro quotes the 1989 NBER paper by Giovannini and Weil. In this paper I can derive the constant. However, it looks completely different than Barro's version, because I end up with an expression that includes $E[R_t^{1-\gamma}]$, where $R_t$ is the return on equity. I believe Barro has replaced $E[R_t^{1-\gamma}]$ with the equilibrium solution of  $R_t$. However, his expression does not include any logs or exp expressions. </p>

<p>I would be grateful for a solution or any hints to the solution.  </p>
","<p>I think Barro means in the footnote that Giovanni and Weil find the same equation, $U_t=\Phi C^{1-\gamma}$, but using the optimal path of $C_t$.
In Barro's paper, the approach is different given that the dynamics of $C_t$ is exogenous: $C_t=Y_t$ by assumption.</p>

<p>Barro uses the limit case when the length of a period gets close to 0. Maybe what may bother the reader is that the model is defined as discrete.</p>

<h2>Rewrite the model</h2>

<p>First, we can rewrite the model with a length of period $\delta$ and then use $\delta\to 0$.
The GDP dynamics write
$$\log(Y_{t+\delta})=\log(Y_t)+g\delta+u_{t+\delta}+v_ {t+\delta}$$ 
with $u_{t+\delta}\sim \mathcal{N}(0,\delta\sigma^2)$, and $v_{t+\delta}=0$ with probability $1-p\delta$ and $\log(1-b)$ with probability $p\delta$.
The utility satisfies
$$
U_t=\frac{1}{1-\gamma}\left\lbrace C_t^{1-\theta}+\frac{1}{1+\rho\delta}\left[(1-\gamma)E_tU_{t+\delta}\right]^\frac{1-\theta}{1-\gamma}\right\rbrace^\frac{1-\gamma}{1-\theta}.
$$</p>

<h2>1) Find $\Phi$ as a function of $E_t\left[\left(\frac{C_{t+\delta}}{C_t}\right)^{1-\gamma}\right]$</h2>

<p>From now suppose there is a $\Phi$ such that $U_t=\Phi C^{1-\gamma}$ (note that $\Phi$ depends on $\delta$ a priori).
Define $H(U)=[(1-\gamma)U]^\frac{1-\theta}{1-\gamma}$, the utility satisfies
\begin{align}
H(U_t)= C_t^{1-\theta}+\frac{1}{1+\rho\delta}H(E_tU_{t+\delta}).
\end{align}
We substitute $U_t$:
\begin{align}
H(\Phi)C_t^{1-\theta}= C_t^{1-\theta}+\frac{1}{1+\rho\delta}H(\Phi)\left(E_t\left[C_{t+\delta}^{1-\gamma}\right]\right)^\frac{1-\theta}{1-\gamma}.
\end{align}
Hence, we obtain for $C_t\neq 0$,
\begin{align}
\frac{1}{H(\Phi)}= 1-\frac{1}{1+\rho\delta}\left(E_t\left[\left(\frac{C_{t+\delta}}{C_t}\right)^{1-\gamma}\right]\right)^\frac{1-\theta}{1-\gamma}.
\end{align}</p>

<h2>2) Find $E_t\left[\left(\frac{C_{t+\delta}}{C_t}\right)^{1-\gamma}\right]$ fromp the GDP dynamics</h2>

<p>The trick is to find the expectation in the right-hand side from the GDP dynamics.
\begin{align}
\left(\frac{Y_{t+\delta}}{Y_t}\right)^{1-\gamma}= \exp\left((1-\gamma)g\delta\right).\exp\left((1-\gamma)u_{t+\delta}\right).\exp\left((1-\gamma)v_ {t+\delta}\right).
\end{align}
Taking the expectation and using the independence between $u_{t+1}$ and $v_{t+1}$, it follows
\begin{align}
E_t\left(\frac{Y_{t+\delta}}{Y_t}\right)^{1-\gamma}= \exp\left((1-\gamma)g\delta\right).E_t\exp\left((1-\gamma)u_{t+\delta}\right).E_t\exp\left((1-\gamma)v_ {t+\delta}\right).
\end{align}
The expectation of $\exp(X)$ where $X$ follows $\mathcal{N}(0,\sigma^2)$ is $\exp(\sigma^2/2)$. $\exp\left((1-\gamma)v_ {t+\delta}\right)$ is a random variable equal to $1$ with probability $1-p\delta$ and $(1-b)^{1-\gamma}$ with probability $p\delta$.
We substitute the expectation operator:
\begin{align}
E_t\left(\frac{Y_{t+\delta}}{Y_t}\right)^{1-\gamma}= \exp\left((1-\gamma)g\delta\right).\exp\left(\frac{(1-\gamma)^2\sigma^2\delta}{2}\right).\left(1-p\delta+pE[(1-b)^{1-\gamma}]\delta\right).
\end{align}
Finally, we use $C_t=Y_t$ to compute an equation for $\Phi$:
\begin{align}
\frac{1}{H(\Phi)}&amp;= 1-\frac{1}{1+\rho\delta}\left\lbrace\exp\left((1-\theta)g\delta\right).\exp\left(\frac{(1-\gamma)(1-\theta)\sigma^2\delta}{2}\right)\right.\\
	&amp;\left. .\left(1-p\delta+pE[(1-b)^{1-\gamma}]\delta\right)^\frac{1-\theta}{1-\gamma}\right\rbrace.
\end{align}</p>

<h2>3) Take the approximation $\delta\to 0$</h2>

<p>The last step consists in taking a first-order approximation (I abusively keep the equal symbol):
\begin{align}
\frac{1}{H(\Phi)}&amp;= 1-(1-\rho\delta). \left(1+(1-\theta)g\delta\right).\left(1+\frac{(1-\gamma)(1-\theta)\sigma^2\delta}{2}\right)\\
	&amp; .\left(1-\frac{1-\theta}{1-\gamma}p\delta+\frac{1-\theta}{1-\gamma}pE[(1-b)^{1-\gamma}]\delta\right).
\end{align}
Pursuing the first-order apprixmation (all the $\delta^i$ with $i&gt;1$ can be neglected), we have
\begin{align}
\frac{1}{H(\Phi)}&amp;= \rho\delta -(1-\theta)g\delta-\frac{(1-\gamma)(1-\theta)\sigma^2\delta}{2}\\
	&amp; +\frac{1-\theta}{1-\gamma}p\delta-\frac{1-\theta}{1-\gamma}pE[(1-b)^{1-\gamma}]\delta.
\end{align}
Substitute $g$ using $g^*=g+\frac{\sigma^2}{2}-pEb$, 
\begin{align}
\frac{1}{H(\Phi)}&amp;= \rho\delta -(1-\theta)g^*\delta+(1-\theta)\frac{\sigma^2}{2}\delta -(1-\theta)pEb\delta -\frac{(1-\gamma)(1-\theta)\sigma^2\delta}{2}\\
	&amp; +\frac{1-\theta}{1-\gamma}p\delta-\frac{1-\theta}{1-\gamma}pE[(1-b)^{1-\gamma}]\delta.
\end{align}
We take $\delta=1$ and invert function $H$ to find the solution in the footnote 7 of the paper. The right-hand side of this equation ""simplifies"" to the within braces in the formula.</p>
","18890"
"Question about constant relative risk aversion","221","","<p>The question:</p>

<p>Consider a person with constant relative risk aversion $p$.</p>

<p>(a) Suppose the person has wealth of $100,000$ and faces a gamble in which he wins or loses $x$ with equal probabilities. Calculate the amount he would pay to avoid the gamble, for various values of p (say, between $0.5$ and $40$), and for some values of $x$. For large gambles, do large values of p seem reasonable? What about small gambles?</p>

<p>(b) Suppose $p &gt; 1$ and the person has wealth $w$. Suppose he is offered a gamble in which he loses x or wins y with equal probabilities. Show that he will reject the gamble no matter how large $y$ is if $p &gt;= (log(0.5)+log(1-x/w))/log(1-x/w)$.</p>

<p>I'm not sure where to start with this. Am I solving for the risk premium and multiplying by $w$?</p>

<p>I know that for someone with CRRA utility $u(w)= (1/(1-p))w^(1-p)$ and that an individual will pay $\pi(w)$ to avoid the gamble if $u((1-\pi)w)=E[u(1+\epsilon \tilde)w)]$. But I'm not sure how to apply this information to solve the question.</p>
","<p>Whenever you need to make someone indifferent between $x$ and $y$, it means that</p>

<p>$$U(x) = U(y)$$</p>

<p><strong>a</strong>:</p>

<p>Denote amount he would pay by $z$. Paying $z$ to avoid the lottery gives him ""certain utility"" $u(100.000 - z)$. With Von Neumann-Morgenstern utility as given,<br>
we can denote the lottery utilities as 
$$prob*U(10.000 + x) + (1-Prob)*U(10.000-x)$$ (Understand why we can do that!) </p>

<p><strong>b</strong></p>

<p>Without uncertainty, he will have $u(w)$. Then, you need to compute the utility of the lottery as the function of $p, x,y$.</p>

<p>That is, you need to solve</p>

<p>$$U(100000) = prob*U(w+y) + (1-prob)*U(w-x)$$</p>

<p>Now, I'm not sure whether you were meant to say <em>loses x or wins y</em>, I suppose it is <em>loses x or wins y</em>. Anyhow, the value of the lottery is on the right hand side. Can it ever dominate the left hand side, given the additional information for $p$ that you were told in that subquestion?</p>
","3269"
"Supply/Demand of Smuggling","221","","<p>I am attempting a (very) basic analysis of smuggling from one economy to the other (Venezuela to Colombia) - arising from price ceilings <em>ceteris paribus</em>. e1 are the equilibria without intervention (price controls), e2 are the equilibria after price ceilings, and e3 show what I assume the markets would look like if Venezuelans supplied Colombia (by smuggling) where the Venezuelans' profit = </p>

<p>[Colombia p-hat - cost of smuggling - Venezuela p-hat]</p>

<p>The supply curve for Colombia becomes the sum of the Venezuelan and Colombian supply curves above the [Venezuelan price ceiling + cost of smuggling], while there is a movement <em>along</em> the Venezuelan supply curve to the point of [Colombian price ceiling - cost of smuggling].</p>

<p>Is this correct?</p>

<p>Thanks!
<a href=""https://i.stack.imgur.com/93oyL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/93oyL.png"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/g6kOP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/g6kOP.png"" alt=""S-D Graph""></a></p>
","<p>You can consider a single competitive firm model with quadratic cost function say $c(y) = \frac{y^2}{2}$. This firm is in Venezuela. Let $\hat{p}_c$ and $\hat{p}_v$ be price ceilings in Colombia and Venezuela respectively. Also, $\hat{p}_c &gt; \hat{p}_v$ indicating the opportunity to smuggle. Also, assume demands are sufficiently high so that the ceilings are binding. Consider competitive suppliers' problem without smuggling:</p>

<p>\begin{eqnarray*} \displaystyle\max_{y\geq 0} &amp;&amp; p_vy - \frac{y^2}{2}\end{eqnarray*}
Solving it, we get the supply curve as $y = p_v$.</p>

<p>Given that the price in Venezuela is $\hat{p}_v$, equilibrium quantity in this case will be $y^* = \hat{p}_v$.</p>

<p>With an option to smuggle with the additional cost say $c(z) = \frac{z^2}{2}$, the profit maximization problem is:
\begin{eqnarray*} \displaystyle\max_{y\geq 0, z \geq 0} &amp;&amp; p_vy + p_cz - \frac{(y + z)^2}{2} - \frac{z^2}{2}\end{eqnarray*}</p>

<p>This gives us the new domestic supply function as:
$y = 2p_v - p_c$</p>

<p>and the quantity smuggled as
$z = p_c - p_v$</p>

<p>So, equilibrium quantity sold in Venezuela has fallen to
$y^{**} = 2\hat{p}_v - \hat{p}_c$ and the quantity smuggled is equal to $z^{**} = \hat{p}_c - \hat{p}_v$.</p>
","15173"
"Pesaran's CCEP estimator in eviews","220","","<p>I intend to use Pesaran's (2006) common correlated effects pooled (CCEP) estimator. However, I'm not yet very familiar with advanced econometrics and advanced use of eviews. More specifically I want to estimate this model:
\begin{equation} 
y_{it} = \alpha_{i} + \beta_{1}x_{1,it} + \beta_{2}x_{2,it}+\gamma_{i}F_{t}+\epsilon_{it}
\end{equation} 
in which $F_{t}$ is an unobserved common factor and $\gamma_{i}$ is a country-specific factor loading. We were taught that $F_{t}$ can be proxied by:
\begin{equation}
F_{t}=\frac{(\bar{y_{t}}-\bar{\alpha}-\beta_{1} \bar{x}_{{1,t}} -\beta_{2} \bar{x}_{{2,t}}-\bar{\epsilon}_{{t}})}{\bar{\gamma}},
\end{equation}
in which $\bar{y_{t}} = \frac{1}{N}\sum_{i=1}^{N} y_{it}$, and $\bar{\gamma_{}}=\frac{1}{N}\sum_{i=1}^{N} \gamma_{i}$, with $N$ the number of cross-sections.</p>

<p>Substituting the second equation into the first yields: 
\begin{equation}
y_{it} = \alpha_{i}-\frac{\gamma_{i}}{\bar{\gamma}}+\beta_{1} x_{1,it} +\beta_{2} x_{2,it} +\frac{\gamma_{i}}{\bar{\gamma}}\bar{y_{t}} - \beta_{1} \frac{\gamma_{i}}{\bar{\gamma}} \bar{x}_{1,t} -\beta_{2}\frac{\gamma_{i}}{\bar{\gamma}}\bar{x}_{2,t}+\epsilon_{it}-\frac{\gamma_{i}}{\bar{\gamma}}\bar{\epsilon_{t}}
\end{equation}
or with $\alpha_{i}-\frac{\gamma_{i}}{\bar{\gamma}}=\alpha'_{i}$ and $\frac{\gamma_{i}}{\bar{\gamma}}=\gamma'_{i}$:
\begin{equation}
y_{it} = \alpha'_{i}
+\beta_{1} x_{1,it} 
+\beta_{2} x_{2,it} 
+\gamma'_{i}\bar{y_{t}} 
- \beta_{1} \gamma'_{i} \bar{x}_{1,t}
-\beta_{2}\gamma'_{i}\bar{x}_{2,t}
+\epsilon_{it}-\gamma'_{i}\bar{\epsilon_{t}}.
\end{equation}</p>

<p>To estimate this in eviews, I had the following idea</p>

<p>The cross-sectional averages $\bar{y_{t}}$, $\bar{x}_{{1,t}}$, and $\bar{x}_{{2,t}}$ can be easily calculated from the dataset. I would use cross-sectional fixed effects to estimate all $\alpha'_{i}$. Next, I would need $N$ terms to estimate all $N$ $\gamma'_{i}$. To do this, I would include these $N$ terms: $\gamma'_{A}\bar{y}_{t}dum_{A} + \gamma'_{B}\bar{y}_{t}dum_{B} + ... + \gamma'_{N}\bar{y}_{t}dum_{N}$, in which each capital letter denotes one of the $N$ cross-sections and the dummy variable takes the value of $1$ once for each cross-section. Then, for each averaged explanatory  variable, $\bar{x}_{1t}$ and $\bar{x}_{2t}$, I would include these $2 \times N$ terms: $\beta_{1}\gamma'_{A}\bar{x}_{1,t} + \beta_{1}\gamma'_{B}\bar{x}_{1,t}+ ... + \beta_{1}\gamma'_{N}\bar{x}_{1,t}$ and $\beta_{2}\gamma'_{A}\bar{x}_{2,t} + \beta_{2}\gamma'_{B}\bar{x}_{2,t}+ ... + \beta_{2}\gamma'_{N}\bar{x}_{2,t}$.</p>

<p>So, to sum up, my suggested input for eviews (to estimate with cross-sectional fixed effects) is the following:
<code>y = c(1)*x1 + c(2)*x2 + c(3)*y_avg*dumA + c(4)*y_avg*dumB + c(5)*y_avg*dumC + ... + c(1)*c(3)*x1_avg + c(1)*c(4)*x1_avg + c(1)*c(5)*x1_avg + ... + c(2)*c(3)*x2_avg + c(2)*c(4)*x2_avg + c(2)*c(5)*x2_avg + ....</code>.</p>

<p>In this equation:</p>

<ul>
<li><code>c(1)</code> = $\beta_{1}$;</li>
<li><code>c(2)</code> = $\beta_{2}$;</li>
<li><code>c(3)</code> = $\gamma'_{A}$;</li>
<li><code>c(4)</code> = $\gamma'_{B}$;</li>
<li><code>c(5)</code> = $\gamma'_{C}$.</li>
</ul>

<p>These are my questions regarding this estimation:</p>

<ul>
<li>First of all, confirmation of the correctness of my derivation would be welcome;</li>
<li>Would the estimation in eviews I suggest do the trick?</li>
<li>If so, should I include an intercept in the fixed-effects estimation?</li>
<li>If not, is there an alternative procedure to implement the CCEP estimator in eviews?</li>
<li>The estimated error terms should be $\epsilon-\gamma'_{i}\bar{\epsilon}$, is this structure automatically obtained? Or should this be imposed one way or another?</li>
<li>The same question for $\alpha'_{i}$: it should equal $\alpha_{i}-\frac{\gamma_{i}}{\bar{\gamma}}$. Should this condition be imposed, or is it automatically fulfilled when inputting my suggested input in eviews;</li>
<li>Other suggestions regarding the use of CCEP estimator in eviews are certainly welcome.</li>
</ul>

<p>Any help, also partial answers, is appreciated!</p>
","<p>The technique described in the question is almost correct. Consider a panel data set consisting of three cross-sections ($a$, $b$, and $c$) and three time-periods ($1$, $2$, and $3$). Let <strong>y</strong> denote the column vector with the observations of the dependent variable, <strong>x</strong> the column vector with observations of the first explanatory variable, and <strong>z</strong> the column vector with observations of the second explanatory variable. They take these forms respectively:</p>

<p>$\textbf{y} = 
\begin{bmatrix} y_{a1} \\ y_{a2} \\ y_{a3} \\  y_{b1} \\ y_{b2} \\ y_{b3} \\ y_{c1} \\ y_{c2} \\ y_{c3} \end{bmatrix}$
; $\textbf{x} = \begin{bmatrix} x_{a1} \\ x_{a2} \\ x_{a3} \\  x_{b1} \\ x_{b2} \\ x_{b3} \\ x_{c1} \\ x_{c2} \\ x_{c3} \end{bmatrix}$;  $\textbf{z} = \begin{bmatrix} z_{a1} \\ z_{a2} \\ z_{a3} \\  z_{b1} \\ z_{b2} \\ z_{b3} \\ z_{c1} \\ z_{c2} \\ z_{c3} \end{bmatrix}$.</p>

<p>Let $\bar{y}_{i} = \frac{1}{3}(y_{ai} + y_{bi}+y_{ci})$, with $i = 1, 2, 3$, and equivalently for $x$ and $z$: $\bar{x}_{i} = \frac{1}{3}(x_{ai} + x_{bi}+x_{ci})$ and  $\bar{z}_{i} = \frac{1}{3}(z_{ai} + z_{bi}+z_{ci})$, both for  $i = 1, 2, 3$.</p>

<p>This is the correct way to get the CCEP estimator allowing for one common factor, as in the model described in the question:
\begin{equation*}
\begin{split}
\begin{bmatrix} y_{a1} \\ y_{a2} \\ y_{a3} \\  y_{b1} \\ y_{b2} \\ y_{b3} \\ y_{c1} \\ y_{c2} \\ y_{c3} \end{bmatrix} = \beta_{1} \begin{bmatrix} x_{a1} \\ x_{a2} \\ x_{a3} \\  x_{b1} \\ x_{b2} \\ x_{b3} \\ x_{c1} \\ x_{c2} \\ x_{c3} \end{bmatrix}+\beta_{2}\begin{bmatrix} z_{a1} \\ z_{a2} \\ z_{a3} \\  z_{b1} \\ z_{b2} \\ z_{b3} \\ z_{c1} \\ z_{c2} \\ z_{c3} \end{bmatrix}+
\gamma_{a} \begin{bmatrix} \bar{y}_{1} \\ \bar{y}_{2} \\ \bar{y}_{3} \\  0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}
+\gamma_{b} \begin{bmatrix}  0 \\ 0 \\ 0 \\ \bar{y}_{1} \\ \bar{y}_{2} \\ \bar{y}_{3} \\  0 \\ 0 \\ 0 \end{bmatrix} + 
\gamma_{c}  \begin{bmatrix}  0 \\ 0 \\ 0 \\  0 \\ 0 \\ 0 \\ \bar{y}_{1} \\ \bar{y}_{2} \\ \bar{y}_{3}  \end{bmatrix} \\
- \beta_{1}\gamma_{a} \begin{bmatrix} \bar{x}_{1} \\ \bar{x}_{2} \\ \bar{x}_{3} \\  0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}
- \beta_{1}\gamma_{b}  \begin{bmatrix}  0 \\ 0 \\ 0 \\ \bar{x}_{1} \\ \bar{x}_{2} \\ \bar{x}_{3} \\  0 \\ 0 \\ 0 \end{bmatrix}
-\beta_{1} \gamma_{c} \begin{bmatrix}  0 \\ 0 \\ 0 \\  0 \\ 0 \\ 0 \\ \bar{x}_{1} \\ \bar{x}_{2} \\ \bar{x}_{3}  \end{bmatrix}
-\beta_{2} \gamma_{a}  \begin{bmatrix} \bar{z}_{1} \\ \bar{z}_{2} \\ \bar{z}_{3} \\  0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}
-\beta_{2} \gamma_{b} \begin{bmatrix}  0 \\ 0 \\ 0 \\ \bar{z}_{1} \\ \bar{z}_{2} \\ \bar{z}_{3} \\  0 \\ 0 \\ 0 \end{bmatrix}
-\beta_{2} \gamma_{c} \begin{bmatrix}  0 \\ 0 \\ 0 \\  0 \\ 0 \\ 0 \\ \bar{z}_{1} \\ \bar{z}_{2} \\ \bar{z}_{3}  \end{bmatrix} \\
+ \phi_{a} + \phi_{b} + \phi_{c} + \mu_{it}
\end{split}
\end{equation*}
Here, $\phi_{a},\ \phi_{b},$ and  $\phi_{c}$ are cross-sectional fixed effects and $\mu_{it}$ a well-behaved error-term that does not require any restrictions. </p>

<p>An interesting remark is that if the six $\beta$s that appear together with the $\gamma$s are not restricted to be equal to each other <em>and</em> equal to the first two $\beta$s,   more than one common factor is allowed.</p>
","11122"
"How did Brexit wipe $2 trillion off world markets?","219","","<p>I read here (<a href=""https://www.theguardian.com/business/live/2016/jun/24/global-markets-ftse-pound-uk-leave-eu-brexit-live-updates"">https://www.theguardian.com/business/live/2016/jun/24/global-markets-ftse-pound-uk-leave-eu-brexit-live-updates</a>) and elsewhere that Brexit wiped \$2tr off world markets.</p>

<p>How did that happen?</p>

<p>Is this equivalent to \$2tr worth of a certain good, sinking to the bottom of the ocean?</p>
","<p>Think about it this way:</p>

<p>You own 100 houses on a private island in Italy. These houses could be sold for $1 million each. </p>

<p>All of a sudden, the Italian prime minister outlaws all boats. There is now no way to get onto the island apart from swimming.</p>

<p>Since you can no longer get onto the island by boat, and have to swim, no one wants to live in your houses, and thus no one wants to buy them for \$1 million. Your houses are still quite nice, though, so people instead will offer to buy them for $200,000. </p>

<p>Your houses were originally worth \$100 million in total (that's how much you would have got if you sold them) but are now only worth $20 million. You have 'lost' \$80 million. </p>

<p>In Brexit, instead of houses, we have stocks. These stocks were originally worth a certain amount of money. When Brexit occurred, people no longer wanted to buy or own British things, because they thought that they would be worth less. The total value of British things dropped by $2 trillion. It's important to note that the things are still there (the stocks didn't disappear!) but are simply valued less to investors. </p>
","12524"
"Lessons From Successfully small island economies","219","","<p>What economic and development lessons/strategies can developing Caribbean countries learn from successfully small island nations like Singapore? </p>
","<p>I like this question, in the sense that although it is broad, I think it can be answered concisely and factually.</p>

<p>Singapore and China (from your <a href=""https://economics.stackexchange.com/questions/3386/chinas-prosperity"">previous question</a>) are largely authoritarian countries. So they were both able to exert a lot of government influence over their development programs.  In this respect, they are not similar to Caribbean countries.</p>

<p>However, in other respects, Singapore is a good case analog because it is an island with very few natural resources and a relatively small population with correspondingly small domestic economic prospects.</p>

<p>Here are some pillars that underpinned Singapore's meteoric economic development.</p>

<ol>
<li><p><strong>Create stable and market-friendly government</strong>.  Economic development takes a long time, and it's hard to execute it if government changes frequently.  Also, governments need to be prepared -- over time -- to relinquish control over their economies as they transition to market-based.  Both Singapore and China accomplished this deliberately and in an ordered fashion (moving too quickly can cause chaos...see Russia for example).</p></li>
<li><p><strong>Create stable currency and a good banking system</strong>.  Singapore, like many developing countries, decided to peg its currency to the US dollar, which gave it exchange rate stability and familarity.  Banking systems are crucial to ensuring liquidity and investment for economic growth, so installing a currency board, conservative fiscal policy, a decent bank, and a set of quasi-government commercial banks helped create financial infrastructure from scratch.</p></li>
<li><p><strong>Invest in general economic infrastructure</strong>.  Singapore carefully built out physical infrastructure (roads, communications), legal infrastructure (courts and business law), and talent infrastructure (through schools and workforce training) to reduce economic friction, create economic resources, and maximize economic opportunity for development.</p></li>
<li><p><strong>Seed strategic industries</strong>.  Singapore identified major industries that could help drive economic growth, and used a combination of government subsidies, pro-business laws, and economic protectionism to nurture these industries.  These investments included: making Singapore a low-cost manufacturing hub and a shipping hub (early economic development), and then subsequently a banking and communications hub (later development). </p></li>
<li><p><strong>Assist trade</strong>.  The Singapore government worked closely with private and semi-public enterprises to help push through trade negotiations with countries (US, Japan, China, etc), reduce tariffs, and generally make Singapore an easy location for trade.  This was crucial to expanding the scope of the economy, because with fewer than 4 million people (at the time), the domestic economy could not be sufficient to drive growth.</p></li>
<li><p><strong>Attract foreign direct investment</strong>.  As the economic infrastructure took root, Singapore became an attractive destination for foreign direct investment.  The government assisted with courting and promoting foreign direct investment into the country, which provided investment capital to build out the economy.  Tax and relocation subsidies helped a lot here.</p></li>
</ol>

<p>Not all of these approaches will be applicable to Caribbean countries (e.g. Singapore's location was particularly strategic as a shipping hub), but not all of them need to be replicated in order to create fertile conditions for economic development in the Caribbean.</p>
","3389"
"Relationship between trade deficit and borrowing","218","","<p>I have seen lots of essays saying that trade deficit means the nation needs foreign funds to finance their imports. In other words, they need to borrow from the foreigners. However, it sounds very unintuitive to me. My concern is that why would do they have to borrow? I always thought financing trade deficit was all about transferring the ownership of financial assets. Of course, if you count the sale of financial assets as borrowing, we are good.</p>
","<p>A) You are right! Its not necessarily ""borrowing"". People say that only as way of speaking. You could sell your foreign exchange reserves, or sell other foreign assets, or sell local assets. </p>

<p>B) The first logic of calling it borrowing is that typically, that's what happens, a country's governments or its corporations will indeed borrow from foreign investors. </p>

<p>C) The other logic of calling it borrowing is that typically the foreign investors don't want any asset within the CA deficit country, so they buy local assets expecting to sell them in exchange for dollars later on. In that sense, even the sale of local firm's equity, for example, looks a little bit like borrowing, because the foreign investor will sell it for dollars when he gets a chance.</p>
","12039"
"Are there data for the evolution of global economic inequality","217","","<p>Please excuse my ignorance of economics. I recently learned about the Gini-Coefficient as a measure of the economic inequality in a country. I have since seen several plots of this coefficient over time, each for an individual country. The following is from <a href=""https://www.equalitytrust.org.uk/about-inequality/scale-and-trends"" rel=""nofollow noreferrer"">Equality trust</a> and concerns the UK.
<a href=""https://i.stack.imgur.com/FTdjo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FTdjo.png"" alt=""United Kingdom, Gini over time ""></a></p>

<p>Another plot, concerning various countries, is found <a href=""http://www.worldatnight.ethz.ch/content/images/figure6.11.png"" rel=""nofollow noreferrer"">here</a>:
<a href=""https://i.stack.imgur.com/mdmnF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mdmnF.png"" alt=""enter image description here""></a></p>

<p>At first sight, it appears impossible, to construct such a curve for the entire world. Yet, in discussing extreme poverty,  I recently learned that incomes can be adjusted to equal purchasing power. Naively it seems, one could measure economic inequality globally. So, are there such data concerning the world as a whole? I know there are maps with countries colour coded by Gini, but this is not what I mean.</p>

<p>My interest is not limited to Gini, if there is another measure, by which the global temporal evolution of inequality can be captured, please tell me!</p>
","<p>It is possible, but it involves consiberable work as you need to collect underlying income distributions across the world or to be able to estimate them.</p>

<p>This has been done, for example in a World Bank policy research working paper 6719, <em><a href=""http://documents.worldbank.org/curated/en/914431468162277879/pdf/WPS6719.pdf"" rel=""nofollow noreferrer"">Global Income Distribution From the Fall of the Berlin Wall to the Great Recession</a></em> by Christoph Lakner and Branko Milanovic in December 2013. It included this chart of global income distributions:</p>

<p><a href=""https://i.stack.imgur.com/vYqC9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vYqC9.png"" alt=""Global income distribution""></a></p>

<p>In fact the real story here is the reduction in the number of very-low-income people in absolute terms, especially in countries such as China over 20 years, plus the rise of middle incomes (in a global sense).</p>

<p>It is possible to use this to estimate Gini indices and the paper gives the following estimates: </p>

<ul>
<li>1988: 72.2</li>
<li>1993: 71.9</li>
<li>1998: 71.5</li>
<li>2003: 71.9</li>
<li>2008: 70.5</li>
</ul>

<p>Points to take from these numbers are </p>

<ul>
<li><p>global inequality is wide with a Gini index higher than almost all countries or regions </p></li>
<li><p>the numbers suggest a global reduction in inequality even when inequality had been increasing within most major countries (especially China) </p></li>
<li><p>the reduction has been small and can easily reverse (either in the future or on re-estimation of the past)</p></li>
</ul>

<p>Regional trends and other inequality measures are in Table 3 of the paper, while other people's estimates of a global Gini index are in the Appendix Table 1.</p>
","13308"
"How to show the production function is concave in K and L but not strictly so?","217","","<p>Suppose we have a production function with constant returns to scale. Let us denote it by $F(A,K,L)$ where $A$ is the technology, $K$ the capital and $L$ Labor. Further assume the first partial derivative of $L,K$ are both positive and the second partial negative. How to show the production function is concave in $K$ and $L$ but not strictly so?</p>

<p>This problem is from Acemoglu's Intro to Modern Economic Growth. I don't quite understand what it means to say the function is concave in $K$ and $L$. Do I need to show that $F(K,L)$ (treating A as constant) is concave? or do I show $F(K)$ and $F(L)$ are concave (treating L,A or K,A as constants)?</p>

<p>If it is the latter, it seems the problem seems trivial by the second derivative test.</p>
","<p>So we want the Hessian to be NSD, so we need the PMs to alternate weakly. </p>

<p>$H=\begin{bmatrix} F_{kk} &amp; F_{kl} \\
F_{kl} &amp; F_{ll}
\end{bmatrix}~~NSD \iff~~~F_{kk},F_{ll}\leq0~~~\&amp;~~F_{kk}F_{ll}-F_{kl}^2\geq0$</p>

<p>We are given that $F_{kk},F_{ll}&lt;0$ so we need to figure out the cross partials.</p>

<p>Constant returns to scale implies that we have a homogeneous of degree 1 function: </p>

<p>$F(K,L)=KF_k+LF_l \implies  F_l=KF_{kl}+LF_{ll}+F_l~~ \&amp;~~  F_k=LF_{kl}+KF_{kk}+F_k$</p>

<p>Now we can substitute these equations into the expression for the 2nd PM:</p>

<p>$\big(-\frac{L}{K}F_{kl}\big)\big(-\frac{K}{L}F_{kl}\big)-F_{kl}^2=0~~~~~$
 and we're done. </p>
","13351"
"What if only the government could create money?","217","","<p>If I understand correctly, under the dominant system of fractional reserve banking, many (all?) private banks can create money by lending.  See, for example, <em><a href=""https://economics.stackexchange.com/q/444/332"">Implications of abolishing Fractional Reserve Banking on mortgages and interest rates</a></em>.  So, money created when people (or other entities) go in debt, and destroyed when those debts are paid back.</p>

<p>Some organisations, such as <a href=""http://www.positivemoney.org/"" rel=""nofollow noreferrer"">Positive Money</a>, advocate there would be considerably advantages if we step away from this system, and <em>only the government could create money</em>.  Quoting from <a href=""http://www.positivemoney.org/our-proposals/"" rel=""nofollow noreferrer"">their website</a>:</p>

<blockquote>
  <p>History has shown that when banks have the power to create money, they create too much in the good times, causing financial crises, and then create too little money in the bad times, making recessions and unemployment even worse. They put most of the money that they create into house price bubbles and speculation on financial markets, and only put a small amount into businesses outside the financial sector. We simply don’t think that banks, with all their incentives and need to maximise their profits, can be trusted with something as powerful as the ability to create money. And it’s not enough to regulate them, because regulators have already failed to keep them under control, and there’s no reason why they should get it right this time around. We need to stop banks being able to create money. Instead, we want to see the power to create money transferred to a democratic, accountable and transparent process (...)</p>
</blockquote>

<p>My question:</p>

<p>What would be the consequence if only a single institution, accountable to the national government, had the ability to create money?  Assume that this institution would use a more or less objective set of criteria to determine how much money to create, for example, in order to meet particular targets.</p>

<p><strong>Edit</strong>: A commenter requested more background motivation why this question is specifically about banks.  Allegedly, the system leads to <a href=""http://www.positivemoney.org/issues/house-prices/"" rel=""nofollow noreferrer"">increasing house prices and debts</a>, along with other <a href=""http://www.positivemoney.org/faqs/"" rel=""nofollow noreferrer"">problems</a>.  My question here is <em>not</em> whether the issues that Positive Money are correct in attributing those problems the current system of private banks creating money; regardless of their correctness, my question is, as stated above, what the consequences would be of having only a single government-controlled institute create money. </p>
","<p>When you dig down, this questions is very nearly a duplicate of this:</p>

<p><a href=""https://economics.stackexchange.com/q/444/119"">Implications of abolishing Fractional Reserve Banking on mortgages and interest rates</a></p>

<p>but based on the comments, it seems that the connection isn't obvious.</p>

<p>This question asking about what would happen if only a government institution could create money, but equally you say the proposal is <em>not</em> to have a fixed money supply.  They are, in practice, the same thing.</p>

<p>The central bank makes the money base, M0, and then the banks create the money supply, with some multiplier to this.  In a full reserve system, that multiplier is 1.0, and so the money supply is always equal to the money base.</p>

<p>In your question, we consider having a M0, but also have a state run bank that chooses the money multiplier to some number, that may or may not be 1.0.</p>

<p>From that point on things become almost identical - it doesn't really matter from the point of view of the economy, whether you make M0 ten times larger or smaller, if you offset it with changing multiplier.  It should be the total money supply that matters - the money base never leaves the central bank, and so may be thought of as a ""construct"" onto which the monetary system is hung.  The important point is that the government gets to directly control the money supply.</p>

<p>Before the era of quantitative easing, when a central bank wanted to increase the money supply, they lowered rates and that increased the multiplier.  With quantitative easing, they simply increase M0 and force the money supply up in a 1:1 ratio.  Either works (for a given value of ""work"").</p>

<p>There is, however, one very important difference:</p>

<ul>
<li>With full reserve banking borrowing money is very expensive - it is economically the same as capital</li>
<li>With a state run lending bank, borrowing could be done at any rate the government chooses, including at an economic loss.</li>
</ul>

<p>So, in your system, you could have a state run bank, that effectively subsidises business and/or people's mortgages using money raised from taxes or elsewhere.  This would be like an extreme version of the UK forcing RBS and Lloyds to increase lending.</p>
","6204"
"Preference over lotteries without independence axiom","216","","<p>Suppose a set of $N$ outcomes can be ranked in the following order: $1\succ 2\succsim\cdots\succsim N$. Further, suppose a decision maker has preference over lotteries over these outcomes. Assume the preference over lotteries is rational, continuous, but <em>not necessarily consistent with the independence axiom</em>. </p>

<p><strong>Does it follow that the best lottery in this case is the degenerate lottery $(1,0,\dots,0)$?</strong></p>

<p><strong>What if the independence axiom is <em>violated</em>?</strong></p>
","<p>No, not necessarily. Without the independence axiom (or something else to replace it) there is not much you can infer about the preferences over lotteries if you only know the preferences over outcomes.</p>

<p>For instance, let $p^L_n$ be the probability of outcomes $n \in \{1,\dots, 3\}$. Then preferences  over lotteries $\succeq^*$ represented by the utility function</p>

<p>$$U(L) = p^L_1 + \beta [p^L_2p^L_3],$$</p>

<p>are continuous  and rational, but do not satisfy the independence axiom. For $\beta$ large enough, it is not even the case that $(1,0,0)$ is the best lottery, although $(1,0,0) \succ^* (0,1,0)$ and $(1,0,0) \succ^* (0,0,1)$.</p>

<p>To see why, observe that</p>

<p>$$ U(1,0,0) = 1, $$
$$ U(0,1,0) = 0, $$
$$ U(0,0,1) = 0, $$</p>

<p>However, for $\beta &gt; 4$,</p>

<p>$$ U\left(0,\frac{1}{2},\frac{1}{2}\right) &gt; 1 .$$</p>

<p>Violation of the independence axiom can be seen from the fact that, when $\beta &gt; 4$,</p>

<p>$$ [1,0,0] \succ [0,1,0]  ,$$</p>

<p>although</p>

<p>$$ \left[0,\frac{1}{2},\frac{1}{2}\right] \succ \left[ \frac{1}{2}, 0, \frac{1}{2}\right]. $$ </p>
","488"
"What to do for missing points in CPI time series?","216","","<p>I am looking at CPI datasets for developing countries which have gaps in them. </p>

<p>For each country I have two time-series with annual averages for years 2000-2013: i) General/Overall CPI and ii) Food CPI. I'm also assuming that Food CPI must have some relationship with the General/Overall CPI since the Food category has its own weight in the General CPI.</p>

<p>Now, I have two types of cases, some such as: <a href=""https://imgur.com/a/9z7o8#1"" rel=""nofollow noreferrer"">http://imgur.com/a/9z7o8#1</a> where gaps are between values. I'm assuming I can interpolate here, if so, how would I go forward with this? I also have to deal with more complicated cases such as: <a href=""https://imgur.com/a/9z7o8#0"" rel=""nofollow noreferrer"">http://imgur.com/a/9z7o8#0</a>, any suggestions in this case? Would a simple extrapolation even make sense here?</p>

<p>An option for my first case that I read (on BLS) is taking the geometric mean of the year immediately before and after of the missing value. Other people have suggested I should predict the missing values by a simple regression model of the CPI on the GDP deflator for that year (which I do have). </p>

<p>Also, in some cases, gaps in annual averages exist because the monthly data needed to calculate these averages is incomplete. So say I only have 2006 data for Russia for months Jan-June, then the annual average data point is missing in the data series. I assume I can just take a simple average of the available months and impute that for 2006? </p>

<p>Thanks in advance</p>
","<p><a href=""http://rads.stackoverflow.com/amzn/click/0471183865"" rel=""nofollow"">Statistical Analysis with Missing Data by Little and Rubin</a> is the go-to reference for working with missing data, at least if nothing state of the art is required. In general, this is a complex problem that remains an area of active research. The relatively easy cases are when the data is <a href=""http://missingdata.lshtm.ac.uk/index.php?option=com_content&amp;view=article&amp;id=75:missing-completely-at-random-mcar&amp;catid=40:missingness-mechanisms&amp;Itemid=96"" rel=""nofollow"">missing-completely-at-random</a> or <a href=""http://missingdata.lshtm.ac.uk/index.php?option=com_content&amp;view=article&amp;id=76:missing-at-random-mar&amp;catid=40:missingness-mechanisms&amp;Itemid=96"" rel=""nofollow"">missing-at-random</a>. Even among the most basic single imputation methods you have a lot of choices (list from Little and Rubin):</p>

<ol>
<li>Mean imputation (replace with mean values)</li>
<li>Regression imputation</li>
<li>Stochastic regression imputation</li>
<li>Hot deck imputation (substitute individual values drawn from ""similar"" response units)</li>
<li>Substitution (not relevant in your context)</li>
<li>Cold deck imputation (replace missing value with constant value from external source like last value)</li>
<li>Composites of the above methods </li>
</ol>

<p>However, if all the the general price level is what's of interest and not the dynamics of the price level (e.g. because you want a deflator instead of studying inflation dynamics) linear interpolation / extrapolation may be just fine. Fundamentally, since deflation is rare, if prices are 100 at time t and 110 at t+2, realistically prices at t+1 are going to be somewhere in $[100,110]$ and lots of models can get you there.  </p>

<p>You can check the within and out of sample prediction quality to asses if your method is a good predictor of the missing prices. Within sample testing could be as simple as asking if the $R^2$ is high of predictive model. Obviously you can do much richer analysis than that. For out of sample testing, consider splitting the sample and calibrating the model only on the first half of the data, then evaluating prediction quality on the second half of the data. </p>
","3114"
"Anscombe-Aumann Acts and Lotteries","215","","<p>Notation: Throughout I will let $\Delta X$ denote the set of probability distributions over the set $X$.</p>

<p>I have been studying expected utility theory, and especially Savage Acts and Anscombe-Aumann Acts. However I am new to it and am not sure if I have the terminology correct.</p>

<p>Let $S$ be the finite set of possible states, let $Z$ be the set of possible outcomes. An Anscombe-Aumann act is defined as a function $f:S \to \Delta Z$. Let the space of acts be denoted $X$. Preferences are defined over acts.</p>

<p>If preferences have a state independent expected utility representation (SIEU) we have that there is a function $u: Z \to \mathbb{R}$ and a distribution over states $p \in \Delta S$ such that for any two acts $f,g \in X$,  $$f \precsim g \iff  \sum_{s \in S} p(s) \sum_{z \in Z} u(z) f(s,z) \leq \sum_{s \in S} p(s) \sum_{z \in Z} u(z) g(s,z)$$</p>

<p>Suppose I want to define a lottery $L \in \Delta Z$ in this situation. For simplicity, suppose $L$ is the lottery that assigns probability $1$ to outcome $z^{*}$ and probability $0$ to all other outcomes. </p>

<p>My Question is: Is this lottery (or any lottery for that matter) a compound lottery first over states ($p$) and then over anscombe -aumann acts ($f$)? Or how is a lottery defined in this situation?</p>

<p>Let me know if any clarification is required. </p>
","<p>You are right, but to make sure that the odds are really exogenous (""objective"") you need to make sure that the subjective uncertainty has no bite here. In other words, you need to assume that the objective lottery played after the horse race is independent of the result of the horse race (in Anscombe-Aumann's terminology). </p>

<p>Let's assume that $Z$ is finite, $Z=\{z_1,\cdots,z_n\}$ and that $L$ is the objective lottery that puts weight $l_i$ on the prize $z_i$, with $l_i \geq 0$ and $\sum_{i=1}^{n}{l_i}=1$.</p>

<p>You can identify the lottery $L$ with the act $f:s \rightarrow \Delta Z$ such that $f(s)=L$ for any $s \in S$. That is, for any $s \in S$, $f(s)$ is the objective lottery that puts weight $l_i$ on the prize $z_i$, exactly as $L$ does.</p>
","8752"
"Financial investment in the composition of GDP","215","","<p>In the production function <strong><em>Y = C + I + G + NX</em></strong></p>

<p>Does foreign investment in domestic assets (<em>i.e. foreign buying of domestic bonds</em>) - and vice versa - come under the Net Exports variable? Which denotation does domestic investment in domestic assets come under? The Investment variable (I), one would think, however I seem to recall being told that the Investment variable does not include financial investment, so does it come under saving?</p>
","<p>What you're describing is a change in the <a href=""https://en.wikipedia.org/wiki/Capital_account"">capital account</a>, not in GDP. They're related through the <a href=""https://en.wikipedia.org/wiki/Balance_of_payments"">balance of payments</a>, in that if a country is running a <a href=""https://en.wikipedia.org/wiki/Current_account"">current account</a> deficit (usually arising through being a net importer), they'll have a capital account surplus (i.e., foreigners will on net buy more domestic assets or domestic owners will be net sellers of foreign assets, or both), and vice-versa. So if you take foreign investment in domestic assets for example, it'll be <em>associated</em> with being a net importer, but it <em>does not appear directly</em> in the national accounting identity $Y=C+I+G+NX$.</p>
","5106"
"What does the Federal Reserve intend to do with bonds it has purchased under QE?","215","","<p>In <a href=""http://nymag.com/daily/intelligencer/2015/12/big-short-genius-says-another-crisis-is-coming.html"" rel=""nofollow"">New York Magazine's interview</a> with investor Mike Burry (made famous by The Big Short), he claims Quantitative Easing has left the Federal Reserve with an extraordinarily high leverage ratio:</p>

<blockquote>
  <p>What makes you most nervous about the future?</p>
  
  <p>Debt. The idea that growth will remedy our debts is so addictive for politicians, but the citizens end up paying the price. The public sector has really stepped up as a consumer of debt. <strong>The Federal Reserve’s balance sheet is leveraged 77:1</strong>. Like I said, the absurdity, it just befuddles me.</p>
</blockquote>

<p>What are numerator and denominator in that leverage ratio? What are the Fed's options for what to do with all of the assets it has purchased? Is it even clear what it intends to do?</p>
","<p>The leverage ratio, as always, is a ratio between liabilities and equity. It has really no significance, as the liabilities of the Fed, which are mostly dollars, need not to ever be paid back.</p>

<p>Only in the case of inflation would the Fed need to reduce its balance sheet (i.e., sell the public debt or MBS). Do note that the profit of the Fed goes back to the government, thus the debt that is sitting there is an asset and liability of the government at the same time, canceling out. That is, the net debt decreases as the Fed buys bonds from the market. You may also view it as inflation or a money tax that pays back the debt.</p>
","9997"
"What happens to Fed's balance sheet when its asset shrink in value?","215","","<p>What happens to Fed's balance sheet when its asset shrink in value? I noticed that Fed's balance sheet is special because I do not see any O.E. category (correct me if I am wrong). Suppsoe Fed's subprime MBS shrink in vlaue, its asset is decreased, but its liability doesn't (correct me if I am wrong), so it has an inbalance between A and L. If no O.E. is there, how can this be?</p>

<p>Also, Prof. Robert Shiller's ""The Subprime Solution"" says ""if losses on collateral [during the crisis] mean that there are not enough funds to cover the defaulted loans, this will be reflected by the Fed paying less to the federal government, hence ultimately higher taxes for individuals."" What does Prof. Shiller mean when he says not enough funds to cover the the defaulted loans and what does he mean by funds? What funds exactly? I mean, Fed has the ability to create reserve so how can there be not enough funds? One last question is why is the Fed paying the federal governemnt? I have never heard of Fed needing to pay the governemnt, shouldn't it be the governemnt pay the Fed due to the marturing of the T-bills and etc?</p>
","<p>When the Fed issues say 100k in liabilities (paper dollars) to buy 100k in assets (t-bills), then they will at the end of the year take their revenue from their assets, subtract their expenses and remit the profits to congress.  This is an obscure process but it does exist.  If you see a congressional budget, you'll see an item marked as miscellaneous revenue...this is a portion of if that.  Now they do not remit as much as they should but that is another story.</p>

<p>If the Fed had to write off say 50k in bad debt, then that would count against their income for their year (and mean they earned 50k less).  The 50k would actually be debited away from equity and not liabilities.</p>

<p>The Fed (that I know of), does not issue money directly to itself nor the treasury.  It can create money to buy investments...and then spend the profits from investments on their own expenses.  It can also sell equities for a profit (rarely done) to boost their equity.</p>

<p>A good question is what would happen if the Fed had to write off more in assets than they had in equity.  I doubt they would shrink the monetary base to balance the books, but instead would fabricate an asset to keep the illusion going (like say a 'good will from the treasury').</p>
","9363"
"Why does a stronger currency have a tightening effect on economic conditions?","215","","<p><a href=""http://www.economist.com/blogs/buttonwood/2015/12/central-bank-predictability"" rel=""nofollow"">http://www.economist.com/blogs/buttonwood/2015/12/central-bank-predictability</a></p>

<blockquote>
  <p>Ever since 1987, banks have been willing to cut rates when markets
  have wobbled. Driving down bond yields has been an explicit aim of QE
  (and pushing up stockmarkets an implicit one). Currencies move in
  anticipation of interest rate divergence (hence the strength of the
  dollar this year) and <strong>a stronger/weaker currency has a
  tightening/easing effect on economic conditions</strong>.</p>
</blockquote>

<p>A related question is what exactly is meant by tightening effect on economic conditions. This term is meant loosely in financial media and I do not know exactly what it means.</p>
","<p>Tight monetary policy reduces the amount of money available in the economy and strengthens the currency. It is usually implemented by raising interest rates, increasing capital requirements for banks, or sometimes selling government bonds.</p>

<p>When there is less money and credit to go around, business activity slows down, economic growth slows down. Businesses that could have expanded by taking out loans do not do so; consumers who could have purchased more with their credit cards can't do so; investors who could have invested more money into businesses (equities) put the money into government bonds.</p>
","9630"
"Is money capital?","213","","<p>The <a href=""http://www.oed.com/view/Entry/27450?rskey=oHaS0u&amp;result=2&amp;isAdvanced=false#eid10137661"" rel=""nofollow""><em>Oxford English Dictionary</em></a> defines ""capital"" as</p>

<blockquote>
  <p>n. economic goods (e.g. railways, ships, machinery, buildings) destined for use in production (as opposed to <em>consumers' goods</em>).</p>
</blockquote>

<p>Historically, the first use of money has been to facilitate trade. According to <a href=""https://archive.org/stream/MN5034ucmf_1#page/n343/mode/2up"" rel=""nofollow"">this</a>, it was only in the past few centuries that money has also been considered capital, and thus capitalists buy and sell money as though it were a productive economic good. Why is this?</p>

<p>How can money be capital? How does money have productive value when money simply facilitates trade? Certainly trade is useful, but is trade productive? Are there contemporary or historical economists who argue money can or cannot be capital?</p>
","<p>Knut Wicksell, author of <em><a href=""https://mises.org/library/interest-and-prices"" rel=""nofollow"">Interest &amp; Prices</a></em>, argues that money ≠ capital:<br><sup>(quoted on p. 8 of Bernard W. Dempsey's <em><a href=""https://isidore.co/calibre/browse/book/5277"" rel=""nofollow"">Interest &amp; Usury</a></em>)</sup></p>

<blockquote>
  <p>It is usually said that in modern communities, capital (of the mobile kind) is lent <em>in the form of money</em>. But this is a metaphorical and inexact manner of speaking which can easily lead to error. Liquid capital, which is what we are considering, or, in other words, goods, are never lent,—they are never given and taken by way of borrowing; they are simply bought and sold.⁵</p>
</blockquote>

<p>and</p>

<blockquote>
  <p>It is not true that ""money is only one form of capital,"" that the lending of money constitutes a lending of real capital in the form of money, etc.…</p>
  
  <p>Liquid real capital (<em>i.e.</em>, goods) are never lent (not even in a system of simple merchandise credit); it is money which is lent and the commodity capital is then <em>sold in exchange for this money</em>.⁶</p>
</blockquote>

<p>and 7 Lectures, II, p. 190.:</p>

<blockquote>
  <p>Money does not enter into the processes of production; it is in itself, as Aristotle showed [in <a href=""https://ebooks.adelaide.edu.au/a/aristotle/a8po/book1.html"" rel=""nofollow""><em>Politics</em> bk. 1</a> § 10, 1258a-b], quite sterile.⁷</p>
</blockquote>
","11402"
"Cointegration test in Stata","212","","<p>I am doing a Engle-Granger test for cointegration and I am unsure about some commands.</p>

<p>""Cointegration and the ECM"" (document) from learneconometric.com says I should use:</p>

<pre><code>regress b f
predict ehat, residual
regress D.ehat L.ehat L.D.ehat, noconstant
</code></pre>

<p>However, ""Time series"" (document from Princeton Uni) says I should use:</p>

<pre><code>regress b f
predict ehat, resid
dfuller ehat, lags(10)
</code></pre>

<p>So I am unsure about the last commands here. Should I use <code>regress D.ehat L.ehat L.D.ehat, noconstant</code> or <code>dfuller ehat, lags(10)</code> and what is the difference here? Also, how many ""lags"" should I include for the Dickey Fuller test?</p>
","<p>Do the last one, the first one is just the same thing but you will not be using the in-built adf function. The second one does it better and you have a choice of including lagged differences to control for possible autocorrelation. If your data is monthly, give it a lag order of 12. </p>
","12046"
"Conventional Monetary Policy and Income Inequality","212","","<p>In almost every textbook, it's stated that monetary policy is preferred to fiscal policy, since the latter is more politically difficult to implement due to smaller consensus on its redistributive effects. Monetary policy would not suffer, since it has no redistribution effect.</p>

<p>Has any empirical study ever tried to verify/assess this claim that Monetary Policy has not redistribution effect?</p>
","<p>Well, certainly you'll see literature saying it is possible to <em>make</em> monetary redistributive. This paper by <em>Brunnermeier and Sannikov</em> (2012), <a href=""http://dc-20788-1635065795.us-east-1.elb.amazonaws.com/system/files/research/documents/brunnermeier_redistributive_monetary_policy.pdf"" rel=""nofollow""><strong>Redistributive Monetary Policy</strong></a>, says that deflation can cause redistributive effects in an economy, and that monetary policy can be used to correct that, but ""shouldn't"" be used as a redistributive tool beyond that correction.</p>

<blockquote>
  <p>In general, conventional monetary policy focuses primarily on the short end of the yield curve. Expectations about future policy indirectly affect the long end of the yield curve. Unconventional monetary policy directly targets the long end of the yield curve and prices of specific assets. All these measures can redistribute wealth across and within sectors.</p>
</blockquote>

<p>Notice how they emphasize the unusual nature of monetary policy meant to create (anti-)redistribution.</p>

<p>This paper by <em>Faust</em> (1996), <a href=""http://www.sciencedirect.com/science/article/pii/S0304393296900379"" rel=""nofollow""><strong>Whom can we trust to run the Fed? Theoretical support for the founders' views</strong></a>, shows that while generally any policy that affects inflation will create redistributive effects, it's better that the Federal Reserve control monetary policy to mitigate those effects rather than let policy be determined by voting, because of conflicts of interest that can arise from voting.</p>

<p>The final paper I'd like to present is by <em>Romer and Romer</em> (1998). Their main findings in their paper, <strong><a href=""http://www.nber.org/papers/w6793"" rel=""nofollow"">Monetary Policy and the Well-Being of the Poor</a></strong>, is that expansionary monetary policy is better for the poor in the short run, but less so in the long run. Low inflation and stable aggregate demand growth is better for the long run, and that usually means tighter monetary policy.</p>

<hr>

<p>So it seems that monetary policy can be redistributive very easily. Also consider that <a href=""http://www.sciencedirect.com/science/article/pii/S1574004899100399"" rel=""nofollow"">optimal monetary policy usually wishes for the nominal interest rate to be close to zero</a>. What does that do for capital owners who want to borrow for investments? How does <em>that</em> change long run growth and affect income inequality? Characterizing that can be a bit nebulous.</p>
","12581"
"Value added by sector of economic activity","212","","<p>I am trying to make a pie chart of value added by economic activity (as a % of gdp). I am trying to use data from world bank for each of the four sectors: manufacturing, agriculture, industry, services <a href=""http://data.worldbank.org/indicator/NV.IND.TOTL.ZS?display=default"" rel=""nofollow"">http://data.worldbank.org/indicator/NV.IND.TOTL.ZS?display=default</a> , but surprisingly the percentage share for each of those sectors, for one country do not add up to 100 but to 120. Why is that?</p>
","<p>The first line of your World Bank link gives you the explanation:</p>

<blockquote>
  <p>Industry corresponds to ISIC divisions 10-45 and includes
  manufacturing (ISIC divisions 15-37)</p>
</blockquote>

<p>Hence, if you add up industry and manufacturing you count some activities twice, the divisions 15-37 that is.</p>

<p>But even if you take this into account you should not find 100% if you are adding up the value added of all the activities. Gross domestic product (GDP) is not the sum of the gross value added (GVA) of all the activities but:</p>

<blockquote>
  <p>GDP = GVA + Taxes on products - Subsidies on products</p>
</blockquote>

<p>According to <a href=""http://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Gross_value_added_at_market_prices"" rel=""nofollow"">Statistics Explained</a></p>

<blockquote>
  <p>Gross value added of the total economy usually accounts for more than
  90 % of GDP</p>
</blockquote>

<p>So, the message is to check carefully the definitions and concepts used by the World Bank. </p>
","5329"
"Which regression technique is used for calculating price elasticity in practice","212","","<p>Since we need to consider 'Endogeneity' between price and quantity while calculating price elasticity and since linear regression cannot handle the phenomenon of endogeneity if objective of the model is to find causality, instrumental variable regression is used. </p>

<p>Since theory backs the idea of using IV regression, does this happens in real world? I mean corporations and governments use IV regression for price elasticity or do they use linear regression despite it's shortcomings in it's inablity to handle endogeneity?</p>
","<p>They use all types of methods. </p>

<p>Often, papers will use a very basic linear regression model and submit to a low prestige journal so one can justify ones grant and boost the H index as much as possible when meta analyses cite your article to clean up the mess.</p>

<p>It's up to the meta analysis to take into account that not all models have correct methodology and create a meta-analytical model to correct for all these inaccuracies. </p>

<p>Fortunately, there are sometimes dynamic lag models and the like to compare to and guess at an appropriate correction term for the others. </p>

<p>Here is an example for gas prices.</p>

<p><a href=""https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;url=http://papers.tinbergen.nl/06106.pdf&amp;ved=0ahUKEwia2Me-85LLAhUUzmMKHWvjAd0QFgghMAE&amp;usg=AFQjCNHi6RH_xX7h9NLPcVRCFAMP0OtERQ&amp;sig2=3ChFSPGwukN_WC4IlhitGA"" rel=""nofollow"">https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;url=http://papers.tinbergen.nl/06106.pdf&amp;ved=0ahUKEwia2Me-85LLAhUUzmMKHWvjAd0QFgghMAE&amp;usg=AFQjCNHi6RH_xX7h9NLPcVRCFAMP0OtERQ&amp;sig2=3ChFSPGwukN_WC4IlhitGA</a></p>

<p>Edit: A meta analytic model is a model to explain why studies obtained the results that they did. Different samples, methodologies, and so forth will produce different results, and a metamodel expresses this formally.</p>

<p>A dynamic lag model (also called a distributed lag model) is a model to predict the current value of a dependent variable based on past values of independent variables. For example, if a change in price causes a change in demand, you can model this by correlating price at time t-1 to demand at time t.</p>
","10854"
"Why Nobel prize winners studied economics?","212","","<p>Recently I have read a great article about  <a href=""https://www.washingtonpost.com/business/the-smartest-economist-youve-never-heard-of/2015/10/02/8659bcf2-6786-11e5-8325-a42b5a459b1e_story.html"" rel=""nofollow noreferrer"">Olivier Blanchard</a> and I wonder why he has chosen to dedicate his life to study economics? Moreover he managed to do a research in several subfields, which is very impressive. </p>

<p>In the article we can find a quote:</p>

<blockquote>
  <p>Also at Nanterre, he developed a fascination with economics and the ways in which it could be used to make the world a better place</p>
</blockquote>

<p>Is there any good book or an article which explain why Nobel prize winners chose to study economics? How did they get passionate about economics? </p>
","<p>The Nobel Prize website is a good source of information. On <a href=""https://www.nobelprize.org/nobel_prizes/economic-sciences/laureates/"">the economics prize page</a> they have a link to a page for each laureate. From there you can find, in particular, a biography for each prize winner where the laureates often talk about the genesis of their interest in economics. </p>

<p>For example, <a href=""https://www.nobelprize.org/nobel_prizes/economic-sciences/laureates/2007/maskin-bio.html"">Eric Maskin writes</a></p>

<blockquote>
  <p>I became a math major at Harvard College, where I studied algebra with Pierre Samuel and Richard Brauer and analysis with George Mackey and Lars Ahlfors − all of them inspiring, some of them amusingly eccentric. Almost by accident, I wandered at one point into a course on ""information economics"" taught by Kenneth Arrow, later my Ph.D. advisor. The course was a hodgepodge of topics from the frontier of economic theory, but a good part of it was devoted to Leonid Hurwicz's work in the nascent field of mechanism design. This work was a revelation to me: it had the precision, rigor, and sometimes the beauty of pure mathematics and also addressed problems of real social importance − an irresistible combination.</p>
  
  <p>In fact, I ended up essentially doing an economics Ph.D. The degree was nominally in applied mathematics. But the applied math program at Harvard in those days was remarkably flexible, and allowed students to study whatever they wanted, as long as they wrote a thesis with ""significant mathematical content."" I took quite a few economics courses (although none, I regretted later, in macroeconomics or economic history), including Truman Bewley's general equilibrium course, where I first got to work with my classmate and later co-Laureate Roger Myerson (we sometimes tackled the rather demanding problem sets together) and Jerry Green's analytic seminar, whose student participants included Elhanan Helpman, Bob Cooter, and Jean-Jacques Laffont.</p>
  
  <p>As an advisor, Ken Arrow was amazingly generous with his time; and I learned an immense amount from our many one-on-one discussions in his office.</p>
</blockquote>
","14344"
"Game theory: Textbooks","211","","<p>I am really a beginner guy in game theory. </p>

<p>Which kind of books could you suggest me as beginner/intermediate/advanced textbooks in game theory ? 
I have no problem in maths, so any books with full of maths are ok for me. </p>

<p>As I don't really know so much about this tool, I can not evaluate which book fits well to my situation.</p>
","<p>My suggestions:</p>

<ul>
<li><p>the best ever written advanced book on game theory is 'Game Theory' by Fudenberg and Tirole: it deals with a lot of material used in research and many applications. When you work on a game theory paper and, for instance, u'r unsure about what kind of equilibrium applies to your case, the book will save your life. It's a bible</p></li>
<li><p>but if you want to get inside the game theory world, learn about what kind of problems game theory is able to deal wth, or even getting some interesting ideas to work on your own, after learning the necessary tools..in these cases I strongly suggests to use <strong>'Game theory evolving' by Herbert Gintis</strong>. He was my professor at the PhD, and I appreciated his ability as educator (other than a researcher)</p></li>
</ul>

<p>I hope you'll find it useful.
Enjoy!</p>
","6192"
"Ricardo's theory of comparative advantage","211","","<p>The aim of this question is to better explore the mathematical economics model behind Ricardo's theory of comparative advantage and the claims that can be made based on this model. This seems necessary because of <a href=""https://economics.stackexchange.com/questions/8290/ricardos-theory-of-comparative-advantage-for-many-countries"">this question</a> and some of the answers given to it. Following is a description of the model as I understand it.</p>

<p>Suppose there are two countries (England and Portugal, denoted by E and P) producing two goods (good x and good y). The only input needed to produce these goods is labor. The economics of scale are constant in both industries of both countries and the labor requirement to produce good $m$ (where $m \in \left\{x,y\right\}$) in country $i$ is denoted by $a_{m,i}$. Without loss of generality I will assume that England enjoys comparative advantage in producing the good $x$, meaning
$$
\frac{a_{x,E}}{a_{y,E}} &lt; \frac{a_{x,P}}{a_{y,P}}.
$$
Let us denote the size of the English labor pool by $L_E$, that of the Portuguese by $L_P$. Denote the produced quantities by $\left(q_{x,E},q_{y,E}\right), \left(q_{x,P},q_{y,P}\right)$. So England may choose any production $\left(q_{x,E},q_{y,E}\right)$ as long as
$$
q_{x,E} \cdot a_{x,E} + q_{y,E} \cdot a_{y,E} \leq L_E.
$$
The income of a country is determined by the value of its production. Denote the equilibrium prices by $p_x, p_y$.</p>

<p>Now follow some assumptions that do result in some loss of generality, but I think these are necessary for simple illustrations. <br>
Assume that the English public's consumption (denoted by $c_{m,E}$) preferences of said goods, $\left(c_{x,E},c_{y,E}\right)$, are described by symmetric a Cobb-Douglas utility function. Assume the same for Portugal, where Portuguese consumption is denoted by $\left(c_{x,P},c_{y,P}\right)$.</p>

<p>A discussion of how England can maximize her profit is probably useful, but I seek to focus on the following claims and whether they are true given this model:</p>

<ol>
<li>England will always produce good $x$ (in some positive quantity).</li>
<li>England will never produce good $y$.</li>
<li>England will never export good $y$.</li>
</ol>

<hr>

<p>In case you are wondering: No, this is not a homework question. But because you do not have to take my word for this I tried to phrase the question in accordance with the current <a href=""https://economics.meta.stackexchange.com/questions/1420/an-alternative-suggestion-regarding-homework-questions"">guidelines</a> for exercises.</p>
","<p>The solution concept used in Ricardo's modell is the competitive equilibrium. Let the set of countries $N$ be defined as $N = \left\{E,P\right\}.$ (England, Portugal) Then the competitive equilibrium is a vector
$$
\left(p,\left(q_{x,i},q_{y,i}\right)_{i\in N},\left(c_{x,i},c_{y,i}\right)_{i\in N}\right),
$$
where $p$ is the equilibrium price ratio of the goods $x$ and $y$, so $p = \frac{p_x}{p_y}$, and $\left(q_{x,i},q_{y,i}\right)$ and $\left(c_{x,i},c_{y,i}\right)$ are the production and consumption vectors of country $i$. The equilibrium vector has the following properties:</p>

<ol>
<li>Profit maximization: <br>
Each country choose a production that maximizes her profit given her production capabilites and the equilibrium price ratio. The set of possible production vectors $T_i$ is defined by the size of the countries labor pool $L_i$ and the labor requirements $a_{x,i},a_{y,i}$ as defined in the question
$$
q_{x,i} \cdot a_{x,i} + q_{y,i} \cdot a_{y,i} \leq L_i.
$$
A production vector $\left(q_x^i,q_y^i\right)$ is profit maximizing if
$$
\max\limits_{(x,y)\in T_i} p \cdot x + y = p \cdot q_{x,i} + q_{y,i}.
$$</li>
<li>Utility (welfare) maximization: <br>
The vector $(c_{x,i},c_{y,i})$ maximizes country $i$'s utility if
$$
\max\limits_{p \cdot x + y \leq p \cdot q_{x,i} + q_{y,i}} U_i(x,y) = U_i(c_{x,i},c_{y,i}).
$$</li>
<li>The good markets are in equilibrium, i.e. in the market of each good demand equals supply (technically only the values are equal, but here, i.e. with Cobb-Douglas preferences, prices are always positive in equilibrium, so there is no difference). The equations for these are
$$
\sum\limits_{i\in N} q_x^i = \sum\limits_{i\in N} c_x^i \hskip 20pt \sum\limits_{i\in N} q_y^i = \sum\limits_{i\in N} c_y^i.
$$</li>
</ol>

<p>Let us examine what these properties imply. The set $T_i$ is a triangle. As goods have positive value in equilibrium so all the labor is used up and the production vector is chosen from the production possibility frontier. Which industry ($x$ or $y$) can employ labor more lucratively? In industry $x$ a unit of labor produces value $\frac{p_x}{a_{x,i}}$. Similarly the value produced in industry $y$ is $\frac{p_y}{a_{y,i}}$. If $\frac{p_x}{a_{x,i}} &gt; \frac{p_y}{a_{y,i}}$ only good $x$ is produced, if $\frac{p_x}{a_{x,i}} &lt; \frac{p_y}{a_{y,i}}$ only good $y$ is produced, if $\frac{p_x}{a_{x,i}} = \frac{p_y}{a_{y,i}}$ it does not matter how labor is allocated among the industries as long as all labor is used. So the profit maximizating quantities are
$$
\left(q_{x,i},q_{y,i}\right) = \left\{
\begin{array}{cc}
\left(\frac{L_i}{a_{x,i}},0\right) &amp; \frac{a_{x,i}}{a_{y,i}} &lt; p \\
\alpha \cdot \left(\frac{L_i}{a_{x,i}},0\right) + (1 - \alpha)  \cdot \left(0,\frac{L_i}{a_{y,i}}\right)
 &amp; \frac{a_{x,i}}{a_{y,i}} = p \\
\left(0,\frac{L_i}{a_{y,i}}\right) &amp; \frac{a_{x,i}}{a_{y,i}} &gt; p. 
\end{array}
\right.
$$
The optimum condition for the utility maximization problem is
$$
MRS_i(c_{x,i},c_{y,i}) = \frac{c_{y,i}}{c_{x,i}} = p.
$$
Because the utility functions in England and Portugal have the same form we can take this further. From
$$
\frac{c_y^A}{c_x^A} = p = \frac{c_y^P}{c_x^P}.
$$
we get
$$
\frac{c_{y,A}}{c_{x,A}} = p = \frac{c_{y,P}}{c_{x,P}}.
$$
we get
$$
c_{y,P}  = \frac{c_{y,A}}{c_{x,A}} \cdot c_{x,P}.
$$
Using this
$$
\frac{c_{y,A}+c_{y,P}}{c_{x,A}+c_{x,P}} = \frac{c_{y,A}+\frac{c_{y,A}}{c_{x,A}} \cdot c_{x,P}}{c_{x,A}+c_{x,P}} =  \frac{c_{x,A}}{c_{x,A}} \cdot \frac{c_{y,A}+\frac{c_{y,A}}{c_{x,A}} \cdot c_{x,P}}{c_{x,A}+c_{x,P}} =
\frac{c_{y,A} \cdot c_{x,A} + c_{y,A} \cdot c_{x,P}}{c_{x,A} \cdot \left(c_{x,A}+c_{x,P}\right)}.
$$
so
$$
\frac{c_{y,A}+c_{y,P}}{c_{x,A}+c_{x,P}} = \frac{c_{y,A} \cdot c_{x,A} + c_{y,A} \cdot c_{x,P}}{c_{x,A} \cdot \left(c_{x,A}+c_{x,P}\right)} = \frac{c_{y,A}}{c_{x,A}} = p.
$$
What this says is that the relative demand ($\frac{c_{y,i}}{c_{x,i}}$) is not only equal to the price ratio for individual countries but also the relative aggregate world demand is equal to the price ratio. (Again, this is only true if the individual countries have Cobb-Douglas utility functions with identical parameters.) We now have a relatively easy way to find the equilibrium price ratio: we calculate relative aggregate supply. As aggregate supply equals aggregate demand in equilibrium, relative aggregate supply will equal relative aggregate demand, and as we have just shown it will also equal $p$. We get relative supply from the profit maximizing productions of the individual countries. Let us first discuss the aggregate of the profit maximizing productions, which I will denote by $(q_x,q_y)$. So $(q_x,q_y) = (q_{x,E} + q_{x,P},q_{y,E} + q_{y,P})$ which means
$$
(q_x,q_y) = \left\{
\begin{array}{cc}
\left(\frac{L_E}{a_{x,E}} + \frac{L_P}{a_{x,P}},0\right) &amp; \frac{a_{x,E}}{a_{y,E}} &lt; \frac{a_{x,P}}{a_{y,P}} &lt; p \\
\left(\frac{L_E}{a_{x,E}} + \alpha \cdot \frac{L_P}{a_{x,P}} , (1 - \alpha) \cdot \frac{L_P}{a_{y,P}} \right) &amp; \frac{a_{x,E}}{a_{y,E}} &lt; p = \frac{a_{x,P}}{a_{y,P}} \\
\left(\frac{L_E}{a_{x,E}} , \frac{L_P}{a_{y,P}} \right) &amp; \frac{a_{x,E}}{a_{y,E}} &lt; p &lt; \frac{a_{x,P}}{a_{y,P}} \\
\left(\alpha \cdot \frac{L_E}{a_{x,E}}, (1 - \alpha) \cdot \frac{L_E}{a_{y,E}} + \frac{L_P}{a_{y,P}} \right) &amp; \frac{a_{x,E}}{a_{y,E}} = p &lt; \frac{a_{x,P}}{a_{y,P}}  \\
\left(0, \frac{L_E}{a_{y,E}} + \frac{L_P}{a_{y,P}} \right) &amp; p &lt; \frac{a_{x,E}}{a_{y,E}} &lt; \frac{a_{x,P}}{a_{y,P}}  .
\end{array}
\right.
$$
The relative aggregate supply is the ratio $\frac{q_x}{q_y}$. It is perhaps best described by this image:</p>

<p><a href=""https://i.stack.imgur.com/NAgbr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NAgbr.png"" alt=""enter image description here""></a></p>

<p>The relative aggregate demand is the ratio $\frac{c_x}{c_y}$. As we have discussed $\frac{c_y}{c_x} = p$ so 
$$
\frac{c_x}{c_y} = \frac{1}{p}.
$$
As a result one can draw the relative aggregate demand in the previous graph as  hyperbole. The intersection with the relative aggregate supply curve will give yield the equilibrium price ratio and will also yield information about the production of individual countries. Where this intersection occurs depends on the parameters $L_E,L_P,a_{x,E},a_{y,E},a_{x,P},a_{y,P}$. I will distinguish between three types of equilibria, each represented in the following figure:</p>

<p><a href=""https://i.stack.imgur.com/lqiOs.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lqiOs.png"" alt=""enter image description here""></a></p>

<p>In the 1. equilibrium the price ratio is $p = \frac{a_{x,E}}{a_{y,E}} &lt; \frac{a_{x,P}}{a_{y,P}}$. Thus Portugal specializes and only produces good $y$, but England does not specialize but produces both good $x$ and $y$. Producing either good gives her the same value. The exact equilibrium quantities England produces are determined by the value the aggregate demand curve takes at price $p$, because
$$
\frac{q_x}{q_y} = \frac{c_x}{c_y} = \frac{1}{p}
$$
and
$$
q_x = q_{x,E} + q_{x,P} = q_{x,E} + 0 \hskip 20pt q_y = q_{y,E} + q_{y,P} = q_{y,E} + \frac{L_P}{a_{y,P}}.
$$
In this case England will still not achieve a net export of good $y$. The preferences tell us that Portugal will consume both goods $x$ and $y$. But the only way it can pay for the goods $x$ consumed is by trading some of its goods $y$, so Portugal, not England, will be a net exporter of good $y$ while England is a net exporter of good $x$. <br>
In the 2. equilibrium both countries specialize: England produces only good $x$, Portugal produces only good $y$. This is usually presented as the textbook case. <br>
The 3. equilibrium is like the 1. equilibrium, but here England specializes and produces only good $x$ while Portugal does not specialize and produces both.</p>

<p>So to answer my original questions: <br>
Given that England has a comparative advantage in producing good $x$,</p>

<ol>
<li>England will always produce good $x$.</li>
<li>England may also produce good $y$.</li>
<li>England will never export good $y$.</li>
</ol>
","10132"
"Budget constraint hyperplanes","210","","<p>This question relates to a <a href=""http://faculty.chicagobooth.edu/eric.budish/research/budish-approxceei-jpe-2011.pdf"" rel=""nofollow"">specific paper by Eric Budish, published in 2011 in JPE</a>, but I've tried to put all relevant information in this question. On page 1072, he defines <em>budget constraint hyperplanes</em> as follows:</p>

<blockquote>
  <p>Let $H(i,x) = \{\mathbf{p}:\mathbf{p} \cdot x = b_i \}$ denote the
  hyperplane in $M$-dimensional price space along which agent $i$ can
  exactly afford bundle $x$. As prices cross $H(i,x)$ from below, bundle
  $x$ goes from being affordable for $i$ to being unaffordable for $i$.</p>
</blockquote>

<p>$\textbf{p}$ represents a price vector for the $M$ goods, which, importantly, are indivisible. $b_i$ is agent $i$'s budget. I think the rest is sufficiently self-explanatory. My confusion is with this subsequent statement:</p>

<blockquote>
  <p>Importantly, the number of such hyperplanes is finite because the
  number of agents and the number of bundles are finite. This is an
  advantage of having only indivisible goods.</p>
</blockquote>

<p>This I don't see. For example, suppose $M=2$. Then aren't all $\textbf{p}=(\alpha b_i, (1-\alpha)b_i)$ such that $\alpha \in [0,1]$ hyperplanes meeting that definition, and thus I have infinitely many?</p>

<p>Having said that, a hyperplane is the set of those price vectors, not each of the vectors, so maybe the full set of price vectors I've just described together define just one hyperplane? I suppose my issue is understanding what a hyperplane is in this setting, and how the indivisibility gives us just a finite set of hyperplanes to work with. Any guidance would be very much appreciated.</p>
","<p>The set $\{\mathbb{p}:\exists \alpha \in (0,1), \mathbb{p}_1=\alpha b_i, \mathbb{p}_2=(1-\alpha)b_i\}$ coincides with the hyperplane $\{\mathbb{p}:p_1+p_2=b_i\}$, therefore you are not finding extra hyperplanes by doing this and varying $\alpha$.</p>

<p>More generally, if you fix $x=(x_1,x_2)$ and $b_i$, you obtain one hyperplane characterized by the equation $\{\mathbb{p}:p_1 x_1+p_2 x_2=b_i\}$. Since there are finitely many such $x$ (and $b_i$ is given), there are finitely many such hyperplanes.</p>
","5966"
"Where can I get pizza data","210","","<p>I'm studying the pizza market, especially in Utah, and I would like to know if there are any pizza data sources. Can some kind of sales tax data be used to study pizza? Is there a straight up pizza study that collected data? How creative do I have to get to find data? Or how much might I need to pay to have someone collect it?</p>

<p>Any data related to these things will be awesome: pizza input markets, pizza production, pizza demand, pizza labor, pizza firms, anything pizza and economics.</p>

<p>I'm not sure exactly what variables I'm after, I was just going to see which are out there first. I put in a request to Yelp.com to get access to their data sets, but it's only allowed for a few universities right now, not mine. We're on a wait list. Other than that, I'm kind of stumped.</p>
","<p>It might not get you very far, but a start would be <a href=""https://www.google.co.uk/trends/explore#q=pizza+delivery,pizza+hut&amp;geo=US"" rel=""nofollow noreferrer"">Google Trends</a>:</p>

<p><a href=""https://i.stack.imgur.com/34d6F.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/34d6F.png"" alt=""Google trends pizza data""></a></p>
","9802"
"Why does the Laffer curve for consumption have no peak?","210","","<p>According to <a href=""http://www.nber.org/papers/w15343.pdf"" rel=""noreferrer"">Trabant and Uhlig (2009)</a>, the Laffer curve for consumption has no peak.</p>

<p>As far as I can make out, the argument is based on the fact that money extracted by taxing consumption ends up back with consumers and then gets taxed again. However I don't understand why the standard idea that taxes deter activity doesn't create a peak.</p>
","<p>This is not a general result. As the auhtors describe in page 10 of their paper, the result obtains only when government lump-sum transfers $s$ do not vary with tax revenues, and instead government spending $g$ does. Then consumption taxes do not affect labor supply, for any level of the tax rate. The relation becomes monotonic, and the Laffer curve <em>with respect to the consumption tax rate</em> becomes also monotonic. This is something that the authors are not very clear in the main text, but it can be detected in the various proofs at the end: they do not argue that the Laffer curve with respect to all three tax rates examined (consumption, labor, capital), becomes monotonic. Only its dimension with respect to the consumption tax.</p>

<p>And more over, on page 9, when government spending is fixed and it is lump-sum transfers that vary with tax revenues (their Proposition 2) they are not clear on what happens, <em>with respect to consumption tax rate</em>. They do say that here the usual Laffer curve emerges, but they comment on a scenario with $\tau^c$ fixed.</p>

<p>Mathematically, the result hinges on the different feasibility constraint that applies in the two cases (eq. $13$ for the fixed government spending case, eq. $14$ for the fixed-transfers case).</p>

<p>In the model, the difference between government spending and transfers, is that the first provides directly utility, while the second increases disposable income in a lump-sum fashion.</p>

<p>Consumption taxes affect <em>utility</em>: a higher consumption tax rate $\tau^c$ will decrease consumption and hence utility of the same income level. When this is offset by higher utility-generating government spending, while transfers remain unaffected, the incentives related to work/income generation (""activity"") remain unaffected, pre-tax income remains the same, tax revenues increase: no extremum point in the Laffer curve. Essentially, this affect how much utility the individuals obtain from private consumption, and how much from government spending.</p>

<p>If alongside the increase in the consumption tax rate, we increase transfers keeping government spending fixed, this creates a substitution effect, a disincentive for labor income: it is better to sit back and collect, rather than work and collect. The individual can increase his utility indirectly, by decreasing the disutility from work. This creates conflicting forces: eventually, for a sufficiently high consumption tax rate (and a correspondingly higher level of transfers) he will decrease his labor supply and hence his labor income <em>more</em> than the increased transfers, thus lowering the consumption tax-base.</p>

<p>The above are of course <em>static</em> effects, ""inside"" each time period, since the Laffer curve is a static concept.</p>
","192"
"Why is money in circulation a liability of the central bank?","210","","<p>We know that the money today is fiat currency, that it is money because the government says it's so. So when new money is printed or loaned out to the commercial banks by buying treasury bonds, government does not technically ""owe"" any thing. The only thing that is stopping it from creating new money every time need arises is the possibility of inflation. </p>

<p>Given all of that why is still money in circulation listed as a liability of the central bank? Am I missing something here?</p>
","<p>Balance sheets always balance, so assets equal liabilities.</p>

<p>Imagine a commercial bank goes to the central bank and wants cash. The central bank provides the cash, but asks for some of the commercial bank's loans (or government bonds) in return.</p>

<p>The central bank now has the loans (or government bonds) as assets and the cash as liabilities.</p>

<p>The cash is a liability, because if the commercial bank goes back to the central bank and gives back the cash, the central bank will have to give back the loans (or government bonds).</p>

<p>So while it's true that cash is not backed by gold, it is still backed by something. You can take your cash to the central bank, exchange it for government bonds, earn cash interest on your government bonds and then use this cash to pay your taxes. More generally cash is backed by the goods that you can purchase for it.</p>
","17936"
"Which foreign workers in USA who send remittances to family are getting the best bang for their buck?","209","","<p>There are probably a lot of ways to measure that, but I want to measure it like this: Foreign national workers grouped by country of origin, which group sends the most money per capita in remittances?</p>

<p>That way it's kind of like saying they have the most income per capita after living expenses.</p>

<p>Maybe that means the skills they brought to USA are getting the best return compared to other groups.</p>

<p>It doesn't say anything about how far that remitted money goes in the origin country. So bang for buck is referring to getting paid in the US, not spending it abroad.</p>

<p>I'm not sure where to start searching for this information. I googled around but just found ads for remittance companies.</p>
","<p>A good start would be <a href=""http://ftp.iza.org/dp1531.pdf"">The Economics of Migrants' Remittances</a> by Hillel Rapoport and Frédéric Docquier. They both work extensively on this topic. In this paper, they review the  theoretical  and  empirical  economic  literature  on  migrants' remittances.</p>

<p>They review six theories decomposed into two broad categories individualistic motives (altruism, exchange, inheritance, and the strategic motive) and two types of familial agreements (on insurance and investment).</p>

<p>In all of these six theories, except one, migrant's income is indeed a very good predictor of remittances. However, other motives matter and may differ across ""foreign national workers grouped by country of origin"". For instance, some societies are more altruistic than others, and assuming  that  altruism  decreases  with  time  of arrival, the size of remittances should be negatively related to this variable in the altruistic case. </p>

<p>They also predict contrasting effects concerning the distance from family. For instance, in the inheritance theory, the amounts remitted are expected to be closely related to the probability of receiving inheritance in the origin country. If, as they assume there is a negative correlation between the distance from family and the probability of receiving inheritance, a Mexican worker will remit more than an Ethiopian worker, other things being equal. This could even be true if the Ethiopian worker has ""the most income per capita after living expenses"".</p>

<p>To sum up, migrant's income is a crucial variable but other variables, which may differ by country of origin, may also be of first-order importance to understand remittances.</p>
","11477"
"Establish demand curve with infrequent sales","208","","<p>I sell variations of an item on eBay. It is an unusual commodity which I purchase in bulk lengths and then cut to various sizes. They come in about 20 types, which I then sell as 10 different lengths, giving a total of 200 variations.</p>

<p>My goal is to determine what price I should charge for each, to maximise monthly profit.</p>

<p>The problem is I only make an average of one sale per day. I have no idea how I can establish a demand curve for the products, given such limited data. (Some variations I only get one sale per 18 months!)</p>

<p><strong>What techniques could I use for this problem?</strong></p>

<p>How could I go about establishing the most profitable price for each of the variations, with such limited information? (Given known costs). </p>

<p>The only clear idea I have is this:</p>

<ul>
<li>Treat all 200 variations as a single product, and vary all their prices simultaneously, to derive a single demand curve. So for example, one month I might set all prices to generate 10% profit on top of the costs, then next month, set all prices to generate 20% profit, and so on, and this way establish what price generates the highest monthly profit.</li>
</ul>

<p>But the variations tend to have wildly different applications, as well as, I expect, alternative products that can satisfy the customers' requirements, and so on - so having a single demand curve could leave significant profits untapped.</p>

<p>The only other idea I have is to profile the demand curve for each item in a different way:</p>

<ul>
<li>For each product, take an example: one that only sells approx every 6 months on average: On each sale, if the time since the last sale was 6 months, I divide the total profit made on that item by 6 - or for a product that sold twice in one month, multiply by two. And then each time there is a sale I can some how establish the demand curve for it. </li>
</ul>

<p>But the snag is for a product that sells infrequently, the demand curve could be static, but obviously this does not mean it would sell, say, once every 6 months like clockwork. So it could take years to establish a demand curve for that variation.</p>

<p>I'm wondering if I should entirely forget about the demand curve and concentrate instead on a marketing-oriented approach, for example:</p>

<ul>
<li>Surveys: (How I would phrase this I'm not sure - I doubt customers would tell me the maximum they'd pay!)</li>
<li>Market research: plot graphs of how much other retailers/distributors charge for each variation. (Although I have seen very few indeed that sell small lengths such as those that I offer)</li>
</ul>
","<p>If you are fairly confident that your current price is not too far from the real profit-maximising price then there is little loss in accuracy from assuming the demand curve to be locally linear (i.e. a straight line in the area around your current point). This is illustrated in the figure below: note how the red (linear) approximation to the curve much more closely follows the shape of the curve when the two endpoints are close together than when they are far apart.</p>

<p><a href=""https://i.stack.imgur.com/CTZLu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CTZLu.png"" alt=""enter image description here""></a></p>

<p>This observation can help you a little because it means you only need two data points to characterize the demand curve provided the price adjustments are small. Moreover, note that you can implement one large price change as a sequence of smaller changes. As soon as you have two datapoints, you can work out which direction you should be adjusting your price in. One procedure would be as follows:</p>

<ol>
<li>reduce your price by a small amount—say, 1–5%. (note: a price decrease might work better than an increase because you have said that you do not sell often and increasing your price will just mean you end up with even fewer sales and hence even less data). Unless there is a kink in the demand curve, a sufficiently small price increase and a small price decrease should give you approximately the same estimate for the demand curve's slope.</li>
<li>observe demanded quantity at the new price (e.g. '$q_\text{new}$ sales per month').</li>
<li>calculate the slope of the inverse demand curve:
$$\text{slope}=\frac{p_\text{new}-p_\text{old}}{q_\text{new}-q_\text{old}}$$
where $q$ means quantity and $p$ means price.</li>
<li>The profit maximising price, $p^*$, solves the equation
$$p^*=c-(q\times \text{slope})$$
where $c$ is your unit cost, slope is calculated above, and $q$ is quantity sold at price $p^*$. If you find that neither $p_\text{new}$ nor $p_\text{old}$ is equal to $p^*$ then you need to make an adjustment to the price (see step 5.).</li>
<li>The linear approximation to demand introduces very little error so long as you don't venture far from the starting price. It therefore makes sense to incrementally adjust towards optimum. For example, suppose that you do steps 1–4 and find that, at your current $p$ and $q$, $p&gt;c-(q\times \text{slope})$ (meaning that your price is above the profit-maximising level). Then it makes sense to reduce the price by a <em>small</em> amount and  repeat steps 2–3 to get a new estimate for the slope of the demand function that is more accurate in the region surrounding the new lower price. Repeated application of this procedure should allow you to converge towards the optimal price.</li>
</ol>

<p><strong>Important caveat:</strong> You should be mindful that the quantity you sell will change not only because you reduced price (i.e. a movement <em>along</em> the demand curve), but also if the whole demand curve changes (e.g. demand for toys will be higher at Christmas independent of whether price changes or not). For this exercise to work, you need to be confident that the demand curve doesn't change too much over time (and to re-estimate the demand curve during periods when it is likely to be different).</p>
","8277"
"Gold Prices and Terrorism","208","","<p>With the Federal Reserve set to review interest rates next month, the price of gold may very well drop if they increase it. But with the current prevalence of terrorism and insecurity, is the price of gold likely to be affected (increase/decrease)?</p>
","<p>Very unlikely. Terrorism events are not economically significant enough to move a commodity like gold.  In fact, terrorist attacks only effect markets if they are likely to lead to a major economy entering a full-scale war like it was after 9/11, 2001. The cost of terrorism, while at historical height, is still very small to effect the markets significantly: <a href=""http://fortune.com/2015/11/17/terrorism-global-economic-cost/"" rel=""nofollow"">http://fortune.com/2015/11/17/terrorism-global-economic-cost/</a>. Even economy of a country like France that have been recently hit by a terrorist attack is not likely to be affected by it too much. Politicians may exploit the terrorist attack to push their agenda though, which may have negative effects on the economy, like this articles argues: <a href=""http://www.marketwatch.com/story/frances-real-challenge-is-growing-stagnant-economy-not-fighting-in-syria-2015-11-19"" rel=""nofollow"">http://www.marketwatch.com/story/frances-real-challenge-is-growing-stagnant-economy-not-fighting-in-syria-2015-11-19</a>.</p>

<p>Yet, gold is a very volatile market and the price of gold can move a lot in any direction for no obvious reason. Purchases and sales of gold by central banks and institutional investors often go unannounced.</p>

<p>Another thing you should keep in mind if you want to speculate on the rate hike is that some big players may be waiting for that moment to BUY gold in large amounts, because that is when they can expect the most people placing sell orders. In that case the price of gold can jump contrary to expectations.</p>
","9426"
"Measure combining growth and distribution of income","207","","<p>A frequently used measure of economic progress is GDP growth. (There are alternative economic indicators as well, such as the Human Development Index.) But there are problems with GDP growth. For example population growth also causes the GDP to grow, because more people produce and consume more goods. You could correct for this by usind GDP/capita growth instead. </p>

<p>But GDP/capita growth still does not take into account the distribution of wealth. Perhaps 90% of the population are doing worse than last year but 10% are doing so much better that on average there is still growth. You could argue that this is still 'better' overall, but I would argue that in a democratic setting most people would probably not vote for an economic policy that clearly and openly supports such an income shift. (If you are thinking of cases where this has happened and will happen: I am afraid I don't care about the political side of this argument. You are welcome to post about it over at politics SE.)</p>

<p>Are there indicators that capture both distribution and growth of income?
<br> A simple example with its own faults would be median GDP/capita growth. Something better (and slightly more complicated) could probably be constructed using the GINI index.
<br> Alternatively: Are there arguments against measuring something other than aggregate or average GDP?</p>
","<p>One concept fairly established in economics is the idea of generalized Lorenz dominance.</p>

<p>The Lorenz curve (<a href=""https://en.wikipedia.org/wiki/Lorenz_curve"" rel=""nofollow"">https://en.wikipedia.org/wiki/Lorenz_curve</a>) plots percentiles of the population on the x axis and the cumulative percentiles of income on the Y axis. If the point (30,10) is on the curve, then this means that the bottom 30% of the population have 10% of the income of the population.</p>

<p>This allows us to compare the inequality of two countries by comparing how low or high their Lorenz curve is. If curve A is everywhere above or equal to curve B, then A is weakly less unequal than B. However, even the poorest person in B may still earn more than A.</p>

<p>The generalized curve multiplies the Y axis with the average income of society. Now we can not only compare A and B in terms of inequality, but also by how well individuals are off in these societies. Curve A being everywhere above or equal to curve B means that every percentile of society A is weakly better off than every matching percentile in society B.</p>

<p>Shorrocks showed that under certain conditions a parameterized family of social welfare functions is higher in society A relative to society B for all parameters if and only if the generalized Lorenz curve of A is higher than B at all points.</p>

<p>Shorrocks, Anthony F. ""Ranking income distributions."" Economica (1983): 3-17.</p>
","9246"
"What was happening in Madagascar during 1971-1996?","207","","<p>In the course of my research I have been examining these days macroeconomic time series for per capital household consumption, using the <a href=""http://data.worldbank.org/indicator/NE.CON.PRVT.KD"" rel=""nofollow noreferrer""><strong>databank of the WorldBank</strong></a>. The unit of measure was constant 2005 USD.  </p>

<p>I got all shorts: smooth upward trends indicating a steadily increasing material well being on average; series with wild swings indicating socioeconomic turmoil, civil wars, coup d'eta's etc; series with an obvious structural shock in the level which then continued to grow at the same rate (for example Finland experienced such a shock when the Soviet Union collapsed); series suspiciously smoothly increasing, too smoothly to be believable and so suspect of being fake...</p>

<p><strong><em>Unique</em></strong> among them, was <strong><a href=""https://en.wikipedia.org/wiki/Madagascar"" rel=""nofollow noreferrer"">Madagascar</a></strong>: its per capita consumption exhibited a steady <strong><em>downward</em></strong> trend for the period 1971-1996, although after that period the trend seems to (gradually) flatten out. Here is the plot:</p>

<p><a href=""https://i.stack.imgur.com/WwvdM.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WwvdM.jpg"" alt=""enter image description here""></a></p>

<p>Again the unique feature here is the almost constant downward trend. There were other countries that saw their consumption level collapsing in this period, but not in such a steady gradual manner, <em>over a quarter of a century</em>.</p>

<p>Does anybody have a clue as to what was happening in the period in this country? Madagascar was colonized by France in 1896 and obtained full independence in 1960. But of course there are many countries that were colonies and de-colonized around that period; none exhibited such behavior.</p>
","<p>I think I have found the explenation for this. If you look at the wikipdedia page of the economy of Madagascar, it states the following:</p>

<p>The standard of living of the Malagasy population has been declining dramatically over the past 25 years. The country has gone from being a net exporter of agricultural products in the 1960s to a net importer since 1971. Inappropriate traditional agricultural methods cause soil to erode and soil quality to decline, and the basis of survival for Madagascar’s people is under serious threat.</p>

<p>The source of this claim is Deutsche Gesellschaft für Internationale Zusammenarbeit. </p>

<p>Now, if you look at the world bank figures on agriculture in Madagascar, you can see this declining trend. For example the Agriculture value added per worker (constant 2005 US$) declines between 1980 and 2014 from 250.1 to 175.8. </p>

<p>Since Madagascar is a country which relies heavily on agriculture (about a quarter of its GDP stems from agriculture), this declining trend influences the whole of this economy.</p>
","9941"
"How can a good be considered both a luxury and a normal one?","206","","<p>Let's say I spend $20$ on pizza with an income of $100$. If my income jumps to $110$, I then spend $25$ on pizza. While my income grew by 10%, my expenditures towards pizza grew by 25%. Hence, I would consider this good a luxury, where $\Delta Q_{D\%} / \Delta I_{\%} &gt; 1$.</p>

<p>How can pizza be considered a normal good in this context.</p>
","<p>In case of normal goods, income elasticity of demand is greater than 0 and in case of luxury goods, it is greater than 1.</p>

<p>Supposing the price of pizza here remain constant at $1, thus when your income increased by 10%, the demand of pizza increased by 25%</p>

<p>Income elasticity of demand = 25/10 = 2.5</p>

<p><strong>2.5 > 0</strong>, hence <strong>normal good</strong></p>

<p><strong>2.5 > 1</strong>, hence <strong>luxury good</strong> </p>

<p>This way, pizza is both normal and luxury good here. </p>
","8767"
"Why isn't the cost of shoes affected by their size?","206","","<p>I have noticed that many shoe selling shops I have visited have the same price tag regardless of the shoe size.</p>

<p>Intuitively I'd think the bigger the shoe the more material and consequently capital invested in producing it. That being the case why would a manufacturer equally price dissimilar shoe sizes?</p>
","<p>Most of the price of creating a shoe is the cost of labour to make it and the cost to ship it to the store. The cost of the materials needed to make the shoe is negligible. So, they can ignore the difference in material costs without losing too much money.</p>

<p>But why would they want to lose any money at all? Logistics. Keeping track of the different prices per shoe, printing the different labels, making sure the shoes are sold at the right price, paying people to determine how much of a price difference the company should charge are all things that cost money.</p>

<p>So the company is looking at creating a giant logistical nightmare for themselves, costing them who knows how much money, all for a penny difference between a size 8 and a size 13.</p>

<p>Trying to charge a different price would be a case of being 'penny smart; dollar stupid'.</p>
","17081"
"Why two goods are of different types of Cross Elasticity if we swap them in formula?","206","","<p>I am using this formula for calculating <a href=""https://en.wikipedia.org/wiki/Cross_elasticity_of_demand"" rel=""nofollow noreferrer""><strong>Cross elasticity of demand:</strong></a></p>

<p>$ E_{XY}^D = \Large\frac{(Q_2^X - Q_1^X)(P_2^Y + P_1^Y)}{(Q_2^X + Q_1^X)(P_2^Y - P_1^Y)}
$</p>

<ul>
<li>If $E_{XY}^D$ <strong>> 0</strong> Then goods <strong>X</strong> and <strong>Y</strong> are <strong>substitutes</strong>.</li>
<li>If $E_{XY}^D$ <strong>&lt; 0</strong>  Then goods <strong>X</strong> and <strong>Y</strong> are <strong>complementary</strong>.</li>
<li>If $E_{XY}^D$ <strong>= 0</strong> Then goods <strong>X</strong> and <strong>Y</strong> are <strong>independent</strong>.</li>
</ul>

<hr>

<p>I have this data:</p>

<p><a href=""https://i.stack.imgur.com/sWoUr.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/sWoUr.jpg"" alt=""enter image description here""></a></p>

<p><em>P1 and P2 are prices; Q1 and Q2 are quantities.</em></p>

<p>Using above formula I have calculated cross elasticity $E_{XY}$ and $E_{YX}$ in Excel:
<a href=""https://i.stack.imgur.com/fqs9M.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fqs9M.jpg"" alt=""enter image description here""></a></p>

<hr>

<p>I calculated Cross Elasticity for <strong>X</strong> and <strong>Y</strong> and the goods turned out to be <strong>Complementary</strong> goods, but when I swapped X and Y and calculated using the same formula the goods <strong>X</strong> and <strong>Y</strong> become <strong>Substitutes</strong>.</p>

<hr>

<p>Why two goods belong to one type of cross elasticity, but if we swap X and Y and plug values into formula the goods turn out to be another type of Cross Elasticity. Can two goods be considered <strong>substitutes</strong> and <strong>complementary</strong> at the same time? Isn't it illogical?</p>

<hr>

<p><em>Excel file with data and calculations available here:</em> <a href=""https://www.dropbox.com/s/ubbre40owjsd92c/Cross%20Elasticity%20SE.xlsx?dl=0"" rel=""nofollow noreferrer""><em>Dropbox</em></a></p>
","<p>The cross elasticity of demand $E_{XY}^D$ is defined as the percent change in quantity demanded for X divided by the percent change in price of Y, <strong>holding the price of X fixed</strong>.</p>

<p>The problem with your calculation is that you did not use the quantity change when the price is fixed. Therefore, you need additional data to calculate the cross elasticities.</p>

<p>Another part of your question is whether cross price elasticities are symmetric. The answer depends on what type of demand you are working with. For Hicksian demand (where we hold the utility constant), the cross elasticities are symmetric. For Marshallian demand (where we hold the income constant), cross price elasticities are generally different, even the signs could be different. The reason that the Marshallian demand has different cross price elasticities is that when price of a good changes, it has both price effect (self and cross) and income effect (self and cross). The ""pure"" cross price effect should be symmetric, which is what we see in Hicksian demand. But the ""gross"" cross price effect, the combined effect of price and income, is not symmetric, because the income effects caused by different goods can be very different. For more details about Hicksian and Marshallian demand, price and income effects, consult any decent intermediate micro textbook. Or probably Google will show you plenty lecture notes on these topics.</p>
","13988"
"Does the concept of Nash-equilibrium conflict with the concept of market equilibrium in the lemon market","205","","<p>Consider a version of Akerlof's <a href=""http://www.iei.liu.se/nek/730g83/artiklar/1.328833/AkerlofMarketforLemons.pdf"" rel=""nofollow"">Lemon market</a> with two types of sellers. One type sells Quality cars the other type sells Lemons. Buyers' reservation prices are $r_{B,Q}$ for a Quality car and $r_{B,L}$ for a Lemon. Sellers' reservation prices are $r_{S,Q}$ for a Quality car and $r_{S,L}$ for a Lemon. The buyers cannot differentiate between the types of the sellers but the sellers know their type. Given a market price $p$ sellers decide whether to sell or not by maximizing their surplus $p - r_{S,t}$. (Not selling yields a surplus of zero.) Buyers decide whether to buy or not by maximizing their expected surplus $E(r_{B,t}) - p$. (Not buying yields a surplus of zero.)</p>

<p>Given a number of buyers $n_B$ a number of sellers for both types $n_Q, n_L$ we can reason about the type of equilibrium. Depending on the parameters you can have total market collapse (if no purchase occurs), adverse selection (if only Lemons are bought and sold) and also markets where both types of cars are sold. For some parameter sets you have multiple market equilibria. That is you have a price $p_1$ at which adverse selection occurs and the corresponding demand at $p_1$ is equal to the supply at $p_1$. You also have a price $p_2$ at which adverse selection does not occur and the corresponding demand at $p_2$ is equal to the supply at $p_2$.</p>

<p>If the surplus of a single buyer is larger at $p_2$ and the surplus of sellers is not smaller at $p_2$, can I claim that $p_1$ is an equilibrium? Seems like any buyer would benefit by deviating from $p_1$ and unilateraly setting $p_2$ or $p_2 + \epsilon$. In competitive equilibrium it is assumed that market actors are price takers but if they are sufficiently small (have no bargaining power like a monopoly) then this coincides with their strategic interests. Here even if the buyer is insignificant, this does not hold (probably due to asymmetric information). So is the market in equilibrium with price $p_1$ or not?</p>

<p>Such parameter combinations exist, an example:
$$
n_B = 4, n_Q = 2, n_L = 4
$$
$$
r_{B,Q} = 18, r_{B,L} = 6, r_{S,Q} = 8, r_{S,L} = 5
$$
$$
p_1 = 8, p_2 = 5
$$</p>
","<p>So this seems to be a known issue. Quoting from the Wilson article of 1980, 
<a href=""http://www.jstor.org/stable/3003403?seq=1#page_scan_tab_contents"" rel=""nofollow"">The Nature of Equilibrium in Markets with Adverse Selection</a>:</p>

<blockquote>
  <p>Using a variant of Akerlof's model of the used car market, we examine the equlibrium of the model under three distinct conventions: (1) an auctioneer sets the price; (2) buyers set the price; (3) sellers set the price. Only in the case of the auctioneer is the equilibrium necessarily characterized by a single price which equates supply and demand.</p>
</blockquote>

<p>Thus the answer to the question is a partial yes. Given some (most) variants of the lemon market the two equilibrium concepts do not result in identical outcomes.</p>
","11704"
"Black-Litterman---in what way are expected returns hard to estimate?","204","","<p>In the Wikipedia article about the <a href=""https://en.wikipedia.org/wiki/Black%E2%80%93Litterman_model"" rel=""nofollow"">Black-Litterman model</a>, it states that the motivation
behind model is that ""it is difficult to come up with reasonable estimates of expected returns."" Why is it that expected returns are difficult to estimate, whereas the covariances are not?</p>
","<p>Your question relates more broadly to modern portfolio theory, and can be illustrated via mean-variance analysis of a univariate time-series. The extension to the multi variate (normal) setting, is trivial. Below I use the term <em>accuracy</em>, in a non-formal way, relating to the variance of an estimator. In particular, when the variance of an estimator can be reduced, take this to mean the estimator can be made more <em>accurate</em>.</p>

<p>Short story: The variance of the estimator for the variance of returns can be reduced by taking more observations (finer observations - up to a limit), whereas this is not true for the variance of the estimator of the expected returns. In this sense, it is <em>more difficult</em> to <em>accurately</em> estimate expected (mean) returns compared to variance of returns. </p>

<p>To see why, consider a time-series of returns, and assume the mean (per unit time), $\mu$, and variance (per unit time), $\sigma^{2}$, are <em>constant</em> over non-overlapping time <em>intervals</em> of frequency $h$. Here, $h$ represents daily, or monthly, or quarterly periods, etc. Further assume that our time-series data are observations over time intervals of length $\Delta$, where $\Delta&lt;&lt;h$. Then, define $n=h/\Delta$, as the number of observations of returns during a time interval of $h$.</p>

<p>For the $k^{\text{th}}$ observation interval (of length $\Delta$) during a period of length $h$, without loss of generality, we can assume that the price process for an asset is given by $$S_{k+\Delta}=S_{k}\exp{(\mu\Delta+\sigma \sqrt{\Delta} \epsilon_{k})},$$ where $\epsilon_{k}$ are iid normal. The logarithmic return (over period $\Delta$) can be written, as
$$X_{k}=\mu\Delta+\sigma \sqrt{\Delta} \epsilon_{k}.$$ For mean-variance portfolio theory, we require estimates of the true values of $\mu$ and $\sigma$, since they are of course, unknown. Call these estimators $\hat{\mu}$ and $\hat{\sigma}$. To answer your question, we only need consider the properties of these estimators.</p>

<p>First
$$\hat{\mu}=\sum_{k=1}^{n}X_{k}/h, \quad \mathbb{E}(\hat{\mu})=\mu, \quad \text{Var}(\hat{\mu})=\sigma^{2}/h.$$</p>

<p>Importantly, the variance of $\hat{\mu}$ depends upon the total length of the observation period and not on the number of observations.</p>

<p>Now consider, the (biased) estimator for $\sigma$:
$$\hat{\sigma}=\sum_{k=1}^{n}X_{k}^{2}/h, \quad \mathbb{E}(\hat{\sigma})=\sigma^{2}+\mu^{2}h/n, \quad \text{Var}(\hat{\sigma})=2\sigma^{4}/n+4\mu^{2}h/n^{2}.$$</p>

<p>The bias can be neglected (see reference for details).</p>

<p>Importantly, the accuracy (variance) of the estimator for $\sigma$, $\text{Var}(\hat{\sigma})$, <strong>does</strong> depend upon the number of observations, $n$ - for fixed $h$. </p>

<p>The consequence of this is, for fixed $h$, by taking finer (smaller) observations intervals, $\Delta$, the accuracy of the variance estimator can be improved ($\text{Var}(\hat{\sigma})$ can be reduced). This is not true of the variance of the estimator of the expected (mean) return, $\text{Var}(\hat{\mu})$, whose accuracy can be improved only by increasing the observation period, $h$.</p>

<p>The reference for this is</p>

<ol>
<li>Merton, R. C. On estimating the expected return on the market. J. financ. econ. 8, 323–361 (1980).</li>
</ol>
","1827"
"Economic schools of thought VS Econometrics","204","","<p>From  <a href=""https://en.wikipedia.org/wiki/Schools_of_economic_thought"" rel=""nofollow noreferrer"">Wikipedia</a>:</p>

<blockquote>
  <p>In the history of economic thought, a school of economic thought is a group of economic thinkers who share or shared a common perspective on the way economies work</p>
</blockquote>

<p>Why is it that different economic schools of thought are  still taught in spite of the fact that we now have data to test their ideas and philosophies of the economy and see if they really line up with reality? </p>
","<p>Actually, many people claim that too few schools of thought are taught.</p>

<p>The question is very broad because it encompasses several topics in the methodology of the social sciences and in epistemology. First, we do not know whether we can actually test theories through econometric analysis. Econometric techniques - and in general statistical ones - are based on sets of assumptions which are not necessarily true. In fact, different econometric models and strategies can be applied to the same problem and we do not always know which one is the best. This is the problem of model selection Dave Harris talks about in his answer. Note that model selection problems can arise even within the same theoretical approach, not only between different ones.</p>

<p>Moreover, people are not even sure that we can use empirical data to test theories. These people propose very different arguments, spanning from Hume's skepticism to the Austrians' point that theory always precedes perception, hence distorting any empirical test (this is one of the most important point in the Methodenstreit, that is the debate between the Austrian School and the German Historical School - the first one to make use of statistical data to ""test"" economic theories). Nonetheless, they basically agree that we only understand the world through more or less structured theories, and we select data and evaluate them in non-random fashion, making useful but aprioristic assumptions.</p>

<p>Second, econometrics has flourished during the heyday of Neoclassical Economics, hence it is partly built on this School's assumptions. It is hardly arguable that a methodology built on a certain set of theories can be objectively used to gauge alternative theories.</p>

<p>Third, different schools of thought are not just diverse groups of theories. They are different paradigms - that is different ""ways"" of looking at the world - and they rest on such different assumptions and explanations that is simply too hard to compare them. Paradigms are better evaluated by their internal consistency, and only after that we can make comparisons. Of course, there is a problem of validation and selection (how do we select a ""better"" paradigm? Why certain paradigms survive and expand and other collapse and fade?). But that is a problem of epistemology more than econometrics.</p>

<p>We would better teach as many paradigms as we think is useful and enhance our understanding of the economy through cross-contamination, always striving for a more convincing explanation, not for an impossible definitive answer.</p>
","16152"
"Microeconomic foundation of discrete choice model","204","","<p>(1) Does the following result in a ""valid"" (in the sense of being consistent with the economic theory) market demand function?<br>
A consumer $i$ maximizes a utility $u_{ij}$ in choosing one of J alternatives, $j=1,..,J$:<br>
$u_{ij} = v_j - \alpha p_j + \epsilon_{ij}$<br>
where $v_j$ is the utility of alternative $j$ without the effect of price (i.e. $-\alpha p_j$) and the logit error term $\epsilon_{ij}$.<br>
The market demand results then as the choices of all consumers.</p>

<p>Is in accordance with economic theory to follow (1) and <em>not</em> assume a budget constraint but let the ultility of an alternative be directly affected by price?  And additionally assume that a consumer chooses one alternative (i.e., a corner solution follows directly from this assumption).  Does (1) result a  ""valid"" (in the sense of being consistent with the economic theory) market demand function ?</p>

<p>(2) Typically the theory of the microeconomic foundation of logit choice model (e.g.
<a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1718571"" rel=""nofollow"">http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1718571</a>)  assumes that consumers maximize a utility function <em>without</em> the price effect <em>but</em> subject to a budget constraint. With a linear utility function, the maximization problem results in a corner solution of a consumer choosing only one choice alternative.
This setup (as outlined in the cited paper) leads than to the market demand.</p>
","<p>Your first equation is an <strong>indirect</strong> utility function. The consumer chooses only one good and we assume that he can afford it. For simplification, the indirect utility discards the budget $m$ (often assumed be the same for all $i$).
Here, your demand function is perfectly inelastic. If the individual demand would not have been perfectly inelastic, the form would have been like $V=a-s(p)$, where $s'$ is strictly concave and increasing.</p>

<p>See, for example, Palma/Anderson/Thisse.</p>
","5110"
"Who were the economists who made lots of money in the financial markets?","204","","<p>I prefer to learn economic theories from economists who made lots of money from the financial markets and were aided by their economic ideas. Who were they? What are the notable economic theories did they formulate? </p>
","<p>At university classes, I always learned that the only economist who ever became rich was Ricardo. However, Ricardo was already rich before becoming an economist. </p>

<p><a href=""https://agenda.weforum.org/2015/10/why-economists-arent-wealthy/"" rel=""nofollow noreferrer"">This</a> article seems support this claim. It also gives an explanation for the lack of rich economist:</p>

<blockquote>
  <p>If becoming wealthy is your goal in studying economics, you may be disappointed.  Although most economists make a good living, few have become rich from their knowledge of economics. In fact, if economists had some secret for making money in, for example, the stock market, they would likely be using those secrets to their own financial advantage [...] In short, economics won’t necessarily make you richer, but it may keep you from making some decisions that would make you poorer.</p>
</blockquote>
","9174"
"Amazon vs Netflix, closely resembles which type of competition?","203","","<p>So we all know Amazon is following the path of Netflix regarding tv shows and movies. Both firms are increasing production of film, and now have their own productions.</p>

<p>If we were to categorize this type of competition, would it more closely resemble Hotelling's Model or Cournot?</p>
","<p>It certainly isn't a Cournot scenario. That would require homogeneous products. In fact there's a ton of differentiation between the two products (Amazon prime and Netflix). They have different TV shows, different movies, different documentaries. </p>

<p>I would argue that it is this differentiation that allows them to charge different prices. </p>

<p>Hotelling's law is much more applicable. However I would argue that they do not maintain minimum differentiation. Yes they may share similarities in their web presence, and they may have adopted the strategy of producing content in house; but they also are so different that it is hard to say they are copying each other on almost everything.</p>

<p>Amazon prime offers reduced price shipping, music streaming, and reduced prices on some items on Amazon. Netflix has none of those things. </p>

<p>That said, Netflix includes hard copies of DVDs as rentals included in their subscription, whereas you would have to buy the DVDs on Amazon. So even though some of their business is similar or matching, they mostly represent differentiated products.</p>
","15600"
"Endogenous Growth: Balanced Growth Path with CRRA Utility","203","","<p>I've got a model of endogenous growth due to spillovers.</p>

<p>$\textbf{Model:}$
$$K_t=\frac{1}{n}\sum_{t=1}^nk_t$$
In this model, $k_t$ is chosen by agents, and $K_t=\bar{k}_t$ (the average of all $k_t$).</p>

<p>Now, agents want to dynamically maximize utility (under certain constraints) and they have CRRA (constant relative risk aversion) utility, so the maximization looks like:
$$\sum_{t=0}^\infty\beta^t\bigg(\frac{c_t^{1-\gamma}}{1-\gamma}\bigg)$$
$$s.t.\;Y_t=k_t^\alpha(E_tL)^{1-\alpha}$$
$$c_t+i_t=Y_t$$
$$k_{t+1}=(1-\delta)k_t+i_t$$
$$c_t,i_t\geq0$$</p>

<p>$E_tL$ is effective labor and the rest of the variables are typical  (I can give their definitions if requested).</p>

<p>One last addition to the model is that there are two equilibrium constraints:
$$E_t=\frac{K_t}{L}$$
$$k_t=K_t$$
$\textbf{Solution:}$</p>

<p>Using an Euler equation approach, two terms in the objective:
$$...\frac{\beta^t[k_t^\alpha K_t^{1-\alpha}+(1-\delta)k_t-k_{t+1}]^{1-\gamma}}{1-\gamma}+\frac{\beta^{t+1}[k_{t+1}^\alpha K_{t+1}^{1-\alpha}+(1-\delta)k_{t+1}-k_{t+2}]^{1-\gamma}}{1-\gamma}...$$
FOC:</p>

<p>w.r.t  $k_{t+1}$ and substituting in consumption:</p>

<p>$$\beta^tc_t^{-\gamma}=\beta^{t+1}c_{t+1}^{-\gamma}[\alpha k_{t+1}^{\alpha-1}K_{t+1}^{1-\alpha}+1-\delta]$$ 
Substituting in the equilibrium constraints:
$$c_t^{-\gamma}=\beta c_{t+1}^{-\gamma}[\alpha+1-\delta]$$
$$\implies \frac{c_{t+1}}{c_t}=[\beta(\alpha+1-\delta)]^{\frac{1}{\gamma}}$$
This implies that consumption grows at a constant rate which depends on preference parameters.</p>

<p>The next thing I want to prove that we have a balanced growth path. By this I mean that all variables grow at the same constant rate. $$\frac{k_{t+1}}{k_t}=\frac{c_{t+1}}{c_t}?$$
I have started to answer the question, but I have gotten stuck. Here is what I have so far:
$$k_{t+1}=k_t^\alpha K_t^{1-\alpha}+(1-\delta)k_t-c_t$$
In equilibrium $K_t=k_t$:
$$k_{t+1}=k_t+(1-\delta)k_t-c_t$$
$$\implies \frac{k_{t+1}}{k_t}=1+(1-\delta)-\frac{c_t}{k_t}$$
If we have a constant rate of capital growth, suppose:
$$\frac{k_{t+1}}{k_t}&lt;\frac{c_{t+1}}{c_t}$$
If this is true:
$$\underset{t\rightarrow \infty}{lim}\;\frac{k_{t+1}}{k_t}=\underset{t\rightarrow \infty}{lim}\;1+(1-\delta)-\frac{c_t}{k_t}=-\infty$$
This means that the growth rate will continue decreasing. Now there are two ways this can happen. The first way is if $\underset{t\rightarrow \infty}{lim}\;k_t=-\infty$, which would clearly show that it couldn't be the case because capital cannot be negative. The second way which this could happen is if $\underset{t\rightarrow \infty}{lim}\;k_t=D$ where $D$ is some positive horizontal asymptote. If it did approach some asymptote, there is no reason why it could not be the case that consumption grows at a faster rate than capital. This is where I am stuck. How can I show that it cannot converge to some asymptote, and that $\underset{t\rightarrow \infty}{lim}\;k_t=-\infty$? Also, if there is an easier way to show that this model exhibits balanced growth paths, what is it? Any help would be greatly appreciated!</p>
","<p>You have obtained</p>

<p>$$ \frac{c_{t+1}}{c_t}=[\beta(\alpha+1-\delta)]^{\frac{1}{\gamma}} \equiv 1+g$$</p>

<p>and</p>

<p>$$\frac{k_{t+1}}{k_t}=1+(1-\delta)-\frac{c_t}{k_t}$$</p>

<p>By equating you can show that there is a unique rule that maintains a balanced growth path</p>

<p>$$\frac{k_{t+1}}{k_t}=\frac{c_{t+1}}{c_t} \implies c_t =( 1-\delta-g)k_t$$ </p>

<p>(too much consumption, by the way). This shows that the model has a unique balanced growth path. </p>

<p>If you want further to argue that the economy will indeed choose this path, you have to invoke the Transversality condition (which constraints the consequences that a chosen path should have  on capital accumulation), and maybe the Inada condition that your chosen utility function satisfies. </p>
","11541"
"Estimating Price Elasticity from sales","203","","<p>I'm looking at data for an online shop with clothing items listed at different prices. I'd like to use this information to do some kind of profit maximization (i.e. I'd like to have some understanding of the impact on sales if I raise/lower price of an individual item).</p>

<p>Unfortunately, I don't have information of the variety ""Q sales for clothing item X at price P"" for a variety of prices; this would be hard to estimate due to the small number of items in each category.</p>

<p>However, I do have a distribution of sales vs. price and the distribution of price of items in the shop. I'm thinking if I compute
$$
\frac{\text{% of all sales at this price}}{\text{% of available items at this price}}
$$, that gives me something analogous to a ""quantity demanded"". For simplicity, I bucketed the prices and sales into $5 increments.</p>

<p>Having done this and doing your traditional log-linear fit
$
\ln(P) = a\ln(Q)+b
$ I get a pretty good fit and a reasonable number (around $-.9$).</p>

<p><strong>Question 1</strong>: Does my methodology make sense? If so, what did I just calculate? I feel like it's an ""aggregate"" price elasticity of all items in the shop. The clothing items for sale are mostly substitutable with each other, the price elasticity of an individual item must be a lot higher (since there are substitutes available).</p>

<p><strong>Question 2</strong>: Is there a way to figure the ""average"" price elasticity of each item from this (approximating that they all have about the same price elasticity)?</p>

<p><strong>EDIT:</strong> Based on the suggestion from @optimal-control and @NickJ, it appears the issue is that I don't really have a good model of what's going on. Here's what I'm imagining:</p>

<p>Suppose you have $n$ unique items, each with a fixed price $p$. Each item has a limited supply available $s$. I observe $q(p, t)$ sales for each unique item, limited by $s$. Let's say $q(p, t)$ is something like a homogeneous poisson process, for simplicity.</p>

<p>The above is starting to look like a markdown optimization problem; I could imagine finding an optimal price for each item based on these factors and my cost structure (storage cost, time value of money, etc.), if I could, say, change prices and estimate the change in $q(p, t)$. Unfortunately, this function is so small, and $s$ is so small (maybe 1 to 5 items) that this may be impossible to estimate. What I'm trying to figure out is some way to estimate the response of $q(p, t)$ with respect to $p$ without modifying prices, off of the assumption that the $n$ items are partial substitutes for one another.</p>

<p>If they were perfect substitutes, I would expect ALL of my lowest price items to sell out, and then my next lowest, etc. going on upward and I could use these results to estimate $q(p, t)$. But clearly this isn't the case, because some more expensive items sell first. The problem is, $q(p, t)$ is dependent on the mix of items and prices available. Any thoughts on how to approach this?</p>
","<p>In this kind of cases, I think you can not use a simple OLS estimation because of endogeneity of your variables. </p>

<p>Probably, there would be causality between prices and sales data, this means that sales are influenced by prices but also prices are influenced by sales. So, in this case, in order to do a non-biaised estimation, you should use instrumental variables in order to avoid endogeneity issues between your variables.</p>
","5477"
"How do we estimate production functions?","203","","<p>In a standard economics education we learn about production functions, indicating an output as a function of a given input of capital and labour.</p>

<p>An average model looks like this:</p>

<p><strong>(1)</strong>    $F(L,K)=L^{a}K^b$</p>

<p>When dealing with real data however, we are first exposed to regression models which are additive in nature which look like this:</p>

<p><strong>(2)</strong>      $y_i={\beta}_0+{\beta}_1x_1+{\beta}_2x_2+...+{\beta}_nx_n$</p>

<p>How do we get a production function that looks like (1) when dealing with real data? </p>
","<p>The following is the basic idea if we are to estimate the parameters by linear regression.</p>

<ol>
<li><p>Take the natural log of the production function $F(L,K)=L^aK^b$, you will then get $$\ln(F)=a\ln(L)+b\ln(K).$$</p></li>
<li><p>For each entity (e.g., firm) $i$, collect data on the production level $F_i$, the amount of labour $L_i$, and the amount of capital $K_i$. Note that measurement issues may arise and that it is important to be explicit about how one is to interpret 'production', 'labour' and 'capital', and how to measure them.</p></li>
<li><p>Apply the transformation $X_i\mapsto \ln(X_i)$ for each variable $X_i$ for each entity $i$ in your dataset. (If there is any $X_i$ such that $X_i\leq 0$ then this will not work. You may delete those observations $X_i$ for which $X_i\leq 0$. If it is real data, think about the following question. ""Why is $X_i\leq 0$? Has the dataset been wrongly registered?"")</p></li>
<li><p>Now, regress $\ln(F)$ on $\ln(L)$ and $\ln(K)$ using your converted dataset (cf. 3) under the assumption that the intercept term is equal to $0$. This gives you estimated values $\hat{a}$ and $\hat{b}$ of $a$ and $b$. Hence, your estimated production function, which is supposed to capture some general tendency regarding production, is $$\hat{F}(L,K)=L^\hat{a}K^\hat{b}.$$</p></li>
<li><p>(If the production function is written as $F(K,L)=AL^aK^b$, where $A$ captures technology for example, you will get an intercept term $\ln(A)$.)</p></li>
</ol>

<p>If we are using <a href=""https://en.wikipedia.org/wiki/Nonlinear_regression"" rel=""nofollow noreferrer"">nonlinear regression</a>, then we take the nonlinear least squares (NLLS) estimate of $a$ and $b$ by solving $$\min_{a,\, b}\sum_i\big(F_i-L_i^aK_i^b)^2.$$ Numerical computing softwares (which uses algorithms such as the <a href=""https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm"" rel=""nofollow noreferrer"">Gauss-Newton algorithm</a>) may assist you when finding the NLLS estimate. </p>
","14556"
"Housing Supply Elasticity: Proxy for Exogenous House Price Movements","202","","<p><a href=""http://scholar.princeton.edu/sites/default/files/SSRN-id2412263_0.pdf"" rel=""nofollow"">Mian and Sufi (2014)</a> say</p>

<blockquote>
  <p>We use individual and zip code level data, and exploit cross-sectional variation in house price growth to estimate the impact of rising home values on borrowing and spending. We use the Saiz (2010) housing supply elasticity of a CBSA as an instrument for house price growth, and focus on the heterogeneous effects of house price gains on borrowing and spending.</p>
</blockquote>

<p>And, later</p>

<blockquote>
  <p>The question we seek to answer is: Are housing wealth shocks also shocks to cash on hand? We answer this question by empirically estimating how changes in housing wealth affect
  household borrowing and spending decisions.</p>
</blockquote>

<p>I miss the step on how to get housing wealth <em>shocks</em> as opposed to general equilibrium changes in housing prices. In general, changes in housing wealth are not necessarily exogenous and unanticipated. How does the housing elasticity help to extrapolate exogenous price movements in the housing sector?</p>
","<p>The idea is that all else equal, areas with inelastic housing supply (e.g., areas that are surrounded by water, so you can't just build some more houses ""over that way"") will see greater house price growth, which increases household wealth, and that these differences in supply elasticity are exogenous and uncorrelated with other things that matter. In <a href=""http://mitcre.mit.edu/wp-content/uploads/2014/03/The-Quarterly-Journal-of-Economics-2010-Saiz-1253-96.pdf"" rel=""nofollow"">Saiz (2010)</a>, he uses terrain and water data to determine the degree to which the housing supply in different metropolitan areas is constrained by geographic features.</p>

<p>It's a method that really only works (to the extent that it does) when house prices are rising, which would induce housing construction. If house prices are falling, supply elasticity tends to be pretty low— we don't tend to bulldoze homes at a particularly high rate.</p>

<p>With respect to the degree to which house price changes are anticipated, I think the best work on expectations is that done by Case and Shiller over the years, most recently <a href=""http://www.brookings.edu/~/media/Projects/BPEA/Fall-2012/2012b_Case.pdf?_lang=en"" rel=""nofollow"">Case, Shiller, and Thompson (2012)</a>.</p>
","5393"
"Sanity of lending out made-up money","202","","<h1>Background</h1>

<p>I've done some research to get an understanding into the issue I want to ask about. Regrettably, I found out general descriptions of the mechanism and/or evidently biased explanations, which I've got no means to question. Please excuse me if I refer to a concept in a less than optimal terminology. I'm a bright guy but definitely not a scholar of economics.</p>

<p>Please note that I'm not asking for how fractional banking works in mathematical terms. I'm questioning the sanity of it. Well, not questioning - rather not grasping how it differs from hiding the lack of funds.</p>

<h1>The traditional approach</h1>

<p>Alice owns X units of currency but doesn't use them. Bob comes by and asks to borrow it for a period of one unit of time. As a reward, he promises to return 5% higher amount. Carol comes by and makes the same request with the difference that he promises 10% return on the investment.</p>

<p>Alice considers the chances of the money being paid back in full including the interest as corresponding to the pay-off (e.g. Bob pays up 1.05 X with the probability of 95% and in any other case he's good for nada, zero, ziltch). Alice regards the offers and realizes that there are three options (partial investment of X units isn't of interests).</p>

<ol>
<li>Keep the money in the mattress (0 risk, 0% gain).</li>
<li>Present the money to Bob (5% risk, 5% gain).</li>
<li>Present the money to Carol (10% risk, 10% gain).</li>
</ol>

<p>Here, Alice might ask himself if the inflation forces him to invest into anything, if there's any slightest difference in correlation (5% gain but 5.01% risk) etc. But that's not the aim of the question.</p>

<p>The mechanics of the above is obvious to me. The bigger the risk (time the money invested), the bigger the gain. If at loss, only the amount being risked is lost. I.e. <strong>only the money risked to get the gain is being risked to getting lost</strong>. This part I view as sane and self-controlled.</p>

<h1>The banking approach</h1>

<p>Suppose there's this typical bank, Bank of Scandinavia. As far I've understood the regulations, it's allowed to lend <strong>more</strong> money than it actually possesses, as long as it doesn't go bananas. The government of Scandinavia decided that the bananas level starts at 50%, meaning that if BS owns 10 X units, they can lend out 20 X without being considered unstable.</p>

<p>This part puzzles me, because the gain of the bank is being generated based on equal parts of <strong>the money risked to getting lost</strong> and <strong>some money that doesn't even exists</strong>.</p>

<p>It's my understanding that the stimulation of the economy is far greater using this approach. I also hear that the wealth created this way is sustainable, at least if we keep the bananas level fairly modest.</p>

<p>As far my research went to its conclusion (and by that I mean that I got tired of googling and watching suspected cartoons on YouTube claiming to reveal the ugly truth), I've learned that some governments set the bananas level to 10% (meaning that BS could lend out 100 X). In fact, during a period, there was the level of 3% in US and it was frown upon as <strong>too restrictive</strong>.</p>

<h1>Main question</h1>

<p>Is it correct to regard the lending set-up as <em>unhealthy</em>, bound to implode and cause mayhem (at an <strong>extremely low</strong> risk, which in practice guarantees that such won't take place)?</p>

<p>Or is there a regulatory system covering either the tiny-whiney risky part or, alternatively, a means to recreate and pay back the part of the lost money that wasn't really there? Are there other gains to this set-up except boosting the economy (at incrementally larger risk)?</p>
","<p>There are two ways I can think of interpreting this question.</p>

<p>My first thought is that a single bank doesn't lend out more money than it has, but the <strong>banking system</strong> does. So let's say someone deposits 100 dollars in Bank A and the reserve requirement is 10%. Then Bank A can lend out 90 dollars. Let's say that money is deposited in Bank B eventually. That bank can then lend out 81 dollars. This money then gets deposited in Bank C eventually, and it can lend out 72.9 dollars. This process continues, and if you take the sum of all this lending, you get that the money supply is now:</p>

<p>$$\sum_{n=0}^\infty 0.9^n(100) = \frac{100}{0.1} = 1000$$</p>

<p>So the banking system can lend out 1000 dollars without being considered unstable under this 10% reserve requirement. Notice how it kind of looks like we are double counting the money that is in the economy, and that's the point of fractional reserve banking. There isn't actually 1000 dollars, but there is credit worth that much floating around in the system.</p>

<hr>

<p>The second way you could argue though is that <strong>individual banks</strong> in fact can lend more money than they have in their account. It creates an electronic record crediting the borrower's deposit with the sum of credit. So here, the limitation is still the reserve requirement. Say Bank A gets a deposit of 100 dollars. It can then lend out 1000 dollars at a 10% reserve requirement. Since it doesn't have 1000 in cash, it gives out credit.</p>

<p>I think that the real economy will use a combination of these two methods to get its lending out, but regardless, the result is the same. A simple money multiplier.</p>

<hr>

<p><strong>Edit:</strong> To reiterate (read: copy-pasted) from the comments below, how can a bank lend out credit that isn't backed up by paper/physical money?</p>

<ol>
<li><p>FDIC insurance from the central bank, but more to the point,</p></li>
<li><p>The bank isn't going to back up all the credit at the same time. Say in our above scenario (100 dollars, 10% req.) the bank lends out ""air money"" of 5 dollars to someone, who then spends the credit purchasing from a business. The business then claims on that credit, and the bank still had some reserve (10 dollars in cash) to pay the business. Meanwhile, the bank, because it lent out so much credit, is also collecting a lotttt of interest, and borrowers pay back that interest...in cash. That replenishes the reserve. So in an equilibrium money market, hopefully the rate at which the bank gets cash in interest is the same as the rate which they pay back the ""air money"" with that actual cash.</p></li>
</ol>

<p>Take the car example from in the comments. That is, say you ""promise both your friends a car, but you only have one car and both friends know this"". Well, the analogy is a little stilted, not quite parallel to what a bank is like. If you were a bank, you would only <em>lend</em> (not give away forever) out the car if you were promised to get it back with some interest, (maybe more gas or something). Problems only happen if both friends want the car the same time. </p>
","9758"
"Extensive form: pareto inefficiency?","200","","<p><img src=""https://i.stack.imgur.com/ept0F.jpg"" alt=""enter image description here""></p>

<p>The question I'm dealing with is:</p>

<blockquote>
  <p>Suppose A plays <em>bf</em>, Which of B's strategies would lead to an outcome that is not pareto efficient?</p>
</blockquote>

<p>The answer is apparently <em>ei</em> as $(bf,ei)=(0,5)$, but I don't understand why. If this answer is correct, could you please explain why?</p>

<p>My understanding of pareto efficiency is that by moving from $(x,y)$, we cannot make any player better off without making the other worse off. If this is the case, then $(x,y)$ is pareto efficient.</p>

<p>$(x,y)$ would be pareto inefficient if there exists a movement away from $(x,y)$, where a player can be made better off without the other being made worse off.</p>

<p>From $(bf,ei)=(0,5)$, we can move to:</p>

<p>$(4,4), (5,0),(2,2)$</p>

<p>I don't see how we can move to any of these without making B worse off, I think that $(bf,ei)$ represents a pareto efficient outcome.</p>

<p>Any chance you could offer some advice?</p>

<p>Thanks.</p>
","<p>Thanks to denesp, I realised that I was only considering outcomes resulting from the following subgame:</p>

<p><img src=""https://i.stack.imgur.com/zYatG.jpg"" alt=""enter image description here""></p>

<p>If you consider all outcomes within the extensive form, then it is clear that $(2,6)$ pareto dominates $(0,5)$.</p>
","5250"
"Reconciling low wages with high technology and high education","199","","<p><a href=""http://www.bbc.co.uk/news/business-36821582"">This</a> is one example of many recent doom storied prognosticating that the ""millennial"" generation will be the first in (recent) history to experience lower incomes than their predecessors—at least in western societies like the UK.</p>

<p>How can we reconcile the idea that millennials will earn lower wages with the observations that</p>

<ul>
<li>millennials work with better production technology than their parents did</li>
<li>millennials have enjoyed higher levels of education/training than their predecessors, and are therefore presumably more productive?</li>
</ul>
","<p>It must be pointed out that, over at least a century or two, technology has been improving at the same time that median, mean, and bottom percentile incomes everywhere have been increasing. This seems to be nearly irrefutable evidence that  technology doesn't itself make workers poorer. </p>

<p>Technology and knowledge makes society wealthier: even poor people all over the world now have enough wealth to own a small device called a cell phone that lets them have a rich life in terms of entertainment, access to services, banking, communication with their loved ones, etc. BUT, that doesn't not mean we all get paid more, because what money does is that it lets you buy somebody else's time. But obviously if you and I both produce more, it can't be the case than now I can buy more of your time than before.... We can both buy lots of things that our parents never even dreamed of, but we can't buy more of each other's time....</p>

<p>Its still definitely true that if your folks work manual jobs, you will get a higher income than they do because you will get a high productivity job. In fact you see a lot of uneducated people being supported by their children with reasonable jobs and being helped with the phone and the google maps and the Amazon shopping thing. The issue is that older people, on average have moved up the command ladder, so they are doing management and maybe managing all these youngsters that are super productive at the basic tasks that they are given. These youngsters are productive, but they are not the managers, and they couldn't be. Technology does not make them better at managing people, only experience and age give you that ability. So despite high productivity, they don't get paid a lot, specially since unemployment has been so high for so long. But, they will be paid a lot when they become the managers....</p>

<p>Of course, there are also differences in the distribution of income over time. Apparently, its true that the fraction of income going to workers (the ""labor  share"") was low over the 90's and 2000's and also that general inequality within countries has increased. Also, young, low skilled workers, during this period suffered the brunt of the crisis, staying unemployed and learning less on the job that other cohorts. So, if you focus on the young, the low skilled, the ones that were looking for their first jobs between 2008 and 2011, you will probably find relatively low incomes. There are also individual skills that have been replaced by technology, like typists, or long distance operators. </p>

<p>Still, its hard to argue that the majority of the US young people are worse off in life than their parents. </p>
","12813"
"When should one use Lagrange Multipliers as opposed to calculating the ratio of Marginal Utilities for MRS?","199","","<p>As far as I could see in the examples I found, they led to the same result through relatively similar processes.  I have only looked at 2 variable utility functions, so is does the use of Lagrange become evident beyond that?  I.e. U(x,y,z) and if so is that the only real use for Lagrange Multipliers?</p>

<p>Edit:  For clarity, I was wondering about why Lagrange Multipliers are used instead of simply calculating partial derivatives individually to find the MRS.  What MRS-related situations are Lagrange Multipliers used in?  Why are they used in those situations?</p>
","<p>Lagrange multipliers not only incorporate constraints on a maximization/minimization problem, but the multiplier itself can have a meaningful interpretation. For example, say we have the problem:</p>

<p>$$\max_{x, m}: U(x, m) = m + \phi(x) \quad s.t. m + px = y$$</p>

<p>Where $m$ is a numeiare good, $p$ is the price of good $x$, and $y$ is income.</p>

<p>Now you could just rewrite the constraint as</p>

<p>$$m = y - px$$</p>

<p>and substitute that into the original maximization problem. But you can't always do this easily. So you can also solve with a Lagrangian.</p>

<p>$$\mathcal{L} = m + \phi{x} - \lambda(m + px - y)$$</p>

<p>Solving for $\lambda$ will give you the shadow price of income, or the marginal price of income. That is, it represents the rate of increase in maximized utility as income is increased. You also need to find $\lambda$ to get a nice full Marshallian demand, or to relate indirect utility to Marshallian demand in <a href=""https://en.wikipedia.org/wiki/Roy%27s_identity"" rel=""nofollow"">Roy's identity</a>.</p>

<p>Even for problems that aren't utility maximization, $\lambda$ is still representing the rate of change of the quantity being optimized as a function of the constraint variable.</p>

<p>Here's a <a href=""http://mjo.osborne.economics.utoronto.ca/index.php/tutorial/index/1/ilm/t"" rel=""nofollow"">useful example</a> with the firm maximization problem and bribing problem.</p>
","10499"
"equilibrium, optimum, and decentralizing the optimum","197","","<p>I'm reading a paper on parking:
Anderson &amp; de Palma, 2003, <em>The economics of pricing parking</em>.</p>

<p>The authors repeatedly refer to either 'decentralizing the optimum' or 'the optimum can be decentralized'....</p>

<p>Here is an example: </p>

<blockquote>
  <p>The optimum involves <em>unequal treatment of equals</em> in the sense that
  different individuals get different utilities at the optimum.  Those
  who are allocated to park closer to the [central business district]
  get higher utility than those who park further away.  The optimumm can
  be decentralized via pricing of parking.  Since parking is more
  desirable closer to the center, the optimum parking tariff increases
  with closeness to the CBD in order to counteract this effect and
  reduce the over-congestion that is more pronounced closest to the CBD.
  We next derive the optimum parking tariff.</p>
</blockquote>

<p>Q1: In general in economics literature and/or in the context of this paper, is ""optimal"" generally accepted as referring to Pareto efficiency?</p>

<p>Q2: What does it mean to ""decentralize the optimum"" ?</p>
","<p><strong>Q1</strong> Optimal usually means one of two things:</p>

<ul>
<li>Pareto optimal (there's no way to change the outcome such that everyone is at least as well-off, but someone is strictly better-off).</li>
<li>Optimal in the utilitarian sense (we maximise the sum of everyone's profit/utility).</li>
</ul>

<p>If utility/profit is quasilinear then the two concepts coincide.</p>

<p>This paper appears to be using the utilitarian standard: the optimum is the allocation that minimises the sum of everyone's costs (which, in this case, are the time spent travelling and parking).</p>

<hr>

<p><strong>Q2</strong> To understand what is meant by decentralisation, it is useful to first know what we mean by centralisation. We say that a decision is centralised if there is one agent (often called a ""social planner"") who makes all of the decisions and imposes them on society. </p>

<p>We know from experience that governments are not very good at centrally planning things (cf. the USSR). Thus, an interesting question is whether we can set up a market, system of prices, or other kind of mechanism such then we can leave each individual to his/her own devices and still end up with the optimal outcome (such as how we get the efficient outcome under perfect competition, without any kind of central planner).</p>

<p>When everyone is left to their own devices like this, the market is said to be <em>decentralised</em>. We say the optimum is decentralised if we find a way to decentralise the market such that the end result is optimal.</p>
","13880"
"Basic Solow Growth Model: Stability Proof","196","","<p>I am reading through McCandless ""The ABCs of RBCs"" this summer to get a preview of what I need to know for the coming Fall semester. It did not take long to find a statement that I can easily accept but cannot prove. On Page 9 after deriving the steady state condition of $(\delta + n)\bar{k} = \sigma A_0 f(\bar{k})$ in a zero-technological growth regime (where $\delta$ is depreciation and $n$ is growth rate of the labor force), the author says that ""the stability of the positive stationary state can be seen from the equation $$ k_{t+1} = g(k_t) = \frac{(1-\delta)k_t + \sigma A_0 f(k_t)}{1+n}$$ Notice that between 0 and the positive $\bar{k}$, the function $g(k_t)$ is above the 45 degree line, so that $k_{t+1}$ is greater than k_t."" He provides a standard-looking Solow model state diagram where I can verify this graphically, but not analytically.</p>

<p>I'm trying to prove every statement in the book in order to better familiarize myself with the details of macroeconomic theory before diving deeper, but I am absolutely stumped as to how I would prove that $k_{t+1} &gt; k_t$ when $0 &lt; k_t &lt; \bar{k}$ and vice versa. I first tried manipulating the capital motion equation to prove it directly, and I could not reach a proof. The next strategy I have been trying to employ is to differentiate the capital motion equation and prove that its derivative is less than 1 at the steady state point, but it fails:</p>

<p>$$
\frac{\partial k_{t+1}}{\partial k_t} = \frac{(1-\delta) + \sigma A_0 f'(k_t)}{1+n} &gt; \frac{(1-\delta) + \sigma A_0 f'(\bar{k})}{1+n} = \frac{(1-\delta)+(\delta+n)}{1+n} = 1
$$</p>

<p>Does anyone have an alternative strategy I can follow? It's been driving me nuts for two days.</p>
","<p>For stability, we want 
$$\frac{\partial k_{t+1}}{\partial k_t}\Big|_{\bar k} &lt;1 \implies  \frac{(1-\delta) + \sigma A_0 f'(\bar k)}{1+n} &lt;1$$</p>

<p>$$ \implies f'(\bar k) &lt;  \frac {\delta+n}{\sigma A_0 } = \frac {f(\bar k)}{\bar k}$$   </p>

<p>So we need the marginal product of capital to be smaller than the average product at the steady state. </p>

<p>Equivalently, we need $\bar k f'(\bar k) &lt; f(\bar k) \implies f(\bar k)-\bar k f'(\bar k)&gt;0$. And this holds, doesn't it? Otherwise...</p>
","16768"
"Price discrimination- how much is optimal?","196","","<p>I am of the understanding that as a general rule, price discrimination does not benefit consumers. Yet I can think of a situation where it does. Look at two countries, Australia and India. The price levels are very different. If there is no price discrimination, prices are identical. Suppose firm profits were higher if they priced out Indians and sold just to Australians.</p>

<p>I am of the impression consumer surplus will be higher if a firm could choose two different prices, one to India and one to Australia.</p>

<p>Under what conditions would partial price discrimination be beneficial?</p>

<p>I am thinking, for simplicity, this firm is a monopolist and there are >2 types of consumers, each with a different valuation of the good.</p>
","<p>Varian has a paper on <a href=""http://au4372.epage.au.edu.tw/ezfiles/71/1071/attach/31/pta_15648_4821688_82730.pdf"">Price Discrimination and Social Welfare</a> in which he gives some necessary and sufficient conditions for (third degree) price discrimination to increase welfare.</p>

<p>A necessary condition is that the total level of output (i.e. the total number of consumers served) increases as a result of the discrimination. </p>

<p>A sufficient condition is that the profitability of the new output (i.e. after discrimination) exceeds the profitability of the old output (before discrimination) evaluated at the new prices.</p>
","291"
"price elasticity: Linear regression low r square","196","","<p>I faced an interview question for a job where interviewer asked me suppose your r square is very low (between 5 to 10%) for a price elasticity model. </p>

<p>How would you solve this question? Anything that a typical econometrics guy would do?</p>

<p><strong>Edit</strong>: <em>I have posted <a href=""https://stats.stackexchange.com/questions/277292/data-scientist-interview-question-linear-regression-low-r2-and-what-would-yo"">this</a> question in <a href=""http://stats.stackexchange.com"">stats.stackexchange.com</a> forum for understanding this problem from the perspective of model diagnostics and feature engineering</em></p>
","<p>I would raise two issues about the dataset to which the regression line was fitted:</p>

<p><strong>The range of prices in the dataset.</strong>  If the datapoints all lie within a very narrow range of prices, then even small variation (whether real or due to measurement error) in the associated quantities can lead to a low coefficient of determination $R^2$.  In terms of the formula:</p>

<p>$$R^2 = 1 - \frac{\text{Residual sum of squares}}{\text{Total sum of squares}}$$</p>

<p>a narrow range of prices tends to result in little of the total sum of squares being explained and most of it being residual, resulting in a low $R^2$.  Note that it is assumed here that the regression takes price as the independent variable and quantity as the dependent variable.</p>

<p><strong>The number of datapoints.</strong>  If the number is small, then, even within its range of prices, the dataset may happen to be unrepresentative of the distribution of points within the population of interest. This can result in the squared residuals calculated from the dataset being on average either much smaller or much larger than is representative of the population.  Thus it is possible that $R^2$ has been correctly calculated from data which is not representative of the population.</p>
","16619"
"Why doesn't anyone talk about GNW (Gross National Wealth)?","196","","<p>I just noticed a very interesting fact. </p>

<p>GDP of the United States: $18.5B</p>

<p>GDP of China: $11.4B </p>

<p>If we look at national wealth... </p>

<p>GNW of the United States: $84.8B</p>

<p>GNW of China: $24.1B</p>

<p>The margin of the GNW is 8.5 times higher of that of the GDP! Why is GDP so paraded and why do we never hear about national wealth? </p>

<p>Sources: <a href=""https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)</a>, <a href=""https://en.wikipedia.org/wiki/National_wealth"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/National_wealth</a></p>
","<p>Historically, the distinction between GDP and GNW goes back (at least) to Adam Smith. Before Smith, it was quite common to measure a country's economic power by its wealth. For example, this was very characteristic of the <strong>Mercantilistic school</strong> in the 17th century. Following the motto ""you are what you have"", mercantilists suggested that countries should try to accumulate as much wealth (for them: gold) as possible. This was to be achieved by a combination of an export oriented economy and political measures to limit imports such as tariffs. Selling goods abroad and keeping one's currency (again, gold) they hoped would result in having more money and thus being more wealthy. This idea is reasonable for the middleages where the difference between having and not having money can decide about which country is able to hire more mercenaries and has the potential to decide wars.</p>

<p>For more modern societies a country's wealth (read assets) becomes less important.  <strong>Adam Smith</strong> was the first to realize that the ""Wealth of Nations"" is not so much about how much money they have but rather about how much economic welfare they can generate. This is measured in the number of goods and services produced in a given year, nowadays known as GDP. </p>

<p><strong>From today's perspective, why do we use GDP rather than GNW:</strong></p>

<ul>
<li>Actual production is much more important to determine a country's productivity than its wealth</li>
<li>Accumulated wealth (GNP) measures past wealth while this years production of goods and services (GDP) is a good indicator of future wealth</li>
<li>There is probably also some path dependency. Given that hardly anyone ever hears about GNP, I agree with you that (despite all arguments against it) GNP is slightly underrated.</li>
</ul>
","14825"
"Applications/generalizations of a theorem of Debreu","195","","<p>I would like to know how the last theorem in Debreu's paper ""Neighboring economic agents"" (La Decision 171 (1969): 85-90; reprinted in G. Debreu, Mathematical Economics: Twenty Papers of Gerard Debreu (1986), pp. 173-178) has been used:</p>

<p><strong>Theorem.</strong> <em>For a topological space $M$ and a metric space $H$, let $\varphi$ be a set-valued mapping from $M$ to $H$ that is compact-valued (i.e. $\varphi(e)$ is compact for every $e \in M$) and <a href=""https://en.wikipedia.org/wiki/Hemicontinuity#Implications_for_continuity"">continuous</a>. Further, for each $e \in M$ let $\lesssim_e$ be a total preorder on $\varphi(e)$ such that the set $\{(e, x, y) \in M \times H \times H : x \lesssim_e y\}$ is closed. Then the set-valued mapping $\varphi^0$ from $M$ to $H$ where</em></p>

<p>$\varphi^0(e) = \{z \in \varphi(e) : x \lesssim_e z \ \ \mbox{for all} \ x \in \varphi(e)\}, \quad e \in M,$</p>

<p><em>is compact-valued and <a href=""https://en.wikipedia.org/wiki/Hemicontinuity#Upper_hemicontinuity"">upper hemi-continuous</a>.</em></p>

<p>Note that the theorem looks similar to the well-known Berge Maximum Theorem. Prior to the statement of the theorem, Debreu writes that special cases of it ""have been repeatedly used in the theory of economic equilibrium and in game theory"", but doesn't give any references; in the paper itself, it's used to prove the upper hemi-continuity of the demand correspondence for an agent in an exchange economy.</p>

<p>I'm especially interested in whether there have been any recent uses or generalizations of this theorem, e.g. to mappings that are not compact-valued.</p>

<p><strong>Questions:</strong> What are some good examples of and/or references for applications of the above theorem? Has it been generalized to mappings that are not compact-valued?</p>
","<p>This result is indeed a version of Berge's maximum theorem. If there is a continuous function $u:M\times H\to\mathbb{R}$ such that $x\preceq_e z$ if and only if $u(e,x)\leq u(e,z)$, one can derive the result directly from Berge's maximum theorem. If $H$ is locally compact, as it is the case if $H=\mathbb{R}^n$, then such a function can always be found, this follows from Theorem 1 in Mas-Colell's <em><a href=""http://www.econ.upf.edu/~mcolell/research/art_023.pdf"">On the Continuous Representation of Preorders</a></em> (at least if $M$ is metrizable, I'm not sure on that point). More on such ""jointly continuous utility functions"" can be found in chapter 8 of <em>Representations of preference orderings</em>, 1995, by Bridges &amp; Mehta.</p>

<p>Now Debreu did not have such a result available, so he worked with preference relations and essentially reproved Berge's maximum theorem (the generalization is mathematically straightforward). Why did he do so? To understand that, one needs to understand the point of Debreu's paper, which is finding a topology on preference relations that has nioce properties and makes economic behavior continuous. The need for such a result comes from the literature on economies with a continuum of agents. </p>

<p>What does it mean that a continuum of agents economy is the limit of a sequence of finite eonomies? One answer is that the distribution on characteristics of agents converges to the distribution of characteristics in the continuum economy, so the notion of convergence is convergence in distribution. To make this idea operational, one needs to topologize the characteristics of agents. Now an agent is characterized by her endowment and by her preferences (and in more general models by her consumption set). There is a natural topology on endowments, the Euclidean topology, but it is less straightforward to topologize preferences, and that is what Debreu did in his paper. An exposition of this distributional approach can be found in Hildenbrand 1974, <em>Core and equilibria of a large economy</em>.</p>

<p>Now, there are cases where one would like to apply Berge's theorem for non-compact sets of choices. This can be important when studying economies with infinite dimensional commodity spaces, in which being closed and bounded does not imply compactness. One way to deal with this problem is to find a compact set so that the correspondence is compact-valued and nonempty-valued when restricted to this set. There is a large, very technical, literature on ""generalized games"" or ""abstract economies"" (basically normalform games in which strategy spaces depend on the actions of others), and they implicitely often contain non-compact generalizations of Berge's theorem. If you can get your hands on the book, check chapter 4 of Xian-Zhi Yuan 1999, <em>KKM Theory and Applications in Nonlinear Analysis</em>. My impression, however, is that these results proved to be not that useful in economic applications. To prove existence of Walrasian equilibria in models with infinite dimensional commodity spaces, one usually uses different methods.</p>
","5608"
"USD/CAD fx: What's the difference between Buying USD and Selling CAD?","195","","<p>Beginner question here.
I'm Canadian, and my investement account is, by default, in CAD currency.
Recently I wanted by buy a US stock so I had to convert some of my CAD money in USD money.</p>

<p>There would have been other ways, but this led me to use an FX tool. The interface was similar to this:</p>

<p>Action: [ ] Buy [ ] Sell</p>

<p>Currency: [ ] CAD [ ] USD</p>

<p>So basically, in order to do what I wanted to do (convert CAD to USD), I had 2 options:</p>

<p>A) Buy USD</p>

<p>B) Sell CAD</p>

<p>What's the difference between both actions ?</p>
","<p>Should be no difference. </p>

<p>You are either (1) buying USD by selling CAD or (2) selling CAD to buy USD. </p>
","12721"
"Why plug deficits with bonds rather than printing money?","194","","<p>The UK is running a budget deficit £107 billion a year. Inflation is currently running at 1%. </p>

<p>Given these facts, why do they plug the gap by selling debt rather than just creating the money to cover the gap?</p>

<p>Just creating the money seems like it has a lot of upside and not a lot of downside when inflation is so low. Why do we not see countries doing this?</p>
","<p>There are several issues with this approach. One is that any changes in the quantity of money - including those considered 'acceptable amounts of inflation' - act to distort the price signal being communicated to all economic participants which is an extremely undesirable side effect. </p>

<p>The other is a little more insidious. Governments can only print cash or asset money. The vast majority, over 98% in most modern banking systems of money being used is liability money - money that is represented as deposits in the banking system. Were the government for example to print physical cash and deposit it in a commercial bank the book keeping operation would be [debit cash, credit deposit]. In almost all cases, it is the deposit money that is actually spent as the government pays salaries etc.</p>

<p>So if a government prints money and its banking regime relies on a framework where assets act as a regulatory control on lending (and consequent deposit creation), and there is no other regulatory control, the result is hyper-inflation. The problem is not just the money created by the government, it is the consequent multiplication that results from banks increasing their credit/money creation. (This form of regulation is generally referred to as the reserve requirement in economic literature.) Typically the resulting inflation then leads the government to print more money, and the result is a rapid spiral that quickly destroys the usefulness of the currency concerned for any economic transaction.</p>

<p>Most modern banking systems use a combination of reserve requirements and capital requirements, and this is why the quantitative easing interventions have so far had no inflationary effect on the economies using them. Even though the US government printed a huge amount of money for the TARP intervention, the capital controls intervened to prevent the runaway hyperinflation that would have occurred under earlier regimes. However it's still a dangerous thing to do, and the long term behaviour of banking systems that rely on basel capital controls is poorly understood.</p>

<p>Finally, it's worth noting that the alternative available to any government besides borrowing, is raising taxes or controlling its' expenditure. Ultimately the government's use of social resources has to be regulated by something, and keeping a more or less balanced budget isn't a bad place to start.</p>
","1888"
"Models for online markets with reputation system","193","","<p>The only relevant model I'm aware of is <a href=""http://web.stanford.edu/group/siepr/cgi-bin/siepr/?q=system/files/shared/pubs/papers/pdf/06-30.pdf"">Liu Qingmin(2011 R.E.S)</a>. Is there any other decent models dealing with the mechanism of online markets under reputation system, and perhaps linking to regulation?</p>
","<p>I would suggest you start by looking at</p>

<blockquote>
  <p>C. Dellarocas. ""The Digitization of Word-of-Mouth: Promise and
  Challenges of Online Reputation Systems"". <em>Management Science</em> 49
  (10), October 2003, 1407-1424.</p>
</blockquote>

<p>for a review of relevant literature and</p>

<blockquote>
  <p>Friedman &amp; Resnick ""The Social Cost of Cheap Pseudonyms"". <em>Journal of
  Economcs and Management Strategy</em>. 10 (2), 173–199.</p>
</blockquote>

<p>and</p>

<blockquote>
  <p>""Sustainable Reputations with Rating Systems,"" 2011. Journal of
  Economic Theory, 146, 2, 479-503</p>
</blockquote>

<p>for some models of online reputation systems that comes to mind. If I think of any others, I will update this answer.</p>
","4888"
"Can You Help Me Understand this Definition of Economic Efficiency","191","","<p>Economic Efficiency:</p>

<p>""A broad term that implies an economic state in which every resource is optimally allocated to serve each person in the best way while minimizing waste and inefficiency. ""</p>

<p>And here's the part I don't understand:</p>

<p>""When an economy is economically efficient, any changes made to assist one person would harm another.""</p>

<p>Can someone please unpack that last part for me?  I'm not sure I understand it.</p>
","<p>My advice would to be to keep clearly separate the very specific concept of ""Pareto efficiency"" (which is presented in @BB King's answer and which is implied by the passage the OP quoted), with the more general term ""economic efficiency"", or just ""efficiency"".</p>

<p>""Pareto efficiency"" is a tricky concept and criterion. The concept essentially formalizes the ""limits of Economics"": once an economic system reaches a point where ""one man's gain"" <em>can only be</em> ""another man's loss"", then any further <em>action</em> will have to be based either on value judgements or on the balance of socieconomic power. Economics may analyze these phenomena, but it cannot <em>prescribe</em> further actions under a universally acceptable criterion.</p>

<p>The general term ""efficiency"" on the other hand is used in various places in the Economics literature to essentially refer to ""not wasting resources"", to ""using resources as efficiently as possible"", i.e. in a more narrow sense, usually focused on production. This is a less ambitious, pragmatic route for economics: leave distributional matters aside, focus on maximizing production and then, it is society's burden to allocate this maximized production between its members (when Economics analyzes ""inequality and growth"", it examines whether inequality hurts growth and production, and <em>not</em> whether it is ""good/bad"" from an ethical or philosophical point of view).</p>

<p>There is a whole related subfield in Economics, with an applied focus but based on rigorous theoretical and mathematical analysis, which deals exclusively with the matter, Efficiency Analysis, which has two main branches,  Stochastic Frontier Analysis (SFA), and Data Envelopment Analysis (DEA). Here, we care about whether the productive mechanisms of society ""use the resources efficiently"", where we look at the matter from different complementary aspects: for example,  </p>

<p>Given the available technology, do firms produce the maximum possible output? (""Technical"" efficiency)</p>

<p>Given technology <em>and</em> factor prices, do firms employ the optimal resource mix? (""Allocative"" efficiency)</p>

<p>etc, see for example </p>

<p><a href=""http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780195183528.001.0001/acprof-9780195183528"" rel=""nofollow"">Fried, H. O., Lovell, C. K., &amp; Schmidt, S. S. (Eds.). (2008). The measurement of productive efficiency and productivity growth. Oxford University Press.</a></p>
","12184"
"Find Change in output from marginal products of labor/capital","191","","<p><em>A firm produces 231 doohickeys with 8.4 units of labour and 22.1 units of capital. the marginal product of labour is 18, the marginal product of capital is 20. Approximately how many doohickeys will it produce with 8.6 units of labour and 22 units of capital?</em></p>

<p>Is this just as simple as taking the difference between the new and original values and multiplying that by the marginal product? </p>

<p>i.e. (8.6-8.4) x 18 + (22-22.1) x 20 = 1.6</p>

<p>so they will produce approximately 232.6 doohickeys</p>

<p>Or am i supposed to take the integral of the marginal products and do something with those? i tried that but I couldnt get any where</p>
","<p>I think your solution is golden.</p>

<p>Taking the integral of the marginal products could only work if the marginal products were constant everywhere. This is not mentioned in the text, and in fact if you assume it to be constant then production given this level of $K$ and $L$ would not be 231.</p>

<p>Another interesting tidbit:
<br> If you knew the marginal product function of $L$ and also that of $K$ taking the integrals and summing them up would only work if $MPL$ is constant in $K$ and vice-versa.</p>
","5952"
"Is money supply affected by the stock market?","191","","<p>Do stock prices have any effect on the money supply of an economy? Please provide a simple example if possible.</p>

<p>Intuition suggests there is more money around when prices are high (consider for instance the dotcom boom). I guess the answer may be dependent on what definition of money supply one uses (M0-M4).</p>
","<p>They may, but probably not much. Because stocks cannot be used as a substitute for money in most transactions there is no direct channel. However, because stocks can act as collateral for loans, and loans have the capacity to create money through the money multiplier mechanism they can have some effect, just as anything that relaxes borrowing constraints could increase the money supply. </p>

<p>Collateralized loans make up the vast majority of bank debt. Suppose, for example, that banks only made collateralized loans. Then when stock prices go up, some borrowers formerly at the limits of borrowing constraints due to limited collateral, would be able to take out additional loans. These loan proceeds could then be deposited in banks or spent, either way likely ending up in banks eventually where, through the mechanism of fractional reserve banking, they could be used to create additional money. However, as you can see in the figures below, margin debt is a very low fraction of GDP in contrast to say household overall debt. So in general this is not going to be a big channel. </p>

<p><img src=""https://i.stack.imgur.com/1ISea.jpg"" alt=""enter image description here"">
Source: <a href=""http://www.fool.com/investing/general/2014/03/07/ominous-sign-as-margin-debt-continues-to-rise.aspx"" rel=""nofollow noreferrer"">Ominous Sign as Margin Debt Continues to Rise</a> </p>

<p><img src=""https://i.stack.imgur.com/uZNoT.png"" alt=""enter image description here"">
Source: <a href=""http://en.wikipedia.org/wiki/Subprime_mortgage_crisis"" rel=""nofollow noreferrer"">Wikipedia Subprime mortgage crisis page</a></p>
","6066"
"What is the usefulness of approximating an optimal decision rule that close enough to steadystate in RBC model?","191","","<p>I'm reading <a href=""https://hec.unil.ch/docs/files/80/599/plosser89.pdf"">understanding real business cycle</a> by Plosser.</p>

<p>Here's my crude understanding: For a RBC model, the FOCs of lagrangian together with transversality condition usually forms a nonlinear difference equations system. The standard way of solving this system is by linearization in the neighbourhood of steadystate,  solve this problem as a linear difference equations system.</p>

<p>What insight can we get from this solution, except for gaining  some knowledge of whether the steadystate is locally stable?</p>
","<p>Side note: This is one way of solving it - the alternative would be formulating a Bellman equation and iterating on that.</p>

<p>If you assume that the real economy is on or sufficiently close to the steady state, you can also infer about responses to shocks. That is, you can look at the impulse response functions to a change in whatever interests you, and see how the model economy changes. Arguing that we're close enough to that steady state will allow you to see how the economy responds to certain shocks.</p>

<p>Also, in general, you can simulate the economy with (for example TFP) shocks, and look whether the simulated economy looks similar to the real economy. Using this comparison you could judge the model.</p>

<p>This needs arguing that we are close to the steady state - or that convergence happens really fast. Generally, the growth literature around Solow has provided arguments for this.</p>

<p>But your argument is very present in most extensions of the basic RBC model: especially when it is important <em>how</em> close we are to the steady state - when models are more nonlinear. There have been many papers showing that this is the case for standard Neo Keynesian extensions of the RBC model.</p>
","3376"
"Why Need a Numeraire Good in Dynamic Analysis","190","","<p>Often in macro pure exchange economy models (sequential trading), authors make the initial period good price $P_0=1$ asserting this set-up is to make the consumption at period $0$ the numeraire.</p>

<p>But I don't see any detailed explanation or justification for doing this.</p>

<p>Just to add some background story:<br>
The usual set-up is that agents are endowed with some units of goods, say oranges. So the unit of their consumptions is oranges. $P_t$ often the price, at $t=0$, of an orange consumption promised for delivery in period $t$. Why make $P_0=1$?</p>
","<p>Is there any reason not to make $P_0 = 1$?</p>

<p>In microeconomics (which your problem seems to be about, rather than macro) consumers are homogeneous of degree zero in prices &amp; income. That is if all parameters measured in money change by the same ratio (say they are all multiplied by 10) consumer decisions are unchanged. The root of this is that what usually matters is the price ratio between two goods. But
$$
\frac{p_1}{p_2} = \frac{r \cdot p_1}{r \cdot p_2}
$$
for all $r &gt; 0$, so any proportional price change does not change the price ratio between two goods.</p>

<p>As a result of this, we are usually left with a degree of freedom when solving these models. To do away with it and simplify equations it is best to just arbitrarily select a good and appoint it numeraire.</p>

<p>In macroeconomics you have similar issues if you assume the <a href=""https://en.wikipedia.org/wiki/Neutrality_of_money"" rel=""nofollow noreferrer"">neutrality of money</a>.</p>
","14776"
"What is an econometrician?","189","","<p>According to Wikipedia, <em>Econometrics is the application of mathematics, statistical methods, and computer science to economic data and is described as the branch of economics that aims to give empirical content to economic relations</em>. It <em>sifts through mountains of data to extract simple relationships</em>. Generally for positions like Analytic Consultant, Data Scientist, Statistician, Quantitative Analyst, background in maths, stats or econometrics is required. What separates econometricians in terms of what they learn in school and how they apply acquired knowledge in work? Or do these fields overlap so much that there is not much to distinguish?</p>
","<p>An interesting question that leads to a debate among econometricians. Some consider that </p>

<p><strong>Econometrics is just statistics applied to economic problems</strong></p>

<blockquote>
  <p>Econometrics is just statistics applied to economic problems—nothing
  more and nothing less. We should probably call it “statistical
  economics,” but I guess people feel that the term “econometrics” has a
  better ring to it. The only cost of using the term “econometrics” is
  that we are sometimes fooled into thinking that we work on a distinct
  discipline, separate from statistics. This is not true. </p>
</blockquote>

<p>From John Stachurski at ANU (see his notes p.108 in Econometric Theory <a href=""http://quant-econ.net/_downloads/course_notes.pdf"">freely downloadable</a>)</p>

<p>Others consider that</p>

<p><strong>Eonometrics by no means the same as economic statistics</strong></p>

<p>This quote is from <a href=""https://en.wikipedia.org/wiki/Ragnar_Frisch"">Ragnar Frisch</a> (one of the founders of the Econometric Society) and his <a href=""http://www.jstor.org/stable/1912224?seq=2#page_scan_tab_contents"">Editor's Note</a> on why the Society has decided to establish its own journal, <a href=""https://www.econometricsociety.org/publications/econometrica/browse"">Econometrica</a>.</p>

<p>The key idea is that <strong>economic theory</strong> is crucial to understand measurement. Neither theory nor measurement on its own is sufficient to further our understanding of economic phenomena. We need both and measurement without theory is unlikely to provide a satisfactory explanation of the way economic forces interact with each other.</p>

<p>Another difference is, as economists, we are biased towards establishing <strong>causal relationships</strong>. So, this explains our focus on endogeneity issues and strategies of identification.</p>
","12392"
"Aggregating CRS Production Functions","188","","<p>If thera are two firms and both of them have constant returns to scale production function. Will the aggregate/industry production function still be the sum of individual production functions. How does CRS effect the aggregate production function of industry? </p>
","<p>Consider two firms with production functions $A_1 F(k,l)$ and $A_2 F(k,l)$. Both have the same curvature (and are CRS), but one is more productive. Here we can solve the social planner's problem (why?) instead of looking at a competitive equilibrium. He will want to equalize marginal returns across the firms. As one is more efficient, it will get more inputs. </p>

<p>And what is the maximum? Give <strong>all</strong> of the inputs to the more productive firm. This is because of CRS (which indeed means that as you scale up one production function, it's marginal product will <strong>always</strong> be larger than the other one's). </p>

<p>That is, define $G(l, k)$ as the aggregate production function. It is given by</p>

<p>$$ G(l,k) = \max_{(l_i, k_i)_{i=1,2}} A_1F(k_1,l_1) + A_2F(k_2,l_2) \text{ s.t. resource constraint}$$</p>

<p>The solution here is $G(l,k) = A_1F(k, l) $ if $A_1 &gt; A_2$, and vice-versa.</p>

<h3>Adding Up Makes No Sense</h3>

<p>If you think that adding them up makes sense, you're not thinking things through:</p>

<p><em>If one cook can bake one cake with each egg, and the other cook can also bake one cake with each egg, then the two cooks together can bake two cakes with each egg?</em></p>

<h3>Decreasing returns to scale</h3>

<p>Now, it won't be the case that one firm is more productive than the other one <em>always</em>. Consider $F_1(k_1) = A_1 k_1^\alpha$ and $F_2(k_2) = A_2 k_2^\alpha$. You will want to split up capital between the two firms such that marginal returns equalize: $k_1, k_2 : F_1'(k_1) = F_2'(k_2)$. Due to DRS, this necessarily means that both $k_1, k_2 &gt; 0$. I leave the actual derivation of the aggregate production function as an exercise.</p>
","9013"
"Why is the consumption line and 45degree line's intersection not the equilibrium income level?","188","","<p>The question is as below</p>

<p><a href=""https://i.stack.imgur.com/Iki8I.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Iki8I.jpg"" alt=""enter image description here""></a></p>

<p>The answer is A. I understand why it is A, but do not understand why it isn't C. Doesn't the point where the consumption line and 45 degrees line intersect represents the equilibrium income level?</p>
","<p>For most people consumption does not equal income. Many consume less (they save) and others consume more (they take on debt) than they earn. In an economy with financial markets and heterogeneous consumers, discounted lifetime income should equal discounted lifetime consumption, but there is no reason why consumption should equal income at every point in time.</p>
","14961"
"Decision Theory Question: Existence and uniqueness of the certainty equivalent of p","187","","<p>Let $X = (x_*,x^*)$ be an interval in the real line and denote by $\Delta(X)$ the set of simple probability distributions on $X$. Consider a preference relation $\succcurlyeq$ on $\Delta(X)$ that satisfies the axioms of expected utility theory. If $\succcurlyeq$ displays monotonicity with respect to first order stochastic dominance and risk aversion then for all $p \in \Delta(X)$ the certainty equivalent of $p$ exists and is unique. </p>

<p>Sketch of the proof: </p>

<p>1) We define the certainty equivalent of lottery $p$: $CE_p \sim \int_{X}u(x)p(x)dx$ </p>

<p>2) We know that if $p$ FOSD $q$ then $p\succcurlyeq q$</p>

<p>3) Because of risk aversion: $\int_{X}u(x)p(x)dx \leq u(\int_{X}xp(x)dx) =u(p)$</p>

<p>4) We want to show that $\exists$ a lottery, call it $s$ such that $CE_p \sim s$; in this respect (from 3 above) we know that $p \succcurlyeq s$; We then pick a particular lottery $q$ such that $p \succcurlyeq q$ </p>

<p>5) Since by assumption $\succcurlyeq$ on $\Delta(X)$ satisfies the axioms of expected utility theorem (in particular continuity) there exists a unique $\alpha$ such that  $\alpha p + (1-\alpha) q \sim s$ ( see MWG p. 177). We therefore proved that $\exists$ a compound lottery $s$ that is the certainty equivalent of lottery $p$.</p>

<p>QUESTION: Am I missing any detail in the proof?</p>
","<p>Your notation is a bit misleading: it would be better to write $\mathbb{E}u(p)$ or $U(p)$ for the expected-utility associated with $p$ instead of $u(p)$, and $u(\mathbb{E}p)$ for the utility of the expected value of $p$. Formally $u$ is defined on $X$ and not on $\Delta(X)$.</p>

<p>Regarding your proof, it seems to me that: $(i)$ you don't explain how to find $s$; $(ii)$ you don't find a certainty equivalent, because $s$ is a lottery. What you want to find is a sure monetary prize, i.e. a <em>degenerate</em> lottery, that the decision-maker values equally as the lottery $p$.</p>

<p>For instance, you can notice that, by the monotonicity of $u$,
\begin{equation}
u(x_{*})\leq \int_{X}{u(x)p(x)dx} \leq u(x^{*})
\end{equation}</p>

<p>In addition, the function $u:x \rightarrow u(x)$ is continuous. Therefore, by the intermediate value theorem, there exists $CE_p \in [x_{*},x^{*}]$ such that $u(CE_p) = \int_{X}{u(x)p(x)dx}$. </p>

<p>For the uniqueness, imagine that $CE'_p$ is another certainty equivalent of $p$, i.e. that $u(CE'_p)=u(CE_p)$. Since $u$ is strictly increasing (which can be seen as a consequence of the monotonicity with respect to first-order stochastic dominance), we obtain $CE'_p=CE_p$.</p>

<p>Notice that you don't need risk aversion to prove the result, but further implies that $CE_p \leq \mathbb{E}p$.</p>
","8877"
"Omitted variables in gravity model","186","","<p>I'm trying to construct a gravity model for EU trade flows using a panel dataset, but am suffering from what appears to be a persistent omitted variable problem. My residuals display a queer log-like, almost polynomial type pattern when plotted against the log of trade volumes. </p>

<p>I have searched the literature and included every variable in the model that has appeared in previous studies, including the logs of;
- gdp per capita
- real and nominal gdp
- distance - multiple different measures.
- Real and nominal exchange rates. 
- Price levels - various measures. 
- Proxies for product differentiation. 
- Exporter / importer fixed effects. 
- Dummies for things like Schengen / Euro membership, home trade, etc. 
Still, the curvilinear / log pattern remains. </p>

<p>Can anyone conjecture as to what the omitted variable may be? I have exhausted my knowledge of the theory. </p>

<p>Any help would be very gratefully appreciated. </p>

<p>Many thanks, </p>

<p>Robert. </p>
","<p>The omitted variable bias in gravity model is an important issue given that some factors are unobserved or difficult to quantity. To solve this issue trade economists tend to rely on various fixed effect estimators. But, the question is what is your variable of interest?</p>

<p><strong>Exporter-by-year and importer-by-year fixed effects</strong> </p>

<p>For instance, if you are interested in evaluating the effect of trade costs on trade, you can introduce exporter-by-year and importer-by-year fixed effects to absorb GDP, GDP per capita, price indexes etc.</p>

<p><strong>Exporter-by-importer fixed effects</strong></p>

<p>If you are interested in evaluating the effect of one country-specific variable on trade, you can introduce exporter-by-importer fixed effects to absorb distance or contiguity effects.</p>

<p><strong>Exporter-by-year, importer-by-year + exporter-by-importer fixed effects</strong></p>

<p>If you are interested in evaluating the effect of a time-varying bilateral factor, like free trade agreements, on trade (see Baier and Bergstrand, 2007), you can introduce exporter-by-year, importer-by-year + exporter-by-importer fixed effects to absorb distance or contiguity effects as well as GDP, GDP per capita, ....</p>

<p><strong>References</strong></p>

<ul>
<li>Baier, S. L., &amp; Bergstrand, J. H. (2007). <a href=""http://www.cec.zju.edu.cn/reod/proimg/2010929112921446.pdf"" rel=""nofollow"">Do free trade agreements actually increase members' international trade?</a>. Journal of international Economics, 71(1), 72-95.</li>
<li>Baldwin, R., &amp; Taglioni, D. (2006). <a href=""http://graduateinstitute.ch/files/live/sites/iheid/files/sites/ctei/shared/CTEI/Baldwin/Publications/Chapters/Trade%20Effects%20Euro/Gravity%20Dummies.pdf"" rel=""nofollow"">Gravity for dummies and dummies for gravity equations</a> (No. w12516). National Bureau of Economic Research.</li>
<li>Head, K., &amp; Mayer, T. (2013). <a href=""http://strategy.sauder.ubc.ca/head/papers/headmayer_revised.pdf"" rel=""nofollow"">Gravity equations: Workhorse, toolkit, and cookbook</a>. <em>This last reference is a must to read to construct a gravity model.</em></li>
</ul>
","12252"
"Alternative way of deriving OLS coefficients","185","","<p>In <a href=""https://economics.stackexchange.com/questions/3194/what-happens-if-the-control-variables-are-also-endogenous"">another question of mine</a>, an answerer used the following derivation of OLS coefficient:</p>

<blockquote>
  <p>We have a model: $$ Y = X_1 \beta + X_2 \beta_2 + Z \gamma + \varepsilon, $$ where $Z$ is unobserved. Then we have: $$\text{plim}\, \hat \beta_{1} = \beta_1 + \gamma \frac{Cov(X_1^*, Z)}{Var(X_1^*)} = \beta_1, $$ where $X_1^* = M_2 X_1$ and $M_2 = [I - X_2(X_2'X_2)^{-1}X_2']$.</p>
</blockquote>

<p>This looks different from the usual $\beta = (X'X)^{-1}X'Y$ that I've seen in Econometrics. Is there a more explicit exposition of this derivation? Is there a name for the $M_2$ matrix?</p>
","<p>The $\mathbf M = \mathbf I-\mathbf X(\mathbf X'\mathbf X)^{-1}\mathbf X'$ matrix is the ""annihilator"" or ""residual maker"" matrix associated with matrix $\mathbf X$. It is called ""annihilator"" because $\mathbf M\mathbf X =0$ (for its own $X$ matrix of course). Is is called ""residual maker"" because $\mathbf M \mathbf y =\mathbf {\hat e}$, in the regression $\mathbf y = \mathbf X \beta + \mathbf e$.  </p>

<p>It is a symmetric and idempotent matrix. It is used in the proof of the Gauss-Markov theorem.  </p>

<p>Also, it is used in the <a href=""http://en.wikipedia.org/wiki/Frisch%E2%80%93Waugh%E2%80%93Lovell_theorem"" rel=""nofollow"">Frisch–Waugh–Lovell theorem</a>, from which one can obtain results for the ""partitioned regression"", that says that in the model (in matrix form)</p>

<p>$$\mathbf y = \mathbf X_1\beta_1 + \mathbf X_2\beta_2 + \mathbf u$$</p>

<p>we have that</p>

<p>$$\hat \beta_1 = (\mathbf X_1'\mathbf M_2\mathbf X_1)^{-1}(\mathbf X_1'\mathbf M_2)\mathbf y $$</p>

<p>Since $\mathbf M_2$ is idempotent we can re-write the above by</p>

<p>$$\hat \beta_1 = (\mathbf X_1'\mathbf M_2\mathbf M_2\mathbf X_1)^{-1}(\mathbf X_1'\mathbf M_2\mathbf M_2)\mathbf y$$</p>

<p>and since $M_2$ is also symmetric we have</p>

<p>$$\hat \beta_1 = ([\mathbf M_2\mathbf X_1]'[\mathbf M_2\mathbf X_1])^{-1}([\mathbf M_2\mathbf X_1]'[\mathbf M_2\mathbf y]$$</p>

<p>But this is the least-squares estimator from the model</p>

<p>$$[\mathbf M_2\mathbf y] = [\mathbf M_2\mathbf X_1]\beta_1 + \mathbf M_2\mathbf u$$</p>

<p>and also $\mathbf M_2\mathbf y$ are the residuals from regressing $\mathbf y$ on the matrix $\mathbf X_2$ only.  </p>

<p>In other words:
1) If we regreess $\mathbf y$ on the matrix $\mathbf X_2$ only, and then regress the <em>residuals</em> from this estimation on the matrix $\mathbf M_2\mathbf X_1$ only, the $\hat \beta_1$ estimates we will obtain will be <em>mathematically</em> equal to the estimates we will obtain if we regress $\mathbf y$ on both $\mathbf X_1$ and $\mathbf X_2$ together at the same time, as a usual multiple regression.  </p>

<p>Now, assume that $\mathbf X_1$ is not a matrix but just one regressor, say $\mathbf x_1$. Then $\mathbf M_2 \mathbf x_1$ is the residuals from regressing the variable $X_1$ on the regressor matrix $\mathbf X_2$. And this provides the intuition here: $\hat \beta_1$ gives us the effect that ""the part of $X_1$ that is unexplained by $\mathbf X_2$"" has on ""the part of $Y$ that is left unexplained by $\mathbf X_2$"".</p>

<p>This is an emblematic part of classic Least-Squares Algebra.</p>
","3206"
"How does the central bank changing interest rates change interest rates in the commerical banking sector?","185","","<p>I understand that the federal reserve manipulates the federal fund rate in order to change interest rates in the wider banking sector. What I am struggling to understand is how the changing the federal funds rate changes the interest rate charged by commercial banks, e.g. Bank of America, Wells Fargo, etc.</p>
","<p>The federal fund rate is a cost for the commercial banks. They borrow at the federal fund rate and then they lend to the consumers.
The federal fund rate variation impacts the lending cost of the banks directly.
It's how it changes the interest rate charged by commercial banks.</p>
","13878"
"What are some reasons for decline of georgism?","185","","<p>I understand that <a href=""https://en.wikipedia.org/wiki/Georgism"" rel=""nofollow"">Georgism</a> was a major economic idea in the late 19th century.  The idea of a simple <a href=""https://en.wikipedia.org/wiki/Land_value_tax"" rel=""nofollow"">land-value tax</a> and <a href=""https://en.wikipedia.org/wiki/Basic_income"" rel=""nofollow"">basic income</a> derived from an equitable distribution of natural resource exploitation seem to be great ideas solving many of the challenges faced in other economic systems.  Also, <a href=""https://en.wikipedia.org/wiki/Progress_and_Poverty"" rel=""nofollow"">Progress and Poverty</a> was one of the most popular books on economics in the late 19th century.</p>

<p>Why has this seemingly great concept lost popularity?  My speculations is that it either does not benefit the ruling elites (so, politics) or that, more plausibly, the idea of basic income derived from natural resources was calculated to be unsustainable amid the population growth of the turn of the century.</p>
","<p>Warren Samuels addresses this issue in his article ""Why the Georgist Movement Has Not Succeeded: A Speculative Memorandum.""</p>

<p>In summary he argues first that Georgism did not succeed because of the conflation of the ideas of income and productivity, leading people to view a tax on land as a tax on productivity even though the tax is meant to equate income with productivity as referenced in the question. This idea, he says, was reinforced by self-interested beliefs of land owners as well as traders in other markets (he names equities) including preference for passing property through inheritance and viewing the proposed tax system as a threat to income through speculation (such as through the stock market), since it would eliminate speculative gains in land prices. The rise of mortgages and home-ownership increased the number of people with these self-interests.</p>

<p>Second, Samuels addresses the fact that George was viewed by many, including mainstream economists, as a radical and admits that relative to the status quo of changes in tax policy being incremental, the proposed single tax system is radical. The Bolshevik revolution in the 1910's and subsequent red scare caused people to distance themselves from ideas that could be viewed as radical leftist. </p>

<p>Samuels continues on to discuss possible internal reasons, such as lack of leadership amongst George' successors, but notes that he is less confident in discussing these factors. </p>

<p>In addition to this article, four responses and Samuel's response to the respondents can be found in the Jul 2003 issue of American Journal of Economics and Sociology.</p>
","6103"
"Do all mixed strategy Nash Equilibria satisfy Trembling Hand perfection?","184","","<p>Moreover, does it fulfill other criteria automatically, like Myerson's ""Proper equilibrium"" refinement?</p>
","<p>No. Trembling hand perfection would be an additional consideration.</p>

<p>Consider this case:</p>

<p>Two agents engage in a two stage game. In stage one, player one selects Rock, Paper or Scissors. In stage two, player two selects Rock, Paper or Scissors. They receive payouts depending on whether or not they match. They both have identical payout matrices.</p>

<p>Payoffs (Match, Unmatched)</p>

<ul>
<li>Rock (1,0)</li>
<li>Paper (1,0) </li>
<li>Scissors (1,-1)</li>
</ul>

<p>In a mixed strategy nash equillibrium consider player one. He can choose any mixed strategy such that</p>

<p>p(Rock)+p(Paper)+p(Scissors)=1</p>

<p>and they would all be equally rational. Since even if he chooses scissors, a rational player two would match him. However, taking into account trembling hand perfection, the subset of strategies where</p>

<p>p(Scissors)=0</p>

<p>dominate the previous strategy set. This is the case because we are concerned that player two has a chance of making a mistake if we choose scissors and not matching us. Therefore, mixed strategy and trembling hand mixed strategy give us different sets of strategies which fulfill our Nash equilibrium criteria.</p>
","14143"
"Effect of positive inflation shock on the exchange rate","184","","<p>How does a positive inflation shock affect the exchange rate? Does the exchange rate appreciate or depreciate? I am looking for an intuitive explanation. </p>
","<p>Before intuition. let's determine the outcome. By the Uncovered Interest Rate Parity </p>

<p>$$ i_t  = i^*_t - [s^e_{t+1 | t} - s_t] \tag{1}$$</p>

<p>where $i_t$ is domestic nominal interest rate, $i^*_t$ is ""foreign"" nominal interest rate, and $[s^e_{t+1} - s_t]$ is expected <em>appreciation</em> of domestic currency in percentage terms ($s$ is the natural logarithm of ""foreign currency per unit of domestic currency"" exchange rate). </p>

<p>The ""Fisher equation"" for the relation between real and nominal interest rate in expected inflation is</p>

<p>$$i_t = r_t + \pi^e_{t+1|t} \tag{2}$$</p>

<p>where  $r_t$ is domestic real interest rate, and $\pi^e_{t+1}$ is expected domestic inflation. Putting $(1)$ and $(2)$ side-by side we have</p>

<p>$$r_t + \pi^e_{t+1|t} = i^*_t - [s^e_{t+1|t} - s_t]$$</p>

<p>Assuming that there are no real effects by an inflation shock, and that the international economy couldn't care less (so also $i^*_t$ remains unaffected), using the <em>change</em> operator we have</p>

<p>$$\Delta \pi^e_{t+1|t} = \Delta (s_t-s^e_{t+1|t}) \tag{3}$$</p>

<p>where now the right-hand side represents ""change in expected <em>depreciation</em>"" of the domestic currency (note that the right hand side may be algebraically negative in which case it is ""negative depreciation"" = appreciation). </p>

<p>Now, it is reasonable to argue that expectations for tomorrow will take into account what happens today. Moreover, usually current inflation shocks either affect in the same direction expectations about future inflation, or not at all.</p>

<p>So an inflation shock happens in period $t$ which increases the left-hand side of $(3)$. Then so must also increase its right-hand: a domestic positive inflation shock increases expected depreciation of the domestic currency. In other words it creates expectation of currency devaluation. The currency may still be expected to appreciate, but less than before the inflation shock.</p>

<p>Mathematically this can come about in different ways but realistically one should expect that what will happen is that $s^e_{t+1|t}$ will go down, i.e. that the domestic currency will be expected to devalue. </p>

<p>The main intuition behind this comes if one realizes that, for the people abroad, domestic currency is just another product, that has a price. If due to inflation this ""product"" is <em>worth</em> less (because now it can buy less of utility-enhancing or productive goods), this should be reflected in its price, which is the domestic exchange rate $s$ (price of domestic currency measured in units of foreign currency), which should get lower.</p>

<p>This is the rationale also behind the closely linked ""purchasing power parity"". Of course, this is a highly stylized analysis and all sorts of real-world imperfections and rigidities will affect what will actually happen. But the tendency is the one described above.</p>
","10922"
"Gini index vs Herfindahl index: one increases while the other decreases","184","","<p>I am comparing two vectors of values which indicate portfolio weights in monetary units at two different dates.</p>

<p>I wanted to quantify if the concentration in the portfolios changed. So I moved on with calculating the Gini index and the Herfindahl index for both vectors.</p>

<p>Now I got the  result that the Gini index increased, but the Herfindahl index decreased. How can I understand this result?</p>

<p>I did it in R, so I provide you with the values and the code:</p>

<pre><code> library(ineq)

V0 &lt;- c(6.162382e+01, 7.870565e+02, 2.922241e+03, 8.367593e-02, 3.306334e+01, 1.937308e+03, 2.114359e+01, 3.942730e+01, 2.682160e+00,
1.929470e+03, 2.052831e+03, 9.902533e+03, 9.603747e+03, 2.370503e+00, 3.841130e+01, 2.364905e+01, 3.627621e-01, 2.248296e+02,
2.330520e+03, 7.286694e+03, 5.218457e+00, 5.961622e-01, 0.000000e+00, 0.000000e+00, 5.048860e+03, 2.885924e+01, 3.051794e+02,
5.937953e+02, 6.668031e+00, 1.004851e+02, 3.319353e+02, 1.796081e+03, 1.407182e+03, 2.728721e+03, 3.892461e+04, 2.996096e+04)

V1 &lt;- c(1.07793e-03, 5.87720e-04, 1.95339e-04, 2.65183e+03, 8.58753e-04, 2.67605e-04, 4.86570e-05, 1.74857e-05, 1.00513e-04, 5.18214e+03,
9.09578e+03, 3.23243e+04, 4.41746e-03, 2.11019e-05, 2.87357e+04, 6.10592e+03, 2.25064e-03, 1.24105e-03, 1.63327e+04, 1.47689e-03,
1.60764e-04, 9.70041e-04, 2.64918e-06, 2.13185e-04, 1.95118e-03, 3.50591e+03, 2.97961e-03, 1.34459e-04, 1.10588e+03, 3.30131e-05,
2.41992e-04, 1.03209e-04, 2.25949e-03, 1.93734e-02, 1.50010e+04, 3.98032e+02)

Gini(V0)
[1] 0.8202071
Gini(V1)
[1] 0.8503999
Herfindahl(V0)
[1] 0.187598
Herfindahl(V1)
[1] 0.1744127
</code></pre>

<p>Clearly, both vectors are rather unequal distributed. The high Gini index says exactly that. The Herfindahl index is rather low to my feelings, but I am not very experienced with inequality/concentration measures. </p>
","<p>They measure different things.  In particular the Gini index measures inequality and is strongly affected by the number of individuals with almost nothing, while the Herfindahl index measures the diversity of the shares (for example the choice in a market) and is almost unaffected by those with almost no share</p>

<p>If $n$ people had equal shares then the Gini index would be $0$, not changing as $n$ increased since inequality would not change, while the Herfindahl index would be $\frac1n$, reducing as $n$ increased to reflect greater diversity</p>

<p>As an an illustration, the following $36$ values give roughly the same results as your two examples</p>

<pre><code>V2 &lt;- c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, 
        0.05, 0.19, 0.19, 0.19, 0.19, 0.19)
Gini(V2)
# [1] 0.8527778
Herfindahl(V2) 
# [1] 0.183
</code></pre>

<p>But the zeros have no impact on the market shares and the Herfindahl index: having somebody extra with no share is as irrelevant as having nobody extra, and somebody with a tiny share is almost as irrelevant.  Removing those zeros would lead to </p>

<pre><code>V3 &lt;- c(0.05, 0.19, 0.19, 0.19, 0.19, 0.19)
Gini(V3)
# [1] 0.1166667
Herfindahl(V3)
# [1] 0.183
</code></pre>

<p>with the Gini index being much smaller (there is less inequality when those with nothing are excluded from consideration) but the Herfindahl index staying the same, corresponding to somewhere between $5$ and $6$ equal shares</p>

<p>You could looking at the Lorenz curves for your examples with something from the package like </p>

<pre><code>plot(Lc(V0), col=""blue"")
lines(Lc(V1), col=""red"")
</code></pre>

<p>or something homemade like </p>

<pre><code>plot(c(0,1), c(0,1), type=""l"")
points((0:length(V0))/length(V0),cumsum(c(0,sort(V0)))/sum(V0), 
    type=""b"", col=""blue"")
points((0:length(V1))/length(V1),cumsum(c(0,sort(V1)))/sum(V1), 
    type=""b"", col=""red"")
</code></pre>

<p>gives a picture like this with V0 in blue and V1 in red</p>

<p><a href=""https://i.stack.imgur.com/GzD9q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GzD9q.png"" alt=""Lorenz curves""></a></p>

<p>So you can see that there is a greater area between the diagonal and the red curve (V1) than between the diagonal and the blue curve (V0), explaing why V1 gives a higher Gini index.  This is largely due to V1 having more extremely low values than V0 does</p>

<p>But on the right hand side, the top two values are greater for blue (the cumulative sums of the others are lower), so shares are more concentrated for V0 leading to a higher Herfindahl index </p>
","17088"
"If Trickle Down Economics Works, Then Shouldn't ""Trickle Up"" Economics Work as Well?","184","","<p>A lot of controversy in economics on the political stage comes from trickle down economics and whether it even works or not. The idea is that if we give sufficient tax cuts to corporations, they'll use that money to expand and create more jobs and just overall bettering the economy for everyone. My question is, why can't that work the other way around? If you give the working class just as much in tax cuts, they'll eventually spend that money to where it does end up at an American corporation. And in my opinion, this way is more capitalist, because the consumers decide what businesses get what percentage of their tax cut, instead of just multiplying the corporation's wealth. </p>
","<p>In Keynesian economics, yes, it can work the other way around - in fact, it may even be more effective. I don't have any textbooks or sources handy, but in general, people with lower incomes have a higher marginal propensity to consume. That is, if you give a poor person an extra dollar, they will spend more of that dollar, and save less of it, than someone who is wealthier. Since more of the additional money is spent, the tax cut will have more of a stimulative effect on the economy. In Keynesian terms, the fiscal multiplier will be larger.</p>

<p>Here are some links that go over this in more detail. And if you really want to understand it, any decent macroeconomics textbook should cover this pretty thoroughly.</p>

<p><a href=""https://www.investopedia.com/exam-guide/cfa-level-1/macroeconomics/multiplier-effect.asp"" rel=""nofollow noreferrer"">https://www.investopedia.com/exam-guide/cfa-level-1/macroeconomics/multiplier-effect.asp</a>
<a href=""https://en.wikipedia.org/wiki/Marginal_propensity_to_consume#MPC_and_the_multiplier"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Marginal_propensity_to_consume#MPC_and_the_multiplier</a>
<a href=""https://en.wikipedia.org/wiki/Fiscal_multiplier#Marginal_Propensity_to_Consume"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Fiscal_multiplier#Marginal_Propensity_to_Consume</a>
<a href=""https://scandalum.wordpress.com/2007/10/17/10-the-marginal-propensity-to-consume-and-the-multiplier/"" rel=""nofollow noreferrer"">https://scandalum.wordpress.com/2007/10/17/10-the-marginal-propensity-to-consume-and-the-multiplier/</a></p>
","19783"
"Conditions for an additive value function","183","","<p>In a standard problem of <a href=""https://en.wikipedia.org/wiki/Far_cake-cutting"" rel=""nofollow"">fair cake-cutting</a>, there is a real interval which is called ""cake"", and it has to be divided among $n$ partners. Each partner $i$ has a subjective value function $v_i$, which is an <em>additive</em> function on subsets of the cake. This means that, for every two disjoint subsets $A$ and $B$:</p>

<p>$$v_i(A\cup B)=v_i(A)+v_i(B)$$</p>

<p>Suppose that, instead of a value function, each partner has a <em>preference relation</em> $\succeq_i$. </p>

<p>A preference relation $\succeq_i$ is <em>represented</em> by a value function $v_i$ iff:</p>

<p>$$A\succeq_i B \iff v_i(A)\geq v_i(B) $$</p>

<p>What properties on the preference relation guarantee that it can be represented by an <em>additive</em> value function?</p>

<p>NOTE: The Wikipedia page <a href=""https://en.wikipedia.org/wiki/Ordinal_utility"" rel=""nofollow"">Ordinal utility</a> describes some conditions under which a preference relation can be represented by an additive value function. But, it deals with preferences on bundles of homogeneous goods. Here, the preferences are on subsets of a heterogeneous good.</p>

<p>EXAMPLES:</p>

<p>$$u_1(A) = \text{len}(A)^2$$</p>

<p>$u_1$ is not additive, but the preference relation it represents can be represented by the additive function $v_1(A) = \text{len}(A)$.</p>

<p>$$u_2(A) = \min[\text{len}(A\cap[0,4]),\text{len}(A\cap[4,8])]$$</p>

<p>The preference relation represented by $u_2$ cannot be represented by an additive function. Proof: suppose by contradiction that the preference relation is represented by an additive function $v_2$. Then, because:</p>

<p>$$u_2([0,1])=u_2([4,5])=u_2(\emptyset)$$</p>

<p>this must also be true for $v_2$:</p>

<p>$$v_2([0,1])=v_2([4,5])=v_2(\emptyset)$$</p>

<p>By additivity:</p>

<p>$$v_2([0,1]\cup[4,5])=v_2(\emptyset\cup\emptyset)=v_2(\emptyset)$$</p>

<p>This must also be true for $u_2$:</p>

<p>$$u_2([0,1]\cup[4,5])=u_2(\emptyset)$$</p>

<p>a contradiction.</p>
","<p>This is only a partial answer because it does not exactly fit your framework, but I hope it will still be helpful (and it's too long for a comment).</p>

<p>If you are ok with discretizing your cake into (possibly arbitrarilly small) pieces of cake, then you will find an answer in </p>

<ul>
<li>Kraft, C. H., Pratt, J. W., &amp; Seidenberg, A. (1959). Intuitive Probability on Finite Sets. The Annals of Mathematical Statistics, 30(2), 408–419.</li>
</ul>

<p>the bulk of which is very well summarized in the introduction of</p>

<ul>
<li>Fishburn, P. C. (1996). Finite linear qualitative probability. Journal of Mathematical Psychology, 40(1), 64–77.</li>
</ul>

<p>Althought the setup of the papers is in terms of probability jugments, it can be reinterpreted from a preference point of view as follows :</p>

<ul>
<li>A finite set of objects $S = \{1,2,\dots,n\}$ (in your problem $S$ could contain the pieces of the cake)</li>
<li>A preference relation $\succeq$ over $2^S$ the set of subsets of $S$.</li>
<li>The question : when is $\succeq$ representable by an additive utility function $U$ on $2^S$.</li>
</ul>

<p>A classical conjecture by de Finetti's was that the following conditions should suffice (here I follows the presentation in Fishburn (1996)):</p>

<ul>
<li>(Order) : $\succeq$ on $2^S$ is a weak order,</li>
<li>(Nonnegativity) : $A \succeq \emptyset$ for every $A \in 2^S$,</li>
<li>(Nontriviality) : $S \succ \emptyset$,</li>
<li>(Additivity) :  For all $A,B,C \in 2^S$, if $(A\cup B) \cap C = \emptyset$, then $[A \succ B] \Leftrightarrow [(A\cup C) \succ (B\cup C)]$.</li>
</ul>

<p>de Finneti observed that these were necessary but could not determine whether they were sufficient. Eventually, Kraft, Pratt &amp; Seidenberg (1959) provided a counter-example as well as an additional condition which, together with the four others implied the existence of an additive representation:</p>

<ul>
<li>(Strong additivity) : for all $m\geq 2$ and all $A_j,B_j \in 2^S$, if $(A_1,\dots,A_M)$ and $(B_1,\dots,B_M)$ contain the same number of replicas of each elements of $S$ (i.e. if $s_1$ appears three times in all the $A_j$ sets, it also appears three times in all the $B_j$ sets, etc) and $A_j \succeq B_j$ for all $j&lt;m$, then we do not have $[A_m \succ B_m]$.</li>
</ul>

<p>The last condition is often referred to in the literature as the ""cancelation"" property. Now (Strong additivity) is not the most intuitive condition. In general, it can be hard to to check and navigate, which has spurred a large literature on alternative sufficient condition. I can send you a reading list if you are interested. Unfortunately, I don't remember of any paper directly tackling preferences over subsets of <em>infinite</em> sets, like your real interval.</p>

<p>From my experience with these kinds of problems, changing the domain over which preferences are defined makes a huge difference in terms of the results that hold and the proof techniques you can use. If a result is not already out there in the literature, it is rarely easy to derive it from apparently similar results on different domains.</p>
","8371"
"Help with CES Utility Function exercise","183","","<p>I am attempting to solve the following CES Utility Function problem:</p>

<p><img src=""https://i.imgur.com/BbDIVg4.png"" alt=""CES Problem""> </p>

<p>However, I am running into issues when I get to 3).</p>

<p>For 1) I have $K = \left(\frac{\omega p_1}{p_2}\right)^{\frac{1}{p+1}}$ </p>

<p>For 2) I get $X_2^M = \frac{m}{\frac{p_1}{K}+p_2} $</p>

<p>For 3) I find $\lambda^* = (K^\rho + \omega)^{-\frac1p-1} \cdot \omega \cdot p_2^{-1} $</p>

<p>and $v(p_1, p_2, m) = \left(\left(\frac{m}{p_1+Kp_2}\right)^{-\rho} + \omega(\frac{mK}{p_1+Kp_2})^{-\rho}\right)^{-1/\rho}$</p>

<p>I then divide $\lambda^*$ by $v(p_1, p_2, m)$, but when I do so I can't seem to fully cancel out $p_1,p_2,m,K$ and $\rho$ which I believe I would have to do to prove that they are proportional. I'm not sure if the issue is with my $\lambda^*$, my $v(p_1,p_2,m)$ or both...</p>

<p>Additionally, for 6) how does one demonstrate homogeneity of a given degree? </p>
","<p>For question 3, I'm sure there are simpler solution than mine. I provide this version for your reference.</p>

<p>By definition,
\begin{align}
\lambda^* &amp;= \frac{\frac{\partial u}{\partial x_1}(x_1^M)}{p_1} = \frac{\left[(x_1^M)^{-\rho}+ w(x_2^M)^{-\rho}\right]^{-\frac{1}{\rho}-1}(x_1^M)^{-(\rho+1)}}{p_1}\\
\\
v(p_1,p_2,m) &amp;= u(x_1^M(p_1,p_2, m), x_2^M(p_1, p_2, m)) \\
&amp; = \left[(x_1^M)^{-\rho}+ w(x_2^M)^{-\rho}\right]^{-\frac{1}{\rho}}
\end{align}
So 
\begin{align}
\lambda^* &amp;= v(p_1,p_2,m) \frac{1}{p_1\left[(x_1^M)^{-\rho}+ w(x_2^M)^{-\rho}\right](x_1^M)^{\rho+1}}\\
&amp;= v(p_1,p_2,m) \frac{1}{p_1\left[x_1^M+ w\left(\frac{x_1^M}{x_2^M}\right)^{\rho+1}x_2^M\right]}\\
&amp; = v(p_1,p_2,m) \frac{1}{p_1\left[x_1^M+ w\left(\frac{1}{\kappa}\right)^{\rho+1}x_2^M\right]}
\end{align}
Plug in the expression for $\kappa = \left(\frac{wp_1}{p_2}\right)^{\frac{1}{\rho+1}}$ to the equation above, we have </p>

<p>\begin{align}
p_1\left[x_1^M+ w\left(\frac{1}{\kappa}\right)^{\rho+1}x_2^M\right] &amp;= p_1\left[x_1^M+ w\frac{p_2}{wp_1}x_2^M\right]\\
&amp; = p_1x_1^M + p_2x_2^M\\
&amp; = m
\end{align}
so $$\lambda^* = \frac{v(p_1,p_2,m)}{m}$$</p>

<p>To show a function $F(x_1, x_2, ... x_n)$ is homogenous of degree $k$, simply show that $$F(kx_1, kx_2, ...kx_n) = \lambda^kF(x_1, x_2, ... x_n)$$ For $\forall \;\lambda&gt;0$</p>
","16367"
"Self-selection bias during the course of experiments","183","","<p>Suppose you are running a randomized experiment to assess the effect of $X$, say some training program for unemployed people, on $Y$, say the chance of finding a job in the coming year. Suppose also that $X$ takes time : maybe it lasts for several month.</p>

<p>Because you randomize, you do not need to worry about self-selection bias initially. But during the course of $X$, some people will likely realize that $X$ is beneficial to them, and others may realize that they are wasting their time. </p>

<p>As a result, one might expect that among people who drop from the program, there is a higher proportion of agents for which the treatment effect would have been smaller. This might induce an over-estimation of the treatment effect.</p>

<p><strong>My questions are</strong> :</p>

<ul>
<li>Is this kind of bias discussed in the literature on randomized experiments?</li>
<li>Does it have a canonical name ?</li>
<li>Do researcher try to control for this, and if yes, how?</li>
</ul>
","<p>Apparently this is called <a href=""http://ije.oxfordjournals.org/content/34/1/87"">attrition bias</a>. It's very similar to <a href=""http://en.wikipedia.org/wiki/Survivorship_bias"">survivorship bias</a>. <a href=""http://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1044&amp;context=famconfacpub"">This paper</a> suggest correcting for it using <a href=""http://en.wikipedia.org/wiki/Heckman_correction"">Heckman correction</a>. <a href=""http://en.wikipedia.org/wiki/Propensity_score_matching"">Propensity score matching</a> may also <a href=""http://econweb.umd.edu/~ham/Rand_Ham_Li%20submit%20july%202011.pdf"">help somewhat</a>. My experience with both has been mixed, but they are commonly used. You should figure out what exact approach is most appropriate for your setting.</p>

<p><strong>One last edit:</strong> <a href=""http://ftp.iza.org/dp4162.pdf"">These</a> <a href=""https://www.princeton.edu/~davidlee/wp/resrevision8.pdf"">two</a> papers, which talk about bounding the average treatment effect, may also be of use to you.</p>
","139"
"How does inflation work in real life?","182","","<p>So when the government prints more money, then it is said the people will have more money in general and as a result the prices of goods and services will also increase. So in the end, we will end up buying the same amount of goods, but by paying more. So its the concept that the more the things is available the less value it has. 
I do not understand how this works in real life. 
When the government prints more money, how does this extra money end up in the hands of the people, they still are being paid the same amount of salary annually by their employers. The income of people is fixed. 
Secondly, why does the price of the goods increase? If rice is worth 1$ per kilo, then just because people are richer why does the cost of rice increase ?</p>

<p>I have recently started studying economics.</p>
","<blockquote>
  <p>When the government prints more money, then how does this extra money end up in the hands of the people, they still are being paid the same amount of salary annually by their employers. </p>
</blockquote>

<p>This is really two questions:</p>

<p><strong>How does the money get into the economy?</strong> The US government increases the money supply by having the Fed buy things with dollars that did not previously exist.  Typically they buy financial assets, pushing their price up and putting new money into the hands of the previous owners of those securities (often the US treasury, which means it is injected into the economy in the form of government spending).</p>

<p><strong>How do individuals get this money if their incomes are fixed?</strong>  For a given individual, their income may be fixed in the short run.  However, across the economy there are many people whose incomes fluctuate with sales or who are up for raises that depend on sales or profit.  Or who get a higher wage when they change jobs.  As the money supply increases, consumers have more money in hand and spend more money, raising wages for those whose wages can go up using these mechanisms. Your intuition is right about people with truly fixed wages, though: in the short run, they do not participate in the money supply increase.  This is why people on a fixed income (like elderly people living on a pension) hate inflation.</p>

<p>Overall inflation shifts wealth from lenders to debtors and from those with fixed incomes to those with adjustable incomes.</p>

<blockquote>
  <p>why does the price of the goods increase?</p>
</blockquote>

<p>The price of a good is the equilibrium between the people buying and the people selling.  A change in the money supply does not change how many goods there are to sell but it does change how many dollars the people buying them have.  If people have more money, they will be willing to pay more, so the price goes up. </p>
","16920"
"Is there a folk theorem for repeated games on networks?","182","","<p>Games on networks have been studied extensively, however, I was not able to find a <a href=""http://en.wikipedia.org/wiki/Folk_theorem_%28game_theory%29"">folk theorem</a> for games on networks. Is there one or can it be derived from an already existing folk theorem?</p>

<p>With <strong>games on networks</strong> I mean games in which the payoff of the stage game only depends on the actions of the direct neighbors in a network. Simple examples for that would be the the majority game (in which the payoff depends on the number of neighbors that play the same action as you are) or a prisoner's dilemma played with each neighbor.</p>
","<p>Yes, there are folk theorems for games on networks, depending on information structure and possible communication. Here are some of the most relevant papers:</p>

<ul>
<li>Ben-Porath, E., &amp; Kahneman, M. (1996). <a href=""http://www.sciencedirect.com/science/article/pii/S0022053196900903"" rel=""nofollow"">Communication in repeated
games with private monitoring</a>. Journal of Economic Theory, 70(2),
281-297. - <em>public communication, private monitoring</em></li>
<li>Renault, J., &amp; Tomala, T. (1998). <a href=""http://link.springer.com/article/10.1007/s001820050089"" rel=""nofollow"">Repeated proximity games</a>.
International Journal of Game Theory, 27(4), 539-559. - <em>complete information, imperfect monitoring</em></li>
<li>Tomala, T. (2011). <a href=""http://pubsonline.informs.org/doi/abs/10.1287/opre.1110.0936"" rel=""nofollow"">Fault reporting in partially known networks and
folk theorems</a>. Operations research, 59(3), 754-763. - <em>partial knowledge of the network and restricted communication</em></li>
<li>Laclau, M. (2012). <a href=""http://www.sciencedirect.com/science/article/pii/S0899825612001285"" rel=""nofollow"">A folk theorem for repeated games played on a
network</a>. Games and Economic Behavior, 76(2), 711-737. - <em>private communication</em></li>
</ul>

<p>Thanks @Ubiquitous for basically providing the answer.</p>
","4865"
"Why wouldn't competition prevent ""usurious"" payday loan rates?","182","","<p>The <a href=""https://en.wikipedia.org/w/index.php?title=Payday_loan&amp;oldid=689253819#Pricing_structure_of_payday_loans"" rel=""nofollow"">current Wiki page on ""Payday Loans""</a> claims loans are priced above marginal cost. The justification is that</p>

<blockquote>
  <p>If a lender chooses to innovate and reduce cost to borrowers in order to secure a larger share of the market, the competing lenders will instantly do the same, negating the effect. For this reason, among others, all lenders in the payday marketplace charge at or very near the maximum fees and rates allowed by local law. <a href=""https://litigation-essentials.lexisnexis.com/webcd/app?action=DocumentDisplay&amp;crawlid=1&amp;doctype=cite&amp;docid=17+Tex.+J.+on+C.L.+%26+C.R.+211&amp;srctype=smi&amp;srcid=3B15&amp;key=c13c18e98eb8940c9ca16a70c4f6a5b7"" rel=""nofollow"">[23]</a></p>
</blockquote>

<p>Doesn't this logic contradict the fact that competitive markets price goods at their marginal cost?</p>

<p>Is there an implicit assumption that the payday loan market is not sufficiently competitive? If so, is this assumption true?</p>
","<p><b>The posted quote is economic nonsense.</b></p>

<blockquote>
  <p>If a lender chooses to innovate and reduce cost to borrowers in order to secure a larger share of the market, the competing lenders will instantly do the same, negating the effect.</p>
</blockquote>

<p>This applies to any industry without intellectual property protection -- it is hardly unique to the payday loan industry. By this logic, we'd expect to encounter massive price gouging across dozens of industries.</p>

<p>Besides, if payday loan innovation is in the form of software that better predicts default (the most likely path), it will be protected under copyright law and potentially software patents. And while business model innovations are not patentable, there's still a first mover advantage.</p>

<p><b>The payday loan business is not highly profitable.</b></p>

<p>Profit margins of payday-loan corporations are publicly available, and <a href=""http://financialuproar.com/2013/08/27/financials-payday-loans-might-bad-think/"" rel=""nofollow"">lower than most other industries</a>. One <a href=""http://ir.lawnet.fordham.edu/cgi/viewcontent.cgi?article=1227&amp;context=jcfl"" rel=""nofollow"">study</a> found that ""despite the common belief, payday lending firms do not always make extraordinary profits. In fact, when compared to many other well-known lending institutions, payday lenders may fall far short in terms of profitability.""</p>

<p>This is not surprsing, since the payday loan market is <a href=""http://www.google.com/maps/search/payday+loans+near+90059"" rel=""nofollow"">highly saturated</a>, which suggests substantial competition.</p>

<p><b>""Usurious"" APR rates are misleading.</b></p>

<p>A typical payday loan charges \$17 for a two-week \$100 loan.
Expressed as an annualized rate, this is an ""outrageous"" 390% APR.
But the loan's short-term nature means transaction costs will likely prevent a large profit.
(The <a href=""http://www.qcholdings.com/mythsaboutlending.aspx"" rel=""nofollow"">source</a> of this information is potentially biased. Be sure to read critically.)</p>
","9237"
"Arbitrage Pricing Theory (APT), orthogonal factors","181","","<p>Why in the Arbitrage Pricing Theory (APT), one of the assumptions is that the factors has to be orthonogal? what if not?</p>
","<p>If you want to describe excess returns in terms of exposure to common risk factors, you want the risk factors to be orthogonal. However, if you have $k$ factors with no perfect collinearity, you can always orthogonalize them and use those. You then call the orthogonalized factors the risk factors. </p>
","3173"
"What would happen if tomorrow all private and public debt was erased?","181","","<p>The question is what would happen if tomorrow all private and public (government) debt was erased? I am especially curious if normal daily economic activities would go on, what would the role of central banks be and how would the economy come into some equilibrium again.</p>

<p>The question is, indeed, a bit vague but I would like to know some opinions from various aspects. I think it is a very nice gedanken experiment.</p>
","<p>It would depend a lot on <em>how</em> the debt was ""erased."" If you are simply suggesting a transfer payment from creditor to debtor, what would force such an event? Or would it be voluntary? If it were forced, then you would have a threat to private property rights and therefore, a disincentive for further lending. Security of capital would be diminished and all investment might stop overnight.</p>

<p>This question is very broad. But the answer of what might happen would depend very much on the details of <em>how</em> all this might come about.</p>
","12702"
"Efficient Market Hypothesis and constant ex-ante real interest rates?","180","","<p>According to Hayashi's Econometrics (page 151), efficient market hypothesis is a joint hypothesis combining:</p>

<p><strong>Rational expectations</strong> $\rightarrow$ expected inflation$= \mathbb{E}(\pi_{t+1}|I_t)$, where $I_t$ is the information available at the beginning of the period.</p>

<p><strong>Constant Real Rates</strong> $\rightarrow$ The ex-ante real interest rate is constant.</p>

<p>Why is the second one also included? I've searched the wikipedia, but I didn't find anything helpful. </p>

<p>Any help would be appreciated.</p>
","<h2>To test market efficiency, you always need to specify the market's model of price formation</h2>

<p>Tests of the efficient markets hypothesis must always include a model of how the market forms prices. One of Fama's big contributions was that you cannot separate these two things in a test. Tests of efficient markets and models of price formations are inherently linked. So, in this case, the assumption of constant real interest rates is merely an assumption of how the market forms prices. Only after assuming this, can we test market efficiency. You might disagree with the model---more sophisticated models will repeat this experiment in that way---but the point is that you <em>have</em> to assume some model for price formation.</p>

<h2>Further reading</h2>

<p>For more information about this, check out Fama's <a href=""http://faculty.chicagobooth.edu/eugene.fama/research/"" rel=""nofollow"">website</a>. You'll find some links to some books of his. It would be helpful to read at least the first two sections of <a href=""http://faculty.chicagobooth.edu/eugene.fama/research/Foundations%20of%20Finance/Chapter%205%20Efficient%20Capital%20Markets.pdf"" rel=""nofollow"">chapter 5 of his book, ""Foundations of Finance.""</a></p>

<p>The argument that he makes in that chapter is approximately the following (borrowing his notation, but changing $\phi$ to $I$).
The point that he makes is that we want to test if the information sets are equal
$I_{t-1}^m = I_{t-1}$, where $I_{t-1}^m$ is the information that the market possesses. But because we can't test this directly, we would like to test
whether the distributions of prices are the same
$$
f_m(p_1,...,p_n \mid I_{t-1}^m) = f(p_1,..., p_n \mid I_{t-1}).
$$
However, this is impossible too. The equality possesses no testable content because we only observe $f(p_1,..., p_n \mid I_{t-1})$ and not $f_m(p_1,...,p_n \mid I_{t-1}^m)$ (see the top of page 137 of the linked chapter). I do not observe the latter because I do not know what $I_{t-1}^m$, except that $I_{t-1}^m \subseteq I_{t-1}$, and I do not know how the market uses this information. For this reason, we specify a model for how the market takes information and turns it into prices. Thus, we specify $f_m$ ourselves (in turn, also specifying what information $I_{t-1}^m$ the market uses). That is, we specify what data the market uses and the way in which it uses that data.</p>

<p>On page 134, Fama says</p>

<blockquote>
  <p>the statement that prices in an efficient market ""fully reflect"" available information conveys
  the general idea of what is meant by market efficiency, but the statement is too general to be
  testable. Since the goal is to test the extent to which the market is efficient, the proposition
  must be restated in a testable form. ... this requires a more detailed specification of the process of price formation, one that gives testable content to the term ""fully reflect.""</p>
</blockquote>

<h2>Why assume constant rates in the example in Hayashi?</h2>

<p>I think it's just an assumption made in that particular example. If you read a little further into the linked chapter, you'll see that Fama discusses 4 different models of market equilibrium. The first two are ridiculous, but he's doing it just to demonstrate the concept. (Part of the reason is that some of the previous ideas about market efficiency had some bizarre consequences, which he demonstrates through those examples.) The point is that any test of market efficiency is always tied to the model that is assumed. If the test fails, you know one of two things: either the market is inefficient or your model of the market is wrong. The unfortunate truth, however, is that you will never know which one it is. </p>
","1908"
"Returns to scale - Constant Function","180","","<p>Suppose we have a production function $f(z)=2$.</p>

<p>I am asked to determine whether the function exhibits increasing, decreasing, constant or no returns to scale.</p>

<p>For $t&gt;0$, $f(tz)=2$.</p>

<p>I'm not sure about the answer: should I say the function exhibits no returns to scale whatsoever or take different values for $t$ ($0&lt;t&lt;1 \implies$decreasing returns to scale, $t=1 \implies$ constant returns to scale, $t&gt;1 \implies$ increasing returns to scale)?</p>
","<p>You want to find a relation between $tF(z)$ and $F(tz)$ for all $t&gt;1$ (or $0$ for CRS). </p>

<p>So since $2t=tF(z)&gt;F(tz)=2$ for all $t&gt;1$, we see decreasing returns to scale.</p>
","14156"
"Generalization of the Heckscher-Ohlin Model","179","","<p>The <a href=""http://en.wikewipedia.org/wiki/Heckscher%E2%80%93Ohlin_model"">Heckscher-Ohlin Model</a> is normally presented for the case of 2 countries, 2 factors of production and 2 traded goods, leading to statements that, subject to free trade and various other assumptions:</p>

<ol>
<li><p>A country with a relative abundance of a factor will specialize in
and export the good whose production makes relatively intensive use
of that factor (the Heckscher-Ohlin Theorem).</p></li>
<li><p>The return to a factor will be equalized between the countries (the
Factor Price Equalization or Heckscher-Ohlin-Samuelson Theorem).</p></li>
</ol>

<p>Do these results generalize, subject to the same assumptions, to cases with more than 2 countries, factors or traded goods, and what are good sources that treat this topic?  Of particular interest are cases with 3 factors: labour, man-made capital and <a href=""http://en.wikipedia.org/wiki/Natural_capital"">natural capital</a>.</p>

<p>I appreciate that the predictions of the Heckscher-Ohlin Model often differ from 
empirical findings (eg the <a href=""http://en.wikipedia.org/wiki/Leontief_paradox"">Leontief Paradox</a>), but this question is about the model itself.</p>
","<p>The HO model has been generalised. Vanek does a good job of it. </p>

<p>Instead of only two countries, there is an index of countries.</p>

<ul>
<li><p>There are many industries.</p></li>
<li><p>Identical technology</p></li>
<li><p>Identical, homothetic tastes.</p></li>
</ul>

<p>The HOV theorem states that if a country is abundant in a factor,
its factor content of trade in that factor should be positive, and
negative otherwise.</p>

<p>Empirically, this model is not that successful. <a href=""http://www.nber.org/papers/w5625.pdf"">Here</a> is a good paper discussing the applications and results.</p>

<p>See below for that extension:
Vanek, Jaroslav, The Factor Proportions Theory: The N-Factor Case,” Kyklos, October 1968, 21, 749-755.</p>
","3089"
"Simple model to predict oil prices","179","","<p>Back when Hugo Chavez was still alive (former leader of Venezuela), he said they made ""simulations"" to predict how much oil prices will increase if they retire the supply of oil they were giving to the world, and that in that time that would cause trouble to US. That made me wonder how oil price could be predicted, since I had classes of computer simulation of different type of systems in the University and I can't even imagine how could it be done to predict oil prices. If I recall correctly, I was also told by a neuronal network professor that a researcher worked in predicting oil prices for years with neuronal networks, and the work became useless when a war triggered oil prices in a completely unexpected way. Knowing how hard making accurate predictions of oil prices could be, is there still an oversimplificated equation or something to predict oil prices in the market?</p>
","<p>The most comprehensive survey of estimating oil prices is <a href=""http://www-personal.umich.edu/~lkilian/handbookpublication.pdf"" rel=""nofollow noreferrer"">here</a>. There you fund from very complicated models to very simple ones. As the article shows, the ultimate answer depends on whether you are estimating nominal or real price, and short-term or long-term prices.</p>

<p>Some simple models to estimate price of oil might be:</p>

<ul>
<li>no-change forecast: if changes in the spot price are unpredictable, the best forecast of the spot price of crude oil is simply the current spot
price ($S_t$):</li>
</ul>

<p>$$ \hat{S}_{t+h|t} = S_t \quad h&gt;0$$</p>

<ul>
<li>futures-based forecast: simply take the market's average expected oil price forecast as your forecast:</li>
</ul>

<p>$$ \hat{S}_{t+h|t} = F^h_t \quad h&gt;0$$</p>

<p>where $F^h_t$ is the future forecast in the market. There are plenty of sources available online (e.g. <a href=""http://www.marketwatch.com/investing/future/crude%20oil%20-%20electronic"" rel=""nofollow noreferrer"">here</a> or <a href=""http://www.cmegroup.com/trading/energy/crude-oil/light-sweet-crude.html"" rel=""nofollow noreferrer"">here</a>).</p>

<ul>
<li>Double-difference forecasting: proposed by <a href=""https://ora.ox.ac.uk/objects/uuid:57adf07f-f189-4af4-9f17-6d36c5db46fd"" rel=""nofollow noreferrer"">Hendry (2006)</a>, it assumes past growth rates for future price changes:</li>
</ul>

<p>$$ \hat{S}_{t+h|t} = S_t \left(1+ \Delta s_t \right)^h \quad h&gt;0 $$</p>

<p>where $\Delta s_t$ is the percent growth rate of $S_t$ between $t-1$ and $t$</p>

<ul>
<li>inflation-based forecast: use forecasts for inflation to predict oil prices (which according to <a href=""https://ideas.repec.org/a/eee/jeeman/v66y2013i3p383-403.html"" rel=""nofollow noreferrer"">Anderson et. al. 2011</a>, this is how households predict gasoline prices):</li>
</ul>

<p>$$ \hat{S}_{t+h|t} = S_t \left(1+ \pi^e_{t,h} \right)^h \quad h&gt;0 $$</p>

<p>where $\pi^e_{t,h}$ is the forecast of inflation, for example, from the <a href=""https://en.wikipedia.org/wiki/Survey_of_Professional_Forecasters"" rel=""nofollow noreferrer"">Survey of Professional Forecasters</a>.</p>

<ul>
<li>AR, ARMA, ARIMA regression models: last but not least, the famous AR-based models are very common. Simply regress the price of oil on its past values, using as many lags as you want (or the <a href=""https://en.wikipedia.org/wiki/Information_criterion"" rel=""nofollow noreferrer"">information criterion</a> tells you), accounting for MA errors (ARMA) and possible <a href=""https://en.wikipedia.org/wiki/Cointegration"" rel=""nofollow noreferrer"">cointegration</a> (ARIMA). For example, the AR model with $p$ lags is:</li>
</ul>

<p>$$ S_{t} = \beta_0 + \beta_1 S_{t-1} + \cdots + \beta_p S_{t-p} + \mu_t $$</p>

<p>After you have estimated the model and obtained values for $\beta_i$, you can forecast oil prices by simply lagging the last $p$ observations one period and put into the model, from where you get $\hat{S}_{t+1|t}$ (assuming $\mu_{t+1} =0$). Then, iterate forward to get forecast for any other future period.</p>
","17509"
"What made The Wörgl Experiment successful?","179","","<p>Background:</p>

<blockquote>
  <p>In 1932, in the midst of the Great Depression, the small town of Wörgl in Austria successfully experimented with its own local currency (in the form of a stamp scrip) ...  They not only re-paved the streets and rebuilt the water system and all of the other projects on Mayor Unterguggenberger’s long list, they even built new houses, a ski jump and a bridge ... every one of the schillings in stamp scrip created between 12 and 14 times more employment than the normal schillings circulating in parallel. <a href=""http://www.lietaer.com/2010/03/the-worgl-experiment/"" rel=""noreferrer"">(Source)</a></p>
</blockquote>

<p>I would like to understand better what made the currency successful. The article offers this short explanation:</p>

<blockquote>
  <p>Because a stamp needed to be applied each month (at 1% of face value), everybody who was paid with the stamp scrip made sure he or she was spending it quickly, automatically providing work for others. </p>
</blockquote>

<p>What does it mean to ""apply a stamp each month""? Does the scrip lose 1% of its face value every month? Is that the incentive for spending? Isn't that economically the equivalent of a normal currency with high inflation? Why was this experiment so successful, and if it truely was, why haven't we seen more experiments like it?</p>
","<p>It was successful because it combined three things at the same time.</p>

<p>Firstly, it increased available currency at a time when currency was scarce for any but the rich - so everyone was more solvent.</p>

<p>Secondly, it had a negative interest rate, so the encouragement was to spend quickly.</p>

<p>And thirdly, it was a local initiative, and belonged to the town, at a time that was particularly introspective - isolationist, even.</p>
","15530"
"Why is M0 higher than M1?","179","","<p>In my understanding, M2 includes M1 and M1 include M0. However, I checked the money supply <a href=""https://tradingeconomics.com/united-states/money-supply-m0"" rel=""nofollow noreferrer"">here</a> and used the ""Compare"" function to compare the money supply of m0 with money supply of m1, and found that the money supply of M0 is higher than that of M1. How come?</p>
","<p>Because what Trading Economics states to be M0 is not really M0 but the monetary base (MB). Compare the data in their graph with the data from the Fed (e.g. <a href=""https://fred.stlouisfed.org/graph/?g=egmp"" rel=""nofollow noreferrer"">here</a>). These are some of the values from the monetary base (variable <code>BOGMBASE</code>):</p>

<pre><code>2016-09-01  3735888
2016-10-01  3572132
2016-11-01  3629770
2016-12-01  3531565
2017-01-01  3595455
2017-02-01  3746401
2017-03-01  3856260
2017-04-01  3821654
2017-05-01  3774390
</code></pre>

<p>They correspond roughly to the ones in the TE graph.</p>

<p>Whilst M1 is indeed larger than M1, the monetary base does not need to be. This is the entry in the <a href=""https://en.wikipedia.org/wiki/Money_supply#United_States"" rel=""nofollow noreferrer"">Wikipedia article</a> for monetary supply in the US:</p>

<ul>
<li>M0: The total of all physical currency including coinage. M0 = Federal Reserve Notes + US Notes + Coins. It is not relevant whether the currency is held inside or outside of the private banking system as reserves.</li>
<li>MB: The total of all physical currency plus Federal Reserve Deposits (special deposits that only banks can have at the Fed). MB = Coins + US Notes + Federal Reserve Notes + Federal Reserve Deposits</li>
<li>M1: The total amount of M0 (cash/coin) outside of the private banking system plus the amount of demand deposits, travelers checks and other checkable deposits</li>
</ul>

<p>A <a href=""https://www.federalreserve.gov/faqs/money_12845.htm"" rel=""nofollow noreferrer"">similar entry</a> from the Fed website indicates that M1 does not include the whole of MB. The relevant quote is:</p>

<blockquote>
  <p>The monetary base is defined as the sum of currency in circulation and reserve balances (deposits held by banks and other depository institutions in their accounts at the Federal Reserve). M1 is defined as the sum of currency held by the public and transaction deposits at depository institutions (which are financial institutions that obtain their funds mainly through deposits from the public, such as commercial banks, savings and loan associations, savings banks, and credit unions).</p>
</blockquote>

<p>It follows that the data from Trading Economics <strong>is misleading</strong>. It might be worth pointing this out to them.</p>
","17358"
"Understanding the impact of Subprime Mortgages crisis on investment banking","178","","<p>I'm interested to know the exact magnitude of impact of Subprime Mortgages crisis on major players in investment banking.</p>

<p>In particular, how can I find data for percentage of revenue from Subprime Mortgages in total revenue for major banks, like Goldman Sachs, Morgen Stanley, The Bear Stearns and  Lehman Brothers?</p>
","<p>Simply put, you can't tell exactly. It's just not possible to tell these entities' subprime losses apart from other losses, with the possible exception of Lehman Brothers, due to the detail made available through its bankruptcy proceedings. Even then, it would be an incredibly labor-intensive task.</p>

<p>There are a number of reasons for this. First, most subprime mortgage exposures of major banks weren't held as on-balance-sheet loans, but in the form of (usually higher-rated) tranches of private-label mortgage-backed securities, which has a number of implications, including: the exposures appeared on the balance sheet as securities, not as mortgage loans; there's no way to know what fraction of those securities contained subprime loans; and due to the structures of the securities, there's not even a linear relationship between the fraction of subprime loans in a given security and the bank's exposure to losses from those loans, among other things. Second, they often had off-balance-sheet exposures in the form of support obligations (whether explicit or implicit) on structured investment vehicles. Third, their exposures varied significantly due to differences in the amount of leverage they used in funding their assets.</p>

<p>As an aside: pre-crisis, none of the four entities you've named were actually banks. Though often referred to as ""investment banks,"" all of those were nonbank broker-dealers.</p>
","5092"
"What are the textbook-like obvious advantages and disadvantages of tipping?","178","","<p>I just came from a coffee place with tipping and now I'm in one without tipping... prices are higher, but there is not tipping. It's not obvious why some places get rid of tipping and others don't. I guess you want the server to be incentivized by the possibility o tipping to give outstanding, charming service. What other considerations are there?</p>
","<p>Interesting question. <a href=""https://sha.cornell.edu/about/directory/instructors/wml3"" rel=""nofollow noreferrer"">Michael Lynn</a>, prof at Cornell, works on <strong>Consumer Behavior and Tipping</strong>. According to him, some restaurateurs may rely on tips to</p>

<ol>
<li>motivate servers to deliver good service, </li>
<li>measure server performance, and </li>
<li>identify dissatisfied customers.</li>
</ol>

<p>All of those uses of tips assume that <strong>service quality</strong> has a large effect on the <strong>size of tips</strong> that consumers leave. He examines and challenges that assumption in his meta-analysis on <a href=""http://scholarship.sha.cornell.edu/cgi/viewcontent.cgi?article=1110&amp;context=articles"" rel=""nofollow noreferrer"">Restaurant Tipping and Service Quality</a>. He finds a <strong>tenuous relationship</strong> that can be depicted in the following figure, which is based on one surveyed paper.</p>

<p><a href=""https://i.stack.imgur.com/ZlzN0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZlzN0.png"" alt=""enter image description here""></a></p>

<p>Then, the question is: <strong>what does explain the change from tipping to no-tipping service?</strong> My answer is unfortunately more opinion-based than fact-based. It could be that</p>

<ol>
<li>managers are aware of this low correlation and want to
experiment a different management based on a fixed payment instead
of a variable one; </li>
<li>due to the financial crisis customers tip less than usual and so managers have to fix the tip to offer better (fixed) wages and attract good waiters.</li>
</ol>

<p><strong>Update:</strong> Note that the no-tipping strategy may have some drawbacks:</p>

<ol>
<li><p>Attrition. Servers may change to tipping places in order to get higher wages</p></li>
<li><p>Higher prices may lead to lower demand by some customers.</p></li>
</ol>

<p>More on the following nice NPR podcasts on </p>

<ul>
<li><p><a href=""http://www.npr.org/sections/thesalt/2016/05/15/478096516/why-restaurants-are-ditching-the-switch-to-no-tipping"" rel=""nofollow noreferrer"">Why Restaurants Are Ditching The Switch To No Tipping</a>. The idea of the no-tipping movement has been to rectify a basic pay unfairness to even out the pay between tipped and untipped employees. Why are they switching back to tipping? Attrition. They were losing staff, servers mostly. </p></li>
<li><p><a href=""http://www.npr.org/sections/money/2016/01/20/463726763/episode-283-why-do-we-tip"" rel=""nofollow noreferrer"">Why Do We Tip?</a>. You can listen to Michael Lynn on this podcast.</p></li>
<li><p><a href=""http://freakonomics.com/podcast/danny-meyer/"" rel=""nofollow noreferrer"">The No-Tipping Point</a> on Freakeconomics Radio. Interesting questions on How much would the restaurant have to raise prices in order to pay its waitstaff what they were losing in tips? How much of a raise would kitchen workers get? Would servers now earn a lot less? And if so, wouldn't they all just quit? Would customers get the service they were used to if they didn’t retain the leverage of the tip?</p></li>
</ul>
","12176"
"What is the average economic value of a human life?","178","","<p>What is the economic value of a human life?</p>

<p>If there are multiple methods to use in calculating, what are they, which method is preferred, and why?</p>

<p><strong>Considerations/sub-questions on methods</strong></p>

<p>A. Is the calculation purely based on output value (i.e. wages, goods produced, etc.), or are there intangibles that must be included (value of innovations that cause progress for society, NPV of progeny, etc.)?</p>

<p>B. As a result of #1, are there things which reduce economic value in one's life?  For example, when one has gone on unemployment, is one's net economic value negative for that period of time?</p>

<p>C.  Is the economic value of life dependent on one's country/state/locale or the sector one performs in?  For example, is it correct to say the economic value of a life is different in the US than in South Africa (due to average output in real terms?</p>
","<p>It depends on the context, of course, but most often in policy analysis ""the value of a life"" has nothing (directly) to do with output, etc, but instead means the maximum amount that people would want the government to spend in order to save a randomly chosen life.  </p>

<p>So in a country of 300,000,000, the question is:  What, to you, is the monetary equivalent of a 1/300,000,000 chance of death?  Because 1/300,000,000 is a very small number, we don't have to worry terribly much about willingness-to-pay versus willingness-to-accept.  (Theory tells us that for small changes, the two willingnesses are effectively equal.)</p>

<p>Returning to the question:  How much would you be willing to pay to avoid a 1/300,000,000 chance of death?  Now multiply that value by 300,000,000.  That's the value of one life, and arguably the amount we'd want our government to spend to preserve a randomly chosen life.  </p>

<p>Obviously there are problems with heterogeneity (you and I might not answer the question identically).  But as a general rough rule, the estimates tend to come in somewhere under $10 million.  </p>
","9403"
"Quality of French wine in the US vs French wine in France","177","","<p>I remember reading a study/paper saying that the AVERAGE bottle of french wine drunk in the US is better than the average bottle of french wine drunk in France, due to the fact that nobody bothers to ship the crappy stuff. Anyone got a link?</p>
","<p>This is called the Alchian–Allen effect. </p>

<blockquote>
  <p>The Alchian–Allen effect was described in 1964 by Armen Alchian and
  William R Allen in the book University Economics (now called Exchange
  and Production). <strong>It states that when the prices of two substitute
   goods, such as high and low grades of the same product, are both
   increased by a fixed per-unit amount such as a transportation cost or
   a lump-sum tax, consumption will shift toward the higher-grade
   product.</strong> This is true because the added per-unit amount decreases the
  relative price of the higher-grade product.</p>
  
  <p>Suppose, for example, that high-grade coffee beans are \$3/pound and
  low-grade beans \$1.50/pound; in this example, high-grade beans cost
  twice as much as low-grade beans. Now add a per-pound international
  shipping cost of \$1. The effective prices are now \$4 and \$2.50;
  high-grade beans now cost only 1.6 times as much as low-grade beans.
  This reduced ratio of difference will induce distant coffee-buyers to
  now choose a higher ratio of high-to-low grade beans than local
  coffee-buyers. (Prices are illustrative only).</p>
  
  <p>The effect has been studied as it applies to illegal drugs and it has
  been shown that the potency of marijuana increased in response to
  higher enforcement budgets, and there was a similar effect for alcohol
  in the U.S. during Prohibition.</p>
  
  <p><strong>Another example is that Australians drink higher-quality Californian wine than Californians, and vice versa, because it is only worth the  transportation costs for the most expensive wine.</strong></p>
</blockquote>

<p>From the <a href=""https://en.wikipedia.org/wiki/Alchian%E2%80%93Allen_effect"" rel=""noreferrer"">Alchian–Allen Wikipedia page</a>, emphasis mine. </p>

<p>I learned about this paradox in the context of <em>Why the Best Washington Apples are Shipped out of State</em>, discussed in a chapter of a fun popular economics book <a href=""http://rads.stackoverflow.com/amzn/click/1840640499"" rel=""noreferrer"">Puzzles and Paradoxes in Economics</a> which also happens to be a great source of undergraduate economics exam questions.</p>
","10406"
"Today's value of the Louisiana Purchase?","177","","<p>A <a href=""https://www.youtube.com/watch?v=e-WO-c9xHms"" rel=""nofollow noreferrer"">video</a> I watched claimed (at 6:50) that while only \$0.25B had been paid for <a href=""https://en.wikipedia.org/wiki/Louisiana_Purchase"" rel=""nofollow noreferrer"">the Louisiana Purchase</a>, the current value was \$1200B (all in 2017 dollars).</p>

<p><a href=""https://i.stack.imgur.com/MeNVR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MeNVR.png"" alt=""enter image description here""></a></p>

<p>I couldn't find any references, but assuming the latter number is correct, what might it refer to? </p>

<p>The current value of the land? </p>

<p>The estimated value of the land if all structures and roads were removed? </p>

<p>(It seems to me that these numbers would be vastly different, and comparing empty land to one with infrastructure is comparing apples and oranges)</p>
","<p>The video has a <a href=""https://drive.google.com/file/d/0B2p-HoK9KXEANjIwc3ZjMWI2SWM/view"" rel=""nofollow noreferrer"">transcript</a> with the references. The \$0.25B figure is obtained from <a href=""http://www.history.com/topics/louisiana-purchase#"" rel=""nofollow noreferrer"">here</a> (after adjusting for inflation). Unfortunately, the author does not provide a source for the \$1.2B figure. </p>

<p>However, there are estimates of the value of land elsewhere. For example, <a href=""https://www.bea.gov/papers/pdf/new-estimates-of-value-of-land-of-the-united-states-larson.pdf"" rel=""nofollow noreferrer"">here</a>. Their estimates on a map:</p>

<p><a href=""https://i.stack.imgur.com/O49mU.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/O49mU.png"" alt=""enter image description here""></a></p>

<p>These estimates consider <strong>the value of land only</strong>, removing the value of structures on that land (which, as you say, makes a big difference; see paper). They use <a href=""https://en.wikipedia.org/wiki/Hedonic_regression"" rel=""nofollow noreferrer"">hedonic regression</a> methods to separate land and building values (check from page 6 of document). </p>

<p>I leave to you the task to compute the precise value of the Louisiana Purchase. (you could ask them to send you the data on the map).</p>
","17855"
"How does an import driven economy function?","176","","<p>Can a country's economy,where everything is imported from other countries, solely depend on the income from its retail industry?</p>
","<p>This is an implausible scenario for a country of any size, the problem being how the imported goods would be paid for.  An individual retailer might pay for its imported goods out of income from sales to other residents of the country.  But for the country as a whole this would not work: there has to be sufficient income <em>from foreign sources</em> to pay for its total imports. The only exceptions would be if the country were running down its assets, or borrowing from abroad, neither of which could continue indefinitely.</p>

<p>In theory the required income could come from a) re-export at a profit of imported goods, and/or b) sales of imported goods at a profit to incoming tourists. However, even with clever marketing, it seems unlikely that (a) could be achieved on any scale if it involves no physical processing to add value, in competition with foreign suppliers operating by more direct routes. So far as (b) is concerned, even if the country has natural tourist attractions (eg scenery, heritage), to bring in many tourists would require ""tourism infrastructure"" (transport, hotels, etc) that is not normally considered part of ""retail"".</p>
","12458"
"How does monopoly affect the informational role of price?","176","","<p>It is said in the textbook ""Intermediate Microeconomics a Modern Approach"" by Hal Varian that monopoly affects the informational role of price. What's the mechanism?</p>
","<p>A foundational result from models of perfect competition is that the competitive market equilibrium (i.e. setting price and quantity such that supply = demand) is efficient. By efficiency we mean that the sum of consumer surplus and producer surplus are maximised.</p>

<p>This is actually quite an amazing thing! It means that each individual consumer buys the good if and only if the welfare he receives from doing so is greater than the marginal cost of producing the good. To see that this must be true, suppose that there were a consumer who values a good at more than the cost of production but did <em>not</em> buy it. Then it would be possible to increase welfare by having the consumer buy the good, contradicting the result that the equilibrium is optimal. Similarly, efficiency demands that sellers produce exactly as much as is necessary to sell to the consumers who will ultimately buy.</p>

<p>How could we get to this efficient point? One way would be to have economists calculate what is efficient and then publish this information so that people could look-up whether they are supposed to buy/sell or not. But wait! We know that there aren't economists running round telling consumers whether it would be efficient for them to buy or not. So how do people figure this out for themselves?!</p>

<p><strong>The answer is that the equilibrium price contains all of the information that they need to figure out what is efficient.</strong> Since the equilibrium price is equal to marginal cost, and since consumers will buy if their willingness to pay is above the price, a consumer wishes to purchase if amd only if his willngness to pay is bigger than the cost—i.e. exactly when it is efficient for him to do so. Thus, one way to think about the role of a price in a competitive market is that it transmits information to market participants about the efficiency of a trade they are contemplating. </p>

<hr>

<p>For a monopoly things are different because the monopolist breaks the direct relationship between price and marginal cost by setting $p&gt;MC$. This means that some consumers who have a willingness to pay that satisfied $p&gt;WTP&gt;MC$. The fact that $p&gt;WTP$ means the price is signalling to these consumers that they should <em>not</em> buy, even though it would be efficient for them to do so (because $WTP&gt;MC$). In other words, the price is no longer directly informative about the efficiency of a trade, so one way to think about the effect of monopoly on prices is that it reduces their information content. </p>

<hr>

<p>ADDENDUM:</p>

<p>It's still possible to calculate cost—and hence the efficient allocation—from the monopoly price, but we need more information. In particular, the monopoly price satisfies $$\frac{p-c}{p}=-\frac{1}{\eta},$$ where $\eta$ is the price elasticity of demand and $c$ is marginal cost. Thus, to figure out marginal cost we need know the price <em>and</em> the elasticity, whereas in a competitive market we only needed to observe the price.</p>
","9474"
"System of Differential Equations- Asymmetric First-Price Auction","175","","<p>I am working on a problem in my Auction Theory textbook regarding a two-player asymmetric first price auction. Assume the bidders are risk neutral. The problem statement is as follows:</p>

<blockquote>
  <blockquote>
    <p>Suppose that bidder $1$'s value $X_{1}$ is distributed according to $F_{1}(x) = \frac{1}{4}(x-1)^{2}$ over $[1, 3]$, and bidder $2$'s value is distributed according to $\text{exp}(\frac{2}{3}x - 2)$ over $[0, 3]$. Show that $\beta_{1}(x) = x - 1$ and $\beta_{2}(x) = \frac{2}{3}x$ constitute equilibrium bidding strategies in a first price auction.</p>
  </blockquote>
</blockquote>

<p>I am trying to work on deriving $\beta_{1}$ and $\beta_{2}$. Unfortunately, my knowledge of differential equations isn't terribly strong. Would someone be able to double check my work and let me know if I have logic errors? I have derived the correct bidding functions, but am not entirely confident my work is sound.</p>

<p>First, suppose the equilibrium bidding functions $\beta_{1} : [1, 3] \to \mathbb{R}_{+}, \beta_{2} : [0, 3] \to \mathbb{R}_{+}$ are strictly increasing and differentiable. Define $g_{1}(x) = \beta_{1}^{-1}(x)$ and $g_{2}(x) = \beta_{2}^{-1}(x)$. </p>

<p>Player $i$ with valuation $v$ can only vary his bid, so he seeks to find the optimal bid given by the optimization problem below.</p>

<p>$$\max_{b} F_{-i}(g_{-i}(b)) \cdot (v - b)$$</p>

<p>We consider the First Order Conditions:</p>

<p>$$F_{-i}(g_{-i}(b)) = \dfrac{f_{-i}(g_{-i}(b))}{\beta_{-i}^{\prime}(g_{-i}(b))} \cdot (v-b)$$</p>

<p>At equilibrium, $v = g_{i}(b)$. Applying this and noting $\dfrac{1}{\beta_{-i}^{\prime}(g_{-i}(b))} = (g_{-i}(b))^{\prime}$, we have:</p>

<p>$$(g_{-i}(b))^{\prime} = \dfrac{F_{-i}(g_{-i}(b))}{f_{-i}(g_{-i}(b))} \cdot \dfrac{1}{g_{i}(b) - b}$$</p>

<p>Plugging in each $F_{i}$, we obtain:</p>

<p>$$g_{2}^{\prime}(b) = \dfrac{3}{2} \cdot \dfrac{1}{g_{1}(b) - b}$$</p>

<p>And:</p>

<p>$$g_{1}^{\prime}(b) = \dfrac{1}{2} \cdot \dfrac{g_{1}(b) - 1}{g_{2}(b) - b}$$</p>

<p>At equilibrium, we have $\beta_{1}(3) = \beta_{2}(3)$. By individual rationality, $\beta_{2}(0) = 0 \implies g_{2}(0) = 0$.</p>

<p>While I could obviously use the problem statement that $\beta_{1}(x) = x - 1$ to conclude that $g_{1}(0) = 1$, I don't know how to justify this boundary condition independently. Does anyone have any insights into this?</p>

<p>Assuming this boundary condition though, I note:</p>

<p>$$g_{2}^{\prime}(0) = \dfrac{3}{2} \cdot \dfrac{1}{1 - 0} = \dfrac{3}{2}$$ </p>

<p>From here, I can wave my hand and guess that $g_{2}^{\prime}(b) = \dfrac{3}{2}$, which would imply $g_{2}(b) = \dfrac{3}{2}b$. I'm not sure how to formally derive this though. Would anyone have insights into this?</p>

<p>Once I have $g_{2}(b) = \dfrac{3}{2}b$, I can plug into $g_{1}^{\prime}(b)$ to get:</p>

<p>$$g_{1}^{\prime}(b) = \dfrac{1}{2} \cdot \dfrac{g_{1}(b) - 1}{\dfrac{3}{2}b - b} = \dfrac{g_{1}(b) - 1}{b}$$</p>

<p>Which is a first order linear differential equation, whose solution is:</p>

<p>$g_{1}(b) = b + 1 \implies \beta_{1}(v) = v - 1$.</p>

<p>And we have $\beta_{2}(v) = \dfrac{2}{3}v$.</p>

<p>My work is certainly a little hand-wavy. I would greatly appreciate any help in solidifying the details. Thank you in advance for any help!</p>
","<p>I followed Oliv's suggestion, which was quite fruitful. So we have the differential equations:</p>

<p>$$g_{1}^{\prime}(b) = \dfrac{1}{2} \cdot \dfrac{g_{1}(b) - 1}{g_{2}(b) - b}$$</p>

<p>And:</p>

<p>$$g_{2}^{\prime}(b) = \dfrac{3}{2} \cdot \dfrac{1}{g_{1}(b) - b}$$</p>

<p>With the boundary conditions $g_{2}(0) = 0$ and $g_{1}(\overline{b}) = g_{2}(\overline{b}) = 3$, where $\overline{b}$ is the maximum bid. </p>

<p>Now we guess that $g_{1}(b) = \alpha b + \gamma$ and $g_{2}(b) = \delta b + \lambda$. Applying $g_{2}(b) = 0$ yields that $\lambda = 0$. </p>

<p>Next, I substitute $g_{1}(b)$ into $g_{2}^{\prime}(b)$ to obtain:</p>

<p>$$g_{2}^{\prime}(b) = \dfrac{3}{2} \cdot \dfrac{1}{(\alpha - 1)b + \gamma}$$</p>

<p>Integrating $g_{2}^{\prime}(b)$ yields </p>

<p>$$g_{2}(b) = \dfrac{3}{2(\alpha - 1)} ln( (\alpha - 1)b + \gamma)$$</p>

<p>We note there is no constant when integrating, as $g_{2}(b) = \delta b$. We now apply $g_{2}(0) = 0$ again, concluding that $ln( \gamma) = 0$. And so $\gamma = 1$. Thus, $g_{1}(b) = \alpha b + 1$.</p>

<p>We now solve:</p>

<p>$$g_{2}(\overline{b}) = 3 = \dfrac{3}{2(\alpha - 1)} ln( (\alpha - 1)\overline{b} + \gamma)$$</p>

<p>From this and noting that $g_{1}(\overline{b}) = 3 = \alpha \overline{b} + 1$, we obtain:</p>

<p>$$e^{2(\alpha - 1)} = 3 - \overline{b} \implies \overline{b} = 3 - e^{2(\alpha - 1)}$$</p>

<p>Plugging this into $g_{1}(b)$ yields:</p>

<p>$$g_{1}(\overline{b}) = \alpha(3 - e^{2(\alpha - 1)}) + 1 = 3$$ </p>

<p>Which implies that the solution $\alpha = 1$. Thus, $\overline{b} = 2$.</p>

<p>So $\delta = \dfrac{3}{2}$. </p>

<p>Thus, $g_{1}(b) = b + 1 \implies \beta_{1}(v) = v - 1$; and $g_{2}(b) = \dfrac{3}{2}b$ implies $\beta_{2}(v) = \dfrac{2}{3}v$ as desired.</p>
","6819"
"Under what circumstances is an increase in national output called economic growth?","175","","<p>An increase in output can be achieved in two basic ways. </p>

<p><strong>The first scenario:</strong>
Aggregate demand increases, so supply extends. In this way the economy is making more use of its resources, but there is still spare capacity, and productive potential hasn't increased.</p>

<p><strong>The second scenario:</strong> Aggregate supply increases. National output increases without demand increasing and productive potential of the country has increased. </p>

<p>Now I know that the second scenario is economic growth for sure, as economic growth is generally characterised by an increase in the productive potential of country. But is the first scenario also economic growth? That is, is it called economic growth if a country just makes use of more resources already available to satisfy increased demand?</p>

<p>Furthermore, can the first scenario be shown on a PPC? Perhaps a shift from a point within the curve to a point on the curve?</p>
","<p>There are actually 2 types of economic growth. Actual growth is when output increases. Potential growth is when productive potential of the economy increases.</p>

<p>If long run aggregate supply increases without any change to short run AS, then you have potential growth but not actual growth. This might happen with if a new discovery is made, but has not yet been applied in industry. </p>

<p>If SRAS increase without any change to LRAS, then you have actual growth, but no potential growth. This might happen to an oil-dependent economy if there is a temporary fall in oil prices. </p>

<p>As long as there is short-term capacity in the economy, increases in aggregate demand will lead to actual growth. Aggregate demand, however, cannot lead to potential growth except by affecting LRAS (e.g. through changes in producer expectation etc). </p>

<p>Finally, you are correct in that actual growth is shown by moving a point closer to the PPC/ in the North East direction.</p>

<p>See any lecture material:
<a href=""http://www.tutor2u.net/business/strategy/economy-economic-growth.html"" rel=""nofollow"">http://www.tutor2u.net/business/strategy/economy-economic-growth.html</a></p>
","10366"
"How many major economic systems are there?","174","","<p>One of the biggest political debates regards the best type of economic system, which usually boils down to capitalism vs socialism.</p>

<p>Are there other kinds of economic systems, aside from more ""primitive"" kinds, like barter?</p>

<p>To put my question in perspective, I think of economic systems as a continuum that looks something like this:</p>

<p>communism | socialism | ""mixed economy"" | capitalism | ""free market capitalism"" (anything goes, rampant corruption and inequality)</p>

<p>So ""mixed economy"" would be a combination of socialism and capitalism, rather than a distinct economic system.</p>

<p>But that's just my opinion. There may be views that are radically different than mine</p>
","<p>Wikipedia has a comprehensive list of <a href=""https://en.wikipedia.org/wiki/Economic_system"" rel=""nofollow noreferrer""> economic systems</a>. </p>

<p>If you want to start thinking about number major economic systems that exist I recomend looking at the section on an economy's <a href=""https://en.wikipedia.org/wiki/Economic_system#Allocation_mechanism"" rel=""nofollow noreferrer""> allocation mechanism</a>.</p>

<p>In particular, Wikipedia lists the following kinds of system:</p>

<blockquote>
  <p>The basic and general economic systems segmented by allocation are:</p>
  
  <ul>
  <li>Market economy (""hands off"" systems, such as laissez-faire capitalism)</li>
  <li>Mixed economy (a hybrid that blends some aspects of both market and planned economies)</li>
  <li>Planned economy (""hands on"" systems, such as state socialism, also known as ""command economy"" when referring to the Soviet model)</li>
  <li>Traditional economy (a generic term for older economic systems)</li>
  <li>Participatory economics (a system where the production and distribution of goods is guided by public participation)</li>
  <li>Gift economy (where an exchange is made without any explicit agreement for immediate or future rewards)</li>
  <li>Barter economy (where goods and services are directly exchanged for other goods or services)</li>
  <li>Post-scarcity economy (a hypothetical form where resources aren't scarce, such as Marx's concept of a Communist society)</li>
  </ul>
</blockquote>
","15662"
"What percentage of UK imports/exports were with the EU in the economic year 2015-2016?","174","","<p>With the referendum over whether or not the UK should leave the EU or not I am interested to know what percentage of UK trade is made up of trade within the EU (Imports &amp; exports).</p>

<p>I am aware that the UK Government currently runs a <a href=""http://www.telegraph.co.uk/finance/economics/12043677/UKs-trade-deficit-in-goods-with-EU-hits-record-high.html"" rel=""nofollow"">trade deficit with the EU</a>, and a ultimately a <a href=""https://www.uktradeinfo.com/Statistics/OverseasTradeStatistics/Pages/OTS.aspx"" rel=""nofollow"">trade deficit</a> in general.</p>

<p><strong>My question is, how much of UK trade is within the EU, and how much of this is imports/exports in the economic year 2015-2016?</strong> 
An objective link proving this would be excellent.</p>

<p>Apologies for the 'trade deficit with EU' link being far from ideal, but as you can imagine, it is hard to find solid fact among the propaganda.</p>

<p>&amp; To clarify, I do not want people's opinion on whether the UK should remain or not. I am in the process of forming my own opinion based on the objective information I come across.</p>

<p>And as always, thank you to those that take the time to answer!</p>
","<p><a href=""http://www.worldstopexports.com/united-kingdoms-top-import-partners/"" rel=""nofollow noreferrer"">UK Exports 2015:</a></p>

<blockquote>
  <p>The United Kingdom shipped US$460.1 billion worth of products around the globe in 2015. [...] From a continental perspective, 53.6% of UK exports by value are delivered to European trade partners while 22.5% are sold to Asian importers. United Kingdom ships another 16.1% to North America but just 2.6% to Africa.</p>
</blockquote>

<p>While the total value of exports is a useful piece of information, here Europe means the continent, not the EU. Thus Norway, Switzerland and several Balkan countries are also included. It is not clear where Russia would fall under such a categorization so it is better to look at Eurostat's statistics.</p>

<p>In 2015 the UK's <a href=""http://ec.europa.eu/eurostat/statistics-explained/index.php/International_trade_in_goods#Intra-EU_trade"" rel=""nofollow noreferrer"">intra-EU trade</a> share was lowest among the member states  but it was still 50%. </p>

<p><a href=""https://i.stack.imgur.com/xChN5.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xChN5.jpg"" alt=""Intra EU share""></a></p>
","11365"
"What Taylor approximation is used in this equation?","174","","<p>In Wickens' Macroeconomic Theory book, in page 48(1st edition), the author states that by doing a taylor approximation we get the following result.</p>

<p><a href=""https://i.stack.imgur.com/r26gg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/r26gg.png"" alt=""enter image description here""></a></p>

<p>Why is that? What approximation did he use? </p>

<p>I've tried several to linearize the fraction $\frac{(1+\eta)^{\sigma}}{\beta}$ around those values, but I don't get the same...</p>
","<p>Even though your question does not allow a definite answer, I am pretty sure the author used a Taylor expansion around the logarithm of both sides of the equation. This process is called <strong>log-linearization</strong>, and is fairly common.</p>

<p>We can approximate (logs of) growth rates as $x \approx log(1+x)$ when $x$ is small. (and by the rules of logarithm:  $\log((1+x)^\sigma ) \approx\sigma x$</p>

<p>Rewriting your equation 
$1+(r_t-\delta)=(1+\eta)^{\sigma}(1+\theta)$</p>

<p>where
$r_t=\alpha (k^{\# *})^{\alpha -1}$</p>

<p>and applying this rule gives</p>

<p>$r_t-\delta=\theta+\sigma \eta$</p>

<p>which gives the desired result.</p>
","13690"
"Chow test of parameter constancy","172","","<p>A bivariate regression is fitted to 20 sample observations on y and X. I know the following:
$X'X=\begin{pmatrix}
                             20 &amp; 10\\
                             10 &amp; 30 \\
                             \end{pmatrix}$, 
$X'y=\begin{pmatrix}
                             30\\
                             40 \\
                             \end{pmatrix}$,
$y'y=75$.</p>

<p>I received that $\beta=\begin{pmatrix}
                             1.4\\
                             1.3\\
                             \end{pmatrix}$.</p>

<p>Then a new observation was obtained: $X=2$, $Y=4$.
I should perform a Chow test of parameter constancy.
In fact I know the formula for the test: $F=\frac{(RSS_{pooled}-RSS_{1}-RSS_{2})/(k+1)}{(RSS_{1}-RSS_{2})/(n-2k-2)}$. Unfortunately, I have no idea how to calculate the RSS for any of these regressions. Help is needed. </p>
","<p>This should help you figure out how to compute RSS for the different models.</p>

<p>Let's begin with what we have:</p>

<p>We know that</p>

<ul>
<li>$y$ is an $n \times 1$ vector that has observations of the endogenous variable</li>
<li>$x$ is an $n \times 2$ matrix of observations of the exogenous variables</li>
<li>$\beta$ is a $2 \times 1$ matrix of coefficients</li>
</ul>

<p>Unfortunately (or fortunately depending on how you look at it), we don't know what $x$ and $y$ look like in this equation. Instead we are given $(x' x)$, $(x' y)$, and $(y' y)$. </p>

<p>Using your comment about what RSS actually is -- Namely, that</p>

<p>$$\text{RSS} = (y_{\text{observed}} - y_{\text{estimated}})' (y_{\text{observed}} - y_{\text{estimated}})$$</p>

<p>First notice that $y_{\text{estimated}}$ is simply $x \beta$. Then replacing this in the previous formula gives us</p>

<p>\begin{align*}
  \text{RSS} &amp;= (y_{\text{observed}} - y_{\text{estimated}})' (y_{\text{observed}} - y_{\text{estimated}}) \\
  &amp;= (y_{\text{observed}} - x \beta)' (y_{\text{observed}} - x \beta) \\
  &amp;= y'y - 2y'x\beta + x \beta \beta' x'
\end{align*}</p>

<p>Now this is almost what we want. We want things to ultimately be in terms of $(y'y)$, $(x'x)$, $(x' y)$, and $\beta$. The first term is exactly $y'y$, but other terms look like they have pieces we want and we just have to find a way to get them.</p>

<p>Now, notice that each of the elements in our equation above is simply a scalar (aka sizes are such that they are $1 \times 1$). The determinant of a scalar is itself, then by using properties of determinants we can say:</p>

<p>\begin{align*}
  2y'x \beta &amp;= \det(2y'x\beta) = \det(2 \beta' x' y) \\
  x \beta \beta' x' &amp;= \det(x \beta \beta' x') = \det(\beta' x' x \beta)
\end{align*}</p>

<p>I will leave the linear algebra itself as an exercise.</p>
","9017"
"Demand function of a family","172","","<p>Different family members have different utility functions, but
All family members consume the same bundle. </p>

<p>For example, consider a family $F$ that has to select a bundle of  funiture ($x$) and electronic equipment ($y$). Each member $i\in F$ has a different utility function $u_i(x,y)$. The family has a budget $I$. How can the demand of the family be calculated?</p>

<p>I thought of several options:</p>

<ol>
<li>Calculate an aggregate utility function, e.g:</li>
</ol>

<p>$$ u_F(x,y) = \min_{i\in F} u_i(x,y) $$</p>

<p>Then, calculate the demand in the usual way: select a bundle $(x_F,y_F)$ that maximizes the aggregate utility $u_F$ in the budget-set.</p>

<p>A problem with this method is that it requires to normalize the members' utility functions to the same scale.</p>

<ol start=""2"">
<li>Calculate the optimal bundle of each family member separately: each member selects a bundle $(x_i,y_i)$ that maximizes his utility function $u_i$ given the family's income $I$. Then, calculate the family bundle as an average of the members' bundles:</li>
</ol>

<p>$$(x_F,y_F) = \frac{1}{|F|}\sum_{i\in F} (x_i,y_i)$$
If the budget-set is convex, then this bundle is also in the budget set. </p>

<ol start=""3"">
<li>Divide the family income $I$ among the family members, such that each member $i\in F$ receives an income $I/|F|$. Then, let each member select a bundle $(x_i',y_i')$ that maximizes his utility function $u_i$ in given his fraction of the income. Then, calculate the family bundle as a sum of the members' bundles:</li>
</ol>

<p>$$(x_F,y_F) = \sum_{i\in F} (x_i',y_i')$$</p>

<p>Each definition probably has different implications on results such as competitive equilibrium, welfare theorem, etc. </p>

<p>What is a good reference on this problem? </p>
","<p>I think any (and none) of your answers is correct. The market demand simply depends on how the family makes its purchasing decisions.</p>

<p>For example, suppose the matriarch $i$ decides on every purchase of the family and acts selfishly. Then obviously the utility function of the family is simply $u_i$.</p>

<p>Compare this with the case where the utility functions are cardinally comparable and the household is utilitarian. In this case, the family utility function is the sum of all utility functions.</p>

<p>More generally speaking, if purchase decisions are made via some game, then you have to solve the game first in order to obtain the demand functions. But whether a utility representation exists for the family utility and what it would look like crucially depends on the game structure.</p>

<p>One special case which has been discussed in the literature is the case where the household income is somehow distributed among family members and each family member spends separately. There then exists a class of utility functions for which the family expenditure will be independent of the distribution of income among the family members. For details, see <a href=""https://en.wikipedia.org/wiki/Gorman_polar_form"" rel=""nofollow"">https://en.wikipedia.org/wiki/Gorman_polar_form</a></p>
","9254"
"External Financing and Corporate Growth","172","","<p>In a book on Corporate Finance, the author writes that 'all other things constant' the higher the rate of growth in sales or assets, the greater will be the need for external financing(bank loans, debt securities, or equity). His reasoning is based on the $\text{Assets}=\text{Liabilities} + \text{Equity}$ equation. My question is why can't a company manager use his cash, in the current-assets, to drive the growth in sales or assets? And why should this equality be maintained in this situation? To answer just that by def. of equity, i.e. assets minus liabilities, in this last question seems to be not answering at all...</p>

<p>Any help would be appreciated</p>
","<p>The assertion of the book is based on the phenomenon of <strong>commercial credit</strong> - the fact that business-to-business sales almost always are on credit, and the differences between terms-of-credit that a company gives to its customers, compared to the terms of credit that enjoys from its suppliers. It describes the (short-term) phenomenon, peculiar to some, that ""the higher the sales and the profits, the lower the cash available"".</p>

<p>A simplified bottom-up unfolding of how this can happen is as follows: Assume that a company has steady monthly sales $S$ for the years 2013 and 2014. Assume that the terms-of-credit that extends to its customers is ""60 days/two months"". Roughly, this means that the Accounts Receivables at the end of, say, year 2013 equal the amount of two months of sales (assume away any seasonality), denote it $AR_{2014} =2S$. On the other side, the company has only a ""1 month"" period to pay its suppliers. Assume the monthly Costs of Sales is $cS$. </p>

<p>So during year 2014 the Cash flow from the Customers-Suppliers loop has been</p>

<p>$$CF_{2014}=12\cdot S - 12\cdot cS = 12(1-c)S$$.</p>

<p>Now assume that starting from January 2015, Sales go up 20%.</p>

<p>During the year 2015  the Collections will be $2S + 10\cdot 1.2\cdot S$: November-December 2014 Sales collected in January-February 2015, and 10 months of collecting the increased sales amount.</p>

<p>As for Accounts Payable, during 2015 the company will have to pay $CSpay = cS + 111\cdot 1.2\cdot cS$ (we keep Inventories constant in value for simplicity).</p>

<p>So for 2015 we will have</p>

<p>$$CF_{2015}=2S + 1.2\cdot 10\cdot S - cS - 1.2\cdot11\cdot cS$$</p>

<p>$$=[14 - 14.2c]S$$</p>

<p>Depending on the value of $c$ we may have $CF_{2015} &lt; CF_{2014}$ (in the specific example, we will need to have $c &gt;0.91$ , i.e. a very small mixed profit margin $1-c$).</p>

<p>Namely, the combination of sales growth with the gap in the terms of credit, may result in the company having less cash available to cover its other, operational expenses like salaries etc. But even if this is not the case, the increase in Cash Flow may not be enough to cover the increase in other Assets that accompany an increase in Sales: an increase of the value of Inventories, but also possibly investments. Both will require increased cash. Also, operational expenses, like marketing or labor cost may have to increase. If the terms-of-credit gap is large and the sales growth aggressive, the company will require a Cash injection from shareholders or a bank loan to be able to pay all its obligations, even though its Sales has gone up.</p>

<p>The above are compacted nicely into a Balance-Sheet-point of view (where the equality $\text{Assets}=\text{Liabilities} + \text{Equity}$ holds always by construction, given how the terms involved are defined and measured). In fact, the Balance Sheet approach is the way many Finance Directors use to get a quick taste of what kind of financing will the company need next year. Essentially, the increased funds ""automatically"" injected by increased suppliers credit (due to increased purchases), plus any projected increased retained profits, may not be enough to cover the increase in the Current Assets due to the increase in Accounts Receivable (and possibly the increase in Inventories and in Fixed Assets that accompany the growth of Sales growth).
It may be the case that such an expansion may be profitable in terms of ""Profit &amp; Loss"" while at the  same time having a negative effect on the Cash Flow, in the short-term.</p>

<p>Indeed, the difference could be covered by running down the cash reserves of the company, but in many cases, companies do not hold so much cash to do that. Then, one has to close the gap by for example, increasing Liabilities, say, taking a loan. </p>
","6683"
"How are disaster effects calculated into GDP?","172","","<p>Assuming no income was lost, only assets were destroyed (e.g. homes), how does disaster event impact GDP numbers?</p>

<p>Or otherwise, is losing and rebuilding wealth neutral to GDP (e.g. spending on construction instead of entertainment)?</p>

<p>Is GDP calculated so well that all subtle effects are reflected in the numbers (e.g. lost home might affect work opportunities in mid-term)?</p>
","<p>GDP is just a partial measure of flow. There are lots of changes to the stock of a nation, its capital, that are not captured by GDP.</p>

<p>Destruction of assets in natural disasters isn't recognised as a loss in GDP. It gets worse: the rebuilding would actually be a positive on GDP. NB any loss in economic output from, say, destruction of factories, <em>would</em> appear as a negative on GDP - the loss of the factory's output.</p>

<p>Changes in natural capital aren't captured either.</p>

<p>GDP is just a measure of volume of transactions. It gets misused as a proxy for economic wellbeing. That's not the indicator's fault, it's the fault of those who misuse it.</p>
","10258"
"If all Banks in the world are emptied..?","172","","<p>What would happen if every person in the world pulled their money out of their bank accounts?</p>
","<p>In principle, <em>not that much</em> would necessarily happen: if people pulled out their bank deposits in the form of cash, then the central bank would just become a much bigger financial intermediary.</p>

<p>Cash is a liability of the central bank: when it introduces cash into the economy, it uses that cash to buy an asset. In a world where the public switched to cash en masse, a central bank fulfilling its usual operating procedure by targeting short-term interest rates would fully accommodate that spike in demand for cash by making much more of it, and accumulating assets in the process. What would these assets be? Well, in this situation they would naturally be loans to banks, which would need the funding.</p>

<p>So by withdrawing its funds from the banking system, <strong>the public would just trade off holding deposits <em>directly</em> in banks for holding these assets <em>indirectly</em> through the central bank</strong> (by holding cash that is backed by loans to those banks).</p>

<p>Of course, this is all a bit idealized. In practice a mass withdrawal of funds would presumably be somewhat chaotic, and the central bank would have to be diligent about its role as lender of last resort to avoid disaster. But there is a natural way for the system to work here, and it's amusing to contemplate how in this scenario, we'd really just be adding one more layer of indirection to the financial system.</p>
","5471"
"In microeconomics : is this the contradiction in the atomicity of firms ?","172","","<p>Let $p$ be the market demand. It is a function of the market production $Q$. Let $q_i$ be the production of firm $i$.</p>

<p>Reading Steve Keen (in <em>Debunking Economics</em>, chapter II) quoting George Stigler, I think the first wants to deduce the following contradiction in the atomicity of firms.</p>

<p>Using the chain rule, we get : $\frac{dp}{dq_i}= \frac{dp}{dQ} \frac{dQ}{dq_i}$.</p>

<p>The firm $i$ is price-taker, so the market price is the same whatever its production and so $\frac{dp}{dq_i}=0$.</p>

<p>The demand $p$ is a (strictly) decreasing function of $Q$ (supposing the law of demand is true). Thus $\frac{dp}{dQ} &lt; 0$</p>

<p>The other firms than firm $i$ are not supposed to react to a change in production of firm $i$, so that $\frac{dQ}{dq_i}=1$.</p>

<p>We get : $0 &lt; 0$. Is that the contradiction that Steve Keen means (or another way of expressing it) ?</p>

<p>Thank you so very much !</p>
","<p>This does sound a lot like the “contradiction” that Keen tries to derive. The key to resolving it is to remember that firms are small relative to the market, so $$\frac{\mathrm dQ}{\mathrm dq_i} = 0.$$</p>

<p>One way to justify the above restriction is to assume there is a continuum of firms, so that each firm has zero measure, and $$Q = \int_{j \in I} q_j \, \mathrm dj,$$ where $I$ is the index set of firms.</p>

<p>Another way to justify the price-taking assumption (which means that price is equal to marginal cost) is to look at a Cournot competition model with a large number of firms, as Michael mentions in his answer to this question. Formally, suppose there are $n$ firms in the industry so that industry output is given by</p>

<p>$$ Q^s = \sum_{i=1}^n q_i, $$</p>

<p>where $q_i$ is the output of firm $i$. Market demand is given by the inverse demand curve</p>

<p>$$ p = a -bQ, $$ where $a,b &gt; 0$. We normalise each firm's (constant) marginal cost to $0$, so that firm $i$'s profits are given by</p>

<p>$$ pq_i=(a-bQ^s)q_i = aq_i - bq_i \sum_{j=1}^n q_j.$$</p>

<p>The choice of $q_i$ that maximises the above expression solves</p>

<p>$$ a - b \sum_{j=1}^n q_j -b q_i = 0. $$</p>

<p>In other words,</p>

<p>$$ q_i^* (q_{-i}) = \frac{a - b\sum_{j \neq i}q_j}{2b} .$$</p>

<p>In a <em>symmetric</em> equilibrium, $q_i^* = q_j^* = q^*$, so the above best response function gives us</p>

<p>$$ q^* = \frac{a - (n-1)bq^*}{2b} \implies q^* = \frac{1}{n+1} \frac{a}{b}. $$</p>

<p>Hence, the equilibrium price is</p>

<p>$$ p^* = a - b \frac{n}{n+1}\frac{a}{b} = \frac{1}{n+1}a. $$</p>

<p>It is now easy to show that $p^* \to 0$ as $n \to \infty$, which is exactly the claim that the equilibrium price approaches marginal cost when the number of firms is large.</p>
","18993"
"Log-normality assumption in consumption based asset pricing","172","","<p>Consider a very basic discrete time representative consumer maximization problem with CRRA utility. There exist a risky asset with time $t$ price $p_t$ that pays time $t+1$ dividend $d_{t+1}$ , and a riskless asset with price $p_t^f$ that pays a constant payoff 1 at $t+1$. We assume that the dividends are a sequence of random variables that follow a Markov process. Assume further that the consumer has no other income streams (i.e. $y_t = 0 \ \forall t$). At time t consumer invests amount $\pi_t$ in the risky asset and amount $\pi_t^0$ in the riskless asset. Therefore, the maximization problem can be stated as</p>

<p>\begin{align*} 
&amp; \underset{\{ c_t, \pi \}_0^\infty}{\text{max}} \ \ E_0 \sum_{t=0}^\infty \ \beta^t \ \frac{c_t^{1-\gamma} -1}{1-\gamma} \\ 
\\
\
s.t  \ \ \ \ &amp; c_t + \pi_t p_t + \pi_t^0 p_t^0 = (d_t+p_t) \pi_{t-1} + \pi_{t-1}^0  \\
&amp; c_t \geq 0
\end{align*}</p>

<p>Say we want to find the equilibrium riskless rate and expected equity premium. In order to close the model, it is often assumed assumed (see e.g. Claus Munk's book <em>Financial Asset Pricing Theory</em> chapter 8.3) that the log-consumption growth and log-risky gross returns are jointly normally distributed. I.e</p>

<p>\begin{align*} 
&amp; ln \ \Big(\dfrac{c_{t+1}}{c_t} \Big) \equiv \bar{g}_{t+1} \sim N(\mu_g, \sigma_g^2) \\ 
&amp; ln R_{t+1} \equiv \bar{r}_{t+1} \sim N(\mu_r, \sigma_r^2) \ , \\
\end{align*}</p>

<p>where gross returns are defined as 
$$R_{t+1} \equiv \frac{p_{t+1} + d_{t+1}}{p_t} \ .$$</p>

<p>What I don't completely understand is where do thelog-normal distribution assumptions ""come from"". I know that since this is a representative agent economy, consumption of the agent must equal the aggregate dividend in the economy.  But since we assumed that there is no income, $y_t = 0 \ \forall t$, the only exogenous dividend process in the economy is $d_t$ and therefore it should have the same distribution as the consumption growth. However, my impression is that when we say the risky rate has log-normal distribution this actually means the dividend process, since it is the 'random part' in the definition of returns (price $p_{t+1}$ is not exogenous but determined inside the model). To me it seems now that we have made two different assumptions about the same endowment process $d_t$. Where does the assumption for consumption come from or what does it stand for? How would the situation change if the consumer had some income stream $y_t &gt; 0$?</p>
","<p>The typical two-period Lagrangian is</p>

<p>$$\Lambda = \beta^t\cdot \Big(\frac{c_t^{1-\gamma} -1}{1-\gamma} + \lambda_t\cdot \big[(d_t+p_t) \pi_{t-1} + \pi_{t-1}^0- c_t - \pi_t p_t - \pi_t^0 p_t^0\big]\Big) \\
+ \beta^{t+1}\cdot \Big(\frac{c_{t+1}^{1-\gamma} -1}{1-\gamma} + \lambda_{t+1}\cdot \big[(d_{t+1}+p_{t+1}) \pi_{t} + \pi_{t}^0- c_{t+1} - \pi_{t+1} p_{t+1} - \pi_{t+1}^0 p_{t+1}^0\big]\Big)$$ </p>

<p>The first order conditions with respect to $c_t, \pi_t$ are</p>

<p>$$c_t^{-\gamma} = \lambda_t \implies ... \gamma\ln \frac {c_{t+1}}{c_t} = \ln \frac {\lambda_{t}}{\lambda_{t+1}} \tag{1}$$</p>

<p>$$-\beta^t\lambda_tp_t + \beta^{t+1}\lambda_{t+1}(d_{t+1}+p_{t+1})=0 \implies  \frac {\lambda_{t}}{\lambda_{t+1}} = \beta \frac{p_{t+1} + d_{t+1}}{p_t} \tag{2}$$</p>

<p>and so, using also the definition of the gross return,</p>

<p>$$\ln \frac {\lambda_{t}}{\lambda_{t+1}} = \ln \beta + \ln R_{t+1} \tag{3}$$</p>

<p>Combining $(1)$ and $(3)$ we get</p>

<p>$$\ln \frac {c_{t+1}}{c_t} = \frac 1 {\gamma}\ln \beta + \frac 1 {\gamma}\ln R_{t+1} \tag{4}$$</p>

<p>So we see that at the optimal path, consumption growth is a direct affine function of the log-risk returns. This among other things implies that their correlation coefficient is equal to unity.</p>

<p>The normal distribution is closed under affine transformations (alternatively, under scaling and shifting), so <em>if</em> we assume that log-risky returns are normally distributed, then consumption growth is also normally distributed (with different mean and variance of course).</p>

<p>Note that although in general, the <em>joint</em> normality assumption is an additional one to be made when two normal random variables are not-independent, here, the fact that the one is an affine function of the other guarantees joint normality. By Cramer's condition for bivariate normality, it must be the case that all linear combinations of two normal random variables have a univariate normal distribution. In our case we have (generic notation) the random vavriable $Y$ and the random variable $X = a+bY$. Consider</p>

<p>$$\delta_1X + \delta_2 Y = \delta_1(a+bY) + \delta_2 Y = \delta_1a + (\delta_1b+\delta_2)Y$$</p>

<p>So for any $(\delta_1, \delta_2)$ (except the zero vector which is excluded a priori), $\delta_1X + \delta_2 Y$ follows a normal distribution if $Y$ does. So it is sufficient to assume that log-risk returns follow a normal distribution to obtain joint normality also.</p>
","13590"
"Where do computational economists work","172","","<p>Does anybody know what kind of work or where computational economists end up working? It seems most end up in research...</p>
","<p>The most useful way of thinking of a Computational Economist is one that will be able to estimate economic models in a quantitatively meaningful way. This makes them very useful for central banks which have the need to study the macroeconomy quantitatively and also have the time and resources to invest in a computational economist...</p>

<p>Other ways to look at this question:</p>

<p>The conferences by the society for computation economics are all populated by academic economists or by central bank economists. <a href=""http://www.iscef.com/4/program-committee.html"" rel=""nofollow"">enter link description here</a></p>

<p>The job-board sites, mostly ask for data scientists when you type in computational economics. <a href=""http://www.indeed.com/q-Computational-Economics-jobs.html"" rel=""nofollow"">enter link description here</a></p>

<p>Commentators at the job econ rumors site claim two things: that computational economics is forever going to be the science of the future, but never the presently hot science.<a href=""http://www.econjobrumors.com/topic/computational-economics-2"" rel=""nofollow"">enter link description here</a></p>
","11906"
"Book recommendation: agent based modeling?","171","","<p>Is there a book along these criteria?</p>

<ul>
<li>introductory</li>
<li>discuss both theory and writing program</li>
<li>focus on social science (economics / politics / sociology)</li>
</ul>

<p>There are bunch of tutorials on the Internet, but journal articles tend not to have code, and a lot of work is not relevant to social science. Thus I think I'll get better recommendation from Econs SE.</p>
","<p>Another book that comes to mind (in keeping with the 1 book per answer guideline) is the Quant-Econ book that is being put together by Tom Sargent and John Stachurski. This book is a little more geared towards programming than John's Economic Dynamics book and can be found (for free) online at <a href=""http://quant-econ.net/"" rel=""nofollow"">http://quant-econ.net/</a>.</p>

<p>All of the book's code is on github and I think it provides a pretty strong introduction to the two programming languages that it uses (Python and Julia).</p>
","6689"
"Cournot Model Monopoly example","171","","<p>Good day</p>

<p>In my Microeconomics course, we are handling the 4 imperfect competition models.</p>

<p>Currently we are discussing the Cournot Model, however I am unsure about a certain example. This is given as a lecture example (all information provided).</p>

<blockquote>
  <p>Let us first assume that we start with a single firm (monopoly).</p>
  
  <p>This monopoly is the owner of a costless spring (and sells the water).</p>
  
  <p>I.e., MC = 0</p>
  
  <p>Start with our demand function:</p>
</blockquote>

<pre><code>Q = 120 – P
Now, determine the profit maximizing price/output combination.
MR = MC
MC = 0
Q = 120 – P (Demand function) 
P = -Q + 120
Thus, MR = -2Q + 120
Thus -2Q + 120 = 0
Thus Q = 60
P = 60
Profits = 3600
</code></pre>

<p>I am familiar with the concept of calculating each firm's demand function, what confuses me is, in this example, we have a a single firm (monopoly) and when deriving its mariginal revenue function, one should end up with the following:</p>

<pre><code>P = -Q + 120
</code></pre>

<p><code>d/dQ = P' = -1</code> (using chainrule for -Q => -1 and dQ of constant = 0)</p>

<p>thus <code>MR = P' = -1</code></p>

<p>but in the example given, we arrive at:</p>

<pre><code>MR = -2Q + 120
</code></pre>

<p>What am I missing or is this example incomplete (not all information given)?</p>
","<p>You have found $\frac{dP}{dQ}=-1$ and $\frac{dQ}{dP}=-1$ </p>

<p>You have $R=PQ$ and $Q=120-P$ (equivalent to $R=120P-P^2$ or $R=120Q-Q^2$)</p>

<p>so the rate of marginal revenue for a small increase in quantity is $\frac{d(PQ)}{dQ}=Q\frac{dP}{dQ}+P\frac{dQ}{dQ} = -Q+P = 120-2Q$ leading to zero when $Q=60$  </p>

<p>while the rate of marginal revenue for a small increase in price is $\frac{d(PQ)}{dP}=Q\frac{dP}{dP}+P\frac{dQ}{dP} = Q-P = 120-2P$ leading to zero when $P=60$</p>

<p>both giving the point on the demand curve $Q=60, P=60$ as revenue maximising for the monopolist </p>
","13541"
"Is there always a pure Nash equilibrium in a resource selection game?","171","","<p>Denote $[r]\triangleq\{1,2,\ldots,r\}$.</p>

<p>Consider a game with $n$ players, $[n]$, each has $m$ strategies, $[m]$.</p>

<p>Each player $i$ has an associated payoff function, which considers only his selected strategy, and the number of players selected the same strategy:
$$U_i:[m]\times[n]\to[0,1]$$</p>

<p>Furthermore, the utility function is monotonically decreasing in the number of players which picked the same strategy, i.e.
$$\forall i\in[n],j\in[m],k\in[n-1]:U_i(j,k)\geq U_i(j,k+1)$$</p>

<blockquote>
  <p><strong>Does this game always have a pure Nash equilibrium?</strong></p>
  
  <p><strong>Can we (computationally) find it efficiently?</strong></p>
</blockquote>

<hr>

<p>Notice that the <strong>special case</strong>, where all players are symmetric ($\forall i,j\in[n]: U_i\equiv U_j\equiv U$), the game reduces to an exact potential game and therefore is guaranteed to have a pure Nash equilibrium. </p>

<p>The potential function for the symmetric case would be, given a strategy profile $s$:
$$\phi(s) = \sum_{j\in[m]}\sum_{k=1}^{\#_j(s)} U(j,k)$$</p>

<p>Where $\#_j(s)$ is the number of players in $s$ playing strategy $j$.</p>
","<p>Yes, there is always a pure Nash equilibrium. See:</p>

<p>I Milchtaich (1996). Congestion games with player-specific payoff functions. 
<em>Games and economic behavior</em> 13 (1), 111-124.</p>

<p>You are interested in the special case of <strong>singleton</strong> congestion games with player-specific payoff functions.</p>

<p>And yes, they can be computed in polynomial time. See Corollary 7 in:</p>

<p>Heiner Ackermann, Heiko Röglin, Berthold Vöcking (2009). Pure Nash equilibria in player-specific and weighted congestion games. <em>Theoretical Computer Science</em> 410 (17), 1552-1563.</p>
","3333"
"Martingale, random walk and rational expectations","171","","<p>What is the link between these concepts?</p>

<p>For example let's take a process $Z_n$ which follows a random walk, I would say that:</p>

<ol>
<li>This is a martingale, because my expectations of tomorrow, i.e. n+1 depends only on today</li>
<li>If we assume an individual with rational expectation, he will assume that the forecast of tomorrow is today</li>
</ol>

<p>So in other words, the forecast of a rational individual follows a martingale?</p>

<p>I am not sure of the difference since one concept is used in finance while the other in economics, but they seem basically the same to me.</p>

<p>Last, I have seen in the example that a random walk implies a martingale, is this always true? Does a martingale implies a random walk?</p>
","<p>All concepts are used in Economics. Definitions (not stated in a fully rigorous manner):</p>

<p><strong>Martingale :</strong> A stochastic process $\{X_t\}$ is called ""martingale"" if and only if it holds that</p>

<p>$$E(X_{t+1} \mid X_t,X_{t-1},...) = X_t \tag{1}$$</p>

<p>There are extensions like ""sub-martingale"", ""super-martingale"" but the basic definition is the above</p>

<p><strong>Random walk :</strong> A stochastic process $\{X_t\}$ is called ""random walk"" if and only if</p>

<p>$$X_{t+1} = X_t + u_{t+1}, \;\;\;u_t \sim \text{White Noise} \tag{2}$$</p>

<p>and you can look up the definition of ""White Noise"".</p>

<p>Here too there are spin-offs (""random walk with drift"" etc).</p>

<p>Comment: it follows that a random walk is (one example of) a martingale, but a martingale does not imply a random walk, the former being a much broader concept.</p>

<p><strong>Rational Expectations</strong> : Originally, the Rational Expectations Hypothesis stated that <em>the aggregate expectation</em> on some unknown (usually future) value of an <em>aggregate</em> random variable (<a href=""https://economics.stackexchange.com/a/141/61"">see also this post on the matter</a>), equals the conditional expectation (in the rigorous mathematical sense) of this variable ""given all relevant information at the time of forming the expectation</p>

<p>$$X^e_{t+k|t} = E(X_{t+k}\mid I_t) \tag{3}$$</p>

<p>Comment: note that the conditioning set in the case of a martingale contains only past values of the process. The conditioning set in the case of the REH contains ""whatever is available and is deemed relevant"".</p>

<p>In a representative agent model, we are forced, for internal methodological consistency, to apply the Rational Expectations Hypothesis at the individual level (something that has raised all sorts of valid objections as regards the availability of information and the information processing constraints of an individual).</p>

<p><strong>So do the forecasts of an individual follow a martingale?</strong> Let's examine it for one-step-ahead forecasts only: our stochastic process is </p>

<p>$$\{X^e_{t+1|t},\,X^e_{t+2|t+1},...\} = \{E(X_{t+1}\mid I_t),\,E(X_{t+2}\mid I_{t+1}),...\} \tag{4}$$</p>

<p>To obtain the martingale property it must hold that</p>

<p>$$E[X^e_{t+1|t} \mid X^e_{t|t-1}, X^e_{t-1|t-2},...] = ?\; X^e_{t|t-1} \tag{5}$$
(I will name in the end what expectations does eq. $(5)$ describes)</p>

<p>$$E[X^e_{t+1|t} \mid X^e_{t|t-1}, X^e_{t-1|t-2},...] = E[E(X_{t+1}\mid I_t) \mid \{E(X_{t}\mid I_{t-1}), E(X_{t-1}\mid I_{t-2}),...\}]$$</p>

<p>As already commented, the outer conditioning set is smaller than the inner conditioning set. By the Law of Iterated Expectations (the Tower property) of Conditional Expectation, we then obtain</p>

<p>$$E[E(X_{t+1}\mid I_t) \mid \{E(X_{t}\mid I_{t-1}), E(X_{t-1}\mid I_{t-2}),...\}] = E[X_{t+1} \mid \{E(X_{t}\mid I_{t-1}), E(X_{t-1}\mid I_{t-2}),...\}] \tag{6}$$</p>

<p>The right-hand-side of $(6)$ is not necessarily equal to the right-hand-side of $(5)$, so we <em>cannot</em> say that the stochastic process of one-step-ahead forecasts under the Rational Expectations Hypothesis is a martingale. </p>

<p>Equation $(5)$ describes the following situation: standing at period $t-1$ we form the expectation $X^e_{t|t-1}$, and ""the best we can say"" (best in the mean-squared-error sense) about our subsequent expectation $X^e_{t+1|t}$ is that it will be equal to $X^e_{t|t-1}$. This is (sometimes) called ""static expectations"" but beware because the term has two totally different meanings in the literature: for some authors, eq. $(5)$ represents ""static"" expectations in the sense that the expectation itself remains (or is expected to remain) unchanged in value. But you will often find authors who write the term ""static expectations"" <em>and mean something totally different</em>, namely $E(X_{t+1}\mid I_t) = X_t$ (""what is, will be""). This in turn <em>looks</em> like the martingale property but it is at best an extended concept of it (because the conditioning set is bigger), and in any case, it is a martingale-like property <em>as regards the actual process $\{X_t\}$</em>, and <em>not</em> the forecasts-process $\{X^e_{t+1|t}\}$.</p>
","11588"
"Time costs and the St. Petersburg paradox","171","","<p>In the St. Petersburg paradox, we end up with the problem that a rational agent should be willing to play the game for any wager, if we look at expected income or utility of expected income. The standard ""solution"" to this is to instead look at expected utility of income, where the marginal utility of income is decreasing.</p>

<p>Intuitively, decreasing marginal utility (for instance, where utility is logarithmic) of income makes sense, since one could argue that the utility of income comes from purchasing power, and standard indifference curves are convex.</p>

<p>But I've seen people (in a statistics department) point out that playing the game also has a time cost in addition to the monetary wager. This suggests potential other trade-offs that could affect decision making here, such as the fact that this time could be spent on more enjoyable pursuits, or in working and making money, even if the decreasing marginal utility is still the most convincing explanation for people's behavior to me.</p>

<p>How might be time-costs factored into the St. Petersburg problem, in terms of limiting the player's wager, and what literature might provide a good coverage of this?</p>
","<p>Consider the version of the paradox from <a href=""http://en.wikipedia.org/wiki/St._Petersburg_paradox"">Wikipedia</a>:</p>

<blockquote>
  <p>A casino offers a game of chance for a single player in which a fair coin is tossed at each stage. The pot starts at 2 dollars and is doubled every time a head appears. The first time a tail appears, the game ends and the player wins whatever is in the pot. Thus the player wins 2 dollars if a tail appears on the first toss, 4 dollars if a head appears on the first toss and a tail on the second, 8 dollars if a head appears on the first two tosses and a tail on the third, 16 dollars if a head appears on the first three tosses and a tail on the fourth, and so on. In short, the player wins 2k dollars, where k equals number of tosses. What would be a fair price to pay the casino for entering the game?</p>
</blockquote>

<p>If there is a finite fixed per-period time cost, $c$, of playing the game then the paradox would not be resolved. The payoff from the lottery would then be
$$-c+\sum_{t=1}^\infty \left[\frac{1}{2^t}\left(2^t-c\right)\right]=\sum_{t=1}^\infty \frac{1}{2^t}2^t-\sum_{t=0}^\infty \frac{c}{2^t}=-2c+1+1+1+\ldots=\infty$$</p>

<p>Thus, as in the original paradox, the value of the lottery is infinite.</p>

<p>An alternative might be to suppose that the marginal cost of time spent is not constant (e.g. it is increasing). However, it is hard to see how one would justify an increasing cost of time without invoking some idea of the dis-utility of time (but the whole purpose of this exercise is to get away from invoking a utility function). </p>

<p>Two solutions that are related (in the sense that they involve a time dimension) and that might be more appealing are:</p>

<p><strong>(1)</strong> discounting. Even if your utility of wealth is linear, you might put a low weight on future payments because you have to forego some return during the period between now and when the payment occurs. If the future is discounted at rate $\delta&lt;1$ then the lottery would have value
$$\sum_{t=1}^\infty\delta^{t-1}\frac{1}{2^t}2^t=\frac{1}{1-\delta}.$$
Thus, the value of the lottery is finite for any $\delta&lt;1$ and the lottery is more valuable to more patient people (i.e. people with larger $\delta$).</p>

<p><strong>(2)</strong> finite lifespan. This is formally equivalent to discounting, but conceptually different. Now the idea is that the player is not going to live forever so there is a chance that they 'die' before having the opportunity to collect the lottery's payoff. In particular, suppose that the player dies at the end of each period with probability $\lambda$ and that the payoff is zero if s/he dies before the end of the lottery. The value of the lottery is therefore
$$\sum_{t=1}^\infty\lambda^{t-1}\frac{1}{2^t}2^t=\frac{1}{1-\lambda}.$$
Thus, players who expect to live a long time have a higher willingness to pay for the lottery, but the value of the lottery is finite for anyone who does not expect to live forever.</p>
","152"
"Limits to Quantitative Easing Programmes","170","","<p>I have been reading recently on the quantitative easing programmes by the ECB and the BOJ, see <a href=""http://www.cnbc.com/2016/04/07/what-the-bank-of-japan-boj-will-do-now-that-negative-rates-have-disappointed.html"" rel=""nofollow"">http://www.cnbc.com/2016/04/07/what-the-bank-of-japan-boj-will-do-now-that-negative-rates-have-disappointed.html</a>, and, <a href=""http://www.bloomberg.com/news/articles/2016-04-21/ecb-to-start-buying-corporate-bonds-in-june-as-part-of-stimulus"" rel=""nofollow"">http://www.bloomberg.com/news/articles/2016-04-21/ecb-to-start-buying-corporate-bonds-in-june-as-part-of-stimulus</a>.</p>

<p>The ECB will be expanding its current programme to include corporate bonds and  it is being suggested that the BOJ may give up on negative interest rates and possibly could buy japanese equities instead. It seems that these central banks are just working their way up the risk asset spectrum. My question is where do these asset buying programmes stop (penny stocks/distressed debt?)? Also what happens to these assets, surely if they sit on the central banks books it could go bankrupt like a commercial bank? Moreover, what could cause these asset buying programmes to be abandoned/fail? </p>
","<p>1) In principle, there is nothing material to stop the central banks. Apparently, during the great recession in the 1930's in the US, the fed bought even stranger stuff. They could go domestic bonds, equities, houses, etc, and then they could go to foreign assets.</p>

<p>2) No, they cannot literally go bankrupt because they can always print money. Some banks have in fact begun to consider printing money as a way to forcefully lower the value of their currencies. </p>

<p>3) My guess is that the issue is really the opposite one. Banks are doing too well: they buy assets, and those assets do well, then the bank is actually backing up each unit of currency with <em>more</em> value than before. It's hard to create inflation like that...</p>

<p>4) The practical limits are twofold: it might be politically unsustainable. A) Sooner or later the public thinks this is useless and they elect a new central banker or ask the president to appoint a new one. B) It might create all kinds of strange incentives. For example, you might want t bribe the central bank reserve managers to buy <em>your</em> company's assets...</p>
","11715"
"Understanding subscripts in first order conditions of dynamic optimization problems","170","","<p>Suppose we have a simple maximization problem as described in Equation 1.1 <a href=""http://www.wouterdenhaan.com/teach/ch1.pdf"" rel=""nofollow"">here</a> or <a href=""http://www.wouterdenhaan.com/teach/ch1.pdf"" rel=""nofollow"">here</a>. This leads us to the Lagrangian Equation 1.3: $$\begin{align*}\mathcal{L} &amp;= \sum_{t=1}^\infty \beta^{t-1}\left\{u(c_t) + \lambda_t \left[ f(k_t) + (1 - \delta)k_t - c_t - k_{t+1}\right]\right\} \\ &amp;= \sum_{t=1}^\infty \left[\beta^{t-1} u(c_t) - \beta^{t-1}\lambda_t c_t + \beta^{t-1} \lambda_t f(\mathbf{k_t}) + \beta^{t-1}\lambda_t(1-\delta)\mathbf{k_t}  - \beta^{t-1}\lambda_t \mathbf{k_{t+1}}\right]  \end{align*}
$$</p>

<p>When we derive the first order condition with respect to $k_{t+1}$, which is:
$$\frac{\partial \mathcal{L} (\cdot)}{\partial k_{t+1}} = 0 :   \beta \lambda_{t+1} \frac{\partial f(k_{t+1})}{\partial k_{t+1}} +  \beta \lambda_{t+1} (1 - \delta) -\lambda_t=0$$</p>

<p>why do we use the subscript $\phantom{.}_{t+1}$ in  $\lambda_{t+1}$ and why does $\beta^{t-1}$ becomes $\beta$? I cannot understand how the first two terms are combined with the last one ($-\lambda_t$). </p>

<p>The relevant terms (with $k$) of the Lagrangian in period $\phantom{.}_{t+1}$ are: $$ \beta^{(t+1)-1} \lambda_{t+1} f(k_{t+1}) +  \beta^{(t+1)-1} \lambda_{t+1} k_{t+1} (1 - \delta) - \beta^{(t+1)-1} \lambda_{t+1} k_{(t+1)+1}$$ so for this part of the sum we do not ""care"" about the last term when we take the derivative with respect to $k_{t+1}$. So for this period this part of the sum is $$\frac{\partial \mathcal{L}_{t+1}}{\partial k_{t+1}} = \beta^{t} \lambda_{t+1} \frac{\partial f(k_{t+1})}{\partial k_{t+1}} +  \beta^{t} \lambda_{t+1}  (1 - \delta)$$ </p>

<p>The relevant terms (with $k$)  of the Lagrangian in period $\phantom{.}_{t}$ are:
$$\beta^{t-1} \lambda_t f({k_t}) + \beta^{t-1}\lambda_t(1-\delta){k_t}  - \beta^{t-1}\lambda_t k_{t+1}$$
so for this period the part of the sum is $$\frac{\partial \mathcal{L}_t}{\partial k_{t+1}} =  - \beta^{t-1}\lambda_t$$
Now the First Order Condition with respect to $k_{t+1}$ should be:  $$\frac{\partial \mathcal{L}_{t+1}}{\partial k_{t+1}} +  \frac{\partial \mathcal{L}_t}{\partial k_{t+1}} = \beta^{t} \lambda_{t+1} \frac{\partial f(k_{t+1})}{\partial k_{t+1}} +  \beta^{t} \lambda_{t+1}  (1 - \delta) - \beta^{t-1}\lambda_t = 0$$right?</p>
","<p>In an intertemporal maximization problem, we seek to find the optimal <em>sequence</em>  of the control and the state variables. It is the recursive nature of the problem that permits us to consider a ""typical"" point in time and just one condition per variable.  </p>

<p>For each such problem, we need to find out (carefully) <em>in how many distinct periods a specific realization of a variable appears</em>. To do this properly we should distinguish between the ""absolute"" index, and a ""running"" index. In the formulation of the Lagrangean as appears in the question, this is not done (and it is usual practice not to, but it may become confusing).  </p>

<p>So I would use the $t$ symbol as the absolute index (to arrive at same-looking first-order conditions), and some other symbol for the running index, say</p>

<p>$$\mathcal{L_t} = \sum_{j=0}^\infty \beta^{j}\left\{u(c_{t+j}) + \lambda_{t+j} \left[ f(k_{t+j}) + (1 - \delta)k_{t+j} - c_{t+j} - k_{t+j+1}\right]\right\} $$</p>

<p>Note that $t$ no longer affects  the discount factor $\beta$, and this is because the discount factor has to do with looking at the future, which is represented by the index $j$. Also, note that $j$ starts at zero, indicating that the first period is the $t$ period.  </p>

<p>Written this way, the Lagrangean says ""we are at some point in time indicated by $t$ (that can take the value zero or whatever positive value), and we are looking forward period by period counted by index $j$"".</p>

<p>For <em>any given</em> $j$ we have</p>

<p>$$\mathcal{L}_t =...+ \beta^{j}\Big\{u(c_{t+j}) + \lambda_{t+j} \left[ f(k_{t+j}) + (1 - \delta)k_{t+j} - c_{t+j} - k_{t+j+1}\right]\Big\} + \beta^{j+1}\Big\{u(c_{t+j+1}) + \lambda_{t+j+1} \left[ f(k_{t+j+1}) + (1 - \delta)k_{t+j+1} - c_{t+j+1} - k_{t+j+2}\right]\Big\} + ...$$</p>

<p>Pondering this, we realize that the variable $k_{t+j+1}$ will appear in only two consecutive periods, and so the first order condition for a ""typical"" element of the sequence $\{k_{t+j}\}_{j=0}^{\infty}$ can be exrpessed by differentiating only these two periods with respect to $k_{t+j+1}$. Doing so we get</p>

<p>$$\frac {\partial \mathcal{L}_t}{\partial k_{t+j+1}} =  -\beta^{j} \lambda_{t+j}  + \beta^{j+1}\Big\{ \lambda_{t+j+1} \left[ f'(k_{t+j+1}) + (1 - \delta)\right]\Big\} $$</p>

<p>Take common factors (which will simplify the discount factor) and set equal to zero</p>

<p>$$\frac {\partial \mathcal{L}_t}{\partial k_{t+j+1}} = \beta^{j} \Big[-\lambda_{t+j}  + \beta\Big\{ \lambda_{t+j+1} \left[ f'(k_{t+j+1}) + (1 - \delta)\right]\Big\}\Big] = 0$$</p>

<p>To lighten the indexing burden, we can express this for $j=0$, to obtain</p>

<p>$$\frac {\partial \mathcal{L}_t}{\partial k_{t+1}} = 0 \implies -\lambda_{t}  + \beta\Big\{ \lambda_{t+1} \left[ f'(k_{t+1}) + (1 - \delta)\right]\Big\} = 0$$</p>
","4592"
"Why do stock exchanges not operate at a fixed frequency?","170","","<p>Would this not be more fair towards traders who don't trade at high frequency?</p>

<p>And would it not be possible to distribute this fixed frequency to other exchanges, modulo relativity?</p>

<p>The reason I'm asking is because I recently learned that <a href=""http://tabbforum.com/opinions/why-hfts-have-an-advantage-part-3-intermarket-sweep-orders"">high-frequency traders are beating inter-market sweep orders</a>.</p>
","<p>As long as trading faster is not explicitly forbidden, there will be people who want to trade faster <em>if</em> they can take advantage of it. </p>

<p>If you are able to trade fast enough, you can take advantage of arbitrage situations.
For instance, if you can detect a fall in the price of soy on the New-York exchange, buy soy on the New-York Exchange, and sell it on the Chicago exchange before the price in Chicago adapts, you will profit from it. </p>

<p>So, on the positive side, the answer to your question in the title ""Why do stock exchanges not operate at a fixed frequency?"" seems to be ""because it's not impossible/forbidden to operate faster and people benefit from it"".</p>

<p>Now, on the normative side, there are certainly a fair amount of people who believe that stock exchanges would perform ``better"" if they operated at a fixed frequency.</p>

<p>Roughly, increasing the frequency of trades is good if it allows prices to adapt faster to new <em>economic</em> <em>information</em>. Some people argue, however, that past a certain threshold, increasing the speed of trade cannot foster more effective price adjustments. The argument is that relevant economic information only arrives every so often, and there is no point in trading faster than the fastest stream of relevant information.
Past this threshold -- so the argument goes, increasing the speed of trade only allows for increased high-frequency speculation in which traders benefits from arbitrage situations that are unrelated with ``actual"" economic fundamentals. </p>

<p>I don't think they are the first to propose it, but Budish, Crampton and John have a recent pair of papers in which they advocate for a cap on the speed of transactions for similar reasons : <a href=""http://papers.ssrn.com/sol3/Papers.cfm?abstract_id=2388265"" rel=""nofollow"">The High-Frequency Trading Arms Race: Frequent Batch Auctions as a Market Design Response</a>, and <a href=""http://www.ingentaconnect.com/content/aea/aer/2014/00000104/00000005/art00071"" rel=""nofollow"">Implementation Details for Frequent Batch Auctions: Slowing Down Markets to the Blink of an Eye</a>.</p>
","11573"
"Interpretation of the growth rate of consumption in a simple one-good model","169","","<p>In Perman et al. ""The efficient and optimal use of natural resources"" it is presented a simple single-good model of welfare dynamic optimisation with non-renewable natural resource where:</p>

<p>Obj:
$$
max \int_{t=0}^{t=inf}{U(C) e^{-\rho t} dt} 
$$
s.t.
$$
\dot S_t = -R_t
$$
$$
\dot K_t = Q(K_t,R_t)-C_t
$$</p>

<p>That is, the economy is comprised of a single output Q that can be either consumed or added to the capital stock K (that doesn't depreciate).</p>

<p>Solving the model and rearranging the first order conditions, the book found that among the optimal path the growth rate of consumption is:</p>

<p>$$
\frac{\dot C} {C} = \frac {Q_k - \rho}{\eta}
$$</p>

<p>where $Q_k$ is the marginal product of the capital, $\rho$ is the social discount rate and $\eta$ being the elasticity of the marginal utility with respect to consumption is, under bland assumptions, guaranteed to be positive.</p>

<p>Now, my problem is the interpretation of the sign implications of this equation.</p>

<p>If $Q_K$ is greater than $\rho$, the consumption rate increases (and the opposite). What does it mean?</p>

<p>The books explains it considering that $\rho$ (the social discount rate) reflects impatience for future consumption, and $Q_K$ (the marginal product of capital) is the pay-off to delayed consumption. </p>

<p>Under this interpretation the relation implies that along an optimal path
when ‘pay-off’ is greater than ‘impatience’ ""<em>consumption is increasing</em>"", or that <em>""the economy will be accumulating K and hence growing</em>"".</p>

<p>But in my experience if $Q_K$ is higher than the discount rate, I have an higher incentive to stock K rather than consume, so how the consumption could increase ?
Also, it is said that ""when ‘pay-off’ is less than ‘impatience’, the economy will be running down K."", but how can the K reduce in this simple model where there is no capital depreciation?</p>
","<p>I think you could have posted the question in a simpler manner. The exhaustible resource stock has nothing to do with the question. It is just the basic Euler equation in canonical Solow growth model.</p>

<p>Basically, if your pure rate of time preference $\rho$ (equivalently, your patience level) is higher than the  interest rate of capital ($\rho&gt;Q_{k}$), it means that you are impatient and consume most of what you have at earlier dates and you have less to consume in future. In which case, your consumption starts with higher values at date $0$ and dynamically decreases over time.</p>

<p>Another way to see this ; if interest rate of capital is higher, you have more incentive accumulate capital (by having savings) at earlier dates and postpone your consumptions to later dates. In this case, you will consume less in earlier dates and consume more at later dates. Therefore, your consumption will increase dynamically over time.</p>

<p>Hope that it helps.</p>
","13499"
"Is the Convex Combination of Two Pareto Optimal Allocations Also Pareto Optimal?","169","","<p>I am studying for my qualifiers, and I ran into this question from a previous year's exam.</p>

<p>$\textbf{Question:}$</p>

<p>Consider a two-consumer two-good pure exchange economy. Both preferences are locally non-satiated and convex. Prove or disprove the following statement: if $(x_1,x_2)$ and $(\hat{x}_1,\hat{x}_2)$ are two different pareto optimal allocations, then the convex combination, $(\alpha x_1+(1-\alpha)\hat{x}_1,\alpha x_2+(1-\alpha)\hat{x}_2$ MUST also be pareto optimal for any $\alpha\in(0,1)$.</p>

<p>I believe the statement is true, and here is the work for my proof below.</p>

<p>$\textbf{My Proof:}$
By pareto optimality of $x_i$ and $\hat{x}_i$: 
$$\not\exists\; x_i^\star\; s.t.\; u_i(x_i^\star)\geq u_i(x_i)\;\forall i\; \text{and}\; u_i(x_i^\star)&gt; u_i(x_i)\;\text{for at least one }i \;\text{or}\;u_i(x_i^\star)\geq u_i(\hat{x}_i)\;\forall i\; \text{and}\; u_i(x_i^\star)&gt; u_i(\hat{x}_i)\;\text{for at least one }i$$
$$\implies\;u_i(\alpha x_i)\geq u_i(\alpha x_i^\star)\;\forall i\;\text{and}\;u_i((1-\alpha)\hat{x}_i)\geq u_i((1-\alpha)x_i^\star)\;\forall i$$
$$\implies\not\exists\;x_i^\star\;s.t.\;u_i(\alpha x_i^\star+(1-\alpha)x_i^\star)\geq u_i(\alpha x_i+(1-\alpha)\hat{x}_i)\;\forall i$$
$$\text{and}\;u_i(\alpha x_i^\star+(1-\alpha)x_i^\star)&gt; u_i(\alpha x_i+(1-\alpha)\hat{x}_i)\;\text{for at least one}\;i$$
$$\implies (\alpha x_i+(1-\alpha)\hat{x}_i)\;\text{is pareto optimal}$$
$$\blacksquare$$</p>

<p>This proof seemed almost too easy, so I'm wondering if it is correct/rigorous.</p>
","<p>Here 
$$\not\exists\;x_i^\star\; s.t.\; u_i(\alpha x_i)\geq u_i(\alpha x_i^\star)\;\forall i\;\text{and}\;u_i((1-\alpha)\hat{x}_i)\geq u_i((1-\alpha)x_i^\star)$$
$$\implies\not\exists\;x_i^\star\;s.t.\;u_i(\alpha x_i^\star+(1-\alpha)x_i^\star)\geq u_i(\alpha x_i+(1-\alpha)\hat{x}_i)$$
you assume that the function $u$ is linear. Unfortunately the statement is false for non-linear utility functions. Try 
$$
U_1(x_1,y_1) = x_1 \cdot y_1^2 \hskip 20pt U_2(x_2,y_2) = x_2^2 \cdot y_2.
$$
Given 1 unit of $x$ and $y$ each, the allocations
$$
(x_1,y_1) = (1,1) \hskip 20pt (x_2,y_2) = (0,0)
$$
and
$$
(x_1',y_1') = (0,0) \hskip 20pt (x_2',y_2') = (1,1)
$$
are both Pareto-optimal. However the points on the connecting $x = y$ line are not. You can verify this by comparing $MRS_1$ and $MRS_2$ for points on the line. Hence the Pareto-set is not convex in this case. (It is a curve connecting the two extreme allocations given above.)</p>
","12421"
"Aside from buying IPOs, what exactly is the point of shareholders?","168","","<p>The more I look at the shareholder system in modern capitalism, the more it starts to appear as nothing more then an otherwise meaningless system that allows rich people to profit off others work while providing nothing and holding no liabilities.</p>

<p>Of course, I will explain why I think this, then I want someone to explain to me why and how I'm wrong. What exactly am I missing?</p>

<p>A company sells shares in order to raise money from the IPO, however:</p>

<blockquote>
  <ol>
  <li>Why couldn't you just use bonds and other forms of debt instead?</li>
  <li>Why should shares give shareholders rights beyond receiving dividends? Couldn't they justify buying the security on that alone?</li>
  <li>Why should the company act for their shareholder's profit? They bought an IPO (or, most of the time, didn't) and are receiving dividends? Why should they arbitrarily be given more?</li>
  <li>Given that major shareholders are often vary rich; doesn't this system just facilitate unhealthy levels of income inequality given how the workers are treated as liabilities to be minimised?</li>
  <li>What's the point of money making via stock buy-backs if smaller companies who could use the money to better compete (and thus help the market) are more rarely in a position to do this?</li>
  <li>Don't hostile takeovers using this system do nothing more then create frustration and monopolies?</li>
  </ol>
</blockquote>

<p>Again, I get the point of the system, but how does having all this gunk help? Again, it just looks to me like a simple idea that was pumped full of crap that conveniently helps no one except power interests.</p>

<p>But as I said; am I wrong? And if so, how?</p>
","<p>a bit late to the party, but:</p>

<p><strong>While shareholders are traditionally considered owners, whether this is legally true is a matter of dispute</strong></p>

<p>As Cornell Law professor Lynn Stout writes in The Shareholder Value Myth:</p>

<p><a href=""http://scholarship.law.cornell.edu/cgi/viewcontent.cgi?article=2311&amp;context=facpub"" rel=""nofollow noreferrer"">http://scholarship.law.cornell.edu/cgi/viewcontent.cgi?article=2311&amp;context=facpub</a></p>

<blockquote>
  <p>Although laymen sometimes have difficulty understanding the point, corporations are legal entities that own themselves, just as human entities own themselves. What shareholders own are shares, a type of contact between the shareholder and the legal entity that gives shareholders limited legal
  rights. In this regard, shareholders stand on equal footing with the corporation’s bondholders, suppliers, and employees, all of whom also enter contracts with the firm that give them limited legal rights.</p>
</blockquote>

<p>And as Harvard business professor Jay Lorsch writes:</p>

<p><a href=""https://hbr.org/2012/07/what-good-are-shareholders"" rel=""nofollow noreferrer"">https://hbr.org/2012/07/what-good-are-shareholders</a></p>

<blockquote>
  <p>In legal terms, shareholders don’t own the corporation (they own securities that give them a less-than-well-defined claim on its earnings)...</p>
  
  <p>But remember, shareholders aren’t quite the same as owners. A simple
  illustration: If you own a car, you’re liable for damages in an
  accident even if they exceed the value of the car. But shareholders
  are on the hook only for what they’ve invested. And although some
  shareholders behave much like owners, most of them are effectively
  renters</p>
</blockquote>

<p>For more, see the works of Stephen Bainbridge or Kent Greenfield, or The Fundamental Rights of the Shareholder by Julian Velasco, which gives a good summary of the debate and shareholders' legal status:</p>

<p><a href=""https://lawreview.law.ucdavis.edu/issues/40/2/articles/davisvol40no2_velasco.pdf"" rel=""nofollow noreferrer"">https://lawreview.law.ucdavis.edu/issues/40/2/articles/davisvol40no2_velasco.pdf</a> (see section IV)</p>

<p><strong>Shareholder primacy ideology is bad for the economy</strong></p>

<p>So when you write:</p>

<blockquote>
  <p>The more I look at the shareholder system in modern capitalism, the more it starts to appear as nothing more then an otherwise meaningless system that allows rich people to profit off others work while providing nothing and holding no liabilities.</p>
</blockquote>

<p>There are a lot of very smart and very well-informed people who believe that this is not too far off, and that our financial system is practically designed to cause inequality and wealth extraction.</p>

<p>Here are some interesting papers with some choice quotes:</p>

<p><a href=""https://hbr.org/2014/09/profits-without-prosperity"" rel=""nofollow noreferrer"">https://hbr.org/2014/09/profits-without-prosperity</a></p>

<blockquote>
  <p>Corporate profitability is not translating into widespread economic prosperity...The allocation of corporate profits to stock buybacks deserves much of the blame. Consider the 449 companies in the S&amp;P 500 index that were publicly listed from 2003 through 2012. During that period those companies used 54% of their earnings—a total of $2.4 trillion—to buy back their own stock, almost all through purchases on the open market. Dividends absorbed an additional 37% of their earnings. That left very little for investments in productive capabilities or higher incomes for employees...</p>
  
  <p>the amount of stock taken out of the market has exceeded the amount issued in almost every year; from 2004 through 2013 this net withdrawal averaged $316 billion a year. In aggregate, the stock market is not functioning as a source of funds for corporate investment...</p>
  
  <p>from 2003 through 2012, Pfizer funneled an amount equal to 71% of its profits into buybacks, and an amount equal to 75% of its profits into dividends. In other words, it spent more on buybacks and dividends than it earned and tapped its capital reserves to help fund them. </p>
</blockquote>

<p><a href=""https://hbr.org/2014/06/the-price-of-wall-streets-power"" rel=""nofollow noreferrer"">https://hbr.org/2014/06/the-price-of-wall-streets-power</a></p>

<blockquote>
  <p>Scholars and executives alike have criticized Wall Street not only for promoting short-term thinking but for sacrificing the interests of employees and customers to benefit shareholders...</p>
  
  <p>One of the most important—and most dangerous—is when a single sector or group is so powerful that it dominates how an entire society thinks about itself. Once you view research from a variety of fields through that lens, it becomes clear that we must do something to curb the enormous and disproportionate power of Wall Street.</p>
</blockquote>

<p><a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2993978"" rel=""nofollow noreferrer"">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2993978</a></p>

<blockquote>
  <p>By legitimizing massive distributions of corporate cash to shareholders, MSV directly undermines the building of the organizational capabilities that are the essence of innovative enterprise.</p>
</blockquote>

<p><a href=""http://cepr.net/documents/publications/private-equity-2012-02.pdf"" rel=""nofollow noreferrer"">http://cepr.net/documents/publications/private-equity-2012-02.pdf</a></p>

<blockquote>
  <p>...regulatory changes that are needed to curb the destructive
  outcomes associated with some types of private equity activity</p>
</blockquote>

<p><a href=""https://www.huffingtonpost.com/dean-baker/finance-in-america-promot_b_5628729.html"" rel=""nofollow noreferrer"">https://www.huffingtonpost.com/dean-baker/finance-in-america-promot_b_5628729.html</a></p>

<blockquote>
  <p>The bloated financial sector in the United States is a major engine of inequality sucking money away from poor and middle-income households and making folks like Lloyd Blankfein, Jamie Dimon, and Robert Rubin incredibly rich.</p>
</blockquote>

<p>(okay, a Huffington Post article isn't an academic paper, but just about everything Dean Baker writes is gold, such as: <a href=""http://cepr.net/documents/working-paper-upward-distribution-income-rents.pdf"" rel=""nofollow noreferrer"">http://cepr.net/documents/working-paper-upward-distribution-income-rents.pdf</a>)</p>

<p>EDIT: not sure why I'm getting downvoted. I (1) provided two reputable sources arguing that the accepted answer is incorrect (don't have enough rep to comment), and (2) giving a broad answer to a broad question, I explained that the OP's concerns about inequity are completely justified and provided reliable and rigorous reading material if they should want to learn more</p>
","19766"
"Differentiating a conditional expectation: RBC models with uncertainty","168","","<p>Is the following true? \begin{equation}\frac{\partial}{\partial X_{t+1}}E_t(f(X_{t+1}))=E_t(\frac{\partial}{\partial X_{t+1}}f(X_{t+1}))\tag{1}\end{equation} where $f$ is some affine function (e.g., $f(x)=a+bx$), $E_t(X_s)=E(X_s|I_t)$ denotes the conditional expectation of $X_s$ given information $I_t$ in time period $t$, and where $X_s$ denotes the value of some variable $X$, say financial asset holdings, in time period $s$, such that $X_s$ is unknown (i.e., stochastic) given information at time periods $0\leq t&lt;s$ but known otherwise.</p>

<p>Edit 3: I <em>think</em> we should view $X_{t+1}$ as a function of information in time period $t$, i.e. $X_{t+1}=X_{t+1}(I_t)$. This hinders $(1)$ from being zero (see Alecos' comment below). If this is the right way to look at the problem (see ""Edit 2"" below; I do not know how to look at the problem, that's why I'm asking!) then $(1)$ may be written in detail as \begin{equation}\frac{\partial}{\partial X_{t+1}}E(f(X_{t+1}(I_t))|I_t)=E(\frac{\partial}{\partial X_{t+1}}f(X_{t+1}(I_t))|I_t).\tag{1'}\end{equation}</p>

<p>I often notice that $(1)$ (or $(1')$) <em>seems</em> to be used when studying real business cycle models with uncertainty where the Lagrange method is applied (this framwork is outlined in e.g. Gregory C. Chow's <em>Dynamic Economics: Optimization by the Lagrange Method</em>). </p>

<p>For example, we may have a situation where we have to differentiate \begin{equation}-\lambda_t A_{t+1}+E_t(\lambda_{t+1}(1+r_t)A_{t+1})+\Phi\tag{2}\end{equation} w.r.t. financial asset holdings $A_{t+1}$ in time period $t+1$, where $\lambda_t,\lambda_{t+1}\geq 0$, $r_t\in\mathbb{R}$ and $\Phi$ are independent of $A_{t+1}$ (i.e., they are not functions of $A_{t+1}$), and <em>seem</em> to use $(1)$ to arrive at the conclusion that the partial derivative of $(2)$ w.r.t. $A_{t+1}$ is \begin{equation}-\lambda_t+E_t(\lambda_{t+1}(1+r_t)).\tag{3}\end{equation}  </p>

<p>I neither understand <em>if</em> $(1)$ is used to justify the implication from $(2)$ to $(3)$, nor <em>if</em> $(1)$ is true, within the framework mentioned in the parenthesis above, but know of other treatments which begin by discussing measure theory and stochastic processes (e.g., <a href=""http://www.econ.yale.edu/smith/econ510a/book.pdf"" rel=""nofollow noreferrer"">Lecture notes for Macroeconomics I: Chapter 6</a>), and then deriving similar, but not exactly analogous, first order conditions to that derived by using fact $(1)$ and the Lagrange method. </p>

<p>Edit 1: I was asked to post a reference. The reference is lecture notes written by my lecturer. It says the following. If we have a representativve household's maximization problem $$\max_{\{C_t,A_{t+1}\}_{t=0}^{\infty}}E_0\sum_{t=0}^{\infty}\beta^tu(C_t)$$ subject to the budget constraint $$C_t+A_{t+1}=Y_t+(1+r)A_t,\quad\forall t\in\mathbb{Z}_{\geq 0},$$ then we want to investigate the first order conditions for the Lagrangian\begin{equation}\mathcal{L}=E_0\left[\sum_{t=0}^{\infty}\beta^tu(C_t)+\sum_{t=0}^{\infty}\lambda_t[Y_t+(1+r)A_t-C_t-A_{t+1}]\right].\tag{4}\end{equation} One first order condition is the partial derivative of $\mathcal{L}$ w.r.t. $A_{t+1}$: $$-\lambda_t+E_t[\lambda_{t+1}(1+r)].$$ (To be exact he writes that the above is a first order condition for the Lagrangian $\mathcal{L}$. I've interpreted that as meaning that he partially differentiates $\mathcal{L}$ w.r.t. $A_{t+1}$.)  My question is then: Why is that true?</p>

<p>Edit 2: I've also used the following reference: <a href=""http://www.sfu.ca/~bkrauth/econ808/808_lec5.pdf"" rel=""nofollow noreferrer"">Chapter 5. Real Business Cycles</a>. See equation $(5.7)$. How does the author derive that equation? Does he differentiate inside the conditional expectations, as expressed by me in $(1)$?</p>

<p>Edit 4: To be more exact, $I_t$ may capture the value of e.g. output $Y_t$ (compare with the budget constraint above).</p>
","<p>As I noted in a comment, to consider non-trivially a derivative, we must have a non-constant function in the first place. So, in generic terms, we are looking at the conditional expectation <em>function</em> $E(X\mid Z)$ and not at the conditional expected value of $X$ given a specific value $Z=  z$. </p>

<p>Then, $E(X\mid Z)=g(Z)$, i.e. it is a function of $Z$ only, not of $X$, so it appears that its derivative with respect to $X$ should be zero.  </p>

<p><strong>But:</strong> the way the problem is formulated, we treat the $X$, ($A_{t+1}$ in the OP's example), <em>as a decision variable</em>. Namely as a variable for which we can <em>choose</em> the value that it takes. But this conflicts with the fundamental characteristic of a random variable, i.e. that it is not under our control and its actual realization is unknown.  By treating it as a decision/command variable, we effectively neutralize any aspect related to a random variable, the conditional expectation aspect in our case. And it is in that sense that we can consider the derivative ""ignoring"" the existence of the conditional expectation operator. </p>

<p>Note that, for the problem laid out at the end of OP's question, <em>if</em> income $Y_t$ is known at the time of the decision for current consumption, then $A_{t+1}$ is also completely determined, there is nothing random/unknown/uncertain about it. This then allows, in a Lagrangian formulation, to treat $A_{t+1}$ also as a decision variable and consider derivatives with respect to it.</p>
","14301"
"Is there an alternative metric to GDP that measures a country's assets rather than flows?","168","","<p>The <a href=""https://en.wikipedia.org/wiki/Gross_domestic_product"" rel=""noreferrer"">Gross domestic product</a> measures <em>the value of all final goods and services produced in a period</em>.</p>

<p>This has some limitations.  For example, if a car hits a lightpost and both need to be repaired and some parts replaced, that contributes to the GDP, even though at the end we're in roughly the same situation as before and the reparation process has used resources (labour and material) that might have been used elsewhere.  From <a href=""https://en.wikipedia.org/wiki/Gross_domestic_product#Limitations_and_criticisms"" rel=""noreferrer"">Wikipedia</a>:</p>

<blockquote>
  <p>The UK's Natural Capital Committee highlighted the shortcomings of GDP in its advice to the UK Government in 2013, pointing out that GDP ""focusses on flows, not stocks. As a result an economy can run down its assets yet, at the same time, record high levels of GDP growth, until a point is reached where the depleted assets act as a check on future growth"". They then went on to say that ""it is apparent that the recorded GDP growth rate overstates the sustainable growth rate. Broader measures of wellbeing and wealth are needed for this and there is a danger that short-term decisions based solely on what is currently measured by national accounts may prove to be costly in the long-term"".</p>
</blockquote>

<p>I'm aware of numerous alternative measures focussing well-being, such as the <a href=""https://en.wikipedia.org/wiki/Human_Development_Index"" rel=""noreferrer"">Human Development Index</a>,<a href=""https://en.wikipedia.org/wiki/Gross_National_Happiness"" rel=""noreferrer"">Gross National Happiness</a>, and the <a href=""https://en.wikipedia.org/wiki/Happy_Planet_Index"" rel=""noreferrer"">Happy Planet Index</a>.  They don't really measure either wealth or well-being (the latter may be impossible to measure), and their exact definition is somewhat arbitrary.</p>

<p>Is there any reasonably well-established alternative to GDP that measures the total value of the stocks of a country?  Wikipedia has a <a href=""https://en.wikipedia.org/wiki/List_of_countries_by_financial_assets_per_capita"" rel=""noreferrer"">financial assets</a> list, but it relates only to households (and on this list, Greece is almost twice as wealthy as <em>Norway</em>, which is so vastly against expectations that I wonder if the definition is useful).  I can reasonably well estimate the value of my own assets (except for the value of my education/skills, which is harder to quantify).  Is there any metric that is used to estimate the value of all assets in a nation: infrastructure, real estate, machines, goods, farmland, but also education, human capital, unmined natural resources, etc.?</p>
","<p>You are correct in pointing out the flaws of GDP. But honestly, it's the best we have came up with; measuring the stock of wealth is just impossible. </p>

<p>You say you can estimate the value of your own assets, and of course it seems that way. We all feel that way, until we actually try. How much is your cellphone worth? Easy to know, go to ebay and look for similar phones in similar conditions and you get a price for that phone, right? Why don't we do that for all the country's cellphones? Well, because if we put all the cellphones in the market <strong>prices would drop down dramatically</strong>. Now, we're not obviously sending all the cellphones to the market, we just want to know how much its value is, but the point is that in order to have an estimation, we have to make <strong>assumptions</strong> regarding the market. The value of one cellphone is easy to calculate because it doesn't really affect the market. </p>

<p>Additionally, who says that you have to sell it in your local market? Why don't you offer it in Australia or Japan or Algeria or wherever the price is higher? And why not sell it another day when the price is up? The same goes for your car, house, computer, clothes, books, etc.</p>

<p>Think now of your financial assets. You can know that, right? All one needs to do is see what the bank says, and it says that my investment portfolio is worth \$100.... at least <strong>today</strong>... and <strong>exactly at the time I checked</strong>. But remember: the value of any financial portfolio is going up and down with high volatility even in the same day. Now try to figure out the value of the financial assets of all the country. Well, you can do that. But again: just today, and just at the time you checked. </p>

<p>Even though it doesn't seem like it, the same goes for goods. Take oil. Say that there is an oil reserve with x millions of barrels just waiting to be extracted and sent out to the market. How much is the value of that reserve? It depends on when you ask, whom you ask to, and who else is asking the same question (other sellers). What about gold? silver? copper? coal? wood? You can estimate a value in a given time, but that can be very different in another time.</p>

<p>What about land? Well, if I sow corn it will give me a given amount, but if I sow rice it will yield a different amount. Besides, would it be the same if my neighbor sows corn and I sow rice than if we both sow the same (competition)? What if I want to use it to generate electricity instead of growing food? Or what if I use it for livestock? What if I sell it? What if we all decide to do the same thing at the same time? Or what if we decide to do completely different things? Indeed to value farm land, you have to assume what use will it have.</p>

<p>Infrastructure is even more complicated. How much is a railroad valued? And what does value even mean in this context? There is no secondary market for railroads is there? There are opportunity costs, though. And we have the construction value too. But the we would have to make assumptions on its depreciation, and say how much of the revenue of the country is due to this specific segment of the railroad. To estimate this, one has to say how much the country would loss was the railroad not there (which is a fictitious value). What about parks?</p>

<p>Don't even get me started on natural resources (rivers, lakes, coast, jungles, biodiversity, etc). But even then, those are the easy ones. We still have left education, experience, skills and the like. But this post is long already, the point has been made and now I have a headache for thinking all this. </p>

<p>Indeed, there are many serious and very clever attempts to make estimations of these. But they are used to answer very specific questions. GDP, on the other hand is easy: just sum all the sells of goods and services. We (economists) don't like it very much either, but that's all we have. Just try to accept it, and don't take it to seriously.</p>
","12160"
"Muth exposition of the rational expectations hypothesis","168","","<p>I am reading in statistical decision theory and stumbled upon the rational expectations literature (rationality with incomplete information->dynamic problem->N.L Stokey->husband). The assumption that subjective expectation approximates the objective probabilities without adaptive learning seems almost ridiculous if one considers that the whole enterprise of statistics is to learn from the past to infer about the future. </p>

<p>Nevertheless, as explained clearly in the <a href=""https://economics.stackexchange.com/a/141/4205"">answer to another question</a>, Muth (1961) proposed the hypothesis of rational expectations as a purely descriptive model, to facilitate explanation of certain market behavior, however unrealistic it might be to generalize this hypothesis to all behavior.</p>

<p>Please refer to the <a href=""http://www.fep.up.pt/docentes/pcosme/S-E-1/se1_trab_0910/se1.pdf"" rel=""nofollow noreferrer"">full text of the paper</a>.</p>

<p>If I understood it correctly, section 3 of the paper is an exposition of how such a rational expectations hypothesis, as the author proposed and shortly justified in section 2, can be applied to analyze several market situations. </p>

<p>I had difficulty understanding the reasoning around equations 3.3-3.4. In particular:</p>

<blockquote>
  <p>Referring to (3.3) we see that if $\frac{\gamma}{\beta}\neq-1$ the rationality assumption (3.4) implies that $p_t^e=0$, or that the expected price equals the equilibrium price. </p>
</blockquote>

<p>What does the last part of the sentence mean? That equation (3.4) holds? How can $\frac{\gamma}{\beta}\neq-1$, $p_t^e\neq0$ and equations (3.3) and (3.4) hold together? </p>

<p>If I understand his exposition as imposing the rational expectations hypothesis (equation 3.4) on the market equilibrium price (equation 3.3), then the solution would be that either $\frac{\gamma}{\beta}=-1$ or that $p_t^e=0$. What does this mean? Or is he trying to show something else?</p>
","<p>Muth assumes a model of </p>

<blockquote>
  <p><em>""...short-period price variations in an isolated market with a fixed
  production lag of a commodity which cannot be stored"".</em></p>
</blockquote>

<p>It is useful to remember that the model's equations are expressed as deviations from equilibrium values. So in a bit more clear notation than the original (a star denotes <em>long-run</em> equilibrium value)</p>

<p>$$\begin{align} &amp; D_t-D^* = -\beta (p_t-p^*) &amp; {\rm (Demand)}\\
&amp; S_t-S^* = \gamma (p^e_t-p^*) + u_t &amp; {\rm (Supply)}\\
&amp; D_t = S_t,\;\; D^* = S^* &amp; {\rm (Market \;Equilibirum)} \end{align}$$</p>

<p>Production is determined one period before, based on expected future price, but final supply is also subject to random shocks, $u_t$, with $E_{t-1}u_t =0$. $p^e_t$ is expected price but we have not yet make any assumption on how it is formed, or to what is equal.</p>

<p>Eliminating quantities through market equilibrium we obtain</p>

<p>$$p_t-p^* = -\frac {\gamma}{\beta} (p^e_t-p^*) - u_t \tag {3.2}$$</p>

<p>Taking expectations conditional on time $t-1$ we obtain</p>

<p>$$E_{t-1}p_t-p^* = -\frac {\gamma}{\beta} (p^e_t-p^*) \tag {3.3}$$</p>

<p>Rearranging and subtracting $p^e_t$ from both sides we see that equation $(3.3)$ leads to</p>

<p>$$p^e_t-E_{t-1}p_t = (1+\gamma/\beta) (p^e_t-p^*) \tag {3.3a}$$</p>

<p>If  $\gamma / \beta =-1$ we obtain, <em>without making any <strong>assumption</strong> on how expectations are formed but as a solution to the model</em>, that $p^e_t=E_{t-1}p_t$. But this is uninteresting, being a very specific configuration of demand and supply responses. Assume then that $\gamma / \beta \neq -1$.</p>

<p>Then this way to write the relation (not in Muth's paper), shows clearly that if $$p^e_t \neq E_{t-1}p_t \implies p^e_t \neq p^*$$
and that
$$p^e_t = E_{t-1}p_t \implies p^e_t = p^*$$</p>

<p>Throughout the paper Muth treats $E_{t-1}p_t$ as the <em>theory's</em> prediction, a <em>best</em> prediction (and it is, in the sense of being the minimizer of mean squared error of prediction). Given this Muth argues as follows: if ""market expectations"" $p^e_t$ (i.e. some concept of ""average"", ""prevailing"" expectations) were <em>not</em> equal to the ""best"" prediction, then <em>recurring</em> pure-profit opportunities would exist, for <em>someone</em> that used $E_{t-1}p_t$ as his own expectation, while all others used some other expectations formation rule. But, is it reasonable to argue that <em>the market as a whole</em> is outperformed by some ""wise man""? Is it reasonable to argue that the firms and the businessmen and any other people whose livelihood depends on the workings of this specific market, would not really try hard to be as efficient and as accurate as possible regarding their predictions? It doesn't sound too convincing, especially since we are talking about the <em>collective wisdom of all market participants</em> here.  </p>

<p>So making the assumption $p^e_t = E_{t-1}p_t$ (i.e. imposing the RE Hypothesis) appears reasonable, and this leads to </p>

<p>$$p^e_t =p^*$$ </p>

<p>(remember the right-hand side is long-run equilibrium price, not next-period's - we are not looking at period-by-period perfect foresight here).</p>

<p>Now use this result on the initial equations describing the market, and eventually obtain the determination of the short-run equilibrium price as </p>

<p>$$p_t = p^* -(1/\beta)u_t$$
This happens <em>because</em> we have imposed REH. In other words the imposition of REH brings about the result that current equilibrium price remains ""attracted"" and ""chained"" to long-run equilibrium, fluctuating randomly but not explosively.</p>

<p>Also we have</p>

<p>$$p_t = p^e_t -(1/\beta)u_t$$</p>

<p>which also means than in <em>unconditional</em> expected-value terms</p>

<p>$$E(p_t) = E(p^e_t)$$</p>

<p>""On average"" (intertemporally), the price expectation will equal the actual price.</p>

<p>In one move Muth obtained two extremely powerful results:<br>
a) Markets do not explode<br>
b) Market participants on average and ""as a whole"" predict correctly.</p>

<p>And really, if markets did tend to explode rather than not explode, they would not be around for thousands of years, as they are. And if market participants were predicting consistently poorly, we would have seen much more personal financial ruins than we do.  </p>

<p>What REH does <em>not</em> do well, is in helping model and analyze short run and transitional dynamics. It remains a long-run concept, a ""long-run view"" if you will, and this is why Adaptive Learning emerged, and this is why we are currently researching (in a frenzy), other expectations formation hypotheses.  </p>
","4767"
"Usage of natural gas in 1970 (where was the demand elasticity?)","168","","<p>The following historical graph of US Marketable Natural Gas volume has me puzzled:</p>

<p><img src=""https://i.stack.imgur.com/xhmZD.png"" alt=""US Marketable Natural Gas 1900-2015""></p>

<p>How was the gas used in 1970 (a peak production period), given that we would seem to be using a lot more gas now? Normally, I think of natural gas as having relatively inelastic demand because it relies on fixed distribution networks which are time-consuming and expensive to build. </p>

<p>In 2010, the graph shows <em>less</em> gas being produced than in 1970, but considering the huge increase in the retail use of natural gas for heating in recent decades, how can this be? Apparently there was some huge, elastic demand in 1970, which I presume was some industrial process. What would that have been? Before you say ""power generation"" look at this graph:</p>

<p><img src=""https://i.stack.imgur.com/2tEXL.jpg"" alt=""power generation from natural gas""></p>

<p>So, we are using a LOT more natural gas now compared to 1970 both in homes and for power generation. So, what is this huge extra use of natural gas in 1970? Where was it going?</p>
","<p><strong>tl;dr: it's basic engineering: efficiencies improved between 1970 and 2010. Additionally, net USA imports increased from 0.75 trillion cubic feet in 1970 to 3.8 trillion cubic feet in 2007</strong></p>

<p>I think there may be some misunderstandings. Firstly: the first chart shows domestic gas production. ""Domestic"" doesn't refer to residential-only use - it just means natural gas produced <em>within</em> country, rather than imported by pipeline or on ship. Secondly: the second graph does <strong>not</strong> show the amount of gas uesd to generate electricity. It shows the amount of electricity generated by gas. There's a huge difference. The latter is the former multiplied by the volume-weighted efficiency of the generation fleet. And thirdly, you discuss the lack of responsiveness because of the need for gas infrastructure, but the period under consideration is 40 years, which <em>is</em> the long run: that's sufficient time for replacement of capital; pretty much all costs are variable over 40 years in gas.</p>

<p>Just because there may have been an increase in demand for gas-fuelled energy services, does not mean there has been a big increase in demand for gas, for example, when part of the increase in demand is stimulated by improvements in energy efficiency.</p>

<p>The USA has two sources of natural gas: domestic production, and imports. One of the ways you get a disconnect between local production and local consumption is a change in net imports, which is what happened:  <a href=""http://www.eia.gov/dnav/ng/ng_move_ist_a2dcu_nus_a.htm"">net USA imports</a> increased from 0.75 trillion cubic feet in 1970 to a peak of 3.8 trillion cubic feet in 2007.</p>

<p>Natural gas gets used directly for heating, including in industrial processes; it also gets used for electricity generation. The latter also had a local peak around 1970. The amount of electricity generated by gas turbines very closely tracks domestic gas production until about 1990.</p>

<p>What's happened over the last 40 years is that energy efficiency has improved. There has been fuel-switching, so that some processes that were done using gas now use coal or electricity; and some processes that did use coal now use gas. There have been net efficiency gains over time, just as you'd expect. Some of this was outside the residential sector, and some is within it.</p>

<p>Some energy efficiency improvements have come about through improvements in boiler technology such as the mainstream appearance of condensing gas boilers; as well as a better understanding of maintenance. And improvements in building heat tightness, from enforced tighter building controls, better materials, better construction techniques. In the UK, we've also seen the replacement of open gas fires with central heating systems, which tends to be more efficient too, and that may have played a role in the USA over the last 40 years.</p>

<p>And particularly, from 1990, the upward trend in electricity generated from gas (the second graph) is stronger than the domestic increase in gas production. Around 1990, there was the introduction of a new type of process, the combined cycle gas turbine (CCGT), which increased the gas-to-electricity efficiencies from around 30% to around 55% - i.e. almost doubling. By 2007, CCGTs had displaced pretty much all the old open-cycle turbines, resulting in almost twice the electricity generated from the same amount of gas.</p>
","1637"
"Why do we want MSB = MSC not MSB > MSC?","168","","<p>Why do economists want Marginal Social Benefit to equal Marginal Social Cost not be greater than?</p>
","<p>Remember that the M in MSB standard for marginal. In other words, the marginal social benefit is the <strong>extra</strong> benefit we would get by increasing the activity by one unit and the marginal social cost is the <strong>extra</strong> cost we would get by increasing the activity by one unit.</p>

<p>Suppose, at the status quo, the MSB is 5 and the MSC is 3 (so MSB > MSC). That means if we increased the activity by one unit we would get 5 units of extra benefit and 3 units of extra cost, so the net change in welfare is $5-3=+2$. Thus, the status quo can't be optimal because we could increase welfare by adding an extra unit of the activity.</p>

<p>Suppose, at the status quo, the MSB is 3 and the MSC is 5 (so MSB &lt; MSC). That means if we reduce the activity by one unit we would loose 3 units of benefit but save 5 units of cost, so the net change in welfare is $-3+5=+2$. Thus, the status quo can't be optimal because we could increase welfare by reducing the activity by one unit.</p>

<p>Only if MSB=MSC is it the case that we can't increase welfare by either increasing or reducing the activity.</p>
","15873"
"How does the ban on surge pricing affect the companies, customers and the economy?","167","","<p>Recently, there has been a ban on surge pricing in two of India's busiest cities, namely Delhi and Bangalore.</p>

<p>I understand that <code>surge pricing</code> is a method to maintain the balance between the supply and demand. So, it's ban would affect the taxi aggregator companies. </p>

<p>However, is it really doing benefit to the consumer, as the Govt. claims?</p>

<p>Overall, how does the ban on surge pricing affects the taxi aggregator companies, the consumers and the economy as a whole?</p>

<p>I have read through articles this <a href=""http://qz.com/657983/is-it-stupid-to-end-surge-pricing-by-ola-and-uber-in-india/"" rel=""nofollow"">this</a>, however, they give a very naive explanation. So, I'm looking for something clearer from a microeconomics point of view.</p>

<p>PS: Delhi has an odd-even rule too (for combating excessive traffic and pollution), which means that cars with an even (registration)number [the one on the number plate] are only allowed in the even dates, and the ones with an odd number o the odd dates. For example, if I am <code>DL 23 BK 1900</code>, I am only allowed on the road on even days, and not in odd days.</p>
","<p>It depends.</p>

<p>If customers are currently making informed decisions when they book a surge-priced car, then banning surge pricing punishes customers, drivers, intermediaries, and the wider economy. It deliberately introduces an economic inefficiency.</p>

<p>If, however, a lot of customers are making uninformed decisions and are effectively being conned by surge pricing that they didn't expect or didn't understand, then banning surge pricing stops economically inefficient activity, protects consumers, and can be a net contributor to the economy.</p>

<p>Or if surge pricing increases negative externalities, then banning it could give a net benefit: for example, if the worst-polluting cars only come onto the road when surge pricing is available.</p>
","11673"
"Is it possible to have a signaling game in which all players are both informed (about themselves) and uniformed (about other players)?","167","","<p>So far, the models of Signaling Games I have seen involve two players. One player is known as the Sender and has more information. The other player is known as the Receiver and has less information. </p>

<p>But suppose I have two people who each don't have information about the other.  Now they start sending signals and learn about the other. </p>

<p>Are there models of Signaling Games that cover such dynamics where both players are senders and receivers? </p>
","<p><strong>A comment on the number of players in signaling games in general.</strong></p>

<p>Signaling games need not have only two players. In the cheap talk literature, there are papers that study signaling games with multiple informed senders and one uninformed receiver (e.g. <a href=""http://qje.oxfordjournals.org/content/116/2/747.abstract"" rel=""nofollow"">Krishna &amp; Morgan, 2001</a>), or one informed sender with multiple uninformed receivers (e.g. <a href=""http://web.mit.edu/rgibbons/www/Gibbons_Farrell_Cheap%20Talk%20with%20Two%20Audiences.pdf"" rel=""nofollow"">Farrel and Gibbons, 1989</a>). There are no theoretical reasons to limit the number of players to two.</p>

<p><strong>Is it possible to have a signaling game in which all players are both informed (about themselves) and uniformed (about other players)?</strong></p>

<p>The answer is yes. For example, auctions with pre-play communication, where each bidder is informed about their own valuations of the object but not about the others'. In the communication stage, they use signals to strategically (mis-)communicate their private information, and to infer about other bidders' types from their signals (e.g. <a href=""http://www.ssc.upenn.edu/~apostlew/paper/pdf/Preplay%20Communication.pdf"" rel=""nofollow"">Mathews and Postlewaite, 1988</a>). In general, mechanism design is about signaling privately observed types. But the specific model depends on what you want to do <em>after</em> the signaling stage, whether signals are costly, and what kind of outcome you want the model to deliver, etc.</p>
","4442"
"What keeps minimum wage rates in balance?","167","","<p>I would posit that the minimum wage is determined more on a political than an economic basis.  The fact is that there are more wage earners than business owners and, generally speaking, the wage earners prefer an increase while the business owners prefer a minimum wage decrease (perhaps even to 0).  There are more wage earners to vote than business owners, and this makes it politically expedient, on the balance, to vote for a minimum wage increase.</p>

<p><strong>First</strong>, is this true?</p>

<p><strong>Second</strong>, if you find it to be true, why doesn't the minimum wage increase substantially more than it has over the years (focusing on the US)?  What is the counter balancing force that causes minimum wages to seek equilibrium at some something between ""poverty"" and ""living wage"" level (again, in the US)?  Or is even that assumption false?</p>
","<h2>How is the minimum wage determined?</h2>

<p>Yes and no. It is a political choice, but with economic reasoning. In the end, that's the case for every economic rule, maybe with the exception of monetary rules, as we try to preserve independence for central bankers (but it isn't <em>completely</em> true for the US FEDs).</p>

<p>When setting the new minimum wage, you compare minimum wages with other states, and with your own (earlier) state, to get a feeling what's possible and what is not. In the end, the minimum wage is a trade-off between raising earnings for some parts of the population, and decreasing employment chance for others. </p>

<h2>How does the minimum wage affect employment?</h2>

<p>The degree of trade-off (if you will, the transition rate between the two) is unclear. In the data, we tend to see no employment effect of minimum wages, but an increase in earnings (Dube et al (2010): (<a href=""http://www.irle.berkeley.edu/workingpapers/157-07.pdf"" rel=""nofollow noreferrer"">Ungated version</a>). In fact, we see a large number of estimates around 0:</p>

<p><a href=""https://i.stack.imgur.com/HXmG7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HXmG7.png"" alt=""Estimated Minimum-Wage Effects Onto Unemployment""></a></p>

<p>Many economists suspect (based on a strong prior that there <em>should</em> be an employment effect) that this is due to poor data (Matt Rognlie's <a href=""http://econlog.econlib.org/archives/2015/08/divine_coincide.html"" rel=""nofollow noreferrer"">comment</a>), or long-term effects of minimum-wages (adjustment costs in technology) that we are not capable of measuring/estimating precisely (Sorkin (2015) (<a href=""https://ideas.repec.org/a/red/issued/13-225.html"" rel=""nofollow noreferrer"">IDEAS</a>)).</p>

<h2>Why doesn't the minimum wage affect employment?</h2>

<p>The counter-effect to some part is the political process. People are not stupid, they will accept raises in the minimum wage to some degree, but not if you go bananas. Also, there are natural counter-forces in the economy: </p>

<ul>
<li>minimum wages are nominal</li>
<li>minimum wages are lower bounds</li>
</ul>

<p>To that end, if you increase the minimum wage, eventually inflation will wash off the real impact. Also, raises in the minimum wage tend to become substitutes for (non-forced) increases in the wage level.</p>

<p>Have a look at the following graph, which depicts the relative impact of minimum wages. The author plots the maximum of minimum wages at a time period, deflated by average hourly wage in the private sector among production and non-supervisory employees (no managers). It really looks as if any spike (raise in the minimum wages) gets deflated quite quickly, doesn't it?</p>

<p><a href=""https://i.stack.imgur.com/NAuXB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NAuXB.png"" alt=""Relative Minimum Wages""></a></p>
","9888"
"why do we analysis the housing market from 'short run' and 'long run'?","167","","<p>As we can see the factors impacting the housing market, particularly house price, are always analysed from the long run and short run, even some researchers analysis those factors from cyclical and structural approach. How can we understand the long run and short run? And what are cyclical and structural influences on house price? Thank you.</p>
","<p>Housing markets are complex and the following are just some basic points.</p>

<p>Key features of houses as economic goods are: 1) their very long life; 2) their differentiation by type and location. In the <strong>short run</strong> housing supply (the total existing stock, plus any new houses completed) is price-inelastic because the number of new houses can be only a tiny proportion of the existing stock.  Hence a short-run analysis of house price changes will focus primarily on short-term changes affecting demand (eg changes in interest rates or in housing-related taxes).  In a <strong>long run</strong> analysis, however, consideration also needs to be given to changes in supply, and to long-term changes affecting demand (eg population growth, rising incomes).</p>

<p><strong>Cyclical factors</strong> are those that tend to reverse over a period of a few years. The cause of a cycle in a housing market could be internal to that market, eg a self-fulfilling expectation at one time that prices will rise, leading to a price bubble and eventual collapse, as described <a href=""https://en.wikipedia.org/wiki/Property_cycle"" rel=""nofollow"">here</a>.  The cause could also lie in the wider economy, eg house prices tending to rise when the economy is booming and fall in a recession.  <strong>Structural factors</strong> are permanent or at least long-lived, eg land availability and planning constraints, housing-related policies that are considered unlikely to change, and the distribution of the existing stock between types and locations.  </p>
","11649"
"Application of Poisson process in economic modelling","166","","<p>To understand the emergence of constitution, <a href=""http://home.uchicago.edu/~rmyerson/foundatn2008.pdf"" rel=""nofollow"">Myerson(2008)</a> models a scernario that a political leader gathers supports from captains in order to defeat challengers whose arrival is modelled by a <a href=""http://en.wikipedia.org/wiki/Poisson_process"" rel=""nofollow"">Poisson process</a>.</p>

<p>I found using Poisson process seems to be simple and reasonable, but it is the only model I know that utilizes Poisson process.Are there any other well-known models utilizing Poisson process in a similar way? If not, what's drawback of Poisson process?</p>
","<p>Most of the literature on ""<strong>Strategic experimentation</strong>"" (or Bandits) uses Poisson processes. Here players can use either a risky or safe arm and one of them generates a fixed stream of payoffs (usually the safe arm) the other one generates lump-sum payments whose arrival times are described by a Poisson process.</p>

<p>Some examples are:</p>

<p>Klein, Nicolas, and Sven Rady. ""<a href=""http://restud.oxfordjournals.org/content/early/2011/03/02/restud.rdq025.short"">Negatively correlated bandits.</a>"" The Review of Economic Studies (2011).</p>

<p>Keller, Godfrey, and Sven Rady. ""<a href=""http://onlinelibrary.wiley.com/doi/10.3982/TE595/abstract"">Strategic experimentation with Poisson bandits.</a>"" Theoretical Economics 5.2 (2010): 275-311.</p>

<p>Keller, Godfrey, Sven Rady, and Martin Cripps. ""<a href=""http://onlinelibrary.wiley.com/doi/10.1111/j.1468-0262.2005.00564.x/abstract"">Strategic experimentation with exponential bandits.</a>"" Econometrica 73.1 (2005): 39-68.</p>
","5457"
"Are strict dominance solvable games weakly dominance solvable?","166","","<p>Okay consider a game $G$ if a strategy $s_i$ has the following property we call $s_i$ the strictly dominant strategy</p>

<p>$$u_i(s_i,s_{-i})&gt;u_i(s_i',s_{-i}) \\ \forall s_{-i} \ \forall s_i' \epsilon S'_i$$</p>

<p>Where $s_{i}$ indicates the strategies of players other then $i$ in the game and $S'_i$ is the set for strategies of player $i$ except the specific strategy $s_i$</p>

<p>Now let's look at the definition of a weakly dominant strategy</p>

<p>if a strategy $s_i$ has the following property we call $s_i$ the weakly dominant strategy</p>

<p>$$u_i(s_i,s_{-i})≥u_i(s_i',s_{-i}) \\ \forall s_{-i} \ \forall s_i' \epsilon S'_i \ and \\ \exists s_i' \epsilon S'_i \ such \ that: \ u_i(s_i,s_{-i})&gt;u_i(s_i',s_{-i})$$</p>

<p>Okay I believe from these two definitions we can derive that any strictly dominant strategy $s_i$ is also a weakly dominant strategy</p>

<p>Definition of strict dominance solvable is as follows :</p>

<p>A strict dominance solvable game is a game where the equilibrium outcome is strict dominance equilibrium.
A weakly dominance solvable games is a game where the equilibrium outcome is weakly dominance equilibrium.</p>

<p>So It seems like then a strictly dominance solvable game is always a weakly dominance solvable game. Am I wrong?</p>
","<p>You're right. Let $s^*=(s_1^*,\dots,s_N^*)$ be the equilibrium of a strictly dominance solvable game. Then by definition, 
$$
u_i(s_i^*,s_{-i})&gt;u_i(s_i,s_{-i})
$$
for all $i$, all $s_i\ne s_i^*$ and all $s_{-i}$. This implies that 
$$
u_i(s_i^*,s_{-i})\ge u_i(s_i,s_{-i})
$$
for all $i$, all $s_i\ne s_i^*$, all $s_{-i}$ and with strict inequality for at least some $s_i$ (in fact, for all $s_i\ne s_i^*$). This makes $s^*$ an equilibrium satisfying the weak dominance solvability criterion.</p>

<hr>

<p>Your quoted definition of <em>strict/weak dominance solvability</em> makes me a little uncomfortable though. I'd say </p>

<blockquote>
  <p>A game is strict (or weak) dominance solvable if the process of iteratively removing strictly (or weakly) dominated strategies leads to a unique outcome (i.e. only one strategy for each player survives).</p>
</blockquote>
","15533"
"How do countries create their own currencies (and give them meaningful value)?","166","","<p>Regardless of why they'd do it, what do countries do to make their own currency, replacing the old one, and give their new one value?</p>

<p>I sorta get how it works, but this kind of economics is still super confusing to me; thus I thought I'd ask. You know, I get the ideas of supply and demand and what-not, but beyond that I'm at a general loss.</p>

<p>Example, if the Ryukyu islands had an uprising and separated from Japan to form their own nation, what could they do to make their own currency? To replace their Japanese Yen? Again, regardless of why they'd want to.</p>
","<p>Money is something which has value because everyone believes it has value. </p>

<p>A good way to create a trustworthy currency is to create a <a href=""https://en.wikipedia.org/wiki/Representative_money"" rel=""nofollow noreferrer"">representative</a> currency. A representative currency is a currency which is backed by some rare commodity by always guaranteeing that it can be exchanged back into that commodity. For example, a state might decide to create a new currency, let's call it the TirousCoin, and back it with gold. They decide that one TirousCoin is worth one gram of gold. The state guarantees that when you give them 100 gram of gold, you get 100 TirousCoins from them. And when you give the state 100 TirousCoins, you get 100 gram of gold. That means the TirousCoin's value is bound to the world market price of gold. Giving someone 10 TirousCoins is as if you would give them 10 gram of gold which is as if you give them 442 USD.</p>

<p>But many countries go a step further and have currencies which are pure <a href=""https://en.wikipedia.org/wiki/Fiat_money"" rel=""nofollow noreferrer"">fiat money</a>. Fiat money is money which is not backed by any commodity. It is simply printed by a central bank, lent to regular banks and from there lent to people. And people trust that central bank to not lend too much of it, because that would cause inflation.</p>

<p>But how do you get people to accept your TirousCoins as their tender for their every day business transactions instead of competing currencies issued by other states?</p>

<ul>
<li>Declare it <a href=""https://en.wikipedia.org/wiki/Legal_tender"" rel=""nofollow noreferrer"">legal tender</a> by law. This means that you decree by law that  the TirousCoin is valid payment for all debts. When someone thinks that someone owes them, they can ask the state to force their debtor to compensate them with money. They do that by bringing the case to the state's civil court system. But the court system will consider a debt settled if it is paid in TirousCoins. When a creditor rejects the debtor's TirousCoins and demand to be paid in some other currency, the state will consider the case closed and won't assist the creditor.</li>
<li>Have the state do all their financial business in TirousCoins. Pay government employees in TirousCoins, demand that taxes are paid in TirousCoins (including taxes on transactions in foreign currency), pay subsidiaries and welfare in TirousCoins and demand fines in TirousCoins. When people need to acquire TirousCoins to avoid going to prison for tax evasion, the coins gain real value.</li>
<li>Make sure TirousCoins are a stable currency. Many states in financial perils make the mistake of paying their bills in freshly printed fiat currency instead of playing fair and only spend what they receive in form of taxes. This leads to an <a href=""https://en.wikipedia.org/wiki/Inflation"" rel=""nofollow noreferrer"">inflation</a> which destroy trust in the currency and leads people to do dealings in other currencies.</li>
</ul>

<p>For further watching, I recommend the Extra History's series on <a href=""https://www.youtube.com/watch?v=-nZkP2b-4vo&amp;list=PLhyKYa0YJ_5CL-krstYn532QY1Ayo27s1"" rel=""nofollow noreferrer"">the history of paper money</a>.</p>
","17551"
"WAPM and CRS across all production plans","166","","<p>In Hal Varian's Book ""Microeconomic analysis"" on page 35 he gives the following description of a profit maximising firm.</p>

<blockquote>
  <p>...If the firm is maximising profits, then the
  observed net output choice at price pt must have a level of profit at least as
  great as the profit at any other net output the firm could have chosen. We
  don't know all the other choices that are feasible in this situation, but we
  do know some of them-namely, the other choices $y^s$ for $s = 1,. . . , T$ that
  we have observed. Hence, a necessary condition for profit maximisation is
  that
  $$p^ty^t\ge p^ty^s$$
  for all $t$ and $s=1,...,T$ </p>
  
  <p>We will refer to this condition as the <strong>Weak Axiom of Profit Maximisation
  (WAPM)</strong>.</p>
</blockquote>

<p>In the case of a firm which has a production function with one input and one output where $p=w$, such that $p$ is the price the output is sold and $w$ is the price of the input across all <a href=""http://www.oxfordreference.com/view/10.1093/oi/authority.20110803100348928"" rel=""nofollow noreferrer"">production possibilities sets</a>. Can such a firm be called profit maximising at any level of output?</p>
","<p>Sure it can, because the maximal profit is 0, and that level is attained at all output levels.</p>

<p>A similar problem is a profit maximizing firm with constant returns to scale. If such a firm has a maximal profit it can attain then that profit level is 0. If the maximal profit level was something else, it could be increased by doubling or halving production.</p>
","15142"
"Adjustment to equilibrium in Cournot model with 2 firms","165","","<p>In pg. 509, of Hal Varian's Intermediate Microeconomics Ch. 27, writer discusses the Cournot equilibrium.</p>

<p>In the figure, the reaction curve of firm 1 <strong>f<sub>1</sub>(y<sub>2</sub>)</strong> was steeper than firm 2 <strong>f<sub>2</sub>(y<sub>1</sub>)</strong>. </p>

<p>When we started from the point <strong>(y<sub>1</sub><sup>t</sup>, y<sub>2</sub><sup>t</sup>)</strong>, we were able to reach the stable equilibrium. But what if <strong>f<sub>2</sub>(y<sub>1</sub>)</strong> was steeper than <strong>f<sub>1</sub>(y<sub>2</sub>)</strong>? I cannot find any adjustment process. Can such condition be viable? If not, then why?![Adjustment process when <strong>f<sub>1</sub>(y<sub>2</sub>)</strong> was steeper than <strong>f<sub>2</sub>(y<sub>1</sub>)</strong>]<a href=""https://i.stack.imgur.com/fnfz6.jpg"" rel=""nofollow noreferrer"">1</a></p>
","<p>The trick is to draw the whole reaction function—including the part that coincides with the axis. Hopefully these figures make it clear:</p>

<p><img src=""https://i.stack.imgur.com/GIKHR.png"" alt=""enter image description here""></p>

<p><img src=""https://i.stack.imgur.com/9Ayzv.png"" alt=""enter image description here""></p>
","5050"
"Are there papers in evolutionary game theory that are influential in economics?","165","","<p>The concept of evolutionary game theory has been around for about forty years. The mathematical details are worked out quite well. Yet this discipline is usually a side note in game theory classes and is seldom applied in economics research. Have there been any papers in this field that are considered influential in economics?</p>

<p>To clarify: <br> There are a lot of papers about the connection of game theory and evolutionary game theory, but only a few that seek to apply evolutionary game theory to explain some economic phenomenon.</p>

<p>I know of <a href=""https://homepage.univie.ac.at/Ana-Begona.Ania-Martinez/ems.pdf"" rel=""noreferrer"">this</a> paper by Vega-Redondo and <a href=""http://www.sciencedirect.com/science/article/pii/0167268189900759"" rel=""noreferrer"">this</a> paper by Schaffer.</p>
","<p>Kandori, Michihiro &amp; Mailath, George J &amp; Rob, Rafael, 1993. ""Learning, Mutation, and Long Run Equilibria in Games,"" Econometrica, Econometric Society, vol. 61(1), pages 29-56, January.</p>

<p>Young, H Peyton, 1993. ""The Evolution of Conventions,"" Econometrica, Econometric Society, vol. 61(1), pages 57-84, January.</p>

<p>I disagree with your assertion that EGT is seldom applied or that it has not been  influential.  Both of the papers referenced above appear in RePEc's list of the
top 1% of citations.</p>

<p>Allowing preferences to 'change' can generate just about any equilibrium you want, so the premise behind EGT is a tough sell in many economic models - not to say compelling research hasn't done so.  The bottom line is that it isn't a part of the atmosphere where mere mortals can tread.</p>

<p>EGT has, in fact, been applied to many problems in economics as well as those traditionally parsed by the other social sciences - particularly the evolution of social norms, political representation, voting, and distributive justice.</p>
","5925"
"Checking incentive compatibility of a mechanism","165","","<p>I was thrilled at seeing an interesting bidding system in an academic institutions. This bidding is for registration of courses.
Each student is allocated some points based on her grade point(GPA). So, a student with higher GPA gets more points. 
Each course has a maximum strength of 60 students and a set of say 15 courses is offered.
A student bids higher for the courses that she wants and feels will be oversubscribed.</p>

<p>According to the literature in this subject, I know that this is not an incentive compatible mechanism as the students' bids are considered equivalent to their preferences but a student may bid more for a subject with less utility but which is has higher number of subscribers. 
Also, I feel that this is a kind of first price auction. Whatever bid I propose, it is consumed if I cross the minimum bid at which the subscription closes. </p>

<p>Courses are different and students have different preferences. Each student would bid for any number of courses that she prefers and expects to go oversubscribed. Students' preferences over courses are on academic basis i.e. courses that are popular or taken by some famous faculty. So, student's objective is to get her favorite course.</p>

<p><strong>EDIT :</strong> In first round, the students give a list of 5 courses they wish to enroll in. 
In second round, bidding happens for the oversubscribed courses. So, if I entered course A in round 1 and it got oversubscribed, then in round 2 I will have to bid for it. 
After round 2, if I get the courses that I wanted then it's fine else I will have to choose some other course (for which seats are not completely filled) so that I have 5 courses. </p>

<p>I am not being able to understand in intuitive terms how a student can behave wrong and hide her true preferences while bidding in such a mechanism. 
Please help point out some intuitive examples which violate the incentive compatibility. Thanks in advance. </p>
","<p>An example:<br>
Student type $t_1$ has 10 points to bid based on her GPA. Her favourite courses are A,B,C,D,E.<br>
Student type $t_2$ has 0 points to bid based on his GPA. His favourite courses are F,G,H,I,J.<br>
Student type $t_3$ has 1 point to bid based on her GPA. She ranks the courses alphabetically, A being best, Z being worst. (Or if there are only fifteen courses then O, as that is the 15th letter.) </p>

<p>Assume sixty $t_1$ type, sixty $t_2$ type and one $t_3$ type students. If all types were to subscribe to their favourite kind of courses, then A,B,C,D,E would have sixtyone applicants and hence they would be oversubsribed. F,G,H,I,J would have sixty applicants and would be full. $t_3$ may lose the bidding war in a reasonable equilibrium of round 2: If all type $t_1$ students bid 2 points on each course they will all get their favourite picks while $t_3$ type, who can only bid 1 point will lose out on all picks. Now she can only pick K,L,M,N,O, as F,G,H,I,J are already full. She would have been better off if she had picked F,G,H,I,J in round one, as there she would have one the bidding for at least one of the courses. Thus the 'truth-telling' strategy is not an equilibrium and hence the mechanism is not incentive compatible.</p>
","14507"
"Fractional reserve banking and the value of someone else's currency","165","","<p>Suppose there are two countries: $A$ and $B$. $A$ is a large, stable, democratic country with its own currency, the dollar. $B$ does not have its own currency. All prices and financial transactions in $B$ use the dollar and $B$'s citizens have a positive quantity of dollars that they hold domestically.</p>

<p>Country $B$ has a monopoly retail bank that is required to hold 5% of the value of its deposits as reserves in the safe keeping of an independent central bank, also located and controlled within $B$.</p>

<p>My question is: does this suffice for the bank in country $B$ to practice fractional reserve banking? If so, am I correct in thinking that the bank in country $B$ is exerting an externality on the people of country $A$ by devaluing their currency every time it creates a new loan? Is there anything that $A$ can do to prevent this?</p>
","<p>It is the policy of pretty much every central bank on the planet to supply reserves on demand when private banks request (in return for assets). But a central bank in country B can not do this, it can not create new dollars. So if dollar based fractional reserve banking were to start up in country B, it would behave rather differently to everyone else's fractional reserve banking.</p>

<p>With regard to whether this could devalue the dollar - yes it could.</p>

<p>With regard whether there is anything A could do about this - well I guess it would be possible for the authorities in A to refuse to accept or process broad money (IOUs of dollars) created by banks in country B.</p>
","6359"
"An increase in Japan's demand for US goods would cause the value of dollar to appreciate?","164","","<p>An increase in Japan's demand for US goods would cause the value of dollar to appreciate? Why is that? The official answer is ""Japan will buy more U.S. dollars."" However, my thought was that isn't it usually the case that US companies get paid of Japanese yen rather than U.S. dollars? And hence Japan will not need to buy more U.S. goods. What is the problem in my thought?</p>
","<p>You're just intermediating. The US companies would still have to pay their workers in USD, therefor, instead of the Japanese companies buying dollars in your scenario, the exporters are using the importers' Yen to buy dollars.</p>

<p>It's the same net effect.</p>
","5523"
"Example of an economy where Equilibria may not be efficient, where one agent is altruistic","164","","<p>I'm looking for a theoretic example of an economy where one agent is altruistic, while the others are not, that would make a walrasian equilibrium not efficient.  </p>
","<p>This is an old question. The first example of inefficiency caused by altruism that I know of is due to <em>Winter, S. (1969). A Simple Remark on the Second Optimality Theorem of Welfare Economics. Journal of Economic Theory, 1, 99–103</em>, but I am sure others were around before that.</p>

<p>Now, the example in Winter(1969) does not answer your question because it features altruism for <em>all</em> agents in the economy. As mentioned by The Almighty Bob you can find another example in Heidhues and Riedel (2007). Another good reference is <em>Dufwenberg, M., Heidhues, P., Kirchsteiger, G., Riedel, F., &amp; Sobel, J. (2011). Other-Regarding Preferences in General Equilibrium. The Review of Economic Studies, 78(2), 613–639</em>, which is a summary paper of Heidhues and Riedel (2007) and contributions on the topics by the other authors.</p>

<p>Without more constraints on the preferences, it is not hard to find an example satisfying the conditions of your question. I am sure you could find it yourself, if you haven't already. But in order to make the answer complete here is one:</p>

<blockquote>
  <p>$\Omega \equiv \{(1,1),(1,1)\}$ (individual endowements)</p>
  
  <p>$U_1 \equiv \min \{x_1,y_1\}$ (perfect complement, no altruism)</p>
  
  <p>$U_2 \equiv \min \{x_2, y_2\} + 2*U_1$ (perfect complement, with (strong) altruism toward $1$)</p>
  
  <p>Walrasian equilibrium = {(1,1),(1,1)}, together with whatever (finite) relative price you like.</p>
</blockquote>

<p>I guess it is clear that the Walrasian equilibrium is not Pareto efficient. Notice that this ""result"" highly depends on the definition of the consumption space. If you add</p>

<ul>
<li>Donation of good $x$ from $2$ to $1$, and</li>
<li>Donation of good $y$ from $2$ to $1$,</li>
</ul>

<p>to the consumption space, then you would recover efficiency (although it might take a little care to define a meaningful notion of Walrasian equilibrium in this case). </p>
","5391"
"How does the fractional reserve banking system work?","164","","<p>I would like to understand better exactly how this works. I have heard a lot recently (particularly since the 2007-08 crash and Occupy movement) about money creation in particular (usually with a very negative bias). However, these descriptions often only go so far into it and I am curious whether it is really so bad once one has the full picture.</p>

<p>I'd like to go through a simple example and point out where I am unsure what is actually supposed to happen.</p>

<p>So, we have one Bank, with perhaps two customers. Alice and Bob. Alice has deposits at the Bank worth £500. Bob has £100 at this bank. A total of £600 of deposits, which the bank is liable make available to the customers at any time. The Bank has £5000 worth of its own capital. Totaling £5600 cash held (I realize that the banks' capital and the deposits are not the same - capital is an asset and deposits are a liability, for one - but this sum represents the full reserve amount, yes? The money which would be used if needed to serve depositors requests for withdrawal). We will say that the capital ratio is 10%. As I understand it, this makes the total <em>lendable</em> capital at the bank £5000 + £450 (Alice) + £90 (Bob) = £5540. I am pretty sure I am correct in my understanding so far.</p>

<p>So, Bob owes Alice a lot of money. He needs to pay her £1000. So, he takes out a loan at 5% interest. The Bank decreases its <em>lendable</em> capital by the amount of the loan, so it can now only loan a further £4540, however it still technically possesses the full £5540 as the £1000 loan is ""new"" money. Naturally, Alice now deposits Bob's £1000 payment in her account. The banks total deposits now sit at £1600, the amount it is holding is now £6600. Due to the new £1000 deposit on Alice's account, £900 is added to the <em>lendable</em> capital. Making it £5440. Is this correct? So far - besides the amount of <em>lendable</em> capital against which ""new"" money may be created - no deductions have been made. In addition, the £1000 loan is considered an asset that the bank owns.</p>

<p>So, now, the loan has eventually accumulated £80 interest and Bob manages to complete his payments to the bank. Bob pays the bank £1080 in total. Here is where I am most confused. What happens to this amount? I have heard people talk about ""money destruction"", implying that the bank quite literally throws away the £1000 originally lent to Bob. But somehow I find that hard to believe, and I am further confused because people mention removing it from circulation - presumably simply not making any use of it - as being the mechanism by which it is ""destroyed"". However, I do not believe it can be effectively removed completely from circulation, as the bank would surely either invest it or use it to make more loans, no? If indeed the money is not really destroyed, the bank has effectively just made £1080 out of nothng, right?</p>

<p>Perhaps I have gone wrong somewhere in my accounting. I have a Software Engineering background so a lot of this is very new/alien to me. I am just very interested in understanding it. I feel like if something is hard to believe (such as many of the claims made about money creation) it usually is for good reason, so I just wanted to understand the full picture for myself.</p>
","<p>The bank hasn't made £1080 out of nothing. Bob paid that money into the bank. It wasn't in the bank earlier, and it is in the bank now. Alice's account has been increased by £1000. And the bank has £80 extra that it earnt by lending to Bob.</p>

<p>It's helpful to distinguish the money that the bank holds, from the amount of money in the whole system, and from the amount of money the bank owns.</p>

<p>£1080 has left the rest of the system, and entered the bank.</p>

<p>The bank's own capital starts at £5000 and finishes at £5080 (ignoring any interest it's paid to Alice, and its operating costs).</p>

<p>Alice's account starts at £500, and finishes at £1500.</p>

<p>Bob's account starts and ends at £100.</p>
","8195"
"How does the limit of $U(x, y) = (ax^{-c} + by^{-c})^{-\frac{1}{c}}$ as c approaches 0 yield the Cobb-Douglas utlity function?","164","","<p>\begin{equation*}
U(x, y) = (ax^{-c} + by^{-c})^{-\frac{1}{c}} 
\end{equation*}</p>

<p>I ask this mainly because after logging both sides of the Utility equation (the first step to proving the assertion, I assume), I am left with:</p>

<p>\begin{equation*}
\lim_{c \rightarrow 0} \dfrac{-\ln(ax^{-c} + by^{-c})}{c}
\end{equation*}
I know that the bottom will go to 0, and I have a feeling that the top will go to 0 to.  However, all I am left with on the top is essentially $a + b$, and for it to go to 0, $a + b = 1$.</p>

<p>How can $a + b = 1$?  Is this the right direction?  What does $a + b = 1$ mean?  Why does $a + b = 1$?</p>

<p>Edit:  And once proven, what does this whole ""limit"" thing say about the original function?  What is so special about this particular equation such that its limit as $c \rightarrow 0$ is the Cobb Douglas function?</p>

<p>Edit 2:  Upon further research, I have discovered a suspiciously similar function known as the CES.  $a$ and $b$, however, are instead $a$ and $(1-a)$ !!  Now I'm even more confused.  How am I supposed to derive that complementary relationship from this equation?  This is supposed to be consumer theory!</p>
","<p>It is not true that this function is equivalent to the Cobb-Douglas utility function when $c \sim 0$ for any values of $(a,b)$; you have to assume $a+b=1$ for that, i.e. $b=1-a$.</p>

<p>To see why it is true, fix $(x,y)$ and consider the following Taylor expansion of $U(x,y)$ when $c$ gets close to $0$. We have</p>

<p>\begin{align*}
(ax^{-c}+by^{-c})^{-\frac{1}{c}} &amp; = e^{-\frac{1}{c} \ln{[ax^{-c}+by^{-c}]}} \\
&amp; = e^{-\frac{1}{c} \ln{[ae^{-c\ln(x)}+be^{-c \ln(y)}]}} \\
&amp; = e^{-\frac{1}{c} \ln{[a(1-c \ln(x) + o(c)) + b(1-c \ln(y) + o(c))}]} \\
&amp; = e^{-\frac{1}{c} \ln{[a+b - c (a \ln(x)+b \ln(y)) + o(c))]}} \\
\end{align*}
If $a+b&gt;1$, the term in the exponential converges to $-\infty$ when $c \rightarrow 0$ and therefore $U(x,y) \rightarrow 0$. If $a+b&lt;1$, the term converges to $+\infty$ and therefore $U(x,y) \rightarrow +\infty$.</p>

<p>To obtain the convergence towards the Cobb-Douglas function, we must therefore assume $a+b=1$. In that case we have
\begin{align*}
U(x,y) &amp; = e^{-\frac{1}{c} \ln{[1-c(a \ln(x) + (1-a) \ln(y))+o(c)]}} \\
&amp; = e^{-\frac{1}{c} [-c(a \ln(x) + (1-a) \ln(y))+o(c)]} \\
&amp; = e^{a \ln(x) + (1-a) \ln(y) + \frac{o(c)}{c}} \\
&amp; \rightarrow_{c \rightarrow 0} e^{a \ln(x) + (1-a) \ln(y)} \\
&amp; = x^{a} y^{1-a}
\end{align*}
which is the Cobb-Douglas utility function with parameters $(a,1-a)$.</p>
","10500"
"Strategic form representation of extensive form games","164","","<blockquote>
  <p><strong>Proposition.</strong> Every finite extensive form game is associated with a unique strategic form representation.</p>
</blockquote>

<p>I think this proposition is true. But how do we prove it rigorously?</p>
","<p>I rely on the definitions from Chapter 2 of the Handbook of Game Theory, Volume 1, by Sergiu Hart.</p>

<p>If I understand you correctly, the proposition can be re-written as</p>

<p><strong>Proposition</strong>. For, every finite extensive form game $\Gamma^E$, there exists a single
 strategic form representation $\Gamma^N =[I^N,\{S^N_i\},\{u^N_i(\cdot)\}]$ (up to relabeling of the agents) such that</p>

<ol>
<li>$I^N = I^E$,</li>
</ol>

<p>and for all $i\in I^N = I^E$,</p>

<ol start=""2"">
<li><p>$S^N_i = \{$ pure strategies of $i$ in $\Gamma^E$ $\}$ ,</p></li>
<li><p>and $u^N_i(s) = u^E_i(c(s))$, where $c(s) $ associates every profile of pure strategy in $\Gamma^E$  with a terminal node of  $\Gamma^E$ resulting from the pure strategy profile $s$.</p></li>
</ol>

<p>I think 1. and 2. are obvious. There only remains to show 3, which is equivalent to proving that $c(s)$ is a function, i.e. every profile of pure strategies is associated with one and only one terminal node in $\Gamma^E$. This follows directly from the fact that the pure strategy of some player $i$ is a function selecting one and only one possible action from every information set. </p>

<ul>
<li>Start from the root node, $r_0$. </li>
<li>By definition of a game in extensive form, the nodes are partitioned between the agents.</li>
<li>Thus $r_0$ belongs to some agent $i_0$.</li>
<li>By definition of the game in extensive form, the nodes of $i_0$ are partitioned into information sets.</li>
<li>Thus $r_0$ belongs to some information set of $i_0$, say $H_i^0$.</li>
<li>By definition of the pure strategy $s$, for any node in  $H_i^0$, $i_0$ always choses a <em>single</em> successor, among the possible successors at $H_i^0$.</li>
<li>Let this successor be $r_1$.</li>
<li><p>Then $r_1$ must be the successor of $r_0$, and the next node on the path.</p></li>
<li><p>Now consider $r_1$.</p></li>
<li>By definition of agame in extensive form, the nodes are partitioned between the agents.</li>
<li>Thus $r_1$ belong to some agent $i_1$ (where $i_1 = i_0$ is allowed).</li>
<li>$\vdots$</li>
<li>Repeating the argument as many time as needed, because the game is finite, we necessarily reach a single terminal node $r_* = c(s)$.</li>
</ul>
","3198"
"Do house prices increases affect inflation?","163","","<p>In this <a href=""http://www.amazon.co.uk/Macroeconomics-Institutions-Instability-Financial-System/dp/0199655790/ref=sr_1_1?ie=UTF8&amp;qid=1449954726&amp;sr=8-1&amp;keywords=soskice%20carlin"" rel=""nofollow noreferrer"">book</a>, page 202, the authors develop the idea that when the central bank increases the interest rates to get the CPI inflation back to target inflation, it will not necessarily cut off an eventual house price bubble, or the financial accelerator. And to justify this assertion, in a footnote they state: «The elements of housing costs included do not influence the overall price indices that enter the inflation target to a high degree. To see this plot the US Consumer Price Index against the US Consumer Price Index less Shelter(Data available from US Bureau of Labor Statistics)». (What I understand from this is that since the housing related costs that enter into CPI computation are negligible, the central banker will perceive an inflation different from what if it included housing prices directly. Did I understand correctly?)</p>

<p>So, I plotted the graph.</p>

<p><a href=""https://i.stack.imgur.com/UlkH9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UlkH9.png"" alt=""enter image description here""></a></p>

<p>I included an extra series, ""All items less Food"". It behaves exactly like the CPI.</p>

<p>How can I deduce from the graph what the authors of the book are saying?</p>

<p>Any help would be appreciated.</p>
","<p>Here's what the <a href=""http://www.bls.gov/cpi/cpiqa.htm"" rel=""nofollow noreferrer"">Bureau of Labor Statistics' FAQ</a> has to say on CPI and housing costs:</p>

<blockquote>
  <p><strong>Q: The CPI used to include the value of a house in calculating inflation and now they use an estimate of what each house would rent for -- doesn't this switch simply lower the official inflation rate?</strong></p>
  
  <p>A: No. Until 1983, the CPI measure of homeowner cost was based largely on house prices. The long-recognized flaw of that approach was that owner-occupied housing combines both consumption and investment elements, and the CPI is designed to exclude investment items. The approach now used in the CPI, called rental equivalence, measures the value of shelter to owner-occupants as the amount they forgo by not renting out their homes.</p>
  
  <p>The rental equivalence approach is grounded in economic theory, receives broad support from academic economists and each of the prominent panels, and agencies that have reviewed the CPI, and is the most commonly used method by countries in the Organization for Economic Cooperation and Development (OECD). Critics often assume that the BLS adopted rental equivalence in order to lower the measured rate of inflation. It is certainly true that an index based on home prices would be more volatile, and might move differently from other CPI indexes over any given time period. However, when it was first introduced, rental equivalence actually increased the rate of change of the CPI shelter index, and in the long run there is no evidence that the CPI method yields lower inflation rates than some other alternatives. For example, according to the National Association of Realtors, between 1983 and 2007 the monthly principal and interest payment required to purchase a median-priced existing home in the United States rose by 79 percent, much less than the rental equivalence increase of 140 percent over that same period.</p>
</blockquote>

<p>Ordinarily, because people can substitute between renting or owning a house, the price of a house should broadly reflect its rental value (e.g. if it were much cheaper to rent than to buy then people would stop buying and start renting until prices 'equalised'). However, if a bubble is being driven by speculation on future house price increases then it is likely that house prices will become decoupled from the long-run rental value of a house. You can see what this looked like during the last housing bubble in the below figure. It can clearly be seen that house prices (the blue line) were not well-reflected by the owner-equivalent rent included in CPI.</p>

<p><a href=""https://i.stack.imgur.com/MVRJc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MVRJc.png"" alt=""House prices versus owner-equivalent rents.""></a></p>
","9779"
"Homothetic preferences and weak separability","163","","<p>With 3 goods (x,y,z), linear Engel curves, where z is separable of x and y, and with all first derivatives are positives and second negatives.</p>

<p>Does the demand of z change with the price of x or y? So, is z independent of $p_{x}$ and $p_y$?</p>

<p>I think so, because I have made some examples where changing prices didn't change the optimal amount of z. However I cannot find a formal proof.</p>
","<p>EDIT: Seems to that after your most recent edit the answer is still no. 
A relatively simple counterexample is:
$$
U(x,y,z) = \sqrt{x} + \sqrt{y} + \sqrt{z}.
$$
<br>This is clearly seperable and homothetic. But $D_z$ is is not independent of $p_x$ and $p_y$. I think this is clear just by looking at the utility function, as it is not of the Cobb-Douglas type. If you have doubts you can calculate $D_z$ from these equations:
\begin{eqnarray*}
MRS_{xz}(x,y,z) &amp; = &amp; \sqrt{\frac{z}{x}} = \frac{p_x}{p_z} \\
\\
MRS_{yz}(x,y,z) &amp; = &amp; \sqrt{\frac{z}{y}} = \frac{p_y}{p_z} \\
\\
m &amp; = &amp; p_x \cdot x + p_y \cdot y + p_z \cdot z.
\end{eqnarray*}
Then
\begin{eqnarray*}
m &amp; = &amp; p_x \cdot x + p_y \cdot y + p_z \cdot z \\
\\
m &amp; = &amp; p_x \cdot z \cdot \left(\frac{p_z}{p_x}\right)^2 + p_y \cdot z \cdot \left(\frac{p_z}{p_y}\right)^2 + p_z \cdot z \\
\\
\frac{m}{p_z}\frac{1}{\frac{p_z}{p_x} + \frac{p_z}{p_y} + \frac{p_z}{p_z}} &amp; = &amp; z.
\end{eqnarray*}
As you can see both $p_x$ and $p_y$ appear.</p>
","14399"
"Is there a systematic approach to find equilibria in sequential games?","163","","<p>I know that one can use backward induction to find one particular subgame perfect NE. And I know that wherever possible one can represent the game in normalform and then find all NE.</p>

<p>But is there a systematic way of finding all extensive form specific subtypes of NE, like sequential or weak perfect Bayesian equilibria? What about the rest of the subgame perfect equilibria that can't be found by backward induction?</p>

<p>Do I always have to guess and proof that it really is the kind of equilibrium I think it is?</p>
","<p>You can first find all NE. Then you check which ones are subgame-perfect. Then you proceed and check for which of the NE you can find beliefs that are consistent with the definition of PBE. You can go on and refine the set of equilibria further by kicking out all equilibria that do not satisfy the additional requirements of your stricter equilibrium concept.</p>

<p>If by ""backward induction"" you mean solving the game backwards subgame-by-subgame, then by definition you find all the SPNE (= all NE in which the equilibrium strategy profile also constitutes NE in all subgames).</p>
","15434"
"What would happen if the US defaults on its debt?","163","","<p>As has been widely discussed already, the situation in Greece is considered more serious than in the US, as they have dollar-denominated debt and can only print Greek currency. The US, has the benefit of World Reserve Currency status. All of that does make sense, but I'm thinking there might be more to the story. So I would like to invite speculation on the consequences if the US one day defaulted on its debt.</p>

<p>A country going bankrupt is hardly a novel event, but few countries of the wealth and influence of the US are can be found in historical precedent. One of the only examples that came to mind is when Russia defaulted in 1998. That had global repercussions to North and South America and beyond. Also it destroyed the business model of Long Term Capital Management, an investment fund headed by a team of nobel-prize winning economists and mathematicians. </p>

<p>World Reserve Currency aside, is the Russian default a fair comparison? What different things might we expect if it were the US to default in the coming years?</p>
","<p>The Russian default was an extraordinarily insignificant event compared with a current-day US default on all treasury securities.  There are no remotely similar events to compare it to.  This makes it hard to make guesses about all the ramifications.  Still, speculating is fun.</p>

<p>My guesses, based on a complete default (no money recovered) on all treasury securities:</p>

<ul>
<li><p><strong>Massive failure of important financial institutions all across the world</strong>.  LTCM was a hedge fund: a type of institution the is specifically expected to have significant failure risk.  On the other hand, treasury securities are held by institutions that are not well-equipped to bear risk.  Pension funds, banks, central banks, possibly whole governments would immediately fail.  There would be ripple effects as other institutions linked to them (or who they owe money to) faced an uncertain future.</p></li>
<li><p><strong>Total freezing of most important financial transactions and many markets</strong>.  Treasury securities are used as currency and margin in many large and important financial transactions.  We witnessed a great deal of hobbling of financial institutions and markets when a few CDS's and mortgage-backed securities failed.  The loss of confidence in financial institutions and markets would be incomparably greater.</p></li>
<li><p><strong>Drastic increases in all interest rates and a sharp decline in all stock prices</strong>.  The Russian default had consequences because it caused investors to dump risky investments in favor of safe ones.  A failure of the safest investment (treasuries) would cause utter loss of confidence in all investments and investors wouldn't know where to put money.  Cash maybe?  They would pull money out of both safe and risky investments, driving down both stock and bond prices. </p></li>
<li><p><strong>Widespread unemployment</strong>. Cash available for lending would dry up.  Firms would be unable to borrow and have to forgo projects and lay people off.  These people would reduce their spending and default on some loans, causing amplified effects on interest rates and economic activity.  I would not be surprised if starvation and loss of social order ensued.  </p></li>
<li><p><strong>Irreparable harm to confidence in the US government</strong>.  The government would never again be able to borrow at low rates, it may not be able to borrow to fund its usual deficit.  This would be problematic since the depression and economic turmoil would require expanding the deficit.  It would be my guess that the US government as we know it would not continue.</p></li>
</ul>

<p>I know this sounds a little alarmist, but wholesale default on all US government debt is truly an end-of-the-world-as-we-know-it scale event.    The world truly would change dramatically. Probably future generations would read about the golden age of humanity that ended with the great default.</p>

<p>Realistically, the US is not going to completely default on its debt any time soon.  If there was even a bit of worry about it, people and institutions would stop using it as such a critical component of their transactions and saving.  This would also be a dramatic change, but it would happen over time and reduce the effects, should a default ever happen.  I'm not sure what people would use as a substitute.  It would be uncharted territory.</p>

<p>A more likely, but still apocalyptic, scenario would be some partial default or sustained high inflation.  See the above consequences, but scaled down and including loss of confidence in the dollar.</p>
","17493"
"Continuous Preference Relation Imply Continuous Utility Fn Existence","162","","<p>I am reading MWG's explanation in Chapter 3 when showing continuous preference relation implies the existence of continuous utility function.</p>

<p>First, the authors show $u(.)$ is continuous by using the definition that the image under $u(.)$ of a convergent sequence is convergent. Consider a sequences $x_n\rightarrow x$. They first claim that $u(x_n)$ must have a convergent subsequence.</p>

<p>I understand the big picture: Since $x_n$ converges to x, for some large N, $u(x_n)$ must all lie in some compact set, and any infinite sequence in a compact set must have a convergent subsequence.</p>

<p><strong><em>The part I am having trouble is when they use monotonicity to show this compact set. The exact excerpt is:</em></strong></p>

<blockquote>
  <p>""By monotonicity, for any $\epsilon&gt;0$, $\alpha(x')$ lies in a compact subset of $\mathbb{R_+}$, [$\alpha_0,\alpha_1$], for all $x'$ such that $\parallel x'-x\parallel$$\leq0$.""</p>
</blockquote>

<p>Here I used $u(.)$ and $\alpha(.)$ interchangeably to represent the utility function. Can somebody elaborate the above claim just little more in detail please?</p>

<p>I understand monotonicity implies local nonsatiation, hence, in any given small ball, you always have some bundle that you prefer that to x. Part of my confusion comes from the Figure they present, which is they put the bundle x on the indifference curve ($\{y\in X:y\sim x$}). But isn't $\alpha(x')$ on the diagnoal line Z?</p>

<p>Please help. Thank you.</p>
","<p>I think you're overthinking this proof. MWG only say that such a compact set exists because, by monotonicity, you can always find $\alpha_0$ and $\alpha_1$ such that $\alpha_0*e&lt;\alpha(x')*e&lt;\alpha_1*e$ (with $&lt;$ I mean strictly preferred). Remember that, by monotonicity, if $y&gt;&gt;x$, then $y$ is strictly preferred to $x$. Therefore, we only need to find some $\alpha_0$ and $\alpha_1$ such that $\alpha_0&lt;\alpha(x')&lt;\alpha_1$ for all $x'$. </p>

<p>This is because the set $\{x':||x'-x||\le\epsilon\}$ is bounded and $x'∼\alpha(x')*e$. </p>

<p>(Note that with local non-satiation the result does not immediately follow).</p>

<p>You're right, $\alpha(x')*e$  is on the diagonal line Z and $x'$ is not (note that $\alpha(x')$ is mutiplied by $e$, a vector filled by 1's). However, working with $\alpha(x')$ reduces the complexity of the problem. Instead of working with two (or more) dimensions, we just work with one (the diagonal line Z or one axis). We can do that because for any element $x\in \Bbb R_+$, there is $x∼\alpha(x)*e$ which is in the diagonal line. </p>
","12450"
"Finding an exchange rate and competitive equilibrium given an initial allocation and utility function","162","","<p>I am attempting to solve the following question.</p>

<p>""Smith and Jones are stranded on a desert island. Each has in his possession some slices of ham (H) and cheese (C). </p>

<p>Smith is a
choosy eater and will eat ham and cheese only in the fixed proportions of 2 slices of cheese to 1 slice of ham. His utility function is given by $U_S = H^{1/2}C^{1/2}$.</p>

<p>Jones is more flexible in his dietary tastes and has a utility function given by $U_J = H^{1/3}C^{2/3}$. </p>

<p>Total endowments are 100 slices of ham and 200 slices of cheese.</p>

<p>Suppose Smith initially had 40H and 80C. What would the equilibrium position be?""</p>

<p>This is where I get completely lost. I'm told that given these initial allocations, the exchange rate is $$P_H/P_C = 4/3 $$ and then the competitive equilibrium is allocation is $H_S = 50, \space C_S = 200/3,\space H_J = 50, \space C_J = 400/3$.</p>

<p>I solved for the contract curve and obtained $$ C_S = 200H_S/{(200-H_S)}$$
I'm honestly completely lost as to how they obtain that exchange rate and the competitive equilibrium. Can someone please explain to me how to find it?</p>

<p>Thanks in advance for the help!</p>
","<p>Equilibrium is achieved when demand equals supply in every market. We solve these types of problems by finding the set of prices which results in market clearing in every market. By Walras' law we know that if demand equals supply in the ham market it the cheese market must also clear, so we can find the set of prices which results in demand equaling supply in the ham market (working with the cheese market would also be valid).</p>

<p>The first step is to find each agent's gross demand for ham. We can find this by solving the utility maximization problem but since these utility functions are Cobb-Douglas we know the general form is</p>

<p>$$\frac{\alpha}{(\alpha+\beta)}\frac{m}{p_h}$$</p>

<p>where $m=40p_h+80p_c$ for Smith and $m=60p_h+120p_c$ for Jones since income is derived from the value of the endowment. </p>

<p>Gross demand gives how much each agent demands given a set of prices. Supply is equal to our total endowment which gives the market clearing condition
$$\frac{40p_h+80p_c}{2p_h}+\frac{60p_h+120p_c}{3p_h}=100.$$</p>

<p>We can always normalise one of the prices to one so let $p_c=1$. Solving the resulting expression gives $p_h=4/3$. To find the allocation just substitute these prices into the gross demands for each agent. </p>
","11726"
"Is there a good way of assessing an estimated absolute value of a currency?","162","","<p>If we want to figure out the strength of a currency relative to another currency, we look at the exchange rate between the two. However, I'm wondering what is the most accurate way of assessing the absolute value of a currency?</p>

<p>I suppose commodities or gold could be used, but there can be variations on the value of those over time (i.e if there is a new use for gold in electronics, the value is obviously going up.) So have economists found a better way?</p>
","<p>I don't think absolute value exists. Every valuation is relative, because these valuations are made by people/by the market. For example: if you'd offer the choice between a ferrari and an icecream to a little kid, the kid might choose the icecream. If you'd offer the same choice to an adult, the adult would probably choose the ferrari. But maybe the adult is very rich, and he already has 10 such ferraris, so he doesn't care and chooses the icecream cause he's very hungry at the moment...</p>

<p>Also with currencies, absolute value doesn't exist, only value relative to other things. I do think that gold/silver are possibly the best measures for currency-value. Everyone always talks about gold going up or down in currency-value. I think we should take a different approach and talk about currency going up or down in gold value cause gold can't be created ad infinitum and at almost no cost. </p>

<p>I don't think that measuring one currency against another has any merit... both currencies can be printed at will. It's like measuring length in centimeters, but every day there are more centimeters in one meter...</p>

<p>So no, in my opinion there's no better way, cause absolute value doesn't exist here...</p>

<p>Anyway, the Austrians have a lot to say about 'subjective value': <a href=""https://mises.org/library/subjective-value-theory"" rel=""nofollow"">https://mises.org/library/subjective-value-theory</a></p>

<p>best regards</p>
","12320"
"Why aren't perpetual bonds more common?","162","","<p>Most government bonds and corporate bonds have a maturity date when the principal must be repaid. </p>

<p>While the few percents of interest every year is generally not a big problem to pay out, when a bond matures the issuer must pay back all the principal at once which can be a huge expense and the issuer can go default if they don't have all the cash at hand by that time.</p>

<p>If the bond issuer issues a bond without maturity, then they only need to deal with the interest payments, which is a fixed amount of money and as the inflation gradually devalues the money it's become gradually less problem to pay it out. </p>

<p>If the price of the bond decreases or after a good year, the bond issuer may repurchase some of his own bonds from the market on his own discretion to further reduce the interest burden.</p>

<p>From the investor side this is kind of security can be bought from the market and sold when they need the cash just like any other security regardless of the lack of maturity. This way this security can be like a stock with a predetermined dividend.
Since the issuer only need to pay interest, the credit risk is lower, but interest risk is high. </p>

<p>So far it looks like a perpetual bond is just another kind of security with interesting properties and risks.</p>

<p>But most bonds do have maturity, so what are the caveats? What's the reason that most bonds do have maturity and perpetual ones are uncommon? </p>
","<ol>
<li>The most famous perpetual bonds are UK Government Bonds known as <a href=""https://en.wikipedia.org/wiki/Consol_%28bond%29"" rel=""nofollow noreferrer"">consols</a>. They weren't issued to avoid the rollover risk you highlight. Rather, their key benefit was liquidity. They could sell new consuls on the same terms as the old consuls and they have enhanced liquidity because it made the new and old issue more liquid. </li>
<li>They turned out to be a pretty horrible investment in real terms for early investors. Inflation ate away most of their value. </li>
<li>Despite their seemingly infinite life, because they pay out coupons and we discount the future geometrically their interest rate sensitivity behavior is similar to existing long dated bonds. </li>
<li>Unless the bond is callable, you generally can't make money by repurchasing your own bond at market prices. If interest rates drop, making you want to replace old bonds, the price of the old bonds goes up until the yield of old and new bonds are equated. Things are a bit different with changes in credit risk but even in that case it can be tricky. </li>
<li>The product you describe also sounds a lot like <a href=""https://en.wikipedia.org/wiki/Preferred_stock"" rel=""nofollow noreferrer"">preferred stock</a>. The Wikipedia article on <a href=""https://en.wikipedia.org/wiki/Perpetuity"" rel=""nofollow noreferrer"">perpetuities</a> gives consuls and preferred stock as two examples. </li>
</ol>
","9811"
"Will a Guaranteed minimum income not eventually just be crowded out by inflation?","162","","<p>That is, if we implement a guaranteed minimum income, would inflation not eventually rise to a point where it is essentially useless? I would expect prices to be adjusted knowing people have a certain amount of money available. Any explanation would be helpful!</p>
","<p>I will not discuss fairness (for example employers gains versus employees gains and bargaining power) principles as you did not ask about those.</p>

<p>Is ""crowding out"" the right phrase here?</p>

<p>Even if inflation lessens the effect of a minimal income there may still be an effect. Imagine that there are two people, $A$ with an income of 0 $B$ with an income of 60, so total income is 60. The government issues a minimal income of 30 so $A$'s income is changed to 30, total income is changed to 90. If this has no real effect on the economy then all prices rise accordingly, that is they rise by 50% because that is by how much nominal incomes haved changed. However if you adjust for this 150% price level, $A$ still can buy goods in value of $\frac{30}{1.5} = 20$ while $B$ can buy goods in value of $\frac{60}{1.5} = 40$. So there could at least be a redistribution effect as previously $A$ could not buy anything and $B$ could buy more things.</p>

<p>One concern is that inflation may not be even. Only the income of poor people will be raised hence demands for goods poor people buy will rise but demand for rich folks will not change. As a result the poor may experience larger inflation than the well to do, making the redistribution of incomes one between only poor people. The lines between poor and well to do here are murky. If (due to inflation) a pop-tart costs \$10 then people will buy quality food unless it is even more expensive. If a pop-tart's price rises to \$1,000 people will buy caviar unless its price is also raised.</p>

<p>A hope of governments implementing such policies is that (aside from fairness and solidarity principles) a minimal wage will also help minimum wage earners be more financially secure. A lot of studies have shown that in extreme poverty you make worse decisions and are less productive simply as a result of stress. If this is indeed a main effect then a minimum wage (or a higher minimum wage) can increase overall productivity. Thus inflation will not be the only effect of the policy but also an increased number of goods will be produced.</p>
","10388"
"Hayek's defense of competition regulation","161","","<p><a href=""https://www.theguardian.com/books/2016/apr/15/neoliberalism-ideology-problem-george-monbiot"" rel=""nofollow noreferrer"">This article</a> claims Hayek endorsed competition regulation:</p>

<blockquote>
  <p>As it evolved, neoliberalism became more strident. Hayek’s view that governments should regulate competition to prevent monopolies from forming gave way – among American apostles such as Milton Friedman – to the belief that monopoly power could be seen as a reward for efficiency.</p>
</blockquote>

<p>In which work did Hayek advance such view?</p>
","<p><a href=""http://www.law.nyu.edu/sites/default/files/ECM_PRO_060889.pdf"" rel=""nofollow noreferrer"">This article</a> states:</p>

<blockquote>
  <p>In  both  of  his  seminal  works  in  political  theory, 
  <em>The  Constitution  of  Liberty</em>  and <em>Law, Legislation and Liberty</em>, Hayek endorsed as a legitimate function of the state the  power  to  regulate  monopolies  and  curtail  industry  practices  in  restraint  of  trade. </p>
</blockquote>

<p>For example, in the first book, in Chapter 15, Hayek declares the importance of the <em>nature</em> of government intervention:</p>

<p><a href=""https://i.stack.imgur.com/VsWHd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VsWHd.png"" alt=""enter image description here""></a></p>

<p>Notice that Hayek considered trade unions as workers' monopolistic institutions that damaged free market. Hence, in his view, these are undesirable. In Chapter 18 of the above books it says:</p>

<p><a href=""https://i.stack.imgur.com/8vwKY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8vwKY.png"" alt=""enter image description here""></a></p>

<p>More on monopoly is in Chapter 17:</p>

<p><a href=""https://i.stack.imgur.com/tJccS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tJccS.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/5Cb1r.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5Cb1r.png"" alt=""enter image description here""></a></p>
","18792"
"Optimality of Zero Capital Taxation","161","","<p>The Chamley-Judd result of zero optimal capital taxation says that 0 capital taxation are required in order to maximize welfare at the steady state. </p>

<p>The result is 30 years old. Still assuming that we only care about the steady state, what's the literature's take on that? How esoteric is it? Or in other words, are there simple extensions of the model that completely overcome the result?</p>
","<p>There is quite a bit of work being done in that area. One very recent example is Straub and Werning's working paper ""<a href=""http://www.nber.org/papers/w20441"">Positive Long Run Capital Taxation: Chamley-Juff Revisited</a>."" 
The point seems to be that we need to consider the rate of convergence to the steady state.</p>

<p>Also, there is other literature that gives some competing results (e.g., ""the new dynamic public finance"" literature). For a more complete summary of mainstream objections, see Diamond and Saez, ""<a href=""https://www.aeaweb.org/articles.php?doi=10.1257/jep.25.4.165"">The Case for a Progressive Tax: From Basic Research to Policy Recommendations</a>,"" (JEP, 2011). They devote a whole section to why they think the Chamley-Judd result is not policy relevant.</p>
","28"
"Proof of nestedness of subgame perfect equilibria","161","","<p>Below is a lemma which I believe to be true and which I would like to use to derive other results</p>

<blockquote>
  <p>Take any two games in extensive form (complete information) $\Gamma$ and $\Gamma'$ differing <em>only</em> through their collections of information sets $\mathcal{H}$ and $\mathcal{H'}$. Suppose that for each decision node $x$ in the set of decisions nodes $\mathcal{X} = \mathcal{X}'$, $H(x)$ is a finer partition of the set of actions $c(x) = c'(x)$ than $H'(x)$.</p>
  
  <p>Then for ever subgame perfect equilibrium <em>outcome</em> of $\Gamma$, there exists a subgame perfect equilibrium of $\Gamma'$ with the same outcome (but the converse does not need to be true).</p>
</blockquote>

<p>I could try to write a complete proof but this seems to be basic enough a statement and I don't want to re-invent the wheel (or fail to pay tribute to former proofs). So my question is:</p>

<ul>
<li>Do you know of any reference where that result is proven (or maybe disproven in case I got something wrong)?</li>
</ul>

<p><strong>Edit :</strong> I am only interested in pure strategies equilibria.</p>
","<p>Perhaps I misunderstand something, maybe you do not allow mixed equilibria. That may be strange in games of imperfect information.</p>

<p>Consider an asymmetric matching pennies game. Both players show either Heads or Tails. I forgot how to type game matrices in mathjax, but the payoffs look something like this:</p>

<p>$\begin{bmatrix} -1,1 &amp; 3,-3 \\ 1,-1 &amp; -3,3 \end{bmatrix}$</p>

<p>Consider two versions of this game.</p>

<p>Version 1, $\Gamma'$
<br>  The moves are simultaneous so player 2 does not observe the move of player 1 and hence has two decision nodes in her information set. In the unique equilibrium player 1 mixes Heads and Tails with 50%-50% probability. Player 2 mixes Heads and Tails with 75%-25% probability respectively. Expected payoff is 0 for both.</p>

<p>Version 2, $\Gamma$
<br>  Sequential matching pennies. Player 1 moves first and his move is observed by player 2. In the unique equilibrium player 1 shows Heads, as does player 2. Payoff is -1 for player 1 and 1 for player 2.</p>

<p>Information-wise $\Gamma$ is a refinement of $\Gamma'$ but the equilibrium outcomes do not match.</p>
","11444"
"Prove that variance of a portfolio cannot exceed variance of individual assets","161","","<p>When reading on Markowitz's portfolio theory, I stumbled across the fact that in a market with two risky assets, if no short selling is not allowed, the variance of a portfolio consisting of the two assets cannot exceed the variances of the risky assets individually. That is:</p>

<p>$${\sigma _p}^2 \le \max \{ {\sigma _A}^2,{\sigma _B}^2\} $$
Where A and B are two different assets.</p>

<p>Could you kindly prove this statement, and possible provide some intuition for why this is the case?</p>
","<p>Let $w$ denote the weight on $A$ so that $1-w$ is the weight on $B$. 
Recall from the properties of variance that</p>

<p>$\sigma_p^2 = w^2\sigma_A^2  + 2w(1-w)\sigma_A\sigma_B \rho_{AB}+ (1-w)^2\sigma_B^2$</p>

<p>Without loss of generality, assume $\sigma_A \geq \sigma_B$.  We wish to show that </p>

<p>$w^2\sigma_A^2  + 2w(1-w)\sigma_A\sigma_B \rho_{AB}+ (1-w)^2\sigma_B^2\leq \sigma_A^2$</p>

<p>Note that </p>

<p>$\sigma_A^2 = \sigma_A^2 (w + (1-w)) ^2 = \sigma_A^2 w^2 + 2w(1-w)\sigma_A^2 + \sigma_A^2(1-w)^2$</p>

<p>Since $\sigma_A \geq \sigma_B$ and $w$, $(1-w)$, and $\sigma_A$ are positive, this means that</p>

<p>$\sigma_A^2 \geq \sigma_A^2 w^2 + 2w(1-w)\sigma_A\sigma_B + \sigma_B^2(1-w)^2$</p>

<p>And since the correlation has the property that $-1 \leq \rho_{AB} \leq 1$ and $w$, $(1-w)$, $\sigma_B$ and $\sigma_A$ are all positive, it must be the case that</p>

<p>$\sigma_A^2 w^2 + 2w(1-w)\sigma_A\sigma_B + \sigma_B^2(1-w)^2 \geq \sigma_A^2 w^2 + 2w(1-w)\sigma_A\sigma_B\rho_{AB} + \sigma_B^2(1-w)^2$</p>

<p>Therefore</p>

<p>$\sigma_A^2 \geq \sigma_A^2 w^2 + 2w(1-w)\sigma_A\sigma_B\rho_{AB} + \sigma_B^2(1-w)^2$ $\square$</p>

<p>In words, looking at the formula for variance of a convex combination of random variables, the variance is maximized if the correlation between the assets is 1.  In this case, the possible portfolio values as a function of $w$ are a straight line segment between $A$ and $B$, which clearly can't have a variance higher than either.  Now, if the correlation is less than 1, then any combination of the two will be lower than the straight line case.</p>

<p>Intuitively, the returns to assets $A$ and $B$ will partially cancel each other out any time they are not a fixed multiple of each other.  This canceling out behavior reduces the variance of the resulting portfolio.  The worst-case scenario is that the two assets are equal to each other, so the portfolio can never have a higher variance than the component asst with the highest variance.</p>
","16918"
"What is the difference between currency manipulation, and a fixed exchange rate regime?","161","","<p>China is labelled by some to be a 'currency manipulator', that is supposedly pegged to the US Dollar. What is the difference between currency manipulation and a fixed regime?</p>

<p><strong>Different motives?</strong>
I figure that it may be that a textbook fixed regime is undertaken to prevent instability, and is minor (just to correct volatility), whereas manipulation is done with the aim of gaining an unfair advantage.</p>

<p><strong>Different means?</strong>
I have also read that it could be due to the fact that a manipulator creates domestic base money with which it can buy currency, without sterilisation.</p>

<p><strong>Legality?</strong> BVJ below makes an interesting comment about the legality of the two... is there a <em>legal framework</em> in which some forms of fixed currency maintenance are allowed and some not?</p>

<p>Could anyone please clarify? Thanks.</p>
","<p>Correct, both a fixed exchange rate and a manipulated exchange rate involve the government setting this price. In BOTH cases it is usually implemented by promising to standing ready to buy or sell any amount at the fixed price. Of course, countries don't always have enough foreign cash to sell it at the promised price, nor do they always want to buy as much as the markets sell to them</p>

<p>The difference is, as you suggest, whether the trading partners (the US is usually the one that labels others manipulators) conclude that the exchange rate is fixed at a too depreciated level. This level keeps foreign goods cheap in the US and US goods expensive in the foreign country. </p>

<p>Also, a fixed exchange rate is often set at a lvel that seems ""too high"", the only question being whether the government will manage to keep it so high, since it creates an incentive for its citizens to buy foreign goods. Instead a manipulated currency is deemed to be ""too low"". </p>
","12866"
"When gradient of utility function is a zero vector","161","","<p>In Advanced Microeconomic theory by Jehle and Reny is said that if $\mathbf{x^*}$ is a solution to the following maximization problem $\max_{\mathbf{x} \in \mathbb{R}_+^n} u(\mathbf{x}) $  subject to $\mathbf{p \cdot x}\le y$, then $\bigtriangledown u(\mathbf{x^*})=\mathbf{0}$<br>
is possible but quite unlikely.</p>

<p>The question is why is it quite unlikely? I can think only budget constraint, but is it right?</p>
","<p>This concerns the partial derivatives of the utility function with respect to goods, and not the partial derivative of the Lagrangian of the maximization problem. </p>

<p>So a zero derivative, and moreover at the optimum, would imply a threshold quantity after which utility <em>diminishes</em>. </p>

<p>In the real world, we all know that consuming excessively may result in utility reduction (think eating too much food too quickly).  </p>

<p>In the theoretical world such utility functional forms have been used, especially ""quadratic utility"" in intertemporal representative consumer models in macroeconomics with a single good, </p>

<p>$$u(x) =ax - bx^2$$</p>

<p>In microeconomics, all abstract development of the theory usually assumes that utility is non-decreasing in each good separately. But in cases where one would want to allow for decreasing utility, then, indeed, the reason why we would not expect to find the optimum at the zero-gradient point, would be the workings of the budget constraint together with relative prices.</p>
","13892"
"Why does local non satiation imply the constraint is binding?","161","","<p>Local non satiation says that for any $x \in X$ and $\epsilon &gt; 0$, there exists $y \in X$ such that $d(x,y) &lt; \epsilon$ and $U(x) &lt; U(y)$.</p>

<p>I don't understand why this implies that $px^* = m$ if $x^*$ sovles consumer problem. If we think of $x \in R^2$, it implies that you can find a $y$ that is strictly preferred in the small neighborhood of $x$. In that case, even $x$ is on $px = m$, LNS seems to imply that there is a $y$ that is strictly preferred than $x$, and that $y$ may not be on the boundary since LNS only says there's a increasing direction but doesn't say which direction it is increasing. </p>
","<p>There are two situations with us when we know that preferences are locally non satiated. 
1) Preferences are monotonic - In this case we know that we have ""good"" goods which necessarily means that more of every good is better, and thus the consumer would want to exhaust his income 
2) Preferences are non monotonic - This permits the existence of ""bad"" goods but that doesn't mean that all goods are bad because that would mean that there is no bundle in the neighbourhood of origin (no good is consumed because all are bad) that is preferred to origin, thus we reach at a bliss/satiation point, violating LNS assumption. So, we need atleast one good which is not bad. In this case, the consumer would not spend anything on all the ""bad"" goods and exhaust his/her entire income on that one good which gives him/her positive utility.</p>
","18859"
"For what demand function is a monopoly most harmful?","160","","<p>Consider a firm with zero marginal cost. If it gives the product for free, then all the demand is satisfied and the social welfare increases by the maximum possible amount; call this increase $W$.</p>

<p>But because the firm is a monopoly, it reduces the demand and increases the price in order to optimize its revenue. Now the social welfare increases by a smaller amount, say, $V$.</p>

<p>Define the relative loss of welfare (deadweight loss) as: $W/V$. This ratio depends on the shape of the demand function. So my question is: is this ratio bounded, or can it be arbitrarily large? In particular:</p>

<ul>
<li>If $W/V$ is bounded, then for what demand function is it maximized?</li>
<li>If $W/V$ is unbounded, then for what family of demand functions can it become arbitrarily large?</li>
</ul>

<hr>

<p>Here is what I tried so far. Let $u(x)$ be the consumers' marginal utility function (which is also the inverse demand function). Assume that it is finite, smooth, monotonically decreasing, and scaled to the domain $x\in[0,1]$. Let $U(x)$ be its anti-derivative. Then:</p>

<p><img src=""https://i.stack.imgur.com/uSaVw.png"" alt=""monopoly deadweight loss""></p>

<ul>
<li>$W = U(1)-U(0)$, the total area under $u$.</li>
<li>$V = U(x_m)-U(0)$, where $x_m$ is the amount produced by the monopoly. This is the area under $u$ except the ""deadweight loss"" part.</li>
<li>$x_m = \arg \max (x \cdot u(x))$ = the quantity which maximizes the producer's revenue (the marked rectangle).</li>
<li>$x_m$ can usually be calculated using the first-order condition: $u(x_m) = -x_m u'(x_m)$.</li>
</ul>

<p>To get some feeling of how $W/V$ behaves, I tried some function families. </p>

<blockquote>
  <p>Let $u(x)=(1-x)^{t-1}$, where $t&gt;1$ is a parameter. Then:</p>
  
  <ul>
  <li>$U(x)=-(1-x)^{t}/t$. </li>
  <li>The first-order condition gives: $x_m=1/t$.</li>
  <li>$W=U(1)-U(0) = 1/t$</li>
  <li>$V=U(x_m)-U(0)=(1-(\frac{t-1}{t})^{t})/t$</li>
  <li>$W/V=1/[1-(\frac{t-1}{t})^{t}]$</li>
  </ul>
  
  <p>When $t\to\infty$,  $W/V \to 1/(1-1/e)\approx 1.58$, so for this family, $W/V$ is bounded.</p>
</blockquote>

<p>But what happens with other families? Here is another example:</p>

<blockquote>
  <p>Let $u(x)=e^{-t x}$, where $t&gt;0$ is a parameter. Then:</p>
  
  <ul>
  <li>$U(x)=-e^{-t x}/t$. </li>
  <li>The first-order condition gives: $x_m=1/t$.</li>
  <li>$W=U(1)-U(0) = (1-e^{-t})/t$</li>
  <li>$V=U(x_m)-U(0)=(1-e^{-1})/t$</li>
  <li>$W/V=(1-e^{-t})/(1-e^{-1})$</li>
  </ul>
  
  <p>When $t\to\infty$, again $W/V \to 1/(1-1/e)\approx 1.58$, so here again $W/V$ is bounded.</p>
</blockquote>

<p>And a third example, which I had to solve numerically:</p>

<blockquote>
  <p>Let $u(x)=\ln(a-x)$, where $a&gt;2$ is a parameter. Then:</p>
  
  <ul>
  <li>$U(x)=-(a-x)log(a-x)-x$. </li>
  <li>The first-order condition gives: $x_m=(a-x_m)\ln(a-x_m)$. Using this <a href=""https://www.desmos.com/calculator/bmu1ilr0jp"" rel=""nofollow noreferrer"">desmos graph</a>, I found out that $x_m \approx 0.55(a-1)$. Of course this solution is only valid when $0.55(a-1)\leq 1$; otherwise we get $x_m=1$ and there is no deadweight loss.</li>
  <li>Using the same graph, I found out that $W/V$ is decreasing with $a$, so its supremum value is when $a=2$, and it is approximately 1.3. </li>
  </ul>
</blockquote>

<p>Is there another family of <em>finite</em> functions for which $W/V$ can grow infinitely?</p>
","<p>An arbitrarily large ratio should occur with demand curve </p>

<p>$P=\begin{cases}
\frac{1}{Q} &amp; \text{if } Q&gt;1 \\
2-Q &amp; \text{if } Q\leq 1 \\
\end{cases}$.</p>

<p>The monopolist prices at $P=1$, but the consumers' surplus if $P=0$ is infinite, because the area under the demand curve contains $\int_1^\infty \frac{1}{Q}dQ=\infty$.</p>
","5178"
"How do I represent this indifference curve graphically?","160","","<p>I am not able to visualize this indifference curve. </p>

<p>I consume only two goods: sugar and milk. </p>

<p>I will prefer a bundle X of sugar and milk over a bundle Y only if $x_{sugar} &gt; y_{sugar}$, and $x_{milk} &gt; y_{milk}$.</p>

<p>If $Y_{sugar} &gt; x_{sugar}$ and $y_{milk} &gt; x_{milk}$, then I prefer Y bundle over X.</p>

<p>If neither case is true, I am indifferent between the two bundles.</p>

<p>How do I plot this on a graph? I need to solve a question, and I believe being able to draw a graph will be helpful!</p>

<p>This is how I visualize it. Is this representation correct? </p>

<p><a href=""https://i.stack.imgur.com/5WrRs.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5WrRs.png"" alt=""enter image description here""></a></p>
","<p>The problem is that there are no indifference ""curves"" but indifference ""areas"". Consider the following graph:</p>

<p><a href=""https://i.stack.imgur.com/07Mxd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/07Mxd.png"" alt=""enter image description here""></a></p>

<p>For a reference bundle $A$ (equivalent to $\{2,3\}$), the gray regions indicate the areas of indifference, based on your definition of preferences (the black lines are part of the indifference areas).</p>

<p>Thus, by selecting <strong>any</strong> bundle, you can find the indifference ""areas"" by plotting the vertical and horizontal lines across that point. Areas to the North-West and South-East will always be the indifference ""areas"".</p>

<hr>

<p>For reference, this is the <code>R</code> code to generate the graph:</p>

<pre><code>remove(list = ls())

a=2
b=3

plot(c(0,5), c(0,5), type = ""n"", xlab = ""Sugar"", ylab = ""Milk"", xaxs=""i"", yaxs=""i"")
rect(0, b, a, 5, border = NA, col = ""grey60"")
rect(a, 0, 5, b, border = NA, col = ""grey60"")
abline(h = b, col = 1, lwd = 2)
abline(v=a, col = 1, lwd = 2)
points(a, b, type=""p"", pch=19, col=""black"", bg=NA, cex=2)
text(1, 4, ""Indifferent"",cex = 1.3)
text(3.5, 1.5, ""Indifferent"",cex = 1.3)
text(1, 1.5, ""Worse off"",cex = 1.3)
text(3.5, 4, ""Better off"",cex = 1.3)
text(2.2, 3.3, ""A"",cex = 1.3)
</code></pre>
","15542"
"IV：Quasi-random variance V.S. 'Placebo' check","160","","<p>I read some papers about transportation infrastructure. I am confuse with the following two case.</p>

<ol>
<li>Some routes are unlikely to have been randomly assigned across cities over time. Thus, In some papers(i.e. Baum-Snow, 2007), they attain consistent estimates of the effect of transportation network on interest by the planned route IV.</li>
<li>But some papers (i.e. Donaldson 2012) use the planned route IV to test 'Placebo' effect.</li>
</ol>

<p>These two case seems contradictory. I'm quite new to this and hope someone can help me.</p>
","<p>There is no contradiction in two approaches. 
Baum-Snow (2007) looks at the effect of the Interstate Highway construction on those MSAs which happened to lie on its way. The randomness comes from the fact that when the plan for the Interstate Highway project was considered, the aim was to connect distant areas. Through which MSAs the highway would go was more or less random (at least this is what the author claims). Thus, some MSAs received treatment by lying on the way whereas other didn't. </p>

<p>Donaldson (2012) uses planned railway routes that were NOT implemented for a placebo test. The concern which Donaldson addresses is that there could exist some unobservable economic factors (different economic development, agricultural income etc) affecting the decision about where to construct the railway. To overcome this, the key assumption he uses is that, on the stage of planning, the several proposed routes were equally desirable from the strategic point of few, but some of them were more costly to build, hence these routes were dropped at some stages of construction. </p>

<p>Now, if we saw an effect on income in areas where railroads were planned but never built compared to areas where railroads were not even planned, this would suggest that railways are probably not the reason to explain main findings in the paper, but rather the selection of more developed areas into treatment (receiving or at least planning to receive railroads) was in place. However, such placebo test shows that areas that were initially selected into construction of railway, but due to technical reasons didn't receive the railways - have no significant income effect. Hence, the selection is argued to be not an issue in Donaldson's identification. </p>
","14716"
"1929 stock market crash and unemployment rate","159","","<p>Thomas Sowell has repeatedly made the case that government intervention is largely responsible for the Great Depression. For example, he notes what happened with the unemployment rate in the months after the stock market crash of 1929. Based on <a href=""https://nyupress.org/books/9780814787922/"" rel=""nofollow noreferrer"">Out of Work</a> by Vedder and Gallaway (alternatively available through <a href=""http://www.jstor.org/stable/j.ctt9qg19k"" rel=""nofollow noreferrer"">JSTOR</a>), page 77, one sees that the unemployment rate went from 5% (Nov. 1929) to 9% (Dec. 1929) and down to 6.3% (June 1930). It is then that Hoover signs the Smoot-Hawley Tariff Act, which Sowell contends is the first cause of the Depression. He then notes that by December 1930, the unemployment rate had shot up to 14.4%. Furthermore, aside from minor fluctuations in early 1931, the unemployment rate dips just below that 14.4% figure in 1936, but that is still the unemployment rate in December 1939. </p>

<p>I'm wondering what alternative factors or explanations could explain the quick increase to the unemployment rate followed by a decrease that approaches the previous numbers and then the marked and sustained increase, or if such alternatives even exist.</p>
","<p>One caveat to the author you refer to, Thomas Sowell is a staunchly conservative economist, so most arguments you hear from him will stick to the Econ 101 wisdom that government intervention is usually bad, tariffs are always bad (to be fair, it is hard to use them to correct externalities for global ""public goods""), etc.</p>

<p>Although tariffs probably were not necessarily the right choice for a tightening economy, the general story is that our central bank in America back then was a lot less independent from politics and less knowledgeable of how to deal with liquidity crises. It ended up tightening monetary policy instead of loosening it to ease the economic contraction, exacerbating employment problems for a long time. Keep in mind as well that this period of unemployment over 10% lasted for over a decade or so; it's not quite feasible to tell what all the factors were that caused the high unemployment, especially without official data on unemployment for a lot of that period.</p>
","17754"
"Are supply and demand always (with arbitrary dimensions but still) linear?","159","","<p>I have economics knowledge of high school level (and basic economics from my engineering degree), and I always noticed that supply and demand functions are linear (in 4+ dimensions).</p>

<p>It is -in practice, in real life- always the case? If not: What counterexamples (with theoretical models) do exist?</p>
","<p>Absolutely not, linear curves are a simplification made for (many) basic economics courses. When considering the basic mechanisms of Supply and Demand (supply rises when the price rises, demand drops when the price rises, etc.) there is no need to use more complicated curves, but as soon as you introduce elements like optimization, it is in many cases necessary to use non-linear functions.</p>

<p>In real life we don't generally observe curves as such, but rather different quantities sold with different prices. We can estimate curves based on this kind of data, but to me that's more of an econometric exercise.</p>
","9434"
"How can I best estimate a company's contribution to GDP?","159","","<p>Would revenues be a good proxy variable? If not, what are the other proxy variables that I can use?</p>
","<p>As a comment noted, value-added is the way to go. And how do we measure value added at the level of an individual firm? </p>

<p>It is </p>

<p>$$\text{Value-added} = \text{Wages and Salaries incl. Insurance}+\text{Depreciation}+\text{Profits before Taxes}$$</p>

<p>""Wages and Salaries including social security fees"" is the reward of Labor, while ""Depreciation plus Profits before Taxes"" is the (gross) reward of Capital.  </p>

<p>This makes sense because if one views GDP from the ""income"" angle, it goes to these two aggregates of productive inputs, ""Labor"" and ""Capital"". </p>

<p>All other expenses that appear in a company's Profit &amp; Loss Statement are ""third-party costs"", or value that other productive entities create.</p>

<p>Depending also on the jurisidiction, in most cases Labor costs, Depreciation and Profits before Taxes can be found as separate items in the financial statements of a company.</p>
","17638"
"Is there a theory about investors' behaviour during bubbles?","159","","<p>As far as I can see there are two senses in which it's 'rational' for an investor to buy during a bubble. </p>

<ol>
<li>The investor has erroneously overvalued the value of the stock/commodity. </li>
<li>The investor is aware that it's a bubble and is overvalued, but believes he can make a profit by selling before the bubble bursts. </li>
</ol>

<p>There are also 'irrational' explanations, such as the investor being caught up in the hype, or fearing missing out. </p>

<p>The question is, is investor behaviour during bubbles well studied, and are there models explaining it? </p>
","<h1>The investor has erroneously overvalued the value of the stock/commodity. </h1>

<p>Here is a prominent paper that models irrational bubbles:</p>

<blockquote>
  <p>This paper attempts to formalise herd behaviour or mutual mimetic
  contagion in speculative markets. The emergence of bubbles is
  explained as a self-organising process of infection among traders
  leading to equilibrium prices which deviate from fundamental values.
  It is postulated furthermore that the speculators' readiness to follow
  the crowd depends on one basic economic variable, namely actual
  returns. Above average returns are reflected in a generally more
  optimistic attitude that fosters the disposition to overtake others'
  bullish beliefs and vice versa. This economic influence makes bubbles
  transient phenomena and leads to repeated fluctuations around
  fundamental values.</p>
</blockquote>

<p>Herd Behaviour, Bubbles and Crashes (<a href=""http://www.jstor.org/stable/2235156?seq=1#page_scan_tab_contents"" rel=""nofollow"">Lux (1995)</a>)</p>

<h1>The investor is aware that it's a bubble and is overvalued, but believes he can make a profit by selling before the bubble bursts. </h1>

<p>Bubbles, rational expectations and financial markets (<a href=""http://papers.ssrn.com/sol3/papers.cfm?abstract_id=226909"" rel=""nofollow"">Blanchard and Watson (1982)</a>) is a famous paper on this subject. </p>

<blockquote>
  <p>This paper investigates the nature and the presence of bubbles in
  financial markets. Are bubbles consistent with rationality? If they
  are, do they, like Ponzi games, require the presence of new players
  forever? Do they imply impossible events in finite time, such as
  negative prices? Do they need to go on forever to be rational? Can
  they have real effects? These are some of the questions asked in the
  first three sections. The general conclusion is that bubbles, in many
  markets, are consistent with rationality, that phenomena such as
  runaway asset prices and market crashes are consistent with rational
  bubbles. In the last two sections, we consider whether the presence of
  bubbles in a particular market can be detected statistically. The task
  is much easier if there are data on both prices and returns. In this
  case, as shown by Shiller and Singleton, the hypothesis of no bubble
  implies restrictions on their joint distribution and can be tested. In
  markets in which returns are difficult to observe, possibly because of
  a nonpecuniary component, such as gold, the task is more difficult. We
  consider the use of both ""runs tests"" and ""tail tests"" and conclude
  that they give circumstantial evidence at best.</p>
</blockquote>

<p>Here is another:</p>

<blockquote>
  <p>We present a model in which an asset bubble can persist despite the
  presence of rational arbitrageurs. The resilience of the bubble stems
  from the inability of arbitrageurs to temporarily coordinate their
  selling strategies. This synchronization problem together with the
  individual incentive to time the market results in the persistence of
  bubbles over a substantial period. Since the derived trading
  equilibrium is unique, our model rationalizes the existence of bubbles
  in a strong sense. The model also provides a natural setting in which
  news events, by enabling synchronization, can have a disproportionate
  impact relative to their intrinsic informational content.</p>
</blockquote>

<p><a href=""http://Abreu1%20and%20Markus%20K.%20Brunnermeier"" rel=""nofollow"">Abreu and Brunnermeier (2003)</a></p>

<h1>[I]s investor behaviour during bubbles well studied, and are there models explaining it? </h1>

<p>Yes, this is a huge literature with probably thousands of papers and hundreds of books written about it. Here is a technical book on the subject:  <a href=""http://books.google.com/books?id=v5wpl6BenL4C&amp;lpg=PT3&amp;ots=CHdqpb0ZEQ&amp;dq=Asset%20pricing%20under%20asymmetric%20information%3A%20Bubbles%2C%20crashes%2C%20technical%20analysis%2C%20and%20herding&amp;lr&amp;pg=PT10#v=onepage&amp;q=Asset%20pricing%20under%20asymmetric%20information:%20Bubbles,%20crashes,%20technical%20analysis,%20and%20herding&amp;f=false"" rel=""nofollow"">Asset Pricing under Asymmetric Information: Bubbles, Crashes, Technical Analysis, and Herding</a>,
 These books are more historical than theoretical: <a href=""https://books.google.com/books?id=sVVdAQAAQBAJ&amp;lpg=PP1&amp;dq=bubbles%20financial&amp;pg=PP1#v=onepage&amp;q=bubbles%20financial&amp;f=false"" rel=""nofollow"">Manias, Panics and Crashes: A History of Financial Crises</a>, <a href=""https://books.google.com/books?id=Iihe6s0XincC&amp;lpg=PP1&amp;dq=this%20time%20is%20different&amp;pg=PP1#v=onepage&amp;q=this%20time%20is%20different&amp;f=false"" rel=""nofollow"">This Time Is Different: Eight Centuries of Financial Folly</a>, <a href=""https://books.google.com/books?id=_aIpBQAAQBAJ&amp;lpg=PP1&amp;dq=irrational%20exuberance&amp;pg=PP1#v=onepage&amp;q=irrational%20exuberance&amp;f=false"" rel=""nofollow"">Irrational Exuberance</a>. </p>
","4890"
"Long Term Impacts of Austerity Measures","159","","<p>Is there much research into the long term impacts of government fiscal contractions. </p>

<p>I have heard about 2nd generation unemployed as a result of Thatcher's policies but that is very much anecdotal. What does the literature have to say on the matter?</p>

<p>I have left the interpretation of government fiscal contraction open so as to capture a broad variety of policies. </p>

<p>There are many articles focusing on short term impacts, not so much long term impacts</p>
","<p><a href=""http://eml.berkeley.edu/~webfac/cromer/e134_sp13/Lecture%2026%20Slides%20Long.pdf"" rel=""nofollow"">This set of lecture notes</a> cites a bunch of great studies.</p>

<p>Effectively, this lecture said that fiscal consolidation (austerity) might have been expansionary (good). The <a href=""https://www.richmondfed.org/publications/research/economic_brief/2013/pdf/eb_13-09.pdf"" rel=""nofollow"">Federal Reserve</a>, however says:</p>

<blockquote>
  <p>fiscal consolidation is not likely to be expansionary today.</p>
</blockquote>

<p>The deciding factor seems to be whether Monetary Policy can offset short-term effects, thogh the Fed goes on to close with:</p>

<blockquote>
  <p>In summary, economists have not definitively answered the question of whether and when austerity is likely to be beneficial. Much of the debate ignores the question of whether implementing austerity is feasible in nations with nonexistent records of long-run fiscal consolidation or that rely on foreign sources of deficit financing. The economic volatility of recent years provides a ripe area of future study regarding the true effects of fiscal contractions.</p>
</blockquote>

<p>Or, ""We'll see...""</p>
","479"
"Showing that production technology exhibits decreasing returns to Scale","159","","<h1>The Question</h1>

<p>Suppose a firm has a production function given by</p>

<p>$$y=F(L,K)=L^{1/4}K^{1/4}$$</p>

<p>where L and K denote inputs used in the production of y units of output.</p>

<p><strong>(a)</strong> Determine whether marginal products are diminishing</p>

<p><strong>(b)</strong> Show that production technology exhibits decreasing returns to scale</p>

<h1>My attempt</h1>

<p><strong>(a)</strong> So the marginal products, $MP_L$ , $MP_K$ are:</p>

<p>$$MP_L={\partial{F}\over\partial{L}}={1\over{4}}L^{-3\over{4}}K^{1\over{4}}$$</p>

<p>$$MP_k={\partial{F}\over\partial{K}}={1\over{4}}L^{1\over{4}}K^{-3\over{4}}$$</p>

<p>To determine if the marginal products are diminishing one needs to simply derive the equations again. Which would be:</p>

<p>$${\partial{MP_L}\over{\partial{L}}}={-3\over{16}}L^{-7\over{4}}K^{1/4}$$</p>

<p>and</p>

<p>$${\partial{MP_k}\over{\partial{K}}}={-3\over{16}}L^{1\over{4}}K^{-7\over{4}}$$</p>

<p>When both Marginal products are derived, their results are both are $&lt;0$ which would imply that they are diminishing. </p>

<p><strong>(b)</strong> This is where I get a little confused, is it not because we know that the Marginal products are diminishing, we know that the production technology exhibits decreasing returns to scale?</p>
","<p>They are two different concepts I think. </p>

<p>Diminishing product means that holding other things fixed, one unit of extra input($K$ or $L$ here) yields less and less additional output, which you have known. </p>

<p>Meanwhile DRS is saying that if you multiply both $K$ and $L$ by some scalar $ t &gt; 1$, the corresponding output would be less than $t$ times the original output. </p>
","14006"
"Taking time derivative, growth equations","158","","<p>Can anyone please help with taking the derivative of the following equation with respect to time?</p>

<p>$ln(\frac{\gamma_t+(n+\delta)}{sA}) = (\beta - 1)ln{k_t}+(\alpha+\beta-1)ln{N_t}$</p>

<p>This is not a homework question, just reading a text on economic growth and not sure how the author arrived at the final expression.</p>

<p>Thanks</p>
","<p>I'll give a try, perhaps it is just this first derivative giving you trouble:</p>

<p>$$ \frac{d}{dt} ln \left( \frac{ \gamma_t + (n+\delta)}{sA} \right) = \frac{sA}{\gamma_t + (n+\delta)} \frac{d}{dt} \left( \frac{ \gamma_t + (n+\delta)}{sA} \right) $$</p>

<p>$$ = \frac{sA}{\gamma_t + (n+\delta)} \frac{\dot{\gamma}_t + 0}{sA} = \frac{\dot{\gamma}_t}{\gamma_t + (n+g)} $$</p>

<hr>

<p>And the rest are simply the time derivative of a log equals its growth rate $ \left( \frac{d}{dt} ln X = \frac{\dot{X}}{X} \right) $:</p>

<p>$$ \frac{d}{dt} \bigg[ (\beta-1) ln k_t + (\alpha + \beta - 1) ln N_t \bigg] = (\beta-1) \frac{\dot{k}_t}{k_t} + (\alpha + \beta - 1) \frac{\dot{N}_t}{N_t} $$</p>

<hr>

<p>Hence concluding the time derivative is:</p>

<p>$$ \frac{\dot{\gamma}_t}{\gamma_t + (n+g)} = (\beta-1) \frac{\dot{k}_t}{k_t} + (\alpha + \beta - 1) \frac{\dot{N}_t}{N_t} $$</p>
","10829"
"A timeline on the the key achievements of Economics and its evolution","157","","<p>Something I've never seen in Economics but have in Maths and Chemistry and really enjoyed is that when I took it we got to the see the evolution of the science (and yes Economics is a [social] science ) showing us the very building blocks and the story of how it evolved into its modern counterparts. </p>

<p>Like with maths: Something like the basis 1) Indian numbers, $+$, $-$, $x$, $\rightarrow$; 2) fractions, radical numbers, square roots; 3) complex numbers.</p>

<p>Something like that it doesn't come to mind well but I quite enjoyed that. It really set the tone. </p>
","<p>I don't think I can really do this question justice. A lot of us probably have different things that come to mind when we think of the history of economics. I tend to take an academic interpretation of your question.</p>

<p>A potpourri of random (mostly microecon, but maybe it'd be better to sort them) events that come to mind:</p>

<p><strong>1838 - Supply and Demand:</strong>
Antoine Augustin Cournot publishes a book about the supply and demand model (Alfred Marshall makes it famous later).</p>

<p><strong>1870s - General Equilbirum Theory:</strong>
William Stanley Jevons, Carl Menger, and French economist Leon Walras develop around the same time the idea of marginal utility, and Walras in particular creates his work in 1874, ""Elements of Pure Economics""</p>

<p><strong>1915(?) - Slutsky Decomposition:</strong>
Eugen Slutsky relates Marshallian and Hicksian demand to separate income and substitution effects. In 1927, he did something with statistics and business cycles that I don't quite understand, but I think that was important too.</p>

<p><strong>1930 - Intertemporal Consumption:</strong>
Irving Fisher lays out early work on discounted saving, though arguably,  Modigliani &amp; Brumberg (1954), Albert Ando, and Milton Friedman (1957) and the work on the life cycle-model is more noteworthy.</p>

<p><strong>1944 - Game Theory:</strong>
John von Neumann and Oskar Morgenstern use Brouwer's fixed-point theorem to create the basis for game theory.</p>

<p><strong>1947 - Von-Neumann Morgenstern Utility</strong>
John von Neumann and Oskar Morgenstern create their four axioms surrounding rationality with probabilistic utility outcomes.</p>

<p><strong>1951 - Arrow's Impossibility Theorem:</strong>
Joseph Kenneth Arrow publishes his book, ""Social Choice and Individual Values""</p>

<p><strong>1973 - Black-Scholes Pricing Model:</strong></p>

<p><strong>1977(?) - Mechanism Design:</strong>
Leonid Hurwicz, Eric Maskin, and Roger Myerson create the foundation for ""reverse game theory"".</p>

<p>As you can see, there are lots of gaps. I still don't know a lot about economic history--just that it is very large.</p>

<p><strong>Other topics to add:</strong>  Behavioral economics, experimental economics, information economics</p>
","9262"
"Does the Independence Axiom Require Statistical Independence?","157","","<p><strong>First:</strong> Given this definition of the Independence Axiom,</p>

<blockquote>
  <p>If for all $P$, $P'$, $P''$ in the set of lotteries over outcome space $X$, when:</p>
  
  <p>$P$ preferred to $P'$ $\implies$ $aP + (1-a)P''$ preferred to $aP' + (1-a)P''$ for all $a$ in $(0,1)$.""</p>
</blockquote>

<p>Can I do what I do here?</p>

<p>Then $P$ preferred to $P'$ $\implies$ $P$ preferred to $aP' + (1-a)P$ for all $a$ in $(0,1)$.</p>

<p><strong>Second:</strong>
Does satisfaction of the Independence Axiom rely on the statistical independence of the lotteries involved? It doesn't seem to be mentioned anywhere I've looked. </p>

<p>Any direction that can be offered is greatly appreciated. </p>
","<p>First Question:</p>

<p>Yes, you can obtain $P \succsim P' \Rightarrow P \succsim a P' + (1-a)P \forall a\in (0,1)$ from setting $P''=P$ in the axiom. Thus, your new condition is a special case of the independence axiom as stated.</p>

<p>Second Question:</p>

<p>Statistical independence of $P,P',P''$ is not assumed in the independence axiom. The notion of statistical independence of lotteries is not even meaningful since you can only choose one lottery. Only when you would choose multiple lotteries at the same time their dependence would matter since you may be able to reduce/increase risk by combining lotteries which are not independent.</p>
","11904"
"Find Variable Cost per Unit","157","","<p>I am trying to do this problem, and I am  not getting the answer.
I need to find the fixed cost of system 1, and system 2.
I know that the fixed cost will be the y-intercept of the equation.
Fixed cost for system 1 is 1000, and fixed cost for system 2 is $5000.
When I tried to find the variable cost per map dispensed, I am not getting the answer.
I know that the variable cost changes with the output. Therefore, it is the slope of the equation. In this case, the variable cost for system 1 is supposed to be 0.90, and the variable cost per map dispensed for system 2 is 0.1. However, the solutions manual shows that the variable cost per map dispensed for system 1 is 0.8, and variable cost per map dispensed for system 2 is 0.16.
Did I do something wrong?</p>

<p><img src=""https://i.stack.imgur.com/mb2Gu.png"" alt=""enter image description here""></p>
","<p>Based on the information you have given, both the solution manual and your solution are wrong. You are correct that the fixed cost for system I is 1. Variable cost is given by $$VC(x)=TC(x)-FC.$$ The variable cost for system I is therefore equal to $0.9x$. Note that the variable cost depends on $x$! For system II the variable cost is $0.1x$.</p>

<p>You appear to have confused variable cost with marginal cost. Variable cost is the part of the total cost that changes with quantity; marginal cost is, roughly, the cost of producing one more unit (and is given by the slope of the total cost curve). Thus, the <em>marginal</em> cost of system I is $0.9$ and the marginal cost of system II is $0.1$.</p>
","1643"
"Is there an intuitive explanation for the tax incidence formula from elasticity?","157","","<p>You're probably familiar with the formula for tax incidence (in a standard Principles framework) from elasticity. Specifically, that the consumer share is</p>

<p>$$\frac{\varepsilon_S}{\varepsilon_S+|\varepsilon_D|}$$
and the producer share is
$$\frac{|\varepsilon_D|}{\varepsilon_S+|\varepsilon_D|}$$</p>

<p>I had always assumed that this was just a byproduct of linear supply/demand and therefore not of much interest, but just now have proven to myself that it's not with a few nonlinear supply/demand forms that also produce this result. </p>

<p><strong>Is there an intuitive reason why the tax incidence takes this particular functional form, or is it just a common mathematical happenstance?</strong> This isn't the only functional form that satisfies what I think of as the intuitive tenets of the tax incidence solution (consumer + producer shares add to 1, increase in your side's elasticity increases your side's burden). Another form that satisfies this, but is not in fact a calculation of incidence share, is $$\frac{(|\varepsilon_D|/\varepsilon_S)}{(|\varepsilon_D|/\varepsilon_S)+(\varepsilon_S/|\varepsilon_D|)}$$</p>

<p>I suppose an alternative explanation is that the counterexamples I happened to test this with satisfy some condition necessary to have those be the shares, and it's not actually universal.</p>
","<p>Ah, never mind, got there.</p>

<p>Both supply and demand share the same change in quantity as a result of the tax, so</p>

<p>$$\Delta Q_S = \Delta Q_D$$</p>

<p>The amount by which the quantities changed is the derivative of that quantity wrt price, times the change in price that side experienced</p>

<p>$$\frac{\partial Q_S}{\partial P_S}\Delta P_S = \frac{\partial Q_D}{\partial P_D}\Delta P_D$$</p>

<p>Multiply both sides by the equilibrium P/Q</p>

<p>$$\frac{\partial Q_S}{\partial P_S}(\frac{P^*}{Q^*})\Delta P_S = \frac{\partial Q_D}{\partial P_D}(\frac{P^*}{Q^*})\Delta P_D$$</p>

<p>which of course is the formula for elasticity at the equilibrium</p>

<p>$$\varepsilon_S \Delta P_S = \varepsilon_D \Delta P_D$$
$$\frac{\varepsilon_S}{\varepsilon_D}\Delta P_S = \Delta P_D$$</p>

<p>So then the producer's share is </p>

<p>$$Incidence_S=\frac{P^*-P_S}{T}=\frac{|\Delta P_S|}{|\Delta P_S|+|\Delta P_D|} = \frac{|\Delta P_S|}{|\Delta P_S|+|\frac{\varepsilon_S}{\varepsilon_D}\Delta P_S|}$$</p>

<p>the price change cancels out and you get producer's share as</p>

<p>$$Incidence_S=\frac{1}{1+|\frac{\varepsilon_S}{\varepsilon_D}|}=\frac{|\varepsilon_D|}{|\varepsilon_D|+\varepsilon_S}$$</p>

<p>So it all comes from the fact that this is the unique formula that produces the price-change ratios that generate identical quantity changes in both sides of the market. Probably not any intuition that can come down to a principles course level but makes a lot more sense than it did before!</p>
","16231"
"Externalities - First order conditions","156","","<p>I am currently reading the book ""Microeconomics: Principles and Analysis"" by Cowell on my own. I'm reading the externalities chapter, and i found an interesting example:</p>

<p>There are just two firms: firm 1 is a polluter and firm 2 the victim. Firm 2 (the victim) makes an offer of a side-payment or bribe to firm 1. The bribe is an amount that is made conditional upon the amount of output that firm 1 generates: the greater the pollution, the smaller is the bribe; so we model the bribe as a decreasing function β(⋅).</p>

<p>The optimization problem is</p>

<p><a href=""https://i.stack.imgur.com/ZX2kO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZX2kO.png"" alt=""enter image description here""></a></p>

<p>My question is how did they arrive at those FOC's? </p>

<p>UPDATE:The second part of this optimization is to look at the problem from firm 1 perspective, it follows like this:
<em>Now look at the problem from the point of view of firm 1. Once the victim
firm makes its offer of a conditional bribe, firm 1 should take account of it. So
its profits must look like this</em></p>

<p><a href=""https://i.stack.imgur.com/5bwPz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5bwPz.png"" alt=""enter image description here""></a></p>

<p>This is from F.A.Cowell - Microeconomics - Principles and Analysis p.444-445</p>
","<p>To make sure it's completely explicit: superscripts below are indices referring to either firm $1$ or firm $2$.</p>

<p>The choice variables in this problem are $\mathbf{q}^2$ and $\beta$. Notice that $\mathbf{q}^2$ is a vector of $n$ quantities. That is to say, $\mathbf{q}^2=\left(q_1^2,q_2^2,\ldots,q_n^2\right)$.</p>

<p>$(13.9)$ is just the derivative of the objective function $(13.8)$ with respect to $q_i^2$. Notice that you can rewrite the objective function $(13.8)$ as $$ p_1q_1^2+p_2q_2^2+\cdots+p_iq_i^2+\cdots+p_nq_n^2-\beta\left(q_1^1\right)-\mu_2\Phi^2\left(q_1^2,\ldots,q_i^2,\ldots,q_n^2 ,q_1^1\right) $$</p>

<p>Differentiating this with respect to $q_i^2$ and setting that equal to $0$ gives us $$ p_i - \mu_2 \frac{\partial\Phi^2 \left( \mathbf{q}^2,q_1^1 \right)}{\partial q_i^2}  = 0 $$</p>

<p>In Cowell's notation, $\Phi^2_i$ is just the derivative of $\Phi^2$ with respect to $q_i^2$.</p>

<p>The second first-order condition is the derivative of the objective function with respect to $\beta$. Since $\beta(\cdot)$ is a decreasing function of $q_1^1$, we can also think of $q_1^1$ as a decreasing function of $\beta$. (Formally, $q_1^1$ is the inverse of $\beta$, which is well-defined since $\beta$ is decreasing. Intuitively, if firm $2$ conditions their bribe on firm $1$'s level of output, then firm $1$'s output choice also depends on the amount of the bribe.)</p>

<p>Thus, applying the chain rule, the derivative of the objective with respect to $\beta$ is $$ -1 -\mu_2\frac{\partial\Phi^2 \left( \mathbf{q}^2,q_1^1 \right)}{\partial q_1^1} \frac{dq_1^1}{d\beta}=0 $$
which, unfortunately, isn't quite the same as in Cowell. Notice however that $\frac{dq_1^1}{d\beta}&lt;0$, so perhaps he is using the absolute value of that derivative to get rid of the minus sign in front of $\mu_2$.</p>
","14469"
"Homogeneous of Degree Two Utility Functions and Homothetic Preferences.","156","","<p>The understanding that I am not clear is in when do homothetic preferences represent a utility function and vice-versa. My solution to the problem is posted below the problem: </p>

<p>A consumer’s preferences are described by a utility function that is homogeneous
of degree two: For all $\alpha &gt; 0$ and $x \in R^{L}_{+} $ , </p>

<p>$u(\alpha x) = \alpha^2 u(x)$</p>

<p>The problem that I am not getting clear is: 
Q) ""Are this consumer’s preferences homothetic? Show that they are or give a counterexample.""</p>

<p>My solution:</p>

<p>According to Mas Colell et al. ""Microeconomic Theory"" (chapter 3, page 50) 
<a href=""https://i.stack.imgur.com/XqLGR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XqLGR.png"" alt=""enter image description here""></a></p>

<p>Therefore, this given consumer's preferences are not homothetic as it doesn't generate a utility function that is homogeneous of degree 1 (HOD(1)). A counter example would be a utility function that is HOD(1) like the Cobb Douglas Utility Function </p>

<p>$ U(x_1, x_2) = x_{1}^{\alpha} x_{2}^{1-\alpha} $</p>

<p>To conclude, this consumer's preferences are not homothetic as it represents a utility function of HOD(2). While , according to Mas Colell et al. preference $\pmb{\succsim}$  is homothetic $\textbf{if and only if}$ it admits a utility function that is HOD(1).</p>

<p>Could you please help me in understanding where I am going wrong with what Mas-Colell mentioned above ""necessary and sufficient condition"" and how a utility function that is HOD(2) implies that $\pmb{\succsim}$ is homothetic.</p>

<p>Thanks. </p>
","<p>First of all, in order to provide a counterexample, you need to construct a utility function that is homogeneous of degree two, but is not homothetic. Therefore, the counterexample you gave in your solution doesn't work.</p>

<p>To prove the statement directly, let $u(x)$ be a utility representation that is homogeneous of degree two. That is, $u(\alpha x)=\alpha^2 u(x)$. Therefore, if $x\sim y$, which means $u(x)=u(y)$, we have 
$$u(\alpha x)= \alpha^2 u(x)=\alpha^2 u(y)=u(\alpha y).$$
This means $\alpha x\sim \alpha y$, and hence the preferences are homothetic.</p>

<p>We can also use the proposition in MWG: A continuous $\succeq$ is homothetic if and only if it <strong>admits</strong> a utility function $u(x)$ that is homogeneous of degree one. One caveat is that the utility representation is unique up to monotone transformations, so even if one representation $u(x)$ is not homogeneous of degree one, the preferences could still be homothetic if a monotone transformation of the representation, $\phi(u(x))$, is.</p>

<p>In this question, if we consider a monotone transformation $\hat{u} (x)=(u(x))^\frac{1}{2}$, this $\hat{u}(x)$ still represents the preferences $\succeq$. Notice that 
$$\hat{u} (\alpha x)=(u(\alpha x))^\frac{1}{2}=(\alpha^2 u(x))^\frac{1}{2}=\alpha (u(x))^\frac{1}{2}=\alpha\hat{u} (x),$$
meaning that this new representation is homogeneous of degree one. Therefore, by the proposition above, the preferences are homothetic.</p>
","18520"
"Pure Exchange Economy","156","","<p>I need help drawing the Pareto Set for an Edgeworth economy. I know how to find the contract curve given an allocation, and I <em>think</em> that ends up being the competitive equilibria, but drawing the Pareto line is much harder than anticipated.</p>

<p>We are given 2 goods and 2 agents, with log utility $(\alpha_i &gt; 0)$:</p>

<p>$$u_i(x_i) = \alpha_i \ln x^1_i + \ln x^2_i$$</p>

<p>We get the tangency condition:</p>

<p>$$\alpha_1 \frac{x_1^2}{x_1^1} = \alpha_2 \frac{x_2^2}{x_2^1}$$</p>

<p>And combine with the resource constraints:</p>

<p>$$x_1^1 + x_2^1 = r^1$$
$$x_1^2 + x_2^2 = r^2$$</p>

<p>A lot of algebra:</p>

<p>$$\alpha_1 \frac{x_1^2}{x_1^1} = \alpha_2 \frac{r^2 - x^2_1}{r^1 - x^1_1}$$</p>

<p>$$\implies \alpha_1 (x^2_1 r^1 - x^2_1 x^1_1) = \alpha_2 (x^1_1 r^2 - x^1_1 x^2_1)$$</p>

<p>$$\implies \alpha_1 x^2_1 r^1 - \alpha_2 x^1_1 r^2 = (\alpha_1 - \alpha_2) x^1_1 x^2_1$$</p>

<p>$$(\alpha_1 \cdot \frac{1}{x^1_1} \cdot r^1) - (\alpha_2 \cdot \frac{1}{x^2_1} \cdot r^2) = \alpha_1 - \alpha_2$$</p>

<p>Which gets us:</p>

<p>$$\boxed{x_1^1 = \frac{\alpha_1 r^1 x_1^2}{\alpha_1 x_1^2 - \alpha_2 x_1^2 + \alpha_2 r^2}}$$ </p>

<p>For our Pareto Set. (You could also solve in terms of $x_1^1$.)</p>

<p>As denesp notes, if $\alpha_1 = \alpha_2 - r^1 = r^2$, then $x_1^1 = x_1^2$.</p>

<p>The question is, how would I draw this for different values of $\alpha$? What is the intuition behind the slope of it?</p>
","<p>As you note in your question the (inner points of the) Pareto set are defined by
$$
x_1^1 = \frac{\alpha_1 r^1 x_1^2}{\alpha_1 x_1^2 - \alpha_2 x_1^2 + \alpha_2 r^2}
$$
In order to better examine this curve, let us treat it as a function. Let
$$
f(x) = \frac{\alpha_1 r^1 x}{\alpha_1 x - \alpha_2 x + \alpha_2 r^2}.
$$
As I stated in my comment
$$
f(0) = 0 \mbox{ and } f(r^2) = r^1,
$$
so the set indeed goes from one corner to the other. In between you have
$$
\frac{d \ f(x)}{d x} = \frac{\alpha_1\alpha_2r^1r^2}{\left(\alpha_1 x - \alpha_2 x + \alpha_2 r^2\right)^2}
$$
and
$$
\frac{d^2 f(x)}{dx^2} = 2 \cdot \frac{(\alpha_1\alpha_2r^1r^2) \cdot (\alpha_2-\alpha_1)}{\left(\alpha_1 x - \alpha_2 x + \alpha_2 r^2\right)^3}.
$$
The first derivative is always positive because $r^2 &gt; x$ and all other parameters are positive. For the same reason, the sign of the second derivative depends on the sign of $\alpha_2-\alpha_1$. <br> Thus the Pareto set will be a strictly increasing curve, which is convex if agent 2 values good 1 'relatively more', concave if agent 1 values good 1 'relatively more', and a straight line if they value it 'relatively equally'.</p>
","9480"
"The Insane Sultan of Slickcrudistan: Calculating Currency Equilibrium","156","","<p>I work for a start-up that has encountered an economics problem no one on our team has been able to crack. </p>

<p>A story form and a general form of the problem are below. I believe they are equivalent, but if there is a difference, please defer to the general form.</p>

<p>We understand there is no precise answer to this question and that the value of any currency considers prices in other factors that this question ignores. Still, we figured, or hoped, that there was some general way of approximating this, even if it's under idealized conditions. Thanks!</p>

<p><strong>Story Form</strong></p>

<blockquote>
  <p>The sultan of Slickcrudistan has gone insane. He has decreed that his country will only accept pre-2015 sand dollars in exchange for oil<sup>1</sup>. Barrels of oil will be sold to the bidder offering the most sand dollars per barrel. Additionally, the sultan is willing to sell sand dollars back to the public at approximately the current US dollar to sand dollar exchange rate. </p>
  
  <p>His country produces 20,000,000 barrels of oil at a market value of $1,000,000,000 USD/year. Additionally, 100,000,000 pre-2015 sand dollars exist. Assuming liquid and efficient markets, what is the equilibrium price of a sand dollar? How would this change if there were a stable inflation in the quantity of sand dollars?</p>
  
  <p><sup>1</sup> Suppose an extremely cheap process exists for verifying this.</p>
</blockquote>

<p><strong>General Form</strong></p>

<blockquote>
  <p>Currency <em>X</em> has a total circulation of <em>a</em> units and a stable inflation rate of currency units of <em>m</em> percent. </p>
  
  <p>Currency <em>Y</em> has a total circulation of <em>b</em> units and a stable inflation rate of currency units of <em>n</em> percent. </p>
  
  <p>Currency <em>Y</em> is completely debased and of no value in comparison to currency <em>X</em> (at market exchange rates, <em>b</em> &lt;&lt; <em>a</em> ). </p>
  
  <p>A market with a value of <em>c</em> units per year in currency <em>X</em> can now only be transacted in a currency <em>Y</em>. <em>c</em> is growing at a stable rate of <em>p</em> percent. </p>
  
  <p>Assuming liquid and efficient market, what is the new equilibrium of exchange?</p>
</blockquote>
","<p>Using a simple textbook-approach, I will provide one possible answer here, showing that in this approach, the one thing that needs to be specified is ""velocity of money"" as regards sand dollars. </p>

<p>I will use also the numerical values provided in the question, after cutting out six zeros.
I assume that the <strong>Law of One Price</strong> holds, so</p>

<p>$$P_s\cdot S_{USD/s} = P_{USD} \tag{1}$$</p>

<p>$P_s$ is ""the price level"" related to sand dollars, $P_{USD}$ is the price level related to USD, and $S_{USD/s}$ is the exchange rate we wish to find (""how many USD per one sand dollar"").</p>

<p>While the price levels are usually price-indexes, here we are looking at a single good, oil, so we can take the $P's$ to mean ""price of oil"".  </p>

<p>The Sultan's oil is the only output that can be bought with sand dollars. And we do know the value of this output in USD</p>

<p>$$P_{USD} \cdot Q_s = P_{USD} \cdot 20 = 1,000 \;\text{USD} \tag{2} $$</p>

<p>Using the Law of One Price, we get</p>

<p>$$P_{USD} \cdot Q_s = P_s\cdot S_{USD/s}\cdot Q_s \implies S_{USD/s} = \frac {P_{USD} \cdot Q_s}{P_s\cdot  Q_s} \tag{3}$$</p>

<p>(<em>don't</em> simplify).</p>

<p>Assuming the <strong>Quantity Theory of Money</strong>, we have</p>

<p>$$P_s\cdot Q_s = V_s \cdot \bar M_s \tag{4}$$</p>

<p>where $\bar M_s$ is the fixed amount of sand dollars available, and $V_s$ is the ""velocity of money"" in relation to sand-dollars (we will return to $V_s$). Inserting $(4)$ into $(3)$ and using also $(2)$ and the fixed value of $\bar M_s$ we have</p>

<p>$$(4),(3),(2) \implies S_{USD/s} = \frac {P_{USD} \cdot Q_s}{V_s\bar M_s} = \frac {1,000}{V_s\cdot 100} = \frac {10}{V_s}$$</p>

<p>So, if we can find a value for $V_s$, we have found the exchange rate we are after. The velocity of money can be thought as ""how many times that same unit of currency, say the same paper bill, will be used in transactions during a production cycle"".  </p>

<p>The <a href=""https://research.stlouisfed.org/fred2/series/M1V"" rel=""nofollow"">M1 velocity of money for USD is approximately </a> $V_{USD} \approx 6$, using this value for the sand-dollars also, we get</p>

<p>$$S_{USD/s} = \frac {10}{6} \approx 1.67$$</p>
","9647"
"Why use empirical macroeconomic models when they are not policy invariant (Lucas Critique)?","156","","<p>With high probability this question is duplicate, and I tried to find one already in the community, but I was unsuccessful. </p>

<p>According to the <a href=""https://en.wikipedia.org/wiki/Lucas_critique"">Lucas Critique, in its more general terms,</a> the problem with empirical macroeconomic models is that they are not invariant to policy changes, and hence we cannot take any policy conclusions out of them. </p>

<p>My question then is why do we still use them? </p>

<p>Any help would be appreciated. </p>
","<p>The response to the Lucas Critique was the emergence of RBC and DSGE models. Using microeconomic foundations of macro models we can simulate how behavior changes when policy changes and only estimate ""deep"" structural paramateres that are not policy variant. Before microfoundations we were estimating models where the estimation included the actions of people. With microfounded models today we try to seperate the actions. This was not possible in older models as we actually did not consider how people act or react, whereas microfoundations tell you how people would react.</p>

<p>However this is a difficult task as once you introduce agents that actively think about their actions you must take into acount their future expectations, which are unknown. One way to deal with this are rational expectations.</p>

<p>A further issue is that such models predict reactions that are quicker than in the data. If agents are perfectly rational, have perfect foresight and all information, they react quickly and perfectly. The solution to this today is to add frictions that slow these reactions down. However old models that we used to estimate (think about IS-LM and especially AS-AD models) also have the huge issue that people are too stupid (only adaptive (backward looking) expectations, do not take information into account when forming expectations, don't think about what may come in the future) and this is partially a piece of the Lucas Critique. Now we have the problem that people are too smart or super-rational. Some models (see models where some fraction of agents are ""Rule of Thumb Consumers"") now also assume that some agents are fully rational (many indeed are) while some just are backward looking (as in the normal IS-LM or AS-AD model), as a balance of the two things to generate a more realistic picture.</p>

<p>As for the critique of rationality: In many experimental micro studies rationality fails. However this does not tell us how many small deviations from rationality aggregate, which is what macro is interested in. It may occur that from many different deviations in different directions that in aggregate rationality is still a good approximation.</p>

<p>Furthermore approaches have been developed now to deviate from rational expectations. These are very difficult to solve though. One interesting way is to assume people are rational, but do not have all the information, which is a reason most people make mistakes. These are models of information frictions. Key words: Rational Inattention (e.g. Sims) and Inattentiveness (e.g. Reis). Another related approach includes Learning Models.</p>

<p>To summarize: we try to have models that are immune to the Lucas Critique. These often require rational expectations to be solved, but other approaches are also being developed.</p>
","8357"
"CV, EV for additive utility; confirm or deny","155","","<p>I'm currently a TA for a class and recently graded a midterm. I gave the answer key back to the teacher, after going over part of the exam in a study hall. I was going to go over the rest of it tomorrow, but while making my own answer key in office hours, I seem to have come to a different answer than the teacher.</p>

<hr>

<p>We maximize
$$u = 2x_1^{1/2} + 4x_2^{1/2}$$
with a normal budget constraint where $p \cdot x \leq w$. We arrive at the Walrasian demand:</p>

<p>$$x^*(p, w) = \left(\frac{p_2 w}{p_1(4p_1 + p_2)} , \frac{4p_1 w}{p_2(4p_1 + p_2)}\right)$$</p>

<p>Suppose $w = 10, \vec p = (1, 4), \vec p' = (3, 2)$.</p>

<p>Thus, $x(p', w) = (\frac{10}{21}, \frac{30}{7})$, and $x(p, w) = (5, \frac{5}{4})$ for our new and old bundles respectively.</p>

<p>So to find <strong>compensating variation</strong> we find the original utility:</p>

<p>$2 \cdot 5^{1/2} + 4 \cdot (5/4)^{1/2} = 4 \sqrt 5$</p>

<p>and find $w'$ that would get old utility and new prices:</p>

<p>$4 \sqrt 5 = 2(\frac{w'}{21})^{1/2} + 4(\frac{3w'}{7})^{1/2} = 2(\frac{w'}{21})^{1/2} + 12(\frac{w'}{21})^{1/2} = 14(\frac{w'}{21})^{1/2} \implies \\
4 \sqrt 5 = 14(\frac{w'}{21})^{1/2} \\
80 = 14^2 \cdot \frac{w'}{21} \\
\boxed{w' = \frac{60}{7}}$</p>

<p>Thus $\boxed{CV = w - w' = 10 - \frac{60}{7} = \frac{10}{7}}$</p>

<p>To find <strong>equivalent variation</strong> we find the new utility:</p>

<p>$2 \cdot (10/21)^{1/2} + 4 \cdot (30/7)^{1/2} = 2 \cdot (10/21)^{1/2} + 12 \cdot (10/21)^{1/2} = 14 \sqrt {\frac{10}{21}}$</p>

<p>and find $\hat w$ that would get new utility at old prices:</p>

<p>$14 \sqrt {\frac{10}{21}} = 2(\frac{\hat w}{2})^{1/2} + 4(\frac{\hat w}{8})^{1/2} = 4(\frac{\hat w}{2})^{1/2} \\
14^2 \cdot \frac{10}{21} = 16 \cdot \frac{\hat w}{2} \\
\boxed{\hat w = \frac{70}{6}}$</p>

<p>Thus $\boxed{EV = \hat w - w = \frac{70}{6} - 10 = \frac{5}{3}}$</p>

<p>The problem is if I recall correctly, the CV and EV are supposed to have the opposite sign so that the change in welfare is ambiguous. Where have I gone wrong, if anywhere? (Worth noting that if you do Slutsky decomposition for this question, you find that good 2 is inferior.)</p>
","<p>Questions with numbers are usually not as good as questions without numbers. If you had written down the formula for CV and EV you would probably have noticed that your premise is false.</p>

<hr>

<p><a href=""https://en.wikipedia.org/wiki/Compensating_variation"" rel=""nofollow"">CV</a> and <a href=""https://en.wikipedia.org/wiki/Equivalent_variation"" rel=""nofollow"">EV</a> are not supposed to have opposing signs. You can see this from their definitions where
$$
CV = e(p_1,u_1) - e(p_1,u_0), \hskip 20pt EV = e(p_0,u_1) - e(p_0,u_0).
$$
Either $u_1 &gt; u_0$ and then a larger income is needed to reach $u_1$ given any price or the opposite is true.</p>

<hr>

<p>In your final comment you also note that good 2 is inferior. As can be seen from your demand function</p>

<p>$$
x^*(p, w) = \left(\frac{p_2 w}{p_1(4p_1 + p_2)} , \frac{4p_1 w}{p_2(4p_1 + p_2)}\right)
$$</p>

<p>this is not true. If income were to increase $x_2^*(p, w)$ would increase as well.</p>
","13751"
"How much does a public sector pay rise actually cost the UK government?","155","","<p>This is something that's in the UK news at the moment. Public sector workers have experienced a 1% annual cap on pay increase since 2013.</p>

<p>Government ministers are appearing on TV saying that they don't have the multiple billions required to fund an increase to bring it in line with the private sector.</p>

<p>Despite the headline figure (let's call it £6 billion), how much does the pay increase actually cost the government?  I'm thinking that VAT receipts, income tax receipts and corporation tax receipts (from an increase in spending) would surely all go up?</p>
","<p><strong>Unison (2014) - Net cost</strong></p>

<p>The Public sector trade union did an analysis of lifting the cap in 2014. The report is <a href=""https://www.unison.org.uk/content/uploads/2014/05/On-line-Catalogue223292.pdf"" rel=""nofollow noreferrer"">here</a>. Unlike the IFS analysis presented above, <strong>Unison estimates the net cost of an increase in public pay</strong> by 3%, using a microsimulation model. They estimates are summarised in the table below:</p>

<p><a href=""https://i.stack.imgur.com/4ddAN.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4ddAN.png"" alt=""enter image description here""></a></p>

<p>The key here is that a gross increase in the cost by approx. £4 billion reduces to a net increase between £1.7 and £2 billion (or £2.2; see Table 6a). The difference between scenarios depends on the assumption of the fiscal multiplier, which can range between 0.34 (used by the Office of Budget Responsibility), and 1.02 (upper bound used by the IMF). Naturally, the larger the multiplier is the higher the benefit from the wage increase, and the lower the net cost.</p>

<p><strong>Institute for Fiscal Studies (2017) - Gross cost</strong></p>

<p>The Institute for Fiscal Studies provided an analysis of the 2017 general election Labour and Lib Dem manifiesto, which included a lift to the 1% public pay cap increase. As the <a href=""https://www.ifs.org.uk/publications/9241"" rel=""nofollow noreferrer"">report states</a>:</p>

<blockquote>
  <p>Our analysis of the Labour plan implies that, compared to the current government’s plans, by 2021–22 a Labour government would need to provide departments and local government with an additional £9.2 billion per year to pay for the higher costs of employing public sector workers. Of this, £2.9 billion would be for the NHS. Comparing the Liberal Democrats’ plans to the current Conservative government’s plans, it would necessitate an extra £5.3 billion per year, of which £1.6 billion would be for the NHS.</p>
</blockquote>

<p>The table below summarises their conclusions:</p>

<p><a href=""https://i.stack.imgur.com/H1v8f.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/H1v8f.png"" alt=""enter image description here""></a></p>

<p>The key difference between the two parties is that the Lib Dem suggested to increase pay in line with inflation, whereas the Labour party suggested to increase pay in line with the private sector (more precisely, based on the recommendations of <a href=""http://press.labour.org.uk/post/160008381504/jonathan-ashworth-shadow-health-secretary-speech"" rel=""nofollow noreferrer"">Pay Review Bodies</a>). </p>

<p>As the report states, any forecast is highly dependent on the state of the economy (uncertainty due to e.g. Brexit):</p>

<blockquote>
  <p>These Figures are highly sensitive to the forecasts of the economy. For the Liberal Democrats, the cost will be higher if inflation is higher in 2018–19 and 2019–20 than is expected by the OBR currently, or lower if inflation is lower. Under Labour’s policy if private sector earnings growth performs less well over the coming years than is forecast by the OBR (it has consistently underperformed OBR forecasts in recent years), then it would cost less than is implied by Table 1. Conversely, if private sector earnings growth performs better than forecast, and public pay is increased faster too, then the cost to departments and local government of Labour’s policy would be higher too.</p>
</blockquote>

<p><strong>Notice that these figures are gross cost estimates</strong>. I.e. they do not include indirect costs or benefits associated with it. For example, further costs might arise due to how the spending is financed. Such increase in spending would certainly require (i) more taxation, and/or (ii) more borrowing (cuts also possible, but less likely, due to party manifestos). The former could change incentives to work or invest (affecting growth), whereas the latter means higher borrowing costs, which have to be paid too. Regarding the benefits, if you have some belief in the <a href=""https://en.wikipedia.org/wiki/Fiscal_multiplier"" rel=""nofollow noreferrer"">fiscal multiplier</a>, you could expect that part of that increase might be offset by extra revenues (income, VAT, etc) due to higher GDP (e.g. via consumption) from public workers. If this is a permanent increase, then such change in consumption is likely to be higher (at least according to the <a href=""https://en.wikipedia.org/wiki/Permanent_income_hypothesis"" rel=""nofollow noreferrer"">permanent income hypothesis</a>).</p>
","17733"
"how to find Cournot equilibrium for 2 firms having different MC?","155","","<p>When MC function is different for both the firms, how will MR = MC work ?</p>
","<p>Let the profit functions of the two firms be 
$$
\begin{aligned}
\pi_1(q_1,q_2)&amp;=p(q_1,q_2)q_1-C_1(q_1)\\
\pi_2(q_1,q_2)&amp;=p(q_1,q_2)q_2-C_2(q_2)
\end{aligned}
$$
where $p(q_1,q_2)$ is the inverse demand depending on the total output of the two firms $q_1+q_2$, and $C_i$ is the total cost function of firm $i\in\{1,2\}$. Thus $C_i'$ is the marginal cost (MC) of firm $i$, and we can impose the condition that $C_1'\ne C_2'$ on the cost functions so that the firms have different MCs. </p>

<p>Now we can solve for the Nash equilibrium (NE). Profit maximization would yield the following first-order conditions for the two firms:
$$
\begin{aligned}
p'_1(q_1^*,q_2)q_1^*+p(q_1^*,q_2)-C_1'(q_1^*)&amp;=0\qquad\qquad(1)\\
p'_2(q_1,q_2^*)q_2^*+p(q_1,q_2^*)-C_2'(q_2^*)&amp;=0\qquad\qquad(2)
\end{aligned}
$$
These are the usual MR=MC condition (<em>for each firm</em>). Solving for $q_1^*(q_2)$ in $(1)$, we get the <strong>best response of Firm 1</strong> as a function of Firm 2's output $q_2$. Likewise, from $(2)$ we get <strong>Firm 2's best response</strong> to Firm 1's output, $q_2^*(q_1)$. </p>

<p>Recall the a NE in a two-player game is <strong>a pair of <em>mutual best responses</em></strong>. Therefore the NE of this two-firm Cournot game with different MCs is the pair $(q_1^*(q_2^*),q_2^*(q_1^*))$, where each firm is best responding to the other firm's best response (to the former firm). Practically, this means to plug $q_2^*$ into $q_1^*(q_2)$ and solve for $q_1^*$, and then plug $q_1^*$ back into $q_2^*(q_1)$ and solve for $q_2^*$. </p>
","12139"
"Predicting $y$ when response variable is $\ln(y)$","155","","<p>My estimated model is </p>

<p>$$\hat \ln(y_t)=9.873-0.472\ln(x_{t2})-0.01x_{t3}$$</p>

<p>I'm asked to find a predictive CI at 95% confidence for the mean of $y_0$, when $x_{02}=250$, and $x_{03}=8$. We're to assume that $s^2 x_0(X^TX)^{-1}x_0^T=0.000243952$, where $x_0=(250,8)$.</p>

<p>I have a solution from a previous year, that goes like this:</p>

<blockquote>
  <p>I find the CI of the form 
  $\text{CI}(E[ln(y_0)|x_0])=\left[\hat\ln(y_t)-t_{\alpha/2}s_E,\hat \ln(y_t)+t_{\alpha/2}s_E\right]$, where $t$ is
  the $\alpha/2$ upper-quantile of distribution $t(n-k)$ and
  $s_E=\sqrt{0.000243952}$. This gives me $[7.1563,7.2175]$.</p>
  
  <p>Then the author does
  $\text{CI}(E[y_0|x_0])=[e^{7.1563},e^{7.2175}]=[1282.158,1363.077]$.</p>
</blockquote>

<p>I disagree with this last step (by Jensen's inequality we'll underestimate). In Wooldridge's Intro to Econometrics, in page 212, he states that if we're sure the error terms are normal, then a consistent estimator is:</p>

<p>$$\hat E[y_0|x_0]=e^{s^2/2}e^{\hat \ln(y_0)}$$ </p>

<p>So, I was thinking of doing </p>

<p>$$\text{CI}(E[y_0|x_0])=\left[e^{s^2/2} 1282.158,e^{s^2/2}1363.077 \right] = \left[ 1282.314,1363.243 \right] $$</p>

<p>Is this correct?</p>

<p>Also, the solution to this exercise states that $\text{CI}(E[y_0|x_0])=[624.020,663.519]$, which is far from either solution I've got.</p>

<p>Any help would be appreciated.</p>

<p>P.S: I've also read that the correction should not be used to the CI but only for the point estimation $\hat E[y_0|x_0]$</p>
","<p>You do not find the same answer because of what I suspect to be a typographical error, which would thus be the main reason of your problem: $x_{03}$ would be set to $80$, not $8$. Another possibility, if you keep $x_{03}=8$, is an error in the second estimated coefficient, say, $\hat{\beta}_2 = -0.1$ instead of $-0.01$.</p>

<p>Anyway, one of these modifications solves everything and yields the same result as the solution to this exercise.</p>

<p>Considering this change, with $t_{\alpha/2}=1.96476138969835$, one gets</p>

<h3>Method 1</h3>

<p>$\text{CI}(E[y_0|x_0])=[e^{6.43618291164626},e^{6.49755798189177}]=[624.020307335178,663.519326788772]$
<strong>(the given solution to this exercise)</strong></p>

<p>or <h3>Method 2</h3>
(as stated In Wooldridge's Intro to Econometrics, in page 212) if we're sure the error terms are normal (and one is extremely lucky)</p>

<p>$$\text{CI}(E[y_0|x_0])=\left[e^{s^2/2}624.0203,e^{s^2/2}663.5193 \right] = \left[ 624.0960,663.6002 \right] $$</p>

<h2>however</h2>

<p>the <strong>method 2</strong> is very unlikely to be correct, since as you mention in your question <em>[...] the (underestimation) correction should not be used to the CI but only for the point estimation.</em></p>

<p>Why ? I would say because of the dependency betweeen the two terms, knowing the expectations of $e^{s^2/2}$ on the one hand and $\hat{y_0}$ on the other hand does not mean one knows the one of $e^{\frac{s^2}{2} + \hat{\ln(y_0)}}$.</p>
","16605"
"What is a merit good?","155","","<p>I just came across the concepts of merit and demerit goods for the first time, in the <a href=""http://www.cie.org.uk/Images/164510-2016-2018-syllabus.pdf"" rel=""nofollow"">Cambridge A-level economics syllabus</a>. I wasn't sure what they were.</p>

<p>Is a merit good simply a good that has positive 'internalities' (benefits that the consumer is unaware of)?  </p>

<p>And similarly, is a demerit good simply one with negative 'internalities' (costs that the consumer is unaware of)?</p>
","<p>Richard Musgrave (<a href=""http://www.jstor.org/stable/40909134"" rel=""nofollow"">1957</a>, <a href=""http://rads.stackoverflow.com/amzn/click/B0006AVID2"" rel=""nofollow"">1959</a>) invented the term. My interpretation of what he says (below) is that <strong>merit goods are simply goods that the ""community"" deems desirable, while demerit goods are those the ""community"" deems undesirable</strong>. </p>

<p>He (<a href=""http://www.dictionaryofeconomics.com/article?id=pde2008_M000152&amp;edition=current&amp;q=merit%20goods&amp;topicid=&amp;result_number=1"" rel=""nofollow"">1987</a>) writes that the concept (of merit goods) is ""best applied where individual choice is restrained by community values"" ... ""Community values ... give rise to merit or demerit goods"" ... </p>

<p>Such goods are where ""community values"" act ""as a restraint on individual choice"". The ""evaluation of a good (its merit or demerit) derives not simply from the norm of consumer sovereignty but involves an alternative norm.""</p>

<ul>
<li>Examples of merit goods are ""Concern for maintenance of historical sites,  respect for national holidays, regard for environment or for learning and the arts."" </li>
<li>Examples of demerit goods are drug use and prostitution because they are ""offences to human dignity (quite apart from potentially costly externalities).""</li>
</ul>

<p>P.S. There is of course the difficult question of who or what exactly the ""community"" is. If I may add my humble opinion, all of this sounds very illiberal and even mildly fascist. Which is perhaps why this concept hasn't been much taken up by mainstream economics.</p>

<p>P.P.S. The above is merely Musgrave's interpretation. As Musgrave himself says:</p>

<blockquote>
  <p>The concept of merit goods ... has been widely discussed and given divergent interpretations ... it is thus difficult to provide a unique definition.</p>
</blockquote>
","10486"
"Why are the 10 year German bunds and 10 year US treasury yield highly correlated?","155","","<p>And when the ECB started QE this year, the 10 year bunds rate naturally plummetted, but so did the 10 year US treasury rate. What fundamental reason could cause the US rate to drop in synchrony? </p>
","<p>Because they are the so called ""Fly to Quality"". When markets turmoil investors look where to safely invest their money to avoid volatility and risk. This lead to a depreciation (because of the more demand in bonds, the less bond rate) in rates. After the QE, as you said, the left risk about the already solid Germany was cut out because of the unlimited coverage by the ECB on European Bonds. Germany and US are considered the two solid major economics of the World and every rational investor who wants to do not run too risk (because it is impossible to avoid it entirely, see ""idiosyncratic risk"" for further information) prefers to invest there. A similar but slightly different chapter is for gold, considered a ""Fly-to-Quality"" good as well. Concluding, part of the correlation is due to economic relationships that there are between US and EU and it also accentuates the effects of important macroeconomic news of one or the other party. </p>

<p><strong>TIP</strong></p>

<p>Do you know why, sometimes, it is possible to see negative rates (as Danish or Switzerland or some Scandinavians)? Because sometimes, even if the rate is negative (you have to pay the issuer) the cost of carry is higher and then investors just leave their money there, paying less than to disinvest and invest again in another kind of security. This happened for some days to German rates too!</p>
","6936"
"Can a monopoly INCREASE the market surplus compared with a competitive market?","154","","<p>Monopolies are often blamed for DWLs(Dead Weight Losses), while competitive markets believed to work without DWLs (assuming zero taxes/subsidies and zero externalities). </p>

<p>But I think I found an example when ABSENCE of a monopoly (in this case - a regulated natural monopoly) and presence of a competitive market can lead to smaller market surplus (i.e. DWLs). Am I correct? If not - why? </p>

<p>Let's assume there is a competitive market for a specific medicine. The competition is tough. Economies of scales aren't exploited to their maximum because in this case, only one firm would be able to survive (there is enough demand only for one Gigafactory) and <strong>for this reason, the state puts limit on maximum size of factories in order to prevent full exploitation of economies of scale</strong>.</p>

<p>So many people can't afford the medicine despite fierce competition. And if you don't buy anything, then obviously you can't have surplus. Not to mention, that in their totality the producers have lower surplus due to higher costs and lower sales.</p>

<p>Now let's suppose that one day the state decided that maybe a monopoly isn't so bad thing if it's properly regulated. So the state let the firms increase their exploitation of economies of scale and soon only one firm was left. Of course, it was regulated in order to prevent abuses. Now the market surplus increased. The surplus of consumers increased because now more people can afford to buy the medicine. The surplus of the producer's also greater than the total surplus of producers of the existed competitive market because the production of the medicine is less costly and it has more buyers.</p>

<p>But if we increased the market surplus compared with the existed competitive market, then what does it mean? Shockingly, it means that said competitive market had DWLs! Even if there were no taxes/subsidies and externalities.</p>

<p>UPDATE 01:</p>

<p>Ok, there is my try to formalize my thought. </p>

<p>Let's suppose that there is a perfectly competitive market for a particular medicine. There are NO taxes/subsidies or externalities.</p>

<p>The aggregative demand is Qd=1000-P</p>

<p>The aggregative supply is Qs=-2+0.2*P</p>

<p>P = 835 is the equalibrium price, thus we will have Q=165 as equalibrimum quantity.</p>

<p>The total surplus of consumers is equal to (1000 - 835)*165*0.5 = 13612.5</p>

<p>The total surplus of producers is equal to (835 - 10)*165*0.5 = 68062.5</p>

<p>Thus the market surplus is 13612.5 + 68062.5 = 81675</p>

<p>Now let's replace the competitive market with a regulated natural monopoly that can fully exploit economies of scale.</p>

<p>The aggregative demand is the same, it's Qd=1000-P</p>

<p>P=ATC=200 by the law, while the price without dead weight losses is P=183.(3)
It means that Q=800.</p>

<p>The monopolist's MC=-100+5*P</p>

<p>The total surplus of consumers is equal to (1000 - 200)*800*0.5= 320000</p>

<p>The total surplus of the monopoly is equal to 180*800*0.5+800*(200-180)=88000</p>

<p>Thus the market surplus is 320000 + 88000 = 408000.</p>

<p>As you can see, the total market surplus is bigger. Much bigger.</p>

<p><strong>UPDATE 02</strong></p>

<p>I found book ""Intermediate Microeconomics"" by  John Hey, it seems to support my conclusion. And there is nothing radical. I will quote some places from the chapter 29. </p>

<p>""One very obvious reason why a single large firm might be more appropriate in some industry is simply that a single large firm might have access to a more efficient technology than lots of small firms. This is a plausible case if centralisation of the industry has consequences in terms of
increased efficiency – contrariwise, if splitting it up into lots of little units causes losses of efficiency and increased bureaucratic costs. ... Even if it behaves like a monopolist – and there is an associated deadweight loss as a consequence – the end product for both consumers and producer might be better.""</p>
","<p>I found book ""Intermediate Microeconomics"" by John Hey, it seems to support my conclusion. And there is nothing radical. I will quote some places from the chapter 29.</p>

<p>""One very obvious reason why a single large firm might be more appropriate in some industry is simply that a single large firm might have access to a more efficient technology than lots of small firms. This is a plausible case if centralisation of the industry has consequences in terms of increased efficiency – contrariwise, if splitting it up into lots of little units causes losses of efficiency and increased bureaucratic costs. ... Even if it behaves like a monopolist – and there is an associated deadweight loss as a consequence – the end product for both consumers and producer might be better.""</p>
","20023"
"Liquidity trap and consumers' reaction to an increase in money supply","154","","<p>I've understood that when the nominal interest rate reaches the <em>zero lower bound</em> there is nothing that the monetary policy can do to increase the output level of a certain economy. Because $i=0$, no one is interested in bonds anymore, and people decide to hold more money in correspondence to the same interest rate. But if they hold more money, why they decide to keep them, instead of increasing their level of consumption and thus increase also the level of production?</p>

<p>It may be a stupid question, but I really cannot figure out the answer. Hope you can help me. Thank you in advance.</p>
","<p>Good question. The answer depends on what exactly you mean by an increase in the money supply and how it is implemented. </p>

<p>Because standard monetary policy (ie. open market operations) is implemented through banks, it is functionally quite different from a pure infusion of cash to consumers, which is more the realm of fiscal policy, depending on how it is financed. Consider a central bank that buys bonds from commercial banks by crediting their accounts with reserves. Banks now have excess reserves which they are able to lend should they so choose. If interest rates are above zero, interest rates will fall enabling banks to offload the excess reserves. However, if interest rates are already at a nominal lower bound of zero, the price of loanable funds cannot fall to stimulate increased demand, and hence banks cannot offload the excess reserves. </p>

<p>It also depends on whether the increase in the money supply is temporary or permanent. A permanent increase in the money supply will permanently increase the price level, thereby inducing a one-period spike in inflation and a contraction in real interest rates ($i^R=i^N-\pi$). The quantity of loanable funds demanded will increase. If the increase in the money supply is temporary, though, this will not work. This is why economists view the implications of permanent versus temporary changes to the money supply very differently during zero bound episodes.</p>

<p>A few links that may be helpful:</p>

<p><a href=""http://www.voxeu.org/article/combatting-eurozone-deflation-qe-people"" rel=""nofollow"">http://www.voxeu.org/article/combatting-eurozone-deflation-qe-people</a>
<a href=""http://www.bruegel.org/nc/blog/detail/article/1527-permanent-qe-and-helicopter-money/"" rel=""nofollow"">http://www.bruegel.org/nc/blog/detail/article/1527-permanent-qe-and-helicopter-money/</a></p>
","1912"
"Real vs Nominal Value Concept","154","","<p>I am having trouble understanding the meaning of the real value of an economic quantity.</p>

<p>The concept is easy to grasp: take a year as a base and adjust for inflation by pricing a commodity with the prices from the base-year.</p>

<p>As I understand it, the real value of, let's say, an orange is, or should be, close to its intrinsic value. It measures the how we value an orange by its potential. This intrinsic value is dimensionless (?).</p>

<p>My difficulty is to reconcile the fact that humans do not think in real terms: we observe and value everything via its nominal value.</p>

<p>In the hypothetical case of comparing two objects that have the same use (let's say, oranges from X country and orange from Y), we always use its nominal value to determine what to buy.</p>

<p>What could be an example that could convince me that the real value is a useful metric to analyze economic data?</p>

<p>What is the philosophical reason to use real vs nominal value?</p>
","<blockquote>
  <p><em>""My difficulty is to reconcile the fact that humans do not think in
  real terms: we observe and value everything via its nominal value.""</em></p>
</blockquote>

<p>Those who do that, suffer from what is called the <a href=""https://en.wikipedia.org/wiki/Money_illusion"" rel=""nofollow"">""money illusion""</a>. </p>

<blockquote>
  <p><em>""In the hypothetical case of comparing two objects that have the same use (let's say, oranges from X country and orange from Y), we always
  use its nominal value to determine what to buy.""</em></p>
</blockquote>

<p>Indeed, because this is a comparison of <em>two distinct</em> (even if comparable) products, <em>at a single point in time</em>.</p>

<p>Now just answer the following question:</p>

<blockquote>
  <p>Your wage today is 100 and the price of oranges today is
  100/kgr. Tomorrow, the price of oranges will be 200/Kgr and your wage
  will still be 100. Will your wage tomorrow be the same, <strong><em>as regards
  what matters</em></strong>, with your wage today?</p>
</blockquote>

<p>Certainly, its <em>nominal</em> value will be the same. But what about its <em>real</em> value, i.e. <strong>the value in terms of what matters</strong>? (how much you can consume, is what matters).</p>
","5613"
"Do general equilibrium models include money?","153","","<p>An economics professor told me that General Equilibrium models are a sophistication of barter. Does that imply that they don't include money? And if that is the case, are there any attempts to include it?</p>

<p>Moreover, does this have any implications on the way we understand macroeconomics?</p>

<p>Thanks.</p>
","<p>While many general equilibrium models do not need to model money to approach the questions that they would like to answer, there are many models that do include money to address questions that need money to be a relevant feature of the model. These models do it in a variety of ways -- some might be more relevant than others. I will try and describe two of the approaches briefly.</p>

<h2>Cash-in-advance</h2>

<p>When I think of a cash-in-advance (CIA) model, the first models that come to mind are Lucas (1982) and Lucas Stokey (1987). Models that take this approach have agents saving in assets and money, but they must finance any consumption solely through their money holdings (basically assets are less liquid than money which isn't the worst approach). There are many critiques of the CIA of which I find Wallace (1998) to be one of the more thoroughly presented.</p>

<h2>New Monetarist</h2>

<p>More recently there has been a push to use models of money that are less ""ad-hoc"" about how money works. Some foundational papers of this field are the Kiyotaki Wright papers (1989, 1991, 1993). These papers build a very basic model of money and show what role it plays in economics -- There is a good discussion on Randall Wright's <a href=""https://en.wikipedia.org/wiki/Randall_Wright"" rel=""nofollow"">Wikipedia page</a> under the sub-title ""Research contribution."" While these models confirmed some of the reasons for money to exist in a model, they were quite simplistic and lacked many other features of the real economy. A monetary course I took labeled these types of models as ""Generation 1 models of money."" There was a group of papers that were known as ""Generation 2 models of money, but these shared many of the simplifications made in Generation 1 (so I won't discuss them here).</p>

<p>Since this time Lagos Wright (2004) introduced a more complete framework (we referred to these as ""Generation 3 models of money."" One of the issues faced by these new monetarist models is that in order to solve the model, one must keep track of the entire distribution of money -- This is computationally infeasible unless the authors introduce a simplification in a different area of the model (in the Lagos Wright model, they simplify the form of utility in order to be able to compute the distribution of money next period). There is on-going research in this area and, in my opinion, is an open area for improvement in the literature.</p>

<h2>References</h2>

<ul>
<li>Nobuhiro Kiyotaki and Randall Wright. ""On Money as a Medium of Exchange."" Journal of Political Economics. 1989.</li>
<li>Nobuhiro Kiyotaki and Randall Wright. ""A Contribution to the Pure Theory of Money."" Journal of Economic Theory. 1991.</li>
<li>Nobuhiro Kiyotaki and Randall Wright. ""A search-theoretic approach to monetary economics."" American Economic Review. 1993.</li>
<li>Ricardo Lagos and Randall Wright. ""A Unified Framework for Monetary Theory and Policy Analysis."" Journal of Political Economy. 2005.</li>
<li>Robert E. Lucas Jr. ""Interest Rates and Currency Prices in a Two Country Model."" Journal of Monetary Economics. 1982.</li>
<li>Robert E. Lucas Jr and Nancy L. Stokey. ""Money and Interest in a Cash-In-Advance Economy."" Econometrica. 1987.</li>
<li>Neil Wallace. ""A Dictum for Monetary Theory."" Federal Reserve Bank of Minneapolis Quarterly Review. Winter 1998.</li>
</ul>
","6932"
"Why currency purchasing power is linked to confidence in central banks","153","","<p>From the New Statesman, <a href=""http://www.newstatesman.com/politics/economy/2016/02/coming-storm"" rel=""nofollow"">http://www.newstatesman.com/politics/economy/2016/02/coming-storm</a>,</p>

<blockquote>
  <p>""Ever since the collapse of the Bretton Woods system of pegged exchange rates in 1971, the sole guarantee that currencies will maintain their purchasing power, both domestically and abroad, has been confidence in central banks’ discretionary policies. A loss of faith in the consensus model of monetary policy would pitch us into the anchorless world that the architects of the Bretton Woods system always feared.""</p>
</blockquote>

<p>I cannot understand the reasoning behind why confidence in central banks' discretionary policies would help currencies maintain their purchasing power.</p>

<p>Moreover, what would be the possible consequences of markets losing their faith in modern central banking?</p>
","<p><strong>TL;DR Version:</strong> 
The trust that money has value gives it its value. If money can be exchanged for gold, then this makes people trust that it will have value. If this is not the case (and it is not, although it used to be the case almost everywhere) then the only thing that can make people trust that money will not lose its value through extreme printing of money is having <em>trustworthy</em> people endowed with the power to print money. These people are called central bankers, hence their credibility matters here. The consequences of losing faith would be (hyper-)inflation.</p>

<p><strong>Long Version:</strong></p>

<p>First a few definitions. The purchasing power of money is basically its value. That is how many goods/services (e.g. bread) you can get for a dollar. Inflation is a price increase, which means that a dollar can now buy less things (as they cost more). Hence money loses its purchasing power when inflation occurs.</p>

<p>Further, the value of money is basically determined just like the value of anything else - supply and demand. So if you print a lot of money (supply increases) its value will go down. That's the reason the government doesn't just print a bunch of dollars and give them to everyone, because that money would lose value, i.e. it would lead to inflation (rising prices).</p>

<p>The reason that money has any value at all in the first place (today) is because people believe it has value. Also, people believe it has value, because it does. They observe that they can use it to obtain goods and services. That's pretty much the only thing distinguishing the dollar from monopoly money today. As is apparent from the reason money has value it is easy to get into vicious cycles. If people stop believing it has value then it won't, which will lead to more people believing it doesn't and so on. </p>

<p>This is why hyperinflation is so hard to stop. Once money loses a lot of its value the trust people have in this money is undermined. They panic and think it won't be worth anything soon. So they try to get rid of it by exchanging it for other things. As everyone tries to exchange money for other things, effectively the supply of money (really the velocity of money) increases, which undermines its value even more. Since everyone wants to get rid of money in this scenario, there is no one to give it to in order to trade with so it becomes worthless (as no one wants it). A german central banker once said that inflation is like toothpaste: once you get it out of the tube it's very hard to get back in again. The problem is, that governments have an incentive to print more money, to pay off debts and have more spending power, etc., which creates inflation.</p>

<p>So there are multiple equilibria possible, where all people (or a critical mass) believe in money and since all do there is no reason not to believe in it. Or nobody does and in this case there is no reason to in fact believe in money. It's also possible for many to believe in it and many not to (e.g. 50-50 or 60-40), but this is not a very stable equilibrium. For more on how money comes into existence at all, see the paper by Kiyotaki and Wright (""Money as a medium of exchange"" and ""A Search-Theoretic Approach to Monetary Economics"" american economic review 1993) , who discuss these equilibria possibilites. There, basically money emerges, because barter (trading goods for other goods) is so inefficient as it requires a rarely occuring double-coincidence of wants. So if money is undermined, probably something else will emerge. E.g. in Germany after a crash people used cigarettes as currency.</p>

<p>Now it wasn't always the case that money <strong>only</strong> had value, because others believed it. On top of that, governments had what was called the ""gold-standard"". This meant that at any time, money could be exchanged for a certain amount of gold. Because of this, governments were restricted in how much money they could print, by how much gold they had in reserve. So this was meant to stopp excessive printing of money and to stop inflation panicks. This however came at a cost, because monetary policy could barely be used and it required governments around the world to frantically search for gold. Nowadays, we don't have the gold standard, so governments are free to do what they want. However, they don't abuse their power, which is evidenced by low inflation rates in the last 30 years and without the drawbacks of the gold standard.</p>

<p>If the central bank is not credible and the government does not guarantee to exchange money for gold, basically there is nothing to ""anchor"" the value of money. So if people expect the central bank to print too much money, then money will lose its value.</p>

<p>One last possibility through which the mistrust of the central bank is important here is because of wage-setting. When negotiating wages, unions take into account rising prices (inflation) so that they don't become poorer through price increases, which is why they demand higher wages. If they expect a lot of inflation to occur in the course of the year, they will demand high wages right now (as these contracts cannot be renegotiated every month). However the rising wages will lead to higher prices, which in fact <em>is</em> inflation and this spiral could get out of control. With a credible central bank, this won't happen of course, as the expectations aren't so wild.</p>
","11071"
"Why is deflation not considered the opposite of inflation?","153","","<p>In <a href=""http://www.antipope.org/charlie/blog-static/2013/12/why-i-want-bitcoin-to-die-in-a.html"">this article from 2013 on bitcoin</a>, the author casually states the importance of knowing that ""deflation is not the opposite of inflation"", without expanding or elaborating. I'm sure that there are differing points of view, but can anyone provide support for this statement and its importance?</p>

<p>To me it seems that deflation is a decline in prices, while inflation is an increase in prices - making them opposites. However, I'm guessing that the author is referring the effects of inflation and deflation not being opposite, or perhaps there are some differences when considering pure currency (the article is about bitcoin) vs. the effect of a currency in the market.</p>
","<p>People think that inflation is bad when it gets out of control, say when its more than 3 or 4% a year. The idea is that we all make economic decisions based on prices and its harder to make those decisions when the prices are constantly changing! Moreover, we try to avoid holding on to money and committing to a price for a long time, because we know those become meaningless over time. Also people associate inflation with the ills of fiat money, and other such things.</p>

<p>Deflation would seem to be not a big deal. You hold on to your cash, it buys more things as time passes! But, it turns out to be a big deal. Deflation turns the real interest rate paid by cash into a positive number. And that means that when the fed wants to lower rates a lot to get you to spend and borrow, it can´t lower them below that real rate. So it can't get you to spend and borrow -> economic fragility! Fed is powerless! So people are now scared to death of deflations! Even small ones seem to be hard to turn around. Japan has been flirting with deflation for a long time, unable to escape from its cold grip....</p>

<p>Therefore, to answer the question:
 Inflation and deflation can be defined as opposites: inflation is a <em>positive</em> rate of change of prices sustained over several periods while deflation is a <em>negative</em> rate of change of prices sustained over several periods. However, the effect of inflation and deflation on the economy are not opposites from each other, and policy-maker's concern for one and the other are different, but not the opposite of each other either.</p>
","11638"
"Why is there a structural deficit/surplus?","153","","<p>I'm going through Fiscal Policy and I'm reading about Structural Budget and Cyclical Budget. To my understanding, Cyclical Budget is what occurs when automatic fiscal policy is in use. So G and T are equal at full employment, if the economy falls into a recession, the automatic fiscal policy will trigger a cyclical deficit. </p>

<p>What I don't understand is the point of Structural Budget. Why is it run if the economy will return to full employment in the long run automatically? I understand that it gives an extra push but why don't we just let it handle it automatically? </p>
","<p>In terms of rule's logic, they are the same. The logic of structural budget is to provide stability and long-term planning to government spending. This is implemented by first finding the ""long-run"" revenue levels. Long run here means the economy in its potential. Additionally, for countries which rely a lot on some particular industries like natural resources (e.g. Copper in Chile), an estimation of the ""long-run"" price of such resources is required. These estimates are usually conducted by an independent, non-partisan, expert-based body, not affiliated with the government.</p>

<p>Once these revenues are defined, then a rule is chosen. It could be a balanced budget (all long-run revenues are spent), which is what you are calling Cyclical Budget, or a deficit/surplus, defined as % of total revenues, which is what you seem to refer to as Structural budget deficit/surplus. Either of these methods provide stability to spending, as the committee evaluating the long-term revenues of the government does this for several years in advance. </p>

<p>Why to chose a structural deficit/surplus? A structural surplus can be chosen to accumulate savings over time, and have a cushion in time of a crisis. In the case of Chile, the aim was to build a cushion in case the long-run price of Copper fell sharply, and long-term government revenues shrank considerably. Others might chose a deficit in order to provide a constant stimulus to the economy. Naturally, the size of the public debt is something to have in consideration regarding which rule to choose.</p>

<p>You can read a bit more about this rule, for the case of Chile, <a href=""http://www.dipres.gob.cl/594/articles-22592_doc_pdf.pdf"" rel=""nofollow noreferrer"">here</a> or <a href=""http://knesset.gov.il/mmm/oecd/Session_5_Klaus_SCHMIDT_HEBBE.pdf"" rel=""nofollow noreferrer"">here</a>. </p>
","17172"
"Difference between NPV and PDV","152","","<p>What is the difference between Net Present value and present discounted value when periods are given in infinity $\infty$ . Both are then equal to $\frac M r$? </p>
","<p>NPV and PDV are two different names for the same concept. If you were to receive M every year and the discount factor is $\delta$ then NPV = PDV = $\sum_{i=0}^{\infty}\delta^i M= \frac{M}{1-\delta}$.</p>
","14935"
"How can 1 BTC gain value in USD if inflation is happening?","152","","<p>So, right now, 1 BTC (bitcoin) is worth ≈ 578.25 USD. But, with the inflation of the USD, how can 1 BTC still hold its value at 578.25? Why doesn't it decrease?</p>

<p>Let's set this example:</p>

<p>1 BTC = 1 USD.</p>

<p>Then, the USD loses half of its value; 1 USD is now actually worth 0.50. </p>

<p>Why won't the BTC lose half of its value?</p>

<p>I guess this principle applies to any currency and I can't seem to grasp the idea.</p>

<p>So, any help will be appreciate. </p>

<p>I also hope that you can understand my question and if you need clarification, please ask! </p>
","<p>I'll try to fit this in an answer. I think you are confusing nominal and relative value. Inflation means that the 'value' of your money depreciates relative to other things. For example, in the year 2000 I could buy a bread for 1 USD. In the year 2015 I can buy a bread for 2 USD. This means that the dollar lost half of it's value relative to bread. But nominal 1 USD is still 1 USD and 1 bread is still 1 bread.</p>

<p>So in your example: today 1 BTC = 578.25 USD. If there is inflation of the USD (the value depreciates), then all else being equal BTC should appreciate against the USD (go up in nominal USD-value). So to work further with the bread-example. If in the year 2000 1 BTC would buy 500 USD then in 2015 1 BTC should buy 1000 USD. So the USD went down in value relative to BTC.</p>

<p>for more information:
<a href=""https://en.wikipedia.org/wiki/Purchasing_power"" rel=""nofollow"">https://en.wikipedia.org/wiki/Purchasing_power</a>
<a href=""http://www.investopedia.com/terms/c/currency-depreciation.asp"" rel=""nofollow"">http://www.investopedia.com/terms/c/currency-depreciation.asp</a></p>
","12338"
"Slutsky and Hicks approach in calculating SE, IE. Differences and interpretation","152","","<p>Level: Ungrad, Micro</p>

<p>I have a task, <a href=""https://imgur.com/a/JT4zB"" rel=""nofollow noreferrer"">http://imgur.com/a/JT4zB</a> I have done some questions. While I can't understand the differences between Slutsky and Hicks approach. I get it theoreticaly, but I don't know what differences would appear during solution. Please help with substitution-income effect calculation.</p>

<p>P.S. I have calculated substitution effect somehow, but I'm not sure wich approach that would be.</p>

<p>Any help is appreciated.</p>
","<p>Hicks compensation ensures that the consumer will reach the same utility level after the price/wealth change. (So graphically will be on the same IC)</p>

<p>Slutsky compensation ensure that the consumer can afford the old bundle after the price/wealth change. (so graphically rotates around the old bundle)</p>

<p>So when working out a problem, you can spot the difference when the consumer either has the same utility level, or can afford the same bundle. </p>
","13493"
"What would be the economic impact of the ""fair tax"" plan?","152","","<p>So I read about an interesting proposal about completely replacing income tax with a heavy national sales tax of about 30% (23% inclusive to compare to income tax).</p>

<p>I was thinking about what the impact of this would be. On one end, income goes up both because people would want to work more and they get to keep everything they earn.</p>

<p>On the other end, prices go up because of the sales tax. I was also learning that spending is crucial for short term economic growth, so that may hurt. But does the laffer curve apply to sales tax as well? People may buy more frequently if it went down, increasing tax revenue. I know the laffer curve is unreliable, but it was just a thought.</p>

<p>Is this thinking process correct, or would the fair tax be a complete disaster? I apologize I just got interested in economics so I don't know much.</p>
","<p>Well, one advantage to a sales tax is that it affects everyone (even those who don't pay income taxes). However, some people may see that same fact as a problem. This problem lies in analysis of the equity of the tax. When we consider every single person being taxed 30% on everything they buy, we need to think about how that affects different income groups. Lower income groups spend a much larger portion of their income on consumption, which means that they will be taxed relatively much more heavily than high income groups. This fact alone is enough to discourage this sort of action because the government tries to encourage saving in the lower income groups (so they can move up to higher income levels). This is one large reason why a tax like this may not be as fair as the name makes it seem.</p>

<p>Another piece of information that must be considered is the incidence of the tax. As we know, the incidence of a sales tax depends upon the relative own-price elasticities of supply and demand. This means that in a market with very inelastic demand (such as cigarettes or oil), the buyer is paying most of the tax whereas in a market with elastic demand the sellers would pay most of the tax. This fact would make it so that different industries would end up paying a different amount of the sales tax compared to one-another. For example, an oil company would end up paying much less of the percentage of the tax than a company making a selfie stick. This, again, seems to be unfair. </p>
","11129"
"Why does falling global bond yields signal coming deflation","152","","<p>In <a href=""http://www.telegraph.co.uk/business/2016/07/02/bond-yields-are-pricing-in-a-depression-and-the-prognosis-scarce/"" rel=""nofollow"">this article</a>, it suggests that, ""Bond markets are signalling something very nasty coming down the road at us – an all encompassing, worldwide deflation. ""</p>

<p>I cannot understand why bond yields falling signals deflation. Is it because falling bond yields is an indicator of a weakening global economy or is there a more direct transmission mechanism?</p>
","<p>Bond yields falling from their current near-zero position will place them in negative yield territory. Negative bond yields are deflationary by definition.</p>

<p><a href=""http://www.telegraph.co.uk/business/2016/07/02/bond-yields-are-pricing-in-a-depression-and-the-prognosis-scarce/"" rel=""nofollow"">Paragraph 3, sentence 5 of the article says</a>:</p>

<blockquote>
  <p>With Bank Rate already close to the floor, and some UK bond yields now in <strong>negative territory</strong>... <em>[emphasis added]</em></p>
</blockquote>

<p>To understand why negative bond yields are deflation markers, consider the example of negative Asian and European central bank rates described in the same article:</p>

<blockquote>
  <p>This is because a negative rate is effectively just a tax on the banks, forcing them to pay for the privilege of holding reserves with the central bank.</p>
  
  <p>Someone has to shoulder the burden of this tax; either borrowers pay more, or depositors get less, or profits go down, and if it is the latter, then it damages the banking sector’s ability to rebuild capital, crimping credit availability accordingly. Whichever it is, the end result is a monetary tightening, rather than the loosening intended.</p>
</blockquote>

<p>So you can think of the effect of negative central bank rates (and, similarly, negative bond yields) as having the inverse impact as quantitative easing which creates an inflationary effect.</p>

<p><a href=""http://thismatter.com/money/banking/money-growth-money-velocity-inflation.htm"" rel=""nofollow"">This page explains the relationship between prices and money supply as follows</a>:</p>

<p>$$P=\frac{MV}{Y}$$</p>

<p>where $P$ represents prices, $M$ is the money supply, $V$ is the velocity of money and $Y$ is the real GDP.</p>

<p>Therefore,</p>

<p>$$\Delta P = \Delta M \cdot \frac{V}{Y}$$</p>

<p>and for constant $V$ and $Y$,</p>

<p>$$\frac{\partial P}{\partial M} = \frac{V}{Y} &gt; 0$$</p>

<p>So an effective restricting of the money supply caused by negative rates/yields via the mechanism above described will tend to put downward pressure on prices (a/k/a <em>deflation</em>).</p>

<p><strong>Edit</strong>:</p>

<p>In the comments to this answer, OP asked about the relationship between negative interest rates and negative bond yields.</p>

<p>Whereas central banks set rates by policy, long term bond yields are determined by the market (i.e., supply-demand equilibrium). An inverted yield curve signals recession and implies rates are set too high relative to market expectations. If central banks set rates in positive territory when long term bond yields are negative, they will <em>de facto</em> force the yield curve to invert. Although this sometimes happens, it is usually counterproductive to the policy goals of the central banks (in most environments) and, therefore, typically avoided.</p>
","12614"
"CES preferences intuition","151","","<p>I asked this question on math.stackexchange but deleted it from there and brought it here.</p>

<p>I had a question about Constant Elasticity of substitution type preferences of the form: $$U=\int_{0}^{1}(c(\omega)^{\rho}d\omega)^{\frac{1}{\rho}}$$
 where the paramter $\rho$
  governs the degree of substitutability between goods. Here, $c(\omega)$
  represents consumption of good $\omega$
  which exists on the unit interval. As such, this type of preference specification aggregates over consumption of different goods.</p>

<p>My question is as follows. I have always thought of integrals of the form: $$I=\int f(x)dx$$
  as approximating sums of areas of infinitesimally small rectangles (in terms of their base) and heights being determined by $f(x)$
 . In the case of the example above, what really is $c(\omega)$
 ? Is it a function?</p>
","<p>It is my impression that the correct expression for ""Dixit-Stiglitz"" preferences is </p>

<p>$$U=\left(\int_{0}^{1}c(\omega)^{\rho}d\omega\right)^{\frac{1}{\rho}}$$</p>

<p>which then can be seen as a continuous incarnation (in [0,1]) of, say</p>

<p>$$\left (\sum_{i=1}^na_i\omega_i^{\rho}\right)^{\frac{1}{\rho}}$$</p>

<p>with $c(\omega_i) = a_i^{1/\rho}\omega_i$.</p>

<p>In other words, a definite (Riemann) integral is indeed conceived as a sum of infinitesimally small rectangles, but it can also be seen as the continuous incarnation of a sum.</p>

<p>A formal link between an integral and a sum is provided by the <strong><a href=""https://en.wikipedia.org/wiki/Euler%E2%80%93Maclaurin_formula"">Euler-MacLaurin formula</a></strong>.</p>
","9625"
"Do the donated NFL losing team shirts destroy local economies?","151","","<p>I've recently become aware of the fact that the NFL prints both championship teams' shirts in advance to satiate incredible demand -- but instead of destroying the losing teams' shirts like they used to, they instead <a href=""http://mentalfloss.com/article/29884/what-happens-losing-teams-championship-shirts"" rel=""nofollow"">donate them to third-world countries</a>. But the thought of flooding these local economies with free shirts, which doesn't create jobs, GDP, and hurts local clothing business, seems like it would be terrible for the economy. Is this indeed the case?</p>
","<p>My answer is no, it doesn't hurt the local economy. This seems like an example of the ""<a href=""https://en.wikipedia.org/wiki/Parable_of_the_broken_window"" rel=""nofollow"">Broken Window Fallacy</a>"":</p>

<p>Suppose, when nobody is looking, I break all of the windows in my neighbour's house. This creates a bunch of work for a glazier who might otherwise have been idle. So it seems like, by going round smashing things up we can provide a boost to the economy. Surely this must be wrong!?</p>

<p>Indeed, the problem with this logic is that we have to think what would happen if I had not broken the windows. My neighbour, not having to incur the expense of replacing his windows, would have some extra money to spend on a hair cut or a new bicycle, creating work for a barber or a bicycle maker. If the windows are broken then those guys miss out.</p>

<p>So the glazier earns some extra income and gains; the barber earns less income and looses. But these two things ""cancel out"": this is just a transfer of wealth from one person to another rather than the creation of new wealth. My neighbour, on the other hand, definitely loses because he doesn't get a hair cut any more. So overall, the broken windows are a net loss to society.</p>

<hr>

<p>The reason I think this is relevant to your question is that we could reframe it as: ""if we burnt the shirts [broke the windows] instead of giving them away for free, wouldn't that create work for a tailor and therefore make society richer?""</p>

<p>I think the answer is no because, freed from the need to buy a shirt, people have more income to spend on food, educating their child, taking care of their health, etc. All of these things create jobs in the local economy to replace the lost jobs in the clothing industry.</p>

<p>It is true that the tailors lose out at the expense of the farmer, teacher, or nurse. But over long time horizons people will adjust to this by training to do the jobs that pay. </p>

<hr>

<p><strong>tldr;</strong> Destroying real resources may create winners and losers, but is almost always bad for society overall.</p>
","13051"
"Evidence on economic impact of 2015 European refugee/migrant influx","151","","<p>At the time of writing (September 2015), Europe is dealing with a large influx of refugees/migrants. Many are fleeing violence in Syria and elsewhere, others come from Africa and the Middle East in search of economic opportunity.</p>

<p>I am interested in knowing <em>what is the current state of the art in understanding the net economic impact of these inflows for the recipient countries</em> in North Western Europe? I am interested in impact along a wide range of dimensions, growth, employment, etc.</p>

<p>In particular, I am interested in evidence that allows us to account for the specific demographic and skills profiles of these migrants. Assuming that the migrants reflect the typical UK asylum seeker, some demographic information can be seen <a href=""http://migrationobservatory.ox.ac.uk/briefings/migration-uk-asylum"">here</a>. The majority are male, between 20 and 50. At least in the current ""crisis"", the majority of migrants appear to be muslim, if that is of any consequence. I was not able to find information about skills.</p>
","<p>I didn't see the evidences on the recent European immigration, but the event is similar to the Mariel Boatlift story in Card (<a href=""https://ideas.repec.org/p/nbr/nberwo/3069.html"" rel=""noreferrer"">1990</a>):</p>

<blockquote>
  <p>The Mariel immigrants increased the population and labor force of the Miami metropolitan area by 7 percent. Most of the immigrants were relatively unskilled: as a result, the proportional increase in labor supply to less-skilled occupations and industries was much greater. Nevertheless, an analysis of wages of non-Cuban workers over the 1979-85 period reveals virtually no effect of the Mariel influx. Likewise, there is no indication that the Boatlift lead to an increase in the unemployment rates of less-skilled blacks or other non-Cuban workers. Even among the Cuban population wages and unemployment rates of earlier immigrants were not substantially effected by the arrival of the Mariels.</p>
</blockquote>

<p>That's for a 7% shock. In contrast, Europe experience a 0.1% shock in labor supply. Maybe the only difference we'd find will be in the areas where immigrants settle densely.</p>

<p>For more reading:</p>

<ul>
<li>Card, “<a href=""https://ideas.repec.org/a/aea/aecrev/v99y2009i2p1-21.html"" rel=""noreferrer"">Immigration and Inequality</a>”;</li>
<li>Card, “<a href=""https://ideas.repec.org/a/ecj/econjl/v115y2005i507pf300-f323.html"" rel=""noreferrer"">Is the New Immigration Really so Bad?</a>”</li>
</ul>

<p>In general, economists suggest that low-skilled natives suffer a bit from an influx of low-skilled immigrants (but again, we're talking about large numbers, >1% of population):</p>

<p><a href=""https://i.stack.imgur.com/khjly.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/khjly.png"" alt=""enter image description here""></a></p>

<ul>
<li><a href=""http://www.igmchicago.org/igm-economic-experts-panel/poll-results?SurveyID=SV_5vuNnqkBeAMAfHv"" rel=""noreferrer"">http://www.igmchicago.org/igm-economic-experts-panel/poll-results?SurveyID=SV_5vuNnqkBeAMAfHv</a></li>
</ul>
","8188"
"Is there an economic term for decreased demand due to expected decrease in price due to a product's value lasting for a finite amount of time","151","","<p>So, at work we are doing a charity bake sale.</p>

<p>Lunch hour is long gone. An email was sent out offering everything at half price.</p>

<p>I imagine decreased demand as everyone knows they have to get rid of it all by the end of the day, therefor everyone will expect the price to decrease further, therefor people will not buy due to the expectation of lower prices when an item is only of value for a finite amount of time.</p>

<p>Is there an economic term to describe this situation?</p>
","<p>You are describing a market where a ""non-storable"" (or ""perishable"") good is traded. This is <em>the</em> (in terms of historical precedent) model of a market, since in the old days, most goods were agricultural, and many amongst them were ""non-storable"".  </p>

<p>The argument behind ""market clearing"", i.e. that prices will adjust so that all quantity available will be sold, owes a lot to the goods being non-storable. You can observe this today in the so-called ""farmer's markets"", where if you monitor a day of trading, you will observe that prices go down as the day nears to an end, as suppliers attempt to sell all their quantity.</p>

<p>Why some consumers nevertheless buy early on and so at higher prices, even though they know that later on prices will go down, has to do with  </p>

<p>a) constraints imposed on the consumer schedule (say, he <em>has</em> to buy early because he has to prepare lunch), and/or  </p>

<p>b) quality considerations: early on the suppliers may give you more room to ""pick and choose"" item per item, or  they themselves will offer the better quality, to justify the higher price. It may be the case that some consumers have a lexicographic preference over a certain threshold of quality, which they expect it won't be around at the end of the day when prices will fall.  </p>

<p>On the other hand, some consumers will hold on, given their constraints/preferences. As you can see, the phenomenon of <em>all</em> consumers waiting till ""the last minute"" presuposes a situation were the consumers are perfectly ""flexible"", and the quality of the good does not deteriorate with time, but the good looses all its ""good-properties"", instantly, at the end of its ""useful life"". In reality quality erodes gradually, in almost all cases.</p>
","4901"
"Quantum Game Theory","150","","<p>This is a request for recommendations. I want to learn quantum game theory. Can anyone suggest where to begin with, some reading materials. (I am well versed in Non-Cooperative Game Theory, so you can assume my aptitude.) That would be very helpful. Thank you!</p>
","<p><a href=""https://arxiv.org/pdf/quant-ph/0506219.pdf"" rel=""noreferrer""><strong>An Introduction to Quantum Game Theory</strong></a> by J. Orlin Grabbe. </p>

<p>There is also <a href=""https://mathoverflow.net/a/135796"">a related question on MathOverflow</a>, answered by <a href=""https://economics.stackexchange.com/users/250/steven-landsburg"">Steven Landsburg</a> (also a member of Econ.SE) that might be of interest to you.</p>
","16762"
"A doubt on the Regression of Mankiw, Romer, Weil 1992 paper","149","","<p>I'm trying to replicate the regression of the <a href=""http://dx.doi.org/10.2307/2118477"" rel=""nofollow"">MRW 1992</a> paper.
(<a href=""https://www.nuffield.ox.ac.uk/teaching/economics/bond/mrw.dta"" rel=""nofollow"">Here's</a> the data, if you're interested)</p>

<p>In the same page where the data set is available, there's this <a href=""https://www.nuffield.ox.ac.uk/teaching/economics/bond/OLS%20Regression%20Using%20Stata.pdf"" rel=""nofollow"">handout</a> explaining how to replicate the results. In page 2 of this handout, we can see two simple stata commands: </p>

<pre><code>li_y=ln(i_y/100) 
 g lpop=ln(0.05+popgrowth/100)
</code></pre>

<p>My question is why the variables <code>i_y</code> (this is Investment over GDP), and <code>popgrowth</code>(this is an averaged population growth rate between 1960-1985) are divided by 100?</p>

<p>Nowhere in the MRW 1992 paper, do I read something telling me that it's necessary to divide it by 100, or do I?</p>

<p>Any help would be appreciated</p>
","<p>I had a look at the data, and it is like @denesp says in his comment: e.g. a $2.60\%=0.0261$ population growth rate is written as $2.60$, a $24\%=0.24$ investment-to-output ratio is written like $24.0$, etc. 
So they must be divided by $100$.</p>
","11303"
"Isoquant creator","149","","<p>I was wondering if anyone had an idea about the first author to have mathematically computed an isoquant or at least the first occurrence of a drawn isoquant ? My best guess would be F. Edgeworth in <em>Mathematical Psychics: An Essay on the Application of Mathematics to the Moral Sciences</em> (1881) but I really doubt it !</p>
","<p>A recently published (and perhaps the only one) paper on the matter is</p>

<p><a href=""http://hope.dukejournals.org/content/44/4/643.short"" rel=""nofollow noreferrer""><strong>Lloyd, P. (2012). The Discovery of the Isoquant. History of Political Economy, 44(4), 643-661.</strong></a></p>

<p>From the Introduction :</p>

<blockquote>
  <p><em>""The absence of a history of the isoquant is in marked contrast to the universal recognition that F. Y. Edgeworth (1881) invented the
  concept of the indifference curve. It turns out that the isoquant does
  have an interesting history of multiple discoveries or apparent
  discoveries. Section 1 outlines the first appearances of the isoquant,
  as far as I have been able to trace them, in chronological order. The
  contributions of two originators, namely, A. L. Bowley and Charles W.
  Cobb, seem not to have been noted before. Section 2 discusses the
  obvious question of why the discovery of the isoquant was not made
  until more than forty years after the discovery of the indifference
  curve, when to a modern analyst the isoquant appears isomorphic to the
  indifference curve and could have been copied straight from utility
  theory.""</em></p>
</blockquote>

<p>In Section 1 we read (p.645)</p>

<blockquote>
  <p><em>""The first unquestionable appearance of isoquants is in Bowley 1924""</em></p>
</blockquote>

<p><strong>(Bowely, A. L. 1924. The Mathematical Groundwork of Economics: An Introductory Treatise. Oxford: Clarendon Press)</strong></p>

<p>Lloyd reproduces the figure to be found in Bowley:</p>

<p><a href=""https://i.stack.imgur.com/MX7uN.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MX7uN.png"" alt=""enter image description here""></a></p>

<p>As for the term ""isoquant"" Lloyd writes</p>

<p><em>""In his second note on the elasticity of substitution in the same
journal, Lerner (1934) called the curve the “isoquant.” This is one of the
first uses of the term isoquant in the English-language literature.</em>""</p>

<p><strong>(Lerner A.P. 1934. “Notes on Elasticity of Substitution II.” Review of Economic Studies 1(2): 147–48.)</strong></p>

<p>As regards the question ""why isoquants took so long after the indiferrence curves invention"", from the three possible (and not antagonistic) explanations that Lloyd puts forward I find very interesting the third one: in his words (p. 658) (bold my emphasis)</p>

<blockquote>
  <p><em>""Following the practice of the English classical writers, <strong>all</strong> neoclassical writers on production and distribution theory
  distinguished a <strong>trilogy of factors—land, labor, and capital</strong>.""</em></p>
</blockquote>

<p>So if your mind is fixed to thinking <em>three</em> inputs, (and a very realistic triplet at that), you won't go easily into thinking just two of them  -and realize that you can represent them graphically.</p>
","11816"
"Regression over the whole population","149","","<p>What's the meaning of the standard error of a coefficient in a regression when the whole population is included?</p>

<p>I've been so puzzled by this question. Because it seems to me, standard errors make no sense when the whole population is included -- there is no need for statistical inference since you already have the whole population.</p>

<p>But it is so widely used even by many articles published in top journals. For example, if I am examining the relationship between a country's GDP growth rate and its population density, I run the regression:</p>

<p>$$ GDP_i = \alpha + \beta Pop_i + \gamma \mathbf{X}_i + \epsilon_i$$</p>

<p>with all 195 countries on the earth. In the case, all countries (the population) are included. But all literature still talk about the statistical significance of the coefficients. </p>

<p>Could somebody explain is it a misuse of statistical inference when regressing over the whole population?</p>
","<p>I had initially flagged this question for moderators to examine whether it would be better to migrate over to the statistics SE site Cross Validated. But since the OP introduced a very specific econometrics example, I believe the (very deep) concept of ""population/sample"" can be usefully discussed for the purposes of this example.</p>

<p><strong>A first issue</strong> is that discussed in @AdamBailey answer: if one considers ""all the countries in the world"" for a given year or years, and it labels the data as ""population"", then the next year should belong to a different population. If it belongs to a different population, then how are we to use results from one population to make inference for another population? So indeed, here our ""population"" is <em>two-dimensional</em>, country <em>and</em> time period -and in that sense, with the time horizon open-ended, we only have a sample in our hands.</p>

<p><strong>The second issue</strong> (partly implied in @luchonacho answer) is the following: our population is not the actually <em>observed realizations</em> of the random variables ""$GDP_i, i=1,..n$. This is the data. Our population is the collection of random variables themselves, which are functions, not values. </p>

<p>So our data is just one of the possible combined realizations of these random variables. These realizations came about not only as a result of deterministic/engineering relations/causality (reflected in the coefficients), but also under the effect of inherently random factors. In that sense, the data is not a ""pure/typical"" image of the ""population"" -it contains noise, non-structural disturbances, one-off shocks etc. </p>

<p>Then this uncertainty will carry over to the estimation of the coefficients we are trying to estimate, because we assume that these coefficients describe causality or co-movement prior to the random elements affecting the final value of the dependent variable.</p>

<p>Due to both aspects above, talking about ""standard error of estimates"" is totally valid, in this case too, and then apply statistical tests as usual.</p>
","18098"
"The phase diagram for the simple RBC model","149","","<p>I'm reading these <a href=""http://www3.nd.edu/~esims1/rbc_notes_2016.pdf"" rel=""nofollow"">notes</a> in the RBC model. In page 14, the author, tries to explain the direction of the arrows, in the space $(\tilde C_t,\tilde K_t)$ (tilde refers to proportional deviations from steady state) , to explain the dynamics. </p>

<p>If I look at equations (47) and (49), the ones that are used to derive the isoclines (equations (50) and (51)), I do not understand how to see the directions  Up/Down, Left/Right... </p>

<p>Any help would be appreciated.</p>
","<p>There are two tricks to safely construct a phase diagram, as regards the dynamics off it.</p>

<p>First, solve for the ""isoclines"" as <em>weak inequalities</em> rather than as equalities. This method makes also clear the dynamics <em>off</em> the isocline.  </p>

<p>Consider a standard capital accumulation equation</p>

<p>$$K_{t+1} = (1-\delta)K_t + F(K_t) - C_t \tag{1}$$</p>

<p>We want to obtain the isocline, but also the dynamics off it. Re-write as</p>

<p>$$K_{t+1} - K_t  = -\delta K_t + F(K_t) - C_t$$</p>

<p>Now require that </p>

<p>$$K_{t+1} - K_t \geq 0 \implies -\delta K_t + F(K_t) - C_t \geq 0$$</p>

<p>$$\implies C_t \leq F(K_t) - \delta K_t \tag{2}$$</p>

<p>With equality, $(2)$ is the expression for the isocline. The inequality tells you that for capital to tend to increase ($K_{t+1} - K_t &gt; 0$), consumption must be <em>lower</em> than the level indicated by the isocline. Etc</p>

<p>The second trick is already used in $(2)$: although this is the capital difference equation, I wrote it as though it is an expression determining consumption. In this way, one can look at the phase diagram and for both difference equations, treat the variable in the vertical axis as the ""dependent"" variable of the two isocline functions. This is the most natural to the eye, and helps avoid the up/down, right/left confusion that can result if one tries to rotate in its mind the phase diagram, for one of the two equations. It also makes easier to determine the slope/shape of the two isoclines.</p>
","11081"
"Are many of the traditionally oil dependent Gulf states really successfully diversifying their economies?","148","","<p>I've often heard the claim that many Persian Gulf states are successfully diversifying their economies away from oil (e.g. <a href=""http://gulfnews.com/business/economy/diversification-raises-non-oil-share-of-uae-s-gdp-to-71-1.795268"" rel=""nofollow"">non-oil share of UAE's GDP is 71%</a> and <a href=""https://www.cia.gov/library/publications/the-world-factbook/geos/sa.html"" rel=""nofollow"">in Saudi Arabia, non-petroleum sectors account for 55% of GDP</a>).</p>

<p>The IMF has the 2015 GDPs per capita of the UAE and Saudi Arabia at \$35392 and \$20139, respectively. If we naively multiply by 0.71 and 0.55, we get that their non-oil GDPs per capita are \$25128 and \$11076. \$25128 is greater than the GDPs per capita of countries such as Portugal and Poland, and \$11076 is greater than those of Mexico and Turkey.</p>

<p>I'm rather surprised by this, as I've always assumed that countries such as Portugal and Mexico would be well ahead of the UAE/Saudi Arabia in terms of development/education/technology etc.</p>

<p>Are the 71% and 55% figures (and similar claims for other Gulf states) misleading in some way? </p>

<p>i.e. Are most of the non-oil sectors in these countries still somehow mostly based on oil (and would they substantially shrink/collapse if the oil ""ran out"")?</p>
","<p>Is the Saudi economy still almost entirely driven by fossil fuels?</p>

<p>Yes.</p>

<p>Does that mean that the 55% figure (% of GDP representing by oil &amp; gas) is misleading?</p>

<p>No.</p>

<p>They sell lots of fossil fuels. All that money then gets spent on housing, food, education, luxury goods, and so on. So, roughly speaking, all other things being equal, all that money goes round the economy about twice - once as oil transactions, and once for all the things that are paid for by selling oil.</p>

<p>Remember that GDP is just an aggregate total value of transactions. Not productivity, not wealth generation, just transaction value.</p>
","10038"
"Intuition behind fixed effects estimator","148","","<p>I understand that the fixed effects estimator in a panel model (say, individuals, $i$ across years, $t$) can be understood either as a including a dummy for each $i$ or running OLS on the time demean-ed data. My question is whether the estimate from the FE model (that is, the within estimator) is equivalent to the average of the estimates from running OLS on each individual separately. Consider the following two approaches:</p>

<p>$y_{it} = constant + \beta x_{it} + v_i + u_{it}$</p>

<p>$y_t = constant + \alpha x_t + e_t$ for all $i \in (1, 2, ... N) $</p>

<p>The second equation gives us an $\alpha^i$ for each individual and my question is whether $\beta =  \frac{1}{N} \sum_i^N \alpha^i$</p>
","<p>I asked exactly the same question on math.stackexchange:</p>

<p><a href=""https://math.stackexchange.com/questions/1470490/fixed-effects-estimation"">https://math.stackexchange.com/questions/1470490/fixed-effects-estimation</a></p>

<p>In short, the answer is yes, it can be viewed as running separate OLS regressions- the weights, however, are not arbitrary. It is a weighted average of the separate OLS regressions.</p>
","10961"
"Is the basic RBC model a weak model?","148","","<p>There are a plethora of examples of weaknesses in my textbook, such as:</p>

<ol>
<li>The Walrasian assumption</li>
<li>Not including nominal shocks</li>
<li>Not including indivisible labour</li>
<li>Not including distortionary taxes</li>
<li>Not including multiple sectors and sector specific shocks</li>
</ol>

<p>In my opinion the greatest weakness is the Walrasian assumption, as I think this is not too realistic in the real world.</p>

<p>I think we want to measure degree of weakness by how closely we see the results posited by the model exhibited in the real world. </p>

<p>So if you have read some articles that improve on the basic RBC model, what are the common extensions (1-5, or other) that you see that address these weaknesses?</p>
","<h3>When is a model really weak?</h3>

<p>A model is an abstraction of reality, to explain a part of it. A model is weak when it cannot explain what it's supposed to be explaining. Just adding features to a model has no intrinsic good. It's much different from a fruit salad, where usually, an increased variety in fruits will lead to a better taste. Here, adding more features makes it hard to understand which feature of the model was necessary to generate the result observed.</p>

<p><em>For example</em>, When your focus is on variation of labor-supply within different income and skill groups, yes, lack of distortionary taxes could be a problem. If the model is not aimed at doing that, and it does fulfill its purpose without requiring those taxes, the lack therein is not a problem.</p>

<h3>The most basic RBC model</h3>

<p>There is no single RBC model. It's most simple (but not representative!) version is the seminal Kydland and Prescott (<a href=""http://www.jstor.org/stable/1913386"" rel=""nofollow noreferrer"">1982</a>) paper. It lacks all those features that you mention, but it is aimed at explaining variations and correlations in output, investment, capital and labor. If it does that job well (<a href=""https://economics.stackexchange.com/a/5306/43"">I'm not going into that discussion here</a>), it is a good model, and the lack of those characteristics is not a weakness.</p>

<h3>The class of RBC models</h3>

<p>The general RBC class of models are those, where variation along the balanced growth path is caused by (random) shocks to productivity. Of course, no economist really believes that a random number generator is attached to each firm and causes fluctuations in output. It's a simplification.</p>

<p>Hence, if you are after a weakness behind the RBC model in general, it ought to be that you believe that this simplification is false. That, whatever the reason for business cycle fluctuations we observe is not caused at the productivity wedge. </p>

<p>For example, some neokeynesian economists believe that it could be mood shocks. People sometimes are more or less lazy, and that recessions go really bad when you people really don't want to work (again, this is a simplification, but the point is that the relevant wedge is not at the output margin, but at the labor-supply and consumption wedge). A critique of these shocks to the household's objective function can be found in Chari, Kehoe, McGratten (<a href=""http://pubs.aeaweb.org/doi/abs/10.1257/mac.1.1.242"" rel=""nofollow noreferrer"">2009</a>).</p>

<p>These productivity shocks are, in the simple one-sector model that is mostly used isomorphic to shocks to technology. However, this doesn't mean that they necessarily are caused by them (<em>hint at @Mustang</em>). For example, Acemoglu and coauthors (<a href=""http://economics.mit.edu/files/8135"" rel=""nofollow noreferrer"">2012</a>) show how mathematically small shocks within firms and sectors (such as variations in the cost function, e.g. unexpected oil price changes), usually cancel each other out, but sometimes aggregate up to great shocks over the whole economy.</p>
","11269"
"Ito's Lemma derivation","148","","<p>I'm getting into asset pricing and was looking at Ito's Lemma, but cannot understand a few steps that are given.</p>

<p>Ito's Lemma states that given</p>

<p>$$dx_t = \mu dt + \sigma dz_t \\
y_t = f(t, x_t)$$</p>

<p>then</p>

<p>$$(1) \quad dy_t = \frac{\partial f}{\partial t} dt + \frac{\partial f}{\partial x} dx_t + \frac{1}{2} \frac{\partial^2 f}{\partial x^2} dx^2_t \\$$</p>

<p>I understand this part using chain rule and a second order Taylor expansion, of the second equation. I don't understand why then the following holds:</p>

<p>$$(*) \quad dy_t = \left[\frac{\partial f}{\partial t} + \frac{\partial f}{\partial x} \mu + \frac{1}{2} \frac{\partial^2 f}{\partial x^2} \sigma^2 \right] dt + \left[  \frac{\partial f}{\partial x} \sigma \right] dz_t \\$$</p>

<p>When I substitute in $dx_t$ into $(1)$ and use the fact that $dz^2_t = dt$, it isn't enough to arrive at $(*)$. I think $dx^2_t$ can literally be interpreted as $(dx_t)^2$, but if there is a better way of handling that term, any guidance there would be appreciated.</p>
","<p>$$dx_t = \mu dt + \sigma dz_t \\
y_t = f(t, x_t)$$</p>

<p>A key idea here is that $\left( dx_t \right)^2=\left( \ldots \right)dt^2 + \left(\ldots\right) dzdt + \sigma^2 dz_t^2 = \sigma^2 dt$. The loose reasoning is that $\left( dz_t\right)^2 = dt$ and all the other terms (i.e. $dt^2$ and $dz\, dt$) are <em>infinitely</em> smaller than $dt$.</p>

<p>Horribly loose intuition for $dz_t^2 = dt$ is that $dz_t$ is normally distributed with variance $dt$, and hence the expectation of the square of $dz_t$ is $dt$.</p>

<p>In any case, we then have:</p>

<p>\begin{align*}
\quad dy_t &amp;= \frac{\partial f}{\partial t} dt + \frac{\partial f}{\partial x} dx_t + \frac{1}{2} \frac{\partial^2 f}{\partial x^2} dx^2_t\\
&amp;= \frac{\partial f}{\partial t} dt + \frac{\partial f}{\partial x} \left( \mu dt + \sigma dz_t  \right)+ \frac{1}{2} \frac{\partial^2 f}{\partial x^2} \sigma^2 dt \\
&amp;= \left(\frac{\partial f}{\partial t} + \frac{\partial f}{\partial x}\mu + \frac{1}{2} \frac{\partial^2 f}{\partial x^2} \sigma^2 \right)  dt + \left( \frac{\partial f}{\partial x}\right)\sigma dz_t
\end{align*}</p>

<p>Which is Ito's lemma.</p>
","13670"
"Perfect risk sharing in Arrow-Debreu w/ the same subjective beliefs over states","148","","<p>So I'm looking at a 2-agent Arrow-Debreu economy with one good. Consumption and endowments are zero in t=0, and 2 states are possible in t=1 with aggregate endowment in both states equal to 1. </p>

<p>We assume utility is strictly increasing and strictly quasiconcave. My question is this:</p>

<p>My professor says by strict monotonicity </p>

<p>$\dfrac{v^{'}_{1}\left(x^1_1\right)}{v^{'}_{1}\left(x^2_1\right)} = \dfrac{v^{'}_{2}\left(1 - x^1_1\right)}{v^{'}_{2}\left(1 - x^2_1\right)} \Rightarrow x^1_1 = x^2_1$</p>

<p>I can see this is obviously true if $v(\cdot)$ is concave, but we only have strict quasi-concavity. For example $f(x) = x^2$ is strictly convex yet strictly quasiconcave. Since agent 1 and agent 2 are not required to have the same utility function, it is possible for agent 1 to have a convex utility and agent 2 to have a concave one. In short, we cannot say the second derivatives are the same sign without the concavity assumption. </p>

<p>Moreover, wouldn't a counter example be aif $v_i(x) = x$ for $i = 1,2$. Then $x_1^1 \neq x_1^2$ would still imply the ratio holds. Is it then something about an interior solution?</p>
","<p>In two details you seem to be mistaken:</p>

<ol>
<li>You need strict concavity of $v(\cdot)$, not concavity.</li>
<li>According to the <a href=""https://en.wikipedia.org/wiki/Quasiconvex_function"" rel=""nofollow"">definition</a> of quasiconcavity, the function $x^2$ is not quasiconcave, it is quasiconvex.</li>
</ol>

<p>Your main point is correct. If both functions are linear, then $x_i^1 = x_i^2$ no longer needs to hold, as the goods $x_i^1$ and $x_i^2$
are perfect substitutes for consumer $i$. Hence all consumption decisions are correct as long as $i$ trades at a price ratio of 1. This is indeed the equilibrium price ratio. The same can be said for the other consumer.</p>
","6117"
"Proving the De Finetti Theorem","148","","<p>Let us have a finite state space, $\Omega = {\omega_1,\cdots,\omega_s}$, where $2 \leq s &lt; \infty$. Define a bet as a function $x:\Omega \rightarrow X$, where $X \subseteq \mathbb{R}^s$ is the set of monetary outcomes. Assume that the agent only cares about expected payoffs. Let $\succcurlyeq$ be a rational, continuous preference relation on $X$.</p>

<p><strong>Additivity:</strong>
$$\forall x, y, z \in X, \text{then} \ x \succcurlyeq y \iff x+z \succcurlyeq y+z$$</p>

<p><strong>Monotonicity</strong>
$$\forall x, y \in X, \text{then} \ x \geq y \iff x \succcurlyeq y$$</p>

<p><strong>Non-Triviality</strong>
$$\exists x, y \in X, \text{s.t.} \ x \succcurlyeq y$$</p>

<hr>

<p><strong><em>De Finetti Theorem</em></strong></p>

<p>$\succcurlyeq$ on $X$ is rational, continuous, additive, monotonic, and nontrivial if and only if</p>

<p>$$\exists p \in \mathbb{R}^s \setminus {0} = \{p \in \mathbb{R}^s \mid \sum^s_{i=1} p_i = 1, \ p_i \in [0,1] \ \forall \ i \}$$</p>

<p>s.t. $\forall x,y \in X$, we have $x \succcurlyeq y \iff p \cdot x \geq p \cdot y$</p>

<p>Moreover, p is unique.</p>

<hr>

<p>So my professor has asked us to prove the De Finetti Theorem, in which she told us that:</p>

<p>First, prove that $\succcurlyeq$ is rational, continuous, additive, monotone, and nontrivial.  </p>

<p>$$( \exists \ p \quad \text{s.t.} \ \forall x,y \ \text{and} \ x \succ y \Leftrightarrow px \geq py )$$</p>

<p>Use the uniqueness of p with a proof of contradiction using:</p>

<p>Assume $\succcurlyeq$, then suppose $x \succcurlyeq y$ but $px &lt; py \ \forall \ p$. Then suppose $px \geq py, \ y$  but $y \succ x \ \forall \ p$.</p>

<p>Second, let $U(\lambda) = px$, then show the property holds.</p>

<p>Then with the uniqueness of $p$, let $s = 2 \rightarrow ( p , 1- p)$</p>

<p>Consider $x \sim y$, and then suppose $p$ is not unique $\rightarrow$ $( p + \epsilon , 1 - p - \epsilon )$.</p>

<p>$\epsilon \in \mathbb{R}$</p>

<p>So the question is: how do I construct $\epsilon$ for it to be consistent with the model? Any help would be appreciated in applying the outline of this proof.</p>
","<p>Here was my attempt at a proof:</p>

<p><em>First let us look at the ""if"" case.</em></p>

<p>Assume $\succcurlyeq$ on $X$ is rational, continuous, additive, monotonic, and non-trivial.</p>

<p>BUT</p>

<p><strong>Case 1:</strong> $x \succcurlyeq y$ and $p \cdot x &lt; p \cdot y \ \forall p$</p>

<p>Suppose $p = \{\frac{1}{s} \cdots \frac{1}{s}\}$</p>

<p>$$p \cdot x &lt; p \cdot y \implies \frac{1}{s} \sum^s_{i=1} x_i &lt; \frac{1}{s} \sum^s_{i=1} y_i \implies \sum^s_{i=1} x_i &lt; \sum^s_{i=1} y_i$$</p>

<p>So $x \succcurlyeq y \iff x \geq y$ by monotonicity</p>

<p>$x \geq y \iff x_i \geq y_i \ \forall i$ by definition</p>

<p>but then $\sum^s_{i=1} x_i \geq \sum^s_{i=1} y_i$ which is a contradiction.</p>

<hr>

<p><strong>Case 2:</strong> $p \cdot x \geq p \cdot y$ and $y \succ x \ \forall p$</p>

<p>Similarly, pick the same $p$.</p>

<p>$$p \cdot x \geq p \cdot y \implies \sum^s_{i=1} x_i \geq \sum^s_{i=1} y_i$$</p>

<p>$y \succ x \iff y &gt; x$ by monotonicity</p>

<p>but then $\sum^s_{i=1} x_i &lt; \sum^s_{i=1} y_i$ which is a contradiction.</p>

<hr>

<p><em>Now, let us look at the ""only if"" case.</em></p>

<p>Let $u(x) = p \cdot x$ and $\exists \ p$ s.t. $\forall x,y$ then $x \succcurlyeq y \iff p \cdot x \geq p \cdot y$</p>

<p>Now we wish to show our five properties hold and the uniqueness of $p$.</p>

<hr>

<p>The above implies that</p>

<p>$\exists \ p$ s.t. $\forall x,y$, then $x \succcurlyeq y \iff U(x) \geq U(y)$</p>

<p>This we have utility function <strong>representation</strong>, by definition. It is a basic proof from the beginning of your class probably that representation implies <strong>rationality</strong>.</p>

<p>We can also say if $U(x)$ is continuous in $X$ and $U(x)$ represents $\succcurlyeq$ on $X$, this implies the preferences are <strong>continuous</strong>.</p>

<p>$x \succcurlyeq y \iff p \cdot x \geq p \cdot y \iff p \cdot (x + z) \geq p \cdot (y + z) \iff x + z \succcurlyeq y + z \quad \forall x,y,z \in X$</p>

<p>So that shows <strong>additivity</strong>.</p>

<p>Now suppose <strong>monotonicity</strong> does not hold. Suppose $x \succcurlyeq y \implies p \cdot x \geq p \cdot y$</p>

<p>but additionally, $x &lt; y$
$\implies p \cdot x &lt; p \cdot y$ which is a contradiction.</p>

<p>Suppose <strong>non-triviality</strong> does not hold. Suppose $x \sim y \ \forall \ x, y$, where $x \neq y$, so $x$ and $y$ are unique. But we have monotonicity now.</p>

<p>but $x &gt; y \iff x \succ y$
and $y &gt; x \iff y \succ x$</p>

<hr>

<p>For the uniqueness of $p$, building off of the outline you gave pick $x, y \in X$ where $x \sim y$ for both $p$ and $p' = (p + \epsilon, 1-p- \epsilon)$</p>

<p>This can only be true if $\epsilon = 0$ or if $x$ and $y$ are not unique, that is, $x_i = y_i \ \forall i$. We will rule out the trivial case where $x$ and $y$ are not unique and show $\epsilon = 0$ (and thus $p = p'$)</p>

<p>$$px_1 + (1-p)x_2 = py_1 + (1-p)y_2$$
and
$$(p+\epsilon)x_1 + (1-p-\epsilon)x_2 = (p+\epsilon)y_1 + (1-p-\epsilon)y_2$$
The second equation implies
$$px_1 + \epsilon x_1 + (1-p)x_2 - \epsilon x_2 = py_1 + \epsilon y_1 + (1-p)y_2 - \epsilon y_2$$</p>

<p>Subtract the first equation from this equation.</p>

<p>$$\epsilon x_1 - \epsilon x_2 = \epsilon y_1 - \epsilon y_2$$
$$\epsilon (x_1 - x_2) = \epsilon (y_1 - y_2)$$</p>

<p>Consider if $x_1 + \delta = y_1$ and $x_2 + \delta = y_2$ for any $\delta &gt; 0$.</p>

<p>Then the differences $x_1 - x_2$ and $y_1 - y_2$ are equal, but bundle x will have higher monetary outcomes in whichever state occurs, so $x \succ y$. Contradiction.</p>

<p>Similarly, if $x_1 = y_1 + \delta$ and $x_2 = y_2 + \delta$, then $y \succ x$, which is again a contradiction with $x \sim y$</p>

<p>Thus $\epsilon = 0$.</p>

<p>$\square$</p>
","9194"
"Update of value function in continuous time - HJB","148","","<p>When solving (numerically, by value function iteration) a dynamic programming problem in discrete time, such as</p>

<p>$$V_1(a) = \max_{c} \ u(c) + \dfrac{1}{1+\rho}V_0(a')$$</p>

<p>we maximize with respect to the control variable and get a first order condition that we then plug back into the functional equation shown above. The result of this step, $V(a)_1$, will then be used on the RHS of a second iteration</p>

<p>$$V_2(a) = \max_{c} \ u(c) + \dfrac{1}{1+\rho}V_1(a')$$</p>

<p>and we repeat this process until $V(a)_n-V(a)_{n+1}&lt;\epsilon$.</p>

<p>My question is how does the update of the value function work in continuous time?  I have been working on a paper that uses continuous time dynamic programming, so the Bellman equation looks as follows</p>

<p>$$\rho V_n(a) = \max_{c} \ u(c) + \dfrac{\partial V_n(a)}{\partial a}da_t \quad (*)$$</p>

<p>where the transition equation is represented by $da_t$. From what I have seen, the update of the value function is done by calculating $\Delta$:</p>

<p>$$ \Delta = \ u(c(a^*)) + \dfrac{\partial V_n(a)}{\partial a}da_t(a^*) - \rho V_n(a)$$</p>

<p>where $u(c(a^*))$ and $da_t(a^*)$ represent the control and transition equation as functions of the optimal policy. That is, we maximize the RHS as in the previous example (the discrete time case), but then we subtract $\rho V(a)$ from both sides. Then updating the value function is done as follows:</p>

<p>$$V_{n+1}(a) = V_n(a) + \Delta$$</p>

<p>How can this be so? I would have thought that I would just use the maximised RHS of (*) and plug back in a new iteration. How come the other method is the correct one?</p>
","<p>You iterate towards a fixed point, so you want to reach a situation where plugging in your current iterated value produces itself. Now using your notation, we are told that we should calculate</p>

<p>$$V_{n+1}(a) = V_n(a) + \Delta$$</p>

<p>where</p>

<p>$$\Delta = \ u(c(a^*)) + \dfrac{\partial V_n(a)}{\partial a}da_t(a^*) - \rho V_n(a)$$</p>

<p>Insert the second into the first to see what the iteration rule is:</p>

<p>$$V_{n+1}(a) = V_n(a) + \ u(c(a^*)) + \dfrac{\partial V_n(a)}{\partial a}da_t(a^*) - \rho V_n(a)$$</p>

<p>When you reach a point where</p>

<p>$$V_{n+1}(a) = V_n(a) $$</p>

<p>(or $\epsilon$-so)</p>

<p>It will mean</p>

<p>$$\rho V_n(a)= \ u(c(a^*)) + \dfrac{\partial V_n(a)}{\partial a}da_t(a^*) $$</p>

<p>which is what you have to satisfy.</p>

<p>Some stars etc may have to be adjusted in the above, for a fully consistent notation.</p>
","11661"
"What caused such an abnormality in the TF2 economy?","148","","<p>In the video game, Team Fortress 2, an economy grew inside of it. It had its own currency and barter systems, and everything was running smoothly. But, in time, things started to get very strange. One of the currency types, keys, started to raise in value (the price of a key was originally at 2.33 refined metal (2 refined and 1 reclaimed), but it slowly went up to 2.66 and greater). Now, the value of keys have reached 15 refined metal (give or take), and the value of many other items have gone down dramatically. For example, a sub currency, called Buds, were valued at 16 keys, but through the rise of keys, have lowered to around 5-6 keys.</p>

<p>My question is, what caused this abnormality to happen, and will the TF2 economy ever be able to recover back to the values they started at (without  the game creator's intervention)? </p>

<hr>

<p>Before I go into how the economy works, I will start with currency.</p>

<p>The most basic currency is Refined metal. One can create a refined metal through crafting. I will explain it more in depth once I have gone over more currencies. Refined metal can be destroyed through crafting, where it and the pieces that make it can be used to craft hats and weapons.</p>

<p>Making up Refined metal are Reclaimed metal. There are 3 Reclaimed metal per Refined. They are obtained by crafting 3 Scrap metal together. </p>

<p>Scrap metal is created by crafting 2 weapons of the same class together (weapons are a common drop). For more on the drop mechanics, go to these Gaming SE questions.</p>

<p><a href=""https://gaming.stackexchange.com/questions/24012/team-fortress-2-item-drop-chances"">https://gaming.stackexchange.com/questions/24012/team-fortress-2-item-drop-chances</a>
<a href=""https://gaming.stackexchange.com/questions/322/when-does-the-weekly-drop-count-reset"">https://gaming.stackexchange.com/questions/322/when-does-the-weekly-drop-count-reset</a></p>

<p>Besides just weapons, both Hats and Crates can drop. Hats are the more valuable of the two, usually at around 2 refined, give or take. Crates on the other hand, have little to no value, albeit some are very expensive (some people would trade their first born for one of the rarer ones), and when a new one is released, it can have a high initial value, that decays with time.</p>

<p>All money used here is in USD, but the $ sign was causing errors when more than one was used.</p>

<p>Unlike how metal is created by users, Keys are purchased from the Mann Co store (this is the main in-game store. You can trade real world money for items here). A Key is valued at 2.49 here. There are also Hats and Weapons on sale here, but the community generally counts those as ridiculously overpriced, seeing that one of the Weapons that you can find (as a common drop) is valued at 9.99 by the Mann Co store. The Mann Co store is run and maintained by the game developers.</p>

<p>The main way of trading is through a barter system. Users search servers and forums for people who have the item(s) they want, and then try to trade with them. A good example of one forum made specificly for TF2 (and other game) trading is <a href=""http://www.tf2outpost.com/"" rel=""nofollow noreferrer"">TF2 Outpost</a>.</p>

<p>You might be thinking,"" If it is a barter system, why do prices exist?"" The price part, comes from a community of people. This site, called Backpack TF is one of the (if not) biggest sites that give item value guide lines. </p>

<p>A link to it is here: <a href=""http://backpack.tf/"" rel=""nofollow noreferrer"">http://backpack.tf/</a></p>

<p>The barter system still exists though. Outside of the people who do not use Backpack TF, many of the rarer items have to be traded through barter, because there are either not enough to try and create a price, or because they don't get traded enough. But, if someone gives the details on what the item was traded for, Backpack TF will try to make a price over time. </p>

<p>Now, time to go in-depth about crates. Crates can be consumed (along with one Key) to open it. Inside, you will find an item that was listed on content list of the crate. Most items inside of the basic crates start high, then drop down. The main type of item that does not follow this are the Unusual Hats. These rare items only have a 1% flat chance of being obtained from ANY type of crate, and event crates tend to have a rarer type. Some of these are valued at 8 Keys (give or take), while some have been in trades with more than 5000+ USD being traded for it, and even more in items. </p>

<p>Another way to get semi-rare items is through MvM, an extra game mode. If a player ""Manns Up"", they get bonus loot at the end of the mission, and a bigger reward at the end of a tour (set of 3-6 missions, depending on difficulty). These bigger rewards started expensive, but slowly dropped. The only one of any value besides the Pro-Killstreak and Austrailium items (better ones are valued like Unusuals, while lower ones are valued at 1-3 keys) is the Golden Frying Pan, which is valued at ridiculous levels. </p>

<p><a href=""http://backpack.tf/stats/Strange/Golden%20Frying%20Pan/Tradable/Craftable"" rel=""nofollow noreferrer"">http://backpack.tf/stats/Strange/Golden%20Frying%20Pan/Tradable/Craftable</a></p>

<p>A big part in trading is the Steam Market, which allows users to sell their items (only certain types) for real world money (that is still stuck in the Steam System). Users can also spend their money on items in a similar fashion. This is all user to user, much like trading. </p>

<p>That is a basic overview of the how the TF2 Economy works and how it is regulated. Outside of the Mann Co store, have little say in the economy. Its community is what creates the prices. Backpack TF probably creates the guide lines off of supply and demand, but because of how easily both can change, that might not be the only factor to the prices. I want to explain more of why things are priced the way they are, but I don't know the inner-workings of Backpack TF. </p>
","<p><strong>TL;DR: I think the most probable reason is a (close to) constant supply of everything and that the demand for everything is declining but we have a slower decline in demand for keys.</strong></p>

<p>Lets start with the <strong>supply side</strong> first:</p>

<p>Most items (as I understood) are created by playing the game. So when you play you generate these items and as people are (obviously) playing this game they are created and we have a supply. Assuming that there is no significant change in the games that are played, we get a constant supply of ""most items"" (i.e., weapons, metals) $s_n$.</p>

<p>Keys however, are bought by players. I am assuming that players will also buy a constant amount of keys $s_k$ (which is probably not true, but I will discuss that later).</p>

<p>Now the <strong>demand side</strong>:</p>

<p>You said metal, guns and stuff like that is either used as as it is or used to create an item. You never said anything about consuming these items, so I guess (is this true?) that, once you have an item you keep it and don't need it anymore. Therefore, if the player base is not increasing fast enough, the demand will decrease at a certain rate $d_n$.</p>

<p>The key are used to generate items of 3 different kinds (I hope I got that right): normal items (like above), hats (which can not be found and are pretty rare) and consumable items (like MvM). Normal items have a change in demand which is $d_n$ (as we defined it like that), hats have a slower decrease in demand, as they are a) more rare (and therefore more people still need them) and b) are randomly created (which means if one wants one specific (but very rare item) one has to open many chests), therefore their decrease in demand is lower $d_h &lt; d_n$. The last item we can get is consumable, so I think it is save to assume that here the demand is also not decreasing that much as they are consumed, i.e. $d_c &lt; d_n$.</p>

<p><strong>Combining demand and supply</strong></p>

<p>So, what do we have? We have seen, that the difference between the change in supply $s_n$ and the change in demand $d_n$ of normal goods (lets call it $e_n = s_n - d_n$) is negative, so there if there would have been a (real and fixed) currency in this universe, the price would be dropping.</p>

<p>What about keys? Here we also have that the difference is decreasing, but at a much slower rate (as $e_k = s_k - d_k &lt; s_k - d_n = s_n-d_n$). Therefore the relative price of keys, compared to the price of normal goods should be increasing.</p>

<p><strong>Why has it just started now?</strong></p>

<p>There could me many reasons for that, some of them could be:</p>

<ul>
<li>not enough new players (many old players have most of the normal things and therefore only need keys)</li>
<li>not enough old players are leaving (pretty much the same as with not
enough new players)</li>
<li>we have a higher normal item drop rate that we are used to (maybe due to</li>
<li>MvMs or something like that?) they added new normal items before that
on a regular basis and now slowed down / stopped</li>
<li>...</li>
</ul>

<p><strong>Could one change this?</strong></p>

<p>Sure, just check every possible demand and supply effect, you could for example buy many normal items (increases $d_n$), sell many keys (increases $s_k$), many people could ignore keys (decreases $d_k$) or don't sell normal items any more (decreases $s_n$). Another way to change the price in the right direction could be to get a constant stream of new players, which grows larger and larger over time or get enough old players to stop playing.</p>

<p>As an economist, I actually see no point in doing that, the market seems to be working like it should. If the designers want to change this, they could do that pretty easily, e.g. by adding new normal items, increasing prices of the keys, add great and expensive consumable items that use up normal items, randomly destroying normal items or just decreasing the normal item drop rate.</p>

<p><strong>Remarks:</strong></p>

<p><em>Constant amount of keys:</em> We don't really need a constant amount of keys bought, but that the supply of keys is not increasing much faster than the supply of normal items, so the assumption is not as bad as it sounds.</p>

<p><em>Other reasons?</em> There are probably other possible explanations, but this one seems, at least to me, the most likely.</p>

<p><strong>Some additional remarks, not really related to your question:</strong></p>

<blockquote>
  <p>You might be thinking,"" If it is a barter system, why do prices
  exist?"" The price part, comes from a community of people. This site,
  called Backpack TF is one of the (if not) biggest sites that give item
  value guide lines.</p>
</blockquote>

<p>This is actually not surprising to an economist, in the end every market is is some kind of ""barter system"".</p>

<blockquote>
  <p>When a new [crate] is released, it can have a high initial value, that
  decays with time.</p>
</blockquote>

<p>This is also expected, as the demand is pretty high from the start but the supply is (pretty much) constant over time.</p>
","5277"
"What is the point of silent auctions?","148","","<p>A while back, someone decided to auction off something unique and valuable, as a silent auction: everyone would submit one bid only, and whoever bid the highest would win.</p>

<p>I submitted a bid that I thought would be higher than most people would pay, but I didn't win.  He posted the final result, though, and the winning bid wasn't much higher than mine.  If I had known it would go that high, I would have bid higher, and other people probably would have as well, which means he ended up leaving money on the table.</p>

<p>That makes me wonder: what is the point of running a silent auction if it can so easily be shown that it brings in less money than an auction in which people can openly bid against each other?</p>
","<p>But perhaps this is not always the case. The price might have been so high that you would not have been willing to bid above it. In fact it might have been so high that the no one but the highest bidder would have given that bid. Knowing this the highest bidder could decrease his bid. In fact in English auctions (non-silent rising bid auctions) the final price is the second highest valuation of the unique good. In the auction you describe (a sealed bid first price auction) the final price is usually somewhat random based on what people believe about each others valuations and each others bidding strategies. It can happen that the final price is higher than it would have been in an English auction because one of the bidders overvalued what his competition would be willing to pay. So the English auction is not clearly advantegous.</p>

<p>It has been shown that given some rather strict conditions the English auction and the sealed bid first price auction have the same expected yield for the auctioner. This is known as the ""Revenue Equivalence Theorem"".</p>

<p>In practice it is somewhat agreed upon that in rising price auctions bidders experience something called 'auction fever'. Basically being outbid encourages them to raise their own bid. This is true even if the auction was designed in such a way that revealing the true highest valuation by all bidders would be an equilibrium move. (Auction by proxy, the auction system eBay and several other sites use is such an auction type.)</p>

<p>So it seems that in practice you might be right and rising price auctions might be better in expected value for the seller. This is just speculation but in your case you I think you might merely be experiencing remorse because you have undervalued your competitor's bid. I have been there :)
<br> (By the way this could encourage you to overbid on your next silent auction, to the benefit of the seller. Such overbidding might give him higher than English auction payoffs. Again, which system is better is not always clear.) </p>
","10921"
"Fair voting procedure when there are many issues","147","","<p>When several people have to decide about a single yes/no issue*, the natural decision rule to use is the majority rule. </p>

<p>But when there are many issues to decide upon, the majority rule is ""unfair"" in the following sense: it is possible that the majority's opinion will be accepted on all topics and the minority's opinion will not be accepted on any topic. As an extreme example, it is possible that 51% of the population will decide about 100% of the issues.</p>

<p>I am looking for a decision rule which prevents this unfairness.</p>

<p>Formally, define a ""uniform group"" as a group of people who always vote in the same way. Define the ""acceptance rate"" of a uniform group as the percentage of issues on which the opinion of the uniform group got accepted. </p>

<p>Define a ""fair decision rule"" as a rule for which, for every uniform group containing X percent of the population, the acceptance rate tends to X when the number of issues tends to infinity.</p>

<p>MY QUESTION IS: Does there exist a fair division rule as defined above?</p>

<p>(* I restrict the question to yes/no issues, since when the issues are not binary the problems are much more complicated).</p>
","<p>That's interesting: the flavor of the frequentist approach to probability used for a socio-political fairness criterion: if my measure as a population group is $0&lt;p&lt;1$, and known, then my opinion should be accepted by the whole at the same measure, as number of issues goes to infinity. In other words, current observed acceptance rate should be a consistent estimator of theoretical acceptance rate, and equal to my measure.  </p>

<p>Then it is very easy to create such a decision rule, while saving public money: <strong>no need to hold one referendum after another, just construct a die,</strong> with as many sides as there are ""uniform groups"", with the die's weight distributed in such a way that the side representing uniform group $i$ will have probability of turning up equal to $p_i$. It won't be difficult to construct, and publicly and objectively test it for the desired properties.</p>

<p>Then, wherever an issue comes up for voting, just roll the die. And ok, spend some money for a suitable public ceremony.</p>

<p>Whenever there is a census, the relative size of each uniform group can be re-measured and a new die can be constructed.</p>

<p>Why do I have the feeling though that no uniform group is likely to ever accept such a scheme?</p>

<p>(This of course puts aside the <em>importance</em> of each issue, in general, for each uniform group, etc, but I took that from the OP which concentrates on <em>number</em> of issues, irrespective of what the issues are about, and to whom they matter and how much they matter, and how do we measure that etc).</p>
","541"
"Federal Reserve Open Market Operations","147","","<p>I am trying to understand how the Fed effects the fed funds rate. <a href=""http://www.amosweb.com/cgi-bin/awb_nav.pl?s=wpd&amp;c=dsp&amp;k=open%20market%20operations"" rel=""nofollow"">Here</a> it says:</p>

<blockquote>
  <p>Once the Federal Open Market Committee deems that economic conditions
  warrant a change in the money supply through specific open market
  operation, the command to buy or sell a specific amount of U.S.
  Treasury securities is passed down through the New York Fed President
  to what is called the Domestic Trading Desk of the New York Federal
  Reserve Bank. The Domestic Trading Desk is then responsible for
  implementing the conducting the actually trades. It does this sending
  messages to a selected group of about 30 securities dealers who
  specializing in the U.S. Treasury securities. These dealers have 15
  minutes to respond back with a indication of their willingness to buy
  participate in the exchange of securities. Some dealers are willing,
  others are not. In fact, the ""open"" part of open market operations
  means that the trades are open to any of the securities dealers
  willing to participant. The Domestic Trading Desk then has 5 minutes
  to respond back to the each of dealers that the terms of the exchange
  is acceptable.</p>
  
  <p>Once all parties have agreed on the exchange terms, the resulting
  transactions work much like any other. If the Fed buys, then it
  collects the securities from the dealers in exchange for checks. If
  the Fed sells, then the dealers collect the securities from the Fed in
  exchange for checks. In both cases, the checks are cleared much like
  any of the millions of checks process each day.</p>
</blockquote>

<p>So the Fed manipulates the reserves of banks in order to increase or decrease fed funds, and it uses open market operations to do this. I am curious, though: what if in the case of ""raising rates"", the Fed wants to sell securities but no bank wants to buy them? And, why wouldn't a bank buy securities anywhere else? </p>

<p>Thanks,</p>
","<p>The actual details of the auction and so on are interesting, but in principle there is no magic. Its just demand and supply:</p>

<p>There is a number of agents that can supply or demand treasury bonds as well as other bonds. There's the government that issues the treasuries, the Fed that sometimes holds them, sometimes sells them, investors of all kinds( brokers, pension funds, individuals, money market funds, etc). All these agents want to sell more if they deem the price high(rates too low) and they want to buy if they deem the price is low (rates too high). </p>

<p>When supply shrinks, then agents that want to buy these assets bid up their prices (bid down the rates). similarly, when supply expands then the price falls (the rate rises) as the buyers bid down the  prices after observing the quantity.</p>

<p>To push up an interest rate, the fed will sell bonds. This will increase supply, until the price falls (i.e. until the rate rises).  To push down an interest rate, the fed will buy bonds. This will decrease supply, until the price increases (i.e. until the rate falls).</p>

<blockquote>
  <p>I am curious, though: what if in the case of ""raising rates"", the Fed wants to sell securities but no bank wants to buy them? And, why wouldn't a bank buy securities anywhere else?</p>
</blockquote>

<p>If no bank wants to buy the securities, but the fed is trying to sell them, then their price would go down, down, down, increasing the rate, until somebody wants them. If this rate is too high for the Fed, then it can instead buy these securities, lowering the market rate. In principle, if nobody wants to buy it means they are willing to sell, if nobody wants to sell it means they are willing to buy.</p>

<p>The banks can buy securities wherever they want, but the rates of all securities are closely related to each other. If the fed lowers rates on Treasuries, the rates on corporates, munies, etc, are all going to follow suit, at least to some extent. This is because the securities are all close substitutes of each other, so if you were thinking of buying a treasury, but its price increases, you go and, for example, you try to buy a muni, thereby increasing its price too.</p>
","11807"
"How to auction shared item with a roommate?","147","","<p>My roommate and I split the cost of a game console a year ago (~$400) but he is now moving out.</p>

<p>We were wondering how to fairly auction the console given the situation:</p>

<ul>
<li>We both paid an equal price of $200+</li>
<li>Right now half the market price of the console is \$175</li>
<li>We both would prefer having the console than being paid for it</li>
<li>He will be splitting the price with his new roommate whereas I will be paying by myself</li>
</ul>

<p>With regular bidding, as my roommate representing both him and his next roommate and me myself, is he at an advantage because he has double the market power? If yes, how can we fix that problem?</p>

<p><strong>Outcome:</strong></p>

<p>Thank you for your answers. While the chosen answer seemed the best way to do this, we both felt it involved too much strategy and would have resulted in envy from one of us. We instead went with the <a href=""https://en.wikipedia.org/wiki/Fair_division#Two_players"" rel=""nofollow"">Divide and Choose</a> method, which worked out fairly for both of us.</p>
","<p>If you think that the distribution of your value and your roommate's value are the same then I would suggest that you consider the following bidding protocol:</p>

<ul>
<li>each bidder submits a sealed bid, $b_i$.</li>
<li>the highest bidder, $i$, received the console and makes a payment of $b_i-b_j$ to the loser, where $b_j$ is the loser's bid.</li>
</ul>

<p><a href=""ftp://www.cramton.umd.edu/papers1984-1989/87econ-dissolving-a-partnership-efficiently.pdf"" rel=""nofollow"">Cramton, Gibbons, and Klemperer (<em>Econometrica</em>, 1987; Section 4)</a> show that this is an efficient way to dissolve a partnership with joint ownership stakes in an asset.</p>

<p>If you think that the two of you have differing value distributions (e.g. because your roommate has a new friend) then Cramton et al. show in Theorem 2 how to adjust the pricing rule to restore efficiency. </p>

<p>I highly recommend taking a look at the Cramton et al. paper. It's surprisingly readable for an <em>Econometrica</em>.</p>

<p>Let us know how you get on if you decide to try it out!</p>
","12276"
"Rationality and Common Belief in Rationality in Brandenburger & Dekel (1987)","147","","<p>One of the fundamental results in epistemic game theory is that the solution concept of <em>correlated rationalizability</em> gives exactly those action profiles that are compatible with rationality and common belief in rationality. A precise statement and formulation of this result is given in </p>

<blockquote>
  <p>Tan, Tommy Chin-Chiu, and Sérgio Ribeiro da Costa Werlang. ""The
  Bayesian foundations of solution concepts of games."" <em>Journal of
  Economic Theory</em> 45.2 (1988): 370-391.</p>
</blockquote>

<p>as Theorem 5.2 and Theorem 5.3. An alternative reference often cited for this result (at least in the context of finite games, Tan &amp; Werlang allow for compact metric action spaces) is </p>

<blockquote>
  <p>Brandenburger, Adam, and Eddie Dekel. ""Rationalizability and
  correlated equilibria."" Econometrica: Journal of the Econometric
  Society (1987): 1391-1402.</p>
</blockquote>

<p>For example, the survey on epitemic game theory in the fourth volume of the handbook of game theory credits Brandenburger &amp; Dekel for this result (<a href=""https://c92d0541-a-62cb3a1a-s-sites.googlegroups.com/site/eddiedekelsite/EpistemicGameTheory-130326.pdf?attachauth=ANoY7cps6Rt9t8BHAt5jqUXK4DlafRwpMzlsT_oMieCrXMlGJz1AMJwODmMVmtQaNtFjR8cs1mj_mXtrXoIZL6bzTgKNwwxm4spccFUheStoyQmTq0NtfpZ2hqoThby97f84NZdM-vEQWBTt_JP8tz-2iwDw4t0rlCqRkRloyiyMZRXErEIcE7SbEkXdaTUzx-9jp8Pn_d4I8O8ZTJ2UIg0ez-zuBj1OXFdQl-QReYlLo9-i4td0I6s%3D&amp;attredirects=0"">online version</a>, see Theorem 1 there). I have actually seen many such references but was not able to locate the result in their paper. That paper contains 4 propositions and none of them corresponds to this result. The authors actually credit Tan &amp; Werlang and write ""Tan and Werlang (1984) and Bernheim (1985) provide formal proofs of the equivalence between rationalizability and common knowledge of rationality."" (Tan &amp; Werlang 1984 is the working paper version).</p>

<p><strong>What am I missing that everyone else gets?</strong></p>
","<p>The concept that Brandenburger and Dekel (1987) call an ""a posteriori equilibrium"" is roughly the same as what Dekel and Siniscalchi call an ""epistemic type structure for a complete information game"" in which all types are rational and there is common belief in rationality. Therefore, Brandenburger and Dekel's Proposition 2.1, together with the remark that immediately follows the proof of Propoistion 2.1, is roughly the same as Theorem 1 in Dekel and Siniscalchi.  </p>
","3150"
"Research Design: Indifference curves and budget lines","147","","<p>I have a basic Idea on how to construct indifference curves such that we must use two goods and then ask for pairs of bundles which are preference indifferent.</p>

<p>When doing applied research on estimating a consumers demand for a given bundle of goods, (which is probably done by survey as far as I'm concerned) what are the main questions we are seeking to answer in order that the data will work out nicely when using such a framework? How should such questions be worded on a survey?</p>
","<p>In order to derive a preference indifference curve between different quantities of two goods, one possible questioning protocol would consist in:</p>

<ol>
<li><p>First choosing any arbitrary combination of quantities for the bundle of goods (e.g. 20 units of A and 5 units of B);</p></li>
<li><p>Then choosing any arbitrary quantity of one of the goods (e.g. 15 units of good A);</p></li>
<li><p>Asking the consumer whether he (or she) is willing to exchange the first bundle of goods (20 of A and 5 of B) by a bundle of goods comprising 15 units of A (or any other quantity as specified in the previous paragraph) and 10 units of B (or any other quantity provided that is greater than 5);</p></li>
<li><p>If the consumer chooses the first bundle then the previous question should be asked again provided that that the previous 10 units of B be replaced by a greater quantity (e.g. 15 units of B); otherwise, if the consumer chooses the second bundle then the question of the previous paragraph should be asked again provided that that the previous 10 units of B be replaced by a smaller quantity (e.g. 8 units of B);</p></li>
<li><p>When the consumer considers that he (or she) is indifferent between two bundles, it means that the two bundles are indifferent and therefore the corresponding points should lie over the same indifference curve.</p></li>
<li><p>Following the previous procedure for a significant set of other combinations of quantities (bundles) would allow to draw the corresponding indifference curve(s).</p></li>
</ol>
","15024"
"Usefulness of the value for the slope of the demand curve","147","","<p>I see the elasticity value(s) of demand being used frequently to determine the relation between demand and variables such as price and income. I have however been unable to find any uses for the slope of the demand curve. Are there any?</p>

<p>Also, is there any relationship between the slope and the elasticity?</p>
","<p>Price elasticity of demand is related (but not equal) to the <strong><em>inverse</em></strong> of the slope of the demand curve.</p>

<p><a href=""https://en.wikipedia.org/wiki/Price_elasticity_of_demand"" rel=""nofollow noreferrer"">This Wikipedia article defines PED as</a>:</p>

<blockquote>
  <p>Price elasticity of demand (PED or Ed) is a measure used in economics to show the responsiveness, or elasticity, of the quantity demanded of a good or service to a change in its price, ceteris paribus. More precisely, it gives the <strong>percentage change in quantity demanded in response to a one percent change in price</strong>. [emphasis added]</p>
</blockquote>

<p>Look at the following (canonical) supply-demand graph.</p>

<p><a href=""https://i.stack.imgur.com/z7pZy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/z7pZy.png"" alt=""enter image description here""></a></p>

<p>Let's define $P^*$ the price of market equilibrium, $Q_D$ as the quantity demanded and $E_D$ as price elasticity of demand. Then:</p>

<p>$$ {slope} = \frac{rise}{run} = \frac{\Delta P}{\Delta Q_D} $$</p>

<p>And in mathematical terms, the verbal description of the PED reduces to:</p>

<p>$$ E_D = \frac{\frac{\Delta Q_D}{Q_D} \cdot 100}{\frac{\Delta P}{P^*} \cdot 100} $$</p>

<p>$$ E_D = \frac{P^*}{Q_D} \cdot \frac{\Delta Q_D} {\Delta P} $$</p>

<p>$$ E_D = \frac{P^*}{Q_D} \cdot \frac{1}{slope} $$</p>

<h2>Edit</h2>

<p>Constructive comments have been incorporated into this answer.</p>

<p>In particular, @Kontorus pointed out:</p>

<blockquote>
  <p>The PED is a percentage change, the slope of the demand curve is an absolute change.</p>
</blockquote>

<p>And @denesp pointed out that:</p>

<blockquote>
  <p>... linear demand curves have constant slopes but changing elasticity. <em>Cobb-Douglas</em> derived demand (hyperbole) has changing slope but constant elasticity.</p>
</blockquote>
","12729"
"Optimal consumption in Merton-like portfolio choice model with constant wage","146","","<h1>My Questions</h1>

<p>Consider the following problem. It is almost identical to
the classic Merton portfolio choice problem. Here I'm solving it using
the so-called Martingale method. I have provided my attempt at
a derivation. I have three questions:</p>

<ol>
<li>Is this correct? </li>
<li>Why does it seem like the consumption path is stochastic? I understand that we can
perhaps interpret this problem as identical to the classic Merton
problem where the agent has some starting wealth $W_0 &gt; 0$.
We can do this by saying that $W_0 = \int_0^\infty \pi_t w dt$.
However, why would the agent simple not choose $C_t = w$? 
My suspicion is that this depends on the relative values of $\rho$
and the interest rate $r$. </li>
<li>Under
what conditions would $C_t = w$, if ever?</li>
</ol>

<h1>Problem setup</h1>

<p>An agent has initial wealth $W_0 = 0$ but receives a constant
stream of wages $w$. There is a riskless asset that pays the interest rate 
$r$ and a risky security that follows the dynamics
$$
\frac{dS}{S} = \mu_S dt + \sigma_S dB_t,
$$
where $B_t$ is a standard brownian motion.</p>

<p>Now, the agent has CRRA utility. Thus, his decision is modelled by
the following program:</p>

<p>\begin{align*}
\max_{\{C_t\}_{t=0}^\infty} \quad \mathbb E\left[\int_0^\infty e^{-\rho t} 
  \left ( \frac{C_t^{1-\gamma}}{1 - \gamma} \right )
  \, \mathrm d t \right ] \\
\text{ s.t. } \mathbb E \left [ \int_0^\infty \pi_t (c_t - w) dt \right ] \leq W_0,
\end{align*}
where $\pi_t$ is the stochastic discount factor, which can
be written as
$$
\frac{d \pi_t}{\pi_t} = - \mu_{\pi} dt - \sigma_{\pi} d B_t.
$$</p>

<h1>My solution attempt</h1>

<p>Proceeding with the Martingale method, the first-order condition on the
appropriate Lagrangian are
$$
u_c(c_t, t) = e^{-\rho t} C_t^{-\gamma} = \lambda \pi_t,
$$
where $\pi = e^{-r t} \xi_t$, $\lambda$ is the Lagrange multiplier,
and the exponential martingale is 
$\xi_t = \exp\left (-\eta B_t - \frac{t}{2} \eta^2 \right )$.
Note that this is based on the assumption of complete markets and
is equivalent to
$$
\frac{d \pi_t}{\pi_t} = - r dt - \eta d B_t,
$$
where $\eta = \frac{\mu_s - r}{\sigma_s}$ is the market price of risk.</p>

<p>The first-order condition implies that 
$C^*_t = \left( \lambda \pi_t e^{\rho t} \right )^{-1/\gamma}$.
We can then substitute this into the budget constraint and
solve for $\lambda$:
\begin{align*}
W_0 &amp;= \mathbb E \int_0^\infty \pi_t (C_t^* - w) \, \mathrm d t \\
0  &amp;= \mathbb E \int_0^\infty \pi_t^{\frac{\gamma - 1}{\gamma}} 
      \lambda ^{\frac{-1}{\gamma}} \exp(-\rho t/\gamma) - \pi_t w \, \mathrm d t.
\end{align*}</p>

<p>Now, in order to proceed, let us make the following intermediate calculations:
\begin{align*}
\mathbb E_0[\pi_t] &amp;= \exp\{-r t\} \\
&amp;\text{and} \\
\mathbb E_0 \left [\pi_t^{\frac{\gamma - 1}{\gamma}} \right ] 
  &amp;= \mathbb E_0 \exp \left \{
  - \frac{\gamma - 1}{\gamma} \left (r + \frac 12 \eta^2 \right ) t 
  - \frac{\gamma - 1}{\gamma} \eta B(t) \right \} \\
  &amp;= \exp \left \{ - \frac{\gamma - 1}{\gamma} (r + \frac 12 \eta^2 ) t 
  + \frac 12 \frac{(\gamma - 1)^2}{\gamma^2} \eta^2 t \right \} \\
  &amp;= \exp \left \{ -t \frac{\gamma - 1}{\gamma} \left[ r + \frac 12 \eta^2 
  \frac{1}{\gamma} \right] \right \}.
\end{align*}
Because of the appropriate regularity conditions, we can exchange
the order of integration to 
make the following calculations:
\begin{align*}
\mathbb E \int_0^\infty \pi_t w \, \mathrm d t &amp;= w \int_0^\infty \mathbb E[\pi_t] \, \mathrm d t
  = w \int_0^\infty \exp(-r t) = \frac{w}{r} \\
 \text{and} \\
\mathbb E \int_0^\infty \pi_t^{\frac{\gamma - 1}{\gamma}} 
  \exp \left (\frac{-\rho t}{\gamma} \right ) \, \mathrm d t
  &amp;= \int_0^\infty \exp(-a t) dt = a^{-1},
\end{align*}
where $a = \frac{\rho}{\gamma} +\frac{\gamma - 1}{\gamma}
  \left[r + \frac 12 \eta^2 \frac{1}{\gamma} \right ] $.
Then, continuing with the budget constraint, we
can solve for $\lambda^{-1/\gamma}$,
$$
\lambda^{-1/\gamma} = \frac{w a}{r}.
$$
We can then substitute this back into our expression for
the optimal path of consumption,
$$
C^*_t = \frac{w a}{r} \pi_t^{-1/\gamma} \exp \left \{ -\frac{1}{\gamma} \rho t
  \right \}.
$$</p>
","<p>$\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\E}{\mathbb{E}}
%short command for inseting abbreviated ""such that"" in a math environment
\newcommand{\st}{\text{ s.t. }}
%text in a math environment ""as""
\newcommand{\as}{\text{ as }}
%various referencing commands
\newcommand{\rref}[1]{(\ref{#1})}
\newcommand{\eref}[1]{eq. (\ref{#1})}
\newcommand{\fref}[1]{Figure \ref{#1}}
%differential d
\newcommand{\dd}{\, \mathrm{d}}
%variance and covariance$</p>

<h1>Part 1</h1>

<p>Yes. However, it is useful to simplify the answer even further and to write
optimal consumption in terms of other. more easily observed quantities.
Here's the derivation. I also solve for the portfolio holdings. </p>

<p><strong>Calculating Optimal Consumption in terms of Wealth</strong> </p>

<p>Start again with some preliminary calculations related to the budget constraint.
\begin{align*}
\mathbb E_t \left [\pi_T^{\frac{\gamma - 1}{\gamma}} \right ] 
  &amp;= \mathbb E_0 \pi_t^{\frac{\gamma-1}{\gamma}} \exp \left \{
  - \frac{\gamma - 1}{\gamma} \left (r + \frac 12 \eta^2 \right ) (T-t)
  - \frac{\gamma - 1}{\gamma} \eta (B(T) - B(t)) \right \} \\
  &amp;= \pi_t^{\frac{\gamma-1}{\gamma}} \exp \left \{ - \frac{\gamma - 1}{\gamma} (r + \frac 12 \eta^2 ) (T-t) 
  + \frac 12 \frac{(\gamma - 1)^2}{\gamma^2} \eta^2 (T-t) \right \} \\
  &amp;= \pi_t^{\frac{\gamma-1}{\gamma}} \exp \left \{ (T-t) \frac{\gamma - 1}{\gamma} \left[ - r + \frac 12 \eta^2 
  \frac{1}{\gamma} \right] \right \}.
\end{align*}
From the budget constraint
\begin{align*}
\pi_t W_t &amp;= \E_t \left[\int_t^\infty \pi_s C_s \dd s\right] \\
W_t &amp;= \frac{1}{\pi_t} \E_t\left[\int_t^\infty \lambda^{-1/\gamma} e^{-\frac{\rho}{\gamma} s} \pi_s^{\frac{\gamma-1}{\gamma}} \dd s\right] \\
  &amp;= \frac{1}{\pi_t} \int_t^\infty \lambda^{-1/\gamma} e^{-\frac{\rho}{\gamma} s} \E_t\left[\pi_s^{\frac{\gamma-1}{\gamma}} \right] \dd s \\
  &amp;= \frac{1}{\pi_t} \int_t^\infty \lambda^{-1/\gamma} e^{-\frac{\rho}{\gamma} s} \pi_t^{\frac{\gamma-1}{\gamma}} \exp\{-(s-t) \frac{\gamma-1}{\gamma} \left[r + \frac 12 \eta^2 \frac 1 \gamma \right]\} \dd s \\
  &amp;= \pi^{\frac{-1}{\gamma}} \lambda^{\frac{-1}{\gamma}} 
  \int_t^\infty \exp\left\{ -\frac{\rho}{\gamma} (s-t) - \frac{\rho}{\gamma} t - (s-t) \frac{\gamma-1}{\gamma} \left[r + \frac 12 \eta^2 \frac 1 \gamma \right]\right\} \dd s\\
  &amp;= \pi^{\frac{-1}{\gamma}} \lambda^{\frac{-1}{\gamma}} 
  e^{-\frac \rho \gamma t} \int_t^\infty \exp\left\{ - (s-t) \frac{\gamma-1}{\gamma} \left[r + \frac{\rho}{\gamma-1} + \frac 12 \eta^2 \frac 1 \gamma \right]\right\} \dd s \\
  &amp;= \pi^{\frac{-1}{\gamma}} \lambda^{\frac{-1}{\gamma}} 
  e^{-\frac \rho \gamma t} \frac 1 a,
\end{align*}
where 
$a = 
\frac{\gamma-1}{\gamma} \left[r + \frac{\rho}{\gamma-1} + \frac 12 \eta^2 \frac 1 \gamma\right]$
(this is the same as defined in attempt demonstrated in the question).
From our derivation of optimal consumption, we have
$$
C_t^* = \lambda^{-\frac 1 \gamma }e^{-\frac \rho \gamma t} \pi_t^{-\frac 1 \gamma} = a W_t.
$$</p>

<p><strong>Deriving the dynamics for optimal consumption: $\dd C_t^*$.</strong></p>

<p>To proceed to find the optimal portfolio to support this level of consumption, we need to compute the dynamics of $C_t^*$.</p>

<p>We will show that, from our derivation of optimal consumption, 
\begin{equation}
\dd W_t = \frac 1 a \dd C_t^* =
\frac 1 a C_t \frac 1 \gamma \left( \eta \dd Z_t + \frac 12 \frac{1+\gamma}{\gamma} \eta^2 \dd t\right). \label{wealth-dynamics-from-optimal-consumption}
\tag 1
\end{equation}</p>

<p>The second equality is derived as follows.</p>

<p>That second equality comes from $\lambda^{-\frac 1 \gamma} = \frac {w a} r$ (derived in the attempt given in the question statement) and
from Ito's lemma applied to
\begin{align*}
C^*_t &amp;=  \lambda^{-\frac 1 \gamma }e^{-\frac \rho \gamma t} \pi_t^{-\frac 1 \gamma} \\
  &amp;=  \frac {w a}{r}  (e^{\rho t} \pi_t)^{-\frac 1 \gamma} \\
&amp;=  \frac {w a}{r}  \xi_t^{-\frac 1 \gamma}.
\end{align*}
Here I have added the simplifying assumption that $\rho = r$ and I have used the definition that
$\pi_t = e^{-r t} \xi_t$.
The calculation of Ito's lemma on optimal consumption proceeds like this:
\begin{align*}
\dd C_t &amp;= - \frac {wa}{r} \frac 1 \gamma \xi_t^{\frac{-1 - \gamma}{\gamma}} \dd \xi_t
+ \frac 12 \frac{wa}{r} \frac 1 \gamma \frac{1 + \gamma}{\gamma} \xi_t^{- \frac 1 \gamma - 2} (\dd \xi_t)^2 \\
  &amp;= - C_t \frac 1 \gamma \left( \frac{\dd \xi_t}{\xi_t} \right) 
+ \frac 12 C_t \frac 1 \gamma \frac{1+\gamma}{\gamma} \left( \frac{\dd \xi_t}{\xi_t}\right)^2 \\
  &amp;= -C_t \frac 1 \gamma (-\eta \dd B_t) + \frac 12 C_t \frac 1 \gamma \frac{1+\gamma}{\gamma} ( \eta^2 \dd t)
\end{align*}
Thus,
$$
\frac{ \dd C_t}{C_t} = \frac 1 \gamma \left( \frac 12 \eta^2 \frac{1+\gamma}\gamma \dd t + \eta \dd B_t \right).
$$</p>

<p><strong>Match terms to derive optimal portfolio.</strong></p>

<p>We can deduce the optimal portfolio be deriving the dynamics of
a portfolio with a trading strategy defined by the weight $\omega_t$
and comparing these dynamics to the dynamics of wealth implied by
the dynamics we calculated for
optimal consumption.</p>

<p>If $\omega$ is the fraction of wealth we invest in the risky security
and $1-\omega$ is the fraction invested in the riskless security,
then the dynamics for wealth can be written
$$
\dd W_t = \omega (\mu -r) W_t \dd t + (r W_t - C_t) \dd t + W_t \omega \sigma \dd Z_t.
$$</p>

<p>Now, we can derive an expression for $\omega$ by matching the terms
of this equation with the terms of equation (\ref{wealth-dynamics-from-optimal-consumption}).
From the terms on $\dd Z_t$,
\begin{align*}
W_t \omega \sigma &amp;= \frac 1 a C_t \frac 1 \gamma \eta \\
\omega &amp;= \frac \eta {\sigma \gamma}.
\end{align*}</p>

<h1>Part 2</h1>

<p>It seems like consumption is stochastic because consumption here <em>is</em> stochastic. 
Consumption
depends on the state of the economy. It is, however,
$\mathcal F_t$-measurable, so optimal consumption at time $t$
depends only on information available at time $t$. 
Because of the positive Sharpe ratio $\eta$ and finite risk aversion, the agent will invest in the risky security. As we showed previously, consumption
is a fraction of wealth, $C_t^* = a W_t$. Wealth depends on the performance
of the agent's investments. In good times, the agent consumes more.
The fraction of wealth consumed, $a$, depends on
the interest rate $r$, subjective discounting $\rho$, risk aversion
$\gamma$, and the market price of risk (Sharpe ratio) $\eta$.</p>

<h1>Part 3</h1>

<p>One way this can occur is if we assume that the agent can only invest
in the riskless security. Just as well, let $\eta = 0$. Also,
suppose that the interest rate is equal to the subjective discount rate, $r = \rho$. </p>

<p>Doing this, we see that $\pi_t = \exp\{-r t\}$. Also, from
the budget constraint we know that wealth is
$$
W_t = B_t + \theta_t S_t + \E_t \frac{1}{\pi_t} \int_t^\infty \pi_s w \dd s = B_t + \theta_t S_t + \frac w r,
$$
where $B_t$ is the amount on money invested in the riskless asset, $\theta_t$
is the dollar amount invested in the risky security $S_t$, and the remaining
term is the expected discounted present value of future wages (the expectation
here could have been left out since $\pi_s$ and $w$ are constant in this case, 
but I've included
it for consistency).
Also, since $\eta = 0$, $a = r$. Thus,
$$
C_t^* = r W_t = r \left( B_t + \frac w r\right).
$$
Since $B_0 = 0$ by assumption, $C_0 = w$. Loosely speaking, an induction-like
argument gives us that $B_t = 0$ for all $t$ and, thus,
$$
C_t^* = \frac w r = w.
$$</p>
","17469"
"What's the significance of the triangular region for calculating the deadweight loss?","146","","<p>I am familiar with the concept of deadweight loss but I can't deduce the significance of the triangular region we consider deadweight loss as.<a href=""https://i.stack.imgur.com/LufM5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LufM5.png"" alt=""Demand Supply Curve""></a></p>

<p>I mean what's the issue with taking the deadweight loss as the area under ABCD instead of CDE or for that matter CDF (F being the mid point of DE) or does that particular area represents some quantity from economic perspective that I might be missing out on?</p>
","<p>I suspect your chart could look more like this:</p>

<p><a href=""https://i.stack.imgur.com/A5hiU.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/A5hiU.png"" alt=""enter image description here""></a></p>

<p>Initially with the price and quantity at E, the combined surplus is the triangle to the left (between the orange line and the lower green line to the left of E, i.e. the pink and grey areas).</p>

<p>But with for example a tax, the new equilibrium has consumers paying the price at C, so the new combined surplus is still between the orange line and the lower green line, but only to the left of C (i.e. the pink area).</p>

<p>So the deadweight loss is the triangle CEF (i.e. the grey area) which is the loss in surplus associated with the reduced quantity.  If all three lines are straight, and the green lines are parallel then this is the same area as the triangle CDE, but not necessarily otherwise.    </p>
","13508"
"Are White's Robust standard errors robust to clustered errors?","145","","<p>I want to ask about OLS White's 1980 ""robust"" standard errors. 
The key assumption, is that regression errors $u_i$ have distinct variances $σ_i^2$. Then the variance matrix is: $$\Sigma = \operatorname{diag}(\sigma_1^2, \ldots, \sigma_n^2)$$ with its White's estimator: $$\hat\sigma_i^2 = \hat u_i^2$$ This is the HCE (heteroscedasticity-consistent estimator). 
 Is the White's robust variance of $\hat{\beta}$ estimated by OLS assuming  independence? For example, assume that there is some $i,j$ such that $$Cov(u_i,u_j)\neq0$$ Because $i,j$ are part of a cluster. In that case $\Sigma$ is not diagonal but has the same diagonal as before. Will the White estimator converge to the diagonal of the true $\Sigma$?  </p>
","<p>No. White's robust errors are only robust to errors that vary linearly based on X(t).  If you have a type of serial correlation or clustering you will want to use Hansen method to adjust standard errors.</p>
","5755"
"Duality Proof - Consumer Theory","145","","<p><em>For solving this question, which assumptions/axioms should be used and should Lagrange multipliers be equal or different?</em> </p>

<p>Think of an agent with utility function u() and wealth w. Assume that u() is continuus and represents a locally non-satiated preference relation. The utility maximization problem of this agent can be stated as:</p>

<p>max  u(x)
 s.t. p.x ≤ w</p>

<p>On the other hand, when the agent’s constraint is to attain a utility level h, her expenditure minimization problem can be stated as:</p>

<p>min  p.x 
s.t. u(x) ≥ h</p>

<p><strong>Show that if x* is optimal in the utility maximization problem when w > 0, then x* is optimal in the expenditure minimization problem when the constraint is to attain a utility level u(x∗).</strong></p>
","<p>Let us prove it by contradiction. Suppose that $x^{*}$ is optimal for the first problem but not for the second. Since $x^{*}$ is not optimal for the expenditure minimization problem, there exists a bundle $x$ such that 
\begin{equation*}
u(x) \geq u(x^{*}) \text{ and } p \cdot x &lt; p \cdot x^{*}
\end{equation*}</p>

<p>Since the function $y \rightarrow p.y$ is continuous, and $p \cdot x &lt; p \cdot x^{*}$, there exists $\epsilon&gt;0$ such that $\|y-x\|&lt;\epsilon \Rightarrow p \cdot y &lt; p \cdot x^{*}$. In addition, since preferences are locally nonsatiated, there exists $y$ such that $\|y-x\|&lt;\epsilon$ and $u(y)&gt;u(x)$. Take such a $y$. We have \begin{equation*}
u(y) &gt; u(x) \geq u(x^{*}) \text{ and } p \cdot y &lt; p \cdot x^{*} \leq w
\end{equation*}</p>

<p>Or, in other words,
\begin{equation*}
u(y)&gt;u(x^{*}) \text{ and } p.y &lt; w
\end{equation*}
which contradicts the assumption that $x^{*}$ is a solution of the utility maximization problem.</p>
","10975"
"Kimball (1995) Specification of Final Good Production","144","","<p><a href=""http://www.nber.org/papers/w5046"" rel=""nofollow"">Kimball (1995)</a> defines production of the final good ($Y$) with intermediate goods $y_l$ in his equation (1) as</p>

<p>$$ 1 = \int_0^1 G\left(\frac{y_l}{Y}\right) dl $$</p>

<p>with $G(1) = 1$, $G'(x) &gt; 0$ and $G''(x) &lt; 0$.</p>

<p>I have never seen such a construct before. What does the $1$ on the left-hand-side mean, is that a normalization or some cost construct? An introduction into this type of production function would be greatly appreciated.</p>
","<p>Some input:<br>
Kimball assumes a constant-returns-to-scale (CRS) production of the final good $Y$ from the intermediate goods (and no other inputs are involved in this function). Turn to discrete space for a moment, and this means that we would have something like</p>

<p>$$Y = F(y_1,...,y_l,...,y_m)$$</p>

<p>Since this is a CRS function we have</p>

<p>$$1 = F\left(\frac {y_1}{Y},...,\frac {y_l}{Y},...\frac {y_m}{Y}\right)$$</p>

<p>But also, from Euler's theorem for homogeneous functions we have</p>

<p>$$Y = \sum_{i=1}^m \frac {\partial F}{\partial y_i}\cdot y_i \implies 1 = \sum_{i=1}^m \frac {\partial F}{\partial y_i}\cdot\frac{ y_i}{Y}$$</p>

<p>Combining and manipulating the index into $[0,1]$-continuity we get something like</p>

<p>$$1 = F\left(\frac {y_1}{Y},...,\frac {y_l}{Y},...\frac {y_m}{Y}\right) =\sum_{i=1}^m \frac {\partial F}{\partial y_i}\cdot\frac{ y_i}{Y}\rightarrow \int_0^1\left[\frac {\partial F}{\partial y_l}\cdot\frac{ y_l}{Y}\right]{\rm d}l$$</p>

<p>In a sense, $G(y_l/Y)$ is the elasticity of final output with respect the the $l$-th intermediate good. Given the assumptions on $G()$, it rules out a Cobb-Douglas CRS production function, where the elasticities not only sum to unity but they are constant, and it looks, say, to a C.E.S. production function with constant returns to scale, where the elasticities are variable but always sum up to unity.</p>
","5172"
"Why does $\frac{MP_L}{MP_K} = \frac{w}{r}$?","144","","<p>I did a practice problem set. I was given a production function $F(K,L)$ and had to derive the firm's cost function. To do this, I used the following relationship: </p>

<p>\begin{equation}
\frac{MP_L}{MP_K}=\frac{w}{r}
\end{equation}</p>

<p>I found this formula in a set of lecture notes online. I have no idea where it comes from. I understand what $MP_K$, $MP_L$, $w$, and $r$ are but I don't know why these ratios are equal. I got the problem correct, but I want to understand this point better. </p>

<p><strong>My Question:</strong> </p>

<p>Can someone explain why this ratio is true? </p>
","<p>This is a result of firm maximization.  Consider a problem that a profit maximizing firm faces --it must rent capital, $k$, at rate $r$ and hires labor, $l$, at wage $w$ to produce goods ($F(k, l)$) for which we can sell at a normalized price of 1.</p>

<p>$$ \max_{k, l} F(k, l) - w l - r k $$</p>

<p>Then if we just think about the firm's maximization, we can take derivatives w.r.t $k$ and $l$ to get:</p>

<p>$$ F_k(k, l) - r = 0 $$
$$ F_k(k, l) = r $$</p>

<p>and</p>

<p>$$ F_l(k, l) - w = 0 $$
$$ F_l(k, l) = w $$</p>

<p>Notice that by definition $MPL_K = F_k(k, l)$ and $MP_L = F_l(k, l)$.  If we take the ratio of the two equations then we get what you initially introduced --that is:</p>

<p>$$ \frac{F_l(k, l)}{F_k(k, l)} = \frac{MP_L}{MP_K} = \frac{w}{r} $$</p>

<p>Edit: As mentioned in another answer, this is imposing some assumptions on the behavior of $F(k, l)$.  These assumptions are $\frac{\partial F}{\partial k} &gt; 0$, $\frac{\partial F}{\partial l} &gt; 0$ and $\frac{\partial^2 F}{\partial k^2} &lt; 0$ $\frac{\partial^2 F}{\partial l^2} &lt; 0$</p>
","3053"
"Slutsky matrix computed from budget shares","143","","<p>In Haag et al. 2009 Testing and imposing Slutsky symmetry in nonparametric demand systems, the authors claim that the Slutsky matrix can be computed from share functions expressed in terms of logged prices and logged wealth. 
In particular they claim that, let $p$ and $w$ be logged prices and logged wealth.
$s_{ij}=\frac{\partial{b_i(p,w)}}{\partial{p_j}}+\frac{\partial(b(p,w))}{\partial w}b_j(p,w)+b_j(p,w)b_i(p,w)-\delta_{i,j}b_i(p,w)$
where $\delta_{i,j}$ is the kronecker delta function that says that in the diagonal terms we have to substract $b_i(p,w)$. 
He claims that this is the Slutsky matrix in unlogged prices terms, but how can this beif everything is in terms of shares. I have tried to derive it myself but I cannot reproduce what they have, but maybe I am making some mistake. The authors cite Mas-Colell et al. do you know the exact reference in the book they only provide the general reference.
Reference:Haag, B. R., Hoderlein, S., &amp; Pendakur, K. (2009). <a href=""http://dx.doi.org/10.1016/j.jeconom.2009.04.003"" rel=""nofollow"">Testing and imposing Slutsky symmetry in nonparametric demand systems</a>. Journal of Econometrics, 153(1), 33–50.</p>
","<p>In all indexed references to the Slutsky matrix in Mas-Collel et al. no such relation can be found. It is my impression that the authors meant that the expression they write <em>conveys the same information and restrictions</em> with the original, being a scaled version of it.  </p>

<p>I will use indices $i$, $k$, and write the logarithm explicitly in order to avoid confusion. </p>

<p>$$\frac {\partial b_i}{\partial \ln p_k} = \frac {\partial (x_ip_i/w)}{\partial \ln p_k}$$</p>

<p>Get liberal with partial differentiation, think of it as a differential, which gives</p>

<p>$$\partial \ln p_k = \partial p_k/p_k$$</p>

<p>Insert above to get
$$\frac {\partial b_i}{\partial \ln p_k} = p_k\frac {\partial (x_ip_i/w)}{\partial p_k} = \frac{p_ip_k}{w}\cdot \frac {\partial x_i}{\partial p_k}$$
and rearranging</p>

<p>$$\implies \frac {\partial x_i}{\partial p_k} = \frac{w}{p_ip_k} \cdot \frac {\partial b_i}{\partial \ln p_k} \tag{1}$$</p>

<p>So we have expressed the first term of the usual Slutsky element in terms of logarithmic derivatives of budget shares. For the second component we have</p>

<p>$$\frac {\partial b_i}{\partial \ln w} = w\frac {\partial (x_ip_i/w)}{\partial w} = w \frac {(\partial x_i/\partial w)p_iw - x_ip_i}{w^2} = p_i\frac {\partial x_i}{\partial w} - b_i$$</p>

<p>rearranging and also multiplying by $x_k$ we get</p>

<p>$$\frac {\partial x_i}{\partial w} x_k = \frac {x_k}{p_i}\frac {\partial b_i}{\partial \ln w} + \frac {x_k}{p_i} b_i$$</p>

<p>Multiply and divide each element by $p_kw$:</p>

<p>$$\frac {\partial x_i}{\partial w} x_k = \frac {x_kp_kw}{p_ip_kw}\frac {\partial b_i}{\partial \ln w} + \frac {x_kp_kw}{p_ip_kw}  b_i$$</p>

<p>$$\implies \frac {\partial x_i}{\partial w} x_k = \frac {w}{p_ip_k}\frac {\partial b_i}{\partial \ln w}  b_k + \frac {w}{p_ip_k}  b_ib_k \tag{2}$$</p>

<p>Combining,</p>

<p>$$(1),(2) \implies s_{ik} = \frac {\partial x_i}{\partial p_k} + \frac {\partial x_i}{\partial w} x_k \\
=\frac{w}{p_ip_k} \cdot \frac {\partial b_i}{\partial \ln p_k} + \frac {w}{p_ip_k}\cdot \frac {\partial b_i}{\partial \ln w}  b_k + \frac {w}{p_ip_k}\cdot  b_ib_k $$</p>

<p>$$\implies s_{ik} = \frac{w}{p_ip_k} \Big(\frac {\partial b_i}{\partial \ln p_k} + \frac {\partial b_i}{\partial \ln w}  b_k +  b_ib_k\Big) \tag{3}$$</p>

<p>The term in the big parenthesis is what the authors give as the off-diagonal element of the Slutsky matrix. The scaling factor $\frac{w}{p_ip_k}$ is symmetrical, so the expression in the big parenthesis nevertheless reflects the same symmetry conditions as the usual $s_{ik}$ terms.  </p>

<p>If you apply the same method for the diagonal elements you will get the $-b_i$ term.  </p>

<p>This form of the Slutsky matrix I believe is old story, and it has come about for purposes of econometric estimation of demand systems. For example, in <a href=""http://eric.ed.gov/?id=EJ231058"" rel=""nofollow"">Theil, H., &amp; Clements, K. W. (1980). Recent Methodological Advances in Economic Equation Systems. American Behavioral Scientist, 23(6), 789-809.</a> we find this form of the Slutsky elements, which the authors call ""elements of the Slutsky matrix"" without any ""explanation"" as to why the textbook expressions are scaled.</p>

<p>But I would advise to go ahead and e-mail the authors asking for clarifications.</p>
","8189"
"Adjusting GDP for Environmental and Resource Impacts","142","","<p>It is widely recognised that GDP as conventionally measured does not reflect an economy’s impact on the environment and its consumption of natural resources.  There have been various attempts to develop broader measures of economic performance via adjustments to conventional GDP (some of which also address non-environmental limitations of conventional GDP), for example:</p>

<ol>
<li>Measure of Economic Welfare (<a href=""http://www.economicsonline.co.uk/Global_economics/Measure_of_economic_welfare_MEW.html"">Nordhaus &amp; Tobin 1972</a>)</li>
<li>“True NNP inclusive of natural resource stock diminution” (<a href=""http://qed.econ.queensu.ca/working_papers/papers/qed_wp_771.pdf"">Hartwick 1990</a>)</li>
<li>Gross Sustainable Development Product (GSDP) (<a href=""http://globalcommunitywebnet.com/globalcommunity/measurementofsd.htm#AF"">Global Community Assessment Centre</a>)</li>
<li>Genuine Progress Indicator (GPI) (eg <a href=""http://anielski.com/wp-content/documents/Alberta%20GPI%20Blueprint.pdf"">Anielski 2001</a>)</li>
<li><a href=""http://en.wikipedia.org/wiki/Green_gross_domestic_product"">Green GDP</a> (a term whose precise content appears to be disputed (see eg <a href=""http://www.rff.org/Documents/RFF-DP-06-24.pdf"">Boyd 2006</a>))</li>
</ol>

<p>Is this just a proliferation of alternative measures, or is it possible to discern progress or convergence towards a best or most useful measure that adjusts GDP for environmental and resource impacts, or perhaps different best measures for different purposes?</p>
","<p>A good place to start is a report by the U.S. National Academy of Science called <a href=""http://www.nap.edu/catalog/6374/natures-numbers-expanding-the-national-economic-accounts-to-include-the"" rel=""nofollow"">Nature's Numbers</a>. The upshot: There is a consensus among economists that it is possible to refine standard measures of GDP rigorously to incorporate adjustments for impacts on environment and natural resources. Implementation is in practice difficult due to data problems. </p>

<p>Most alternative indicies, e.g. GPI, are not consistent with national income accounting principles. But since there is a demand for such indicies, there is a supply response.</p>
","12744"
"Asset pricing Coursera resources","142","","<p>I am trying to learn <a href=""https://en.wikipedia.org/wiki/John_H._Cochrane"" rel=""nofollow"">John Cochrane's</a> <em><a href=""https://en.wikipedia.org/wiki/John_H._Cochrane#Asset_Pricing"" rel=""nofollow"">Asset Pricing</a></em>. I notice there are <a href=""https://en.wikipedia.org/wiki/Coursera"" rel=""nofollow"">Coursera</a> resources (<a href=""https://www.coursera.org/instructor/johncochrane"" rel=""nofollow"">link</a>). However, it is not available now. Did anyone try that class before? Does anyone know what's the next time it opens? Is it worth waiting for? Are there any good alternatives?</p>
","<p>I have uploaded all the videos on YouTube as two separate playlists which cover asset pricing part 1 &amp; 2 courses. </p>

<p>Asset Pricing part 1:  <a href=""https://www.youtube.com/playlist?list=PLpccx1MwQZb7t7HJ6lBo4L3DXhknCD0K7&amp;disable_polymer=true"" rel=""nofollow"">https://www.youtube.com/playlist?list=PLpccx1MwQZb7t7HJ6lBo4L3DXhknCD0K7&amp;disable_polymer=true</a></p>

<p>Asset Pricing part 2:  <a href=""https://www.youtube.com/playlist?list=PLpccx1MwQZb6XsKU3O81GrpqaxyyGoHpH"" rel=""nofollow"">https://www.youtube.com/playlist?list=PLpccx1MwQZb6XsKU3O81GrpqaxyyGoHpH</a></p>

<p>Regarding the class, I think Coursera moved to the new platform and thats why these courses and some others have disappeared. I heard that they are preparing the courses based on the new platform. </p>
","12878"
"Is the S&P 500 now in a boom-bust cycle?","142","","<p>This question was originally <a href=""https://money.stackexchange.com/questions/41773/is-the-sp-500-now-in-a-boom-bust-cycle"">posted</a> at money.stackexchange but was moved here per a commentor's suggestion after the question was put on hold for being opinion-based.  The original question was:</p>

<blockquote>
  <p>When I google ""SP500"" I get the following chart:</p>
</blockquote>

<p><img src=""https://i.stack.imgur.com/0FiDv.png"" alt=""SP500 history""></p>

<blockquote>
  <p>Isn't this a boom-bust cycle, that's overdue for a ""correction"" that
  drops everything back down to below the 1,000 level like in 2002 and
  2009? What are the arguments against such a prediction?</p>
</blockquote>

<p>The first comment someone posted argued against a drop but was confusing because it claims drops can happen from ""causal forces"" other than cycles.  That actually sounds like an additional reason for a drop (causal forces, not just cycles) although I wouldn't understand how a cycle would be established or maintained without causal forces in the first place.</p>

<p>It also claims ""you would only expect it to come back down on schedule if you believe that it goes up and down on schedule"".  That sounds like ""if there's a cycle, it will go up and down"", but doesn't make it clear how you determine if a cycle is happening.</p>

<p>The second comment says ""markets always move in cycles"" although the first half of the graph doesn't seem to back that up.</p>

<p>The third comment says ""in the long term the markets have exponential growth"" although it then cherrypicks the portions of the graph that reflect that (in effect replacing a ""long term"" argument with ""short term"" examples).  And exponential growth can't happen forever, right?</p>

<p>The final comment suggest a log graph, though none is offered.  My first search result for a log graph led to <a href=""http://www.advisorperspectives.com/dshort/updates/Regression-to-Trend.php"" rel=""nofollow noreferrer"">this page</a>, which actually seems to make the case the market is <strong>always</strong> cyclic, although it throws so many numbers around in such a complicated fashion I'm not left with a sense of real understanding.  (I also find it odd to compute things like annualized growth rate over 140 years, when any individual's investing career probably rarely exceeds 60 years, and most investors probably average much less.)</p>

<p>Returning to the original question, is there any argument the market is <strong>not</strong> cyclic, and not overdue for a substantial drop?  Also, is there any measurement indicating whether investors believe that, and are exiting index funds?</p>
","<p>Here's the <a href=""http://en.wikipedia.org/wiki/Efficient-market_hypothesis"">Efficient Market Hypothesis</a> (EMH) explanation for why one cannot say that a correction is overdue:</p>

<p>Suppose that it were widely known that, by looking at the above figure, one could ascertain that the market was ""due for a drop"" one week from now. Financial analysts and investors would look at the graph and come to this conclusion. How would people respond to this knowledge? They would go and sell their stocks before those stocks loose a substantial portion of their value. However, this flurry of selling activity would cause the price of the stocks (and hence the stock index) to fall today—one week earlier than forecast.</p>

<p>This example is obviously a highly simplified and stylised exposition of how markets function, but it should serve to make clear the basic point: any hypothesised means by which one can look at a chart like this and forecast the future movement of prices is automatically self-defeating and any information about the future of the market is instantly built in to the current price of securities. The drop you think might be due will come, says the EMH, if and only if new information about the economy becomes available that suggests the economic outlook is less promising that people had thought.</p>
","1867"
"Quantitative Easing in Africa","142","","<p>I am currently doing a research work on quantitative easing and can't find any example of it occurring in Africa. Have any African central banks ever used QE?</p>
","<p>For Quantitative Easing to happen, a central bank needs to expand its balance sheet by, more or less, ""printing money"" from scratch. Quantitative Easing is a difficult policy in that you want to encourage inflation to force investment, but at the same time you need to control that inflation. For this reason QE should be used only when central banks believe economy is growing slower than it could/should be, which does not happen a lot in Africa.</p>

<p>For QE to be efficient, you need a strong central bank/currency, ie printing new dollars will create more dollars, but printing new 1920s Deutschmarks will only bring down the value of an individual Deutschmark.</p>

<p>To my knowledge, the only African country that wandered in Quantitative Easing is <a href=""http://en.wikipedia.org/wiki/Economy_of_Zimbabwe#Hyperinflation_2004-2009"" rel=""nofollow noreferrer"">Zimbabwe</a>. The success of this policy may by itself discourage any other comparable country to engage in such a policy.</p>

<p>QE is a last resort policy for stalling economies. Japan, Western Europe and the USA are countries where QE has been widely discussed because it is sometimes believed investment is delayed in hope of better days - QE should prevent this, but this is not a typically African problem, to my knowledge.</p>

<p>TL;DR: Even if African central banks were strong enough to engage in QE, African economies don't need such a policy to date.</p>

<p>Note that as mentionned in a comment, Quantitative Easing is a set of policies that has no standardized definition and that some examples above are anachronic with regard to the relatively recent introduction of the notion. While the term dates back to the early 2000s, what we know describe as QE was never practised as strongly as in the 1930s and 1940s against the Great Depression.</p>
","5640"
"One bidder in 2nd price auction","141","","<p>in second priced auctions, the highest bidder wins the auction and pays the price of the second highest bidder. What happens if there's only one bidder? That bidder would have won the auction, but does the winner pay his/her own bid? Or does the winner pay zero, imagining a second bidder with zero value bid?</p>

<p>Thanks</p>
","<p>The purpose of a 2nd price auction (<a href=""https://en.wikipedia.org/wiki/Vickrey_auction"" rel=""nofollow noreferrer"">Vickrey Auction</a>) is to encourage bidders to bid their true maximum willing payment for a good rather than the lowest price they expect will win the auction. The reason for this is because they pay the value of the unknown second bid they don't have to worry about bidding to high because the highest bid will always pay the exact lowest they would have had to pay in order to obtain the product and don't have to worry about overbidding.</p>

<p>For a auction to be called an auction there must be multiple bidders. If I know that I am the only bidder I would always just bid <code>$.01</code> and get everything for free. To prevent this and other types of bidder collusion all auction houses have a minimum starting bid for a product usually determined by the seller. If no one is willing to pay more than the minimum then the product simply wont be sold. Individual rule for vickrey auctions differ depending on the venue but I imagine if only one bid is made then the price would default to the minimum bid set before the auction.</p>
","16663"
"Risk Premia in Continuous Time","141","","<p>Take some state variable $X(t)$, which follows the law of motion</p>

<p>$$ \dot X(t) = f(t)X(t) $$</p>

<p>where $f(t)$ is a policy function, and determines the growth rate of $X(t)$. As a second shock, we have $\psi$, which is iid. The agent defaults whenever</p>

<p>$$ g(X(t), \psi) \leq 0$$</p>

<p>Allow the agent to borrow some money that he will have to repay continuously. Let's compute the risk premium. The probability of default at $t+\epsilon$ is</p>

<p>$$Prob(g(X(t+\epsilon), \psi) \leq 0) $$</p>

<p>As the lending has to be repaid continuously, the interest rate, given some risk-free interest rate $r^*$ and risk-neutral lenders, is given by</p>

<p>$$ r^* = r \cdot \lim_{\epsilon\to 0} \left(1 - Prob(g(X(t+\epsilon), \psi) \leq 0)\right)$$</p>

<p>However, as the law of motion for $X(t)$ is continuous, in the limit, this becomes</p>

<p>$$ r^* = r \cdot \left(1-Prob(g(X(t), \psi) \leq 0) \right)$$</p>

<p>This would mean that the agent's risk premium is independent of what he is doing: his policy $f(t)$ does not appear anymore.</p>

<p>But since $f(t)$ affects the state $X(t)$ and the latter the default probability, I feel it should. What's my mistake here? </p>

<p>References are fine. Most of continuous time finance references I know are much too deep for this rather simple question.</p>
","<p>The easiest way to model short-term but risky debt in continuous time is to have your $\psi$ be the increment of a compound Poisson process. </p>

<p>Jumps in this process correspond to events that might or might not cause default; the size of the jump can enter together with the state $X(t)$ into a function like your $g(X(t),\psi)$ to determine whether or not default actually occurs. Using this formulation, one can circumvent your concern in the comment that ""debt is risk-less, if it is almost immediately paid back"". </p>

<p>If, for instance (in a simple case), default occurs whenever there is a nonzero increment in the compound Poisson, regardless of the size of this increment, then if the arrival rate of these jumps is $\mu$, the interest rate will be $r=r^*+\mu$, the risk-free rate plus the flow default rate. If (in a more complicated case) default only occurs for some increment sizes, according to a threshold that depends on $X(t)$, then we can get $r$ varying with $X$.</p>

<p>In this environment, your observation that $f(t)$ does not affect $r(t)$ is completely correct. But this is because $f(t)$ does not contemporaneously affect $X(t)$ and hence does not affect whether or not there will be a default if the Poisson shock occurs at time $t$. $f$ does affect <em>future</em> $X$, and thus will potentially affect future default probabilities and interest rates.</p>

<p>The property we see here - where your policy today doesn't affect your interest cost today, because short-term creditors only care about the <em>current</em> probability of default and your policy can't affect that right away - is generically a strange feature of short-term debt models, and is brought into starkest relief in the continuous-time environment. This is why models of long-term debt are often more realistic, because the price of long-term debt incorporates future default decisions and therefore the effects of policy on future values of the state variable.</p>
","577"
"Should central bank raise interest rates during a condition of liquidity trap?","141","","<p>I was studying about liquidity traps and understood it fairly well that according to widespread beliefs the monetary policy turns out to be ineffective as nominal interest rates are close to zero and the public has deflationary expectations. Since nominal rates are close to zero nobody wants to hold financial assets and prefer cash instead. 
My question here is that in such a condition when nobody is investing in bonds, should not the central bank raise interest rates to give higher incentive to bond holders. I know I am missing some point but can someone please explain this relationship between interest rates, inflation and bonds in the context of liquidity trap. </p>
","<p>A very good question, but first some clarifications.</p>

<p>The banking sector is unique from all other industries in that it creates its own liquidity.  Banks borrow short term low yield debt and invest in high yield long term assets.  The maturity mismatch that occurs in the aggregate is tremendous and not sustainable.  Banks are always reliant on individuals perpetually rolling over such short term debt as in the aggregate it can never be redeemed.</p>

<p>Many argue that such maturity mismatching is reckless and not responsible.  That banks should suffer the consequences when they gamble by with such outrageous maturity differences.  Instead the Fed makes the problem worse, by constantly guaranteeing a source of short term debt to constantly proper up long term assets banks have no business owning.</p>

<p>So you can't equate interest/investment with the economy at large with what banks do.  Banks are unique!  They're problems should not necessarily be our problems.</p>

<p>As for a liquidity trap...it is constantly happening and CB's like the Fed are constantly bailing them out by injecting short term debt into the fed funds market through the ""open market"".</p>

<p>Banks mostly rely on other banks for their sources of reserves.  When banks stop trusting each other, the money multipliers collapses and the means by which short term debt can be redeemed starts to vanish.  I like to think of this as a liquidity fire instead of a liquidity trap as the banks have promised more reserves than they have in the aggregate...and when they scramble to claim their chairs when the music stops, it will just make the problem worse.</p>

<p>When a central bank talks about interest rates approaching zero, they're not talking about real investments (like securities and mortgages).  They're just talking about the rate they are trying to manipulate banks to lend each other. Bank to bank debt. Given that such a rate is determined by bank trust, such a rate does not necessarily have to correlate to the greater market rate at all.</p>

<p>Raising the fed funds rate will great increase a liquidity trap (not necessarily a bad thing).  More bonds won't make a difference...the banking system's ponzi scheme is being exposed and they need more reliable short term assets...not long term like bonds.  </p>

<p>Kind of a long answer...but I hope you found this somewhat helpful.  The question is important.</p>
","9396"
"Throw-away paradox with independent goods","141","","<p>The <a href=""https://en.wikipedia.org/wiki/Throw_away_paradox"" rel=""nofollow"">throw-away paradox</a> is a situation in which a trader can gain by throwing away some of his initial endowment.</p>

<p>The specific example, brought by <a href=""http://www.sciencedirect.com/science/article/pii/0304406874900123"" rel=""nofollow"">Aumann and Peleg in 1974</a>, concerns an economy with two commodities and two traders:</p>

<ul>
<li>In one situation, the initial endowments are (20,0) and (0,10). In competitive equilibrium, the bundle of trader A is (4,2).</li>
<li>In the second situation, trader A throws away 10 units of commodity x, so the initial endowment is now (10,0) and (0,10). In equilibrium, the bundle of trader A is (5,5) - more of ''every'' commodity than in the first situation!</li>
</ul>

<p>In their example, both traders have the same utility function, which has the following characteristics:</p>

<ul>
<li>It is homothetic;</li>
<li>The slope of the indifference curves at (y,y) is -1;</li>
<li>The slope of the indifference curves at (2y,y) is -1/8.</li>
</ul>

<p>One such function is $$u(x,y)=\frac{1}{(x+ay)^{-3}+(ax+y)^{-3}}$$</p>

<p>But, in this example, the products are dependent.</p>

<p>MY QUESTION IS: Is there an example of such a ""throw away paradox"", when the products are independent?</p>

<p>NOTE: both products are goods (have non-negative utility).</p>
","<p>It seems (from the first page, at least; I don't have JSTOR access right now) that the essence of Aumann and Peleg's example is that</p>

<blockquote>
  <p>this rise in <em>price</em> of the commodity [trader A] holds is more than enough to compensate for the drop in the amount.</p>
</blockquote>

<p>One similar situation from history occurred during the New Deal, when farmers were paid to plough over cotton fields and send hogs to be slaughtered for no reason, in order to take excess quantities of these goods off the market.</p>

<p>Obviously, the difference here is that this was a centralized intervention in a decentralized (and huge) market. The set of incentives are more complicated, and the many ""trader A's"" in this scenario were compensated for throwing away their goods. But the sentiment is very similar.</p>
","8581"
"What would be the defining characteristic of New-Keynsian thought?","141","","<p>If you had to summarize New-Keynsian thought into one paragraph, or a set of equations, what would it be?</p>
","<p><a href=""http://press.princeton.edu/titles/8654.html"">Gali's Monetary Policy, Inflation, and the Business Cycle: An Introduction to the New Keynesian Framework</a>, provides an advanced undergraduate / first-year graduate student introduction to these models, and I'd recommend it for self studies. According to <a href=""http://press.princeton.edu/chapters/s8654.pdf"">chapter 1, available online, which offers an overview of the  New Keynesian Model</a>, the key elements are:</p>

<ol>
<li>Structural characteristics of Real Business Cycle (RBC) Dynamic Stochastic General Equilibrium (DSGE) models</li>
<li>Monopolistic competition</li>
<li>Nominal rigidities</li>
<li>Short run non-neutrality of monetary policy</li>
</ol>
","3410"
"While calcluating GNP, the overall income of a citizen working abroad is considered or only his/her remittances?","141","","<p>Suppose a citizen of Country A is working in Country B with income X USD, and he sends Y USD as remittance to A, what is considered while calculating GNP? X or Y? (X is inclusive of Y)</p>
","<p>GNI (<em>Gross National Income</em>) is the current description of what used to be called <em>GNP</em>.  It is GDP (<em>Gross Domestic Product</em>) plus net primary income from abroad (primary income receivable from the rest of the world less primary income payable to the rest of the world)</p>

<p>Assuming this individual is a long-term resident (1 year or more) in Country B, than none of this counts as Country A's GNI (<em>Gross National Income</em> is the current description of what used to be called <em>GNP</em>).  The earnings count in Country B's GDP (as part of the income measure) and GNI, while the remittance is part of Country A's secondary income from Country B and affects the Balance of Payments current accounts of the two countries.  See <a href=""https://www.imf.org/external/pubs/ft/bop/2007/pdf/chap12.pdf"" rel=""nofollow"">chapter 12 of the IMF Balance of Payments manual</a>.  Something similar happens with the self-employed</p>

<p>If however this individual is a short-term resident (less than a year) or a cross-border worker, employee compensation counts as primary income and so is part of Country A's GNI though Country B's GDP (as part of the income measure).   Any goods or services this individual pays for in Country B is counted as a export from Country B to Country A. See <a href=""https://www.imf.org/external/pubs/ft/bop/2007/pdf/chap11.pdf"" rel=""nofollow"">chapter 11 of the IMF Balance of Payments manual</a>. For short-term self-employed migrants, income counts as an export of services from Country B to Country A, and so counts in Country A's GDP and GNI, but again anything spent in Country B counts as trade the other way</p>

<p>Measuring these flows and making these distinctions are difficult for national statistical services, especially for migrant workers who do not know how long they will be staying in another country </p>
","13837"
"Who exploits comparative advantage in international trade?","141","","<p>Suppose that under autarky, Colombia makes coffee and cars at \$1 and \$2 each, and Japan makes coffee and cars at \$20 and \$10 each. Since Japan has a comparative advantage in car manufacture, the standard theory says that Colombia will import cars and export coffee.</p>

<p>However, I'm having a hard time imagining how this actually happens in practice. If I run a Colombian car business, why would I import cars from Japan, when they cost five times as much? Why not just buy cars at home?</p>

<p>In general, I see no reason why any business dealing in a single market should care about price ratios; they only see the absolute prices of a single good. For the trade to actually happen in this case, you'd either need a company that trades both cars and coffee (do those actually exist?) or government-controlled trade. Neither of these feel realistic.</p>

<p>If we can look at <a href=""https://en.wikipedia.org/wiki/Comparative_advantage#Ricardo.27s_example"" rel=""nofollow noreferrer"">Ricardo's original example</a>, the same problem appears. Ricardo is assuming that production across an entire country is synchronized in some way; his theory would work if a single business in each country controlled all production of all goods there. But I don't see how the logic holds if there are separate companies producing cloth and wine.</p>

<p>In real life, how are comparative advantages actually exploited?</p>
","<p>It's fine to make a supposition that it costs Colombia twice as much to make cars as coffee, and Japan twice as much to make coffee as cars.  It's also fine to express these ratios in terms of the respective local currencies.    </p>

<p>The apparent problem you describe only arises because you go beyond the above and express the costs in terms of a common currency (\$).  But in a situation of autarky, there is no way in which the exchange rates needed to convert prices in other currencies to \$ could be determined. Thus your supposition is incoherent.</p>

<p>The way in which comparative advantage would be exploited, given the ratios you describe and given free trade, is that the rate of exchange of Colombian to Japanese currency would adjust to a level at which, in both countries, Colombian coffee is cheaper than Japanese, and Japanese cars are cheaper than Colombian. The Colombian car business will then be able to benefit from comparative advantage while not needing to look beyond the relative prices of locally produced and imported cars. </p>

<p><em>Addendum</em>:  If, in the past, two countries both used gold as a currency, this would not, given autarky, be equivalent to a common currency. Even if the gold were physically the same, it might just happen (eg for geological reasons) to be scarcer and therefore more valuable in one country than the other.  In the absence of international trade and of payment in gold for traded goods, there would be no mechanism to equalize the value of gold in the two countries.  It would therefore be feasible that the cost, in terms of their respective gold currencies, of producing every good would be higher in one country than the other.  Given free trade, however, the value of gold in the two countries would be equalized at a level at which some goods would be cheaper in one country and some in the other.  The mechanism for equalization would be that people and businesses in the more expensive (and therefore more gold-abundant) country,  taking their own rational decisions and without any need for central control, would import goods from the cheaper country, paying in gold and therefore causing an outflow of gold to the cheaper country.</p>
","14517"
"Why does competition work for capitalism?","141","","<p>As far as I know, capitalism is based on competition: 
If two(or more) companies produce similar products that compete against other, these companies are in a competition.
Because the objective of a company is to earn as much money as possible, the company will try to maximise the selling of their product. However, because normally there are more than a single company, every company has to sell their best possible product for the lowest price without making enough profit. That leads to a situation where the consumer gets a very good product for a very fair-realistic price.</p>

<p>My problem here is, that this only works if every company only can make the decision about what price they make for what quality once. Like in the <a href=""https://en.wikipedia.org/wiki/Prisoner%27s_dilemma"" rel=""nofollow noreferrer"">prisoner's dilemma</a>.
The prisoner (the company) will (usually; if he is sane) make the decision to betray his member (-><a href=""https://en.wikipedia.org/wiki/Game_theory"" rel=""nofollow noreferrer"">Game Theory</a>).
The point is the ideal strategy changes if this 'game' will be repeated forever (is identical to a situation where nobody knows, when the game ends). The strategy any sane prisoner would take is to not betray his gang-member, however, if his member betrays him he will betray him, too, until his member does not betray him anymore.
Because this is a simplified version of a real competition, real companies should act like the prisoners: make a high price until the competitor make a low price. However, no company would make a low price because although they would make better profit in short term, the company would make better in longterm if they made the unspoken deal with the other companies.</p>

<p>So why is it not like this in real world, or is it like this and I haven't noticed that yet?</p>
","<p>When two companies produce commodities and/or services that are <em>substitutes</em> then they are simply producing for a market that allows the presence of two or more substitutes.</p>

<blockquote>
  <p>""...If two (or more) companies produce similar products that compete against other, these companies are in a competition""</p>
</blockquote>

<p>Two firms do not necessarily compete with each other when they are supplying substitutes in the market. </p>

<p>What needs to be clear is that qualifying a market as <em>competitive</em> amounts to making a series of statements about the way the participants in the market behave, their numbers, how potential new participants can interact with the market, the relevant time scale etc. </p>

<p>Narrowing the focus on two members of a market and claiming that they are in competition is not warranted by the assumptions. Nothing has been said about the structure of the market they are embedded in. They could eg be simply trying to flood the market with alternatives to a third commodity so as to narrow the market share of a third producer; the possibilities are really unbounded.</p>

<blockquote>
  <p>""...Because the objective of a company is to earn as much money as possible, the company will try to maximise the selling of their product.""</p>
</blockquote>

<p>The objectives of firms are really as diverse as is the number of industries and producers immense. ""<em>Making money</em>"" is not always a single operative constraint. Firms have a plurality of goals and obtaining liquidity is one of them. How binding that goal is depends on a host of issues like the market they are embedded in, the firm's size and relative position in the market, probably its access on financing etc.</p>

<p>Profit maximization is an assumption about the behavior of firms which is historically relevant and analytically useful but it is not always the case that firms are maximizing profits. They may be going for market share, or they may be simply optimizing some other metric. And, of course it could very well be the case that they are just winging it!</p>

<blockquote>
  <p>""...However, because normally there are more than a single company, every company has to sell their best possible product for the lowest price without making enough profit...""</p>
</blockquote>

<p>Again, this claim is not universally true. The number of firms in the market is not always a guarantee of '<em>quality</em>' and '<em>affordability</em>'. What matters is the cost structure of the industry, the technology and the assumptions about the market structure. Also, profits that vanish to zero is, again, a feature of the competitive model; not what '<em>really</em>' obtains.</p>

<p>Now, as far as the '<em>Prisoner's dilemma</em>' is concerned: In an one-shot game the <em>best</em> thing to do is to '<em>defect</em>'. In a repetitive setting, that is also open-ended (no predetermined end date) I think that anything goes. You would have to make more assumptions about the number of players and their strategies <em>over time</em> (and in response to others') in order to arrive at definitive conclusions. </p>

<p>The short and non-definitive answer to the question of why don't firms collude when involved into price-competition with each other would be that there are laws that prevent them from that ie the fundamental cost structure of the game is different than what the '<em>dilemma</em>' posits.</p>
","18314"
"Infinitely repeated games and real-world situations?","140","","<p>I do understand the gist of what infinitely repeated games are in that T=$\infty$ ; that is the stage game is played each period for an infinite number of periods.</p>

<p>In his book <em>""Strategy""</em>, Watson makes the following claim:</p>

<blockquote>
  <p>Although such a game may not seem realistic at first (people do not
  live forever), infinitely repeated games are useful <strong>for modeling some
  real-world situations</strong>.</p>
</blockquote>

<p>With reference to the part in bold, could you elaborate?</p>

<p>Thanks.</p>
","<p>In most situations it is not clear when a game ends, it is just clear that at every point in time there is a probability that this is the last period of them game.</p>

<p>Just try to say what is this $T$ for the life of a human? 150 years? Even if you are 150 years old there is a (probably small) chance that you will survive another year. And the next year? There is also another chance to live another year, and so on.</p>

<p>As long as there is no fixed endpoint to the game, infinitely repeated games are, in my opinion, more realistic as long as there is some chance of ending the game included (i.e., as a discount rate).</p>

<p>Infinitely repeated games are also a way to resolve some problems backward induction (for example in the Chain-store paradox). You really have to know that there is a very last situation to use backward induction.</p>
","5008"
"Long-term interest rate and stock market correlation","140","","<p>What correlation is there between (1) long-term interest rates and (2) the stock market valuation? Please provide a simple intuitive explanation. </p>

<p>For example, as I understand it from <a href=""http://www.nytimes.com/2015/05/13/business/daily-stock-market-activity.html"" rel=""nofollow"">recent news reports</a>, rising long-term interest rates put pressure on the stock market. Why?</p>
","<p>Many organisations <em>borrow</em> money to purchase shares (trading on margin). Their enthusiasm for doing this will depend on the interest rate. So lower interest rates means more borrowing for purchasing shares, which means prices rise.</p>

<p>A similar thing happens with other stuff that people tend to buy with borrowed money - like housing.</p>
","6360"
"Ordinal utility and monotonic transformations","140","","<blockquote>
  <p>If <em>u(x)</em> is an ordinal utility function that represents the (weak) preference relation <em>R</em>, then</p>
  
  <p>(a) any strictly monotonic transformation of <em>u(x)</em> also represents $R$, <em>or</em></p>
  
  <p>(b) any monotonic transformation of <em>u(x)</em> also represents $R$.</p>
  
  <p>Which is the right proposition, (a) or (b)?</p>
</blockquote>

<p>I thought that (b) is the right answer, but when I looked up various online sources I found both definitions, so I'm no longer sure. </p>

<p>I thought (a) cannot be right, because the condition for a monotonic transformation is usually formulated as a conditional: F is a strictly monotonic transformation of u if the following holds: (1) if $u(x)&gt;u(y)$, then $F(u(x))&gt;F(u(y))$. But that doesn't deal with the case (2) $u(x)=u(y)$, which represents xIy. Wouldn't $F(u(x))&gt;F(u(y))$ be compatible with (1) and (2), but represent xPy? Thinking about it, however, it seems that the same as (1) with ""greater than or equal"" wouldn't do it either. Are the monotonicity conditions formulated as biconditionals? I'm confused.</p>
","<p>You need to be clear about the definitions. Lets take:</p>

<p>(1) $u: X \to \mathbb{R}$ <strong>represents</strong> $\succsim$ if $u(x) \geq u(y) \iff x \succsim y$.</p>

<p>(2) A function $h: \mathbb{R} \to \mathbb{R}$ is <strong>monotone</strong> if $z \geq w \implies h(z) \geq h(w)$. $h$ is <strong>strictly</strong> monotone if $z &gt; w \implies h(z) &gt; h(w)$.</p>

<p>First, note that every strictly monotone function is monotone. Why? Well let $z \geq w$, and there are two cases to check: (i) $z &gt; w$: apply the definition; (ii) $z = w$: then $h(z) = h(w)$ by the definition of equality (this is because $\mathbb{R}$ is a totally ordered set). </p>

<p>So immediately, we see that your condition (b) implies your condition (a). However, (b) is false (I do not understand Kanak's line of reasoning, but it is certainly wrong, although perhaps can be rationalized by non-standard definitions). To show that it is wrong, we need a counter example. Lets let $X = \{x,y\}$ and let $x \succ y$. Then $u(x) = 1$ and $u(y) = 0$ represents $\succsim$. Moreover, $h: z \mapsto 0$ is a monotone transformation. But, $h(u(x)) = h(u(y)) = 0$ does not.</p>

<p>Indeed, this example shows that it is <em>weakly</em> monotone transformations that destroy information (they need not be invertible), which in terms of the representation, indicates that strict preference gets collapsed into weak inequality. </p>

<p>Showing that (a) holds is a straightforward application of the definitions. (Hint: show that strict monotonicity can be defined via a bi-conditional statement).  </p>
","18512"
"Predictive Game Theory","140","","<p>I was reading this neat piece by Fudenberg <a href=""http://fudenberg.fas.harvard.edu/predictive%20game%20theory.pdf"">http://fudenberg.fas.harvard.edu/predictive%20game%20theory.pdf</a> on Predictive Game Theory. He argues correctly that most traditional work in Game Theory is not suited for prediction in real world set-ups. </p>

<p>Do you know any work that has advanced the theory or empirics of  predictive game theory? </p>

<p>I am aware of some recent work of partial identification for games but I am more interested in learning in games and off-equilibrium dynamics. </p>
","<p>Actually, Section 3 of the paper you linked is probably one of the most comprehensive lists you could find of the movers and the shakers with regard to predictive game theory. I know that many of them have both published and working papers addressing these issues. Fudenberg even addresses those specific two topics. A few selections from the paper:</p>

<blockquote>
  <p>Ignacio Esponda, Philippe Jehiel, and David K. Levine are leaders in studying adaptive processes in extensive form games, and the sorts of non-Nash equilibrium outcomes that can persist even when players have a lot of experience with the game.</p>
  
  <p>Michel Benaïm, Josef Hofbauer, William Sandholm, and Sylvain Sorin are making important advances in the mathematics of dynamical systems and applying them to non-equilibrium dynamics.</p>
  
  <p>Chaim Fershtman and Ariel Pakes are developing estimation methods for field data that allow for incorrect off-path beliefs.</p>
  
  <p>Jeff Shamma is a pioneer in bringing techniques from the feedback-control literature to the study of learning in games.</p>
</blockquote>

<p>I would recommend going through these authors' websites and looking for papers that fit.</p>
","6194"
"Urn balls and probabilities","140","","<p>Think of the following balls as individuals of populations. </p>

<p>Say I have $U$ urns, and some balls. Both numbers are <em>really</em> large. So large, that authors like Blanchard and Diamond have approximated the binomial operations that follow with Poisson probabilities.</p>

<p>The balls are either red ($R$) or green ($G$). At the beginning of the period, every ball is (randomly, iid) tossed into an urn. There is no miss chance (i.e. every ball is in <em>some</em> urn). Some urns will have more than one ball, some might have none.</p>

<p>There are two exercises I want to do in this setup, and I'm not sure to what extent they're overlapping (i.e. helping me understand one would help me understand the other one as well), so I will post both.</p>

<p>My issue is kind of that I have a binomial thinking going on, and you can see that from the structure that I have imposed onto solving the following probabilities. Should I switch to Poisson probabilities instead? What is the <em>neatest</em> way to solve the following setups?</p>

<h3>Red Ball Solo</h3>

<p>I would like to compute the ex-ante probability of a red ball (from the perspective of a red ball) of being tossed into an urn where there is no other red ball.</p>

<p>So far, I was thinking about doing</p>

<p>$$ 
Prob(\text{sole red ball}) = \sum_{x = 1}^{R + G} Prob(\text{Urn has $x$ balls}) \cdot \sum_{y=0}^{x-1}Prob(\text{No other red ball }  | x \text{ balls})
$$ </p>

<h3>Red Ball Super Ball</h3>

<p>Out of each urn, one red ball becomes a super ball. This probability is uniform. I would like to compute the probability of a red ball becoming a super ball.</p>

<p>My abstract idea was again similar:</p>

<p>$$ 
Prob(\text{red ball becomes super ball}) = \sum_{x = 1}^{R + G} Prob(\text{Urn has $x$ balls}) \cdot \sum_{y=0}^{x-1}Prob(\text{$y$ other red balls | $x$ total balls }) \frac{1}{1+y}
$$ </p>
","<p><em>(If urns are vacancies and balls are unemployed, what distinction between unemployed workers does the Red/Green dichotomy reflects?)</em>  </p>

<p>Each ball has in front of it an identical box, each with the exact same lottery tickets, its ticket has a number on it, and each number corresponds to an urn. </p>

<p>We say ""Go!"" and each ball draws ""randomly"" (i.e. with equal probability) a ticket from the box in front of it. Note that the requirement that the probabilities are Uniform, impose the condition that, if we want to have proper distributions, the number of urns must be <em>finite</em> (not even countably infinite -see <a href=""https://stats.stackexchange.com/questions/103930/discrete-uniform-random-variable-taking-all-rational-values-in-a-closed-inter"">this post in statistics.se</a>) Then:</p>

<p><strong>RED BALL SOLO</strong><br>
<strong>From the point of view of a single Red ball, what is the probability that it will draw a number that no other Red ball draws?</strong></p>

<p>Since each ball draws independently from the others, it is clear that we don't care at all about the existence of Green balls, to the degree that no upper limit of ""number of balls in an urn"" exists (if it existed the draws would not be independent). So Green balls (their number and what they draw from their boxes) can be kept out of the picture.</p>

<p>Since Red balls are indistinguishable, let's take $R_1$ as our hero. If it draws the number $1$ (i.e. conditional on) we want the probability</p>

<p>$$\Pr(R_j \neq 1 \mid R_1 =1)\;\;  j=2,...N_R$$
But draws are independent so we want simply</p>

<p>$$\Pr(R_j \neq 1) = \prod_{j=2}^{N_R}[1-\Pr(R_j = 1)] =  (1-1/N_U)^{N_R-1}$$</p>

<p>But $R_1$ can draw not just $""1""$, but any number, and each with probability $1/N_U$. So the probability of the event that we want, denote it $\Pr(\text{RBS})$ is (<a href=""https://en.wikipedia.org/wiki/Law_of_total_probability"" rel=""nofollow noreferrer"">Law of Total Probability</a>)</p>

<p>$$ \Pr(\text{RBS}) = \sum_{i=1}^{N_U}\left(\frac {1}{N_U}\right)\cdot \Pr(R_j \neq i \mid R_1 =i) = \left(\frac {1}{N_U}\right)\sum_{i=1}^{N_U}(1-1/N_U)^{N_R-1}$$</p>

<p>$$\implies \Pr(\text{RBS}) = \left(\frac {1}{N_U}\right) \cdot N_U \cdot (1-1/N_U)^{N_R-1} = (1-1/N_U)^{N_R-1}$$</p>

<p>...again.</p>

<p>This is intuitive: the greater the number of urns, the higher the probability. The greater the number of Red balls, the lower the probability.</p>

<p>Now, define job market tightness as usual by 
$$\theta = N_U/N_R \implies N_R = \frac 1 {\theta} N_U$$ </p>

<p>(here ""U"" denotes ""urns"" so vacancies). Then</p>

<p>$$\Pr(\text{RBS}) = \left(1-\frac 1{N_U}\right)^{\frac 1 {\theta}  N_U-1}$$</p>

<p>If $N_U$ grows ""large"" then the above is well approximated by </p>

<p>$$\Pr(\text{RBS}) \approx e^{-\frac 1 {\theta} }$$</p>

<p>The higher job market tightness, the higher the probability that an unemployed will be matched solo to a vacancy (again, ignoring what the Greens represent).</p>
","7086"
"Why does profit maximization implies that both of the following are equal?","140","","<p>Why Profit maximization implies that rate of return to capital equals the net marginal product of capital. Prove and give intuition why both are equal.</p>

<p>I also wonder that why it doesn't implies rate of return to capital equals the net marginal product of labor?</p>

<p>The highlight part and equation (6.32) is my concern</p>

<p>Please zoom in the web browser to view the image more clearly(press ctrl + turn the scroll wheel of the mouse simultaneously).</p>

<p><img src=""https://i.stack.imgur.com/giKEy.jpg"" alt=""enter image description here""></p>

<p><img src=""https://i.stack.imgur.com/pqBwG.png"" alt=""enter image description here""></p>

<p><img src=""https://i.stack.imgur.com/cQ7uL.jpg"" alt=""enter image description here""></p>
","<p>The production side is modeled as follows:
There are $m=1,...,j$ identical firms (the number of firms is not necessarily equal to the number of workers of course), that operate in a perfectly competitive environment. This means that firms are price takers, both in the goods market and in the production input market, i.e. they take prices as given when they seek to attain their objective. It also means that markets ""clear"": in particular, prices adjust without frictions/delay so that all capital and all labor are employed. The firms solve a static (not intertemporal) problem: maximize profits period-by-period separately. Labor is provided totally inelastically, no labor-leisure choice here from the part of workers. Moreover each firm has a constant-returns to scale production function in capital and labor, i.e. the function is homogeneous of degree one.  </p>

<p>Omitting the time subscript, the typical firm's production function is</p>

<p>$$F(K_j, L_j),\;\; j=1,...,m$$</p>

<p>and the objective of the firms is to maximize profits which are defined as the surplus of production over payments to labor $wL_j$, net payments to rented capital $rK_j$, and depreciation $\delta K_j$:</p>

<p>$$\max_{K_j, L_j} \pi = F(K_j, L_j)-wL_j-rK_j-\delta K_j$$</p>

<p>Note that these are ""real"" magnitudes in the <em>economics</em> sense of the word, i.e. that we have divided throughout by the price of output (we do not show it usually, we just say, ""expressed in real terms"").</p>

<p>Denote $\kappa_j \equiv K_j/L_j$, the capital-labor ratio <strong>at firm level</strong>. Due to the homogeneity of degree one we can re-write the maximization problem of the firm as</p>

<p>$$\max_{\kappa_j} \pi = L_j\cdot \big[F(\kappa_j, 1)-w-r\kappa_j-\delta \kappa_j\big]$$</p>

<p>Note that $L_j$ has become a multiplicative factor, so we can maximize only the term in brackets, and so only with respect to the capital-labor ratio. We also set $F(\kappa_j, 1) \equiv f(\kappa_j)$ to arrive at</p>

<p>$$\max_{\kappa_j} \pi = \max_{\kappa_j} \big[f(\kappa_j)-w-r\kappa_j-\delta \kappa_j\big]$$</p>

<p>The first order condition for a maximum is for the first derivative to be set equal to zero so</p>

<p>$$f'(\kappa_j) - r - \delta = 0 \implies f'(\kappa_j) - \delta = r$$</p>

<p>This is not yet the funky equation $(6.32)$,although it looks a lot like it, because the latter is expressed in terms of ""per capita"" capital $k\equiv K/N_1$,  i.e. at the level of individuals/consumers/workers, not at firm level.</p>

<p>How do we arrive at $(6.32)$? Well, since we have assumed that all firms are identical, that labor is provided inellastically, and also that the markets for production inputs clear, we have that</p>

<p>$$mK_j = K \implies K_j = K/m,\;\;\; mL_j = N_1 \implies L_j = N_1/m $$</p>

<p>So</p>

<p>$$\kappa_j = \frac {K_j}{L_j} = \frac {K/m}{N_1/m} = K/N_1 \equiv k$$</p>

<p>and now we have obtained $(6.32)$.</p>

<p>Note how all the assumptions made have been used in order to arrive at this result.</p>
","6242"
"Why is GDP growth so important that central banks are trying to impose negative interest rate?","140","","<p>BoJ just announced its negative interest rate policy in an effort to drag Japanese out of a deflationary mindset and hoping to shift the demand curve to boost the economy. However, my question is, if people don't want to spend, why bother?</p>

<p>Consider the following simple model of an ideal economy. Suppose this economy has a maxium output is 100 units of bread. Further suppose it is a one-factor economy, i.e. all output is produced by labor. Suppose everyone in the country is considered a labor and there is a total of 100 units of labor in the economy. Suppose the most comfortable level of consumption of bread by people is a total of 10 units. Then my question is why would the cnetral banks impose policies to force people to demand more of it when they do not want to? It only made sense under the following circumstance: since only 10 units of bread is needed, maybe only 10 units of labor is employed to do all the production and the rest of the people is not employed, which means they do not have any money to buy the bread. In this case, it made sense for government to raise demand so the rest of the people can have a job and earn money, and therefore spend money, which further helps the economy. However, in Japan's case, unemployment rate looks fine, around $3.5\%$ as I checked yesterday, partly because Japanese companies are reluctant in cutting employees. Connecting to the simple model I had beforehand, Japan's case is like having all the 100 units of labor employed to produce 10 units of bread, althought they really only needed 10 units of labor. This implies that all the people are getting what they want. </p>

<p>So why is there anything to worry about that the central bank of Japan even start to adopt these agressive monetary policies?</p>
","<p>Central banks do not try to increase growth. Instead, they commonly have two targets: 1) to maintain price stability and 2) to minimize the output gap. Let us ignore the first goal for a moment. The minimization of the output gap implies that if output falls short of what the central bank believes to be the natural level of output, then it will try to use economic policies which promote growth.</p>

<p>In your example, 10 units of bread being produced seems to be the natural level of output. If the central bank sees that the economy produces only 9 units of bread, it will try to stimulate the economy with low interest rates. If it observes 11 units being produced, it will raise interest rates to reduce the output. (Note that this is still possible even if firms produce 9 units of bread using 10 (or even 100) units of labor, i.e. if firms are not cutting employees efficiently.). Thus, if the central bank of Japan currently has low interest rates, it believes that current output falls short of the natural level of output, despite low unemployment rates.</p>

<p>You may still ask why the central bank tries to minimize the output gap in the first place. Why should it not just focus on price stability or why not even do something random. It turns out that up to second order approximations, an interest rate policy which minimizes a combination of price volatility and output gap volatility maximizes people's welfare in so-called new-Keynesian models. This was first shown by Woodford and Rotemberg in several articles:</p>

<blockquote>
  <p>Woodford, Michael. ""Inflation stabilization and welfare."" B.E. Journal of Macroeconomics, 2, (2002).</p>
  
  <p>Woodford, M. (1999). Optimal Monetary Policy Inertia. Retrieved from <a href=""http://www.nber.org/papers/w7261"" rel=""nofollow"">http://www.nber.org/papers/w7261</a></p>
  
  <p>Rotemberg, J., &amp; Woodford, M. (1999). Interest rate rules in an estimated sticky price model. Monetary Policy Rules. Retrieved from <a href=""http://www.nber.org/chapters/c7414.pdf"" rel=""nofollow"">http://www.nber.org/chapters/c7414.pdf</a></p>
</blockquote>
","10474"
"GDP in expenditure approach","139","","<p>GDP calculated using expenditure apporach is like this:
GDP=C+I+G+(X-M)
However on this site:
<a href=""http://www.singstat.gov.sg/statistics/visualising-data/charts/share-of-gdp-by-expenditure"" rel=""nofollow noreferrer"">http://www.singstat.gov.sg/statistics/visualising-data/charts/share-of-gdp-by-expenditure</a></p>

<p>The data is avaialable for C, G and net exports, but there are two variables: Gross Fixed Capital Formation and Changes In Inventories. Since there is no 'I' variable, can I assume that the sum of those two variables are equal I?</p>
","<p>The authoritative source here is the <a href=""https://unstats.un.org/unsd/nationalaccount/sna.asp"" rel=""nofollow noreferrer"">United Nations System of National Accounts</a>, SNA.</p>

<p>Change in inventories are indeed part of what we normally call Investment. First, for clarification, the definition of ""change in inventories"", taken from page 108 of <a href=""https://unstats.un.org/unsd/nationalaccount/docs/SNA2008.pdf"" rel=""nofollow noreferrer"">SNA, version 2008</a>:</p>

<blockquote>
  <p>The basic principle underlying the measurement of changes
  in  inventories  of  finished  goods  is  that  <strong>output  should  be
  recorded at the time it is produced</strong> and valued at the same
  price  <strong>whether  it  is  sold,  otherwise  used  or  entered  into
  inventories for sale or use later</strong>. In effect, goods only enter
  inventories when they are not immediately used
   for sale or other use in the period they
   are produced. Similarly, goods are  withdrawn  from  inventories  when  the  demand  for  the
  goods exceeds the amount produced in a period. <strong>No output
  is recorded when goods produced previously are withdrawn
  from  inventories  and  sold</strong>  or  otherwise  used  unless  a
  storage activity as described be low in section F takes place. </p>
</blockquote>

<p>Second, the components of ""Investment"" (officially called Gross capital formation), as stated in page 282 of the aforementioned document is:</p>

<blockquote>
  <p>There are three types of capital formation to be examined,
  gross  fixed  capital  formation,
    changes  in  inventories  and
  acquisition less disposal of valuables. </p>
</blockquote>

<p>This and following pages go about explaining each of them, and how to measure them. </p>

<p>Finally, the document provides a worked example of the table of ""uses of output"" (the expenditure approach of GDP). Here is a screenshot of a section of that worked example, presented in page 291. You can see that change in inventories are indeed treated as part of ""Gross Capital Formation"":</p>

<p><a href=""https://i.stack.imgur.com/2PSX8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2PSX8.png"" alt=""enter image description here""></a></p>
","16590"
"Restricting ""money creation"" to the central bank","139","","<p>Iceland is considering <a href=""http://www.forsaetisraduneyti.is/media/Skyrslur/monetary-reform.pdf"" rel=""nofollow"">removing ""money creation"" from commercial banks</a>. </p>

<p>[Despite the date of the article, I don't think this is a joke, as it has been picked up in other places since without anyone claiming it was a joke.]</p>

<p>I guess that what they are proposing is that borrowing short and lending long based on fractional reserves wouldn't be allowed, and only the central bank would be allowed to issue unbacked long-term loans in exchange for short-term deposits. Commercial banks could fund their own lending with these loans and would make short-term deposits at the central bank to reflect deposits made with them.</p>

<p>What are the advantages and drawbacks of this approach? If it makes sense, why isn't everyone else already doing so?</p>
","<p>The proposal is to prohibit fractional reserve banking. So if enacted, Icelandic banks would have to have at least as much in reserves as they have in checking deposits. To do any lending, the bank would need to raise funds either from it's equity holders or by borrowing from investors. A number of US economists, such as Chicago economist John Cochrane, have endorsed this idea.</p>

<p>The main reason for abolishing fractional reserve banking is to eliminate the potential for bank runs. Standard banks don't keep enough money in reserve to pay out everyone's deposits, but they are obligated to let anyone withdraw their deposits at any time. Thus, if too many people withdraw at once the bank can go bankrupt, and that possibility of loosing their deposit in turn <em>causes</em> everyone to try to withdraw at once. It's a self-fulfilling panic that can happen at anytime, and doesn't necessarily even need to be caused by anything in particular. In economics terms, fractional reserve banking has two equilibria at all times: the normal one with deposits and lending, and the bank run equilibrium.</p>

<p>The US and most countries have tried to elimintate the bank-run equilibrium by insuring deposits--this is what the FDIC does. The problem, as countries like Cyprus found, is that if depositors don't believe the government really has the resources to pay out the full insured deposit amount for everyone, then you can still get a bankrun, this time not merely wiping out the banks and everyone's savings, but also the government's finances as well. Small countries that can't borrow and lend in their own currency are especially vulnerable here. Iceland does have its own currency, but often does business in US dollars or Euros anyway.</p>

<p>Additionally, there is concern that fractional reserve banking could lead to increased risk-taking by banks, since part of the risk is born by the depositors who (it is assumed) aren't as sophisticated as equity investors at measuring the banks' risks.</p>

<p>The drawback, of course, is that this likely makes checking more expensive to depositors since the bank can no longer lend the money out to make interest. Presumably it won't lead to higher borrowing costs because the central bank would offset the inability to lend out deposits with a larger base money stock, but it could exacerbate inequality as depositors would no longer share the returns to banks' investments (think Mr. Potter vs Bailey Savings and Loan from the movie ""It's a Wonderful Life"").</p>
","5280"
"Tax wedge in labour market","139","","<p>I'm reading a book ( Macroeconomics - Institutions, Instability and the Financial System )  and on page 62, the authors define tax wedge as the ""difference between the real consumption wage and  the real product wage"". Should I understand this as a subtraction?</p>

<p>The real consumption wage is measured as $\frac{W}{P_c}$, where $W$ is the after-tax wage that employees receive, and $P_c=P(1+t_v)$ with $t_v$ being the indirect tax rate (VAT, etc).</p>

<p>The real product wage is the wage paid by firms to workers, and is measured by $W^{gross}/P$ where $W^{gross}=W(1+t_d)$ with $t_d$ being the direct tax rate(social securities contributions, etc).</p>

<p>Any help would be appreciated</p>
","<p>From <a href=""https://data.oecd.org/tax/tax-wedge.htm"" rel=""nofollow"">OECD website</a>, </p>

<blockquote>
  <p><strong>Definition of Tax wedge</strong></p>
  
  <p>Tax wedge is defined as <strong>the ratio</strong> between the amount of taxes paid by
  an average single worker (a single person at 100% of average earnings)
  without children and the corresponding total labour cost for the
  employer. The average tax wedge measures the extent to which tax on
  labour income discourages employment. This indicator is measured in
  percentage of labour cost.</p>
</blockquote>

<p>So here, it is a ratio, but <em>not</em> between wages, but rather of the <em>direct</em> tax burden (including social security contributions), as a percentage of total labor cost (i.e of total reward of labor). But it does <em>not</em> include indirect taxes.</p>

<p>As you can see, there are different ways to define the concept (extending it to include indirect taxes makes sense -the problem would be to measure it at that level).But it appears that in general we are talking about a ratio rather than a difference. </p>

<p>To reconcile, it is the ""difference (in absolute terms maybe) between the real consumption wage and the real product wage"" <em>as a percentage of real product wage</em>.</p>
","9211"
"The Law of Supply","139","","<p>The supply of an individual firm indicates the various quantities of a good (or service) a firm is willing and able to produce and supply to the market for sale at different possible prices, during a particular time period, ceteris paribus. </p>

<p>According to the law of supply, there is a positive causal relationship between the quantity of a good supplied over a particular time period and its price, ceteris paribus: as the price of the good increases, the quantity of the good supplied also increases; as the price falls, the quantity supplied also falls, ceteris paribus. </p>

<p>The reasoning offered for the law of supply makes sense to some extent, too: Higher prices generally mean that the firm’s profits increase, and so the firm faces an incentive to produce more output. Lower prices mean lower profitability, and the incentive facing the firm is to produce less. Therefore, there results a positive relationship between price and quantity supplied: the higher the price, the greater the quantity supplied. </p>

<p>However, to me, possibly due to the way the definition is phrased with “willing and able to produce to the market at different possible prices,” I feel that the negative relationship of demand would be the relationship for price and supply as well:</p>

<p>Here’s my reasoning: If I am a farmer, and some authoritative figure, such as the government, that is determined to plot graphs of the economy from real world data goes up to the only supplier of corn, me, and asks me for a set of prices, ""how much would you be willing and able to produce and supply to the market"", I would first determine how much income I would be at least satisfied with, almost determining a minimum wage for myself, and accordingly, I would divide this minimum wage by the set of prices the government wants to collect data on, to in effect end up on how much I’d be willing to produce and supply for each given price:</p>

<p>If I say that I’d be happy with 500 a week, and the government asks for data on the prices (10, 20, 30, 40, 50), because I would have to sell lesser units of corn for each higher price to achieve the 500 I have set as the minimum wage I’d have to receive to be willing and able to produce corn to the market, my units of corn at each price would be 50, 25, 17, 13, 10 respectively. </p>

<p>This way, supply would have a negative relationship with price…</p>

<p>To me, both reasonings make sense, however, I can’t say that the first one that explains the law of supply outweighs the reasoning I presented. What’s flawed in this reasoning?</p>
","<p>One flaw in your reasoning where you get a negative relationship between price and supply is to assume a monopolist. With a monopolist the ""market supply curve"" as such does not exist! The monopolist looks at the demand curve and <strong>chooses</strong>(!) his optimal point, he doesn't draw up a supply curve, since he has all the power. </p>

<p>Furthermore, since a monopolist chooses <strong>his</strong> optimal point on the <strong>demand curve</strong>, the monopolist's reasoning (as you describe) incorporates the demand curve, which is decreasing in prices. Hence you get that relation. Furthermore, since he <em>incorporates</em>  the demand curve we can't speak of a supply curve (which must be independent of the demand curve to have sense) as such.</p>
","9950"
"If Germany is the largest exporter, why do Chinese products pervade the the US market?","138","","<p>Despite <a href=""https://en.wikipedia.org/wiki/List_of_countries_by_exports"" rel=""noreferrer"">Germany being the third larger exporter in the world</a>, I have not once seen German products on online retail sites such as Amazon.com. Why is this the case? <a href=""http://www.cnbc.com/2016/07/08/amazons-chinese-counterfeit-problem-is-getting-worse.html"" rel=""noreferrer"">Amazon in particular is plagued with Chinese counterfeits</a>, so why haven't market forced led to the appearance of an Amazon alternative, focused on original German (or Japanese) products, for customers that are more quality-sensitive than price-sensitive?</p>
","<p>Intermediate and capital goods used in the production of other goods are often very expensive and made by Germany. Think fancy manufacturing equipment in chemicals, semiconductors, and metal fabrication as well as precisely manufactured consumables like processed chemicals and auto-parts. Chinese goods are ubiquitous because they are skewed towards final goods like toys and white goods we consume at in our homes. </p>

<p>This shows the mix of German exports is heavily intermediate and capital good focused:</p>

<p><a href=""https://richardbrenneman.files.wordpress.com/2016/07/blog-german-exports.png?w=500&amp;h=276"" rel=""noreferrer""><img src=""https://richardbrenneman.files.wordpress.com/2016/07/blog-german-exports.png?w=500&amp;h=276"" alt=""enter image description here""></a></p>

<p>This shows that China is more consumer goods focused (but the trend towards this as a shrinking fraction of a growing total):</p>

<p><a href=""https://i.stack.imgur.com/JQNrx.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/JQNrx.gif"" alt=""enter image description here""></a></p>
","15829"
"Is there any scientific proof that 2%-3% target inflation rate is ideal?","138","","<p>There are a couple of central banks (RBA, Federal reserve for example) that use inflation rate as a key indicator to regulate their official cash rates. </p>

<p>Those target inflation rates usually range from 2%-3%.</p>

<p>This is taken from federal reserve's official website:</p>

<blockquote>
  <p>Over time, a higher inflation rate would reduce the public's ability to make accurate longer-term economic and financial decisions. On the other hand, a lower inflation rate would be associated with an elevated probability of falling into deflation</p>
</blockquote>

<p>World has changed in the past 10 years or so:</p>

<p><a href=""https://i.stack.imgur.com/WFiSk.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WFiSk.jpg"" alt=""rba cash rate""></a></p>

<p><a href=""https://i.stack.imgur.com/7jBwT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7jBwT.png"" alt=""federal cash rate""></a></p>

<p>World's prevailing overnight cash rates have plunged from 3%-20% in the 20th century to 0%-3% in the past 5 years.</p>

<p>So is there any scientific proof that 2% inflation rate (or 2%-3% in RBA's case), is still the optimum target in today's low interest rate regime? </p>
","<p>Science doesn't work on the basis of ""proof"". Proof is something that belongs only in the realms of mathematics and philosophical logic. Whereas science works on the basis of the best-available explanation that fits the available evidence.</p>

<p>That's as true of physics as it is of economics.</p>

<p>The challenge in economics is that it's much harder to do experiments to gather additional evidence, particularly in macro-economics. So decisions have to be made on the basis of quite thin evidence. Nevertheless, the principle is the same: we look for the best-available explanation that fits the available evidence.</p>

<p>The point of a 2-3% inflation target was that it was neither too high nor too low. And that's based on the harm we see being done during periods of deflation (such as the Great Depression) and during periods of high inflation (the oil crises in the early and late 1970s).</p>

<p>And because it's a target, rather than a cap or a floor, that means that it's applicable in a period of high inflation and high interest rates; <em>and</em> it's applicable in a period of near-zero inflation and near-zero interest rates. The evidence that supported this target pre-2007, is still the evidence that supports it now.</p>
","13369"
"Why there are no famous software/IT companies in Europe? (unlike USA)","138","","<p>Both USA and Europe have highly developed economies with famous car, aircraft, food, oil etc. companies.
However, when it comes to IT - </p>

<p>USA has Google, Facebook, Amazon, Dell, Cisco, Microsoft, Red Hat, HP, Apple etc.
Europe has... nothing? (Nokia is dead)</p>

<p>Why? </p>
","<p>The question should rephrase to ""Why Europe IT companies are not as prominent as USA IT companies""? </p>

<p>Do you think Bosch is a IT company(when they supply software to VW)?</p>

<p>European capital model and ways of doing business is the opposite of US neo-liberalism models.  If you don't believe, you can compare Europe public own company capital with privately own company capital.  Even things like loan facilities, Germany private owns <a href=""https://de.wikipedia.org/wiki/Genossenschaftsbank"" rel=""nofollow noreferrer"">credit union/cooperative bank</a>(more than 1000) total asset is around 818 billion EUR (2015). Loan facilities from these ""small banks"" are mostly base on prudent loan criteria and credit records. So Europe society and the government basically favor prudent and organic growth. 
However, this also means very conservative expansion. This explains why Northen Europe are less speculative. (with many historical lessons learned) </p>

<p>In addition, European private business owner also concerned about ""meeting profits target"", handle control over a board with huge shares. In addition, the profits target concerned also raise issues of ""scorch and run"" common practice in USA PLTD company, i.e. using mass layoff to boost profits per shares, which against the Europe societies values(with exception of UK, which scorch their industries under Thatcherism). </p>
","17293"
"Is education a part of the U.S. exports component of GDP?","137","","<p>I was searching for this but could not find an answer.</p>

<p>My question is whether education of the U.S. universities provided to foreign students counts in exports component on GDP.</p>

<p>And if so, can we call the U.S. ""the largest education exporter in the world""?</p>
","<p>Education is indeed in exports according to the US Government's Trade.gov website:</p>

<p><strong>Trade in Services:</strong></p>

<blockquote>
  <p>The U.S. Bureau of Economic Analysis collects and compiles U.S.
  services import and export statistics. These are released in a monthly
  press release entitled U.S. International Trade in Goods and Services
  report (FT900). The services statistics are estimates of services
  transactions between foreign countries and the 50 states, the District
  of Columbia, Puerto Rico, the U.S. Virgin Islands, and other U.S.
  territories and possessions. Unlike trade in goods, which is closely
  tracked through the submission of EEIs to the AES system, services
  trade calculations are based on quarterly, annual, and benchmark
  surveys and partial information generated from monthly reports.
  Services trade totals are then estimated from these survey results.
  Limited country or area detail is available due to the lack of
  adequate source data upon which to base estimates.</p>
  
  <p>In June 2014, the BEA introduced a new presentation of the
  International Transactions Accounts and a new presentation of the
  International Investment Position. These new presentations reflect a
  comprehensive restructuring of the international accounts that
  enhances the quality and usefulness of the accounts for customers and
  bring the accounts into closer alignment with international
  guidelines. Additional information on the restructuring is available
  from the Bureau of Economic Analysis.</p>
  
  <p>Services trade data are shown in nine broad categories: ...
  <strong>Travel (for all purposes including education) – Includes goods and services acquired by nonresidents while abroad. A traveler is defined
  as a person who stays, or intends to stay, for less than one year in a
  country of which he or she is not a resident or as a nonresident whose
  purpose is to obtain education or medical treatment, no matter how
  long the stay.</strong></p>
</blockquote>

<p><a href=""http://www.trade.gov/mas/ian/referenceinfo/tg_ian_001872.asp"" rel=""nofollow"">Trade Data Basics from trade.gov</a></p>
","4971"
"Optimisation using value function","137","","<p>I have the following optimisation problem:</p>

<p>max $E_{0}\sum_{t=0}^{\infty}[log(c_{t}) + log(m_{t})]$ subject to $y + \frac{M_{t-1}}{p_{t}} + R_{t-1}\frac{B_{t-1}}{p_{t}} = c_{t} + m_{t}+b_{t}+\tau_{t}$</p>

<p>Where lower case letters indicate real variables and $R$ is the gross nominal interest rate.</p>

<p>I am trying to solve this using the value function approach but I am having a difficult time understanding what the state variable should be in this case. I tried using wealth as the state and formulated the following value function:</p>

<p>$V(a_{t}) = \max_{c_{t}, m_{t},b_{t}} [u(c_{t},m_{t}) + \beta V(a_{t+1})]$</p>

<p>where $a_{t} = y+ \frac{M_{t-1}}{p_{t}} + R_{t-1}\frac{B_{t-1}}{p_{t}} $ and initial values are assumed to be given. My problem now is that I don't know what to substitute for $a_{t+1}$. I have tried forwarding the left-hand side of the budget constraint (i.e $a_{t+1} =  y + \frac{m_{t}}{\pi_{t+1}} + R_{t} \frac{b_{t}}{\pi_{t+1}})$ and then differentiating w.r.t c,m and b but my results are very strange. Furthermore, if I have understood correctly, I also have to find $V_{a}(a_{t})$ which I cannot do with this substitution.</p>

<p>I am trying to learn this using Walsh's book and in his example, the budget constraint has capital which appears on both sides of the budget constraint, this allows him to re-write capital as a function of $a_{t}$. I tried to do the same but with real balances;</p>

<p>From the budget constraint I can write $m_{t} = a_{t}-c_t-b_t-\tau_t$</p>

<p>So, $V(a_{t}) = [u(c_{t},m_{t}) + \beta V(y + \frac{a_{t}-c_t-b_t-\tau_t}{\pi_{t+1}}) + R_{t} \frac{b_{t}}{\pi_{t+1}} ]$</p>

<p>Again I differentiate w.r.t c,m and b and this time my results are looking less crazy but still not correct. I get:</p>

<p>(c) $u_{c} - \beta V_{a}(a_{t+1})[\frac{1}{\pi_{t+1}}] = 0$</p>

<p>(m) $u_m + \beta V_{a}(a_{t+1})[\frac{1}{\pi_{t+1}}] = 0$</p>

<p>(b) $\beta V_{a}(a_{t+1})[\frac{R_{t}}{\pi_{t+1}} - \frac{1}{\pi_{t+1}}] = 0$</p>

<p>And lastly, $V_{a}(a_{t}) = \beta V_{a}(a_{t+1})[\frac{1}{\pi_{t+1}}] $</p>

<p>The final condition implies that $u_{c} = V_{a}(a_{t})$ which is similar to Walsh's answer but I can't seem to obtain a form of the Fisher equation and money demand function from my workings. </p>

<p>There is also the equilibrium condition $c_{t} = y-g$ but I have no idea when to impose it. </p>

<p>Any thoughts on what I have done incorrectly?</p>
","<p>Starting with your original equation:</p>

<p>$max_{c_t, m_t, b_t} E_0\sum_{t=0}^\infty U(c_t, m_t)$</p>

<p>s.t.</p>

<p>(1) $y+\frac{m_{t-1}}{1+\pi_t}+\frac{1+i_{t-1}}{1+\pi_t}b_{t-1}=c_t+m_t+b_t+\tau_t$</p>

<p>Here: $R_{t-1} =1+i_{t-1}$ and $1+\pi_t=\frac{P_t}{P_{t-1}}$</p>

<p>Note that in this problem, you have have two state variables, $m_{t-1}$ and $b_{t-1}$, and your main issue have been that you have bunched these together. your Bellman should be:</p>

<p>$V(m_{t-1},b_{t-1})=max_{c_t, m_t, b_t} U(c_t,m_t)+E_t\beta V(m_t,b_t)$</p>

<p>s.t. (1)</p>

<p>You can here use your contstraint to get rid of one control, or you can solve it using the lagrangian. If you use your constraint to substitute for $c_t$, your updated problem becomes:</p>

<p>$V(m_{t-1},b_{t-1})=max_{m_t, b_t} U(c_t(y, m_{t-1}, b_{t-1},m_t, b_t, \tau _t),m_t)+E_t\beta V(m_t,b_t)$</p>

<p>For clarification:</p>

<p>$c_t(y, m_{t-1}, b_{t-1},m_t, b_t, \tau _t)=y+\frac{m_{t-1}}{1+\pi_t}+\frac{1+i_{t-1}}{1+\pi_t}b_{t-1}-m_t-b_t-\tau _t$</p>

<p>FOCs:</p>

<p>$[b_t$]: $-U_{c_t}+\beta E_tV_{b_t}=0 $</p>

<p>$[m_t]$: $-U_{c_t}+U_{m_t}+\beta E_tV_{m_t}=0$</p>

<p>Envelopes:</p>

<p>$[b_{t-1}]$: $U_{c_t}\frac{1+i_{t-1}}{1+\pi _t}\implies V_{b_t}=U_{c_{t+1}}\frac{1+i_t}{1+\pi _{t+1}}$</p>

<p>$[m_{t-1}]$: $U_{c_t}\frac{1}{1+\pi _t}\implies V_{m_t}=U_{c_{t+1}}\frac{1}{1+\pi _{t+1}}$</p>

<p>You should be able to combine these equations such that you find the demand for money. To me, your equilibrium condition (along with the fact that no capital is present in the set-up) impies that there is no saving in real variables, and hence you have nothing that can pin down the real interest rate, and you therefore lack information to find the fisher equation.</p>
","17789"
"What does the value of bitcoins depend on?","137","","<p>I've been looking up stuff about bitcoins for some time now and i have two question stuck in my mind:</p>

<p>How is the value of bitcoins so unstable?</p>

<p>And can there be bitcoin inflation?</p>
","<p>The price is unstable because there's a fairly small free float (the quantity available for buying and selling with true currencies) compared to the level of transactions.</p>

<p>It's a Ponzi scheme, so demand is driven by Bitcoin marketing: it is in immediate financial interest of the holders of Bitcoin to drive up the price by ""ramping"" it: talking up the market price. The amount of attention that the media gives Bitcoin goes up and down - this affects demand, and that drives the price, as supply is fairly stable.</p>

<p>The originators of Bitcoin, and the original hoarders, have most to gain: it was easiest for them to create Bitcoins. It would be rational for them to slowly release their hoard into the market as price goes up.</p>

<p>It's also attracted a lot of gullible but evangelical supporters: for them, continuing to hold Bitcoin is a means of validating their beliefs, and even validating the identity they've built for themselves around it. That's why the free float tends to stay low.</p>
","16495"
"Why recent crises all started with a housing bubble?","137","","<p>I was writing some notes about the last economic and financial crisis and I noticed that all these recent crisis start with a housing bubble. Beside the 2007-08 US's one, also Japanese crisis in the beginning of the 90s and Spain's crisis, just to cite a couple of them, all have started by housing price boosting. </p>

<p>Why are all recent crisis starting with a housing bubble? Is something related to modern economies or just a coincidence?</p>
","<p>In a fractional reserve monetary system <a href=""http://www.bankofengland.co.uk/publications/Documents/quarterlybulletin/2014/qb14q1prereleasemoneycreation.pdf"" rel=""nofollow noreferrer"">loans create money and loan repayments destroy money</a>. Most bank lending in modern times is for <a href=""https://qz.com/586664/lord-adair-turner-on-the-largely-fictional-world-of-finance/"" rel=""nofollow noreferrer"">the purpose of purchasing real estate</a>. So the amount of money that exists in the economy is closely tied to the enthusiasm for purchasing real estate. You could not really make this kind of statement for any other class of asset - this is why the housing market in particular has such an impact on the economy. During the upswing of a housing bubble the money supply will be growing fast, but when the bubble bursts the money supply will fall (as existing mortgages are repaid) leading to recession. The whole point of QE is to <a href=""https://en.wikipedia.org/wiki/Quantitative_easing"" rel=""nofollow noreferrer"">counteract this fall in the money supply</a>.</p>

<p>Confusingly economists use the word ""<a href=""https://en.wikipedia.org/wiki/Demand_deposit"" rel=""nofollow noreferrer"">credit</a>"" to describe (most of) the money we use in the economy, so many people do not realise that the ""credit crunch"" was in fact a ""money crunch"".</p>

<p><a href=""https://en.wikipedia.org/wiki/Hyman_Minsky"" rel=""nofollow noreferrer"">Hyman Minsky</a> is the most famous economist that would subscribe to these kind of views. You might also want to look up the term <a href=""https://en.wikipedia.org/wiki/Credit_cycle"" rel=""nofollow noreferrer"">credit cycle</a>.</p>

<p>By the way, none of these views are mainstream. Mind you the mainstream economists did not see the last crash coming, so you should not really expect them to explain what happened.</p>
","16074"
"""Auction"" versus ""Bidding war""","136","","<p>Real estate sales sometimes occur at an official auction.  But sometimes a seller who does not take their house to auction may find themselves entertaining multiple bids for the house.  In this case, the articles on real estate always seem to talk about managing a ""bidding war"".  What is the difference between a bidding war and an auction?  Are there regulatory issues that prevent a seller from converting their bidding war into a straight-up auction?  </p>

<p>(For instance, a seller with multiple bids could simply notify all bidders of the current highest bid, set a minimum bidding increment, and see if anyone bids higher, and repeat until one bidder is left.)</p>
","<p>From a practical standpoint, bidding wars are effectively informal auctions. What is usually done is that the buyers inform their agents of their maximum price, and the buyers' agents tell the seller's agent ""This is my client's bid, but please let us know if we're outbid."" Sometimes this is formalized through what is known as an <a href=""http://www.bankrate.com/finance/real-estate/escalation-clause.aspx"" rel=""nofollow"">escalation clause</a>, which is essentially an offer to bid some increment more than any other highest bid, up to some reservation price. </p>

<p>Some sellers accept escalation clauses, some don't, and this decision appears to be influenced partially through strategy and partially through custom in the area. Not accepting an escalation clause can force buyers into what is effectively a <a href=""https://en.wikipedia.org/wiki/Auction#Sealed_first-price_auction"" rel=""nofollow"">first-price sealed-bid auction</a>, while accepting them turns it into more of a traditional (<a href=""https://en.wikipedia.org/wiki/English_auction"" rel=""nofollow"">English</a>) auction.</p>

<p>As an additional note, the point that @desnep makes is true— while proof of other bids is required, it's not always possible to determine that those bids in fact represent genuine offers to buy. My understanding is that for this reason, when bids are expected to be few, buyers are encouraged to submit fixed bids and be prepared to walk away if they lose out, as there's a stronger incentive for sellers to fabricate bids (i.e., market manipulation is more effective in less-liquid markets).</p>
","6211"
"Constant Returns in a Production Function $\frac{Y}{L}=\left(\frac{K}{L}\right)^{\alpha}\left(\frac{R}{L}\right)^{\beta}$ ($R$ = Resource)","136","","<p>In his <a href=""https://www.jstor.org/stable/1828079?seq=1#page_scan_tab_contents"" rel=""nofollow noreferrer"">1977 article</a> (from which has developed a considerable literature on the Hartwick Rule for maintaining long-term constant consumption given depletion of non-renewable natural resources), Hartwick uses (on p 973) this aggregate production function:</p>

<p>$$x = k^{\alpha}y^{\beta}1^{\gamma}$$</p>

<p>Here (see p 972) $x$ is per capita output, $k$ is per capita reproducible capital, and $y$ is per capita use of an exhaustible resource. $1$ is just the number one, labour being assumed constant (so the term $1^{\gamma}$ seems redudant).  So in more familiar notation (output $Y$, capital $K$, use of exhaustible resource $R$, labour $L$), and glossing over the difference between population and labour, this is:</p>

<p>$$\frac{Y}{L}=\left(\frac{K}{L}\right)^{\alpha}\left(\frac{R}{L}\right)^{\beta}$$</p>

<p>Hartwick then assumes (p 972) constant returns to scale in the form (explicitly on p 973) $\alpha+\beta=1$.</p>

<p><em>Question</em>: What reasons might justify the assumption of constant returns in the above form?  Isn't it more plausible to assume constant returns when <em>all</em> factors are increased, that is to assume $\alpha+\beta+\gamma=1$ in a production function of the form:</p>

<p>$$Y=K^{\alpha}R^{\beta}L^{\gamma}$$
This does imply the above function since:</p>

<p>$$\frac{Y}{L} = \frac{K^{\alpha}R^{\beta}L^{\gamma}}{L^{\alpha}L^{\beta}L^{\gamma}}=\left(\frac{K}{L}\right)^{\alpha}\left(\frac{R}{L}\right)^{\beta}$$</p>

<p>However, given $\gamma&gt;0$, it is inconsistent with $\alpha+\beta=1$: instead $\alpha+\beta&lt;1$.</p>
","<p>The purpose of the paper under consideration is to examine/show the ""investment rule"" that leads to ""intergenerational equity"", which with constant population translates into constant consumption. </p>

<p>The investment rule under examination is (last line of p. 973) ""invest all net <em>returns</em> from exhaustible resources in reproducible capital"" (and consume the rest).</p>

<p>Earlier, eq. $(1)$ of the paper (the law of capital accumulation) tells us that <em>gross</em> returns to exhaustible resources equal $f_yy$: this implies that we assume that the return per unit of exhaustible resource <em>equals its marginal product</em>.</p>

<p>But this in turn implies pricing and the existence of markets. So there must be a market for capital also. If the capital market is also characterized by marginal pricing, then , if we assume that the production function has decreasing returns to scale in capital and exhaustible resource ($\alpha + \beta &lt;1$), then</p>

<p>$$f_kk + f_yy &lt; x$$</p>

<p>and some part of output would have been left unaccounted for.</p>

<p>So the author assumes constant returns to scale in these two so that he can also assume competitive markets and marginal pricing, and per capita output exhausted in the rewards to these inputs.</p>

<p>This of course begs the  question: <strong>what happens to the labor market?</strong>
Well, we can get away with murder making the following assumption: There is no leisure-labor choice, labor is offered inelastically, and moreover, <em>there is no market for labor</em>, it is subsumed to the other factors of production, i.e. it is offered together with them and it is not paid separately: think capital owners that also work in their business without paying themselves a wage.</p>

<p>This of course means that the formulation with unitary labor and an irrelevant exponent $\gamma$ is sloppy and problematic, it should be absent (it would not affect the paper), and it rightfully led to the OP's question.</p>
","14236"
"Elasticity of substitution in Jehle and Reny Advanced Micro (3rd ed) exercise 3.8","136","","<p>Letting $f_i(\mathbf{x})=\partial f(\mathbf{x})/\partial x_i$, ($\mathbf{x}$ is a vector, a commodity bundle, and $x_i$ is a scalar, commodity $i$ in the bundle) show that,</p>

<p>$\sigma_{ij}(\mathbf{x})\equiv -\frac{x_if_i(\mathbf{x})+x_jf_j(\mathbf{x})}{f^2_j(\mathbf{x})f_{ii}(\mathbf{x})+2f_i(\mathbf{x})f_j(\mathbf{x})f_{ij}(\mathbf{x})+f_i^2(\mathbf{x})f_{jj}(\mathbf{x})}\frac{f_i(\mathbf{x})f_j(\mathbf{x})}{x_ix_j}$</p>

<p>Then using the above formula, show that $\sigma_{ij}(\mathbf{x})\geq0$ whenever $f$ is increasing and concave.</p>

<hr>

<p>PS: I know $\sigma_{ij}$ can be written as</p>

<p>$\sigma_{ij}=-\frac{d (x_i/x_j)}{x_i/x_j} \frac{f_i(\mathbf{x})/f_j(\mathbf{x})}{d (f_i(\mathbf{x})/f_j(\mathbf{x}))}$</p>

<p>How can we derive the result from this known fact? Thank you.</p>

<p><a href=""https://i.stack.imgur.com/zM19k.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zM19k.png"" alt=""enter image description here""></a></p>
","<p><a href=""https://i.stack.imgur.com/4ldMG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4ldMG.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/UqV2S.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UqV2S.png"" alt=""enter image description here""></a></p>

<p>I emailed the question to one of the authors. He said the solution manual will come soon!</p>
","13286"
"Is a small business owner without employees a capitalist?","136","","<p>If a man has a small business where he is the only employee or if he is self employed, that makes him a capitalist?</p>

<p>For example a freelance writer. Or a subsistence farmer that only produces enough to feed himself and his family. Or a subsistence farmer that makes a little income on top of feeding himself and his family. Is there an income threshold that makes them capitalist?</p>
","<p><strong>Small Business Owner: Yes.</strong><br>
<strong>Freelance Writer: Yes.</strong><br>
<strong>Subsistence Farmer: No.</strong>  </p>

<p>Capitalism is the use to the private sector to grow the economy.<br>
This means that the private sector has to be producing a good or service that can be sold in the marketplace to benefit society.  </p>

<p>Let us take a look at your examples. </p>

<p>A small business owner is, by definition, owning a business that is producing some good or service for which there is a market.  One example would be a barber shop or a ""mom and pop"" restaurant.  It does not matter if the venture is making millions of dollars or just making ends meet.  It does not even matter if they are the only employee.  The business is making a good or service that is demanded, and they are fulfilling that demand.  </p>

<p>A freelance writer is also producing a good or service that is demanded by others.  This could be written articles, books, essays, etc. or the service of taking notes and transcribing words.  Again, it does not matter the payment received for this good or service or if the freelance writer is a loner.  </p>

<p>However, the subsistence farmer is different.  By definition, a subsistence farmer is only producing enough food to keep themselves alive; they are not producing any food to sell to anyone else.  The farmer (presumably) has no other source of income and is forced to produce all other items on their own.  So, although they are innovative, the subsistence farmer is not a capitalist.  </p>
","18936"
"Certifications for economists","135","","<p>Are there certifications or professional designations that are specifically geared for economists? i.e much like the CPA and CA exists for accountants.</p>
","<p>Separate from their academic qualifications, no there are not.  The reason is that certifications generally serve two functions, either to show a legal status or where there are no academic qualifications required to show some learning process has happened that is similar to an academic designation.</p>

<p>To provide an example, the MD, the CPA and the PE designations have legal meaning.  Their existence is postulated in state and federal law as necessary to engage in certain forms of practice, though medical doctors at the state level also have additional licensing.  Federal physicians do not always have to have a state license, such a military doctors.  Physicians also have higher level certifications to show skill in a narrow area to convince customers they can be trusted in that narrow area.</p>

<p>Beyond this, some fields are heavily populated with people who have no academic degree and for those narrower certifications are available such as CFA or licensing such as the barber's license.  The barber's license is a strange throwback to when barbers did surgery, we still license barbers but the need is less apparent than it was when it started.</p>

<p>Economists have no legal standing.  There is no field of practice that the legislators of the world have felt necessary to impose additional qualifications for beyond a doctorate.  Indeed, you could have a doctorate in another field and engage in economic research and consulting.  This certainly happens with finance professors, mathematicians, sociologists, psychologists and political scientists.  Psychologists and mathematicians have won the Nobel for economics before.</p>

<p>It also is unlikely there are certifications that would be meaningful.  The simplest way to determine the technical skill of an economist is to read their doctoral dissertation, or masters thesis, and their research body of work.  It is an open source process, so unlike craftsmen whose work is only visible to their prior customers the work of economists is very public and very visible.</p>

<p>Of all professions, it should be easier to evaluate an economist than maybe any other.  Certifications would do what?  For whom?</p>
","16000"
"Is a strong foundation in advanced microeconomic theory essential to study environmental economics at the graduate level?","135","","<p>Advanced theory of individual economic behaviour in production, consumption, and general equilibrium. Are these topics useful to study environmental economics a the graduate level, or is there not a lot of overlap?</p>
","<p>It depends on what you like to do in environmental economics. There are lots of people who are working on moral hazard issues on environmental economics by principal-agent models. </p>

<p>More specifically, an interesting question arises from non-point source pollution. Let's say farmers are using pesticides which cause pollution. Probably, you don't know specifically which of farmers are responsible. How could you create ""incentives"" in order to avoid this situation(pollution) ? 
You can look at the Segerson (1988), published in Journal of Environmental Economics and Management in order to understand this issue more precisely. </p>

<p>Another field could be about social choice theory (and decision theory) in environmental economics, especially on equity between individuals and generations. These issues can be included in microeconomics but more in applied math as they use topology etc. (Geir Asheim, Stéphane Zuber's papers could be interesing for this subject.)</p>

<p>Just to finish, I think there are more things to do in environmental economics at a macroeconomic level. (Note that my opinion could be biased as I am working at macro level.)</p>
","7097"
"$U=xy$ for all people in a small island, What are the pareto efficient allocations?","134","","<blockquote>
  <p>On a certain island there are only two goods, wheat and milk.The only
  scarce resource is land. There are 1,000 acres of land. An acre of
  land will produce either 16 units of milk or 37 units of wheat. Some
  citizens have lots of land, some have just a little bit. The citizens
  of the island all have utility functions of the form U(M,W)=MW. At
  every pareto-optimal allocation,</p>
  
  <p>(a) The number of units of milk produced equals the number of units of
  wheat produced.</p>
  
  <p>(b) Total milk production is 8,000</p>
  
  <p>(c) Every consumer’s marginal rate of substitution between milk and
  wheat -1.</p>
  
  <p>(d) None of the above is true at every pareto optimal allocation.</p>
</blockquote>

<p>Hello, Is the MRS for everyone =$\frac{\mathrm{d} W}{\mathrm{d} M}=\frac{37}{16}$?</p>

<p>Also,What are the Pareto-efficient allocations?</p>
","<ol>
<li><p>A Pareto efficient allocation is an allocation for which it is impossible to change the allocation and make someone better off without making someone else worse off.</p></li>
<li><p>In this economy you can produce either 16,000 units of milk or 37,000 units of wheat and you exchange 16 units of milk for 37 units of wheat by changing one acre from producing milk to producing wheat. - 16 / 37 is the slope of the production possibility frontier.</p></li>
<li><p>The price of producing one unit of wheat is 1/37th of an acre. The price of producing one unit of milk is 1/16th of an acre. There are a total of 1,000 acres. The problem for the island as a whole is:</p></li>
</ol>

<p>$\max_{w,m} \quad m\cdot w \quad s.t. \quad 1,000 = \frac{1}{16} m + \frac{1}{37} m$ </p>

<p>This can be re-written as the Lagrangian $\Lambda$:</p>

<p>$\Lambda = m\cdot w + \lambda \left(1,000 - \frac{1}{16} m - \frac{1}{37}w\right)$</p>

<p>The First Order Conditions for a maximum are:</p>

<p>$m: w - \frac{1}{16} \cdot \lambda = 0\\$</p>

<p>$w: m - \frac{1}{37} \cdot \lambda = 0\\$</p>

<p>$\lambda: 1,000 - \frac{1}{16} m - \frac{1}{37}w = 0\\$</p>

<p>This can be re-written as:</p>

<p>$16 w = \lambda$</p>

<p>$37 m = \lambda$</p>

<p>Or,</p>

<p>$\frac{16}{37} = \frac{m^*}{w^*}$ (The MRS in equilibrium is therefore not equal to - 1.)</p>

<p>Plugging $\frac{16}{37}w^* = m^*$ back into $\lambda:$:</p>

<p>$ w^* = 18,500$
$ m^* = 8,000$</p>

<p>The answer is b.</p>

<p>The reason why you can treat each individual problem as the problem of the Island as a whole is because all agents have identical utility function and only the quantity of land differs between them. The problem is therefore identical for all agents. The only difference is the quantity of land that they are constrained to. </p>

<p>Hope that this helps?</p>
","16481"
"In this scenario, which coin is more valuable?","134","","<p>There are two coins, Coin A and Coin B. You can transfer Coin A for Coin B or Coin B for Coin A only in the two following ways:</p>

<p>Give 100 Coin A for 10 Coin B</p>

<p>Or</p>

<p>Give 10 Coin B for 50 Coin A</p>

<p>In this situation, which of the coins is worth a higher value? A friend of mine presented this problem and we were unable to find a solution. Any thought?</p>
","<p>From the first equation,
$$100A_{1}=10B_{1}$$
so $A_{1}=0.1B_{1}$.</p>

<p>From the second equation,
$$10B_{2}=50A_{2}$$
so $A_{2}=0.2B_{2}$.</p>

<p>So it follows,
$$0.2B_{2}\ge A_{2} &gt; A_{1} \ge 0.1B_{1}$$</p>

<p>Now, as $A_{2}&gt;A_{1}$ then the only possible conclusion from the inequality is that for sure $0.2B_{2}&gt;A_{1}$ and thus we deduce that $B$ has the higher value.</p>

<p>Hence if you are forced to choose strictly within the constraints set out in the problem then one would be best served by choosing only the B coin.  </p>
","11112"
"Oil as a function of GDP","134","","<p>In <a href=""http://rads.stackoverflow.com/amzn/click/0538453060"" rel=""nofollow"">Mankiw, N. (2012). <i>Principles of Macroeconomics</i> (6th ed.).</a>, on pg 456 Mankiw says ""The amount of oil used to produce a unit of real GDP has declined about 40 percent since the OPEC shocks of the 1970s.""</p>

<p>How would one measure that?</p>

<p>That's unfortunately just kind of dropped at the end of a chapter as the second to last sentence in a five paragraph side note about OPEC, and I've been curious for years now if that reduction was because the mix of energy supply changed (rise in natural gas consumption?), or production is simply more energy efficient, or what.</p>

<p>Can someone clarify the claim, the process, or point toward primary sources (US EIA maybe?), rereading this book has reminded me how frustrating that bit was. </p>
","<p>I don't think it's any more complicated than looking at the ratio of global oil consumption and global Gross Domestic Product. The OECD, World Bank, IMF and others produce estimates of each.</p>

<p>There is some <strong>fuel-switching</strong>: for example, the world burns much less electricity from oil than it used to: in 1973 (the first oil crisis started around October that year) 251 million tonnes were used for electricity; by 2000, this had dropped to 110; by 2012, to 70 (table 7A on IV.81 of <a href=""http://dx.doi.org/10.1787/electricity-2014-en"" rel=""nofollow"">the IEA Electricity Information 2014</a>).</p>

<p>There's several decades of <strong>energy efficiency</strong>, kickstarted in large part by the oil shocks of the 1970s.</p>

<p><strong>The share of services (relative to physical goods) within global GDP has increased</strong>; IIRC services require much lower energy inputs than goods, on average, even though transport is one of the services (I'll check this and edit later - please nudge me in comments if I haven't after a week or so). The <a href=""http://data.worldbank.org/indicator/BG.GSR.NFSV.GD.ZS"" rel=""nofollow"">World Bank</a> only gives services as a share of global GDP from 1990 onwards: this share grew from 60.7% in 1990 to 70.2% in 2011.</p>

<p>The combination of energy efficiency and the increase in the share of services (relative to physical goods) within global GDP, means that energy consumption per unit of global GDP has fallen: <a href=""http://holtz.org/Library/Social%20Science/Economics/Estimating%20World%20GDP%20by%20DeLong/Estimating%20World%20GDP.htm"" rel=""nofollow"">J. Bradford DeLong</a> gives global GDP at \$12 trillion for 1970 and \$41 trillion for 2000 (preferred measure, 1990 international dollars). The <a href=""http://www.bp.com/en/global/corporate/about-bp/energy-economics/statistical-review-of-world-energy/statistical-review-downloads.html"" rel=""nofollow"">BP Statistical Review of World Energy 2014</a> gives 1970 energy consumption at 4.9 billion tonnes of oil equivalent (btoe) and 9.3 btoe for 2000. So <strong>energy per unit global GDP almost halved (44% reduction) over those thirty years 1970-2000.</strong></p>

<p>Understanding an individual country's changes are harder, because we then have to unpick whether oil intensity of GDP has dropped because of energy-efficiency &amp; fuel-switching, or because oil-intensive goods are now imported rather than produced domestically: for further reading on this, see papers by John Barrett and by Dieter Helm.</p>
","1860"
"Using another person's guess as an IV","134","","<p>In <a href=""http://www.jstor.org.erl.lib.byu.edu/stable/pdfplus/2117766.pdf?acceptTC=true"" rel=""nofollow""><em>Estimates of the Economic Return to Schooling from a New Sample of Twins</em></a> by Orley Ashenfelter and Alan Krueger, they correct sampling error with an IV. They claim that their results imply a larger effect of education on earnings than what was found before.</p>

<p>Each respondent has a twin. Each respondent is asked how much money they make, which has inherent sampling error. Then, the respondent's twin is asked how much money the first respondent makes. That estimate is used as an IV, and together they reveal the true income of the first respondent.</p>

<p>Can this work for revealing how many pennies are in a jar? Or how much a person likes a political candidate?</p>

<p>Or how does this work? I see this as magic. If I want to get the truth about something, I just have to get a second opinion?</p>
","<p>Instruments are used as a replacement for an independent variable if we think that independent variable is endogenous. That means, we think it may be correlated with our error term. So in the case of estimating money made by a twin, we have a model:</p>

<p>$$\text{salary} = \beta_0 + \beta_1 \cdot \text{guess} + u$$</p>

<p>Where $u$ has standard properties mean zero and normal standard deviation. Here the problem is that the person's ""guess"" might be correlated with other things that affect a person's salary that isn't measured here, such as truthfulness. We also violate a normal Gauss-Markov assumption of random sampling. So we can use an instrument in place of the guess.</p>

<p>We wish for our instruments to be <em>relevant</em> and <em>valid</em>. Which means we want the instrument to be correlated with the guess, and also uncorrelated with the error term. The other twin's guess would be a good fit because it is probably correlated with the twin's guess, but also their guess probably does not correlate as much with external factors that might affect their sibling's salary.</p>

<p>In your hypothetical for measuring pennies in a jar, taking the other twin's guess itself won't be more accurate, and there might not even be an endogeneity problem. But if you were sampling groups of people instead of individuals, then you could probably expect that result to be more accurate, if groups are clustered together randomly.</p>

<p>In your case with liking a political candidate, you might struggle to argue that a twin's guess of their siblings affinity to a politician could be a relevant instrument. People change their political opinion noticeably when under observation by others, even close family members. So at least you might get some bias there.</p>
","11142"
"What are the prerequisites to study Mathematical Economics?","134","","<p>I am a high school student with keen interest in mathematics and economics. I wish to study mathematical economics, but most of the books I have encountered begin with quite advanced mathematics. In particular, Mathematical Economics by Akira Takayama begins with Nonlinear Programming [Concave Programming, Differentiation and Unconstrained Maximum Problem and Quasi Saddle Point Charecterization]. Frankly, I find myself at sea while trying to understand this content. Could someone please recommend what prerequisites one must have in order to fully understand books of such caliber.  </p>
","<p>In the preface, Takayama writes that the book was written with the intention to keep the prerequisites to a minimum: elementary calculus and matrix algebra. </p>

<p>Perhaps he was exaggerating a little, but I suspect, after skimming the table of contents, that knowledge of the aforementioned subjects and experience working with (i.e. reading/understanding and independently constructing) mathematical proofs should be enough.</p>

<p>I'm assuming you've taken calculus and linear algebra -- in which case you might want to get more experience with working with proofs. I'm quite fond of Axler's <a href=""http://rads.stackoverflow.com/amzn/click/3319110799"" rel=""nofollow"">Linear Algebra Done Right</a>, and I've heard good things about Abbott's <a href=""http://rads.stackoverflow.com/amzn/click/1493950266"" rel=""nofollow"">Understanding Analysis</a>. </p>

<p>If you haven't studied those two subjects, work on learning those first. You can try the two textbooks I suggested to do so, but that might be a bit rough-going. I'm sure your math teacher might have more helpful suggestions for a first reference to learn calculus and matrix algebra from.</p>

<p>I think with a bit of what mathematicians like to call 'mathematical maturity', you should be able to manage Takayama just fine.</p>
","14435"
"What do economist state as evidence that ""structural reform"" works?","134","","<p>The typical recipe for countries to improve their growth rate and escape high indebtedness is to reduce expenditure and implement structural reform. What do people use as evidence of structural reform working?</p>
","<p><strong>A rather positive view of structural reforms</strong></p>

<p>In their recent Economic Policy Reforms 2016, <a href=""http://www.keepeek.com/Digital-Asset-Management/oecd/economics/economic-policy-reforms-2016_growth-2016-en#page17"" rel=""nofollow"">Going for Growth Interim Report</a>, the OECD reviews the main growth challenges faced by OECD and selected non-OECD countries and takes stock of the progress made since 2015 in the adoption and implementation of structural policy reforms to address these challenges. </p>

<p>The chapter 2 in particular reviews the main issues related to the short-term impact of structural reforms in different macroeconomic contexts and takes stock of existing theoretical and empirical studies. It lays out the case of reforms introduced in ""normal"" and ""bad"" times. It identifies the main channels through which structural reforms influence <strong><em>rather favorably</em></strong> short-term activity through consumption, investment and net exports. The chapter discusses </p>

<ol>
<li>Model-based assessments taken from studies that make use of Dynamic Stochastic General Equilibrium (DSGE) models for the analysis of specific reforms</li>
<li>Empirical analysis based on aggregate or sectoral data. Look in particular at Bouis, R., O. Causa, L. Demmou, and R. Duval (2012), ""<a href=""http://izajolp.springeropen.com/articles/10.1186/2193-9004-1-12"" rel=""nofollow"">How quickly Does Structural Reform Pay Off?</a> An Empirical Analysis of the Short-Term Effects of Unemployment Benefits Reform"", <em>IZA Journal of Labor Policy 2012</em>, 1:12.</li>
<li>Empirical analysis based on micro studies. In this category, a recent paper that is not reviewed in the OECD report but in a VOX CEPR column on <a href=""http://voxeu.org/article/impact-structural-reforms-eurozone-firm-level-data"" rel=""nofollow"">Eurozone rebalancing: Are we on the right track for growth? Insights from the CompNet micro-based data</a>.  Their results are ""in line with the postulate that the crisis and ensuing structural policies may be generating ‘cleansing effects’."" The author are cautious, however. ""It is obvious that the evidence presented is still preliminary and only suggestive of the potential use of the dataset.""</li>
</ol>

<p>Look also at Bouis, R., O. Causa, L. Demmou, and A. Zdzienicka (2012), ""<a href=""http://dx.doi.org/10.1787/5k9csvk4d56d-en"" rel=""nofollow"">The Short-Term Effects of Structural Reforms: An Empirical Analysis</a>"", OECD Economics Department Working Papers, No. 949. They conclude</p>

<blockquote>
  <p>This analysis indicates that the benefits from reforms typically take time to fully materialise. When significant effects are found in the short run, reforms seldom involve significant aggregate economic losses; on the contrary they often deliver some benefits. The absence of major depressing effects does not lend support to the view that reforms should be in general accompanied by substantial macroeconomic policy easing in order to deliver some short-term gains. Nevertheless, there is also tentative evidence that some labour market reforms (e.g. of unemployment benefit systems and job protection) pay off more quickly in good times than in bad times, and can even entail short-term losses in severely depressed economies.</p>
</blockquote>

<hr>

<p><strong>A rather negative view of structural reforms</strong></p>

<p>However, when <strong>Krugman</strong> sees influential people calling for structural reform as the universal answer to all economic problems, he gets angry. He considers that <a href=""http://krugman.blogs.nytimes.com/2014/02/21/structural-reform-is-the-last-refuge-of-scoundrels/"" rel=""nofollow"">Structural Reform is the Last Refuge of Scoundrels</a>. For Krugman, traditionally, structural reform was offered as an answer to the problem of stagflation, which makes a fair bit of sense according to <a href=""http://krugman.blogs.nytimes.com/2014/11/20/structural-deformity/"" rel=""nofollow"">him</a>.</p>

<p>Dany <strong>Rodrik</strong> also opposes structural reforms notably in his paper <a href=""https://www.sss.ias.edu/files/pdfs/Rodrik/Research/Goodbye-Washington.pdf"" rel=""nofollow"">Goodbye Washington Consensus, Hello Washington Confusion?</a>. He argues that ``evidence has come a more skeptical reading of the cross-national relationship between policy reform and economic growth'' (Page 5).</p>

<p>Moreover, <a href=""http://www.hvtc.edu.vn/Portals/0/files/635870649753930599LeadershipandGrowth.pdf#page=165"" rel=""nofollow"">Acemoglu and Robinson (2010, chap 5)</a> document that </p>

<blockquote>
  <p>The  attempt  to  induce  African  countries  to   implement institutional  reforms  such as reducing  distortions was not a success   (van  der  Walle,  1993,  2000),  mostly  for  the  reason that international  financial   institutions  (IFIs) did  not  take into  account  the  political  rationale  for  the  inefficient policies they  were  trying  to  reform.  The  most  dramatic  example  of this  is   discussed by Herbst (1990) and Reno (1998).  They argued that attempts by IFIs to  induce   downsizing   of   the   public   sector,   for example  by closing  down unprofitable parastatals,  had  played  an  important  role  in  creating  civil war  in   Sierra  Leone  and  Liberia.</p>
</blockquote>
","11848"
"Does Craigslist Reduce Unemployment?","133","","<p>If a substantial (though admittedly I have no idea how large) part of the natural rate of unemployment is caused by the job search, do more efficient means of communication create more efficient labor markets, and if so, can anyone quantify their impact with data?</p>
","<p>Kroft and Pope (<a href=""http://faculty.chicagobooth.edu/devin.pope/research/pdf/Website_Craigslist.pdf"">working paper</a>, published in JoLE 2014) ask exactly this question, and their tentative answer is ""no"".</p>

<p>They view Craigslist as a unique opportunity to study the benefits of online job sites, since it grew rapidly and somewhat idiosyncratically while other popular sites grew steadily (leaving few opportunities for identification). That said, they don't have a great identification strategy - they just treat the rise of Craigslist starting in 2005 as an event study and compare MSAs where it grew quickly to MSAs where it grew sluggishly, making the case via various alternative specifications and falsification tests that there isn't any substantial bias.</p>

<p>Interestingly, they find that Craigslist <em>does</em> seem to have crowded out traditional newspaper classified ads, but had no discernible effect on unemployment. (This doesn't surprise me too much, since Craigslist seems like a pretty minor advance over traditional classifieds for job search, and if anything you'd expect a contribution from other sites that are more specialized or make more efforts to facilitate matching.)</p>

<p>On the other hand, they find that Craigslist <em>does</em> seem to have some effect on rental vacancy rates. Perhaps simple, searchable Craigslist-style classified ads facilitate rental search (I know they have for me) but are too crude to do much for employment.</p>
","1797"
"How do we prevent big companies conspiracy?","132","","<p>These days we can see a bunch of troubling trends.</p>

<ul>
<li>Consumer goods are less quality.</li>
<li>Big companies merge.</li>
<li>Patent laws and strict requirements on appearance remove small entrepreneurs from the manufacturing business.</li>
</ul>

<p>These problems had been subjects of dystopian sci-fi scenarios for many times. Even though it is profitable for a starting bussinessman to buy and sell as the supply and demand dictates, for a few big companies, ruling over the market it is profitable to keep the prices up. </p>

<p>What can lawmakers do about concluding conspiratorial agreements or merging big companies to keep the supply and demand principle?</p>
","<p>The kinds of practices you describe are frequently controlled through competition/antitrust policy. For example:</p>

<ul>
<li><p>In the US conspiratorial agreements (such as price-fixing cartels, bidding cartels, or other agreements that restrict competition) or conspiring to abuse a position of dominance in a manner that harms competition is illegal under the terms of the Sherman Act 1890. Likewise, these kinds of practices are prohibited within the EU by Article 101 of the Treaty on the Functioning of the European Union.</p></li>
<li><p>In the US, the Clayton Act 1914 provides for the prevention of mergers that are deemed anti-competitive. A merger between ""big"" companies is likely to be anticompetitive because it will result in a significant increase in market concentration. More formally, <a href=""https://www.justice.gov/atr/herfindahl-hirschman-index"">the DOJ writes</a>, ""Transactions that increase the <a href=""https://en.wikipedia.org/wiki/Herfindahl_index"">HHI</a> by more than 200 points in highly concentrated markets are presumed likely to enhance market power under the Horizontal Merger Guidelines issued by the Department of Justice and the Federal Trade Commission."" Article 102 of the Treaty on the Functioning of the European Union serves the purpose of preventing anti-competitive mergers in the EU.</p></li>
</ul>

<p>The laws mentioned above are regularly used to prevent conspiracies or mergers that harm competition, and firms are often subjected to significant penalties for violations of these laws. For example, <a href=""http://ec.europa.eu/competition/cartels/cases/cases.html"">here is a list</a> of cases in which the European Commission has intervened to prevent cartels. <a href=""http://ec.europa.eu/competition/elojade/isef/index.cfm?fuseaction=dsp_merger_by_date"">Here is a similar list</a> for merger cases.</p>

<p>The relevant EU laws are mirrored in national law within EU member states so that member state competition authorities can also intervene to prevent conspiratorial behaviour.</p>

<ul>
<li>The issue of patents is a slightly more tricky issue. A patent is a state-granted right to behave anti-competitively. When a patent is awarded, the state is basically saying ""we are going to let you behave like a monopoly over this technology for the next 20 years"". This is harmful for all the usual reasons that monopoly is bad. <em>But</em>, there is an important trade-off. Firms invest a lot of resources into research and development. For example, developing a new drug is estimated to <a href=""http://www.forbes.com/sites/matthewherper/2013/08/11/how-the-staggering-cost-of-inventing-new-drugs-is-shaping-the-future-of-medicine/#5bce8fed6bfc"">cost as much as $5,000,000,000</a>. Companies would not be willing to make this investment if they thought that, as soon as the drug were invented, others would enter the market, copy the idea, and sell a cheaper competing generic alternative. If we want firms to innovate then there has to be some reward to innovation. Thus, the compromise we have is that firms are allowed to be a monopoly for a limited period of time in return for making their inventions public by writing them into a patent filing.</li>
</ul>
","11209"
"Markov decision processes, contractions and value iteration","132","","<p>I am reviewing Markov decision processes (MDP) and there is something I am missing with respect to the contraction argument. I am pretty sure it is a silly mistake somewhere (maybe computational), but anyways, I cannot figure it out. Here it goes.</p>

<p>Consider a simple MDP with two states and two actions defined as follows.</p>

<p>$$ r(s,a) = \begin{pmatrix} 1 &amp; 1 \\ 1 &amp; 1 \end{pmatrix},$$</p>

<p>$$ P(s,s',1) = \begin{pmatrix} 1 &amp; 0 \\ 1 &amp; 0 \end{pmatrix},$$</p>

<p>$$ P(s,s',2) = \begin{pmatrix} 0.5 &amp; 0.5 \\ 0.5 &amp; 0.5 \end{pmatrix},$$</p>

<p>$$ \beta \in (0,1). $$</p>

<p>Now suppose we start with two guesses for the value function</p>

<p>$$ V_1 (s) = \begin{pmatrix} 100 \\ 0 \end{pmatrix}, $$</p>

<p>and </p>

<p>$$ V_2 (s) = \begin{pmatrix} 0 \\ 1 \end{pmatrix}. $$</p>

<p>If we iterate on these approximate value functions using the Bellman operator we get</p>

<p>$$ T(V_1) = \begin{pmatrix} \max_a \begin{cases} 1 +  100\beta, \qquad \text{ if }  a = 1, \\
                                                 1 +  50\beta,  \qquad \text{ if }  a = 2.                                               \end{cases}\\
                             \max_a \begin{cases} 1 +  100\beta, \qquad \text{ if }  a = 1, \\
                                                 1 +  50\beta,  \qquad \text{ if }  a = 2.                                               \end{cases} \end{pmatrix} = 
\begin{pmatrix} 1 + \beta 100 \\ 1+ \beta 100 \end{pmatrix}$$</p>

<p>and </p>

<p>$$ T(V_2) = \begin{pmatrix} \max_a \begin{cases} 1 +  0\beta, \qquad \text{ if }  a = 1, \\
                                                 1 +  0.5\beta,  \qquad \text{ if }  a = 2.                                               \end{cases}\\
                             \max_a \begin{cases} 1 +  0\beta, \qquad \text{ if }  a = 1, \\
                                                 1 +  0.5\beta,  \qquad \text{ if }  a = 2.                                               \end{cases} \end{pmatrix} = 
\begin{pmatrix} 1 + \beta 0.5 \\ 1+ \beta 0.5 \end{pmatrix}$$</p>

<p>But then for $\beta$ close enough to $1$ and taking for instance the Manhattan norm, we have</p>

<p>$$ d(V_1(s),V_2(s)) \approx 101,$$</p>

<p>and </p>

<p>$$ d(T(V_1(s)),T(V_2(s))) \approx 199.$$</p>

<p>Now that sounds weird to me because I thought $T$ was supposed to be a contraction mapping. Where did I screw up? Is there a mistake in my computation? I am forgetting to apply an important hypothesis? Or am I misunderstanding something about contraction mappings?</p>
","<p>The value iteration operator is a contraction with respect to the <em>supremum</em> norm. Your example probably provides a counterexample for the statement that it's a contraction with respect to the Manhattan norm.</p>
","4463"
"No competitive equilibrium for pooling contracts","132","","<p>In class we dealt with insurance economics and, specifically, adverse selection due to information asymmetry. As one possible solution we considered pooling contracts, i.e. the same contract for both high- and low-risk households for some average price. We showed and I understood why the high-risk households now would buy more insurance than the low-risk ones and thus everybody would act as if they were low-risk whether this is true or not. What I am not sure about is why there wouldn't be an equilibrium in a competitive market. </p>

<p>It's clear that the low-risk individuals have reason to go for a lesser premium and, if some other insurer would offer this, then they would go there. </p>

<p>Therefore, my <strong>questions</strong> are: </p>

<p>1) So why won't there be an equilibrium? I would think that if a new insurer appears with a better deal than the pooling contract, then there would again be the problem with adverse selection. Hence, the new insurer wouldn't appear and offer a better deal in the first place? </p>

<p>2) I also read that this is pareto-inefficient in that it disadvantages the low-risk households (obvious) but does not benefit the high-risk households. The latter point I do not understand since the high-risk households will have a higher demand since the pooling contract situation makes the insurance relatively cheap. Isn't that a benefit? </p>
","<p>As one of the comments points out, there are many models of equilibria in insurance markets. But it sounds to me like you are referring to the Rothschild-Stiglitz (1976) paradigm. I will provide a basic summary of the key takeaways here, but there is a more complete explanation in <a href=""https://www.princeton.edu/~dixitak/Teaching/EconomicsOfUncertainty/Slides&amp;Notes/Slides15.pdf"" rel=""nofollow noreferrer"">this set of slides</a> and in those from any second-year graduate course in Public Economics.</p>

<ul>
<li>In this paradigm, mixed strategy equilibria are ruled out. So when we say that ""no equilibrium exists"", we are actually just saying that no <em>pure strategy</em> equilibrium exists.</li>
<li>There is never a pooling equilibrium. The basic reason for this is that a firm could profitably come in and offer a cheaper package with less insurance and poach away the low risk types. This leaves the existing firm with only the high risk types and it makes a loss.</li>
<li>There <em>may</em> or <em>may not</em> exist a separating equilibrium. If there does not, it is because - starting from a separating equilibrium - there exist pareto-improving cross-subsidies (from high to low risk types). This means that a firm can profitably come in and offer a package that attracts both types (i.e., a pooling contract).</li>
<li><strong>EDIT</strong>: To answer your second question, the separating equilibrium - if one exists - is indeed not pareto efficient but it does benefit both high and low risk types. The pareto efficient separating contract would offer full insurance to both type, but the Rothschild-Stiglitz candidate cannot. To see why, suppose that it did. Then both receive full insurance but the low-risk types get it for less. Clearly the high risk types will pretend to be low types and the incumbent firm will make a loss.</li>
</ul>

<p>In summary, this particular model offers a theory of pure strategy Nash Equilibria in insurance markets with adverse selection and multiple risk types. An equilibrium may or may not exist. If it does, then it is separating. </p>

<h2>Additional information</h2>

<p>There are competing paradigms that solve this problem with assumptions about the timing of when offers are made and accepted (e.g., Miyazaki-Wilson-Spence). Another classic model to compare is Akerlof-style adverse selection. Neither alternative suffers from the non-existence problem.</p>
","17034"
"Tests of rational inattention","132","","<p>Can you provide a reference regarding a revealed preference test(s) of rational inattention models, as proposed by Sims, ergo, using a mutual information measure as the cost of putting attention. And if possible can you briefly explained it. A link that explains the model is given here <a href=""http://sims.princeton.edu/yftp/Gerzensee/info.pdf"">http://sims.princeton.edu/yftp/Gerzensee/info.pdf</a></p>
","<p>Empirical Evidence on rational inattention:</p>

<p>-<em>Title:</em> Attention Discrimination: Theory and Field Experiments with Monitoring Information Acquisition,
<em>Authors:</em> Vojtěch Bartoš, Michal Bauer, Julie Chytilová, and Filip Matějka.
<em>Source:</em> IZA Discussion Paper No. 8058. </p>

<p><em>Link</em>: <a href=""http://ftp.iza.org/dp8058.pdf"" rel=""nofollow"">Attention Discrimination: Theory and Field Experiments with Monitoring Information Acquisition</a></p>

<p>-<em>Title:</em> What Can Survey Forecasts Tell Us about Information Rigidities?
<em>Authors:</em> Olivier Coibion and Yuriy Gorodnichenko.
<em>Source:</em> Journal of Political Economy, Vol. 120, No. 1 (February 2012), pp. 116-159</p>

<p><em>Link:</em> <a href=""http://goo.gl/3OPzQB"" rel=""nofollow"">What Can Survey Forecasts Tell Us about Information Rigidities?</a></p>

<p>-<em>Title:</em> A Rational Theory of Mutual Funds’ Attention Allocation,
<em>Authors:</em> Marcin Kacperczyk, Stijn Van Nieuwerburgh, Laura Veldkamp.
<em>Source</em>: NYU Working Paper No. 2451/28347 June 5, 2014</p>

<p><em>Link:</em> <a href=""http://goo.gl/Hdsnai"" rel=""nofollow"">A Rational Theory of Mutual Funds’ Attention Allocation</a></p>
","8372"
"What were the factors that caused the Philips curve to stop working during the 1970s?","132","","<p>Philips curve says that inflation and unemployment were inversely correlated. In the 1970s, stagflation happened. If Philips curve hold true, stagflation is impossible. </p>

<p>What were the factors that caused the Philips curve to stop working during the 1970s when the economy was hit by stagflation?</p>
","<p>The general way people figured the Phillips curve worked was that a shock in aggregate demand or fiscal stimulus would cause labor demand to increase as government spending generated growth, which makes labor more scarce and causes firms to compete for workers by raising nominal wages. Wage costs then rise, and the firm passes on some of the cost to the consumer by raising the prices of their products.</p>

<p>So in this way, unemployment and inflation become tradeoffs. The problem is then this can be easily exploited, but also easily noticed. Lucas's critique states that people's expectations of inflation--and future inflations--will affect price levels as well. So if a policy maker tried to create inflation all the time to lower unemployment, what would happen is that the Phillips curve would actually shift around, so the tradeoff would hold, but you would be getting worse tradeoffs as people's expectations shifted.</p>

<p>By raising inflation constantly by the central bank and by politicians, you'd fall into a liquidity trap (when raising inflation fails to decrease interest rates and stimulate and economy). The reason why is because if everyone expected the rise in inflation, there'd be no reason to hire more workers, since real demand is staying the same. So instead of a short run rise in output, firms just went straight to raising prices instead of hiring more people.</p>

<p>That said, today, Lucas's critique has its limitations. Even transparent policies that are fully known to increase inflation by firms can still boost output in the short run. This is probably because after the 1970s in America, the new head of the Federal Reserve, Paul Volcker, decided that the central bank should commit more heavily to a set inflation rate in the long run, so that their policies would be more credible.</p>

<hr>

<p>We can set up a game-theoretic model for optimal monetary policy, as such:</p>

<p>$$\max_{u, \pi} V(u, \pi) = -(u^2 + \pi^2)$$</p>

<p>The central bank wants to minimize a combination of unemployment and inflation. Their constraint is a simple Phillips curve:</p>

<p>$$u = u^* - k(\pi - \pi^e)$$</p>

<p>Where $k &gt; 0$ is some weight for the degree of the tradeoff ($-k$ is the slope of the Phillips curve). $u^*$ is the natural rate of unemployment and fixed, while $\pi^e$ is the expected inflation.</p>

<p>Comparing the Ramsey and Nash equilibria of this game, where consumers and firms set expectations of inflation and the central bank tries to game that, we'll find that if firms trust the central bank to be honest about what inflation they are targeting, the central bank will always have the incentive to lie, if only acting for one period.</p>

<p>Substitute the Phillips curve into the central bank's maximization problem:</p>

<p>$$\begin{align}
&amp; V = [u^* - k(\pi_t - \pi^e)]^2 + \pi^2 \\
&amp; \frac{\partial V}{\partial\pi} = -2[u^* - k(\pi_t - \pi^e)]k + 2\pi = 0\\
&amp; \implies \pi_{\text{opt}} = \frac{k}{1+k^2}(u^* + k\pi^e)\\
&amp; u_{\text{opt}} = u^* - k(\pi - \pi^e) \\
&amp; \implies u_{\text{opt}} = \frac{1}{1+k^2}u^* +  \frac{k}{1+k^2}\pi^e \\
\end{align}$$</p>

<p>Now assume the private sector knows the Fed's optimal monetary policy problem, and set $\pi^e = \pi_{\text{opt}}$. Say the Fed is credible.</p>

<p>$$\pi_{\text{opt}} = \pi^e = \frac{k}{1+k^2}(u^* + k\pi^e)$$
$$\boxed{\pi^e = ku^*}$$</p>

<p>$$u_{\text{opt}} = \frac{1}{1+k^2}u^* +  \frac{k}{1+k^2}\pi^e$$
$$= \frac{1}{1+k^2}u^* +  \frac{k}{1+k^2}ku^*$$
$$\boxed{u = u^*}$$</p>

<p>These are the best responses for the Fed...if they are worried about telling the truth. Investigating Ramsey's time inconsistency problem, the Fed can technically do better. Suppose it announces $\pi = 0$ as a target.</p>

<p>$$\pi_{\text{opt}} = \frac{k}{1+k^2}u^*$$
$$u_{\text{opt}} = \frac{1}{1+k^2}u^*$$</p>

<p>You can verify that the Fed has an incentive to deviate in a one-period game.</p>
","9050"
"Distribution of US after-tax money income by household size","131","","<p>I'm looking for the US household distribution of after-tax after-transfers income by household size, at a finer grain than quintiles. CPS has total money income (<a href=""https://www.census.gov/cps/data/incdef.html"" rel=""noreferrer"">after-transfer</a>) in ~$2,500 increments, but  I can't find an after-tax version. Do the full census, BLS, or think tanks estimate this?</p>
","<p>You can find this information <a href=""https://ourworldindata.org/incomes-across-the-distribution/"" rel=""nofollow noreferrer"">here</a>. They provide an overview of their results, together with a link to the data and its description. The data is also available through <a href=""http://www.lisdatacenter.org/resources/other-databases/"" rel=""nofollow noreferrer"">LIS</a> (second item).</p>

<p>Interestingly, this does not only include the US, but also many other OECD countries, in a homogeneous methodology (great for comparisons). Additionally, this is a longitudinal study of each country. In total, <strong>they have data for 27 developed countries between 1978 and 2013</strong>.</p>

<p>The data is very comprehensive, and it is <strong>at the decile level</strong>. It includes:</p>

<ul>
<li>Entire population, decile cut-offs, equivalised household income</li>
<li>Working age population, decile cut-offs, equivalised household income</li>
<li>Entire population, decile means, equivalised household income</li>
<li>Working age population, decile means, equivalised household income</li>
<li>Entire population, decile cut-offs, per capita household income</li>
<li>Working age population, decile cut-offs, per capita household income</li>
<li>Deflator and PPP</li>
</ul>
","16005"
"Jordi Gali Euler Equation Beta","131","","<p>Derivation euler equation in gali book, I don't understand </p>

<p>"" β "" transformation.</p>

<p>Jordi Gali book, page 42
<a href=""https://i.stack.imgur.com/PYceI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PYceI.png"" alt=""enter image description here""></a></p>

<p>There is no explanation gali book</p>

<p>the notes which are prepared by Drago Bergholt (Page 6)</p>

<p>explain FOC for ""Ct""  (2.13)
and
(2.18) explain Euler equation</p>

<p>Writer uses FOC for ""Ct"" and FOC for ""Ct+1"" to form euler.</p>

<p><a href=""https://i.stack.imgur.com/v70QA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/v70QA.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/XzvjP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XzvjP.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/2MGhp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2MGhp.png"" alt=""enter image description here""></a></p>

<p>and I expect to different "" β "" for ""Ct""  and for ""Ct+1"" in (2.18)
But there is only one "" β "" in (2.18)
<a href=""https://i.stack.imgur.com/8K5KG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8K5KG.png"" alt=""enter image description here""></a></p>

<p>My question is assumption of ""In the baseline calibrations of the model’s preference parameters it is assumed β = 0.99"" and
for this (0.99) need to βt+1 is less than βt. Is it possible ?</p>

<p>Sincerely</p>
","<p>There is no trick in that Euler equation. In the New Keynesian model, the Euler equation for consumption is derived from the first order condition for $B_t$, the bond holding. You have to pay attention to the fact that bonds appear in the budget constraint at two moments in time $t$ and $t+1$. Thus you have to compute the foc as
\begin{gather}
B_t:\beta^t\lambda_tQ_t-\beta^{t+1}\lambda_{t+1}=0
\end{gather}
Then substituting $\lambda$ using the foc for $C_t$ and simplifying the betas, you obtain
\begin{gather}
Q_t=\beta E_t\{\frac{U_{c_{t+1}}}{U_{c_t}}\frac{P_t}{P_{t+1}}\}=0
\end{gather}</p>

<p><strong>EDIT</strong>: In the NK model, household maximizes its utility function choosing $C_t$, $N_t$ and $B_t$. Thus, you have to compute the FOC for these three variables, i.e.
\begin{align}
B_t:&amp;\beta^t\lambda_tQ_t-\beta^{t+1}E_t\{\lambda_{t+1}\}=0 \\
C_t:&amp;\beta^tU_{c,t}-\lambda_tP_t=0 \\
N_t:&amp;\beta^tU_{n,t}-\lambda_tW_t=0
\end{align}</p>

<p>In order to compute the consumption Euler equation, you need to substitute $\lambda_t$ from the $C_t$ foc into the $B_t$ foc. Then rearranging and simplifying $\beta$ as $\beta^{t+1}/\beta^t=\beta$ you get the equation you wrote above. </p>

<p>You get only one $\beta$ because it is constant over time, it is not index by $t$ as the other variables, it is a constant. Thus whatever time is $C$, you will have the same $\beta$. I think it is well explained in Gali too.</p>
","15110"
"Minimum wage vs wage subsdies","131","","<p>Many politicians argue that the minimum wage is essential for providing an sufficient standard of living to all. However, there are many issues binding price floors predicted by standard supply and demand theory. Why couldn't wage subsidies be used instead? I know that they are used. However, why do politicians always argue for increasing the minimum wage as opposed to increasing wage subsidies?</p>

<p><strong>what advantages does the minimum wage have versus wage subsidies?</strong></p>
","<p>We could distinguish between two kinds of ""wage subsidies"": </p>

<p>A) The government pays to the firm part of the wage <em>cost</em>, usually social security fees.</p>

<p>B) The government pays to the employee a markup on his wage. </p>

<p>In scenario <strong>A</strong>, labor supply is not affected but labor demand shifts outwards: the tendency <em>should</em> be higher employment <em>and</em> higher equilibrium wage (so eventually more disposable income for the workers). Usually, what is observed is that employment rises (after all, usually such programs are on  condition of <em>net new</em> jobs creation in a company), but wages do not increase (i.e. firms don't share the subsidy with the employees). So no betterment of standard of living <em>of those employed</em>.</p>

<p>In scenario <strong>B</strong>, take-home income will increase at no cost to the firms. So now, workers know that if the current wage is $w$, if they work they will receive $w+s$. This will shift the labor supply curve outwards (because now it responds to $w+s$), while the labor demand curve will remain unchanged (which still responds to $w$ only). This will tend to result in higher employment and <em>lower</em> equilibrium wage. But this contradicts (and partly or wholly offsets) the very purpose of the measure, which is <em>not</em> to increase employment, but to increase disposable worker income.  </p>

<p>So in both cases, wage subsidies are more about employment rather than income, while minimum wage is clearly about income and standard of living <em>of those employed</em>, even though it may hurt employment.</p>

<p>...and one cannot avoid in these matters a dash of political economy and political science (as well as social psychology): subsidies bear always a risk of fraud, and are always suspect of being an instance of pork-barrel politics. Moreover, they are mostly seen as measures in time of macroeconomic (or regional) recession/depression, where the main concern is to boost employment.  </p>

<p>On the other hand, minimum wage is not about a faltering economy as regards activity and <em>level</em> of production/income, but about market failure as regards <em>distribution</em> of income. Issues of distribution are inextricably linked to issues of fairness, and this creates a more passionate political agenda, occasionally  satisfying also the expectations of the public for a ""strong government"" which, ""when markets create unjust misery"", intervenes ""decisively"", imposing by decree ""what's fair"" (or fairer).</p>
","9688"
"Schumpeterian Business Cycles","131","","<p>The basic idea of Schumpeterian Business Cycles is that new technologies require creative destruction but will yield positive growth. These two opposing forces have impacts onto the real economy at different times, which will create fluctuations around the trend. </p>

<p>Romer (1986) has these effects in an explicit growth model, but he neglects the business cycle fluctuations.</p>

<p>Has there been any literature of business cycles based on the idea of Schumpeterian Growth? </p>
","<p>I will toot my own horn and cite - Phillips and Wrase. (2006) ""Is Schumpeterian ‘Creative Destruction’ a Plausible Source of Endogenous Real Business Cycle Shocks?,"" Journal of Economic Dynamics and Control, vol. 30 no. 11 pp. 1885-1913.</p>

<p>We found it difficult to match the volatility using Schumpterian mechanisms alone.  The business cycle asymmetries from our model were also exactly backward.  That is, a sudden discovery leads to a jump in output which slowly peters out.  While recessions tend to suddenly jump downward and then slowly recover.</p>

<p>The mechanism in our model was that an increase in productivity due to the discovery, leads to a reallocation of resources away from innovation toward production of output and this slows down the innovation process.</p>
","279"
"Will China's GDP be greater than the USA's and Europe's combined?","131","","<p>A newspaper said in 2080 China can be a developed country, with a bigger population. Does that mean China's GDP is going to be bigger than the USA's and Europe's combined?</p>

<p>Also, is this possible even though China's land area per person is smaller?</p>
","<p>Of course this is is possible. China is a very large economy currently and it is likely quite a way away from reaching its production frontier. It has lots of room to grow.</p>

<p>A lot can happen in 65 years and any forecasting this far into the future will be subject to a high degree of error. Don't forget that the US and Europe are dynamic as well. The current world economic climate may be in China's favour now but in 65 years who knows. Maybe everything we will need can be 3D printed an large scale manufacturing won't exist.</p>

<p>It is hard to look at <a href=""http://rads.stackoverflow.com/amzn/click/0767923057"" rel=""nofollow"">The Next 100 years</a>. It attempts to speculate on what can happen. *Spoiler*, the author does not expect the 21st century to be China's.</p>
","1896"
"Applications to Green's Theorem in Economics?","130","","<p>I was wondering about possible of application of integration to economics (other than welfare), more specifically, how might Green's theorem be useful for an economist?</p>

<hr>

<p>Let <em>C</em> be a positively oriented, piecewise smooth, simple closed curve in a plane, and let <em>D</em> be the region bounded by <em>C</em> . If <em>G</em> and <em>H</em> are functions of <em>(x,y)</em> defined on an open region containing <em>D</em> and have continuous partial derivatives there, then</p>

<p>$$\oint_C{(G\ dx + H\ dy) = \int\!\!\!\int_D {({{\partial H} \over {\partial x}} - {{\partial G} \over {\partial y}})\ dx\ dy} } $$</p>

<p>where the path integral is traversed counterclockwise.</p>

<p>The idea behind this theorem is that if you have a line integral in two dimensions, then Green's theorem can be used to compute the integral: 
 Green's theorem transforms the line integral around a simple closed curve $C$ into a double integral over the plane region $D$ bounded by $C$.</p>
","<p><a href=""http://www.tandfonline.com/doi/pdf/10.1080/1350486X.2010.531588?needAccess=true"" rel=""nofollow noreferrer"">Here</a> and <a href=""http://www.tandfonline.com/doi/abs/10.1080/135048698334673"" rel=""nofollow noreferrer"">here</a> are two application of the theorem to finance.</p>

<p><a href=""https://ideas.repec.org/p/fth/bereco/176.html"" rel=""nofollow noreferrer"">Here</a> is an application to game theory. </p>

<p><a href=""http://www.sciencedirect.com/science/article/pii/S0047259X0900089X"" rel=""nofollow noreferrer"">This</a> is an application of the theorem to complex Bayesian stuff (potentially useful in econometrics).</p>

<p>Also, the Green's theorem is used in <a href=""https://en.wikipedia.org/wiki/Bendixson%E2%80%93Dulac_theorem"" rel=""nofollow noreferrer"">this proof</a>, which relates to dynamics system, and therefore could be related to economic models (source of this <a href=""https://matheducators.stackexchange.com/questions/376/applications-of-vector-calculus-to-economics-finance#comment2379_376"">here</a>)</p>

<p>Last but surely not least, <a href=""http://www.springer.com/la/book/9783540073901"" rel=""nofollow noreferrer"">this book</a> might have relevant stuff. At least <a href=""https://books.google.co.uk/books?id=x5_wCAAAQBAJ&amp;pg=PA228&amp;lpg=PA228&amp;dq=green+theorem+use+in+economics&amp;source=bl&amp;ots=Iys4Nq7Qzv&amp;sig=ikQhNoygdMx1C2EwFGAVk2YUuiQ&amp;hl=es-419&amp;sa=X&amp;ved=0ahUKEwjS-q3Mvp7TAhWMCcAKHR8LA1sQ6AEIVTAI#v=onepage&amp;q=green%20theorem%20use%20in%20economics&amp;f=false"" rel=""nofollow noreferrer"">Chapter 12</a> does use it.</p>
","16232"
"Current knowledge about the empirics of consumer theory","130","","<p>I would like to get up to speed on the current state of empirical work done to test the assumptions and predictions of consumer theory (think Chapters 1, 2, 3, and 6 of Mas-Colell et al.).</p>

<p>Can anyone recommend a good survey or provide a brief summary of what we currently know about how much empirical support there is for our primary means of modelling individual behavior?</p>
","<p>The primary literature concerned with this type of question (at least where classical results break down) is behavioral economics. There's a great general compilation of papers put together by the Russell Sage Foundation called the ""Behavioral Economics Reading List"" that includes, among other things, a General Introduction section with overview papers by some of the big movers and shakers (Camerer, Kahneman, Laibson, etc.).</p>

<p>Many of the papers you will find through the Russell Sage paper list will be on alternative methods to classical consumer theory. If you want just the tests of assumptions/predictions, I would recommend looking through the abstracts of John Lists's papers on <a href=""http://home.uchicago.edu/jlist/research2/theory.html"">Testing Economic Theory</a>. List is one of the most prolific experimentalist authors on the subject and has weighed in on most questions that other people work on in this field as well. Just reading his abstracts on that page should give you a pretty good idea of the state of the literature up through 2011 (the website isn't updated). His <a href=""http://home.uchicago.edu/~jlist/JLIST_CV.pdf"">CV</a> is updated, but doesn't give you the abstracts without looking up the papers individually.</p>
","5421"
"Derivation of Equilibrium Strategy in 1st-price Auction?","130","","<p>Hey, everyone. I desperately need help understanding some math in auction theory.  I have been writing a paper as an undergrad for auction theory, and after all of my research I just cannot understand one step the author of a book uses to derive the equilibrium strategy for first-price auctions under independent private value conditions.<br>
The steps in the derivation process essentially follow this:
Let x = the chosen player's personal valuation, G(x) = the probability that the highest opposing bid, an order statistic, Y_1, is &lt; x.
\begin{equation}
\beta(x) = x - \int_0^x\frac{G(y)}{G(x)} \, dy \\
\end{equation}
Then without much explanation, other than ""values are uniformly distributed on [0,1]"" he just converts this equation to
\begin{equation}
\beta(x) = \frac{N-1}{N},
\end{equation}
Which makes sense and is usable.</p>

<p>The book I am using is Vijay Krishna's Auction Theory, and I would extremely appreciate someone helping me understand this last step.</p>
","<p>I remember slaving over the notation in this book when I was a bad undergraduate. It brings up some interesting memories, some which may help you.</p>

<ul>
<li>$F(x)$ is the cumulative distribution of a single bidder's valuation.</li>
<li>$G(x)$ is the cumulative distribution of the highest bidder's valuation, given $N$ bidders.</li>
</ul>

<p>For the example you are referring to, values being uniformly distributed along $[0,1]$ implies $F(x) = x.$ That's pretty straightforward. The chance of you having a valuation of $\frac{1}{2}$ or less for the object is, well, $\frac{1}{2}$. The chance of you having at least a value of $1$ should be a probability of $1$.</p>

<p>But why is $G(x) = x^{N-1}$ ?</p>

<p>For $n =1$, the chance of your valuation being the largest valuation or less is...well, $1 \ (= x^0)$.</p>

<p>For $n = 2$, the chance of your valuation being the largest valuation or less is just the chance that the other bidder has a valuation lower than you, or exactly $x$.</p>

<p>For $n = 3$, the chance of your valuation being the biggest or less is just the chance that both other bidders value the object less. Since you're working with independent private values, you can think of their valuations as independent (duh) events, so you can just multiply the events together. (<a href=""https://en.wikipedia.org/wiki/Conditional_probability#Formal_derivation"" rel=""nofollow noreferrer"">More on conditional probability here</a>). So for example the chance of someone having a smaller value than you is $x$, but there is another person who also has to have a smaller value than you, with the same chance $x$. The chance of both of them having smaller values than you is $x \cdot x = x^2$.</p>

<p>So it goes, the more bidders (independent valuations) you have.</p>

<hr>

<p>So we have your general formula for an optimal bid under a first-price auction:</p>

<p>$$\beta^1(x) = x - \int^x_0 \frac{G(y)}{G(x)} dy$$</p>

<p>So substitute in $G(x)$:</p>

<p>$$\beta^1(x) = x - \int^x_0 \frac{y^{N-1}}{x^{N-1}} dy$$</p>

<p>Evaluate:</p>

<p>$$= x \ - \ \biggr\lvert \frac{y^N}{Nx^{N-1}} + c\biggr\rvert^x_0$$
$$= x - \frac{x}{N} = \frac{Nx}{N} - \frac{x}{N}$$
$$\boxed{\beta^1(x) = x\frac{N - 1}{N}}$$</p>

<hr>

<p>The next example in Krishna's book has an exponential distribution, but only with two bidders. If you try using the same line of reasoning as I used above to find $G(x)$, you'll notice things appear a bit difficult, but the author doesn't explicitly state $G(x)$ in this case in fact. Try seeing for yourself if you understand why Krishna gives the helpful statement:</p>

<p>$$\frac{G(y)}{G(x)} = \left[\frac{F(y)}{F(x)}\right]^{N-1}$$</p>

<p>for the generic case where there is no functional form for the distributions.</p>
","14420"
"Finding optimal Inflation - Walsh","130","","<p>I am solving questions from Walsh and then verifying with a solutions manual. However, I keep solving a question and arriving at a slightly different answer than that suggested by the solution manual. </p>

<p>The solution given by the manual: </p>

<p><a href=""https://i.stack.imgur.com/teUsy.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/teUsy.png"" alt=""enter image description here""></a></p>

<p>However, when I take the optimal $\pi^e$ and substitute into (121) I get </p>

<p>$$\pi^* = \frac{\pi^T[-1-\lambda]}{[-1-\lambda]} + \frac{\lambda k [ -1-\lambda]}{[-1-\lambda]} + \frac{\theta k [1+ \lambda]}{[-1-\lambda]} +e\frac{\lambda - \theta}{[-1-\lambda]}$$ </p>

<p>and this simplifies to: </p>

<p>$$\pi^*= \pi^T + k(\lambda - \theta) - e\frac{\lambda + \theta}{[1 + \lambda]}$$</p>

<p>And so my issue is that I don't see how there is no $\lambda$ in the numerator of the fraction multiplying e at the end of the simplification. </p>

<p>Can anyone see my error? I must be missing something simple. </p>
","<p><strong>Edit:</strong> Roel Beetsma replied! He says he got the same derivation we basically got. So the solutions seem to be mistaken and we win! Also I'm removing the strikeout below.</p>

<p><a href=""https://i.stack.imgur.com/vXkfe.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vXkfe.png"" alt=""enter image description here""></a></p>

<p>Note that
$$+ e\frac{\lambda - \theta}{[-1-\lambda]}$$</p>

<p>actually simplifies to</p>

<p>$$ - e\frac{\lambda - \theta}{[1 + \lambda]} $$</p>

<p>rather than with $\lambda + \theta$ in the numerator like you had.</p>

<p>So the solutions has</p>

<p>$$- e \frac{1 + \theta}{1 + \lambda}$$</p>

<p>instead of what we have above. The difference between the two is:</p>

<p>$$-e\frac{-1 - \lambda}{1 + \lambda} = e$$</p>
","12230"
"How to close the gap between non-Econ background and Macroeconomics","130","","<p>I'm a first year PhD student with mathematical finance background, and am not quite familiar with all the assumptions/setup for macroeconomics. During study I found the math relatively easy but I'm having hard time to grasp the often critical relation between variables. For example capital market clearing implies that the total capital that firms have equal to the total assets that households have. First of all, I didn't even know there's a market clearing until I ask my TA, secondly, there are too many such assumptions I don't know. My professor would probably think it's too dumb to tell students about these because most of my classmates have an Econ background, but I don't and it's really killing me. Is there any good reference I can read, open courses I can watch that could help me with this? Given limited amount of time, I hope it won't take as much time as a full course. Thanks in advance. </p>
","<p>Surprisingly, I think the best way would be to read a Microeconomics textbook. You described difficulties with concepts like market clearing conditions. Macroeconomic models are usually based on general equilibrium models which students of Macroeconomics learn in their Microeconomics education. Consider reading the relevant parts of an intermediate Microeconomics textbook or Mas-Colell, Whinston + Green's classic Micro textbook for PhD students.</p>

<p>With this background knowledge, you can start reading Macroeconomics textbooks, e.g., Ljunquist/Sargent which teach you about the Macro-specific variations and applications.</p>

<p>You should also think about the quality of your program. A descent Economics PhD program will most certainly offer/require courses in Micro, Macro, and Econometrics.</p>
","8849"
"Question regarding General Equilibrium under non-convexities","130","","<p>I have the following question on my problem set:</p>

<p><a href=""https://i.stack.imgur.com/YiVkt.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YiVkt.png"" alt=""enter image description here""></a></p>

<p>It's clear to me, since consumer 2 does not care about good 2, that we should give all the economy's endowment of good 2 to consumer 1. In the other hand, both consumers care about good 1.</p>

<p>For item a), I think that in any optimal allocation we should have $x_{2,1} = 1$, since consumer 2 does not care about good 2.</p>

<p>Also, with this in mind, any allocation that has $x_{1,1} + x_{1,2} = 1$ is Pareto optimal, because we can only make one better hurting the other (assuming we have already exhausted good 2, giving all the economy's endowment to consumer 1). Question: is this reasoning right?</p>

<p>Another question: assuming I got it right, I have no idea how to find the vector price for each case.</p>

<p>For item b), the 1st Welfare Theorem needs to hold because there's local non-satiation for both consumers. On the other hand, lexicographic preferences are not convex. So, there's no reason for the 2nd theorem to hold. Is that sound?</p>

<p>Thanks a lot in advance!!</p>
","<p>You are right. Set of Pareto efficient allocations consist of all feasible allocations $((x_{11}, x_{21}), (x_{12}, x_{22}))$ satisfying the property that individual 1 consumes all of good 2 i.e. $x_{21} = 1$ and $x_{22} = 0$.</p>

<p>Competitive (or Walrasian) equilibrium in such an economy does not exist. At all price vectors $(p_1, p_2)$ satisfying $p_1 &gt; 0$ and $p_2 &gt; 0$, both the consumers will only demand good 1. As a result we will always have excess demand for good 1 and excess supply of good 2. When we consider a price vector $(p_1, p_2)$ of the form $p_1 &gt; 0$ and $p_2 = 0$, then consumer 1 will demand infinite amount of good 2 leading to excess demand for good 2. Therefore, there does not exist a price vector that clears both the markets.</p>

<p>First Welfare Theorem holds because preferences satisfy Local Non Satiation. Second Welfare Theorem does not hold because no matter how we distribute endowments, competitive equilibrium in such an economy does not exist, but efficient allocations exist.</p>

<p>Also, please note that the lexicographic preferences are convex. </p>
","16421"
"Stock Markets and Monetary Policies","130","","<p>Assuming we're dealing with rational investors, the stock price is equal to the present value of all future dividends(supposedly discounting at the nominal or real interest rates should give the same present value).</p>

<p>Imagine the Central Bank increases the real money supply, from an initial state of equilibrium, and this increase is unexpected by the investors of the stock market.</p>

<p>Now we have the consequences of monetary expansion in the 'physical' economy:</p>

<ul>
<li>In the short run, the expansion causes the <strong>nominal</strong> interest rate to decrease and the output to increase. However, in the medium run, the output reverts back to the natural level, and assuming for simplicity that the output growth rate is zero, the nominal interest rate also increases when compared to initial medium run equilibrium.</li>
<li>In the short run, <strong>real</strong> interest rate decrease. In the medium run it increases to the natural level, and remains equal to initial levels.</li>
</ul>

<p>In a book I'm reading on macroeconomics, it's stated that since in the short run the output (and dividends) increase, and the nominal interest rate decreases, the stock prices will go up, because the monetary expansion was unexpected. </p>

<p>My question is: shouldn't the rational investor know that changes in the nominal interest rate are only short term, with the longer term effect being in the opposite direction, and hence it's not clear cut that stocks' price should go up? Or should they always go up? Is it due to expected inflation that counteracts the higher expected nominal interest rate?</p>
","<p>I think at the outset you have to make the distinction between the real interest rate and the nominal interest rate. The nominal interest rate is the real interest rate less inflation. Assuming the money supple curve is a vertical line in M-r space, then a shift of the line to the right (as indicated by a monetary expansion) implies a decrease in the nominal interest rate. Some books make the distinction between money demand being dependent on nominal interest rates, but it makes intuitively more sense that money demand be a function of real interest rate rather than nominal. The <strong>real</strong> interest rate decreases as the nominal return on assets stays constant but the price level increases (increase in inflation as a result of the monetary expansion). Remember that the price of a stock in a perfect world is the net present value of all future dividends, discounted by <strong>real</strong> interest rate. As this interest rate decreases, we discount stocks less, and hence price increases. This is the intuition behind the inverse relationship between asset prices and interest rates. This however, is a short run effect, so stock prices increase in the short run. When the real interest rate returns to its original level in the medium run, the stock prices decrease again. In short, the fluctuations in stock prices reflect fluctuations in interest rate. (the illustration is simplest for a fixed coupon bond that pays <em>C</em> every period). Basically, it all depends <em>when</em> you examine the price.  </p>
","7133"
"Why are European countries happy to be outside Eurozone?","130","","<p>In EU countries like Poland, Czech Republic, Hungary, etc, people are happy that they are not in Euro zone and Euro crises like that of Greece do not affect their economics.</p>

<p>However, some European currencies outside the Eurozone are pegged to a narrow band around the Euro, so their values largely change in line with the Euro's. So, what is the difference if we call a currency Euro or something else, when its value is changing by Euro crises?</p>

<p>For example, what is the advantage of currency in Czech over Slovakia now?</p>
","<p>I largely agree with mathtastic, but I think it is necessary to add something.</p>

<p>When joining a monetary union a country does indeed lose its power to conduct monetary policy. However simply not being able to reduce the interest rate was not the main issue that Greece and other countries faced because of being in the Eurozone. This is because the ECB lowered interest rates (almost) down to the zero lower bound.</p>

<p>To adequately address your question we have to distinguish advantages of a country from having its own currency while in a crisis, vs. advantages from always having had its own currency in the first place.</p>

<p><strong>Reasons why it is helpful to have your own currency when a crisis has already hit:</strong></p>

<p>The issue in this case was the impossibility of devaluation of the currency. One way to understand the Greek crisis is as a current account crisis. Not only was the government over indebted, but the country as a whole. That is to say that there was a too large trade deficit for too long. The trade deficit creates a sort of debt that the whole country owes to other countries in total and was a main point of focus in the debates about Greek debt. You might have heard the issue of competitiveness being cited as a factor in the Greek crisis, which simply means the impossibiliy of the Greek economy to export sufficiently. You may have also heard about ""living above their means"" or ""BMWs going to Greece financed by German money"". All this refers to the trade deficit, i.e. the current accuont crisis.</p>

<p>To help itself out of this current account crisis, Greece would have to reduce its trade deficit, i.e export more and import less. If Greece would have had its own currency, a natural reaction to the crisis (without any government intervention even required) would be that Greece's currency loses value. Hence its exports are cheaper which leads to more exports and its imports are more expensive, which leads to less imports. In this way Greece would have an easier time dealing with the crisis and could also ""grow its way out of the crisis"" - policy advice often heard in this whole debate. </p>

<p>In addition to reducing the trade deficit, a currency devaluation would have helped Greece's economy grow and help with debt service, because the private and public sector were over indebted and not in a position to borrow. This means that domestic demand was very low, so foreign demand- i.e. exports- would have to pick up the slack.</p>

<p>Now, you might say that Greece could export more by simply reducing its prices even without currency devaluation. This is in theory true and is indeed what was recommended and what was attempted in Greece. You can look this up under the term <em>""internal devaluation""</em>. However there are several problems with this. First of all it is easier to simply devalue the currency (one price adjustment) than to reduce prices of all export goods (many price adjustments). Furthermore, price decreases mean deflation, which brings with it further problems and is hard to combat later on, when it is no longer desired. A term to look up for more information on this would be <em>""deflationary spiral""</em>. Third and perhaps most importantly is the issue of <em>""downward nominal rigidity""</em>. This is the empirically observed phenomenon that nominal prices tend to not go down as much as they should or at all, i.e. are rigid in going downwards. This come perhaps from money illusion. It is easier to inflate away workers' wages than to actually reduce them, because the former doesn't cause any protest, while the latter does. Although this is not rational, it happens. Hence it is very difficult to reduce prices and export more (i.e. be more competitive) without an own currency. </p>

<p>This is the reason many countries are likely happy to have their own currency. As to why they are happy despite possibly being ""pegged"" to the Euro, is because they can break that peg much more easily than Greece if they wanted to.</p>

<p><strong>Reasons why it is helpful to have your own currency before a crisis hits:</strong></p>

<p>For information on how it could have come to such a loss of competitiveness in Greece I can recommend looking up the <em>""Balassa-Samuelson effect""</em>, although this may not be the whole story.</p>

<p>Personally, I am not totally convinced by the conventional wisdom, especially popular in European media, that if Greece were to return now to the Drachma that things would be better. This is because their debts may then legally still be denominated in Euro and after the inevitable devaluation of the Drachma against the Euro (the whole point of having the Drachma now) would cause the debt burden to increase even further. For more on models where such effects are present see so-called <em>""third generation currency crisis models""</em>.</p>

<p>However had they not had the Euro in the first place, like the ""happy"" European countries you are mentioning, then their debts would have likely never been denominated in Euro in the first place and could more easily pay that debt through a currency devluation / inflation.</p>

<p>Another reason countries are happy to not have had the Euro in the first place is because the Euro created interest rates for Greece's public debt that were too low than what they should have been. This means the government became over-indebted, which lead to the problems we see today. Had the interest rates been (correctly) higher the government would have perhaps borrowed less and not too much. This is to say that due to the Euro (and the false positie expectations caused by it) the ""price signal"" was not working so well. Other countries that never adopted the Euro did not experience such a loss of information from the price signal.</p>
","8654"
"A feasible rational payoff that is not an equilibrium payoff in the repeated game","129","","<p>The textbook I am currently reading claims that, in an infinitely-repeated game with discount, there might be a payoff vector which is feasible and individually-rational, but it is not an equilibrium payoff vector in the repeated game. The example is the following basic game for three players:</p>

<pre><code>     L       R
T  0,2,5    0,0,0
M  0,1,0    2,0,5
B  1,1,0    1,1,0
</code></pre>

<p>The third player is a dummy player with only one possible action.</p>

<p>In this game:</p>

<ul>
<li>The minimax values of the players are 1,1,0.</li>
<li>The payoff vector 1,1,5 is both individually-rational and feasible (e.g. by mixing TL and MR with equal frequencies).</li>
</ul>

<p>The book claims that the only payoff vector in equilibrium is 1,1,0! Why?</p>

<p>Let $E$ be some equilibrium in the repeated game. The payoffs of the row and column players in $E$ must be 1, because:</p>

<ul>
<li>They must be at least 1 because these are the minimax values;</li>
<li>They must be at most 1 because the sum of utilities of these players in every outcome is at most 2.</li>
</ul>

<p>In the TR and ML cells, the sum of utilities of the row and column players is less than 2; hence, these cells are not played in equilibrium at all.</p>

<p>So in equilibrium, the only cells that may be played with positive frequency are: TL, MR, BL, BR.</p>

<p>Now, the authors claim that TL and MR are also not played at all in equilibrium. From this they conclude that the payoff of the dummy player is 0. I didn't understand this part. Is it true that TL and MR are never played in equilibrium? Why?</p>
","<p>It is true because of the discounting. If the discount parameter were $\delta = 1$ then players 1 and 2 could alternate playing TL and MR in equilibrium and then reach the average payoff vector $1,1,5$. But if $\delta &lt; 1$ someone will not play along. Suppose the players are supposed to start with TL. Then MR would follow in the next round then, then TL again, and so on. In this case
$$
U_1 = 0 + 2 \cdot \delta + 0 \cdot \delta^2 + 2 \cdot \delta^3 + ...
$$
Yet by always playing B player 1 would achieve the payoff
$$
U_1' = 1 + 1 \cdot \delta + 1 \cdot \delta^2 + 1 \cdot \delta^3 + ...
$$
which is larger then $U_1$. Similarly player 2 would not want to start with MR. So these are not equilibrium playoffs. (Not even Aumann's correlated-equilibrium would do the trick.)</p>
","9098"
"Labor theory of value examples and exercises","129","","<p>I'm looking for a working book of Marx's Labor Theory of Value. It would be nice if the book would explain his theory with calculated examples and some exercises with solutions that one can do. Since I'm a German I could read The Capital for myself, but I find it too complicated. Any good books on this?</p>
","<p>Check <a href=""https://www.postkeynesian.net/downloads/kingston13/JW110713.pdf"" rel=""nofollow noreferrer"">these slides</a>, which includes a fairly introductory analysis to the LTV, including some trivial examples and calculations.</p>

<p>Another introduction can be found <a href=""http://www.marxist.com/marx-marxist-labour-theory-value.htm"" rel=""nofollow noreferrer"">here</a> (part one) and <a href=""http://www.marxist.com/marx-marxist-labour-theory-value2.htm"" rel=""nofollow noreferrer"">here</a> (part two).</p>

<p>Yet, <a href=""http://www.jstor.org/stable/29790106"" rel=""nofollow noreferrer"">this</a> is the best I am aware of. It is an attempt to explain the theory to ""undergraduates"" using a simple example. Worth reading!</p>
","15257"
"Why do companies push users to use inferior software?","129","","<p>Sometimes, companies influence users in order to make them use inferior software and other services. For example, Microsoft makes it difficult to use anything other than Bing for Cortana, even though Google is mostly considered to be better. Similarly, Siri uses Safari instead of Chrome and it is difficult to change this, even though the latter is generally considered superior.</p>

<p>At first glance, the answer seems obvious: companies push users to use their products because they are the ones who get revenue from their own products, due to advertisements in search results.</p>

<p>However, this answer seems insufficient. Suppose Microsoft generates $n$ USD in revenue per unit time from using Bing with Cortana. It seems reasonable to suppose that if Cortana had used Google, Google would generate $n + \epsilon$ USD per unit time from her, where $\epsilon &gt; 0$ due to Cortana using a superior search engine, which would cause her her to be at least slightly more popular. If this is the case, why doesn't Microsoft make Cortana use Google under the condition that Google gives $n + \epsilon'$ to Microsoft, where $0 &lt; \epsilon' &lt; \epsilon$? Wouldn't this roughly give Microsoft an additional $\epsilon' &gt; 0$ in profit and give Google an additional $\epsilon - \epsilon' &gt; 0$? If Microsoft using Google would further increase Google's name recognition and decrease Microsoft's, then why not just increase $\epsilon'$ to take this into account?</p>
","<p>There are a lot of factors that can explain why they do not. The stackexchange says to avoid ""Making statements based on opinion;"" but I do not think that this is possible.  There is most likely no one answer to this, and I would mark it a behavioral economic question instead of just micro economics. This answer assumes that your example gives each firm an additional profit. </p>

<p>1) Microeconomics assumes that each firm acts rationally; that is maximizes utility. Traditionally this means maximizing profit. This major assumption has been proved wrong again and again, and evidence suggest that the pure neo-classical model is not a sufficient indicator of firms actions. </p>

<p>2) While the end result of a contract will lead to a higher profit, the transaction cost between the firms may be high. <a href=""http://down.cenet.org.cn/upfile/39/20057517433183.pdf"" rel=""nofollow"">Transaction Cost Theory</a> basically adds friction to the invisible hand of neo-classical economics. Read the introduction, section 2.2-.3, and all of section 3.1. The external transaction cost between the two firms would be huge. Both companies are opportunistic, both firms have their own strategic intent, and assume both firms would not trust each other. What would have to result is an extremely ridged contract trying to encompass all possibilities, which can offset the additional profit both would obtain and lead to an extremely bureaucratic system that is not a characteristic of a successful tech company.  For example, if I was using a Windows Cortana and searched via a joint venture with Google for a pc, would my search be directed to Microsoft's store or Google's store? A better example would Googles licensing rights. Would google be able to license it's product to other firms. If it was, it could charge a lower price else where via more favorable terms and undercut Microsoft all together (much like Microsoft did to IBM with DOS). If it couldn't, it would be depended to Microsoft, something the firm certainly does not need. </p>

<p>3) Google is dealing with anti-trust suits in Europe. For Google, teaming up with Microsoft to gain further market share would not go well in their efforts to prove they are not a monopoly, and it may bring anti-trust suit in the US. For Microsoft, given their history, I am positive they want to stay as far away from this as possible.</p>

<p>4) Potential may be the most over valued asset. While a search engine is valuable today, in the future having your own may be infinitely valuable. I am not a tech guy, but I can see the value in controlling what people find when they search certain key words. The short-term lose of potential profits as a result of an inferior search engine can be far out weighed by devolving one that meets industry standards. Add that with the fact that Microsoft's core business (OS) is not going to be undermined by a poor search engine, I can understand why they want to deploy their own.</p>

<p>As I said earlier, these are just possibilities, and a combination of factors leads them not to collaborate. </p>
","7095"
"Does it make sense to apply complex mathematics in economics given that the result can be off by substantial percentage points?","128","","<p>Complex mathematics make sense if the results can be calculated with precision. This applies for the physical sciences like physics and engineering. Economics is more of a social science subject. Does complex mathematics make sense in this context?</p>
","<p>In the field of economics complex math is often used for</p>

<p>a) Economic modelling</p>

<p>There are usually tons of factors that influence even the simplest economic event. It is often necessary to resort to complex math to include all the variables that represent those factors in the right way.</p>

<p>b) Analysis of statistical data</p>

<p>It is often very difficult to support economic theories with good data, again because there are so many factors in play. On top of that, many simple mathematical instruments have drawbacks and should not be applied in certain situations. For example, to test relationship between two variables, you can use a simple correlation coefficient, but there are cases where outliers or certain patterns can make it unreasonably high or low. Then you can use simple linear regression, but if you spent months gathering data you may want to spend a few days trying to build a custom regression equation for a better fit. Finally, if you are preparing a paper for publication, you may want to use as many statistics as you can to try to convince reviewers and readers that your findings are actually true.</p>

<p><strong>Drawbacks of using complex math in economics</strong></p>

<p>1) There are not that many readers out there who are proficient in advanced mathematics. Unless you want to limit your target audience to a few math enthusiasts, keep it as simple as possible.</p>

<p>2) If you are preparing a paper for review at a journal, keep in mind that reviewers in economic journals are not necessarily mathematicians. It usually takes longer for math-heavy papers to get reviewed and the quality of those reviews may not be great, unless its a top journal.</p>
","9171"
"Learning about Debt and Credit","128","","<p>I am very interested in learning about debt and credit - not personal debt and credit - but debt and credit of countries and the like. I have searched everywhere but it's difficult to find books that are related to these topics. One such book that I found was Alexander Graeber's ""Debt: The First 5000 Years"". </p>

<p>I was wondering if someone has a recommendations for books that would allow someone to get a much better idea of what exactly debt and credit are and how they affect the world around us. </p>

<p>Thanks!</p>

<p>P.S. I apologize in advance if this question is off topic but this was my last resort. <code>:)</code></p>
","<p>You might call Graeber's theory of money as something emerging from a system of compensation from the harm of others. </p>

<p>The Chartalist's say the state is what makes money, they demand taxes be paid in money, this gives money value, and then the state makes money which it spends on what it wants. </p>

<blockquote>
  <p>The Chartalist contribution turns on the recognition that money cannot
  be appropriately studied in isolation from the powers of the state –
  be it modern nation-states or ancient governing bodies. It thus offers
  a view diametrically opposed to that of orthodox theory, where money
  spontaneously emerges as a medium of exchange from the attempts of
  enterprising individuals to minimize the transaction costs of
  barter. The standard story deems money to be neutral – a veil, a simple
  medium of exchange, which lubricates markets and derives its value
  from its metallic content. Chartalism, on the other hand, posits that
  money (broadly speaking) is a unit of account, designated by a public
  authority for the codification of social debt obligations. More
  specifically, in the modern world, this debt relation is between the
  population and the nation-state in the form of a tax liability. Thus
  money is a creature of the state and a tax credit for extinguishing
  this debt. If money is to be considered a veil at all, it is a veil of
  the historically specific nature of these debt relationships.
  Therefore, Chartalism insists on a historically grounded and socially
  embedded analysis of money.</p>
  
  <p>This chapter distinguishes between several broad Chartalist
  propositions about the origin, nature and role of money, and several
  specific propositions about money in the modern context. It offers
  only a cursory examination of the historical record to illumin- ate
  the essential characteristics of money emphasized in the Chartalist
  tradition. Chartalist ideas are not new, although they are most
  closely associated with the writings of Georg Friedrich Knapp of the
  German Historical School. Thus the chapter briefly surveys instances
  in the history of thought which have emphasized the chartal nature of
  money. The paper then expounds on Chartalism, clarifying aspects of
  the concepts and drawing out the implications for modern currencies.
  It concludes with a discussion of the various applications of this
  approach to policy.</p>
</blockquote>

<p><a href=""http://pavlina-tcherneva.net/Tcherneva-Chartalism.pdf"" rel=""nofollow noreferrer"">Chartalism and the tax-driven approach to money</a></p>

<p>Economics (as a profession) generally focuses on another motive for money, solving the problem of the double coincidence of wants. That is, in barter we generally need to both want what the other has or we can't make a deal (unless we have credit, but consider barter among strangers). Money presents an alternative, a good that we don't want per se, but we can use for transactions because everyone else wants it and we can rely upon to want it later as well. Such a thing should be portable, hard to counterfeit, and easily identified. Then when Art wants to buy a Ball and Charlie has a Ball but wants to a Dog, Art can use his money to buy the Ball from Charlie so that later he can use money to buy a Dog from Eric who will then use it to buy Florence's Goat, and so on...</p>

<p>There is an accessible and justifiably famous paper on this sort of money, <a href=""http://www.jstor.org/stable/2550133?seq=1#page_scan_tab_contents"" rel=""nofollow noreferrer"">The Economic Organisation of a P.O.W. Camp</a>,  about how cigarettes emerged as this sort of money in WW II POW camps. Graeber singles this paper out for scorn, saying these people already knew about money and so this is not a good example of a origin story for money, but it is a nice example of money as an emergent phenomenon to solve the double coincidence of wants problem. </p>

<p>I haven't read <a href=""http://rads.stackoverflow.com/amzn/click/0143116177"" rel=""nofollow noreferrer"">Ascent of Money,</a> I recall it getting mixed reviews, but I really enjoyed a Ferguson's somewhat related <a href=""http://rads.stackoverflow.com/amzn/click/0465023266"" rel=""nofollow noreferrer"">The Cash Nexus</a>,  which might help you understand the national aspect of your question. I also enjoyed <a href=""http://rads.stackoverflow.com/amzn/click/0195175719"" rel=""nofollow noreferrer"">The Origins of Value: The Financial Innovations that Created Modern Capital Markets</a>, but that book covers much more than just money.  <a href=""https://www.aeaweb.org/assa/2005/0108_0800_0805.pdf"" rel=""nofollow noreferrer"">Famous Myths of Fiat Money</a> has some nice examples of commodity money emerging to solve transactional issues. <a href=""https://pantherfile.uwm.edu/vesely/www/831/Kiyotaki%201989%20JPE.pdf"" rel=""nofollow noreferrer"">On Money as a Medium of Exchange</a> is a famous (relatively modern) theory paper that covers the benefits of fiat over commodity money. The book <a href=""http://rads.stackoverflow.com/amzn/click/B000FBFKI6"" rel=""nofollow noreferrer"">What is Money?</a> in many ways is a long answer to your question, with <a href=""http://books.google.com/books?id=VtSFAgAAQBAJ&amp;lpg=PA139&amp;ots=5WJcwFV0Op&amp;dq=The%20Invisible%20Hand%20and%20the%20Evolution%20of%20the%20Monetary%20System.&amp;lr&amp;pg=PA142#v=onepage&amp;q=The%20Invisible%20Hand%20and%20the%20Evolution%20of%20the%20Monetary%20System.&amp;f=false"" rel=""nofollow noreferrer"">chapter 7</a> in particular covering a lot of these issues.  </p>
","3258"
"Log-linearization of the market clearing condition","128","","<p>I am dealing with a paper of Walsh &amp; Ravenna.</p>

<p>www.banque-france.fr/fondation/gb/telechar/bourses_recherche/Welfare-based_Ravenna.pdf</p>

<p>I am kind of confused by the euqation (19) on page 33.</p>

<p>The market clearing condition goes as follows:</p>

<p>$$Y_{t} = C_{t} - w^{u}(1 - N_{t}) + \kappa\upsilon_{t}$$</p>

<p>Log linearization around the steady state yields</p>

<p>$$\hat{y}_{t} = \frac{\bar{C}}{\bar{Y}}\hat{c}_{t} - w^{u}\hat{n}_{t} + \left( \frac{\kappa\bar{\upsilon}}{\bar{Y}}\right)(\hat{\Theta}_{t} + \hat{u}_{t} )    \;\;\; \mathbf{(19)} $$</p>

<p>I don't know how this formula (19) is derived?
Isn't there something missing? From my basic understanding of log linearization it ought to look like this:</p>

<p>$$\hat{y}_{t} = \frac{\bar{C}}{\bar{Y}}\hat{c}_{t} - \left( \mathbf{\frac{\bar{N}}{\bar{Y}}} \right) w^{u}\hat{n}_{t} + \left( \frac{\kappa\bar{\upsilon}}{\bar{Y}}\right)(\hat{\Theta}_{t} + \hat{u}_{t} )$$</p>

<p>with
$$ Y_{t}\;\;...\;\; output $$
$$ C_{t}\;\;...\;\;  consumption $$
$$ w^{u}\;\;...\;\;  wage\;of\;unmatched\;workers $$
$$ 1-N_{t}\;\;...\;\;  unmatched\;workers $$
$$ w^{u}(1-N_{t})\;\;...\;\;home\;production$$
$$ \kappa\;\;...\;\;  cost\;of\;posting\;vacancy $$
$$ v_{t}\;\;...\;\;  vacancies $$
$$ \hat{v}_{t} = (\hat{\Theta}_{t} + \hat{u}_{t} ) $$
$$ \omega = \frac{v_{t}}{u_{t}}\;\;...\;\;measure\;of\;labour\;market\;tightness$$
$$ \hat{\cdot}\;\;...\;\;log\;deviation\;from\;steady\;state\;value$$
$$ \bar{\cdot}\;\;...\;\;steady\;state\;value$$</p>

<p>Small letter with a hat: log deviation of a variable arount its steady state.
Big letter with a bar: steady state value.
K: cost of posting a job vancancy.
w^u: ""wage"" of unemployed workers.</p>

<p>I've read the paper and the appendix aswell, read both the papers in the bibliography of this one aswell as later ones basing on this publication, but I could not find a helpful hint.</p>

<p>Is there any special relationship between N and Y in the steady state that explains why this whole term vanishs? Or do I have a wrong understanding of log-linearization?</p>

<p>I have to apologyze for my rusty English. I am already taking care of this problem. But for the above mentioned I would like to have your help. Does anyone has a decisive hint?</p>
","<p>We have:</p>

<p>$$y_t = c_t − w^u(1 − N_t) + \kappa v_t$$</p>

<p>We take the log of both sides:</p>

<p>$$\ln y_t = \ln \left[ c_t − w^u(1 − N_t) + \kappa v_t \right]$$</p>

<p>And then linearize around the steady states:</p>

<p>$$\begin{align}
\ln \bar{y} + \frac{1}{\bar{y}}(y_t - \bar{y}) &amp; = \ln \left[ \bar{c} - w^u(1-\bar{N}) + \kappa \bar{V} \right] + \frac{1}{\left[ \bar{c} - w^u(1-\bar{N}) + \kappa \bar{V} \right]}(c_t - \bar{c}) \\
&amp; + \frac{w_u}{\left[ \bar{c} - w^u(1-\bar{N}) + \kappa \bar{V} \right]}(N_t - \bar{N}) \\
&amp; + \frac{\kappa}{\left[ \bar{c} - w^u(1-\bar{N}) + \kappa \bar{V} \right]}(V_t - \bar{V})
\end{align}
$$</p>

<p>Cancel $\ln \bar{y}$ and $\ln \left[ \bar{c} - w^u(1-\bar{N}) + \kappa \bar{V} \right]$</p>

<p>$$\begin{align}
\frac{1}{\bar{y}}(y_t - \bar{y}) &amp; = \frac{1}{\left[ \bar{c} - w^u(1-\bar{N}) + \kappa \bar{V} \right]}(c_t - \bar{c}) \\
&amp; + \frac{w_u}{\left[ \bar{c} - w^u(1-\bar{N}) + \kappa \bar{V} \right]}(N_t - \bar{N}) \\
&amp; + \frac{\kappa}{\left[ \bar{c} - w^u(1-\bar{N}) + \kappa \bar{V} \right]}(V_t - \bar{V})
\end{align}
$$</p>

<p>Multiply the first term on the right hand side by $\frac{\bar{c}}{\bar{c}}$, and similarly for the other terms:</p>

<p>$$\begin{align}
\frac{1}{\bar{y}}(y_t - \bar{y}) &amp; = \frac{\bar{c}}{\left[ \bar{c} - w^u(1-\bar{N}) + \kappa \bar{V} \right]}\frac{(c_t - \bar{c})}{\bar{c}} \\
&amp; + \frac{w_u \bar{N}}{\left[ \bar{c} - w^u(1-\bar{N}) + \kappa \bar{V} \right]}\frac{(N_t - \bar{N})}{\bar{N}} \\
&amp; + \frac{\kappa \bar{V}}{\left[ \bar{c} - w^u(1-\bar{N}) + \kappa \bar{V} \right]}\frac{(V_t - \bar{V})}{\bar{V}}
\end{align}
$$</p>

<p>And we simplify, taking advantage of the fact that $\hat{v}_t = \hat{\theta}_t + \hat{u}_t$, to get what you have:</p>

<p>$$\hat{y}_t = \frac{\bar{C}}{\bar{Y}}\hat{c}_t + w^u \frac{\bar{N}}{\bar{Y}} \hat{n}_t + \left( \frac{K\bar{V}}{\bar{Y}} \right) (\hat{\theta}_t + \hat{u}_t) $$</p>

<p>I don't think this derivation is wrong. But you can see that $y_t$ and $N_t$ are directly proportional to each other. It's definitely plausible that $\frac{\bar{N}}{\bar{Y}} = 1$, but I've pored over the equations in the setup for 3 hours to no avail at showing that rigorously. It's probably something silly that I don't understand. I'll look back later and if nothing else, I'll turn this answer into a community wiki so anyone who has the right idea can edit it.</p>
","12109"
"Simple closed economy problem","128","","<p>Consider a simple closed economy model where <strong>Y = C + I + G</strong>, consumption is given by the function <strong>C = 100 + 0.5 (Y - T)</strong>, investment is <strong>I = 50</strong>, government purchases are <strong>G = 20</strong>, and the government’s 
budget is balanced. </p>

<p>How do I work out what tax is, to work out the amount of autonomous spending? Is there something obvious I'm missing?</p>
","<p>Given your equations, you can find</p>

<p>$$Y = C + 50 + 20 \implies Y = C + 70$$</p>

<p>You can then substitute $Y$ for its equal into your other equation</p>

<p>$$C = 100 + 0.5(C + 70 - T)$$</p>

<p>Finally, given a balanced buget, you know that $G = T$, which should be enough for you to solve for $C$.</p>
","13241"
"Speed of convergence of output on the balanced growth path","128","","<blockquote>
  <p>Find how quickly $y$ converges to $y^*$ in the vicinity of the balanced growth path
  $$ y=Y/AL=f(k); \; y^*=f(k^*) $$
  They suggest the hint, write $k=g(y)$, where $g(\bullet)=f^{-1}(\bullet)$.)</p>
  
  <p>$Y$ is product output; $AL$ is effective labour; $K$ is capital; lowercase letters are divided by $AL$ (e.g. $y=Y/AL$); $k^*$ is the balanced growth path of capital.</p>
</blockquote>

<p>This is problem $1.11$ in Advanced Macro by Romer.  I have tried looking at <a href=""https://en.wikipedia.org/wiki/Lagrange_inversion_theorem"" rel=""nofollow"">Lagrange Inversion Theorem</a>, and applying the above get to the first order Taylor series centered around $k^*$</p>

<p>$$ \displaystyle g(y) = k^* + \lim_{k \to k^*} \left( \frac{y-f(k^*)}{1!} \right) \frac{d^0}{dw^0} \left( \frac{k-k^*}{f(k)-f(k^*)} \right) $$</p>

<p>but since $y=f(k)$ and the zeroth derivative is the function itself, we get the following cancelation:</p>

<p>$$ = k^* + \lim_{k \to k^*} \frac{f(k)-f(k^*)}{f(k)-f(k^*)}(k-k^*) $$</p>

<p>$$ = k^* + \lim_{k \to k^*}(k - k^*) = k^* $$</p>

<p>Which doesn't tell us anything ... Do we need to look at the second order derivative?</p>
","<p>I believe there is a quicker way here. By the inverse function theorem, we have</p>

<p>$$y = f(k) \implies k = f^{-1}(y) = f^{-1}[f(k)] \implies \frac {\partial f^{-1}(y)}{\partial y} = \frac {1}{f'(k)}$$</p>

<p>Keeping all these relations in mind, we also have</p>

<p>$$\dot y = f'(k)\cdot \big[sf(k) - (n+g+\delta)\cdot f^{-1}(y)\big]$$</p>

<p>$$\implies  \frac{\partial \dot y}{\partial y} \bigg|_{y=y^*}  = \frac {\partial f'(k^*)}{\partial y}\cdot \big[sf(k^*) - (n+g+\delta)\cdot k^*\big]\\ + f'(k^*)\cdot \left[s - (n+g+\delta)\cdot \frac {1}{f'(k^*)} \right]$$</p>

<p>$$\implies \frac{\partial \dot y}{\partial y} \bigg|_{y=y^*} = 0 + sf'(k^*) - (n+g+\delta)$$</p>

<p>etc</p>
","10347"