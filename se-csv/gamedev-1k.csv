title,viewcount,title,body,body,acceptedanswerid
"Where can I find free sprites and images?","322432","","<p>I need sprites and images, such as characters, landscapes and others.  Where can I find them?</p>
","<p><a href=""http://www.lostgarden.com/search/label/free%20game%20graphics"" rel=""noreferrer"">Lost Garden</a> has lots of free graphics that you can use in your games.</p>

<p>For RPG Games you have a <a href=""http://www.rpg-palace.com/visual-resources/tilesets-rmxp"" rel=""noreferrer"">cool 32x32 tileset</a> and lots of <a href=""http://untamed.wild-refuge.net/rmxpresources.php?characters"" rel=""noreferrer"">free to use sprites, objects, icons, etc.</a>.</p>

<p><a href=""http://soundimage.org/"" rel=""noreferrer"">http://soundimage.org/</a>  has a lot of cool textures that are free to use...many of them are seamless so they tile. They are on the ""TXR"" pages. </p>
","106"
"How do I get started making Android games?","241297","","<p>I am new to game development. I am interested in developing 2D games for the Android platform. What is the best place to start with (i.e) What are the basics and how to proceed? I already have programming experience in Java but don't have any experience with graphics or animation.</p>
","<p>Android might not be the best choice for starting game development because you would be learning several different things at the same time (Android SDK, making games, optimization, different phone models, etc.). Consider making some simple Java games on your computer to get familiar with making games in general; <a href=""http://zetcode.com/tutorials/javagamestutorial/"">this tutorial</a> looks like a good place to start. </p>

<p>Once you're comfortable with both Java and game development, start with the <a href=""http://developer.android.com/resources/tutorials/hello-world.html"">Android tutorials</a>. The development guide is very useful, in particular you need to know <a href=""http://developer.android.com/guide/topics/fundamentals.html"">Android fundamentals</a> and activity life cycle, as well as <a href=""http://developer.android.com/guide/topics/graphics/index.html"">graphics</a>. Get the <a href=""http://developer.android.com/tools/samples/index.html"">Android samples</a> and check out the Lunar Lander and Snake game samples (there's also <a href=""http://developer.android.com/resources/samples/JetBoy/index.html"">JetBoy</a>, but that's focused on the JetPlayer).</p>

<p>The canvas class is actually good enough for most 2D games, but if you need better performance or want to move to 3D graphics later you will have to learn <a href=""http://en.wikipedia.org/wiki/OpenGL_ES"">OpenGL ES</a>. However, this is beyond the scope of getting started (unless you already know OpenGL).</p>
","3402"
"Famous games written in Python","178497","","<p>I've seen a couple of these, namely <a href=""https://gamedev.stackexchange.com/questions/3789/famous-games-written-in-java"">Java</a> and <a href=""https://gamedev.stackexchange.com/questions/1667/famous-games-written-in-net-and-xna"">C#/XNA</a>...and I've recently been picking up Python. Which kind of made me think.</p>

<p>What (famous) games have been written in Python, with Pygame/Pyglet/Pyopengl?</p>
","<p><a href=""http://www.eveonline.com/"" rel=""nofollow""><strong>Eve Online</strong></a> is probably the biggest, and uses <a href=""http://www.stackless.com/"" rel=""nofollow"">Stackless Python</a>, a lightweight, microthreaded version of Python. And Civilization IV had a Python interpreter built-in, but I'm not sure if that was for scripting only, or how much of the game was written in it.</p>

<p>Also, Disney's <a href=""http://www.panda3d.org/showss.php?shot=ssg-pirates/pirates01"" rel=""nofollow"">Pirates of the Caribbean</a> was written using the <a href=""http://www.panda3d.org/"" rel=""nofollow"">Panda3d</a> game engine (which allows both Python and C++ scripting, but from googling it - Disney used Python). The <em>engine</em> is in C++, but then again, the Python <em>interpreter</em> itself also uses a lot of C code. :)</p>

<p>For a long list of games:</p>

<ul>
<li><a href=""http://wiki.python.org/moin/PythonGames"" rel=""nofollow"">Python Games</a></li>
</ul>

<p>which also covers a lot of well-known games, like <a href=""http://www.taleworlds.com/"" rel=""nofollow"">Mount and Blade</a>.</p>
","5044"
"Must read game development books","139680","","<p>Let's make a list of the best books that every game developer should read.</p>

<p>Each answer should have a single book (by title and optionally author), a link to buy the book, and a short synopsis of what the book is about.</p>
","<p><strong><a href=""http://www.gameprogramminggems.com/"" rel=""nofollow noreferrer"">Game Programming Gems</a>, all of them.</strong><br/>
<strong>Internet Archive: <a href=""https://web.archive.org/web/20160419011213/http://www.gameprogramminggems.com:80/"" rel=""nofollow noreferrer"">Game Programming Gems</a></strong></p>

<p>Even just reading them will give you a lot of ideas and insights in different approaches that will spark your thought processes and will give you a nice interdisciplinary toolbag. Also, lots of references to other interesting works.</p>
","1271"
"What tools do you use for 2D art/sprite creation?","133716","","<p>What cheap/free tools do you use for 2D art and/or animation? </p>

<p>I don't really like Gimp's interface, Paint.NET is limited and GraphicsGale is sort of archaic. Cosmigo ProMotion looks like it could be good, anyone use it? Seems a bit pricey at $78/92 but of course cheaper than Photoshop. </p>

<p>I used to like Jasc Paint Shop Pro 7, but the newer versions Corel makes are more for photos. </p>

<p>2D Bones support would be handy also. </p>
","<p>I recently discovered Allegro Sprite Editor: <a href=""http://www.aseprite.org/"" rel=""noreferrer"">http://www.aseprite.org/</a></p>

<p>It's a fairly basic pixel graphics editor with animation support, but I do prefer it over Graphics Gale as ASE has proper alpha channel support and the UI is cleaner, a bit reminiscent of Deluxe Paint. It has layer support and basic onion skinning. </p>

<p>It is an open source product, but downloading the source requires compilation.  You can purchase the pre-compiled application.  See the FAQ: <a href=""http://www.aseprite.org/faq/#If-Aseprite-is-open-source-how-is-that-you-are-selling-it"" rel=""noreferrer"">if Aseprite is open source, how is it that you are selling it?</a></p>
","1332"
"What are good games to ""earn your wings"" with?","127575","","<p>I believe that in order to become a good game developer, you need to make games. </p>

<p>From a <em>programmer's perspective</em>, what are some good entry level games to get your hands dirty? What skills and challenges do each of these games teach you? </p>
","<p><strong>Breakout</strong></p>

<p>Easy game since you don't have much state to worry about (it's an array of brick values -- if you only have one brick color, it's an array of flags), there isn't any AI, and you get to do a little bit of physics to get the ball to bounce correctly.</p>

<p><strong>Solitaire</strong></p>

<p>The rules are a bit more complex than Breakout and the interface to it is a lot different.  It forces you to think about different methods of implementing a game.  i.e, what works in one game isn't necessarily what you would use in another.</p>

<p><strong>Pac-Man</strong></p>

<p>This one is nice because you get to work on a little bit of AI.  Having the ghosts follow the player (but not too well - you want the player to have a chance) can be quickly implemented, and you will have a fun little game that you can tweak and show off to friends and family (positive feedback is always a good thing when you are starting out).</p>

<p>I find that if you look for inspiration in early video games, you can find tons of ideas that are relatively simple to implement.  Plus, you can get away with super simple artwork and sounds because you're copying something so simple anyway.  This allows you to focus on the basics first -- getting your game loop up and running, figuring out how to get your pixels to the screen, playing a sound, keeping score, getting the player's input into the game.  </p>

<p>It almost really doesn't matter which game you choose first -- just make sure you pick something simple that you can get quick results with, that way you can move on the next day and make another one.  And another.  And another -- the more you make, the more you'll push yourself, and eventually you'll be making complex games before you know it.</p>
","862"
"What is ambient occlusion?","93823","","<p>I've heard about ambient occlusion and it looks nice, but what exactly is it?</p>
","<p>Ambient occlusion is a method to approximate how bright light should be shining on any specific part of a surface, based on the light and it's environment. This is used to add realism.</p>

<p><a href=""http://en.wikipedia.org/wiki/Ambient_occlusion#Method_of_implementation"" rel=""noreferrer"">Wikipedia</a> has a nice paragraph that explains what is done.</p>

<blockquote>
  <p>Ambient occlusion is most often calculated by casting rays in every direction from the surface. Rays which reach the background or “sky” increase the brightness of the surface, whereas a ray which hits any other object contributes no illumination. As a result, points surrounded by a large amount of geometry are rendered dark, whereas points with little geometry on the visible hemisphere appear light.</p>
</blockquote>

<p><a href=""https://developer.nvidia.com/GPUGems/gpugems_ch17.html"" rel=""noreferrer"">Here is a highly technical article about it.</a></p>
","54"
"Good game design books?","88235","","<p>I have some experience in creating, however I like to have some well written reference material to help me produce better products.  Are there any game design books that are not aimed at a particular programming language?</p>
","<p>Here's Top 3 books on game design that I'd recommend:</p>

<ul>
<li><a href=""http://rads.stackoverflow.com/amzn/click/0123694965"">The Art of Game Design: A book of lenses</a> (and I suggest to purchase actual lenses deck on <a href=""http://artofgamedesign.com/cards/"">Art of Game Design website</a></li>
<li><a href=""http://rads.stackoverflow.com/amzn/click/0240809742"">Game Design Workshop, Second Edition: A Playcentric Approach to Creating Innovative Games</a></li>
<li><a href=""http://rads.stackoverflow.com/amzn/click/158450580X"">Challenges for Game Designers</a></li>
</ul>

<p>Now, probably the most important thing is that game design as a discipline is pretty thin, but it draws a lot from other areas like art, history, economics, math (specifically theory of probabilities &amp; statistics), psychology, writing and even music &amp; filmmaking. So good books in all those disciplines probably would be equally important for a game designer as well as specific game design books. </p>
","529"
"What is the correct order to multiply scale, rotation and translation matrices for a proper world matrix?","85789","","<p>Assume DirectX as the platform, if that is important. (Pretty sure it isn't)</p>

<p>Assuming I have a proper scale, rotation and translation matrix, in what order do I multiply them to result in a proper world matrix and why?</p>

<p>By ""proper"", I mean ""I could throw them straight into DirectX and get the most commonly-used 3D frame.""</p>
","<p><em>Usually</em> it is scale, then rotation and lastly translation. With matrix denotation (i.e. T for translation matrix, R for the rotation matrix and S for the scaling matrix) that would be:</p>

<p>T * R * S</p>

<p>However, if you want to rotate an object around a certain point, then it is scale, point translation, rotation and lastly object translation.</p>

<p>Why: First you want to scale the object so that the translations work properly. Then you rotate the axes so the translation takes place on the adjusted axes. Finally you translate the object to it's position.</p>

<p>In OpenGL you can use gluLookAt to get a full camera transformation in one call. There is likely a similar call for DirectX.</p>
","16721"
"What is the difference between an alpha and a beta release?","83462","","<p>What is the difference between an alpha and a beta release? I'm surprised this question hasn't been asked here before.</p>
","<p>In traditional software engineering, Alpha releases will still be introducing new features, while Beta releases will see no new features, but rather polishing up the existing stuff.</p>

<p>However the current development environment in game dev is that both of these are simply ""not complete yet"", and alpha is generally just ""less complete"" than beta. </p>

<p>Beta releases will still see new features, while sometimes I'll see alphas that simply try and flesh out existing stuff. And even a few things that stay in alpha or beta forever.</p>
","75814"
"What is Vulkan and how does it differ from OpenGL?","79794","","<p><a href=""https://www.khronos.org/"">Khronos Group</a> (the standards body behind OpenGL) <a href=""https://www.khronos.org/vulkan"">has just announced <em>Vulkan</em></a>:</p>

<blockquote>
  <p>Vulkan is the new generation, open standard API for high-efficiency access to graphics and compute on modern GPUs. This ground-up design, previously referred to as the Next Generation OpenGL Initiative, provides applications direct control over GPU acceleration for maximized performance and predictability.</p>
</blockquote>

<p>Their page is quite <a href=""http://en.wiktionary.org/wiki/marketese"">marketese</a>/<a href=""https://en.wikipedia.org/wiki/Jargon"">jargon</a>-heavy, as is <a href=""https://www.khronos.org/news/press/khronos-reveals-vulkan-api-for-high-efficiency-graphics-and-compute-on-gpus"">the press release</a>… In simple terms, what does Vulkan mean to game developers? (Gabe Newell is quoted as being strongly in favour, without further explanation.)</p>

<p>What exactly is Vulkan's relationship to OpenGL? Its previous name ""glNext"" (short for ""Next Generation OpenGL Initiative"") makes it sound like a replacement.</p>

<hr>

<p>Update: The <a href=""https://www.khronos.org/registry/vulkan/"">Vulkan 1.0 spec</a> was released on 16-02-2016.</p>
","<p>Vulkan is a new API for hardware-accelerated graphics (and general computation) via traditional GPUs. OpenGL will continue to be developed, as it is a higher-level API than Vulkan is intended to be. Originally referred to ""glNext,"" one can infer that Vulkan was likely going to end up being ""OpenGL 5,"" but that the standards body eventually decided that a new name would better coincide with the relatively clean break the API purports to make from existing OpenGL paradigms.</p>

<p>Vulkan's <em>practical</em> advantages to game developers are primarily about control (as in, allowing more of it, potentially allowing for better optimizations at the cost of significantly more up-front work on the developer's part). Specifically:</p>

<ul>
<li>The API is oriented around asynchronous generation of command buffers across multiple threads and sequenced processing of those buffers to a command pipeline. This reflects the realities of modern hardware. Most high-profile and/or high-performance software built on OpenGL today implement this kind of behavior themselves; having the API support this itself means that developers need not implement and maintain that framework themselves, or that they can do so with less effort.</li>
<li>Thread and memory management tasks are left to the application, not the driver, allowing game developers more control over those behaviors and thus potentially more accurate tailoring of those behaviors to their individual game's needs.</li>
<li>Validation and diagnostics layers can be independently enabled, allowing in theory for better tools integration with the API (something OpenGL itself has suffered from) and disabling of excessive validation, in theory allowing ""<a href=""https://www.youtube.com/watch?v=BRWvfMLl4ho"" rel=""noreferrer"">the graphics on level three</a>"" to be that much more performant.</li>
<li>There's no hard API differential between mobile and desktop versions, which will in theory ease the porting of cross-platform games and if nothing else reduce version-checking headaches that everybody hates.</li>
</ul>

<p>Vulkan's very C-like / OpenGL-like in superficial structure (the look and feel of the API calls, et cetera. It is, however, better typed (in that not everything is a bare <code>int</code>; there are relevant typedefs and so on).</p>

<p>It is much lower-level than OpenGL. One can expect a jump in operational setup and complexity between OpenGL and Vulkan as was seen in the D3D9 to D3D10 transition, which exposed a lot more of the under-the-cover details of GPU device operation to the API client. The transition is actually more akin to D3D11 to 12, since D3D12 is itself a very similar API to Vulkan, capability-wise.</p>
","96016"
"How does a single non-artistic programmer make a game?","78281","","<p>I'd like to try my hand at making games. In making some simple ones, I realised <em>I can't do art</em>!</p>

<p>I've tried to find others to help: Most existing teams wouldn't want me because of my limited experience (I'm in high school) and I've been unable to find an available local artist with an appropriate skillset.</p>

<p>How do you guys do it? Do I have to wait until college to see if I like working in games? Is there a way to get free art so I can start messing around on my own? Or am I just having bad luck or looking in the wrong places for others interested?</p>
","<p>I work full-time doing security software, and in my ""free"" time I work on <a href=""http://byte56.com"">my game</a>. I'm not spending any money on making my game, I'm only using free software and making my own art. Don't get me wrong, I'm NOT an artist, just a programmer. It's not stopping me though. I just keep chugging away on my game, and I'll worry about making it look really pretty later. Or just make it good enough that the art doesn't matter. For now it's ordained with what I call ""Programmer Art"". Depending on the type of game you want to make, the art can be really important. But for a lot of games, it's all about the gameplay. Look at <a href=""http://www.bay12games.com/dwarves/"">Dwarf Fortress</a>. Not really a lot of ""art"" involved, but the gameplay is great!</p>

<p>If anything, you can get your game built with Microsoft Paint textures and sprites, then you'd have something to show off to get an artist interested.</p>

<p>You should definitely try your hand at making a game. I love making my game. It's the most fun I've ever had programming. Every aspect is a new interesting thing to learn. </p>

<p>Not everyone can do it all, so we just have to make do with the skills we have. Our skill is programming, so that's what we do. I think it's been proven more often than not, that it's the gameplay (programming) that makes or breaks games, not the art.</p>
","12350"
"What are some programming design patterns that are useful in game development?","72949","","<p>I have a few books on Design Patterns, and have read some articles, but cannot intuitively figure out which programming design patterns would be useful in game development.</p>

<p>For example, I have a book called ActionScript 3 with Design Patterns that details several design patterns such as Model View Controller, Singleton, Factory, Command, etc.</p>

<p>As someone new to this, I cannot figure out which of these would be useful, or in fact if any of these are the design patterns I should be learning and trying to use.  Perhaps there are other, more game-programming-specific design patterns that I am not even aware of?</p>

<p>If you have experience using a certain design pattern in game development, I'd love to hear it.  Reasoning as to why it was used, code samples, or online resources would all be very helpful as well if you have them.  I am at the moment most interested in ActionScript 3 and C++ implementations, but could definitely benefit from experience and examples from any language.</p>

<p>Thanks!</p>
","<p>Now for a less flippant response, with some suggestions. Don't take these as implementation recommendations, more as examples of possible use.</p>

<ul>
<li>Builder: set up component-based entity one component at a time, based on data</li>
<li>Factory Method: create NPCs or GUI widgets based on a string read from a file</li>
<li>Prototype: store one generic 'Elf' character with initial properties and create Elf instances by cloning it.</li>
<li>Singleton: <a href=""http://www.informit.com/articles/article.aspx?p=1404056""><em>this space deliberately left blank.</em></a></li>
<li>Adapter: incorporate an optional 3rd party library by wrapping it in a layer that looks like your existing code. Very useful with DLLs.</li>
<li>Composite: make a scene graph of renderable objects, or make a GUI out of a tree of Widgets</li>
<li>Facade: simplify complex 3rd party libraries by providing a simpler interface to make your life easier later.</li>
<li>Flyweight: store the shared aspects of an NPC (eg. models, textures, animations) separately from the individual aspects (eg. position, health) in a mostly transparent way</li>
<li>Proxy: Create small classes on a client that represent larger, more complex classes on a server, and forward requests via the network.</li>
<li>Chain of responsibility: handle input as a chain of handlers, eg. global keys (eg. for screen shots), then the GUI (eg. in case a text box is focused or a menu is up), then the game (eg. for moving a character)</li>
<li>Command: encapsulate game functionality as commands which can be typed into a console, stored and replayed, or even scripted to help test the game</li>
<li>Mediator: implement game entities as a small mediator class that operates on different components (eg. reading from the health component in order to pass the data to the AI component)</li>
<li>Observer: have the renderable representation of a character listen to events from the logical representation, in order to change the visual presentation when necessary without the game logic needing to know anything about rendering code</li>
<li>State: store NPC AI as one of several states, eg. Attacking, Wandering, Fleeing. Each can have its own update() method and whatever other data it needs (eg. storing which character it is attacking or fleeing from, the area in which it is wandering, etc.)</li>
<li>Strategy: switch between different heuristics for your A* search, depending on what sort of terrain you're in, or perhaps even to use the same A* framework to do both pathfinding and more generic planning</li>
<li>Template method: set up a generic 'combat' routine, with various hook functions to handle each step, eg. decrement ammo, calculate hit chance, resolve hit or miss, calculate damage, and each type of attack skill will implement the methods in their own specific way</li>
</ul>

<p>Some patterns left out due to lack of inspiration.</p>
","4161"
"How can I get started making textures for 3D games?","69952","","<p>Just wondering where to find good tutorials on making textures for 3D games?</p>

<p>Also, is it common practice to take photographs and convert them into game textures or do designers draw the textures themselves?</p>

<p><strong>UPDATE:</strong></p>

<p>To make the situation more specific, I am trying to make a simple game where the game character is in a small building so I would be making textures for computers, tables, chairs, doors, windows, walls, etc... What is outside the building is mostly irrelevant. I don't have any experience in 3D modeling though I'm thinking of using Blender.</p>
","<p>How you should create the textures depends a lot on the visual style of the game.</p>

<p>A lot of texture assets I see from more photorealistic games, (or fantastical games with  realistic structures) are indeed retouched photographs. It is mostly just with the diffuse colors that photographs are used. Usually, entire textures for props and smaller details are used, but for entire walls and facades it's not uncommon to combine elements from different photographs of buildings to create an entirely new one for fictional settings. Sky textures are likely going to be taken as photographs too.</p>

<p>Games that have more of a stylized look tend to use more hand-drawn textures from scratch, especially if you're going for a cartoon-like look. In this case you'll need some decent drawing skills to pull off good depth and lighting effects. In last-gen games where normal mapping was much less common, such features had to be drawn in by the artist. It is still useful, though, to use real photographs as a reference.</p>

<p>If you're not very artistically inclined, use existing photos as a base. <a href=""http://www.cgtextures.com/"" rel=""nofollow"">CG Textures</a> has a large collection of photographs of realistic materials. The best way to start out is picking a texture and in a program like Photoshop, start adding in additional layers or adjustment layers to enhance the colors or shading of the photo. </p>

<p>Gamasutra also has a great article on how to use the <a href=""http://www.gamasutra.com/view/feature/3073/the_power_of_the_high_pass_filter.php"" rel=""nofollow"">high pass filter</a> in Photoshop to improve the look of tiled textures. This filter gives you a finer control over the details of a photograph.</p>
","18566"
"Tool to create a bitmap font from a true type font","68821","","<p>What tool do you use to convert ttf fonts to bitmap fonts?</p>

<p>Following is a list of features I'm looking for.  I'd be happy with any tool really, but one that had these features would be better.</p>

<ul>
<li>outputs power-of-2 texture atlas</li>
<li>parsible config file (so I don't have to use their rendering library)</li>
<li>output kerning information</li>
<li>cross platform</li>
<li>a rendering library would be great if it lets me make the actual OpenGL calls.</li>
</ul>

<p>So what tool have you used?  Were you happy with it?</p>
","<h3><a href=""https://github.com/andryblack/fontbuilder"">Font Builder</a></h3>

<p>Font Builder does almost everything I need.  Both Font Studio and Angel Code's BMFont and perform similar tasks.  Here are some of Font Builders features.</p>

<ul>
<li>A QT app, and so works equally well on all platforms.</li>
<li>Open source so it can easily extend the app if needed</li>
<li>Designed to allow custom image and description(layout) exporters, making it even easier to extend</li>
<li>Loads fonts from the filesystem instead of windows registry.  This makes it a ton easier to generate texture fonts from my own TTFs.</li>
<li>Auto sizes the final image so I don't need to guess( like in FontStudio).  Further, these textures can be constrained to be power of 2 sizes.</li>
<li>Kerning pairs are supported, so that info can be exported if your TTF uses them.</li>
</ul>

<p>It's not all perfect however.  The default layout plugins suck.  The Box layout tool just fills the texture from top left to bottom right using the characters alphabetically.  Not very efficient.  I changed it to sort the characters by height first and quickly improved its efficiency (a 2 line change).</p>
","3811"
"Why don't C++ Game Developers use the boost library?","68062","","<p>So if you spend any time viewing / answering questions over on <a href=""http://www.stackoverflow.com"">Stack Overflow</a> under the C++ tag, you will quickly notice that just about <em>everybody</em> uses the <a href=""http://www.boost.org/"">boost</a> library; some would even say that if you aren't using it, you're not writing ""real' C++ (I disagree, but that's not the point).</p>

<p>But then there is the game industry, which is well known for using C++ and <em>not</em> using boost.  I can't help but wonder why that is.  I don't care to use boost because I write games (now) as a hobby, and part of that hobby is implementing what I need when I am able to and using off-the-shelf libraries when I can't.  But that is just me.</p>

<p>Why don't game developers, in general, use the boost library?  Is it performance or memory concerns?  Style?  Something Else?</p>

<p>I was about to ask this on stack overflow, but I figured the question is better asked here.</p>

<p>EDIT :</p>

<p>I realize I can't speak for all game programmers and I haven't seen all game projects, so I can't say game developers <em>never</em> use boost; this is simply my experience.  </p>

<p>Allow me to edit my question to also ask, if you do use boost, why did you choose to use it?</p>
","<p>Some developers do, some developers don't (in games and elsewhere). It depends on what the needs/requirements of those developers are, and what existing technology they have to leverage. </p>

<p>C++'s standard library is often given the same treatment, and people often wonder the same thing you are wondering about <em>it</em>, too. Most of the reasons are similar, for example:</p>

<ul>
<li><p>A developer may already have an in-house library of functionality that provides the same services that the standard library or Boost provides. Such in-house libraries were often written long ago, when implementation support for the standard library was weak and Boost was basically non-existent, so they more-or-less <em>had</em> to be written. In this scenario, it's usually not really worth transitioning away from the in-house functionality -- it would be a major porting effort that would destabilize a lot of code, and provide almost no benefit.</p></li>
<li><p>A developer may be working on platforms where compiler support for the advanced C++ techniques leveraged by Boost are not well supported, such that the Boost code doesn't compile at all or performs quite poorly. This applies to the standard library as well, although much less so these days.</p></li>
<li><p>Boost and the language's standard library are general purpose, and while that is fine and good for most applications, sometimes a developer has specific needs that can be better addressed by more specialized containers.</p></li>
</ul>

<p>I think the above are two reasonable reasons, although there are certainly others. You have to be careful though because many reasons for avoiding Boost, the standard libraries, or whatever boil down to ""not invented here"" syndrome, which <em>can</em> be an indication that the reason isn't very well grounded in practical realities.</p>

<p>Also remember that the needs of a large-ish studio are usually very different from the needs of an individual developer. For example, an individual developer probably has less legacy code floating around to maintain and so perhaps porting from a home-grown version of the Boost or standard library functionality will not be as big of a time sink and will save that developer from having to maintain that code as extensively in the future -- thus invalidating my first bullet point.</p>

<p>In the end, it is all about evaluating your requirements and time investiture against your desired goal and determining which option meets your needs the best. Developers who aren't using Boost or the standard library have usually done so and reached that conclusion -- perhaps you will too, and perhaps not.</p>
","8984"
"What are some good podcasts for game developers to listen to?","66698","","<p>This could include specific game dev, general dev or general game podcasts.</p>

<p>Please provide a brief description along with links.</p>
","<p><a href=""http://gamedesignadvance.com/?page_id=1616"" rel=""nofollow"">Another Castle</a> - Professionals talk game design.</p>

<p><a href=""http://www.gamedevradio.com/"" rel=""nofollow"">Game Developers Radio</a> - Great guests, a different game or development platform discussed each week.</p>

<p><a href=""http://www.brainygamer.com/the_brainy_gamer/podcast/"" rel=""nofollow"">Brainy Gamer</a> - Game design from designer, journalist, academic and player perspectives.</p>

<p><a href=""https://www.digipen.edu/news-and-events/podclass-the-digipen-podcast/"" rel=""nofollow"">DigiPen</a> - Professionals and educators talk games.</p>

<p><a href=""http://www.indiegamepod.com/"" rel=""nofollow"">IndieGamePod</a> Interviews with developers about their games.</p>

<p><a href=""http://alifewellwasted.com/"" rel=""nofollow"">A life well wasted</a> Arty, philosophical trip around gaming culture.</p>

<p><a href=""http://www.gameaudiopodcast.com/"" rel=""nofollow"">Game Audio Podcast</a>: Self-explanatory. Found it while searching for a talk on footsteps in games.</p>

<p><a href=""http://thedebuglog.com/"" rel=""nofollow"">The Debug Log</a> Professionals talks game dev; Relevant guests is invited, and relevant approaches and software is discussed.</p>

<p><a href=""http://www.doombrowski.com/podcast"" rel=""nofollow"">Doom Ninja Podcast</a>: Indie studio Doombrowski talks games and development. Also includes video game live streaming perspective from co-host.</p>
","735"
"How should I write a main game loop?","65330","","<p>How should I write a main game loop? What are some things that you should do in the game loop, and what are some things that you shouldn't do in the game loop?  </p>

<p>I've written plenty of them, but I've never really read up on game loops. I'm sure I could improve them considerably, but I am unsure how. </p>
","<p><strong>The main game loop handles three major tasks:</strong></p>

<ol>
<li>Get user input</li>
<li>Update the game state</li>
<li>Draw the game</li>
</ol>

<p><strong>A simple game loop just mushes these three tasks into one while loop. This has some undesired results:</strong></p>

<ol>
<li>Game runs at different speeds on different computers.</li>
<li>CPU (can be needlessly) pegged at 100% usage.</li>
<li>""Game states""/menus are missing or mixed with game code.</li>
<li>Main game loop is very long and hard to maintain.</li>
<li>Code is difficult to extend/port to other platforms.</li>
</ol>

<p><strong>Advanced gamed loops address the issues listed above.</strong> Here are some useful articles:</p>

<ul>
<li><a href=""http://www.koonsolo.com/news/dewitters-gameloop/"" rel=""noreferrer"">deWiTTERS Game Loop</a></li>
<li><a href=""http://wiki.allegro.cc/index.php?title=Timers#How_to_use_them.3F"" rel=""noreferrer"">Integrating a timer into a game loop</a></li>
<li><a href=""http://gamedevgeek.com/tutorials/managing-game-states-in-c/"" rel=""noreferrer"">Managing Game States in C++</a></li>
<li><a href=""http://creators.xna.com/en-US/samples/gamestatemanagement"" rel=""noreferrer"">XNA Game State Management</a> and <a href=""http://creators.xna.com/en-us/sample/network_game_state_mgt_sample"" rel=""noreferrer"">Network Game State Management</a></li>
<li><a href=""http://higherorderfun.com/blog/2010/08/17/understanding-the-game-main-loop/"" rel=""noreferrer"">Understanding the Game Main Loop</a></li>
</ul>

<p><strong>For an excellent example game loop, take a look at the Allegro skater demo game:</strong></p>

<ul>
<li>Game loop code is in <a href=""https://alleg.svn.sourceforge.net/svnroot/alleg/demos/skater/src/framewk.c"" rel=""noreferrer"">framewk.c</a>.</li>
<li>Browse full source code <a href=""https://alleg.svn.sourceforge.net/svnroot/alleg/demos/skater/"" rel=""noreferrer"">here</a>.</li>
</ul>

<p><strong>Game loops often do the same type of work for most games, so I have been thinking of a way to make a generalized game framework.</strong> It is better to write one implementation of a game loop and share it between games. It saves work when creating a new game, and improvements to the shared game loop can be shared by all games (for example, adding a FPS counter or screen capture feature).</p>
","656"
"How would I find the SDK folder for Android Studio so I can build my Unity project?","65231","","<p>So I've been trying to build my unity project for android, but my problem is that I don't know how to find the Android SDK. I have the old developer bundle installed, when it was still the one with eclipse, but this version is not supported by Unity. So, I installed the latest version of Android Studio, the new official Android IDE, but the SDK folder is not in the same place as the rest of the program. How would I find the SDK folder for Android Studio so I can build my Unity project?</p>
","<p>the sdk may be hidden in the AppDatafolder (the folder itself was hidden).</p>

<p>If you want to look for AppData, but can't find it, open explorer and type %appdata%, press enter. It will show the hidden files. Path will look like this;
C:\Users\Your.name\AppData\Local\Android\sdk1
Now that you have found the sdk, go back in to unity and click EDIT / Preferences / External Tools. You will see a field for Android SDK location - enter the path in that field.</p>
","93611"
"Why is it so expensive to develop an MMO?","64606","","<p>I want to develop an MMO, like <em>World of Warcraft</em>, but some basic research says that it is going to take a lot of time and money. I'd like to know why.</p>

<p>Why is it so expensive to develop an MMO?</p>
","<p>The first problem is that the software itself is very complicated, particularly for a new or inexperienced game developer. You have to maintain (at the very least) a client and server application while providing more content than you would expect for a ""regular"" multiplayer or single-player game.</p>

<p>Even on their own as a single player game, an RPG with the complexity of a World of Warcraft would take professional teams years to develop to the same level of polish: an enormous content investment, lots of work up front and afterward with balancing and playtesting, and some of the most complicated interactions of any game genre. These are commercial-level games, and while yours might be smaller, it will still require a lot of effort just to be a good <em>game</em> before you pour in the extra work to make it become a good multiplayer game.</p>

<p>Networked game development is not trivial; there are large obstacles to overcome in not only latency, but cheat prevention, state management and load balancing. If you're not experienced with writing a networked game, this is going to be a difficult learning exercise.</p>

<p>Building it shouldn't be your sole concern for manpower and money, either; also consider the costs of running it <em>after</em> it's developed. Even a small massively multiplayer online game will need constant improvements to its hardware/software to keep up with demand and staff to manage the game and provide support for your players.</p>

<p>Think about the following:</p>

<ul>
<li>Hosting - Where are you going to host the servers? How will you pay for the bandwidth? How will you load balance players between servers and keep a minority of players from monopolizing the resources of the game? You'll need people to keep an eye on the condition of your hardware and software hosting the game in order to make sure that it will continue to work well.</li>
<li>Technical support - Not just getting the game to run, but dealing with problems between players and handling player feedback in a way that will keep them loyal. If you're charging money (say, for a subscription), the billing system will be even more complicated (and most likely require legal assistance and possibly international representation and banking/processing fees). People who deal with these things need salaries.</li>
<li>Security - Not just of their game accounts, but you have to consider cheat prevention and doing frequent repairs and community maintenance effort whenever a new exploit is discovered by players.</li>
</ul>
","119"
"Is Java viable for serious game development?","63284","","<p>I have scoured the internet, but there are not very many resources for Java game development, not nearly as many as C++. In fact, most engines are written in C++. I tried to play a game made with jMonkeyEngine, but the game was terribly slow, to the point where my computer froze. I had no other Java applications running, and nothing too resource intensive. In contrast, my computer can play most modern 3D games with ease. If I continue to learn and improve Java now, and it turns out that later I am required to learn C++, making the switch might be difficult.</p>

<p>Is Java an acceptable language for serious game development? By serious, I mean high quality graphics, without much lag on modern computers. I also want to consider making games for consoles. </p>
","<p>Yes it is, check <a href=""http://lwjgl.org/projects.php"">this list</a> for a proof. Those are some games made with Java using The Lightweight Java Game Library (LWJGL). It is a low-level framework, which provides OpenGL for high quality graphics and OpenAL for sounds. It also provides input API. With these you can quite easily get started to serious game development in Java.</p>

<p>I am currently writing my second 3D game as a hobby project in Java, and I just love it. In the past I used to write my games with C++, but after switching to Java there is no going back. Supporting multiple operating systems with Java can be very easy, for example my previous Java game, which I developed in Windows for a year, worked in Linux right away and in OS X with only one bug without any need to compile anything on those platforms.</p>

<p>On the other hand, with Java you have couple of problems. </p>

<ol>
<li>Garbage collector. As others have stated, non-deterministic memory management is a problem, and you need to code that in mind.</li>
<li>Lack of 3rd party libraries. Most of the available libraries do not support Java. On the other hand you always have the option to call these native libraries from Java also, but it's more work to do so. There are also Java ports or ready-made wrappers available for popular libraries, for example I'm using <a href=""http://jbullet.advel.cz/"">JBullet - Java port of Bullet Physics Library</a>. On the other hand Java has a huge class library built-in, which reduces the need for third party libraries that are not game related. The lack of libraries has not been a problem for me, but I can imagine that it can be for others.</li>
<li>Java is not supported by popular game consoles and there is no easy switch to those from Java as far as I know. On the other hand Android, which is a popular mobile platform, uses some form of Java. This is an option also, but don't except the same Java code to work both on a PC and Android device.</li>
<li>Smaller community. Most game programmers use C++ and in my experience often dislike Java. Don't expect to get as much help from others. Don't expect to get a job in game development without C++ skills.</li>
</ol>
","25512"
"Unity new UI - Dynamically change the functions called by GUI elements","62454","","<p>Looking to dynamically change the value in the button OnClick and slider On Value Changed
<img src=""https://i.imgur.com/Wz8cyiY.png"" alt=""example 1"">
<img src=""https://i.imgur.com/KdQz3pV.png"" alt=""example 2"">. </p>

<p>If I had to guess on how this was done, get a reference to the button/gui element. Next get the Button script component and access that list of function calls. However I'm not sure how to modify that list. Anyone have any ideas?</p>

<p>More Details that might help:</p>

<ul>
<li>The function being called is apart of a custom script component</li>
<li>Using the 'dynamic' variable option for the sliders</li>
<li>Could be used to create dynamic buttons</li>
</ul>
","<p>There's a super simple way to change events:</p>

<p><strong>EDIT</strong></p>

<p>See my other answer for the quick and easy way to add an event for the <code>OnClick</code> event only. For other events, like <code>OnDrag</code> see below.</p>

<hr>

<p>Additionally, if you need more than just the events provided by default, I'd suggest instead attaching a <code>EventTrigger</code> to your game object. This gives us access to the <code>BaseEventData</code> object returned from the event, telling us stuff like the object that created the event. Then you can do something like:</p>

<pre><code>//Create an event delegate that will be used for creating methods that respond to events
public delegate void EventDelegate(UnityEngine.EventSystems.BaseEventData baseEvent);
</code></pre>

<p>Then we can create a method for handling events, the signature must match that of our delegate. So, it needs to return <code>void</code> and accept <code>BaseEventData</code> as its first and only parameter:</p>

<pre><code>public void DropEventMethod(UnityEngine.EventSystems.BaseEventData baseEvent) {
    Debug.Log(baseEvent.selectedObject.name + "" triggered an event!"");
    //baseEvent.selectedObject is the GameObject that triggered the event,
    // so we can access its components, destroy it, or do whatever.
}
</code></pre>

<p>Finally, to dynamically add the event:</p>

<pre><code>//Get the event trigger attached to the UI object
EventTrigger eventTrigger = buttonObject.GetComponent&lt;EventTrigger&gt;();

//Create a new entry. This entry will describe the kind of event we're looking for
// and how to respond to it
EventTrigger.Entry entry = new EventTrigger.Entry();

//This event will respond to a drop event
entry.eventID = EventTriggerType.Drop;

//Create a new trigger to hold our callback methods
entry.callback = new EventTrigger.TriggerEvent();

//Create a new UnityAction, it contains our DropEventMethod delegate to respond to events
UnityEngine.Events.UnityAction&lt;BaseEventData&gt; callback =
    new UnityEngine.Events.UnityAction&lt;BaseEventData&gt;(DropEventMethod);

//Add our callback to the listeners
entry.callback.AddListener(callback);

//Add the EventTrigger entry to the event trigger component
eventTrigger.delegates.Add(entry);
</code></pre>

<p>If you're using version 5.3.3 or above, use this line instead instead of the last line above, <a href=""http://docs.unity3d.com/ScriptReference/EventSystems.EventTrigger-delegates.html"" rel=""nofollow"">delegates is depreciated</a>:</p>

<pre><code>eventTrigger.triggers.Add(entry); 
</code></pre>
","83029"
"What are the pro/cons of Unity3D as a choice to make games?","61936","","<p>We are doing our school project with Unity3d, since they were using Shiva the previous year (which seems horrible to me), and I wanted to know your point of view for this tool.</p>

<p>Pros:</p>

<ul>
<li>multi platform, I even heard Google is going to implement it in Chrome</li>
<li>everything you need is here</li>
<li>scripting languages makes it a good choice for people who are not programming gurus </li>
</ul>

<p>Cons:</p>

<ul>
<li>multiplayer ?</li>
<li>proprietary, you are totally dependent of unity and its limit and can't extend it</li>
<li>it's less ""making a game from scratch""</li>
<li>C++ would have been a cool thing</li>
</ul>

<p>I really think this kind of tool is interesting, but is it worth it to use at school for a project that involves more than 3 programming persons ? What do we really learn in term of programming from using this kind of tool (I'm ok with python and js, but I hate C#) ? We could have use Ogre instead, even if we were learning direct x starting january...</p>
","<p>The main ""pro"" of Uinty3D is that it's crazy fast. I'm not talking about performance here, but about development speed. You have:</p>

<ul>
<li>Unified asset pipeline. No need to spend time on resource subsystem at all, no buggy import routines to write and fix: just drop a file into folder, and it works.</li>
<li>Integrated level editor. No need to spend time on level tools: just get straight to business.</li>
<li>Great tweaking and debugging support: all your gameplay variables are shown right as you play, and can be changed on the fly too - and all this without writing a single line of code. Pause the game anytime, or step through code one statement at a time. </li>
<li>Quite comprehesive library of ready-made components. Rendering, sound, physics, controls - a lot of ""boilerplate"" code is already written.</li>
<li>Mono as a script host. While one can argue about merits of C# as a language, Mono's base class library offers a wealth of functions. Collections, I/O, multithreading, and insanely expressive LINQ all speed up development considerably.</li>
</ul>

<p>Also, Unity3d is really good on multiple platforms. Of course, you can't create, say, a windows .exe game and then magically have it ""just work"" on the iPhone; but Unity gets pretty close to that. What is required is ""tweaking"" more than ""porting"". </p>

<p>Of course, in some cases Unity3D is not ideal. Network multiplayer integrated in Unity is OK for some LAN peer-to-peer play, but anything that requires central server pretty much requires you write all network code from scratch. Unity's GUI system is quite quirky and slow, so making complex in-game GUIs is a pain. However, all <em>other</em> game GUI systems I've seen are painful too, so Unity's one is not that bad overall. </p>

<p>And, of course, Unity3D is a little less flexible than ""game engines"" like OGRE, that offer only a library/source code. Its performance is not exactly top-notch, and since you only have a scripting sandbox, you can't use some clever low-level hacks to improve it. For example, if Unity's built-in tree renderer doesn't satisfy you for some reason, you can't write your own one (well, you could, but it would be working through scripts and most probably be too slow and too much hassle). Still, it's possible to do just about anything with Unity so long as you don't mind losing a bit of performance.</p>

<p>The biggest ""con"" of Unity3D, though, is source control. As already mentioned, Unity's own Asset Server costs a pretty penny. And it sucks, really, really hard. It doesn't even have branching. While Unity3D theoretically supports 3rd-party SCM systems, using them is wrought with peril too. I've seen import settings ""magically"" change after SVN commit, or all objects' parameters disappear after using Perforce. All these can be worked around, but anyway, Unity3D + Source control = pain.</p>

<p>So, to actually answer your question. I believe Unity3D is one of the best, if not <em>the</em> best, choice of game engine for a ""little"" game. Especially in prototype stage. </p>

<p>That said, if we're talking about an educational project, I' recommend against it. To learn how games work it's better to write one on as low level as possible. Game engines are a great tool; but to use it for maximum gains, it's necessary to understand how they work, and <em>why</em> they work that way. And the best way to learn this is write your own game engine - even if it turns out crappy in the end.</p>
","8133"
"What are some famous games developed with .NET and/or XNA?","59141","","<p>Are there famous games written in .Net and/or XNA?</p>
","<p><a href=""http://en.wikipedia.org/wiki/Schizoid_%28video_game%29"">Schizoid</a> is a pretty successful XBLA game. Does that count? (not really, but its the best I could find)</p>

<p>I think what you mean is are there any AAA-scale games made using XNA and/or XNA GS. To that, the answer is no. The games industry has been very slow move past C/C++ as the gold standard. This isn't for no reason, most AAA games would rather trade all the nice syntax and runtime support for an extra 5FPS and 50MB less RAM usage since both of those directly translate to units sold. Granted there is argument for lower development costs and faster cycles, but thats a hard calculus to use in this industry.</p>
","1670"
"Recommended 2D Game Engine for prototyping","59097","","<p><strong>What high-level game engine would you recommend to develop a 2D game prototype on windows? (or mac/linux if you wish)</strong></p>

<p>The kind of things I mean by ""high-level"" includes (but is definitely not limited to):</p>

<ul>
<li>not having to manage low-level stuff like screen buffers, graphics contexts</li>
<li>having an API to draw geometric shapes</li>
<li>well, I was going to omit it but I guess being based on an actual ""high-level"" language is a plus (automatic resource management and the existence a reasonable set of data structures in the standard library come to mind).</li>
</ul>

<p>It seems to me that Flash is the proverbial elephant in the room for this query but I'd very much like to see different answers based on all kinds of languages or SDKs.</p>
","<p>I've used <a href=""http://www.pygame.org/"">pygame</a> extensively, and it has lots of positives:</p>

<ul>
<li>it's a library for Python, which is a high-level language</li>
<li>it's got good clear <a href=""http://www.pygame.org/docs/"">documentation</a></li>
<li>it's got an active community</li>
</ul>

<p>Pygame is a wrapper around SDL, a cross-platform 2D graphics library. Pygame also has wrappers for sound, music etc. Note that despite Python being a high-level programming language, pygame is (for the most part) a fairly low-level graphics library.</p>
","545"
"How should a one-man team do game audio?","58978","","<p>Most game development (game design, art, programming, etc.) can be done by one person with relatively little equipment:
A game designer needs a pencil and paper, an artist Photoshop or Paint, a programmer a laptop and compiler.</p>

<p>Sound is different: External noises are a big problem, sound effects can't be made with instruments, and small mistakes easily produce disaster.</p>

<p>I can see how large companies with big studios and budgets do this.
<br><strong>How can I do this as a one-man indie?</strong></p>

<p>Should I synthesize everything? Record sounds and buy some crazy program for editing them?</p>
","<p>First, read these questions:</p>

<ul>
<li><a href=""https://gamedev.stackexchange.com/questions/8/where-can-i-find-free-sounds-for-my-game"">Where can I find free sounds for my game?</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/1377/how-are-sound-effects-made"">How are sound effects made?</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/14444/game-sound-effects-availability"">Game Sound Effects Availability</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/7392/what-are-good-sites-that-provide-free-media-resources-for-hobby-game-development"">What are good sites that provide free media resources for hobby game development?</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/14/where-can-i-find-free-music-for-my-game"">Where can I find free music for my game?</a></li>
</ul>

<p>Second, there are <em>so many</em> musicians and sound designers of all skill levels (and expecting various degrees of compensation from free to standard rates) wanting to join on with a project. If you're having trouble finding somebody, you just need to find more internets. ModDB, GameDev.net, forums for specific engines/tools that have tried to form a general game development community. Seriously consider giving working with somebody a shot. You'll both learn a lot.</p>

<p>If you're wanting to be a one-man developer, then you can take a sound editor, microphone, and samples and synths, and now you're a sound guy. It's another art/craft to learn, no different in that regard to drawing/modeling/other-graphic-art, game design, and programming. Use the tools Valryon mentioned (SFXR and Audacity) to get started. Also look into:</p>

<ul>
<li><a href=""http://www.wavosaur.com/"" rel=""nofollow noreferrer"">Wavosaur</a> - A freeware sound editor</li>
<li><a href=""http://reaper.fm/"" rel=""nofollow noreferrer"">Reaper</a> - A very inexpensive DAW (digital audio workstation, used for producing music from audio recordings and midi) and <a href=""http://ardour.org/"" rel=""nofollow noreferrer"">Ardour</a>, a FOSS alternative for Linux and OS X</li>
<li><a href=""http://kvraudio.com/"" rel=""nofollow noreferrer"">KVRAudio.com</a> for free basic VSTs (often playable directly in Reaper and other DAWs</li>
<li><a href=""http://www.modplug.com/"" rel=""nofollow noreferrer"">Modplug</a>, <a href=""http://www.renoise.com/"" rel=""nofollow noreferrer"">Renoise</a>, <a href=""http://www.warmplace.ru/soft/sunvox/"" rel=""nofollow noreferrer"">SunVox</a>, and <a href=""http://www.buzzmachines.com/"" rel=""nofollow noreferrer"">Buzz</a> are music trackers for old-school-style game music composition</li>
<li>Links for the lazy: <a href=""http://audacity.sourceforge.net/"" rel=""nofollow noreferrer"">Audacity</a> and <a href=""http://www.drpetter.se/project_sfxr.html"" rel=""nofollow noreferrer"">SFXR</a></li>
</ul>

<p>For learning about sound, you should be aware of some of its <a href=""http://physics.info/sound/"" rel=""nofollow noreferrer"">physical properties</a> and how we are able to <a href=""http://en.wikipedia.org/wiki/Digital_audio"" rel=""nofollow noreferrer"">digitally represent</a> it.</p>

<p>To start making music, you should learn about <a href=""http://www.teoria.com/index.php"" rel=""nofollow noreferrer"">music theory</a> and how to <a href=""http://tweakheadz.com/guide.htm"" rel=""nofollow noreferrer"">produce music</a>.</p>
","22528"
"GLSL: How do I cast a float to an int?","57772","","<p>In a GLSL fragment shader I am trying to cast a <code>float</code> into an <code>int</code>. The compiler raises an error:</p>

<pre><code>ERROR: 0:60: '=' :  cannot convert from 'mediump float' to 'highp int'
</code></pre>

<p>I tried raising the precision of the <code>int</code>:</p>

<pre><code>mediump float indexf = floor(2.0 * mixer);
highp int index = indexf;
</code></pre>

<p>but to no avail.</p>

<p>How do I cast the <code>int</code> properly?</p>
","<p>Try this:</p>

<pre><code>highp int index = int(indexf);
</code></pre>

<p>I found it <a href=""http://www.gpgpu.org/forums/viewtopic.php?t=4857"">here</a>.</p>
","8719"
"Where to promote your indie game?","57026","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://gamedev.stackexchange.com/questions/1639/where-to-advertise-my-game"">Where to advertise my game?</a>  </p>
</blockquote>



<p>Let's say I have developed a game and I want to ""get it out there"".  What I have in mind is open-source, non-commercial games.</p>

<p>What websites do you know of where you can promote your newly developed game, rather than simply posting it on your blog?</p>
","<p><a href=""http://www.indiedb.com/"" rel=""nofollow"">http://www.indiedb.com/</a> has just been created, and might be an excellent choice, in addition to David McGraw's recommendation.</p>

<p><a href=""http://www.igdb.com/indie"" rel=""nofollow"">http://www.igdb.com/indie</a> Internet Game Database is a good place to add your indie game.</p>
","2290"
"Does Unity let you code in Java?","56949","","<p>I am fairly new to Unity3D experience , but I have a very good knowledge of Java and Android development. I am really confused that if Java is at all needed for developing android applications? I read somewhere in Unity documentation that adding behaviour to objects in Unity requires use of scripts, and that unity only supports C# , .Net , and Boo scripts. Is there no use of Java at all?</p>
","<p>Java is not supported by Unity. You should check out C#, however; it's a very similar language that takes a lot of influence from Java while arguably smoothing out some of the rougher edges of the language. <strike>It should also be noted that you will need both Unity Pro and Unity Android Pro in order to create Android games using Unity.</strike> As jhocking and ashes999 note in the comments, you don't need Unity Pro and Unity Android Pro top release commercial Unity games on Android.</p>
","74661"
"Algorithm for dynamically calculating a level based on experience points?","56368","","<p>One of the struggles I've always had in game development is deciding how to implement experience points attributed to gaining a level.  There doesn't seem to be a pattern to gaining a level in many of the games I've played, so I assume they have a static dictionary table which contains experience points vs. the level.  e.g.</p>

<pre><code>Experience   Level
0            1
100          2
175          3
280          4
800          5
</code></pre>

<p>...There isn't a rhyme or reason why 280 points is equal to level 4, it just is.</p>

<p>I'm not sure how those levels are decided, but it certainly wouldn't be dynamic.  I've also thought about the possibility of exponential levels, as not to have to keep a separate lookup table, e.g.</p>

<pre><code>Experience   Level
0            1
100          2
200          3
400          4
800          5
1600         6
3200         7
6400         8
</code></pre>

<p>...but that seems like it would grow out of control rather quickly, as towards the upper levels, the enemies in the game would have to provide a whopping amount of experience to level -- and that would be to difficult to control.  Leveling would become an impossible task.</p>

<p>Does anyone have any pointers, or methods they use to decide how to <em>level</em> a character based on experience?  I want to be fair in leveling and I want to stay ahead of the players as not to worry about constantly adding new experience/level lookups.</p>
","<p>It's quite common to use a square relation.</p>

<p><code>level = constant * sqrt(XP)</code></p>

<p>Or the approximate equivalent of a linearly rising level gap.</p>

<pre><code>Level   XP      Difference
1       0       -
2       100     100
3       300     200
4       600     300
5       1000    400
</code></pre>

<p>These systems work pretty well when the XP gain is approximately linear. If a high level character can earn XP faster than a low level character then this is not the right system.</p>
","13639"
"How do you generate tileable Perlin noise?","55406","","<p>Related:</p>

<ul>
<li><a href=""https://gamedev.stackexchange.com/questions/20880/simple-noise-generation"">Simple noise generation</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/18330/understanding-perlin-noise"">Understanding Perlin Noise</a></li>
</ul>

<p>I'd like to generate tileable Perlin noise.  I'm working from <a href=""http://paulbourke.net/texture_colour/perlin/"" rel=""noreferrer"">Paul Bourke's</a> <code>PerlinNoise*()</code> functions, which are like this:</p>

<pre><code>// alpha is the ""division factor"" (how much to damp subsequent octaves with (usually 2))
// beta is the factor that multiplies your ""jump"" into the noise (usually 2)
// n is the number of ""octaves"" to add in
double PerlinNoise2D(double x,double y,double alpha,double beta,int n)
{
   int i;
   double val,sum = 0;
   double p[2],scale = 1;

   p[0] = x;
   p[1] = y;
   for (i=0;i&lt;n;i++) {
      val = noise2(p);
      sum += val / scale;
      scale *= alpha;
      p[0] *= beta;
      p[1] *= beta;
   }
   return(sum);
}
</code></pre>

<p>Using code like:</p>

<pre><code>real val = PerlinNoise2D( x,y, 2, 2, 12 ) ; // test

return val*val*skyColor + 2*val*(1-val)*gray + (1-val)*(1-val)*cloudColor ;
</code></pre>

<p>Gives sky like</p>

<p><img src=""https://i.stack.imgur.com/DDWmK.png"" alt=""nontileable""></p>

<p>Which isn't tileable.</p>

<p>The pixel values are 0->256 (width and height), and pixel (0,0) uses (x,y)=(0,0) and pixel (256,256) uses (x,y)=(1,1)</p>

<p>How can I make it tileable?</p>
","<p>There's two parts to making seamlessly tileable fBm noise like this.  First, you need to make the Perlin noise function itself tileable.  Here's some Python code for a simple Perlin noise function that works with any period up to 256 (you can trivially extend it as much as you like by modifying the first section):</p>

<pre><code>import random
import math
from PIL import Image

perm = range(256)
random.shuffle(perm)
perm += perm
dirs = [(math.cos(a * 2.0 * math.pi / 256),
         math.sin(a * 2.0 * math.pi / 256))
         for a in range(256)]

def noise(x, y, per):
    def surflet(gridX, gridY):
        distX, distY = abs(x-gridX), abs(y-gridY)
        polyX = 1 - 6*distX**5 + 15*distX**4 - 10*distX**3
        polyY = 1 - 6*distY**5 + 15*distY**4 - 10*distY**3
        hashed = perm[perm[int(gridX)%per] + int(gridY)%per]
        grad = (x-gridX)*dirs[hashed][0] + (y-gridY)*dirs[hashed][1]
        return polyX * polyY * grad
    intX, intY = int(x), int(y)
    return (surflet(intX+0, intY+0) + surflet(intX+1, intY+0) +
            surflet(intX+0, intY+1) + surflet(intX+1, intY+1))
</code></pre>

<p>Perlin noise is generated from a summation of little ""surflets"" which are the product of a randomly oriented gradient and a separable polynomial falloff function.  This gives a positive region (yellow) and negative region (blue)</p>

<p><img src=""https://i.stack.imgur.com/ApUk6.png"" alt=""Kernel""></p>

<p>The surflets have a 2x2 extent and are centered on the integer lattice points, so the value of Perlin noise at each point in space is produced by summing the surflets at the corners of the cell that it occupies.</p>

<p><img src=""https://i.stack.imgur.com/uSIeC.png"" alt=""Summation""></p>

<p>If you make the gradient directions wrap with some period, the noise itself will then wrap seamlessly with the same period.  This is why the code above takes the lattice coordinate modulo the period before hashing it through the permutation table.</p>

<p>The other step, is that when summing the octaves you will want to scale the period with the frequency of the octave.  Essentially, you will want each octave to tile the entire just image once, rather than multiple times:</p>

<pre><code>def fBm(x, y, per, octs):
    val = 0
    for o in range(octs):
        val += 0.5**o * noise(x*2**o, y*2**o, per*2**o)
    return val
</code></pre>

<p>Put that together and you get something like this:</p>

<pre><code>size, freq, octs, data = 128, 1/32.0, 5, []
for y in range(size):
    for x in range(size):
        data.append(fBm(x*freq, y*freq, int(size*freq), octs))
im = Image.new(""L"", (size, size))
im.putdata(data, 128, 128)
im.save(""noise.png"")
</code></pre>

<p><img src=""https://i.stack.imgur.com/H4jG7.png"" alt=""Tileable fBm Noise""></p>

<p>As you can see, this does indeed tile seamlessly:</p>

<p><img src=""https://i.stack.imgur.com/KmaEv.png"" alt=""fBm Noise, Tiled""></p>

<p>With some small tweaking and color mapping, here's a cloud image tiled 2x2:</p>

<p><img src=""https://i.stack.imgur.com/chO7I.png"" alt=""Clouds!""></p>

<p>Hope this helps!</p>
","23705"
"How can I implement gravity?","55161","","<p>How can I implement gravity? Not for a particular language, just pseudocode...</p>
","<p>As others have noted in the comments, the basic <a href=""http://en.wikipedia.org/wiki/Euler_method"" rel=""nofollow noreferrer"">Euler integration</a> method described in <a href=""https://gamedev.stackexchange.com/a/16466"">tenpn's answer</a> suffers from a few problems:</p>

<ul>
<li><p>Even for simple motion, like ballistic jumping under constant gravity, it introduces a systematic error.</p></li>
<li><p>The error depends on the timestep, meaning that changing the timestep changes object trajectories in a systematic way that may be noticed by players if the game uses a variable timestep.  Even for games with a fixed physics timestep, changing the timestep during development can noticeably affect the game physics such as the distance that an object launched with a given force will fly, potentially breaking previously designed levels.</p></li>
<li><p>It doesn't conserve energy, even if the underlying physics should.  In particular, objects that <em>should</em> oscillate steadily (e.g. pendulums, springs, orbiting planets, etc.) may steadily accumulate energy until the whole system blows apart.</p></li>
</ul>

<p>Fortunately, it's not hard to replace Euler integration with something that is <em>almost</em> as simple, yet has none of these problems &mdash; specifically, a second-order symplectic integrator such as <a href=""http://en.wikipedia.org/wiki/Leapfrog_method"" rel=""nofollow noreferrer"">leapfrog integration</a> or the closely related <a href=""http://en.wikipedia.org/wiki/Velocity_Verlet"" rel=""nofollow noreferrer"">velocity Verlet method</a>.  In particular, where basic Euler integration updates the velocity and position as:</p>

<pre>
acceleration = force(time, position) / mass;
time += timestep;
position += timestep * velocity;
velocity += timestep * acceleration;
</pre>

<p>the velocity Verlet method does it like this:</p>

<pre>
acceleration = force(time, position) / mass;
time += timestep;
position += timestep * <b>(</b>velocity <b>+ timestep * acceleration / 2)</b>;
<b>newAcceleration = force(time, position) / mass;</b>
velocity += timestep * <b>(</b>acceleration <b>+ newAcceleration) / 2</b>;
</pre>

<p>If you have multiple interacting objects, you should update <em>all</em> their positions before recalculating the forces and updating the velocities.  The new acceleration(s) can then be saved and used to update the position(s) on the next timestep, reducing the number of calls to <code>force()</code> down to one (per object) per timestep, just like with the Euler method. </p>

<p>Also, if the acceleration is normally constant (like gravity during ballistic jumping), we can simplify the above to just:</p>

<pre>
time += timestep;
position += timestep * <b>(</b>velocity <b>+ timestep * acceleration / 2)</b>;
velocity += timestep * acceleration;
</pre>

<p>where the extra term in bold is the only change compared to basic Euler integration.</p>

<p>Compared to Euler integration, the velocity Verlet and leapfrog methods have several nice properties:</p>

<ul>
<li><p>For constant acceleration, they give exact results (up to floating point roundoff errors, anyway), meaning that ballistic jump trajectories stay the same even if the timestep is changed.</p></li>
<li><p>They are second order integrators, meaning that, even with varying acceleration, the average integration error is only proportional to the square of the timestep.  This can allow for larger timesteps without compromising accuracy.</p></li>
<li><p>They are <a href=""http://en.wikipedia.org/wiki/Symplectic_integrator"" rel=""nofollow noreferrer"">symplectic</a>, meaning that they conserve energy if the underlying physics do (at least as long as the timestep is constant).  In particular, this means that you won't get things like planets spontaneously flying out of their orbits, or objects attached to each other with springs gradually wobbling more and more until the whole thing blows up.</p></li>
</ul>

<p>Yet the velocity Verlet / leapfrog method are nearly as simple and fast as basic Euler integration, and certainly much simpler than alternatives like <a href=""http://en.wikipedia.org/wiki/RK4"" rel=""nofollow noreferrer"">fourth-order Runge-Kutta integration</a> (which, while generally a very nice integrator, lacks the symplectic property and requires <em>four</em> evaluations of the <code>force()</code> function per time step).  Thus, I would strongly recommend them for anyone writing any sort of game physics code, even if it's as simple as jumping from one platform to another.</p>

<hr>

<p><strong>Edit:</strong> While the formal derivation of the velocity Verlet method is only valid when the forces are independent of the velocity, in practice you can use it just fine even with velocity-dependent forces such as <a href=""http://en.wikipedia.org/wiki/Drag_%28physics%29"" rel=""nofollow noreferrer"">fluid drag</a>.  For best results, you should use the initial acceleration value to estimate the new velocity for the second call to <code>force()</code>, like this:</p>

<pre>
acceleration = force(time, position, velocity) / mass;
time += timestep;
position += timestep * <b>(</b>velocity <b>+ timestep * acceleration / 2)</b>;
velocity += timestep * acceleration;
<b>newAcceleration = force(time, position, velocity) / mass;</b>
<b>velocity += timestep * (newAcceleration - acceleration) / 2</b>;
</pre>

<p>I'm not sure if this particular variant of the velocity Verlet method has a specific name, but I've tested it and it seems to work very well.  It's not quite as accurate as fouth-order Runge-Kutta (as one would expect from a second-order method), but it's much better than Euler or naïve velocity Verlet without the intermediate velocity estimate, and it still retains the symplectic property of normal velocity Verlet for conservative, non-velocity-dependent forces.</p>

<p><strong>Edit 2:</strong> A very similar algorithm is described e.g. by <a href=""http://pages.csam.montclair.edu/~yecko/ferro/papers/FerroDPD/GrootWarren_ReviewDPD_97.pdf"" rel=""nofollow noreferrer"">Groot &amp; Warren (<em>J. Chem. Phys.</em> 1997)</a>, although, reading between the lines, it seems that they sacrificed some accuracy for extra speed by saving the <code>newAcceleration</code> value computed using the estimated velocity and reusing it as the <code>acceleration</code> for the next timestep.  They also introduce a parameter 0 &le; <em>&lambda;</em> &le; 1 which is multiplied with <code>acceleration</code> in the initial velocity estimate; for some reason, they recommend <em>&lambda;</em> = 0.5, even though all <em>my</em> tests suggest that <em>&lambda;</em> = 1 (which is effectively what I use above) works as well or better, with or without the acceleration reuse.  Maybe it's got something to do with the fact that their forces include a stochastic Brownian motion component.</p>
","41917"
"Why don't more games use vector art?","54166","","<p>It would seem to me that vector art is more efficient in terms of resources/scalability; however, in most cases I have seen artists using bitmap/rasterized art. Is this a limitation put on the artists by the game programmers/designers? As a programmer I think vector art would be more ideal, since it allows for scaling up resolution without having to recreate the art, creating really large graphics or causing graphics to become blurry.</p>

<p>The questions: why aren't more people using SVG/AI to create 2D game art? Would it actually be preferred (and who prefers it)? Are bitmap graphics a standard or a limitation (or maybe neither)?</p>

<p>Background: I am working on an engine, and I had some kinda cool ideas for vector based graphics; however, I don't want to piss off artists in the future. </p>

<p>I guess this is more a question centered around pragmatism and developing games. </p>
","<p>Unlike other art forms, vector art requires extremely high precision, making it unsuitable for many art styles. Basic shapes and such are easy using Vector art but it's just a pain to add small details which would be really easy to paint. So its kinda restricted to very simple ""symbolic"" styles. For everything else painting just works better.</p>

<p>What vector art is suitable for, is icons and design and there you won't find many artists who would use something different.</p>

<p>By the way: Scalability isn't really a problem for raster graphics either, painting in 10x resolution isn't that much of a difference than painting in the resolution it is going to be displayed. Something which is done quite a lot nowadays (often advertised as ""HD-Graphics"").</p>
","30114"
"Convert Flash game to work on Android devices","51665","","<p>Is there any way to convert a <code>Flash games</code>(file with .swf extention) to work with android devices? I want the game to use Android device native controls like <code>sensor</code>, <code>accelerometer</code>, etc.</p>
","<p>petr's answer assumes you already know how to deploy a Flash app on Android; maybe you already know that, but you don't mention it in your question so I want to point out that you can <a href=""http://help.adobe.com/en_US/air/build/WSfffb011ac560372f-5d0f4f25128cc9cd0cb-8000.html"">package a Flash .swf as an Android .apk using AIR.</a></p>

<p>Once you are actually deploying your in-development game as an Android app then you get to the higher level concerns of adapting your game logic to the new input devices.</p>
","29611"
"How to make a character jump?","51556","","<p>I am currently making a game in C# using Direct X 9.0. The game remake is Donkey Kong NES. I have nearly everything completed, but I am having problems with the physics of Mario's jump. I have variables declared for the Y and X co-ordinations.</p>

<p>I was wondering if there was a simple method of doing this. I have searched high and low for an answer but the answers I have found are either irrelevant/ or using a different programming language such as XNA.</p>

<p>I currently have a bool variable set to check to see if W has been pressed then that will trigger any code to make him jump. I have been messing around such as.</p>

<pre><code>  if (jump == true)
    {

        Playerypos -=  vel;
        Playerxpos +=  vel;
    }
</code></pre>

<p>Which didn't work that well. I have searched high and low for an answer and now I am desperate, if someone could point me in the right direction to a simple solution. That would be great. Much appreciated for any responses.</p>
","<p>First of all, XNA also uses C# too so it's the same programming language. And although the underlying API might have some differences from DirectX, that has nothing to do with jumping, so the same tutorials or answers should apply here. Also, there are numerous ways to implement this, depending on a lot of factors. What I'll describe below is just one of the possibilities.</p>

<p><strong>Basic Physics Requirements</strong></p>

<p>First you need some basic physics variables and calculations on your update loop. In particular, you need position, velocity, and gravity defined, and your update loop should be doing something roughly similar to this (collision detection and response omitted for simplicity):</p>

<pre><code>float positionX, positionY;     // Position of the character
float velocityX, velocityY;     // Velocity of the character
float gravity = 0.5f;           // How strong is gravity

void Update(float time)
{
    positionX += velocityX * time;      // Apply horizontal velocity to X position
    positionY += velocityY * time;      // Apply vertical velocity to X position
    velocityY += gravity * time;        // Apply gravity to vertical velocity
}
</code></pre>

<p><strong>Fixed Height Jump</strong></p>

<p>Now the easiest way to implement a jump that always has the same height, no matter how long you press the key, is simply to change the vertical velocity once. This will make the character start rising, while gravity will automatically take care of bringing him down:</p>

<pre><code>void OnJumpKeyPressed()
{
    velocityY = -12.0f;   // Give a vertical boost to the players velocity to start jump
}
</code></pre>

<p><em>Important</em> You don't want to be able to start a jump if your character is not on the ground, so you'll need to add a check for that.</p>

<p><strong>Variable Height Jump</strong></p>

<p>But games like Mario and Sonic have a variable jump where the height of the jump depends on how long you press the button down. In this case you'll need to handle both pressing <em>and</em> releasing the jump key. You could add something like:</p>

<pre><code>void OnJumpKeyReleased()
{
    if(velocityY &lt; -6.0f)       // If character is still ascending in the jump
        velocityY = -6.0f;      // Limit the speed of ascent
}
</code></pre>

<p>Tweaking all of these values (i.e. the numbers like <code>0.5</code>, <code>-12.0f</code> or <code>-6.0f</code>) in the code above you can change the feel of your jump, how high he jumps, how much momentum does he keep even after releasing the jump button, how fast he falls, etc.</p>

<p><em>Important</em> Don't call these functions every frame. Call them only once when the key is pressed or released. Otherwise your character will fly instead of jump.</p>

<p><strong>Working Example</strong></p>

<p>I have just created a quick example of the techniques described above, which you can try on your browser here (press mouse button to jump, release it midway to control the height of the jump). It's in JS but like I mentioned earlier, the language is irrelevant in this case.</p>

<p><a href=""http://jsfiddle.net/LyM87/"">http://jsfiddle.net/LyM87/</a></p>
","29618"
"most efficient AABB vs Ray collision algorithms","51265","","<p>Is there a known 'most efficient' algorithm for AABB vs Ray collision detection?</p>

<p>I recently stumbled accross Arvo's AABB vs Sphere collision algorithm, and I am wondering if there is a similarly noteworthy algorithm for this.</p>

<p>One must have condition for this algorithm is that I need to have the option of querying the result for the distance from the ray's origin to the point of collision. having said this, if there is another, faster algorithm which does not return distance, then in addition to posting one that does, also posting that algorithm would be very helpful indeed.</p>

<p>Please also state what the function's return argument is, and how you use it to return distance or a 'no-collision' case. For example, does it have an out parameter for the distance as well as a bool return value? or does it simply return a float with the distance, vs a value of -1 for no collision?</p>

<p>(For those that don't know: AABB = Axis Aligned Bounding Box)</p>
","<p>Andrew Woo, who along with John Amanatides developed the raymarching algorithm (DDA) used ubiquitously in raytracers, wrote <a href=""https://web.archive.org/web/20090803054252/http://tog.acm.org/resources/GraphicsGems/gems/RayBox.c"" rel=""nofollow noreferrer"">""Fast Ray-Box Intersection""</a> (alternative source <a href=""https://github.com/erich666/GraphicsGems/blob/master/gems/RayBox.c"" rel=""nofollow noreferrer"">here</a>) which was published in Graphics Gems, 1990, pp. 395-396. Rather than being built specifically for integration through a grid (eg. a voxel volume) as DDA is (see zacharmarz' answer), this algorithm is specifically suited to worlds that are not evenly subdivided, such as your typical polyhedra world found in most 3D games.</p>

<p>The approach provides support for 3D, and optionally does backface culling. The algorithm is derived from the same principles of integration used in DDAs, so it is <em>very</em> quick.  More detail can be found in the original Graphics Gems volume (1990).</p>

<p>Many other approaches specifically for Ray-AABB to be found at <a href=""http://www.realtimerendering.com/intersections.html"" rel=""nofollow noreferrer"">realtimerendering.com</a>.</p>

<p>EDIT: An alternative, branchless approach -- which would be desirable on both GPU &amp; CPU -- may be found <a href=""https://tavianator.com/fast-branchless-raybounding-box-intersections/"" rel=""nofollow noreferrer"">here</a>.</p>
","21030"
"Rotate an object smoothly on the Y axis in Unity","51196","","<p>I am attempting a simple script to swing a door open in Unity.  This requires a smooth rotation of 90 degrees around the Y axis.  I have seen that one way to do this is using Unity's Quanternion object.  I believed that this should work:</p>

<pre><code>public class DoorOpenScript : MonoBehaviour 
{

    public float smooth = 20;

    // Use this for initialization
    void Start () 
    {   
        SwingOpen ();
    }

    // Update is called once per frame
    void Update () 
    {

    }

    void SwingOpen()
    {   
        Quaternion newRotation = new Quaternion(transform.rotation.x,transform.rotation.y,transform.rotation.z,transform.rotation.w);;
        newRotation *= Quaternion.Euler(0, 90, 0); // this add a 90 degrees Y rotation
        transform.rotation= Quaternion.Slerp(transform.rotation, newRotation,20 * Time.deltaTime);      

    }

}
</code></pre>

<p>However, this just opens the door completely. I have tried playing with the third parameter to <code>Slerp</code> but with no results. What am I doing incorrectly? </p>
","<p>Think about what you need to do, open the door over time. It's not going to happen all in one call in the <code>Start</code> function. You'll need to add a little more rotation each frame to rotate the object smoothly. Something like the following will rotate the object from 0 to 90 degrees over time:</p>

<pre><code>void Update () {
    SwingOpen();
}

void SwingOpen()
{   
    Quaternion newRotation = Quaternion.AngleAxis(90, Vector3.up);
    transform.rotation= Quaternion.Slerp(transform.rotation, newRotation, .05f);      
}
</code></pre>

<p>Notice it's using the <code>Update()</code> function instead of <code>Start()</code>. That's because we want to change it a little each frame. Using <code>Slerp</code> you'll notice that the object swings fast at first, then slower until finally reaching its rotation. The last parameter controls that rate of change, with <code>1</code> being instantly and <code>0</code> being never. </p>

<p>Perhaps this is your intended behavior, if not you can also perform a constant rotation over time with something like the following:</p>

<pre><code>public float rotationDegreesPerSecond = 45f;
public float rotationDegreesAmount = 90f;
private float totalRotation = 0;
// Use this for initialization
void Start () {

}

// Update is called once per frame
void Update () {
    //if we haven't reached the desired rotation, swing

    if(Mathf.Abs(totalRotation) &lt; Mathf.Abs(rotationDegreesAmount))
        SwingOpen();
}

void SwingOpen()
{   
   float currentAngle = transform.rotation.eulerAngles.y;
   transform.rotation = 
    Quaternion.AngleAxis(currentAngle + (Time.deltaTime * degreesPerSecond), Vector3.up);
   totalRotation += Time.deltaTime * degreesPerSecond;
}
</code></pre>

<p>In this case, the rotation of the door will take 2 seconds to reach 90 degrees.</p>

<p>And just a tip, setting the variables to <code>public</code> will allow you to edit them from the Unity editor. This means you can apply this same script to multiple objects, but change the values for each object without editing the script.</p>
","61383"
"C++ low-level optimization tips","51101","","<p>Assuming you already have the best-choice algorithm, what low-level solutions can you offer for squeezing the last few drops of sweet sweet frame rate out of C++ code?  </p>

<p>It goes without saying that these tips only apply to that critical code section that you've already highlighted in your profiler, but they should be low-level non-structural improvements.  I've seeded an example.</p>
","<p><strong>Optimise your data layout!</strong> (This applies to more languages than just C++)</p>

<p>You can go pretty deep making this specifically tuned for your data, your processor, handling multi-core nicely, etc. But the basic concept is this:</p>

<p>When you are processing things in a tight loop, you want to make the data for each iteration as small as possible, and as close together as possible in memory. That means the ideal is an array or vector of objects (not pointers) that contain only the data necessary for the calculation.</p>

<p>This way, when the CPU fetches the data for the first iteration of your loop, the next several iterations worth of data will get loaded into the cache with it.</p>

<p>Really the CPU is fast and the compiler is good. There's not really much you can do with using fewer and faster instructions. <a href=""http://supercomputingblog.com/optimization/taking-advantage-of-cache-coherence-in-your-programs/"">Cache coherence</a> is where it's at (that's a random article I Googled - it contains a good example of getting cache coherency for an algorithm that doesn't simply run through data linearly).</p>
","870"
"Using multiple shaders","50972","","<p>I'm currently studying opengl shaders but I can't figure out something: how to apply different shaders to the objects, for example, a teapot rendered using toon shader and another one in the same scene using a very reflective surface and other distorted from a noise function, like in this video</p>

<p><a href=""http://www.youtube.com/watch?v=1ogg4ZfdBqU"">http://www.youtube.com/watch?v=1ogg4ZfdBqU</a></p>

<p>Another one is applying a bloom shader in a scene and a motion blur shader afterwards. How to achieve those effects when you can only have one vertex shader and one fragment shader? Is there any trick such as using more than one shader program?</p>
","<p>The simple answer is you change them between each draw call. Set a shader, draw a teapot, set another shader, draw another teapot.</p>

<p>For more complex stuff where you need to apply multiple shaders to just one object such as blur, glow and so on. You basically have everything rendered to texture(s). Then you render a quad over your entire screen with that texture applied while using another shader.</p>

<p>For example if you want to render a glow effect, you first need to render your regular non-glowing scene, then render just the colored silhouette of the stuff that you want to glow on a texture then you switch to a blur shader and render your quad with that texture attached over your non-glowing scene.</p>

<p>There is another technique called <a href=""http://en.wikipedia.org/wiki/Deferred_shading"">Deferred shading</a> where you render the scene without lighting and apply it later in screen space. The core goal is to reduce the expense of per pixel lighting. </p>

<p>Normally you render a color buffer which is put on the screen. With deferred shading you instead render a color buffer as well as a normal and depth buffer in one shader pass (you can store the normal vectors and the depth in a texture like with normal and height mapping). </p>

<p>This means that, for every pixel, you know the position of the nearest piece of non transparent geometry (depth or distance from eye) the color and the normal. Because of this you can apply lighting to each pixel on the screen instead of to each visible pixel of every object you render. Remember that some object will be drawn over the top of other objects if the scene isn't perfectly rendered in front to back order.</p>

<p>For shadows you actually render just the depth buffer from the point of view of your light then use that depth information to work out where the light strikes. That's called shadow mapping (there is also another approach called shadow volumes that works out a silhouette of the geometry and extrudes it, but your still going to be using shaders.).</p>

<p>With more modern OpenGL (3.0+) you use a <a href=""http://www.opengl.org/wiki/Framebuffer_Object"">Framebuffer Object</a> with Renderbuffers Objects attached. Since renderbuffers can be treated like a texture. You might do things like have 1 shader render to multiple different renderbuffers (so you don't have to render your texture then your normals <em>then</em> the glow components) but the underlying practice is still the same.</p>

<p>Also it's desirable to minimize the number of shader switches as much as possible to save on overhead. So some engines will group everything with the same material together so it can all be drawn at once.</p>
","22218"
"Which is better a computer science degree or a Software engineer degree?","50957","","<p>I'm asking here so since you all have experience in or around game programming, that's what I want to do, and I’m trying to find as many options as I can before my senior year, which is next year. So do you have any opinions on the matter of which would give me a better education in programming?</p>

<p>Please no talking about anything other than the two degrees because I know of game programming degrees out there but I like to see which of these would provide the best alternate choice.</p>
","<p>Since you're asking on the game development forum, I'm assuming you're interested in a game development career.  Both programs would be fine. They have some overlap, but they also would lead you in different directions.</p>

<p>A traditional computer science program is aimed at the more theoretical aspects of computing. You'd generally work in more traditional languages (C/C++/Java) and you'd spend a lot of time contemplating data structures, algorithms, and efficiency. CS majors typically are required to take a great deal of Math and Science. (I encourage our students to get a Math minor, because they're only one course away by the time they take our requirements.)  The focus on math and theory are good preparation for certain kinds of game programming (say building game engines and creating lighting models.)  </p>

<p>Software engineering has a different focus. Software engineering programs are typically more focused on business applications. The emphasis is on working with large teams of developers and building large software projects.  Games are a form of business application, so the skills would be applicable.</p>

<p>Plenty of CS majors move into software engineering as they gain experience, but fewer people seem to move into CS after they've studied software engineering.</p>
","5463"
"Is it possible to use C++ with Unity instead of C#?","50825","","<p>The title kind of says it all. Is it possible to replace C# with C++ on a game using Unity?</p>
","<p>It is possible to use C++ with the Free version of Unity, although it is easier to work with if you have a Unity Pro license. All you have to do is wrap it up in a DLL and follow the instructions below on where to place it.</p>

<p>I wrote an article that covers this topic: <strong><a href=""http://ericeastwood.com/blog/17/unity-and-dlls-c-managed-and-c-unmanaged"">Unity and DLLs: C# (managed) and C++ (unmanaged)</a></strong></p>

<blockquote>
  <p>For Unity 4 Free:</p>
  
  <ul>
  <li>Add unmanaged code to the Unity Project Root: <code>UnityProject</code></li>
  <li>Add managed code to the Plugins folder: <code>UnityProject</code>-><code>Plugins</code></li>
  <li>When you build a project, copy the unmanaged code to <code>BuildRoot</code>-><code>Data</code>-><code>Plugins</code></li>
  </ul>
  
  <p>For Unity 4 Pro and any Unity 5:</p>
  
  <ul>
  <li>Just copy the DLLs into <code>UnityProject</code>-><code>Plugins</code></li>
  </ul>
</blockquote>

<p>Unmanaged means C++ and Managed means C#</p>
","82523"
"Simple collision detection in Unity 2D","50494","","<p>I realise other posts exist with this topic yet none have gone into enough detail for me. I am attempting to create a 2D game in Unity using C# as my scripting language.</p>

<p>Basically I have two objects, <code>player</code> and <code>bomb</code>. Both were created simply by dragging the respective PNG to the stage.</p>

<p>I have set up touch controls to move <code>player</code> left and right; gravity of any kind is not needed as I only require it to move <code>x</code> units when I tap either the left or right side of the screen. This movement is stored in a script called <code>playerController.cs</code> and works just fine.</p>

<p>I also have a variable <code>health = 3</code> for <code>player</code>, which is stored in <code>healthScript.cs</code>.</p>

<p>I am now at a point where I am stuck. I would like it so that when <code>player</code> collides with <code>bomb</code>, <code>health</code> decreases by one and the <code>bomb</code> object is destroyed. So what I tried doing is using a new script called <code>playerPhysics.cs</code>, I added the following:</p>

<pre><code>void OnCollisionEnter2D(Collision2D coll){
        if(coll.gameObject.name==""bomb"")
        {
            GameObject.Destroy(""bomb"");
            healthScript.health -= 1;
        }
}
</code></pre>

<p>While I'm fairly sure I don't know the proper way to reference a variable in another script and that's why the health didn't decrease when I collided, <code>bomb</code> never disappeared from the stage so I'm thinking there's also a problem with my collision.</p>

<p>Initially, I had simply attached <code>playerPhysics.cs</code> to <code>player</code>. After searching around though, it appeared as though <code>player</code> also needed a rigidBody attached to it, so I did that. Still no luck. I tried using a circleCollider (<code>player</code> is a circle), using a rigidBody2D, and using all manner of colliders on one and/or both of the objects. If you could please explain what colliders (if any) should be attached to which objects and whether I need to change my script(s), that would be much more helpful than pointing me to one of the generic documentation examples I've already read. Also, if it would be simple to fix the health thing not working that would be an added bonus but not exactly the focus of this question.</p>

<p>Bear in mind that this game is 2D; I'm not sure if that changes anything.</p>

<p>Thanks!</p>
","<p>I did the following to achieve results:</p>

<p>Added a Rigidbody2D to the player (deactivate Gravity).
Added a 2D-Collider to the bomb.
Added control and health script (basic stuff, just position updates). My health is just a public variable.
Used the following code in playerPhysics.cs:</p>

<pre><code>void OnCollisionEnter2D(Collision2D coll)
{
    if (coll.gameObject.name == ""bomb"")
    {
        Destroy(coll.gameObject);
        this.GetComponent&lt;healthScript&gt;().health -= 1;
    }
}
</code></pre>

<p>Note the way I fetched the HealthScript. If you do this on a regular basis, you may want to store this in a private Variable of type healthScript.</p>

<pre><code>private healthScript hs = this.GetComponent&lt;healthScript&gt;();

//...usage in methods
hs.health = 9001;
</code></pre>
","82128"
"What are some good learning resources for OpenGL?","48536","","<p>I have been using the OpenGL ES on the iPhone for a while now and basically I feel pretty lost outside to the small set of commands I've seen in examples and adopted as my own. I would love to use OpenGL on other platforms and have a good understanding of it.</p>

<p>Every time I search for a book I find this HUGE bibles that seem uninteresting and very hard for a beginner. If I had a couple of weekends to spend on learning OpenGL what would be the best way to spend my time (and money)?</p>
","<p>Be careful when you look at OpenGL tutorials, because many of them (NeHe) included just teach you things that you shouldn't do anymore. Todays OpenGL is a different beast that it was 10 years ago.</p>

<p>Some nice examples avoiding the deprecated stuff can be found here:
<a href=""http://www.g-truc.net/post-tech-content-sample.html"">http://www.g-truc.net/post-tech-content-sample.html</a></p>

<blockquote>
  <p>The OpenGL Samples Pack 4.0.1.0 is an update that brings the number of samples to a total of 58 samples; including 13 OpenGL 4 samples, 33 OpenGL 3.3 samples and 12 OpenGL 2 samples for Visual Studio 2008 and 2010 in 32 and 64 bits.</p>
</blockquote>
","1147"
"Game Development In C Only. Is it possible?","48232","","<p>I am a first year college student in India and want to make a small game as a this semester project.</p>

<p>I am quite good at C and am learning it rapidly but I wanted to ask if developing a game entirely in C (no C++ or C#) I'd love to use these but for college projects, we have strict requirements of using only C.</p>

<p>What I am looking for is a simple top view driving game. It won't have anything fancy and even the visual things will be powered by simple characters. For example, user controlled car can be represented by ▓ and edges of road by series of |'s.
What do you think?</p>
","<p>Writing games in C is possible. For example, <a href=""http://en.wikipedia.org/wiki/Quake_II"">Quake II</a> is written purely in C, so writing other games in C should be no problem at all. It may be the better choice if you're more proficient and comfortable in C than in C++.</p>
","8573"
"'Resetting' Google Play Games Services so app forgets it previously connected (so it shows confirmation screen again)","48165","","<p>When I first integrated Google Play Games Services into my app, it came up with a 'confirmation screen', something like:</p>

<p><strong><em>App Name</em> wants to connect to Google Play Game Services</strong></p>

<p>I don't recall the exact wording.</p>

<p>While Alpha testing my app, one of my users has discovered a potential issue where he presses 'cancel' at that point instead of connecting. I would like to try to resolve this issue, but I can't recreate it because I can't work out how I can get that confirmation screen again!</p>

<p>I have implemented a 'log out' button in my app and that works, but when subsequently connecting, it just goes ahead without displaying the confirmation screen again.  Any ideas how I can force that screen to show again for testing?!</p>
","<p>Follow these steps to ""deauthorize"" an app with G+ sign-in:</p>

<ol>
<li>Open the <code>Google Settings</code> app on your device.</li>
<li>Next select the <code>Connected apps</code> option.</li>
<li>Find your app in the list and select it.</li>
<li>Finally click the <code>Disconnect</code> button.</li>
</ol>

<p>A confirmation/warning will be displayed. Note that it says it can take up to an hour for the process to be completed.</p>

<p>After doing this your next sign-in attempt should re-request access for G+ sign-in.</p>

<p>Edit (screenshot of Google Settings):</p>

<p><img src=""https://i.stack.imgur.com/5azzU.png"" alt=""Google Settings""></p>
","80888"
"Can I legally remove the default Unity splash screen by removing it from the APK?","48044","","<p>While using Unity I export an Android game as an APK. When the APK is run, the first thing that is displayed is the Unity splash screen. I worked out that I could replaced that image by opening the APK like a zip file, looking for the splash screen image  (<code>App.apk/assests/bin/Data/splash.png</code>) and replacing it with any image I wanted.</p>

<p>Is it legal to publish Unity-powered Android game apps with modified splash screens like this? I remember that some games on PS3, 360 and Wii have been created with Unity but don't display a Unity splash screen when run on their respective consoles.</p>
","<p>There are several sections of the Unity <a href=""http://unity3d.com/company/legal/eula"">End-User License Agreement</a> (which is for version 4.x as I write this, although earlier versions are similar) that pertaining to this issue. </p>

<p>The most directly relevant is section 3, which reads (in part):</p>

<blockquote>
  <p>You will not delete or in any manner alter any Unity or third-party
  copyright, trademark or other proprietary rights notices or markings
  appearing on or in the Software (including the runtime portion
  thereof).</p>
</blockquote>

<p>This is a pretty straightforward answer to your question: <em>no</em>, you are not permitted to remove the Unity splash screen from your Unity-based game.</p>

<p>There are other restrictions, such as section 2.f, which reads (in part): </p>

<blockquote>
  <p>General Restrictions. Except as expressly specified in this Agreement,
  you may not: (i) copy (except in the course of loading or installing)
  or modify or create derivative works of the Software;</p>
</blockquote>

<p>and continues</p>

<blockquote>
  <p>Accordingly, you agree not to disassemble, decompile or reverse
  engineer the Software, in whole or in part, or permit or authorize a
  third party to do so, except to the extent such activities are
  expressly permitted by law notwithstanding this prohibition.</p>
</blockquote>

<p>For the terms of the license, the term ""Software"" refers to ""all 4.x versions and updates of all the Unity software products identified on Unity’s website."" Further, the agreement is governed by the laws of Denmark, a fact which probably does not particularly apply to this question but is nonetheless worth noting.</p>

<p>Your technique for digging around in the final binaries of the game and gutting the default splash screen pretty clearly violates the above; your only recourse for splash screen modification is going to be whatever is <a href=""http://docs.unity3d.com/Documentation/Manual/MobileCustomizeSplashScreen.html"">built-in to the version of Unity you have</a>. Your technique violates the license agreement.</p>
","72090"
"Is ruby a suitable language for game development?","46769","","<p>I want to move into some game development, but the only language I know really well is Ruby. Most of what I have read seems to point towards lower level languages like C++ for game development, or languages for specific frameworks like C# for using XNA. Does anyone have any experience using a language like ruby for game development? If so, would you advise for or against it?</p>
","<p>I have no preference towards Ruby (or Python), I'm a Java person myself. But UnknownDevice's answer about how Ruby is somehow ""not really for games"" and Python is, frustrated me. I do hope he will clarify.</p>

<p>I know Pygame exists and has been around, and I recognize that Python has a larger userbase than Ruby. But to be honest, neither of them seems like a language ""for games"". Neither does Java, and that's my game programming language of choice. (and when I say ""of choice"", I do mean <strong>by choice</strong>, not because it's what's taught in school or because it's something I ""know""). And really, what is a language ""for games""? Well, speed is a factor, and obviously it must have libraries for graphics and other game systems (audio, input, etc).</p>

<p>As far as speed goes, it seems to be a tossup between Ruby and Python. Do some searches and you'll quickly find benchmarks and arguments for both sides of the spectrum, and various configurations which put one or the other ahead. Python with something called ""Psycho"" seems a popular speed demon compared to Ruby, yet regular Python seems to be a bit slower than Ruby. In the end, if you're choosing such a high-level language you're obviously not concerned with native speeds anyway; go with the language you know best. And obviously you know Ruby best, so I encourage it!</p>

<p>The other factor is whether the technology is there to create games; whether it can support drawing to the screen and collecting input and playing audio. Ruby can do all of these. In fact there are a good number of options in this respect. There's a <a href=""http://ruby-opengl.rubyforge.org/"">ruby-opengl</a> package at RubyForge which will give OpenGL support to Ruby (or it might be included by default?). Alternatively, <a href=""http://ippa.se/chingu"">Chingu</a> provides ""lightning fast OpenGL accelerated 2D graphics!"" according to its homepage; it builds extra features on top of <a href=""http://www.libgosu.org/"">Gosu</a>, which you could choose to use if Chingu is too much for you. Or for 3D graphics, if you don't want to use ruby-opengl, try <a href=""http://g3d-ruby.rubyforge.org/"">G3DRuby</a>, ""a very clean set of wrapper classes for many of the more advanced OpenGL features"". There's even <a href=""http://rubygame.org/"">Rubygame</a>, which I can't find much information on but it claims to be ""a cross-platform multimedia library"" and given the name, must have emphasis on game development. If you are familiar with the popular <a href=""http://www.libsdl.org/"">SDL</a> library for C++, there's <a href=""http://www.kmc.gr.jp/~ohai/rubysdl.en.html"">Ruby/SDL</a> or <a href=""http://sourceforge.net/projects/rudl/"">RUDL</a>, both of which are Ruby wrappers of SDL. Or if you prefer the newer, more object-oriented <a href=""http://www.sfml-dev.org/"">SFML</a>, it is also available for Ruby!</p>

<p>There is no reason that Ruby should be less of a game programming language than Python; if there is one, I'd really like to hear it so I can argue against it. <strong>If you feel most comfortable programming in Ruby, and you are aware of the pros and cons compared to other popular languages, then by all means you can certainly develop games in Ruby!</strong></p>
","3586"
"In Pong, how do you calculate the ball's direction when it bounces off the paddle?","46703","","<p>I'm trying to wrap my head around this very Hello World-y problem in game development. I've created a TicTacToe game in XNA so I guess the next step would be a <a href=""http://en.wikipedia.org/wiki/Breakout_(video_game)"">Breakout</a> clone.</p>

<p>Keep in mind that I have <strong>no</strong> knowledge on game programming or even what maths I should apply to where. That's why I'm asking this question.</p>

<hr>

<p>To the question: How can I determine where the ball should bounce when it hits the paddle at the bottom of the screen?</p>

<p>I'd imagine it would be something like:</p>

<ol>
<li>Capture speed and angle from incoming ball.</li>
<li>Detect where it touched the bar (far left, far right, center) and according to that give it a higher speed if it touched the outer areas.</li>
<li>This is where I'm stuck. Hehe.</li>
</ol>

<p>Any insights? I realize this is not a straightforward answer type question, but I'm sure it's one everyone faces at some point.</p>

<p>I'm reading the book <em>Linear Algebra</em> that was recommended on this website, but I still have no idea if I should apply it here.</p>
","<p>Here's the relevant logic I used on the pong on <a href=""http://richardcarter.org/"">my homepage</a>: (please go play it before reading, so that you know the effect I'm achieving with the following code)</p>

<p>Essentially, when the ball collides with the paddle, its direction is completely disregarded; it is given a new direction according to how far from the center of the paddle it collided. If the ball hits the paddle right in the center, it is sent away exactly horizontal; if it hits right on the edge, it flies off at an extreme angle (75 degrees). And it always travels at a constant speed.</p>

<pre><code>var relativeIntersectY = (paddle1Y+(PADDLEHEIGHT/2)) - intersectY;
</code></pre>

<p>Take the middle Y value of the paddle, and subtract the Y intersection of the ball. If the paddle is 10 pixels high, this number will be between -5 and 5. I call this the ""relative intersect"" because it is in ""paddle space"" now, the ball's intersection relative to the middle of the paddle.</p>

<pre><code>var normalizedRelativeIntersectionY = (relativeIntersectY/(PADDLEHEIGHT/2));
var bounceAngle = normalizedRelativeIntersectionY * MAXBOUNCEANGLE;
</code></pre>

<p>Take the relative intersection and divide it by half the paddle height. Now our -5 to 5 number is a decimal from -1 to 1; it's <em>normalized</em>. Then multiply it by the maximum angle by which you want the ball to bounce. I set it to 5*Pi/12 radians (75 degrees).</p>

<pre><code>ballVx = BALLSPEED*Math.cos(bounceAngle);
ballVy = BALLSPEED*-Math.sin(bounceAngle);
</code></pre>

<p>Finally, calculate new ball velocities, using simple trigonometry.</p>

<p>This might not quite be the effect you're going for, or you might want to also determine a speed by multiplying the normalized relative intersection by a max speed; this would make the ball go faster if it hits near the edge of a paddle, or slower if it hits near the center.</p>

<hr>

<blockquote>
  <p>I'd possibly like some code on what a vector would look like or how I could save the variable of the vector the balls has (speed and direction).</p>
</blockquote>

<p>A vector contains both speed and direction, implicitly. I store my vector as a ""vx"" and ""vy""; that is, the speed in the x direction and the speed in the y direction. If you haven't taken an introductory course in physics this might seem somewhat foreign to you.</p>

<p>The reason I do this is because it reduces the per-frame calculations necessary; every frame, you just do <code>x += vx * time;</code> and <code>y += vy * time;</code> where time is the time since last frame, in milliseconds (therefore the velocities are in pixels per millisecond).</p>

<hr>

<p>Regarding implementing the ability to curve the ball:</p>

<p>First of all, you'd need to know the paddle's velocity at the time the ball hits; which means you'd need to keep track of the paddle's history, so that you can know one or more of the paddle's past positions so that you can compare them to its current position to see if it moved. (change in position / change in time = velocity; so you need 2 or more positions, and the times of those positions)</p>

<p>You now also need to track an <a href=""http://en.wikipedia.org/wiki/Angular_velocity"">angular velocity</a> of the ball, which practically represents the curve along which it is traveling, but is equivalent to the real-world spin of the ball. Similar to how you would interpolate the bounce angle from the relative position of the ball on collision with the paddle, you would also need to interpolate this angular velocity (or spin) from the velocity of the paddle on collision. Rather than simply setting the spin like you do with the bounce angle, you might want to add or subtract to the ball's existing spin, because that tends to work well in games (the player can notice the ball is spinning, and cause it to spin even more wildly, or counter the spin in an attempt to make it travel straight).</p>

<p>Note, however, that while this is the most common sense and probably easiest way to implement it, the actual physics of a bounce doesn't rely solely on the velocity of the object it hits; an object with no angular velocity (no spin) which hits a surface at an angle, will have a spin imparted upon it. This might lead to a better game mechanic, so you may want to look into this, but I'm not certain of the physics behind it so I'm not going to try to explain it.</p>
","4255"
"What's the most efficient way to find barycentric coordinates?","46568","","<p>In my profiler, finding barycentric coordinates is apparently somewhat of a bottleneck.  I am looking to make it more efficient.</p>

<p>It follows the method in <a href=""http://books.google.ca/books/about/Fundamentals_of_computer_graphics.html?id=WY5Urwcqsa4C&amp;redir_esc=y"">shirley</a>, where you compute the area of the triangles formed by embedding the point P inside the triangle.</p>

<p><img src=""https://i.stack.imgur.com/8VODS.png"" alt=""bary""></p>

<p>Code:</p>

<pre><code>Vector Triangle::getBarycentricCoordinatesAt( const Vector &amp; P ) const
{
  Vector bary ;

  // The area of a triangle is 
  real areaABC = DOT( normal, CROSS( (b - a), (c - a) )  ) ;
  real areaPBC = DOT( normal, CROSS( (b - P), (c - P) )  ) ;
  real areaPCA = DOT( normal, CROSS( (c - P), (a - P) )  ) ;

  bary.x = areaPBC / areaABC ; // alpha
  bary.y = areaPCA / areaABC ; // beta
  bary.z = 1.0f - bary.x - bary.y ; // gamma

  return bary ;
}
</code></pre>

<p>This method works, but I'm looking for a more efficient one!</p>
","<p>Transcribed from Christer Ericson's <a href=""http://realtimecollisiondetection.net/"">Real-Time Collision Detection</a> (which, incidentally, is an excellent book):</p>

<pre><code>// Compute barycentric coordinates (u, v, w) for
// point p with respect to triangle (a, b, c)
void Barycentric(Point p, Point a, Point b, Point c, float &amp;u, float &amp;v, float &amp;w)
{
    Vector v0 = b - a, v1 = c - a, v2 = p - a;
    float d00 = Dot(v0, v0);
    float d01 = Dot(v0, v1);
    float d11 = Dot(v1, v1);
    float d20 = Dot(v2, v0);
    float d21 = Dot(v2, v1);
    float denom = d00 * d11 - d01 * d01;
    v = (d11 * d20 - d01 * d21) / denom;
    w = (d00 * d21 - d01 * d20) / denom;
    u = 1.0f - v - w;
}
</code></pre>

<p>This is effectively Cramer's rule for solving a linear system. You will not get much more efficient than this—if this is still a bottleneck (and it might be: it doesn't look like it's much different computation-wise than your current algorithm), you'll probably need to find some other place to gain a speedup.</p>

<p>Note that a decent number of values here are independent of <em>p</em>—they can be cached with the triangle if necessary.</p>
","23745"
"How much does it cost to produce a major video game?","45822","","<p>I asked this same question <a href=""https://gaming.stackexchange.com/questions/9085/how-much-does-it-cost-to-produce-a-major-video-game"">here</a>, but was closed and told to ask it on this site instead.</p>

<p>How much would it cost to develop a video game. I mean like a major PS3/360 video game. I know there really is no set price; but there has to be a pall bark, 100 grand, 10 mil, etc.</p>

<p>I am asking how much the games cost to make, (studio cost, developer salaries, etc.)</p>

<p>Examples would be nice.</p>
","<p>Somewhere between $20M and $100M would be reasonable depending on genre for a AAA game. XBLA/PSN downloadable games often cost much less, and people have made XBLIG games for a few hundred dollars in their spare time. As a recent example, APB was rumored to have cost $100M (MMOs are among the most expensive games to produce).</p>
","4519"
"Is there a tool to make a Spritesheet out of 1000 PNG's?","45353","","<p>My graphics designer has made graphics in separate PNG files. Is there a clever tool/script that mashes them into a spritesheet?</p>

<p>I could probably code something myself, but why re-invent the wheel :)</p>
","<p>Am I the only one who uses <a href=""https://github.com/nickgravelyn/SpriteSheetPacker"" rel=""nofollow noreferrer"">SpriteSheetPacker</a>?  It's free and open source so you can modify it and learn how it works.</p>
","27229"
"Why do we move the world instead of the camera?","44809","","<p>I heard that in an OpenGL game what we do to let the player move is not to move the camera but to move the whole world around.</p>

<p>For example here is an extract of this tutorial: <a href=""http://open.gl/transformations#TransformationsinOpenGL"">OpenGL View matrix</a></p>

<blockquote>
  <p>In real life you're used to moving the camera to alter the view of a certain scene, in OpenGL it's the other way around. The camera in OpenGL cannot move and is defined to be located at (0,0,0) facing the negative Z direction. That means that instead of moving and rotating the camera, the world is moved and rotated around the camera to construct the appropriate view.</p>
</blockquote>

<p>Why do we do that?</p>
","<p><strong>Why ?</strong></p>

<p>Because, A camera represents a projection view. </p>

<blockquote>
  <p>But in case of 3D Camera (Virtual Camera), camera moves instead of
  the world. I have made a detailed explanation later of this answer.</p>
</blockquote>

<p><strong>Understanding Mathematically</strong></p>

<p>Projection View moves around space and change its orientation. The first thing to notice is that the desired projection on the screen does not change with view direction.</p>

<ul>
<li><a href=""http://www.eng.utah.edu/~cs6360/Lectures/frustum.pdf"" rel=""noreferrer"">http://www.eng.utah.edu/~cs6360/Lectures/frustum.pdf</a></li>
</ul>

<p>For this reason, we transform other things to get the desired projection. </p>

<p><strong>Understanding From  <a href=""http://opengl.org"" rel=""noreferrer"">http://opengl.org</a></strong></p>

<p>To give the appearance of moving the camera, your OpenGL application must move the scene with the inverse of the camera transformation. where OpenGL is concerned, there is no camera. More specifically, the camera is always located at the eye space coordinate (0, 0, 0)</p>

<ul>
<li><a href=""http://www.opengl.org/archives/resources/faq/technical/viewing.htm"" rel=""noreferrer"">http://www.opengl.org/archives/resources/faq/technical/viewing.htm</a></li>
</ul>

<p><strong>Understanding From  <a href=""http://open.gl"" rel=""noreferrer"">http://open.gl</a></strong></p>

<p>Also want to share the following lines from <strong>View matrix</strong> portion of <a href=""http://open.gl/transformations"" rel=""noreferrer"">http://open.gl/transformations</a> </p>

<blockquote>
  <p>To simulate a camera transformation, you actually have to transform
  the world with the inverse of that transformation. Example: if you
  want to move the camera up, you have to move the world down instead.</p>
</blockquote>

<p><strong>Understanding by perspective</strong></p>

<p>In the real world, we see things in a way that is called ""perspective"".</p>

<p>Perspective refers to the concept that objects that are farther away appear to be smaller than those that are closer to you. Perspective also means that if you are sitting in the middle of a straight road, you actually see the borders of the road as two converging lines.</p>

<p>That’s perspective. Perspective is critical in 3D projects. Without perspective, the 3D world doesn't look real.</p>

<p>While this may seem natural and obvious, it's important to consider that when you create a 3D rendering on a computer you are attempting to simulate a 3D world on the computer screen, which is a 2D surface. </p>

<p>Imagine that behind the computer screen there is a real 3D scene of sorts, and you are watching it through the ""glass"" of your computer screen. Using perspective, your goal is to create code that renders what gets ""projected"" on this ""glass"" of your screen as if there was this real 3D world behind the screen. The only caveat is that this 3D world is not real…it's just a mathematical simulation of a 3D world.</p>

<p>So, when using 3D rendering to simulate a scene in 3D and then projecting the 3D scene onto the 2D surface of your screen, the process is called perspective projection.</p>

<p>Begin by envisioning intuitively what you want to achieve. If an object is closer to the viewer, the object must appear to be bigger. If the object is farther away, it must appear to be smaller. Also, if an object is traveling away from the viewer, in a straight line, you want it to converge towards the center of the screen, as it moves farther off into the distance.</p>

<p><strong>Translating perspective into math</strong></p>

<p>As you view the illustration in following figure , imagine that an object is positioned in your 3D scene. In the 3D world, the position of the object can be described as xW, yW, zW, referring to a 3D coordinate system with the origin in the eye-point. That’s where the object is actually positioned, in the 3D scene beyond the screen.</p>

<p><img src=""https://i.stack.imgur.com/2uaqu.jpg"" alt=""enter image description here""></p>

<p>As the viewer watches this object on the screen, the 3D object is ""projected"" to a 2D position described as xP and yP, which references the 2D coordinate system of the screen (projection plane).</p>

<p>To put these values into a mathematical formula, I'll use a 3D coordinate system for world coordinates, where the x axis points to the right, y points up, and positive z points inside the screen. The 3D origin refers to the location of the viewer's eye. So, the glass of the screen is on a plane orthogonal (at right angles) to the z-axis, at some z that I’ll call zProj.</p>

<p>You can calculate the projected positions xP and yP, by dividing the world positions xW, and yW, by zW, like this:</p>

<blockquote>
  <p>xP = K1 * xW / zW<br>
  yP = K2 * yW / zW</p>
</blockquote>

<p>K1 and K2 are constants that are derived from geometrical factors such as the aspect ratio of your projection plane (your viewport) and the ""field of view"" of your eye, which takes into account the degree of wide-angle vision.</p>

<p>You can see how this transform simulates perspective. Points near the sides of the screen get pushed toward the center as the distance from the eye (zW) increases. At the same time, points closer to the center (0,0) are much less affected by the distance from the eye and remain close to the center.</p>

<p>This division by z is the famous ""perspective divide.""</p>

<p>Now, consider that an object in the 3D scene is defined as a series of vertices. So, by applying this kind of transform to all vertices of geometry, you effectively ensure that the object will shrink when it's farther away from the eye point.</p>

<p><strong>Other Important Cases</strong></p>

<ul>
<li>In case of 3D Camera (Virtual Camera), camera moves instead of the world.</li>
</ul>

<p>To get a better understanding of 3D cameras, imagine you are shooting a movie. You have to set up a scene that you want to shoot and you need a camera. To get the footage, you'll roam through the scene with your camera, shooting the objects in the scene from different angles and points of view.</p>

<p>The same filming process occurs with a 3D camera. You need a ""virtual"" camera, which can roam around the ""virtual"" scene that you have created.</p>

<p>Two popular shooting styles involve watching the world through a character's eyes (also known as a first person camera) or pointing the camera at a character and keeping them in view (known as a third person camera).</p>

<p>This is the basic premise of a 3D camera: a virtual camera that you can use to roam around a 3D scene, and render the footage from a specific point of view.</p>

<p><strong>Understanding world space and view space</strong></p>

<p>To code this kind of behavior, you'll render the contents of the 3D world from the camera's point of view, not just from the world coordinate system point of view, or from some other fixed point of view.</p>

<p>Generally speaking, a 3D scene contains a set of 3D models. The models are defined as a set of vertices and triangles, referenced to their own coordinate system. The space in which the models are defined is called the model (or local) space.</p>

<p>After placing the model objects into a 3D scene, you'll transform these models' vertices using a ""world transform"" matrix. Each object has its own world matrix that defines where the object is in the world and how it is oriented.</p>

<p>This new reference system is called ""world space” (or global space). A simple way to manage it is by associating a world transform matrix to each object.</p>

<p>In order to implement the behavior of a 3D camera, you'll need to perform additional steps. You'll reference the world—not to the world origin—but to the reference system of the 3D camera itself.</p>

<p>A good strategy involves treating the camera as an actual 3D object in the 3D world. Like any other 3D object, you use a ""world transform"" matrix to place the camera at the desired position and orientation in the 3D world. This camera world transform matrix transforms the camera object from the original, looking forward rotation (along the z-axis), to the actual world (xc, yc, zc) position, and world rotation.</p>

<p>Following figure shows the relationships between the World (x, y, z) coordinate system and the View (camera) (x', y', z') coordinate system.</p>

<p><img src=""https://i.stack.imgur.com/LSGAz.jpg"" alt=""enter image description here""></p>
","40746"
"Best way to get elapsed time in miliseconds in windows","44603","","<p>I'm trying to do it using two FILETIMEs, casting them to ULONGLONGs, substracting the ULONGLONGs, and dividing the result by 10000. But it's pretty slow, and I want to know if there is a better way to do it.I use c++ with visual studio 2008 express edition. This is what I'm using:</p>

<pre><code>FILETIME filetime,filetime2;
GetSystemTimeAsFileTime(&amp;filetime);
Sleep(100);
GetSystemTimeAsFileTime(&amp;filetime2);
ULONGLONG time1,time2;
time1 = (((ULONGLONG) filetime.dwHighDateTime) &lt;&lt; 32) + filetime.dwLowDateTime;
time2 = (((ULONGLONG) filetime2.dwHighDateTime) &lt;&lt; 32) + filetime2.dwLowDateTime;
printf(""ELAPSED TIME IN MS:%d"",(int)((time2-time1)/10000));
</code></pre>
","<p>Use <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/ms644904%28v=vs.85%29.aspx"">QueryPerformanceCounter</a>.</p>

<pre><code>long long milliseconds_now() {
    static LARGE_INTEGER s_frequency;
    static BOOL s_use_qpc = QueryPerformanceFrequency(&amp;s_frequency);
    if (s_use_qpc) {
        LARGE_INTEGER now;
        QueryPerformanceCounter(&amp;now);
        return (1000LL * now.QuadPart) / s_frequency.QuadPart;
    } else {
        return GetTickCount();
    }
}

// Somewhere else...
    // ...
    long long start = milliseconds_now();
    // ....
    long long elapsed = milliseconds_now() - start;
</code></pre>
","26766"
"Fastest way to draw quads in OpenGL ES?","44425","","<p>I am using OpenGL ES 2.0
I have a bunch a quads to be drawn, would love to be able to have to pass only 4 vertices per quad as if I were using GL_QUADS, but basically I just want to know the best way of drawing a bunch of separate quads.</p>

<p>So far what I've found I could do:
-GL_TRIANGLES(6 vertices per quad)
-Degenerate GL_TRIANGLE_STRIP(6 vertices per quad)</p>

<p>Possibities I've found:
-GL_TRIANGLE_STRIPS with a special index value that resets quad strip(this would mean 5 indexes per quad, but I dont think this is possible is OpenGL ES 2.0)</p>
","<p>Just use index buffer and GL_TRIANGLES. In this case you need 4 vertices + 6 indices per quad (6 additional indices may sound large overhead but in reality it is not - once you have constructed your index buffer you don't have to touch it again). See <a href=""http://www.songho.ca/opengl/gl_vertexarray.html"">this page for more information</a> (search for glDrawElements)</p>

<p>Simple example code:</p>

<pre><code>GLfloat vertices[] = {-1, -1, 0, // bottom left corner
                      -1,  1, 0, // top left corner
                       1,  1, 0, // top right corner
                       1, -1, 0}; // bottom right corner

GLubyte indices[] = {0,1,2, // first triangle (bottom left - top left - top right)
                     0,2,3}; // second triangle (bottom left - top right - bottom right)

glVertexPointer(3, GL_FLOAT, 0, vertices);
glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_BYTE, indices);
</code></pre>

<p>Also, if you are drawing just one quad you need only 4 vertices to draw it with triangle strips (<a href=""http://en.wikipedia.org/wiki/Triangle_strip"">as shown in wikipedia</a>) but I guess you already knew this.</p>
","10741"
"What C# libraries can be used to support game development?","44261","","<p>As games are based on many different subsystems things like graphics (DirectX, OpenGL, ...), sound (OpenAL, Ogg Vorbis, ...) or physics (collisions, ...), what libraries do you know that are useful for game development in C# and what benefits do they offer?</p>
","<p>Graphics/Sound</p>

<ul>
<li><a href=""http://creators.xna.com"" rel=""nofollow"">XNA</a>  High level wrapper on DirectX9. Allows you to get up and running quickly. Supports PC, Xbox360 and windows phone 7. Support Xact audio aswell as its own SoundEffect API.</li>
<li><a href=""http://slimdx.org"" rel=""nofollow"">SlimDX</a> Lower level wrapper on DX9/10/11. If its in the DX SDK, its wrapped here.</li>
<li><a href=""http://www.opentk.com/"" rel=""nofollow"">OpenTK</a> Wrapper on OpenGL/AL.</li>
<li><a href=""http://cs-sdl.sourceforge.net/index.php/Main_Page"" rel=""nofollow"">SDL.net</a> A port of thr popular SDL lib.</li>
</ul>

<p>Engines</p>

<ul>
<li><a href=""https://waveengine.net/"" rel=""nofollow"">WaveEngine</a> Component based game engine architecture, C# api, 2d and 3d physics engine, beautiful visual effects, cross-platform support Android, Linux, Mac, iOS &amp; Windows, advanced layout system and much more.</li>
<li><a href=""http://www.neoaxis.com/"" rel=""nofollow"">NeoAxis</a> A 3D engine with support for NVIDIA PhysX physics engine, C# bindings, supports WPF &amp; Windows Forms, rich selection of tools like map, object, model, material, terrain editors, in game browser using Chromium, Pathfinding with Navigation Mesh and more.</li>
<li><a href=""http://www.torquepowered.com/products/torquex-3d"" rel=""nofollow"">TorqueX</a> A 2D/3D engine for XNA. Good editor suppport, garage games have recently reinvested in the engine after a period of neglect.</li>
<li><a href=""http://www.truevision3d.com/"" rel=""nofollow"">truevision 3d</a> C++ game engine with c# bindings</li>
<li><a href=""http://axiom3d.net/"" rel=""nofollow"">Axiom</a> A rewrite of Ogre in c#. Supports numerous backed rendering APIs.</li>
<li><a href=""http://unity3d.com/"" rel=""nofollow"">Unity</a> is a C++ graphics/game engine that supports gameplay scripting in C#</li>
<li><a href=""http://www.jeffongames.com/2009/05/angelxna-v10"" rel=""nofollow"">AngelXNA</a> A port of EALA's open source angle protoypeing framework</li>
</ul>

<p>Physics</p>

<ul>
<li><a href=""http://farseerphysics.codeplex.com/"" rel=""nofollow"">Farseer</a> A popular 2D physics engine, supports .net(desktop), compact(xbox) and micro(silverlight).</li>
<li><a href=""http://www.jitter-physics.com/"" rel=""nofollow"">Jitter</a> a relatively new 3D physics engine, Much better than its completion.</li>
<li><a href=""http://code.google.com/p/box2dx"" rel=""nofollow"">Box2Dx</a> A direct port of box2D</li>
<li><a href=""http://box2dxna.codeplex.com/"" rel=""nofollow"">Box2D.XNA</a> Another port of Box2D for XNA; more recent than Box2Dx</li>
<li><a href=""http://jiglibx.codeplex.com/"" rel=""nofollow"">JigLib</a></li>
<li><a href=""http://xnadevru.codeplex.com/wikipage?title=Managed%20Bullet%20Physics%20Library&amp;ProjectName=xnadevru"" rel=""nofollow"">BulletX</a> A c# port of Bullet, seems to be abandoned. </li>
</ul>
","226"
"How are voxel terrain engines made?","43087","","<p>A few days ago I found something called voxel terrains and I think that they're pretty cool.  But I don't know anything generating them. Do you model it in your modeling software or use something like a heightmap? I read on <a href=""http://en.wikipedia.org/wiki/Voxel"">wikipedia</a> that voxels are like 3d pixels or volumetric pixels.</p>

<p>After I make the voxel terrain, how can I take these voxels and make them  <strong>destroyable/diggable</strong>?</p>

<p><br />
I will pick the best answer based on:</p>

<ol>
<li><strong>code and algorithms.</strong> preferably based in C#</li>
<li><strong>explanations.</strong> I am a beginner with algorithms but I'm very familiar with object oriented programming</li>
<li><strong>step by step demonstrations.</strong> Not only concept but direction.</li>
<li><strong>diagrams/illustrations.</strong> No, not screenshots of other engines.</li>
</ol>

<p><br />
I know that this is a complicating subject. But, thanks for any help!</p>

<p>No, I'm not trying to make a minecraft clone.</p>

<hr>

<h2>Edit</h2>

<p>Thanks to everyone for your great help (especially Nick Wiggill)! <a href=""http://www.youtube.com/watch?v=Xt75w7cwKXo"">This</a> is what I managed to make (Work in progress).</p>
","<p><strong>To generate a voxel terrain</strong></p>

<p><strong>(a)</strong> A common method is to generate a heightmap using Perlin noise. A heightmap is basically a monochrome image representing different heights by the darkness or lightness of its pixels.</p>

<p><img src=""https://i.stack.imgur.com/XCvkZ.jpg"" alt=""enter image description here""></p>

<p>You'll look at individual pixels in this heightmap to create ""stacks"" of voxels up to different heights (z-axis) in different (x,y) locations, according to the brightness of that pixel in the heightmap image. Because a Perlin noise image is smooth (no sharp edges of light against dark), you will have smoothly rolling terrain as a result.</p>

<p><strong>(b)</strong> You can construct it incrementally by creating the landscape out of different polyhedra. Create a polyhedral vector shape that approximates the voxel shape you want. Using any 3D-point-in-polyhedron method (most often, point-in-convex-hull), check which points of your world grid fall within that polyhedral volume. For example, define a pyramid in space. After checking every point in the local region of your world space against that pyramidal volume, you will know which points fall within it, and you can set those cells as ""present"" meaning they become voxels rather than empty space. You now have a voxel pyramid in your space. You can continue to add shapes of any sort together, in this way, until you have formed a terrain.</p>

<p><strong>(c)</strong> (Really the same as <strong>b</strong>) Write a modelling tool. <a href=""http://www.youtube.com/watch?v=epwh1qJVoB8"" rel=""noreferrer"">Voxatron</a> show how this would look. This is just creating the voxel forms in a substitute world (the editor) and then importing these into your actual runtime game world. I believe <a href=""http://advsys.net/ken/voxlap.htm"" rel=""noreferrer"">Voxlap</a> had the first  open source editor for voxels. You can place individual voxels, or you can use a voxel ""brush"" with different shapes / volumes to draw voxels into your world.</p>

<hr>

<p><strong>What you'll need to construct your own voxel-based game</strong> </p>

<p>I include this section because the voxel road is not an easy one, at least not at present. Lately, a lot of research is once again being put into voxel engines by the big players, toward rendering and physics applications.</p>

<p><strong>Simplicity</strong> may be a problem, because dynamically constructing a world out of raw voxels is a procedural approach to world construction and this <strong>not inherently simple</strong>. So sorry, there are going to be a few technical terms here. Writing a voxel engine is a pretty serious undertaking and requires knowledge across multiple areas of game engine development, particularly in terms of spatial concepts, and this means understanding 3D vector math, matrices and basic calculus to some reasonable level.</p>

<p>Having said that, your ""generation of a voxel terrain"" requires a context in which to work, since voxel engines aren't exactly widespread. Lets proceed to a basic description of how a voxel engine works.</p>

<p>Voxels are the basic building blocks of your world. Their positions are defined by an integer-indexed 3D grid (array) rather than a continuous floating-point space (as used in vector-based 3D games). These will be the ""atoms"" of your world. They could be 3 feet high as in games like Minecraft, or they could be smaller than your virtual character's eye could actually see, unless clustered together in large numbers -- a bit more like molecules. There are two kinds:</p>

<ul>
<li>Cubic mesh based voxels (<a href=""http://www.youtube.com/watch?v=jNqtwGc-NRE&amp;feature=related"" rel=""noreferrer"">example</a>) -- these are a newer sort, used for simplicity and easily usable in conjunction with modern graphics tech. Used in games like MineCrat and Dungeon Keeper.</li>
<li>Point voxels (<a href=""http://www.youtube.com/watch?v=PwtKI_Cx6Dw&amp;feature=related"" rel=""noreferrer"">example</a>, <a href=""http://www.youtube.com/watch?v=TjmRPjnWJ5g"" rel=""noreferrer"">example</a>) -- the original voxel. Each is an individual, collidable point in space, although it may be surrounded by a spherical bounding volume. They are simpler, so you can have many more of them in your world, and you can thus make them smaller, which is generally favourable. Two games that used these were Comanche and the 1990s remake of Lords of Midnight.</li>
</ul>

<p>Either way, your approach to manipulating voxels in your world is much the same, as follows.</p>

<p>To construct and move objects in your world, you will need the mathematical tools mentioned above. For example, to create a wall: Construct a box of the appropriate dimensions in 3D space, using vectors. Use matrix math to transform your box to the rotation and position you desire in your 3d world (in continuous vector space). For a voxel engine, the additional step is to now use a 3D point-in-polyhedron algorithm to determine which of your voxels fall inside that rotated space.</p>

<p>Essentially, this is the way you would construct most objects in your world. Beyond that, you could write your own tools to ""model"" a character in the way you might in say, Maya or 3DS Max. But since you are modelling you character out of voxels instead of points, edges and faces, your methods will be substantially different. If you decided to then rotate these objects in your world, you would need to similarly use matrix transformations to do so.</p>

<p>Destructible terrain is as simple as either removing one voxel at a time according to some method of your choosing, or using CSG (Constructive Solid Geometry) operations on large volumes of voxels to remove them according to some predefined volume; for example, if shooting a laser beam through a rock, you might use a cylindrical volume to subtract the voxels here the beam is shooting through the rock. CSG is a relatively simple process using the 3D spatial grids which form your voxel world, and checking every cell in a section of a base grid (in this case the rock) against another grid (in this case, the laser beam)</p>

<p>In order to have material ""flows"" (as Vigil hinted at in his comment on sand), you will need to look into fluid dynamics and cellular automata. These were used by the author of Dwarf Fortress, Tarn Adams, in what is essentially also a voxel world (albeit the voxels are much larger in this case, comparable to Dungeon Keeper, the principle remains the same). These are cutting edge topics and not a necessity for voxel engines as defined, so I will leave this as a ""stub"" for your own research.</p>

<p>CSG and fluid dynamics bring me, lastly, to optimisation. Voxel engines currently in development almost exclusively make use of sparse voxel octrees (SVOs) which is a method of subdividing voxel space to varying resolutions, as evidenced <a href=""http://www.youtube.com/watch?v=4AYBm-9cBqs"" rel=""noreferrer"">in this video</a> showing off the upcoming Atomontage engine. Using octrees/SVOs is more of a necessity than an optimisation choice, because of the processing overheads involved in processing one massive, uniform grid. An octree is essentially an tree (directed acyclic graph) where every node has either 8 or zero child nodes depending on whether the space it represents contains any physical volumes. Diagrams showing how octrees subdivide space to form voxels are <a href=""http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter37.html"" rel=""noreferrer"">here</a>.</p>

<p>The best open source voxel implementation I know of is Ken Silverman's <a href=""http://advsys.net/ken/voxlap.htm"" rel=""noreferrer"">Voxlap Engine</a>, which was used for Voxelstein3D. It is written in C++, and implements CSG operations for terrain deformation.</p>
","16564"
"How did LoZ: A Link to the Past handle sub-tile collisions?","43021","","<p><em>The Legend of Zelda: A Link To The Past</em> is rendered with 16×16 tiles. How did they implement collision with tiles where only a quarter or half is occupied?</p>

<p>You can see such tiles in the cliff corners here:</p>

<p><img src=""https://i.stack.imgur.com/iGpPx.png"" alt=""screenshot from A Link To The Past, with tile grid overlaid""></p>

<p>Did they use a finer grid for collision detection, like four 8×8 tiles?  If so, how do the diagonally cut tiles work?</p>

<p>The corners of the tiles also seem ""round"": if Link walks into a tile's corner, he can keep on walking and automatically moves around it.  How is that done?</p>
","<p>Given the memory limitations of the SNES, the solution must be very simple.  </p>

<p>My guess is that they have another 16*16 grid that tells you how to handle collision in the tile. A tile can be:  </p>

<ul>
<li>Empty</li>
<li>Full (i.e. a square block collision)</li>
<li>Half-full-1 (a diagonal top-left to bottom-right line collision)</li>
<li>Half-full-2 (a diagonal top-right to bottom-left line collision)</li>
</ul>

<p>So, when Link moves, the game engine checks the surrounding tiles and applies the collision logic for them, according to the collision grid.</p>

<p>Of course, I didn't disassemble the Zelda sources, I'm just saying how I would do it.</p>

<p>And the ""roundness"" of the corners is just an illusion - some special code written to make them feel that way. Developers have been doing it since <a href=""http://www.gamasutra.com/view/feature/132330/the_pacman_dossier.php?page=4"" rel=""noreferrer"">the Pac-Man years</a>.</p>

<p>As you see, even though the maze's topography is both tiled and super simple (only squares), a technique like smooth turning can be simulated by creating an optical illusion (square tiles with round textures) and some clever code (beginning a turn before the end of the tile).</p>
","8338"
"Hexagonal grid/tiles tutorials","42980","","<p>Are there any platform or language agnostic (preferably step by step) tutorials regarding creating hexagonal grid based maps/games? I'm mainly interested in grid/tiles basics and not advanced game engine stuff. So far I have found these:</p>

<ul>
<li><a href=""http://www.codeproject.com/KB/graphics/hexagonal_part1.aspx"">Hexagonal grid for games and other projects</a></li>
<li><a href=""http://www.gdreflections.com/2011/02/hexagonal-grid-math.html"">Hexagonal grid math</a></li>
</ul>
","<p>I have been working on a hex tile game and found these tutorials useful:</p>

<ul>
<li><a href=""http://www.gamedev.net/page/resources/_/reference/programming/sweet-snippets/coordinates-in-hexagon-based-tile-maps-r1800"">Coordinates in Hexagon-Based Tile Maps</a></li>
<li><a href=""http://www.gamedev.net/page/resources/_/reference/programming/isometric-and-tile-based-games/298/isometric-n-hexagonal-maps-part-i-r747"">Isometric 'n Hexogonal Maps Part I</a></li>
<li><a href=""http://www.gamedev.net/page/resources/_/reference/programming/isometric-and-tile-based-games/298/isometric-r748"">Isometric 'n Hexogonal Maps Part II</a></li>
<li><a href=""http://forums.adobe.com/message/3603631"">Drawing a Hex Grid in Illustrator</a> (for designing maps)</li>
</ul>

<p>Good luck with your project!</p>
","15900"
"Random map generation","42888","","<p>I'm starting/started a 2D tilemap RPG game in Java and I want to implement random map generation. I have a list of different tiles, (dirt/sand/stone/grass/gravel etc) along with water tiles and path tiles, the problem I have is that I have no idea where to start on generating a map randomly.</p>

<p>It would need to have terrain sections (Like a part of it will be sand, part dirt, etc.) Similar to how Minecraft is where you have different biomes and they seamlessly transform into each other. Lastly I would also need to add random paths into this as well going in different directions all over the map.</p>

<p>I'm not asking anyone to write me all the code or anything, just piont me into the right direction please.</p>

<p>tl;dr - Generate a tile map with biomes, paths and make sure the biomes seamlessly go into each other.</p>
","<p>Among the many other related questions on the site, there's an often linked article for map generation: <a href=""http://www-cs-students.stanford.edu/~amitp/game-programming/polygon-map-generation/"" rel=""noreferrer"">Polygonal Map Generation for Games</a> you can glean some good strategies from that article, but it can't really be used as is.</p>

<p>While not a tutorial, there's <a href=""http://www.gamasutra.com/view/feature/3549/interview_the_making_of_dwarf_.php?page=7"" rel=""noreferrer"">an article</a> on how Dwarf fortress world maps are generated. Basically you generate multiple layers of noise, for height, moisture, temperature, salinity. Then you'd use something like this:</p>

<p><img src=""https://i.stack.imgur.com/s8LS6.gif"" alt=""enter image description here""></p>

<p>Or this</p>

<p><img src=""https://i.stack.imgur.com/IJbAc.jpg"" alt=""enter image description here""></p>

<p>to generate biomes based on the layers of noise you produced before. Typically this gives a fairly smooth transition between biomes and the transitions are logical. 
I also modify the moisture and temperature maps based on elevation. This naturally generates a ""timber line"" and produces rocky mountains with snowy caps.</p>

<p>I'm using this strategy my game and it produces maps like this very quickly:</p>

<p><img src=""https://i.stack.imgur.com/omu1b.png"" alt=""enter image description here""></p>

<p>Additionally, you can see me scroll through a few more maps at the beginning of <a href=""http://youtu.be/svhkiFc-0pI"" rel=""noreferrer"">this video</a>.</p>

<p>And here's some more to get you started:</p>

<p><a href=""https://gamedev.stackexchange.com/questions/18735/how-can-i-create-a-random-world-in-a-tile-engine?rq=1"">How can I create a random &quot;world&quot; in a tile engine?</a></p>

<p><a href=""https://gamedev.stackexchange.com/questions/15775/how-can-i-identify-feature-regions-in-a-procedurally-generated-world?rq=1"">How can I identify feature regions in a procedurally generated world?</a></p>

<p><a href=""https://gamedev.stackexchange.com/questions/5224/how-do-i-create-tileable-solid-noise-for-map-generation?rq=1"">How do I create tileable solid noise for map generation?</a></p>
","31245"
"How to move gameobject with touch on Android","42753","","<p>I'm trying to make a game where you control a character via touch on Android devices.</p>

<p>The player will have two degrees of movement. </p>

<p>When you touch the touch screen and move your finger, the game object should move to your finger's location and follow your finger as you move it.</p>

<p>Here is an example of what I'm trying to do: <a href=""http://www.youtube.com/watch?v=OoqRC8QptzM#t=01m01s"">http://www.youtube.com/watch?v=OoqRC8QptzM#t=01m01s</a> (@ 1:02).</p>

<p>I already know I need to use Input.touches.</p>

<p>I've tried using Transform.translate and Vector3.Lerp, neither gave me the results I wanted. </p>

<p>Here is some of the code I've tried using:</p>

<pre><code>#pragma strict

var speed : float = 1;

function Start () {

}

function Update () {
    if (Input.touchCount &gt; 0 &amp;&amp; 
        Input.GetTouch(0).phase == TouchPhase.Moved) {


        // Get movement of the finger since last frame
        var touchDeltaPosition:Vector2 = Input.GetTouch(0).deltaPosition;

        var touchPosition:Vector3;

        touchPosition.Set(touchDeltaPosition.x, 
                           transform.position.y, 
                           touchDeltaPosition.y);


        // Move object across XY plane
        transform.position = Vector3.Lerp(transform.position,
                                                touchPosition, 
                                                Time.deltaTime*speed);
    }

}
</code></pre>
","<p>I think you need to translate screen to world space. </p>

<p><a href=""http://docs.unity3d.com/Documentation/ScriptReference/Camera.ScreenToWorldPoint.html"" rel=""nofollow"">Camera.ScreenToWorldPoint</a></p>
","45958"
"What are atan and atan2 used for in games?","42750","","<p>I am having some trouble understanding <code>Math.tan()</code> and <code>Math.atan()</code> and <code>Math.atan2()</code>.</p>

<p>I have basic knowledge of trigonmetry but the usage of SIN, COS, and TAN etc for game development is very new to me.</p>

<p>I am reading on some tutorials and I see that by using tangent we can get the angle in which one object needs to be rotated by how much to face another object for example my mouse. So why do we still need to use atan or atan2?</p>
","<p>The tangent formula is this:</p>

<p><code>tan(angle) = opposite/adjacent</code></p>

<p>Refer to this drawing:</p>

<p><img src=""https://i.stack.imgur.com/awfKB.png"" alt=""Diagram of a right-angled triangle, with an angle theta and its opposite and adjacent sides marked""></p>

<p>Where <code>a</code> is the adjacent side, <code>o</code> is the opposite side and <code>theta</code> is the angle. Similarly, sine and cosine are sin(ang)=o/h and cos(ang)=a/h where <code>h</code> is the long side: <a href=""http://www.mathwords.com/s/sohcahtoa.htm"">http://www.mathwords.com/s/sohcahtoa.htm</a></p>

<p>Meanwhile <code>atan</code> (short for <em>arc-tangent</em>, also known as the <em>inverse tangent</em>) is the reverse of <code>tan</code>, like so:</p>

<p><code>atan(opposite/adjacent) = angle</code></p>

<p>Thus, if you know the values of both the opposite and adjacent sides (for example, by subtracting the object's coordinates from the mouse coordinates) you can get the value of the angle with <code>atan</code>.</p>

<p>In game development though, it can happen fairly often that the adjacent side is equal to 0 (e.g. the x coordinate of a vector being 0). Remembering that <code>tan(angle) = opposite/adjacent</code> the potential for a disastrous divide-by-zero error should be clear. So a lot of libraries offer a function called <code>atan2</code>, which lets you specify both the <code>x</code> and <code>y</code> parameters, to avoid the division by zero for you and give an angle in the right quadrant.</p>

<p><img src=""https://i.stack.imgur.com/xQiWG.png"" alt=""atan2 diagram""></p>

<p>(diagram courtesy of gareth, please vote up his answer too)</p>

<hr>

<p>The use of trigonometry in game development is pretty common, especially with vectors, but usually libraries hide the trigonometry work for you. You can use sin/cos/tan for a lot of tasks which involve geometric manipulations to find a value from a triangle. All you need is 3 values (side lengths / angle values) to find the other values of a rectangle triangle, so it's quite useful.</p>

<p>You can even use the ""cycling"" nature of the sine and cosine functions for special behaviors in a game, e.g. I've seen cos/sin used a lot to make an object turn around an other one.</p>
","14603"
"What things should an indie game developer never do?","42686","","<p>What are some of the biggest - and better yet: insidious and unexpected - mistakes that indie game developers make? Especially when making the transition from hobbyist to full-time indie?</p>
","<p>One of the major pitfalls is focusing too much on developing the framework / tools / engine, and too little about making the actual game.</p>

<p>You risk to get all entangled up into that and to lost focus. Never forget you are first and foremost making a game not making a middle-ware component.</p>

<p>i.e. You should not start by coding the math library but instead by figuring out how to make the game entertaining.</p>
","766"
"Blender: How to ""meshify"" an object I made from Bezier curves","42497","","<p>I made a star shape using Bezier curves, and extruded it (see pic below):</p>

<p><img src=""https://i.stack.imgur.com/A4uql.png"" alt=""enter image description here""></p>

<p>What I want to do is give it a rounder look - not just around the edges by using beveling. I want it to kind of look like this (well, that shape anyway):</p>

<p><img src=""https://i.stack.imgur.com/4hxkk.png"" alt=""enter image description here""></p>

<p>How would I go about doing this? Please keep in mind that I am extremely new to Blender.</p>

<p>I thought that I could somehow turn this star into those default shapes that have tonnes of squares which I could pull out, and apply a mirror to it so that the same thing happens on both sides. I really don't know how to do it, and would appreciate your help.</p>
","<p><code>ALT+C</code> will help you to convert a path to a mesh, then select a loop like in figure</p>

<p><img src=""https://i.stack.imgur.com/llf1M.jpg"" alt=""enter image description here""></p>

<p><code>E</code> for extruding and right after press <code>S</code> to scale and move the cursor to the center of the star.</p>

<p>Now you get how to extrude the shape to the center, to give a vertical extrusion just press <code>E</code> and right after <code>G</code> to grab and then the axis where you want to move the selection like <code>Z</code>.</p>

<p>To create the final point for closing the center of the star just press <code>E</code> again with the final edge loop selected and press <code>ALT+M</code> to collapse the selection to the center of the shape.</p>

<p>With this you can achieve what you want to do.</p>

<hr>

<p>this star is simply generated through a script:</p>

<ul>
<li>go in the User Preferences panel</li>
<li>Addons > Add Mesh</li>
<li>Enable <code>Extra Objects</code></li>
<li>just exit or <em>Save as default</em> as you wish</li>
<li><code>SHIFT+A</code> in the 3D viewport</li>
<li>Mesh > Extra Objects > Basic Objects > Star</li>
</ul>
","35774"
"Is it unethical to make a game AI that is secretly non-competitive?","42013","","<p>In several games the AI is designed to give the player an easy time without their knowledge. This can be having a 0% chance to hit the first time you appear, enemy letting you sneak up on them by not turning around, or the lowering of difficulty when the player is hurt or has restarted several times.</p>

<p>I would be offended if at the end of a board game or sport I was told that a human had not tried their hardest.</p>

<p>Does the same ethics exist for an AI?</p>

<p>edit
As in the title, my main concern was <strong>keeping the handicap hidden</strong> from the player, for example, when playing a shooter it is reasonable to expect the player knows the AI has an artificial reaction time and poor aim but my question was about games that hide things such as enemies not using the best weapon or lowering their difficulty when the player is inured.</p>
","<p>What do you want to accomplish with your AI?</p>

<p>If your game is trying to tell a <em>story</em>, then it is reasonable to have the AI adjust so that you get the story you want to tell.</p>

<p>If you want the player to have a <em>sense of accomplishment</em> from overcoming an obstacle or beating an opponent, making the controlling AI throw the game takes away from that &mdash; you need the AI to actually be the threat it's presented as.</p>
","149770"
"Why are MVC & TDD not employed more in game architecture?","41744","","<p>I will preface this by saying I haven't looked a huge amount of game source, nor built much in the way of games.</p>

<p>But coming from trying to employ 'enterprise' coding practices in web apps, looking at game source code seriously hurts my head:
""What is this view logic doing in with business logic? this needs refactoring... so does this, refactor, refactorrr""</p>

<p>This worries me as I'm about to start a game project, and I'm not sure whether trying to mvc/tdd the dev process is going to hinder us or help us, as I don't see many game examples that use this or much push for better architectural practices it in the community.</p>

<p>The following is an extract from a <a href=""http://gamesfromwithin.com/prototyping-youre-probably-doing-it-wrong"">great article on prototyping games</a>, though to me it seemed exactly the attitude many game devs seem to use when writing production game code:</p>

<blockquote>
  <p>Mistake #4: Building a system, not a game</p>
  
  <p>...if you
  ever find yourself working on
  something that isn’t directly moving
  your forward, stop right there. As
  programmers, we have a tendency to try
  to generalize our code, and make it
  elegant and be able to handle every
  situation. We find that an itch
  terribly hard not scratch, but we need
  to learn how. It took me many years to
  realize that it’s not about the code,
  it’s about the game you ship in the
  end.</p>
  
  <p>Don’t write an elegant game component
  system, skip the editor completely and
  hardwire the state in code, avoid the
  data-driven, self-parsing, XML
  craziness, and just code the damned
  thing.</p>
  
  <p>... Just get stuff on the screen as
  quickly as you can.</p>
  
  <p>And don’t ever, ever, use the argument
  “if we take some extra time and do
  this the right way, we can reuse it in
  the game”. EVER.</p>
</blockquote>

<p>is it because games are (mostly) visually oriented so it makes sense that the code will be weighted heavily in the view, thus any benefits from moving stuff out to models/controllers, is fairly minimal, so why bother?</p>

<p>I've heard the argument that MVC introduces a performance overhead, but this seems to me to be a premature optimisation, and that there'd more important performance issues to tackle before you worry about MVC overheads (eg render pipeline, AI algorithms, datastructure traversal, etc).</p>

<p>Same thing regarding TDD. It's not often I see games employing test cases, but perhaps this is due to the design issues above (mixed view/business) and the fact that it's difficult to test visual components, or components that rely on probablistic results (eg operate within physics simulations). </p>

<p>Perhaps I'm just looking at the wrong source code, but why do we not see more of these 'enterprise' practices employed in game design? Are games really so different in their requirements, or is a people/culture issue (ie game devs come from a different background and thus have different coding habits)? </p>
","<p>As the quote says, many programmers make the mistake of (trying to) build a system, not a game. Typically that system keeps ballooning out of control until it's so complex that <em>theoretically</em> it can handle anything, but in practicality all you have is a big bundle of code. Or more often, before you even get to a working stage, you are so tangled up in code that doesn't run that you lose focus (if you had any to begin with) and motivation (since nothing is truly working).</p>

<p>Prototypes and iteration tend to work much better. In the end, a great design might come out of it, but more often something more simple and refined comes out of it. <a href=""http://en.wikipedia.org/wiki/KISS_principle"" rel=""nofollow noreferrer"">KISS</a> and <a href=""http://en.wikipedia.org/wiki/YAGNI"" rel=""nofollow noreferrer"">YAGNI</a> come to mind.</p>

<p>I personally believe there needs to be a balance. If there's a core mechanic of your game, work on it. You still need to iterate, but you do need to refine it. Hint: organization of your code is not a core mechanic of your game.</p>

<p>Case in point: <a href=""http://en.wikipedia.org/wiki/Peggle"" rel=""nofollow noreferrer"">Peggle</a>, by PopCap Games. A core mechanic of the game is the ball physics. They perfected it! I'm sure they spent quite a lot of time making sure it was absolutely perfect, because it is what makes the game. But at the same time, I can totally picture an early prototype of their game that maybe just draws sprites to the screen and does some type of more primitive collision detection and bouncing, just to see if the game idea is fun. Then once they found out that shooting a ball and watching it bounce can actually be fun, they refined the bouncing of the ball. <sub>(this is all just speculation, of course)</sub></p>

<p>It also depends on your technical requirements, which you should nail down early on (not your game design, just the technical requirements). The platform that your game runs on should not change, or if it should be allowed to change, you need to know exactly the extent that you plan to allow it to change, no more and no less. Design on that. If you're developing a game for OpenGL, and you don't care about DirectX, then really, don't care about it. That means that if it's more convenient for you to have each entity draw itself and not worry about Factories and other design patterns like that, then do that. It's okay, because it meets the requirements. You should not have to change it later, despite what you tell yourself. And really, worst case scenario? Refactor later. It takes time later but it lets you focus on the <strong>now</strong>, getting a working game on one platform even if it means it can't simultaneously and automatically run on your toaster.</p>

<p>Test driven design, however, is a more opinionated topic. I am of the belief that game developers should do more of it. I also think game developers have some of the most rigorous, tight schedules, and they think they can't afford to spend time on TDD when they just want to get a game going. Also, again with the motivation, TDD is a lot slower and you get to see a lot less of a functioning game (in the beginning at least). This can have serious negative effects on programmer motivation.</p>

<p>I think it's also just a general lack of knowledge and practice. I don't think TDD is prevalent in other areas either, but like agile development, I think it's spreading. You might say it's ahead of its time (or maybe not, as the case may be years from now). More important than TDD is ""RDD"" - Requirements Driven Development. <sub>I just made that up.</sub> What is your goal? To make a game. Everything else comes second. If you can prove that TDD increases productivity and helps teams reach deadlines, then don't you think everyone would be using it? And maybe that's the case. But right now, our industry is more competitive than ever, there are harder and sooner deadlines, and stuff just needs to work. Construction workers don't build scaffolding first; they lay a foundation, then they raise some walls and floors, and only then do they build selective bits of scaffolding to do specific tasks which scaffolding makes more convenient. I think the same applies to software development.</p>

<p>Sorry for such a long post. I hope you've gained some bits of wisdom from it. I am just a student, talking about my observations, with very limited industry experience but a lot of reading from industry experts. So take my words with a grain of salt.</p>

<p>And hey, do what you think will work. You can always change it or scrap it and start over. That's the cool thing about any form of engineering; if at first you don't succeed, try something different. (or something like that :-P ) You're not pouring concrete; software is malleable.</p>

<hr>

<p>By the way, I've been asking this same type of question and researching these types of design principles for some time. Here are some questions, both here and in Stack Overflow, that you might find relevant:</p>

<ul>
<li><a href=""https://stackoverflow.com/questions/555283/how-can-you-organize-the-code-for-a-game-to-fit-the-mvc-pattern"">""How can you organize the code for a game to fit the MVC pattern?""</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/2921/how-to-design-a-games-software-such-that-it-is-easy-to-unit-test"">""How to design a game's software such that it is easy to unit test?""</a></li>
<li><a href=""https://stackoverflow.com/questions/1901251/component-based-game-engine-design"">""Component based game engine design""</a></li>
<li><a href=""https://stackoverflow.com/questions/2752438/any-good-tutorials-or-resources-for-learning-how-to-design-a-scalable-and-compon"">""Any good tutorials or resources for learning how to design a scalable and “component” based game 'framework'?""</a></li>
<li><a href=""https://stackoverflow.com/questions/2756655/seperation-of-game-and-rendering-logic"">""Seperation of game- and rendering logic""</a></li>
<li><a href=""https://stackoverflow.com/questions/2418845/is-unit-testing-viable-in-game-programming"">""Is unit testing viable in game programming?""</a></li>
<li><a href=""https://stackoverflow.com/questions/2210026/is-the-mvc-design-pattern-used-in-commercial-computer-games"">""Is the MVC design pattern used in commercial computer games""</a></li>
<li><a href=""https://stackoverflow.com/questions/619634/is-test-driven-development-a-normal-approach-in-game-development"">""Is test driven development a normal approach in game development?""</a></li>
<li><a href=""https://stackoverflow.com/questions/1992194/do-any-of-you-use-scrum-for-game-development"">""Do any of you use Scrum for game development?""</a></li>
<li><a href=""https://stackoverflow.com/questions/1044998/architecture-for-game-to-couple-or-not-to-couple"">""Architecture for Game - To couple or not to couple?""</a></li>
<li><a href=""https://stackoverflow.com/questions/1145427/oo-game-design-question"">""OO game design question""</a></li>
</ul>
","3427"
"Why are textures always square powers of two? What if they aren't?","41415","","<p>Why are the resolution of textures in games always a power of two (128x128, 256x256, 512x512, 1024x1024, etc.)? Wouldn't it be smart to save on the game's file size and make the texture exactly fit the UV unwrapped model?</p>

<p>What would happen if there was a texture that was not a power of two?</p>

<p>Would it be incorrect to have a texture be something like 256x512, or 512x1024? Or would this cause the problems that non-power-of-two textures may cause?</p>
","<blockquote>
  <p>Why are the resolution of textures in games always a power of two
  (128x128, 256x256, 512x512, 1024x1024, etc.)?</p>
</blockquote>

<p>As Byte56 implied, the ""power of two"" size restrictions are (were) that each dimension must be, independently, a power of two, not that textures must be square <em>and</em> have dimensions which are a power of two.</p>

<p>However, on modern cards and which modern graphics APIs, this ""restriction"" has been relaxed significantly such that textures dimensions can be, within reason, just about anything you like. However:</p>

<blockquote>
  <p>Wouldn't it be smart to save on the game's file size and make the
  texture exactly fit the UV unwrapped model? What would happen if there
  was a texture that was not a power of two?</p>
</blockquote>

<p>By ensuring the texture dimensions are a power of two, the graphics pipeline can take advantage of optimizations related to efficiencies in working with powers of two. For example, it can be (and absolutely was several years back before we had dedicated GPUs and extremely clever optimizing compilers) faster to divide and multiply by powers of two. Working in powers of two also simplified operations within the pipeline, such as computation and usage of mipmaps (a number that is a power of two will always divide evenly in half, which means you don't have to deal with scenarios where you must round your mipmap dimensions up or down).</p>

<p>It's true you ""waste"" some space this way, but the extra space is usually worth it for the tradeoff in render performance. Additionally there are techniques, such as compression or packing multiple images into a single texture space that can alleviate some of the storage waste.</p>
","26189"
"How'd they do it: Millions of tiles in Terraria","40726","","<p>I've been working up a game engine similar to <a href=""http://terraria.org"">Terraria</a>, mostly as a challenge, and while I've figured out most of it, I can't really seem to wrap my head around how they handle the millions of interactable/harvestable tiles the game has at one time. Creating around 500.000 tiles, that is 1/20th of what's possible in <a href=""http://terraria.org"">Terraria</a>, in my engine causes the frame-rate to drop from 60 to around 20, even tho I'm still only rendering the tiles in view. Mind you, I'm not doing anything with the tiles, only keeping them in memory.</p>

<p><strong>Update</strong>: Code added to show how I do things.</p>

<p>This is part of a class, which handles the tiles and draws them. I'm guessing the culprit is the ""foreach"" part, which iterates everything, even empty indexes.</p>

<pre><code>...
    public void Draw(SpriteBatch spriteBatch, GameTime gameTime)
    {
        foreach (Tile tile in this.Tiles)
        {
            if (tile != null)
            {
                if (tile.Position.X &lt; -this.Offset.X + 32)
                    continue;
                if (tile.Position.X &gt; -this.Offset.X + 1024 - 48)
                    continue;
                if (tile.Position.Y &lt; -this.Offset.Y + 32)
                    continue;
                if (tile.Position.Y &gt; -this.Offset.Y + 768 - 48)
                    continue;
                tile.Draw(spriteBatch, gameTime);
            }
        }
    }
...
</code></pre>

<p>Also here is the Tile.Draw method, which could also do with an update, as each Tile uses four calls to the SpriteBatch.Draw method. This is part of my autotiling system, which means drawing each corner depending on neighboring tiles. texture_* are Rectangles, are set once at level creation, not each update.</p>

<pre><code>...
    public virtual void Draw(SpriteBatch spriteBatch, GameTime gameTime)
    {
        if (this.type == TileType.TileSet)
        {
            spriteBatch.Draw(this.texture, this.realm.Offset + this.Position, texture_tl, this.BlendColor);
            spriteBatch.Draw(this.texture, this.realm.Offset + this.Position + new Vector2(8, 0), texture_tr, this.BlendColor);
            spriteBatch.Draw(this.texture, this.realm.Offset + this.Position + new Vector2(0, 8), texture_bl, this.BlendColor);
            spriteBatch.Draw(this.texture, this.realm.Offset + this.Position + new Vector2(8, 8), texture_br, this.BlendColor);
        }
    }
...
</code></pre>

<p>Any critique or suggestions to my code is welcome.</p>

<p><strong>Update</strong>: Solution added.</p>

<p>Here's the final Level.Draw method. The Level.TileAt method simply checks the inputted values, to avoid OutOfRange exceptions.</p>

<pre><code>...
    public void Draw(SpriteBatch spriteBatch, GameTime gameTime)
    {
        Int32 startx = (Int32)Math.Floor((-this.Offset.X - 32) / 16);
        Int32 endx = (Int32)Math.Ceiling((-this.Offset.X + 1024 + 32) / 16);
        Int32 starty = (Int32)Math.Floor((-this.Offset.Y - 32) / 16);
        Int32 endy = (Int32)Math.Ceiling((-this.Offset.Y + 768 + 32) / 16);

        for (Int32 x = startx; x &lt; endx; x += 1)
        {
            for (Int32 y = starty; y &lt; endy; y += 1)
            {
                Tile tile = this.TileAt(x, y);
                if (tile != null)
                    tile.Draw(spriteBatch, gameTime);

            }
        }
    }
...
</code></pre>
","<p>Are you looping through all 500,000 tiles when you're rendering?  If so, that's likely going to cause part of your problems.  If you loop through half a million tiles when rendering, and half a million tiles when performing the 'update' ticks on them, then you're looping though a million tiles each frame.</p>

<p>Obviously, there's ways around this.  You could perform your update ticks while also rendering, thus saving you half the time spent looping through all those tiles.  But that ties your rendering code and your update code together into one function, and is generally a <em>BAD IDEA</em>.</p>

<p>You could keep track of the tiles that are on the screen, and only loop through (and render) those.  Depending on things like the size of your tiles, and screen size, this could easily cut down the amount of tiles you need to loop through, and that would save quite a bit of processing time.</p>

<p>Finally, and perhaps the best option (most large world games do this), is to split your terrain into regions.  Split the world into chunks of, say, 512x512 tiles, and load/unload the regions as the player gets close to, or further away from, a region.  This also saves you from having to loop through far away tiles to perform any sort of 'update' tick.</p>

<p>(Obviously, if your engine doesn't perform any sort of update tick on tiles, you can ignore the part of this answers that mentions those.)</p>
","15616"
"Tools for creating 2d tile based maps","40497","","<p>What are some tools I can use to create 2d tile based maps? </p>

<p>Please provide the information below, and try to limit to one tool per answer.</p>

<ul>
<li>Name</li>
<li>Link to website</li>
<li>General features</li>
<li>Export format</li>
<li>Anything else you deem noteworthy</li>
</ul>
","<p><a href=""http://www.mapeditor.org/"">Tiled Map Editor</a></p>

<p>From the website:</p>

<blockquote>
  <ul>
  <li>General purpose tile map editor with XML-based map format</li>
  <li>Supports orthogonal and isometric maps</li>
  <li>Custom objects can be placed with pixel precision</li>
  <li>Full undo/redo and copy/paste support</li>
  <li>Add custom properties to tiles, layers, objects or the map</li>
  <li>Automatically reloads tilesets when changed externally</li>
  <li>Resize or offset your tile map later as needed</li>
  <li>Efficient tile editing tools like stamp and fill brushes</li>
  <li>Supports input/output plugins to open and save files in custom formats</li>
  </ul>
</blockquote>
","234"
"How to get and use delta time","40319","","<p>I have mice looking and walking in my game, but they are very slow and hard to use. I think it's because I'm using fixed speed. I heard that in big projects developers use delta time. How do I calculate delta time in glut? How do I calculate speed using delta time?</p>
","<p>The ""delta time"" used to be the time elapsed between two frame updates (but it can also be used in other contexts; this is usually the result of a time subtraction).</p>

<p>You can get the delta time in glut using the <a href=""http://www.opengl.org/documentation/specs/glut/spec3/node70.html"" rel=""nofollow noreferrer"">glutGet</a> method and the GLUT_ELAPSED_TIME parameter, plus some operations.<br><br> The following line returns the number of milliseconds since glutInit was called (or first call to glutGet(GLUT_ELAPSED_TIME)) :</p>

<pre><code>int timeSinceStart = glutGet(GLUT_ELAPSED_TIME);
</code></pre>

<p>So if you register the current timeSinceStart at each rendering loop, you can know the deltaTime by subtracting the old one to the new one.</p>

<pre><code>int oldTimeSinceStart = 0;

while( ... )
{
     int timeSinceStart = glutGet(GLUT_ELAPSED_TIME);
     int deltaTime = timeSinceStart - oldTimeSinceStart;
     oldTimeSinceStart = timeSinceStart;

     //... stuff to update using deltaTime
}
</code></pre>

<hr>

<p>You can also do it almost the same way, using the C/C++ <a href=""http://www.cplusplus.com/reference/clibrary/ctime/"" rel=""nofollow noreferrer"">ctime library</a> with <a href=""http://www.cplusplus.com/reference/clibrary/ctime/clock/"" rel=""nofollow noreferrer"">clock()</a> and the macro constant expression <a href=""http://www.cplusplus.com/reference/clibrary/ctime/CLOCKS_PER_SEC/"" rel=""nofollow noreferrer"">CLOCKS_PER_SEC</a> that specifies the relation between a clock tick and a second.</p>

<hr>

<p>Basically, you can use deltaTime to update your movements in ratio to this elapsed time instead of using a fixed time value. This way, the movement speed of your character should be almost the same if your program runs at 60 fps or if it runs at 10 fps.</p>

<p><br>Here is a small example: suppose you want to move something by 10 units each second on the x axis. You could do something like this (if deltaTime use milliseconds indeed).</p>

<pre><code>Position.x += 10/1000 * deltaTime;
</code></pre>

<p>This way, whether your program updated 2 times or 100 times, 1 second later the position should be almost the same, and the game-play is less impacted by the low fps of a small computer than if it use fixed values.</p>

<ul>
<li><p>With fixed values ==> low fps = less updates = slow movements whereas high fps = more updates = very fast movements.</p></li>
<li><p>With deltaTime ==> ""almost"" the same movements.</p></li>
</ul>

<hr>

<p>Finally, you should read <a href=""https://gamedev.stackexchange.com/questions/1589/fixed-time-step-vs-variable-time-step"">Fixed time step vs Variable time step</a> on  gamedev.stackexchange.</p>
","13011"
"What is the most serious limitation of Unity?","40163","","<p>Having read <a href=""https://gamedev.stackexchange.com/questions/15154/unreal-engine-3-vs-id-tech-3-vs-unity"">this heated question</a> about Unity vs. UDK vs. ID something, I'm curious to know: what the <strong>repeatedly-hit, most crippling limitation(s) of Unity?</strong></p>

<p>In order to keep this question non-subjective, again, I'm talking about the top repeated offender(s) of Unity are. This is something that, as a Unity user, you really wish someone had told you about before you started using it.</p>

<p>I have heard from someone that Unity does not deal well with version control, since it generates a lot of binary files (which are un-diffable). This, to me, is not really crippling as I work alone.</p>

<p>Thoughts? </p>
","<p>Let me preface this that the Unity guys have been pretty good about hearing the major qualms that their community faces and eventually gets around to promising to improve things.  There are also a lot of issues that only come up on certain platforms or are a matter of personal preference or specific issues of the game you're working on.</p>

<p>That being said:</p>

<p>1) Poor source control integration and large team tools.  As you mentioned, lots of non-diffable binary files.  The editor ignores the read only flag for scene files.  The actual files you have to check in isn't immediately obvious.  Some of this is being rectified in 3.5 with SVN and P4 integration.  There is also promises of text based scene formats. UPDATE: The text-based scene format is now available in the Pro version of Unity. See <a href=""http://docs.unity3d.com/Documentation/Manual/TextualSceneFormat.html"">here</a>.</p>

<p>2) Slow, programmer centric UI tools.  Each widget is its own draw call, which has a lot of overhead on mobile platforms.  There isn't the concept of things like panels with animations and all that other fancy stuff that makes a UI feel good without rolling it yourself.  There is a promise of a new UI system on the roadmap (3.6?).  There are some third party tools but they're not great.</p>

<p>3) Really rudimentary particle editing.  They're promising a new curve-based system in 3.5, though. UPDATE: This curve-based system, called Shuriken, is now available. See <a href=""http://unity3d.com/unity/quality/special-effects"">here</a>. </p>

<p>4) You can't nest prefabs.  A small issue but when you're used to working with the prefab system and all the power it provides you, it can get frustrating.  This has been promised but no specific date. UPDATE: You now can nest prefabs.</p>

<p>5) Next to impossible to get an iOS game under the over the air limit.  The binary alone is like 8 megs in a best case scenario.  This isn't something that's easily fixable.</p>

<p>6) Null reference exceptions crash platforms that don't allow JIT compiled code.  On standalone or web versions, NREs are caught.  It's still an uncaught exception, but at least the application will try to continue running.  On iOS, it crashes the device.  You can put it in debug mode and catch some types of exceptions, but performance suffers.</p>

<p>7) When working on a multiplatform game, whenever you switch build targets you have to reimport everything and that takes a long time.  I've worked around this by actually just having multiple copies of the project on disk.  Apparently there's an imported asset server coming in 3.5.  </p>
","18426"
"How can I convert a 3ds Max .max to a Cinema 4D .c4d and maintain the animation?","40116","","<p>I have recently purchased this asset from the3dstudio.com:</p>

<p><a href=""http://www.the3dstudio.com/product_details.aspx?id_product=193089"" rel=""nofollow"">http://www.the3dstudio.com/product_details.aspx?id_product=193089</a></p>

<p>It has a corrupt .3ds file available, and a .max (as well as what appears to be a broken .dfx and a textureless and animation-less .obj).</p>

<p>I wrote the site administrator, who attempted to make me a new .3ds file from his master copy (I'm assuming the working .max file) but said:</p>

<p>""The .3ds export doesn't seem to be completed so normally we would just re-export it but I can't get a good export on this model. Only the low-poly control mesh wants to export so I emailed the author to see if they can get us a better file and will let you know as soon as they reply.</p>

<p>""With any non-max format you will not have any rigging in the model as common formats (3ds, dxf, obj, etc) do not support things like rigging (which are program specific) so any export to 3DS (and thus C4D) would just be the geometry, textures, and basic materials.""</p>

<p>So it was my understanding based on my very limited knowledge and this e-mail I got that none of the formats that I'd be able to get into Cinema 4D would be able to carry animation data. Then I saw this Elance job posting:</p>

<p><a href=""http://www.elance.com/j/convert-3d-studio-max-animation-cinema-4d/19612175/"" rel=""nofollow"">http://www.elance.com/j/convert-3d-studio-max-animation-cinema-4d/19612175/</a></p>

<p>Now obviously that's not, like, internet canon: I realize just because there was a listing on some site somewhere that made it seem like it was possible doesn't make it true. But it looks like that team in India was willing to do it for sixty bucks, which makes it hard to believe it could be that in-depth of a process. But maybe that's my naïveté about either 3D or American to Indian currency conversion rates or both.</p>

<p>So, is this possible?</p>
","<p>Cinema 4d <a href=""http://www.maxon.net/es/products/general-information/general-information/product-comparison.html"" rel=""nofollow"">seems to support</a> FBX format. Even the cheapest C4D. You might be using a very old Cinema, thugh. Check if you can import FBX.</p>

<p>FBX is a format that does support perfectly bones, weights, animation. So, all you need to do is get someone that opens in Max that *.max file you have, and export as FBX. Then you could import into your Cinema4D, and have it ready.</p>

<p>This is not 100% safe path, in the sense that always there can be issues, that is, when importing an FBX file into any package. But it should work with some settings tweaking: FBX is a format thought for exchange.</p>

<p>So, possible solutions (go with whichever bellow, but I'd go trying in the listed order...):</p>

<ul>
<li><p>Ask the The3DStudio crew, which have fame to be eficient and serious, to export for you in FBX format (considering the initial corrupt *.3ds file problem, might be a kind detail...though dunno if is legally allowed by the file author) , is easy for them and would have use very little time unless appears some big issue.</p></li>
<li><p>Have one friend having a Max license open the max file and simply got to menu, export fbx (it comes by default, needs no plugin) </p></li>
<li><p>Have those guys from elance take care as well of the C4D import, so you might ensure no issues, if they know their stuff.</p></li>
</ul>

<p>Note: Sometimes is not enough to play with FBX i/o settings, and you need to try a pair of FBX versions, usually 5.x or 6.x. I don't know which is the current number. I tested to be safer to export in default Max FBX, the one that comes included, than installing as a plugin. Anyway, sometimes older versions work better with older packages.</p>

<p>About the 60$ of the third option, I guess they charge that for in case some issue arises, as the actual thing is open, export, import. Just that there might be fixing involved. Sometimes really easy ones, other times can even make it impossible, depending on package versions, status of original file, etc.</p>
","10133"
"Which image format is more memory-efficient: PNG, JPEG, or GIF?","39938","","<p>Which image format is more efficient to save memory? PNG, JPEG, or GIF?</p>
","<p>""Memory"" and ""efficiency"" are commonly misused terms, so I'll give you an answer for four different elements that may affect the performance of your game.</p>

<p>I will be oversimplifying way too many things to keep it short and concise, but there are tons of inaccuracies in this text below, so take it with a pinch of salt. However, the main concepts should be understandable.</p>

<p><strong>Storage</strong></p>

<p>This is the size your images consume on your software distribution. The more space your resources consume, the longer the <em>download</em> (as in from your website) will be. If you're distributing on physical media, such as CDs or DVDs, you're probably going to have to do some serious optimizations in this front.</p>

<p>In general, JPEG compresses the best for photographs and images with no sharp borders. However, your images will have degraded quality because JPEG uses <a href=""https://en.wikipedia.org/wiki/Lossy_compression"">lossy compression</a> (you can fine tune the compression level/degradation when exporting images as JPEG. Refer to your imaging software's documentation for more information on this).</p>

<p>However, as good as JPEG may be, it doesn't support <em>transparency</em>. This is crucial if you want to have images that show through others, or if you want images with irregular shapes. GIF is a good choice, but it has been largely superseded by PNG (there's only a few things GIF supports that PNG doesn't, but they're largely irrelevant in game programming).</p>

<p>PNG supports transparency (and semitransparency), compresses data without degradation in quality (i.e. it uses lossless compression), and compresses fairly well, but not as much as JPG.</p>

<p>The problem arises when you need good compression, as well as transparency. If you don't mind slightly degraded images, you can use PNG quantization programs such as <a href=""http://pngquant.org/"">pngquant</a>, which you can test online at <a href=""http://tinypng.org/"">TinyPNG</a>. Keep in mind that the image degradation performed by quantization on its own is different than that of JPEG (which includes quantization as well as other aggressive techniques), so be sure to try both, with a wide variety of settings.</p>

<p>If you want to aggressively minimize your distribution size, you could manually process every image like this:</p>

<pre><code>if the image has transparency then
    try pngquant on the image
    if the results are not satisfactory then
        revert to the non-quantized image
    end
    store as PNG
else
    try storing it as JPG with different quality settings
    if no single setting yields an image of an acceptable quality then
        try pngquant on the image
        if the results are not satisfactory then
            revert to the non-quantized image
        end
        store as PNG
    else
        store as JPG
    end
end
</code></pre>

<p>Tip: it is okay to store some images in one format, and others in another format.</p>

<p>There are other specialized formats such as DXT, ETC and PVRTC. They support compression, and can also be loaded compressed into memory, but they are only supported by specific GPUs, and most of these GPUs only support one of them, so unless you know the exact hardware specifications of your target hardware (a notable case is the iPhone/iPad, which supports PVRTC textures), you should avoid these formats.</p>

<p><strong>Program Memory</strong></p>

<p>I included it here, because this is what's commonly known by ""memory"". However, if your game uses graphics acceleration (and if you're making a game after 1998, you most likely are), then the only thing that will consume memory are your texture descriptors (just a few bytes per image), which is only effected by the <em>amount</em> of images, and not their size or format (this has a few caveats, but are mostly irrelevant).</p>

<p>If your platform does not have dedicated video memory, is not hardware accelerated, or other uncommon cases, then the next section regarding VRAM will happen completely or partially in RAM, but the main principles will be the same.</p>

<p><strong>Video Memory</strong></p>

<p>This is where your images will be stored once your program is running. In general, the format in which you stored them will make no difference here, as all images are decompressed before loading them into video memory. </p>

<p>Now, the VRAM consumed by your images will roughly be <code>width * height * bitdepth</code> <em>for each</em> image loaded in VRAM. There are a couple of things to notice here:</p>

<ol>
<li><p>The width and height in which your images are stored in VRAM will not necessarily match the ones of your original image. Some GPUs can only handle textures with sizes in powers of 2, so your 320x240 image may actually be stored in a 512x256 space in VRAM, with the unused memory effectively wasted. Some times you're not even allowed to load textures with sizes that are not powers of 2 (like in GLES 1.1).</p>

<p>So if you want to minimize VRAM usage, you may want to considering <a href=""https://en.wikipedia.org/wiki/Texture_atlas"">atlasing</a> your images, and sizing them with powers of 2, which will also have the advantage of fewer render state changes when rendering. More on this later.</p></li>
<li><p>The bitdepth is very important. Usually textures are loaded into VRAM in 32-bit ARGB or 32-bit XRGB, but if your hardware can support 16-bit depths, and you don't mind having a lower bitdepth, you can half the amount of VRAM consumed by each image, which may be something interesting to consider.</p></li>
<li><p>But no matter what you do, the most important factor when considering the amount of VRAM your game uses, is the <em>amount of images</em> you have in VRAM at a given time. This is the number you most likely want to keep as low as possible if you want a good performing game. Loading and unloading textures into VRAM is expensive, so you can't just load each image whenever you're going to use it. You must find a balance between preloading the images you will most likely use, and unload them when you're sure you're not going to use them anymore. Doing this right is not trivial, and you have to think of your own strategy for your particular game.</p></li>
</ol>

<p><strong>Execution speed</strong></p>

<p>Even though not ""memory"", it is very related with performance in games. Drawing images is expensive, and you want to make sure your rendering runs as fast as possible. Of course, in here, format doesn't matter, but other things do:</p>

<ol>
<li><p>Image size (actually, it would be ""sampling size""): the biggest the region of an image you're going to draw, the more time it will take to draw it. Rendering a huge image in a small section of the screen is not very effective, so there is a technique called <a href=""https://en.wikipedia.org/wiki/Mipmap"">mipmapping</a>, which consists of trading VRAM for rendering speed, by storing your images several times at several resolutions and using the smallest one that can give you the required quality at any given time. Mipmapping can be performed when the images are loaded, which will impact loading speed and VRAM usage, or at preprocessing (by manually storing different versions of the same image, or using a format that natively supports mipmapping such as DDS), which will impact storage and VRAM usage, but will have little impact on loading speed.</p></li>
<li><p>Render state changes. You will most likely want to draw several different images on the screen at the same time. However, the GPU can only use a single source image at any given time (this is not true, but please bear with me here). The currently used image for rendering is one of many <em>render states</em>, and it is expensive. So if you're going to use the same image several times (remember when I mentioned <a href=""https://en.wikipedia.org/wiki/Texture_atlas"">texture atlases</a>?), you will notice a huge performance gain if you reuse an image as much as you can before you change the render state and start using a different image (there are other render states apart from this, and fine tuning the order in which you draw your stuff to minimize render state changes is a very common activity when enhancing the performance of a game)</p></li>
</ol>

<p><strong>However</strong>, image usage optimization is a very complex topic, and what I wrote here is a very broad and oversimplified overview of some of the factors you will have to consider when writing a game, so I think it's definitely best if you keep it simple, and only optimize whenever you really need to do so. Most of the times, prematurely optimizing is unnecessary (and sometimes even detrimental), so take it easy.</p>
","48311"
"How to correctly draw a line in Unity","39844","","<p>I'm working on a game which requires me to draw a few lines from a single point that is more formally said </p>

<p>Given point A with coordinates x,y I draw n lines where the i-th line has the coordinates named as xi,yi. Given the LineRenderer capabilities inside Unity3D I was unable to draw more than one line from a particular point with it since it renders only polylines. </p>

<p>I'm currently using the Debug.DrawLine() method which successfully renders the line. I have tried using GL.Begin() as it is shown in <a href=""http://answers.unity3d.com/questions/149210/creating-gl-lines.html"">the Unity example</a> but I cannot see my lines being drawn.</p>

<p>My question is : are there any other methods for doing this? If not, can you tell me how can I show the line that is being drawn with Debug.DrawLine() inside play mode? I've saw that I could use Gizmos.DrawLine() but I didn't quite understand it's usage. </p>
","<h1>Using GL Lines:</h1>

<p>I would recommend using the the <a href=""http://docs.unity3d.com/ScriptReference/GL.html"">GL</a> API for drawing lines. The line thickness will always be 1px on screen and there is no option to change it. There will also be no shadows.</p>

<p>The GL method calls are executed immediately so you need to make sure to call them after the camera has already rendered.</p>

<p>Attaching the script to the camera and using <a href=""http://docs.unity3d.com/ScriptReference/Camera.OnPostRender.html"">Camera.OnPostRender()</a> works good for rendering in the game window. To get them to show in the editor, you can use <a href=""http://docs.unity3d.com/ScriptReference/MonoBehaviour.OnDrawGizmos.html"">MonoBehaviour.OnDrawGizmos()</a>.</p>

<p>Here is the barebones code to draw a line with the GL API:</p>

<pre><code>public Material lineMat = new Material(""Shader \""Lines/Colored Blended\"" {"" + ""SubShader { Pass { "" + ""    Blend SrcAlpha OneMinusSrcAlpha "" + ""    ZWrite Off Cull Off Fog { Mode Off } "" + ""    BindChannels {"" + ""      Bind \""vertex\"", vertex Bind \""color\"", color }"" + ""} } }"");

void OnPostRender() {
    GL.Begin(GL.LINES);
    lineMat.SetPass(0);
    GL.Color(new Color(0f, 0f, 0f, 1f));
    GL.Vertex3(0f, 0f, 0f);
    GL.Vertex3(1f, 1f, 1f);
    GL.End();
}
</code></pre>

<p>Here is a full script that attaches all of the given points to the main point. There are some instructions in the comments of the code to get it set up right and about what is going on.</p>

<p>If you are having problems changing the color of the connecting lines, make sure to use a shader on your line material that takes into account the vertex color such as <code>Unlit/Color</code>.</p>

<pre><code>using UnityEngine;
using System.Collections;

// Put this script on a Camera
public class DrawLines : MonoBehaviour {

    // Fill/drag these in from the editor

    // Choose the Unlit/Color shader in the Material Settings
    // You can change that color, to change the color of the connecting lines
    public Material lineMat;

    public GameObject mainPoint;
    public GameObject[] points;

    // Connect all of the `points` to the `mainPoint`
    void DrawConnectingLines() {
        if(mainPoint &amp;&amp; points.Length &gt; 0) {
            // Loop through each point to connect to the mainPoint
            foreach(GameObject point in points) {
                Vector3 mainPointPos = mainPoint.transform.position;
                Vector3 pointPos = point.transform.position;

                GL.Begin(GL.LINES);
                lineMat.SetPass(0);
                GL.Color(new Color(lineMat.color.r, lineMat.color.g, lineMat.color.b, lineMat.color.a));
                GL.Vertex3(mainPointPos.x, mainPointPos.y, mainPointPos.z);
                GL.Vertex3(pointPos.x, pointPos.y, pointPos.z);
                GL.End();
            }
        }
    }

    // To show the lines in the game window whne it is running
    void OnPostRender() {
        DrawConnectingLines();
    }

    // To show the lines in the editor
    void OnDrawGizmos() {
        DrawConnectingLines();
    }
}
</code></pre>

<p><img src=""https://i.imgur.com/eNkdqGT.gif"" alt=""""></p>

<p><em>Further note on shadows:</em> I explored using a geometry shader to make shadows but since the GL calls run immediately, they are not in the normal rendering pipeline and <code>AutoLight.cginc</code> and <code>Lighting.cginc</code> won't pick up the <code>ShadowCaster</code> pass.</p>

<hr>

<h1>Lines with Shadows and Radius</h1>

<p>If you need to change the line thickness and want to have realistic shadows. Just use a cylinder mesh and scale the height.</p>

<p>Here is a script that will make a cylinder to connect each point to the main point. Place it on a empty game object and fill in the parameters. It will hold all of the extra connecting objects.</p>

<pre><code>using UnityEngine;
using System.Collections;

public class ConnectPointsWithCylinderMesh : MonoBehaviour {

    // Material used for the connecting lines
    public Material lineMat;

    public float radius = 0.05f;

    // Connect all of the `points` to the `mainPoint`
    public GameObject mainPoint;
    public GameObject[] points;

    // Fill in this with the default Unity Cylinder mesh
    // We will account for the cylinder pivot/origin being in the middle.
    public Mesh cylinderMesh;


    GameObject[] ringGameObjects;

    // Use this for initialization
    void Start () {
        this.ringGameObjects = new GameObject[points.Length];
        //this.connectingRings = new ProceduralRing[points.Length];
        for(int i = 0; i &lt; points.Length; i++) {
            // Make a gameobject that we will put the ring on
            // And then put it as a child on the gameobject that has this Command and Control script
            this.ringGameObjects[i] = new GameObject();
            this.ringGameObjects[i].name = ""Connecting ring #"" + i;
            this.ringGameObjects[i].transform.parent = this.gameObject.transform;

            // We make a offset gameobject to counteract the default cylindermesh pivot/origin being in the middle
            GameObject ringOffsetCylinderMeshObject = new GameObject();
            ringOffsetCylinderMeshObject.transform.parent = this.ringGameObjects[i].transform;

            // Offset the cylinder so that the pivot/origin is at the bottom in relation to the outer ring gameobject.
            ringOffsetCylinderMeshObject.transform.localPosition = new Vector3(0f, 1f, 0f);
            // Set the radius
            ringOffsetCylinderMeshObject.transform.localScale = new Vector3(radius, 1f, radius);

            // Create the the Mesh and renderer to show the connecting ring
            MeshFilter ringMesh = ringOffsetCylinderMeshObject.AddComponent&lt;MeshFilter&gt;();
            ringMesh.mesh = this.cylinderMesh;

            MeshRenderer ringRenderer = ringOffsetCylinderMeshObject.AddComponent&lt;MeshRenderer&gt;();
            ringRenderer.material = lineMat;

        }
    }

    // Update is called once per frame
    void Update () {
        for(int i = 0; i &lt; points.Length; i++) {
            // Move the ring to the point
            this.ringGameObjects[i].transform.position = this.points[i].transform.position;

            // Match the scale to the distance
            float cylinderDistance = 0.5f*Vector3.Distance(this.points[i].transform.position, this.mainPoint.transform.position);
            this.ringGameObjects[i].transform.localScale = new Vector3(this.ringGameObjects[i].transform.localScale.x, cylinderDistance, this.ringGameObjects[i].transform.localScale.z);

            // Make the cylinder look at the main point.
            // Since the cylinder is pointing up(y) and the forward is z, we need to offset by 90 degrees.
            this.ringGameObjects[i].transform.LookAt(this.mainPoint.transform, Vector3.up);
            this.ringGameObjects[i].transform.rotation *= Quaternion.Euler(90, 0, 0);
        }
    }
}
</code></pre>

<p><img src=""https://i.imgur.com/XIue3QY.gif"" alt=""""></p>
","96966"
"Why would a game developer write their own engine instead of using existing ones?","39707","","<p>I have observed that many big and well-known game developers often develop their own engines. Examples include Valve, Crytek, Ubisoft, Epic Games and Square-Enix.</p>

<p>Could it simply be because they can, or is it likely that existing engines do not meet enough requirements, so we would develop our own? I can hardly imagine a game that requires a specific engine. The likes of of Unity or Unreal are simply enough to make any kind of game; even if not, they have source code, which can be modified to satisfy even some extraordinary needs.  </p>

<p>Why would a game developer write their own engine instead of using existing ones?</p>
","<p>There are several reasons a studio may choose to ""build"" instead of ""buy"" their technology:</p>

<ul>
<li>Legacy technology; a studio may have started building their own toolchain before there was existing, viable middleware for it.</li>
<li>Specific requirements; a studio may have a particular collection of requirements that is not well-suited to existing middleware or</li>
<li>Budget concerns; a studio may not be able to afford the expense or contractual obligations of existing middleware.</li>
<li>""Not built here syndrome;"" the studios technical leadership may be wary (reasonably or unreasonably so) of technology they did not build and therefore do not fully understand.</li>
</ul>

<p>In general, it does make good sense to own and control the things that are critical to the success of your business, and to outsource those that aren't.</p>

<p>For some studios, the design or storytelling aspect of their games may be the critical resource they expect to capitalize on for success. For those studios, it makes sense to simply buy technology that will allow their designers to realize the appropriate vision.</p>

<p>For others, technology may be the foundation for success. Studios that build MMOs, for example, generally will need to build that infrastructure themselves because it is critical to their success (and existing middleware is generally inappropriate, at least for larger, ""AAA"" titles).</p>

<p>Note that some of the studios you listed (Crytek and Epic in particular) have basically <em>stopped</em> trying to be dominating forces in the games market directly, and almost certainly make far more as middleware vendors than they do as game developers. </p>
","74390"
"Good 2D Platformer Physics","39196","","<p>I have a basic character controller set up for a 2D platformer with Box2D, and I'm starting to tweak it to try to make it feel good. Physics engines have a lot of knobs to tweak, and it's not clear to me, writing with a physics engine for the first time, which ones I should use. Should jumping apply a force for several ticks? An impulse? Directly set velocity? How do I stop the avatar from sticking to walls without taking away all its friction (or do I take away all the friction, but only in the air)? Should I model the character as a capsule? A box with rounded corners? A box with two wheels? Just one big wheel? I feel like someone must have done this before!</p>

<p>There seem to be very few resources available on the web that are not ""baby's first physics"", which all cut off where I'm hoping someone has already solved the issues. Most examples of physics engines for platformers have floaty-feeling controls, or in-air jumps, or easily exploitable behavior when temporary penetration is too high, etc.</p>

<p>Some examples of what I mean:</p>

<ul>
<li>A short tap of jump jumps a short distance; a long tap jumps higher.</li>
<li>Short skidding when stopping or reversing directions at high velocity.</li>
<li>Standing stably on inclines (but maybe sliding down them when ducking).</li>
<li>Analog speed when using an analog controller.</li>
<li>All the other things that separate good platformers from bad platformers.</li>
<li>Dare I suggest, stable moving platforms?</li>
</ul>

<p>I'm not really looking for ""hey, do this."" Obviously, the right thing to do is dependent on what I want in the game. But I'm hoping someone somewhere has gone through the possibilities and said ""well technique A does feature X well, technique B does Y well, but that doesn't work with C"", or has some worked examples beyond ""if (key == space) character.impulse(0, 1)""</p>
","<p><a href=""http://info.sonicretro.org/Sonic_Physics_Guide"">Here is an extremely detailed Sonic The Hedgehog physics guide</a>. I would recommend reading it over, if not actually copying parts of it mostly-verbatim.</p>
","2841"
"Number of Impressions on Admob for revenue","39184","","<p>Just curious of a rough estimate:  About how many impressions would it take to make 300 dollars a day in ad revenue?</p>

<p>Thanks for any help!</p>
","<p>It is not possible to determine an accurate estimate because the rate of each click-through or impression changes for each ad that is displayed.</p>

<p>However, if we take some made up stats from <a href=""http://developer.admob.com/wiki/Definitions"">http://developer.admob.com/wiki/Definitions</a>, it gives that you could theoretically have a estimated cost-per-1000-impression (eCPM) of $1.11. Based on that, it means you would need over 270,000 <strong>unique</strong> impressions a day to make $300. If your eCPM was only half of that, you would have to double the numbers.</p>

<p>If we look at the cost-per-click model, and you assume the average cost-per-click is $0.30 (again, a made up figure obtained from the link above), then it will take 1000 <strong>unique</strong> clicks a day to make $300/day.</p>

<p>Remember, the above stats are completely made up. Each person will have a different experience and the only true way to find out is to implement it in your app and record your own stats.</p>
","4499"
"How to read a data from text file in unity","39120","","<p>Can anybody help me out with giving the steps needed for reading data from the text file in unity and how can the script be added.</p>
","<h2>C# Version.</h2>

<pre><code>using System.IO;

void readTextFile(string file_path)
{
   StreamReader inp_stm = new StreamReader(file_path);

   while(!inp_stm.EndOfStream)
   {
       string inp_ln = inp_stm.ReadLine( );
       // Do Something with the input. 
   }

   inp_stm.Close( );  
}
</code></pre>

<p>EDIT: (Fixed an error on line 9; changed ""stm.ReadLine();"" to ""inp_stm.ReadLine();"")</p>
","85917"
"Good resources for learning modern OpenGL (3.0 or later)?","38400","","<p>I stumble upon the search of a good resource to start with OpenGL (3.0 or later) . Well, I found a lot of books but none of them can be considered a good resource! </p>

<p>Here two examples: </p>

<p><strong>OpenGL Programming Guide (7th edition)</strong>
<a href=""http://rads.stackoverflow.com/amzn/click/0321552628"">http://www.amazon.com/exec/obidos/ASIN/0321552628/khongrou-20</a>
This is FULL of deprecated material! Almost every chapters begin with a note about that.</p>

<p><strong>OpenGL Superbible (5th Edition)</strong>
<a href=""http://rads.stackoverflow.com/amzn/click/0321712617"">http://www.amazon.com/exec/obidos/ASIN/0321712617/khongrou-20</a>
This book uses a library created by the author to explain the main arguments, hiding  what you want to learn! I don't want to learn how to use your library! I want to learn OpenGL! </p>

<p>I hope that you understand this is not the same question like ""hey I'm not able to use Google... tell me how to learn OpenGL"". I've just finished a full and deep search but I can't find a good and complete resource to learn the ""new"" OpenGL avoiding deprecated topics.</p>

<p>Can someone heading me in the right direction? I know C++ and I have 10 years of experience in development... where I can find a good resource?! I want to spend time on it and I want to learn deeply.</p>
","<p>I agree about the above books with a few notes:</p>

<ul>
<li><p>The OpenGL programming 8th guide is now out and has be redone for modern OpenGL 4.3.</p></li>
<li><p>The SuperBible 5th ed, does provide you will a crutch library to start off but as you go through the book you reimplement the functionality of that library so by the end of it you should be fully versed. I also highly recommend wrapping OpenGL stuff in something if your using a object orientated language. I'm working on my own library for fun which seems to be the way to go, implementing it myself I understand all the ins and outs and I only need to put in the bits I actually use. Also you can abstract away some things like sending data to shaders (isn't shinyMaterial.setColor(Red) much nicer), this can also let you backport some stuff by providing legacy alternatives. There is also <a href=""http://oglplus.org/oglplus/html/index.html"">oglplus</a>.</p></li>
</ul>

<p>The main problem with learning modern 'core' OpenGL is that to get a basic pipeline up and running even if it's just to draw a cube you need to understand the following:</p>

<ul>
<li>Matrix operations (use <a href=""http://glm.g-truc.net/"">GLM</a> if you on C++, you will also need a MatrixStack <a href=""http://glsdk.sourceforge.net/docs/html/classglutil_1_1_matrix_stack.html"">OpenGL Unofficial SDK's version here</a>, or my <a href=""https://github.com/dcbishop/g3test/blob/master/src/OpenGL/GLMatrixStack.hpp"">simple one here</a>.)</li>
<li>GLSL shader programming.</li>
<li>binding data to shaders and Vertex Buffer Objects.
If you wanted to learn just real pure core profile they would all need to be implemented simultaneously and if anything is broken you just wont see anything and have almost no clue where it went wrong. That also doesn't cover things like basic lighting (where you need to learn the shading algorithms in addition to the programming language).</li>
</ul>

<p>But you don't need to start in the deepend with the core profile. Use <em>some</em> of the deprecated functionality at the beginning, just about everything will still support it, then modernize it.</p>

<p>Another issue is that 'modern' OpenGL can really refer to 3 things:</p>

<ul>
<li><p>The first one is the programmable shader pipline as opposed to the fixed function pipeline. The core 'modern' techniques have been possible since OpenGL 2.0 was released in 2004 when shaders where introduced (the tutorials just didn't get updated)  also 1.5 had Vertex Buffer Objects's which are another cornerstone of modern OpenGL. A problem is that even today OpenGL developers might not even be able to take advantage of all that stuff, there are plenty of crappy netbooks out there with those Intel chipsets that only support OpenGL 1.5 and phones such as older iPhones/Android ones that only support OpenGL ES 1.1. The only real difference between this stuff in OpenGL 2.0 and OpenGL 3.x/4.x is it's now mandatory for the core profile.</p></li>
<li><p>Modern OpenGL could also refer to the new stuff that's in 3.x, 4.x. Things like <a href=""http://www.opengl.org/wiki/Vertex_Array_Object"">Vertex Array Objects</a>, <a href=""http://www.opengl.org/wiki/Framebuffer_Object"">Framebuffer Objects</a>, <a href=""http://www.opengl.org/wiki/Uniform_Buffer_Object"">Uniform Buffer Objects</a>/<a href=""http://www.opengl-redbook.com/appendices/AppL.pdf"">std140</a>, <a href=""http://www.opengl.org/wiki/GLSL_Type_Qualifiers#Layout_qualifiers"">layout qualifiers</a>, <a href=""http://www.packtpub.com/article/opengl-glsl-4-using-subroutines-select-shader-functionality"">GLSL subroutines</a> and so on. Many of those I have found can make things much much nicer to program with. They can also subtly change your overall engine pipelines. They are also things that with a little effort you can backport by making helper functions and so on (For example write a generic shader manager object that you can use to set uniforms, if UBOs are supported use that otherwise manage uploading the values to shaders manually, maybe put a little shader rewriting stuff in there to automate it). This stuff only runs on new video cards, you wont see any netbooks supporting it or any current generation video game consoles (they use their own subset of OpenGL similar to OpenGL ES). The latest OSX only have 3.2 support and I understand that they will be fixed at this version forever since Apple write their graphics drivers and specify OpenGL versions based on the OS version not the GFX drivers/video card capabilities the only way for a user to get a new OpenGL on a current generation Mac would be to pay for an upgrade to a new version of OSX.</p></li>
<li><p>The Ultra Modern nextgen OpenGL. OpenGL 4.3 was just released. It comes with compute shaders, glMultiDrawElementsIndirect and shader storage buffers. This allows for a fundamentally different pipeline where you upload all the vertex data to the GPU and then use compute shaders to calculate what should be drawn rather than doing it in your program. Unfortunately this is very new so I don't know of any decent tutorials on it. Take a look at the <a href=""http://www.g-truc.net/doc/OpenGL4.3review.pdf"">OpenGL 4.3 review</a> which gives an outline of how this works (also the author says there is a GPU Pro article to be released explaining it). Being brand new it's not going to be supported anywhere at this stage (unless you're on a newer nvidia card with beta drivers). Although you might be able to use OpenCL/CUDA to implement some of it.</p></li>
</ul>

<p>I would skip glBegin, glEnd, glVertex*, glNormal*, glTextCoord*, glTranslate*, glRotate*, glLoadIdenity, glModelViewMatrix and so on. Instead start with learning Vertex Buffer Objects without shaders, don't try 3D at this point just a flat white triangle so you don't have to work with 3d operations using matrices (as you will need to learn to bind them to shaders soon so no sense in learning to old way). Next add in in the shaders, you will need to change how your vertex buffer objects are bound since you will now want to use vertex attributes. Learn how to communicate properties to them via uniforms. Then learn matrix operations with GLM, bind the matrices to the shaders and get 3D going. Once you have that done then it's basically just learning more advanced things like texturing, lighting and some special features like framebuffer objects, vertex array objects, uniform buffer objects, GLSL routines and so on (those are all things I recommend you have a look at. Most of it is fairly new except for texturing and lighting but if you learn them as shader concepts rather than as OpenGL ones, you should get the modern approach).</p>

<p>Some general online modern OpenGL tutorials, covering the shader programming pipeline that most of which works with OpenGL 2.0+:</p>

<ul>
<li><p><a href=""http://www.opengl-tutorial.org/"">opengl-tutorial.org</a> - Eaiser subject matter in bite sizes. Does the gradual order starting with a triangle that I mentioned above.</p></li>
<li><p><a href=""http://www.arcsynthesis.org/gltut/"">The popular Arcsynthesis one.</a> - Fairly in depth, modern OpenGL tutorials starting from scratch. A bit harder than some other basic tutorials though.</p></li>
<li><p><a href=""http://en.wikibooks.org/wiki/OpenGL_Programming"">Wikibooks</a></p></li>
<li><p><a href=""http://www.opengl.org/wiki/Tutorial:_OpenGL_3.1_The_First_Triangle_(C++/Win)"">Official OpenGL Wiki</a></p></li>
<li><p>My <a href=""http://www.davidbishop.org/oglmeta"">OpenGL Metatutorial</a></p></li>
</ul>

<p>For other general learning resources. OpenGL ES might be a good starting point. OpenGL ES has stripped out all the deprecated stuff. OpenGL 4.1 has full compatibility with OpenGL ES so it should be possible to take an OpenGL ES program and run it in OpenGL 4.1. And the basic principles are the same for both.</p>

<p>Some things to note is that <a href=""http://www.khronos.org/news/press/khronos-releases-opengl-es-3.0-specification"">OpenGL ES 3.0 has just been released</a> but as it's new, it won't have any tutorials or hardware support yet. It doesn't seem to have any major fundamental changes (like the difference between fixed pipeline and shader model that we saw with OpenGL ES 1.0->2.0). So you probably won't be learning any out of date stuff.</p>

<p>Also, OpenGL ES will often be using <a href=""http://en.wikipedia.org/wiki/EGL_(OpenGL)"">EGL</a> so you will need to learn another way to open a Window but that shouldn't be too hard. Otherwise there are a few OpenGL ES wrappers/emulators around or you can learn on Android/iPhone if you have one (or look at using their emulators).</p>

<p>There is the <a href=""http://opengles-book.com/"">Addison Wesley OpenGL ES 2.0 Programming Guide</a> which is the equivalent of the red book.</p>

<p>You can also look at GLSL shader focused stuff since that's where most of modern OpenGL lives. You just need to ensure what you learn covers the OpenGL binding 'glue' side of things.</p>

<p>Check out the OpenGL Shading Language 2nd edition (Orange Book).</p>

<p>The OpenGL 4.0 Shading Language Cookbook covers some more bleeding edge OpenGL stuff but isn't itself a comprehensive tutorial. Its definitely worth a look to get some understanding in the latest real world OpenGL practices such as uniform buffer objects and GLSL subroutines.</p>

<p>Finally you could have a look at WebGL, although being in JavaScript that is going to be somewhat different and much harder to debug.</p>
","32917"
"How to use Input.GetAxis(""Mouse X/Y"") to rotate the camera?","38265","","<p>I want to make a first person camera that rotates with the mouse.</p>

<p>I looked at the <a href=""http://docs.unity3d.com/ScriptReference/Input.GetAxis.html"" rel=""nofollow"">Input.GetAxis</a> Scripting API page and found a sample code, which I have included at the bottom of my post. Upon trying it out, I realized that although it has the same basic functionality I hoped it would have, it does not keep the camera parallel to the xz plane, particularly when moving the mouse in circles. After a while the camera would be at an odd angle, and the player would be completely discombobulated!</p>

<p>Is there a quick fix to this code that would restrict the camera movement somehow, or is there a better way to rotate the camera?</p>

<pre><code> using UnityEngine;
 using System.Collections;

     public class ExampleClass : MonoBehaviour {
         public float horizontalSpeed = 2.0F;
         public float verticalSpeed = 2.0F;
         void Update() {
             float h = horizontalSpeed * Input.GetAxis(""Mouse X"");
             float v = verticalSpeed * Input.GetAxis(""Mouse Y"");
             transform.Rotate(v, h, 0);
         }
     }
</code></pre>
","<p>The problem is that you are updating the existing rotation instead of tracking it yourself and replacing it each update.</p>

<p>When you update the rotation it combines your new rotation with the old one which leads to unexpected behaviour.</p>

<p>The solution is to to keep track of your accumulated rotation and reset the rotation entirely each update with your new values.</p>

<p>Credit where due, I found the answer here: <a href=""http://forum.unity3d.com/threads/how-to-lock-or-set-the-cameras-z-rotation-to-zero.68932/#post-441968"" rel=""noreferrer"">Unity Answers: how-to-lock-or-set-the-cameras-z-rotation-to-zero</a></p>

<p>Working Code:</p>

<pre><code>using UnityEngine;
using System.Collections;

public class FirstPersonCam : MonoBehaviour {

    public float speedH = 2.0f;
    public float speedV = 2.0f;

    private float yaw = 0.0f;
    private float pitch = 0.0f;

    void Update () {
        yaw += speedH * Input.GetAxis(""Mouse X"");
        pitch -= speedV * Input.GetAxis(""Mouse Y"");

        transform.eulerAngles = new Vector3(pitch, yaw, 0.0f);
    }
}
</code></pre>

<p>Key differences:</p>

<ul>
<li>Store the yaw and pitch as class members, rather than local method
variables so you can keep track of the accumulated values.</li>
<li>Use += and/or -= to accumulate each update.</li>
<li>Use eulerAngles (to overwrite the rotation value each update) instead of Rotate (which applies your new rotation onto the old one).</li>
</ul>
","104779"
"Glass Material for Unity 5","38053","","<p>Anyone know how to make a glass material in Unity 5?</p>

<p>I can do metal and image textures, but not sure how to create a glass material. </p>

<p>A search on Google would not get me anything for Unity 5 so it must be fairly easy to do.</p>

<p>It's for a shower door and plane glass like this:</p>

<p><img src=""https://i.stack.imgur.com/ZNg71.jpg"" alt=""glass""></p>
","<p>Here's few things i could gather up, hope this helps you. There's multiple ways to get this done. You can write shaders or if you don't mind about having very simple glass, you can use default shaders and some PNG magic.</p>

<ol>
<li><a href=""https://alastaira.wordpress.com/2013/12/21/glass-shader/"" rel=""noreferrer"">Glass Shader</a> made by <strong>Alastair Aitchison</strong></li>
<li><a href=""http://benoculus.com/unity-3d/shaders/reflective-transparent-shader-for-unity-3d/"" rel=""noreferrer"">Reflective transparent ""Glass shader""</a> made by <strong>benoculus</strong></li>
<li><a href=""https://www.assetstore.unity3d.com/en/#!/search/glass"" rel=""noreferrer"">Unity asset store search: Glass</a></li>
<li><a href=""https://www.assetstore.unity3d.com/en/#!/content/9800"" rel=""noreferrer"">Free asset - Breakable glass</a></li>
</ol>

<hr>

<p>EDIT: As this is getting some attention, i decided to add step by step tutorial for very basic window/transparency</p>

<ol>
<li>Create PNG image with transparency on places, where you need it.</li>
<li>Drag and drop it to your assets inside Unity</li>
<li>Drag it from assets to your gameObject, that you wanna use as glass</li>
<li>Select shader -> Transparent -> Specular ( or any of the choices, i liked specular )</li>
<li>Enjoy</li>
</ol>

<hr>

<p>I created simple 64x64 image with full background transparency and added black text on it
<img src=""https://i.stack.imgur.com/l7c6t.png"" alt=""Transparent PNG""></p>

<p>Then i imported it to unity ( dragged it ) and then dragged it over the cube i had there. After that, i selected transparent shader for it.
<img src=""https://i.stack.imgur.com/2S5i5.png"" alt=""Step by step image""></p>

<p>Results ( game is running )
<img src=""https://i.stack.imgur.com/ZbC87.png"" alt=""Result cube""></p>

<p>After this, you could easily create PNG that has some scratches on it or other similar effects to make it look more real. You can even create borders with some color, that could look like a wood or metal. Try the different transparent shaders to find what looks best.</p>
","98560"
"Best Way to Create A Map for a 2D Game?","36810","","<p>I apologize for the subjective ""best"" keyword.</p>

<p>My friend and I have started creation of a 2D adventure game. It will be top-down in the style of pokemon or zelda (just the perspective). We have been discussing methods of creating a large world-map that the player can traverse without straining the memory capabilities of our machine.</p>

<p>Our first impulse was to create a large map and a circle around the player in which content will be loaded. We figured this won't hold for long and decided to partition the map into sections. First we had four large sections, but realized we could simply break it down into many tiny sections.</p>

<p>I played some Zelda from the SNES and saw that, during the shift of a map, the content could be loaded just then. What I mean is, instead of just checking a rectangular area for data to load, we simply section the map into many tiny chunks that load and de-load data as we move from map-portion to map-portion.</p>

<p>Today, he told me he wanted to create a simply 2D array map[WIDTH][HEIGHT] that contains data about every grid in the game and is a constant save-to-disk operation for data that we don't need.</p>

<p>I'm not sure about these ideas and thought that I might as it here. Any links, resources or tutorials on the subject would be greatly appreciated as well as direct answers to our question on how to do it efficiently.</p>
","<p>First off, estimate your map size. Don't just assume that a ""big world"" is not going to fit in memory. Nowadays, a map taking upwards of 10 mb in memory is absolutely acceptable, and you can stuff a LOT in 10 mb in a simple tile-based 2D world.</p>

<p>If you have a <em>really</em> large world, the most robust solution is indeed use map chunks. Split your world into fixed-size chunks (say, 64x64). Load chunks on-the-fly as player moves around, keeping at least one chunk loaded in all directions (i.e. load the chunk the player is in and all its neighbors).</p>

<p>As for unloading chunks, you can choose between several strategies. Eagerly unloading means you unload and save to disk all chunks the moment player moves sufficiently far away; but you can also delay unloading to improve performance (saving chunk, as any disk access, is a costly operation).</p>
","5186"
"Where do I begin if I want to write a C++ 2d game?","36798","","<p>I am a C# web developer and I want to expand my skillset and have some fun while doing it. I know some of the basics of C++ and I would love to write a simple 2d game/game engine for myself using C++. What other libraries or SDKs do I need and where would I find some tutorials and informational resources to move forward?</p>

<p>I've already looked into XNA with C#. There are a lot of resources for that but I would rather use non Microsoft products. The point of this is to have a little fun while becoming a better rounded programmer.</p>

<p>Please note that I'm not asking for the <em>best</em> place to start. I'm just asking for <em>a</em> place to start.</p>

<p>Thanks for any help!</p>
","<p>The standard starting place (in my experience) for C++ game dev is <a href=""http://lazyfoo.net/SDL_tutorials/index.php"">SDL</a>. You've got to get your hands a little dirtier with this than you do XNA.</p>

<p>If you want to try something a little higher level then I would suggest <a href=""http://sfml-dev.org/"">SFML</a>. It handles some of the more menial tasks for you but you've still got to keep your eye on your memory usage, etc.</p>
","18264"
"What are good solutions for serialization in C++?","36241","","<p>I'm curious what solutions game developers have come up with for serializing the different types of data that they deal with for their games. Do you guys use some monolithic GameObject hierarchy that houses a serialization interface for derived types, use sort of custom RTTI-based solution, perform explicit stream serialization for certain classes, or use some of the open source solutions (boost::serialization, s11n, etc).</p>
","<p><a href=""http://code.google.com/p/protobuf/"">Protocol buffers</a> from Google can be a pretty good approach for serializing c++ objects. You may have to make some intermediated objects as part of the serialization process, but it also works across many platforms and languages.</p>
","2271"
"STL for games, yea or nay?","36161","","<p>Every programming language has its standard library of containers, algorithms, and other helpful stuff. With languages like C#, Java, and Python, it's practically inconceivable to use the language <em>without</em> its standard lib.</p>

<p>Yet, on many C++ games I've worked on, we either didn't use the STL at all, used a tiny fraction of it, or used our own implementation. It's hard to tell if that was a sound decision for our games, or one simply made out of ignorance of the STL.</p>

<p>So... is the STL a good fit or not?</p>
","<p>Back when I worked in professional game development, STL was too immature and bloated. But that was >10 years ago.</p>

<p>Now I work in military simulation, which has even tougher performance requirements (like the framerate can never go below some FPS). In military simulation STL is used all over the place. </p>

<p>Some of the people who tell you not to use STL use the argument that it's not always the perfect or even the best solution to the problem. But that isn't an answer to the question. The question should be: Is there something inherently wrong with using STL in games? I'd say no, STL is most of the time a better implementation than what a user would come up with on their own. </p>

<p>Just make sure you know how to use the STL, and use it in your game. Read some books and look at the implementation code in the STL you are using.</p>
","343"
"Is it reasonable to write a game engine in C?","36142","","<p>Even though C++ appears to be king, from what I've been told C is still widely used in games, especially on the consoles. However, would writing an entire game engine in C be unreasonable today? What are, if any, some advantages that C has over C++? Why would someone possibly want to use C over C++?</p>
","<blockquote>
  <p>However, would writing an entire game engine in C be unreasonable today?</p>
</blockquote>

<p>It's reasonable, but the question is what does it buy you? You likely don't need the extreme portability C offers, and it's a shame to give up all of the features C++ offers unless you're really philosophically set against it.</p>

<blockquote>
  <p>What are, if any, some advantages that C has over C++?</p>
</blockquote>

<p>Better compilation time?</p>

<blockquote>
  <p>Why would someone possibly want to use C over C++?</p>
</blockquote>

<p>I think it's mostly an aesthetic choice. Many people like C because it's simple and minimal and feels clean. C++ has a lot of nice features (namespaces alone make it worth using), but it's also big and messy.</p>
","373"
"How can I orbit a camera about it's target point?","36061","","<p>I'm drawing a scene where the camera freely moves about the universe.  The camera class keeps track of the view (or <em>look at</em>) point, the position of the camera, and the up vector.  These vectors/points are then passed into gluLookAt.  </p>

<p>Pan and zoom are nearly trivial to implement.  However, I'm finding rotation about the <em>look at</em> point to be much more of an issue.  I want to write a function Camera.rotate that takes 2 angles, one that rotates up/down and one that rotates left/right along an imaginary sphere that is centered about the <em>look at</em> point.</p>

<p>Is there an easy way to do this?</p>

<p>I've (briefly) read about quaternions, but I wanted to see if there was an easier solution given the relatively simple construction of my scene.</p>
","<p>What you are asking for is called Arcball rotation. Quaternions are the easy solution only if you understand how they work. You can achieve the same without quaternions however.</p>

<p><strong>Pre-requisites</strong></p>

<p>Do you know how to rotate objects in general? Let's say you have an object at the origin. Do you know how you rotate it (hint: multiply by some rotation matrix)? If yes, then I am assuming you know what will happen if you translate the object first and then rotate it?</p>

<p>You must know how to calculate a rotation matrix from angle-axis (easy as pie, look at the myriad of equations online, a lot of them give you the code as well)</p>

<p><strong>Solution</strong></p>

<ul>
<li>Get the camera's <strong>up</strong> and <strong>right</strong> vectors. Note that they should be normalized.</li>
<li>Get the vector from the focus point to the camera (camPosition - Focus). This is the vector that you are going to be rotating. Let's call this <strong>camFocusVector</strong>.</li>
<li>Decide how much you want to rotate in yaw/pitch in relation to the camera</li>
<li>Create two rotation matrices. The 1st rotation matrix will use the <strong>up</strong> of the camera as the axis and <strong>yaw</strong> angle that you decided. The 2nd rotation matrix will use the <strong>right</strong> of the camera as the axis and <strong>pitch</strong> angle that you decided.</li>
<li>Now rotate the <strong>camFocusVector</strong> with the new rotation matrices. This is now your new position of the camera relative to the origin. We of course, want it to be relative to the focus point...</li>
<li>Add the focus point position to <strong>camFocusVector</strong>. This is now your camera's new position. Translate your camera accordingly.</li>
<li>Finally, ask the camera to focus on the focus point by calling your lookAt() function</li>
</ul>

<p><strong>Caveats</strong></p>

<p>You will have to lookout for certain cases or singularities at which your camera will stop working. Looking straight down/up for example. I will let you figure out how to deal with those.</p>

<p><strong>EDIT1: How to recalculate the orthonormal vectors of the camera</strong></p>

<p>You already know the direction of the camera ( (cameraPos - focusPoint).normalize() ). Now assume that your camera's up is +Y (or w/e your world's current up axis is... that is up to you). Now simply cross the <strong>direction</strong> with the <strong>up</strong> to get the <strong>right</strong>. Done? Nope! Your up vector is no longer orthogonal to the other two. To fix that, cross <strong>right</strong> with <strong>direction</strong> and you get your new <strong>up</strong>.</p>

<p>Note that the <a href=""https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process"" rel=""nofollow noreferrer"">Gram-Schmidt</a> is really what should be used to orthonormalize vectors.</p>

<p>Again, take a note of the caveats as this will fail to work in some cases (<strong>direction</strong> is parallel to <strong>up</strong> for example).</p>
","20769"
"How are 8/16 bit sprites created?","35898","","<p>I already found <a href=""https://gamedev.stackexchange.com/questions/8214/how-were-art-assets-created-in-the-late-16-bit-early-32-bit-era"">this question</a>, but it only talks about the kind of software used - not the actual methods. Were they drawn at a high resolution first and then shrunk down? Or did you just zoom way in? Do you do a vague outline first, then make it more detailed? How was the coloring done? And when you have to do long animations, do you hand draw each frame, or are there tools to help automate the process? Or do you just copy paste the basic sprite and only change the moving parts?</p>

<p>Etc.</p>
","<p>Pixel art is its very own art form. There are several tutorials on the net about it, but basically you plot one pixel at a time.</p>

<p>Here's a few tutorials, but I'm sure you can google for more:</p>

<ul>
<li><p><a href=""http://www.natomic.com/hosted/marks/mpat/"">http://www.natomic.com/hosted/marks/mpat/</a></p></li>
<li><p><a href=""http://www.derekyu.com/?page_id=218"">http://www.derekyu.com/?page_id=218</a></p></li>
<li><p><a href=""http://petesqbsite.com/sections/tutorials/tuts/tsugumo/"">http://petesqbsite.com/sections/tutorials/tuts/tsugumo/</a></p></li>
</ul>

<p>There are some tools for sprite animation creation, but those are relatively recent; back then people just drew the animation frames with deluxe paint (or similar).</p>
","34859"
"How can I create a random ""world"" in a tile engine?","35720","","<p>I am designing a game that is working on a classic tile engine, but whose world is generated randomly. Are there existing games or algorithms that do this? 
The procedural generation algorithms I have found are never using a tile system...
What would be the best way to generate a whole ""world"" using a tile system? I am not talking about mazes of blocks, but an overall ""world map""
thanks</p>
","<p>Your question leads you into the field of procedural content generation.</p>

<p><strong>Tile-based world generation derived from continuous/analog methods</strong></p>

<p>By continuous, I means something that is not tiles, something that is analog, an example being a vectorised map. You can use any continuous technique for generation, and then quantise it. For example generate a high resolution Perlin noise image, then reduce it's resolution to fit your tilemap size, and sample the pixels to provide yourself a heightmap. (Heightmaps can be a great starting point for your world.) This because you mentioned seeing sources that didn't show you what to do in regards to how to apply it to tiles.</p>

<p><strong>Tile-based world generation using a ""blinkered"" carving approach</strong></p>

<p>With a tile (cell) based approach, you can do a sort of a blind generation where you generate the world bit by bit without looking further than eg. the directly neighbouring tiles, but this tends to look like the work of an insect. This is typical CA (cellular automata) stuff, and displays little larger scale intelligence.</p>

<p><strong>Tile-based world generation using a broader world view, top-down</strong></p>

<p>This takes a more intelligent approach to building the world tile by tile, since it will first build it region-by-region. In this way you get control over eg. different biomes, political regions, etc. as Tarn Adams has done in Dwarf Fortress. Of course this requires you to think a bit about how you would like to divide up your world. There are many ways, you will have to do your own research.</p>

<hr>

<p>Procedural content generation is a pretty broad topic, so you'll need to do a good amount of reading before getting a solid idea of what it is you <em>really</em> want and how to go about it -- <strong>the devil is always in the detail</strong>. For that reason, some good sources for this are the <a href=""http://groups.google.com/group/rec.games.roguelike.development/topics"">rec.games.roguelike.development</a> mailing list (a ton of information on tile based procedural worlds), <a href=""http://theory.stanford.edu/~amitp/GameProgramming/"">AmitP's game programming pages</a> (look under ""Other Topics""), the <a href=""http://gpwiki.org/"">Game Programming Wiki</a> and last but not least, the <a href=""http://pcg.wikidot.com/"">Procedural Content Generation Wiki</a>.</p>
","18737"
"How do I create a cel-shaded cartoon look?","35580","","<p>I am interested in everything related to this kind of effect (modeling, game engine, animation). What sort of stuff is needed?</p>

<p>Here are some sample images of what I mean:</p>

<p><img src=""https://i.stack.imgur.com/NxGqz.jpg"" alt=""a town in Ni No Kuni"">
<img src=""https://i.stack.imgur.com/eIaqL.jpg"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/6TFBt.jpg"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/rz3gF.jpg"" alt=""enter image description here""></p>
","<h2>Cel shading / Toon shading</h2>

<p>There might be something more to it, but in general, all of your examples use <a href=""http://en.wikipedia.org/wiki/Cel_shading"" rel=""nofollow noreferrer"">Cel shading</a> to some extent.</p>

<p>As for your question, whether there are any engines that support this. Well, that should be possible in every engine out there. The ones that aren't hobby projects should actually have such shader available in their standard assets (<a href=""http://www.unity3d.com/"" rel=""nofollow noreferrer"">Unity3D</a> has those dupped <strong>Toon shader</strong>).</p>

<p>But, the power behind the cel shading is <a href=""http://en.wikipedia.org/wiki/Shader"" rel=""nofollow noreferrer"">shaders</a>.</p>

<h3>2D Games</h3>

<p>For 2D applications, using software rendering, you could achieve this by applying a per-pixel modification. That won't be nowhere near fast, but it's doable.<br>
Though, for a software rendered application I'd suggest that you ask your graphics artists to make such sprites out-of-box. </p>

<p>A quick <a href=""https://www.google.lv/search?q=photoshop+cel+shading"" rel=""nofollow noreferrer"">google</a> <a href=""https://www.google.lv/search?q=photoshop+toon+shading"" rel=""nofollow noreferrer"">search</a> gave me <a href=""http://celesse.deviantart.com/art/Photoshop-Cel-Shading-Tutorial-9731752"" rel=""nofollow noreferrer"">these</a> <a href=""http://karlmac.com/2012/11/simple-cel-shading-with-adjustment-layers-photoshop-tutorial/"" rel=""nofollow noreferrer"">results</a>. There has to be more.</p>

<h3>3D Games</h3>

<p>As for 3D applications, rendering is done either by <a href=""http://en.wikipedia.org/wiki/OpenGL"" rel=""nofollow noreferrer"">OpenGL</a> or <a href=""http://en.wikipedia.org/wiki/Microsoft_Direct3D"" rel=""nofollow noreferrer"">Direct3D</a>. Both of these have shader languages implemented, that can do your kind of manipulations and many others.</p>

<p>OpenGL has <a href=""http://en.wikipedia.org/wiki/GLSL"" rel=""nofollow noreferrer"">GLSL</a> — OpenGL Shading Language.<br>
Direct3D has <a href=""http://en.wikipedia.org/wiki/High_Level_Shader_Language"" rel=""nofollow noreferrer"">HLSL</a> — High-level Shading Language.</p>

<p>As for tutorials and guides, there are plenty (<a href=""https://www.google.lv/search?q=glsl+cel+shader"" rel=""nofollow noreferrer"">GLSL</a>, <a href=""https://www.google.lv/search?q=glsl+cel+shader"" rel=""nofollow noreferrer"">HLSL</a>), due to the release of <a href=""http://en.wikipedia.org/wiki/Borderlands_(video_game)"" rel=""nofollow noreferrer"">Borderlands</a> and huge amounts of Indie studios started the past years, the information available about cel/toon shading is aplenty.</p>

<p>There is a specific question on GLSL cel shader right here in GameDev.SE: <a href=""https://gamedev.stackexchange.com/questions/6638/is-there-any-opengl-cel-shading-tutorial-out-there-without-glaux"">Is there any opengl cel shading tutorial out there (without GLAUX)?</a>.</p>

<p><img src=""https://i.stack.imgur.com/XVTIu.jpg"" alt=""Borderlands"">
<em>A screenshot of Borderlands</em></p>

<p>That should be enough information to get you started with.</p>
","56545"
"Free to use resources for 2d platformer Sprites","35445","","<p>I've looked at a couple other questions about Sprites but most seem to apply to Isometric or RPG related sprites. So I'm wondering if there is a decent place for 2D side scrolling plat-former type sprites?</p>
","<p>You can try the <a href=""http://hasgraphics.com/free-sprites/"" rel=""nofollow"">free sprites</a> from hasgraphics. They can be used in commercial and non-commercial projects.</p>
","6439"
"What is the pixels to units property in Unity sprites used for?","35439","","<p>I'm starting to learn Unity for 2D development.</p>

<p>So, I am importing several sprites into the game, and I couldn't help but notice that there is a ""pixels to units"" property, by default on <code>100</code>. I normally set it to <code>1</code>. Is there a reason why I would need to have this value different than <code>1</code>? Or, more generally, is there a reason to have multiple sprites with different </p>
","<p>100 pixels per unit would mean a sprite that's 100 pixels would equal 1 unit in the scene. It's simply a scale to say how many pixels equal one unit. This can affect things like physics. A lower pixels to units setting would require more force to move one unit than a higher pixels to units setting. </p>

<p>Yes, there may be times where you'll want to manipulate the pixels per unit. If you have a tile sheet of 16x16 tiles, you may want to consider setting the pixels per unit to 16 so that you can easily snap tiles together in a scene, for example. </p>
","83434"
"What are some good game development programs for kids?","34998","","<p>I know a very bright little boy who excels in math, but at home he's glued to his Nintendo DS.</p>

<p>When I asked him what he wanted to do when he grew up he said ""Make video games!""</p>

<p>I remember a few years ago there was mention of a MIT software called Scratch and I thought maybe this kid can do want he wants to do.</p>

<p>Has anyone used any of the ""game development"" for kids softwares out there? Can you recommend any?</p>
","<p>Not looked at it myself, but I thought I'd mention <a href=""http://research.microsoft.com/en-us/projects/kodu/"" rel=""nofollow"">Kodu</a>. What works for you will depend a lot on age and how keen they are.</p>

<p>Way back when I was a kid we had the <a href=""http://en.wikipedia.org/wiki/Shoot%27Em-Up_Construction_Kit"" rel=""nofollow"">Shoot'Em-Up Construction Kit</a>. :)</p>
","9464"
"Where are all the tutorials for libGDX?","34550","","<p>I've searched online for help and tutorials on LibGDX but I couldn't really find any, except and the wiki for asking questions on stackexchange. Besides the <a href=""http://code.google.com/p/libgdx/source/browse/"">source</a> (demos) and <a href=""http://code.google.com/p/libgdx/w/list"">wiki</a>, is there any other tutorials online that's hidden or indirect?</p>

<p>From what I read, there isn't much documentation for LibGDX, so there's only two options I see</p>

<ul>
<li>Give up move to a different framework.</li>
<li>Ask people a lot of questions.</li>
</ul>
","<p>Welcome to open source! As most developers will tell you: ""What documentation?"". Documenting code is probably the least fun developers have when creating a project. So what do you think is often severely lacking when the developer isn't even getting paid for their creation? Documentation of course! (Even fully paid programmers will often leave out the documentation). </p>

<p>I mentioned to you before that open source isn't ""supposed"" to be easy. This is one of the reasons. However, the nice thing about open source is that it's open, so you can find out what the code is doing on your own. However this is often <em>a lot of work</em>.</p>

<p>That being said, I took a look at the <a href=""https://github.com/libgdx/libgdx/wiki/Running-Demos"">demos provided</a> in the libgdx source, and the <a href=""https://github.com/libgdx/libgdx"">wiki</a>. <strong>Libgdx is pretty well documented</strong>, considering it's open source. I don't think your issue is with documentation. I think you may be trying to bite off more than you can chew. From your previous questions, I understand that you're pretty new to programming in general and brand new to the Android platform. Programming on the Android platform isn't the easiest place to start, and programming games on the Android is even further from the mark. </p>

<p>I really think you should try some 2D game programming for the PC, there are plenty of tutorials for getting started in 2D Java game programming on the PC. Once you're more comfortable with programming in general, I think you'll find that the resources available to you for libgdx are more than sufficient.</p>
","26224"
"Where can I find good (well organized) examples of game code?","34269","","<p>Where can I find good (well organized) examples of game code? I'm hoping that I can pick up some organizational tips. Most examples in books are too short and leave out lots of detail for the sake of brevity. I'm particularly interested on how to group your variables and methods so that another programmer would know where to look in the code. For example initializers at the top, then methods that take input, then methods that update views.</p>

<p>I don't care about a particular language, as long as its OOP. I looked at the Quake 2 and 3 sources, but they're straight C and not much help for getting tips on organizing your objects.</p>

<p>So, have you seen some good source? Any pointers to code that makes you say ""wow, that's well organized"" would be great. </p>
","<p>Several commercial games have had their source code released. Some of the games are <a href=""http://en.wikipedia.org/wiki/List_of_open-source_video_games"">listed here</a>. There's no guarantee that the code in these is well organized, but by looking at some source code from games that were commercially successful you might get a good idea what works in practice.</p>

<p>Also, while not a game, <a href=""http://www.openscenegraph.org/projects/osg"">OpenSceneGraph</a> has many of the components of a game and is well architected in C++, using different design patterns, plug-ins, etc. It's a big enough code base and has been around long enough that you can learn a lot from it.</p>
","1513"
"Cross Platform 2D Graphics Engines","34252","","<p>I'm looking for a 2D graphics engine that would allow me to release to Windows, Mac and the iPhone, much the way Unity does for 3D.</p>

<p>Is there a good engine that does this and is specific to 2D?</p>
","<p>There's always the old standby, <a href=""http://www.libsdl.org/"" rel=""nofollow noreferrer"">SDL</a>. It's fairly low level, but that simplicity is what allows it to be ported to bajillions of platforms (including windows, linux, mac, nintendo DS, wii, etc etc). There is an <a href=""http://code.google.com/p/iphone-sdl-1-3/"" rel=""nofollow noreferrer"">iPhone port</a>, which I haven't used, but <a href=""https://stackoverflow.com/questions/597459/how-mature-is-sdl-for-iphone"">seems mature enough.</a></p>
","32"
"What is the role of ""systems"" in a component-based entity architecture?","34200","","<p>I've been reading a lot about entity components and systems and have thought that the idea of an entity just being an ID is quite interesting. </p>

<p>However I don't know how this completely works with the components aspect or the systems aspect. A component is just a data object managed by some relevant system. A collision system uses some BoundsComponent together with a spatial data structure to determine if collisions have happened. </p>

<p>All good so far, but what if multiple systems need access to the same component? Where should the data live? An input system could modify an entities BoundsComponent, but the physics system(s) need access to the same component as does some rendering system. </p>

<p>Also, how are entities constructed? One of the advantages I've read so much about is flexibility in entity construction. Are systems intrinsically tied to a component? If I want to introduce some new component, do I also have to introduce a new system or modify an existing one?</p>

<p>Another thing that I've read often is that the 'type' of an entity is inferred by what components it has. If my entity is just an id how can I know that my robot entity needs to be moved or rendered and thus modified by some system?</p>

<p>Sorry for the long post (or at least it seems so from my phone screen)!</p>
","<p>There are a multitude of ways to represent and implement entity component systems, but here is an explanation of one way. Keep in mind there is no concrete definition of entity/component/system architectures, so this is just one implementation.</p>

<p>I'm going to introduce an analogy for entity/component/system architectures that might help. Let's think of an entity like a key.</p>

<h2>The Entity</h2>

<p><img src=""https://i.stack.imgur.com/ZPCm3.png"" alt=""Entity key""></p>

<p>Keys also have teeth (dark blue). The teeth of our entity key is the components that make it up. You can tell entities apart by their ID, even if they have the same teeth. So what do keys fit into? Locks. Locks are our systems. For example, a movement system.</p>

<h2>The System</h2>

<p><img src=""https://i.stack.imgur.com/wpZEu.png"" alt=""Movement system lock""></p>

<p>The lock only works if our key has teeth for both position and velocity. This system only processes entities that have a position and a velocity. There are multiple ways to set up how these systems recognize which entities to process, but one way is to use a <code>long</code>. Each bit is reserved for a component type. For our example lets assume a 4 bit type instead of a 64 bit long. Our example entity would have all available components. So it's key would be <code>1111</code>. Then, the system is looking for any entity that has a <code>11--</code>. (The <code>-</code> represent don't care, because movement doesn't care if there's a sprite or health). It can check an entity with a simple <code>AND</code> operation. So our entity matches if <code>((1111 &amp; 1100) == 1100)</code>. If I lost you there check out some more about <a href=""http://en.wikipedia.org/wiki/Bitwise_operation"">bitwise operations</a>.</p>

<p>As you can see, systems have access to outside resources. They can access the time, graphics, sound and so on. They are simply little processors that take one key at a time, and process data. You see that the movement system takes the velocity, delta time and position; then does some calculations and stores the result back into position.</p>

<p>The entity keys are really easy to generate. You can add or remove them at will. The entity doesn't care, it's just a way to group and hold the components. The components have no interdependence. The closest the components get to interacting with each other is when a system operates on them and uses data from one to update another, like our movement example.</p>

<p>Lets take a look at another system to help solidify the idea:</p>

<p><img src=""https://i.stack.imgur.com/IgPio.png"" alt=""Drawing system lock""></p>

<p>This is our drawing system. It looks for components that match <code>1-1-</code>. This entity matches because: <code>((1111 &amp; 1010) == 1010)</code> Additionally, you can see that this system outputs information to the screen, by drawing the entity sprite at its position.</p>

<p>OK, one more. Let's look at another entity and see how it might fit into our example so far.</p>

<p><img src=""https://i.stack.imgur.com/gUYpS.png"" alt=""Non moveable entity key""></p>

<p>As you can see, this entity has fewer components attached to it. By looking at the components it does have, it looks like it could be a static item like a rock. It just has a position and a sprite. It's not going to move and it's not going to be affected by any health changes. This entity would produce a key of 1010. So what systems operate on this entity? Lets check:</p>

<p>Against our movement system:
    <code>((1010 &amp; 1100) != 1100)</code> Nope. Looks like the movement system doesn't care about this entity, because it doesn't have the components required.</p>

<p>Against our drawing system:
    <code>((1010 &amp; 1010) == 1010)</code> Hey, that's a match. This entity will be operated on by the drawing system. The drawing system will draw the sprite at the position defined.</p>

<hr>

<p>Hopefully you can see how easy it would be to now add another system that would take our components and operate on them. Let me ensure I've addressed your questions:</p>

<blockquote>
  <p>What if multiple systems need access to the same component? Where should the data live? </p>
</blockquote>

<p>Typically, systems operate one after the other. They process all the entities that match their requirements, then the next system does the same and so on. The data lives with the entity. There shouldn't be anything stored in the system, it's just a lock that gets turned, the key is where the information stays and moves from lock to lock.</p>

<blockquote>
  <p>How are entities constructed? Are systems intrinsically tied to a component? If I want to introduce some new component, do I also have to introduce a new system or modify an existing one?</p>
</blockquote>

<p>Entities are just bags of components. They have a unique ID and a list of components. Systems are only tied to components in the way described above. You can have components without systems that operate on them, but that's pretty pointless. Similarly you can have systems that are looking for components that no entities have. That's less pointless, because they may just be waiting for an entity to be created that matches their lock. So, yes, if you introduce a new component, you'd want to make a system that utilizes that component. Otherwise you're just adding teeth to your key for a lock that doesn't exist.</p>

<blockquote>
  <p>If my entity is just an id how can I know that my robot entity needs to be moved or rendered and thus modified by some system?</p>
</blockquote>

<p>I think I answer this with the idea of a <code>long</code> key that defines the components contained in an entity. You know because the key fits the lock.</p>

<p>Phew! That was a long post! (Or at least it seems so from my large monitor.)</p>
","31491"
"How can I make a peer-to-peer multiplayer game?","34172","","<p>How can I make a p2p multiplayer game?
I would like to have a server-less multiplayer game. But then, how all the clients know each other?</p>

<p>Why the p2p-protocol is so famous in file transfer but not in multiplayer games?</p>
","<p>Peer to peer games generally still have a game host. Its the game host that posts the game to the master games list and accepts new connections. Whenever the game host accepts a new client to the game it notifies all existing clients about the new client so that they can ensure they connect to the new client.</p>

<p>The simplest way to implement p2p is with a lobby. All clients connect to the host in a lobby (or chat room). When the host is ready the player presses start and they all enter the game at the same time (commonly used in strategy games). A more complex approach is to use ""drop-in drop-out"" where players can join and leave mid game, however this is a lot more complex to implement in a p2p game and requires a feature called host-migration.</p>

<p>A good number of games use peer to peer networking, including most strategy, sports and driving titles. Just about all Xbox360 and PS3 games use p2p networking. The client-server architecture is mostly used in first person shooter or MMO games.</p>

<p>Client-Server is generally easier to implement as only 1 machine has not know the entire game state, the clients are basically just renderers with some prediction to make things look smooth.</p>

<p>When you build a p2p engine, all clients need a full state of the game world and they all are required to stay in sync.</p>

<p>For more details on p2p and client-server architectures I suggest you read the following article: <a href=""http://gafferongames.com/networking-for-game-programmers/what-every-programmer-needs-to-know-about-game-networking/"">http://gafferongames.com/networking-for-game-programmers/what-every-programmer-needs-to-know-about-game-networking/</a></p>

<p>And if you're new to networking in general checkout the other great articles on that site. Glenn is a networking genius. </p>
","3891"
"What are the pros and cons of HLSL vs GLSL vs cg?","34017","","<p>What are the pros / cons of the three?</p>
","<p>coderanger is right about HLSL targeting DirectX, GLSL targeting OpenGL and CG being available with both interfaces.</p>

<p>However there are other things to consider (learned on the OGRE forum) :</p>

<ul>
<li>CG will not allow you to use the latest features of GLSL (I'm not sure about HLSL). It's a middle ground so you'll not be able to fully exploit the GLSL features, only the common one until Shader Model 3.0 (AFAI understood).</li>
<li>CG is made by NVidia that optimize it for it's card but don't seem to do lot of work for ATI cards... some people report that there might be problems with ATI cards using CG.</li>
<li>OpenGL seem to be a bit slower than DirectX on Windows platforms. That's really relative to what you're doing and the reason for this find it's source in the drivers implementations but it's good to know before you choose the API and the associated shader language. However, OpenGL is the only one interface available on all (win/mac/unix/some consoles) platforms. So knowing that, using exclusively GLSL might be the better choice for a non-Microsft-centric-cross-platform game.</li>
<li>NVidia drivers on Linux seem to be more stable than ATI drivers, making CG more interesting if you need to be sure it works nicely on linux (that's all reported informations, you'll have to check for details)</li>
</ul>

<p>So, if you're not using the lastest shader features, CG seem a good choice. GLSL seem a beter one if you're going full OpenGL. HLSL if you're going exclusively on Microsoft platforms. </p>

<p>Now first developping in HLSL for windows to use DirectX and then convert to GLSL for linux and mac could be the better solution to be sure of performance and have the larger set of shader features available. It might however be a lot of work (didn't do it myself so I cannot tell). OGRE graphics engine (and other engines) allow to use any API (DirectX or OpenGL or others) so it helps, but there is still shader code to convert if you go this way.</p>

<p>That's all the information I gathered while choosing my shader language (I've not made my decision yet).</p>

<hr>

<p>Update: <a href=""http://www.i-programmer.info/news/144-graphics-and-games/4590-opengl-faster-than-directx-or-is-it.html"">Valve did a conversion of one of their game to OpenGL and found no way to make the DirectX version faster than the OGL one</a>. So keep in mind that the state of driver implementation, API quality, etc., all that change too much each year for you to totally rely on raw performance as an argument to choose one or the other. With this in mind, choose OpenGL/GLSL to simplify your life when working (or having plans or hopes to work) with other platforms than Windows, use DirectX/HLSL if you really want to use only Microsoft platforms and focus and maybe have some good API faster than OpenGL (this is reversing now, so don't count on it); use CG if you want to provide both possibilities to the user, but if you have the work force (and tools) to do it, using both GLSL and HLSL might be a viable solution too.</p>

<hr>

<p>Update (2012): It is important to note that CG has been discontinued, and is no longer supported or actively worked on by Nvidia. Nvidia recommends that all users switch to a combination of GLSL and HLSL, or a newer library such as nvFX (on github). This is because it was too difficult to maintain feature-compatibility between GLSL and HLSL.</p>
","4333"
"How do I scale up pixel art without blur in GM Studio?","33841","","<p>I'm creating a game in Game Maker Studio that uses pixel art.   When I launch the game, all scaled-up textures are really blurry. (It doesn't happen to small ones.)</p>

<p>For example, this image</p>

<p><img src=""https://i.stack.imgur.com/OE22c.png"" alt=""nice :)""></p>

<p>renders in the game like this:</p>

<p><img src=""https://i.stack.imgur.com/uOeLl.png"" alt=""blurred :(""></p>

<p>Is there anyway to resize <em>small pixels</em> into <em>big pixels</em> instead of <em>blurred pixels</em>?  </p>
","<p>Found a solution from some resource. Go to Global Game Settings, then go to any platform spoiler(for example ""Windows"" or ""Android""), there choose the spoiler titled ""Graphics"" and toggle ""Interpolate colors between pixels"" off. Have fun :)</p>
","72413"
"What is the future of XNA in Windows 8 or how will managed games be developed in Windows 8?","33720","","<p>I know this is a potential dupe of <a href=""https://gamedev.stackexchange.com/questions/1736/where-is-xna-headed"">this question</a>, but the last answer there was 18 months ago and a lot has happened since.</p>

<p>There seems to be some uncertainty about XNA in Windows 8. Specifically, Windows 8 by default uses the Metro interface, which is not supported by XNA. Also the Windows 8 store will not stock non-metro apps, so it will not stock XNA apps.</p>

<p>Should we stick with XNA or does Microsoft want us to move to a different framework for managed game development in Windows 8? </p>

<p>Edit: As pointed out in one of the comments, Windows 8 will be able to run XNA games in a backward compatibility mode. But that smells of deprecation.</p>
","<p>EDIT: <a href=""http://gamasutra.com/view/news/185894/Its_official_XNA_is_dead.php#.UREwnmResyF"" rel=""nofollow noreferrer"">It's official, Microsoft has killed off XNA</a>. I'm saddened by this but it was not unexpected, it's what I was predicting would happen, but hoping I was wrong. Everything below this point is my original post from early 2012.  </p>

<p>Something else to consider is that Microsoft is likely to release a new console in mid to late 2013. Will they continue with trying to have something like XNA work on their console? If they want individuals to make games on the new Xbox, they're going to need something, and it would be wasteful to scrap XNA and start anew with something else. Additionally, Windows 8 will run on tablets with ARM processors, and we all know how big the market is for apps for phones and tablets, that's a big opportunity for Microsoft to have an API for creating apps on those devices, but will that be XNA, or only .NET?</p>

<p>I see a couple of potential paths:</p>

<ol>
<li><p>XNA hasn't been extremely successful with the current Xbox, mostly due to how few XNA games are showing up, and how poorly setup the store is for XNA games on Xbox Live. So Microsoft may decide to pull the plug entirely, leaving us with XNA 4.0, which is compatible with DX10, and will be a decent platform for people to make simple PC games with for the next few years before it disappears.</p></li>
<li><p>Microsoft may see the huge possibilities with homemade apps, things like Apple's App Store are huge money makers, and if Microsoft can make it easier to make games and get them onto Xbox Live and Windows 8 tablets, then they have a chance to make it big in the console apps market. If Microsoft goes down this path I see the new XNA supporting DX11.1 with its next version, and continuing support for XNA for at least 5 more years. </p></li>
</ol>

<p>Some things to consider:</p>

<ul>
<li><p>Currently with XNA you must pay $100 if you want to develop your game for the Xbox 360, that's $100 just to try it out and see if you could make any money, and even then MS gets a chunk of the profits from your game. If Microsoft takes out the $100 fee and just takes the chunk of the profits, they may actually end up seeing a lot more games and make more money off of the deal.</p></li>
<li><p>XNA games have performance problems on the Xbox 360. Microsoft did not want XNA games posing a security risk when they ran on other people's Xboxes, so they basically run XNA games in a sandbox with limited access to the CPU, GPU, and memory. In addition to the limited access, games programmed on the full Xbox SDK are not written in C# and do not need things like garbage collection, but XNA runs on Microsoft's own C#, so Microsoft had to write a wrapper to get XNA to run on the Xbox, and that wrapper slows things down quite a bit. Things like floating point performance can be up to 10x slower than Xbox games that are written through the full SDK. These performance problems mean that Xbox games developed through XNA cannot really use the full potential of the Xbox, which just hurts the quality of the games that Microsoft can get from the community. Microsoft would  do well to consider this if they continue with XNA so that their next console allows XNA developers to use the system to its full potential.</p></li>
<li><p>As far as I know, XNA will not support Windows 8's metro style, so developers will not be able to write games to take advantage of it. XNA also will not run on ARM processors, so you could not use XNA to write apps for Windows 8 tablets that will be coming out soon. Is this a sign that XNA might not be supported in the future?</p></li>
<li><p>Microsoft uses XNA for games right now, but with a little work it could be used to make some interesting applications as well. If Microsoft pushed XNA to communities other than game developers then it might get used more often and have more reason for Microsoft to continue supporting it.</p></li>
<li><p>The XNA forums have dried up a bit, it takes more time for people to get answers, and I rarely see any member of the XNA team on the forums anymore except Shawn Hargreaves, so they may just be in a support role at this time.</p></li>
<li><p>I created and support an <a href=""http://quickstartengine.codeplex.com/"" rel=""nofollow noreferrer"">open-source game engine</a> for XNA, over the last 2 years the downloads of the engine have dropped to about half of what they started at, even though the engine is much better than it used to be. This signals to me that a lot fewer people are using XNA than used to. Here's a graph of the number of hits I have on my site, you can see interest in XNA peaked around late 2007 to mid 2008.
<img src=""https://i.stack.imgur.com/PnIbV.jpg"" alt=""QuickStart Engine Page Views""></p></li>
</ul>

<p>Here is a long discussion that includes some members of the XNA team. Of course, they're not willing to comment on much because Microsoft doesn't talk about things much before they're announced:</p>

<p><a href=""http://xboxforums.create.msdn.com/forums/t/91616.aspx"" rel=""nofollow noreferrer"">http://xboxforums.create.msdn.com/forums/t/91616.aspx</a></p>

<p>Also quotes like this are interesting:</p>

<blockquote>
  <p>Create immersive games using the power of DirectX
  The new Windows 8 graphics stack is better integrated, making Direct2D, Direct3D, and DirectCompute components easier to use together and requiring fewer duplicated resources than before. Capabilities previously available only in XNA, such as DirectXMath, XAudio2, and XInput, are now available. For the ultimate experience in gaming and video, use DirectX 11.1 to bring stereoscopic 3D to your apps.</p>
</blockquote>

<p><a href=""http://download.microsoft.com/download/1/E/4/1E455D53-C382-4A39-BA73-55413F183333/Windows_Developer_Preview-Windows8_guide.pdf"" rel=""nofollow noreferrer"">http://download.microsoft.com/download/1/E/4/1E455D53-C382-4A39-BA73-55413F183333/Windows_Developer_Preview-Windows8_guide.pdf</a></p>

<p>I currently support an open-source game engine for XNA, so I would prefer to see it supported in the future, however, even if XNA 4.0 is the last XNA, it's still a decent platform for creating Windows games quickly and easily, and also a great API for those who want to learn how to make video games.</p>

<p>My honest opinion is that XNA 4.0 will be the last one, but I truly hope I'm wrong about that.</p>
","22536"
"How to begin serious game development (in C++)","33225","","<p>I would like to start developing games. I have tried before <em>Game Maker 8</em>, which was a very easy way to start creating games, if you were new in game development. Then, I tried <em>Unity 3D</em>, which was a much more serious and complete tool to create computer-games, and required some experience. And now, I would like to start creating games, and don't use any special environment or developer, but just code (in C++ preferably). So, here is my question: from where should I begin, if I would like to start programming games? Thanks in advance.</p>

<p><em><strong>Note:</strong></em> I work in ubuntu 10.04, I can also use windows 7, but I prefer ubuntu.</p>
","<p>Any of these already existing posts on gamedev may be useful. In fact, this is just a short list of the top voted questions (most of them are closed, because they don't fit this site's objective) on Gamedev.</p>

<ul>
<li><a href=""https://gamedev.stackexchange.com/questions/854/what-are-good-games-to-earn-your-wings-with"">What are good games to &quot;earn your wings&quot; with?</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/765/what-things-should-an-indie-game-developer-never-do"">What things should an indie game developer never do?</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/3223/game-development-blogs"">Game development Blogs</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/12348/how-does-a-single-programmer-make-a-game"">How does a single non-artistic programmer make a game?</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/455/good-resources-for-learning-about-game-architecture"">Good resources for learning about game architecture?</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/651/tips-for-writing-the-main-game-loop"">Tips for writing the main game loop?</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/497/good-game-design-books"">Good game design books?</a></li>
</ul>
","42062"
"How can I translate a game object towards a position?","33222","","<p>I am instantiating my game objects (spheres) through scripts. I want my spheres to move from one location to another. but I don't know how to do this. <code>Update</code> is called once per frame. Is that what I should use? I am using the free version of Unity; I don't want to use special plugins.</p>

<p>How do I move these game objects from one location to another, over time?</p>
","<p>Yes, the <code>Update</code> loop is ideal for this. There are no special plug-ins required and you can do this with the free version. Basically you move the objects a tiny bit towards their destination each frame. When all those frames run one right after the other, it gives the appearance of smooth movement. A self contained script would look like the one I've created below. Ideally you'd take this as a starting point, and update it to use your own speed and starting point.</p>

<pre><code>//move towards a target at a set speed.
private void MoveTowardsTarget() {
    //the speed, in units per second, we want to move towards the target
    float speed = 1;
    //move towards the center of the world (or where ever you like)
    Vector3 targetPosition = new Vector3(0,0,0);

    Vector3 currentPosition = this.transform.position;
    //first, check to see if we're close enough to the target
    if(Vector3.Distance(currentPosition, targetPosition) &gt; .1f) { 
        Vector3 directionOfTravel = targetPosition - currentPosition;
        //now normalize the direction, since we only want the direction information
        directionOfTravel.Normalize();
        //scale the movement on each axis by the directionOfTravel vector components

        this.transform.Translate(
            (directionOfTravel.x * speed * Time.deltaTime),
            (directionOfTravel.y * speed * Time.deltaTime),
            (directionOfTravel.z * speed * Time.deltaTime),
            Space.World);
    }
}
</code></pre>

<p>This code could be anywhere (for now just put it inside the script you're using it from). Tn the script attached to the sphere you want to move, you'd put: <code>MoveTowardsTarget()</code> in the <code>Update()</code> function.</p>
","72539"
"How does Lua work as a scripting language in games?","33220","","<p>I'm a little hazy on what exactly Lua is and how a game that is programmed in C++ would use it. I'm asking primarily about how it is compiled and run.</p>

<p>For instance when you use a program written in C++ which uses Lua scripts: does the code in Lua just call to functions in the main program written in C++ and act as a uncompiled class waiting to be compiled and added to the memory heap of the C++ program?</p>

<p>Or does it act like a bash script in Linux where it just executes programs completely separate from the main program?</p>
","<p>Scripting is a programming abstraction in which you (conceptually) have a program (the script) running inside another program (the host). In most cases, the language in which you write the script is different from the language in which the host is written, but any program-inside-a-program abstraction could be considered scripting.</p>

<p>Conceptually, the common steps to enable scripting are the following (I will be using pseudo-c for the host and pseudo-lua for the script. These are not exact steps, but more like the general flow in which you enable scripting)</p>

<ol>
<li><p>Create a virtual machine in the host program:</p>

<pre><code>VM m_vm = createVM();
</code></pre></li>
<li><p>Create a function and expose it to the VM:</p>

<pre><code>void scriptPrintMessage(VM vm)
{
    const char* message = getParameter(vm, 0); // first parameter
    printf(message);
}

//...

createSymbol(m_vm, ""print"", scriptPrintMessage);
</code></pre>

<p>Notice that the name in which we exposed the function (<code>print</code>) does not have to match the internal name of the function itself (<code>scriptPrintMessage</code>)</p></li>
<li><p>Run some script code that uses the function:</p>

<pre><code>const char* scriptCode = ""print(\""Hello world!\"")""; // Could also be loaded from a file though
doText(m_vm, scriptCode);
</code></pre></li>
</ol>

<p>That's all there is to it. The program then flows in the following manner:</p>

<ol>
<li><p>You call <code>doText()</code>. Control is then transferred to the virtual machine, which will execute the text inside <code>scriptCode</code>.</p></li>
<li><p>The script code finds a previously exported symbol <code>print</code>. It will then transfer control to the function <code>scriptPrintMessage()</code>.</p></li>
<li><p>When <code>scriptPrintMessage()</code> finishes, control will transfer back to the virtual machine.</p></li>
<li><p>When all of the text in <code>scriptCode</code> has been executed, <code>doText()</code> will finish, and control will be transferred back to your program on the line after <code>doText()</code>.</p></li>
</ol>

<p>So in general, all you're doing is running a program inside another program. Theoretically speaking, there is nothing you can do with scripts that you can't do without them, but this abstraction allows you to do some interesting things really easily. Some of them are:</p>

<ul>
<li><p>Separation of concerns: it is a common pattern to write a game engine in C/C++ and then the actual game in a script language like lua. Done right, the game code can be developed completely independently from the engine itself.</p></li>
<li><p>Flexibility: scripting languages are commonly interpreted, and as such, a change in a script will not necessarily require a rebuild of the entire project. Done right, you can even change a script and see the results without even a program restart!</p></li>
<li><p>Stability and security: since the script is running inside a virtual machine, if done right, a buggy script won't crash the host program. This is specially important when you allow your users to write their own scripts to your game. Do remember that you can create as many independent virtual machines as you like! (I once created an MMO server in which each match ran on a separate lua virtual machine)</p></li>
<li><p>Language features: when using scripting languages, based on your choice for host and script languages, you can make use of the best features each language has to offer. In particular, lua's coroutines are a very interesting feature that is very difficult to implement in C or C++</p></li>
</ul>

<p>Scripts are not perfect though. There are some common disadvantages to using scripting:</p>

<ul>
<li><p>Debugging becomes very difficult: usually, the debuggers included in common IDEs are not designed to debug the code inside scripts. Because of this, console trace debugging is much more common than I'd like.</p>

<p>Some scripting languages like lua have debugging facilities which can be taken advantage of in some IDEs like Eclipse. Doing this is very difficult, and I've honestly never seen script debugging working as well as native debugging.</p>

<p>By the way, the extreme lack of interest the Unity developers have in this matter is my main criticism of their game engine, and the main reason I don't use it anymore, but I digress.</p></li>
<li><p>IDE integration: It is unlikely that your IDE will know which functions are being exported from your program, and as such, features such as IntelliSense and the like are unlikely to work with your scripts.</p></li>
<li><p>Performance: Being commonly interpreted programs, and meant for an abstract virtual machine whose architecture may be different from the real hardware, scripts are commonly slower to execute than native code. Some VMs like luaJIT and V8 do a really good job though. This may be noticeable if you do some very heavy usage of scripts.</p>

<p>Usually, context changes (host-to-script and script-to-host) are very expensive, so you may want to minimize them if you're having performance problems.</p></li>
</ul>

<p>How you use your scripts is up to you. I've seen scripts used for things as simple as loading settings, to as complex as making entire games in the scripting language with a very thin game engine. I once even saw a very exotic game engine that mixed lua and JavaScript (via V8) scripting.</p>

<p>Scripting is just a tool. How you use it to make awesome games is completely up to you.</p>
","73735"
"How were cartridge-based games programmed?","32936","","<p>I'm thinking of like the SNES, N64, Atari... even the DS today, I suppose.</p>

<p>SNES games did not usually take up more than 4 MB of space, and N64 games were usually 32 to 64 MB worth of data.</p>

<p>These days, you can barely compile a ""hello world!"" program without the resulting compilation generating 1.21 gigabytes!! of data. (Joking aside, files today do take up tons and tons of space compared to some of the technology back then.)</p>

<p>So... how did they do it?</p>

<ul>
<li>What did they program these games in? ASM? <em>The entire thing in ASM?!</em></li>
<li>How were graphics created? What technology did they have to create sprite sheets and, in some cases (like the N64), 3D models?</li>
<li>How did they fit so many levels, characters, quests and items on these cartridges? I mean, Super Mario World on the SNES clocks in around 1 MB, and it has 96 exits! Ocarina of Time, Banjo-Kazooie, DK64 and a few other games take up less than 64 MB and had huge worlds, tons of content and 3D models!</li>
</ul>

<p>Sorry if my questions seem a little out-there, I'm just amazed that a lot of great titles out there managed to fit in such a small storage space. </p>

<p>It's fascinating to me because even tiniest and most trivial of files and games manage to take up at least a few MB, so imagining that huge levels like those in GoldenEye 007 managed to take almost no data at all is mind-blowing.</p>
","<p>It's the art and audio resources that take up space, choice of programming language was more about getting the most of out of the hardware.</p>

<p>Using N64 as an example, most of the 3rd party games were 8, 12, or 16Mb. The 32 &amp; 64Mb games were mostly from Nintendo as it was so expensive to ship on carts that big for everyone else. That sounds tiny, but then so were the art assets and the final visual output. You have to remember that most N64 games rendered at 320x240 not the 1280x760 or more of today. With such a small output resolution, textures and sprites were much smaller than they are today.</p>

<p>Because of the tiny texture cache on the N64, most textures were 32x64 pixels with a 4/8bit palette (aka 16/256 colors). Extra color detail was often done by mixing textures and vertex colors. The Banjo games are a good example of this. </p>

<p>Today a single rock in an Unreal engine game will have multiple 512x512x24bpp or even 32bpp. Plus instead of just a single diffuse texture, you've now got normal maps, specular masks, reflection masks, reflection cubemaps and more. So an object that used to have 4Kb of textures is now covered in several MB of data. </p>

<p>Old games also have a massive amount of reuse of art. The bushes in Super Mario Bros. are the same sprites as the clouds, the hills are the same as the mushrooms. Different characters are just color shifted versions of the same art resources. All of this got more usage out of each texture or sprite that was on the cart.</p>

<p>Audio is another big difference for modern games. Nearly everything in the old days was done with sequenced tracks. Now both music tracks, voice and sound effects are stored in various compressed audio formats. While certainly smaller than uncompressed data, they are still significantly bigger than their sequenced equivalents.</p>
","4396"
"Convert Autocad DWG to OBJ, FBX or similar","32775","","<p>I know this is only partially game development related, but couldnt find another place to ask.</p>

<p>How can i convert an autocad dwg or dxf file to a more 'common' format like OBJ, FBX, 3DS, etc. ?</p>

<p>i tried directly using autocad LT but the export options dont have any other format.s</p>

<p>free and oss solutions preferred.</p>
","<p>Try <a href=""https://knowledge.autodesk.com/support/autocad/downloads/caas/downloads/content/autodesk-3dsout-command.html"" rel=""nofollow noreferrer"">3DSOUT</a></p>

<ol>
<li><p>At the command prompt, enter 3dsout.</p></li>
<li><p>Select objects in the drawing to export.</p></li>
<li><p>Press ENTER.</p></li>
<li><p>In the 3D Studio Output File dialog box, in the File Name field,
enter a file name.</p></li>
<li><p>Click Save.</p></li>
<li><p>In the 3D Studio File Export Options dialog box, select or change
the necessary options. (See the <a href=""http://knowledge.autodesk.com/sites/default/files/file_downloads/readme_3dsout.html#3DSOUTReference"" rel=""nofollow noreferrer"">3DSOUT Reference</a> below for more
information about these options.)</p></li>
<li><p>Click OK.</p></li>
</ol>
","16828"
"How to get the rotation matrix to transform between two 3d cartesian coordinate systems?","32718","","<p>I'd like to know how to get the rotation matrix for the transformation from one cartesian coordinate system <code>(X, Y, Z)</code> to another one <code>(X', Y', Z')</code>. </p>

<p>Both systems are defined with three orthogonal vectors as one would expect. No scaling or translation occurs. I'm using <em>OpenSceneGraph</em> and it offers a <code>Matrix</code> convenience class, if it makes finding the matrix easier: </p>

<blockquote>
  <p><a href=""http://www.openscenegraph.org/documentation/OpenSceneGraphReferenceDocs/a00403.html"" rel=""nofollow noreferrer"">http://www.openscenegraph.org/documentation/OpenSceneGraphReferenceDocs/a00403.html</a>.</p>
</blockquote>
","<p>One easy way is to think of both coordinate systems as transforms from the unit vectors (1,0,0) (0,1,0) and (0,0,1). You start off in this coordinate space (I will call it '1')whose transform matrix is the identity matrix:</p>

<pre><code>    [1,0,0]
I = [0,1,0]
    [0,0,1]
</code></pre>

<p>then your first coordinate space (I will call it '2') has the transform matrix:</p>

<pre><code>    [Xx,Xy,Xz]
A = [Yx,Yy,Yz]
    [Zx,Zy,Zz]
</code></pre>

<p>and your second coordinate space (I will call it '3') has the transform matrix:</p>

<pre><code>    [Xx',Xy',Xz']
B = [Yx',Yy',Yz']
    [Zx',Zy',Zz']
</code></pre>

<p>For your points to be in the first coordinate system, then you have transformed them from 1 to 2. If you want to go from 2 to 3 then you can undo the transform from 1 to 2 then do the transform from 1 to 3. You can reverse the transform by inverting 2's transform matrix.</p>

<p>A point v in 2 can be transformed to a point v' in 3 with this equation: v' = B(A^-1)v where (A^-1) is the inverse of A. </p>

<p>Note this also handles scaling even though you don't need it. This approach will work with translation as well, though you would need a 4x4 matrix instead of a 3x3. </p>
","26085"
"Path finding algorithms?","32163","","<p>I posted this question on stack overflow first, but I guess no one is very interested in video games there...</p>

<p>What are some path finding algorithms used in games of all types? (Of all types where characters move, anyway) Is Dijkstra's used a whole lot? I would think not, as it doesn't actually trace out the steps to take to get somewhere, right? If I'm understanding it right, it only determines which object is the closest. I'm not really looking to code anything; just doing some research, though if you paste pseudocode or something, that would be fine (I can understand Java and C++). I'm basically looking for a quick overview of path finding in general.</p>

<p>I know A* is like THE algorithm to use in 2D games. That's great and all, but what about 2D games that are not grid-based? Things like Age of Empires, or Link's Awakening. There aren't distinct square spaces to navigate to, so what do they do?</p>

<p>What do 3D games do? I've read this thingy <a href=""http://www.ai-blog.net/archives/000152.html"">http://www.ai-blog.net/archives/000152.html</a>, which I hear is a great authority on the subject, but it doesn't really explain HOW, once the meshes are set, the path finding is done. IF A* is what they use, then how is something like that done in a 3D environment? And how exactly do the splines work for rounding corners?</p>
","<p>Too many questions at once, so it's hard to give a concrete answer but to discuss a few of these topics. I'll divide the answer in two and try to address it as best as I can. I don't claim any of these lists to be <em>complete</em>, but they're some of the different methods I could remember.</p>

<hr>

<h1>Part 1 - Pathfinding Algorithms</h1>

<p>For starters, there are <em>many</em> ways to implement pathfinding, but not all of them return the shortest path, or are efficient or even reliable. For instance:</p>

<ul>
<li><p>Primitive methods that don't ""look ahead"" and take one step at a time:</p>

<ul>
<li><p><strong>Random backstepping</strong> - Take one step at a time in the direction of the goal. If an obstacle is encountered try to work around it by backstepping a bit in a random direction and then trying again. Not reliable at all and will get stuck in a multitude of situations.</p></li>
<li><p><strong>Obstacle tracing</strong> - Other approach, similar to random backstepping but instead of moving back randomly, start tracing around the object once a collision is found, as if you had the right hand stuck to the wall and had to move touching it. Once there's no collision continue moving in the goal's direction. Once again can get stuck in many situations.</p></li>
</ul></li>
<li><p>Methods that look ahead to find the entire path at once:</p>

<ul>
<li><p><strong>Breadth First Search</strong> - Simple graph traversal by visiting each layer of children at a time, stop when path is found. If the graph is <em>unweighted</em> (i.e. the distance between each adjacent node is always the same) it finds the shortest path although not too efficiently. For weighted graphs it might not return the shortest path, but will always find one if it exists.</p></li>
<li><p><strong>Depth First Search</strong> - Another way to traverse a graph, but instead of taking it layer by layer, the algorithm tries to search deep into the graph first. This method can have problems if the depth of the search is not limited, especially when using a recursive implementation, which may lead to a stack overflow, so it is usually safer to implement it iteratively using a stack.</p></li>
<li><p><strong>Best First Search</strong> - Similar to Breadth First Search but uses an heuristic that chooses the most promising neighbor first. The path returned may not be the shortest, but it's faster to run than breadth first search. A* is a type of Best First Search. </p></li>
<li><p><strong>Dijkstra's Method</strong> - Keeps track of the total cost from the start to every node that is visited, and uses it to determine the best order to traverse the graph. Works with weighted graphs and returns the shortest path, but might involve a lot of searching.</p></li>
<li><p><strong>A*</strong> - Similar to Dijkstra but also uses an heuristic to estimate how likely each node is close to the goal, in order to make the best decision. Because of this heuristic, A* finds the shortest path in a weighted graph in a much more timely manner. </p></li>
</ul></li>
<li><p>Then there are variations of A* (or pathfinding optimizations in general) that make it faster or more adapted to certain circunstances, such as (see <a href=""https://gamedev.stackexchange.com/a/21759/11686"">related answer</a> and a <a href=""https://cstheory.stackexchange.com/questions/11855"">comprehensive list on cstheory.SE</a>):</p>

<ul>
<li><strong>LPA*</strong> - Similar to A* but can more quickly recalculate the best path when a small change to the graph is made</li>
<li><strong>D* Lite</strong> - Based on LPA*, it does the same thing, but assumes the ""start point"" is a unit moving towards the finish while graph changes are being made</li>
<li><strong>HPA* (Hierarchical)</strong> - Uses several layers at different abstraction levels to speed up the search. For instance, an higher level layer may simply connect rooms, while a lower level layer takes care of avoiding obstacles.</li>
<li><strong>IDA* (Iterative Deepening)</strong> - Reduces memory usage in comparison with regular A* by using iterative deepening.</li>
<li><strong>SMA* (Simplified Memory-Bounded)</strong> - Only makes use of available memory to carry out the search.</li>
<li><strong>Jump Point Search</strong> - Credits to Eric in the comments for mentioning it! Speeds up pathfinding on uniform-cost grid maps (<a href=""http://harablog.wordpress.com/2011/09/07/jump-point-search/"" rel=""nofollow noreferrer"">link</a>).</li>
</ul></li>
</ul>

<hr>

<h1>Part 2 - Search Space Representation</h1>

<p>And finally to address this question:</p>

<blockquote>
  <p>I know A* is like THE algorithm to use in 2D games. That's great and all, but what about 2D games that are not grid-based? </p>
</blockquote>

<p>Two big misconceptions here! In fact:</p>

<ol>
<li>A* doesn't care if the game is 2D or 3D, and is equally appropriate for both cases.</li>
<li>A* works under <em>any</em> graph representation, so it doesn't care whether the world is a grid or not.</li>
</ol>

<p>So if the world doesn't need to be a grid, in what other ways can you represent it? Here's a brief overview of ways to partition the world space for pathfinding, and most of these work both for 2D and 3D alike:</p>

<ul>
<li><p><strong>Rectangular grid</strong> - Partition world into regular grid of squares with each cell in the grid being one node in the graph, and the connection between two unobstructed nodes is an edge.</p>

<p><img src=""https://i.stack.imgur.com/TZ1ih.jpg"" alt=""enter image description here""></p></li>
<li><p><strong>Quadtree</strong> - Another way to partition the space, but instead of partitioning into a grid of regular sized cells, partition in four, then recursively divide each of these in four again. Adding a third dimension makes it an <strong>octree</strong>.</p>

<p><img src=""https://i.stack.imgur.com/IVVNk.png"" alt=""enter image description here""></p></li>
<li><p><strong>Convex polygons</strong> - Partitioning the walkable area into a mesh of interconnected convex polygons. Each polygon becomes a node, and shared edges are the edges of the graph. These can be triangles for instance, and sometimes even be a mesh created by an artist when creating the level assets. Often referred to as a <strong>navigation mesh</strong>. See this <a href=""http://www.ai-blog.net/archives/000152.html"" rel=""nofollow noreferrer"">link</a>. Here's a very popular navigation mesh construction toolset: <a href=""http://code.google.com/p/recastnavigation/"" rel=""nofollow noreferrer"">Recast</a>.</p>

<p><img src=""https://i.stack.imgur.com/TorgR.png"" alt=""enter image description here""></p></li>
<li><p><strong>Points of visibility</strong> - The most common way is to place a node just outside each of the obstacle's convex  vertices, and then connect each pair of nodes that can <em>see</em> each other. Check <a href=""http://www.david-gouveia.com/pathfinding-on-a-2d-polygonal-map/"" rel=""nofollow noreferrer"">this link</a>. The nodes don't have to be the vertices though, and can be placed manually by the designer in the map. In that case, the system is frequently referred to as a <strong>waypoint graph</strong>.</p>

<p><img src=""https://i.stack.imgur.com/UOlgl.png"" alt=""enter image description here""></p></li>
</ul>
","28044"
"How can I effectively manage a hobby game project?","32117","","<p>What are your tips and tricks to successfully finish a hobby game project in your freetime?
How do you motivate yourself to keep it up and drive right through to the finish without losing interest or motivation along the way?</p>
","<p>These tips apply to any hobby software project, and not just games.</p>

<ul>
<li><p><strong>Set tiny milestones.</strong> Having a goal like ""item system works in my RPG game"" is all well and good, but that implies a whole lot of under-specified functionality that you probably didn't even know you needed. What about ""graphics environment set up""? Or, ""A sprite is displayed on the screen.""</p></li>
<li><p><strong>Do a little bit each day.</strong> Marathon sessions are great and all, but you're trying to squeeze a long-term commitment into an already crowded life. If you do a little bit each day you are making measurable progress and establishing a structure within which you can achieve your milestones. </p></li>
<li><p><strong>Scale yourself back.</strong> Whatever your grand vision is, try and figure out what the smallest achievable portion is and do that. Making an RPG? Start with one quest and no NPCs. Making a platformer? Start with one level and no enemies.</p></li>
<li><p><strong>Prototype early.</strong> Before you sink a bunch of your hard-earned hobby hours into a game, figure out if it'd be fun first. There's nothing so dispiriting as working your ass off on something for dozens of hours only to find that the basic concept sucks.</p></li>
<li><p><strong>Develop something iterable.</strong> My favorite hobby software projects are the ones where the basic concept allows for later tinkering. Is your game like that? Can you ship something and then revisit it later and add cool stuff?</p></li>
<li><p><strong>Don't build an engine or a framework.</strong> You don't want an engine, you want a game. Don't worry about the framework-y, reusable bits until after your game is shipping. Once you start on the second game, then you can go back to your first and see if there's anything you could bring over. That's not to say that you shouldn't use sound software development praxis, but don't start by writing a Sprite class until you know what you need your sprites to do -- you'd be surprised how little it'll turn out to be. Start with a Hero class, then a Monster class, and then -- oh look! -- there's some common stuff!</p></li>
<li><p><strong>Shipping is a feature.</strong> You're never going to finish your game, you're only going to abandon it. ( = What is the minimum amount you can do before you're not completely embarrassed to show your game to someone else? Chances are, you can do less than that and still have a game to be proud of.</p></li>
</ul>
","206"
"GLSL - one-pass gaussian blur","32065","","<p>It is possible to implement fragment shader to do one-pass gaussian blur? 
I have found lot of implementation of two-pass blur (gaussian and box blur):</p>

<ul>
<li><a href=""http://callumhay.blogspot.com/2010/09/gaussian-blur-shader-glsl.html"">http://callumhay.blogspot.com/2010/09/gaussian-blur-shader-glsl.html</a></li>
<li><a href=""http://www.gamerendering.com/2008/10/11/gaussian-blur-filter-shader/"">http://www.gamerendering.com/2008/10/11/gaussian-blur-filter-shader/</a></li>
<li><a href=""http://www.geeks3d.com/20100909/shader-library-gaussian-blur-post-processing-filter-in-glsl/"">http://www.geeks3d.com/20100909/shader-library-gaussian-blur-post-processing-filter-in-glsl/</a></li>
</ul>

<p>and so on.</p>

<p>I have been thinking of implementing gaussian blur as convolution (in fact, it is the convolution, the examples above are just aproximations):</p>

<p><a href=""http://en.wikipedia.org/wiki/Gaussian_blur"">http://en.wikipedia.org/wiki/Gaussian_blur</a></p>
","<p>Yes, you <em>can</em> implement Gaussian blur in one pass, by sampling all n^2 pixels in the kernel (for kernel width n).  It's usually <em>faster</em> to run it on the rows and columns in two passes, since then you have O(n) pixels to sample rather than O(n^2).  This is not an approximation, since Gaussian blur is mathematically separable.</p>
","26655"
"What path finding algorithms are there?","31983","","<p>I'd like to read up on path finding algorithms. Is there a primer available or any material or tutorials on the Internet that would be a good start for me?</p>
","<p>If you're looking to research and learn about pathfinding in general, I'd definitely suggest learning more than just one algorithm. You'll want to understand the overall concepts but be able to apply them to whatever it is you are working on. Most game developers who need to do any serious pathfinding end up writing their own custom algorithms, although highly based on known solutions, every game is different and will have different requirements.</p>

<p>I'd start by reading up on some of the more well know methods like A*, Dijkstra's Algorithm, Depth and Breadth-First searches. There's a lot of good information on the internet on each of these. (<a href=""http://en.wikipedia.org/wiki/Pathfinding"">http://en.wikipedia.org/wiki/Pathfinding</a>)</p>

<p>While reading them, take note on what the upsides and downsides are to each approach, as well as the type of data the algorithm can operate on. Can it be applied to 3-dimensional paths? Can it be modified to account for our human AI who wants to avoid the landmines in the map?</p>

<p>When it comes to pathfinding, A* is pretty much the golden ticket that everyone uses. You should definitely know how it works. (<a href=""http://en.wikipedia.org/wiki/A%2a_search_algorithm"">http://en.wikipedia.org/wiki/A*_search_algorithm</a>)</p>

<p>Here's a good example of A* as it applies to an RTS game, which needs to take entities of different size into account: <a href=""http://aigamedev.com/open/tutorials/clearance-based-pathfinding/"">http://aigamedev.com/open/tutorials/clearance-based-pathfinding/</a></p>

<p>Good luck!</p>
","57"
"How can the Unreal Development Kit be used with Android?","31881","","<p>I've read the <a href=""http://3dg.me/gamedev/udk/udk-eventually-will-get-android-support"" rel=""nofollow"">UDK will support Android development</a>, I checked the download page on the site and found nothing related to Android.</p>

<p>also read that Dungeon Defenders Android game was built with Unreal engine.</p>

<p>so is there a way to use the UDK with Android ?</p>
","<p>I think that only the licensees have the access to android part of udk as the below page clearly mentioned about this</p>

<p><strong><code>Android support is available to full UE3 source licensees. If you are developing a UDK title and wish to explore moving from UDK to UE3 in order to target additional platforms, please contact the sales team at Epic to discuss our competitive terms and licensing options.</code></strong></p>

<p><a href=""http://udn.epicgames.com/Three/MobileHome.html"" rel=""nofollow"">http://udn.epicgames.com/Three/MobileHome.html</a></p>

<p>But if you want to confirm you can probably ask this on there development forums to the people who have there games out there.</p>

<p><a href=""http://forums.epicgames.com/forum.php"" rel=""nofollow"">Here</a> is the link to epics forum.  </p>
","23222"
"How can I include vertex color information in .OBJ files?","31825","","<p>The .obj files I export are missing data for vertex colors. Is there a way to include color information in the .obj file? If not, what are the alternatives?</p>
","<p>Blender can export PLY files (.ply), which are text-based, very easy to parse, and include vertices colors. The hard way is to change the OBJ exporter code so that it includes the vertices colors (thus breaking obj compatibility).</p>
","21304"
"Texture packing algorithm","31501","","<p>What is a good texture packing algorithm?  Technically, <a href=""http://en.wikipedia.org/wiki/Bin_packing_problem"">bin packing</a> is <a href=""http://en.wikipedia.org/wiki/NP-hard"">NP-hard</a>, so a heuristic is what I'm really after.</p>
","<p>I spent a few months at one job coming up with a better texture packing algorithm.</p>

<p>The algorithm we started with was simple. Collect all the input items. Sort them by total pixels consumed, large-to-small. Lay them out in your texture in scanline order, just testing stuff from the topleft pixel to the topright pixel, moving down a line, and repeating, resetting to the topleft pixel after every successful placement.</p>

<p>You either need to hardcode a width or come up with another heuristic for this. In an attempt to preserve squareness, our algorithm would start at 128, then increase by 128s until it came up with a result that wasn't any deeper than it was wide.</p>

<p>So, we had that algorithm, and I decided to improve it. I tried a bunch of wacky heuristics - trying to find objects that fit together, doing some weighting over a bunch of desired space packing properties, rotating and flipping. After all my work, quite literally three months of work, I ended up saving 3% space.</p>

<p>Yeah. 3%.</p>

<p>And after we ran our compression routine over it, it actually ended up <em>larger</em> (which I still can't explain) so we threw the entire thing out and went back to the old algorithm.</p>

<p>Sort items, jam into texture in scanline order. There's your algorithm. It's easy to code, fast to run, and you won't get much better without an amazing amount of work. That work just isn't worthwhile unless your company is at <em>least</em> 50 people large, and probably more.</p>

<p><img src=""https://i.stack.imgur.com/e1Gal.png"" alt=""alt text""></p>

<p>And as a side note, I just implemented this algorithm (fixed width 512 pixels) for quite literally the exact same application that you're doing (no ftgles, but opengl-rendered freetype glyphs.) Here's the result. It looks blurry because mine is using Valve's <a href=""http://www.valvesoftware.com/publications/2007/SIGGRAPH2007_AlphaTestedMagnification.pdf"">distance-field based text rendering algorithm</a>, which also accounts for the extra space between glyphs. Obviously, there's not a lot of empty space left over, and it does a good job of cramming things into open spots.</p>

<p>All the code for this is BSD-licensed and available <a href=""https://github.com/zorbathut/glorp/blob/4307a13af75ca1c5386988b1b693c5d97a4c3a94/fontbaker/main.cpp"">at github</a>.</p>
","2839"
"Moving an object in a circular path","31477","","<p>I want to move one object (dot) in a circular path. How should I change the X and Y coordinates to accomplish this?</p>
","<p>You can do that using simple math:</p>

<pre><code>X := originX + cos(angle)*radius;
Y := originY + sin(angle)*radius;
</code></pre>

<p><em>(originX, originY)</em> is the center of your circle.
<em>radius</em> is its radius. That's it.</p>

<p>This works because the <a href=""https://en.wikipedia.org/wiki/Sine#Relation_to_the_unit_circle"">sine and cosine are mathematically related to the unit circle</a>.</p>

<p><img src=""https://i.stack.imgur.com/E5spU.gif"" alt=""relationship of sine and cosine to the unit circle"">
<br><sup>Image credit: <a href=""https://commons.wikimedia.org/wiki/User:LucasVB"">LucasVB</a> (Own work) [Public domain], <a href=""https://commons.wikimedia.org/wiki/File:Circle_cos_sin.gif"">via Wikimedia Commons</a>. (Scaled down to 70%.)</sup></p>
","9610"
"What is the correct way to use GameObject.Find in Unity?","30972","","<p>I have been following along with a Lynda.com video course to familiarize with Unity. I am currently attempting to grab a reference to a scene's First Person Controller's transform as follows:</p>

<pre><code>Transform targetObject;

// Use this for initialization
void Start ()
{
    targetObject = gameObject.Find(""First Person Controller"").transform;
}
</code></pre>

<p>And this is within a script/class that inherits from <code>MonoBehaviour</code>. However, this gives the error:</p>

<pre><code> Static member `UnityEngine.GameObject.Find(string)' cannot be accessed with an instance reference, qualify it with a type name instead
</code></pre>

<p>I am sure there is a way to just change the logic and get the desired affect with a different approach.  But I do not understand why this results in an error. It is the same code used by the instructor of the course, and from the Unity Script Reference, I can see that <code>MonoBehaviour</code> inherits a <code>gameObject</code> member which has the <code>Find()</code> method.  So this error is saying there is only one <code>GameObject</code> instance for all <code>MonoBehaviour</code> classes right? But shouldn't I still be able to call it's methods? </p>

<p>I am using Unity 4.1 with C# while the instructor is using 3.5 (with JS) if that helps any.</p>
","<p>You actually just made a simple typo. <code>gameObject</code> is the current <code>GameObject</code> that your script is attached to. <code>GameObject</code> is the type. The error message is saying that the <code>Find(string)</code> function only works when it is called on the type (<code>GameObject</code>) not an instance of the type (<code>gameObject</code>). </p>

<p>Simply put, use <code>GameObject.Find(""First Person Controller"")</code> instead of <code>gameObject.Find(""First Person Controller"")</code>.</p>
","60281"
"Transform Matrix multiplication order","30817","","<p>I am experiencing difficulties trying to figure out the correct multiplication order for a final transform matrix. I always get either strange movement or distorted geometry. My current model is explained below:</p>

<p>For a single node my multiplication order is:</p>

<blockquote>
  <p>L = S * R * T</p>
</blockquote>

<p>where</p>

<blockquote>
  <p>L = local transformation matrix</p>
  
  <p>S = local scale matrix</p>
  
  <p>R = local rotation matrix</p>
  
  <p>T = local translate matrix</p>
</blockquote>

<p>For a node's world transformation:</p>

<blockquote>
  <p>W = P.W * L</p>
</blockquote>

<p>where</p>

<blockquote>
  <p>W = world transformation matrix</p>
  
  <p>P.W = parent world transformation matrix</p>
  
  <p>L = the local transformation matrix calculated above</p>
</blockquote>

<p>When rendering, for each node I calculate the matrix : </p>

<blockquote>
  <p>MV = Inv(C) * N.W</p>
</blockquote>

<p>where</p>

<blockquote>
  <p>MV = the model view transformation matrix for a particular node</p>
  
  <p>Inv(C) = the inverse camera transformation matrix</p>
  
  <p>N.W = the node's world transformation matrix calculated above.</p>
</blockquote>

<p>Finally, in the shader I have the fallowing transformation:</p>

<blockquote>
  <p>TVP = PRP * MV * VP</p>
</blockquote>

<p>where</p>

<blockquote>
  <p>TVP = final transformed vertex position</p>
  
  <p>PRP = perspective matrix</p>
  
  <p>MV = the node's world transformation matrix calculated above</p>
  
  <p>VP = untransformed vertex position.</p>
</blockquote>

<p>With the current model, child nodes which have local rotation, rotate strangely when transforming the camera. Where did I go wrong with the multiplication order? </p>
","<p>Any combination of the order <code>S*R*T</code> gives a valid transformation matrix. However, it is pretty common to first scale the object, then rotate it, then translate it:</p>

<pre><code>L = T * R * S
</code></pre>

<p>If you do not do it in that order, then a non-uniform scaling will be affected by the previous rotation, making your object look skewed. And the rotation will be affected by the translation, making the final position of your object very different from what the value of the translation would make you expect.</p>
","29265"
"C# creating a simple snake game","30355","","<p>I was thinking about creating a snake game with C#, so I ran ideas in my head, and some problems came up.</p>

<p>How can I track and output in the correct location the blocks that run after the snake's head?</p>

<p>If the snake is built of five blocks, and the user starts going in a circle, how can I print the snake body in the right location?</p>

<p>Also, how can I create an action that will run on the background, which will move the snake forward, no matter what the user does?</p>

<p>What structure should my code have? (code design structure)</p>

<p>This should be a console application, since it's the only framework I am familiar with.</p>

<p>I am not looking for finished code, since I want to really understand how it should work.</p>
","<p><strong>Representing the Snake</strong></p>

<p>Creating a Snake game is pretty simple. The first thing you need is a way to <em>represent</em> your snake's body. If you consider your snake to be made up of blocks or tiles, your body can simply be a list of these blocks coordinates. </p>

<p>In your case, if you intent do a console application, each of these will be a character on the console, and the position would correspond to one line or row of the console output. So you start with this:</p>

<pre class=""lang-cs prettyprint-override""><code>// List of 2D coordinates that make up the body of the snake
List&lt;Point&gt;() body = new List&lt;Point&gt;();
</code></pre>

<p>At this point, your list is empty, so your snake has no body. Let's say you want a snake of length 5 and the head should start in position (5,2) and grow towards the bottom. Just add those positions to the list when the game starts, for instance:</p>

<pre><code>// Initialize the snake with 5 blocks starting downwards from (5,2)
for(int i=0; i&lt;5; ++i)
{
    body.Add(new Point(5, 2 + i));
}
</code></pre>

<p><strong>Rendering the Snake</strong></p>

<p>For rendering just draw a character at each position on the body list. The example above for instance could be drawn as:</p>

<pre class=""lang-none prettyprint-override""><code>...................
...................
.....O............. -- y = 2
.....#.............
.....#.............
.....#.............
.....V.............
...................
     |
     x = 5
</code></pre>

<p>You can get more complicated by choosing different characters for the character's head (first element on the list) and tail (last element on the list) and even orient them depending on the positions of the adjacent blocks. But for starters, just render everything as a <code>#</code> or something.</p>

<p>You could for instance start with a 2D char array containing the background like this:</p>

<pre class=""lang-cs prettyprint-override""><code>// Array with map characters
char[,] render = new char[width, height];

// Fill with background
for(x=0; x&lt;width; ++x)
    for(y=0; y&lt;height; ++y)
        render[x,y] = '.';
</code></pre>

<p>And then iterate over the snake's body drawing it to the array:</p>

<pre><code>// Render snake
foreach(Point point in body)
    render[point.X, point.Y] = '#';
</code></pre>

<p>And finally iterate over the array again and write each character to the console, with a linebreak at the end of each row.</p>

<pre><code>// Render to console
for(y=0; y&lt;height; ++y)
{
    for(x=0; x&lt;width; ++x)
    {
        Console.Write(render[x,y]);
    }
    Console.WriteLine();
}
</code></pre>

<p><strong>Moving the Snake</strong></p>

<p>Finally, movement. The first thing you need is to keep track of the <code>Direction</code> the snake is moving. This can be a simple enum:</p>

<pre class=""lang-cs prettyprint-override""><code>// Enum to store the direction the snake is moving
enum Direction { Left, Right, Up, Down }
</code></pre>

<p>And the act of moving the snake can be done just by <em>removing the last block from the list and adding it on the front, in the correct direction</em>. In other words something like:</p>

<pre><code>// Remove tail from body
body.RemoveAt(body.Count - 1);

// Get head position
Point next = body[0];

// Calculate where the head should be next based on the snake's direction
if(direction == Direction.Left) 
    next = new Point(next.X-1, next.Y);
if(direction == Direction.Right) 
    next = new Point(next.X+1, next.Y);
if(direction == Direction.Up) 
    next = new Point(next.X, next.Y-1);
if(direction == Direction.Down) 
    next = new Point(next.X, next.Y+1);

// Insert new head into the snake's body
body.Insert(0, next);
</code></pre>
","24823"
"How to avoid texture bleeding in a texture atlas?","30352","","<p>In my game there is a Minecraft-like terrain made out of cubes. I generate a vertex buffer from the voxel data and use a texture atlas for looks of different blocks:</p>

<p><img src=""https://i.stack.imgur.com/BlEWW.png"" alt=""texture atlas for voxel based terrain""></p>

<p>The problem is that the texture of distant cubes interpolates with adjacent tiles in the texture atlas. That results in lines of wrong colors between cubes (you may need to view the screenshot below at its full size to see the graphical flaws):</p>

<p><a href=""https://i.stack.imgur.com/XRmml.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/XRmml.png"" alt=""screenshot of terrain with stripes of the wrong color""></a></p>

<p>For now I use these interpolation settings but I tried every combination and even <code>GL_NEAREST</code> without mipmapping doesn't provide better results.</p>

<pre><code>glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
</code></pre>

<p>I also tried added an offset in the texture coordinates to pick a slightly smaller area of the tile but since the unwanted effect depends on the distance to the camera this cannot solve the problem completely. At far distances the stripes occur anyway.</p>

<p>How can I solve this texture bleeding? Since using a texture atlas is popular technique there might be a common approach. Sadly, for some reasons explained in the comments, I cannot change to different textures or texture arrays.</p>
","<p>After struggling a lot with this issue, I finally came up with a solution.</p>

<p>To use both, a texture atlas and mipmapping, I need to perform the downsampling myself, because OpenGL would otherwise interpolate over the boundaries of tiles in the atlas. Moreover I needed to set the right texture parameters, because interpolating between mipmaps would also cause texture bleeding.</p>

<pre><code>glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST_MIPMAP_LINEAR);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
</code></pre>

<p>With these parameters, no bleeding occurs.</p>

<p>There is one thing you have to notice when providing custom mipmaps. Since it doesn't make sense to shrink the atlas even if each tile is already <code>1x1</code>, the maximal mipmap level must be set according to what you provide.</p>

<pre><code>glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAX_LEVEL, 7); // pick mipmap level 7 or lower
</code></pre>

<p>Thanks for all other answers and very helpful comments! By the way I still do not know how to use linear up scaling, but I guess there is no way.</p>
","50777"
"How can I make huge terrains in Unity?","30294","","<p>How can I make <strong>extremely</strong> huge terrains in Unity? It seems like I can set width and length to large values. But the Heightmap resolution only goes up to 4097 and the Detail resolution only goes up to 4048.</p>

<p>Any ideas?</p>
","<p>Split the terrain into square ""chunks"", load those you care about (mostly: Those near the currently active camera) in Update() and - if you are strapped for space (you likely will be), unload the not needed ones far away.</p>

<p>Use pre-calculated low-poly models for far-away terrain LoD, unless you don't mind having a low view distance. Also, if you need the terrain heightmap of far away terrain for anything (like NPC movement or some other simulation), create a low-resolution or variable resolution variant of your terrain to keep in memory; don't use the full terrain data for it. This can be done automatically on game load, but generally it's a better idea to make a tool which creates this pre-generated data during the build or package.</p>

<p>Finally: To avoid floating point precision problems, you'll have to reposition the whole scene every time your main camera moves far away from (0.0f, 0.0f, 0.0f).</p>

<p>Possibly relevant question on Unity Answers <a href=""http://answers.unity3d.com/questions/17225/dynamic-terrain-loading.html"">http://answers.unity3d.com/questions/17225/dynamic-terrain-loading.html</a></p>
","15646"
"Writing a server for a multiplayer game","30198","","<p>I've been looking on the internet, but I can't really find any good answers to all my questions..</p>

<p>I started to think about writing a little multiplayer game on my own and after thinking and thinking and thinking about how I should begin I came to the conclusion, that implementing the network communication part at first wouldn't be a bad idea since the testing part becomes ""easier"".</p>

<p>So my first question is:</p>

<p>Is there any library that would make my life easier if I wanted to write the server part in C++?</p>

<p>I just don't know how one would implement the communication between server and client. Imagine a game that is made up of blocks (like minecraft if you want) but the client should only receive a tiny part of that map. So my question at this one is: Would you send raw byte data? Or would you use more abstract formats like XML? Let us assume that this should work with ""many"" clients as well..</p>

<p>And here is another thing..</p>

<p>Would one use either a single thread that collects all connections and sends requests to specific worker threads or would you create a new thread for every single connection that is established to the server?</p>
","<p>One library to use is <a href=""http://enet.bespin.org/"" rel=""noreferrer"">ENet</a>, which implements a generic network API suitable for many games.  Or <a href=""http://libevent.org/"" rel=""noreferrer"">libevent</a> even, which just handles the low-level network events.</p>

<p>There is not a direct need for threads on most platforms, though Windows forces their use for large numbers of clients.  Separate threads can be useful when you need a fixed response time or a constant packet send rate, less so for less action-y games.</p>

<p>Send raw bye data, compressed/packed as best you can.  It lets clients with worse connections play better, is faster, and keeps your server bandwidth costs down.  Some platforms (not yours most likely) have requirements that the game be playable at some low bandwidth like 128kbps, so packing your packets efficiently is a good skill to cultivate.  Good game network programmers tend to get hired quickly and paid towards the higher end for game devs, and knowing how to keep bandwidth usage low is part of that skill set.  XML is great for a number of reasons, but being small isn't one of them.</p>

<p>Packing mostly comes down to only using as many bits as you need and no more.  If all your tiles can be enumerated with 4 bits, pack two tiles per byte.  It's a bit more work when things don't line up nicely, but not much.  If you use floats, consider writing the code for 16-bit half-precision or custom precision and use that as appropriate (its only a few lines of code - I have a simple template that supports arbitrary mantissa and exponent sizes and optional sign bit that I can also use for half-precision; converting to and from single and double precision is super simple.)</p>

<p>It can be helpful to have a bitstream (vs the usual byte stream) buffer that you can read and write values to.</p>

<p>Actually handling the networking part differs heavily by platform, which is why libevent is useful.  Best recommendation there is to not worry deeply about it unless you want to be a pro game network coder.  If you so want to learn, your best bet is to just read a lot of books and online docs on hoe each OS's network stack and API works.  Making Linux work well is very different than an XBox, for instance.</p>

<p>Only send meaningful changes.  If an object is not moving, there is no need to send position.  Likewise, if the client he already been sent a chunk if the world and it hadn't changed, don't send it again.</p>

<p>Use some form of Area of Interest filtering to send only relevant things to each client.  The client cant see an object 10 miles away, so don't send updates about that object.  Just send updates about nearby objects.</p>

<p>As always, read the <a href=""http://gafferongames.com/networking-for-game-programmers/"" rel=""noreferrer"">Gaffer on Games</a> networking articles for a good light introduction to networking games.</p>
","48346"
"Typical Maximum steering angle of a real car","30027","","<p>I'm building a car sim in Unity3D. I'm trying to set the properties of the car to be as realistic as possible. I can't seem to get a straight answer on Google so I thought of asking here.</p>

<p>What is the typical maximum steering angle of a normal passenger car ?</p>
","<p>You can calculate this based on the properties of the vehicle. Using <a href=""http://en.wikipedia.org/wiki/Ackermann_steering_geometry"" rel=""noreferrer"">Ackermann steering geometry</a> you can calculate the center of the turning circle. This will take into account the length and width of the car and simulate accurately the maximum steering radius you can take.</p>

<p><img src=""https://i.stack.imgur.com/DQsP9.png"" alt=""enter image description here""></p>

<p>The reason you're unable to find a definitive answer is because it varies from car make to car make. The maximum turning angle of the front wheels depends on the available wheel well space and the hardware involved. You can assume some maximums based on the hardware commonly involved. I would say the wheels wouldn't turn any more than 65 degrees in either direction. That's a pretty high upper bound. However, this is something you can simulate using the model you've created of your car. How far can you turn the wheels before they contact the wheel well?</p>
","50024"
"What name should I give each difficulty level?","29985","","<p>I have a game with 4 difficulty levels (or levels of AI) and I'm wondering what to name them instead of the boring Easy, Normal, Hard, Impossible.</p>
","<p>Naming is one of those things that people can spend a lot of time tossing around.  A little comedic value always makes it more memorable - for instance, the difficulty levels from Rise of the Triad were more descriptive phrases that gave it a little more character.</p>

<p><img src=""https://i.stack.imgur.com/OG7AC.jpg"" alt=""Rise of the Triad difficulty screen""></p>

<p>Sean's advice is spot on too - theme them after something related to your game.  Here are some examples:</p>

<h3>Street racing game using import tuner-type cars:</h3>

<ul>
<li>I use auto-only</li>
<li>Where's third gear?</li>
<li>There is no speed limit</li>
<li>The Flash eats my dust</li>
</ul>

<p>The intended audience is probably the type of kid who likes cars but can't drive yet, so a little attitude to goad (I mean, encourage) them wouldn't be out of line.</p>

<h3>Puzzle game using blocks:</h3>

<ul>
<li>First time on the block</li>
<li>Blocks are my friends</li>
<li>Blockhead</li>
</ul>

<p>Here I use some fairly simple tie-ins with the puzzle type and the descriptions.</p>

<h3>Farm-building whatever:</h3>

<ul>
<li>Mouse</li>
<li>Piglet</li>
<li>Horse</li>
<li>Cow</li>
</ul>

<p>A simple way to have the user correlate difficulty with the size of the animal.  Much more memorable than ""easy"" etc.  You could sneak in an unlockable ""There is no cow level"" if you feel snarky enough.  This goes back to one-word descriptions too, if you're sticking to that limit.</p>

<h3>Side-scrolling platformer with very wacky theme</h3>

<ul>
<li>Ooze-ball</li>
<li>Magic fairy</li>
<li>Toaster</li>
<li>Spinach</li>
</ul>

<p>I'm thinking of something like Earthworm Jim, although I don't think there were more than 2 difficulty levels and I don't remember if they had names either, but this is with that in mind.  In this one, my idea was to be completely nonsensical, and try to use names for which there ARE NO correlations to difficulty.  The desired affect is to make it more memorable by being silly, and if the players talk to each other, they know immediately what they're referring to which makes it an inside joke and thus more memorable.</p>

<p>Anyway, from these examples hopefully you get idea how to approach it.  If you're really stuck, grab a thesaurus and find synonyms for ""easy"", etc.  At least it would be different. =)</p>
","1814"
"Game Development Degree vs Computer Science Degree","29905","","<p>I'm at the point in my life where I'm starting to look at schools, and was hearing a lot of mixed things about schools such as Digipen or Fullsail that target game development specifically. As someone who is planning on becoming a programmer and getting into the games industry, would getting a game development degree be better than a traditional computer science degree?</p>
","<p>Schooling isn't going to get you a job.</p>

<p>If you're good at what you do, and you care about it, you don't need a degree.</p>

<p>A game-focused degree is good at helping you getting your foot in the door since a lot of those schools have teachers or advisors who are actually in the industry.  It'll also help you by providing you useful team experience.</p>

<p>Also, and this is very important, a Computer Science degree <em>is not</em> about programming.  You might have a class here and there that might be useful, but the degree as a whole is not about good programming practices or really anything pragmatic that you would need on a day to day basis.  (Note: this may vary based on your school.)</p>

<p>That being said, getting a CS degree usually implies going to a non-game-focused school, which also implies getting a more well rounded education, which might pay off int the end.  Also a lot of regular schools have game development programs these days which could get you some connections to the local industry.</p>

<p>At least in my experience, getting a certificate from one of these game development colleges  is almost worthless on its own.  Unless you have side projects or have some kind of way of proving that you care about whatever field you're interested in other than just going to school, you'll be going in the ""maybe someday I'll get around to these people"" pile of resumes (hint: I won't).</p>

<p><em>Edit</em>: since I really didn't answer the question, basically my opinion is this:</p>

<p>If you have the motivation to work on games in your spare time, do that and get a traditional education.  It'll pay off in more ways than if you just went to more of a niche school. </p>

<p>If you're the kind of person that works better when somebody is telling them to do something, or if you need to feel like your money is on the line, try to go for a game dev school instead.</p>

<p>If your sole focus in life is to get into the game industry (it shouldn't be), and you're smart and motivated enough, try taking a year and working on things in your spare time (mods, solo projects, demos, whatever) and bypassing both options.</p>
","1612"
"How does one obtain an official Nintendo development SDK?","29601","","<p>I've seen before a topic here asking if there is any significant differences between using PALib or Nintendo's Nitro SDK... and that got me curious: what does it take to obtain the official SDK ? </p>
","<p>Costs I can't speak on personally, and I don't know if anyone who is a licensed developer can either. But there are some requirements that I do know of. I don't imagine it is that expensive because from what I saw around the internet the development kit for the Wii is under 5k. </p>

<p>What will cost you however, is having a brick-and-motar location dedicated to your studio's work. Nintendo requires this of it's licensees.</p>

<p>Following that, they also request back financials so that they can ensure that you would actually have the resources to bring your game to market.</p>

<p>If you think you qualify, you can <a href=""http://www.warioworld.com/apply/"">fill out the application to become a licensed Nintendo Developer</a>.</p>
","14730"
"in/out keywords in GLSL","29582","","<p>I don't really understand how to use the <strong><code>in</code></strong> / <strong><code>out</code></strong> keywords in GLSL, and google is being uncharacteristically unhelpful.</p>

<p>What exactly do they do? How would I use them if, for example, I want to pass a varying variable set per vertex to the fragment shader?</p>

<p>Literally every tutorial I find uses the <strong><code>varying</code></strong> / <strong><code>attribute</code></strong> keywords and that's not helpful.</p>
","<p>The storage qualifiers <code>in</code> and <code>out</code> actually have a purpose that contains and supersedes that of <code>varying</code> and <code>attribute</code>. They define what variables are respectively <strong>in</strong>puts and <strong>out</strong>puts for the shader. See the <a href=""http://www.khronos.org/files/opengl42-quick-reference-card.pdf"" rel=""noreferrer"">GLSL 4.2 reference card</a> page 7:</p>

<ul>
<li><strong><code>in</code></strong>: linkage into shader from previous stage</li>
<li><strong><code>out</code></strong>: linkage out of a shader to next stage</li>
<li><strong><code>attribute</code></strong>: same as <code>in</code> for vertex shader</li>
<li><strong><code>varying</code></strong>: same as <code>out</code> for vertex shader, same as <code>in</code> for fragment shader</li>
</ul>

<p>With the side note that the latter two are sort of deprecated: they are not present in the 4.2 core profile, only in the compatibility profile.</p>

<hr>

<h2>What exactly do they do?</h2>

<p>As for usage, take the vertex shader from <a href=""http://duriansoftware.com/joe/An-intro-to-modern-OpenGL.-Chapter-2.2:-Shaders.html"" rel=""noreferrer"">An intro to modern OpenGL. Chapter 2.2: Shaders</a>:</p>

<pre class=""lang-glsl prettyprint-override""><code>#version 110

attribute vec2 position;    
varying vec2 texcoord;

void main()
{
    gl_Position = vec4(position, 0.0, 1.0);
    texcoord = position * vec2(0.5) + vec2(0.5);
}
</code></pre>

<p>It should be rewritten in 4.2 core as:</p>

<pre><code>#version 420

in vec2 position;    
out vec2 texcoord;

void main()
{
    gl_Position = vec4(position, 0.0, 1.0);
    texcoord = position * vec2(0.5) + vec2(0.5);
}
</code></pre>

<hr>

<h2>Unhelpful Tutorials</h2>

<p>I'm guessing the main reason you find ""outdated"" tutorial code is that not everyone has access to GLSL 3.3+ compatible hardware. Regardless, for a good and more up to date tutorial I'll gladly point you in the direction of <a href=""https://gamedev.stackexchange.com/users/8240/nicol-bolas"">Nicol Bolas'</a> <a href=""http://alfonse.bitbucket.org/oldtut/"" rel=""noreferrer"">Learning Modern 3D Graphics Programming</a>.</p>
","29673"
"Why is it so bad to optimize too early?","29393","","<p>After looking into optimization a bit, I have discovered (literally everywhere) that it seems to be a universally recognized sin to optimize a game too early.</p>

<p>I really don't understand this, would it not be incredibly difficult to change some of the core structures of the game at the end, rather than developing them the first time with performance in mind?</p>

<p>I get that waiting until the game is finished will tell you if you even need optimizations, but shouldn't you do it anyway, after all, it could widen the variety of devices the game could run on, which would increase the number of potential players.</p>

<p>Could someone explain to me why it's such a bad idea to optimize too early?</p>
","<p><strong>Preamble:</strong></p>

<p>A few objections have been raised in the comments, and I think they largely stem from a misunderstanding of what we mean when we say ""premature optimization"" - so I wanted to add a little clarification on that.</p>

<p>""Don't optimize prematurely"" does <em>not</em> mean ""write code you know is bad, because Knuth says you're not allowed to clean it up until the end""</p>

<p>It means ""don't sacrifice time &amp; legibility for optimization until you know what parts of your program actually need help being faster."" Since a typical program spends most of its time in a few bottlenecks, investing in optimizing ""everything"" might not get you the same speed boost as focusing that same investment on just the bottlenecked code.</p>

<p>This means, <em>when in doubt</em>, we should:</p>

<ul>
<li><p>Prefer code that's simple to write, clear to understand, and easy to modify for starters</p></li>
<li><p>Check whether further optimization is needed (usually by profiling the running program, though one comment below notes doing mathematical analysis - the only risk there is you also need to check that your math is right)</p></li>
</ul>

<p>A premature optimization is <em>not</em>:</p>

<ul>
<li><p>Architectural decisions to structure your code in a way that will scale to your needs - choosing appropriate modules / responsibilities / interfaces / communication systems in a considered way.</p></li>
<li><p>Simple efficiencies that don't take extra time or make your code harder to read. Things like using strong typing can be both efficient and make your intent more clear. Caching a reference instead of searching for it repeatedly is another example (as long as your case doesn't demand complex cache-invalidation logic - maybe hold off on writing that until you've profiled the simple way first).</p></li>
<li><p>Using the right algorithm for the job. A* is more optimal and more complex than exhaustively searching a pathfinding graph. It's also an industry standard. Repeating the theme, sticking to tried-and-true methods like this can actually make your code easier to understand than if you do something simple but counter to known best practices. If you have experience running into bottlenecks implementing game feature X one way on a previous project, you don't need to hit the same bottleneck again on this project to know it's real - you can and should re-use solutions that have worked for past games.</p></li>
</ul>

<p>All those types of optimizations are well-justified and would generally not be labelled ""premature"" (unless you're going down a rabbit hole implementing cutting-edge pathfinding for your 8x8 chessboard map...)</p>

<p>So now with that cleared up, on to <em>why</em> we might find this policy useful in games specifically:</p>

<hr>

<p>In gamedev especially, iteration speed is the most precious thing. We'll often implement and re-implement far more ideas than will ultimately ship with the finished game, trying to ""find the fun.""</p>

<p>If you can prototype a mechanic in a straightforward &amp; maybe a bit naive way and be playtesting it the next day, you're in a much better position than if you spent a week making the most optimal version of it first. Especially if it turns out to suck and you end up throwing out that feature. Doing it the simple way so you can test early can save a ton of wasted work optimizing code you don't keep.</p>

<p>Non-optimized code is also generally easier to modify and try different variants on than code that's finely-tuned to do one precise thing optimally, which tends to be brittle and harder to modify without breaking it, introducing bugs, or slowing it way down. So keeping the code simple and easy to change is often worth a little runtime inefficiency throughout most of development (we're usually developing on machines above the target spec, so we can absorb the overhead and focus on getting the target experience first) until we've locked down what we need from the feature and can optimize the parts we now know are slow.</p>

<p>Yes, refactoring parts of the project late in development to optimize the slow spots can be hard. But so is refactoring repeatedly throughout development because the optimizations you made last month aren't compatible with the direction the game has evolved since then, or were fixing something that turned out not to be the real bottleneck once you got more of the features &amp; content in.</p>

<p>Games are weird and experimental — it's hard to predict how a game project and its tech needs will evolve and where the performance will be tightest. In practice, we often end up worrying about the wrong things — search through the performance questions on here and you'll see a common theme emerge of devs getting distracted by stuff on paper that likely is not a problem at all.</p>

<p>To take a dramatic example: if your game is GPU-bound (not uncommon) then all that time spent hyper-optimizing and threading the CPU work might yield no tangible benefit at all. All those dev hours could have been spent implementing &amp; polishing gameplay features instead, for a better player experience.</p>

<p>Overall, most of the time you spend working on a game will not be spent on the code that ends up being the bottleneck. Especially when you're working on an existing engine, the super expensive inner loop stuff in the rendering and physics systems is largely out of your hands. At that point, your job in the gameplay scripts is to basically stay out of the engine's way - as long as you don't throw a wrench in there then you'll probably come out pretty OK for a first build.</p>

<p>So, apart from a bit of code hygiene and budgeting (eg. don't repeatedly search for/construct stuff if you can easily reuse it, keep your pathfinding/physics queries or GPU readbacks modest, etc), making a habit of not over-optimizing before we know where the real problems are turns out to be good for productivity - saving us from wasting time optimizing the wrong things, and keeping our code simpler and easier to tweak overall.</p>
","141400"
"Can I do server side programming with unity?","29363","","<p>Another thought to my <a href=""https://gamedev.stackexchange.com/questions/5692/client-side-code-in-browser-with-server-communication"">last question</a>. If i were to do a client/server game with unity3d would i be able to do serverside programming with unity? if not can i use C# .net? if not then is there some sort of package or lib i can use with C++? is the communication just raw sockets?</p>
","<p>Unity's built-in networking is RakNet.  As far as I know, inside Unity it's only really for peer to peer games (i.e. you can't really run a standalone server).</p>

<p>Most web games I know of that use Unity and have multiplayer use <a href=""https://www.exitgames.com/en/PUN"" rel=""nofollow"">Exit Games' Photon</a>.  Paradise Paintball uses it.  So does Atmosphir.  You write server code in .NET that gets compiled to a DLL and run with their server software.  There's a client DLL you can just drop into Unity along with your own specific code.  </p>

<p>You can't distribute the server since it's licensed per machine you're running on, but if you just want clients to be able to connect to your servers then it's a proven solution for that.</p>
","5699"
"Why is Minecraft's default resolution (seemingly) non-standard?","29326","","<p>Background: I'm writing some articles on Minecraft in an attempt to introduce 10-year olds to development through modding. I know very little about the game itself, though :)</p>

<p>I'm trying to understand why Minecraft appears to run in an ""odd"" default resolution. Grabbing a screenshot, I think it's rendering at 550x310 but that doesn't seem to match any of the ""common"" aspect ratios (although it's close to 16:9), nor is it evenly divisible by 16, which appears to be what the texture packs use.</p>

<ol>
<li><p>Is it actually running at 550x310 in its default windowed mode? If not, what is the resolution?</p></li>
<li><p>Depending on the answer to the first question, why isn't it using one of the standard aspect ratios? I'm not familiar with OpenGL programming either so perhaps there is a common resolution close to what I'm guessing at that would make perfect sense.</p></li>
</ol>
","<p>Actually, Minecraft will run at whatever resolution you size your window to (348x866):</p>

<p><img src=""https://i.stack.imgur.com/PnhVV.png"" alt=""enter image description here""></p>

<p>So it's likely that whomever took the screenshot you grabbed, just happened to have their window sized that way.</p>

<p>The default screen size when I start the game appears to be 856x482, which is pretty close to 16:9. It doesn't need to use a standard aspect ratio or resolution. The display size doesn't have anything to do with the texture packs. It's not required to be divisible by 16. A game might have these restrictions if it was 2D and you wanted to fit a whole number of tiles on the screen at one time. However, with a 3D game the display size (in windowed mode) can be whatever the developer decides they like. </p>

<p>When the game is run full screen, it's best to match the game resolution and aspect ration with the resolution and aspect ratio of the screen.</p>
","58644"
"How do I tell if an object is currently colliding with another object?","29251","","<p>I can't figure out how to tell if a <code>GameObject</code> is currently colliding with another in Unity. I've looked online and can't find any tutorials or answers that work.</p>

<p>Also, what's the difference between a <code>Collision</code> and a <code>Collider</code> w.r.t. Unity?</p>

<hr>

<p>My dilemma:</p>

<p>I have a third person controller set up and want it to wall jump. I already have an isGrounded function, I just need to test if I'm hitting anything other than the floor. Otherwise I want it to wall jump backwards.</p>

<p>I've already tried:  </p>

<pre><code>if (this.OnCollisionEnter){
     ...
}

if (Collider.OnCollisionEnter){
     ...
}
</code></pre>

<p>But it did not work. I now tried:</p>

<pre><code>function OnCollisionStay(){
   Debug.Log(""Collision"");
}
</code></pre>

<p>I checked my logs, console and still can't find anything.</p>
","<ol>
<li><p>The function <code>MonoBehavior.OnCollisionStay()</code> (<a href=""http://docs.unity3d.com/Documentation/ScriptReference/MonoBehaviour.OnCollisionStay.html"" rel=""nofollow"">link</a>) is called every frame for every collider that is touching another collider there are also <code>OnCollisionEnter()</code> (<a href=""http://docs.unity3d.com/Documentation/ScriptReference/MonoBehaviour.OnCollisionEnter.html"" rel=""nofollow"">link</a>) and <code>OnCollisionExit()</code> (<a href=""http://docs.unity3d.com/Documentation/ScriptReference/MonoBehaviour.OnCollisionExit.html"" rel=""nofollow"">link</a>) for similar behavior at the start and end of contact.  If you want to do something while your object is being collided with, put that function in a script on that object and put your code in there.</p></li>
<li><p>A Collider is the object that does the colliding.  The Collision is the event/data that tells you about the collision.  Some explanation can be found <a href=""http://docs.unity3d.com/Documentation/Components/class-SphereCollider.html"" rel=""nofollow"">here</a> and other places in the Unity docs. </p></li>
</ol>
","33503"
"Good resources for learning about game architecture?","29190","","<p>Are there any good resources for learning about game architectures? I am looking for high level overviews of different architectures. I tend to find information about the various pieces of a game such as entities, physics engines, scripting, etc but not about how to bring all of the pieces together.</p>

<p>As a bonus, how does the type of game influence this? For example, a platformer and an MMO would have differences.</p>
","<p><a href=""http://www.gameenginebook.com/"">Game Engine Architecture</a> by Jason Gregory is a good book in this topic. You can read it in <a href=""http://books.google.cl/books?id=LJ20tsePKk4C&amp;printsec=frontcover&amp;dq=game+engine+architecture&amp;hl=es&amp;ei=oC0_TL2DHYOclgfYutSrCA&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=2&amp;ved=0CC0Q6AEwAQ#v=onepage&amp;q&amp;f=false"">Google Books</a> before buying it.</p>
","466"
"How are bullets simulated in video games?","28937","","<p>I have been playing games like MW2 recently and, as a programmer, I tend to ask myself how do they make the game so immersive. For example, how to they simulate bullet speed. </p>

<ol>
<li><p>When an NPC fires a bullet from his gun, does the bullet really travel from his gun to the given target or do they they completely ignore this part and just put a bullet hole on the target?</p></li>
<li><p>If the bullet is really travelling from the gun to the target, at what speed is it actually travelling? </p></li>
</ol>
","<p>Most FPS games use raycasting for the actual gameplay; bullets instantly travel and hit the target when fired.</p>

<p>But most games also employ the use of ""fake"" tracers. Every 3 shots, or some other interval, a tracer will be fired along with the bullet, the tracer will be really fast, but not instantaneous. This is done as a visual effect only, and does not affect the game-play directly, but helps give cues to the shooter, the shootee, and gives bystanders a directional reference to gunshots.</p>

<p>Most games that use these kinds of bullet physics are unrealistic, as there is no ricochets, no bullet fragments, and if there is any penetration its usually linear.</p>

<p>Some games, such as ARMA II, STALKER(entire series) use more realistic bullet physics with travel time, ricochets, and penetration with deflection angles. I believe these systems are using raycasting, but with a limit that is determined by the speed of the bullet. With these games the muzzle velocity can be realistic as in ARMA II, or looks about right as in STALKER.</p>

<p>I greatly prefer having realistic bullet physics, as guns fire projectiles, not lasers.</p>
","13656"
"Changing color of UI Text in Unity into custom values","28593","","<p>There are a few objects in the scene as well as a title. I want the title to change its text and color based on the object that is mouse-overed. The script below is added to each object that is intended to change the color and text of the title.</p>

<p>The title changes it's color correctly when values like <code>Color.red</code> are assigned but doesn't change color when values like <code>new Color(254f, 152f, 203f)</code>. </p>

<pre><code>public Text title;

void OnMouseEnter()
{
    switch(name)
    {
    CONDITION1:
        title.color = Color.yellow;  // works well
        break;

    CONDITION2:
        title.color = new Color(254f, 152f, 203f);  // doesn't work
        break;
    }

    title.text = name;
}

void OnMouseExit()
{
    title.text = ""DEFAULT VALUE"";
    title.color = Color.white;
}
</code></pre>

<p>Is there a specific reason to the former method to work and latter not to work? How can I change the color of the <code>Text</code> element with custom values?</p>
","<p>Constructor of Color class takes float parameters from 0 to 1 like this <code>title.color = new Color(1f, 0.5f, 0.8f);</code></p>
","92151"
"glTranslate, how exactly does it work?","28412","","<p>I have some trouble understanding how does glTranslate work.
At first I thought it would just simply add values to axis to do the transformation.</p>

<p>However then I have created two objects that would load bitmaps, one has matrix set to GL_TEXTURE:</p>

<pre><code>public class Background
{
    float[] vertices = new float[]
        { 0f, -1f, 0.0f, 
          4f, -1f, 0.0f, 
          0f, 1f, 0.0f, 
          4f, 1f, 0.0f };

    ....
    private float backgroundScrolled = 0;
    public void scrollBackground(GL10 gl)
    {
        gl.glLoadIdentity();
        gl.glMatrixMode(GL10.GL_MODELVIEW);
        gl.glTranslatef(0f, 0f, 0f);
        gl.glPushMatrix();

        gl.glLoadIdentity();
        gl.glMatrixMode(GL10.GL_TEXTURE);
        gl.glTranslatef(backgroundScrolled, 0.0f, 0.0f);
        gl.glPushMatrix();

        this.draw(gl);
        gl.glPopMatrix();

        backgroundScrolled += 0.01f;
        gl.glLoadIdentity();
    }
}
</code></pre>

<p>and another to GL_MODELVIEW:</p>

<pre><code>public class Box
{
    float[] vertices = new float[]
        { 0.5f, 0f, 0.0f, 
          1f, 0f, 0.0f, 
          0.5f, 0.5f, 0.0f, 
          1f, 0.5f, 0.0f };

    ....

    private float boxScrolled = 0;
    public void scrollBackground(GL10 gl)
    {
        gl.glMatrixMode(GL10.GL_MODELVIEW);
        gl.glLoadIdentity();
        gl.glTranslatef(0f, 0f, 0f);
        gl.glPushMatrix();

        gl.glMatrixMode(GL10.GL_MODELVIEW);
        gl.glLoadIdentity();
        gl.glTranslatef(boxScrolled, 0.0f, 0.0f);
        gl.glPushMatrix();

        this.draw(gl);
        gl.glPopMatrix();

        boxScrolled+= 0.01f;
        gl.glLoadIdentity();
    }
}
</code></pre>

<p>Now they are both drawn in Renderer.OnDraw. However background moves exactly 5 times faster. If I multiply boxScrolled by 5 they will be in sinc and will move together. If I modify backgrounds vertices to be</p>

<pre><code>    float[] vertices = new float[]
        { 1f, -1f, 0.0f, 
          0f, -1f, 0.0f, 
          1f, 1f, 0.0f, 
          0f, 1f, 0.0f };
</code></pre>

<p>It will also be in sinc with the box.
So, what is going under glTranslate?</p>
","<p>Here is my full answer:</p>

<p>Your glPushMatrix and glPopMatrix count should be equal. It's first problem.</p>

<p>But main problem is in matrix mode. In first case (background), you are using texture matrix, which is modified by glTranslate. It means, that in every step texture coordinates will be multiplied by this translation. </p>

<p>Because texture coordinates are in range &lt;0,1>, and your background rectangle is wide 4 units, <strong>it will not be translated by 0.01</strong> every frame, but <strong>it will be translated by 0.04 units</strong> in world.</p>

<p>In second case (box), you are changing modelview matrix. Which will cause to translate your box by 0.01 units every frame in world.</p>

<p>When you change background rectangle to new coordinates (x coordinates are 0 and 1), then every frame texture coordinates are really translated by 0.01 units.</p>
","30293"
"What are normal, tangent and binormal vectors and how are they used?","28349","","<p>I would like to find out the following information:</p>

<ul>
<li>What are they?</li>
<li>Example usage in game development (the area they are used in)</li>
</ul>

<p>About the following vector types:</p>

<ul>
<li><code>Normal</code></li>
<li><code>Tangent</code></li>
<li><code>Binormal</code></li>
</ul>

<p>A simple game development centric explanation would suffice.</p>
","<p>Generally speaking, a Normal vector represents the direction pointing directly ""out"" from a surface, meaning it is orthogonal (at 90 degree angles to) any vector which is coplanar with (in the case of a flat surface) or tangent to (in the case of a non-flat surface) the surface at a given point.</p>

<p>A Tangent vector is typically regarded as one vector that exists within the surface's plane (for a flat surface) or which lies tangent to a reference point on a curved surface (ie. if a flat plane were constructed with the same normal from the reference point, the tangent vector would be coplanar with that plane).</p>

<p>The concept of a Binormal vector is a bit more complex; in computer graphics, it generally refers to a Bitangent vector (reference <a href=""http://mathworld.wolfram.com/BinormalVector.html"" rel=""noreferrer"">here</a>), which is effectively the ""other"" tangent vector for the surface, which is orthogonal to both the Normal vector and the chosen Tangent vector.<img src=""https://i.stack.imgur.com/tAQNN.png"" alt=""Normal, Tangent, Bitangent""></p>

<p>With regards to how they are computed, this varies depending on the complexity of the surface and how precise you want the normal to be (in some cases, such as with smooth shaders, it is more desirable to calculate a normal for an approximated surface, when the actual information for a surface is not present), but there are several generalized formulas given <a href=""http://en.wikipedia.org/wiki/Normal_%28geometry%29#Calculating_a_surface_normal"" rel=""noreferrer"">here</a>.</p>

<p>In terms of where they occur, the answer is <strong>EVERYWHERE</strong>. Normal vectors are used to position cameras and objects in 3D space, to determine trajectories, reflections, and angles in physics calculations, to map skins and textures to 3D models, to determine aim trajectory offsets in AI programming, to give hints to shaders about how to light, shade, and color points on a surface relative to lights, the camera, and other objects, and so on. They are possibly one of the most useful pieces of information to have in a 3D environment, and they even come in extremely handy in 2D as well.</p>
","51402"
"How does Dwarf Fortress keep track of so many entities without losing performance?","28274","","<p>In Dwarf Fortress you can have hundreds of Dwarves, animals, goblins, etc in game at any one time, each with their own complex AI and pathfinding routines. My question is how does this not produce noticeable slowdown? Does each Dwarf run in its own thread?</p>
","<p>Any system which had a thread for each of so many characters would run out of resources very quickly. Threads may give you access to extra processor cores but they don't make anything intrinsically more efficient, and they come with overhead.</p>

<p>The simple answer is just to be efficient about processing each entity in the game.</p>

<ul>
<li>Don't process every entity each frame.</li>
<li>Split processing into stuff that needs doing often and stuff that does not need doing often.</li>
<li>Spread long-running algorithms across multiple frames so that they don't block processing in other systems.</li>
<li>Ensure that efficient algorithms and data structures are used.</li>
<li>Cache the results of expensive calculations if they are likely to be used again.</li>
</ul>
","32819"
"Unity3D Orbit around orbiting object (transform.RotateAround)","27732","","<p>The best way to explain this is I'm attempting to make a small model solar system (not to scale or anything complicated, just simple rotation as a learning exercise). There's a sun, a planet, and that planet's moon. The planet orbits like normal, however the moon orbiting around the planet shoots off and makes an extremely large and far-away orbit.</p>

<p>My code is as follows (where ""target"" is the object being orbited around, and ""transform""  is the orbiting object itself. Both are ""Transform"" objects.):</p>

<pre><code>public class RotateAndOrbit : MonoBehaviour {
    public Transform target;
    public float RotationSpeed = 100f;
    public float OrbitDegrees = 1f;
    void Update () {
       transform.Rotate(Vector3.up, RotationSpeed * Time.deltaTime);
       transform.RotateAround(target.position, Vector3.up, OrbitDegrees);
    }
}
</code></pre>

<p>I'm not sure how to compensate for this or even what my mistake is called, but any help would be appreciated.</p>
","<p>Make the moon a child of the planet object, and the planet a child of the star. Now, if the moon wasn't orbiting, it will stay with the planet in its orbit. </p>

<p>You can easily rotate an arbitrary point around another arbitrary point with the following:</p>

<pre><code>public static Vector3 RotatePointAroundPivot(Vector3 point, Vector3 pivot, Quaternion angle) {
   return angle * ( point - pivot) + pivot;
}
</code></pre>

<p>When everything is set up in the parent/child fashion as I said above, you can easily create a generic script to handle the orbits. Then just drop that script onto the bodies you want to orbit their parents. Update the orbit by adding the rotation for that step:</p>

<pre><code>transform.position = 
    RotatePointAroundPivot(transform.position,
                           transform.parent.position,
                           Quaternion.Euler(0, OrbitDegrees * Time.deltaTime, 0));
</code></pre>
","62002"
"How does a collision engine work?","27701","","<p>How exactly does a <a href=""http://en.wikipedia.org/wiki/Physics_engine#Collision_detection"">collision engine</a> work?</p>

<p>This is an extremely broad question. What code keeps things bouncing against each other, what code makes the player walk into a wall instead of walk through the wall? How does the code constantly refresh the players position and objects position to keep gravity and collision working as it should?</p>

<p>If you don't know what a collision engine is, basically it's generally used in <a href=""http://en.wikipedia.org/wiki/Platform_game"">platform games</a> to make the player acutally hit walls and the like. There's the 2D type and the 3D type, but they all accomplish the same thing: collision.</p>

<p>So, what keeps a collision engine ticking?</p>
","<p>There is a big difference between a collision engine and a physics engine.  They do not do the same thing, although the physics engine generally relies on a collision engine.</p>

<p>The collision engine is then split into two parts: collision detection and collision response.  The latter is generally part of the physics engine.  This is why collision engines and physics engines are usually rolled into the same library.</p>

<p>Collision detection comes in two forms, discrete and continuous.  Advanced engines support both, as they have different properties.  In general, continuous collision detection is very expensive and only used where it is really needed.  The majority of collision and physics is handled using discrete methods.  In discrete methods, objects will end up penetrating each other, and the physics engine then works to push them apart.  So the engine does not actually stop a player from walking partially through a wall or the floor, it just fixes it up after detecting that the player is partially in the wall/floor.  I'm going to focus on discrete collision detection here, since that's what I have the most experience implementing from scratch.</p>

<p><strong>Collision Detection</strong></p>

<p>Collision detection is relatively easy.  Every object has a transform and a shape (possibly multiple shapes). Naive approaches would have the collision engine do an O(n^2) loop through all object pair and tests if there's overlap between the pairs. In smarter approaches there are multiple spatial data structures (e.g., for static vs dynamic objects), a bounding shape for each object, and multi-part convex sub-shapes for each object.</p>

<p>The spatial data structures include things like KD-Trees, Dynamic AABB trees, Octrees/Quadtrees, Binary Space Partitioning trees, and so on.  Each has their advantages and disadvantages, which is why some higher end engines use more than one.  Dynamic AABB trees for instance are really really fast and good for handling lots of moving objects while a KD-Tree may be more suitable for the static level geometry that objects collide with.  There are other options as well.</p>

<p>The broad phase uses the spatial data structures and an abstract bounding volume for each object.  A bounding volume is a simple shape that encloses the entire object, generally with the goal of enclosing it as ""tightly"" as possible while remaining cheap to do collision tests with.  The most common bounding shapes are Axis-Aligned Bounding Boxes, Object-Aligned Bounding Boxes, Spheres, and Capsules.  AABBs are generally considered the fastest and easiest (Spheres are easier and faster in some cases, but many of those spatial data structures would require converting the sphere into an AABB anyway), but they also tend to fit many objects rather poorly.  Capsules are popular in 3D engines for handling character-level collisions.  Some engines will use two bounding shapes, such as an AABB for the first level of detection and then an OABB or Capsule for the second.</p>

<p>The last phase of collision detection is to detect exactly where the geometry is intersecting.  This usually implies using the a mesh (or a polygon in 2D), though not always.  The purpose of this phase is to find out if the objects really truly do collide, if a fine level of detail is required (say, bullet collision in a shooter, where you want to be able to ignore shots that just barely miss), and also to find out exactly where the objects collide, which will affect how the objects respond.  For example, if a box is sitting on the edge of a table, the engine must know at what points the table is pushing against the box; depending on how far the box is hanging over, the box may begin to tilt and fall off.</p>

<p><strong>Contact Manifold Generation</strong></p>

<p>Algorithms used here include the popular GJK and Minkowski Portal Refinement algorithms, as well as the Separating Axis test.  Because the popular algorithms typically only work for convex shapes, it is necessary to break many complex objects into convex sub-objects, and do collision tests for each individually.  This is one of the reasons why simplified meshes are often used for collision, as well as the reduction in processing time for using fewer triangles.</p>

<p>Some of these algorithms not only tell you that the objects have collided for sure, but where they collided -- how far they are penetrating each other and what the ""contact points"" are.  Some of the algorithms require additional steps, such as polygon clipping, to get this information.</p>

<p><strong>Physical Response</strong></p>

<p>At this point, a contact has been discovered, and there is enough information for the physics engine to process the contact.  The physics handling can get very complex.  Simpler algorithms work for some games, but even something as seemingly straight-forward as keeping a stack of boxes stable turns out to be quite difficult and requires a lot of work and non-obvious hacks.</p>

<p>At the most basic level, the physics engine will do something like this: it'll take the colliding objects and their contact manifold and calculate the new positions required to separate the collided objects.  It will move the objects to these new positions.  It'll also calculate the velocity change resulting from this push, combined with restitution (bounciness) and friction values.  The physics engine will also apply any other forces acting on the objects, such as gravity, to calculate the objects' new velocities, and then (next frame) their new positions.</p>

<p>More advanced physics response gets complicated quickly.  The approach above will break down in many situations, including one object sitting on top of two others.  Dealing with each pair by itself will cause ""jitter"" and the objects will bounce around a lot.  The most basic technique is to do a number of velocity-correction iterations over the pairs of colliding objects.  For example, with a box ""A"" sitting on top of two other boxes ""B"" and ""C"", the collision A-B will be handled first, causing box A to tilt further into box C.  Then the A-C collision is handled, evening out the boxes somewhat, but pulling A down and into B.  Then another iteration is done, so the A-B error caused by the A-C correction is slightly resolved, creating a bit more error in the A-C response.  Which is handled when A-C is processed again.  The number of iterations done is not fixed, and there is no point at which it becomes ""perfect,"" but rather just whatever number of iterations stops giving meaningful results.  10 iterations is a typical first try, but it takes tweaking to figure out the best number for a particular engine and a particular game's needs.</p>

<p><strong>Contact Caching</strong></p>

<p>There are other tricks that turn out to be really handy (more or less necessary) when dealing with many types of games.  Contact caching is one of the more useful ones.  With a contact cache, each set of colliding objects is saved in a lookup table.  Each frame, when a collision is detected, this cache is queried to see if the objects were previously in contact.  If the objects were not previously in contact, then a ""new collision"" event can be generated.  If the objects were previously in contact, the information can be used to provide a more stable response.  Any entries in the contact cache that were not updated in a frame indicate two objects that separated, and a ""separating object"" event can be generated.  Game logic often has uses for these events.</p>

<p>It's also possible for the game logic to respond to new collision events and flag them as ignored.  This is really helpful for implemented some features common in platforms, like platforms that you can jump up through but stand on.  Naive implementations may just ignore collisions that have a downward platform->character collision normal (indicating the player's head hit the bottom of the platform), but without contact caching, this will break if the player's head pokes up through the platform and then he begins to fall.  At that point, the contact normal may end up pointing upward, causing the player to pop up through the platform when he shouldn't.  With contact caching, the engine can reliably look at the initial collision normal and ignore all further contact events until the platform and player separate again.</p>

<p><strong>Sleeping</strong></p>

<p>Another very useful technique is to mark objects as being ""asleep"" if they are not being interacted with.  Sleeping objects do not get physics updates, do not collide with other sleeping objects, and basically just sit there frozen in time until another non-sleeping object collides with them.</p>

<p>The impact is that all the pairs of colliding objects that are just sitting there doing nothing don't take up any processing time.  Also, because there is not a constant amount of tiny physics corrections, stacks will be stable.</p>

<p>An object is a candidate for sleeping when it has had a near-zero velocity for more than a single frame.  Note that the epsilon you use for testing this near-zero velocity will probably be a bit higher than the usual floating point comparison epsilon, as you should expect some jitter with stacked objects, and you want whole stacks of objects to fall asleep if they're staying ""close enough"" to stable.  The threshold will of course require tweaking and experimentation.</p>

<p><strong>Constraints</strong></p>

<p>The last major bit of many physics engines is constraint solver.  The purpose of such a system is to facilitate the implementation of things like springs, motors, wheel axis, simulated soft-bodies, cloth, ropes and chains, and sometimes even fluid (though fluid is often implemented as an entirely different system).</p>

<p>Even the basics of constraint solving can get very math intensive and goes beyond my expertise in this subject matter. I recommend checking out <a href=""http://gamedevelopment.tutsplus.com/tutorials/modelling-and-solving-physical-constraints--gamedev-12578"">Randy Gaul's excellent article series on physics</a> for a more in-depth explanation of the topic.</p>
","26506"
"How can I get involved with open source game projects?","27544","","<p>I have a limited experience in game development and would like to get involved with open source game project.  Where should I look and how should I begin?</p>
","<p>Without referring to any of my previous projects, I can say that I've been involved with a great deal of open source activities, game-related and otherwise, and by and large I have thoroughly enjoyed the ride. Right now I'm a manager with the jMonkeyEngine project. I'll be glad to type up somewhat of an 'introduction to open source games', but bear in mind this will by no means be an exhaustive list of resources.</p>

<p>I highly recommend checking out <a href=""http://www.googleguide.com/similar_pages.html"" rel=""nofollow noreferrer"">similar pages</a> for all of the links I provide.</p>

<h2>Free, open source etc. - The subtle differences</h2>

<p>It's worth merely noting that there are some differences to terms like 'free' (vs 'gratis'), 'open source', and 'free software'. The GNU project has a good but somewhat one-sided take on it, titled <a href=""http://www.gnu.org/philosophy/open-source-misses-the-point.html"" rel=""nofollow noreferrer"">Open Source Misses The Point</a>. Simply put though, I'd say the most damaging misconception about open source is that you're not supposed to make any money off of it.</p>

<p>Point is, even if you're giving away your code as well as your art assets (though copyrighted art assets could be a good way to make an essential part of your game proprietary, without really damaging its technical 'openness') for free, that doesn't mean you can't commercialize other parts of your project.</p>

<p>There's another gamedev thread here that'll hopefully bring in many good ideas on <a href=""https://gamedev.stackexchange.com/questions/297/what-are-some-common-ways-to-generate-revenue-from-a-free-game"">how to commercialize a free game</a>.</p>

<h2>Independent preparation</h2>

<p>If you want to sharpen your talents before getting involved with a group of fellow developers, 'try make your own game' is a no-brainer, and there's no shortage of open source engines (see <a href=""http://www.devmaster.net/engines/"" rel=""nofollow noreferrer"">devmaster.net/engines</a> and <a href=""http://en.wikipedia.org/wiki/List_of_game_engines"" rel=""nofollow noreferrer"">wikipedia.org/wiki/List_of_game_engines</a>). If you're looking for a little motivational push though, there's nothing like a little bit of competition:</p>

<ul>
<li><a href=""http://www.ludumdare.com/"" rel=""nofollow noreferrer"">Ludum Dare</a> - Frequently hosted 48h game competitions.</li>
<li><a href=""http://gamejolt.com/"" rel=""nofollow noreferrer"">GameJolt</a> - Infrequently hosts uniquely themed competitions. You can also upload your finished games there for free promotion.</li>
<li><a href=""http://www.gamecareerguide.com/features/"" rel=""nofollow noreferrer"">GameCareerGuide's Game Design Challenges</a> - Although not always requiring programming, GCG's weekly challenges open up a lot of opportunity for networking and unique concepts.</li>
</ul>

<h2>Find a project</h2>

<p>There are plenty of places to look, and it's been a while since I was on the lookout, but I reckon most of the hobbyist projects (because that's what every open source game project is right now) make an appearance at either of these waterholes:</p>

<ul>
<li><a href=""http://www.gamedev.net/community/forums/forum.asp?forum_id=8"" rel=""nofollow noreferrer"">GameDev.net - Help Wanted</a> or</li>
<li><p><a href=""http://www.indiedb.com/jobs"" rel=""nofollow noreferrer"">IndieDB - Jobs</a> (they also have a
<a href=""http://www.indiedb.com/jobs"" rel=""nofollow noreferrer"">recruiting forum</a>, I dunno why).</p>

<p>Remember, progress is the best sign of promise; look for it. Speaking of which...</p></li>
</ul>

<h2>Choose a project</h2>

<p>Choosing the right project that matches your particular skillset and interests (no one's gonna want to work with you if you're not enthusiastic about the game you're making) can prove to be quite the challenge. Take your time, and for the love of all that is good pick (or start, but I'll get back to that) a project that looks perfectly achievable within just a couple months time, at most. There are disappointingly few of these around, but for a first-time open source project it comes highly recommended.</p>

<p><strong>Extra pointers:</strong></p>

<ol>
<li>Don't start out too picky; look in
different sites, consider odd
genres, get to know the width of
your skill-sets and interests.</li>
<li>Consider scope. How much time are
you willing to commit? How soon do
you want to see the project finish? Any pending time-sinkholes (studies, work, life commitment) worth factoring in?</li>
<li>Start by talking. Exchange at least
1000 words with someone involved
in a given project before finally making up
your mind.</li>
<li>Now stick with it and bring it to
the finishline!</li>
</ol>

<p>A great thing about open source projects is the low barrier to entry. There's loads of ways to contribute to a project besides applying your key skills. Here's <a href=""http://www.jmonkeyengine.com/wiki/doku.php/contribute"" rel=""nofollow noreferrer"">a list I made</a> for my own project. (I might rewrite and relocate that to a 'neutral' domain soon). I'm not a programmer myself, so I spend a lot of my time doing 'miscellaneous' tasks like listed there.</p>

<p>Honestly, the 'open source games' complete/incomplete ratio could use a boost. The beauty of transparency and open source though is that 'incomplete' is far from 'unsuccessful' so long as you make the most out of the ride.</p>

<p><strong>Update:</strong> Also see my closely related <a href=""http://opensource.com/life/11/2/open-source-games-it%E2%80%99s-team-effort"" rel=""nofollow noreferrer"">article on opensource.com</a>, which is based on this answer.</p>
","2681"
"How do I implement anti-aliasing in OpenGL?","27357","","<p>I want to do full-screen anti-aliasing in OpenGL, and dont want to use the anti-aliasing that is provided by OpenGL itself, since I am building a game and want good effects in it.</p>

<p>How should I proceed?</p>
","<p>There are several alternatives to native MSAA in OpenGL. With post-processing effects, the best thing about them is that you can usually just throw in the shader to the final, unprocessed image and it does the rest. Here are three methods worth taking a look:</p>

<ul>
<li><p><a href=""http://www.geeks3d.com/20110405/fxaa-fast-approximate-anti-aliasing-demo-glsl-opengl-test-radeon-geforce/"">Fast Approximate Anti-Aliasing (Geeks3D)</a> - Good in most cases. Pretty easy to apply and understand. Drawback is sharp, high contrast noise in textures gets blurred a bit. Edges as subtle as 1/4 pixels steep look dead-accurate as traditional MSAA. Any less steep than that, it loses a bit of accuracy.</p></li>
<li><p><a href=""http://www.gamedev.net/topic/580517-nfaa---a-post-process-anti-aliasing-filter-results-implementation-details/"">Normal Filtered Anti-Aliasing (GameDev</a>) - Haven't tested this one yet accurately, but it's the easiest to understand. In best cases it resembles 16x MSAA and in worst cases it's like 2x MSAA. It generates a temporary normal map to represent edges and relative angles. You can sample the normal map either with luma difference or color difference.</p></li>
<li><p><a href=""http://www.iryoku.com/mlaa/"">Morphological Anti-Aliasing (Iryoku)</a> - been improved to SMAA - Subpixel Mophological AA. It's pretty complex at 4 passes, but achieves the best results I've seen. It creates gradients along edges as gradual as 1/100 to 1/200 pixels steep (!). Sampling can be luma-based, color-based or depth-based. Textures stay very crisp and clean. (the example is DX10 and HLSL based, would take some time to port it to GLSL accurately)</p></li>
</ul>

<p>These techniques don't super-sample or multi-sample, so lines that appear less than 1 pixel in thickness will appear with gaps and not be anti-aliased correctly. This is the downside to using a non-MSAA approach. Since you're only working with a raster image at full resolution, you can't create additional information from these empty gaps.</p>

<p>Take notice that all of these techniques are dependent on sampling adjacent luma (brightness) or chroma (color) values. Calculating luma and optional gamma correction requires additional instructions on the AA shader, though it's pretty straightforward. 
You can offload this by calculating the luma in the previous shader that provides the un-retouched image, storing the luma in the alpha channel. Then in the AA shader, you will simply sample the alpha.</p>
","18783"
"In Unity, how do I correctly implement the singleton pattern?","27337","","<p>I have seen several videos and tutorials for creating singleton objects in Unity, mainly for a <code>GameManager</code>, that appear to use different approaches to instantiating and validating a singleton.</p>

<p>Is there a correct, or rather, preferred approach to this?</p>

<p>The two main examples I have encountered are:</p>

<p><strong>First</strong></p>

<pre><code>public class GameManager
{
    private static GameManager _instance;

    public static GameManager Instance
    {
        get
        {
            if(_instance == null)
            {
                _instance = GameObject.FindObjectOfType&lt;GameManager&gt;();
            }

            return _instance;
        }
    }

    void Awake()
    {
        DontDestroyOnLoad(gameObject);
    }
}
</code></pre>

<p><strong>Second</strong></p>

<pre><code>public class GameManager
{
    private static GameManager _instance;

    public static GameManager Instance
    {
        get
        {
            if(_instance == null)
            {
                instance = new GameObject(""Game Manager"");
                instance.AddComponent&lt;GameManager&gt;();
            }

            return _instance;
        }
    }

    void Awake()
    {
        _instance = this;
    }
}
</code></pre>

<p>The main difference I can see between the two is:</p>

<p>The first approach will attempt to navigate the game object stack to find an instance of the <code>GameManager</code> which even though this only happens (or should only happen) once seems like it could be very unoptimised as scenes grow in size during development.</p>

<p>Also, the first approach marks the object to not be deleted when the application changes scene, which ensures that the object is persisted between scenes. The second approach doesn't appear to adhere to this.</p>

<p>The second approach seems odd as in the case where the instance is null in the getter, it will create a new GameObject and assign a GameManger component to it. However, this cannot run without first having this GameManager component already attached to an object in the scene, so this is causing me some confusion.</p>

<p>Are there any other approaches that would be recommended, or a hybrid of the two above? There are plenty of videos and tutorials regarding singletons but they all differ so much it is hard to drawn any comparisons between the two and thus, a conclusion as to which one is the best/preferred approach.</p>
","<p>It depends, but usually I use a third method. The problem with the methods that you used is that in the event that the object is included to begin with, it will not remove them from the tree, and they can still be created by instantiating too many calls, which could make things really confusing. </p>

<pre><code>public class SomeClass : MonoBehavior {
    private static SomeClass _instance;

    public static SomeClass Instance { get { return _instance; } }


    private void Awake()
    {
        if (_instance != null &amp;&amp; _instance != this)
        {
            Destroy(this.gameObject);
        } else {
            _instance = this;
        }
    }
}
</code></pre>

<p>The problem with both of your implementations is that they do not destroy an object that is created later. It could work, but one could throw a monkey wrench into the works that could result in a very difficult to debug error down the line. Make sure to check in Awake if there is an instance already, and if so, destroying the new instance.</p>
","116010"
"How do Raymarch shaders work?","27306","","<p>I have been looking at shaders found here  shadertoy.com and most of the cool ones have noise and raymarch in common. I do not understand the source code at all but I really want to. How do these shaders work and how does the raymarch algorithm work? I've searched all over and can't find anything on the topic.</p>

<p>Thanks</p>
","<p>It's probably easiest to understand by contrast with raytracing.</p>

<p>To render a primitive with raytracing, you need a function that, given the primitive and input ray, tells you exactly where that ray hits the primitive. Then you can test the ray against all relevant primitives, and pick the closest intersection. CPUs are good at this.</p>

<p>With raymarching, you don't have such a simple ray intersection function. Given a point on the ray, you can estimate how close the point is to the surface, but you don't know exactly how far you need to extend that ray to hit the surface.</p>

<p>So, you ""march"" one step at a time:</p>

<ol>
<li><p>Start at the ""beginning"" of the ray - the near plane for scene rendering, or the intersection with the bounding volume if it's just one object in the scene. (P0 in the diagram below)</p></li>
<li><p>Evaluate your distance function to get an estimate for how close you are to the surface. (The largest circle in the diagram)</p></li>
<li><p>Move forward along the ray according to your estimate. The move should be conservatively short, so you're confident you won't tunnel through the surface anywhere.</p></li>
<li><p>Now you have a new point (P1 below) - get a new estimate and repeat.</p></li>
<li><p>Continue getting estimates and stepping forward until you get within a threshold distance of the surface, or you hit your maximum step count. (P4 below)</p></li>
<li><p>Now you have the depth of the surface, and can infer things like normals/ambient occlusion from nearby samples, and use this data to light &amp; colour the pixel.</p></li>
</ol>

<p><img src=""https://i.stack.imgur.com/Pg4xa.jpg"" alt=""Marching a ray from P0 toward its intersection""></p>

<p><a href=""http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter08.html"" rel=""noreferrer"">Example diagram from GPU Gems 2, chapter 8</a></p>

<p>Because each ray is independent and uses (generally) only local information at each step, it's ripe for parallelizing on GPUs. Often, only two triangles will be drawn on the screen. After rasterizing these, each pixel passed to the fragment shader represents a single ray. The fragment shader marches that ray until it reaches the surface, returning the result (often just the depth value for texturing &amp; shading in a separate full-screen pass).</p>

<p>The exact steps depend a lot on the particular effect you're trying to achieve. Raymarching techniques are used with...</p>

<ul>
<li>heightfields to simulate surface displacement on traditional rasterized geometry (parallax occlusion mapping)</li>
<li>scene depth buffers for things like screenspace reflections</li>
<li>volume textures for visualizing 3D-sampled datasets (often scientific/medical)</li>
<li>implicit functions for rendering things like fractals</li>
<li>procedural distance fields as in <a href=""http://www.iquilezles.org/default.html"" rel=""noreferrer"">Iñigo Quilez's work</a> (great links from msell in the comments above).</li>
</ul>

<p>Raymarching is also used with blending at each step (often using fixed steps instead of estimating a distance each time) for rendering volumetric translucency, as in <a href=""http://en.wikipedia.org/wiki/File:Volume_ray_casting.png"" rel=""noreferrer"">this example from Wikipedia</a>.</p>

<p><img src=""https://i.stack.imgur.com/LUGD8.png"" alt=""Raymarching a translucent volume texture""></p>

<p>This has become a popular way to <a href=""https://www.guerrilla-games.com/read/the-real-time-volumetric-cloudscapes-of-horizon-zero-dawn"" rel=""noreferrer"">render detailed clouds in realtime</a>.</p>

<p>Even <a href=""http://interiormapping.oogst3d.net/"" rel=""noreferrer"">Interior Mapping</a>, a way of simulating interior room detail behind building windows, could be considered a form of raymarching, where the ray is stepped from the point it enters the window to the closest wall, floor/ceiling, or furniture plane.</p>

<p>If there's a specific type of raymarching effect you're interested in, you can probably get more detailed answers by asking a new question with specific examples. As a family, the technique is too diverse to cover everything in one short answer. ;) I hope this gives you a framework for understanding what's happening under the hood in these shaders.</p>
","67745"
"How to learn 2d animation?","27295","","<p>Where can I learn how to do simple 2d animation well? Or is it really just literally drawing every single frame of something in photoshop? Is there tips or tricks? Tutorials to help get started?</p>

<p>Also, what software options are there (preferably open source or even just free)?</p>
","<p>Right now, I can think of a few ways you can do a 2-D animation:</p>

<ul>
<li>Moving an object's x,y coordinates around (e.g. to slide a rectangular menu - you change the y-coordinates every few ms)</li>
<li>Drawing every single frame out in an image editor and choosing the right frame to draw at the right moment (e.g. drawing a flame animation)</li>
<li>combining the two above (e.g. having a sprite walk across a screen)</li>
</ul>

<p>It's all about giving the <em>illusion</em> of movement.</p>

<p>How to do it well?</p>

<ul>
<li>It has to be timed properly to make it appear smooth (be aware of hardware constraints)</li>
<li>The more frames you have, the more details you can show, and the better it will look (however you end up having to draw more frames)</li>
</ul>

<p>Tips and tricks?</p>

<ul>
<li>Wikipedia has some concepts that you should take a look at: <a href=""http://en.wikipedia.org/wiki/Tweening"" rel=""nofollow"">tweening</a>, <a href=""http://en.wikipedia.org/wiki/Morphing"" rel=""nofollow"">morphing</a>, <a href=""http://en.wikipedia.org/wiki/Onion_skinning"" rel=""nofollow"">onion skinning</a> and <a href=""http://en.wikipedia.org/wiki/Interpolated"" rel=""nofollow"">interpolated</a> rotoscoping</li>
</ul>

<p>Software options? </p>

<ul>
<li>I would say it depends on what you are trying to animate. If you want to animate sprites or simple objects, then MS Paint will probably suffice</li>
<li><a href=""http://www.gimp.org/"" rel=""nofollow"">GIMP</a> is an open source alternative to Photoshop</li>
<li><a href=""http://www.photoscape.org/ps/main/index.php"" rel=""nofollow"">Photoscape</a> is another free photo editor. It also allows you to make animated GIFs - good for testing the timing in your animations </li>
<li><a href=""http://sourceforge.net/projects/synfig/"" rel=""nofollow"">Synfig</a> Is the libre alternative to <a href=""https://www.toonboom.com/"" rel=""nofollow"">ToonBoom</a> for doing animations without taking care about the tweening and then export them to video, gif, or maybe saving some frames as images for the sprites</li>
<li><a href=""http://inkscape.org/?lang=en"" rel=""nofollow"">InkScape</a> Is a vector vector graphics editor that is the libre alternative to <a href=""http://helpx.adobe.com/illustrator/topics-cs6.html"" rel=""nofollow"">Adobe Illustrator</a></li>
</ul>

<p>As for tutorials, I think this depends a lot on your goal. If you are doing a flash game, then search flash tutorials. Drawing is one thing, but you also need to time (and possibly move) the images to animate it properly - and so you might as well learn how to do it in the platform you are going for.</p>
","7794"
"How is 2D lighting implemented?","27288","","<p>I am wondering what the best way to approach a ""lighting"" effect in 2D games is. For instance, if my main character is glowing, what techniques can I use to complete the visual effect of the character glowing when it is near other objects which would be affected by the light?</p>
","<p>You could overlay a simple glow effect texture with soft transparent edges.
If you want lighting/shadows similar to what you may find in a 3d world you could do something like this: <a href=""http://www.catalinzima.com/2010/07/my-technique-for-the-shader-based-dynamic-2d-shadows/"">http://www.catalinzima.com/2010/07/my-technique-for-the-shader-based-dynamic-2d-shadows/</a>. However, if you are new to HLSL, then that may be a little bit too much.</p>

<p><strong>edit</strong>: I stumbled onto a nice HTML5 <a href=""http://blog.greweb.fr/2012/05/illuminated-js-2d-lights-and-shadows-rendering-engine-for-html5-applications/#underthehood"">2d light tutorial</a></p>
","4178"
"How many threads should I have, and for what?","27142","","<p>Should I have separate threads for rendering and logic, or even more?</p>

<p>I'm aware of the immense performance drop caused by data synchronization (let alone any mutex locks).</p>

<p>I've been thinking of taking this to the extreme and doing threads for conceivable every conceivable subsystem. But I'm worried that may slow things too. (For example, is it sane to separate the input thread from rendering or game logic threads?) Would the data synchronization required make it pointless or even slower?</p>
","<p>The common approach for taking advantage of multiple cores is, frankly, just plain misguided. Separating your subsystems into different threads will indeed split up some of the work across multiple cores, but it has some major problems. First, it's very hard to work with. Who wants to muck around with locks and synchronization and communication and stuff when they could just be writing straight up rendering or physics code instead? Second, the approach doesn't actually scale up. At best, this will allow you to take advantage of maybe three or four cores, and that's if you <em>really</em> know what you're doing. There are only so many subsystems in a game, and of those there are even fewer that take up large chunks of CPU time. There are a couple good alternatives that I know.</p>

<p>One is to have a main thread along with a worker thread for each additional CPU. Regardless of subsystem, the main thread delegates isolated tasks to the worker threads via some sort of queue(s); these tasks may themselves create yet other tasks, as well. The sole purpose of the worker threads is to each grab tasks from the queue one at a time and perform them. The most important thing, though, is that as soon as a thread needs the result of a task, if the task is completed it can get the result, and if not it can safely remove the task from the queue and go ahead and perform that task itself. That is, not all tasks will end up being scheduled in parallel with each other. Having more tasks than can be executed in parallel is a <em>good</em> thing in this case; it means that it is likely to scale as you add more cores. One downside to this is that it requires a lot of work up front to design a decent queue and worker loop unless you have access to a library or language runtime that already provides this for you. The hardest part is making sure your tasks are truly isolated and thread safe, and making sure your tasks are in a happy middle ground between coarse-grained and fine-grained.</p>

<p>Another alternative to subsystem threads is to parallelize each subsystem in isolation. That is, instead of running rendering and physics in their own threads, write the physics subsystem to use all your cores at once, write the rendering subsystem to use all your cores at once, then have the two systems simply run sequentially (or interleaved, depending on other aspects of your game architecture). For example, in the physics subsystem you could take all the point masses in the game, divide them up among your cores, and then have all the cores update them at once. Each core can then work on your data in tight loops with good locality. This lock-step style of parallelism is similar to what a GPU does. The hardest part here is in making sure that you are dividing your work up into fine-grained chunks such that dividing it evenly <em>actually</em> results in an equal amount of work across all processors.</p>

<p>However, sometimes it's just easiest, due to politics, existing code, or other frustrating circumstances, to give each subsystem a thread. In that case, it's best to avoid making more OS threads than cores for CPU heavy workloads (if you have a runtime with lightweight threads that just happen to balance across your cores, this isn't as big of a deal). Also, avoid excessive communication. One nice trick is to try pipelining; each major subsystem can be working on a different game state at a time. Pipelining reduces the amount of communication necessary among your subsystems since they don't all need access to the same data at the same time, and it also can nullify some of the damage caused by bottlenecks. For example, if your physics subsystem tends to take a long time to complete and your rendering subsystem ends up always waiting for it, your absolute frame rate could be higher if you run the physics subsystem for the next frame while the rendering subsystem is still working on the previous frame. In fact, if you have such bottlenecks and can't remove them any other way, pipelining may be the most legitimate reason to bother with subsystem threads.</p>
","8219"
"What kind of databases are usually used in an MMORPG?","27105","","<p>Do people write their own DB for some reason?</p>
","<p>We did, hopefully Ben Z will give a better explanation of the reasons than I can since he was actually the original author of our database. The short version is that relational DBs are not very useful for games because they cannot efficiently store heavily structured hierarchical data, which makes up the vast majority of data an MMO needs for normal operation. We choose to build a custom object database and part of a distributed transaction processing system, which is now in production and powering our two live games.</p>

<p>As for if you should do the same? Probably not, at least not at first. I would still advocate avoiding SQL, but there are now many more options in the ""NoSQL"" world that didn't exist a few years ago.</p>

<p>That said, most MMOs do run on SQL (relational) databases. I know Eve runs on a SQL Server installation sitting on top of a few multi-TB RAMSANs (I will probably never in my life have as much money as those things cost).</p>

<p>EDIT: Hopefully he won't mind me posting this here, but <a href=""http://doublebuffered.com/2008/02/26/gdc-08-sql-considered-harmful/"">this</a> is a blog entry with some links and comments about the presentation we gave at GDC'08 about our database.</p>
","2283"
"Workaround to losing the OpenGL context when Android pauses?","27071","","<p>The Android documentation says:</p>

<blockquote>
  <p>There are situations where the EGL
  rendering context will be lost. This
  typically happens when device wakes up
  after going to sleep. When the EGL
  context is lost, all OpenGL resources
  (such as textures) that are associated
  with that context will be
  automatically deleted. In order to
  keep rendering correctly, a renderer
  must recreate any lost resources that
  it still needs. The
  onSurfaceCreated(GL10, EGLConfig)
  method is a convenient place to do
  this.</p>
</blockquote>

<p>But having to reload all the textures in the OpenGL context is both a pain and hurts the game experience for the user when reentering the app after a pause. I know that ""Angry Birds"" somehow avoids this, I'm looking for suggestions on how to accomplish the same?</p>

<p>I'm working with the Android NDK r5 (CrystaX version.) I did find <a href=""http://www.anddev.org/android-2d-3d-graphics-opengl-problems-f55/minimizing-opengl-texture-reloads-on-pause-resume-t52932.html"">this possible hack</a> to the problem but I'm trying to avoid building an entire custom SDK version.</p>
","<p>Replica Island has a <a href=""http://code.google.com/p/replicaisland/source/browse/trunk/src/com/replica/replicaisland/GLSurfaceView.java"">modified version</a> of GLSurfaceView that deals with this issue (and works with earlier Android versions). According to <a href=""https://groups.google.com/group/replica-island-coding-community/browse_thread/thread/45bf454a3ee25136/b9dc4e26fc127d50"">Chris Pruett</a>:</p>

<blockquote>
  <p>Basically, I hacked up the original
  GLSurfaceView to solve a very specific
  problem: I wanted to go to different
  Activities within my app without
  throwing all of my OpenGL state away. 
  The major change was to separate the
  EGLSurface from the EGLContext, and to
  throw the former away onPause(), but
  preserve the latter until the context
  is explicitly lost.  The default
  implementation of GLSurfaceView (which
  I didn't write, by the way), throws
  all GL state away when the activity is
  paused, and calls onSurfaceCreated()
  when it is resumed.  That meant that,
  when a dialog box popped up in my
  game, closing it incurred a delay
  because all the textures had to be
  reloaded.</p>
  
  <p>You should use the default
  GLSurfaceView.  If you must have the
  same functionality that mine has, you
  can look at mine.  But doing what I
  did exposed all sorts of awful driver
  bugs in some handsets (see the very
  long comments near the end of that
  file), and you can avoid all that mess
  by just using the default one.</p>
</blockquote>

<p>Edit: I just realized you already posted the link to a similar hack. I don't think there is any built-in solution prior to honeycomb. Replica Island is a popular game working on many devices and you might find Chris's implementation and comments helpful.</p>
","12662"
"Error on new XNA 4.0 game project - No suitable graphics card found","27041","","<p>Any ideas on how to fix this? According to what I remember about XNA 3 was that when running the application from scratch, I would get a blue colored windows with nothing rendered.</p>

<p>Any suggestions?</p>

<p><img src=""https://i.stack.imgur.com/YkosH.png"" alt=""alt text""></p>

<p><strong>EDIT!</strong></p>

<p>I right clicked the project and selected Properties and changed the Game Profile from <strong>Use HiDef</strong> to <strong>Use Reach</strong>. Now the familiar blue tint window is showing as expected.
<img src=""https://i.stack.imgur.com/50G4Y.jpg"" alt=""alt text""></p>

<p>What am I losing if I choose the limited API and why did I even have to choose this for it to work?</p>
","<p>To answer your follow up question:</p>

<blockquote>
  <p>What am I losing if I choose the limited API?</p>
</blockquote>

<p><a href=""http://blogs.msdn.com/b/shawnhar/archive/2010/03/12/reach-vs-hidef.aspx"">This blog post explains the differences between Reach and HiDef</a>. In a nutshell, the Reach profile does not allow the use of some of the more advanced graphics card features. But it runs on more hardware.</p>
","4282"
"What languages are used to develop MMORPGs like EVE Online and WOW?","27037","","<p>As I understand it, MMORPGs are games that run on your computer like any other normal 3d video game but, with each action that happens with in the game, changes are made to the universe via HTTP calls to the server. So the players computer does all the heavy lifting in terms of rendering the graphics and animations but, web frameworks do the online communication.</p>

<ul>
<li><p>So I am wondering what web frameworks, web servers and databases are being used to create MMORPGs like EVE Online and W.O.W.? </p></li>
<li><p>Also, what programming languages and 3d game engines are being used to make the client side (3d graphics/animation/sounds) part of the game?</p></li>
</ul>
","<p>Most companies use C++. Eve is an outlier, the core graphics engine is in C++, while the game logic is, as others have noted, in Python. CCP also makes a lot of contributions to Stackless itself, which is in C for the most part. WoW is C++ for the game itself, though the UI is scripted in Lua. Cryptic (Champions Online, Star Trek Online) uses plain C, but that it is somewhat rare in the industry. Java pops up every now and then, ex. Runescape, but I can't think of anything AAA. Disney has used Panda3D (a Python-based engine written in C) for a number of their MMOs, but as with Eve thats uncommon.</p>

<p>Overall it seems like C++ for the game logic and engine, with Lua for client scripting is the closest you will find to a standard.</p>

<p>As for the web side, it is all over. We (Cryptic) use a mix of PHP, C, and Python (Django) for various bits. CCP uses ASP for the website itself, and Python to power the backend (slowly drifting together though). WAR and LOTRO both use PHP for their site, though it isn't clear what particular frameworks they are using (if any).</p>

<p>You mentioned that MMOs work via web API calls though, which isn't the case. An HTTP-based protocol would be far too inefficient, and HTTP is not designed for long-running connections. Pretty much all MMOs (that aren't web based like Kingdom of Loathing or Urban Dead) use custom servers and custom protocols. The clients are highly stateful, doing something like bringing up an inventory UI isn't going to fire off a request to the server since all that information is cached on the client. </p>
","4881"
"What is the purpose of glScissor?","26964","","<p>I know that it is more efficient than stencil test, but am I right assuming that the same functionality could be achieved using projection transformations with viewport?</p>
","<p>They are more complementary than alternatives to each other. You almost always want to set the scissor rectangle to the same values as the viewport.</p>

<p>glViewport() specifies a transformation from normalized projection space to screen space. Polygons are clipped to the edge of projection space, but other draw operations like glClear() are not. So, you use glViewport() to determine the location and size of the screen space viewport region, but the rasterizer can still occasionally render pixels outside that region.</p>

<p>That's where scissor in comes in. glScissor() defines a screen space rectangle beyond which <em>nothing</em> is drawn (if the scissor test is enabled).</p>

<p>So for example, the following code will clear the whole screen, even though the viewport is set to a small portion of the larger window:</p>

<pre><code>glViewport(200,200,100,100);
glClear(GL_COLOR_BUFFER_BIT);
</code></pre>

<p>Adding glScissor() and enabling the scissor test (which is disabled by default) restricts the clear.</p>

<pre><code>glViewport(200,200,100,100);
glScissor(200,200,100,100);
glEnable(GL_SCISSOR_TEST);
glClear(GL_COLOR_BUFFER_BIT);
</code></pre>

<p>Occasionally you come across an implementation that automatically scissors to the viewport region, but that violates the GL specification.</p>

<p>Beyond that, the scissor rectangle can be used to temporarily restrict drawing to a sub-rectangle of the viewport, for special effects, UI elements, etc.</p>
","40713"
"What are the advantages of putting cheat codes into a game?","26929","","<p>Some games have cheat codes in them, but I'm not sure I want to add some to mine because I fear they'll ruin the game by making it too easy to beat. </p>

<p>What would be the advantages of putting cheat codes into my game?</p>
","<p>One major feature is that they make debugging easier.</p>

<p>If there's a broken puzzle door that's not unlocking, and you can bypass it by clipping through the walls, or skip past some tough combat with invulnerability and an insta-kill weapon, or shortcut the economy grind by giving yourself infinite money to make sure the last-game purchaseables all work, you've saved yourself a lot of time! Being able to manually spawn an object or character you need to test on demand, rather than finding them organically in the world, can be another huge time-saver.</p>

<p>Without these ways to break the rules, then if the rules themselves aren't working in one part of the game, you can be blocked from testing everything else in the game that depends on or comes after the glitched part (something we call a ""walkthrough break,"" one of our highest priority classes of bug)</p>

<p>This is especially important on large teams where even once you find a bug and someone is actively working to fix it, other developers and testers can be blocked from doing their work, massively slowing down development. Being able to cheat around small issues gives some insulation against this kind of deadlock.</p>

<p>Here's a <a href=""https://twitter.com/Ed_dV/status/928852382577913856?s=09"" rel=""noreferrer"">tweet I spotted today from @Ed_dV</a> that illustrates this nicely (click through for video):</p>

<blockquote>
  <p>Made a little floating window with all of my debug tools, cheat
  toggles, time of day slider etc. I can't believe I didn't implement
  cheats earlier - noclip/fly is vital in the early bug-ridden days.</p>
</blockquote>

<p>(Of course, you must still follow-up with cheat-free playthroughs whenever possible, to make sure it's not just the cheated version of the game that works)</p>

<p>Once you've put in the work of developing these cheats, there's often little to no cost to leave them in for players, accessible by a secret key combo, cheat menu, or debug console - as long as the game is single-player so they can't be used to interfere with other players' games.</p>

<p>These codes can be a delightful easter egg for players - how many times have you tried entering the <a href=""https://en.wikipedia.org/wiki/Konami_Code"" rel=""noreferrer"">Konami Code</a> on a game or website, just to see if it would do something? A lot of us have fond childhood memories of no-clipping through walls in DOOM or giving ourselves all the weapons in GTA, or spawning so many rings and springs in Sonic the Hedgehog that the framerate stuttered. :)</p>

<p>If you give out the cheat codes in-game as rewards for solving difficult challenges, it's an impactful prize that's reasonably cheap to implement, compared to giving the player a new ability or item that needs to be balanced against the rest of the game. With cheats, there's a tacit understanding that it's <em>allowed</em> to break the balance or fiction, in an opt-in way. And it lets players feel elite, entrusted with secret knowledge (which they can share with their friends for social cred too).</p>

<p>Lastly, these can provide additional accessibility for players who, for medical or other reasons, might not be able to get to all parts of your game on their own otherwise. If it's the difference between a player enjoying a lower-challenge version of my game than I'd originally intended, versus not getting to enjoy my game at all, I'd rather offer them that lower-challenge version, to the extent that they want to use it.</p>

<p>And for the most part, cheats don't negatively impact the players who dislike them. Players are very good at challenging themselves - for example, opting into difficult ""Ironman"" or ""Nuzlocke"" play styles even when not enforced by the game's rules. So players who want a difficult experience generally don't use or even look up the cheat codes.</p>
","150564"
"Why does Mojang write Minecraft in Java","26784","","<p>Is there any specific reason why Java was the right choice for Minecraft?</p>
","<p>I saw a video from GDC where he said that he used Java because it's what he felt most productive in, at least at the time. It was only a passing comment though and note that this video is post-Minecraft, so his reasoning may not have been the same when he started Minecraft.</p>

<p>Source: <a href=""http://www.gdcvault.com/play/1015646/Back-to-the-Garage-The"">This video</a> from about 14:45 in answer to the question ""What Tools or Technology Would You Recommend?""</p>
","56914"
"Packaging HTML5 games as applications for iPhone/Android","26775","","<p>Is it possible to package HTML5 game for iPhone and Android as an application or does it have to be accessed through a browser?</p>
","<p>There's <a href=""http://www.phonegap.com/"">http://www.phonegap.com/</a> which is open source and cross-platform. Besides packaging your HTML 5 as a native app, it also lets you access native features of the mobile phone.</p>
","8612"
"What is the easiest genre of game to make?","26769","","<p>Before you down vote let me give some restrictions.</p>

<p>I like RPG but they seem long and hard to make but after you make the framework the rest sort of falls into place where as platformers never get faster as each map starts from scratch.</p>

<p>So under these conditions what is the easiest genre of game to develop as a hobby project.</p>

<ol>
<li><p>I am on my own.</p></li>
<li><p>The style of graphics must be available. Can be ripped (not publishing).</p></li>
<li><p>Not bothered about commercial quality.</p></li>
<li><p>Must be real size game, multiple levels and stuff.</p></li>
</ol>

<p>Thanks </p>

<p>Edit:</p>

<p>I build games in C++ and Direct x 9.c</p>
","<p>I agree with Apreche, a side-scrolling shoot 'em up is by far the easiest genre to create a simple game in.</p>

<p>For the basic setup, all you need is three parts:</p>

<ul>
<li>Player: Moves to where mouse is</li>
<li>Enemies: Move down- or left-ward, depending on if horizontal or vertical shooter</li>
<li>Bullets: Move opposite to Enemy direction</li>
</ul>

<p>Then you just need to add collision checks for Bullet-Enemy and Enemy-Player, and you've got a game.</p>

<p>From there on, you can then expand upon your design, adding enemies that shoot back, power-ups, asteroids, points, etc. </p>

<p>You can also easily try out adding all kinds of interesting ""features"" to your code-base before starting on a new project: AI finite state machines, spatial partitioning for collisions, particle systems, parallax scrolling, the list goes on and on.</p>

<p>In short: As your first game, you want something that is easy to make, and easy to expand upon, making a SHMUP an excellent choice.</p>
","10818"
"How do I create a 3D model based on 2D drawings?","26661","","<p>I'm a programmer. I have a great draftsman, but I don't know how to take his drawings to 3D.</p>

<p>My gut feeling is to have him draw different view angles, then work based on those, adding each dimension to the model turn. But really I'm just guessing here.</p>

<p>How do I do this methodically and correctly?</p>
","<p>As Tim Holt said, you need a 3D modeler in order to translate the 2D designs into models. However, if you're willing to try your hand at modeling, the basic process generally goes like this:</p>

<ol>
<li>Add the image you're working from to the 3D scene so that you can add vertices in front of it. Your modeling program may have a built in method for this, otherwise use a regular plane with the image as a texture.</li>
<li>Set your view so that you are viewing the image flat (camera's direction vector is perpendicular to the image)</li>
<li>If possible, follow step 1 and 2 for your alternative-angle images at an appropriate angle to the original and set up extra camera views so you can see both or all images  from the correct angle simultaneously.</li>
<li>Start adding vertices to your model that match up to the image outlines.</li>
<li>Use your supplementary images to make any additional vertices you need, and to position your vertices from step 4 in the third dimension.</li>
</ol>

<p>There are tool-specific and more <a href=""http://en.wikibooks.org/wiki/Blender_3D%3a_Noob_to_Pro/2D_Image_%28logo%29_to_a_3D_Model"">in-depth tutorials</a> available on the web.</p>
","14110"
"A good way to build a game loop in OpenGL","26506","","<p>I'm currently beginning to learn OpenGL at school, and I've started making a simple game the other day (on my own, not for school). I'm using freeglut, and am building it in C, so for my game loop I had really just been using a function I made passed to <code>glutIdleFunc</code> to update all the drawing and physics in one pass. This was fine for simple animations that I didn't care too much about the frame rate, but since the game is mostly physics based, I really want to (need to) tie down how fast it's updating.</p>

<p>So my first attempt was to have my function I pass to <code>glutIdleFunc</code> (<code>myIdle()</code>) to keep track of how much time has passed since the previous call to it, and update the physics (and currently graphics) every so many milliseconds. I used <code>timeGetTime()</code> to do this (by using <code>&lt;windows.h&gt;</code>). And this got me to thinking, is using the idle function really a good way of going about the game loop?</p>

<p>My question is, what is a better way to implement the game loop in OpenGL? Should I avoid using the idle function?</p>
","<p>The simple answer is no, you do not want to use the glutIdleFunc callback in a game that has some sort of simulation. The reason for this is that this function divorces animation and draw code from window event handling but not asynchronously. In other words, receiving and handing window events stalls draw code (or whatever you put in this callback), this is perfectly fine for an interactive application (interact, then response), but not for a game where the physics or game state must progress independent of interaction or render time.</p>

<p>You want to completely decouple input handling, game state, and draw code. There is an easy and clean solution to this that does not involve the graphics library directly (i.e. it's portable and easy to visualize); you want the entire game loop to produce time and have the simulation consume the produced time (in chunks). The key however is to then integrate the amount of time your simulation consumed into your animation.</p>

<p>The best explanation and tutorial I have found on this is Glenn Fiedler's <a href=""http://gafferongames.com/game-physics/fix-your-timestep/"">Fix Your Timestep</a></p>

<p>This tutorial has the full treatement, however if you do not have an <em>actual</em> physics simulation, you can skip the true integration but the basic loop still boils down to (in verbose pseudo-code):</p>

<pre><code>// The amount of time we want to simulate each step, in milliseconds
// (written as implicit frame-rate)
timeDelta = 1000/30
timeAccumulator = 0
while ( game should run )
{
  timeSimulatedThisIteration = 0
  startTime = currentTime()

  while ( timeAccumulator &gt;= timeDelta )
  {
    stepGameState( timeDelta )
    timeAccumulator -= timeDelta
    timeSimulatedThisIteration += timeDelta
  }

  stepAnimation( timeSimulatedThisIteration )

  renderFrame() // OpenGL frame drawing code goes here

  handleUserInput()

  timeAccumulator += currentTime() - startTime 
}
</code></pre>

<p>By doing it this way, stalls in your render code, input handling, or operating system do not cause your game state to fall behind. This method is also portable and graphics library independent.</p>

<p>GLUT is a fine library however it is <em>strictly</em> event-driven. You register callbacks and fire off the main loop. You always hand over control of your main loop using GLUT. <a href=""http://www.sjbaker.org/steve/software/glut_hack.html"">There are hacks to get around it</a>, you can also fake an external loop using timers and such, but another library is probably a better (easier) way to go. There are many alternatives, here are a few (ones with good documentation and quick tutorials):</p>

<ul>
<li><a href=""http://www.glfw.org/"">GLFW</a> which gives you the ability to get input events inline (in your own main loop).</li>
<li><a href=""http://www.libsdl.org/"">SDL</a>, however its emphasis is not specifically OpenGL.</li>
</ul>
","8628"
"Are there existing FOSS component-based frameworks?","26318","","<p>The component based game programming paradigm is becoming much more popular. I was wondering, are there any projects out there that offer a reusable component framework? In any language, I guess I don't care about that. It's not for my own project, I'm just curious.</p>

<p>Specifically I mean are there projects that include a base <code>Entity</code> class, a base <code>Component</code> class, and maybe some standard components? It would then be much easier starting a game if you didn't want to reinvent the wheel, or maybe you want a <code>GraphicsComponent</code> that does sprites with Direct3D, but you figure it's already been done a dozen times.</p>

<p>A quick Googling turns up <a href=""http://cjcat.blogspot.com/2010/02/rusher-game-framework.html"">Rusher</a>. Has anyone heard of this / does anyone use it?
If there are no popular ones, then why not? Is it too difficult to make something like this reusable, and they need heavy customization? In my own implementation I found a lot of boilerplate that could be shoved into a framework.</p>
","<blockquote>
  <p>If there are no popular ones, then why not?</p>
</blockquote>

<p>Because there is nothing resembling a consensus on how such a framework would operate.</p>

<p>On a thread on Gamedev.net I determined that when people talk about component-based game systems there are actually at least 8 possible permutations of how they expect them to work, based on 3 different factors:</p>

<p><strong>Inboard vs. outboard</strong> - should components be aggregated into an entity, or should they be part of a subsystem and only associated by an entity ID?</p>

<p><strong>Static vs. dynamic composition</strong> - should entities consist of a known set of components (eg. 1 Physics, 1 Animation, 1 AI, etc) that can communicate in code via well-known interfaces, or can entities have arbitrary quantities of components added to them (with associated strategies for locating other components of interest)</p>

<p><strong>Data on component vs data on entity</strong> - Should data be held by the component that primarily operates upon it? Or should data be stored on the entity in a shared space, accessible by all components?</p>

<p>Beyond that there are further questions over how the components should communicate (via the shared data? Via function pointers? Via signals/slots? Or not at all?), how they should update (in a fixed order based on component type? a per-entity order defined at creation time? based on a topological sort of component interdependencies?), etc.</p>

<p>Each of these choices are completely arbitrary, and anything you can do with one system can be done with the other. But the way in which you have to code it is quite different in each case. And people seem to have strong opinions over which way works best for them.</p>

<p>Right now people are still too caught up in the idea that components are somehow a replacement for object orientation (which they're not) and also imagining that they're a massive change from how games were traditionally made (which again, they were not - people have factored out the various subsystems in their entities for ages), so there's a lot of hyperbole and not much agreement. Maybe in a few years things will have settled down and people will settle on one or two fairly standard approaches.</p>
","4966"
"Is the TCP protocol good enough for real-time multiplayer games?","26304","","<p>Back in the day, TCP connections over dialup/ISDN/slow broadband resulted in choppy, laggy games because a single dropped packet resulted in a resync. That meant a lot of game developers had to implement their own reliability layer on top of UDP, or they used UDP for messages that could be dropped or received out of order, and used a parallel TCP connection for information that must be reliable.</p>

<p>Given the average user has faster network connections now, can a real time game such as an FPS give good performance over a TCP connection?</p>
","<p>I would say no. Spacial information of game objects need to be as fast as possible, and for that it's better to use UDP, because reliability is not 100% crutial. Even on modern connections, UDP is still slow enough that you have to make some special considerations for interpolation and such. Even just in terms of the amount of data transferred, TCP would add significant overhead to this.</p>

<p>However, TCP is perfectly acceptable for non-realtime things, such as multiplayer negotiation, chat messages, score updates, etc.</p>
","434"
"Where to start with game development?","26223","","<p>I asked this earlier in <a href=""https://stackoverflow.com/questions/5189399/where-to-start-with-game-development"">this thread</a> at stackoverflow.com. One of the early comments redirected me here to gamedev.stackexchange.com, so I'm reposting here.</p>

<p>Searching for related questions I found a number of very specific questions, but I'm afraid the specifics have proved fruitless for me and after 4 hours on Google I'm no closer than I started, so I felt reaching out to a community might be in order.</p>

<p>First, my goal: I've never made a game before, although I've muddled over the possibility several times. I decided to finally sit down and start learning how to code games, use game engines, etc. All so that one day (hopefully soon) I'll be able to make functional (albeit simple) games. I can start adding complexity later, for now I'd be glad to have a keyboard-controlled camera moving in a 3D world with no interaction beyond that.</p>

<p>My background: I've worked in SEVERAL programming languages ranging from PHP to C++ to Java to ASM. I'm not afraid of any challenges that come with learning the new syntax or limitations inherent in a new language. All of my past programming experience, however, has been strictly non-graphical and usually with little or extremely simple interaction during execution. I've created extensive and brilliant algorithms for solving logical and mathematical problems as well as graphing problems. However in every case input was either defined in a file, passed form an HTML form, or typed into the console. Real-time interaction with the user is something with which I have no experience.</p>

<p>My question: Where should I start in trying to make games? Better yet- where should I start in trying to create a keyboard-navigable 3D environment? In searching online I've found several resources linking to game engines, graphics engines, and physics engines. Here's a brief summary of my experiences with a few engines I tried:</p>

<p>Unreal SDK: The tutorial videos assume that you already have in-depth knowledge of 3D modeling, graphics engines, animations, etc. The ""Getting Started"" page offers no formal explanation of game development but jumps into how Unreal can streamline processes it assumes you're already familiar with. After downloading the SDK and launching it to see if the tools were as intuitive as they claimed, I was greeted with about 60 buttons and a blank void for my 3D modeling. Clicking on ""add volume"" (to attempt to add a basic cube) I was met with a menu of 30 options. Panicking, I closed the editor.</p>

<p>Crystal Space: The website seemed rather informative, explaining that Crystal Space was just for graphics and the companion software, CEL, provided entity logic for making games. A demo game was provided, which was built using ""CELStart"", their simple tool for people with no knowledge of game programming. I launched the game to see what I might look forward to creating. It froze several times, the menus were buggy, there were thousands of graphical glitches, enemies didn't respond to damage, and when I closed the game it locked up. Gave up on that engine.</p>

<p>IrrLicht: The tutorial assumes I have Visual Studio 6.0 (I have Visual Studio 2010). Following their instructions I was unable to properly import the library into Visual Studio and unable to call any of the functions that they kept using. Manually copying header files, class files, and DLLs into my project's folder - the project failed to properly compile.</p>

<p>Clearly I'm not off to a good start and I'm going in circles. Can someone point me in the right direction? Should I start by downloading a program like Blender and learning 3D modeling, or should I be learning how to use a graphics engine? Should I look for an all-inclusive game engine, or is it better to try and code my own game logic? If anyone has actually made their own games, I would prefer to hear how they got their start.</p>

<p>Also- taking classes at my school is not an option. Nothing is offered.</p>
","<p>I have asked such a question when I joined GD. Here are some links that might be of interest to you which I hope will guide you toward your objective.</p>

<p>In short, I would go with <code>XNA Game Studio</code> to get a grip on game development. Then, moving forward to what you wish to achieve as knowledge/technology. <code>XNA</code> taught me about working with sprites, and allowed me to apply some of my knowledge right from the beginning of my learning curve so that I have been able to get a grasp fast enough to understand how I should design my game to use classes while working with dependency injection and so forth. So, I'm keeping you waiting no more.</p>

<ol>
<li><a href=""https://gamedev.stackexchange.com/questions/7657/where-to-start-writing-games-any-tutorials-or-the-like"">Where to start writing games, any tutorials or the like?</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/8995/what-are-the-fundamentals-of-game-development/8999#8999"">What are the fundamentals of game development?</a> (Interesting question, IMHO)</li>
<li><a href=""https://gamedev.stackexchange.com/questions/8195/separating-physics-and-game-logic-from-ui-code/8198#8198"">Separating physics and game logic from UI code</a></li>
<li><a href=""https://gamedev.stackexchange.com/questions/8055/moving-my-sprite-in-xna-using-classes/8057#8057"">Moving my sprite in XNA using classes</a></li>
</ol>

<p>Why XNA will you ask? Simply because of your Java background. XNA uses C# which is similar to Java on some multiple ways, and is also a simple framework to use which abstracts away the Game Loop and stuff so that you may concentrate on what is important.</p>

<p>I really do hope this will get you starting. =)</p>
","9294"
"How do I get players to say ""no"" when they are afraid of missing out on sidequests or XP?","26124","","<p>In my RPG, I have a companion NPC who is overconfident in his abilities and lacks self-control. I wanted to create a few situations where the player needs to reign them in and tell them ""no"". One such situation basically boiled down to this:</p>

<blockquote>
  <p>Companion: Hey boss, I want to do this really stupid thing that will almost certainly make things harder for us down the road and possibly jeopardize our goal. Is that okay?</p>
  
  <p>Player Choices: </p>
  
  <ul>
  <li>Yes, go ahead!</li>
  <li>No, don't do that!</li>
  </ul>
</blockquote>

<p>My hypothesis was that the vast majority of playtesters would choose ""No"". To my surprise, the vast majority <em>chose ""Yes""</em>! And then when the consequences played out and indeed made things worse, playtesters wanted to reload from an earlier save point and pick the other option (choosing ""Yes"" wasn't game-ending, but it did mean that a perfect outcome wasn't achievable).</p>

<p>When I asked the playtesters why they chose yes, they made it clear that they understood that saying yes was undesirable and saying no was desirable. They also weren't seeking a challenge or anything. Instead, the most common thing I heard was:</p>

<blockquote>
  <p>I was afraid that if I said ""No"", then I'd miss out on a sidequest or XP. </p>
</blockquote>

<p>One of them even said that in other RPGs he played, the only way to get a 100% playthrough was to say yes at every opportunity, and so they assumed that was the case for mine.</p>

<p>I don't want players to assume that saying ""yes"" is always the right answer, and for now, I'd like to keep the situation of having to tell the NPC ""no"" every once in a while. But I don't know how to overcome these player expectations and their fear of missing out of content, especially without just flat out saying ""this isn't like other games, you won't miss out if you say 'no'"".</p>

<p>So how do I get players to say ""no"" when they are afraid of missing out on sidequests or XP?</p>
","<p>That is the common concept in nearly all RPG videogames out there: you either say <em>yes</em> to take the quest or <em>no</em> to not take it. Players get used to this pattern by encountering it over and over throughout their walkthroughs, and finally simply start assuming beforehand that this pattern is also true for your game.</p>

<p>A good example of handling it is <strong>Deus Ex: Human Revolution</strong>. In the beginning of the game, the player is told to not waste time exploring and rush in for the quest, or else ""people will die"". Many players simply assumed that was simply an ""<em>in-game immersion</em>"" statement which wouldn't affect the gameplay at any rate. Consequently, not two minutes after they were told that hostages were killed and they were too late, thus <em>breaking the pattern players were used to</em> very early in the game while still allowing them to rollback the two minutes they already spent exploring and instead prioritize the quest.</p>

<p>That could be a solution in your case. If many players think your game follows already established patterns, show them that it does not! Have a small quest (or better yet, a few of them) that would require players to reason and use their judgement to make a choice, so that they get used to the new concept. You could also display a ""help window"" during the first time they get a quest that ""<em>not all of the quests should be taken</em>"" or ""<em>player shouldn't agree to everything they're told</em>"". Once they are familiar with the concept, throw in your important quests, which they will immediately recognize as one of the problems they'd have to think about.</p>

<p>Another thing you might want to consider: if there is an important decision for players to make, give them as much information as possible and give them the time to think. That is, instead of having an NPC make a simple statement that looks like a quest offer (""Let's try this totally silly thing!""), elaborate on what they're offering and allow players to inquire for details and possible drawbacks. Make it feel as an important decision to be made, and your players will treat is as such.</p>
","149032"
"How to implement A.I. for checkers/draughts?","26032","","<p>I saw this <a href=""http://www.iphonedevsdk.com/forum/iphone-sdk-game-development/13001-tic-tac-toe-tutorial-walkthrough.html"">checkers game</a> and I wondered how the A.I. was implemented.</p>

<p>How should I implement an A.I. for <a href=""http://www.youtube.com/watch?feature=related&amp;hl=en-GB&amp;v=abdfSTLtZrg&amp;amp="">checkers</a> (draughts, dama, dame)? Are there any known algorithms?</p>

<hr>

<p>Very thnaks full to all. I m very wonder to see this <a href=""http://www.iphonedevsdk.com/forum/iphone-sdk-game-development/13001-tic-tac-toe-tutorial-walkthrough.html"">Tic Tac Toe</a> game tutorial blog post.</p>

<p>So, i want <a href=""http://www.youtube.com/watch?feature=related&amp;hl=en-GB&amp;v=abdfSTLtZrg&amp;amp="">dama game</a> algorithm open source code and blog post..  Is there any helpful link or any doc file..? please let me know..</p>
","<p>Oh I do love these games!</p>

<p>So first things first, in order for a computer to play a game, it needs: </p>

<ol>
<li>a structure to work with </li>
<li>rules to play by</li>
<li>a win condition to work towards</li>
</ol>

<p>Let's tackle this one piece at a time.</p>

<hr>

<h2>Structure</h2>

<p>Since the board is an 8x8 grid (but could easily scale), and each grid space may exist in only one of five states, let's define those states: </p>

<pre><code>[EMPTY, WHITE_PIECE, BLACK_PIECE, WHITE_PIECE_PROMOTED, BLACK_PIECE_PROMOTED]
</code></pre>

<p>Respectively ENUM'd to:</p>

<pre><code>[0, 1, 2, 3, 4]
</code></pre>

<p>Now that we know what each space can be we need some way to represent all the spaces, or the board if you will.  Almost every strong language will support a multi-dimensional array (an array where each element is an array holding data).
So take the following slack-code for defining our array:</p>

<pre><code>BOARD_ARRAY = array(8, 8)
</code></pre>

<p>This will give us an 8 x 8 array in which we can store integers (our enums from before):</p>

<pre><code>(
[0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0, 0],
)
</code></pre>

<p>Now you can already see how that this is beginning to look like a board!
I've never played the variant mentioned in the youtube video but it appears to start with 2 rows of white pieces one row from the bottom, and 2 rows of black pieces one row from the top.  Which would mean when we start a game our array should look like this:</p>

<pre><code>(
[0, 0, 0, 0, 0, 0, 0, 0],
[2, 2, 2, 2, 2, 2, 2, 2],
[2, 2, 2, 2, 2, 2, 2, 2],
[0, 0, 0, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 0, 0, 0, 0],
[1, 1, 1, 1, 1, 1, 1, 1],
[1, 1, 1, 1, 1, 1, 1, 1],
[0, 0, 0, 0, 0, 0, 0, 0],
)
</code></pre>

<p>(Remember 2 represents 'BLACK_PIECE' and 1 represents 'WHITE_PIECE')</p>

<p>So now the computer has a structure to work with. Step 1 complete!</p>

<hr>

<h2>Rules</h2>

<p>Let's imagine you had an actual board set up in front of you, playing against a master player.  If you tried to move one of his pieces, you'd get your hand slapped.  If you tried to move a piece in a way you couldn't, you'd get your hand slapped.  If you tried to cheat well... you get the idea.  But the problem is, computers don't.  So it's our job to provide <strong>strict</strong> rules to play within.</p>

<p>We need to create a way to check if any given move is 'legal'.  Which means we first need some way to represent a 'move'.  One way would be to use array positions; For example to move a piece from [0, 0] to [0, 1], we could create a function that will update the board given that move.  So back to slack:</p>

<pre><code>MY_MOVE = array( [0, 0], [0, 1] )
</code></pre>

<p>The above represents one piece, moving one space down from the top corner of the board (assuming 0, 0 is the top left corner).  You may also notice I chose to use a multidimensional array for the move.  This is because pieces may theoretically move a great number of times in one turn (for 'jumping' other pieces).  So let's pretend at 0, 1 there was an opponents piece, meaning we would land at 0, 2:</p>

<pre><code>MY_MOVE = array( [0, 0], [0, 2] )
</code></pre>

<p>Pretty simple eh.  The program should understand that if we skip a space we are jumping another piece (or else it's an illegal move, and should throw an error).  Now let's jump two pieces:</p>

<pre><code>MY_MOVE = array ( [0, 0], [0, 2], [0, 4] )
</code></pre>

<p>This gives us a way to describe any move on the board. Yay!  Now since I don't fully understand the rules of the exact game in question (although I've played a bit of Canadian checkers in my day) the exact move legality will need to be defined by you.  A good flow up to this point would look like:</p>

<pre><code>FUNCTION_FIND_ALL_LEGAL_MOVES( MY_BOARD ) Returns: array ALL_LEGAL_MOVES
FUNCTION_FIND_BEST_MOVE( MY_BOARD, ALL_LEGAL_MOVES ) Returns: array MY_MOVE
FUNCTION_DO_MOVE( MY_BOARD, MY_MOVE ) Throws: error ILLEGAL_MOVE Updates: MY_BOARD
repeat from start for each turn
</code></pre>

<p>The above assumes you can cycle through each piece to find all it's legal moves, then given a collection of all the legal moves somehow choose the best one (strategy here).  The move is then applied to the board, or throws an error.  Then the next player takes their turn.
So we have an AI that knows how to play!  Joy!  Moving on.</p>

<hr>

<h2>Winning</h2>

<p>Simple games are wonderful, because winning is defined by a very simple state.  Ain't no white pieces on the board?  Well I guess you've won!  This is implemented in step 2 when we choose the best move to take us closer to the winning condition.</p>

<p>To make some very intelligent AI you could keep a database that stored every possible board as a state, with every possible move from every possible state, to find chains towards winning.</p>

<p>You could also create strategies, like: if there is a piece that WILL be jumped, save that piece or if a piece is able to jump more than one other piece do that jump.</p>

<hr>

<p>That should give you a good jumping off point, it is only one method of literally unlimited possibilities.  You could theoretically build a giant robot to draw with crayons then conduct spectral analysis on the drawing to choose moves... but it wouldn't work very good, or fast.  This way has worked in the past, and worked well (:  Hope that helps!</p>

<hr>

<h2>A Few Words On Implementation</h2>

<p>Checkers is what is referred to as a 'solved' game, in that we can calculate every move with no unknowns.  But that's a whole whack of moves!  So there is no way to do it all manually... if only there was some... oh right we're programmers. <em>fist pump</em></p>

<p>SQL is a wonderful tool for storing all these seemingly endless moves.  For those with no experience with SQL, mySQL is a free (fairly easy to use) and open source SQL server.  SQL is used for managing databases, sorta like a spreadsheet on steroids.  It is also able to hold seriously large amounts of data and work with it very quickly.</p>

<p>So how can we use this?  Since we know that if the board is in an exact state (each piece in a certain position) we can calculate all the available moves, and save them. For example:</p>

<pre><code>+Board State+          +All Possible Moves+               +Best Move+
([0,0,1,2,3],[3..)     ([0,1],[0,2]), ([7,6],[7,7],[5..)  ([7,6],[7,7])
([0,0,2,2,3],[3..)     ([0,1],[0,2]), ([7,6],[7,7],[5..)  ([5,5],[5,4])
([0,0,1,3,3],[3..)     ([0,1],[0,2]), ([7,6],[7,7],[5..)  ([4,4],[4,3])
etc...
</code></pre>

<p>So when the computer needs to make a move it simply looks up the board state (stored as the primary key) in the database, and can either choose the best move (should be unbeatable) or one of the other moves to make a more friendly AI.</p>

<p>Great now let's build this database.  First we need to calculate every board state.  Which can be done with a great big nasty loop, if someone wants to spend some time and work it out that would be awesome.  Look at the array as one big number, then count upwards, except in base 5 (0, 1, 2, 3, 4), and condition that each player may only have 16 pieces.</p>

<p>At this point we should have every board state stored and can go through calculating all possible moves.</p>

<p>Once all possible moves are calculated comes the fun part of pathfinding the best possible moves.  This is where my knowledge begins to fall short, and things like Minimax or A* start to come into play.  Sorry I can't be of more help on that :/</p>
","16141"
"How can a programmer learn to draw 2D assets?","25929","","<p>Are there any good tutorials for someone who wants to create 2D graphical game assets? Drawing classes for absolute beginners, preferably teaching skills that can be as relevant as possible to games - drawing characters sideways/top-down, isometric, drawing textures and such.</p>
","<p>First, you want to search for tutorials on the internet.  Youtube is your friend.  Seriously, it's probably the best way to learn drawing.  It's easy to look at some really amazing drawing and say ""oh, I could never do that, he's been doing that since he was a kid.""  But when someone slowly walks you through the steps and explains every part of the way, the mountain suddenly seems a lot easier to climb.  </p>

<p>Next the problem is figuring out what to search for.  You don't want to start off with the hard stuff, so don't go searching for ""digital art"" or ""character design"" as you will be lost very fast.  There's a lot of tutorials out there that start off like ""first draw a basic human figure"" or ""start by sketching out some buildings"".  Avoid those.  </p>

<p>Now, a tutorial to get you started.  First, search YouTube for ""perspective drawing"".  It's a basic skill that's the first thing they teach you in any art class.  Play around with this a bit, drawing 3D houses, etc.  Now, try to find something in your house that's roughly box-shaped.  Your speakers or desktop should work fine.  Now draw it using perspective.  What you just did is called ""life drawing"" which is basically where you draw something from real life.  It's really important that you do this, because you figure out neat little things on your own when you draw real things.<br>
Eventually, you'll get to the point where you can look at something and start thinking ""how would I draw this?""  That's important, because then when you need to draw, say, a potion for a game, you can look at a glass bottle and think about how to draw it, then apply that to your potion.  Think of it like writing a ""method"" for drawing a bottle.  You'd probably start out with a method called ""DrawLine"", use it for ""DrawCylinder"", then make ""ShadeGlass"" and combine ""ShadeGlass"" with ""DrawCylinder"" to get ""DrawBottle"".</p>

<p>Also, when you watch a tutorial you'll see that a lot of what you drew looks a lot messier or uglier than what you saw in the tutorial.  Do not be worried, it's not that you're less creative or that you didn't follow the tutorial, you just haven't built up some of the basic skills that the artists in the tutorials have.  An easy way to help this is to just draw lots of basic shapes over and over again.  Keep a pad of paper next to you while watching tv, and during the commercial break see if you can draw 20 circles, lines, or squares.  Think of it like learning the basic methods in a new language so that you don't have to look through pages of the documentation.  </p>

<p>Another thing to watch out for is details.  Say you're drawing a person.  You decide to start with the head.  So you start with drawing a circle.  Then you think ""oh, I've already got the circle, I'll give it eyes and a mouth!""  Next thing you know, you've got a pretty good head, with hair, a nose, eyes, a mouth, ears, etc.  So you start drawing the body.  After doing some pretty good shoes and maybe a cool shoulder armor you realize that your drawing looks horrible.  The head is too big, the legs are different sizes, and the feet look backwards.  My point is that you have to focus on big shapes and try to resist the urge to start adding details.  </p>

<p>Finally, learn to critique your own drawings.  Don't just look at the person you drew and say ""that's ugly"".  Pick out specific things to improve upon.  Say ""those hands could be better"" or ""the proportions seem kinda weird"" or ""The hair looks too fuzzy"". Then look up tutorials for whatever you need to improve on.  There's a lot of good resources out there, but you have to know what you are looking for.  You wouldn't just search for ""Making my program faster"", you would look up ""improving performance rendering triangle strips in XNA"".  </p>

<p>Anyways, assuming you already did perspective drawing, here's some things to search for to get stated.  (inserting ""tutorial"" after all of these can give better results)
3D shading 
Figure drawing
Gesture drawing
Basic Pixel Art</p>

<p>Just with that stuff you should have a good month or two of stuff to practice.  Try to keep sketchbooks, so that you can look back and see how much you've improved.  If you want to look forward and see how good you can get, look up ""speed painting"" on YouTube.  And if you are getting frustrated with all sorts of technical details and stuff, watch <a href=""http://www.youtube.com/watch?v=heKK95DAKms"">this video</a> and try to have some fun.  </p>

<p>Good luck, and make sure you draw often!</p>
","11796"
"What's the best Python 3D engine?","25920","","<p>I want a straight 3d Python engine that's easily obtainable for linux and easy to use. Soya3D failed for me because of the lack of documentation. I should be able to load common 3D models without an issue.</p>
","<p><a href=""http://panda3d.org/"">Panda3D</a> is only other one I would really call an engine per se. There are Python bindings for Ogre, but I've heard mixed review of them. Unity can be scripted in Boo which is almost, but not quite, entirely unlike Python.</p>
","8293"
"How closely can a game legally resemble another?","25880","","<p>Most games build on other games' successes and many are downright clones. Where is the limit of imitation before legal issues come into play? Is it down to literary or graphic work like characters and storyline that cause legal problems, or can someone actually claim to own gameplay mechanics?</p>

<p>There are so many similar clone games out there that the rules are probably very slack or nonexistent, but I'd like to hear the views of more experienced developers / designers.</p>
","<p>I am not a lawyer and this is not legal advice. These are things I've heard many times over and have no reason to doubt.</p>

<p>Game mechanics cannot be copyrighted or protected in any fashion.</p>

<p>I could make a game called ""Crystallized"" that was Bejeweled, in every imaginable way, and as long as I didn't copy the art from Bejeweled (either directly, or by drawing new art that just happens to be nigh-identical) I'd be totally fine.</p>

<p>Game mechanics have been copied often enough that, if this weren't the case, I have no doubt we'd have heard about it by now. Game design is pretty much one giant incestuous ball of borrowing, and, honestly, is better for it.</p>

<p>Keep in mind that you can be sued for anything, even if you're not breaking any contracts or laws, and they might win. But I've never heard of that happening with regards to game design.</p>
","1660"
"How does gluLookAt work?","25608","","<p>From my understanding,   </p>

<pre><code>gluLookAt(
        eye_x, eye_y, eye_z,
        center_x, center_y, center_z,   
        up_x, up_y, up_z
    );
</code></pre>

<p>is equivalent to:  </p>

<pre><code>glRotatef(B, 0.0, 0.0, 1.0);
glRotatef(A, wx, wy, wz);
glTranslatef(-eye_x, -eye_y, -eye_z);
</code></pre>

<p>But when I print out the <code>ModelView</code> matrix, the call to <code>glTranslatef()</code> doesn't seem to work properly. Here is the code snippet:</p>

<pre><code>#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;GL/glut.h&gt;

#include &lt;iomanip&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;

using namespace std;

static const int Rx = 0;
static const int Ry = 1;
static const int Rz = 2;

static const int Ux = 4;
static const int Uy = 5;
static const int Uz = 6;

static const int Ax = 8;
static const int Ay = 9;
static const int Az = 10;

static const int Tx = 12;
static const int Ty = 13;
static const int Tz = 14;

void init() {
    glClearColor(0.0, 0.0, 0.0, 0.0);
    glEnable(GL_DEPTH_TEST);
    glShadeModel(GL_SMOOTH);
    glEnable(GL_LIGHTING);
    glEnable(GL_LIGHT0);
    GLfloat lmodel_ambient[] = { 0.8, 0.0, 0.0, 0.0 };
    glLightModelfv(GL_LIGHT_MODEL_AMBIENT, lmodel_ambient);
}

void displayModelviewMatrix(float MV[16]) {
    int SPACING = 12;
    cout &lt;&lt; left;
    cout &lt;&lt; ""\tMODELVIEW MATRIX\n"";
    cout &lt;&lt; ""--------------------------------------------------"" &lt;&lt; endl;
    cout &lt;&lt; setw(SPACING) &lt;&lt; ""R"" &lt;&lt; setw(SPACING) &lt;&lt; ""U"" &lt;&lt; setw(SPACING) &lt;&lt; ""A"" &lt;&lt; setw(SPACING) &lt;&lt; ""T"" &lt;&lt; endl;   
    cout &lt;&lt; ""--------------------------------------------------"" &lt;&lt; endl;
    cout &lt;&lt; setw(SPACING) &lt;&lt; MV[Rx] &lt;&lt; setw(SPACING) &lt;&lt; MV[Ux] &lt;&lt; setw(SPACING) &lt;&lt; MV[Ax]  &lt;&lt; setw(SPACING) &lt;&lt; MV[Tx] &lt;&lt; endl;
    cout &lt;&lt; setw(SPACING) &lt;&lt; MV[Ry] &lt;&lt; setw(SPACING) &lt;&lt; MV[Uy] &lt;&lt; setw(SPACING) &lt;&lt; MV[Ay]  &lt;&lt; setw(SPACING) &lt;&lt; MV[Ty] &lt;&lt; endl;
    cout &lt;&lt; setw(SPACING) &lt;&lt; MV[Rz] &lt;&lt; setw(SPACING) &lt;&lt; MV[Uz] &lt;&lt; setw(SPACING) &lt;&lt; MV[Az] &lt;&lt; setw(SPACING)  &lt;&lt; MV[Tz] &lt;&lt; endl;
    cout &lt;&lt; setw(SPACING) &lt;&lt; MV[3] &lt;&lt; setw(SPACING) &lt;&lt; MV[7] &lt;&lt; setw(SPACING) &lt;&lt; MV[11] &lt;&lt; setw(SPACING) &lt;&lt; MV[15] &lt;&lt; endl;
    cout &lt;&lt; ""--------------------------------------------------"" &lt;&lt; endl;
    cout &lt;&lt; endl;
}

void reshape(int w, int h) {
    float ratio = static_cast&lt;float&gt;(w)/h;
    glViewport(0, 0, w, h);
    glMatrixMode(GL_PROJECTION);
    glLoadIdentity();
    gluPerspective(45.0, ratio, 1.0, 425.0);
}

void draw() {
    float m[16];
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
    glMatrixMode(GL_MODELVIEW);
    glLoadIdentity();
    glGetFloatv(GL_MODELVIEW_MATRIX, m);
    gluLookAt(
        300.0f, 0.0f, 0.0f,
        0.0f, 0.0f, 0.0f,
        0.0f, 1.0f, 0.0f
    );
    glColor3f(1.0, 0.0, 0.0);
    glutSolidCube(100.0);
    glGetFloatv(GL_MODELVIEW_MATRIX, m);
    displayModelviewMatrix(m);
    glutSwapBuffers();
}


int main(int argc, char** argv) {
    glutInit(&amp;argc, argv);
    glutInitDisplayMode(GLUT_DOUBLE | GLUT_RGB | GLUT_DEPTH);
    glutInitWindowSize(400, 400);
    glutInitWindowPosition(100, 100);
    glutCreateWindow(""Demo"");
    glutReshapeFunc(reshape);
    glutDisplayFunc(draw);
    init();
    glutMainLoop();
    return 0;
} 
</code></pre>

<p>No matter what value I use for the <code>eye</code> vector:<br>
<code>300, 0, 0</code> or<br>
<code>0, 300, 0</code> or<br>
<code>0, 0, 300</code><br>
the translation vector is the same, which doesn't make any sense because the order of code is in backward order so <code>glTranslatef</code> should run first, then the 2 rotations. Plus, the rotation matrix, is completely independent of the translation column (in the ModelView matrix), then what would cause this weird behavior?
Here is the output with the eye vector is <code>(0.0f, 300.0f, 0.0f)</code></p>

<pre><code>        MODELVIEW MATRIX
--------------------------------------------------
R           U           A           T
--------------------------------------------------
0           0           0           0
0           0           0           0
0           1           0           -300
0           0           0           1
--------------------------------------------------
</code></pre>

<p>I would expect the <code>T</code> column to be <code>(0, -300, 0)</code>! So could anyone help me explain this?</p>

<p>The implementation of <code>gluLookAt</code> from <a href=""http://www.mesa3d.org"">http://www.mesa3d.org</a></p>

<pre><code>void GLAPIENTRY
gluLookAt(GLdouble eyex, GLdouble eyey, GLdouble eyez, GLdouble centerx,
      GLdouble centery, GLdouble centerz, GLdouble upx, GLdouble upy,
      GLdouble upz)
{
    float forward[3], side[3], up[3];
    GLfloat m[4][4];

    forward[0] = centerx - eyex;
    forward[1] = centery - eyey;
    forward[2] = centerz - eyez;

    up[0] = upx;
    up[1] = upy;
    up[2] = upz;

    normalize(forward);

    /* Side = forward x up */
    cross(forward, up, side);
    normalize(side);

    /* Recompute up as: up = side x forward */
    cross(side, forward, up);

    __gluMakeIdentityf(&amp;m[0][0]);
    m[0][0] = side[0];
    m[1][0] = side[1];
    m[2][0] = side[2];

    m[0][1] = up[0];
    m[1][1] = up[1];
    m[2][1] = up[2];

    m[0][2] = -forward[0];
    m[1][2] = -forward[1];
    m[2][2] = -forward[2];

    glMultMatrixf(&amp;m[0][0]);
    glTranslated(-eyex, -eyey, -eyez);
}
</code></pre>
","<p><code>gluLookAt</code> will rotate and translate the world in a way, that the camera will be located at <code>{0, 0, 0}</code> and looks towards the negative z-axis. This is the camera setup used in OpenGL. The camera actually never moves, the world does. Sound confusing? Hell yeah, let me try to explain :)</p>

<p>Lets take this example:</p>

<pre><code>eye    :  {300, 0, 0}
lookat :  {  0, 0, 0}
up     :  {  0, 1, 0}

MODELVIEW MATRIX
--------------------------------------------------
R           U           A           T           
--------------------------------------------------
0           0           -1          0           
0           1           0           0           
1           0           0           -300        
0           0           0           1           
--------------------------------------------------
</code></pre>

<p>First we need to analyze the rotational part of the matrix: <code>R</code>, <code>U</code> and <code>A</code>. As you can see the right vector (<code>R</code>) is not in the x-axis anymore <code>{1, 0, 0}</code>, it is in the z-axis <code>{0, 0, 1}</code>. That means it is rotated by 90 degrees around the y-axis. The same happens to the eye-position. Rotating <code>{-300, 0, 0}</code> by 90 degrees around the y-axis lets it end up at <code>{0, 0, -300}</code>, voila, there it is.</p>

<p>It is <code>-300</code> and not <code>300</code> because the world is moved and not the camera, so the world is moved in the opposite direction, still 300 units away from the camera at <code>{0, 0, 0}</code>. And again, it is moved towards the negative z-axis, because that is where the OpenGL camera looks to, as mentioned above.</p>

<hr>

<p>Note: there is an an anomaly in your example, the normalized vector from eye-position to look-at-point must not be the same as the up-vector, so:</p>

<pre><code>eye    : {0, 300, 0}
lookat : {0,   0, 0}
up     : {0,   1, 0}    

normalize(eye - lookat): {0, 1, 0} -&gt; the same as the up-vector
</code></pre>

<p>will in fact not work, we must pick another up-vector, for instance <code>{1, 0, 0}</code></p>
","41969"
"Will the inclusion of LGBT characters in my game detract from possible sales?","25585","","<p>As we all know, the inclusion of LGBT characters has been a mighty controversial topic in recent film and literature (<a href=""http://time.com/4691035/franklin-graham-beauty-and-the-beast-gay-character/"" rel=""noreferrer"">Beauty and the Beast probably being the premier example</a>). Some love it with <em>every fiber of their being</em>, while others <em>absolutely detest the very thought of it</em>. Now, keep in mind that <strong><em>I am not here to start a political firestorm</em></strong> nor am I here to preach my own personal beliefs regarding this, I'm simply asking the question: <em>will the inclusion of LGBT characters decrease potential sales?</em></p>

<p>In our game, a pseudo-'90s JRPG, one of our main story writers added two <a href=""https://en.wikipedia.org/wiki/Consul"" rel=""noreferrer"">consuls</a> (of a civilization with heavy Roman influence, but with different laws), both female, married. Originally hailing from an area in which LGBT relationships are looked down upon, I was quick to note that it may be <em>too much controversy</em>, but it truly depends on where you live—for him it was almost completely normal.</p>

<p>As I see it, we have three choices.</p>

<ul>
<li>We can keep the characters just as they are.</li>
<li>We can keep the characters, but only imply their relationship.</li>
<li>We can alter the relationship entirely, changing one to a male.</li>
</ul>

<p>Right now, our main goal is to satisfy the general public while still strongly appealing to those who actually played JRPG's such as <em>Dragon Quest</em> or <em>Final Fantasy</em> back in the day. Which of these three options should we choose to best enhance our sales, or, if it's not up there, what is the wisest way to go about doing this? <strong><em>I am looking for facts and data if possible and/or applicable</em></strong>.</p>

<p>EDIT: Our target audience is Everyone! Like we said, we’re aiming to <em>satisfy the general public</em> while still appealing to those who played JRPG’s back in the ‘90s. </p>

<p>EDIT II: Wow. Every almost answer here contained a <em>wealth</em> of information, and I'd like to formally thank all that contributed. I will be using the information from just about all of these answers, and I'm sure may others facing this issue may as well.</p>

<p>EDIT III: If you have comments that aren’t answers or you’d like to further discuss this, please refer to the <a href=""http://chat.stackexchange.com/rooms/65797/discussion-on-question-by-nd523-will-the-inclusion-of-lgbt-characters-in-my-game"">official chat room</a> as opposed to commenting. Thanks! </p>
","<p>I come from a place in the Internet most people deem to be horrible in every single way. While I generally don't agree with most of the stuff said in that website, I can provide some insight on what happens around there when a pro-LGBT game is released.</p>

<ul>
<li>A small but very vocal group of (probable) trolls will complain about it, no matter the way they are depicted, under the argument that it's ""degenerate"", ""pozzed"" and a thousand other descriptors usually containing the word ""cuck"" in them. They swear they won't ever buy the game because of these small details, and will generally attempt to derail any serious discussion about the game, but they are a really tiny percentage of the population that just happens to invade any threads made about games like these.</li>
<li>Some users, the less sarcastical version of the above, will automatically qualify whether it's cute or ""degenerate"" exclusively depending on whether the game was made in Japan or not. It's as dumb as arbitrary, but they are somewhat grounded in reality considering the vast majority of Japanese depictions of LGBT people is very different from the vast majority of their western counterparts.</li>
<li>Some users will only care about whether the girls and the relationship are cute and whether it comes of as preachy or not.</li>
<li>Some users will only care about whether the game presents this plot point as preachy or very ""in your face"". Probably the biggest demographic around these places.</li>
</ul>

<p>Some research on Gamergate and its slow declive into the alt-right should give some light on the above positions, but the general idea is, they are tired of games being marketed on their ""progressiveness"", which usually tends to overinflate their scores in game journalism sites even though the games are not that good (in the case of Gone Home, some people don't even consider it a game, yet it managed to score a 10/10 in many reviews, which didn't sit well with many gamers). This resulted in an influx of games with progressive values being thrown in your face in the most preachy and obnoxious way possible just to achieve ""brownie points"" in attempts to replicate the success of previous games who did this, something they didn't like because it went against their beliefs and political stances. This may seem inmature, but nobody likes to feel like the games they are playing are going directly against them, so it is kind of logical to expect such an outcome.</p>

<p>Thing is, these gamers are very wary of these topics because they feel ""stiff"" and ""fake"", as in, so shoehorned it becomes obvious the devs are trying to virtue signal in hopes their game gets noticed by the games journalism crowd. Most of the LGBT character depictions shown on many recent games seem to default to the ""accepted"" representations of their gender or sexuality (how many characters would describe ""strong independent lesbian woman who needs no man, is snarky towards everyone, always looks angry and has short hair"", despite that description being very specific?), so many of these characters end up having the same personalities, same background and sometimes even same questlines, which to these people smells like mass produced token LGBT. The queer characters are often presented as borderline Mary Sue saints who could do no wrong, but are always wronged by (most of the time, and I think this is your game's case as well) white cishet males just because they are hateful mysoginistic beings or something like that, even when they are not. Queer people are still people after all, so they should probably have as many flaws as the non-queer people, and you should contemplate that into writing them as actual characters and not ""that lesbian couple"" in that game.</p>

<p>But people will always find a way to complain. This is a ""damned if you do, damned if you don't"" situation in which incorporating LGBT characters or not, making them flawed or not, making it an extremely secondary trait or their whole personality, making them evil or good, making them stereotypical or not, will result in outrage from certain demographics. My advice is, just do whatever you think will be best for your game without thinking of sales, reviews or prohibitions, because there are not enough cotton gloves in the world to tackle these topics without offending anyone.</p>

<p>If all you want to know is whether this will boost sales or not, it all depends on your target. As people mentioned before, do you want this game not o be 18 or not? Do you plan on translating it to Russian and selling it there? Do you want to target hardcore gamers who most often than not despise preachy politics in their games? If the answer to any of these is ""yes"", you may want to just leave it as heavily implied at best. Do you want to target fans of JRPG, who are very likely to like Japanese media in general? As stupid as it seems, your best bet is sexualizing them (people will get mad about this, but if they are outside of your target demographic, it doesn't really matter). Otherwise, if you want to target a more casual (not in a bad sense, not even as in people who only play Candy Crush on their phones - still ""core"" gamers, just not as fixated on videogames that take a lot of effort to play) or modern demographic, such as the people who played and liked Life is Strange, Gone Home, or Dragon Age: Inquisition, making them blatantly gay could even boost your sales.</p>

<p><strong>EDIT:</strong> I remember Dofus had two NPC, a major and her secretary, named Mayor Cantille and Lou Bricante (yes, that's probably a sexual pun; game is full of them), who were very explicitly implicitly closet lesbians for each other. People talked a bit about this, but nobody seemed to care because it was cute and both girls were cute. Villagers would often gossip about it for comedic purposes. It wasn't given much relevance, and it was always treated in a very lighthearted tone -like the rest of the game-, so it simply happened to be a very secondary side story that was consistent with the setting, so I guess people simply accepted it; which brings me to the point that, if it is not a relevant plot point, just mention it in passing just like you would comment on any plot point of little relevancy.</p>

<p>I guess your case with the consul could be similar, but keep in mind that, depending on how directly based on Roman society the society in your game is, some people could complain about lack of realism (yeah, even if otherwise your game contains dragons and magic crystals). While ancient Rome didn't really treat homosexual relationships much differently to heterosexual relationships, they did treat women, and whoever they deemed to fulfill the role of the woman in a relationship, as inferior. I am unsure how would have ancient Rome reacted to a masculine lesbian consul, considering information on lesbians in ancient Rome is scarce, but chances are she would have stood no chance against other male politicians.</p>

<p>To avoid these complaints, either try to show (don't just tell!) in which ways this society distanced itself from our ancient Rome, and try to justify how could this happen, and of course, what could the possible reactions to this be, or just treat it in a consistent manner (if it isn't something people usually accept, why would they be telling anyone but people they utterly trust?).</p>

<p>Part of why people disliked the transsexual character in Baldur's Gate: Siege of Dragonspear is because they were out of place. It's already weird enough to bump into a stranger and casually start talking about stuff, so don't make it any weirder by talking about personal stuff most people have no bussiness knowing. This, combined by the fact that it just comes out of the blue (shoehorning), that the universe has genderbending magic that's apparently not in play here (inconsistency), that the topic isn't relevant at all to the plot or worldbuilding at al (virtue signaling at its finest), and that it's one of the only dialogues that doesn't let you any agency at all on how to react to this (which comes out as inconsistent, preachy and gives the impression Mizhena is above other characters just because she is trans) made several people, <a href=""https://forums.beamdog.com/discussion/50420/my-thoughts-on-mizhena-as-a-transgender-person-myself"" rel=""noreferrer"">including trans people themselves</a>, angry about the inclusion of just a token LGBT character for the sake of having a token LGBT character, above the normal rules of the world and dialog mechanics.</p>
","148554"
"How to generate Spritefonts for monogame","25401","","<p>I just want to render some text to the screen using:</p>

<ul>
<li>monogame 3.0</li>
<li>MS Visual Studio 2010 C# Express</li>
</ul>

<p>In XNA, you were able to add fonts to the content pipeline quite easily. But this doesn't seem to be the case in monogame. Loading TTF Files using <code>Content&lt;SpriteFont&gt;.Load()</code> doesn't work. Is there any way to generate or download *.spritefont files or *.xnb files containing the font data (without resorting to install XNA)?</p>
","<p>An alternative is to use pre-generated bitmap fonts instead. Here's a tutorial I wrote a while back on using the BMFont tool to get text into your game using the <a href=""https://github.com/craftworkgames/MonoGame.Extended"" rel=""nofollow"">MonoGame.Extended</a> library.</p>

<p><a href=""http://dylanwilson.net/bmfont-rendering-with-monogame-extended"" rel=""nofollow"">http://dylanwilson.net/bmfont-rendering-with-monogame-extended</a></p>
","46137"
"How do you draw a straight line between two points in a bitmap?","25354","","<p>I'm playing around with height maps (bitmaps), trying to create some of my own in my game, and for that I need to implement some basic drawing methods. I've quickly realized that drawing straight lines isn't as basic as I thought.</p>

<p>It simple's if your points share an X or Y coordinate, or if they are aligned so you can draw a perfectly diagonal line. But in all other cases its trickier.</p>

<p>What algorithm do you use to determine what pixels need to be coloured for it to become a ""straight"" line ?</p>
","<p>I think what you need is <a href=""https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm"">Bresenham's line algorithm</a>. </p>

<p>From what I remember it is used to determine <em>what</em> point should be coloured, not <em>how much</em> each point should be coloured. </p>
","71306"
"Match-three puzzle games algorithm","25348","","<p>I am trying to write a match-three puzzle game like 'call of Atlantis' myself. The most important algorithm is to find out all possible match-three possibilities. Is there any open source projects that can be referenced? Or any keywords to the algorithm? I am trying to look for a faster algorithm to calculate all possibilities. </p>

<p>Rules:</p>

<ul>
<li>Diagonals don't count.</li>
<li>The size is 8x8</li>
</ul>

<p>Thanks.</p>
","<p>I helped port one of these games to a handheld platform.  Looking back at their AI code for finding potentials: yipe, it's complicated, brutish (quadruply nested loop, calls itself recursively occasionally, etc), and it doesn't appear at all cache-friendly at first glance.</p>

<p>(Some of that complexity comes from trying to evaluate the strength of the move in context: valuing longer chains higher, looking for combos, etc...)</p>

<p>But it doesn't really need to be ""optimal""; we didn't even touch the code when we ported it.  It never showed up on the profiler.</p>

<p>Looking at it now, even at one 32 bit word per cell (and I think they actually used a byte per cell), the entire board will fit in a minuscule L1 cache, and you can do many excess reads on stuff that's cached without impacting framerate too much.  <em>Especially</em> since you only need to do this whole process once each time the board configuration changes.  (A <a href=""http://en.wikipedia.org/wiki/Big_O_notation"">big-theta</a> hovering around <code>n^2</code> isn't that horribly bad with a very low <code>n</code>, not to mention the small multiplier given the cached memory.)</p>

<p>That having been said: for amusement, let's attempt to parallelize the problem.  Starting with bitwise operations.</p>

<p>Assume you have a bitmask representing all of the pieces (we'll call them stones) in a row that are of one particular type (we'll use colors to distinguish types).  We'll start only looking at red stones, and worry about the cost of calculating the bitmask later.</p>

<pre><code>// Let's assume top right indexing.
// (The assumption is not necessary, --
//    it just makes the left-shift and right-shift operators 
//    look like they're pointing in the correct direction.)

// this is for row 2
col index  76543210
color      BRRGYRBR // blue, red, red, green, yellow, ...
""red"" bits 01100101
</code></pre>

<p>We're looking for the series that need just one swap to become a series of 3.  Courtesy Kaj, this is one of three combinations, basically: <code>XoX</code>, <code>oXX</code>, or <code>XXo</code> where <code>X</code> is a matching stone and <code>o</code> is something else.</p>

<p>(This idea is borrowed from the marvelous <a href=""http://www.hackersdelight.org/"">Hacker's Delight book</a>; see also the <a href=""http://www.jjj.de/fxt/#fxtbook"">fxtbook</a> if such things delight you.)</p>

<pre><code>// using c-style bitwise operators:
// &amp; is ""and""
// ^ is ""xor""
// | is ""or""
// &lt;&lt; and &gt;&gt; are arithmetic (non-sign-extending) shifts

redBitsThisRow = redBitsRows[2]

// find the start of an XoX sequence
startOfXoXSequence = redBitsThisRow &amp; (redBitsThisRow &lt;&lt; 2);
// for our example, this will be 00000100

// find any two stones together in a row
startOfXXSequence = redBitsThisRow &amp; (redBitsThisRow &lt;&lt; 1);
// for our example, this will be 01000000
</code></pre>

<p>It's more useful to know the positions of the missing stones, not the start of the XX or XoX sequence:</p>

<pre><code>// give us any sequences that might want a stone from the left
missingLeftStone = startOfXXSequence &lt;&lt; 1;
// for our example, this will be 10000000

// give us any sequences that might want a stone from the right
missingRightStone = startOfXXSequence &gt;&gt; 2;
// for our example, this will be 00010000

// give us any sequences that might want a stone from the top or bottom
missingTopOrBottomStone = missingRightStone | missingLeftStone | (startOfXoXSequence &gt;&gt; 1)
// for our example, this will be 10010010
</code></pre>

<p>(About 1 load and 9 ALU instructions -- 5 shifts, 2 ors, 2 ands -- with a dreadful CPU that doesn't include an inline shifter.  On many architectures these shifts might be free.)</p>

<p>Can we fill these missing places?</p>

<pre><code>// look to the left, current row
leftMatches = redBitsThisRow &amp; (missingLeftStone &lt;&lt; 1)

// look to the right, current row
rightMatches = redBitsThisRow &amp; (missingRightStone &gt;&gt; 1)

// look on the row above
topMatches = redBitsRow[1] &amp; missingTopOrBottomStone

// look on the row below
bottomMatches = redBitsRow[3] &amp; missingTopOrBottomStone
</code></pre>

<p>(Another 2 loads and 6 ALU instructions -- 4 ands, 2 shifts -- with a bad CPU.  Note that row 0 and row 7 may give you trouble -- you can choose to branch around these calculations, or avoid the branch by allocating space for two extra rows, one before 0 and one after 7, and leave them zeroed out.)</p>

<p>Now we have several ""matches"" vars that indicate the position of a stone that can be swapped in to make a match.</p>

<p>This assumes a ""count trailing zeros"" intrinsic or very cheap inline method:</p>

<pre><code>swapType = RIGHT_TO_LEFT;
matches = leftMatches;
while ( (colIdx = ctz(matches)) &lt; WORD_BITS ) {
   // rowIdx is 2 in our examples above
   workingSwaps.insert( SwapInfo(rowIdx, colIdx, swapType) );
   // note that this SwapInfo construction could do some more advanced logic:
   //   run the swap on a temporary board and see how much score it accumulates
   //   assign some sort of value based on preferring one type of match to another, etc

   matches = matches ^ (1&lt;&lt;colIdx); // clear the match, so we can loop to the next
}
// repeat for LEFT_TO_RIGHT with rightMatches
// repeat for TOP_TO_BOTTOM with topMatches
// repeat for BOTTOM_TO_TOP with bottomMatches
</code></pre>

<p>Note that none of this bit logic should break down in little-endian vs big-endian environments.  It gets much more tricky for boards wider than your machine word size.  (You could experiment with something like <code>std::bitset</code> for this.)</p>

<p>What about columns?  It may be easiest just to have two copies of the table, one stored in row-order and one stored in column-order.  If you have getters and setters wrapping board access, this should be trivial.  I don't mind keeping two arrays up to date, after all a set becomes <code>rowArray[y][x] = newType; colArray[x][y] = newType;</code> and that's simple.  </p>

<p>...but managing <code>rowBits[color][row]</code> and <code>colBits[color][col]</code> becomes obnoxious.</p>

<p>However, as a quick aside, if you do have <code>rowBits</code> and <code>colBits</code>, you can run the <em>same code</em> with rowBits pointing at colBits instead.  Pseudocode, assuming board width = board height = 8 in this case...</p>

<pre><code>foreach color in colors {
    foreach bits in rowBits, colBits {
        foreach row in 0..7 { // row is actually col the second time through
            // find starts, as above but in bits[row]
            // find missings, as above
            // generate matches, as above but in bits[row-1], bits[row], and bits[row+1]
            // loop across bits in each matches var,
            //    evaluate and/or collect them, again as above
        }
    }
}
</code></pre>

<p>What if we don't want the bother with converting a nice 2D array into bits?  With an 8x8 board, 8 bits per cell, and a 64-bit-capable processor, we might be able to get away with it: 8 cells = 8 bytes = 64 bits.  We're locked to our board width, now, but this seems promising.</p>

<p>Assume ""0"" is reserved, stones begin at 1 and go to NUM_STONE_TYPES inclusive.</p>

<pre><code>startOfXXSequence = rowBytes ^ (rowBytes &lt;&lt; (8*1))
// now all bytes that are 0x00 are the start of a XX sequence

startOfXoXSequence = rowBytes ^ (rowBytes &lt;&lt; (8*2))
// all bytes that are 0x00 are the start of a XoX sequence
</code></pre>

<p>Note this doesn't need one pass per color.  In <code>BRBRBRGY</code> we'll get a <code>startOfXoXSequence</code> that might be something like <code>0x00 00 00 00 aa bb cc dd</code> -- the top four bytes will be zero, indicating a possible sequence starts there.</p>

<p>It's getting late, so I'll leave off here and possibly come back later -- you can continue along this vein with xors and ""detect first zero byte"" tricks, or you could look into some integer <a href=""https://secure.wikimedia.org/wikipedia/en/wiki/SIMD"">SIMD</a> extensions.</p>
","2627"
"What are the best resources on multi-threaded game or game engine design and development?","25190","","<p>What are the best resources on multi-threaded game or game engine design and development? As this is obviously where computers are headed, I intend to study this topic and I'd like to know what resources and examples are out there.</p>
","<p>Some intel resources.</p>

<p><a href=""http://software.intel.com/en-us/articles/designing-the-framework-of-a-parallel-game-engine/"">http://software.intel.com/en-us/articles/designing-the-framework-of-a-parallel-game-engine/</a></p>

<p><a href=""http://software.intel.com/en-us/videos/dont-dread-threads-part-1/"">http://software.intel.com/en-us/videos/dont-dread-threads-part-1/</a></p>
","2131"
"How can I calculate the angle and proper turn direction between two 2D vectors?","25165","","<p>I am working on some movement AI where there are no obstacles and movement is restricted to the XY plane. I am calculating two vectors, <strong>v</strong>, the facing direction of ship 1, and <strong>w</strong>, the vector pointing from the position of ship 1 to ship 2.</p>

<p>I am then calculating the angle between these two vectors using the formula</p>

<pre><code>arccos((v · w) / (|v| · |w|))
</code></pre>

<p>The problem I'm having is that <code>arccos</code> only returns values between 0° and 180°.  This makes it impossible to determine whether I should turn left or right to face the other ship.</p>

<p>Is there a better way to do this?</p>
","<p>It's much faster to use a 2d cross-product.  No costly trig function involved.</p>

<pre><code>b2Vec2 target( ... );
b2Vec2 heading( ... );

float cross = b2Cross( target, heading );

if( cross == -0.0f )
   // turn around

if( cross == 0.0f )
  // already traveling the right direction

if( cross &lt; 0.0f)
  // turn left

if( cross &gt; 0.0f)
  // turn right
</code></pre>

<p>If you still need the actual angles I recommend using <code>atan2</code>.  <code>atan2</code> will give you the absolute angle of any vector.  To get the relative angle between any to vectors, calcuate their absolute angles and use simple subtraction.</p>

<pre><code>b2Vec2 A(...);
b2Vec2 B(...);

float angle_A = std::atan2(A.y,A.x);
float angle_B = B.GetAngle(); // Box2D already figured this out for you.

float angle_from_A_to_B = angle_B-angle_A;
float angle_from_B_to_A = angle_A-angle_B;
</code></pre>
","7155"
"How many textures can usually I bind at once?","25133","","<p>I'm developing a game engine, and it's only going to work on modern (Shader model 4+) hardware. I figure that, by the time I'm done with it, that won't be such an unreasonable requirement.</p>

<p>My question is: how many textures can I bind at once on a modern graphics card? 16 would be sufficient. Can I expect most modern graphics cards to support that amount?</p>

<p>My GTX 460 appears to support 32, but I have no idea if that's representative of most modern video cards.</p>
","<p>I believe 32 is the maximum number of textures that can be bound currently. As far as I can tell even the 8800 series had 32 texture units.</p>

<p>As far as I know, for openGL 4.x support you will need a Fermi or newer nvidia card(or corresponding amd card), the higher end models all seem to have 32 units, while the lowest end cards (GT 430, for example) have 16. 
However, looking at AMD spec sheets they list numbers like 80 or 128 texture units, but list 32 color ROP units which seem to have remained constant through generations. </p>

<p>The GTX 480 on the other hand is listed with 60 texture units and 48 ROP units, while lower end cards like the 430 reportedly only have 16 texture units and 4 ROP inits.
So on the whole I'm not really convinced either of those is the number you are actually looking for.</p>

<p>You can check the number of texture units available for non-fixed function pipeline rendering with <code>glGetIntegerv(GL_MAX_TEXTURE_IMAGE_UNITS, &amp;texture_units);</code>, though, so if you have access to some diverse hardware you could check yourself.</p>

<p>EDIT: this site lets you compare the reported openGL capabilities of all sorts of video cards, that should give you the numbers you need: <a href=""http://feedback.wildfiregames.com/report/opengl/device/GeForce%20GTX%20580"" rel=""nofollow"">http://feedback.wildfiregames.com/report/opengl/device/GeForce%20GTX%20580</a></p>

<p>PS: AMD and nvidia have recently introduced ""bindless textures"", (amd has a different name for it) which allows you to use large numbers of textures without binding them to textutre units, at the moment this is only available in openGL.</p>
","30044"
"How do I create 2D water with dynamic waves?","25120","","<p><em>New Super Mario Bros</em> has really cool 2D water that I'd like to learn how to create.</p>

<p><a href=""http://www.ign.com/videos/2012/11/17/new-super-mario-bros-u-3-star-coin-walkthrough-sparkling-waters-1-waterspout-beach"" rel=""noreferrer"">Here's a video</a> showing it. An illustrative part:</p>

<p><a href=""https://i.stack.imgur.com/Wptbp.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Wptbp.gif"" alt=""New Super Mario Bros water effects""></a></p>

<p>Things hitting the water create waves. There are also constant ""background"" waves. You can get a good look at the constant waves just after 00:50 in the video, when the camera isn't moving.</p>

<p>I assume the splash effects work as in the first part of <a href=""http://gamedev.tutsplus.com/tutorials/implementation/make-a-splash-with-2d-water-effects/"" rel=""noreferrer"">this tutorial</a>.</p>

<p>However, in <em>NSMB</em> the water also has constant waves on the surface, and the splashes look very different. Another difference is that in the tutorial, if you create a splash, it first creates a deep ""hole"" in the water at the origin of the splash. In new super mario bros this hole is absent or much smaller. I am referring to the splashes that the player creates when jumping in and out of the water.</p>

<p><strong>How do I create a water surface with constant waves and splashes?</strong></p>

<p>I am programming in XNA. I've tried this myself, but I couldn't really get the <a href=""https://gamedev.stackexchange.com/questions/44216/re-create-2d-side-on-wave-effect-from-worms-game?lq=1"">background sine waves</a> to work well together with the dynamic waves.</p>

<p>I am not asking how the developers of <em>New Super Mario Bros</em> did this exactly—just interested in how to recreate an effect like it.</p>
","<p>I tried it.</p>

<h1>Splashes (springs)</h1>

<p>As <a href=""http://gamedev.tutsplus.com/tutorials/implementation/make-a-splash-with-2d-water-effects/"" rel=""noreferrer"">that tutorial</a> mentions, the surface of water is like a wire: If you pull on some point of the wire, the points next to that point will be pulled down too. All points are also attracted back to a baseline.</p>

<p>It's basically lots of vertical springs next to each other that pull on each other also.</p>

<p>I sketched that in Lua using <a href=""https://love2d.org/"" rel=""noreferrer"">LÖVE</a> and got this:</p>

<p><img src=""https://i.stack.imgur.com/IBwQH.gif"" alt=""animation of a splash""></p>

<p>Looks plausible. Oh <a href=""http://en.wikipedia.org/wiki/Hooke%27s_law"" rel=""noreferrer"">Hooke</a>, you handsome genius.</p>

<p>If you want to play with it, here is a <a href=""http://jsfiddle.net/phil_mcc/sXmpD/8/#run"" rel=""noreferrer"">JavaScript port</a> courtesy of <a href=""https://gamedev.stackexchange.com/users/3681/phil-mccull"">Phil</a>! My code is at the end of this answer.</p>

<h1>Background waves (stacked sines)</h1>

<p>Natural background waves look to me like a bunch of sine waves (with different amplitudes, phases and wavelengths) all summed together. Here's what that looked like when I wrote it:</p>

<p><img src=""https://i.stack.imgur.com/61xIA.gif"" alt=""background waves produced by sine interference""></p>

<p>The interference patterns look pretty plausible.</p>

<h1><em>All together now</em></h1>

<p>So then it's a pretty simple matter to sum together the splash waves and the background waves:</p>

<p><img src=""https://i.stack.imgur.com/sGuhH.gif"" alt=""background waves, with splashes""></p>

<p>When splashes happen, you can see small grey circles showing where the original background wave would be.</p>

<p>It looks a lot like <a href=""http://www.ign.com/videos/2012/11/17/new-super-mario-bros-u-3-star-coin-walkthrough-sparkling-waters-1-waterspout-beach"" rel=""noreferrer"">that video you linked</a>, so I'd consider this a successful experiment.</p>

<p>Here's my <code>main.lua</code> (the only file). I think it's quite readable.</p>

<pre class=""lang-lua prettyprint-override""><code>-- Resolution of simulation
NUM_POINTS = 50
-- Width of simulation
WIDTH = 400
-- Spring constant for forces applied by adjacent points
SPRING_CONSTANT = 0.005
-- Sprint constant for force applied to baseline
SPRING_CONSTANT_BASELINE = 0.005
-- Vertical draw offset of simulation
Y_OFFSET = 300
-- Damping to apply to speed changes
DAMPING = 0.98
-- Number of iterations of point-influences-point to do on wave per step
-- (this makes the waves animate faster)
ITERATIONS = 5

-- Make points to go on the wave
function makeWavePoints(numPoints)
    local t = {}
    for n = 1,numPoints do
        -- This represents a point on the wave
        local newPoint = {
            x    = n / numPoints * WIDTH,
            y    = Y_OFFSET,
            spd = {y=0}, -- speed with vertical component zero
            mass = 1
        }
        t[n] = newPoint
    end
    return t
end

-- A phase difference to apply to each sine
offset = 0

NUM_BACKGROUND_WAVES = 7
BACKGROUND_WAVE_MAX_HEIGHT = 5
BACKGROUND_WAVE_COMPRESSION = 1/5
-- Amounts by which a particular sine is offset
sineOffsets = {}
-- Amounts by which a particular sine is amplified
sineAmplitudes = {}
-- Amounts by which a particular sine is stretched
sineStretches = {}
-- Amounts by which a particular sine's offset is multiplied
offsetStretches = {}
-- Set each sine's values to a reasonable random value
for i=1,NUM_BACKGROUND_WAVES do
    table.insert(sineOffsets, -1 + 2*math.random())
    table.insert(sineAmplitudes, math.random()*BACKGROUND_WAVE_MAX_HEIGHT)
    table.insert(sineStretches, math.random()*BACKGROUND_WAVE_COMPRESSION)
    table.insert(offsetStretches, math.random()*BACKGROUND_WAVE_COMPRESSION)
end
-- This function sums together the sines generated above,
-- given an input value x
function overlapSines(x)
    local result = 0
    for i=1,NUM_BACKGROUND_WAVES do
        result = result
            + sineOffsets[i]
            + sineAmplitudes[i] * math.sin(
                x * sineStretches[i] + offset * offsetStretches[i])
    end
    return result
end

wavePoints = makeWavePoints(NUM_POINTS)

-- Update the positions of each wave point
function updateWavePoints(points, dt)
    for i=1,ITERATIONS do
    for n,p in ipairs(points) do
        -- force to apply to this point
        local force = 0

        -- forces caused by the point immediately to the left or the right
        local forceFromLeft, forceFromRight

        if n == 1 then -- wrap to left-to-right
            local dy = points[# points].y - p.y
            forceFromLeft = SPRING_CONSTANT * dy
        else -- normally
            local dy = points[n-1].y - p.y
            forceFromLeft = SPRING_CONSTANT * dy
        end
        if n == # points then -- wrap to right-to-left
            local dy = points[1].y - p.y
            forceFromRight = SPRING_CONSTANT * dy
        else -- normally
            local dy = points[n+1].y - p.y
            forceFromRight = SPRING_CONSTANT * dy
        end

        -- Also apply force toward the baseline
        local dy = Y_OFFSET - p.y
        forceToBaseline = SPRING_CONSTANT_BASELINE * dy

        -- Sum up forces
        force = force + forceFromLeft
        force = force + forceFromRight
        force = force + forceToBaseline

        -- Calculate acceleration
        local acceleration = force / p.mass

        -- Apply acceleration (with damping)
        p.spd.y = DAMPING * p.spd.y + acceleration

        -- Apply speed
        p.y = p.y + p.spd.y
    end
    end
end

-- Callback when updating
function love.update(dt)
    if love.keyboard.isDown""k"" then
        offset = offset + 1
    end

    -- On click: Pick nearest point to mouse position
    if love.mouse.isDown(""l"") then
        local mouseX, mouseY = love.mouse.getPosition()
        local closestPoint = nil
        local closestDistance = nil
        for _,p in ipairs(wavePoints) do
            local distance = math.abs(mouseX-p.x)
            if closestDistance == nil then
                closestPoint = p
                closestDistance = distance
            else
                if distance &lt;= closestDistance then
                    closestPoint = p
                    closestDistance = distance
                end
            end
        end

        closestPoint.y = love.mouse.getY()
    end

    -- Update positions of points
    updateWavePoints(wavePoints, dt)
end

local circle = love.graphics.circle
local line   = love.graphics.line
local color  = love.graphics.setColor
love.graphics.setBackgroundColor(0xff,0xff,0xff)

-- Callback for drawing
function love.draw(dt)

    -- Draw baseline
    color(0xff,0x33,0x33)
    line(0, Y_OFFSET, WIDTH, Y_OFFSET)

    -- Draw ""drop line"" from cursor

    local mouseX, mouseY = love.mouse.getPosition()
    line(mouseX, 0, mouseX, Y_OFFSET)
    -- Draw click indicator
    if love.mouse.isDown""l"" then
        love.graphics.circle(""line"", mouseX, mouseY, 20)
    end

    -- Draw overlap wave animation indicator
    if love.keyboard.isDown ""k"" then
        love.graphics.print(""Overlap waves PLAY"", 10, Y_OFFSET+50)
    else
        love.graphics.print(""Overlap waves PAUSED"", 10, Y_OFFSET+50)
    end


    -- Draw points and line
    for n,p in ipairs(wavePoints) do
        -- Draw little grey circles for overlap waves
        color(0xaa,0xaa,0xbb)
        circle(""line"", p.x, Y_OFFSET + overlapSines(p.x), 2)
        -- Draw blue circles for final wave
        color(0x00,0x33,0xbb)
        circle(""line"", p.x, p.y + overlapSines(p.x), 4)
        -- Draw lines between circles
        if n == 1 then
        else
            local leftPoint = wavePoints[n-1]
            line(leftPoint.x, leftPoint.y + overlapSines(leftPoint.x), p.x, p.y + overlapSines(p.x))
        end
    end
end
</code></pre>
","45247"
"What is the difference between OpenGL ES and OpenGL?","25073","","<p>Android uses OpenGL ES, what is the difference between it and OpenGL?</p>
","<p>OpenGL ES (Embedded Systems) is a stripped down version of OpenGL. There are a lot of differences between those two and if you want to go way into the details, <a href=""http://www.khronos.org/registry/gles/specs/1.1/es_cm_spec_1.1.12.pdf"">then you can read this 128 specification paper.</a> But ES is a subset of OpenGL so all ES apps work on non ES systems but not the opposite.</p>

<p>There is no one place where you can easily define what is in ES and what is not. Even one definition is ""OpenGL-ES is just like OpenGL, but without a lot of stuff. For example, there's no glBegin or glEnd.""</p>
","161"
"Why do game studios need graphics programmers if they're using game engines?","25069","","<p>In the credits section of the games I play, there are names of <em>graphics programmers</em>. If they used a game engine, why do they need a <em>graphics programmer</em>? Isn't the game engine doing their job?</p>
","<p>Even with an engine, getting something to display on the screen the way you want it is not always trivial. There will be many instances where someone with programming knowledge is required to make the graphics display correctly. These people may be called graphics programmers in the credits (graphics programmer is not a certified or protected title, and the difference between different titles can vary a lot by company).</p>

<p>Let's bring a concrete example. We need an animated rotating circle, as follows:</p>

<p><a href=""https://i.stack.imgur.com/EJmTx.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/EJmTx.gif"" alt=""enter image description here""></a></p>

<p>Some of our options are:</p>

<p>1 Put the circle on a billboard, write a script to rotate the billboard.</p>

<p>2 Use an animated gif as the source.</p>

<p>3 Do the whole thing in a shader, which allows 2 different options:</p>

<ul>
<li>Rotate the billboard in the vertex shader</li>
<li>Draw a rotated circle in the fragment shader.</li>
</ul>

<p>In 1. someone needs to write that script, which is some kind of programming task that has to do with graphics. For 2. we don't need a programmer, unless the engine - like most - doesn't support import of animated gifs, in which case somebody needs to program that part. In 3. someone has to program the shader, which could be an artist or a programmer. </p>

<p>EDIT to address downvotes:</p>

<p>The downvotes seem  to be because the effect is too simple and thus wouldn't be implemented by a ""real"" graphics programmer. I don't really know who else it would be implemented by if there is a dedicated graphics programmer on the team, and I occasionally do implement such rotation effects in shaders - although usually the rotation is just a part of a bigger whole, as in <a href=""https://gamedev.stackexchange.com/a/111584/65776"">this example</a>.</p>
","142035"
"How do you prevent inflation in a virtual economy?","25032","","<p>With your typical MMORPG, players can usually farm the world for raw materials essentially forever. Monsters/mineral veins/etc are usually on some sort of respawn timer, so other than time there really isn't a good way to limit the amount of new currency entering the system. </p>

<p>That really only leaves money sinks to try to take money out of the system. What are some strategies to prevent inflation of the in-game currency?</p>
","<p>Money sinks are I guess the only real answer. Which means items or currency getting lost forever. </p>

<p>Eve Online blatantly has this through the mass destruction of items and ships through pvp (only partially replaced by insurance). Eve also has many other money sinks such as office rent, station fuels, ammunition etc.</p>

<p>Other games have similar consumables, either necessities like ammo or items that provide buffs etc. (food, potions, pet food, poisons etc.) </p>

<p>Many games (such as World of Warcraft) feature Bind on Pickup and Bind on Equip items. They are actually money sinks. You can enchant and add gems to your items but at some point you will upgrade it. So upgrading actually destroys the old item along with any value to added to it via enchanting etc. Or in some games you can 'recycle' it for less that the original value.</p>

<p>This is a nice sink because it doesn't negatively impact players.They only really notice it at the same time as they are cheering about their brand new shiny loot. Also, even if the item is never lost and just remains in a character's backpack it can be considered out of the economy because it will never pass to another player.</p>

<p>Which brings us to other utility money sinks like increased bank and inventory space. </p>

<p>Aesthetic upgrades are also a good way to introduce sinks without affecting the gameplay balance of your game. Things like clothing dye or vanity mounts and pets.</p>
","1099"
"Freeglut vs SDL vs GLFW","25010","","<p>i need to port my game project from Android (written in C, OpenGL ES 2.0, thanks to NDK) to Windows and Linux platforms. Of course i will need to rewrite some platform depended code, but now i stuck with question which library for creating OpenGL and input handle use.  </p>

<p>Just a quick googling get me 3 candidates:  </p>

<p>1) Freeglut - rewrited and free good old GLUT.<br>
2) SDL - most well know one lib, used in many games.<br>
3) GLFW - some kind of new, but simple and functional.  </p>

<p>I just quite new to PC develop and don't see any significant differences beetweem them.
Can you help me which one to choose? I clearly need just core mouse/keyboard input and creating of OpenGL context, also i will use GLEW to get to modern OpenGL with easy.</p>
","<p><strong>GLFW</strong> <em>is modern</em> and <em>has a very well defined scope</em>. It's also under very active development.</p>

<p><strong>SDL</strong> on the other side <em>is rock solid</em> and has a lot features in different scopes but is somewhat lacking in all of them (for example: SDL can do audio, but you might prefer using OpenAL because its far superior in that matter). It might be notable that SDL was ported to many different platforms, unlike GLFW which is only for desktop platforms (win/linux/mac).</p>

<p><strong>GLUT</strong>, well, <em>should be avoided</em>. There simply isn't really anything about it what makes it good.</p>

<hr>

<p>In my opinion as perfectionist GLFW is the better choice. Because it does exactly what one wants, nothing less nothing more. The very active development is also a good sign for long term projects because it usually means that bugs will be fixed, that new features will be added, it will keep up with newer standards and that it won't be abadoned anytime near. This isn't important for a quick port or a 6-month game, but for a engine or a library you want to reuse I would keep that in mind.</p>
","32601"
"onTouchEvent only working for one view within activity","24899","","<p>I have a parent Activity which contains 2 views. One view is a custom view class, where I am overriding the onDraw method. This view contains an onTouchEvent function, which is checking for user clicks within the view. </p>

<p>Below this view I have another view, which is a view extending LinearLayout, which contains 9 buttons which are numbers to be selected by the user[I am basically trying to build a simple Sudoku game]. Now user clicks on my top view, which is the Sudoku Grid works fine, but it is calling the onTouchEvent of the top view, even when I click on the buttons within the bottom view keypad.</p>

<p>I have tried everything, from setFocusable(true), in the XML, in the constructor, from the parent activity. I even placed a onTouchListener on the keypad view. This listener is getting called when I click anywhere within the keypad view, except for on the buttons???</p>

<p>How can I detect a keyPress on the bottom view??</p>

<p>The bits of code</p>

<pre><code>public class TrialBoard extends View{
@Override
public boolean onTouchEvent(MotionEvent event){
if(event.getAction() == MotionEvent.ACTION_DOWN)
{
 selX = (int)event.getX();
 selY = (int)event.getY();
 Log.d(TTAG,""Touch X : "" + selX + "" Touch Y : "" + selY);
 getRect(selX, selY);
 return true;
}else
if((event.getAction() == MotionEvent.ACTION_CANCEL)||(event.getAction()==MotionEvent.ACTION_OUTSIDE)){
 return false;//TRIED THIS BUT NOT WORKING
}else{
 return super.onTouchEvent(event);
}   
</code></pre>

<p>}</p>

<pre><code>public class CustomKeypad extends LinearLayout {

@Override
public boolean onTouchEvent(MotionEvent event){
    if(event.getAction() == MotionEvent.ACTION_DOWN)
    {
        Log.d(KTAG,""Inside onTouch of keypad"");
        return true;
    }else{
        return super.onTouchEvent(event);
    }
//NOT GETTING CALLED AT ALL 
}
}

public class TrialActivity extends Activity {

@Override
public void onCreate(Bundle savedInstanceState){
    super.onCreate(savedInstanceState);
    Log.d(TRIALTAG,""Inside on create"");
    setContentView(R.layout.trial_activity);
    keypadView = findViewById(R.id.keypad); 
    selNumber = 0;
    keypadView.bringToFront();
    keypadView.setFocusable(true);
    keypadView.setFocusableInTouchMode(true);
    keypadView.setOnTouchListener(new View.OnTouchListener() {
        public boolean onTouch(View v, MotionEvent event){
            Log.d(TRIALTAG,""Inside keypad view touched listener event"");
            return true;
        }
    });
}
}
</code></pre>

<p>EDIT 2:
My XML for keypad:</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
android:layout_width=""fill_parent""
android:layout_height=""match_parent""
android:orientation=""horizontal""
android:background=""@drawable/keypad_background"" &gt;
</code></pre>

<p></p>

<pre><code>&lt;TableRow &gt;
   &lt;Button android:id=""@+id/keypad_1""
       android:text=""@string/key1""
       android:padding=""2dp""
       android:onClick=""num1Clicked""/&gt;
   &lt;Button android:id=""@+id/keypad_2""
       android:text=""@string/key2""
       android:padding=""2dp""
        android:onClick=""num2Clicked""/&gt;
   &lt;Button android:id=""@+id/keypad_3""
       android:text=""@string/key3"" 
       android:padding=""2dp""
        android:onClick=""num3Clicked""/&gt;
&lt;/TableRow&gt;
&lt;TableRow &gt;
    &lt;Button android:id=""@+id/keypad_4""
        android:text=""@string/key4""
        android:padding=""2dp""
         android:onClick=""num4Clicked"" /&gt;
    &lt;Button android:id=""@+id/keypad_5""
        android:text=""@string/key5""
        android:padding=""2dp""
         android:onClick=""num5Clicked"" /&gt;
    &lt;Button android:id=""@+id/keypad_6""
        android:text=""@string/key6""
        android:padding=""2dp""
         android:onClick=""num6Clicked"" /&gt;
&lt;/TableRow&gt;
&lt;TableRow &gt;
    &lt;Button android:id=""@+id/keypad_7""
        android:text=""@string/key7""
        android:padding=""2dp""
         android:onClick=""num7Clicked"" /&gt;
    &lt;Button android:id=""@+id/keypad_8""
        android:text=""@string/key8""
        android:padding=""2dp""
         android:onClick=""num8Clicked"" /&gt;
    &lt;Button android:id=""@+id/keypad_9""
        android:text=""@string/key9""
        android:padding=""2dp""
         android:onClick=""num9Clicked"" /&gt;
&lt;/TableRow&gt;
&lt;/TableLayout&gt;
</code></pre>

<p>I added the onClick later, coz I realized too late that this was a easier and saner way to get a button click event. I guess in a way I do deserve a flag down coz I should have remembered this, but I am still puzzled as to why it would not pick up the button click on the onTouchEvent.</p>
","<p>It does not work because the buttons are Views too, just as LinearLayout and since they are on top they need their own ""onTouchEvent"" listener, which is onClick listener in their case. LinearLayout does not detect the touch on its children views because the children overtake the touch events for themselves.</p>

<p>But did you try to touch around the button? Then the LinearLayout's onTouchEvent may work.</p>
","54421"
"What are 3D textures?","24887","","<p>Google has failed me, I could not find anything informative. So perhaps GameDev can :).</p>

<ul>
<li>What are 3D textures?</li>
<li>When are they
used?</li>
<li>Performance costs?</li>
<li>How are they stored?</li>
</ul>

<p>I have many vague ideas, but no 'definitive' definition.</p>

<p>Any references to examples or tutorials is appreciated, especially in rendering particle systems via 3D textures.</p>
","<p>3D texture works like regular texture. But it is truly 3D. 2D textures has UV coords, 3D has UVW (you had to use them propably). Texture coords are unit cube (0 - 1, 0 - 1, 0 - 1).</p>

<p><strong>Possible usage</strong>:</p>

<ul>
<li>volumetric effects in games (fire, smoke, light rays, realistic fog)</li>
<li>caching light for realtime global illumination (<a href=""http://www.youtube.com/watch?v=Pq39Xb7OdH8"" rel=""noreferrer"">CryEngine</a> for example)</li>
<li>scientific (MRI, CT scans are saved into volumes)</li>
</ul>

<p><strong>Performance</strong>:<br>
Same as regular texture - super fast (fastest memory access in gpu). Cached for threads and optimized for the situation when near threads (pixel shaders) are looking for near values.</p>

<p>Can be read as point or used linear sampling (native tri-linear interpolation. Eq bi-linear interpolation in 2D texture).</p>

<p>They are stored in memory like a array of 2D textures.</p>

<p>Mipmapping on 3D texture:<br>
<img src=""https://i.stack.imgur.com/mLWdJ.png"" alt=""enter image description here""></p>
","9674"
"outline object effect","24816","","<p>How can I achieve an outline effect similar to the ones found in League of Legends or Diablo III?</p>

<p><img src=""https://i.stack.imgur.com/T9jPJ.png"" alt=""League of Legends outline"">
<img src=""https://i.stack.imgur.com/4fn3i.png"" alt=""League of Legends outline"">
<img src=""https://i.stack.imgur.com/EGF3E.jpg"" alt=""Diablo III outline""></p>

<p>Is it done using a shader? How?<br>
I would prefer answers that are not tied up to any particular engine but one that I can adapt to whatever engine I'm working on.</p>
","<p><strong>You <em>will</em> have to render the object twice at some point.</strong> You can get away with rendering just the faces facing the camera once and the faces facing <em>away</em> from the camera once, but it has its trade-offs.</p>

<p>The most simplest common solution is done by rendering the object twice in the same pass:</p>

<ul>
<li>You use a vertex shader to invert the normals of the object and ""blow it up"" by the size of the outline and a fragment shader to render it in the outline colour</li>
<li>Over that outline render, you render the object normally. The z-order is usually automatically right, more or less, since the outline is made by the faces which are in the ""back"" of the object while the figure itself is made up of faces facing the camera.</li>
</ul>

<p>This is simple enough to build and implement and avoids any render-to-texture tricks, but has a few noticeable drawbacks:</p>

<ul>
<li>The outline size, if you don't scale it by the distance from the camera, will vary. Objects further away will have a smaller outline than those nearby. Of course, this might be what you actually <em>want</em>.</li>
<li>The ""blow up"" vertex shader doesn't work very well for complex objects like the skeleton in you example, easily introducing z-fighting artefacts to the render. Fixing it requires you to render the object in two passes, but saves you from reversing the normals.</li>
<li>The outline and the object might not work very well when other objects are occupying the same space and are in general a pain to get right when combined with reflection and refraction shaders.</li>
</ul>

<p>The basic idea for such a shader looks like this (Cg, for Unity - the code is a slightly modified toon shader I found somewhere and didn't note the source, so it's more badly-written proof-of-concept than a ready-to-use shader):</p>

<pre><code>Shader ""Basic Outline"" {
    Properties {
        _Color (""Main Color"", Color) = (.5,.5,.5,1)
        _OutlineColor (""Outline Color"", Color) = (1,0.5,0,1)
        _Outline (""Outline width"", Range (0.0, 0.1)) = .05
        _MainTex (""Base (RGB)"", 2D) = ""white"" { }
    }
    SubShader {
        Tags { ""RenderType""=""Opaque"" }
        Pass {
            Name ""OUTLINE""
            Tags { ""LightMode"" = ""Always"" }
CGPROGRAM
#pragma exclude_renderers gles
#pragma exclude_renderers xbox360
#pragma vertex vert

struct appdata {
    float4 vertex;
    float3 normal;
};

struct v2f
{
    float4 pos : POSITION;
    float4 color : COLOR;
    float fog : FOGC;
};
float _Outline;
float4 _OutlineColor;
v2f vert(appdata v)
{
    v2f o;
    o.pos = mul(UNITY_MATRIX_MVP, v.vertex);
    float3 norm = mul ((float3x3)UNITY_MATRIX_MV, v.normal);
    norm.x *= UNITY_MATRIX_P[0][0];
    norm.y *= UNITY_MATRIX_P[1][1];
    o.pos.xy += norm.xy * _Outline;
    o.fog = o.pos.z;
    o.color = _OutlineColor;
    return o;
}
ENDCG
            Cull Front
            ZWrite On
            ColorMask RGB
            Blend SrcAlpha OneMinusSrcAlpha
            SetTexture [_MainTex] { combine primary }
        }
        Pass {
        Name ""BASE""
        Tags {""LightMode"" = ""Always""}
CGPROGRAM
#pragma fragment frag
#pragma vertex vert
#pragma fragmentoption ARB_fog_exp2
#pragma fragmentoption ARB_precision_hint_fastest
#include ""UnityCG.cginc""

struct v2f {
    float4 pos : SV_POSITION;
    float2    uv            : TEXCOORD0;
    float3    viewDir        : TEXCOORD1;
    float3    normal        : TEXCOORD2;
}; 

v2f vert (appdata_base v)
{
    v2f o;
    o.pos = mul (UNITY_MATRIX_MVP, v.vertex);
    o.normal = v.normal;
    o.uv = TRANSFORM_UV(0);
    o.viewDir = ObjSpaceViewDir( v.vertex );
    return o;
}

uniform float4 _Color;

uniform sampler2D _MainTex;
float4 frag (v2f i)  : COLOR
{
    half4 texcol = tex2D( _MainTex, i.uv );

    half3 ambient = texcol.rgb * (UNITY_LIGHTMODEL_AMBIENT.rgb);
    return float4( ambient, texcol.a * _Color.a );
}
ENDCG
    }
    }
    FallBack ""Diffuse""
}
</code></pre>

<p>The other common method renders the object twice as well, but avoids the vertex shader fully. On the other hand, it can't be easily done in a single pass, and needs render-to-texture: Render the object once with a ""flat"" outline-coloured fragment shader and use a (weighted) blur on this render in <em>screen space</em>, then render the object as usual on top of it.</p>

<p>There's also a third and possibly easiest to implement method, though it taxes the GPU a bit more and will make your artists want to murder you in your sleep unless you make it easy for them to generate: Have the objects have the outline as a separate mesh all the time, just fully transparent or moved somewhere where it's not seen (like deep underground) until you need it</p>
","34654"
"How to change Gravity towards certain object in Unity?","24810","","<p>I have two spheres in Unity. One is 1000x in size other is 1x in size. So I want the smaller sphere to be attracted to bigger sphere. So how do I do it. I know that it can be down through gravity using rigid body. But how do I change gravity angle towards the big sphere?</p>
","<p>Gravity in the Unity physics engine only goes in one direction and is controlled in the Physics menu in the Edit->Project Settings menu.</p>

<p><img src=""https://i.stack.imgur.com/8ZgiL.jpg"" alt=""enter image description here""></p>

<p>If you want to do something other than that, you'll have to implement your own gravity. </p>

<p>Basically, you can add a sphere collider on the object you want to be the center of gravity. The collider should encompass the entire area where you want objects to be affected by the gravity of that object. Whenever an object collides with this ""sphere of influence"", you apply a force to it. You continue to apply a force to it as long as it's inside the sphere of influence.</p>

<p>The gravitational constant you use can be tweaked by you, but the standard one used for calculations in the real world is:</p>

<blockquote>
  <p>F = Gm1m2/r2</p>
</blockquote>

<p>Spelled out that's:</p>

<blockquote>
  <p>Force = <a href=""http://en.wikipedia.org/wiki/Gravitational_constant"" rel=""noreferrer"">Gravitational constant</a> * mass of object 1 * mass of object 2 / the distance between the two objects squared.</p>
</blockquote>

<p>Do note that Gravitational constant is not 9.81. That's the acceleration caused by gravity at the earth's surface.</p>
","63547"
"What to consider when deciding on 2D vs 3D for a game?","24665","","<p>How much ""harder"" is 3D than 2D in terms of:</p>

<ul>
<li>Amount/complexity of the code</li>
<li>Level of math skills required</li>
<li>Time involved in making art assets</li>
</ul>

<p><em>Original title: How hard is 3D game development versus 2D?</em></p>
","<p>3D is an order of magnitude harder than 2D:</p>

<p><strong>Programming:</strong></p>

<ul>
<li><strong>The math is significantly more complex</strong> for rendering, physics, collision, etc. Hope you like matrices and vectors!</li>
<li>Because of the previous point, <strong>good performance is much more difficult to attain</strong>. With today's hardware, you can make a nice-looking 2D game without having to think about performance at all beyond not being actively stupid. With 3D, you will have to do some optimization.</li>
<li><strong>The data structures are much more complex.</strong> Because of the previous point, you'll need to think about culling, space partitioning, etc. all of which are more challenging then a simple ""here's a list of everything in the level"".</li>
<li><strong>Animation is much more complicated.</strong> Animation in 2D is just a filmstrip of frames with possibly different positions for each frame. With 3D, you'll need to deal with separate animation assets, bones, skinning, etc.</li>
<li><strong>The volume of data is much higher.</strong> You'll have to do intelligent resource management. Games ship with gigs of content, but consoles sure as hell don't have gigs of memory.</li>
<li><strong>The pipelines are more complex to develop and maintain.</strong> You'll need code to get assets into your engine's preferred format. That code doesn't write itself.</li>
</ul>

<p><strong>Art:</strong></p>

<ul>
<li><strong>The assets are, of course, much more complex.</strong> You'll need textures, models, rigs/skeletons, animation, etc. The tools are much more complex and expensive, and the skills to use them harder to find.</li>
<li><strong>The set of skills needed is wider.</strong> Good animators aren't often good texture artists. Good lighters may not be good riggers.</li>
<li><strong>The dependencies between the assets are more complex.</strong> With 2D, you can partition your assets across different artists cleanly: this guy does level one, this guy does enemies, etc. With 3D, the animation affects the rig which affects the skeleton which affects the model which affects the textures which affect the lighting... Your art team will have to coordinate carefully and constantly.</li>
<li><strong>The technical limitations are more complex to deal with.</strong> With 2D it's basically ""here's your palette and your max sprite size"". With 3D, your artists will have to balance texture size (for multiple textures: specular, color, normal, etc.), polygon count, keyframe count, bone count, etc. The particulars of the engine will place random weird requirements on them (""Engine X blows up if you have more than 23 bones!"").</li>
<li><strong>Asset processing takes longer.</strong> Pipelines to convert 3D assets to game-ready format are complex, slow, and often buggy. This makes it take much longer for artists to see their changes in game, which slows them down.</li>
</ul>

<p><strong>Design:</strong></p>

<ul>
<li><strong>User input is bitch.</strong> You have to deal with camera tracking, converting user input into the character's space intuitively, projecting 2D selections into world space, etc.</li>
<li><strong>Levels are hard to author.</strong> Your level designers basically need the skills of a game designer and an architect. They have to take into account players getting lost, visibility, etc. when building levels.</li>
<li><strong>Level physics is tedious to author.</strong> You'll have to check and recheck and recheck again to make sure there aren't gaps and bugs in the level physics where players can get stuck or fall through the world.</li>
<li><strong>Tools are much harder.</strong> Most games need their own tools for authoring things like levels. Since the content is so much more complex, the tools are more work to create. That usually results in tools that are buggier, incomplete, and harder to use.</li>
</ul>
","637"
"Unity 5 2D drawing sprites programmatically","24591","","<p>How can I draw sprites in Unity 5 programmatically ? I am looking for something similar to <code>spriteBatch.Draw()</code> in XNA. The results I get when I search about it are either outdated <a href=""http://wiki.unity3d.com/index.php?title=SpriteManager"" rel=""noreferrer"">http://wiki.unity3d.com/index.php?title=SpriteManager</a> (this was written in 2012), or they are done using the unity interface. All I can find is a <code>Sprite</code> class in UnityEngine.dll. Is this what I need ? How would the drawing work ? I really don't get it.</p>
","<p>Unity does not have this kind of ""direct mode"" rendering, you won't be calling <code>Draw</code> in any update loops for Unity.</p>

<p>In Unity you need to create a game object, then attach scripts to that game object. Those scripts will control how the object behaves, if and how it's displayed on screen, if it's part of the physics system etc.</p>

<p>To create a new sprite to draw on screen you'll need to create a new game object, then attach the SpriteRenderer script to it and set its sprite.</p>

<pre><code>GameObject go = new GameObject();
SpriteRenderer renderer = go.AddComponent&lt;SpriteRenderer&gt;();

renderer.sprite = Resources.Load(""Sprites/Player"", typeof(Sprite)) as Sprite;
</code></pre>

<p>This assumes a directory structure of </p>

<pre><code>-Assets
--Resources
---Sprites
----&lt;Your 2D assets, set with their texture type to Sprite (2D and UI)&gt;
</code></pre>

<p>For example:</p>

<p><img src=""https://i.stack.imgur.com/x0vP3.png"" alt=""enter image description here""></p>

<p>Then you'd had a different script for changing the position, rotation etc, depending how you want it to behave.</p>

<p>The easiest way to accomplish all of this without having to write as much code? Create the game object in the Unity editor first. Once the game object is equipped with the sprite you want and the behavior scripts and all that. Drag and drop it into a resources directory. This creates a prefab. Prefabs are just what they sound like, pre-fabrications. They're complete objects that you can then reference and create on the fly.</p>

<p>You'd create those like:</p>

<pre><code>public void CreateObject(string prefabName) {
   GameObject newObject = 
      GameObject.Instantiate(Resources.Load(prefabName)) as GameObject;
}
</code></pre>

<p>This will spawn a clone of the prefab you created before. So, if for example, you'd given your prefab the behavior of moving towards the player and attacking, every time you spawn a new prefab of that type, they will start moving towards the player and attacking. The scripts you only had to write once control all of those game objects.</p>

<p>I think the main difference you're seeing here is the heavy use of components. Which you likely haven't seen in other game engines like XNA. Unity really is a powerful engine, but your frustration comes from trying to use it like other engines, when it's not like other engines. Check out my profile for some training, I added a link for a free trial so you don't have to pay.</p>
","96065"
"How do I instantiate a prefab to a specific coordinate?","24547","","<p>I have a prefab called ‘road’.  How can I instantiate it (using C#) such that it appears initially at coordinates <code>(5, 5, 5)</code>?</p>
","<p>If you put the prefab into a directory called <code>Resources</code> inside your <code>Assets</code> directory, you'll be able to use the <a href=""http://docs.unity3d.com/ScriptReference/Resources.html""><code>Resources</code></a> class and its <a href=""http://docs.unity3d.com/ScriptReference/Resources.Load.html""><code>load</code></a> functionality. This will load a prefab up as a <code>GameObject</code>, which can then be instantiated.</p>

<p>For example:</p>

<pre><code>GameObject myRoadInstance = Instantiate(Resources.Load(""road"")) as GameObject;
</code></pre>

<p>Will create a instance of your ""road"" prefab in the game world.</p>

<p>You can either set its position by modifying its transform, or you can use the alternate version of <a href=""http://docs.unity3d.com/ScriptReference/Object.Instantiate.html""><code>Instantiate</code></a> to specify a position.</p>

<pre><code>GameObject myRoadInstance =
            Instantiate(Resources.Load(""road""),
            new Vector3(5, 5, 5),
            Quaternion.identity) as GameObject;
</code></pre>
","97375"
"Best C++ Math Library for Game Engine?","24517","","<p>I'm looking for a fast opensource C++ math-library for my game engine
with the following features:</p>

<ul>
<li>fast (sse?)</li>
<li>vectors </li>
<li>matrices </li>
<li>quaternions</li>
</ul>

<p>suitable for both opengl and directx</p>
","<p>XNA Math might be for you. It's a header only C++ math library that is distributed with the latest DirectX SDK and uses SSE intrinsics. I can't talk much about its performance but from what I read about it, it seems to be pretty decent.</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ee415574%28VS.85%29.aspx"">XNA Math Reference</a></p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ee415571%28VS.85%29.aspx"">XNA Math programming guide</a></p>

<p><a href=""http://www.microsoft.com/downloads/en/details.aspx?displaylang=en&amp;FamilyID=3021d52b-514e-41d3-ad02-438a3ba730ba"">DX SDK download</a></p>

<p>EDIT: I'm also not sure about the licensing terms. The DX SDK Eula states that ""Distributable Code"" may not be </p>

<blockquote>
  <p>""run on a platform other than the Windows, Xbox and Windows Mobile platforms;""</p>
</blockquote>

<p>I'm not entirely sure whether this applies for xna math as only sample and utility code is explicitly marked as ""Distributable Code""</p>
","9939"
"Algorithm for creating spheres?","24483","","<p>Does anyone have an algorithm for creating a sphere proceduraly with <code>la</code> amount of latitude lines, <code>lo</code> amount of longitude lines, and a radius of <code>r</code>? I need it to work with Unity, so the vertex positions need to be defined and then, the triangles defined via indexes (<a href=""http://docs.unity3d.com/Documentation/ScriptReference/Mesh.html"" rel=""noreferrer"">more info</a>).</p>

<hr>

<p><strong>EDIT</strong></p>

<p><img src=""https://i.stack.imgur.com/oxZ4V.png"" alt=""enter image description here""></p>

<p>I managed to get the code working in unity. But I think I might have done something wrong. When I turn up the <code>detailLevel</code>, All it does is add more vertices and polygons without moving them around. Did I forget something?</p>

<hr>

<p><strong>EDIT 2</strong></p>

<p><img src=""https://i.stack.imgur.com/jfiUG.png"" alt=""enter image description here""></p>

<p>I tried scaling the mesh along its normals. This is what I got. I think I'm missing something. Am I supposed to only scale certain normals?</p>
","<p>To get something like this:</p>

<p><img src=""https://i.stack.imgur.com/bSq13.png"" alt=""enter image description here""></p>

<p>Create an icosahedron (20-sided regular solid) and subdivide the faces to get a sphere (see code below).</p>

<p>The idea is basically:</p>

<ul>
<li>Create a regular n-hedron (a solid where every face is the same size). I use an icosahedron because it's the solid with the greatest number of faces where every face is the same size. (There's a proof for that somewhere out there. Feel free to Google if you're really curious.) This will give you a sphere where nearly every face is the same size, making texturing a little easier.</li>
</ul>

<p><img src=""https://i.stack.imgur.com/ROb4t.png"" alt=""enter image description here""></p>

<ul>
<li><p>Subdivide each face into four equally-sized faces. Each time you do this, it'll quadruple the number of faces in the model.</p>

<pre><code>///      i0
///     /  \
///    m02-m01
///   /  \ /  \
/// i2---m12---i1
</code></pre></li>
</ul>

<p><code>i0</code>, <code>i1</code>, and <code>i2</code> are the vertices of the original triangle. (Actually, indices into the vertex buffer, but that's another topic). <code>m01</code> is the midpoint of the edge <code>(i0,i1)</code>, m12 is the midpoint of the edge <code>(i1,12)</code>, and <code>m02</code> is, obviously, the midpoint of the edge <code>(i0,i2)</code>. </p>

<p>Whenever you subdivide a face, make sure that you don't create duplicate vertices. Each midpoint will be shared by one other source face (since the edges are shared between faces). The code below accounts for that by maintaining a dictionary of named midpoints that have been created, and returning the index of a previously created midpoint when it's available rather than creating a new one.</p>

<ul>
<li><p>Repeat until you've reached the desired number of faces for your cube.</p></li>
<li><p>When you're done, normalize all of the vertices to smooth out the surface. If you don't do this, you'll just get a higher-res icosahedron instead of a sphere.</p></li>
<li><p>Voila! You're done. Convert the resulting vector and index buffers into a <code>VertexBuffer</code> and <code>IndexBuffer</code>, and draw with <code>Device.DrawIndexedPrimitives()</code>. </p></li>
</ul>

<p>Here's what you'd use in your ""Sphere"" class to create the model (XNA datatypes and C#, but it should be pretty clear):</p>

<pre><code>        var vectors = new List&lt;Vector3&gt;();
        var indices = new List&lt;int&gt;();

        GeometryProvider.Icosahedron(vectors, indices);

        for (var i = 0; i &lt; _detailLevel; i++)
            GeometryProvider.Subdivide(vectors, indices, true);

        /// normalize vectors to ""inflate"" the icosahedron into a sphere.
        for (var i = 0; i &lt; vectors.Count; i++)
            vectors[i]=Vector3.Normalize(vectors[i]);
</code></pre>

<p>And the <code>GeometryProvider</code> class</p>

<pre><code>public static class GeometryProvider
{

    private static int GetMidpointIndex(Dictionary&lt;string, int&gt; midpointIndices, List&lt;Vector3&gt; vertices, int i0, int i1)
    {

        var edgeKey = string.Format(""{0}_{1}"", Math.Min(i0, i1), Math.Max(i0, i1));

        var midpointIndex = -1;

        if (!midpointIndices.TryGetValue(edgeKey, out midpointIndex))
        {
            var v0 = vertices[i0];
            var v1 = vertices[i1];

            var midpoint = (v0 + v1) / 2f;

            if (vertices.Contains(midpoint))
                midpointIndex = vertices.IndexOf(midpoint);
            else
            {
                midpointIndex = vertices.Count;
                vertices.Add(midpoint);
                midpointIndices.Add(edgeKey, midpointIndex);
            }
        }


        return midpointIndex;

    }

    /// &lt;remarks&gt;
    ///      i0
    ///     /  \
    ///    m02-m01
    ///   /  \ /  \
    /// i2---m12---i1
    /// &lt;/remarks&gt;
    /// &lt;param name=""vectors""&gt;&lt;/param&gt;
    /// &lt;param name=""indices""&gt;&lt;/param&gt;
    public static void Subdivide(List&lt;Vector3&gt; vectors, List&lt;int&gt; indices, bool removeSourceTriangles)
    {
        var midpointIndices = new Dictionary&lt;string, int&gt;();

        var newIndices = new List&lt;int&gt;(indices.Count * 4);

        if (!removeSourceTriangles)
            newIndices.AddRange(indices);

        for (var i = 0; i &lt; indices.Count - 2; i += 3)
        {
            var i0 = indices[i];
            var i1 = indices[i + 1];
            var i2 = indices[i + 2];

            var m01 = GetMidpointIndex(midpointIndices, vectors, i0, i1);
            var m12 = GetMidpointIndex(midpointIndices, vectors, i1, i2);
            var m02 = GetMidpointIndex(midpointIndices, vectors, i2, i0);

            newIndices.AddRange(
                new[] {
                    i0,m01,m02
                    ,
                    i1,m12,m01
                    ,
                    i2,m02,m12
                    ,
                    m02,m01,m12
                }
                );

        }

        indices.Clear();
        indices.AddRange(newIndices);
    }

    /// &lt;summary&gt;
    /// create a regular icosahedron (20-sided polyhedron)
    /// &lt;/summary&gt;
    /// &lt;param name=""primitiveType""&gt;&lt;/param&gt;
    /// &lt;param name=""size""&gt;&lt;/param&gt;
    /// &lt;param name=""vertices""&gt;&lt;/param&gt;
    /// &lt;param name=""indices""&gt;&lt;/param&gt;
    /// &lt;remarks&gt;
    /// You can create this programmatically instead of using the given vertex 
    /// and index list, but it's kind of a pain and rather pointless beyond a 
    /// learning exercise.
    /// &lt;/remarks&gt;

    /// note: icosahedron definition may have come from the OpenGL red book. I don't recall where I found it. 
    public static void Icosahedron(List&lt;Vector3&gt; vertices, List&lt;int&gt; indices)
    {

        indices.AddRange(
            new int[]
            {
                0,4,1,
                0,9,4,
                9,5,4,
                4,5,8,
                4,8,1,
                8,10,1,
                8,3,10,
                5,3,8,
                5,2,3,
                2,7,3,
                7,10,3,
                7,6,10,
                7,11,6,
                11,0,6,
                0,1,6,
                6,1,10,
                9,0,11,
                9,11,2,
                9,2,5,
                7,2,11 
            }
            .Select(i =&gt; i + vertices.Count)
        );

        var X = 0.525731112119133606f;
        var Z = 0.850650808352039932f;

        vertices.AddRange(
            new[] 
            {
                new Vector3(-X, 0f, Z),
                new Vector3(X, 0f, Z),
                new Vector3(-X, 0f, -Z),
                new Vector3(X, 0f, -Z),
                new Vector3(0f, Z, X),
                new Vector3(0f, Z, -X),
                new Vector3(0f, -Z, X),
                new Vector3(0f, -Z, -X),
                new Vector3(Z, X, 0f),
                new Vector3(-Z, X, 0f),
                new Vector3(Z, -X, 0f),
                new Vector3(-Z, -X, 0f) 
            }
        );


    }



}
</code></pre>
","31312"
"Event-driven Communication in a Game Engine: Yes or No?","24366","","<p>I am reading <a href=""http://rads.stackoverflow.com/amzn/click/1584506806""><em>Game Coding Complete</em></a> and the author recommends <em>Event Driven communication</em> among game objects and modules.</p>

<p>Basically, all living game actors should communicate with the key modules (Physics, AI, Game Logic, Game View, etc.) via an internal event messaging system. This means having to design an efficient event manager. A badly designed system eats CPU cycles, especially affecting mobile platforms.</p>

<p>Is this a proven and recommended approach? How should I decide whether to use it?</p>
","<p>This is an expansion of <a href=""https://gamedev.stackexchange.com/questions/7718/event-driven-communication-in-a-game-engine-yes-or-no#comment9957_7718"">my comment</a> to a full answer, as suggested.</p>

<p><em>Yes</em>, plain and simple. Communication needs to happen and while there are situations where <em>'Are we there yet?'</em>-type polling is required, having things check to see if they should be doing something else generally wastes time. You could instead have them react to things they are told to do. Plus, a well defined communication pathway between objects/systems/modules boosts parallel setups significantly.</p>

<p>I've given a high-level overview of an event messaging system <a href=""https://stackoverflow.com/questions/4574016/game-objects-talking-to-each-other/4580241#4580241"">over on Stack Overflow</a>. I have used it from school into professional gaming titles and now non-gaming products, adapted to the use case every time of course.</p>

<p><em>EDIT</em>: To address a comment question on <em>how do you know which objects should get the message</em>: The objects themselves should <code>Request</code> to be notified about events. Your <code>EventMessagingSystem</code> (EMS) will need a <code>Register(int iEventId, IEventMessagingSystem * pOjbect, (EMSCallback)fpMethodToUseForACallback)</code> as well as a matching <code>Unregister</code> (making a unique entry for an <code>iEventId</code> out of the object pointer and callback). This way, when an object wants to know about a message it can <code>Register()</code> with the system. When it no longer needs to know about the events, it can <code>Unregister()</code>. Clearly, you'd want a pool of these callback registration objects and an effective way to add/remove them from lists. (I've usually used self ordering arrays; a fancy way of saying they track their own allocations between a pool stack of unused objects and arrays that shift their sizes in place when needed).</p>

<p><em>EDIT</em>: For a completely working game with an update loop and an event messaging system, you might want to check out <a href=""http://sourceforge.net/projects/bpfat/files/"" rel=""nofollow noreferrer"">an old school project of mine</a>. The Stack Overflow post linked above also refers to it.</p>
","7725"
"How do I destroy a Box2D body on contact without getting an IsLocked assertion error?","24356","","<p>I get this error when attempting to remove a body from the world:</p>

<blockquote>
  <p>java:
  /var/lib/hudson/jobs/libgdx/workspace/trunk/gdx/jni/Box2D/Dynamics/b2World.cpp:134:
  void b2World::DestroyBody(b2Body*): Assertion 'IsLocked() == false'
  failed.</p>
</blockquote>

<p>What am I doing wrong?</p>
","<p>From my little experience with box2d in libgdx, it can sometimes be difficult to isolate and resolve issues with exceptions which was only worsened by the latest port. Pre 2.2.1, I could easily remove bodies from the world without synchronization issues like you are experiencing but after migrating to the libgdx build that supported 2.2.1, I started seeing the same issues. The workaround for me, which was suggested by several people was that you cannot remove bodies from the world while the world is possibly being simulated. </p>

<p>Is there a possibility that you are attempting to remove a body from the world when the world is being stepped? Basically, if you try to do this, box2d doesn't like it so what you have to do is remove bodies outside of the <code>world.step</code>. What I did was added a utility class for the body's <code>.userData</code> with a bool isFlaggedForDelete which would get checked <strong>outside</strong> the world.step method.</p>

<pre><code>public void sweepDeadBodies() {
   for (Iterator&lt;Body&gt; iter = CURRENT_WORLD.getBodies(); iter.hasNext();) {
     Body body = iter.next();
     if(body!=null) {
          YourCustomUserData data = (YourCustomUserData) body.getUserData();
          if(data.isFlaggedForDelete) {
          CURRENT_WORLD.destroyBody(body);
            body.setUserData(null);
            body = null;
          }
     }
}
</code></pre>

<p>If you run something like this right after your world.step, it should work. In your code where you are trying to destroy the body, just set it's .isFlaggedForDelete to true and it will get removed before the next world.step. </p>
","27136"
"What does a Game Designer do? what skills do they need?","24337","","<p>I know someone who is thinking about getting into game design, and I wondered, what does the job <em>game designer</em> entail? what tools do you have to learn how to use? what unique skills do you need? what exactly is it you'd do from day to day. I may be wording this a bit wrong because I'm not sure if the college program is <em>become a game designer</em> or learn <em>game design</em>. but I think the same questions apply either way.</p>
","<p><strong>What does the job game designer entail?</strong> </p>

<p>I always explain design to people like this:</p>

<blockquote>What's the difference between Black Jack and Poker?</blockquote>

<p>They both involved players and the same deck of cards, but are entirely different games because the rules that define how the games are played are different. In essence that is what a designer does, writes a series of rules as to how a game plays.</p>

<p>These days as games get more complicated, the job often includes narrative elements in the areas of story/setting/characters. Although many parts of that are given to people dedicated to writing and not design.</p>

<p>Design is a pretty broad term in the industry and it covers everything from high level system design (rules) to narrative design (story/character) to level design (the placing of assets and scripting)</p>

<p><strong>What tools do you have to learn how to use?</strong> </p>

<p>Getting a job directly as a designer is hard. Many of us came from either Programming or Art backgrounds or in my case both. On smaller teams, it'll be expected that you can do something other than design full time as well. The tools change depending on the type of design you are doing.</p>

<p><em>System designer/Creative Director</em> - Most time spent in Excel, Word, and Powerpoint. </p>

<p><em>Narrative designer</em> - Word, maybe Final Draft. These guys are mostly writers.</p>

<p><em>Level Designers</em> - Excel, custom level design software or common 3rd party tools (UnrealEd, and so on) Typically should be comfortable navigating the popular 3D-art packages (Max/Maya)</p>

<p><strong>What unique skills do you need?</strong> </p>

<p>Communication, both writing and verbal is probably your most often used skill once you get to the higher levels of design. Coming up with a design is a pretty small part of the job. You spend most of the time communicating how to build that design to the rest of the team.</p>

<p>Critical thinking, ability to break down a problem into a series of small discrete steps. It's not enough to play a bunch of games. You need to be able to clearly understand how the parts of those games work together. When/why they combine and work, and why they can fail when combined.</p>

<p>Level designers benefit from an art background. An understanding of composition and architecture both help.</p>

<p>A basic psychology understanding is also helpful for designers. The more you understand about how and why people respond to stimulus the better your can predict their response to future designs. </p>
","5390"
"MVC (Model-View-Controller) Game Engine Architecture - Yes or No?","24286","","<p>I am reading one great book, <strong><a href=""http://rads.stackoverflow.com/amzn/click/1584506806"" rel=""nofollow noreferrer"">Game Coding Complete</a></strong>, and that book strongly recommends using <strong>MVC (Model-View-Controller)</strong> approach, with three key layers:</p>

<ol>
<li><em>Game Application Layer</em></li>
<li><em>Game Logic</em></li>
<li><em>Game View</em></li>
</ol>

<p>To me, this approach looks like an overkill for a mobile computer game. </p>

<p>What is your opinion, please? Is it worth of implementing this architecture, even if it adds extra communication needed between modules? Can this design consume so much CPU power, that at the end, the result would be significantly slower, than if it weren't implemented?</p>
","<p>I somewhat support using an MVC structure even for a simple mobile game.  If nothing else, it helps with an issue that plagues developers who haven't gotten bitten by it enough times: separating the display code from the game logic.</p>

<p>I'll also say, though, to keep in mind that MVC, like all design patterns, exists <em>to make your life easier</em>.  That means that if, at any given time, staying within some set of rules about what you should and shouldn't do when using MVC is making your life harder, <em>ignore it</em>.  One of two things will happen: 1) you'll get bitten later, and then will understand why doing it differently in the first place would actually have made your life easier in the long run, or 2) no consequences whatsoever.</p>

<p>Computer programming, by its nature, gets a lot of rule-followers who value adherence to elegant principle over actually accomplishing anything, and they love to propound their value system; don't let them make you one of them.  The most important thing that can happen to your game is <em>shipping it</em>.</p>
","7717"
"Moving from A(x,y) to B(x1,y1) with constant speed?","24279","","<p>I currently have something like:</p>

<pre><code>float deltaX = point0.getX() - point1.getX();
float deltaY = point0.getY() - point1.getY();
</code></pre>

<p>And every 0.01 seconds I refresh my objects position like this:</p>

<pre><code>object.setPosition(object.getX()-deltaX/100,object.getY()-deltaY/100);
</code></pre>

<p>So this moves my object from point0 to point1 in 1 second. What I need is having the 2 points, to be able to move the object from point0 ,facing(in the direction of) point1 with a constant speed. Thus, when I have a point closer to my initial point the object will move towards it with the same speed it does if I would have a farther point.
Any suggestions are appreciated. Thanks.</p>
","<p>I'll use some linear algebra structures since it's easier to describe the operations that way. In case you don't know how to implement these vector operations I'll give a quick explanation at the end.</p>

<p>So let's say you start with these values: <code>start</code>and <code>end</code> mark the end points of the movement, <code>speed</code> is how many pixels it should move by second, and <code>elapsed</code> is the rate at which you'll update your object's position (some engines already provide that value for you):</p>

<pre class=""lang-cs prettyprint-override""><code>Vector2 start = new Vector2(x1, y2);
Vector2 end = new Vector2(x2, y2);
float speed = 100;
float elapsed = 0.01f;
</code></pre>

<p>The first thing you'll want to calculate is the distance between both points, and a normalized vector containing the direction from start to end. Also, you should ""snap"" the object position to the <code>start</code> point. This step is done only once, at the beginning:</p>

<pre><code>float distance = Vector2.Distance(start, end);
Vector2 direction = Vector2.Normalize(end - start);
object.Position = start;
moving = true;
</code></pre>

<p>Then on your update method, you move the object by adding a multiplication of <code>direction</code>, <code>speed</code> and <code>elapsed</code> to its position. After that, to check if the movement is over, you see if the distance between the start point and the object's current position is <em>greater</em> than the initial distance you calculated. If that's true, we snap the object's position to the end point, and stop moving the object:</p>

<pre><code>if(moving == true)
{
    object.Position += direction * speed * elapsed;
    if(Vector2.Distance(start, object.Position) &gt;= distance)
    {
        object.Position = end;
        moving = false;
    }
}
</code></pre>

<hr>

<p><strong>Quick Vector Operations Reference</strong></p>

<p><em>Representation</em></p>

<pre><code>Vector2 A = float aX, aY;
</code></pre>

<p><em>Sum / Subtract</em></p>

<pre><code>A+B = a.x + b.x; a.y + b.y;
A-B = a.x - b.x; a.y - b.y;
</code></pre>

<p><em>Multiply by Scalar (float)</em></p>

<pre><code>A*float = a.x*float; a.y*float;
</code></pre>

<p><em>Length / Distance</em></p>

<pre><code>length(A) = sqrt(a.x*a.x + a.y*a.y)
distance(A,B) = length(B-A)
</code></pre>

<p><em>Normalize</em></p>

<pre><code>normalize(A) = a.X/length(A); a.Y/length(A);
</code></pre>

<p>That should be enough to convert the above code into regular operations if you don't have a <code>Vector</code> class available to you.</p>

<hr>

<p><strong>Example of Conversion</strong></p>

<pre><code>// Your Variables
float startX, startY, endX, endY;
float speed = 100;
float elapsed = 0.01f;

// On starting movement
float distance = Math.sqrt(Math.pow(endX-startX,2)+Math.pow(endY-startY,2));
float directionX = (endX-startX) / distance;
float directionY = (endY-startY) / distance;
object.X = startX;
object.Y = startY;
moving = true;

// On update
if(moving == true)
{
    object.X += directionX * speed * elapsed;
    object.Y += directionY * speed * elapsed;
    if(Math.sqrt(Math.pow(object.X-startX,2)+Math.pow(object.Y-startY,2)) &gt;= distance)
    {
        object.X = endX;
        object.Y = endY;
        moving = false;
    }
}
</code></pre>
","23450"
"How can determine the number of instances of an object in Game Maker?","24270","","<p>I am making a small puzzle based game.  I want the number of instances of an object to be equal to the ammo count plus 2.</p>

<p>Each time a new room is loaded, the main object's creation method with run this script:</p>

<pre><code>var ammo = instance_count(jellyfish)+2;
</code></pre>

<p>Then each time a bullet is fired, I subtract one. When there is no ammo left, the player goes to the 'failure' room.</p>

<p>However, I get the error: <code>Unknown function or script: instance_count</code>.</p>

<p>I have see this script on Google, but am not sure if it has deprecated or not. Is there a way I can do this? </p>
","<p>The function you want is <code>instance_number(obj)</code> (<a href=""http://docs.yoyogames.com/source/dadiospice/002_reference/objects%20and%20instances/instances/instance%20functions/instance_number.html"" rel=""nofollow"">documentation found here</a>). </p>

<blockquote>
  <p>This functions returns the number of instances of a object that exist
  in the current room.</p>
</blockquote>
","51546"
"Which game engine is ideal for a 3D RPG?","24189","","<p>I am thinking about making a small RPG. I know some basics of openGL, but I do not want create my own engine. </p>

<p>My criteria are:</p>

<ol>
<li>Ease of use</li>
<li>Can do rpg
game </li>
<li>3D</li>
</ol>

<p>Which game engine is ideal for a 3D RPG?</p>
","<p>it is absolutely Unity3D, and the basic version is for free.</p>

<p><a href=""http://unity3d.com/"" rel=""nofollow"">http://unity3d.com/</a></p>

<p>Good luck</p>
","8441"
"How long does it take to ceate a game?","24002","","<p>I know that this question depends really very much on plenty factors: 2D-Pong and a MMORPG are two totally different worlds; it also depends on creators' experience, on game quality, on the available technologies, on target platform and so on, but well, I guess we can categorize games and study the average (or maybe focus on real-world examples).</p>

<p>How long, in <strong>man-hour</strong>, does it take on average to create a:</p>

<ul>
<li><p>AAA MMORPG</p></li>
<li><p>AAA non-MMO game (like a RTS, an FPS etc, RPG)</p></li>
<li><p>Indie game</p></li>
<li><p>Game for mobiles</p></li>
<li><p>Amateur desktop game</p></li>
</ul>

<p>What phases can we split the game creation process in (story designing, writing the engine, creating art, testing ...) and how long would each of these take (for the above categories)?</p>

<p>Examples of real games would be apprecciated!</p>
","<p>You'll have to define AAA. For some people it's a budget scale definition, to others it's a team scale definition, to others it's a art-resources quality scale definition.
Anyway, your question is too broad.</p>

<p>Let's choose indie games. The variety of different games (that are often their own type) is bigger than in the industry  and it's a lot more than most people even can imagine. </p>

<p>How to answer your question knowing that?</p>

<p>Anyway what you're asking for is more related to the alchemy between those factors : </p>

<ul>
<li>Budget (to use to modify the other factors)</li>
<li>Target deadline </li>
<li>Team experience</li>
<li>Team size</li>
<li>Features count</li>
<li>Features complexity</li>
<li>Platform constraints</li>
</ul>

<p>For examples on time taken to make games (published or not) I recommend searching for Post-Mortem articles on <a href=""http://gamasutra.com"" rel=""noreferrer"">http://gamasutra.com</a> - lot of wisdom and feedback there.</p>
","5934"
"Why are gaming graphics not as beautiful as animated movies?","23961","","<p>I remember watching the Tomb Raider pre-rendered trailer, and wished those graphics could be in the game itself.</p>

<p>Why there is such a big difference between the trailer and the actual game? I understand the game is a completely different concept, it has different pipeline, it has to go through different kinds of player interactions etc. I want to know what it is about games that makes rendering them so difficult compared to animated films.</p>

<p>So far I know that making a game and an animated movie share some basic workload, e.g. making 3d models, rendering them (only in-game it happens live). Animated movies render for a long time and we only see pre-rendered scenes. That's all I know so I hope you'll answer from that perspective!</p>

<p>What about animated movies rendering for hours and hours makes them so beautiful while in-game live rendering is less beautiful (from a general point of view)? </p>
","<p>You already mentioned one of the central points: <em>Time</em>.</p>

<p>In the process behind rendering a high fidelity animation, multiple different approaches and algorithms are used (all usually combined under the term <a href=""http://en.wikipedia.org/wiki/Global_illumination"">""Global Illumination""</a>), with <a href=""http://en.wikipedia.org/wiki/Ray_tracing_%28graphics%29"">Ray-Tracing</a> being one of the most common ones (others include for example <a href=""http://en.wikipedia.org/wiki/Radiosity_%28computer_graphics%29"">Radiosity</a> and <a href=""http://en.wikipedia.org/wiki/Ambient_occlusion"">Ambient Occlusion</a>). </p>

<p>Ray-Tracing involves simulating a (usually high) number of light rays going through the scene and calculating their paths, their reflections and refractions when they hit objects with different materials. Different materials in return then have different physical properties that result in specific reactions for the rays (the amount of light that bounces from one objects for example is higher for a shiny objects compared to a glossy one).</p>

<p>Another point is <em>Physics</em>: Simulating thousands of hair strains in a physically correct way is time-consuming. This is why in older games, hairs are often approximated with a very rough mesh that is then textured to give the impression of hair, perhaps with some additional moving objects to make it look a bit more realistic.</p>

<p>Also to be considered: <em>Memory &amp; Bandwidth</em>. The higher the quality of a texture applied to an object in a scene should be, the more memory you need to load and use it in a game. But not only does the system need to have enough memory to hold the data, but this data also needs to be transferred around which uses up the available bandwidth. Since memory and bandwidth are limited, there is a maximum what can be achieved. </p>

<p>Games often cheat a bit by only using the high-resolution textures for near objects, and use lower resolution images for the far away objects (term: <a href=""http://en.wikipedia.org/wiki/Mipmap"">MipMapping</a>) thus reducing the needed bandwidth since less texels need to be fetched which in return increases the performance (see <a href=""https://developer.apple.com/library/prerelease/ios/documentation/3DDrawing/Conceptual/OpenGLES_ProgrammingGuide/TechniquesForWorkingWithTextureData/TechniquesForWorkingWithTextureData.html#//apple_ref/doc/uid/TP40008793-CH104-SW8"">section about MipMapping</a> in Apple's OpenGLES Programming Guide). </p>

<p>Similarly, games also often use different meshes for objects depending how far away they are with far away objects being less detailed (term: LoD = <a href=""http://en.wikipedia.org/wiki/Level_of_detail"">Level of Detail</a>).</p>

<p><em>Conclusion:</em> In real-time graphics (such as games and simulations), this detailed and complex rendering process will of course not work to produce fluid/smooth scenes. You need at least 20 rendered frames per second to achieve that fluid animation/movement effect for the human eye. On the other side, rendering a single frame (!) in an animation movie can easily take up anything from a few hours to multiple days depending on many factors such as the number of used rays in Ray-Tracing or the number of samples for Ambient Occlusion (see this <a href=""http://renderman.pixar.com/view/global-illumination-and-all-that"">Pixar page</a> for screenshot of 16 vs. 256 samples) as well as the desired movie resolution (more pixels = more information to be calculated). Also see <a href=""http://venturebeat.com/2013/04/24/the-making-of-pixars-latest-technological-marvel-monsters-university/"">this article</a> about the process behind Pixar's <em>Monsters University</em> animation movie, giving some interesting insights and also mentioning 29 hours render time per frame.</p>

<p>In general: The higher the fidelity / realism that is to be achieved, the more iterations / bounces / samples are usually needed which in return then requires more resources (both time and/or computation power / memory). To visualize the difference see the resulting render based on the number of bounces for the refraction calculation in this example: <a href=""https://www.keyshot.com/keyshot3/manual/realtime_settings/ray_bounces.html"">Diamond Bounces from Keyshot</a></p>

<p>But of course, the quality in real-time applications increases all the time for two reasons:</p>

<ol>
<li>Stronger hardware: As the (gaming) computers get better (= more [parallel] computing power, higher data transmission between computer components, more and faster memory, etc.), the visual fidelity increases as well, because more time-consuming computations actually become feasible in a real-time system.</li>
<li><p>More clever methods/formulas are developed and implemented that are able to create rather photo-realistic effects without needing raytracing. This often involves approximations and sometimes pre-calculated data. Some examples:</p>

<ul>
<li><a href=""http://blog.codinghorror.com/fast-approximate-anti-aliasing-fxaa/"">Different types of anti-aliasing such as FXAA</a></li>
<li><a href=""http://http.developer.nvidia.com/GPUGems/gpugems_ch16.html"">Approximation to sub-surface scattering</a></li>
<li><a href=""http://www.marmoset.co/toolbag/learn/pbr-theory"">Physically Based Shading</a> (PBS) / Physically Based Rendering (PBR), <a href=""https://www.unrealengine.com/blog/physically-based-shading-in-ue4"">e. g. in Unreal Engine 4</a>.</li>
</ul></li>
</ol>
","82818"
"How to ignore collision between two objects","23832","","<p>I have a player that shoots in the direction that it is facing. However, the shot that is created when I click, also destroys the player (<a href=""http://gfycat.com/TediousAridFeline"" rel=""nofollow"">example</a>). How would I make the shot ignore collision with the player? Or better yet, how to make a shot destroy anything it touches and destroy itself without affecting the player?</p>

<p>This is the code that controls collisions:</p>

<pre><code>function OnTriggerEnter (col : Collider) {
    Destroy(col.gameObject);
}
</code></pre>

<p>The shot is a trigger, but the player isn't. Not sure if this changes anything in this case.</p>
","<p>There are a lot of ways to ensure that.</p>

<p>The best approach is to use the ""Layer Collision Matrix"". To keep things organized, you could create a <code>Bullets</code>, <code>Enemies</code> and a <code>Player</code> Layer. Then go to <em>Edit</em> > <em>Project Settings</em> > <em>Physics</em> and you'll see the collision matrix.</p>

<p><img src=""https://i.stack.imgur.com/lmeFS.png"" alt=""Unity Layer Collision Matrix""></p>

<p>You can check all the layer-pairs that should report collisions there. In the screenshot you can see that Bullets will only collide with Enemies and Enemies also collide with the Player. Then all that's left to do is assign the matching layers to your GameObjects or Prefabs.</p>

<p>Using the collision matrix is the best approach, because it directly affects the physics simulation (non-colliding layers don't have to be checked for collisions at all) which is the most performant solution to your problem.</p>

<p>Another approach (or you could also combine the two) is to implement <code>OnCollisionEnter</code> or <code>OnTriggerEnter</code> on the Enemies and Players, and not the Bullet. Then you're free to implement different behavior for each entity and also report scores or perform other tasks.</p>

<p>Bullets could also use</p>

<pre><code>col.gameObject.SendMessage(""HitByBullet"", null,
    SendMessageOptions.DontRequireReceiver);
</code></pre>

<p>instead of your current <code>Destroy(col.gameObject)</code>. Then you can implement a <code>HitByBullet</code> method in your Enemy Script and destroy the object there, play a sound effect etc.</p>
","75784"
"How to extract euler angles from transformation matrix?","23810","","<p>I have a simple realisation of entity/component game engine.<br>
Transform component have methods to set local position, local rotation, global position and global rotation.<br></p>

<p>If transform is being set new global position, then local position also changes, to update local position in such case I'm just applying current transform local matrix to parent's transform world matrix.<br></p>

<p>Until then I have no problems, I can get updated local transform matrix.<br>
But I'm struggling on how to update local position and rotation value in transform.
Only solution I have in mind is to extract translation &amp; rotation values from localMatrix of transform.<br></p>

<p>For translation it's quite easy - I just take 4th column values.
but what's about rotation?<br>
How to extract euler angles from transformation matrix?</p>

<p>Is such solution right?:<br>
To find rotation around Z axis, we can find difference between X axis vector of localTransform and X axis vector of parent.localTransform and store result in Delta, then:
localRotation.z = atan2(Delta.y, Delta.x);</p>

<p>Same for rotation around X &amp; Y, just need to swap axis.</p>
","<p>Normally I store all objects as 4x4 Matrices (you could do 3x3 but easier for me just to have 1 class) instead of translating back and forth between a 4x4 and 3 sets of vector3s (Translation, Rotation, Scale). Euler angles are notoriously difficult to deal with in certain scenarios so I would recommend using Quaternions if you really want to store the components instead of a matrix.</p>

<p>But here is some code I found a while back that works. I hope this helps, unfortunately I do not have the original source for where I found this. I have no idea what odd scenarios it may not work in. I am currently using this to get the rotation of YawPitchRoll rotated, left handed 4x4 matrices.</p>

<pre><code>   union {
        struct 
        {
            float        _11, _12, _13, _14;
            float        _21, _22, _23, _24;
            float        _31, _32, _33, _34;
            float        _41, _42, _43, _44;
        };
        float m[4][4];
        float m2[16];
    };

    inline void GetRotation(float&amp; Yaw, float&amp; Pitch, float&amp; Roll) const
    {
        if (_11 == 1.0f)
        {
            Yaw = atan2f(_13, _34);
            Pitch = 0;
            Roll = 0;

        }else if (_11 == -1.0f)
        {
            Yaw = atan2f(_13, _34);
            Pitch = 0;
            Roll = 0;
        }else 
        {

            Yaw = atan2(-_31,_11);
            Pitch = asin(_21);
            Roll = atan2(-_23,_22);
        }
    }
</code></pre>

<p>Here is another thread I found while trying to answer your question that looked like a similar result to mine.</p>

<p><a href=""https://stackoverflow.com/questions/1996957/conversion-euler-to-matrix-and-matrix-to-euler"">https://stackoverflow.com/questions/1996957/conversion-euler-to-matrix-and-matrix-to-euler</a></p>
","50968"
"Why do game engines convert models to triangles instead of using quads?","23733","","<p>I've worked using Maya for animation and more film orientated projects however I am also focusing on my studies on video game development. Anyways, I was talking with one of my professor and we couldn't figure out why all game engines (that I know of) convert to triangles.</p>

<p>Anyone happen to know why game engines convert to triangles compared to leaving the models as four sided polygons? Also what are the pros and cons (if any) of doing this?</p>
","<p>The bottom line is Triangle Rasterization, which is how computers render objects to the screen. Though others say it more elquently than I:</p>

<blockquote>
  <p>All 3D objects that we see on the computer screen are actually made of tiny little geometrical objects often called primitives. Quadrilaterals, triangles, n-gons etc. are example of primitives. We will concentrate on triangles mostly because of one main reason: <strong>every object can be split into triangles but a triangle cannot be split into anything else than triangles.</strong> Because of this, drawing triangles is a lot simpler than drawing polygons of higher order; less things to deal with. This is why those triangles are so commonly used in computer graphics.</p>
</blockquote>

<p>Emphasis mine. Source: <a href=""http://www.devmaster.net/articles/software-rendering/part3.php"">http://www.devmaster.net/articles/software-rendering/part3.php</a></p>
","9512"
"How to draw 2D images using OpenGL, in SDL?","23568","","<p>After everything, I managed to find a simple piece of code that shows how to draw a 2D image with openGL:</p>

<pre><code>    #include ""SDL/SDL.h""
    #include ""SDL/SDL_opengl.h""
    #include ""SDL/SDL_image.h""

    const int SCREEN_WIDTH = 640;
    const int SCREEN_HEIGHT = 480;
    const int SCREEN_BPP = 32;

    int tex;

    int loadTexture(char* fileName){
        SDL_Surface *image=IMG_Load(fileName);
        SDL_DisplayFormatAlpha(image);
        GLuint object;
        glGenTextures(1,&amp;object);
        glBindTexture(GL_TEXTURE_2D,object);
        glTexParameterf(GL_TEXTURE_2D,GL_TEXTURE_MIN_FILTER,GL_NEAREST);
        glTexParameterf(GL_TEXTURE_2D,GL_TEXTURE_MAG_FILTER,GL_NEAREST);
        glTexParameterf(GL_TEXTURE_2D,GL_TEXTURE_WRAP_S,GL_CLAMP_TO_EDGE);
        glTexParameterf(GL_TEXTURE_2D,GL_TEXTURE_WRAP_T,GL_CLAMP_TO_EDGE);
        glTexImage2D(GL_TEXTURE_2D,0,GL_RGBA,image-&gt;w,image -&gt;h,0,GL_RGBA,GL_UNSIGNED_BYTE,image-&gt;pixels);
        SDL_FreeSurface(image);
        return object;
    }
    void init(){
        glClearColor(0.0,0.0,0.0,0.0);
        glMatrixMode(GL_PROJECTION);
        glLoadIdentity();
        glOrtho(0.0,800,600,1.0,-1.0,1.0);
        glEnable(GL_BLEND);
        glEnable(GL_TEXTURE_2D);
        glBlendFunc(GL_SRC_ALPHA,GL_ONE_MINUS_SRC_ALPHA);
        tex = loadTexture(""hi.png"");
    }
    void draw(){
        glClear(GL_COLOR_BUFFER_BIT);
        glBindTexture(GL_TEXTURE_2D,tex);
        glBegin(GL_QUADS);
            glTexCoord2f(0,0);
            glVertex2f(0,0);
            glTexCoord2f(1,0);
            glVertex2f(500,0);
            glTexCoord2f(1,1);
            glVertex2f(500,500);
            glTexCoord2f(0,1);
            glVertex2f(0,500);
        glEnd();
        glFlush();
    }
    int main(int argc,char** argv){
        SDL_Init(SDL_INIT_EVERYTHING);
        SDL_Surface* screen=SDL_SetVideoMode(800,600,32,SDL_SWSURFACE|SDL_OPENGL);
        bool running=true;
        Uint32 start;
        SDL_Event event;
        init();
        while(running){
            start=SDL_GetTicks();
            draw();
            while(SDL_PollEvent(&amp;event)){
                switch(event.type){
                    case SDL_QUIT:
                        running=false;
                        break;
                }
            }
            SDL_GL_SwapBuffers();
            if(1000/60&gt;(SDL_GetTicks()-start))
                SDL_Delay(1000/60-(SDL_GetTicks()-start));
        }
        SDL_Quit();
        return 0;
    }
</code></pre>

<p>I'm inexperienced in 2D, and about a week ago started messing with SDL. Built some simple structures to have images, which would be on layers, so I could have my own drawing order, so sprites would be drawn after background, etc, and then did a little ""sprite engine"".
I got a Megaman sprite walking left and right just like I wanted it, above a simple 900x900ish background image.</p>

<p>Thing is, CPU almost reached 20% on my i5... so I thought of using the graphic card to do the drawing! Delved abit into OpenGL and today, finally managed to get gl3w working!</p>

<p>So now I'm looking for a simple way to display my sprites/images, on the window, through use of OpenGL. I've tried all sorts of code I ran across, but I can't get anything displaying, despite that I've done error checks basically everywhere, and everything seems to check out to be right!</p>

<p><strong>TL:DR; I was looking for some simple working code, using SDL, on how to draw 2D images (which, if it doesn't work, for sure I've got something wrong).</strong></p>

<p>Thanks!</p>
","<p>I recommend loading your sprites using <a href=""http://www.lonesock.net/soil.html"">SOIL</a>, and then rendering them by just drawing textured quads. If you do it without any deprecated functionality (use shaders) you will find it's very fast.</p>
","46644"
"Camera rotation - First Person Camera using GLM","23491","","<p>I've just switched from deprecated opengl functions to using shaders and GLM math library and i'm having a few problems setting up my camera rotations (first person camera). I'll show what i've got setup so far.</p>

<p>I'm setting up my ViewMatrix using the glm::lookAt function which takes an eye position, target and up vector</p>

<pre><code>// arbitrary pos and target values
pos = glm::vec3(0.0f, 0.0f, 10.0f);
target = glm::vec3(0.0f, 0.0f, 0.0f);
up = glm::vec3(0.0f, 1.0f, 0.0f);

m_view = glm::lookAt(pos, target, up);
</code></pre>

<p>i'm using glm::perspective for my projection and the model matrix is just identity</p>

<pre><code>m_projection = glm::perspective(m_fov, m_aspectRatio, m_near, m_far);

model = glm::mat4(1.0);
</code></pre>

<p>I send the MVP matrix to my shader to multiply the vertex position</p>

<pre><code>glm::mat4 MVP = camera-&gt;getProjection() * camera-&gt;getView() * model;
// in shader
gl_Position = MVP * vec4(vertexPos, 1.0);
</code></pre>

<p>My camera class has standard rotate and translate functions which call glm::rotate and glm::translate respectively</p>

<pre><code>void camera::rotate(float amount, glm::vec3 axis)
{
    m_view = glm::rotate(m_view, amount, axis);
}
void camera::translate(glm::vec3 dir)
{
    m_view = glm::translate(m_view, dir);
}
</code></pre>

<p>and i usually just use the mouse delta position as the amount for rotation</p>

<p>Now normally in my previous opengl applications i'd just setup the yaw and pitch angles and have a sin and cos to change the direction vector using (gluLookAt) but i'd like to be able to do this using GLM and matrices. </p>

<p>So at the moment i have my camera set 10 units away from the origin facing that direction. I can see my geometry fine, it renders perfectly. When i use my rotation function...</p>

<pre><code>camera-&gt;rotate(mouseDeltaX, glm::vec3(0, 1, 0));
</code></pre>

<p>What i want is for me to look to the right and left (like i would with manipulating the lookAt vector with gluLookAt) but what's happening is 
It just rotates the model i'm looking at around the origin, like im just doing a full circle around it. Because i've translated my view matrix, shouldn't i need to translate it to the centre, do the rotation then translate back away for it to be rotating around the origin? Also, i've tried using the rotate function around the x axis to get pitch working, but as soon as i rotate the model about 90 degrees, it starts to roll instead of pitch (gimbal lock?).</p>

<p>Thanks for your help guys,</p>

<p>and if i've not explained it well, basically i'm trying to get a first person camera working with matrix multiplication and rotating my view matrix is just rotating the model around the origin. </p>
","<p>Answer:</p>

<p>Thanks for your help guys.</p>

<p>I just kept track and updated the position and heading variable separately from the view matrix. </p>

<pre><code>glm::vec3 m_position;
glm::vec3 m_direction;

...

// speed is usually 0.1f or something small like that
void camera::rotate(float amount, glm::vec3&amp; axis)
{
    m_direction = glm::rotate(m_direction, amount * m_speed, axis);
}

void camera::translate(glm::vec3&amp; direction)
{
    m_position += direction;
}

// call this once per loop
// m_up is glm::vec3(0, 1, 0) for a first person camera
void camera::update()
{
    m_view = glm::lookAt(m_position, m_position + m_direction, m_up);
}
</code></pre>

<p>and just if anyone is curious about strafing of the camera i'll add that code in </p>

<pre><code>enum MovementType {FORWARD, BACKWARD, STRAFE_L, STRAFE_R};

void camera::applyMovement(MovementType movement)
{
    switch (movement)
    {
        case FORWARD:
            m_position += m_direction;
        break;
        case BACKWARD:
            m_position -= m_direction;
        break;
        case STRAFE_LEFT:
            m_position += glm::cross(m_direction, m_up);
        break;
        case STRAFE_RIGHT:
            m_position -= glm::cross(m_direction, m_up);
        break;
    }
}
</code></pre>
","31042"
"Understanding Perlin Noise","23476","","<p>I'm toying with Perlin Noise after some work with Diamond Square. I followed the <a href=""http://freespace.virgin.net/hugo.elias/models/m_perlin.htm"" rel=""noreferrer"">implementation by Hugo Elias</a> that basically, makes a series of functions with x,y as input to throw each coordinate value.</p>

<p>My PHP code is <a href=""http://pastebin.com/6j6vQYTt"" rel=""noreferrer"">here</a>:</p>

<p>I have two questions:</p>

<p>How do I use the algorithm to generate a height map in an array? I did not fully understand it and just ported to PHP the pseudocode, but doing the last function (map_perlined) after reading somewhere that the algorithm ""magically"" gives you transitioned values for each x,y point given (apparently, without having to read its adjacent values), I just get this when using as random function <code>mt_rand(-100,100)/100;</code></p>

<p><img src=""https://i.stack.imgur.com/u85xq.png"" alt=""enter image description here""></p>

<p>And this when using the cryptographic: <code>1.0-(($n*($n*$n*15731+789221)+1376312589)&amp;0x7fffffff)/1073741824.0;</code> (which, BTW, can be implemented ""as-is"" in PHP?):</p>

<p><img src=""https://i.stack.imgur.com/InaIF.png"" alt=""enter image description here""></p>

<p>So, summing up, three questions:</p>

<ol>
<li>Is my code correct?</li>
<li>The random function can be ported to PHP as described in the code? It throws no errors, but the results are not there.</li>
<li>How do I actually use the algorithm?</li>
</ol>

<p><strong>UPDATE</strong></p>

<p>Ok, made a PHP port of the code shown in Gustavson paper, and as other coder said, it just generate one octave. Have any other useful site/paper/guide about how to use this with the concepts of multiple octaves, amplitude, frequency, etc. to control the noise function? On Gustavson's paper just shows the results, not the actual implementation of the algorithm, perhaps i'm missing something?</p>

<p><strong>UPDATE 2</strong><br>
@NATHAN</p>

<p>I made something like:</p>

<pre><code>$persistence = 0.5;

for ($j = 0; $j &lt; $size; $j++) {
    for ($i = 0; $i &lt; $size; $i++) {

        for ($o = 0; $o &lt; 8; $o++) {
            $frequency = pow(2,$o);
            $amplitude = pow($persistence, $o);
            $value += SimplexNoise($i*$frequency, $j * $frequency) * $amplitude;
            }

            //$value = SimplexNoise($i, $j) + 0.5 * SimplexNoise($i, $j) + 0.25 * SimplexNoise($i, $j);
            $this-&gt;mapArray[$i][$j] = new Cell($value);
</code></pre>

<p>And after normalizing the values to 0..1, I get a rather dull height map such as:</p>

<p><img src=""https://i.stack.imgur.com/ZcuKb.png"" alt=""enter image description here""></p>

<p>How do I seed the map?
Perhaps what I need to implement is the 3d version with the third value a random height? But if so, I'd have to find out to take in consideration neighbour values, which I'd be ending with something like a diamond square algorithm, exactly what I do not want to do.</p>

<p><strong>UPDATE 3</strong></p>

<p>More Perlin work. I have yet to find a way to guide the noise to my results. Check these octaves and the final result:</p>

<p>Octave I to IV</p>

<p><img src=""https://i.stack.imgur.com/m7JG6.png"" alt=""Octave1""><img src=""https://i.stack.imgur.com/tLfWN.png"" alt=""Octave2""><img src=""https://i.stack.imgur.com/UTqDS.png"" alt=""Octave3""><img src=""https://i.stack.imgur.com/DSg7V.png"" alt=""Octave4""></p>

<p>Summed up</p>

<p><img src=""https://i.stack.imgur.com/8fVEb.png"" alt=""Octaves 1-4 summed""></p>

<p>Each octave is pretty much the same. Check the code:</p>

<pre><code>$persistence = 0.5;

    for ($j = 0; $j &lt; $size; $j++) {
      for ($i = 0; $i &lt; $size; $i++) {
        $value = 0;

        for ($o = 0; $o &lt; 4; $o++) {
          $frequency = pow(2,$o);
          $amplitude = pow($persistence, $o);
          $value += improved_noise($i*$frequency, $j*$frequency, 0.5)*$amplitude;

        }
        $this-&gt;map[$i][$j] = new Cell($value);
</code></pre>

<p>The results are normalized. What would you use have a strong influence in the development of the noise? I see examples where changing the amplitude gives soft or rough surfaces, but even if I give a huge amplitude, I see little difference.</p>
","<p>What you implemented isn't Perlin noise.  I'm not sure why Hugo Elias says it is, but he's confused.  <a href=""http://cs.nyu.edu/~perlin/noise/"">Here</a> is Ken Perlin's reference implementation.  It doesn't actually call any external random number generator, but uses a built-in hash function to produce the pseudorandom gradient vectors.</p>

<p>Note also that Perlin noise consists of just one octave.  Summing up multiple octaves (scaled instances of the noise function), as Hugo Elias suggests, is a useful technique, but not part of Perlin noise.  What you get by doing that is called fractal noise, sometimes ""fractal Brownian noise"" (because of the supposed similiarity to Brownian motion).</p>

<p>If you want to understand geometrically what the algorithm is doing, try <a href=""http://www.itn.liu.se/~stegu/simplexnoise/simplexnoise.pdf"">this paper</a>.  It's about a different kind of noise called ""simplex noise"", but also includes an explanation of classic Perlin noise.  Incidentally, simplex noise was also invented by Perlin and is supposed to be an improvement over his classic noise, so you might try implementing it too if you're interested in playing with noise functions.</p>
","18331"
"How to calculate corner positions/marks of a rotated/tilted rectangle?","23297","","<p>I've got two elements, a 2D point and a rectangular area. The point represents the middle of that area. I also know the width and height of that area. And the area is tilted by 40° relative to the grid.</p>

<p>Now I'd like to calculate the absolute positions of each corner mark of that tilted area only using this data. Is that possible?</p>
","<pre><code>X = x*cos(θ) - y*sin(θ)
Y = x*sin(θ) + y*cos(θ)
</code></pre>

<p>This will give you the location of a point rotated θ degrees around the origin.  Since the corners of the square are rotated around the center of the square and not the origin, a couple of steps need to be added to be able to use this formula.  First you need to set the point relative to the origin. Then you can use the rotation formula. After the rotation you need to move it back relative to the center of the square.</p>

<pre><code>// cx, cy - center of square coordinates
// x, y - coordinates of a corner point of the square
// theta is the angle of rotation

// translate point to origin
float tempX = x - cx;
float tempY = y - cy;

// now apply rotation
float rotatedX = tempX*cos(theta) - tempY*sin(theta);
float rotatedY = tempX*sin(theta) + tempY*cos(theta);

// translate back
x = rotatedX + cx;
y = rotatedY + cy;
</code></pre>

<p>Apply this to all 4 corners and you are done!</p>
","86784"
"Should I use textures not sized to a power of 2?","23275","","<p>In the early days of OpenGL and DirectX, texture sizes were required to be powers of two.  This meant interpolation of float values could be done very quickly, using shifting and such.</p>

<p>Since OpenGL 2.0 (and preceding that, via an extension) non-power-of-two texture dimensions have been supported.</p>

<p>Do power-of-two textures have performance advantages on modern integrated and discrete GPUs? What advantages do non-power-of-two textures have?</p>

<p>Does a significant desktop population have cards supporting non-power-of-two textures?</p>
","<p><strong>Are there performance advantages to sticking to power-of-two textures on modern integrated and discrete GPUs?</strong></p>

<p>Most of modern GPUs support non-power of two (NPOT) textures and handle them well. Performance drop is quite little. But there are few problems to consider:</p>

<ul>
<li><p>When using NPOT texture it takes more space in RAM, just like next-sized POT texture. Technically you just waste the space that could be used to put something in there;</p></li>
<li><p>NPOT textures may be handled noticeably slower (in OpenGL 2.1 I had up to 30% performance drop) compared to POT of next size;</p></li>
<li><p>Older GPUs and on-board/on-chip GPUs are not so advanced, they often support NPOT textures, but support is quite slow and clumsy;</p></li>
<li><p>Even older GPUs may refuse to accept/display NPOT textures at all;</p></li>
<li><p>There could be edging artifacts caused by mip-map interpolation, your 25x25 texture might have a black fringe where pixels were added to stuff it to 32x32 size.</p></li>
</ul>

<p>P.S. I don't know for sure about mobile devices, there might be even more restrictions regarding POT textures.</p>

<p><strong>What advantages do non-power-of-two textures have, if any?</strong></p>

<p>As far as I know there are only 2 advantages:</p>

<ul>
<li>They take less space on HDD if they are not packed (when packed empty areas give very little add)</li>
<li>You can save time on writing NPOT -> POT converter. You will need one for release version, but using NPOT textures for designing and prototyping interface / models is just fine</li>
</ul>

<p><strong>Are there large populations of desktop users who don't have cards that support non-power-of-two textures?</strong></p>

<p>As far as I know and tested on PC - Yes. That includes major percentage of speed-drop / minor bugs GPUs and minor percentage of cards that won't handle NPOT at all.</p>
","7949"
"Is there a good way to get pixel-perfect collision detection in XNA?","23264","","<p>Is there a well-known way (or perhaps reusable bit of code) for pixel-perfect collision detection in XNA?</p>

<p>I assume this would also use polygons (boxes/triangles/circles) for a first-pass, quick-test for collisions, and if that test indicated a collision, it would then search for a per-pixel collision.</p>

<p>This can be complicated, because we have to account for scale, rotation, and transparency.</p>

<p><strong>WARNING:</strong> If you're using the sample code from the link from the answer below, be aware that <strong>the scaling of the matrix is commented out for good reason.</strong> You don't need to uncomment it out to get scaling to work.</p>
","<p>I see that you tagged the question as 2d, so I'll go ahead and dump my code:</p>



<pre class=""c# prettyprint-override""><code>class Sprite {

    [...]

    public bool CollidesWith(Sprite other)
    {
        // Default behavior uses per-pixel collision detection
        return CollidesWith(other, true);
    }

    public bool CollidesWith(Sprite other, bool calcPerPixel)
    {
        // Get dimensions of texture
        int widthOther = other.Texture.Width;
        int heightOther = other.Texture.Height;
        int widthMe = Texture.Width;
        int heightMe = Texture.Height;

        if ( calcPerPixel &amp;&amp;                                // if we need per pixel
            (( Math.Min(widthOther, heightOther) &gt; 100) ||  // at least avoid doing it
            ( Math.Min(widthMe, heightMe) &gt; 100)))          // for small sizes (nobody will notice :P)
        {
            return Bounds.Intersects(other.Bounds) // If simple intersection fails, don't even bother with per-pixel
                &amp;&amp; PerPixelCollision(this, other);
        }

        return Bounds.Intersects(other.Bounds);
    }

    static bool PerPixelCollision(Sprite a, Sprite b)
    {
        // Get Color data of each Texture
        Color[] bitsA = new Color[a.Texture.Width * a.Texture.Height];
        a.Texture.GetData(bitsA);
        Color[] bitsB = new Color[b.Texture.Width * b.Texture.Height];
        b.Texture.GetData(bitsB);

        // Calculate the intersecting rectangle
        int x1 = Math.Max(a.Bounds.X, b.Bounds.X);
        int x2 = Math.Min(a.Bounds.X + a.Bounds.Width, b.Bounds.X + b.Bounds.Width);

        int y1 = Math.Max(a.Bounds.Y, b.Bounds.Y);
        int y2 = Math.Min(a.Bounds.Y + a.Bounds.Height, b.Bounds.Y + b.Bounds.Height);

         // For each single pixel in the intersecting rectangle
         for (int y = y1; y &lt; y2; ++y)
         {
             for (int x = x1; x &lt; x2; ++x)
             {
                 // Get the color from each texture
                 Color a = bitsA[(x - a.Bounds.X) + (y - a.Bounds.Y)*a.Texture.Width];
                 Color b = bitsB[(x - b.Bounds.X) + (y - b.Bounds.Y)*b.Texture.Width];

                 if (a.A != 0 &amp;&amp; b.A != 0) // If both colors are not transparent (the alpha channel is not 0), then there is a collision
                 {
                     return true;
                 }
             }
         }
        // If no collision occurred by now, we're clear.
        return false;
    }

    private Rectangle bounds = Rectangle.Empty;
    public virtual Rectangle Bounds
    {
        get
        {
            return new Rectangle(
                (int)Position.X - Texture.Width,
                (int)Position.Y - Texture.Height,
                Texture.Width,
                Texture.Height);
        }

    }
</code></pre>

<p><strong>Edit</strong>: While this code is almost self explanatory, I did feel bad for not having comments, so I added some ;) I also got rid of the bitwise operations since it was doing basically what the Color.A property does in a more complicated way ;)</p>
","15201"
"Java - Best Implementation KeyListener For Games","23263","","<p>I am working on a game using only the swing and awt packages. Note I can only use the default Java libs. Meaning I have to use KeyListener. I have imported KeyListener properly, however, it is still relatively buggy. Here is a snippet of my code. </p>

<p>p is for Player class, I am going to set x and y to private, however, this is for simplicity </p>

<pre><code>public void keyPressed(KeyEvent e) {
    keys[e.getKeyCode()] = true;

    if(keys[KeyEvent.VK_W] || keys[KeyEvent.VK_UP]){
        p.y += 5;
    }

    if(keys[KeyEvent.VK_S] || keys[KeyEvent.VK_DOWN]){
        p.y -= 5;
    }

    if(keys[KeyEvent.VK_A] || keys[KeyEvent.VK_LEFT]){
        p.x += 5;
    }

    if(keys[KeyEvent.VK_D] || keys[KeyEvent.VK_RIGHT]){
        p.x -= 5;
    }
}

public void keyReleased(KeyEvent e) {
    keys[e.getKeyCode()] = false;
}

public void keyTyped(KeyEvent e) {
}
</code></pre>

<p>Sadly this code has a lag to it. Of a second... Also, the motion is not a fluid... However, I don't want you to fix my code. Rather, what other methods are more clean? As well, I have worked with engines, they all seem to have an: isDown, PressedOnce, Released(However, I know how to implement this), ect.</p>
","<p><strong>Possible cause :</strong>
From your code, no visible sources of lag are present. The lag may come from the way they are accessed from the game loop thread. Dont forget, the variables have to be synchronized, or you have to use locks for your app to be thread safe.</p>

<p>The lag you experienced may be from the fact that you increment the <em>x</em> and <em>y</em> by 5 each. I am guessing that this makes them move by 5 pixels. Maybe if you change it to something like 2, you will see smoother graphics.</p>

<p><strong>Suggested format:</strong>
I suggest you try to implement something like the following for maximum efficiency and thread safety.</p>

<p><img src=""https://i.stack.imgur.com/yhtZ9.png"" alt=""Suggested structure""></p>

<p><strong>Explanation :</strong></p>

<pre><code>1. The InputManager class detects the input and stores them in local variables inside
the InputManager class itself.

2. At some point in the game loop, a method (Maybe getProcessedData()) is called that
is inside the InputManager class that processes the data stored in it and returns.

3. The recieved information is used by the game loop.

4. Don't directly modify the original flags(The ones in the game loop) as is may lead
to unstability.
</code></pre>

<p><strong>Additional :</strong> 
Another possible source of lag may be that you are processing heavily in the game loop. Try moving heavier processes to new threads.</p>

<p><strong>Experience :</strong> Designing a multi-threaded platformer using swing. Pretty similar to yours.</p>
","56019"
"Immediate GUI - yae or nay?","23237","","<p>I've been working on application development with a lot of ""retained"" GUI systems (below more about what I mean by that) like MFC, QT, Forms, SWING and several web-GUI frameworks some years ago. I always found the concepts of most GUI systems overly complicated and clumsy. The amount of callback events, listeners, data copies, something to string to something - conversions (and so on) were always a source of mistakes and headaches compared to other parts in the application. (Even with ""proper"" use of Data Bindings/Models).</p>

<p>Now I am writing computer games :). I worked with one GUI so far: Miyagi (not well-known, but basically the same Idea as all the other systems.)</p>

<p>It was horrible.</p>

<p>For real-time rendering environments like Games, I get the feeling that ""retained"" GUI systems are even more obsolete. User interfaces usually don't need to be auto-layouted or have resizable windows on-the-fly. Instead, they need to interact very efficiently with always-changing data (like 3d-positions of models in the world)</p>

<p>A couple of years ago, I stumbled upon ""IMGUI"" which is basically like an Immediate Graphics mode, but for user interfaces. I didn't give too much attention, since I was still in application development and the IMGUI scene itself seemed to be not really broad nor successfull. Still the approach they take seem to be so utterly sexy and elegant, that it made me want to write <em>something</em> for the next project using this way of UI (I failed to convince anyone at work :(...)</p>

<p>let me summarize what I mean by ""retained"" and ""immediate"":</p>

<p>Retained GUI:
In a separate initialization phase, you create ""GUI controls"" like Labels, Buttons, TextBoxes etc. and use some descriptive (or programmatical) way of placing them on screen - all before anything is rendered. Controls hold most of their own state in memory like X,Y location, size, borders, child controls, label text, images and so on. You can add callbacks and listeners to get informed of events and to update data in the GUI control.</p>

<p>Immediate GUI:
The GUI library consists of one-shot ""RenderButton"", ""RenderLabel"", ""RenderTextBox""... functions (edit: don't get confused by the <em>Render</em> prefix. These functions also do the logic behind the controls like polling user input, inserting characters, handle character-repeat-speed when user holds down a key and so on...) that you can call to ""immediately"" render a control (doesn't have to be immediately written to the GPU. Usually its remembered for the current frame and sorted into appropiate batches later). The library does not hold any ""state"" for these. If you want to hide a button... just don't call the RenderButton function. All RenderXXX functions that have user interaction like a buttons or checkbox have return values that indicate whether e.g. the user clicked into the button. So your ""RenderGUI"" function looks like a big if/else function where you call or not call your RenderXXX functions depending on your game state and all the data update logic (when a button is pressed) is intermangled into the flow. All data storage is ""outside"" the gui and passed on-demand to the Render functions. (Of course, you would split up the big functions into several ones or use some class abstractions for grouping parts of the gui. We don't write code like in 1980 anymore, do we? ;))</p>

<p>Now I found that Unity3D actually uses the very same basic approach to their built-in GUI systems. There are probably a couple of GUI's with this approach out there as well?</p>

<p>Still.. when looking around, there seem to be a strong bias towards retained GUI systems? At least I haven't found this approach except in Unity3D and the original IMGUI community seems to be rather .... ..  quiet.</p>

<p>So anyone worked with both ideas and have some strong opinion?</p>

<p>Edit: I am most interested in opinions that stem from real-world experience. I think there is a lot of heated discussions in the IMGUI-forum about any ""theoretical weakness"" of the immediate GUI approach, but I always find it more enlightening to know about <em>real-world</em> weaknesses.</p>
","<p>Nay. I've done paid gamedev work on an awful 'retained mode' GUI and on an awful 'immediate mode' GUI and although both made me want to tear my eyes out, the retained mode approach is still clearly the better one.</p>

<p>The downsides of immediate mode are many:</p>

<ul>
<li>they don't make it easy for artists and designers to configure the layout;</li>
<li>they make you mix logic with presentation;</li>
<li>they make it harder to have a single consistent input model;</li>
<li>they discourage complex controls of dynamic data (eg. list views);</li>
<li>layering becomes very awkward (eg. if I call RenderComboBox, the drop-down box can't possibly render yet because it needs to go above the rest of the window - same for tool-tips)l</li>
<li>configuring rendering style ends up being done with globals (ick) or extra function arguments (ick);</li>
<li>performance can be poor because calling all these functions to query values that may or may not have changed tends to create many small objects, stressing the memory manager;</li>
<li>...and I can't even imagine how painful it would be to allow someone to drag bits the GUI around and re-order them. You'd have to maintain a data structure telling you where to render everything - which is much like rewriting a retained mode system yourself.</li>
</ul>

<p>Immediate mode GUIs are tempting for lone programmers who want a quick HUD system, and for that purpose they are great. For anything else... just say no.</p>
","24148"
"Logic behind a bejeweled-like game","23174","","<p>In a prototype I am doing, there is a minigame similar to bejeweled. Using a grid that is a 2d array (<code>int[,]</code>) how can I go about know when the user formed a match? I only care about horizontally and vertically. </p>

<p>Off the top of my head I was thinking I would just look each direction. Something like:</p>

<pre><code>int item = grid[x,y];
if(grid[x-1,y]==item)
{
    int step=x;
    int matches =2;
    while(grid[step-1,y]==item)
    {
        step++;
        matches++
    }
    if(matches&gt;2)
        //remove all matching items
}
else if(grid[x+1,y]==item
    //....
else if(grid[x,y-1==item)
    //...
else if(grid[x,y+1]==item)
    //...
</code></pre>

<p>It seems like there should be a better way. Is there?</p>
","<p>Loop through each item in the same axis (x or y), if they are the same as the previous item them increment matches. When the next item becomes different, check if matches is or greater than 3, call a function that removes matching items, and continue. </p>

<p>AS3 code:</p>

<pre><code>var grid:Array = [[2,3,2,2,2,4],
                  [ .. ]]; //multidimensional array
var matches:uint;
var gemType:uint;
for(col = 0; col &lt; grid.length; col++){
    matches = 0;        
    gemType = 0; //Reserve 0 for the empty state. If we make it a normal gem type, then only 2 are needed to match for the start.
    for(i = 0; i &lt; grid[0].length; i++){
        if(grid[col][i] == gemType){
            matches++;
        }
        if(grid[col][i] != gemType || i == grid[0].length - 1){ //subtract 1 because arrays start at 0
            if(matches &gt;= 3){
                removeMatches(blah);
            }
            gemType = grid[col][i];
            matches = 1;
        }
    }
}
</code></pre>

<p>This is only for the x axis, for y, grid[col][i] would become grid[i][row], etc. I'm sure you can figure that out :)</p>
","14933"
"What happens if I make more than $100k with the free Unity license?","23126","","<p>If an indie game developer makes more than $100,000 using the free version of Unity, what happens to the money that goes over $100k? How will Unity people come to know how much money they are making?</p>

<p>What precautions should I take just in case a game is a great success?</p>
","<blockquote>
  <p><strong>Update:</strong> In June 2016, <a href=""http://blogs.unity3d.com/2016/06/05/subscription-why/"" rel=""noreferrer"">Unity revised their business model</a>. They no longer offer permanent licenses, only subscriptions. However, they now offer a cheaper plus-version without the unprofessionally-looking Unity splash screen but with a revenue limit of $200,000. They also made some changes to the license agreement which required an update to this answer.</p>
</blockquote>

<hr>

<p>The <a href=""https://unity3d.com/legal/terms-of-service/software"" rel=""noreferrer"">Unity software terms regarding the differences between the personal, plus and pro version</a> are pretty clear: When your company makes a gross revenue (not profit!) of more than $100,000 per year, you need to subscribe to the plus-version ($200,000 limit), pro version (no limit) or enterprise version (no limit): </p>

<blockquote>
  <p>Unity Personal may not be used by:</p>
  
  <ul>
  <li>a Commercial Entity that has either: (a) reached annual gross revenues in excess of US$100,000, or (b) raised funds (including but not limited to crowdfunding) in excess of US$100,000, in each case during the most recently completed fiscal year;</li>
  <li>a Non-Commercial Entity (this means academic and governmental entities as defined below) with a total annual budget in excess of US$100,000 (for the entire Non-Commercial Entity (not just a department)) for the most recently completed fiscal year; or</li>
  <li>an individual (not acting on behalf of a Legal Entity) or a Sole Proprietor that has reached annual gross revenues in excess of US$100,000 from its use of the Unity Software during the most recently completed fiscal year, which does not include any income earned by that individual which is unrelated to its use of the Unity Software.</li>
  </ul>
</blockquote>

<p>The upgrade becomes required at the end of the fiscal year, because that's the way revenue is calculated according to the license conditions. As long as you don't subscribe to licenses for all your Unity users, you are obligated to stop using Unity. You are still allowed to sell your games, but you are no longer allowed to update them, even when you don't need the Unity editor to make updates:</p>

<blockquote>
  <p>During the term of this Agreement, you expressly acknowledge and agree that if you are a Unity Personal or Unity Plus user and the above thresholds are exceeded, then you may no longer use that tier of the Unity Software, and you must either: (a) purchase Unity Plus (if eligible) or Unity Pro; or (b) destroy all copies of the Unity Software in your possession or control, and cease updating Your Project Content. Unity will monitor your compliance with and enforce these restrictions and requirements including but not limited to monitoring the number of downloads of Your Project Content and any available revenue estimate data.</p>
</blockquote>

<p>What happens when you don't? When your games are that successful, you will likely not stay under the radar. When Unity Technologies suspects that you make more than $100,000 with the free version of their product they might sue you. During that lawsuit you might be forced to show your books to prove how much revenue you made and how many people you had working. </p>

<p>The court will decide what happens with any of the money above $100,000 you received from sales. Depending on the jurisdiction in which you are sued and their interpretation of the applicable laws and the EULA they might rule that you are entitled to it, that Unity Technologies is entitled to it, or that the sales are void and you need to refund it to your customers. Ask your lawyer what they consider the most likely outcome (don't tell us you can't afford one when you make over $100,000 a year).</p>
","107786"
"Free voxel editor?","23115","","<p>Does anyone know of a good free voxel editor and/or voxel-to-mesh converter?</p>
","<p>Thermite3D is a voxel-based game engine.  It isn't an editor per se.  It does, however, have a list of voxel editors on its wiki here: <a href=""https://bitbucket.org/volumesoffun/polyvox/wiki/Voxel%20editors"" rel=""nofollow"">Thermite-Recommended Voxel Editors</a>.</p>

<p>Of those, Sproxel, Voxel, and QBlock are all free.  Paint3d and Everygraph (Voxel3d) have trial versions, and one not on the list, <a href=""http://www.minddesk.com/"" rel=""nofollow"">Qubicle Constructor</a>, has a crippled trial as well.</p>
","13316"
"GLSL Shader - Change Hue/Saturation/Brightness","22996","","<p>I'm trying to change the hue of an image using a GLSL fragment shader. I want to achieve something similar to Photoshop's Hue/Saturation Adjustment layer.</p>

<p>In the following image you can see what I've got so far. I want to change the hue of the green square so it looks like the red square on the right, but with this shader I get a half red half pink square (the square in the middle).<br>
<img src=""https://i.stack.imgur.com/W1bPL.png"" alt=""enter image description here""></p>

<p>What I'm doing in the fragment shader is converting the texture's color to HSV, then I add the HSV color that I get from the vertex shader to it and I convert the color back to RGB.<br>
What am I doing wrong?    </p>

<p>Fragment shader:    </p>

<pre><code>precision mediump float;
varying vec2 vTextureCoord;
varying vec3 vHSV;
uniform sampler2D sTexture;

vec3 convertRGBtoHSV(vec3 rgbColor) {
    float r = rgbColor[0];
    float g = rgbColor[1];
    float b = rgbColor[2];
    float colorMax = max(max(r,g), b);
    float colorMin = min(min(r,g), b);
    float delta = colorMax - colorMin;
    float h = 0.0;
    float s = 0.0;
    float v = colorMax;
    vec3 hsv = vec3(0.0);
    if (colorMax != 0.0) {
      s = (colorMax - colorMin ) / colorMax;
    }
    if (delta != 0.0) {
        if (r == colorMax) {
            h = (g - b) / delta;
        } else if (g == colorMax) {        
            h = 2.0 + (b - r) / delta;
        } else {    
            h = 4.0 + (r - g) / delta;
        }
        h *= 60.0;
        if (h &lt; 0.0) {
            h += 360.0;
        }
    }
    hsv[0] = h;
    hsv[1] = s;
    hsv[2] = v;
    return hsv;
}
vec3 convertHSVtoRGB(vec3 hsvColor) {
    float h = hsvColor.x;
    float s = hsvColor.y;
    float v = hsvColor.z;
    if (s == 0.0) {
        return vec3(v, v, v);
    }
    if (h == 360.0) {
        h = 0.0;
    }
    int hi = int(h);
    float f = h - float(hi);
    float p = v * (1.0 - s);
    float q = v * (1.0 - (s * f));
    float t = v * (1.0 - (s * (1.0 - f)));
    vec3 rgb;
    if (hi == 0) {
        rgb = vec3(v, t, p);
    } else if (hi == 1) {
        rgb = vec3(q, v, p);
    } else if (hi == 2) {
        rgb = vec3(p, v, t);
    } if(hi == 3) {
        rgb = vec3(p, q, v);
    } else if (hi == 4) {
        rgb = vec3(t, p, v);
    } else {
        rgb = vec3(v, p, q);
    }
    return rgb;
}
void main() {
    vec4 textureColor = texture2D(sTexture, vTextureCoord);
    vec3 fragRGB = textureColor.rgb;
    vec3 fragHSV = convertRGBtoHSV(fragRGB);
    fragHSV += vHSV;
    fragHSV.x = mod(fragHSV.x, 360.0);
    fragHSV.y = mod(fragHSV.y, 1.0);
    fragHSV.z = mod(fragHSV.z, 1.0);
    fragRGB = convertHSVtoRGB(fragHSV);
    gl_FragColor = vec4(convertHSVtoRGB(fragHSV), textureColor.w);
}
</code></pre>

<p><strong>EDIT:</strong>
Using the functions Sam Hocevar provided in his answer, the problem with pink bands is solved, but I can only reach half of the color spectrum. I can change the hue from red to green, but I can't change it to blue or pink.
<img src=""https://i.stack.imgur.com/rGg5f.jpg"" alt=""enter image description here""></p>

<p>In the fragment shader, I'm doing this now:</p>

<pre><code>void main() {
    vec4 textureColor = texture2D(sTexture, vTextureCoord);
    vec3 fragRGB = textureColor.rgb;
    vec3 fragHSV = rgb2hsv(fragRGB);
    float h = vHSV.x / 360.0;
    fragHSV.x *= h;
    fragHSV.yz *= vHSV.yz;
    fragHSV.x = mod(fragHSV.x, 1.0);
    fragHSV.y = mod(fragHSV.y, 1.0);
    fragHSV.z = mod(fragHSV.z, 1.0);
    fragRGB = hsv2rgb(fragHSV);
    gl_FragColor = vec4(hsv2rgb(fragHSV), textureColor.w);
}
</code></pre>
","<p>As Nicol Bolas suggested in the original post's comments, I'm posting the solution to my problem in a separate answer.</p>

<p>The first issue was the image being rendered with pink bands, as the image in the original post shows. I fixed it using the functions Sam Hocevar provided in his answer (<a href=""https://gamedev.stackexchange.com/a/59808/22302"">https://gamedev.stackexchange.com/a/59808/22302</a>).</p>

<p>The second issue was that I was multiplying the hue of the texture's pixel by the value I was sending to the shader, which is meant to be an offset from the textures's pixel hue, so I had to perform an addition instead of a multiplication.<br>
I still perform a multiplication for saturation and brightness because I get a weird behaviour otherwise, and I don't really need incrementing them further than the original texture's saturation or brightness at the moment.</p>

<p>This is the main() method of the shader I'm using right now. With this I can shift hue from 0º to 360º, desaturate the image, and reduce brightness.</p>

<pre><code>void main() {
    vec4 textureColor = texture2D(sTexture, vTextureCoord);
    vec3 fragRGB = textureColor.rgb;
    vec3 fragHSV = rgb2hsv(fragRGB).xyz;
    fragHSV.x += vHSV.x / 360.0;
    fragHSV.yz *= vHSV.yz;
    fragHSV.xyz = mod(fragHSV.xyz, 1.0);
    fragRGB = hsv2rgb(fragHSV);
    gl_FragColor = vec4(fragRGB, textureColor.w);
} 
</code></pre>
","59879"
"What are the advantages and disadvantages to using a game engine?","22976","","<p>How do I know whether or not to use a game engine? I want to make a relatively complex 2D game for Android. What factors should I weigh to decide whether to find, install and learn a game engine or just do everything manually?</p>
","<p><strong>Advantages:</strong></p>

<ul>
<li><p>Most if not all of the coding is done for you, so all you have to worry about is content, level layout, etc.</p></li>
<li><p>Along those lines, memory management, asset loading, lighting (in complex engines), etc has all been designed and tested thoroughly (hopefully).</p></li>
<li><p>As mentioned below, if the engine is cross platform you will have to do little to no work to port your game.</p></li>
</ul>

<p><strong>Disadvantages:</strong></p>

<ul>
<li>If you are modifying anything, you now need to become familiar with a new codebase.</li>
<li>If there is a bug in the engine, unless it is open source you can't fix it.</li>
<li>The engine was not designed specifically for your game, so it may be less efficient than code you write specifically for your game.</li>
<li>Game engines generally are not free.</li>
<li>If a game is small, the overhead of using an engine may not be worth the time invested to write code yourself.</li>
<li>If your game engine also has any editors or tools, you will have to build and test those as well before turning them over to artists or relying on them yourself.</li>
</ul>

<p>Don't let the fact that the list of disadvantages is longer: when the time spent coding and testing all the systems you need is too long for your production cycle, or if you have more skill with art than code, using a game engine is definitely a good idea.</p>

<p>A comparison of game engines is in the works in this question: <a href=""https://gamedev.stackexchange.com/questions/351/pros-and-cons-of-various-3d-game-engines"">Pro&#39;s and Con&#39;s of Various 3D Game Engines</a></p>
","865"
"Why don't we use octogonal maps instead of hexagonal maps?","22969","","<p>I understand the advantage of hexagonal tiles over square ones. But why aren't octagons used instead? I would think they would provide better, more natural movement in eight directions.</p>

<p>I was thinking about using that kind of map in some game, but I haven't seen any games using that kind of map, so I wonder if I missed something obviously flawed about using it?</p>
","<p>Octogons:</p>

<p><a href=""http://forum.profantasy.com/extensions/InlineImages/image.php?AttachmentID=2376"" rel=""noreferrer"">http://forum.profantasy.com/extensions/InlineImages/image.php?AttachmentID=2376</a></p>

<p>Hexagons:</p>

<p><img src=""https://i.stack.imgur.com/ZFYan.gif"" alt=""enter image description here""></p>

<p>The gaps in the octogons make for an unappealing game world.</p>

<p>Typically, if you wanted to allow for eight directions of movement, you would just use squares.</p>
","54028"
"Unity3D draw call optimization : static batching VS manually draw mesh with MaterialPropertyBlock","22918","","<p>I've read <code>Unity3D</code> draw call batching <a href=""http://docs.unity3d.com/Documentation/Manual/DrawCallBatching.html"" rel=""nofollow"">documentation</a>.</p>

<p>I understood it, and I want to use it (or something similar) in order to optimize my application.</p>

<p>My situation is the following:</p>

<ul>
<li>I'm drawing hundreds of 3d buildings. Each building can be represented using a <code>Mesh</code> (or a SubMesh for each building, but I don't thing this will affect performances)</li>
<li>Each building can be textured with several combinations of texture patterns(walls, windows,..). Textures are stored into an <code>Atlas</code> for optimizaztion (see <a href=""http://docs.unity3d.com/Documentation/ScriptReference/Texture2D.PackTextures.html"" rel=""nofollow"">Texture2d.PackTextures</a>)</li>
<li>Texture mapping and facade pattern generation is done in fragment shader. The shader can be the same (except for few values) for all buildings, so I'd like to use a <code>sharedMaterial</code> in order to optimize parameters passed to the GPU.</li>
</ul>

<p>The main problem is that, even if I use an Atlas, share the material, and declare the objects as static to use static batching, there are few parameters(very fews, it could be just even a float I guess) that should be different for every draw call.</p>

<p>I don't know exactly how to manage this situation using <code>Unity3D</code>.
I'm trying 2 different solutions, none of them completely implemented.</p>

<p><strong>Solution 1</strong></p>

<ol>
<li>Build a GameObject for each building building (I don't like very much the overhead of a GameObject, anyway..)</li>
<li>Prepare each GameObject to be static batched with <a href=""http://docs.unity3d.com/Documentation/ScriptReference/StaticBatchingUtility.Combine.html"" rel=""nofollow"">StaticBatchingUtility.Combine</a>.</li>
<li>Pack all texture into an atlas</li>
<li>Assign the parent game object of combined batched objects the Material (basically the shader and the atlas)</li>
<li>Change some properties in the material before drawing an Object</li>
</ol>

<p>The problem is the point 5. Let's say I have to assign a different id to an object before drawing it, how can I do this? </p>

<ul>
<li>If I use a different material for each object I can't benefit of
static batching.</li>
<li>If I use a sharedMaterial and I modify a material property, all GameObjects will reference the same modified variable</li>
</ul>

<p><strong>Solution 2</strong></p>

<ol>
<li>Build a Mesh for every building (sounds better, no GameObject overhead)</li>
<li>Pack all textures into an Atlas</li>
<li>Draw each mesh manually using <a href=""http://docs.unity3d.com/Documentation/ScriptReference/Graphics.DrawMesh.html"" rel=""nofollow"">Graphics.DrawMesh</a> </li>
<li>Customize each DrawMesh call using a <a href=""http://docs.unity3d.com/Documentation/ScriptReference/MaterialPropertyBlock.html"" rel=""nofollow"">MaterialPropertyBlock</a></li>
</ol>

<p>This would solve the issue related to slightly modify material properties for each draw call, but the documentation isn't clear on the following point:</p>

<p>Does several consecutive calls to <code>Graphic.DrawMesh</code> with a different MaterialPropertyBlock would cause a new material to be instanced?</p>

<p>Or Unity can understand that I'm modifying just few parameters while using the same material and is able to optimize that (in such a way that the big atlas is passed just once to the GPU)?</p>
","<ol>
<li>Textures are stored in vram and don't get deleted even between frames, draw calls just bind these textures to the texture units. Changing a texture has always the same cost, regardless of the texture size. Each state change is expansive. DrawMesh looks pretty good, it should sort all meshes using this material and limit the state changes to the property block and transformations. I expect it to not create a new material, it is a little bit lower than that and only set the MaterialPropertyBlock's properties in addition to the material. Still, unity's batching will no longer work which means one draw call peer subject.</li>
<li>As soon as you want to change any material properties per instance static and dynamic batching will not be possible, at least unity's batching methods look that way. Still, if you meshes contain submeshes that may use shared materials, unity should combine these at least. </li>
</ol>

<p>I don't think unity will give you access to the low level rendering APIs to implement real hardware instancing eg using per instance vertex streams? If the amount of data is really low, you can implement your own static batching, by cloning the meshes and adding the data to each vertex, eg as color attribute, then unity's static batching should work. What a waste of memory... :-) </p>
","45467"
"How to prevent the ""Too awesome to use"" syndrome","22886","","<p>When you give the player a rare but powerful item which can only be used once but is never really <em>required</em> to proceed, most players will not use it at all, because they are waiting for the perfect moment. But even when this moment comes, they will still be reluctant to use it, because there might be an even better moment later. So they keep hoarding it for a moment which will never come. </p>

<p>In the end, they will carry the item around until it is outclassed by other, more readily available resources, or even until the very end of the game. That means that such one-shot items don't provide any gameplay-value at all. They are simply <a href=""http://tvtropes.org/pmwiki/pmwiki.php/Main/TooAwesomeToUse"">too awesome to use</a>.</p>

<p>What can you do to encourage the player to make use of their one-shot items and not hoard them?</p>
","<p>Thank you all for your answers. There are some great ideas between them. I decided that instead of accepting one of them, I decided to collect all ideas from the posts above, summarize them in one answer, and accept this answer as reference for future readers.</p>

<p>Reasons why players hoard:</p>

<ul>
<li>They develop a habit to solve certain situations using certain tools. When they have a tool which can only be used once, they will never develop a habit for using it. As a result they forget that they actually have this tool.</li>
<li>They don't know what the item is actually doing, so they aren't aware when they are in a situation where it could be useful.</li>
<li>They don't want to do a mistake and prevent further progress by using an item too early.</li>
</ul>

<p>How to prevent it as a game designer:</p>

<ul>
<li>Give the player a hint when in a situation where a certain one-shot item would be useful</li>
<li>Make it possible to re-obtain the items after use.</li>
<li>Give the player so many one-shot items, that each individual one doesn't seem that valuable and irreplaceable.</li>
<li>Add severe consequences to dying (more than having to reload the last savegame), so that the player will use one-shot items when desperate.</li>
<li>Don't make them single-use. Add a long cooldown to items instead or allow them to be recharged with another resource, so that the player can use them multiple times.</li>
<li>Make it impossible to hoard them. When the player is aware that they will lose the item anyway, they will use it sooner. This could be done by adding a time-limit, removing them after completing the level or severely limiting the number of items which can be carried at a time.</li>
<li>Punish the player for hoarding too many one-shot items, so that they will be motivated to get rid of them soon.</li>
</ul>
","55834"
"Upload Games to Steam without Greenlight?","22703","","<p>I've been working on a little game, (which is <strong>nowhere</strong> near completion) and wanted to know, that when I'm finished, if I would be able to release it onto Steam without having to get it Greenlit.</p>

<p>The reason why this is, is that I already payed for tools and editors for <strong>making</strong> my game, and don't want to have to pay another $100 in order to release my game.</p>

<p>Is this possible?</p>
","<p>No</p>

<p>Quoting Steam's <a href=""http://steamcommunity.com/workshop/about/?appid=765&amp;section=faq"">description</a> of the Greenlight process:</p>

<blockquote>
  <p><strong>Who should submit their games to Steam Greenlight? Is there another
  way to submit my game to Steam?</strong></p>
  
  <p>Steam Greenlight has replaced our
  previous submission process. Any developer or publisher who is new to
  Steam and interested in submitting their game to the platform should
  submit their game through Steam Greenlight.</p>
</blockquote>

<p>The idea behind Greenlight is to do an effort to prevent very low quality games into Steam, and let in only games that users are genuinely interested in (whether or not it succeeds at it is another discussion).</p>

<p>In my experience, getting a game through Greenlight is <strong>hard</strong>. There are so many games with so many interesting concepts, and so many games with much larger teams and budgets, that it is very difficult to gain enough traction to get released.</p>

<p>In addition, <em>making</em> a game is <strong>very hard</strong>. Just like anything in life, making good games takes practice, and I would say it would take at minimum 4 or 5 completed games to actually start making games that people like, and therefore get voted on greenlight.</p>

<p>Don't despair though, Steam is not the only way to get your game known. Focus on making your game, focus on <em>finishing</em> the game, show it to other people, make a blog about it, sell it (or give it away) on your site, and before you know it, you will have a few games under your belt, hundreds of loyal followers, and enough traction so the next game you make will actually make it on steam.</p>
","92494"
"Visual Studio 2012 and Game Development","22558","","<p>Alright, I think it's a simple question, but I got difficulties to find some answers around.</p>

<p>I already read that XNA wouldn't be in Visual Studio 2012.  I recently learned to use XNA, but since I would like to work on games, I'd like to know if there's a way to develop games using C# on Visual Studio 2012, or if I should learn everything again using C++ and Direct3D?</p>

<p>C# is a language I like a lot, so if there's no way to do it in C# but something quite easy to use Java for game development, I'd also be interested.</p>

<p>Thanks a lot!</p>
","<p>Visual Studio 2012 does not work out of the box with XNA 4.0 but there is a <a href=""https://stackoverflow.com/questions/10881005/how-to-install-xna-game-studio-on-visual-studio-2012-rc"">workaround</a> but since this still requires VS2010 to be installed as well I would recommend to just use VS2010 since that still works as expected.</p>
","35413"
"Does a minor in math increase my hirability?","22545","","<p>I've been pondering this question for some months now, and have been unable to get an answer from anyone in the industry (likely because I know no one in the industry).</p>

<p><strong>I am currently completing a B.S. in Computer Science, and I want to know if minoring in math will look good on my resume to gaming companies large and small.</strong></p>

<p>I am not set on becoming a game developer, but I certainly want to have that option available to me.</p>

<p><strong>UPDATE:</strong> It's been a couple years since I asked this question, and have since graduated WITHOUT the minor. I was able to get a job at an amazing company, but not in game development. I am now personally of the opinion that minors are not really a major selling point for aspiring Software Engineers. The most important thing is building software and showing it off to potential employers.</p>
","<p>Hiring is kind of a black box.  It really depends on the person who's looking at your resume/CV.</p>

<p>All I can say is that saying you have a minor in something is just another bullet point.  Sometimes that helps.  Maybe it shows you're more useful on the heavy math side of programming which some generalists programmers have trouble with.  Maybe the person looking over your resume completely skips the education section because it generally isn't relevant.</p>

<p>I can't think of a reason it would hurt, though.  At worse it should do nothing.</p>
","5501"
"How do I blend a bitmap with a color?","22458","","<p>I have a png which is mostly transparent, except for a shape I've drawn in white. I want to be able to blend this bitmap with a color when drawing it with Canvas. I'd like something like [Sa, (Dc * (1 - Sa)) + (Sc * C * Sa)], where C would be the color I want to blend with. I assumed I would just set the paint color to C, then call drawBitmap, but the default behavior doesn't seem to be blending.</p>

<p>Is this the right approach? Are there some Xfer codes I'm missing? Can I create a custom shader to do this? Is there an example in the android sdk api I missed that does this?</p>

<p>As an additional constraint, I should mention I want to avoid just creating a new bitmap with the blended color to use. The color C (above) could change every frame, and I don't want to have to generate 100's of these bitmaps for every color that I might need.</p>
","<pre><code>Paint p = new Paint();
ColorFilter filter = new LightingColorFilter(Color.RED, 0);
p.setColorFilter(filter);
</code></pre>

<p>Then draw with that <code>Paint</code> object.</p>

<p>Found at <a href=""https://stackoverflow.com/questions/3499095/how-do-you-tint-a-bitmap-in-android"">""How do you tint a bitmap in Android?""</a></p>
","5394"
"How can I draw an outline in Unity3d?","22450","","<p>I am trying to highlight a rectangle of arbitrary height. I thought the easiest way to do this would be to create a separate ""box"" gameobject that outlines the rectangle.</p>

<p>I've tried with both a MeshRenderer + Transparent Texture, and a LineRenderer to outline the four points of the rectangle. Neither are very satisfactory.</p>

<p><img src=""https://i.stack.imgur.com/FT8SF.png"" alt=""enter image description here""></p>

<p>(Line renderer on in the middle, scaled cube on the right)</p>

<p>What's the right way to go about this? I am trying to get something like the left rectangle - a simple perimeter of fixed width through four points of my choosing.</p>
","<p>Use <code>GUI.Box()</code>.</p>

<p>If you only need a 2D rectangle, GUI is the way to go. Create a new GUIStyle using a simple rectangle as a texture (the inside of the rectangle should be transparent, of course), set up its <code>Border</code> value so that it is not stretched, and call <code>GUI.Box(new Rect(...),"""",myGuiStyle);</code>. </p>

<p>You can use <code>Camera.WorldToScreenPoint</code> method if you want to outline something in world coordinates (i.e. 3D), just remember that in Unity's world coordinates y goes from bottom to top, and in GUI y goes from top to bottom.</p>

<p><strong>Code Example:</strong></p>

<pre><code>void OnGUI()
{
    //top left point of rectangle
    Vector3 boxPosHiLeftWorld = new Vector3(0.5f, 12, 0);
    //bottom right point of rectangle
    Vector3 boxPosLowRightWorld = new Vector3(1.5f, 0, 0);

    Vector3 boxPosHiLeftCamera = Camera.main.WorldToScreenPoint(boxPosHiLeftWorld);
    Vector3 boxPosLowRightCamera = Camera.main.WorldToScreenPoint(boxPosLowRightWorld);

    float width = boxPosHiLeftCamera.x - boxPosLowRightCamera.x;
    float height = boxPosHiLeftCamera.y - boxPosLowRightCamera.y;


     GUI.Box(new Rect(boxPosHiLeftCamera.x, Screen.Height - boxPosHiLeftCamera.y, width, height),"""", highlightBox);
}
</code></pre>
","48781"
"Why is it difficult to port games from consoles to PC?","22327","","<p>PC ports of console games often come out a month or two later. Why is this?</p>

<p>Games are written in languages that compile on PCs too, so the game logic should compile without issue. What's holding them back then? Is it rendering code or what?</p>
","<p>There are a number of reasons why a PC port can take a while. (I apologize if I seem to be repeating myself somewhere; this is sort of written on the fly.)</p>

<h3>Adapting controls and gameplay</h3>

<p>When you're playing on a console, this alone puts certain limitations on what you can do, since all the user has is a gamepad.</p>

<p>Just creating 1:1 mappings between keyboard keys and controller inputs is not always a good idea - if even possible - so sometimes it takes longer to figure out a good solution.</p>

<h3>Hardware abstraction/Fragmentation</h3>

<p>When you develop for e.g. a Wii U, you know exactly how a Wii U behaves, because all Wii Us are identical. This is not true for PCs; you have many different graphics cards and CPUs, and sometimes something won't work on some of them. It takes a lot of testing to uncover these bugs, and fixing them also takes time.</p>

<p>If you've <em>never</em> used your engine to make a PC version, you also need to code your hardware abstraction accordingly. Some games want to support multiple DirectX versions <em>and</em> OpenGL for Linux/Mac, and all of that takes time to write if it hasn't been done before.</p>

<h3>Resource contention</h3>

<p>On consoles, the game doesn't have to compete with an OS for resources, etc. - not a whole lot of stuff goes on in the background.</p>

<p>On a PC, you have the OS running, you have a plethora of background programs, and this all means you won't get as large a share as you were hoping for. This means you sometimes need to perform additional optimizations, especially for players on lower end systems</p>

<h3>Improving assets</h3>

<p>With a console, you have a fixed target, so you write shaders, etc. to match that target.</p>

<p>On a PC, some graphics cards support more advanced features, and maybe you want to use a better shader for those. Well, that means you'll have to write that shader.</p>

<h3>Platform-specific stuff</h3>

<p>Console SDKs may have a lot of convenient features that don't map over easily to a PC - for example, it might provide access to hardware timers or a good sound API.</p>

<p>Those things aren't usually available on PCs; you need to use other ways of accomplishing those things and maybe that changes how you have to abstract the platform differences.</p>
","60824"
"How to create a new GameObject, without adding it to the scene?","22293","","<p>I'm creating what is essentially my own prefab system. Game objects are defined by a human readable data file. I'd like to create an empty GameObject, load it with the components defined in the data file and have it ready and waiting for an <code>Instantiate()</code> call. However, whenever I use <code>GameObject go = new GameObject()</code> a new game object is added to the scene.</p>

<p>Using Unity built in prefabs, I can load a prefab as a GameObject, and it's not added to the scene. (See example below)</p>

<p>The rationale behind this is I'd like to have one list that contains GameObjects, some generated by loading Unity prefabs and others created by my custom prefab system. This needs to happen at run time, and can't involve the Unity Editor (since ideally end users would be able to define their own data files).</p>

<p>How can I create a new GameObject, without Unity automatically instantiating it for me?</p>

<hr>

<p>For example, I can make a call like this:</p>

<pre><code>Resources.LoadAll(""PrefabsDirectory"", typeof(GameObject))
</code></pre>

<p>And I'll get a list of GameObjects, none of which are added to the scene when the call is made. Essentially, I'm creating a <code>LoadAll</code> method for my own prefabs, and likewise, I don't want to instantiate the GameObjects when the call is made.</p>
","<p>You could change the <a href=""https://docs.unity3d.com/Documentation/ScriptReference/HideFlags.html"" rel=""noreferrer"">GameObject's hideFlags?</a></p>

<p>I just tried running this:</p>

<pre><code>GameObject myGameObject = new GameObject ();
myGameObject.name = ""Obvious Name"";

myGameObject.hideFlags = HideFlags.HideInHierarchy;
</code></pre>

<p>...and it's there, but it's not in the hierarchy. Technically, it's in the scene, but you don't see it until you change it's flags back to HideFlags.None. It's not the answer you're looking for, but at least as far as releasing this to developers goes, it's cleaner than grouping your objects. </p>
","73372"
"How to not freeze the main thread in Unity?","22229","","<p>I have a level generation algorithm that is computationally heavy. As such, calling it always results in the game screen freezing. How can I place the function on a second thread while the game still continues to render a loading screen to indicate the game is not frozen?</p>
","<p><strong>Update:</strong> In 2018, <a href=""https://create.unity3d.com/jobsystem"" rel=""nofollow noreferrer"">Unity is rolling out a C# Job System</a> as a way to offload work and make use of multiple CPU cores.</p>

<p>The answer below predates this system. It will still work, but there may be better options available in modern Unity, depending on your needs. In particular, the job system appears to resolve some of the limitations on what manually-created threads can safely access, described below. <a href=""https://twitter.com/LotteMakesStuff/status/952273492015243264"" rel=""nofollow noreferrer"">Developers experimenting with the preview report performing raycasts and constructing meshes in parallel</a>, for example.</p>

<p>I'd invite users with experience using this job system to add their own answers reflecting the current state of the engine.</p>

<hr>

<p>I've used threading for heavyweight tasks in Unity in the past (usually image &amp; geometry processing), and it's not drastically different than using threads in other C# applications, with two caveats:</p>

<ol>
<li><p>Because Unity uses a somewhat older subset of .NET, there are some newer threading features and libraries we can't use out of the box, but the basics are all there.</p></li>
<li><p>As Almo notes in a comment above, many Unity types are not threadsafe, and will throw exceptions if you try to construct, use, or even compare them off the main thread. Things to keep in mind:</p>

<ul>
<li><p>One common case is checking to see if a GameObject or Monobehaviour reference is null before trying to access its members. <code>myUnityObject == null</code> calls an overloaded operator for anything descended from UnityEngine.Object, but <code>System.Object.ReferenceEquals()</code> works around this to a degree - just remember that a Destroy()ed GameObject compares as equal to null using the overload, but is not yet ReferenceEqual to null.</p></li>
<li><p><em>Reading</em> parameters from Unity types is usually safe on another thread (in that it won't immediately throw an exception as long as you're careful to check for nulls as above), but <a href=""https://gamedev.stackexchange.com/a/115188/39518"">note Philipp's warning here</a> that the main thread might be modifying state while you're reading it. You'll need to be disciplined about who's allowed to modify what &amp; when in order to avoid reading some inconsistent state, which can lead to bugs that can be devillishly hard to track down because they depend on sub-millisecond timings between threads that we can't reproduce at will.</p></li>
<li><p>Random and Time static members are not available. Create an instance of System.Random per thread if you need randomness, and System.Diagnostics.Stopwatch if you need timing info.</p></li>
<li><p>Mathf functions, Vector, Matrix, Quaternion, and Color structs all work fine across threads, so you can do most of your computations separately</p></li>
<li><p>Creating GameObjects, attaching Monobehaviours, or creating/updating Textures, Meshes, Materials, etc. all need to happen on the main thread. In the past when I've needed to work with these, I've set up a producer-consumer queue, where my worker thread prepares the raw data (like a big array of vectors/colours to apply to a mesh or texture), and an Update or Coroutine on the main thread polls for data and applies it.</p></li>
</ul></li>
</ol>

<p>With those notes out of the way, here's a pattern I often use for threaded work. I make no guarantee that it's a best-practice style, but it gets the job done. (Comments or edits to improve are welcome - I know threading is a very deep topic of which I only know the basics)</p>

<pre><code>using UnityEngine;
using System.Threading; 

public class MyThreadedBehaviour : MonoBehaviour
{

    bool _threadRunning;
    Thread _thread;

    void Start()
    {
        // Begin our heavy work on a new thread.
        _thread = new Thread(ThreadedWork);
        _thread.Start();
    }


    void ThreadedWork()
    {
        _threadRunning = true;
        bool workDone = false;

        // This pattern lets us interrupt the work at a safe point if neeeded.
        while(_threadRunning &amp;&amp; !workDone)
        {
            // Do Work...
        }
        _threadRunning = false;
    }

    void OnDisable()
    {
        // If the thread is still running, we should shut it down,
        // otherwise it can prevent the game from exiting correctly.
        if(_threadRunning)
        {
            // This forces the while loop in the ThreadedWork function to abort.
            _threadRunning = false;

            // This waits until the thread exits,
            // ensuring any cleanup we do after this is safe. 
            _thread.Join();
        }

        // Thread is guaranteed no longer running. Do other cleanup tasks.
    }
}
</code></pre>

<p>If you don't strictly need to split work across threads for speed, and you're just looking for a way to make it non-blocking so the rest of your game keeps ticking, a lighter-weight solution in Unity is <strong>Coroutines</strong>. These are functions that can do some work then yield control back to the engine to continue what it's doing, and resume seamlessly at a later time.</p>

<pre><code>using UnityEngine;
using System.Collections;

public class MyYieldingBehaviour : MonoBehaviour
{ 

    void Start()
    {
        // Begin our heavy work in a coroutine.
        StartCoroutine(YieldingWork());
    }    

    IEnumerator YieldingWork()
    {
        bool workDone = false;

        while(!workDone)
        {
            // Let the engine run for a frame.
            yield return null;

            // Do Work...
        }
    }
}
</code></pre>

<p>This doesn't need any special cleanup considerations, since the engine (so far as I can tell) gets rid of coroutines from destroyed objects for you.</p>

<p>All the local state of the method is preserved when it yields and resumes, so for many purposes it's as though it was running uninterrupted on another thread (but you have all the conveniences of running on the main thread). You just need to make sure each iteration of it is short enough that it's not going to slow your main thread unreasonably.</p>

<p>By ensuring important operations aren't separated by a yield, you can get the consistency of single-threaded behaviour - knowing that no other script or system on the main thread can modify data you're in the middle of working on.</p>

<p>The yield return line gives you a few options. You can...</p>

<ul>
<li><code>yield return null</code> to resume after the next frame's Update()</li>
<li><code>yield return new WaitForFixedUpdate()</code> to resume after the next FixedUpdate()</li>
<li><code>yield return new WaitForSeconds(delay)</code> to resume after a certain amount of game time elapses</li>
<li><code>yield return new WaitForEndOfFrame()</code> to resume after the GUI finishes rendering</li>
<li><code>yield return myRequest</code> where <code>myRequest</code> is a <a href=""http://docs.unity3d.com/ScriptReference/WWW.html"" rel=""nofollow noreferrer"">WWW</a> instance, to resume once the requested data finishes loading from the web or disc.</li>
<li><code>yield return otherCoroutine</code> where <code>otherCoroutine</code> is a <a href=""https://docs.unity3d.com/ScriptReference/Coroutine.html"" rel=""nofollow noreferrer"">Coroutine instance</a>, to resume after <code>otherCoroutine</code> completes. This is often used in the form <code>yield return StartCoroutine(otherCoroutineMethod())</code> to chain execution to a new coroutine that can itself yield when it wants to.</li>
</ul>

<p>...depending on when you want the coroutine to take its next turn.</p>

<p>Or <code>yield break;</code> to stop the coroutine before it reaches the end, the way you might use <code>return;</code> to early-out of a conventional method.</p>
","113098"
"Having trouble with grouping in 3D Studio Max","22182","","<p>I'm using 3D Studio Max 2012. I've got a simple mesh and several other polygons and I want to group everything all together. But the option is greyed out, I can't actually select 'Group' under the menus.</p>

<p>I've tried exploding and collapsing the mesh but nothing seems to work.</p>

<p>How can I group them together, what things can I do to try to diagnose the problem?</p>

<p>EDIT:
My object hierarchy looks weird:</p>

<pre><code>scene root:
 . object 1
model:
 - object 2 ... 99
</code></pre>
","<p>3D Studio Max has issues when trying to group objects with different parents. In a way, it makes sense that objects with different hierarchies shouldn't be allowed to group together. However, from an unwary user's perspective, this is a frustrating, wtf, kind of ""gotcha"". </p>

<p>To fix it, simply correct the hierarchy. </p>
","17858"
"Unity 2d: How stop movement when object hit a wall","22175","","<p>I created a square that slides on a flat ground.</p>

<pre><code>public class PlayerMoveScript : MonoBehaviour
{

float move = 0;

    void Start (){}

    void FixedUpdate ()
    {
        if (move == 0) {
            move = Input.GetAxis (""Horizontal"");
            if (move != 0) {
                move = 15*Mathf.Sign(move);
                rigidbody2D.velocity += new Vector2 (move, rigidbody2D.velocity.y);
            }
        } else 
            {
            rigidbody2D.velocity = new Vector2 (move, rigidbody2D.velocity.y);
            }

    }
}
</code></pre>

<p>On both sides of the ground lies a wall, when the square hits a wall and stops his movement, the square instead continues to push in his direction.
What I trying to do, is that when the square hits the wall, the square stop the movement and stop to push on the wall, in a way that the player can choose a new direction until the square will hit a new wall.</p>

<p>So imagine a big picture frame, a little square lies on the center.</p>

<ol>
<li>The player hit the down key</li>
<li>The square starts to move down, with a constant velocity </li>
<li>The square hits the bottom side of the frame, and it stops </li>
<li>The player choose a new direction.</li>
<li>The square starts to move in the new direction</li>
<li>Back to 2</li>
</ol>

<p>N.B: The walls are rigid bodies 2d with a box collider 2d.</p>
","<p>Based on how you explained your movement one simple way of doing it is... </p>

<p>Raycast in the direction you move there are only four directions so everytime you move</p>

<ol>
<li>Raycast in the direction you are moving.</li>
<li>In your update once the raycast gets within a certain distance say 0.2 unity units..</li>
<li>dont allow movement in that direction</li>
<li>and so once the player pushes a button in that direction you raycast to see if there a wall</li>
</ol>

<p>For this setup to work you just will need 8 raycasts two for each direction you can move to define the width of the object.  </p>

<p>The benefit of doing it this way is that you can keep a certain distance away from your box in otherwords you can define at what distance you want to stop before a collision actually happens which is what you probably want.</p>

<p>Also make sure to raycast only when you are moving.</p>
","72510"
"Difference between orthogonal map and isometric map","22167","","<p>I am laughing at myself ignorant on this. Google didn't produce an obvious answer. Could someone explain what orthogonal map and isometric map are, and how they are different?</p>
","<p>I made a picture to sum it up. Basically, the difference between both types of maps has mostly to do with the <strong>angle formed between each axis</strong> which results in one appearing to be seen from a topdown point of view, while the other appears to be seen from an angle:</p>

<p><img src=""https://i.stack.imgur.com/4TfHP.jpg"" alt=""enter image description here""></p>

<p>It is also worth noticing the visual difference between an <em>isometric</em> projection and <em>perspective</em> projection which is what almost every 3D game uses.</p>

<p><img src=""https://i.stack.imgur.com/FD9BJ.png"" alt=""enter image description here""></p>

<p>Notice how <strong>lines are drawn parallel to each other</strong> when using an <em>isometric</em> projection, while when using a <em>perspective</em> projection, lines converge towards one (or more) <a href=""http://en.wikipedia.org/wiki/Vanishing_point"" rel=""nofollow noreferrer"">vanishing points</a>.</p>
","22279"
"How to find the window size in XNA","22163","","<p>I just wanted to know if there was a way to find out the size of the window in XNA. I don't want to set it to a specific size; I would like to know what dimensions it currently displays as automatically. Is there a way to find this information out?</p>

<p>I realize I probably should have found this information out (or set it myself manually) before working on the game, but I'm a novice and am now hoping to work within the dimensions I have already become invested in. Thanks!</p>
","<p>Here are your options:</p>

<p>To get the back-buffer size use:</p>

<p><code>GraphicsDevice.PresentationParameters.Bounds</code> (for a rectangle) or <code>BackBufferWidth</code> and <code>BackBufferHeight</code>.</p>

<p>You want the back-buffer size if you're doing stuff like setting viewports, taking screenshots, etc.</p>

<p><strong>To get the <em>Viewport</em>, use:</strong></p>

<p><code>GraphicsDevice.Viewport.Bounds</code> (for a rectangle) or <code>Width</code> and <code>Height</code>.</p>

<p><strong>The size of the viewport is what you want to use when you're actually rendering stuff</strong>. Any coordinates you pass to <code>SpriteBatch</code> are in pixel-aligned client space in terms of the viewport: (0,0) for the top left pixel to (width-1,height-1) for the bottom right. If you're doing 3D stuff, <em>projection space</em> goes from (-1,-1) in the bottom left of the viewport to (1,1) in the top right.</p>

<p>You can adjust the size and position of the viewport on screen (for doing effects like split-screen). So, while it is initialised to the size of the back-buffer, it is not necessarily always the same.</p>

<p>If you're doing interface layout stuff, particularly if you will run on the Xbox 360, be aware of <code>Viewport.TitleSafeArea</code>. This tells you what region is definitely visible on screens that may cut off some of the border.</p>

<p>If, for some reason, you're actually working with the game window itself, use <code>Game.GameWindow.ClientBounds</code>.</p>
","8694"
"Why would you use software rendering over hardware rendering, today?","22160","","<p>As opposed to CPU or software rendering I assume?</p>

<p>Wouldn't generally all current rendering be GPU based, seeing as you would be using OpenGL or Direct X?</p>

<p>Could someone give me some info here, can't find any suitable answers?</p>
","<p>As you clearly already know what GPU rendering is... let me answer what you seem to be asking.</p>

<p>Traditionally, hardware rendering has carried a stigma of being very complex. This has in large part been due to the design of the application programming interfaces (APIs) which have not been well-geared to concealing complexity; that is, the learning curve has been steep. It has also been in part due to an understanding that writing 3D applications -- for which these APIs are heavily geared -- is far more complex than writing 2D ones. Re interface complexity, I'm referring to interfaces like OpenGL and DirectX. Re 3D vs 2D, I'm referring to the mathematics and geometry which goes into constructing 3D scenes, vs. the simplicity with which the untrained mind can approach 2D problems.</p>

<p>However, in recent years, not only has learning material become much more available, but also, many libraries that wrap the underlying complexities of these interfaces have become available and have lowered the barriers to entry. All of this has fed back into a cycle of increased interest which was already present due to the increasing importance of visualisation, slick user interfaces, and performance on low-powered devices.</p>

<p>So software rendering and 2D rendering have been good entry points and focus areas for those who were new to graphics and / or wanted to create a product where rendering did not take too much of the available time on a project. At least in regards to 2D, this still applies; technology has largely covered the gap in bringing 2D rendering to GPU.</p>
","73497"
"How can I find a projectile's launch angle?","21995","","<p>I am making a 2d game in which units fire arrows at each other.
I know the shooter's and the target's position and the initial velocity of the projectile. I want to know the angle the projectile should have in order to land on the target. The target could be at a different height than the shooter.</p>

<p>To sum up I know v0, R and g and I need to find the angle (or the height ?).</p>

<p>I read <a href=""http://en.wikipedia.org/wiki/Projectile_motion"" rel=""noreferrer"">http://en.wikipedia.org/wiki/Projectile_motion</a> ,but I can't find something related to what I need.</p>
","<p>The formula to find the angle is </p>

<p><img src=""https://i.stack.imgur.com/DXjOm.png"" alt=""Formula""></p>

<p>where v is initial launch speed, g is the gravity constant, x and y are the target's distance and height.</p>

<p>The two roots of this equation give you two possible angles. If the results are <a href=""http://en.wikipedia.org/wiki/Imaginary_number"" rel=""noreferrer"">imaginary</a> then your initial velocity is not great enough to reach the target (if you want to calculate the angle of reach read <a href=""http://en.wikipedia.org/wiki/Trajectory_of_a_projectile#Angle_of_reach"" rel=""noreferrer"">this</a>).  It's up to you which angle is selected. It would make sense to choose the most direct path i.e. the smaller angle.</p>

<p>You can see a GIF of this equation below with different target values and a constant launch velocity.</p>

<p><img src=""https://i.stack.imgur.com/wM0HK.gif"" alt=""Formula graphed as animated GIF""></p>

<p>Resources from this wikipedia <a href=""http://en.wikipedia.org/wiki/Trajectory_of_a_projectile#Angle_required_to_hit_coordinate_.28x.2Cy.29"" rel=""noreferrer"">article</a></p>
","53563"
"Tile sizes in 2D games","21955","","<p>While developing a small game using tile-mapping method a question came to my mind: </p>

<p>I would develop the game on Windows but wouldn't exclude adapting it to another platform.</p>

<p>What size(in pixels) would you recommend using for creating the tiles of a tile-mapped game(ie: RPG) with the following requirements?</p>

<ul>
<li>Have an acceptable level of detail without having too many tiles.</li>
<li>Having a decent map size. </li>
<li>Allow adaptation of the game on a handheld(ie: PSP), smartphone or a computer without too much loss of detail or slowdowns.</li>
<li>Allow more or less important zoom-in / zoom-out.</li>
<li>Have a resolution of tile that permits either pixel-perfect collision or block-collision.</li>
</ul>

<p>Anything from a good explanation to a game example is useful as long as it can fit the requirements.</p>

<p>This question may seem a bit simplistic, but I noticed that many Indies game developer were using inappropriate scales scenery.</p>

<p><em>Also sorry for the poor syntax and the lack of vocabulary of my question, being a non-native English speaker doesn't help when talking about computers programming.</em></p>
","<p>You can calculate the tile size based on the screen resolution and the number of tiles that need to be visible. If you were putting up a chess board (8x8 tiles) on a 768 pixel tall screen, your tiles can't be more than 768/8 or 96 pixels, otherwise they won't all fit on the screen.  How many tiles need to be visible is of course dependent on your game design.</p>

<p>So decide how many tiles a player should see at once, decide on the screen resolution, and calculate from there. </p>

<p>That said, I like 64x64 ;^)</p>

<hr>

<p>I wanted to go back and edit this old answer to add a link to a nice post with tile making guidelines.  It could be of use to anyone looking at tile size and tile design in general.</p>

<p><a href=""http://lpc.opengameart.org/static/lpc-style-guide/styleguide.html"">http://lpc.opengameart.org/static/lpc-style-guide/styleguide.html</a>  This is a great </p>
","6679"
"Algorithm for generating a 2d maze","21914","","<p>What algorithm have you used in the past to generate a simple 2d maze? </p>
","<p>There are a lot of various ways of making mazes.  There's a huge list of them and their descriptions here: <a href=""http://www.astrolog.org/labyrnth/algrithm.htm"">http://www.astrolog.org/labyrnth/algrithm.htm</a></p>

<p>I think I used the one described under ""Perfect"".</p>
","915"
"What does it mean to ""bake lights""?","21842","","<p>What does it mean to bake lightmap ? I heard this in Unity3d, and again found this LightUp plugin for sketchup that bakes lightmap.</p>

<p>From what I observe, the lightmap baked gives the 3d object a much more realistic feel. Is the purpose of baking light on object to give that cg animation look you see on pre-rendered animations?</p>
","<p>When you have a static (non-moving) light in a game, you have two options for rendering this light. You could render it the same as a dynamic light; that is, feed it through the shader pipeline which will calculate its effect on everything around it, every frame, on its way to the screen. This is obviously pretty expensive. Or, an editor can bake the light into the scene.</p>

<p>What I've always thought of baking was perhaps a more simple version: basically the editor just takes the textures of everything around the light, calculates the effect of the light on those textures (brightens them, perhaps colors them, shadows, etc.), and saves them as replacement textures to use. So all the textures around the ""light"" look like they have a light cast on them, but at runtime there actually isn't a light from a calculation standpoint; it's an optical illusion, essentially.</p>

<p>Unity, however, seems to be generating a <a href=""http://en.wikipedia.org/wiki/Lightmap"">lightmap</a>. This is similar to the above notion, but the baked lighting is kept separately instead of modifying the underlying texture, and I assume a shader merges the two at runtime. This would have the advantage of keeping the advantage of tiled textures (i.e. low memory usage), since they wouldn't have the light baked right into them therefore they could remain tiled, and the shader would be very lightweight, especially compared to treating the light as dynamic.</p>

<p>A light obviously needs to be static for this to work; that is, you can't move it during gameplay, because the light has been baked into the textures. Also, any dynamic objects in the room (such as the player character) won't have the light shining on them so there needs to be some sort of exception, where the light is rendered for dynamic objects but not (re-)rendered on the static scenery.</p>
","9994"
"Huge procedurally generated 'wilderness' worlds","21817","","<p>I'm sure you all know of games like Dwarf Fortress -  massive, procedural generated wilderness and land. Something like this, taken from <a href=""http://www.nolithius.com/game-development/world-generation-breakdown"" rel=""noreferrer"">this very useful article.</a></p>

<p>However, I was wondering how I could apply this to a much larger scale; the scale of Minecraft comes to mind (isn't that something like 8x the size of the Earth's surface?). Pseudo-infinite, I think the best term would be.</p>

<p><img src=""https://i.stack.imgur.com/0gRm4.png"" alt="":D""></p>

<p>The article talks about fractal perlin noise. I am no way an expert on it, but I get the general idea (it's some kind of randomly generated noise which is semi-coherent, so not just random pixel values). </p>

<p>I could just define regions X by X in size, add some region loading type stuff, and have one bit of noise generating a region. But this would result in just huge amounts of islands.</p>

<p>On the other extreme, I don't think I can really generate a supermassive sheet of perlin noise. And it would just be one big island, I think.</p>

<p>I am pretty sure Perlin noise, or some noise, would be the answer in some way. I mean, the map is really nice looking. And you could replace the ascii with tiles, and get something very nice looking.</p>
","<p>I think I better understand what you are asking now.</p>

<p>Noise is not random - it's random-looking but is completely based on a mathematical formula and is repeatable. All the information is encoded in the formula. This means that you can have a formula that potentially covers an infinite area, and just use the formula on the coordinates of the area you need. When you need an adjacent area, you just re-use the formula on the new coordinates, and since the formula yields continuous values, the areas will join seamlessly.</p>

<p>Here's a simplified example, using sine instead of perlin noise for the height generation, and imagining the world is infinite in the X axis but only 1 unit high in the Y and Z axes.</p>

<p>Formula is: <code>height(x,y) = sin(x/20)</code></p>

<p>The game starts, and we generate heights for the nearby area, ie. (0,0) to (9,0):</p>

<p><code>[0.0, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.34, 0.39, 0.43]</code></p>

<p>We have a hill, rising up towards the right. Let's say we walk to the end of it and need to generate the values from (10,0 to 19,0) now:</p>

<p><code>[0.48, 0.52, 0.56, 0.61, 0.64, 0.68, 0.72, 0.75, 0.78, 0.81]</code></p>

<p>Notice how the hill keeps rising steadily, and that the value at (10,0) follows on nicely from the one at (9,0). This is because the sine function is continuous, which basically means that if you feed it 2 adjacent numbers in, you'll get 2 adjacent results out - for a certain definition of adjacent. So if you use your world coordinates as the parameters to the function that defines your world, you will get a continuous landscape that fits together no matter how much or little of it you generate at once. When you generate new parts, they will flow on from the existing parts automatically, because the heights are already pre-determined.</p>

<p>If the world isn't going to change, you don't even need to store anything, since you can calculate exactly what the height is at any given point from the formula. Obviously with something like Minecraft the world is totally deformable so you just save each chunk as you create it. Given that there is a high degree of coherence between adjacent chunks (ie. if 1 block is grass, it's more likely than not that the block next to it will be grass too) you can compress the data very efficiently - run length encoding would work well, but then so would almost any standard compression algorithm.</p>

<p>Whereas I have talked about height as the most obvious value, you can use the same system to generate any characteristic you want. Use a mathematical function with continuous properties and where the inputs are your world coordinates and that can decide the presence of landmarks, mineral deposits, spawn points, whatever you like. (Obviously the values in one formula may affect another - no point placing a coal deposit in mid-air, so you generate the world height map and then only calculate coal possibilities for the blocks that are far enough below ground.)</p>
","4654"
"How to design a game engine in an object-oriented language?","21765","","<p>Whenever I try and write a game in any object-oriented language, the first problem I always face (after thinking about what kind of game to write) is how to design the engine. Even if I'm using existing libraries or frameworks like SDL, I still find myself having to make certain decisions for every game, like whether to use a state machine to manage menus, what kind of class to use for resource loading, etc. </p>

<p>What is a good design and how would it be implemented? What are some tradeoffs that have to be made and their pros/cons?</p>
","<p>I doubt somebody is going to be able to say 'You have to do this and that and this and this slots with that using pattern X'. </p>

<p>However, some useful resources:<br>
<a href=""http://www.gamedev.net/page/resources/_/technical/game-programming/enginuity-part-i-r1947"" rel=""nofollow noreferrer"">Enginuity</a> - a series of engine building articles on Gamedev.net.<br>
<a href=""http://rads.stackoverflow.com/amzn/click/1584506806"" rel=""nofollow noreferrer"">Game Coding Complete</a> - I own this book, and it goes over every (well, almost) aspect of game programming well. It also does have an engine built throughout the book.<br>
<a href=""http://www.gameenginebook.com/"" rel=""nofollow noreferrer"">Game Engine Architecture</a> - This is another great book for engine design.<br>
<a href=""https://i.stack.imgur.com/81zIY.png"" rel=""nofollow noreferrer"">C4 Engine Layout</a> - Taken from my comment, but this shows a high-level way of fitting each part of the engine together.  </p>

<p>These may be a little too much for what you need, but you can't know too much about something, and I'm sure you'll get a good plan from them.</p>

<p>EDIT: I forgot the Gamedev articles have been archived since the new site, fixed :)</p>
","8508"
"Sorting array of points in clockwise order","21753","","<p>Is there such an algorithm to sort an array of 2D points in clockwise order?<br>
I'm specifically dealing with right triangle in my case so only 3 points.    </p>

<p>However I'm interested in knowing if such an algorithm exist, if not what is a simple way to return the 3 points of my triangle in clockwise order?</p>

<p>Edit: I am trying to compute the points clockwise relative to the centroid of the polygon, which  is convex.</p>

<p><strong>Update:</strong>
This is the implementation I ended up using based on the chosen answer, it's not performance critical and only happens once in a while so it works out.</p>

<pre><code>ArrayList&lt;PVector&gt; pointList = new ArrayList&lt;PVector&gt;();
pointList.add(A);
pointList.add(B);
pointList.add(C);
Collections.sort( pointList, new TriangleVectorComparator(origin) );

return pointList;

// Comparator
package triangleeditor;

import java.util.Comparator;

import processing.core.PVector;

public class TriangleVectorComparator implements Comparator&lt;PVector&gt;  {
    private PVector M; 
    public TriangleVectorComparator(PVector origin) {
        M = origin;
    }

    public int compare(PVector o1, PVector o2) {
        double angle1 = Math.atan2(o1.y - M.y, o1.x - M.x);
        double angle2 = Math.atan2(o2.y - M.y, o2.x - M.x);

        //For counter-clockwise, just reverse the signs of the return values
        if(angle1 &lt; angle2) return 1;
        else if (angle2 &lt; angle1) return -1;
        return 0;
    }

}
</code></pre>
","<p>Your question is not precise enough. An array of points is only « clockwise » or « anti-clockwise » relative to a reference point. Otherwise, any array of three points can always be either CW or CCW. See the following picture: on the left, the points are ordered clockwise; on the right, the exact same points are ordered anticlockwise.</p>

<p><a href=""http://zoy.org/~sam/cw-ccw.png"" rel=""noreferrer"">clockwise or anticlockwise http://zoy.org/~sam/cw-ccw.png</a></p>

<p>In your case, I believe using the barycenter of the points as a reference point is reasonable.</p>

<p>A good method for an unknown number of points could be the following one:</p>

<ul>
<li>let <code>P[0], P[1], ... P[n-1]</code> be the list of points to sort</li>
<li>let M be the barycenter of all points</li>
<li>compute <code>a[0], a[1], ... a[n-1]</code> such that <code>a[i] = atan2(P[i].y - M.y, P[i].x - M.x);</code></li>
<li>sort points relative to their <code>a</code> value, using <code>qsort</code> for instance.</li>
</ul>

<p>However, you can be sure that a good sorting algorithm will perform poorly with three input values compared to an ad-hoc method. Using <code>atan2</code> is still valid, but just don't use <code>qsort</code>.</p>
","13232"
"Is OpenGL appropriate for 2D games?","21715","","<p>I have been teaching myself the OpenGL library for a while now, and want to start making a game. However, for an easier introduction, I want to start with something 2D, such as a top down Pokemon-style game.</p>

<p>Is this a good plan, or is OpenGL made specifically for 3D?</p>
","<p>OpenGL is quite appropriate for 2D games.  Although it is generally used for 3D, the same functionality can be used for 2D games.  That is to say, anything you can do with 3D OpenGL will be applicable with ""2D"" OpenGL.</p>

<p>Some further information can be found at <a href=""http://en.wikibooks.org/wiki/OpenGL_Programming/Modern_OpenGL_Tutorial_2D"" rel=""noreferrer"">this location</a>.</p>

<p>2D OpenGL is achieved in the same manner that 3D OpenGL is.  2D OpenGL is only the application of a technique, that is, rendering the scene on a flat plane, then using and orthographic projection instead of a perspective projection, which, depending on your setup, could distort the scene.</p>

<p>An example:</p>

<p><img src=""https://i.stack.imgur.com/NmREM.jpg"" alt=""Ortho vs perspective""></p>

<p>(a) is a scene in an orthographic projection.  (b) is the same scene, using a perspective projection.  In a 2D game, this can cause mis-positioning of sprites if their depth is altered (which, depending on how you go about development, may be the case).  Using a perspective projection also makes aligning things in screen coordinates more difficult.</p>

<p>In addition, OpenGL carries many, many, <strong>many</strong> benefits with it.  Primarily, hardware acceleration is a huge plus.  There's also a much finer degree of control over what the graphics card does and how it goes about it, allowing for case-specific optimizations</p>
","59164"
"What exactly is UV and UVW Mapping?","21661","","<p>Trying to understand some basic 3D concepts, at the moment I'm trying to figure out how textures actually work. I know that UV and UVW mapping are techniques that map 2D Textures to 3D Objects - Wikipedia told me as much. I googled for explanations but only found tutorials that assumed that I already know what it is.</p>

<p>From my understanding, each 3D Model is made out of Points, and several points create a face? Does each point or face have a secondary coordinate that maps to a x/y position in the 2D Texture? Or how does unwrapping manipulate the model?</p>

<p>Also, what does the W in UVW really do, what does it offer over UV? As I understand it, W maps to the Z coordinate, but in what situation would I have different textures for the same X/Y and different Z, wouldn't the Z part be invisible? Or am I completely misunderstanding this?</p>
","<p>Your understanding is close. Each 3D model is made out of vertexes. Each vertex usually defines the location of a point in space, a normal (used in lighting calculations) and 1 or more texture coordinates. These are generally designated as <em>u</em> for the horizontal part of the texture and <em>v</em> for the vertical.</p>

<p>When an object is textured, these coordinates are used to look up which texel or pixel to plot from the texture. I find it easiest to think of them as percentages or ratios between the left edge of texture (<em>u</em> = 0) and the right edge of the texture (<em>u</em> = 1.0) and from the top of the texture (<em>v</em> = 0) and the bottom of it (<em>v</em> = 1.0). They are interpolated between the vertexes and looked up for each on-screen pixel that is rendered. They can be larger or smaller than these ranges and the render state that is set when the object is rendered specifies what happens. The options for this are CLAMP and REPEAT. Clamping limits the coordinate to either 0 or 1, causing the texture to smear where it is outside of the range. Repeat causes the texture to repeat when it is outside the range; it is effectively the same as grabbing just the decimal portion of the coordinate and using that in its place.</p>

<p>Before the texture coordinates are applied onto an object, they are multiplied by a texture matrix to apply some transformation to them (such as scaling, translation or rotation). This effect is sometimes animated in games to make it appear as though something is moving across an object without having to move the object itself... the texture is simply scrolling across it. When the texture matrix is multiplied by the texture coordinates, it produces 2 values that are used to look up the texel to plot (lets call them <em>s</em> and <em>t</em>). These are generated automatically from <em>u</em> and <em>v</em> even when the texture matrix is not set; it is the equivalent of multiplying <em>u</em> and <em>v</em> by an identity matrix. </p>

<p>This is where the <em>w</em> coordinate comes in, though it isn't used that often. It is an extra parameter to multiply the texture matrix against and is usually used when you want to take perspective into account (such as in <a href=""http://en.wikipedia.org/wiki/Shadow_mapping"">Shadow Mapping</a>). It works the same as when you transform a location in object-space to screen-space via a world-view-projection matrix. By multiplying the UVW with a projection transform, you end up with 2 coordinates, the <em>s</em> and <em>t</em> which are then mapped onto a 2D texture.</p>
","6914"
"OpenGL: why do I have to set a normal with glNormal?","21645","","<p>I'm learning some basics of OpenGL but I'm wondering why there is a call <code>glNormal</code> to set the normal of vertices.</p>

<p>If I create a simple triangle like this:</p>

<pre><code>glBegin(GL_TRIANGLES);
    glVertex3f(0,0,0);
    glVertex3f(1,0,0);
    glVertex3f(0,1,0);
glEnd();
</code></pre>

<p>Shouldn't the normals be defined implicitly by the type of the geometric primitive? If I don't set a normal will OpenGL calculate it?</p>
","<p>Calling <code>glNormal</code> multiple times between <code>glBegin/End</code> allows you to set a normal per vertex instead of per primitive.</p>

<pre><code>glBegin(GL_TRIANGLES);
    glNormal3f(0,0,1);
    glVertex3f(0,0,0);
    glNormal3f(0,0,1);
    glVertex3f(1,0,0);
    glNormal3f(0,0,1);
    glVertex3f(0,1,0);
glEnd();
</code></pre>

<p>For a more complex mesh consisting of multiple triangles you would want the normal at one vertex depend on the other triangles of the surrounding geometry and not just the normal of the triangle it belongs to.</p>

<p>Here is an example of the same geometry with:</p>

<ul>
<li>on the left <strong>per-vertex normals</strong> - so each vertex of a face has a different normal (for this sphere it means all normals point outward from its center), and</li>
<li>on the right <strong>per-face normals</strong> - each vertex gets the same normal value (since you specify it only once, or because it uses the default normal value of <code>(0,0,1)</code>):</li>
</ul>

<p><img src=""https://i.stack.imgur.com/7sklR.jpg"" alt=""per-vertex normals on the left, per-face normals on the right""></p>

<p>The default shade model (<code>GL_SMOOTH</code>) causes the normals of the face's vertices to be interpolated across the face. For the <strong>per-vertex normals</strong> this results in a smooth shaded sphere, but for the <strong>per-face normals</strong> you end up with the characteristic faceted look.</p>
","50656"
"How are sound effects made?","21445","","<p>My friend and I are finishing up our first game right now and I have just discovered that even though he can make some decent music tracks, he has no idea how to make a sound effect. An explosion, for example.</p>

<p>How are sound effects made?</p>
","<p>Do some research on what a Foley Artist does:</p>

<p><a href=""http://en.wikipedia.org/wiki/Foley_artist"">http://en.wikipedia.org/wiki/Foley_artist</a></p>
","1398"
"Is it legal to develop a game using D&D rules?","21422","","<p>For a while now I've been thinking about trying my hand at creating a game similar in spirit and execution to Baldur's Gate, Icewind Dale and offshoots. I'd rather not face the full bulk of work in implementing my own RPG system - I'd like to use D&amp;D rules.</p>

<p>Now, reading about the subject it seems there is something called ""The License"" which allows a company to brand a game as D&amp;D. This license seems to be exclusive, and let's just say I don't have the money to buy it :p.</p>

<p>Is it still legal for me to implement and release such a game? Commercially or open-source? I'm not sure exactly which edition would fit the best, but since Baldur's Gate is based of 2nd edition, could I go ahead an implement that?</p>

<p><strong>in short: what are the issues concerning licensing and publishing when it comes to D&amp;D?</strong></p>

<p>Also: Didn't see any similar question...</p>
","<p>You cannot brand your game as D&amp;D, period.  You can brand your game as being D20 System compatible provided you follow a number of stipulations, not the least of which is that you can't reproduce or include rules for character advancement (XP, gaining levels, etc.) which basically means a player of your game would need a copy of the D&amp;D Player's Handbook to level up; obviously those requirements are not in any way geared towards computer games, and creating one that is in any way officially a part of the D&amp;D universe is going to require you forking over boatloads of cash to WotC.  You can just take the 3rd edition rules under the OGL, so long as your rules are also under the OGL.  I have no idea how that translates to non-print rules, though, and it may well just be fundamentally incompatible (ask a lawyer; programmer nerds won't be able to answer that for you).</p>

<p>You are basically free to use a ruleset that looks an awful lot like D&amp;D at any time, though.  Ever since the first computer RPG, D&amp;D has been ""ripped off"" repeatedly, down to seeing obviously D&amp;D-original mechanics like THAC0 showing up in a lot of old non-TSR-affiliated computer RPGs.  You are legally obligated to avoid WotC trademarks (campaign setting names, iconic creatures like Beholders or Mind Flayers, etc.) and your rules cannot be a direct copy of the D&amp;D source material.  If you've got the same races with the same ability modifiers and the same feat tree and the same prestige classes, you're probably going to be in trouble.  If you've got your own races and classes and a new ""perk"" tree and it just so happens that you have Primary Attributes that mathemtically work like D20's Ability Scores and a level advancement scheme that uses XP to gain levels and you get Primary Attribute increases every X levels and a new perk every Y levels and other class abilities each level... well, that's what just about every other combat-based RPG ever made has done and there's nothing WotC can do about it.  A system that ""feels"" like D&amp;D is one thing so long as nobody is going to look at it and think, ""holy cow, that's D&amp;D!""</p>

<p>I know it's not an answer to your question, but my advice is to just steer clear, if for the following reason only: different gaming mediums have different strengths and weaknesses, and the design choices and compromises made for one medium rarely make sense when transferred to another.  D&amp;D's rules work great in pen-and-paper games but do not work well in a computer game, an ARG or LARP, a card game, or so on.  Even awesome classic D&amp;D computer games like Baldur's Gate made a lot of subtle and not-so-subtle tweaks to the rules and even then still came out with worse experience than what could have been accomplished with a set of mechanics better suited to a point-and-click real-time dungeon crawler.</p>

<p>And really, inventing your own game mechanics isn't terribly hard in the grand scheme of things.  If you can write a game like Baldur's Gate (something a team of fans working on GemRB has still yet to completely finish off even after years of work, and that's ignoring the development of any custom content!), you can absolutely write an RPG rule set.  Doing so is going to take a tiny fraction of the time it'll take you to make the rest of the code and content for your game.</p>
","19725"
"How do you start development of a game?","21375","","<p>When you start a new game project, what do you do first? How do you begin? What gives you the best head start toward completing the project rather than burning out before it gets anywhere?</p>

<p><sub>Mods please help with the tags... I have no clue how to categorize this... :)</sub></p>
","<p>Prototype. Try to implement your game concept using some sort of quick iteration tool. Try python or just some easy-to-work-with open source api to get your ""game idea"" running. Try to simplify as much as possible, use balls instead of characters, get the vision down on some sort of visual representation. That way you can always look at it, discuss it, debate it and give feedback. Put a set timeline for each prototype (maybe 2 days? maybe a week tops?). That way you only get to do as much as you want to do in the prototype.</p>

<p>Sometimes you might be able to plot your idea down on a little piece of paper if it's simple enough. Once you have your idea set, start planning to see what kind of systems and mechanics you need. Try to structure the time-lines for things and see if it's possible to commit to them. If you're a bunch of people that want to make a game together, you need to do this together. Do it over a beer, either in person or using a voice-chat program. Once you know what to do - everyone can start with what they're doing. Make sure that you have communication. Try to have a team-meeting with a frequent interval dependant on how much time you guys want to put down. </p>

<p>If you are making your own game, remember that time is limited and you can't do everything pretty. Maybe spheres and cubes will be enough to get your graphics going if you're a programmer. Realize your limitations and work with them rather than against them.</p>

<p>I hope these few tips help :)</p>
","2483"
"I prefer C/C++ over Unity and other tools: is it such a big downer for a game developer?","21259","","<p>We have a big game project using Unity at school. There are 12 of us working on it. My teacher seems to be convinced it's an important tool to teach students, since it makes students look from the high level to the lower level.</p>

<p>I can understand his view, and I'm wondering: Is unity such an important engine in game development companies? Are there a lot of companies using it because they can't afford to use something else? He is talking like Unity is a big player in game making, but I only see it fit small indie game companies who want to do a game as fast as possible.</p>

<p>Do you think Unity is of that much importance in the industry?
Does it endanger the value of C++ skills?</p>

<p>It's not that I don't like Unity, it's just that I don't learn anything with it, I prefer to achieve little steps with Ogre or SFML instead.</p>

<p>Also, we also have C++ practice exercises, but those are just practice with theory, nothing much.</p>
","<p>Unity is a perfectly valid solution in this context.  Imagine for a second having 12 people, most of whom are still in the process of learning C++, writing a large and complex game application using it.  In the amount of time spent debugging alone you will probably have been able to write <em>another</em> game in Unity.</p>

<p>I'm not saying knowing how to use C++ is not important - it is, especially if you plan on joining the 'mainstream' gaming industry.  But perhaps your instructor is correct in this case - use this project as a learning experience in how to think about architecting a game, and have fun doing it.  In the process, try to hone your C++ skills using exercises or even go so far as to write small games in the meantime using SFML or some other basic framework.</p>

<p>When it is all done, you will have learned a lot, probably become a better programmer, and your next project can be tackled in C++ with a lot more confidence.</p>
","8554"
"Fitting Android game to different screen sizes","21242","","<p>I am making an Android game that is only in portrait screen orientation.  It works great when I run it on my phone, but when I run it on a tablet, even though the screen size is bigger, all of the bitmaps are the same size. Is there any way to make the bitmaps stay the same proportion even on different size screens?</p>
","<p>Unless you're using <a href=""http://developer.android.com/reference/android/widget/AbsoluteLayout.html"">AbsoluteLayout</a> (Usually a very bad idea, as you design your layout using x/y coordinates, which will only suit the device it's been designed on) this should not happen - Android applications automatically adjust to the device's screen-size. However from what you describe (Layout does not adjust to Table Screen), it sounds like AbsoluteLayout might be the issue here.</p>

<p>Make sure that in your layout XML files you're NOT using absolute layouts (this includes setting explicit coordinates/widths/heights on any kind of View). Instead consider using:</p>

<ul>
<li><a href=""http://developer.android.com/reference/android/widget/LinearLayout.html"">LinearLayout</a> - Stacks multiple views horizontally or vertically</li>
<li><a href=""http://developer.android.com/reference/android/widget/FrameLayout.html"">FrameLayout</a> - Usually contains one Child</li>
<li><a href=""http://developer.android.com/reference/android/widget/RelativeLayout.html"">RelativeLayout</a> - Align children relative to each other</li>
<li><a href=""http://developer.android.com/reference/android/widget/TableLayout.html"">TableLayout</a> - A Table-based layout</li>
<li><a href=""http://developer.android.com/reference/android/widget/ScrollView.html"">ScrollView</a> - May contain one child item (such as a LinearLayout) and lets you scroll it's content</li>
</ul>

<p>... whatever best suits your purpose. </p>

<p><strong>If you're new to Android</strong>, then Google offers <a href=""http://developer.android.com/guide/topics/ui/layout-objects.html"">a nice  tutorial</a> that introduces to the different Layout Types mentioned above. More tutorials can be found <a href=""http://developer.android.com/resources/browser.html?tag=tutorial"">here</a>.</p>

<p>Furthermore your API Level would be relevant (to know whether you're using Android 2.x or 4.x - I don't assume 3.x as it's not available for Smartphones) to figure out the cause of your issue.</p>

<p>Are you forcing your Application into Portrait mode by setting:</p>

<pre><code>@Override
protected void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    // Set screen orientation for this dialog to portrait
    setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_PORTRAIT);
}
</code></pre>

<p>... in your Activity that displays the game's views?</p>

<p>Please provide more info on how you're layouting your views (are you using XML for the layout that you later inflate in your Activity, or are you using in-code layouting in your Activity etc....) ? Furthermore: Did you try running your app in a Smartphone - and Tablet-sized Emulator? If yes, does the issue persist?</p>

<hr>

<p><strong>UPDATE: HOW TO SCALE BITMAPS</strong></p>

<p>The OP asked how he can scale the bitmap's he's using in his game. One option (from all I know about the OP's setup): The SurfaceHolder.Callback that you're overriding to display your game and on which you render all the Bitmaps etc... has a method called:</p>

<pre><code>surfaceChanged(SurfaceHolder holder, int format, int width, int height)
</code></pre>

<p>That method gives you the width/height of your surface, so you could now use:</p>

<pre><code>Bitmap.createScaledBitmap (Bitmap src, int dstWidth, int dstHeight, boolean filter)
</code></pre>

<p>from the <a href=""http://developer.android.com/reference/android/graphics/Bitmap.html#createScaledBitmap%28android.graphics.Bitmap,%20int,%20int,%20boolean%29"">Bitmap class</a>. To resize your images in proportion to the size of the surface you're drawing onto.</p>

<p>What you need to do is this: If you know the dimensions of your bitmap in relation to a given screensize, for instance the screen-size of your smartphone. Then you can calculate the target dimensions of the scaled bitmaps. Here is the math (wrapped in an example):</p>

<p>Say you have a <strong>Bitmap A</strong> with the dimensions <strong>25x50 (widthxheight)</strong> which is displayed on a screen with the dimensions 100x200 (widthxheight). For that screen size (100x200) the bitmap has the correct dimensions - now if you want to display the bitmap on a larger screen you need to:</p>

<ul>
<li>Calculate the scale factor for the bitmap size</li>
<li>Maintain the aspect ratio of the bitmap (so it does not get distorted)</li>
</ul>

<p>Say the larger screen is 200x300 (widthxheight) then the scale-factor for the width is:</p>

<pre><code>200(target screen width)/100(default screen width) = 2
</code></pre>

<p>So <strong>2</strong> is our scale-factor for the width and height value of the bitmap, since we need to maintain the aspect ratio of the bitmap, we can simply multiply the scale factor with the width and height of the bitmap:</p>

<pre><code>bitmapWidth * 2 = scaledBitmapWidth
bitmapHeight * 2 = scaledBitmapHeight
</code></pre>

<p>So using our example bitmap A from above and the mentioned formula, the new dimensions of the bitmap would be: 50x100 (widthxheight) because:</p>

<pre><code> 2*25(width) = 50 height
 2*50(height) = 100 height
</code></pre>

<p>Soo now that we know the new size of our bitmap  we simply use the API call I mentioned above and fill in the blanks:</p>

<pre><code>   Bitmap.createScaledBitmap (myBitmap, 50, 100, false)
</code></pre>

<p>myBitmap in the above example is the original bitmap A that had the dimensions 25x50 and is scaled to 50x100 using the above code-snippet.</p>

<hr>

<p><strong>However</strong> - this wouldn't solve your original issue of the application taking up only the upper right corner of a tablet-sized device. To answer that one we'd require answers to the questions we asked you regarding your setup. I'll quickly sum them up here:</p>

<ul>
<li>Are you using a game-engine such as <a href=""http://www.andengine.org/"">AndEngine</a> or <a href=""http://unity3d.com/"">Unity</a> ?</li>
<li>Are you writing your layout in xml? If yes, what's your root-layout for rendering your   your game content?</li>
<li>You mentioned that you're implementing SurfaceHolder.Callback? The width/height provided in the method call of surfaceChanged gives you the size of the surface - is it the same size when your app runs on a smartphone or a tablet?</li>
<li>Do you have any access to the SurfaceView (or whatever is linked to that SurfaceHolder.Callback you're implementing), so we could determine if that's the one rigidly setting the app size to smartphone size.</li>
<li>Do the same resize-issues occur in the emulator with different screen resolutions?</li>
</ul>

<p>A general suspicion: Not every smartphone has the same screen size, in fact there's a wide range of screen sizes, which makes me wonder: Did u ever test your app on a smartphone with a different screen size than your screen? Because - the fact that it fits your screen, but not a tablet, makes me wonder who sets those dimensions and when. Because I doubt that an app can adjust to all smartphone-screen-sizes, but not to tablet sizes - won't make much sense (because they more or less have the same android core running on them, some differences between s.x, 3.x and 4.x aside) UNLESS you're using a framework which does not support (for whatever reason - maybe you'd have to buy tablet support extra or whatever) tablet-sized screen sizes. That's why it's really important to know, whether the app resizes properly on your phone only, or on other smartphones as well. The only way I am aware of how an app can be limited to the screen size of one specific phone is by using AbsoluteLayout and generally absolute dimensions for widgets etc...</p>

<hr>

<p><strong>UPDATE: Scaling x/y Coordinates</strong></p>

<p>In order to adjust your bitmap's location to the screen size, something like the following should do the job:</p>

<ul>
<li>Screen dimensions: 100/200 (width/height)</li>
<li>Bitmap location: x=50/y=100</li>
</ul>

<p>Now, if you increase the screen size, you'd have to scale those x/y values along:</p>

<ul>
<li>Screen dimensions: 200/400 (width/height)</li>
</ul>

<p>The scale factor would be 2, because the width and height equally increased by two. Hence the dimensions would be...</p>

<ul>
<li>Bitmap location: x=100/y=200</li>
</ul>

<p>Another try - this time with different scale factors for width/height</p>

<ul>
<li>Screen dimensions: 100/150 (width/height)</li>
<li>Bitmap location: x=50/y=50</li>
</ul>

<p>If the new target screen is 150/250 then calculations are:</p>

<ul>
<li>Scale factor for width = targetWidth / originalWidth = 1.5</li>
<li>Scale factor for height = targetHeight / originalHeight = 1.666... (Period)</li>
</ul>

<p>Now we need to scale the x/y coordinates, x is scaled using the width-scale and height is scaled using the height-scale, here's the result:</p>

<ul>
<li>x = originalX * 1.5 = 75</li>
<li>y = originalY * 1.666.. (Period) = 83.333... (Period)</li>
</ul>

<p>So the new screen dimensions and the scaled x/y coordinates are:</p>

<ul>
<li>width = 150</li>
<li>height = 250</li>
<li>x = 75</li>
<li>y = 83,333... (Period)</li>
</ul>

<p>To make a long story short, the algorithm for scaling bitmaps is:</p>

<pre><code>X = (targetScreenWidth / defaultScreenWidth) * defaultXCoordinate
Y = (targetScreenHeight / defaultScreenHeight) * defaultYCoordinate
</code></pre>
","29784"
"How Do I Do Alpha Transparency Properly In XNA 4.0?","21198","","<p>Okay, I've read several articles, tutorials, and questions regarding this.  Most point to the same technique which doesn't solve my problem.  I need the ability to create semi-transparent sprites (texture2D's really) and have them overlay another sprite.  </p>

<p>I can achieve that somewhat with the code samples I've found but I'm not satisfied with the results and I know there is a way to do this.  In mobile programming (BREW) we did it old school and actually checked each pixel for transparency before rendering.  </p>

<p>In this case it seems to render the sprite below it blended with the alpha above it.  This may be an artifact of how I'm rendering the texture but, as I said before, all examples point to this one technique.  Before I go any further I'll go ahead and paste my example code.</p>

<pre><code>    public void Draw(SpriteBatch batch, Camera camera, float alpha)
    {
        int tileMapWidth = Width;
        int tileMapHeight = Height;

        batch.Begin(SpriteSortMode.Texture,
            BlendState.AlphaBlend,
            SamplerState.PointWrap,
            DepthStencilState.Default,
            RasterizerState.CullNone,
            null, camera.TransformMatrix);

        for (int x = 0; x &lt; tileMapWidth; x++)
        {
            for (int y = 0; y &lt; tileMapHeight; y++)
            {
                int tileIndex = _map[y, x];

                if (tileIndex != -1)
                {
                    Texture2D texture = _tileTextures[tileIndex];

                    batch.Draw(
                        texture,
                        new Rectangle(
                            (x * Engine.TileWidth),
                            (y * Engine.TileHeight),
                            Engine.TileWidth,
                            Engine.TileHeight),
                        new Color(new Vector4(1f, 1f, 1f, alpha )));
                }
            }
        }

        batch.End();

    }
</code></pre>

<p>As you can see, in this code I'm using the overloaded SpriteBatch.Begin method which takes, among other things, a blend state.  I'm almost positive that's my problem.  I don't want to BLEND the sprites, I want them to be transparent when alpha is 0.  In this example I can set alpha to 0 but it still renders both tiles, with the lower z ordered sprite showing through, discolored because of the blending.  This is not a desired effect, I want the higher z-ordered sprite to fade out and not effect the color beneath it in such a manner.</p>

<p>I might be way off here as I'm fairly new to XNA development so feel free to steer me in the correct direction in the event I'm going down the wrong rabbit hole.</p>

<p>TIA</p>
","<p>If I follow the issue correctly try calling Begin with BlendState.NonPremultiplied. This article may also help shed some light on how alpha blending works in XNA:</p>

<p><a href=""http://blogs.msdn.com/b/shawnhar/archive/2010/04/08/premultiplied-alpha-in-xna-game-studio-4-0.aspx"">http://blogs.msdn.com/b/shawnhar/archive/2010/04/08/premultiplied-alpha-in-xna-game-studio-4-0.aspx</a></p>
","7105"
"Free ebooks about game development","21169","","<p>Are there good free ebooks on game development? I don't care if they are theoretical or technology specific, I want to start reading one free book that worth it.</p>
","<p><strong>Game Design</strong></p>

<ul>
<li><a href=""http://directory.vancouver.wsu.edu/people/sue-peabody/art-computer-game-design"" rel=""nofollow noreferrer"">The Art of Computer Game Design</a> by Chris Crawford (1984) [PDF]</li>
<li><a href=""http://erasmatazz.com/page78/page146/page147/BalanceOfPower.html"" rel=""nofollow noreferrer"">Balance of Power</a> by Chris Crawford (1986) [TXT]</li>
<li><a href=""http://www.hyw.com/Books/WargamesHandbook/Contents.htm"" rel=""nofollow noreferrer"">The Complete Wargames Handbook</a> (Second Edition) by James F. Dunnigan (1997) [HTML]</li>
</ul>

<p><strong>Programming</strong></p>

<ul>
<li><a href=""http://developer.nvidia.com/GPUGems/gpugems_part01.html"" rel=""nofollow noreferrer"">GPU Gems</a> (2004), <a href=""http://developer.nvidia.com/GPUGems2/gpugems2_part01.html"" rel=""nofollow noreferrer"">GPU Gems 2</a> (2005), <a href=""http://developer.nvidia.com/GPUGems3/gpugems3_part01.html"" rel=""nofollow noreferrer"">GPU Gems 3</a> (2007) [HTML]</li>
<li><a href=""http://developer.nvidia.com/CgTutorial/cg_tutorial_chapter01.html"" rel=""nofollow noreferrer"">The Cg Tutorial</a> by Randima Fernando and Mark J. Kilgard (2003) [HTML]</li>
<li><a href=""http://www.pangeasoft.net/book/buy.html"" rel=""nofollow noreferrer"">Pangea Software's Ultimate Game Programming Guide for Mac OS X</a> by Brian Greenstone (2004) [PDF]</li>
<li><a href=""http://inventwithpython.com/"" rel=""nofollow noreferrer"">Invent Your Own Computer Games with Python</a> by Al Sweigart (2010) [PDF]</li>
<li><a href=""http://www.gamedev.net/community/forums/topic.asp?topic_id=500691"" rel=""nofollow noreferrer"">ShaderX2: Shader Programming Tips and Tricks with DirectX 9.0</a> by Wolfgang Engel (2003) [PDF]</li>
<li><a href=""http://www.gamedev.net/community/forums/topic.asp?topic_id=500691"" rel=""nofollow noreferrer"">ShaderX2: Introductions and Tutorials with DirectX 9.0</a> by Wolfgang Engel (2003) [PDF]</li>
<li><a href=""http://tog.acm.org/resources/shaderx/Direct3D.ShaderX.Vertex.and.Pixel.Shader.Tips.and.Tricks_Wolfgang.F.Engel_Wordware.Pub_2002.pdf"" rel=""nofollow noreferrer"">Direct3D ShaderX: Vertex and Pixel Shader Tips and Tricks by Wolfgang Engel</a> (2002) [PDF]</li>
<li><a href=""http://www.gamedev.net/reference/articles/article1698.asp"" rel=""nofollow noreferrer"">Michael Abrash's Graphics Programming Black Book by Michael Abrash</a> (1997) [PDF]</li>
<li><a href=""http://www.fastgraph.com/makegames/sidescroller/index.html"" rel=""nofollow noreferrer"">Action Arcade Adventure Set</a> by Diana Gruber (1994) [HTML]</li>
</ul>

<p><strong>Art</strong></p>

<ul>
<li><a href=""http://wiki.yoyogames.com/index.php/Ari_Feldman%27s_Book_on_Game_Graphics"" rel=""nofollow noreferrer"">Designing Arcade Computer Game Graphics</a> by Ari Feldman (2000) [PDF]</li>
</ul>

<p><strong>Culture and Studies</strong></p>

<ul>
<li>ETC Press: ETC Press have been published plain text version of their books for free.

<ul>
<li><a href=""http://www.etc.cmu.edu/etcpress/wellplayed1.0"" rel=""nofollow noreferrer"">Well Played 1.0</a> by Drew Davidson et al (2009)</li>
<li><a href=""http://www.etc.cmu.edu/etcpress/beyondfun"" rel=""nofollow noreferrer"">Beyond Fun: Serious Games and Media</a> by Drew Davidson et al (2008)</li>
<li><a href=""http://www.etc.cmu.edu/etcpress/content/ludoliteracy-defining-understanding-and-supporting-games-education"" rel=""nofollow noreferrer"">Ludoliteracy: Defining, Understanding, and Supporting Games Education</a> by José P. Zagal (2010)</li>
<li><a href=""http://www.etc.cmu.edu/etcpress/content/toward-ludic-architecture"" rel=""nofollow noreferrer"">Toward a Ludic Architecture: The Space of Play and Games</a> by Steffen P. Walz (2010)</li>
<li><a href=""http://www.etc.cmu.edu/etcpress/content/cross-media-communications"" rel=""nofollow noreferrer"">Cross-Media Communications</a> by Drew Davidson et al (2010)</li>
</ul></li>
<li><a href=""http://stevenpoole.net/blog/trigger-happier/"" rel=""nofollow noreferrer"">Trigger Happy</a> by Steven Poole (2001) [PDF]</li>
<li><a href=""http://www.futureofthebook.org/gamertheory2.0/"" rel=""nofollow noreferrer"">Gamer Theory 2.0</a> by McKenzie Wark (2007) [HTML]</li>
<li><a href=""http://www.sirlin.net/ptw"" rel=""nofollow noreferrer"">Playing to Win</a> by David Sirlin (2006) [HTML]</li>
<li><a href=""http://www.lulu.com/product/file-download/psx-the-guide-to-the-sony-playstation-(pdf-version)/243124"" rel=""nofollow noreferrer"">PSX: The Guide to the Sony Playstation</a> By Kevin Bryan (2005) [PDF]</li>
</ul>
","1581"
"What is the difference between Unity's Sprite and Texture2D classes?","21119","","<p>Unity has both a <a href=""http://docs.unity3d.com/Documentation/ScriptReference/Texture2D.html""><code>Texture2D</code></a> class and a <a href=""http://docs.unity3d.com/Documentation/ScriptReference/Sprite.html""><code>Sprite</code></a> (with related <code>SpriteRenderer</code>). What is the difference between these two classes? Both represent an image, for 2D games should I favor one over the other?</p>

<p>Is the main difference between the two that using <code>Sprite</code> I don't need to create the ""billboard"" quad myself? And that the <code>Sprite</code> is always rendered directly against the camera?</p>
","<p>You are correct - somewhat. Sprites, by default are rendered directly against the camera, however you can easily change this if you are using the Sprite Renderer in a 3D scene. </p>

<p>Sprites are physical objects in your scene, whereas Texture2D is exactly what it says it is. A texture. A texture must be attached to a material, and the material to a game object(e.g a plane). </p>

<p>Back in Unity 3.x days you didn't have sprite support right out of the box so you had to roll your own Sprite Manager/Class(or you had the option of buying an asset off the asset store that attempted to remedy this annoyance). Unity was really never meant to support 2D games(nevertheless developers found ways to make it happen), until 4.x, when the Unity Developers finally provided built-in support for 2D games(sprites, sprite sheets, 2D physics).</p>

<p>If you're doing a 2D game, always try to use the Sprite class. It's better than rolling your own, and offers more than enough. </p>
","68878"
"How to render a texture partly transparent?","20994","","<p>Good Morning StackOverflow, I'm having a bit of a problem right now as I can't seem to find a way to render part of a texture transparently with openGL.</p>

<p>Here is my setting : I have a quad, representing a wall, covered with <a href=""https://i.stack.imgur.com/m0KqO.png"" rel=""noreferrer"">this texture</a> (converted to PNG for uploading purposes). Obviously, I want the wall to be opaque, except for the panes of glass. There is another plane behind the wall which is supposed to show a landscape. I want to see the landscape from behind the window. Each texture is a TGA with alpha channel.</p>

<p>The ""landscape"" is rendered first, then the wall. I thought it would be sufficient to achieve this effect but apparently it's not the case. The part of the window supposed to be transparent is black and the landscape only appears when I move past the wall.</p>

<p>I tried to fiddle with GLBlendFunc() after having enabled it but it doesn't seem to do the trick.</p>

<p>Am i forgetting an important step ?</p>

<p>Thank you :)</p>
","<p>In addition to everything you've stated (textures with alpha channels, drawing the landscape before drawing the wall+window), you also need to do two more things.</p>

<p>First, you need to enable OpenGL's blending functionality:</p>

<pre><code>glEnable(GL_BLEND);
</code></pre>

<p>Second, you need to tell OpenGL how to calculate the colors of blended pixels (which OpenGL calls ""fragments"", incidentally).  In this case, you'll be fine with something simple like this:</p>

<pre><code>glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA);
</code></pre>

<p>Once blending is turned on, OpenGL will combine pixel colors according to the function parameters you give it in glBlendFunc.  Specifically, it will do ""source.color * source.alpha + destination.color * (1-source.alpha)"", where ""source"" is the texture you're currently rendering, and ""destination"" is the color already in the framebuffer (the landscape).  So wherever your alpha channel is white, you'll get the wall color, and wherever the alpha channel is black, you'll get the landscape color.  If the alpha channel is grey, then you'll get some cross-fade between the two colors.</p>

<p>If your window is fully transparent then there are other ways to do this, where the order in which you draw the two polygons isn't important, but that starts getting into more advanced concepts such as alpha thresholds.  Probably not needed for your current situation.</p>
","13795"
"Unreal Engine 3 vs id Tech 3 vs Unity","20931","","<p>I'm trying to decide which engine I should start using to try to start building a game in.</p>

<p>I had chosen <a href=""http://unity3d.com/"">Unity</a>, but upon hearing that <a href=""http://udk.com/"">Unreal Engine 3</a> had just become kinda free to use, I found myself questioning my decision.</p>

<p>Technically Unreal is still the most expensive commercially, then Unity, then <a href=""http://en.wikipedia.org/wiki/Id_Tech_3"">id Tech 3</a> (free).</p>

<p>But, it also could be the fastest to work in? Or is just the most powerful, but Unity actually does so much for you, that it makes the most sense to work with this, and take a hit on performance/tuning (like Java/C#).</p>

<p>Thoughts please, can anyone speak from experience of all three?</p>

<p>I have experience with modding since the doom days, then in Quake 1 and Half Life. I also have experience in 3DS Max. I don't have a desire at this point my life to really get into the nitty gritty of C++ animation and rendering issues, I'd rather get something up and running quickly, to see if it's possible. But Unreal experience tempts me greatly.</p>
","<p>UDK, id Tech 3, and Unity are all vastly different tools.</p>

<p>With UDK, you have script-level access, not native. As such, you are somewhat limited in the modifications you can perform. Additionally, UnrealScript is extremely slow; as such, it's difficult to optimize any product you do end up creating.</p>

<p>Overall, it's not very well crafted for anything that drastically doesn't match Epic's product line.</p>

<p>id Tech 3 will give you C++ access. That being said, it's much older technology, the tools aren't as robust, etc. Personally, I've never used it; but, it's not something you're going to build a commercial product with (unless you're looking for something scaled back. Check out this list: <a href=""http://en.wikipedia.org/wiki/Id%5FTech%5F3#Projects%5Fbased%5Fon%5Fthe%5FGPL%5Fsource%5Frelease"">http://en.wikipedia.org/wiki/Id%5FTech%5F3#Projects%5Fbased%5Fon%5Fthe%5FGPL%5Fsource%5Frelease</a>).</p>

<p>As for Unity? It's a great place for a beginner/someone that doesn't want to have to delve into the complex details of an engine. Additionally, it's more flexible.</p>

<p>Can you release a triple-A title on it? No. That being said, you're not going to be using it for that.</p>

<p>With the ultimate goal of educating yourself without having to dive into C++, I'd highly recommend Unity.</p>
","15156"
"most efficient way to create a grid system in unity","20866","","<p>I'm creating a little tower defence game to get myself acquainted with unity.</p>

<p>At first I was going to emulate a grid system by capturing touches / mouse clicks and rounding the coordinates to the nearest whole numbers. This is very low cost and works well for placing things, however I'm a bit of an AI geek and I've decided to make a more tangible grid so that the agents can run searches on it for pathfinding.</p>

<p>For this I'll need a grid of nodes and for those nodes to have a bit of information attached. Would it be a much better idea to do this entirely in code? Or could I get away with placing actual cubes in a big grid on the map?</p>

<p>This would certainly be easy as then I could ray cast against them - but I've tried this and rendering that many cubes slows down the game a lot!</p>

<p>I suppose my question is - is it unnecessarily expensive to have a load of cubes set up like this, but not rendered? Or should the cost of having a load of cube shaped collision volumes be only marginally more expensive than emulating this in code? (if at all...)</p>

<p>Also as a side question - should I be able to render say, 200 cubes and have a smooth game? Am I missing some instancing options? I presumed things would be automatically instanced.</p>
","<p>I am going to attack your question out of order, partly because I am seeing issues with the way I think your attacking the problem.</p>

<blockquote>
  <p>This [cubes] would certainly be easy as then I could ray cast against them - but I've tried this and rendering that many cubes slows down the game a lot!</p>
</blockquote>

<p>I don't know why this would be slow, unless you are constantly creating, altering, and destroying these cubes at run-time, but even then 200 cubes is child's play to unity (when you start getting to say 10,000 simultaneously interacting items then Unity can start to have problems.</p>

<p>You don't need to have physical ""objects"" in your world to ray-cast between them. you simply need to have objects in your world (Empty GameObjects)</p>

<blockquote>
  <p>I suppose my question is - is it unnecessarily expensive to have a load of cubes set up like this, but not rendered? Or should the cost of having a load of cube shaped collision volumes be only marginally more expensive than emulating this in code? (if at all...)</p>
</blockquote>

<p>200 cubes (even 200 RigidBodies) is not that much in Unity. on the part about emulating in code depends on what you absolutely need your nodes to know.</p>

<blockquote>
  <p>Also as a side question - should I be able to render say, 200 cubes and have a smooth game? Am I missing some instancing options? I presumed things would be automatically instanced.</p>
</blockquote>

<p>instancing in Unity is based around the prefab system (basically make up your thing then create a prefab, and then use it again, and again in your game/scenes)</p>

<blockquote>
  <p>At first I was going to emulate a grid system by capturing touches / mouse clicks and rounding the coordinates to the nearest whole numbers. This is very low cost and works well for placing things, however I'm a bit of an AI geek and I've decided to make a more tangible grid so that the agents can run searches on it for pathfinding.</p>
</blockquote>

<p>if you can mask your entire game level/scene in a fixed grid you should in theory be able to use standard grid traversal, but all of your book keeping will probably need to be specificly value centric, and in the end run this is not going to be very clean/efficient.</p>

<blockquote>
  <p>For this I'll need a grid of nodes and for those nodes to have a bit of information attached. Would it be a much better idea to do this entirely in code?</p>
</blockquote>

<p>yes, no, maybe it depends on what information you absolutely <strong>need</strong> your nodes to have (the simplest node I can think of for a tower defense game is  is a point, a bool occupied, and a bool reachable)</p>

<blockquote>
  <p>Or could I get away with placing actual cubes in a big grid on the map?</p>
</blockquote>

<p>Why would you do this? I see no value besides having something that you can physically see in the editor, and when it comes time to run the game you wont be doing anything with these cudes as cubes, so why have them in the first place if your just going to take away their collision, and rendering. All you have left is a transform which you could have right away by having empty gameObjects.</p>

<p>the easiest way to do nodes in Unity is to create empty gameObjects(mainly for the position), and then give them a script for all the variables you <strong>need</strong>, and then put all those nodes onto their own layer.</p>

<p><strong>EDIT</strong> (In response to request for more detail in comment):</p>

<blockquote>
  <p>Isn't making a cube, and taking away its collision, and rendering the same as creating an empty gameObject?</p>
</blockquote>

<p>yes, and no. yes its the same in terms of physics, and rendering, but no in terms of the engines book-keeping. every fixedUpdate (especially in non-release mode) the system takes all components that a object has, and the same for its children, and puts them to be calculated, and then if any of those are not active throws it away. so its still trying to do stuff with the inactive components its just not that much. if you multiply this enough times it can amount to maybe an extra half second per frame, but that's probably up there.</p>

<blockquote>
  <p>Are empty gameObjects by default cube shaped?</p>
</blockquote>

<p>No. from an application standpoint think of an empty gameObject as a modifier that is modifying something, or nothing. I can create an empty gameObject, and then move it around the world/scene, and then I can rotate it, and scale it, but if it doesn't have any children nothing happens, but the changes are recorded. then if I take, and create a sphere, and make it a child of that empty gameObject then that child will take on those modifications, and have its own values stored with respect to its parent, but in essence of physical logic that empty gameObject is nothing (no size, shape, or anything), but it does have a transform, and can receive components.</p>

<blockquote>
  <p>Because if they're not the benefit of a grid of cubes would be the foundations of a navMesh.</p>
</blockquote>

<p>your right to a point. when I say the word grid most people think about drawing boxes, and having all of those boxes be uniform dimensions, but when we go to put things in those boxes all we really care about is a point in space  (usually the center for 3D, but for 2D sprites top left) so if we take away the boxes, and instead only keep those points in space we still have a grid, we just don't have boxes.</p>

<p>You can still use all your favorite pathfinding algorithms with points/nodes that you did with a grid, and more. Calculate the distance between them, and apply a weight to that distance (dijoksra, and A*), Allow the agent to consider multiply nodes at once (fuzzy logic), track the players movements through a set grid pattern, and then give a weight to a set of rules that correspond, and then have the agent chose a response based on the highest weight (exert systems).</p>

<p>A grid is just a visual representation that the player may never see (unless you actually want to draw those boxes on the screen, in 2D ok, but if your in a 3D perspective that can get confusing quickly especially if the camera can rotate).</p>

<blockquote>
  <p>could you explain what you mean when you said - 'but all of your book keeping will probably need to be specificly value centric, and in the end run this is not going to be very clean/efficient.""</p>
</blockquote>

<p>I meant having each agent have to do the same rounding that you do for your mouse clicks which is very value centric, and you end up having to do a lot of the same clean up work of hard coded values, and you get the same end run checks as when doing <code>if(X&gt;300){//do something}</code>. but if you do just find the nodes nearest to here (its up to you if you want diagonals), and if you really wanted to you could use the same logic for mouse clicks instead of rounding values just ray-cast to find the nearest node.</p>
","29324"
"Which Unreal Engine 4 project files can I ignore in source control?","20839","","<p>I want to put an Unreal Engine 4 project under source control with git. (I know the editor has Perforce and Subversion support, but I don't care for those.)</p>

<p>What folder and files do I include in the repository and which can I ignore?</p>

<p>The way I see it, the following is needed: <code>Config</code>, <code>Content</code>, <code>Source</code>, <code>*.sln</code>, <code>*.uproject</code></p>

<p>Things that I can ignore: <code>Binaries</code>, <code>DerivedDataCache</code>, <code>Intermediate</code>, <code>Saved</code>, <code>*.suo</code>, <code>*.sdf</code>, <code>*.opensdf</code></p>

<p>Is this correct?</p>
","<p>I'm using GitHub for Windows which generates a nice gitignore ignoring most extraneous files like log files or files specific to VS that don't need to be shared.</p>

<p>From what I can gather from <a href=""https://docs.unrealengine.com/latest/INT/Engine/Basics/DirectoryStructure/index.html"">this page in the Unreal docs</a>, you can probably ignore these directories:</p>

<pre><code>DerivedDataCache
Intermediate
Saved
</code></pre>

<p>I'm not going to ignore Binaries, if only because I'm working with a level designer who doesn't have VS and so will need the DLL files I build (I assume, I could be wrong).</p>

<p>Again keep in mind I'm using Git for Windows that generates gitignore for you when you create a project, and it's pretty big. I'm pretty much only committing the following (where ""ReallyCoolGame"" is the name of your project):</p>

<pre><code>.gitattributes
.gitignore
Binaries
Config
Content
Source
ReallyCoolGame.sln
ReallyCoolGame.uproject
</code></pre>

<p>I've only just committed this myself, and I've yet to test it with my level designer, so caveat emptor.</p>

<p>Also, I'm referring to a project created using the first-person C++ template, which gets saved to: <code>E:\Documents\Unreal Projects\ReallyCoolGame</code> (<code>My Documents == E:\Documents</code> on my machine) and not within the Unreal Engine source directory structure.</p>

<p>Edit: I also don't want to include all the default content, so I'm going to have a subdirectory within Content just for the game assets themselves with the same name as the project, and ignore all other subdirectories of Content. So the lines at the top of my .gitignore now look like:</p>

<pre><code>DerivedDataCache
Intermediate
Saved
Content/*
!Content/ReallyCoolGame
</code></pre>

<p>And the level designer will put all of our assets in <code>Content/ReallyCoolGame</code> instead.</p>

<p><strong>UPDATE:</strong></p>

<p>The Intermediate directory actually contains Visual Studio's project files, which are needed to build the project. If the Intermediate directory is ignored, you won't be able to build the project because the Visual Studio solution won't find it. But there are two easy workarounds for this.</p>

<p>1) Just don't ignore the Intermediate directory. Of course in that case Visual Studio will still find all project files it needs and be able to build the project.</p>

<p>2) This one is even better, especially for version control: Open your project in Unreal Engine 4 editor and go to ""File > Refresh Visual Studio Project"". This will generate an all new solution file for you, which means you won't even need to commit it and can add the *.sln in the project folder to the .gitignore file.</p>

<p>Also *.suo and *.sdf files can be ignored in general, since Visual Studio just generates new ones when you open your solution. </p>
","72293"
"What is the point of a borderless fullscreen window?","20743","","<p>Quite a lot of game allow user to play in a ""borderless fullscreen window"" instead of a ""fullscreen mode"". I've been wondering. Why would one prefer a fullscreen window over the ""built-in"" fullscreen mode? </p>

<p>Simple test of my own showed me, that using fullscreen mode instead yields better performance. I also tried to search on Google and on SO, but most answers are gaming related or on how to actually create those windows in API X,Y or Z.</p>

<p>So what is the point of having a borderless fullscreen window? Are there any technical reasons?</p>
","<p>""Regular"" fullscreen involves taking ""exclusive"" access of the GPU, which means a lot more work in handling resolution switching, resource management (in older APIs, in particular) and so on, <em>especially</em> around supporting correct alt-tab behavior. This might seem odd at first, but it arises because when you lose exclusivity (when alt-tabbed out), your game's GPU resources are effectively evicted and must be restored when you tab back in.</p>

<p>A ""borderless fullscreen"" window is just a regular window, with window chrome disabled, that is the size of the whole screen. This means it acts just like a regular window and doesn't incur the extra complication and overhead of exclusive GPU access, which makes things easier for developers at the cost of some negligible performance. This is the main <em>technical</em> reason: less work.</p>

<p>It also makes things easier on users, usually, because many games that use exclusive fullscreen modes also happen to not handle alt-tab very well, and crash, or act oddly when restored to fullscreen. This can be exceedingly annoying for players who want to alt-tab to look at GameFAQs, chat on Discord or IRC, or whatever. It's also more friendly to multi-monitor setups.</p>
","136368"
"Getting Started with 2d Game Dev (C++): DirectX or OpenGL?","20668","","<p>So, i'm a student looking to get my foot in the door of game development and im looking to do something 2D, maybe a tetris/space invaders/something-with-a-little-mouse-interaction clone. </p>

<p>I pointed my searches in the direction of C++ and 2d and was eventually lead to DirectX/OpenGL</p>

<p>Now as i understand it, all these packages will do for me is draw stuff on a screen. And thats all i really care about at this point. Sound isn't necessary. Input can be handled with stdlib probably. </p>

<p>So, for a beginner trying to create a basic game in C++, would you recommend DirectX or OpenGL? Why? What are some key feature differences between the two? Which is more usable?</p>
","<p>I'd recommend SDL (<a href=""http://www.libsdl.org/"" rel=""nofollow"">http://www.libsdl.org/</a>) for 2D, it was where I first started with graphics stuff and it was pretty easy to use, even though I barely knew C++ at the time.</p>

<p><a href=""http://cone3d.gamedev.net/cgi-bin/index.pl?page=tutorials/gfxsdl/index"" rel=""nofollow""><strike>This</strike></a> <a href=""http://web.archive.org/web/20060925173826/http://cone3d.gamedev.net/cgi-bin/index.pl?page=tutorials/gfxsdl/index"" rel=""nofollow"">(mirror)</a> is the set of tutorials that I started with and found very useful (they were a bit dated even ~4 years ago when I worked through them, but I don't think SDL has changed much and they should still be relevant).</p>

<p>SDL also does input handling and SDL_Mixer can do basic audio.</p>

<p>I've never worked with DirectDraw or OpenGL for 2D stuff, so I can't comment there, but I can definitely recommend SDL.</p>
","2043"
"Generating tile map","20652","","<p>I am programming a tile based game and I have some basic tiles (grass, dirt, etc..), but I can't figure out how to make good random map generation, because when I do some really random selection, if the tile should be grass/dirt, I get this:</p>

<p><img src=""https://i.stack.imgur.com/oWTEZ.png"" alt=""In-game picture""></p>

<p>I understand why this is happening, but what I want is to create some random continuous areas of grass or dirt. Something that would make more sense, like this:</p>

<p><img src=""https://i.stack.imgur.com/duxwd.png"" alt=""Desired result""></p>
","<p>What you could do is randomly generate a Voronoi map like this:</p>

<ol>
<li>Picking random <code>center points</code> (see the black dots) and randomly decide if they are grass or dirt.</li>
<li>Then for over all tiles, check if it's closest to a <code>center point</code> of dirt or a grass.</li>
<li>Done!</li>
</ol>

<p>If what you did previously is ""flip a coin"" for each tile (noise), generating a Voronoi diagram will provide a much better result.</p>

<p>You could improve on this by dividing the <code>center points</code> into <code>islands</code> with an algorithm that:</p>

<ol>
<li>Picks a small group of <code>centers points</code> and designates them as <code>leaders</code>.</li>
<li>Iteratively adds a random adjacent undecided center point each turn.</li>
<li>Done!</li>
</ol>

<p><img src=""https://i.stack.imgur.com/GsCYW.jpg"" alt=""enter image description here""></p>
","79050"
"How do I make a background fill the whole screen in Libgdx?","20600","","<p>I'm using this code to set a 800x420 image to be full screen:</p>

<pre><code>public void show() {
    float w = Gdx.graphics.getWidth();
    float h = Gdx.graphics.getHeight();
    camera = new OrthographicCamera(1, h / w);
    batch = new SpriteBatch();
    texture = new Texture(Gdx.files.internal(""images/splashatlas/splashatlas1.png""));
    texture.setFilter(TextureFilter.Linear, TextureFilter.Linear);
    TextureRegion region =
    new TextureRegion(texture, 0, 0, 800, 420);
    sprite = new Sprite(region);
    sprite.setSize(0.9f,
            0.9f * sprite.getHeight() / sprite.getWidth() );
            sprite.setOrigin(sprite.getWidth() / 2,
            sprite.getHeight() / 2);
            sprite.setPosition(-sprite.getWidth() / 2,
            -sprite.getHeight() / 2);
}


public void render(float delta) {
    Gdx.gl.glClearColor( 1f, 1f, 1f, 1f );
    Gdx.gl.glClear( GL20.GL_COLOR_BUFFER_BIT );
    batch.setProjectionMatrix(camera.combined);
    batch.begin();
    sprite.draw(batch);
    batch.end();
}
</code></pre>

<p>But on real device it looks like this:</p>

<p><img src=""https://i.stack.imgur.com/W6NsH.jpg"" alt=""On a real device""></p>

<p>I tried to <code>setSize</code> with different parameters:</p>

<pre><code>    sprite.setSize(1.0f,
            1.0f  );
</code></pre>

<p>Now it's fullscreen, but it's really stretched:</p>

<p><img src=""https://i.stack.imgur.com/ek0Yp.jpg"" alt=""fullscreen, but stretched""></p>

<p>What is the way to set a background to be full screen? I want it to look like this:</p>

<p><img src=""https://i.stack.imgur.com/oxml7.jpg"" alt=""what I want""></p>
","<p>the problem was in my images size , i set the viewport to be 800x480 but the images size was 800x420 , i just changed the images size to 800x480 and in setSize() i changed it like the following :</p>

<pre><code>sprite.setSize(1f,
            1f * sprite.getHeight() / sprite.getWidth() );
</code></pre>

<p>and its work perfectly now.</p>
","71255"
"How do I linearly interpolate between two vectors?","20572","","<p>I have a velocity vector where my client is at and where its going, and I have the same vector that comes from the server telling where the client should be. Sometimes its a bit different, so I want to interpolate between my current position to the server correct position.</p>

<p><img src=""https://i.stack.imgur.com/v5gWI.png"" alt=""enter image description here""></p>

<p>The black arrow is the client velocity vector, the red arrow is the client velocity  vector on the server and the blue arrow is the one that I want to calculate and interpolate to.</p>

<p>How do I calculate the blue vector? Then, how can I linear interpolate between them?</p>
","<p>Blue vector can be calculated easily: red - black (the sign between vectors is minus). But if you want just to interpolate between black and red vector, you don't have to calculate it. Linear interpolation is just linear combination. So you can just take: alpha * black + (1 - alpha) * red, where alpha has to be from interval &lt;0,1>. If alpha will be 1, then you will get black vector, when alpha is 0, you will get red vector. </p>

<p>And if I understood it right, you will interpolate between these vectors in time. So just choose right increment of alpha in time.</p>

<p>Did I understand you right? Or did you meant something completelly diffent?</p>
","18617"
"How do you prevent your JavaScript / HTML5 web game from being copied or altered?","20554","","<p>I'm in the middle of planning a game built using JavaScript and HTML5.  </p>

<p>I'm having trouble understanding how you could prevent someone from simply copying the JavaScript from the web server and either making their own game with it (not my biggest concern), or substituting their own JavaScript functions and dashing any hope for reliable clients in the wild if the game was to eventually support multiplayer.</p>

<p>Can anything be done to prevent just anybody from reading the JavaScript?  </p>

<p>If not, should all game processing be taking place on a server somewhere with the client's only responsibilities being capturing user input and drawing graphics?  </p>
","<p>Keep all your game data and logics on the server. Part of the game which is on the client side can be copied using appropriate tools anyway (even if it's in Flash or Java), so just accept it and don't care too much about it.</p>

<p>To keep your javascript less copyable, because of bad readability, you can <a href=""http://www.maxkiesler.com/2007/11/04/how-to-minimize-your-javascript-and-css-files-for-faster-page-loads/"">minify it</a>. That's a good practice anyway as it makes the gaming site download faster.</p>
","3697"
"What are some good resources for building a voxel engine?","20511","","<p>What are some good resources (tutorials, code, papers, etc.) for learning about <a href=""http://en.wikipedia.org/wiki/Voxel"">voxel</a> rendering?</p>
","<p>I recently did some experimentation with voxels for rendering terrain, with support for overhangs. I pretty much used these articles to build my prototype:</p>

<ul>
<li>This <a href=""http://http.developer.nvidia.com/GPUGems3/gpugems3_ch01.html"">GPU gems 3 chapter</a> on generating procedural terrain on the GPU. Even though my solution was CPU based (I work with shader model 3, so I couldn't reuse any of their shaders). There's a lot of good information buried in here!</li>
<li>The wikipedia entry on <a href=""http://en.wikipedia.org/wiki/Marching_cubes"">the marching cubes</a> algorithm. Great set of references, such as to <a href=""http://users.polytech.unice.fr/~lingrand/MarchingCubes/algo.html"">this site that has a good pictorial overview</a> on how things work.</li>
<li>For any procedural work, you're going to need a good noise library like <a href=""http://libnoise.sourceforge.net/"">Lib noise</a> (<a href=""http://libnoisedotnet.codeplex.com/"">also has a c# version</a>).</li>
</ul>

<p>Something to look out for, I could never get normal generation to work correctly once I had generated a mesh from my voxels. If anyone can give any pointers for this, I'd be grateful. </p>
","311"
"I can't figure out how to animate my loaded model with Assimp","20279","","<p>I have loaded in a model to my C++ OpenGL game. It is a COLLADA file type that I have loaded, and I setup an animation under blender for the file. The problem is I don't know how to animate the model. The Assimp documentation didn't really help me out. Their source code didn't use animations, and I can't seem to find anywhere online that someone explains how to animate your loaded model... I'm sorta wondering if someone could link me to a helpful website, or maybe just help me out, so that maybe I will understand how to do animations with assimp.</p>
","<p>Valkea's forum link is a good resource. Careful though as it may be slightly confusing as I think everything which comes from the POV of someone else's problem (and misunderstandings!) has the risk of being - Animation in Assimp is straightforward so don't let anything put you off!</p>

<p>Disclaimer: I use <a href=""http://code.google.com/p/assimp-net/"" rel=""noreferrer"">AssimpNet</a> which is a managed wrapper around Assimp, though the object graph used by Assimp remains unchanged so the process is equivalent no matter the platform.<br>
I personally think Assimp is a wonderful idea and implementation, it has saved me countless hours, but translating their graph to your engine <em>is</em> writing an importer and learning everything required to do so.</p>

<p>(Also, I am assuming you are referring to Skeletal animation (not mesh animation or just animating individual nodes, though the latter I'll mention anyway))</p>

<p>Right, animation. As you'll know, Assimp collects entities in your source file in a tree of <code>nodes</code>. These nodes can have things like <code>meshes</code> attached to them, to identify visual geometry, or they can be 'abstract' nodes which exist to identify the world transforms of things like lights, and in your case, bones. Many file formats will 'flatten' the hierarchy so you will have a model with a single level of children, each one with a mesh. COLLADA is not one of those, and therefore its a little more complicated because if you want your imported model to behave correctly, you need to preserve its structure.</p>

<p><img src=""https://i.stack.imgur.com/aZW8i.png"" alt=""enter image description here""></p>

<p>Take the above diagram. The dashed boxes are Node objects, some have meshes but all exist within the graph eminating from the Root Node which you find in the scene object.</p>

<p><strong>Importing the Animations</strong></p>

<p>Importing the animation data is the simplest part of the process. The <code>aiScene</code> object will have a member <code>aiAnimations</code> which is a list of <code>aiAnimation</code> objects. Each <code>aiAnimation</code> will have a list of <code>aiNodeAnim</code>* objects, in the <code>mChannels</code> member.
Essentially, each channel controls a single node, and contains a list of keyframes, each with a scale, a rotation, and a translation value for this node at a specific point in time. Animation tracks identify nodes to control via their name.</p>

<p>(It is worth nothing at this point, that some exporters (such as 3DSMax) combine animations in odd ways, resulting in a single animation containing tracks for unrelated nodes, so if you are not animating a skinned mesh, make sure you check all the animation objects!)</p>

<p>So, say you are animating ""Box"". You have already imported the node 'Box' with its geometry and you have an item in your world with a transform. To animate the box, get the animation from <code>aiAnimations</code> and iterate over each <code>aiNodeAnim</code> (channel) until you find one with the mNodeName matching ""Box"". Then, iterate over each of the Position, Scale, and Rotation keyframes in the <code>mPositionKeys</code>, <code>mScalingKeys</code>, and <code>mRotationKeys</code> members, transforming the value (Vectors or Quaternions, and the time offset) into whatever structure your application stores animation data in.</p>

<p>Then just pick a keyframe/interpolate between them as usual and apply the transform specified by the frame to that nodes local transform and see it move!</p>

<p>Extracting skeletal animation is an identical process, since in Assimp bones are just other nodes. The skinning data is slightly trickier. To animate a skinned model you need three things:</p>

<ol>
<li><p>The transforms for each bone from the animation (which we get above)</p></li>
<li><p>The hierarchy of the skeleton</p></li>
<li><p>The skinning transforms for each bone (a.k.a inverse bind pose transforms) which we get from the mesh objects.</p></li>
</ol>

<p>The first thing to do, though, is find the skeleton.</p>

<p><strong>Finding the Skeleton</strong></p>

<p>The example diagram above is what you will find in every COLLADA DOM I have seen so far. That is, the skeleton will exist as a separate tree of nodes, sibling to the 'visual' geometry just under the root node.<br>
Assimp makes no distinction between 'bone nodes' and 'nodes', which means your importer will have to engage in some guesswork to pick the right starting node before reading in the whole tree.</p>

<p>The reason we need to find the skeleton is because, as can be seem from the diagram, each bone is parented to each other bone; the transforms extracted from the animation tracks/channels need to be combined with the transforms from other tracks to move the vertices correctly.</p>

<p>The way I do it is this:</p>

<p>Go over all the meshes and identify all the bones that they use, then for each bone, I look for a node in the object graph under root with the same name. I check how far down in the tree from root this bone is. The bone with the lowest value (degree of separation) is the root of the skeleton.</p>

<p>Once you have this, it is a case of reading in this node and each of its children, storing the <em>transform</em> of the node, and its <em>parent node's name</em>. Using this information, you can look up the parent for each bone.</p>

<p><strong>Skinning Data</strong></p>

<p>This is the trickiest bit, extracting the bones and weights from each mesh. The member you are looking for this time in <code>mBones</code> and it will be a member of <code>aiMesh</code>. It contains two things of interest:</p>

<ol>
<li><p><code>mOffsetMatrix</code> - this is the skinning transform, or Inverse Bind Pose transform - you want to store this for each bone along with the bones original transform and the name of its parent.</p></li>
<li><p><code>mWeights</code> - these are the vertex weights - and they are, well, sort of backwards!</p></li>
</ol>

<p>Each aiVertexWeight object contains mVertexId (which identifies the vertex) and mWeight, which is the weighting of the bone. The mVertexId is the index of the vertex in the 'vertex array' that serves the mesh. 
What that means is that you have to define a 'master list' of bone names, so that you can assign a number to each bone and have it refer consistently to the same bone. Then you need to look up that number for the name of the aiBone object which contains the vertex weight. Now you can update the vertex in your mesh with the bone ids and weights.</p>

<p>(You see what I mean about backwards, the weight contains the vertex id, while its parent contains the bone - although it makes it easier to write importers)</p>

<p><img src=""https://i.stack.imgur.com/A7qn2.png"" alt=""enter image description here""></p>

<p><strong>Summary</strong></p>

<p>Now you should have, for non-skinned items, a list of keyframes which define transforms of a node (identified by the name) at specific times. Which is all you need to animate a node (just update its local transform).</p>

<p>If you have a skinned mesh then you should have:</p>

<p>a. A list of bones in a specific order<br>
b. A list of bone ids and their weights, for each vertex in the mesh, ready to be packed into your vertex data array.<br>
c. A list of skinning/inversebindpose transforms, one for each bone in the list in (a)<br>
d. The parent for each bone in (a)<br>
e. The bind pose transform for each bone in (a) (same place you got (d), or just take the inverse of the skinning transform)    </p>

<p>This is the ""standard dataset"" for skeletal animation, and if you know about skeletal animation then it's all you need! If not, that best be a different question since it's quite a large area ;)</p>

<p><em>I hope that has helped, or at the very least not added to the confusion. Good luck!</em></p>

<p>(*Animations also contain mMeshAnim which allow for animating the mesh directly, I assume you are not talking about this just yet)</p>
","26442"
"What is a good tool for producing animated sprites?","20277","","<p>Has anyone come across a software package that allows you to build animations in a similar way to how you can in Flash (i.e. using techniques such as tweens &amp; bones &amp; easings, etc) and then have the result exported as a sprite sheet?</p>
","<p>You can use Flash, a 3D Tool or even Photoshops animation feature. Then render the frames to images and combine them to a sprite-sheet.</p>

<p><a href=""http://www.imagemagick.org/"">ImageMagick</a> has a great tool for that purpose called <em>montage</em>.
Here's a <a href=""http://www.bensnider.com/imagemagick-split-and-join-a-sprite-sheet.html"">blog post</a> explaining how to use it to create a sprite sheet.</p>
","385"
"How to calculate a 3x3 rotation matrix from 2 direction vectors?","20272","","<p>I've got 2 direction vectors, for the X axis and the Y axis of the object. How do I calculate the rotation matrix of the object using these?</p>
","<p>The basic idea is to use a <a href=""http://en.wikipedia.org/wiki/Cross_product"">cross product</a> to generate the extra orthogonal axes of your rotation matrix, based upon the axes that you already have.</p>

<pre><code>Matrix3x3 MakeMatrix( Vector3 X, Vector3 Y )  
{  
    // make sure that we actually have two unique vectors.
    assert( X != Y );

    Matrix3x3 M;  
    M.X = normalise( X );  
    M.Z = normalise( cross_product(X,Y) );
    M.Y = normalise( cross_product(M.Z,X) );  
    return M;
}
</code></pre>

<p>Note that the above does not make assumptions about X and Y vectors (apart from them not being identical), and does a lot of extra math that it might not have to do in your situation.</p>

<p>For example, in this code I'm doing a second cross-product to be sure our matrix gets an orthogonal Y axis, instead of blindly trusting that the input X and Y axes are precisely 90 degrees apart.  If in your situation you are sure that your input axes really are orthogonal to each other, then you can skip the second cross product, and just assign the input Y vector directly, instead of recalculating it.</p>

<p>Note that I'm assuming that your matrix representation has accessible 'X, Y, Z' vector members.  Some implementations just expose an array of nine floats instead, in which case the 'X' vector will be either elements 0, 1, and 2, or 0, 3, and 6, depending upon whether the matrix is row-major or column-major.  In this (annoying) situation, I usually find that it's easier to just try both ways and see which one works, rather than to search through documentation to try to figure out which ordering your particular matrix implementation is using.  :)</p>

<p>Finally, note that depending on your 3D coordinate system's handedness, you may need to multiply M.Z by negative one, in order to generate a legal rotation matrix for your 3D engine.</p>
","20100"
"Decision Tree vs Behavior Tree","20210","","<p>What are some differences between Decision Trees and Behavior Trees for AI Game Development?  When would you use one over the other? </p>
","<p>The two are pretty different. The real indicator is in the names. Decision trees are just for making decisions. Behavior trees are for controlling behavior. Allow me to explain. A major difference in the two is the way they are traversed, likewise the way they're laid out and the node 'types' are different.</p>

<p><strong>Decision trees</strong> are evaluated from root to leaf, every time. For a decision tree to work properly, the child nodes of each parent must represent all possible decisions for that node. If a node can be answered ""Yes, No, Maybe"", there must be three children, Yes node, No node and Maybe node. This means there's always some lower node to traverse, until reaching an end node. The traversal is always down. Graphical form:</p>

<p><img src=""https://i.stack.imgur.com/UqXMK.gif"" alt=""enter image description here""></p>

<p>Pretty simple. We start at the root, and based on some evaluation, choose 1, 2 or 3. We choose 3. Then we do some other evaluation and choose B or B... Well I reused the graphic from below, sorry. Pretend the B on the left is magic B.</p>

<p><strong>Behavior trees</strong> have a different evaluation. The first time they are evaluated (or they're reset) they start from the root (parent nodes act like selectors) and each child is evaluated from left to right. The child nodes are ordered based on their <strong>priority</strong>. If all of a child node's conditions are met, its behavior is started. When a node starts a behavior, that node is set to 'running', and it returns the behavior. The next time the tree is evaluated, it again checks the highest priority nodes, then when it comes to a 'running' node, it knows to pick up where it left off. The node can have a sequence of actions and conditions before reaching an end state. If any condition fails, the traversal returns to the parent. The parent selector then moves on to the next priority child. I'll attempt a graphical form here:</p>

<p><img src=""https://i.stack.imgur.com/RLRXd.gif"" alt=""enter image description here""></p>

<p>The traversal starts at the root, goes to child 1, checks the child condition (something like ""any enemies near by?""). The condition fails, and the traversal moves back up the tree to move on to node two. Node 2 has an action that's performed (maybe something like finding a path). Then a behavior (something like following the path). The following path is set to running and the tree returns its state as running. The nodes that failed or completed are returned to 'Ready'. Then the next time we check, we start again with the highest priority node. It fails again, so we proceed to node two. There we find we have a behavior running. We also find the behavior has completed, so we mark it completed and return that. The tree is then reset and ready to go again.</p>

<p>As you can see the behavior trees are more complex. Behavior trees are more powerful and allow for more complex behavior. Decision trees are easy to understand and simple to implement. So, you'd use behavior trees when you want more complex behavior, or more control over the behavior. Decision trees can be used as part of a behavior tree, or used alone for simple AI.</p>

<p>Some good understanding of how behavior trees are parsed can be found <a href=""http://www.altdevblogaday.com/2011/02/24/introduction-to-behavior-trees/"" rel=""noreferrer"">here</a>.</p>
","51722"
"How do I get into Facebook game development?","20188","","<p>I have some ideas that I think might make interesting games for a Facebook-like platform, in that they are social and casual. Does anyone have advice on how to get into Facebook development from a background in traditional C++ game development? Is there anything special that differentiates developing facebook games from developing other web-based games, such as API intricacies and so forth? </p>

<p>To start with this will probably be hobbyist level instead of some sort of professional enterprise, anything I need to know about making indie-level facebook games?</p>
","<p>You need to use the <a href=""http://developers.facebook.com/docs/guides/web"">Graph API</a> that they provide. In my experience it changes pretty frequently and is not terribly well documented -- though that may have changed. One thing worth considering is whether you want your game to work solely on Facebook using their canvas or anywhere through the Connect API.</p>

<p>The best clients seemed to be written in PHP (not surprising since Facebook itself is written in the language) and Javascript (ditto). If you choose to use Flash to write the game you'll likely want to use the ExternalInterface API to make calls to a Javascript layer you create, or you could make REST calls to a web server running PHP.</p>

<p>I think the biggest thing to be aware of is that there is a ton of competition amongst games on the platform, so if you build it they will likely not come. From a game design perspective I would actually advocate starting by detailing what the ""sharing"" moments are and why they will engage users. Once you've nailed these scenarios you can build the rest of your game to fit. This will give your game the best chance of being distributed by users amongst their friends.</p>

<p>Another gotcha is testing. When I made my game the only way to test, say, that your high score list worked was to register 20 fake accounts, <a href=""http://wiki.developers.facebook.com/index.php/Test_Accounts"">mark them as test accounts</a>, and then perform a manual test. I think for a more complex game it would be worth mocking the entire Facebook API that you leverage.</p>
","1632"
"What is the standard C# / Windows Forms game loop?","20168","","<p>When writing a game in C# that uses plain-old Windows Forms and some graphics API wrapper like <a href=""http://slimdx.org"">SlimDX</a> or <a href=""http://www.opentk.com"">OpenTK</a>, how should the main game loop be structured?</p>

<p>A canonical Windows Forms application has an entry point that looks like</p>

<pre><code>public static void Main () {
  Application.Run(new MainForm());
}
</code></pre>

<p>and while one can accomplish <em>some</em> of what is neccessary by hooking <a href=""http://msdn.microsoft.com/en-us/library/system.windows.forms.form_events%28v=vs.90%29.aspx"">the various events of the <code>Form</code> class</a>, those events don't provide an obvious place to put the bits of code to perform constant periodic updates to game logic objects or to begin and end a render frame.</p>

<p>What technique should such a game use to achieve something akin to the canonical</p>

<pre><code>while(!done) {
  update();
  render();
}
</code></pre>

<p>game loop, and to do with minimal performance and GC impact?</p>
","<p>The <code>Application.Run</code> call drives your Windows message pump, which is ultimately what powers all the events you can hook on the <code>Form</code> class (and others). To create a game loop in this ecosystem, you want to listen for when the application's message pump is empty, and while it remains empty, do the typical ""process input state, update game logic, render the scene"" steps of the prototypical game loop.</p>

<p>The <a href=""http://msdn.microsoft.com/en-us/library/system.windows.forms.application.idle(v=vs.110).aspx""><code>Application.Idle</code></a> event fires once every time the application's message queue is emptied and the application is transitioning to an idle state. You can hook the event in the constructor of your main form:</p>

<pre><code>class MainForm : Form {
  public MainForm () {
    Application.Idle += HandleApplicationIdle;
  }

  void HandleApplicationIdle (object sender, EventArgs e) {
    //TODO: Implement me.
  }
}
</code></pre>

<p>Next, you need to be able to determine if the application is <em>still</em> idle. The <code>Idle</code> event only fires once, when the application <em>becomes</em> idle. It does not get fired again until a message gets into the queue and then the queue empties out again. Windows Forms doesn't expose a method to query the state of the message queue, but you can use <a href=""http://msdn.microsoft.com/en-us/library/aa288468(v=vs.71).aspx"">platform invocation services</a> to delegate the query to <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/ms644943(v=vs.85).aspx"">a native Win32 function that can answer that question</a>. The import declaration for <code>PeekMessage</code> and its supporting types looks like:</p>

<pre><code>[StructLayout(LayoutKind.Sequential)]
public struct NativeMessage
{
    public IntPtr Handle;
    public uint Message;
    public IntPtr WParameter;
    public IntPtr LParameter;
    public uint Time;
    public Point Location;
}

[DllImport(""user32.dll"")]
public static extern int PeekMessage(out NativeMessage message, IntPtr window, uint filterMin, uint filterMax, uint remove);
</code></pre>

<p><code>PeekMessage</code> basically allows you to look at the next message in the queue; it returns true if one exists, false otherwise. For the purposes of this problem, none of the parameters are particularly relevant: it's only the return value that matters. This allows you to write a function that tells you if the application is still idle (that is, there are still no messages in the queue):</p>

<pre><code>bool IsApplicationIdle () {
    NativeMessage result;
    return PeekMessage(out result, IntPtr.Zero, (uint)0, (uint)0, (uint)0) == 0;
}
</code></pre>

<p>Now you have everything you need to write your complete game loop:</p>

<pre><code>class MainForm : Form {
  public MainForm () {
    Application.Idle += HandleApplicationIdle;
  }

  void HandleApplicationIdle (object sender, EventArgs e) {
    while(IsApplicationIdle()) {
      Update();
      Render();
    }
  }

  void Update () {
    // ...
  }

  void Render () {
    // ...
  }

  [StructLayout(LayoutKind.Sequential)]
  public struct NativeMessage
  {
      public IntPtr Handle;
      public uint Message;
      public IntPtr WParameter;
      public IntPtr LParameter;
      public uint Time;
      public Point Location;
  }

  [DllImport(""user32.dll"")]
  public static extern int PeekMessage(out NativeMessage message, IntPtr window, uint filterMin, uint filterMax, uint remove);
}
</code></pre>

<p>Furthermore, this approach matches up as close as possible (with minimal reliance on P/Invoke) to the canonical <em>native</em> Windows game loop, which looks like:</p>

<pre><code>while (!done) {
    if (PeekMessage(&amp;message, window, 0, 0, PM_REMOVE)){
        TranslateMessage(&amp;message);
        DispatchMessage(&amp;message);
    }
    else {
        Update();
        Render();
    }
}
</code></pre>
","67652"
"Why should I consider using the Source Engine?","20122","","<p>I've always been a Valve fan, but now that I have the opportuninty to choose a game engine for a project I'm not sure I want to choose the Source Engine after watching <a href=""http://en.wikipedia.org/wiki/Source_engine#Criticism"" rel=""nofollow"">this wikipedia entry</a>. My options essentially boiled down to an open source stack (Horde3D + Zoidcom + Spark + SFML + CEGUI, and well, not OSS but PhysX too), UDK and the Source Engine.</p>

<p>My question is (because I really have no experience with it) what would be the <strong>technical reasons</strong> (not license or other) for any developer to choose the Source Engine over any other open source or commercial option ?, is the Source Engine really worth it as a game development tool or has it time already passed and it is obsolete against other solutions?.</p>

<p>Thanks</p>

<hr>

<p>Edit: Precised my question a little more
, I'm looking for technical reasons to choose the Source Engine.</p>
","<p>Well, by far and away your biggest question should be: is my game going to be commercial? If so, then you will have to obtain a Source engine license, which is going to be (in most cases) substantially more costly than other engines, especially options like Unity. From the jist of your post I assume you aren't going to be commercial, though.</p>

<p>If your game is not going to be commercial, you can use the Source engine for free, but then you will have limited access to the engine and be at the mercy of the SDK tools. Valve has not done a great job (I am putting this lightly) at maintaining the SDK lately and the tools remain in a near-broken state.</p>

<p>Personally, speaking as someone who has worked on multiple Source SDK mods since 2005, I would stay as far away from source as possible. The tools are simply far too outdated and unkempt at this point. They have literally gotten worse as time has passed; for example the demo smoother tool (used to edit the camera movement in a demo to get good footage for movies such as trailers), has actually become harder to use from the Episode 1 SDK to the Orange Box SDK. It has more bugs and more crashes. The other tools can have the same said of them, OBSDK's Hammer (the level editing tool) now has multiple render bugs that did not exist in previous SDK versions, etc... it simply feels as if they do not care about their free tools anymore. It's a shame, as mods are a huge part of why Valve is what they are today. I do not know if their commercial tools fare the same (I would hope not!), but given what I have experienced with the free SDK there is no way I would ever consider purchasing/using the source engine for a commercial game.</p>

<p>As for other free engines, Ogre3D and Irrlicht are worth looking into as well. Also the Torque engine from Garage Games has just recently re-launched with a much lower price, $100 for their 3D engine, down from what used to be around $2000 iirc.</p>
","8120"
"Determine Resulting Angle of Wall Collision","20095","","<p>So I have an object moving in a direction towards a fixed horizontal or vertical wall. How do I compute the angle that the object should bounce off at? The object can approach the wall at an arbitrary angle.</p>
","<p>If you know the wall's normal vector and have an incoming direction for the object, then what you want is the <a href=""http://en.wikipedia.org/wiki/Reflection_%28mathematics%29#Reflection_across_a_line_in_the_plane"">reflection of a vector across a plane</a>.</p>

<p>If <strong>n</strong> is a normalized vector, and <strong>v</strong> is the <em>incoming</em> direction, then what you want is −(2(<strong>n</strong> · <strong>v</strong>) <strong>n</strong> − <strong>v</strong>). The minus sign accounts for the fact that the reflection formula doesn't actually reverse the direction, as an object's velocity would reverse.</p>

<p>This answer is given in terms of vector math, not an angle, because that's usually preferable if you don't have an explicit reason to use an angle. Note that if you must talk about angles, the angle of reflection is equal to the angle of incidence. If the angle is measured from the normal, the outgoing angle is the negation of the incoming angle; if the angle is measured from the wall, then it's the complement of the incoming angle.</p>
","23674"
"Get angle in radians given a point on a circle","20049","","<p>I'm working on a dial that rotates around a circle.</p>

<p><img src=""https://i.stack.imgur.com/nZMKC.jpg"" alt=""before click""></p>

<p>This dial should lets you mousemove anywhere in a circle to adjust the position of the dial to a point on the circle with the same angle as the click. For example, from the dial above if you clicked the spot shown in pink below I'd move the dial above that point but on the circle.</p>

<p><img src=""https://i.stack.imgur.com/YaImE.jpg"" alt=""after click (pink)""></p>

<p>I know how to get the position of a point on a circle given a radius and an angle (in radians). That's <a href=""https://gamedev.stackexchange.com/questions/18340/get-position-of-point-on-circumference-of-circle-given-an-angle"">this formula</a>:</p>

<pre><code>x = Cos(angle) * radius + CenterX;
y = Sin(angle) * radius + CenterY;
</code></pre>

<p>However, I am looking to do somewhat of the opposite -- I've got a click point, which I want to turn into a point on a circle (where the control knob goes). I'm trying to use this point (and a given radius) to figure out the angle in radians for it, so that I can place the control knob on the circle at the same angle.</p>

<p>Is there a handy formula I can use to accomplish this?</p>
","<p>Check out the <a href=""http://en.wikipedia.org/wiki/Atan2"">atan2</a> function.</p>

<p>It gives you the angle between (0, 0) and (x, y), <code>x</code> and <code>y</code> being the function arguments.</p>

<p><strong>Edit:</strong> if the center of the circle isn't (0, 0), no matter, just do this: <code>atan2(y - cy, x - cx)</code>.</p>
","33710"
"How to check if a variable is an integer?","19956","","<p>I'm going through my C++ book and have currently made a working Guess The Number game. </p>

<p>The game generates a random number based on current time, has the user input their guess, and then tells them whether it was too high, too low, or the correct number.</p>

<p>The game functions fine if you enter a number, but returns 'Too High' if you enter something that is not a number (such as a letter or punctuation). Not only does it return 'too high', but it also continually returns it.</p>

<p>I was wondering what I could do to check if the guess, as input by the user, is an integer and if it is not, to return 'Not a number. Guess again.'</p>

<p>Here is the code.</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;cstdlib&gt;
#include &lt;ctime&gt;
using namespace std;

int main()
{
    srand(time(0)); // seed the random number generator
    int theNumber = rand() % 100 + 1; // random number between 1 and 100
    int tries = 0, guess;

    cout &lt;&lt; ""\tWelcome to Guess My Number!\n\n"";

    do
    {
        cout &lt;&lt; ""Enter a guess: "";
        cin &gt;&gt; guess;
        ++tries;

        if (guess &gt; theNumber)
                cout &lt;&lt; ""Too high!\n\n"";

        if (guess &lt; theNumber)
                cout &lt;&lt; ""Too low!\n\n"";

    } while (guess != theNumber);

    cout &lt;&lt; ""\nThat's it! You got it in "" &lt;&lt; tries &lt;&lt; "" guesses!\n"";
    cout &lt;&lt; ""\nPress Enter to exit.\n"";

    cin.ignore(cin.rdbuf()-&gt;in_avail() + 1);
    return 0;
}
</code></pre>
","<p>Easiest is to use stringstream and check if conversion to int succeeded (reached eof)</p>

<pre><code>#include ""sstream""

//your code

cout &lt;&lt; ""Enter a guess: "";

std::string str;
cin &gt;&gt; str;
std::istringstream iss(str);
iss &gt;&gt; guess ;
if (iss.eof() == false)
    std::cout &lt;&lt; ""its not int"";

//cin &gt;&gt; guess;
</code></pre>
","56259"
"How to capture video of my mobile game?","19907","","<p>I've been keeping a <a href=""http://rawdev.tumblr.com"">blog</a> for my current Android game and as I get closer to an actual playable version of the game, screenshots just aren’t enough to show new progress anymore. What I need is video. The problem is, my game won’t run on the current emulator (uses OpenGL ES 2.0), and my computer couldn’t run the emulator if it wanted to anyways. So desktop video capture is out of the question. The only real idea I have is holding the phone in front of the only video camera I own: a webcam… yeah. Does anyone know a better (preferably free) way to capture video from an Android device?</p>
","<p>Perhaps something like <a href=""http://droid-at-screen.ribomation.com/"" rel=""nofollow"">Droid@Screen</a> would work? Here's a <a href=""http://www.youtube.com/watch?v=QtB36BTllwY"" rel=""nofollow"">video</a> of setting it up and capturing video using <a href=""http://camstudio.org/"" rel=""nofollow"">CamStudio</a>. Droid@Screen is in alpha, so it <em>might</em> work. Good luck! I'll keep an eye out for those videos on your blog .) </p>

<p>Hopefully your computer can handle that much :/</p>

<p>If your android device is rooted, there's an entirely on the phone option with <strong>ScreenCast &amp; Recorder</strong>. Here's an <a href=""http://www.redmondpie.com/record-android-screen-with-screencast-screen-recorder-for-android/"" rel=""nofollow"">article</a> and the android market page for <a href=""https://market.android.com/details?id=com.ms.screencast"" rel=""nofollow"">paid</a> and <a href=""https://market.android.com/details?id=com.ms.screencastfree"" rel=""nofollow"">free</a>. Free version limits to 30 seconds of recording.</p>
","16958"
"Does Unity for PC use Direct3D or OpenGL?","19903","","<p>I am a mac developer using Unity and I hardly use a PC. When you build a Unity game for Windows, does it use Direct3D or OpenGL?</p>

<p>P.S. I'm not sure if it's called Direct3D or DirectX</p>
","<p>Unity supports several renderers for its various platforms, Direct3D and OpenGL among them. You can find references to this fact in the <a href=""http://unity3d.com/unity/whats-new/unity-3.4"">release notes</a>, for example, and in this documentation explaining some <a href=""http://unity3d.com/support/documentation/Components/SL-PlatformDifferences.html"">differences between renderer implementations</a> that users should be aware of.</p>

<p>It appears that by default, Unity will use D3D on Windows. You can force it to use an OpenGL rendering path, apparently, <a href=""http://forum.unity3d.com/threads/6946-forcing-opengl-on-windows"">via a command-line argument</a> (although that thread is quite old). Configuring the rendering path in your game settings appears to be more about deferred versus forward renderers, and not the underlying API used.</p>
","18414"
"How can I programatically generate sprite instances in Unity?","19901","","<p>I want to create a block-based puzzle game that generates blocks as they are required, however I cannot seem to find any good information on how to do something like this using Unity's new sprite system.</p>

<p>Ideally the following would occur:</p>

<ul>
<li>Generate a random number to determine the type of block</li>
<li>Create a sprite object of correct block type</li>
<li>Display block on screen</li>
</ul>

<p>I currently have the following:</p>

<pre><code>using UnityEngine;
using System.Collections;

public class Block : MonoBehaviour {

    public SpriteRenderer blockSprite;
    int row;
    int column;

    // Use this for initialization
    void Start () 
    {
        row = 0;
        column = 0;
    }

    // Update is called once per frame
    void Update () 
    {
        // gravity check
    }

    public void GenerateNewBlock()
    {
        int randNumber = Random.Range(0, System.Enum.GetNames(typeof(BlockType)).Length);
        Sprite sprite = new Sprite();

        blockSprite = gameObject.GetComponent&lt;SpriteRenderer&gt;();

        switch (randNumber)
        {
        case 0:
            sprite = Sprite.Create(AssetsLoader.Instance.BlockSprites[BlockType.Water], new Rect (0, 0, 100, 100), new Vector2(0, 0), 100.0f);
            break;
        case 1:
            sprite = Sprite.Create(AssetsLoader.Instance.BlockSprites[BlockType.Fire], new Rect (0, 0, 100, 100), new Vector2(0, 0), 100.0f);
            break;
        }
    }
}

public enum BlockType
{
    Water,
    Fire
}
</code></pre>

<p>And an assets loader Singleton class to load in the textures once into memory</p>

<pre><code>using UnityEngine;
using System.Collections.Generic;

public class AssetsLoader : MonoBehaviour
{
    // instance variable to prevent multiple instances of this class
    private static AssetsLoader instance;

    // variables we want to retain state
    public Dictionary&lt;BlockType, Texture2D&gt; BlockSprites;

    // empty private constructor
    private AssetsLoader() {}

    // Property that holds the instance
    public static AssetsLoader Instance
    {
        get
        {
            if (instance == null)
            {
                instance = new AssetsLoader();
            }

            return instance;
        }
    }

    // Use this for initialization
    void Start () 
    {
        BlockSprites = new Dictionary&lt;BlockType, Sprite&gt;();

        Sprite newSprite;

        newSprite = Resources.Load(""Sprites/water block"") as Texture2D;
        BlockSprites.Add(BlockType.Water, newSprite);

        newSprite = Resources.Load(""Sprites/fire block"") as Texture2D;
        BlockSprites.Add(BlockType.Fire, newSprite);
    }
}
</code></pre>

<p>Can someone please help me understand what needs to be done to create block objects in my scene. Ideally I would only use <code>Sprite</code> objects but I think I might need to load the assets in as <code>Texture</code>s in order to get them to display. </p>
","<p>I would use prefabs for a situation like this, you could use then to fill your dictionary like so:</p>

<pre><code>public class AssetsLoader : MonoBehaviour
{
    public GameObject[] blockPrefabs;
    public Dictionary&lt;String, Texture2D&gt; blockTypes;

// ...

   void Start () 
   {
       blockTypes = new Dictionary&lt;String, Sprite&gt;();

       foreach(GameObject prefab in blockPrefabs) {
           blockTypes[prefab.name] = prefab;
       }
   }
}
</code></pre>

<p>This will expose the <code>blockPrefabs</code> array so you can drop any number of prefabs into it using the Inspector.  Use meaningful names and they can function as keys for the dictionary.</p>

<p>You can then spawn them in your scene using <a href=""http://docs.unity3d.com/Documentation/ScriptReference/Object.Instantiate.html"" rel=""nofollow""><code>Instantiate</code></a>.</p>

<p><strong>Edit:</strong>
Another approach that would allow for enum based reference would be:</p>

<pre><code>public enum BlockType
{
    Water = 0,
    Fire = 1
}

public class AssetsLoader : MonoBehaviour
{
    [SerializeField]
    private GameObject[] blockPrefabs;

    // ...

    public GameObject BlockSprites(BlockType blockType) {
        return blockPrefabs[(int)blockType];
    }
}
</code></pre>

<p>Here there would be a requirement to keep the contents of the array <code>blockPrefabs</code> and the values of the enum <code>BlockType</code> in sync.</p>
","68787"
"Press button event instead of onClick() in Unity","19900","","<p>I want to add a nitro in my arcade game and i want to detect press UI button instead of click. unfortunately only onClick() event is available for UI button</p>

<p><a href=""https://i.stack.imgur.com/RV1Jd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RV1Jd.png"" alt=""enter image description here""></a></p>

<p>what kind of options do I have ?</p>

<p>Thank you</p>
","<p>You can use <a href=""http://docs.unity3d.com/ScriptReference/UI.Selectable.OnPointerDown.html"" rel=""nofollow noreferrer"">OnPointerDown</a>. Here is the example: <a href=""http://forum.unity3d.com/threads/touch-and-hold-a-button-on-new-ui.266065/#post-1758312"" rel=""nofollow noreferrer"">http://forum.unity3d.com/threads/touch-and-hold-a-button-on-new-ui.266065/#post-1758312</a></p>

<pre><code>public static bool mouseDown;
public float timeMouseDown;

void Update(){
    if(mouseDown)
       timeMouseDown += time.deltaTime;
}

void OnPointerDown(){
      mouseDown = true;
}
void OnPointerUp(){
      mouseDown = false;
      timeMouseDown = 0;
}
</code></pre>
","108515"
"OpenGL ES 2.0: Setting up 2D Projection","19858","","<p>This article describes in general, how to draw sharp OpenGL 2D graphics, using fixed function pipeline.</p>

<ul>
<li><a href=""http://basic4gl.wikispaces.com/2D+Drawing+in+OpenGL"">http://basic4gl.wikispaces.com/2D+Drawing+in+OpenGL</a></li>
</ul>

<p>Because OpenGL ES 2.0 has some ES 1.x functions not available (such as: glOrtho()), their functionality must be substituted in Fragment/Vertex shaders.</p>

<p>My question is, how to setup the following 2D projection in programmable function pipeline?</p>

<pre><code>const XSize = 640, YSize = 480
glMatrixMode (GL_PROJECTION)
glLoadIdentity ();
glOrtho (0, XSize, YSize, 0, 0, 1)
glMatrixMode (GL_MODELVIEW)
</code></pre>

<p>How Fragment and Vertex shaders must be configured to fully substitute the above mentioned fixed function 2D projection setup?</p>
","<p>In my OpenGL ES 2.X engine, i compute the MVP matrix (Model View Projection) on CPU Side
and inject it in vertex shader.</p>

<p>The Orthogonal projection is a <a href=""http://www.opengl.org/sdk/docs/man/xhtml/glOrtho.xml"">4*4 matrix</a>. When i have the MVP, i inject it in the
vertex shader with:</p>

<pre><code> mMvpLoc = getUniformLocation(""uMvp"");
 glUniformMatrix4fv(mMvpLoc, 1, false, mMvp.pointer());
</code></pre>

<p>The mMvp is my matrix 4*4 on CPU side. The getUniformLocation can be done only one time after you have loaded the program shader.</p>

<p>An example of vertex shader:</p>

<pre><code>uniform mat4    uMvp;
attribute vec3 aPosition;
varying vec4 vColor;

void main() {
   vec4 position = vec4(aPosition.xyz, 1.);
   gl_Position = uMvp * position;
}
</code></pre>

<p>The gl_Position is a special predefined variable. It must contain the position of the
vertex.</p>

<p>An example of fragment shader. For each point to draw, the final color ""gl_FragColor""
must be computed:</p>

<pre><code>#ifdef GL_ES
precision highp float;
#endif

void main(void)
{
   gl_FragColor = vColor;
}
</code></pre>

<p>This program draw a triangle with a smoothing of colors defined for each vertex.</p>

<p>For a better tutorial, look <a href=""http://duriansoftware.com/joe/An-intro-to-modern-OpenGL.-Table-of-Contents.html"">this wonderful document.</a></p>
","4326"
"What are some cool examples of procedural pixel shader effects?","19782","","<p>What are some good examples of procedural or screen-space pixel shader effects? No code is necessary; I'm just looking for inspiration.</p>

<p>In particular, I'm looking for effects that are not dependent on geometry or the rest of the scene (so they would look okay rendered alone on a quad) and are not based on image processing (they don't require a ""base image,"" though they can incorporate textures). Multi-pass or single-pass is fine. Screenshots or videos would be ideal, but ideas work too.</p>

<p>Here are a few examples of what I'm looking for (all from the RenderMonkey samples):
<a href=""http://public.blu.livefilestore.com/y1pXcNg_0EPZVzwu1T84a4Yek373x8062rhrNCA7UcftTjCkeiY-5uAuJiBYY29x2E53p5MO-uMA8FmEquvxsPCkA/effect1.jpg?psid=1"" rel=""nofollow noreferrer"">alt text http://public.blu.livefilestore.com/y1pXcNg_0EPZVzwu1T84a4Yek373x8062rhrNCA7UcftTjCkeiY-5uAuJiBYY29x2E53p5MO-uMA8FmEquvxsPCkA/effect1.jpg?psid=1</a><a href=""http://public.blu.livefilestore.com/y1p_5Lx7BdjFyFRBkbcc0WakAT7Q-99fVcFOxmTXBbG4VtoFzC0UfAj51eSnE7ZOD84EYL2Y51HhMS2nWsohhn1mQ/effect2.jpg?psid=1"" rel=""nofollow noreferrer"">alt text http://public.blu.livefilestore.com/y1p_5Lx7BdjFyFRBkbcc0WakAT7Q-99fVcFOxmTXBbG4VtoFzC0UfAj51eSnE7ZOD84EYL2Y51HhMS2nWsohhn1mQ/effect2.jpg?psid=1</a>
<a href=""http://public.blu.livefilestore.com/y1p_5Lx7BdjFyE3KhYtHe-Cdg7XuXcJ9Ou-GKzED-kZnzACyB5ypA6NSCfsYfuKa0h3ztoDRwwq9qBddX2OfG0fhg/effect3.jpg?psid=1"" rel=""nofollow noreferrer"">alt text http://public.blu.livefilestore.com/y1p_5Lx7BdjFyE3KhYtHe-Cdg7XuXcJ9Ou-GKzED-kZnzACyB5ypA6NSCfsYfuKa0h3ztoDRwwq9qBddX2OfG0fhg/effect3.jpg?psid=1</a><a href=""http://nv3wrg.blu.livefilestore.com/y1p1iHFwf-wytDo8HlTJca8RfckA-iTKgvLiJm0t9iz3S35YgeEnt99NMjKDgotxa3Bv90wAhOYLabzx2Sd3LoEH2Hs76WR1vFM/effect5.jpg?psid=1"" rel=""nofollow noreferrer"">alt text http://nv3wrg.blu.livefilestore.com/y1p1iHFwf-wytDo8HlTJca8RfckA-iTKgvLiJm0t9iz3S35YgeEnt99NMjKDgotxa3Bv90wAhOYLabzx2Sd3LoEH2Hs76WR1vFM/effect5.jpg?psid=1</a></p>

<p>I'm aware of <a href=""https://gamedev.stackexchange.com/questions/1673/is-there-any-shaders-directory"">this question</a>; I'm not asking for a source of actual shader implementations but instead for some inspirational ideas -- and the ones at the <a href=""http://developer.download.nvidia.com/shaderlibrary/webpages/shader_library.html"" rel=""nofollow noreferrer"">NVIDIA Shader Library</a> mostly require a scene or are image processing effects.</p>
","<p><a href=""http://www.proun-game.com/Oogst3D/index.php?file=CODING/InteriorMapping/InteriorMapping.txt"" rel=""noreferrer"">Interior mapping</a> is a pretty awesome effect. It takes a boring flat quad and makes it look like a building with interiors, all entirely within the pixel shader. It's semi-procedural in that some of the assets are hand-crafted, but the shader places them procedurally.</p>

<p><img src=""https://i.imgur.com/ToAks.jpg"" alt=""alt text""></p>
","2759"
"How to add a scrolling camera to a 2D Java game?","19763","","<p>I am attempting to create a game where the camera follows the player, always making sure the player is in the center of the screen. How would I go about this? This game is a 2D Java game, made with no engine.</p>

<p>I found an opensource game demonstrating what I want but I cannot work out how to add that to my game. The game is <a href=""https://github.com/DeathJockey/Zombie-Effects/raw/master/ZE.jar"">here</a>, if you need it.</p>

<p>Thanks</p>
","<p>First, you need to define the size of the viewport (the camera resolution), for simplicity, let's assume the camera viewport is the size of the screen, we have a 800*600 screen.</p>

<p>Next, you need to define the maximum and minimum offsets of your camera. Assuming you have a world with a size of 1600*1200, the maximum offset would be 800 on X and 600 on Y and 0 on both axis for the minimum offsets. The  general formulas to determine the offsets is:</p>

<pre><code>offsetMaxX = WORLD_SIZE_X - VIEWPORT_SIZE_X
offsetMaxY = WORLD_SIZE_Y - VIEWPORT_SIZE_Y
offsetMinX = 0
offsetMinY = 0
</code></pre>

<p>Now, over frames, you need to calculate the actual position of the camera. A position that would make the player being centered on the screen. The position need to be calculated relatively to the player position.</p>

<pre><code>camX = playerX - VIEWPORT_SIZE_X / 2
camY = playerY - VIEWPORT_SIZE_Y / 2
</code></pre>

<p>Don't forget to check if the camera position do not exceed the maximum and minimum offsets.</p>

<pre><code>if camX &gt; offsetMaxX:
    camX = offsetMaxX
else if camX &lt; offsetMinX:
    camX = offsetMinX
if camY &gt; offsetMaxY:
    camY = offsetMaxY
else if camY &lt; offsetMinY:
    camY = offsetMinY
</code></pre>

<p>Now that you know the position of the camera, you will to <em>translate</em> the world to this position. When you open a plain window and start drawing stuffs, the area you see start at 0,0. To create the illusion of a camera following the player, you will need to set your drawing area position (the screen in your example) to the camera position.</p>

<p>I don't know what framework/engine you are using but the easiest way to do it is to translate the whole graphic context by the opposite of the current offsets. You will need to know how to access your graphic context and apply a translation to it.</p>

<p>In slick2d, it could look like this:</p>

<pre><code>public void render(..., Graphics g) {
    g.translate(-cam.x, -cam.y)
    //render the rest of your game
}
</code></pre>
","44270"
"How can I create borders in an open-world game that don't feel artificial?","19696","","<p>When creating open-world maps, a big issue to take into consideration is how <em>""borders""</em> of sorts are implemented. Obviously, in an open-world game, there shouldn't be invisible-wall borders, as it ruins immersion, and makes the game feel more <em>""artificial""</em>.</p>

<p>I've done a little bit of research online and I've found the following methods:</p>

<ul>
<li>Have the map be an island, surrounded by water that will kill you if you venture out too far.</li>
<li>Have the map be surrounded by mountains that are much too steep to climb over.</li>
<li>A combination of the above; mountains plus a body of water. The Elder Scrolls V: Skyrim does something like this but does have places where paths lead out of the world. <em>(Thanks @Pharap)</em></li>
</ul>

<p>These seem like the best methods, but I'm wondering if there are any other methods that can be used to create borders in an open world without ruining immersion, if there are others.</p>
","<p>Just some quick additional suggestions, that sometimes complement what others have already said.</p>

<p>1) <strong>water solution</strong>: I never understood why killing the player with a shark or something. Just let him/her swim infinitely (like with a proceduraly generated infinite ocean). That alone would closer resemble the idea of how distant it would be in real life to cross an ocean by swimming. The player would just get tired at some point of going forward and then would decide to reload (because going back all over again would be just as tedious).</p>

<p>Of course, if you have modern boats, ships, jet-skis, etc, and the concept of gas as resource, that works well too and then it becomes part of the item number 4 below, since the player can just sail until running out of gas. Then, if he/she can swim, it becomes again a problem of just letting him/her swim forever.</p>

<p>2) <strong>scene barrier</strong>: it does not have to be mountains. A dense forest, as someone else told here. A canyon with a beautiful view. A part of a city with too many buildings in the way and the only possible streets blocked. A huge fire destroying parts of a city, or a gas leak, or a radiation accident in part of a city that blocks the way. If the city was invaded by aliens, maybe the gigantic spaceship is itself blocking the path to other parts of the city as it crushed when arriving. Or, why not, you can have flying islands like in Zelda Skyward Sword, where the boundary is given by not-falling-to-death.</p>

<p>3) <strong>challenging who tries</strong>: you can always increase the challenge exponentially as far as the player goes. Imagine an open-world in the country fields. The player crosses farms in the direction of the inner-lands of your world. More and more enemies show up with no power-up, health kits or something in the way. If you make these field camps procedural and increase the challenge, the player will eventually get killed without having the feeling that he/she was cheated by an artificial border. I like this approach because it even creates in the mind of the players the impression that there might be something hidden ahead (of course, you have to take care and don't abuse on this illusion, to avoid the players becoming mad at you!).</p>

<p>4) <strong>lack of resources</strong>: if a player has to eat/take medicine/whatever, and/or if vehicles have gas, you don't need boundaries. Let the player and/or its vehicles die. That is particularly useful in a space game, where creating a non-artificial barrier is quite difficult. In other words, if that suits your gameplay framework, make the open world finite by not being accessible due to being impossible to accumulate resources to go beyond a give distance.</p>

<hr>

<p>I won't keep going with a ton of suggestions based on storyline and gameplay. My reasons: first I don't know which type of game we are talking about. Second: frankly, as nice as it can be to have a story-line or gameplay related solution such as failing missions because some hostage has died when you tried to get out of the borders, I don't think that is exactly what you meant and, on the contrary, I found those to be usually harmful for immersion. But if you happen to be interested in these types too, let me know and I can drop some ideas that I have either seen or thought.</p>

<p>Also, as a general point, notice that more than once I touched procedural generation. Really, I think procedural generation is your friend here. You don't need to use it only for having infinite worlds. I always say we should start using it much more often to make the finite open-games more realistic and diverse. Using it for a fake endless border would be a neat use.</p>
","112281"
"How are 3D models created in video games?","19500","","<p>How are 3D models in games designed and displayed? Is it all code? Drawn on paper, then on a 3D graphics software, then... what?</p>

<p>Of course, game <em>programmers</em> won't define every vertex of every shape(/object,) they want to be drawn, all in code (whether in Direct3D or OpenGL.) So, do the game <em>designers</em> have tools to use, like Maya or something like it of proprietary 3D graphics softwares out there; they ""draw"" the model in that software, export it in whatever format, then <em>programmers</em> parse it via code and automatically enter the decoded/parsed raw vertices of the object/model?</p>

<p>I have Googled much but I couldn't find something solid to explain how this aspect of professional video games is worked on.</p>
","<p>In all the games I've worked on, the the Asset Creation Pipeline goes something like this:</p>

<ol>
<li>the concept artist (for levels/backgrounds/level models) or character artist (for models) will generate sketches for characters/levels/etc. usually multiple options are given to the creative director / lead art to decide which one they like better. </li>
<li>The concept / character art that has been approved is given to a modeler to use as reference. Sometimes additional profile/front on art is done by the character artist to provide a cleaner frame or reference for the modelling process. I've seen many a modeler with the concept art stuck up within 3d max/maya/etc as direct reference.</li>
<li>The modelers typically generate the base textures for the model as well, usually with the correct shader materials for the runtime. shaders are used to render the model in the game, and may have specific texture/uv/etc requirements which need to be provided by the modeler or assigned texture artist.</li>
<li><p>It will be the Level Designer's job to piece together the assets to ""build"" level itself. </p>

<p>Its unusual for an entire level to be built as a single piece of geometry. Most levels are built of pieces, or sections. (eg: infamous used a set of hexagon ""tiles"" <a href=""http://www.gamasutra.com/php-bin/news_index.php?story=118581"">http://www.gamasutra.com/php-bin/news_index.php?story=118581</a> and skyrim (and many others) use a lego style approach to piece together levels <a href=""http://www.gamasutra.com/blogs/JoelBurgess/20130501/191514/"">http://www.gamasutra.com/blogs/JoelBurgess/20130501/191514/</a>) </p>

<p>There's usually a level editor of some description involved in this process, although many games have used 3d modelers as ""level editors"" for instancing previously created assets.</p></li>
<li><p>Once all this is done, the assets are typically processed by the <em>Toolchain</em> which turns the 3D Modeler friendly files into game ready data which can be loaded directly into the Runtime.</p>

<p>Toolchains (the bit that takes the raw assets and transforms them into game ready data) are often some of the most complicated pieces of engineering in game development. They need to talk to many different applications, understand many different file formats, and also understand how to transform data into a more efficient and instantly usable format. Toolchains typically also perform lighting pre-passes, vertex welding, LOD generation and so on. Often building the entire data set for a large AAA game will take a very long time, often greater than 8 hours for a complete rebuild. So Toolchains typically also contain distributed processing to spread the load across all the PC's in the entire studio. </p>

<p>The <em>Runtime</em> is the game itself. The executable which runs on your PC, or Console. Inside the Runtime there will be a system called a Resource Manager. It's the Resource Manager's job to load the assets requested by other systems within the game.</p>

<p>E.g.: When you tell the game load into a Level, the Level's metadata will provide the Resource Manager with a list of which assets need to be loaded to display the level. Likewise, each Asset will contain a list of any Textures, Materials, or Sub Assets that are required to be loaded.</p></li>
<li><p>Once everything's actually loaded into memory. The game will send things which are visible to the <em>Renderer</em> which will then interact with the API used to actually draw things on the screen.  </p></li>
</ol>

<p>Programmers can (and do) generate vertex information by hand. This is typically called ""Immediate Mode Rendering"". It's not very efficient, and is only used for situations where its not possible to use pre-generated, or shader manipulated vertex data. Eg: UI Rendering, Fullscreen Quads.</p>

<p>Typically 99% of the objects onscreen will be pre-generated vertex information rendered in ""Retained"" mode, With shaders performing any manipulation required. Eg: Skinned Animation</p>
","57817"
"How can I convert a mouse click to a ray?","19425","","<p>I have a perspective projection.  When the user clicks on the screen, I want to compute the ray between the near and far planes that projects from the mouse point, so I can do some ray intersection code with my world.</p>

<p>I am using my own matrix and vector and ray classes and they all work as expected.</p>

<p>However, when I try and convert the ray to world coordinates my far always ends up as 0,0,0 and so my ray goes from the mouse click to the centre of the object space, rather than through it.  (The x and y coordinates of near and far are identical, they differ only in the z coordinates where they are negatives of each other)</p>

<pre><code>GLint vp[4];
glGetIntegerv(GL_VIEWPORT,vp);
matrix_t mv, p;
glGetFloatv(GL_MODELVIEW_MATRIX,mv.f);
glGetFloatv(GL_PROJECTION_MATRIX,p.f);
const matrix_t inv = (mv*p).inverse();
const float
    unit_x = (2.0f*((float)(x-vp[0])/(vp[2]-vp[0])))-1.0f,
    unit_y = 1.0f-(2.0f*((float)(y-vp[1])/(vp[3]-vp[1])));
const vec_t near(vec_t(unit_x,unit_y,-1)*inv);
const vec_t far(vec_t(unit_x,unit_y,1)*inv);
ray = ray_t(near,far-near);
</code></pre>

<p>What have I got wrong?  (How do you unproject the mouse-point?)</p>
","<p>I recently had to solve this myself for a WebGL application. I've attached the complete source code, but incase it doesn't work right off the bat for you here are some debugging tips:</p>

<ol>
<li>Don't debug your unproject method in your game. If possible, try to write unit-test style tests to make it easier to isolate what is going wrong.</li>
<li>Be sure to print the output rays for both the near and far clipping planes.</li>
<li>Remember that matrix math is NOT commutative. A x C != C x A. Double check your math.</li>
</ol>

<p>Also, to reply to some comments above, you almost never want to use OpenGL's selection APIs. That helps you pick existing items, like if you were creating a menu, however it fails to perform most real-world scenarios like 3D model editing. Where you need to add geometry as a result of the click. </p>

<p>Here is my implementation. There is nothing magic going on here. Just JavaScript and Google's Closure library.</p>

<h3>gluUnProject</h3>

<pre><code>/**
 * Port of gluUnProject. Unprojects a 2D screen coordinate into the model-view
 * coordinates.
 * @param {Number} winX The window point for the x value.
 * @param {Number} winY The window point for the y value.
 * @param {Number} winZ The window point for the z value. This should range
 *    between 0 and 1. 0 meaning the near clipping plane and 1 for the far.
 * @param {goog.math.Matrix} modelViewMatrix The model-view matrix.
 * @param {goog.math.Matrix} projectMatrix The projection matrix.
 * @param {Array.&lt;Number&gt;} view the viewport coordinate array.
 * @param {Array.&lt;Number&gt;} objPos the model point result.
 * @return {Boolean} Whether or not the unprojection was successful.
 */
octorok.math.Matrix.gluUnProject = function(winX, winY, winZ,
                        modelViewMatrix, projectionMatrix,
                        viewPort, objPos) {
  // Compute the inverse of the perspective x model-view matrix.
  /** @type {goog.math.Matrix} */
  var transformMatrix =
    projectionMatrix.multiply(modelViewMatrix).getInverse();

  // Transformation of normalized coordinates (-1 to 1).
  /** @type {Array.&lt;Number&gt;} */
  var inVector = [
    (winX - viewPort[0]) / viewPort[2] * 2.0 - 1.0,
    (winY - viewPort[1]) / viewPort[3] * 2.0 - 1.0,
    2.0 * winZ - 1.0,
    1.0 ];

  // Now transform that vector into object coordinates.
  /** @type {goog.math.Matrix} */
  // Flip 1x4 to 4x1. (Alternately use different matrix ctor.
  var inMatrix = new goog.math.Matrix([ inVector ]).getTranspose();
  /** @type {goog.math.Matrix} */
  var resultMtx = transformMatrix.multiply(inMatrix);
  /** @type {Array.&lt;Number&gt;} */
  var resultArr = [
    resultMtx.getValueAt(0, 0),
    resultMtx.getValueAt(1, 0),
    resultMtx.getValueAt(2, 0),
    resultMtx.getValueAt(3, 0) ];

  if (resultArr[3] == 0.0) {
    return false;
  }

  // Invert to normalize x, y, and z values.
  resultArr[3] = 1.0 / resultArr[3];

  objPos[0] = resultArr[0] * resultArr[3];
  objPos[1] = resultArr[1] * resultArr[3];
  objPos[2] = resultArr[2] * resultArr[3];

  return true;
};
</code></pre>

<h3>Usage</h3>

<pre><code>  this.sys.event_mouseClicked = function(event) {
    // Relative x and y are computed via magic by SystemModule.
    // Should range from 0 .. viewport width/height.
    var winX = event.relativeX;
    var winY = event.relativeY;
    window.console.log('Camera at [' + me.camera.position_ + ']');
    window.console.log('Clicked [' + winX + ', ' + winY + ']');

    // viewportOriginX, viewportOriginY, viewportWidth, viewportHeight
    var viewPort = [0, 0, event.viewPortWidth, event.viewPortHeight];
    var objPos = [];  // out parameter.

    // The camera's model-view matrix is the result of gluLookAt.
    var modelViewMatrix = me.camera.getCameraMatrix();
    // The perspective matrix is the result of gluPerspective.
    var perspectiveMatrix = pMatrix.get();

    // Ray start
    var result1 = octorok.math.Matrix.gluUnProject(
      winX, winY, 0.0,
      modelViewMatrix, perspectiveMatrix,
      viewPort, objPos);
    window.console.log('Seg start: ' + objPos + ' (result:' + result1 + ')');

    // Ray end
    var result2 = octorok.math.Matrix.gluUnProject(
      winX, winY, 1.0,
      modelViewMatrix, perspectiveMatrix,
      viewPort, objPos);
    window.console.log('Seg end: ' + objPos + ' (result:' + result2 + ')');
  };
};
</code></pre>
","9091"
"How do I make a circular hole inside an editable poly without boolean operations?","19396","","<p>I have created a rectangle, then converted it into an editable poly. Then I created a circle and converted it to editable poly too. How to make it so that that the circle becomes a hole in the rectangle?</p>

<p><img src=""https://i.stack.imgur.com/lE8gB.png"" alt=""enter image description here""></p>
","<p>That's called a <strong>Boolean operation</strong>. You can find a <a href=""http://www.youtube.com/watch?v=uwp2c-mAzkU"" rel=""nofollow"">video tutorial</a> here for almost the exact situation you're asking about.</p>

<p>Essentially, it looks like you create a new object with your two objects selected. You'll likely need to make your circle a cylinder first. The new object is a Compound Object of type Boolean. Then in the operations you select A-B (where A is your rectangle and B is your cylinder).</p>

<p>It's still a boolean operation. It's just done with splines that share a common plane. Check the Boolean heading on this <a href=""http://docs.autodesk.com/3DSMAX/15/ENU/3ds-Max-Help/files/GUID-EC9BB02A-FDE3-4B50-824E-07BE9E5ACE3C.htm"" rel=""nofollow"">page</a>.</p>
","40018"
"How to play animations in Cocos2d-x?","19372","","<p>I'm new to Cocos2d-x and looking for a good way/tutorial on how to play animations in Cocos2d-x.</p>
","<p>Sprite animation is pretty simple. You just create a <code>CCAnimation</code> node, add the images to loop, then create an action using <code>CCAnimate::actionWithDuration(float, CCAnimation, bool)</code> and make the sprite run it.</p>

<p><strong>Example:</strong></p>

<pre><code>CCAnimation * anim = CCAnimation::animation();
// There are other several ways of storing + adding frames, 
// this is the most basic using one image per frame.
anim-&gt;addFrameWithFileName(""bear1.png"");
anim-&gt;addFrameWithFileName(""bear2.png"");
anim-&gt;addFrameWithFileName(""bear3.png"");
anim-&gt;addFrameWithFileName(""bear4.png"");
anim-&gt;addFrameWithFileName(""bear5.png"");
anim-&gt;addFrameWithFileName(""bear6.png"");
anim-&gt;addFrameWithFileName(""bear7.png"");
anim-&gt;addFrameWithFileName(""bear8.png"");

CCAnimate *theAnim = CCAnimate::actionWithDuration(1.8f,anim,true); 
// Duration, animation action and bool to return to frame 1 after finishing.

CCSprite *bear = CCSprite::spriteWithFile(""bear1.png"");
addChild(bear,0); //Don't forget to add any sprite you use as a child to the CCLayer!
bear-&gt;runAction(theAnim);   
</code></pre>
","25518"
"Importing and Displaying .fbx files","19341","","<p>I have a little problem with importing/displaying .fbx files.</p>

<p>I checked the examples but the ones which I am intrested the most (animation and texture) are badly documented for understanding by someone who is new to this like I am.</p>

<p>This is what I have tried: I managed to get the vertices and the normals but I'm stuck on getting the texture coords for each vertex.</p>

<p>Here is my code so far:</p>

<p>3dModelBasicStructs.h    </p>

<pre><code>struct vertex
{
float x,y,z;
};

struct texturecoords
{
float a,b;
};

struct poligon
{
int a,b,c;
};
</code></pre>

<p>Model.h</p>

<pre><code>#ifndef MODEL_H
#define MODEL_H
#define FBXSDK_NEW_API

#define MAX_VERTICES 80000

#include ""3dModelBasicStructs.h""

#include &lt;fbxsdk.h&gt;
#include &lt;iostream&gt;
#include &lt;GL/glut.h&gt;
using namespace std;

class Model
{

     public:

         Model(char*);
         ~Model();

         void ShowDetails();

         char* GetModelName();
         void  SetModelName( char* );
         void  GetFbxInfo( FbxNode* );
         void  RenderModel();


      private:

          char Name[25];

          vertex vertices[MAX_VERTICES];
          texturecoords txt[MAX_VERTICES];

          float *normals;
          int numNormals;

          int *indices;
          int numIndices;

          int numVertices;


};
#endif
</code></pre>

<p>Model.cpp</p>

<pre><code>#include ""Model.h""

Model::Model(char *filename)
{
cout&lt;&lt;""\nA model has been built!"";

numVertices=0;
numIndices=0;

FbxManager *manager = FbxManager::Create();

FbxIOSettings *ioSettings = FbxIOSettings::Create(manager, IOSROOT);
manager-&gt;SetIOSettings(ioSettings);

FbxImporter *importer=FbxImporter::Create(manager,"""");
importer-&gt;Initialize(filename,-1,manager-&gt;GetIOSettings());

FbxScene *scene = FbxScene::Create(manager,""tempName"");

importer-&gt;Import(scene);
importer-&gt;Destroy();

FbxNode* rootNode = scene-&gt;GetRootNode();
this-&gt;SetModelName(filename);
if(rootNode) { this-&gt;GetFbxInfo(rootNode); }

}

Model::~Model()
{
cout&lt;&lt;""\nA model has been destroyed!"";
glDisableClientState(GL_VERTEX_ARRAY);
}


void Model::ShowDetails()
{
cout&lt;&lt;""\nName:""&lt;&lt;Name;
cout&lt;&lt;""\nVertices Number:""&lt;&lt;numVertices;
cout&lt;&lt;""\nIndices Number:""&lt;&lt;numIndices;

}

char* Model::GetModelName()
{
return Name;
}

void Model::SetModelName(char *x)
{
strcpy(Name,x);
}

void Model::GetFbxInfo( FbxNode* Node )
{

int numKids = Node-&gt;GetChildCount();
FbxNode *childNode = 0;

for ( int i=0 ; i&lt;numKids ; i++)
{
    childNode = Node-&gt;GetChild(i);
    FbxMesh *mesh = childNode-&gt;GetMesh();

    if ( mesh != NULL)
    {
//================= Get Vertices ====================================
        int numVerts = mesh-&gt;GetControlPointsCount();

        for ( int j=0; j&lt;numVerts; j++)
        {
            FbxVector4 vert = mesh-&gt;GetControlPointAt(j);
            vertices[numVertices].x=(float)vert.mData[0];
            vertices[numVertices].y=(float)vert.mData[1];
            vertices[numVertices++].z=(float)vert.mData[2];
    //      cout&lt;&lt;""\n""&lt;&lt;vertices[numVertices-1].x&lt;&lt;"" ""&lt;&lt;vertices[numVertices-1].y&lt;&lt;"" ""&lt;&lt;vertices[numVertices-1].z;
        }
//================= Get Indices ====================================
        numIndices=mesh-&gt;GetPolygonVertexCount();
        indices = new int[numIndices];
        indices = mesh-&gt;GetPolygonVertices();
        cout&lt;&lt;numIndices;
//================= Get Normals ====================================


        FbxGeometryElementNormal* normalEl = mesh-&gt;GetElementNormal();
        if( normalEl)
        {
            numNormals = mesh-&gt;GetPolygonCount()*3;
            normals = new float[numNormals*3];
            int vertexCounter=0;
            for(int polyCounter = 0 ; polyCounter&lt;mesh-&gt;GetPolygonCount(); polyCounter++)
            {
                for(int i=0;i&lt;3;i++)
                {
                    FbxVector4 normal = normalEl-&gt;GetDirectArray().GetAt(vertexCounter);
                    normals[vertexCounter*3+0] = normal[0];
                    normals[vertexCounter*3+1] = normal[1];
                    normals[vertexCounter*3+2] = normal[2];
                    cout&lt;&lt;""\n""&lt;&lt;normals[vertexCounter*3+0]&lt;&lt;"" ""&lt;&lt;normals[vertexCounter*3+1]&lt;&lt;"" ""&lt;&lt;normals[vertexCounter*3+2];
                    vertexCounter++;
                }
            }
        }


    }
    this-&gt;GetFbxInfo(childNode);
}
}

void Model::RenderModel()
{
int i,j;
for(i=0;i&lt;numIndices-3;i++)
{
    glBegin(GL_TRIANGLES);
    glNormal3f(normals[i*3+0],normals[i*3+1],normals[i*3+2]); 
    for(j=i;j&lt;=i+2;j++)
            glVertex3f(vertices[indices[j]].x,vertices[indices[j]].y,vertices[indices[j]].z);
    glEnd();
}
}
</code></pre>

<p>My questions are:</p>

<ol>
<li>How do I get the texture coords?</li>
<li>How do I make blender export the texture in a photo format? (like .jpg or .tga)</li>
<li>Are there any mistakes in my displaying way so far?</li>
<li>Is there a project in the .fbx samples which only display a scene (including animation and texture; I couldn't find one myself)?</li>
</ol>
","<p><em>Regarding #1</em>: The method <a href=""http://docs.autodesk.com/FBX/2013/ENU/FBX-SDK-Documentation/index.html?url=cpp_ref/class_fbx_mesh.html,topicNumber=cpp_ref_class_fbx_mesh_html,hash=ab5244776beaf32682ed28ecc89f85502"" rel=""nofollow"">GetTextureUV</a> of FbxMesh should get the trick done.</p>

<p><strong>EDIT:</strong> The following code is untested and rougly copied from <a href=""http://www.ogre3d.org/forums/viewtopic.php?f=2&amp;t=13977"" rel=""nofollow"">here</a>:</p>

<pre><code>int polygonCount = mesh-&gt;GetPolygonCount();
for (int i = 0; i &lt; polygonCount; ++i) {

  FbxLayerElementArrayTemplate&lt;KFbxVector2&gt;* uvVertices= 0;
  mesh-&gt;GetTextureUV(&amp;uvVertices, KFbxLayerElement::eTextureDiffuse);

  for (int j = 0; j &lt; mesh&gt;GetPolygonSize(i); ++j) {

     FbxVector2 uv = uvVertices[mesh-&gt;GetTextureUVIndex(i, j)];

     texturecoords.a = uv[0];
     texturecoords.b = uv[1];

  }
}
</code></pre>

<p><strong>EDIT 2:</strong> 
I went through some other examples I found: There seems to be two similar classes: FbxVector2 and <a href=""http://download.autodesk.com/us/fbx/SDKdocs/FBX_SDK_Help/files/fbxsdkref/class_k_fbx_vector2.html"" rel=""nofollow"">KFbxVector2</a> where the latter one has the direct access to the included double values. Compare that example: </p>

<pre><code>KFbxLayerElementArrayTemplate&lt;KFbxVector2&gt;* lUVArray = NULL;    
pMesh-&gt;GetTextureUV(&amp;lUVArray, KFbxLayerElement::eDIFFUSE_TEXTURES); 

lUVArray-&gt;GetAt(mesh-&gt;GetTextureUVIndex(i, j)).mData[0];
</code></pre>

<p>Can you use those K* types?</p>

<p><strong>EDIT3:</strong> Those K* types are apparently from an older FBX SDK, so not relevant for everyone.</p>
","46805"
"Moving a character according to the animation, rather than code","19267","","<p>I'm using 3ds Max to export character animations in which my character is moving. I expected this to mean that the character will move in Unity, but it doesn't...</p>

<p>For example, if my animation (in 3ds Max) moves my character forward for a second, from <code>0,0,0</code> to <code>1,0,0</code>, in Unity, the character snaps back to <code>0,0,0</code> once the animation ends.</p>

<p>Is there a way to change the position of the character according to the <em>animation</em>, without something like <code>CharacterController.Move</code>?</p>
","<p>The prevailing wisdom has been to separate your animations from your movement. I.e. Animate the character in-place and move it via code. Dependent on your game type, this can indeed be the better method.</p>

<p>However, Unity (4.x) provides the <a href=""http://unity3d.com/unity/animation"">Mecanim</a> animation system, which allows for <a href=""http://docs.unity3d.com/Documentation/Manual/RootMotion.html"">root motion</a> to be applied from the animation to the character's in-game transform. In order for root motion from the animation to be applied, make sure the ""Apply Root Motion"" option is checked in the <a href=""http://docs.unity3d.com/Documentation/Components/class-Animator.html"">animator component</a>.</p>

<p>Mecanim will also retarget animations for humanoid rigs auto-magically. By using the retargeting with root motion, you can use the same animations for a long-legged character and a short-legged character, and the movement will then (auto-magically) line up with the animation.</p>

<p>Skeletal meshes should include an animator component by default as of Unity 4.3, and I believe this is still the case as of 4.3.4.</p>

<p>Using Mecanim will also require you to make an <a href=""http://docs.unity3d.com/Documentation/Components/class-AnimatorController.html"">Animator Controller</a>, which is a state machine for controlling your animations.</p>

<p>The Mecanim reference can be found in the <a href=""http://docs.unity3d.com/Documentation/Manual/MecanimAnimationSystem.html"">Unity manual pages here</a>.</p>
","69850"
"GLSL Shader Effects: How to do motion blur?","19229","","<p>I have a full 2D environment, with sprites going around as landscape, characters, etc.</p>

<p>To make it more state-of-art looking, I want to implement a motion blur effect, similar to modern FPS games (i.e. Crysis) blur when moving the camera quickly.</p>

<p>In a sidescroller, the desired effect is having this slight blur appearing to give the idea of fast movement when the camera is moving. If anyone could give me some tips on doing this, I'm assuming in a pixel shader, I'd be grateful.</p>
","<p>Keep a copy of the last framebuffer. Get the camera movement vector and invert it. Draw your scene as usual, then draw the last framebuffer with a slight offset (the camera delta you just calculated) and 0.75 alpha. Repeat as many times as you like to give the motion blur effect.</p>
","8819"
"What are some good jquery/javascript game engines?","19184","","<p>So I have decided to try a bit of javascript/html5 game development (worked with XNA/Unity so far).  Wondering if anyone had any suggestions.  I am currently looking at impact, gameQuery and Jaws.  </p>

<p>(also a little nervous that I won't be able to make as powerful games as in XNA...only doing 2d though)</p>
","<p>Here is a very good list on GitHub of JS game engines...</p>

<p><a href=""https://github.com/bebraw/jswiki/wiki/Game-Engines"">https://github.com/bebraw/jswiki/wiki/Game-Engines</a></p>

<p>As I've explored different JS game engines for a project, I've found that the good ones have good demos, where someone actually has made a real game with it to show what it can do.  <a href=""http://impactjs.com/"">Impact</a> is good for this, as is <a href=""http://www.limejs.com/"">LimeJS</a>.  Lack of demos doesn't mean bad engine necessarily, but it does show the developer has a sense of using their project for something actually functional.</p>

<p>Which ever you try, do make sure you test it out on all browsers, especially IE.  People hate on it, but <a href=""http://en.wikipedia.org/wiki/Usage_share_of_web_browsers"">a lot of people use it</a>.</p>

<p>PS</p>

<p>A shout out for <a href=""http://craftyjs.com/"">Crafty</a> for having some good polish on the website along with good documentation.</p>
","16028"
"Is C# viable for a real-time game server?","19165","","<p>Most of the question is in the title.</p>

<p>Basically, I'm starting to develop a 2D multiplayer action game. The client is (probably) going to be in XNA, and I thought I'd ask here about whether it's a good idea to use C# for server side development as well.</p>

<p>I guess the fact that the language is managed is not something problematic as Java is being used in even MMO game servers (correct me if I'm wrong), so are there any reasons to avoid C# for this purpose? I need it to be fast and responsive, to communicate over TCP, to chat with an SQL server. And if there is no reason to avoid C#, how would I deploy such a web server, would it be a .NET EXE running on the server machine?</p>
","<p>Not only viable, but really good, in my experience. I've developed several MMO servers using C#, and I must say I never regretted the choice of language and platform.</p>

<p>There are lots of great libraries and tools for C# and .NET in general - network, logging, O/R mapping, etc. And, compared to Java C# is more expressive and less verbose (some people might argue about this, though..)</p>

<p>The GC ""overhead"" that scares some people is not really an issue, unless you happen to abuse it with billions of allocations per second. As an example, our current server allocates up to 50 mb/second under heavy load, and GC does not introduce any noticeable lag. We did have to use object pooling in strategic places, though - most importantly, objects representing network packets are pooled and not garbage-collected. Still, even with pooling turned off, GC is not the biggest problem.</p>

<p>As an example of how cool C# is, this is what we recently implemented. Our server runs several WCF services, that the game client uses for non-time-critical tasks, and we also use them for server administration. It turns out, it's very easy to make a WCF service to simply return our game objects to the caller. So we did just that, then made a little plugin to LINQPad that connects to our server - and now we can run queries like</p>

<pre><code>from character in Service.GetOnlineCharacters()
where character.LocationManager.LocationId==5 &amp;&amp; character.Attributes.Level&lt;10
select new { character.Id, character.Nick }
</code></pre>

<p>On a live server, no less! I don't think you can do this with any other platform. Not in couple day's work, at least.</p>
","10166"
"How can I move a sprite in the direction it is facing?","19161","","<p>I'm using Java/Slick 2D. I'm trying to use the mouse to rotate the sprite and the arrow keys to move the sprite. I can get the sprite to rotate no problem, but I cannot get it to move in the direction it is supposed to. When I hit ""forwards"", the sprite doesn't necessarily move towards the mouse. Actually, it will only move towards the left of the screen really. I'm sure there has to be some standard code for this since many games use this style of motion. Can anyone help me out with what the trig is supposed to be? Thanks</p>

<p>EDIT: Here is the rotation code (which does something else weird: <a href=""https://stackoverflow.com/questions/12610320/why-is-my-image-rotating-off-center"">https://stackoverflow.com/questions/12610320/why-is-my-image-rotating-off-center</a>)</p>

<pre><code>int mX = Mouse.getX();
        int mY = HEIGHT - Mouse.getY();
        int pX = sprite.x;
        int pY = sprite.y;
        int tempY, tempX;
        double mAng, pAng = sprite.angle;
        double angRotate=0;

        if(mX!=pX){
            mAng = Math.toDegrees(Math.atan2(mY - pY, mX - pX));
            if(mAng==0 &amp;&amp; mX&lt;=pX)
                mAng=180;
        }
        else{
            if(mY&gt;pY)
                mAng=90;
            else
                mAng=270;
        }

        sprite.angle = mAng;
        sprite.image.setRotation((float) mAng); 
</code></pre>

<p>And the movement code. I can only move towards the left of the screen...</p>

<pre><code>double ang = sprite.angle;
            Input input = gc.getInput();

            if(input.isKeyDown(sprite.up)){
                sprite.x += Math.cos(ang)*sprite.moveSpeed;
                sprite.y += Math.sin(ang)*sprite.moveSpeed;
            }if (input.isKeyDown(sprite.down)){
                sprite.x += -1*Math.cos(ang*Math.PI/180)*sprite.moveSpeed;
                sprite.y += -1*Math.sin(ang*Math.PI/180)*sprite.moveSpeed;
            }if (input.isKeyDown(sprite.left)){
                sprite.x -= Math.cos(ang*Math.PI/180)*sprite.moveSpeed;
                sprite.y += Math.sin(ang*Math.PI/180)*sprite.moveSpeed;
            }if (input.isKeyDown(sprite.right)){
                sprite.x += Math.cos(ang*Math.PI/180)*sprite.moveSpeed;
                sprite.y -= Math.sin(ang*Math.PI/180)*sprite.moveSpeed;
            }
</code></pre>
","<p>You'll want to get a vector based on your current velocity and heading. Then use that vector to increment your position.</p>

<pre><code>//first get the direction the entity is pointed
direction.x = (float) Math.cos(Math.toRadians(rotation));
direction.y = (float) Math.sin(Math.toRadians(rotation));
if (direction.length() &gt; 0) {
    direction = direction.normalise();
}
//Then scale it by the current speed to get the velocity
velocity.x = direction.x * speed;
velocity.y = direction.y * speed;
</code></pre>

<p>So now you know your velocity based on your rotation. You can the update your position with that information.</p>

<pre><code>//Update the position based on our current speed
//This is basic s = vt physics
position.x += velocity.x * timeElapsed;
position.y += velocity.y * timeElapsed;
</code></pre>
","37627"
"Why are games built on cross-platform engines sometimes exclusive to Windows?","19155","","<p>If an engine supports Windows, OS X, and Linux, why do we sometimes see games using these engines, like <em>Space Hulk: Deathwing</em>, restricted to Windows only? </p>
","<p><strong>Technical Reasons:</strong></p>

<ul>
<li><strong>Game made platform specifically</strong>: When some developers are making their games, they can sometime rely on platform specific functions. While the game engine will build the game for multiple platforms, the non-game specific code might make a Windows specific call that either doesn't exist on other platforms or would require remaking a difficult part of the game (Licensing services, File Saving systems, etc.).</li>
<li><strong>Lack of Capable Machines</strong>: For a long time, most Apple computers did not come with enough graphics power to run most games. So why release somewhere where the users will most likely only have a bad experience? This is slowly changing, thanks to better integrated graphics, but might still be a reason why some go Windows only.</li>
<li><strong>Plugin/Library compatibility</strong>: Game developers might use 3rd party libraries to help speed up development or use industry standard/validated code (SSL, Serialisation libraries, etc). If these don't support platform X, the game most likely won't run reliably on it, so they get excluded.</li>
<li><strong>Increased QA</strong>: During game development, there is a small subsection of the team that ensures that there are no bugs and that the game meets performance standards. Once you add a platform, the game must essentially be tested twice! The generic parts of the game could be left alone, but there is still much more testing to do before release. This can also lead to increased cost, not only with the additional time needed but also specialised hardware, depending on the platform (Apple, Xbox, PlayStation, Phones, etc.).</li>
<li><strong>Increased Support</strong>: As games release they will have bugs (some games more than others). As you add more platforms, the amount of post-release support the developer has to do increases. Platform-specific bugs will have to be fixed in a way that fixes it for the broken platform and doesn't affect the platforms which are not affected. If a platform changes, say, Windows 7 to 8 or an OSX iteration, there will have to be some level of QA to ensure that there are no bugs on the newer version. And, if there are, that is yet another platform that must be supported alongside the older version. This can have a huge affect on cost, especially after the game has launched (were the game to not make a lot of money), 3-6 months after release.</li>
</ul>

<p><strong>Non-Technical Reasons:</strong></p>

<ul>
<li><strong>Publisher Agreement</strong>: Some developers will have agreements with the platform holder to release specifically on their platform. While this happens more with consoles, this could also be the case for PC platforms (e.g., Windows).</li>
<li><strong>First party Developer</strong>: Some developers are owned by the platform holder and are not allowed to release their games on specific platforms. You likely won't see Halo on PS4 or Forza on Mac.</li>
<li><strong>Lack of an audience</strong>: Developers have lots of statistics about consumer trends on specific platforms, especially if they have large publishers with lots of data available. If they have information that says that 90% of their target audience is on Windows, they might not bother to release on other platforms to try and reduce potential bugs or/and keep the marketing material focussed.</li>
<li><strong>Does not meet Platform Requirements</strong>: Some platforms such as Apple's App Store have strict requirements on layout and design that need to be followed in order to be published. If a game doesn't meet these requirements for a popular distribution platform, it might not be worth the engineering time to adapt the game and release it if there are not enough predicted sales.</li>
<li><strong>Lack of experience with a platform</strong>: If the developer has solely worked with Windows (and there are no/few people with experience of other systems), it might be a lot of work to learn the small differences that can cause issues late in development. Or there might not be enough budget to hire new staff to be in charge of a Linux/OSX build.</li>
</ul>

<p>I'm sure there are more. These are just some of the top of my head. Hope this helps.</p>
","144587"
"Is UDP still better than TCP for data-heavy realtime games?","18891","","<p>I know that UDP is usually recommended for real-time multiplayer games with high data usage.</p>

<p>Most articles are serval years old, and since ~80% of all data transmitted on the internet is TCP, a lot of optimization must have been done for TCP.</p>

<p>This make me wonder: is UDP still superior in terms of speed and latency?  Could recent TCP optimizations have made TCP perform better than UDP?</p>
","<p>No, UDP is still superior in terms of <s>performance</s> latency, and will always be faster, because of the philosophy of the 2 protocols - assuming your communication data was designed with UDP or any other lossy communication in mind.</p>

<p>TCP creates an abstraction in which all network packets arrive, and they arrive in the exact order in which they were sent. To implement such an abstraction on a lossy channel, it must implement retransmissions and timeouts, which consume time. If you send 2 updates on TCP, and a packet of the first update gets lost, you will not see the second update until:</p>

<ol>
<li>The loss of the first update is detected.</li>
<li>A retransmission of the first update is requested.</li>
<li>the retransmission has arrived and been processed.</li>
</ol>

<p>It doesn't matter how fast this is done in TCP, because with UDP you simply discard the first update and use the second, newer one, right now. Unlike TCP, UDP does not guarantee that all packets arrive and it does not guarantee that they arrive in order.</p>

<p>This requires you to send the right kind of data, and design your communication in such a way that losing data is acceptable. </p>

<p>If you have data where every packet must arrive, and the packets must be processed by your game in the order they were sent, then UDP will not be faster. In fact using UDP in this case would likely be slower because you're reconstructing TCP and implementing it by means of UDP in which case you might as well use TCP.</p>

<p>EDIT - Adding some additional information to incorporate/address some of the comments:</p>

<p>Normally, the packet loss rate on Ethernet is very low, but it becomes much higher once WiFi is involved or if the user has an upload/download in progress. Let's assume we have a perfectly uniform packet loss of 0.01% (one way, not round-trip). On a first person shooter, clients should send updates whenever something happens, such as when the mouse cursor turns the player, which happens about 20 times per second. They could also send updates per frame or on a fixed interval, which would be 60-120 updates per second. Since these updates get sent at different times, they will/should be sent in one packet per update. On a 16 player game, all 16 players send these 20-120 packets per second to the server, resulting in a total of 320-1920 packets per second. With our packet loss rate of 0.01%, we expect to lose a packet every 5.2-31.25 seconds. In this example we ignore the packets sent from the server to the players for simplicity.</p>

<p>On every packet we receive after the lost packet, we'll send a DupAck, and <a href=""https://blogs.technet.microsoft.com/networking/2011/05/16/tcp-dupacks-and-tcp-fast-retransmits/"" rel=""nofollow noreferrer"">after the 3rd DupAck the sender will retransmit the lost packet</a>. So the time TCP requires to initiate the retransmit is 3 packets, plus the time it takes for the last DupAck to arrive at the sender. Then we need to wait for the retransmission to arrive, so in total we wait 3 packets + 1 roundtrip latency. The roundtrip latency is typically 0-1 ms on a local network and 50-200 ms on the internet. 3 packets will typically arrive in 25 ms if we send 120 packets per second, and in 150ms if we send 20 packets per second.</p>

<p>In contrast, with UDP we recover from a lost packet as soon as we get the next packet, so we lose 8.3 ms if we send 120 packets per second, and 50 ms if we send 20 packets per second.</p>

<p>With TCP things get messier if we also need to consider <a href=""https://en.wikipedia.org/wiki/Nagle%27s_algorithm"" rel=""nofollow noreferrer"">Nagle</a> (if the developer forgets to turn off send coalescing, or <a href=""https://stackoverflow.com/questions/22583941/what-is-the-workaround-for-tcp-delayed-acknowledgment"">can't disable delayed ACK</a>), <a href=""https://en.wikipedia.org/wiki/TCP_tuning"" rel=""nofollow noreferrer"">network congestion avoidance</a>, or if packet loss is bad enough that we have to account for multiple packet losses (including lost Ack and DupAck). With UDP we can easily write faster code because we quite simply don't care about being a good network citizen like TCP does.</p>
","120057"
"Complex Game AI for Turn-based Strategy Games","18866","","<p>I'm doing some research for a turn-based Strategy game project and looking for good resources on this topic. The game is a typical war game where countries can fight each other, deploy units and have these units move around on a hexagonal tilemap, attack each other, etc.</p>

<p>I'm particularly interested in how the AI of Civilization V is organized! According to Wikipedia the game uses four different AI systems for different layers of the game's AI:</p>

<ul>
<li>tactical AI controls individual units</li>
<li>the operational AI oversees the entire war front</li>
<li>the strategic AI manages the entire empire</li>
<li>the grand strategic AI sets long-term goals and determines how to win the game</li>
</ul>

<p>Conceptually this looks like it makes a lot of sense to achieve a complex AI and it makes me curious to find out about how these different AI systems work (and work together). The tactical AI is probably the most easy to understand since it handles the decision-making for a single unit (move, attack, repair, retreat, etc.) but I think the other AI systems are where it really gets interesting. For example what does the operational AI do and how does it do that? I'm sure these are best-kept secrets by Firaxis Games but it would be cool to get some discussion started on this to find out more about it.</p>

<p>Also if anyone knows any good books that handle turn-based strategy game AI it would be great to know. Obviously this is a sparsely seeded topic on the web. I got ""Programming Game AI by Example"" but that book is more about single agent behavior AI than high-level goal-oriented AI.</p>
","<p>Whilst I agree with DampeS8N's opening paragraph (i.e. game AI only needs to be smart enough to make the player <em>think</em> that it's smart), I feel that this question needs a little more elaboration. The data structures in use could be FSMs for all levels, but that doesn't really answer the question as to <em>how</em> the individual systems work.</p>

<p>Disclaimer: I have hardly played the Civilization games so my understanding of the gameplay is limited. If there are any obvious errors, I do apologise. Please correct me, and I'll gladly edit.</p>

<p>I'll be taking quotes from the original <a href=""http://uk.pc.ign.com/articles/107/1075587p1.html"">IGN Article</a>.</p>

<p><strong>1. Tactical AI</strong>  </p>

<blockquote>
  <p>At the lowest level, the tactical AI uses the forces at hand to win a battle on a local scale.</p>
</blockquote>

<p>This is probably the most standard part of the subsystem. There are limitless ways to carry this out from using FSMs, Behaviour Trees (or even performing random actions, depending on the difficulty of the AI). </p>

<p>However, since this is a turn based game, similar to Risk, I think what is more likely happening is that each unit is assigned a score. There are then multipliers attached to this score depending on different variables (allegiances, terrain bonuses, etc). </p>

<p>The outcome is then calculated by something like this:</p>

<pre><code>If (AI unit score &gt;&gt; (much greater) enemy unit score) Then Completely destroy enemy unit
If (AI unit score &gt; (somewhat greater) enemy unit score) Then Partially destroy enemy unit
If (AI unit score &lt; (somewhat less) enemy unit score) Then Partially destroy AI unit
If (AI unit score &lt;&lt; (much less) enemy unit score) Then Completely destroy AI unit
</code></pre>

<p>It makes sense that the AI will try and maximize this score when in battle.</p>

<p>Add in an epsilon value (e.g. small random chance of failure/success) and you've got a pretty decent looking AI (no one wants a perfect opponent, that's just not fun!).</p>

<p><strong>2. Operational AI</strong></p>

<blockquote>
  <p>One step up from that, the operational AI picks which battles to fight and makes sure that the necessary forces are available.</p>
</blockquote>

<p>I think there are a couple of points to this:</p>

<ul>
<li>Evaluating current strength</li>
<li>Reinforcement of units</li>
<li>Evaluating which fights to pick/avoid</li>
</ul>

<p><em>Evaluating Current Strength</em> - This just screams <a href=""http://aigamedev.com/open/tutorial/influence-map-mechanics/"">Influence Map</a> to me. It can be easily represented on a hex grid. As this subsystem is combat oriented, the influence values can be representative of the strength values of each unit in the vicinity. If you have a massive army focused in a small area of hexagons, the influence value will be huge and the operational AI will take this into account when evaluating fights to pick. Don't forget, the influence values of opposing armies will also be calculated. This allows the operational AI to predict potential incoming threats.</p>

<p><em>Reinforcements of units</em> - By receiving information on opposing factions from the influence map, the AI can determine which units are under the most threat. The AI can then issue a command to close-by units to go and reinforce the threatened parties.</p>

<p><em>Evaluating which fights to pick/avoid</em> - A couple of situations can occur here. If the AI detects a unit is under threat AND there are no nearby units to help it could a) decide to sacrifice the unit (if they're just lowly infantry, instead of an irreplaceable general, for example) or b) Order the unit to retreat. Conversely, if the AI detects a weak enemy unit near an army, it could order the units to take this enemy out.</p>

<p><a href=""http://www.csse.uwa.edu.au/cig08/Proceedings/papers/8075.pdf"">Here's a decent paper</a> that makes use of influence maps in Real Time Strategy games.</p>

<p><strong>3. Strategic AI</strong></p>

<blockquote>
  <p>Moving even higher, the strategic AI manages the empire as a whole, focusing on where to build cities and what to do with them.</p>
</blockquote>

<p>""Where should I build a city?"" just sounds like position evaluation. Chess programs and other games use it to determine the desirability of a given position. For example:</p>

<p>Hex A: Close to resources, on high terrain, close to allies, close to enemy
Hex B: Far from resources, on mid level terrain, medium distance from allies, far from enemy</p>

<p>The position evaluation function could take these three factors like so:</p>

<pre><code>Score = Proximity to resources (closer yields a higher score) + 
terrain elevation (higher yields higher score) + 
proximity to allies (closer is better) + 
proximity to enemies (farther is better)
</code></pre>

<p>And whichever hexagon has the higher score, will be where the city is built. More information on evaluation functions can be found <a href=""http://www.cgf-ai.com/docs/straatman_remco_killzone_ai.pdf"">here</a>.</p>

<p>I reckon the strategic AI also has a bunch of pseudo-prebaked strategies in the game depending on the type of victory the AI is going for.</p>

<p><strong>4. Grand Strategic AI</strong></p>

<blockquote>
  <p>At the top of the ladder is the grand strategic AI, which decides how to win the game.</p>
</blockquote>

<p>I think this is probably the simplest of the bunch, and it gives the impression that it's more impressive than it really is. In a game such as this, there will only be a finite number of victory types. The article mentions a Conquest victory, assuming that there are also Alliance victories, etc, it could be as simple as randomly picking one of the types and then pass it onto the other systems.</p>

<p>EDIT: Of course as pointed out by DampeS8N, the type of map could dictate the best victory condition to go for, in which case it could be hardcoded by the designers or some sort of evaluation function factoring in different variables.</p>

<p><strong>Summary</strong><br>
I think what's really important to note about this kind of system is that the way the subsystems are layered, they don't actually need to be communicating a great deal with eachother. It looks to be a top-down architecture with the components loosely coupled. From a technical design point-of-view it's clean and it's flexible and probably takes its inspiration from <a href=""http://en.wikipedia.org/wiki/Emergence"">Emergent Behaviour</a> and/or the <a href=""http://en.wikipedia.org/wiki/Subsumption_architecture"">Subsumption Architecture</a>.</p>

<p>I really do apologise for the length of this post, it's turned into a bit of a beast :(</p>

<p>Either way, I hope it helps!</p>
","21617"
"How do I unload a scene after doing LoadLevelAdditive?","18763","","<p>I have scene A loaded.</p>

<p>I load scene B with LoadLevelAdditive.</p>

<p>How do I unload scene B and keep scene A loaded?</p>
","<p>You essentially need to Destroy(..) the GameObjects that came from your 2nd scene, manually. </p>

<p>Quick solution: for your 2nd scene, make an empty root GameObject positioned at global 0,0,0. Any other GameObject in your scene becomes a child of that. After loading the 2nd scene additively, the root will be in the hierarchy. Just Destroy(...) the root, and all GameObjects that came from the 2nd scene will be deleted too.</p>
","71751"
"Android game development in c++","18705","","<p>So being a primarily c/c++ developer, I've always thought that the only option for mobile game development for me was using iOS, which allows for c/c++ (and minimising objective C).</p>

<p>I heard from a friend though, that android has a native development toolkit which allows for c++ code to work on android.</p>

<p>Has anyone used this, and if so, how do you find it? I mean, will it ""just work"" like iOS, or are there more considerations that need to be taken care of due to the wide variety of android devices available?</p>
","<p>Android APIs are Java. Since 2010, Google provides the NDK (a SDK) for C/C++ developers. </p>

<p>The NDK offers two ways:</p>

<ul>
<li>for android 1.5 devices, you can load an elf library and uses it from the java application via a JNI  bridge</li>
<li>for android 2.3 devices, you can use a NativeActivity to bypass the Java Activity code for Fullscreen Application.</li>
</ul>

<p>The NDK offers few C/C++ API:</p>

<ul>
<li>a pseudo libc called bionics: many functions aren't availabled</li>
<li>a pthread library</li>
<li>OpenGL ES 1.x (>Android 1.5) and OpenGL ES 2.x (Android 2.0)</li>
<li>OpenSL (limited support on Android 2.3) </li>
</ul>

<p>But many API are Java only (also available via JNI).</p>

<p>NDK 5 version is the first usable for C++ developers because it offers:</p>

<ul>
<li>RTTI</li>
<li>Exceptions supports</li>
<li>STLport</li>
<li>gdb support for multi-threaded programs</li>
</ul>

<p>The most painful operation is debugging on android devices. So i develop my own multi-platform framework (OS X, Windows, Linux, iOS and Android) to debug first on desktop platform, next iOS platform (on Simulator) and Last (Android).</p>

<p>The android Emulator (not a simulator) have a poor performance and can't emulate OpenGL ES 2.x. I recommend real devices to develop.</p>

<p>You can find many useful informations :</p>

<ul>
<li><a href=""http://www.iopixel.com/blog/keyboard-input-with-ndk/"">input code</a></li>
<li><a href=""http://www.philhassey.com/blog/2010/07/20/android-day-1-sdk-eclipse-ide-and-device-activation/"">Phil hassley porting Galcon</a>  (10 articles)</li>
</ul>
","9303"
"Algorithms for rainfall + river creation in procedurally generated terrain","18694","","<p>I've recently become fascinated by the things that can be done with procedurally terrain and have started experimenting with world building a bit. I'd like to be able to make worlds something like Dwarf fortress with biomes created from meshing together various maps.</p>

<p>So first step has been done. Using the diamond-square algorithm I've created some nice hieghtmaps. Next step is I would like to add some water features and have them somewhat realistically generated with rainfall. I've read about a few different approaches such as starting at the high points of the map, and ""stepping"" down to the lowest neighboring point, pooling/eroding as it works its way down to sea level.</p>

<p>Are there any documented algorithms with this or are they more off the cuff?</p>

<p>Would love any advice/thoughts.</p>
","<p>Amit Patel, a user of this site, has created a <a href=""http://www-cs-students.stanford.edu/~amitp/game-programming/polygon-map-generation/"" rel=""noreferrer"">wonderful resource</a> of information about random world generation that will certainly be of use to you.</p>

<p>Further there are some great questions/answers about procedural generation on this site.</p>

<p><a href=""https://gamedev.stackexchange.com/questions/31263/road-river-generation-on-2d-grid-map"">Road / river generation on 2d grid map</a></p>

<p><a href=""https://gamedev.stackexchange.com/questions/14004/procedural-world-generation-oriented-on-gameplay-features"">Procedural world  generation oriented on gameplay features</a></p>

<p><a href=""https://gamedev.stackexchange.com/questions/29044/how-can-i-generate-random-lakes-and-rivers-in-my-game"">How can I generate random lakes and rivers in my game?</a></p>

<p><a href=""https://gamedev.stackexchange.com/questions/31241/random-map-generation?lq=1"">Random map generation</a></p>
","45405"
"How can I make OpenGL textures scale without becoming blurry?","18664","","<p>I'm using OpenGL through LWJGL.</p>

<p>I have a 16x16 textured quad rendering at 16x16. When I change it's scale amount, the quad grows, then becomes blurrier as it gets larger.</p>

<p><em>How can I make it scale without becoming blurry, like in Minecraft.</em></p>

<p>Here is the code inside my RenderableEntity object:</p>

<pre><code>public void render(){       
    Color.white.bind();
    this.spriteSheet.bind();        
    GL11.glBegin(GL11.GL_QUADS);
        GL11.glTexCoord2f(0,0);
        GL11.glVertex2f(this.x, this.y);
        GL11.glTexCoord2f(1,0);
        GL11.glVertex2f(getDrawingWidth(), this.y);
        GL11.glTexCoord2f(1,1);
        GL11.glVertex2f(getDrawingWidth(), getDrawingHeight());
        GL11.glTexCoord2f(0,1);
        GL11.glVertex2f(this.x, getDrawingHeight());
     GL11.glEnd();

}
</code></pre>

<p>And here is code from my initGL method in my game class</p>

<pre><code>GL11.glEnable(GL11.GL_TEXTURE_2D);
GL11.glClearColor(0.46f,0.46f,0.90f,1.0f);
GL11.glViewport(0,0,width,height);
GL11.glOrtho(0,width,height,0,1,-1);
</code></pre>

<p>And here is the code that does the actual drawing</p>

<pre><code>public void start(){
    initGL(800,600);
    init();

    while(true){
        GL11.glClear(GL11.GL_COLOR_BUFFER_BIT);

        for(int i=0;i&lt;entities.size();i++){
            ((RenderableEntity)entities.get(i)).render();
        }

        Display.update();
        Display.sync(100);

        if(Display.isCloseRequested()){
            Display.destroy();
            System.exit(0);
        }
    }
}
</code></pre>
","<p>You need to change the texture magnification type, like so:</p>

<pre><code> glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
</code></pre>

<p>Read about <a href=""http://www.opengl.org/sdk/docs/man/xhtml/glTexParameter.xml"">glTexParameter</a>.</p>
","19076"
"Why can't cross-platform multiplayer games exist?","18618","","<p>At least, why are they so difficult to make? - assuming that's the reason why not even AAA studios accomplish this feat for their games. Especially with modern cross-platform game engines like Unreal and Unity that can build on Xbox, PS4, and PC, why hasn't this been done yet on a large scale?</p>

<p>For example, Diablo III is a game released on a variety of platforms. Despite it being a product of Blizzard, one of the wealthiest video game companies in the world, it does not allow an Xbox player to play with someone using a PC.</p>
","<p>It's no real hardware or software limitation. Cross-platform gameplay <strong>is</strong> possible, if implemented. <strong>Final Fantasy XIV - A Realm Reborn</strong> is a perfect example, featuring cross-play between consoles and PC.</p>

<p>If a game is released on multiple consoles and/or as a PC game in parallel, non-cross-platform multiplayer is most likely a design decision either due to contractual reasons or for fairness.</p>

<p>A very recent example for both would be <strong>The Elder Scrolls Online: Tamriel Unlimited</strong>. The game has been released on PC/Mac last year. Both platforms play on the same servers, so are able to play against each other or together.</p>

<p>However, both console versions they're releasing next month (PS4 and Xbox One) will be limited to their own platforms, i.e. PS4 players won't be able to play with non-PS4 players and XBOne players won't be able to play with non-XBOne players (and the same for PC/Mac).</p>

<p>The game is played on a different pace and precision when comparing mouse/keyboard and gamepad controls and since there's PvP involved, this would get PC/Mac players a clear advantage (let's ignore the fact that consoles might support mouse and keyboard, it's not the preferred input schema there).</p>

<p>But even besides that, couldn't PS4 and Xbox One players play with or against each other? Sure they can, but I guess neither Microsoft nor Sony really want this (<em>Want to play with your friend? Buy him one of our consoles!</em>).</p>

<p>Similar considerations might have existed for <strong>Diablo III</strong>, although it's no real PvP game (besides duelling).</p>

<p>The differences you mention in number of players etc. are another thing, mostly due to hardware power and framerate issues I guess. These wouldn't prevent cross-platform gameplay though, just prevent console players from entering 64 player servers (for example).</p>
","101050"
"How can I find the perpendicular to a 2D vector?","18585","","<p>I'm making a top down game where the player moves forwards towards the position of the mouse cursor. As part of the player's movement code, I need to determine a vector that is perpendicular to the player's current facing vector (to implement strafing behavior).</p>

<p>How can I compute the perpendicular vector of a given 2D vector?</p>
","<p>To get the 2D vector perpendicular to another 2D vector simply swap the <code>X</code> and <code>Y</code> components and negate the new <code>Y</code> component. So <code>{ x, y }</code> becomes <code>{ y | -x }</code>.</p>
","70076"
"Creating offline multiplayer Android games with Unity","18585","","<p>Is it possible to create offline multiplayer Android games with Unity (played over bluetooth/ wi-fi)?
If so, then I would like to create a 2 player game prototype, containing a single room (empty cube) with 2 cubes (3rd person controllers) - each controlled by one player. The cubes can be moved about as their owners (players) wish. Any movement made by any of the 2 players can be seen in realtime in the other player's display.
How do I achieve this?</p>

<p>P.S. I know some basics of Unity. I have already created a small hack &amp; slash game in Unity (PC-standalone). I am new to Unity Android, though.</p>
","<p>Yes, it is possible to create offline multi-player games with Unity3D. You can achieve this most easily by using Unity's built in Master Server.</p>

<p><a href=""http://docs.unity3d.com/Documentation/Components/net-MasterServer.html"" rel=""nofollow"">Unity3D Master Server</a></p>

<p>A good tutorial for learning how to use Unity's built in networking can be found here:
<a href=""http://www.scribd.com/doc/38400039/M2H-Unity-Networking-Tutorial"" rel=""nofollow"">M2H Networking Tutorial</a></p>
","51667"
"Can I use popular classical music as my game's soundtrack?","18546","","<p>Can I use popular classical music in my game as a soundtrack? I'm concerned about copyright protection. I don't plan to make money off of my game.</p>

<p>Will I break some law if I do that?</p>
","<h2><strong>No.</strong></h2>

<p><em>In most cases... also, I am not a lawyer, find one they help.</em></p>

<p>Arrangements of, and recordings of, specific performances of classical music are both copyrighted separately. This means that even if a piece in its original form is in the public domain, the piece itself is still someone's active intellectual property.</p>

<h2>So, when can you use classical music?</h2>

<p><em>(Also, this list isn't exhaustive; get a lawyer, really.)</em></p>

<ul>
<li>The piece needs to be in the public domain. </li>
<li>You have to have the sheet music as it exists in the public domain. This usually means originals, but sometimes people release their later arrangements to the public. It's safer to have someone that can confirm that it is the public domain arrangement and not someone's later copyrighted work.</li>
<li>You need to then perform &amp; record the piece (yourself, or hire a band or orchestra to play the piece. Make sure you get the rights when you do this also)</li>
</ul>

<p>Then there may be a few more things to consider. But when it comes down to it unless you are an awesome musician with a lot of time on your hands to find music that is in the clear (and have a lawyer to confirm that it is) you'd save a lot of money to just license music. If you are an awesome musician, you still save a lot of time by just licensing music.</p>
","23499"
"Is it possible to rotate an image on an HTML5 canvas, without rotating the whole canvas?","18535","","<p>So I basically want to rotate single sprites on the canvas without rotating the whole canvas, is that someway possible. </p>

<p>I also don't want to create a new canvas for each object I have.</p>

<p>Also, it would be interesting to know which solution is then the most performant.</p>
","<blockquote>
  <p>It’s important to note that changing the co-ordinate system with
  rotate and translate do not affect anything that’s currently drawn
  into the canvas. <strong>It only affects subsequent drawing actions</strong>.</p>
</blockquote>

<pre><code>var TO_RADIANS = Math.PI/180; 
function drawRotatedImage(image, x, y, angle)
{ 
    // save the current co-ordinate system 
    // before we screw with it
    context.save(); 

    // move to the middle of where we want to draw our image
    context.translate(x, y);

    // rotate around that point, converting our 
    // angle from degrees to radians 
    context.rotate(angle * TO_RADIANS);

    // draw it up and to the left by half the width
    // and height of the image 
    context.drawImage(image, -(image.width/2), -(image.height/2));

    // and restore the co-ords to how they were when we began
    context.restore(); 
}
</code></pre>

<p>Source: <a href=""http://creativejs.com/2012/01/day-10-drawing-rotated-images-into-canvas/"">http://creativejs.com/2012/01/day-10-drawing-rotated-images-into-canvas/</a></p>
","67276"
"How do I determine my games minimum hardware/software requirements?","18420","","<p>With me going it alone in development I only have limited resources at my disposal i.e one pc with which I develop and test the game. so I only know for certain my game works with that setup.</p>

<p>What options have I got in testing the game on the many different hardware/operating system combinations? Its a windows desktop game.</p>
","<p>Off the top of my head I'd suggest trying to run the game on a few other PCs from friends or relatives. After that you might want to consider some form of beta test, i.e. publishing a demo or something so you can get community feedback.</p>
","439"
"How can I use XNA with Visual Studio Express 2013 for Windows?","18407","","<p><a href=""http://dev.windowsphone.com/en-us/downloadsdk"">http://dev.windowsphone.com/en-us/downloadsdk</a></p>

<p>I downloaded the current version of Visual Studio to develop Windows Phone apps, but I don't know how to add XNA. I tried to install XNA, but it's not working with Visual Studio.</p>

<p>How can I use XNA with Visual Studio Express 2013 for Windows?</p>
","<p><a href=""https://msxna.codeplex.com/wikipage?title=How%20install%20XNA%204.0%20on%20Visual%20Studio%202013&amp;referringTitle=Documentation"">How install XNA 4.0 on Visual Studio 2013</a> </p>

<ol>
<li><a href=""https://msxna.codeplex.com/releases"">Download XNA 4.0 Refresh</a> (Visual Studio 2013)</li>
<li>Unzip archive</li>
<li>Install DirectX from the archive</li>
<li>Install Xna Framework 4.0 Redistribution from the archive</li>
<li>Install Xna Game Studio 4.0 Platform Tools from the archive</li>
<li>Install Xna Game Studio 4.0 Shared from the archive</li>
<li>Install XNA Game Studio 4.0.vsix from the archive</li>
</ol>
","73240"
"What's the process for making a PS4 game?","18401","","<p>Now that Sony has said that devs can self publish for PS4, I'm betting that a lot more people will be interested in producing games for that platform.</p>

<p>What is the process for getting the SDK, documentation, and testing environment for a PS4?</p>
","<p>Thus far, there is no indication that Sony's self-publishing option for the PlayStation 4 is actually an <em>open</em> publishing environment (like the PC). You still need to become a registered developer and that still involves being vetted and approved by Sony, licensing hardware, et cetera.</p>

<p>According to this <a href=""http://us.playstation.com/corporate/about/press-release/scea-partners-with-worlds-most-talented-developers-to-expand-industry-for-all-ps-platforms.html"">press release</a>:</p>

<blockquote>
  <p>For more information about the SCEA Publisher and Developer Relations
  Group, please visit: <a href=""http://us.playstation.com/develop"">http://us.playstation.com/develop</a> or email
  selfpublish@playstation.sony.com.</p>
</blockquote>

<p>You will note that the linked site details a four-step process to register, but notes that, before applying, the following requirements should be met:</p>

<ul>
<li>Form a corporate entity and have a tax ID number.</li>
<li>Have a static IP for your company that Sony can whitelist for developer network access.</li>
<li>Be physically located in US, Mexico, Central America, South America, or Canada.</li>
</ul>

<p>The actual online application form asks for various other things an established company should have, as well as information about your development history and published titles, six-month product development plan, et cetera.</p>
","57313"
"How to detect 2D line on line collision?","18383","","<p>I'm a flash actionscript game developer who is a bit backward with mathematics, though I find physics both interesting and cool.</p>

<p>For reference this is a similar game to the one I'm making: <a href=""http://www.addictinggames.com/puzzle-games/untangle.jsp"" rel=""noreferrer"">Untangled flash game</a></p>

<p>I have made this untangled game almost to full completion of logic. But, when two lines intersect, I need those intersected or 'tangled' lines to show a different color; red.</p>

<p>It would be really kind of you people if you could suggest an algorithm for detecting <strong>line segment</strong> collisions. 
I'm basically a person who likes to think 'visually' than 'arithmetically' :)</p>

<p>Edit: I'd like to add a few diagrams to make convey the idea more clearly</p>

<p><img src=""https://i.stack.imgur.com/6qko1.jpg"" alt=""no intersection"">
<img src=""https://i.stack.imgur.com/3hM63.jpg"" alt=""no intersection"">
<img src=""https://i.stack.imgur.com/Px4v4.jpg"" alt=""intersection"">
<img src=""https://i.stack.imgur.com/0Kc6U.jpg"" alt=""no intersection""></p>

<p>P.S I'm trying to make a function as </p>

<pre><code>private function isIntersecting(A:Point, B:Point, C:Point, D:Point):Boolean
</code></pre>

<p>Thanks in advance.</p>
","<p>I use the following method which is pretty much just an implementation of <a href=""http://local.wasp.uwa.edu.au/~pbourke/geometry/lineline2d/"" rel=""nofollow noreferrer"">this algorithm</a>. It's in C# but translating it to ActionScript should be trivial.</p>

<pre class=""lang-cs prettyprint-override""><code>bool IsIntersecting(Point a, Point b, Point c, Point d)
{
    float denominator = ((b.X - a.X) * (d.Y - c.Y)) - ((b.Y - a.Y) * (d.X - c.X));
    float numerator1 = ((a.Y - c.Y) * (d.X - c.X)) - ((a.X - c.X) * (d.Y - c.Y));
    float numerator2 = ((a.Y - c.Y) * (b.X - a.X)) - ((a.X - c.X) * (b.Y - a.Y));

    // Detect coincident lines (has a problem, read below)
    if (denominator == 0) return numerator1 == 0 &amp;&amp; numerator2 == 0;

    float r = numerator1 / denominator;
    float s = numerator2 / denominator;

    return (r &gt;= 0 &amp;&amp; r &lt;= 1) &amp;&amp; (s &gt;= 0 &amp;&amp; s &lt;= 1);
}
</code></pre>

<p>There's a subtle problem with the algorithm though, which is the case in which two lines are coincident but don't overlap. The algorithm still returns an intersectioin in that case. If you care about that case, I believe <a href=""https://stackoverflow.com/a/2255848/1086334"">this answer on stackoverflow</a> has a more complex version that addresses it.</p>

<p><strong>Edit</strong></p>

<blockquote>
  <p>I did not get a result from this algorithm, sorry ! </p>
</blockquote>

<p>That's strange, I've tested it and it's working for me except for that single case I described above. Using the exact same version I posted above I got these results when I took it for a test drive:</p>

<p><img src=""https://i.stack.imgur.com/jIrjl.png"" alt=""enter image description here""></p>
","26022"
"How do I make a fiery particle system?","18325","","<p>I added a particle system to the flame-emitting object in my Unity scene. But it's just little white balls, and I can't figure out how to make it fiery.</p>

<p>Anyone?</p>

<p>Everything I see on the internet involves buying some asset pack that somebody put together. Does Unity really not have any built in flames stuff?</p>
","<p>Unity has a built-in fire particle effect package.  Just <a href=""http://docs.unity3d.com/Documentation/Manual/HOWTO-InstallStandardAssets.html"" rel=""nofollow"">import the 'Particles' standard asset package</a>.  It will include small and large flames (and they even have a smoke element to them).  You can toy with that to get what you want.</p>
","44392"
"Moving a sprite in XNA/C#, using vectors","18295","","<p>I'm currently looking into XNA game development with the C# language.</p>

<p>I have two classes: the main game handler and a ""sprite"" class. Following is some basic pseudo-code which I hope adequately describes the issue.</p>

<p><strong>Game.cs</strong></p>

<pre><code>class game {
  sprite the_sprite;
  void update(time) {
    var mouse = mouse.state
    if(mouse.clicked) { this.the_sprite.moveTo(mouse.x, mouse.y) }
    this.the_sprite.update(time)
    base.update(time)
  }
}
</code></pre>

<p><strong>Sprite.cs</strong></p>

<pre><code>class sprite {
  vector2 location;
  vector2 move_to;
  void moveTo(x, y) { this.move_to = new vector2(x, y) }
  void update(time) {
    if(this.location.x &gt; this.move_to.x /* (or less than) */) {
      // adjust location.x
    }
    if(this.location.y &gt; this.move_to.y /* (or greater than) */) {
      // adjust location.y
    }
  }
}
</code></pre>

<p>Basically: when the user clicks somewhere in the game window, the x and y coordinates of the mouse are taken, and the game object will move towards that location over a period of time.</p>

<p>Well... the code works, but it's ugly, and objects don't move directly towards the object (instead, it's diagonal movement, followed by single-axis movement). I'm guessing there are some mathematical functions I can use, but I honestly haven't a clue where to get started. Any suggestions?</p>
","<p>If I understand your problem properly, you should just have a direction Vector2 representing the direction you want to move in inside your sprite class.
Like this:</p>

<pre><code>public Vector2 Direction { get; set; }
</code></pre>

<p>This is the normalized vector(which means it has a length of 1) showing where you want to go.</p>

<p>Then, add a Speed float property, which says how fast the sprite should go.</p>

<pre><code>public float Speed { get; set; }
</code></pre>

<p>You also need to add a UpdateSprite function, so why not put it inside your Sprite class?</p>

<pre><code>public Update(GameTime gameTime)
{
   Position += Direction * Speed * gameTime.ElapsedGameTime.TotalSeconds;
}
</code></pre>

<p>This will update the sprite's position to make it move(you multiply by the delta seconds so that the sprite moves properly on slow computers too).</p>

<p>Finally, you just set your direction property like this:</p>

<pre><code>sprite.Direction = location - sprite.Position;
sprite.Direction.Normalize();
</code></pre>
","7757"
"How to generate caves that resemble those of Minecraft?","18263","","<p>I've been working on a 3D procedural world for a while now and am wanting to start adding cave systems. I'm currently using 2D/3D Perlin Noise for the terrain generation in combination with Marching Cubes for smoother terrain. I'm just getting stumped when it comes to long interconnecting caves.</p>

<p>I'm hoping to get something more like Minecraft's cave systems. They seem to be very connected, branch off randomly in nearly any direction, and nearly any point in the cave would have a fairly circular look with a fairly equal radius throughout (not the best wording, but not quite sure how else to put it).</p>

<p>The biggest challenge for generating caves like I'm wanting is that I want to generate the world on the fly. The world is generated chunk by chunk currently, starting where the player is and it generates outwards from there. <strong>I would NOT want to generate any of the world and then dig the caves out using a wandering pattern, cellular automata, etc.</strong></p>

<p>Are there any well known algorithms that can be used for this? If so, does anyone want to share how they do something similar? I'd greatly appreciate any help.</p>

<p>A good example: <img src=""https://i.stack.imgur.com/3rzh0.jpg"" alt=""enter image description here""></p>
","<p>Minecraft's caves are generated by ""perlin worms"" method.  The generator snakes through terrain and caves out a tunnel.  Minecraft <strong>does not</strong> use 3d perlin noise for cave generation, because it tends to leave unconnected pockets in the terrain.  Minecraft caves have not been generated through 3d Perlin noise since very early Alpha versions.</p>

<p>Here are caves in <a href=""http://gnomescroll.com"" rel=""noreferrer"">Gnomescroll</a> generated from the ""perlin worm"" method.  </p>

<p><img src=""https://i.stack.imgur.com/GsxBy.png"" alt=""Gnomescroll Cave System First Person View 1""></p>

<p><img src=""https://i.stack.imgur.com/rOWU4.png"" alt=""Gnomescroll Cave System First Person View 2""></p>

<p><img src=""https://i.stack.imgur.com/QFmH5.jpg"" alt=""Gnomescroll Cave System Third Person View 2""></p>

<p>These are the libnoise ""Perlin Worms"" from the libnoise tutorial.  The technique closely reproduces the  caves generated in Minecraft.</p>

<p><img src=""https://i.stack.imgur.com/4C4pp.png"" alt=""Linoise Tutorial Perlin Worms""></p>

<p>The snaking parameters affects the quality of the cave system and determine how vertical the caves are and how fast they change direction.  Caves in minecraft branch and the radius of the cave tunnel is varied over the length of the caves.</p>

<p>Minecraft generates the caves on a chunk by chunk basis.  The approach required is complicated and no one has perfectly reverse engineered Minecraft's cave generator yet, despite interest by server modders.</p>

<p>The most likely approach generates the snaking caves chunk by chunk as the infinite map is generated and expands outward.  The caves on the current chunk are functions of the cave seeds on the closest N chunks for some N.  Using a random number generator which is a function of chunk coordinates to seed the caves it is possible to compute the caves on the current chunk for an infinite map while only evaluating the chunks within a finite chunk radius.</p>
","33801"
"How can I find an optimum set of colors for 10 players?","18194","","<p>I want to give each of 10 players a unique identifying color. Is there an optimum set of colors for this? How do I create one?</p>

<p>Every set I've come up with contains colors that are too similar.</p>

<p>Update: I was asked below what this is for (fair question). Now I can tell you - <a href=""http://www.windward.net/code-wars-prep/code-wars-windwardopolis/"">Windwardopolis</a> and the colors worked great.</p>
","<p>You could generate equidistant hue values in the HSV space:</p>

<pre><code>for (int i = 0; i &lt; 10; i++)
    colors[i] = HSV(0.1 * i, 0.5, 1.0);
</code></pre>

<p><img src=""https://i.stack.imgur.com/GvInX.png"" alt=""try 1""></p>

<p>However, it’s possible that you will not always have 10 players. In that case, the palette would not be very efficient unless you re-generated a different palette for another number of players. Instead, <a href=""http://martin.ankerl.com/2009/12/09/how-to-create-random-colors-programmatically/"">some authors</a> recommend generating a palette using the golden ratio, taking advantage of a property resulting from the <a href=""http://en.wikipedia.org/wiki/Equidistribution_theorem"">equidistribution theorem</a>:</p>

<pre><code>for (int i = 0; i &lt; 10; i++)
    colors[i] = HSV(fmod(i * 0.618033988749895, 1.0), 0.5, 1.0);
</code></pre>

<p><img src=""https://i.stack.imgur.com/nVq0h.png"" alt=""try 2""></p>

<p>That way, even if you stop at 3 or 4 or 7 players, you get a very good hue spread.</p>

<p>Many irrational numbers will do, but the golden ratio will work best (it has been <a href=""http://brpreiss.com/books/opus4/html/page214.html"">proven</a>).</p>

<p>Finally, you can use two different generating sequences in order to tweak <code>S</code> or <code>V</code>, too. For instance (<strong>edit</strong>: I added the <code>sqrt</code> call for better <a href=""http://mathworld.wolfram.com/DiskPointPicking.html"">equidistribution</a>):</p>

<pre><code>for (int i = 0; i &lt; 10; i++)
    colors[i] = HSV(fmod(i * 0.618033988749895, 1.0),
                    0.5,
                    sqrt(1.0 - fmod(i * 0.618033988749895, 0.5)));
</code></pre>

<p><img src=""https://i.stack.imgur.com/CiDex.png"" alt=""try 3""></p>

<p><strong>Update</strong>: the above results can be improved by using a correction curve for <code>H</code> (similar to the gamma curve for RGB components) that takes the human visual system into account. This is the hue correction curve that I computed using the <a href=""http://en.wikipedia.org/wiki/Color_difference#CIEDE2000"">CIEDE2000 metric</a>:</p>

<p><img src=""https://i.stack.imgur.com/9DYFS.png"" alt=""hue correction curve""></p>

<p>The results for equidistant hue values are as follows:</p>

<p><img src=""https://i.stack.imgur.com/oSJ1o.png"" alt=""try 4""></p>

<p>And for the golden ratio generation sequences (with and without tweaks on <code>V</code>):</p>

<p><img src=""https://i.stack.imgur.com/PiovV.png"" alt=""try 5"">
<img src=""https://i.stack.imgur.com/VewLV.png"" alt=""try 6""></p>

<p>I will publish an approximation of the curve formula for use in programs as soon as I find a reasonably good one.</p>
","46469"
"How can you put all images from a game to 1 file?","18147","","<p>I've just finished a basic RPG game written in C++ SFML, I've put a lot of effort into the game and I'd want to distribute it, however I've ran into a small issue. </p>

<p>Problem is, I have well over 200 images and map files (they're .txt files which hold map codes) all in the same folder as the executable, when I look in the folder, it makes me want to cry a little bit seeing so many resources, I've never seen a game which shows you all the resources directly, instead I believe they pack the resources in a certain file.</p>

<p>Well, that's what I'm trying to achieve: I'm hoping to pack all the images in 1 file (Maybe the .txt files as well) then being able to read from that file or easily add to it.</p>
","<p>Game programmers have relied on one of two main methods of data storage:</p>

<ul>
<li>store each data file as a separate file</li>
<li>store each data file in a custom archive format</li>
</ul>

<p>The drawback to the first solution is the wasted disk space problem, as well as the problem of slower installations.</p>

<p>The second solution provides it's own pitfalls, first is that you must write all your own image/sound/etc. loading routines which use a custom API for accessing the archived data. A further drawback is that you have to write your own archive utility to build the archives in the first place. </p>

<p>Unless you will always load all files from the archive, TAR/GZ might not be a very good idea, because you cannot extract specific files as you need them. This is the reason many games use ZIP archives, which do allow you to extract individual files as required (a good example is Quake 3,​​​​ whose PK3 files are nothing but ZIP files with a different extension).</p>

<ul>
<li><a href=""http://zpp-library.sourceforge.net/"">http://zpp-library.sourceforge.net/</a></li>
<li><a href=""http://www.winimage.com/zLibDll/minizip.html"">http://www.winimage.com/zLibDll/minizip.html</a></li>
</ul>

<p><strong>EDIT :</strong> ""Hide"" the game folder structure and ""Keep"" only the executables</p>

<blockquote>
  <p>Another solution is often used to ""hide"" the game files in folder
  structure. Keep only your executables and maybe a readme file in the main
  directory and move the game files into a sub folder named ""data"" or other related.</p>
</blockquote>

<p><strong>EDIT :</strong> Gamedev Tuts Plus have a nice resource</p>

<ul>
<li><a href=""http://gamedev.tutsplus.com/tutorials/implementation/create-custom-binary-file-formats-for-your-games-data/"">http://gamedev.tutsplus.com/tutorials/implementation/create-custom-binary-file-formats-for-your-games-data/</a></li>
</ul>

<p><strong>EDIT :</strong> libarchive</p>

<p>One potential solution libarchive, which is an archiving library that will handle extracting files from an archive such as a ZIP file. It even allows you to assign the extracted file to a standard FILE pointer, which would make interfacing with any other libraries potentially more straightforward.</p>

<ul>
<li><a href=""http://libarchive.github.com/"">http://libarchive.github.com/</a></li>
</ul>

<p><strong>EDIT :</strong> ZIP Format files with alternative extension</p>

<p>Here, I like @Joachim Sauer's Comment</p>

<blockquote>
  <p>Using ZIP-format files with alternative extensions has a great
  tradition outside of games as well: <a href=""https://en.wikipedia.org/wiki/JAR_%28file_format%29"">Java does it</a>, the <a href=""https://en.wikipedia.org/wiki/OpenDocument#Specifications"">OpenDocument
  Format (a.k.a. the OpenOffice/LibreOffice format) does it</a>, even <a href=""https://en.wikipedia.org/wiki/Office_Open_XML"">Office
  Open XML (a.k.a. the ""new"" Microsoft Office format) does it</a>.</p>
</blockquote>
","37649"
"How does one buy the rights for a game?","18091","","<p>Let's take some old popular at a time but abandoned game: WorldRacing/HiOctane/Constructor/any other. Say I with a team want to revitalize said game and bring it to year 2011 without major changes and then work on improving it (e.g. add multiplayer). Also it is important to keep the game's spirit, assets, story, music, so basically the game remains the same, but gets better (e.g. adapting DOS game to Win7).</p>

<p>My questions are from ""How is it usually made?"" area:</p>

<ul>
<li>How do I purchase rights to the title and the game's assets (graphics, sounds, music, storyline). Whom to contact and what purchase options are possible? Is it possible to obtain source codes, design documents.</li>
<li>How to deal with various platforms, is it terms of contract saying which platforms are allowed to be used if there are several?</li>
<li>How to deal with localizations in other languages, are they to obtain from other companies or do they belong to master publisher?</li>
<li>What could be the reasonable price for said games in example?</li>
<li>Is it possible to pursue owners to release the game as open source?</li>
</ul>

<p>Remember Heroes of Might and Magic was owned by New World Computing, but later changed its owner to Nival. I'm interested in that sort of process.</p>
","<p><a href=""http://www.savetz.com/articles/byte-abandonware.php"">Byte published a high-level summary of the ""abandonware"" situation in 2001, which answers many of these questions.</a> However, it's dealing with the case where you simply want the company to re-release the software or release it into the public domain. If you intend to license it and resell it, you will definitely need a lawyer to draft up a contract to protect <em>your</em> commercial rights, at some point in the process.</p>

<blockquote>
  <p>How To Do It</p>
  
  <p>You don't need to be an attorney or work at a software publisher to bring new life to old software anyone can help make it happen. The hardest part is often finding the right person to ask. If the company that published the software has been sold, you'll have to find out who bought it: A little Web research goes a long way here.</p>
  
  <p>Once you find the company, it's time to approach their attorneys. Call the company's main office and ask for the legal department, or write to the company. The person you talk to may not have heard of the software you're referring to, so be ready to provide as many details as possible, including who published it, in what year, and for what platforms.</p>
  
  <p>Also, know what you want: Asking for a license to distribute the software for free on your web site may be reasonable to many publishers. Or perhaps you'd like the publisher to release the software into the public domain an option that will be distasteful to many publishers who are unwilling to completely give up rights to their work, no matter how old. Don't expect an answer right away even once you find a helpful individual, it may take months for them to give you an answer.</p>
</blockquote>

<p>To answer your specific queries:</p>

<blockquote>
  <p>Whom to contact and what purchase options are possible?</p>
</blockquote>

<p>You contact whoever owns the copyrights. This can actually be very tricky to track down in the case of some old games, and unfortunately, there is no general way to handle it. In some cases the paper trail may just be buried too deep, and you're SOL. For example, as described in the Byte article, the legal records needed to transfer the rights to MECC's game catalog are apparently gone forever.</p>

<blockquote>
  <p>Is it possible to obtain source codes, design documents.
  How to deal with localizations in other languages, are they to obtain from other companies or do they belong to master publisher?</p>
</blockquote>

<p>They're assets like any other. These may have been owned by a different party to begin with; they may have been sold to a different party during liquidation; they may be lost forever.</p>

<p>Some things, like trademarks, may now be owned by entirely unrelated entities. If they're actually using them for their unrelated business, you probably can't get them at all.</p>

<blockquote>
  <p>How to deal with various platforms, is it terms of contract saying which platforms are allowed to be used if there are several?
  What could be the reasonable price for said games in example?</p>
</blockquote>

<p>This depends entirely on your negotiating skill. You want to convince the current holders it's worth $0 to them, and that even $1 would be a great move on their part to let you remake the game on all platforms.</p>

<blockquote>
  <p>Is it possible to pursue owners to release the game as open-source?</p>
</blockquote>

<p>Sure. Open source licensing is licensing like any other. If you have the rights, you can do what you want.</p>
","15885"
"Best practices of texture size","18078","","<p>I wanted to know how should I determine a good texture size ?
Currently, I always create UV texture that are 1024x1024px but if I create for example, a big house with a 1024px texture size, it will looks pretty bad.</p>

<p>So, should I create different texture size (512, 1024, ...) for different mesh size like this ? :</p>

<p><img src=""https://i.stack.imgur.com/PhRTf.png"" alt=""texture size""></p>

<p>or is it better to always do high-resolution texture and then reduce it in the software (ie : increase the LODBias settings in UDK reduce the size of the texture) ?</p>

<p>Thanks for your answer.</p>

<p>ps : sorry for my english !</p>
","<p>One way to choose texture sizes is to have a target texel density relative to the size of an object.  For instance, if you wanted 128 texels per meter, then an object 4 meters in size should have a 512x512 texture, an object 8 meters in size should have a 1024x1024 texture, etc.  The same guideline can be applied to tiling textures as well.</p>

<p>Another thing to take into account is how close the camera can get to a particular object.  If the camera can get very close, for example to a character, you would want a higher texel density.  A character might only be 2 meters tall but you would probably want a lot more than 256x256 for her textures.  Conversely, a mountain in the distance will never be seen up close, so it doesn't need a very high texel density.</p>

<blockquote>
  <p>is it better to always do high-resolution texture and then reduce it in the software (ie : increase the LODBias settings in UDK...)</p>
</blockquote>

<p>I wouldn't use LOD bias settings to reduce textures.  If you do that, you're still paying for the cost of the high-res texture in memory and loading time.  Instead, reduce the texture in a preprocess, and only load the smaller version of it.  It's still good to author the original textures at a high resolution so you have the extra detail in case you need it later.</p>
","64109"
"What's a way to implement a flexible buff/debuff system?","18067","","<p><strong>Overview:</strong></p>

<p>Lots of games with RPG-like statistics allow for character ""buffs"", ranging from simple ""Deal 25% extra damage"" to more complicated things like ""Deal 15 damage back to attackers when hit.""</p>

<p>The specifics of each type of buff aren't really relevant.  I'm looking for a (presumably object-oriented) way to handle arbitrary buffs.</p>

<p><strong>Details:</strong></p>

<p>In my particular case, I have multiple characters in a turn-based battle environment, so I envisioned buffs being tied to events like ""OnTurnStart"", ""OnReceiveDamage"", etc.  Perhaps each buff is a subclass of a main Buff abstract class, where only the relevant events are overloaded.  Then each character could have a vector of buffs currently applied.</p>

<p>Does this solution make sense?  I can certainly see dozens of event types being necessary, it feels like making a new subclass for each buff is overkill, and it doesn't seem to allow for any buff ""interactions"".  That is, if I wanted to implement a cap on damage boosts so that even if you had 10 different buffs which all give 25% extra damage, you only do 100% extra instead of 250% extra.</p>

<p>And there's more complicated situations that ideally I could control.  I'm sure everyone can come up with examples of how more sophisticated buffs can potentially interact with each other in a way that as a game developer I may not want.</p>

<p>As a relatively inexperienced C++ programmer (I generally have used C in embedded systems), I feel like my solution is simplistic and probably doesn't take full advantage of the object-oriented language.</p>

<p>Thoughts?  Has anyone here designed a fairly robust buff system before?</p>

<p><strong>Edit: Regarding Answer(s):</strong></p>

<p>I selected an answer primarily based on good detail and a solid answer to the question I asked, but reading the responses gave me some more insight.</p>

<p>Perhaps unsurprisingly, the different systems or tweaked systems seem to apply better to certain situations.  What system works best for my game will depend on the types, variance, and number of buffs I intend to be able to apply.</p>

<p>For a game like Diablo 3 (mentioned below), where nearly any bit of equipment can change a buff's strength, the <em>buffs are just character stats</em> system seems like a good idea whenever possible.</p>

<p>For the turn-based situation I'm in, the event-based approach may be more suitable.</p>

<p>In any case, I'm still hoping someone comes along with a fancy ""OO"" magic bullet which will allow for me to apply a <em>+2 move distance per turn</em> buff, a <em>deal 50% of damage taken back to the attacker</em> buff, and a <em>automatically teleport to a nearby tile when attacked from 3 or more tiles away</em> buff in a single system without turning a <em>+5 strength</em> buff into its own subclass.</p>

<p>I think the closest thing is the answer I marked, but the floor is still open.  Thanks to everyone for the input.</p>
","<p>This is a complicated issue, because you're talking about a few different things that (these days) get lumped together as 'buffs':</p>

<ul>
<li>modifiers to a player's attributes</li>
<li>special effects that happen on certain events</li>
<li>combinations of the above.</li>
</ul>

<p>I always implement the first with a list of active effects for a certain character. Removal from the list, whether based on duration or explicitly is fairly trivial so I won't cover that here. Each Effect contains a list of attribute modifiers, and can apply it to the underlying value via simple multiplication.</p>

<p>Then I wrap it with functions to access the modified attributes. eg.:</p>

<pre><code>def get_current_attribute_value(attribute_id, criteria):
    val = character.raw_attribute_value[attribute_id]
    # Accumulate the modifiers
    for effect in character.all_effects:
        val = effect.apply_attribute_modifier(attribute_id, val, criteria)
    # Make sure it doesn't exceed game design boundaries
    val = apply_capping_to_final_value(val)
    return val

class Effect():
    def apply_attribute_modifier(attribute_id, val, criteria):
        if attribute_id in self.modifier_list:
            modifier = self.modifier_list[attribute_id]
            # Does the modifier apply at this time?
            if modifier.criteria == criteria:
                # Apply multiplicative modifier
                return val * modifier.amount
        else:
            return val

class Modifier():
    amount = 1.0 # default that has no effect
    criteria = None # applies all of the time
</code></pre>

<p>That lets you apply multiplicative effects easily enough. If you need additive effects also, decide what order you're going to apply them in (probably additive last) and run through the list twice. (I'd probably have separate modifier lists in Effect, one for multiplicative, one for additive).</p>

<p>The criteria value is to let you implement ""+20% vs Undead"" - set the UNDEAD value on the Effect and only pass the UNDEAD value to <code>get_current_attribute_value()</code> when you're calculating a damage roll against an undead foe.</p>

<p>Incidentally, I wouldn't be tempted to try and write a system that applies and unapplies values directly to the underlying attribute value - the end result is that your attributes are very likely to drift away from the intended value due to error. (eg. if you multiply something by 2, but then cap it, when you divide it by 2 again, it'll be lower than it started with.)</p>

<p>As for event-based effects, such as ""Deal 15 damage back to attackers when hit"", you can add methods on the Effect class for that. But if you want distinct and arbitrary behaviour (eg. some effects for the above event might reflect damage back, some might heal you, it might teleport you away randomly, whatever) you'll need custom functions or classes to handle it. You can assign functions to event handlers on the effect, then you can just call the event handlers on any active effects.</p>

<pre><code># This is a method on a Character, called during combat
def on_receive_damage(damage_info):
    for effect in character.all_effects:
        effect.on_receive_damage(character, damage_info)

class Effect():
    self.on_receive_damage_handler = DoNothing # a default function that does nothing
    def on_receive_damage(character, damage_info):
        self.on_receive_damage_handler(character, damage_info)

def reflect_damage(character, damage_info):
    damage_info.attacker.receive_damage(15)

reflect_damage_effect = new Effect()
reflect_damage_effect.on_receive_damage_handler = reflect_damage
my_character.all_effects.add(reflect_damage_effect)
</code></pre>

<p>Obviously your Effect class will have an event handler for every type of event, and you can assign handler functions to as many as you need in each case. You don't need to subclass Effect, as each one is defined by the composition of the attribute modifiers and event handlers it contains. (It will probably also contain a name, a duration, etc.)</p>
","30011"
"How do audio based games such as Audiosurf and Beat Hazard work?","17999","","<p><em>Note: I am not asking how to make a clone of one of these. I am asking about how they work.</em></p>

<p>I'm sure everyone's seen the games where you use your own music files (or provided ones) and the games produce levels based on them, such as <a href=""http://www.audio-surf.com/"">Audiosurf</a> and <a href=""http://store.steampowered.com/app/49600/"">Beat Hazard</a>.</p>

<p><a href=""http://www.youtube.com/watch?v=2EsVyEnhxWY"">Here is a video</a> of Audiosurf in action, to show what I mean.</p>

<p>If you provide a heavy metal song, you would get a completely different set of obstacles, enemies, and game experience from something like Vivaldi.</p>

<p>What does interest me is how these games work. I do not know much about audio (well, data-side), but how do they process the song to understand when it is settling down or when it's speeding up? I guess they could just feed the pitch values (assuming those sorts of things exist in audio files) to form a level, but it wouldn't fully explain it.</p>

<p>I'm either looking for an explanation, some links to articles about this sort of thing (I'm sure there's a term or terms for it), or even an open-source implementation of this kind of thing ;-)</p>

<p>EDIT: After some searching and a little help, I found out about <a href=""http://en.wikipedia.org/wiki/Fast_Fourier_transform"">FFT</a> (Fast Fourier Transform). This maybe a step in the right direction, but it is something that does not make any sense to me..or fits with my physics knowledge of waves.</p>
","<p>The term you're looking for is <a href=""http://en.wikipedia.org/wiki/Signal_analysis"" rel=""nofollow"">signal processing/analysis</a> There are lots of techniques involved but the fundamental one that those games make use of is <a href=""http://www.gamedev.net/page/resources/_/technical/math-and-physics/beat-detection-algorithms-r1952"" rel=""nofollow"">Beat Detection</a>. This tries to calculate the tempo of the song and where the beats in a measure are and hence place the obstacles the appropriate distance apart to coincide with each beat.</p>

<p>The way that the games know when to ""kick in"" etc can range from being very simple and measuring the amplitude (volume) of the waveform or something more complex like isolating the volume of certain frequencies and measuring their volume.</p>

<p>If you're interested, look into Digital Signal Processing to see how you can analyse waveforms, which is essentially what these games are doing in their loading phase. </p>

<p>These links are good to get you started:</p>

<p><a href=""http://dsp-book.narod.ru/spv.pdf"" rel=""nofollow"">Introduction to Sound Processing</a><br>
<a href=""http://crca.ucsd.edu/~msp/techniques.htm"" rel=""nofollow"">Theory and Techniques of Electronic Music</a><br>
<a href=""http://www.dsprelated.com/dspbooks"" rel=""nofollow"">Introduction to Digital Filters</a></p>

<p>Hope that helps :)</p>

<p>-Ray</p>

<p>EDIT: I just saw your edit regarding Fourier transforms and thought I'll add some insight into it, although I'm by no means an expert on it!</p>

<p>FFT is a way of calculating the actual Fourier transform of a waveform. Basically, if you load up an audio file into <a href=""http://audacity.sourceforge.net/"" rel=""nofollow"">Audacity</a>, you'll see the wave form with the timeline along the top, this is known as the <em>time domain</em>. The FFT will convert a signal from the time domain into the <em>frequency domain</em> (basically all the frequencies that occur within the audio). </p>

<p>This conversion is useful for spectral analysis. In a game example, if you were to do a Fourier transform, you could easily calculate the amount of high frequency occurrences in the audio, and from that you could add twinkly visual effects, stars, or something associated with typically high frequency sounds. For the low frequencies you could have big, gluttonous monsters moving in time to the bass sounds, etc. </p>
","14643"
"Playing an animation relative to current Transform in unity?","17996","","<p>I have an animation created with the built-in dope sheet. It plays correctly but I would like it to be played relative to current object transformation. For example I have a palm tree that moves its leaves. If I rotate the palmtree and then start the animation leaves does not play animation relative to its new position/orientation. I know it is playing this way because of the animation being absolute. Is there any way to make it realtive to current transformation?.</p>

<p>Thanks in advance.</p>
","<p>The only way to do this is to make an empty gameobject and then put the object you wish to animate inside it, then putting an animator on the new parent.</p>

<p>For example, here you would put the tree and leaves in a parent object, and transform the parent object as needed while the animation plays relative to the parent.</p>
","73154"
"How can I achieve a good fire effect with alpha blending and particles?","17992","","<p>Using the following setting for the OpenGL particle effect:</p>

<pre><code>SRC: GL_SRC_ALPHA
DST: GL_ONE
</code></pre>

<p>Creates an additive blend, which looks spectacular on a black background but terrible on brighter colours, as it begines to fade to white.</p>

<p>I then used alpha blending:</p>

<pre><code>SRC: GL_SRC_ALPHA
DST: GL_ONE_MINUS_SRC_ALPHA
</code></pre>

<p>This allows other backgrounds to be used without affecting the color of the particles, but the particles themselves look dull compared to the additive blend. 
How can I achieve a good fire effect with alpha blending and particles?</p>

<p>Additive:</p>

<p><img src=""https://i.stack.imgur.com/RnXuP.png"" alt=""Additive on black""> <img src=""https://i.stack.imgur.com/oSo5A.png"" alt=""Additive on blue""></p>

<p>Alpha:</p>

<p><img src=""https://i.stack.imgur.com/YNOlP.png"" alt=""Alpha on black""> <img src=""https://i.stack.imgur.com/5H6OP.png"" alt=""Alpha on blue""></p>

<p><strong>UPDATE:</strong></p>

<p>Following David's advice below, I created a separate texture and then used additive blend on the particle effect before drawing onto the texture. The problem with that is that drawing on an alpha=0 texture resulted in just the coloured parts of the particle appearing in front of my world map, since normally you have a black background instead. The trick was to use two textures. I created a black texture and then drew the particles on it. Then I removed the alpha layer of the particles from this texture, effectively removing all the surrounding solid black and fading out the partially visible particles, while leaving the underlying black as you'd expect when making additive blend particles on a black background. In short, a gruelling process, but I got there eventually:</p>

<p><img src=""https://i.stack.imgur.com/1Rzvm.png"" alt=""Regular additive and my version""></p>

<p>Here's the thread where I posted my process: <a href=""http://www.cocos2d-iphone.org/forum/topic/28707?replies=8#post-141528"" rel=""nofollow noreferrer"">http://www.cocos2d-iphone.org/forum/topic/28707?replies=8#post-141528</a></p>

<p>Video: <a href=""http://www.youtube.com/watch?v=JptGbEO3b5E"" rel=""nofollow noreferrer"">http://www.youtube.com/watch?v=JptGbEO3b5E</a></p>
","<p>I admit I'm not aware of any ideal solution to this problem, so I'll describe a workaround that you may or may not be comfortable with:</p>

<ol>
<li>Render all of the particles using <strong>additive blending</strong> to a <em>separate</em> texture (or render target) with its background cleared to <em>transparent</em>.</li>
<li>Render that texture (or render target) on <em>top</em> of your scene using <strong>alpha blending</strong>.</li>
</ol>

<p>I tried it in Photoshop and here's what I got - It's not perfect, but at least it preserves the original colors better:</p>

<p><img src=""https://i.stack.imgur.com/xDz3A.jpg"" alt=""enter image description here""></p>

<p>Here's the original texture without doing additive blending on the particles:</p>

<p><img src=""https://i.stack.imgur.com/gxuaY.jpg"" alt=""enter image description here""></p>
","22990"
"How to detect mouse over for UI image in Unity 5?","17863","","<p>I have an image that I have setup to move around and zoom in and out from. The trouble is the zoom can be done from anywhere in the scene, but I only want it to zoom when the mouse is hovering over the image. I have tried to use OnMouseEnter, OnMouseOver, event triggers, all three of those without a collider, with a collider, with a trigger collider, and all of that on the image itself and on an empty game object. However none of those have worked...So I am absolutely stumped...Could someone help me out here!</p>

<p>Here is my script:</p>

<pre><code>    private float zoom;
    public float zoomSpeed;
    public Image map;

    public float zoomMin;
    public float zoomMax;

    void Update () {
        zoom = (Input.GetAxis(""Mouse ScrollWheel"") * Time.deltaTime * zoomSpeed);
        map.transform.localScale += new Vector3(map.transform.localScale.x * zoom, map.transform.localScale.y * zoom, 0);
        Vector3 scale = map.transform.localScale;
        scale = new Vector3(Mathf.Clamp(map.transform.localScale.x, zoomMin, zoomMax), Mathf.Clamp(map.transform.localScale.y, zoomMin, zoomMax), 0);
        map.transform.localScale = scale;
    }
</code></pre>
","<p>You can implement <code>IPointerEnter</code>  and <code>IPointerExit</code> interfaces and keep boolean for 'over state':</p>

<pre><code>using System;
using UnityEngine;
using UnityEngine.EventSystems;

public class TestOver : MonoBehaviour, IPointerEnterHandler, IPointerExitHandler
{
    public bool isOver = false;

    public void OnPointerEnter(PointerEventData eventData)
    {
        Debug.Log(""Mouse enter"");
        isOver = true;
    }

    public void OnPointerExit(PointerEventData eventData)
    {
        Debug.Log(""Mouse exit"");
        isOver = false;
    }
}
</code></pre>
","108627"
"Get position of point on circumference of circle, given an angle?","17850","","<p>I would like to know how to get a specific point on the circumference of a circle, given an angle. The diameter of the circle is 1, and the center point of the circle is <code>{ X: 0.5, Y: 0.5 }</code>.</p>
","<p>You can work this out using basic trigonometry.
<a href=""http://www.freehomeworkmathhelp.com/Trigonometry/Trigonometry_Introduction/trigonometry.html"" rel=""nofollow noreferrer"">http://www.freehomeworkmathhelp.com/Trigonometry/Trigonometry_Introduction/trigonometry.html</a></p>

<pre><code>Tan(angle) = Opposite / Adjacent
Sin(angle) = Opposite / Hypotenuse
Cos(angle) = Adjacent / Hypotenuse
</code></pre>

<p>I always remember the above as</p>

<pre><code>The Old Arab
Sat On His
Camel And Howled
</code></pre>

<p>The above means if we have the angle and one length of a right-angled triangle we can work out the lengths of the other sides. Luckly your problem can be thought of as calculating the length of triangle sides:</p>

<p><img src=""https://i.stack.imgur.com/jhYJt.png"" alt=""Circle Triangle Image""></p>

<p>Above, r is the hypotenuse, x is the adjacent and y is the opposite.</p>

<p>So for x:</p>

<pre><code>Cos(a) = x / r
Cos(a) * r = x
x = Cos(a) * r
</code></pre>

<p>And for y:</p>

<pre><code>Sin(a) = y / r
Sin(a) * r = y
y = Sin(a) * r
</code></pre>

<p>This is assuming a circle at (0, 0), so we just add on the circle's center.</p>

<pre><code>radius = 1;
CenterX = 0.5;
CenterY = 0.5;

x = Cos(angle) * radius + CenterX;
Y = Sin(angle) * radius + CenterY;
</code></pre>

<p><strong>Note:</strong> The C# Math functions use angles in radians, so if you have degrees convert them first:</p>

<pre><code>radians = degrees * Math.PI / 180
</code></pre>
","18341"
"Implementing a 2D destructible landscape (like Worms)","17794","","<p>What steps would be involved in constructing a destructible 2D landscape, like in Worms? Ideally, What are some ways that this process could be made efficient as possible?</p>
","<p>I don't know how the landscape in worms was implemented exactly, but I'm pretty sure they used a bitmap for the landscape (at least in the older games of the series).</p>

<p>A very basic approach would be a bitmap image (B/W) where black pixels represent <em>air</em> and white pixels represent <em>ground</em>. Destruction of the landscape can be done easily using pixel operations. So if a rocket hits the ground, paint a black circle with <code>radius = blastRadius</code> at the point of impact.</p>

<p>You can then render your world (or just a portion of it) using that bitmap. For better performance I suggest you implement it in a way, that you can update/render just a portion of the ""world"". Eg. if some parts of the landscape are destroyed by a rocket, just re-render the affected areas, not the whole world.</p>

<p>Instead of a B/W image as your ""collision-map"", you could also use a 24bit image where you use two channels to store the surface-normal (x,y) per pixel and one channel to store the actual ""collision-map"". Having the surface-normal at hand will greatly help you to calculate bouncing grenades, or to determine if a character can move in a given direction.</p>
","6723"
"What quality should my sounds be?","17781","","<p>Sound and it's quality is something like religion. Never ending story.</p>

<p>People will say, that MP3 320kbps is lossless, while experts will say that any MP3 is crap, but in the end, no one will hear a difference in the result... unless they're in the music industry for 20 years+.</p>

<p>What would be the best format for video game, and what properties should be enough (Hertz, bitrate etc.), assuming that 320kbps MP3 is ""heavy""?</p>

<p>Maybe an example or two, how some AAA titles work with their sounds.</p>
","<h1>Update July 2017</h1>

<p>If you are using Unity or another big engine that has an asset management system, don't request Ogg Vorbis from your sound designers and composers. Get WAVs or AIFFs.</p>

<p>Unity and Unreal are structured to work with high quality bounces and then apply compression settings per-platform. Having the source asset as Ogg or Mp3 means you are double-compressing the audio and introducing additional artifacts for no benefit.</p>

<p>If you see that starting from ogg or mp3 reduces your build size, that's not a good reason. It likely means you are pre-exporting with different compression settings than you have applied in Unity/Unreal. Are there execptions? Yes, but you wouldn't be looking up this answer if you knew when those exceptions were applicable.</p>

<p>If you're pre-compressing in order to reduce the size of your repo, use LFS, use a centralized version control system, or grin and bear it.</p>

<hr>

<h1>TL;DR</h1>

<ol>
<li><strong>Yes</strong>, MP3 320k sounds great. BUT . . .</li>
<li>Don't use MP3, use Ogg Vorbis at 44.1kHz, quality 6 for music. For sound effects, just use 16/44.1 WAV unless you really feel you need the trim the fat.</li>
<li>If you have to use MP3, such as in Flash, try to use 192k-256k (VBR 1 or 2), but you may have to settle for 128k. Don't go lower than 128k (VBR 6).</li>
</ol>

<h1>The Real Answer</h1>

<blockquote>
  <p>People will say, that MP3 320kbps is lossless, while experts will say that any MP3 is crap, but in the end, no one will hear a difference in the result... unless they're in the music industry for 20 years+.</p>
</blockquote>

<p>Audio encoded in MP3, regardless of encoding quality, is <strong>always</strong> lossy. Its a perceptual codec, and therefore works by encoding properties of the sound over time in ~1152 sample chunks in a compressed form, from which uncompressed samples can be extrapolated by the decoder. Its goal is not to accurately recreate the original audio, just provide one that is ""good enough"".</p>

<p>However, like you said, 320kbps sounds very good. It's generally regarded to be as good or better than CD quality. However, it is still not possible to perfectly recreate the original samples of an uncompressed WAV encoded as a 320kbps MP3.</p>

<p>Generally Ogg Vorbis is a better format than MP3. It's generally agreed to give you better quality for the same size file, and unlike MP3 can be easily looped seamlessly. Those 1152-sample chunks that MP3 uses to encode audio will often leave silence at the beginning and end of a sound. Not as big a deal for basic sound effects, but a massive problem for music loops.</p>

<p>The Flash IDE gets around this during the .swf export, it strips out the silence manually. People using streaming audio (or pure mxmlc) achieve looping via the SampleDataEvent and manually dropping samples or preprocessing the MP3 file (see <a href=""http://blog.andre-michelle.com/2010/playback-MP3-loop-gapless/"" rel=""nofollow noreferrer"">Andre Michelle's blog</a> and the <a href=""http://www.compuphase.com/mp3/mp3loops.htm"" rel=""nofollow noreferrer"">CompuPhase mp3loop utility</a>)</p>

<p>Also, using an MP3 decoder technically requires you to acquire a patent license to use (since the MP3 patent is owned by Technicolor, Fraunhofer, and others). Obviously tons of people have released freeware games that used MP3, but it's best not to screw around with that.</p>

<blockquote>
  <p>What would be the best format for video game, and what properties should be enough (Hertz, bitrate etc.), assuming that 320kbps MP3 is ""heavy""?</p>
  
  <p>Maybe an example or two, how some AAA titles work with their sounds.</p>
</blockquote>

<p>That depends: What are your target platforms, what other technologies are you using, how are you distributing your game, and what style are you going for? I'm going to break this down into a few categories based on platform, technology, and aesthetic.</p>

<h2>High-End PC and Console Titles</h2>

<p>AAA games are going for top-of-the-line production quality, so they're recording and producing assets uncompressed 24bit/48kHz (also the standard for film postproduction). Titles with slightly lesser ambitions than say Battlefield 3 might record and produce in 16/44.1, which is the official standard for CD quality audio.</p>

<p>Of course you can't ship a bunch of 24/48 uncompressed WAVs with a game, it'd be too big. So ultimately there has to be some sort of compression happening. Generally the rule of thumb is, if it's a quick sound effect like a gun sound (like the Portal 2 gun fizzle in Sprunth's answer), it's fine to leave it as a WAV, possibly reducing the sample rate depending on the frequency (see the <a href=""http://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem"" rel=""nofollow noreferrer"">Nyquist theorem</a>, sounds that are made up of low-frequency content can be encoded at lower sampling rates). For music, there's really no way around compression. Ogg Vorbis at CD quality is the way to go (44.1kHz, quality 5-6 or higher). </p>

<p>Also, AAA games will often use an intermediary tool for the compression, either an in-house tool or audio middleware like FMOD or Wwise. The way it works in FMOD and Wwise is that you import most things as 16/44.1 or 24/48 WAVs (or, if the sound is all low-frequency content, it may be imported with a lower sampling rate), then give FMOD a compression factor for each asset, choosing an encoding like ADPCM, MP3, or Ogg Vorbis.</p>

<p>FMOD actually recently dropped support for encoding assets in the soundbanks you export from FMOD Designer (.fsb files) as Ogg Vorbis in favor of a <a href=""http://www.celt-codec.org/"" rel=""nofollow noreferrer"">new codec from Xiph called CELT</a>. Ogg Vorbis can be a little tough on the CPU, so CELT is being developed to provide an alternative. You can load the files directly, but no longer use for encoding from the Designer application.</p>

<p>By the way, here's a cool link about <a href=""http://blogs.battlefield.ea.com/battlefield_bad_company/archive/2010/01/22/an-audiophile-s-guide-to-bf-bc2-full.aspx##"" rel=""nofollow noreferrer"">Battlefield Bad Company's audio</a> that also goes into surround a bit. DICE is pretty much at the forefront of audio technology in games, so it's a good series for study.</p>

<p>Also, related to surround is the issue mono vs stereo. Just in case you didn't know, all of your sound effects should be mono, unless some of them actually make use of panning effects. Stereo's awkward to spatialize into a 3d environment, and you can pan sounds in code to place them in a 2d environment.</p>

<h2>Slightly-Less-High-End Titles, Indie Games</h2>

<p>Obviously this can widely vary. A quick glance shows that Frozen Synapse uses entirely Ogg Vorbis files, for both sound effects and music. Dungeons of Dredmor on the other hand follows the scheme of Ogg Vorbis for music, and 16/44.1 WAV for sound effects.</p>

<p>The Dungeons of Dredmor approach is preferable. Even stored as uncompressed WAVs, the sound effects are generally short enough that they don't take up that much space, and you save a lot of CPU cycles not having to decode them. You want to be able to quickly load a sound effect into memory and play it. If you encode your sound effects in Ogg Vorbis, there's the potential for a tiny amount of delay before a player hears your sound effect for the first time.</p>

<h2>Browser Games, HTML5 and Flash (with a dash of Mobile)</h2>

<p>HTML5 audio is a mess. You have to provide both ogg and MP3 versions of your sounds. Encode in the highest quality you can without your user raging at the long load time. For MP3, don't go below 128k, it's bad enough at 128.</p>

<p>Flash only accepts 16bit/44.1kHz MP3 unless you go nuts and write your own decoder for some other format (like the experimental Ogg Vorbis decoder in the Alchemy labs). In the past, Flash had problems with Variable Bit Rate MP3s, but I've never had a problem. The quality setting you choose for your Flash game will depend on how large you want your final .swf to be.</p>

<p><strong>Update:</strong> As <a href=""https://gamedev.stackexchange.com/a/20702/3656"">Tetrad mentioned</a>, mobile games have to be considered with memory and storage. The way you encode your audio for mobile games is much like Flash, you want to retain as high a quality as you can, but ultimately you have to fit a memory and storage budget. Tracker music is especially good if you're on a tight storage budget for music. Tell your composer to limit his sample palette and you can fit a <em>ton</em> more music in the game.</p>

<h2>""8-bit"" or Chiptune Type Sound Effects and Music</h2>

<p>Most games are just going to do what Frozen Synapse and Dungeons of Dredmor do. However, you can probably get away with reducing sampling rate and bit depth. Not only might it fit the aesthetic you're going for, but it could save you some space.</p>

<p>Also, tracker music generally stores samples at low sample rates, just let it happen.</p>
","20684"
"Collision detection, stop gravity","17730","","<p>I just started using Gamemaker Studio and so far it seems fairly intuitive.  However, I set a room to ""Room is Physics World"" and set gravity to 10.  I then enabled physics on my player object and created a block object to match a platform on my background sprite.</p>

<p>I set up a Collision Detection event for the player and the block objects that sets the gravity to 0 (and even sets the vspeed to 0). I also put a notification in the collision event and I don't get that either. I have my key down and key up events working well, moving the player left and right and changing the sprites appropriately, so I think I understand the event system.</p>

<p>I must just be missing something simple with the physics.  I've tried making both and neither of the objects ""solid"".  Pretty frustrating since it looks so easy.</p>

<p>The player starting point is directly above the block object in the grid and the player does fall through the block.  I even made the block sprite solid red so I could see it (initially it was invisible, obviously).</p>
","<p>Okay I technically answered the original question.  I had to create a collision detection event for the block as well as the player.  I didn't put any action in other than a comment.  Now he falls and lands as you would expect.</p>

<p>In short, you need the following:
1. Room Physics enabled
2. Player and Block object physics enabled
3. Collision events for BOTH player > block and block > player.</p>

<p>The only problem is, once the player lands the left/right movement doesn't work, but that's for another question...</p>
","40083"
"What's the difference between Update and FixedUpdate in Unity, and should I bother?","17710","","<p>I was told to use <code>Update()</code> for graphics and <code>FixedUpdate()</code> for physics, but sometimes my inputs won't register when I use <code>FixedUpdate()</code>. It works fine if I use <code>Update()</code> for everything though.</p>

<p>Should I bother with <code>FixedUpdate()</code>, or am I doing something wrong?</p>
","<p><a href=""http://docs.unity3d.com/Documentation/ScriptReference/MonoBehaviour.FixedUpdate.html""><code>FixedUpdate</code></a> can run faster or slower than <a href=""http://docs.unity3d.com/Documentation/ScriptReference/MonoBehaviour.Update.html""><code>Update</code></a> depending on your settings. That'll depend on load (how fast <code>Update</code> is running) and speed you have set for <code>FixedUpdate</code> (found in  Edit->Project Settings->Time). Ideally, since <code>Update</code> is run once per frame, this is where you want to capture input. If you need to act on input in the <code>FixedUpdate</code> method (like controlling physics bodies), set flags in <code>Update</code> then handle them in <code>FixedUpdate</code>:</p>

<pre><code>bool leftMouseDown = false;

void Update()
{
    if(Input.GetMouseButtonDown(0))
        leftMouseDown = true;
}

void FixedUpdate()
{
    if(leftMouseDown )
    {
        //update physics bodies with input
        leftMouseDown = false;
    }
}
</code></pre>

<p>It's still a good idea to control physics from the <code>FixedUpdate</code> method, since it's unlikely the physics needs to be updated as often, and physics on a fixed update is much easier to predict (<a href=""http://en.wikipedia.org/wiki/Deterministic_system"">determinism</a>) than physics on a variable update.</p>
","73715"
"Rotating vector3 by a quaternion","17706","","<p>I am attempting to rotate a vector3 by a given quaternion.</p>

<p>I know that this is true</p>

<p>$$ v' = q \cdot v \cdot q^{-1} $$</p>

<p>I know that \$ q^{-1} \$ is the inverse which just \$ \frac {-q} {magnitude(q)} \$, but how do I map the multiplication of the vector to the quaternion to get back a vector?</p>

<p>I have found that you can treat <code>v</code> as a matrix, and convert <code>q</code>, and <code>q'</code> to matrices, and then convert <code>v'</code> from a matrix to a vector, but this seems a little over the top just to get a vector. Is there a cleaner implementation that I could use?</p>
","<p>As Nathan Reed and teodron exposed, the recipe for rotating a vector <em>v</em> by a unit-length quaternion <em>q</em> is:</p>

<p>1) Create a pure quaternion <em>p</em> out of <em>v</em>. This simply means adding a fourth coordinate of 0:</p>

<p><img src=""https://i.stack.imgur.com/O01so.png"" alt=""p = (vx, vy, vz, 0) &lt;=&gt; p = (v, 0)""></p>

<p>2) Pre-multiply it with <em>q</em> and post-multiply it with the conjugate <em>q*</em>:</p>

<p><img src=""https://i.stack.imgur.com/JLPhQ.png"" alt=""p&#39; = q x p x q*""></p>

<p>3) This will result in another pure quaternion which can be turned back to a vector:</p>

<p><img src=""https://i.stack.imgur.com/8g4C9.png"" alt=""v&#39; = (p&#39;x, p&#39;y, p&#39;z)""></p>

<p>This vector <em>v'</em> is <em>v</em> rotated by <em>q</em>.</p>

<hr>

<p>This is working but <strong>far from optimal</strong>. Quaternion multiplications mean tons and tons of operations. I was curious about various implementations <a href=""https://code.google.com/p/kri/wiki/Quaternions"" rel=""nofollow noreferrer"">such as this one</a>, and decided to find from where those came. Here are my findings.</p>

<p>We can also describe <em>q</em> as the combination of a 3-dimensional vector <em>u</em> and a scalar <em>s</em>:</p>

<p><img src=""https://i.stack.imgur.com/Xm8wp.png"" alt=""q = (ux, uy, uz, s) &lt;=&gt; q = (u, s)""></p>

<p>By the rules of <a href=""http://en.wikipedia.org/wiki/Quaternion#Scalar_and_vector_parts"" rel=""nofollow noreferrer"">quaternion multiplication</a>, and as the conjugate of a unit length quaternion is simply it's inverse, we get:</p>

<p><img src=""https://i.stack.imgur.com/nqg2p.png"" alt=""this is very long to re-type""></p>

<p>The scalar part (ellipses) results in zero, as detailed <a href=""http://gns.wikia.com/wiki/Quaternions"" rel=""nofollow noreferrer"">here</a>. What's interesting is the vector part, AKA our rotated vector <em>v'</em>. It can be simplified using <a href=""http://en.wikipedia.org/wiki/Vector_calculus_identities#Addition_and_multiplication"" rel=""nofollow noreferrer"">some basic vector identities</a>:</p>

<p><img src=""https://i.stack.imgur.com/oBhWx.png"" alt=""that too""></p>

<p>This is now <strong>much more optimal</strong>; two dot products, a cross product and a few extras: around half the operations. Which would give something like that in source code (assuming some generic vector math library):</p>

<pre><code>void rotate_vector_by_quaternion(const Vector3&amp; v, const Quaternion&amp; q, Vector3&amp; vprime)
{
    // Extract the vector part of the quaternion
    Vector3 u(q.x, q.y, q.z);

    // Extract the scalar part of the quaternion
    float s = q.w;

    // Do the math
    vprime = 2.0f * dot(u, v) * u
          + (s*s - dot(u, u)) * v
          + 2.0f * s * cross(u, v);
}
</code></pre>
","50545"
"How viable ogre3d is for a commercial project?","17680","","<p>Well, I don't really what else to add to the question, since I don't really know what competitors have that OGRE doesn't.</p>

<p>Of course I'm talking game rendering quality here, I don't really think there are very complicated programming stuff left, maybe AI...</p>

<p>Since torchlight is the best game done with OGRE (I think), is it still a good solution for future games, whatever the 3D graphics technologies will be ?</p>

<p>What prevents OGRE3D from not being the best engine ? (consoles excluded, since they used some specific graphic library, except the xbox360 maybe...)</p>
","<p>Whether Ogre3d is the best or viable depends entirely on the type of game.  In the industry, what often happens is you use something like Ogre3d (or IdTech, or Source, or Unreal) as a starting point and build on it from there depending on your needs and requirements.</p>

<p>For instance, compare a game like GTA IV to Modern Warfare 2.  The rendering requirements are completely different.  </p>

<p>GTA IV has a day-night cycle, a weather system, fast moving vehicles, tons of light sources from cars to street lamps, a lot of animated actors on the screen, and it's an huge open world.  GTA IV runs around 30hz and the gameplay is such that some input lag is tolerable.</p>

<p>MW2 is an fps with few vehicles, lots of explosions and screen effects, relatively few actors on screen, textures that your camera can go right up against, and a mostly predictable path through a pretty small world.  MW2 runs at 60hz and input lag severely impacts gameplay.</p>

<p>It's impossible to make a rendering engine that's optimal for both kinds of games.</p>

<p>Ogre3d could be a good starting point for what you're trying to do, but as Ranieri said, don't be afraid to get your hands dirty.</p>
","4099"
"(2D) Detect mouse click on object with no script attached","17680","","<p>I'm creating a 2D project which does not have a character. So i created an empty gameobject and attached the script to it. In the script, i have declared other objects which are in the scene like this:</p>

<pre><code>public GameObject obj1,obj2,obj3;
</code></pre>

<p>How can I know if obj1 or obj2 or obj3 was clicked? Is raycasting the only solution?</p>
","<p>Yes, you can use <a href=""http://docs.unity3d.com/ScriptReference/Physics.Raycast.html"">raycasting</a> to detect the objects in your scene. You don't need to attach a custom script to the game objects you want to detect, but you do need to attach colliders to them.</p>

<p>In the update method of your script, attached to the otherwise empty object, you can check for when the mouse button is pressed. Then, cast a ray into the scene from the camera, through the mouse. Something like the following:</p>

<pre><code>void Update() {
    if (Input.GetMouseButtonDown(0)) {
        Debug.Log(""Pressed left click, casting ray."");
        CastRay();
    }
}

void CastRay() {
    Ray ray = Camera.main.ScreenPointToRay(Input.mousePosition);
    RaycastHit hit;
    if (Physics.Raycast(ray, out hit, 100)) {
        Debug.DrawLine(ray.origin, hit.point);
        Debug.Log(""Hit object: "" + hit.collider.gameobject.name);
    }
}
</code></pre>
","82929"
"How do you add a scripting language to a game?","17600","","<p>Let's say I have a game written in C++. But I want to add some modding or scripting functionality to it. How would one go about adding a scripting functionality to your game?</p>
","<p>First of all, you should decide what part of your game is scripted. One option is to have a fully scripted game in the sense that while the time-critical backend operations are coded in C++, all the game logic is in the scripting language. Designers use the backend as a library called from the high level scripting language. On the other extreme, you can have few specific places where scripts are used, such as the user interface or scripted sequences, with the majority of the game code is still in C++. There are advantages to each approach (speed, flexibility, compilation time, scope of game, etc.), but you need to decide that beforehand.</p>

<p>Once you know how you want to use scripting, you now need to decide if you're going to use an existing scripting language or your own. Today there are many scripting languages to choose from with different design goals and target audiences, so I'm not sure if it's worth creating your own anymore. You can read about implementing your own scripting engine <a href=""http://www.flipcode.com/articles/scripting_issue01.shtml"">here</a>.</p>

<p>Some popular scripting languages include <a href=""http://www.lua.org/"">Lua</a>, which is lightweight and easy to embed. It uses a stack for communication between the host and embedded language and it was successfully used in many professional games. Another option is <a href=""http://www.angelcode.com/angelscript/"">AngelCode</a>, which allows you to call C and C++ functions directly. <a href=""http://www.python.org/"">Python</a> and <a href=""http://www.ruby-lang.org/en/"">Ruby</a> are a bit more complex to embed but once you have done that they are very pleasant to program in. If you want to embed Python then take a look at <a href=""http://www.boost.org/doc/libs/1_43_0/libs/python/doc/index.html"">Boost.Python</a>. You can also try embedding JavaScript and take advantage of the fast scripting engines developed for browsers. For my game we are using Google's <a href=""http://code.google.com/p/v8/"">V8</a> engine which is very fast and easy to embed, but  Mozilla's <a href=""http://www.mozilla.org/js/spidermonkey/"">SpiderMonkey</a> is another option.</p>
","425"
"Which is better for a beginner, UDK or Unity?","17562","","<p>I am just getting into game development and I would like to know which engine would be best to learn first.</p>

<p>In terms of my current skills, I know a good deal of javascript, but not much beyond that. This is all a learning experience for me (I am an extremely fast learner).</p>

<p>I am using HTML5 canvas right now as that's mostly what I was hinting at when i said javascript. I probably should have made it a bit more clear.</p>
","<p>Definitely Unity. Its really kind to beginners, and has a really nice, ""just-works"" API.
Also, It'll give you good experience in working with proprietary game engines, which will help if you ever think of getting into the game industry. 
It also supports more freedom in game design than UDK which (as much as they claim to the contrary,) is geared (no pun intended :P) completely towards FPS style games.</p>

<p>However like what Twitchy said, eventually you will want to use custom libraries like XNA, or MOGRE; it is the natural next step in game development (in my opinion).</p>

<p>Good luck, and have fun :)</p>
","22385"
"How do modern game engines achieve real-time rendering vs Blender's ""slow"" rendering?","17561","","<p>I'm new to both gamedev and Blender, and there's something I can't shake:</p>

<p>In Blender, a single render (even using the more advanced Cycles renderer) can take up to 45 seconds on my machine. But obviously, in a game, you can have amazing graphics, and so rendering is obviously happening continuously, multiple times a second in real-time. </p>

<p>So I'm also wondering what the disconnect is, regarding how ""slow"" Blender's renders seem to be, versus how game engines achieve real-time (or near real-time) rendering.</p>
","<p>Real-time rendering, even modern real-time rendering, is a grab-bag of tricks, shortcuts, hacks and approximations.</p>

<p>Take shadows for example.</p>

<p>We still don't have a completely accurate &amp; robust mechanism for rendering real-time shadows from an arbitrary number of lights and arbitrarily complex objects.  We do have multiple variants on shadow mapping techniques but they all suffer from the <a href=""https://msdn.microsoft.com/en-us/library/windows/desktop/ee416324(v=vs.85).aspx"">well-known problems with shadow maps</a> and even the ""fixes"" for these are really just a collection of work-arounds and trade-offs (as a rule of thumb if you see the terms ""depth bias"" or ""polygon offset"" in anything then it's not a robust technique).</p>

<p>Another example of a technique used by real-time renderers is precalculation.  If something (e.g. lighting) is too slow to calculate in real-time (and this can depend on the lighting system you use), we can pre-calculate it and store it out, then we can use the pre-calculated data in real-time for a performance boost, that often comes at the expense of dynamic effects.  This is a straight-up memory vs compute tradeoff: memory is often cheap and plentiful, compute is often not, so we burn the extra memory in exchange for a saving on compute.</p>

<p>Offline renderers and modelling tools, on the other hand, tend to focus more on correctness and quality.  Also, because they're working with dynamically changing geometry (such as a model as you're building it) they must oftn recalculate things, whereas a real-time renderer would be working with a final version that does not have this requirement.</p>
","136765"
"best way to compute vertex normals from a Triangle's list","17541","","<p>hi
i'm a complete newbie in computergraphics so sorry if it's a stupid answer.
i'm trying to make a simple 3d engine from scratch, more for educational purpose than for real use.</p>

<p>for now i compute only face normals. in this way:</p>

<p>i have a Surface object with inside a Triangle's list. i compute normals inside Triangle class, in this way:</p>

<pre><code>triangle.computeFaceNormals() {
    Vec3D u = v1.sub(v3)
    Vec3D v = v1.sub(v2)
    Vec3D normal = Vec3D.cross(u,v)
    normal.normalized()
    this.n1 = this.n2 = this.n3 = normal
}
</code></pre>

<p>and when building surface:</p>

<pre><code>t = new Triangle(v1,v2,v3)
t.computeFaceNormals()
surface.addTriangle(t)
</code></pre>

<p>and i think this is the best way to do that.. isn't it?</p>

<p>now.. this works, ok. but light it's not smoothed. i'm trying to compute also vertex normals. (i'm testing my engine with tubolar surfaces so i have almost all vertex shared with more then one triangles)</p>

<p>i've found this simple algorithm: <a href=""http://www.flipcode.com/archives/Vertex_Normals.shtml"">flipcode vertex normal</a>
but.. hei this algorithm has.. exponential complexity? (if my memory doesn't fail my computer science background..) (bytheway.. it has 3 nested loops.. i don't think it's the best way to do it..)</p>

<p>any suggestion?</p>
","<p><strong>""Best"" is pretty subjective -- it's going to involve weighing what you need out of the algorithm versus it's inputs, runtime complexity and other properties.</strong> </p>

<p>That said, both your approach and the linked FlipCode approach are reasonable in terms of producing usable results (you could quite simply copy your 'face normals' to each vertex, if you are not sharing actual vertex instances between triangles, which I'm unclear on from your code). Other techniques include weighting the contribution of each face normal by the size of the angle made with each face shared by the vertex.</p>

<p>You are correct in that the FlipCode approach appears suboptimal as written, but it could just be poorly specified: it's a little unclear whether or not it intends to suggest the second loop traverse <em>all</em> faces in the model, versus the handful of faces that share the vertex in question. If you have the adjacency information to reduce the search space of the second loop, it becomes less of a concern. Of course you may not have that adjacency information -- this is sort of what I mean by considering what inputs you have available to your algorithm. </p>

<p>If you don't just want to copy the face normal into the vertices, or you are sharing vertices and don't want to split them, you could:</p>

<pre><code>foreach vertex:
   set vertex normal to (0,0,0)

foreach triangle:
   foreach vertex on that triangle:
      set vertex normal = normalize( vertex normal + face normal )
</code></pre>

<p>This assumes that each triangle is actually referencing each vertex rather than storing a copy of it -- I don't know what language you're using so I don't know if that's the case or not.</p>
","8409"
"How can I discourage camping while still supporting a ""sniper"" style of play?","17536","","<p>I am trying to add features into a third person shooter that suit a sniper style of play, in addition to the current rush/deathmatch style it was designed for. The current gameplay is similar in style to Gears of War and Battlefield, perhaps similar to Call of Duty in terms of combat ranges but a little slower paced. The levels are similar in size to large COD maps, or medium Battlefield maps. </p>

<p>Two things which I was planning to add includes some long sight lines and also some ""sniper nests"". I am concerned though because these two features can open the door to a lot of camping. Sniping and camping are not the same things in my opinion, but it can be easy for campers to abuse such features for easy gain, when they were intended to promote tactical sniper use. That said, I don't believe in blaming the flaws of a game on a player's choice of play style.</p>

<p><strong>Sniper</strong>: Uses long range rifles, may stay in a specific spot that is tactically advantageous at the time, but knows how to move to other locations good for sniping. Provides spotting and suppression for more offensive/rush style team members.</p>

<p><strong>Camper</strong>: May use any weapon, always stays in the one spot and waits for players to pass by, leading to easy low risk kills. Follows the same strategy regardless of what is happening in the game/match. Is more focussed on own performance as opposed to supporting team members.</p>

<p>So, I am trying to think of some ways in which to try to discourage camping while still allowing legitimate sniper play and preserving the original rush gameplay.</p>
","<h2>How games I've played do this</h2>

<p>I've played about 300+ hours of Counter Strike: Global Offensive and find the sniper in it to be quite balanced.
There are a variety of ways this game helps counter snipers (AWP).</p>

<ol>
<li>The map has little clutter with a lot of entrances to points of interest.</li>
<li>You can go to the other bomb site if there are campers in a strong camping spot.</li>
<li>You can use a different entrance to a bomb site to kill snipers that are camping, from a place they are not looking.</li>
<li>You can use a flash bang to blind the sniper and assault them.</li>
<li>The AWP is a one shot kill so if you know where they are camping you can one shot them, before they do you.</li>
<li>The AWP makes you move slower, so it's harder to get into cover.
When scoped you move a lot slower.</li>
<li>The AWP reduces your FOV and so you can't see people entering from other places.</li>
<li>The AWP has both a long chambering duration and reload time, that makes you extremely vulnerable.</li>
<li>The AWP is very loud, so everyone can tell where it is from.</li>
</ol>

<p>If you want to know possibly more tactics then I mention around how the sniper in CS:GO is balanced you could look at the <a href=""http://counterstrike.wikia.com/wiki/AWP"">AWP page</a>, there are two other snipers, but they aren't used as much as the AWP.</p>

<hr>

<p>I remember in a few Quake games some friends and I played there were two maps with sniper positions:</p>

<p>One allowed you to be shot from near enough anywhere on the map, and there was a button to kill everyone in that spot.</p>

<p>On the other map the spot was so far away it was hard to be accurate with the sniper.</p>

<hr>

<p>Both Halo and Call Of Duty use smoke trails to show where the sniper was.</p>

<h2>General mechanics you can implement</h2>

<ul>
<li><p>Have a sparse map: Less cover, easier to see the sniper.</p></li>
<li><p>Have lots of entrances to the sniper nest: Harder for the sniper to protect themselves.</p></li>
<li><p>Don't allow the sniper nest to have more that 50% cover of the player: Only hide their legs, this reduces their 'camouflage' one of the most important things for them.</p></li>
<li><p>Have a built in way to blow up the sniper nest: If you shoot it with an RPG for example and you destroy it with everyone in it, it will discourage everyone going there.</p></li>
<li><p>Allow opponents to be able to pre-camp the sniper nest: This allows for an easy counter to what could be an OP spot.</p>

<p>Say it takes player 1 5 seconds to get into position to kill the player in the sniper nest.
And it takes player 2 either:</p>

<ul>
<li>10 seconds to get into the sniper nest, peek and be shot.</li>
<li>4 seconds to get into position to snipe player 1.</li>
</ul></li>
<li><p>Give the sniper a long reload time: The opponent can now just stand there and shoot them.</p></li>
<li><p>Make it very inaccurate if not resting: This makes sniping good.
But if you're in close quarter combat the gun will be luck based.</p></li>
<li><p>Give it a small amount of ammunition: It'll make the sniper happy when they die.
And will encourage the player to not waste shots.</p></li>
<li><p>Give it a smoke trail to show everyone where it's come from.</p></li>
<li><p>Give it a loud, global audio, and distinct sound.</p></li>
<li><p>Make it only fatal on head shots: This makes it harder to use, and makes small accuracy changes become massive gameplay changes.</p></li>
<li><p>Make the economic benefit of getting kills with it worse than other weapons: Say you get points in your game, get like 5 points for a sniper kill and 10 for a pistol kill.</p></li>
<li><p>Reduce the FOV: Makes the sniper more vulnerable to back/side attacks.</p></li>
</ul>
","118227"
"Is learning OpenGL 2.1 useless today?","17532","","<p>I'm new to 3D OpenGL/DirectX world and I found out that OpenGL 4.1 and GLSL specifications were just released today.</p>

<p>A friend of mine gave me the Red Book for OGL v2.1 but, as far as I've read, 3.x and 4.x differ a lot from 2.x and a lot of things are deprecated now.</p>

<p>Can I use the book to start learning the basics of 3D and CG or is it better to find a newer copy?</p>
","<p>In times like this I always head for the Steam Hardware Survey: <a href=""http://store.steampowered.com/hwsurvey/"">http://store.steampowered.com/hwsurvey/</a> - you'll see that market penetration of DX10/11 class systems is at almost 80%; this being broadly equivalent to GL3.3 or above.  This 80% is restricted to Vista/7 users - add in a DX10/11 GPU with XP and you rise to just over 90%.</p>

<p>Bearing in mind that we're talking about slightly more hardcore gamers here, you then need to start thinking about your target audience.  Are these the people you want to target?  Are you aiming at those with more downlevel hardware instead?  What about Intel graphics?  What about Mac and Linux users?  These are all questions that you need to answer for yourself, so broadly general guidelines are the best you're going to get.</p>

<p>Adding to that, you need to take account of the fact that if you're starting to learn today with the intention of shipping something, you're looking at a period of about one year minimum before you get there (unless we're talking about really trivial/simple cases).  With the upward trend of gfx capabilities continuing, we're looking at being real close to 100% uptake of GL3.3+ hardware by then.</p>

<p>Then factor in that with GL2.1 or lower you're going to be learning and using an awful lot of crufty old nonsense, even if you restrict yourself to the shaders and VBOs subset of GL2.1 (downlevel GLSL versions are nasty to use, and streaming VBOs are all but unusable without GL_ARB_map_buffer_range) - GL3.3+ has introduced <em>much</em> nicer (and more performant) ways of handling many things, you'll be making better use of the player's hardware (and they'll be grateful to you for that) and you'll be spending more time writing productive code rather than fighting an API that really doesn't want to co-operate with you.</p>

<p>And then of course there's the dreaded driver situation.  The hard but true fact is that GL drivers on Windows are in a sorry state - NV support things they shouldn't, AMD don't support things they should, and with Intel you really need to restrict yourself to GL functionality for which there is an equivalent in D3D.  The newer the GL_VERSION is the more likely it is you'll encounter driver bugs, but for GL3.3 things are reasonably stable now.</p>

<p>So the summary is that, in the absence of any other info (target audience, etc), I'd target GL3.3 as a baseline (possibly pulling in functionality from higher GL_VERSIONs where it's available and where it doesn't disrupt the codebase too much) unless there was a very specific and definitively identified reason to go any lower (and I'd want to be absolutely 100% certain of that rather than using some vague notion of ""<em>but what about those with older hardware</em>"").  In the latter case I wouldn't go below GL2.1, and I'd look to pull in as much 3.x functionality as possible even then.</p>
","34698"
"Preferred way to render text in OpenGL","17527","","<p>I'm about to pick up computer graphics once again for an university project. For a previous project I used a library called <a href=""http://sourceforge.net/apps/mediawiki/ftgl/index.php?title=Main_Page"">FTGL</a> that didn't leave me quite satisfied as it felt kind of heavy (I tried lots of rendering techniques, text rendering didn't scale very well).</p>

<p>My question is, is there a good and <strong>efficient</strong> library for this? If not, what would be the way to implement fast but nice looking text? Some intended uses are:</p>

<ul>
<li>Floating object/character labels</li>
<li>Dialogues</li>
<li>Menus</li>
<li>HUD</li>
</ul>

<p>EDIT: Preferably it could also load fonts</p>
","<p>A popular framework is <a href=""http://www.cegui.org.uk/wiki/index.php/Main_Page"" rel=""nofollow"">Crazy Eddie's GUI</a>.</p>

<p>But whilst that is appealing, its not unusual to roll your own (and perhaps regret it as the scope increases later ;))</p>

<p>Its normal to have your glyphs on bitmaps and then draw the bitmaps using OpenGL.</p>

<p>Sometimes you show transient text that might only appear for a handful of frames.  Just using GL_QUADS+glVertex will be sufficient.  But for any large quantity of text or any long duration of visibility its well worth putting the GL_QUADS in a VBO - I've noticed big performance improvements from this.</p>

<p>There is of course the question of generating the actual glyphs that you need.  There are programs like <a href=""http://www.angelcode.com/products/bmfont/"" rel=""nofollow"">bmfont</a> that you can use for that.  Or you might need rather more complicated rendering, e.g. freetype on demand.  I've been using bmfont with my own renderer quite happily, its very straightforward to deduce.</p>
","7563"
"What is actually moving in an endless runner?","17526","","<p>For example the famous Flappy Bird game, or anything that sort really,
is the player(in this case the bird, or the camera whichever you prefer) moving forward or is the whole world moving backwards(the bird only changes Y position and has a constant X position)?</p>
","<p>Both options work. </p>

<p>But if you want the endless runner to be truly endless, you will have to keep the player stationary and move the world. Otherwise you will eventually hit the limits of the variables you use to store the X-position. An integer would eventually overflow and a floating point variable would become increasingly less accurate which would make the gameplay glitchy after a while. But you can avoid this problem by using a large enough type that nobody will encounter these problems within the timespan one could conceivably play in one session (when a player moves 1000 pixels per second, a 32 bit integer will overflow after 49 days).</p>

<p>So do whatever feels conceptually more intuitive to you.</p>
","151733"
"How to render 2D particles as fluid?","17493","","<p>Suppose you have a nice way to move your 2D particles in order to simulate a fluid (like water). Any ideas on how to render it? </p>

<p>This is for a 2D game, where the perspective is from the side, <a href=""http://b.vimeocdn.com/ts/217/438/217438149_640.jpg"">like this</a>. The water will be contained in boxes that can be broken in order to let it fall down and interact with other objects. The simplest way that comes to my mind is to use a small image for each particle. I am interested in hearing more ways of rendering water.</p>
","<p>Check out how <a href=""https://www.google.co.uk/search?tbm=isch&amp;q=pixeljunk%20shooter"" rel=""noreferrer"">PixelJunk Shooter</a> did it (including simulation) in this <a href=""http://fumufumu.q-games.com/gdc2010/shooterGDC.pdf"" rel=""noreferrer"">presentation (PDF)</a> at GDC2010.</p>

<hr>

<p><img src=""https://i.stack.imgur.com/dNUpe.jpg"" alt=""Sample PixelJunk Shooter Image""></p>
","26317"
"Can Unity 2D be used to make pixel-art games?","17478","","<p>I'm looking at the new 2D features introduced in Unity 4.3, and I think I might be missing something.</p>

<p>To me it looks like they are designed for high-res 2D games, where scaling the sprites is ok, but it is unsuitable for pixel-art games.</p>

<p>A pixel-art sprite is designed to be displayed exactly 1:1 pixels on the screen: scaling destroys it (linear up-scaling is an exception, i.e. you may scale it 2x, 3x, 4x etc.).</p>

<p>However I've found no way to ""just display it as-is"", apparently Unity insists in scaling it to whatever resolution it sees fit: I may control the Camera.size parameter, and the ""pixels to units"" parameter of the sprite, but I didn't manage to obtain this result.</p>
","<p><a href=""http://gamasutra.com/blogs/JoshSutphin/20130519/192539/Making_2D_Games_With_Unity.php"">This article</a> gives some useful explainations, even if that's before 4.3 came out:</p>

<blockquote>
  <p>If you’re going for the “pixel art” look then the camera’s
  orthographic size is of critical importance; this is the trickiest
  part of nailing 2D in Unity.</p>
  
  <p>The orthographic size expresses how many world units are contained in
  the top half of the camera projection. For example, if you set an
  orthographic size of 5, then the vertical extents of the viewport will
  contain exactly 10 units of world space. (The horizontal extents are
  dependent on the display aspect ratio.)</p>
  
  <p>Recall that your sprite quad is 1 unit to a side. That means the
  orthographic size tells you how many sprites you can stack vertically
  in the viewport (divided by 2).</p>
  
  <p>To render the pixel-art look cleanly, you need to ensure that each
  pixel of the sprite’s source texture maps 1:1 to the viewport display.
  You don’t want source pixels being skipped or doubled-up, or your
  sprites will look distorted and “dirty”. The trick to ensuring this
  1:1 ratio is to set an orthographic size that matches your vertical
  screen resolution divided by the pixel height of a sprite.</p>
  
  <p>Let’s say you’re running at 960x640, and you’re using 64x64 sprites.
  Dividing the vertical screen resolution (640) by the pixel height of a
  sprite (64) yields 10, the number of 64x64 sprites that can be
  vertically stacked in 640 pixels. Remember that the orthographic size
  is a half-height, so your target orthographic size in this case is
  going to be 5 (one-half of 10). It should look like this:</p>
  
  <p>If you set your orthographic size to half or double that target you
  may still get usable results, because the sprite’s vertical size will
  still divide evenly into the viewport’s vertical size. But if you set
  the orthographic size incorrectly, you will see some pixels skipped or
  doubled, and it will look very bad indeed:</p>
  
  <p><strong>Variable Resolution</strong></p>
  
  <p>You don’t need to be confined to a single, fixed resolution in order
  to render clean pixel art. <strong>The simplest way to handle variable
  resolutions is to attach a custom script to your camera which sets the
  orthographic size according to the current vertical resolution and a
  known (fixed) sprite size</strong>:</p>
</blockquote>

<pre><code>// set the camera to the correct orthographic size
// (so scene pixels are 1:1)
s_baseOrthographicSize = Screen.height / 64.0f / 2.0f;
Camera.main.orthographicSize = s_baseOrthographicSize;
</code></pre>

<blockquote>
  <p>While that is a simple fix, it does have a drawback: as the screen resolution
  decreases, you’ll see less and less of the world, and sprites will
  take up more and more of the screen. That’s the consequence of keeping
  a 1:1 ratio between source and screen pixels: a 64x64 sprite takes up
  more apparent space at 640x480 than it does at 1920x1200. Whether this
  is a problem or not depends on the needs of your specific game.</p>
  
  <p>If you want your sprites to remain the same apparent size regardless
  of screen resolution, then simply set the orthographic size to a fixed
  value and leave it there regardless of the screen resolution. The
  drawback there is that your sprites will no longer have a 1:1
  source-to-screen pixel ratio. You can mitigate the ill effects of that
  by only allowing resolutions which are exactly half or exactly double
  your target resolution.</p>
</blockquote>

<p><em>(some emphasis added)</em></p>

<p>This obviously works better if the height resolution is divisible by the sprite size, but even when it isn't, it still gives a good approximation of a decent result.</p>

<hr>

<p><strong>TL;DR</strong>: <code>cameraSelf.orthographicSize = screenH / (float)spriteSize / 2f;</code></p>
","66292"
"When to use a vertex array and when to use a VBO?","17397","","<p>I'm trying to learn about <strong>vertex arrays</strong> and <strong>vertex buffer objects</strong>, but I don't understand the differences in terms of:</p>

<ul>
<li>case-of-use (static geometry like terrains, geometry that changes every frame like a particle system, etc.)</li>
<li>performance</li>
<li>portability (old graphics card, consoles, devices like Android or iPhone, etc.)</li>
</ul>

<p>some clarifications?</p>
","<p><a href=""http://www.opengl.org/wiki/Vertex_Buffer_Objects"" rel=""nofollow"">Here</a> is a decent writeup about VBOs.</p>

<p><strong>Performance</strong></p>

<p><a href=""http://ezekiel.vancouver.wsu.edu/~cs442/lectures/vbo/vbo.pdf"" rel=""nofollow"">Here</a> is a good overview of the calling semantics.</p>

<p><a href=""http://developer.amd.com/media/gpu_assets/PerformanceTuning.pdf"" rel=""nofollow"">Here</a> here is another good overview of performance issues; in it we see that VBOs are more performant than arrays.</p>

<p>The reason we prefer VBOs is that the data is loaded onto the card, and so you don't have to transfer it every frame. Depending on the type of VBO created, you can give the graphics driver hints on the usage (write-many, read-many vs. write-many, never-read, etc).</p>

<p><strong>Usage</strong></p>

<p>VBOs are really good for static geometry like terrain that you don't expect to change, or for instanced geometry.</p>

<p>Vertex arrays are good for data that changes frequently but that also is read by the host machine--so, for directly rendering data that is being manipulated (laser rangefinder data buffers, for example, are where I've used them) frequently. If you can get away with never reading the data on the host device (so, just pushing it out onto the card), VBOs in write-only mode are a good option.</p>

<p><strong>Portability</strong></p>

<p><em>Client Side Vertex Arrays</em>
These are available in OpenGL prior to 3.0, deprecated in 3.0, and gone in 3.1+.
OpenGL ES supports them (OpenGL ES 2 does not).</p>

<p><em>VBOs</em>
These are available after OpenGL 1.5.
These are the only way to store geometry data in OpenGL ES 2 (and so, WebGL).</p>
","11445"
"OpenGL/GLSL: Render to cube map?","17385","","<p>I'm trying to figure out how to render my scene to a cube map. I've been stuck on this for a bit and figured I would ask you guys for some help. I'm new to OpenGL and this is the first time I'm using a FBO.</p>

<p>I currently have a working example of using a cubemap bmp file, and the samplerCube sample type in the fragment shader is attached to GL_TEXTURE1. I'm not changing the shader code at all. I'm just changing the fact that I wont be calling the function that was loading the cubemap bmp file and trying to use the below code to render to a cubemap. </p>

<p>You can see below that I'm also attaching the texture again to GL_TEXTURE1. This is so when I set the uniform: </p>

<pre><code>glUniform1i(getUniLoc(myProg, ""Cubemap""), 1);
</code></pre>

<p>it can access it in my fragment shader via <code>uniform samplerCube Cubemap</code>. </p>

<p>I'm calling the below function like so:</p>

<pre><code>cubeMapTexture = renderToCubeMap(150, GL_RGBA8, GL_RGBA, GL_UNSIGNED_BYTE);
</code></pre>

<p>Now, I realize in the draw loop below that I'm not changing the view direction to look down the +x, -x, +y, -y, +z, -z axis. I really was just wanting to see something working first before implemented that. I figured I should at least see something on my object the way the code is now.</p>

<p>I'm not seeing anything, just straight black. I've made my background white still the object is black. I've removed lighting, and coloring to just sample the cubemap texture and still black. </p>

<p>I'm thinking the problem might be the format types when setting my texture which is GL_RGB8, GL_RGBA but I've also tried:</p>

<p>GL_RGBA, GL_RGBA
GL_RGB, GL_RGB</p>

<p>I thought this would be standard since we are rendering to a texture attached to a framebuffer, but I've seen different examples that use different enum values.</p>

<p>I've also tried binding the cube map texture in every draw call that I'm wanting to use the cube map:</p>

<pre><code>glBindTexture(GL_TEXTURE_CUBE_MAP, cubeMapTexture);
</code></pre>

<p>Also, I'm not creating a depth buffer for the FBO which I saw in most examples, because I'm only wanting the color buffer for my cube map. I actually added one to see if that was the problem and still got the same results. I could of fudged that up when I tried. </p>

<p>Any help that can point me in the right direction would be appreciated.</p>

<pre><code>GLuint renderToCubeMap(int size, GLenum InternalFormat, GLenum Format, GLenum Type)
    {

    // color cube map
    GLuint textureObject;
    int face;
    GLenum status;

    //glEnable(GL_TEXTURE_2D);
    glActiveTexture(GL_TEXTURE1);
    glGenTextures(1, &amp;textureObject);
    glBindTexture(GL_TEXTURE_CUBE_MAP, textureObject);
    glTexParameterf(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
    glTexParameterf(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
    glTexParameterf(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
    glTexParameterf(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
    glTexParameterf(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_R, GL_CLAMP_TO_EDGE);

    for (face = 0; face &lt; 6; face++) {
        glTexImage2D(GL_TEXTURE_CUBE_MAP_POSITIVE_X + face, 0, InternalFormat, size, size, 0, Format, Type, NULL);
    }

    // framebuffer object
    glGenFramebuffers(1, &amp;fbo);
    glBindFramebuffer(GL_FRAMEBUFFER, fbo);

    glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_CUBE_MAP_POSITIVE_X, textureObject, 0);

    status = glCheckFramebufferStatus(GL_FRAMEBUFFER);
    printf(""%d\""\n"", status);
        printf(""%d\n"", GL_FRAMEBUFFER_COMPLETE);

    glViewport(0,0,size, size);

    for (face = 1; face &lt; 6; face++) {

        drawSpheres();
        glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0,GL_TEXTURE_CUBE_MAP_POSITIVE_X + face, textureObject, 0);

    }

     //Bind 0, which means render to back buffer, as a result, fb is unbound
       glBindFramebuffer(GL_FRAMEBUFFER, 0);

       return textureObject;
    }
</code></pre>
","<p>Well, I can't guarantee that this will help you figure out what's going on. You simply haven't posted enough information about what you're doing to track down any particular errors. Though I can correct one thing of yours really quick:</p>

<pre><code>glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_CUBE_MAP_POSITIVE_X, textureObject, 0);

...

for (face = 1; face &lt; 6; face++) {
    drawSpheres();
    glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_CUBE_MAP_POSITIVE_X + face, textureObject, 0);
}
</code></pre>

<p>This will only call <code>drawSpheres</code> <em>five</em> times. I'm guessing you wanted to call it 6 times.</p>

<p>But I can post a <a href=""https://ideone.com/VroYK"" rel=""nofollow"">working answer.</a> Note that this code is designed to be run <a href=""http://alfonse.bitbucket.org/oldtut/"" rel=""nofollow"">alongside my tutorial series</a>, so it makes reference to code that isn't present. But this is mainly things like creating meshes and so forth; nothing truly important.</p>

<p>Here are the salient points. The shaders for the main sphere object.</p>

<p>Vertex shader:</p>

<pre><code>#version 330

layout(std140) uniform;

layout(location = 0) in vec4 position;
layout(location = 2) in vec3 normal;

out vec3 modelSpaceNormal;

uniform Projection
{
    mat4 cameraToClipMatrix;
};

uniform mat4 modelToCameraMatrix;

void main()
{
    gl_Position = cameraToClipMatrix * (modelToCameraMatrix * position);
    modelSpaceNormal = normal;
}
</code></pre>

<p>Fragment shader:</p>

<pre><code>#version 330

in vec3 modelSpaceNormal;

uniform samplerCube cubeTexture;

out vec4 outputColor;

void main()
{
    outputColor = texture(cubeTexture, modelSpaceNormal);
//  outputColor = vec4(normalize(modelSpaceNormal), 1.0);
}
</code></pre>

<p>The creation of the cubemap texture that will be used as a render target:</p>

<pre><code>void CreateCubeTexture()
{
    glGenTextures(1, &amp;g_cubeTexture);
    glBindTexture(GL_TEXTURE_CUBE_MAP, g_cubeTexture);

    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_BASE_LEVEL, 0);
    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MAX_LEVEL, 0);
    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MIN_FILTER, GL_LINEAR);

    std::vector&lt;GLubyte&gt; testData(CUBE_TEXTURE_SIZE * CUBE_TEXTURE_SIZE * 256, 128);
    std::vector&lt;GLubyte&gt; xData(CUBE_TEXTURE_SIZE * CUBE_TEXTURE_SIZE * 256, 255);

    for(int loop = 0; loop &lt; 6; ++loop)
    {
        if(loop)
        {
            glTexImage2D(GL_TEXTURE_CUBE_MAP_POSITIVE_X + loop, 0, GL_RGBA8,
                CUBE_TEXTURE_SIZE, CUBE_TEXTURE_SIZE, 0, GL_RGBA, GL_UNSIGNED_BYTE, &amp;testData[0]);
        }
        else
        {
            glTexImage2D(GL_TEXTURE_CUBE_MAP_POSITIVE_X + loop, 0, GL_RGBA8,
                CUBE_TEXTURE_SIZE, CUBE_TEXTURE_SIZE, 0, GL_RGBA, GL_UNSIGNED_BYTE, &amp;xData[0]);
        }
    }

    glBindTexture(GL_TEXTURE_CUBE_MAP, 0);
}
</code></pre>

<p>I actually fill the texture with data (rather than passing NULL to glTexImage2D) as a debugging aid. It ensures that everything was working prior to starting to use the texture as a render target.</p>

<p>Also, notice that I provide a BASE_LEVEL and MAX_LEVEL. I <em>always</em> do that with my textures immediately after creation. It's just a good habit, as OpenGL can be picky sometimes about texture completeness and the mipmap pyramid. Rather than remembering the rules, I just set them to the correct values religiously.</p>

<p>Here's the main drawing function:</p>

<pre><code>void display()
{
    //Draw the cubemap.
    glBindFramebuffer(GL_DRAW_FRAMEBUFFER, g_framebuffer);
    glFramebufferRenderbuffer(GL_DRAW_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, g_depthbuffer);

    for(int loop = 0; loop &lt; 6; ++loop)
        DrawFace(loop);

    glBindFramebuffer(GL_DRAW_FRAMEBUFFER, 0);

    //Draw the main scene.
    //The projection matrix is in a uniform buffer.
    ProjectionBlock projData;
    projData.cameraToClipMatrix = glm::perspective(90.0f,
        (g_viewportSize.x / (float)g_viewportSize.y), g_fzNear, g_fzFar);

    glBindBuffer(GL_UNIFORM_BUFFER, g_projectionUniformBuffer);
    glBufferSubData(GL_UNIFORM_BUFFER, 0, sizeof(ProjectionBlock), &amp;projData);
    glBindBuffer(GL_UNIFORM_BUFFER, 0);

    glViewport(0, 0, (GLsizei)g_viewportSize.x, (GLsizei)g_viewportSize.y);

    glClearColor(0.75f, 0.75f, 1.0f, 1.0f);
    glClearDepth(1.0f);
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

    glutil::MatrixStack modelMatrix;
    modelMatrix.ApplyMatrix(g_viewPole.CalcMatrix());

    if(g_pSphere)
    {
        glutil::PushStack push(modelMatrix);

        glUseProgram(g_progMain.theProgram);
        glUniformMatrix4fv(g_progMain.modelToCameraMatrixUnif, 1, GL_FALSE,
            glm::value_ptr(modelMatrix.Top()));

        glActiveTexture(GL_TEXTURE0 + g_cubeTexUnit);
        glBindTexture(GL_TEXTURE_CUBE_MAP, g_cubeTexture);

        g_pSphere-&gt;Render(""lit"");

        glBindTexture(GL_TEXTURE_CUBE_MAP, 0);

        glUseProgram(0);
    }

    glutPostRedisplay();
    glutSwapBuffers();
}
</code></pre>

<p>This makes reference to <code>DrawFace</code>, which draws the given face of the cubemap. That is implemented as follows:</p>

<pre><code>void DrawFace(int iFace)
{
    glFramebufferTexture2D(GL_DRAW_FRAMEBUFFER, GL_COLOR_ATTACHMENT0,
        GL_TEXTURE_CUBE_MAP_POSITIVE_X + iFace, g_cubeTexture, 0);

    GLenum status = glCheckFramebufferStatus(GL_DRAW_FRAMEBUFFER);
    if(status != GL_FRAMEBUFFER_COMPLETE)
        printf(""Status error: %08x\n"", status);

    //The projection matrix is in a uniform buffer.
    ProjectionBlock projData;
    projData.cameraToClipMatrix = glm::perspective(90.0f, 1.0f, g_fzNear, g_fzFar);

    glBindBuffer(GL_UNIFORM_BUFFER, g_projectionUniformBuffer);
    glBufferSubData(GL_UNIFORM_BUFFER, 0, sizeof(ProjectionBlock), &amp;projData);
    glBindBuffer(GL_UNIFORM_BUFFER, 0);

    glViewport(0, 0, (GLsizei)CUBE_TEXTURE_SIZE, (GLsizei)CUBE_TEXTURE_SIZE);

    const glm::vec4 &amp;faceColor = g_faceColors[iFace];
    glClearColor(faceColor.x, faceColor.y, faceColor.z, faceColor.w);
    glClearDepth(1.0f);
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

    if(g_pSphere)
    {
        glutil::MatrixStack modelMatrix;
        modelMatrix.Translate(g_faceSphereLocs[iFace]);

        glUseProgram(g_progUnlit.theProgram);
        glUniformMatrix4fv(g_progUnlit.modelToCameraMatrixUnif, 1, GL_FALSE,
            glm::value_ptr(modelMatrix.Top()));

        const glm::vec4 &amp;sphereColor = g_faceSphereColors[iFace];
        glUniform4fv(g_progUnlit.objectColorUnif, 1, glm::value_ptr(sphereColor));

        glActiveTexture(GL_TEXTURE0 + g_cubeTexUnit);
        glBindTexture(GL_TEXTURE_CUBE_MAP, g_cubeTexture);

        g_pSphere-&gt;Render(""flat"");

        glBindTexture(GL_TEXTURE_CUBE_MAP, 0);
        glUseProgram(0);
    }
}
</code></pre>

<p>This function makes reference to a set of global tables that I use to give each face a distinct background color, a distinct sphere color, and to position the sphere (in camera-space) properly for that face.</p>

<p>The salient points for <code>DrawFace</code> are these.</p>

<p>As a general rule, unless I have <em>certain</em> knowledge that state is set, I set that state. I set the viewport each time I call <code>DrawFace</code>. I set the projection matrix each time. Those are superfluous; I could have set them back in <code>display</code> before the loop that calls <code>DrawFace</code>, just as I do with the current FBO and depth renderbuffer.</p>

<p>But I <em>also</em> clear the buffers, which is different for each face (since each face has a different color). </p>
","19771"
"Simple noise generation","17375","","<p>I'm looking to generate noise that looks like this:</p>

<p><img src=""https://i.stack.imgur.com/Gcsc2.png"" alt=""enter image description here""><img src=""https://i.stack.imgur.com/K8Uwc.jpg"" alt=""enter image description here""></p>

<p>(images courtesy of <a href=""https://gamedev.stackexchange.com/questions/18330/understanding-perlin-noise"">Understanding Perlin Noise</a>)</p>

<p>I'm basically looking for noise with lots of small ""ripples"". The following is undesirable:</p>

<p><img src=""https://i.stack.imgur.com/nO2eC.png"" alt=""enter image description here""></p>

<p>Are there any <strong>simple</strong> ways to do this? I've been looking at perlin and simplex for a week now and I can't seem to ever get it to work in JavaScript, or when I do, I don't have the correct parameters to generate such images, or it is excruciatingly slow.</p>

<p>I understand that the 3 images I posted could probably be achieved by the same algorithm but at a different scale, but I don't need that algorithm. I just need a very simple algorithm to achieve something like in the first image ideally. Maybe some kind of blurring would do the job, but I can't manage to have results.</p>

<p>I'm developing this in JavaScript but any kind of code or even a simple and detailed explanation will work.</p>
","<p>While the existing answers provide a good way to achieve what the images in the question show, the comments revealed that the goal is to generate an image as shown below:</p>

<p><img src=""https://i.stack.imgur.com/6h552.jpg"" alt=""perlin noise turbulence""></p>

<p>This type of noise is quite different from the noise shown in the images of the question, as it forms close isolated blobs.</p>

<p>Turns out that this kind of noise is called <em>turbulence</em> which (according to <a href=""http://http.developer.nvidia.com/GPUGems/gpugems_ch05.html"" rel=""noreferrer"">this CPU Gems article</a>) is implemented as follows (where <code>noise</code> is your Perlin-noise function returning values from -1..1):</p>

<pre><code>double turbulence(double x, double y, double z, double f) {
    double t = -.5;
    for ( ; f &lt;= W/12 ; f *= 2) // W = Image width in pixels
        t += abs(noise(x,y,z,f) / f);
    return t;
}
</code></pre>

<p>Mashing up this <a href=""https://gist.github.com/304522"" rel=""noreferrer"">JavaScript Perlin-noise implementation</a> with the turbulence function described above generates noise which is pretty similar to the image above:</p>

<p><img src=""https://i.stack.imgur.com/8koWp.png"" alt=""turbulence noise""></p>

<p>The JavaScript code that was used to generate the image above can be found in <a href=""http://jsfiddle.net/yRD6Z/1/"" rel=""noreferrer"">this jsFiddle</a>.</p>
","20957"
"What is deferred rendering?","17287","","<p>I've heard about deferred rendering and how using it can allow for ""lots"" of lights in a scene without a huge performance hit, but what is it and (from a high level) how is it implemented?</p>
","<p>The defining characteristic of deferred rendering is that it essentially changes the complexity of scene rendering from O(geometry * lights) to O(geometry + lights).</p>

<p>This is achieved by first rendering the scene using shaders designed to output basic attributes such as (at a minimum) position*, normal, and diffuse color. Other attributes might include per-pixel specular values and other material properties. These are stored in full screen render targets, collectively known as the G-buffer.</p>

<p>(*: <em>It's worth noting that developers will more commonly opt to store depth, and use that to reconstruct position, since having depth available is useful for so many other effects.</em>)</p>

<p>Once the G-buffer has been generated, it's possible to compute a fully lit result for any pixel on the screen by solving the BRDF exactly once per pixel per light. In other words, if you have 20 meshes that each are affected by 20 lights, traditional (""forward"") rendering would demand that you re-render each mesh several times in order to accumulate the result of each light affecting it. In the worst case, this would be one draw call per mesh per light, or 400 total draw calls! For each of these draw calls, you're redundantly retransforming the vertices of the mesh. There's also a good chance that you'll be shading pixels that aren't actually affected by the light, or won't be visible in the final result (because they'll be occluded by other geometry in the scene). Each of these results in wasted GPU resources.</p>

<p>Compare to deferred rendering: You only have to render the meshes once to populate the G-buffer. After that, for each light, you render a bounding shape that represents the extents of the light's influence. For a point light, this could be a small sphere, or for a directional light, it would be a full screen quad, since the entire scene is affected.</p>

<p>Then, when you're executing the pixel/fragment shader for that light's bounding volume, you read the geometry attributes from the appropriate position in the G-buffer textures, and use those values to determine the lighting result. Only the scene pixels that are visible in the final result are shaded, and they are shaded exactly once per light. This represents a potentially huge savings.</p>

<p>However, it's not without drawbacks. It's a paradigm which is very difficult to extend to handle transparent geometry (see: depth peeling). So difficult, in fact, that virtually all deferred rendering implementations fall back to forward rendering for the transparent portions of the scene. Deferred rendering also consumes a large amount of VRAM and frame buffer bandwidth, which leads to developers going to great lengths to cleverly pack and compress G-buffer attributes into the smallest/fewest components possible.</p>
","184"
"Examples of Android Joystick Controls?","17222","","<p>I can't seem to find any well executed code examples for Android joystick controls.</p>

<p>Whatever it may be, algorithms, pseudo code, actual code examples, strategies, or anything to assist with the design and implementation of Android joystick controls; I can't seem to find anything decent on the net.</p>

<p><strong>What are some well executed examples?</strong></p>

<p>More specifically,</p>

<ul>
<li>Pseudo Code</li>
<li>Current Examples</li>
<li>Idea/Design</li>
<li>Functionality Description</li>
<li>Controller Hints Related Directly to Android Architecture</li>
</ul>

<p>What kind of classes will I have making this? Will there be only one? How would this be implemented to the game architecture? All things I am thinking about.</p>

<p>Cheers!</p>

<p><strong>UPDATE</strong></p>

<ul>
<li><p>I've found this on the subject <a href=""http://www.youtube.com/watch?v=MYehFrsiCcg"" rel=""nofollow"">Joystick Example1</a>, though I am still looking for different examples/resources.</p></li>
<li><p>Answered my own question with a link to the code of the above video. It's a fantastic start to Android Joystick Controls.</p></li>
</ul>
","<p><a href=""https://web.archive.org/web/20111229070701/http://www.java2s.com/Open-Source/Android/Widget/mobile-anarchy-widgets/com/MobileAnarchy/Android/Widgets/Joystick/JoystickView.java.htm"" rel=""nofollow"">Anarchy Joystick Widget</a></p>

<p>The link above is code for implementing a Joystick. You can see this code in action with <a href=""http://www.youtube.com/watch?v=MYehFrsiCcg"" rel=""nofollow"">this video</a>.</p>
","18142"
"What is the view perspective angle of most 2.5D isometric games","17200","","<p>I examined several quite popular games to determine what perspective angle they are using. For the purpose I created a grid that is 45 and 60 degrees isometric viewed and put it onto a screenshot (of Diablo II in this case). None of these grids fit to the game's perspective. So I tried to find the angle that fits best to the perspective and it is close to 53.5 degrees. However, this number seems like coming from nowhere and I believe there is a strong logic behind the number that defines the perspective angle. I tried 9/16 * 90 degrees and 3/4 * 90 degrees (coming from ratios of screens resolution 16:9 and 4:3) but none of my assumptions seem to be correct. Here are screenshots of what I mean:</p>

<p>60 degrees
<img src=""https://i.stack.imgur.com/8uPeg.jpg"" alt=""enter image description here""></p>

<p>45 degrees
<img src=""https://i.stack.imgur.com/bbBIM.jpg"" alt=""enter image description here""></p>

<p>Something between the two - 53.5 degrees - quite near to the real number
<img src=""https://i.stack.imgur.com/BBgSc.jpg"" alt=""enter image description here""></p>

<p>I really need to know what the real degrees are and where it derives from. Any help is quite appreciated! Thank you!</p>
","<p>I believe your intuition was correct, just not your formula.</p>

<pre><code>atan(4 / 3) = 53.1301024 degrees
</code></pre>

<p>This ratio can be useful because it forms a <a href=""http://en.wikipedia.org/wiki/Pythagorean_triple"" rel=""noreferrer"">Pythagorean triangle</a>, meaning that the length of the diagonal is an exact integer value.</p>

<p><img src=""https://i.stack.imgur.com/xVlPU.jpg"" alt=""Pythagorean ""></p>
","47165"
"Isometric game engine in JavaScript/HTML5","17154","","<p>Is anybody aware of any stable-ish (ie out of alpha) isometric drawing engines for JavaScript/HTML5?  I have done some Google searches and found a few, but they were mostly in alpha/invite-only status.</p>

<p>Is there anything mature enough to be used in a production environment?  Or should I simply roll my own implementation for now and wait for the rest of the world to catch up?</p>
","<p>As you said, the only ones I have found are either betas or alphas with none seeming to be ready for release.</p>

<p><strong>At this point in time it is probably better to roll your own:</strong></p>

<ul>
<li><p>Better understanding of the internals.</p></li>
<li><p>Able to tweak the engine to your needs.</p></li>
<li><p>Develop the features you need to use</p></li>
<li><p>Skip features of other engines you don't need, reducing code bloat, and overhead.</p></li>
<li><p>Bugs and issues will be your own problem, and easier and faster to fix than an unfinished engine.</p></li>
</ul>
","6174"
"Unity 3d auto-move player forward script","17147","","<p>Trying to write a basic script to attach to the player on Unity 3D, I want them to move forward automatically. I'm guessing that will be part of the Update function and using transform, but that's about as far as I get.</p>

<p>I'm assuming it's a Transform.translate function too, but not sure what parameters to use to move forward 1 m/s automatically (for example). Also, how do I block W and S keys moving forwards and backwards, and instead use the for up and down? (My character is 'floating' and I'm looking to incorporate space harrier style controls)</p>

<p>Thank you!</p>
","<p>The first sample code is what you want. 
<a href=""http://unity3d.com/support/documentation/ScriptReference/Transform.Translate.html"" rel=""nofollow"">http://unity3d.com/support/documentation/ScriptReference/Transform.Translate.html</a></p>

<pre><code>function Update() 
{
    transform.Translate(Vector3.forward * Input.GetAxis(""Vertical"") * Time.deltaTime);
}
</code></pre>

<p>Vector3.forward is the same as (0,0,1), and transform.Translate() is local translate, so Translate(0,0,1) is always moving forward. Time.deltaTime let speed equal to 1 m/s.</p>

<p>And you can change the default key in ""Input Manager""
<a href=""http://unity3d.com/support/documentation/Components/class-InputManager.html"" rel=""nofollow"">http://unity3d.com/support/documentation/Components/class-InputManager.html</a></p>
","19460"
"Game State 'Stack'?","17134","","<p>I was thinking about how to implement game states into my game. The main things I want for it are:</p>

<ul>
<li><p>Semi-transparent top states-being able to see through a pause menu to the game behind</p></li>
<li><p>Something OO-I find this easier to use and understand the theory behind, as well as keeping orgranised and adding more to.</p></li>
</ul>

<p><br><br>
I was planning on using a linked list, and treat it as a stack. This means I could access the state below for the semi-transparency.
<br>
Plan: Have the state stack be a linked list of pointers to IGameStates. The top state handles its own update and input commands, and then has a member isTransparent to decide whether the state underneath should be drawn.
<br> Then I could do:</p>

<pre><code>states.push_back(new MainMenuState());
states.push_back(new OptionsMenuState());
states.pop_front();
</code></pre>

<p>To represent the player loading, then going to options, and then main menu.
<br>
Is this a good idea, or...? Should I look at something else?</p>

<p><p>
Thanks.</p>
","<p>I worked on the same engine as coderanger. I have a differing viewpoint. :)</p>

<p>First, we did not have a stack of FSMs - we had a stack of states. A stack of states makes a single FSM. I don't know what a stack of FSMs would look like. Probably too complicated to do anything practical with.</p>

<p>My biggest problem with our Global State Machine was that it was a stack of states, and not a set of states. This means, e.g., .../MainMenu/Loading was different than .../Loading/MainMenu, depending on if you got the main menu up before or after the loading screen (the game is asynchronous and loading is mostly server-driven).</p>

<p>As two examples of things this made ugly:</p>

<ul>
<li>It led to e.g. the LoadingGameplay state, so you had Base/Loading, and Base/Gameplay/LoadingGameplay for loading within the Gameplay state, which had to repeat much of the code in the normal loading state (but not all, and add some more).</li>
<li>We had several functions like ""if in character creator go to gameplay; if in gameplay go to character select; if in character select go back to login"", because we wanted to show the same interface windows in different states but make the Back/Forward buttons still work.</li>
</ul>

<p>Despite the name, it was not very ""global"". Most internal <em>game</em> systems did not use it to track their internal states, because they didn't want their states mucking about with other systems. Others, e.g. the UI system, could use it but only to copy state into their own local state systems. (I would especially caution against the system for UI states. UI state is not a stack, it's really a DAG, and trying to force any other structure on it is only going to make UIs that are frustrating to use.)</p>

<p>What it was good for was isolating tasks for integrating code from infrastructure programmers who didn't know how the game flow was actually structured, so you could tell the guy writing the patcher ""put your code in Client_Patch_Update"", and the guy writing the graphics loading ""put your code in Client_MapTransfer_OnEnter"", and we could swap certain logic flows around without much trouble.</p>

<p>On a side project, I have had better luck with a state <em>set</em> rather than a <em>stack</em>, not being afraid to make multiple machines for unrelated systems, and refusing to let myself fall into the trap of having a ""global state"", which is really just a complicated way to synchronize things through global variables - Sure, you're going to end up doing it near some deadline, but don't design with that as your <em>goal</em>. Fundamentally, state in a game is not a stack, and states in a game are not all related.</p>

<p>The GSM also, as function pointers and non-local behavior tend to do, made debugging things more difficult, though debugging those kind of large state transitions wasn't very fun before we had it either. State-sets instead of state-stacks does not really help this, but you should be aware of it. Virtual functions rather than function pointers may alleviate that somewhat.</p>
","1785"
"How do I use the dot product to get an angle between two vectors?","17124","","<p>I am learning to use normalized vectors in my games.</p>

<p>I've learned that in order to know the angle between two vectors, I can use the dot product. This gives me a value between -1 and 1, where</p>

<ul>
<li>1 means the vectors are parallel and facing the same direction (the angle is 180 degrees).</li>
<li>-1 means they are parallel and facing opposite directions (still 180 degrees).</li>
<li><code>0</code> means the angle between them is 90 degrees.</li>
</ul>

<p>I want to know how to convert the dot product of two vectors, to an actual angle in degrees. For example, if the dot product of two vectors is <code>0.28</code>, what is the corresponding angle, between 0 and 360 degrees?</p>
","<p><code>dot(A,B) = |A| * |B| * cos(angle)</code>
<br />which can be rearranged to
<br /><code>angle = arccos(dot(A,B) / (|A|* |B|))</code>.</p>

<p>With this formula, you can find the smallest angle between the two vectors, which will be between 0 and 180 degrees. If you need it between 0 and 360 degrees <a href=""https://gamedev.stackexchange.com/questions/7131/how-can-i-calculate-the-angle-between-two-2d-vectors?rq=1"">this question may help you.</a></p>

<hr>

<p>By the way, the angle between two parallel vectors pointing in the same direction should be 0 degrees, not 180.</p>
","69476"
"Why is account sharing so bad?","17114","","<p>In games where you have to use an account to sign in or otherwise authenticate yourself (e.g MMO games), it is often prohibited to share your account with other people.</p>

<p>For example in the <a href=""http://eu.blizzard.com/en-gb/company/legal/wow_tou.html"" rel=""noreferrer"">World of Warcraft Official Terms of Use Agreement</a>:</p>

<blockquote>
  <p>[...] You may not share the Account with anyone, except that if you are a parent or guardian, you may permit one (1) minor child to use the Account when not in use by you. You are liable for all uses of the Account that has been enabled by you […]</p>
</blockquote>

<p>And the <a href=""http://eune.leagueoflegends.com/en/legal/termsofuse"" rel=""noreferrer"">League of Legends Terms of Use</a>:</p>

<blockquote>
  <p>[...] You can’t share your account or Login Credentials with anyone. You can’t sell, transfer or allow any other person to access your account or Login Credentials, or offer to do so. You’re entirely responsible for maintaining the confidentiality of your Login Credentials. [...]</p>
</blockquote>

<p>What is the reason for this? Is it because of legal reasons and / or security reasons? I imagine account sharing would not be a problem if there weren't some real-world consequences for the <em>company</em>, not just the end-user.</p>
","<p>It's important to have a firm grasp of precisely who the legal entities are in any contractual agreement, so you know who you have to sue or blame or whatever if it ever comes to that.</p>

<p>Less seriously, if account-sharing were permissible, then blaming ""somebody else who was using the account at the time"" would be a reasonable response to any punishments for violating any other rules. By prohibiting sharing that way, a company eliminates the hassle of having to deal with that argument (which is usually impossible to disprove) in response to bans. Obviously people still try to use that defense, but a company can simply point to the rule against account sharing and say ""well that's not allowed either."" It makes life way simpler for the GM team.</p>

<p>It also has a small side-benefit: it means that if you and your friend want to play, you have to buy two copies of the game, you can't buy one and share it. This is obviously also better for the company.</p>
","148356"
"Can I use DirectX with C#?","17096","","<p>I thought that if you wanted to make games using DirectX, you had to know C++. But I recently found out that that is not actually true. It looks like some parts of Direct3D can be used from C#. <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/bb153354%28v=vs.85%29.aspx"" rel=""nofollow"">This MSDN document</a>, for example, which has C# examples.</p>

<p>Am I understanding this incorrectly? Have I waited all these years for nothing?</p>
","<p>Yes, there are DirectX bindings for C#. This has been available for almost 10 years or more. </p>

<p><a href=""http://www.microsoft.com/en-us/download/details.aspx?id=23714"">XNA</a> (announced 2004), <a href=""http://monogame.codeplex.com/"">MonoGame</a> (announced 2009), <a href=""http://sharpdx.org/"">SharpDX</a> and more all provide you the ability to access DirectX using C#. You actually only need to Google ""C# DirectX"" and you'll find plenty resources on this. The MSDN documents you are link to in your question, however, are referencing Microsoft's own ""Managed DirectX,"" which is now deprecated and not a viable choice for new development.</p>

<p>Additionally, you only need to look a little further into link you provided to find sample projects you can use with the <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/bb153298%28v=vs.85%29.aspx"">Direct3D API</a>.</p>
","62841"
"Runescape Private Server - How does it work?","17074","","<p>I've seen a lot of Runescape private servers lately. How do they work? Most of them are based on the old Runescape, but a few look exactly like the real Runescape.</p>

<p>How do they make the servers? Has the source code of the game been leaked on several occasions, and is that used to make Runescape servers? Or have some people just replicated Runescape, and tried to make the same game themselves (and ""stolen"" the 3D objects and texture from Jagex to make it look the same, and written the code to be able to replicate most functions of Runescape)?</p>
","<p>Most Runescape Private Servers are coded in the Java language. For the most part, it's been a community effort. From the early days of Runescape classic, there was some leaked source, and from there it's been mostly the community reverse engineering updates as they come. Textures and images are found through URL-Manipulation, and some source code can be found to this day through such methods. Until late, a lot of the game could be analyzed through making a client, and then reading what gets sent to the client by the real Runescape server. Nowadays, you can get a lot of good source code for making your own, from <a href=""http://runelocus.com"">large Runescape Private Server communities.</a> You can get source ranging from a fully developed engine, all the way down to just a simple construct that needs to be fully scripted.</p>
","28856"
"OpenGL ES 2.0: Repository of Quality Shaders","17070","","<p>Could I kindly ask, to suggest me a repository of <strong>high quality OpenGL (OpenGL ES 2.0) vertex and fragment shaders</strong>, please?</p>

<p>I am looking for <strong>pixel based ligting shaders</strong> (such as <strong>phong</strong>) and simmilar. It would be nice to see more of them, to be able to choose between quality vs shader performance.</p>
","<p>Shaders of any complexity aren't generally the kind of thing you can download and drop in to your project like interchangeable cogs. Typically the more interesting effects require a fair bit of coupling to the CPU-side rendering subsystem in order to achieve their results. The same is generally true of performance -- performance tradeoffs with respect to accuracy and quality over instruction count or pipelining tend to be rooted in application-specific requirements.</p>

<p>As a result there really isn't much in the way of the kind of repositories you are thinking of. The GPU Gems books offer a good collection of cookbook-style descriptions of techniques with both game and shaded code examples that you may want to take a look at, though. So do the Shader X books.</p>
","12314"
"How common is automated testing in game development?","17069","","<p>Do gamers developers use to write unit and integration tests? How common is it among puzzle developers? And among developers of MMORPGs and FPSes?</p>

<p>(I have no background in game development neither am I cogitating about working with it - it is just a doubt that occurred to me. So, no need of trying to <em>convince</em> me to write them, even because I already like to write automated tests.)</p>
","<p>In general, unit and integration testing of games isn't that common. This is mostly because the rendering aspect of games is usually closely tied to the rest of the game mechanics that it can be very hard to actually write unit tests that work.</p>

<p>That said, unit testing can happen in game development, and if the code is set up for it, it can be of great benefit. However, it can be much more common to write automated tests for games, usually in the form of an AI program that can effectively play the game at a higher speed than a normal player. There's some excellent stories of developers doing just that in <a href=""https://gamedev.stackexchange.com/questions/574/automated-testing-of-games"">this question about automated testing</a>. This sort of automated testing is potentially better, since unit testing might not catch a bug in the rendering engine, but an automated test is more likely to expose such a problem.</p>

<p>In the end, though, this all depends on the studio. Some studios will some sort of automated testing, while others might just hire 20 high school kids over the summer to play their game for hours on end.</p>
","21400"
"What is the basic skill set that a Professional Game Programmer needs to have?","17039","","<p>I have a very general question which bothers me but i want to add some details first. I'm a core Java programmer. I have independently created some small games in Java for fun. Now, the more I'm looking into professional game development the more I'm getting confused. This is because, whenever I Google about some game development topics or visit any fora etc., I come across different suggestions.  </p>

<p>Some will say C++ is good, while some will say JAVA may be better, while still others will say some other language is the ur-language, like Python, Lua, UnrealScript, etc. Also it is suggested that one ought to have knowledge of game engines like Unreal, Torque, Blender, Panda, etc and knowledge of OpenGL, AI, Collision Detection is required. I have even created a game using Android SDK.</p>

<p>What I want to ask is:</p>

<ul>
<li>What is the basic skill set that a Professional Game Programmer needs to have? Is it any 1 Programming Language + 1 Scripting language + 1 Game engine knowledge + OpenGL? (Phew!!)  </li>
<li>If I want to enter into Game Industry as Gameplay Programmer or AI programmer then can I get into it with my current skills and portfolio (as stated above)?  </li>
<li>Is learning one programming language is enough for Game Development?  </li>
</ul>

<p>Any guideline will be helpful. </p>
","<ol>
<li><p>You should be proficient and competent with at least one programming language. Doing so will help you to pick up other languages more easily. The type of job you're applying to depends on what language you should probably know before hand. Most triple A titles released on PC and console will most likely be developed in C++. Mobile applications and games on the other hand will most likely be using Java (Google Android and other phones) or Objective-C (iPhone). If you take a look around at job listings for software engineers on developers websites, it usually will mention what language experience you need to have. For example, ""Proficient and knowledgeable in C++"" or ""Experience with C++ for at least two years."" Learning a scripting language won't hurt you. It'll only benefit you. Learning always benefits, and never hurts.You don't need to have a working knowledge of any game engine, but if you're applying to a company that uses that specific engine, it'll probably help you're resume. If you're an expert on the Source engine, but you apply to id software and know nothing about the id tech engines, that's not really super helpful (but beneficial cause learning is always beneficial).</p></li>
<li><p>If you've completed projects from start to finish, and you show that you have, then I think that would help boost you're resume. I'm not sure about a plethora of tech demos though. Lots of people seem to be doing tech demos and they don't have any or few game projects completed. Gameplay programmer tends to be a jr. level position, so yes, depending on your resume you should be able to find a job somewhere.</p></li>
<li><p>I think that knowing one language and being able to use it proficiently and competently is better than knowing 5 languages and barely knowing how to use them.</p></li>
</ol>

<p>Disclaimer: Never worked in industry, these are just my opinions that have been formed after reading several threads and articles about game programming jobs, based on what I thought were the most sensible articles/opinions I've read.</p>
","5554"
"How does one make games playable before they are fully downloaded?","16968","","<p><em>Diablo 3</em> and <em>StarCraft 2</em> have a nice feature: I can start playing before the full game or update has finished downloading.</p>

<p>I guess <em>Diablo 3</em> downloads mandatory files like like UI assets and some meshes and textures that are used across several levels first. However, when starting a game, I can choose any level I want, assuming I have appropriate saves. I never experienced any lag from such when playing—starting is always very smooth.</p>

<p>How does this work? How could I implement a similar feature?</p>
","<p>Assets such as sound, video, models, and textures are a majority of the download and for each of these assets there are multiple versions. These multiple versions are to support various graphic options. </p>

<p>By sending the assets needed for a low graphics option first (which also happen to be the smallest ones). You have everything you need to play the game despite having only 15% or so of the total assets needed to support every graphics option. </p>

<p>You can test this by re-installing StarCraft 2. Play it as soon as it will let you then go to the graphical options screen. Many options and setting will be unavailable. </p>
","86205"
"Procedural... house with rooms generator","16956","","<p>I've been looking at <a href=""http://pcg.wikidot.com/"" rel=""noreferrer"">some algorithms and articles</a> about procedurally generating a dungeon. The problem is, I'm trying to generate a house with rooms, and they don't seem to fit my requirements.</p>

<p>For one, dungeons have corridors, where houses have halls. And while initially they might seem the same, a hall is nothing more than the area that isn't a room, whereas a corridor is specifically designed to connect one area to another.</p>

<p>Another important difference with a house is that you have a specific width and height, and you have to fill the entire thing with rooms and halls, whereas with a dungeon, there is empty space.</p>

<p>I think halls in a house is something in between a dungeon corridor (gets you to other rooms) and an empty space in the dungeon (it's not explicitly defined in code).</p>

<p>More specifically, the requirements are:</p>

<ul>
<li><strong>There is a set of predefined rooms</strong><br>
I cannot create walls and doors on the fly.</li>
<li><strong>Rooms can be rotated but not resized</strong><br>
Again, because I have a predefined set of rooms, I can only rotate them, not resize them.</li>
<li><strong>The house dimensions are set and has to be entirely filled with rooms (or halls)</strong><br>
I.e. I want to fill a 14x20 house with the available rooms making sure there is no empty space.</li>
</ul>

<p>Here are some images to make this a little more clear:</p>

<p><img src=""https://i.stack.imgur.com/ZJ2Bg.png"" alt=""Typical dungeon generator"">
<img src=""https://i.stack.imgur.com/8IygF.png"" alt=""Dungeon with no corridors"">
<img src=""https://i.stack.imgur.com/KOoTd.png"" alt=""House generator result""></p>

<p>As you can see, in the house, the ""empty space"" is still walkable and it gets you from one room to another. </p>

<p>So, having said all this, maybe a house is just a really really tightly packed dungeon with corridors. Or it's something easier than a dungeon. Maybe there is something out there and I haven't found it because I don't really know what to search for. </p>

<p>This is where I'd like your help: <strong>could you give me pointers on how to design this algorithm?</strong> Any thoughts on what steps it will take? If you have created a dungeon generator, how would you modify it to fit my requirements? You can be as specific or as generic as you like. I'm looking to pick your brains, really.  </p>
","<p>So, here is how I solved this problem. But first, I'd like to thank both @Shadows In Rain and @egarcia for their answers. They gave me a good direction which helped me get some results. </p>

<p>I used Shadows In Rain's space partitioning to generate a basic house and then followed egarcia's advice to fill in the area with rooms.</p>

<p>The space partitioning was pretty straightforward since 90% of the code was done by Shadows. The ""fill in the rooms"" part was a little more challenging. I decided to use a pseudo AI Planning system that uses A* to position the rooms appropriately. The good thing about using planning instead of just A* is that the preconditions help cut down the search space significantly.</p>

<p>Here are some screenshots with the results:</p>

<p><a href=""https://i.stack.imgur.com/X2uWA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/X2uWA.png"" alt=""Floor plan generation phase""></a>
Floor plan generation phase</p>

<p><a href=""https://i.stack.imgur.com/2iYvr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2iYvr.png"" alt=""Room placement phase""></a>
Room placement phase</p>

<p><a href=""https://i.imgur.com/PrKgZQR.jpg"" rel=""nofollow noreferrer""><img src=""https://i.imgur.com/PrKgZQR.jpg"" alt=""Now with connecting doors!""></a><br>
Now with connecting doors!</p>
","58164"
"How can I get multiple sprites on a Unity2D Sprite Renderer","16828","","<p>I have a GameObject that I want to have multiple sprites.  I tried adding an extra Sprite Renderer, but it tells me I can't add the same component multiple times.  </p>

<p>I'd really rather not have to have four GameObjects just to display this thing correctly. </p>

<p>For example, I would want to have a tile background, a tile artwork, a tile character, and a nice shine on the top.  If I were to make that all a single image, I would have to export nearly a thousand images to get all possible combinations.</p>

<p>Tile Background: <img src=""https://i.stack.imgur.com/e3Bxm.png"" alt=""Tile Background""></p>

<p>Tile Artwork: <img src=""https://i.stack.imgur.com/eyii6.png"" alt=""Tile Artwork""></p>

<p>Tile Character:<img src=""https://i.stack.imgur.com/7q6XJ.png"" alt=""Tile Character""></p>

<p>Shine (Barely visible): <img src=""https://i.stack.imgur.com/S3NCD.png"" alt=""Tile Shine""></p>

<p>Everything put together how I want it in-game: <img src=""https://i.stack.imgur.com/M2U8I.png"" alt=""Final Image""></p>
","<p>Yes, you'll need to have a single game object for each sprite, but you'll only have as many game objects as you have layers. </p>

<p>So you'd create a game object with the following children (and save it as a prefab):
<img src=""https://i.stack.imgur.com/dH49V.png"" alt=""Icon game object""></p>

<p>You can then have a script that changes the sprite for each layer:</p>

<pre><code>public class Icon : MonoBehaviour
{
    public SpriteRenderer artwork;

    public void SetArtworkSprite(Sprite art)
    {
        artwork.sprite = art;
    }
}
</code></pre>

<p>The Icon script would be in the Icon game object and would have all its fields linked with the child game objects. So then you can have an icon generator script as so:</p>

<pre><code>public IconGenerator : MonoBehaviour
{
    public Icon iconPrefab;

    public void CreateIcon(...)
    {
          Icon newIcon = Instantiate(iconPrefab) as Icon;
          newIcon.SetArtworkSprite(...);
          newIcon.SetBackgroundSprite(...); 
          [...]
    }
}
</code></pre>

<p>If you REALLY need everything to be a single game object, than I believe you can achieve this by creating a shader that takes X textures and renders them. But I'm not sure if it's worth it.</p>
","72561"
"How do game bots perceive the game world & other entities?","16811","","<p>This question has been on my mind for a while...mainly because I see bots for all sorts of games like WoW and others. My question is; how do the bots know what is appearing on the screen? I don't play WoW so my example may be wrong but if for example there is a monster, how does the bot know where that monster is on the screen and how does it know how to interact with it?</p>

<p>Can you apply this to any game or is it specific for each game? I'm sorry if the question isn't clear...and I'm not asking how to make a bot, more asking how they detect things on the screen as its quite fascinating to me!</p>

<p>Thanks in advance :)</p>
","<p>There are many points where a bot can inject itself into the game. </p>

<ul>
<li><p>The screen is one of them, but by far not the most useful. However, I have once seen a very early aimbot for Counter Strike which used color coding. It came with alternative character models with single-colored textures (the game was modding-friendly enough to allow this) and then just detected pixels of those colors. Not a very effective method, though. It was already quite clunky back then, and becomes less and less viable because graphic engines become more and more powerful, which means more and more detail to confuse any optical recognition algorithms.</p></li>
<li><p>Another point is reading the memory directly<sup>[1]</sup>. It is possible to have one program on your computer read the memory of another. So the developer just needs to find out at which memory address the game is saving the information which is relevant to the bot. There are tools which assist the developer with finding what they want by creating a memory image and providing various search tools. A countermeasure is to use address layout randomization, but a smart bot might be able to still find what they are looking for automatically.</p></li>
<li><p>It is possible to modify the game executable itself. In order to do this the bot developers need to be able to read and program in assembler, which isn't that hard with some practice. They then look for the code which handles the information they are interested in and rewrite it to pass it to their bot. A possible countermeasure from the perspective of the game developer is to use an obfuscator to make the game's assembler code less readable, but these are usually not good for performance and there are tools for many obfuscators which reverse their work.</p></li>
<li><p>And then there is the netcode. In an online game, the server sends the properties and positions of all objects in the game via network. The network data stream between server and client can be intercepted and analyzed. A popular tool for doing this is <a href=""https://www.wireshark.org/"">wireshark</a>. When the developer reverse-engineered the netcode, they can write a bot which intercepts the network traffic just like Wireshark does and uses the information to make its decision. When the developer is more motivated, they can even develop a complete game client from scratch which implements the network protocol and plays the game without even having any graphical output. Such bots are very popular with gold farmers because without the graphics output the client is usually far more resource-friendly, which means they can run a lot of them at once on a small server.</p></li>
</ul>

<hr>

<p><sup>1:</sup> Since you mention WoW, it's worth pointing out that the early and notorious WoWGlider botting program used direct memory access. Blizzard had a subprogram called Warden that was designed to detect and block outside programs from accessing WoW's internal game state. Since the bot program circumvented this protection and read the memory without permission, the <a href=""https://en.wikipedia.org/wiki/MDY_Industries,_LLC_v._Blizzard_Entertainment,_Inc."">2006 lawsuit MDY v Blizzard</a> was decided in favor of Blizzard on the grounds that <a href=""http://arstechnica.com/gaming/2009/01/judges-ruling-that-wow-bot-violates-dmca-is-troubling/"">the bot maker was encouraging and enabling its users</a> to commit copyright infringement and violate the <a href=""https://en.wikipedia.org/wiki/Digital_Millennium_Copyright_Act"">DMCA</a>.</p>
","102853"
"Is C# different in Unity?","16684","","<p>Does Unity use a different version of C#, or is it all the same? It looks different from regular C# but there are some regular C# elements in there.</p>
","<p>As stated in other answers Unity 4.x uses a <strong>modified</strong> version of Mono based on <a href=""http://unity3d.com/unity/faq#"">Mono 2.6</a></p>

<p>For the most part, this is <a href=""http://docs.unity3d.com/412/Documentation/ScriptReference/MonoCompatibility.html"">compatible with the .Net 2.0</a>, though I haven't managed to track down a Mono 2.6 specific compatibility list.</p>

<blockquote>
  <p>It looks different from regular C# but there are some regular C#
  elements in there.</p>
</blockquote>

<p>As mentioned in one of the comments on your question, this is likely due to Unity's particular scripting API rather than the language itself.</p>

<p>As an example, a lot of code in a typical Unity projects is contained in subclasses of a class called MonoBehavior. These are components that are dropped on GameObjects within the Unity Editor environment. This architecture leads to C# code that looks different to typical C# code (to me anyway) in a number of ways:</p>

<ul>
<li>Until Unity 4 was released, these objects could not be contained in namespaces, so they're always in the global namespace</li>
<li>They expose fields to the editor environment by making them public (or by using the SerializeField attribute, but I find very few people use this), which leads to an unusually large number of public fields on classes</li>
<li>Unity's privacy and case conventions don't follow Microsoft's, so this can also look strange to a ""traditional"" C# developer</li>
<li>They make use of a number of special methods on these components, such as Start and Update, that are not overrides as one would typically expect, but are accessed by means of reflection instead.</li>
</ul>

<p>Practically speaking, the biggest C# language feature I miss in Unity's current C# version is support for <a href=""http://msdn.microsoft.com/en-us/library/hh156513.aspx"">async</a> and related keywords and functionality. A similar concept in Unity is <a href=""http://docs.unity3d.com/Manual/Coroutines.html"">coroutines</a>. These execute on the main thread so aren't true async, but do allow long running code to be broken up over multiple frames. Lower level multithreading is still supported.</p>
","80471"
"How to move rigidbodies","16666","","<p>Have i understood this correct: If i want to use a rigidbody for physics then </p>

<ol>
<li>i should not move an object through its transform.position. </li>
<li>I should never move it by riigidbody.velocity since i then affect the physics. </li>
<li>So what is left is moving it using addForce. I guess its like mimicking how in the real world everything that moves has something that drives it. </li>
</ol>
","<p>You seem to be answering your own question in your ""question"", and it seems to me like you are asking for clarification. Please note that my answer is Unity specific. </p>

<h2>Why use Rigidbodies?</h2>

<p>When you use a rigidbody, then you should <em>use</em> a rigidbody. Allow me to explain what I mean. Often times, when I see developers using rigidbodies; they are neglecting its use. They are:</p>

<ol>
<li>Directly modifying the transforms position and attempting to <em>use</em> the rigidbody correctly</li>
<li>Using it for collision response only and doing No.1</li>
<li>Have an incorrect understanding of transforms and rigidbodies. </li>
</ol>

<p><strong>Golden Rule</strong>: Use a rigidbody when you want all aspects of your entity to act under the laws of physics (gravity,forces,torque, etc.)</p>

<h2>Moving your body</h2>

<p>Keeping the golden rule in mind(see above) and the three no-no's, we can talk about how to move your rigid-body. In Unity, you have <code>AddForce()</code> and you have <code>AddTorque()</code>. </p>

<p>Pretty straightforward. The AddForce function, of course, adds a force to your rigidbody. AddTorque adds torque, which is a twisting force, causing your object to spin around a specified axis. </p>

<p>You might ask the question, ""Well, why can't I directly modify the position when using a rigidbody?"" in regards to movement, per say.</p>

<p>You can, but you'd essentially be emulating the behavior of a transform, that of which is not able to be acted on by force or torque. Transforms, hence the name, can be ""translated"", but it's not the same as moving it with physics. Rigid-bodies, however, are able to be acted on by force and torque for movement related purposes. Please note that directly modifying the rigidbody's position is acceptable for certain cases.</p>

<p><a href=""http://docs.unity3d.com/Documentation/Components/class-Rigidbody.html"">Le Documentation</a></p>
","69586"
"Entity/Component Systems in C++, How do I discover types and construct components?","16660","","<p>I'm working on an entity component system in C++ that I hope to follow the style of Artemis (http://piemaster.net/2011/07/entity-component-artemis/) in that components are mostly data bags and it's the Systems that contain the logic. I'm hoping to take advantage of the data-centric-ness of this approach and build some nice content tools.</p>

<p>However, one hump I'm coming across is how to take some identifier string or GUID from a data file and use that to construct component for an Entity. Obviously I could just have one big parse function:</p>

<pre><code>Component* ParseComponentType(const std::string &amp;typeName)
{
    if (typeName == ""RenderComponent"") {
        return new RenderComponent();
    }

    else if (typeName == ""TransformComponent"") {
        return new TransformComponent();
    }

    else {
        return NULL:
    }
}
</code></pre>

<p>But that's really ugly. I intend to be adding and modifying components frequently, and hopefully building some sort of ScriptedComponentComponent, such that you could implement a component and system in Lua for the purposes of prototyping. I'd like to be able to write a class inheriting from some <code>BaseComponent</code> class, maybe toss in a couple of macros to make everything work, and then have the class available for instantiation at runtime.</p>

<p>In C# and Java this would be pretty straightforward, since you get nice reflection APIs to look up classes and constructors. But, I'm doing this in C++ because I want to increase my proficiency in that language.</p>

<p>So How is this accomplished in C++? I've read about enabling RTTI, but it seems most people are wary about that, especially in a situation where I only need it for a subset of object types. If a custom RTTI system is what I need there, where can I go to start learning to write one?</p>
","<p><em>A comment:</em><br>
The Artemis implementation is interesting. I came up with a similar solution, except I called my components ""Attributes"" and ""Behaviors"". This approach of separating types of components has worked very nicely for me.</p>

<p><em>Regarding the solution:</em><br>
The code is easy to use, but the implementation might be hard to follow if you're not experienced with C++. So...</p>

<h1>The desired interface</h1>

<p>What I did is to have a central repository of all components. Each component type is mapped to a certain string (which represents the component name). This is how you use the system:</p>

<pre><code>// Every time you write a new component class you have to register it.
// For that you use the `COMPONENT_REGISTER` macro.
class RenderingComponent : public Component
{
    // Bla, bla
};
COMPONENT_REGISTER(RenderingComponent, ""RenderingComponent"")

int main()
{
    // To then create an instance of a registered component all you have
    // to do is call the `create` function like so...
    Component* comp = component::create(""RenderingComponent"");

    // I found that if you have a special `create` function that returns a
    // pointer, it's best to have a corresponding `destroy` function
    // instead of using `delete` directly.
    component::destroy(comp);
}
</code></pre>

<h1>The implementation</h1>

<p>The implementation is not that bad, but it's still pretty complex; it requires some knowledge of templates and function pointers.</p>

<p><strong>Note:</strong> Joe Wreschnig has made some good points in the comments, mainly on how my <a href=""https://gamedev.stackexchange.com/revisions/17759/18"">previous implementation</a> made too many assumptions about how good the compiler is at optimizing code; the issue was not detrimental, imo, but it did bug me as well. I also noticed that the former <code>COMPONENT_REGISTER</code> macro did not work with templates.</p>

<p>I've changed the code and now all of those problems should be fixed. The macro works with templates and the issues that Joe raised have been addressed: now it's much easier for compilers to optimize away unnecessary code.</p>

<p><strong><em>component/component.h</em></strong></p>

<pre><code>#ifndef COMPONENT_COMPONENT_H
#define COMPONENT_COMPONENT_H

// Standard libraries
#include &lt;string&gt;

// Custom libraries
#include ""detail.h""


class Component
{
    // ...
};


namespace component
{
    Component* create(const std::string&amp; name);
    void destroy(const Component* comp);
}

#define COMPONENT_REGISTER(TYPE, NAME)                                        \
    namespace component {                                                     \
    namespace detail {                                                        \
    namespace                                                                 \
    {                                                                         \
        template&lt;class T&gt;                                                     \
        class ComponentRegistration;                                          \
                                                                              \
        template&lt;&gt;                                                            \
        class ComponentRegistration&lt;TYPE&gt;                                     \
        {                                                                     \
            static const ::component::detail::RegistryEntry&lt;TYPE&gt;&amp; reg;       \
        };                                                                    \
                                                                              \
        const ::component::detail::RegistryEntry&lt;TYPE&gt;&amp;                       \
            ComponentRegistration&lt;TYPE&gt;::reg =                                \
                ::component::detail::RegistryEntry&lt;TYPE&gt;::Instance(NAME);     \
    }}}


#endif // COMPONENT_COMPONENT_H
</code></pre>

<p><strong><em>component/detail.h</em></strong></p>

<pre><code>#ifndef COMPONENT_DETAIL_H
#define COMPONENT_DETAIL_H

// Standard libraries
#include &lt;map&gt;
#include &lt;string&gt;
#include &lt;utility&gt;

class Component;

namespace component
{
    namespace detail
    {
        typedef Component* (*CreateComponentFunc)();
        typedef std::map&lt;std::string, CreateComponentFunc&gt; ComponentRegistry;

        inline ComponentRegistry&amp; getComponentRegistry()
        {
            static ComponentRegistry reg;
            return reg;
        }

        template&lt;class T&gt;
        Component* createComponent() {
            return new T;
        }

        template&lt;class T&gt;
        struct RegistryEntry
        {
          public:
            static RegistryEntry&lt;T&gt;&amp; Instance(const std::string&amp; name)
            {
                // Because I use a singleton here, even though `COMPONENT_REGISTER`
                // is expanded in multiple translation units, the constructor
                // will only be executed once. Only this cheap `Instance` function
                // (which most likely gets inlined) is executed multiple times.

                static RegistryEntry&lt;T&gt; inst(name);
                return inst;
            }

          private:
            RegistryEntry(const std::string&amp; name)
            {
                ComponentRegistry&amp; reg = getComponentRegistry();
                CreateComponentFunc func = createComponent&lt;T&gt;;

                std::pair&lt;ComponentRegistry::iterator, bool&gt; ret =
                    reg.insert(ComponentRegistry::value_type(name, func));

                if (ret.second == false) {
                    // This means there already is a component registered to
                    // this name. You should handle this error as you see fit.
                }
            }

            RegistryEntry(const RegistryEntry&lt;T&gt;&amp;) = delete; // C++11 feature
            RegistryEntry&amp; operator=(const RegistryEntry&lt;T&gt;&amp;) = delete;
        };

    } // namespace detail

} // namespace component

#endif // COMPONENT_DETAIL_H
</code></pre>

<p><strong><em>component/component.cpp</em></strong></p>

<pre><code>// Matching header
#include ""component.h""

// Standard libraries
#include &lt;string&gt;

// Custom libraries
#include ""detail.h""


Component* component::create(const std::string&amp; name)
{
    detail::ComponentRegistry&amp; reg = detail::getComponentRegistry();
    detail::ComponentRegistry::iterator it = reg.find(name);

    if (it == reg.end()) {
        // This happens when there is no component registered to this
        // name. Here I return a null pointer, but you can handle this
        // error differently if it suits you better.
        return nullptr;
    }

    detail::CreateComponentFunc func = it-&gt;second;
    return func();
}

void component::destroy(const Component* comp)
{
    delete comp;
}
</code></pre>

<h1>Extending with Lua</h1>

<p>I should note that with a bit of work (it's not very hard), this can be used to seamlessly work with components defined in either C++ or Lua, without ever having to think about it.</p>
","17759"
"Checkers AI Algorithm","16656","","<p>I am making an AI for my checkers game and I'm trying to make it as hard as possible. Here is the current criteria for a move on the hardest difficulty:</p>

<p>1: Look For A Block: This is when a piece is being threatened and another piece can be moved in behind it to protect it. Here is an example:</p>

<p>Black Moves
<br>
<code>|W| |W| |W| |W| |</code><br>
<code>| |W| |W| |W| |W|</code><br>
<code>|W| | | |W| |W| |</code><br>
<code>| | | |W| | | | |</code><br> 
<code>| | | | |B| | | |</code><br>
<code>| |B| | | |B| |B|</code><br>
<code>|B| |B| |B| |B| |</code><br>
<code>| |B| |B| |B| |B|</code><br></p>

<p>White Blocks
<br>
<code>|W| |W| |W| |W| |</code><br>
<code>| |W| | | |W| |W|</code><br>
<code>|W| |W| |W| |W| |</code><br>
<code>| | | |W| | | | |</code><br> 
<code>| | | | |B| | | |</code><br>
<code>| |B| | | |B| |B|</code><br>
<code>|B| |B| |B| |B| |</code><br>
<code>| |B| |B| |B| |B|</code><br></p>

<p>2: Move pieces out of danger: if any piece is being threatened, and a piece cannot block for that piece, then it will attempt to move out of the way. If the piece cannot move out of the way without still being in danger, the computer ignores the piece.</p>

<p>3: If the computer player owns any kings, it will attempt to 'hunt down' enemy pieces on the board, if no moves can be made that won't in danger the king or any other pieces, the computer ignores this rule.</p>

<p>4: Any piece that is owned by the computer that is in column 1 or 6 will attempt to go to a side. When a piece is in column 0 or 7, it is in a very strategic position because it cannot get captured while it is in either of these columns</p>

<p>5: It makes an educated random move, the move will not indanger the piece that is moving or any piece that is on the board.</p>

<p>6: If none of the above are possible it makes a random move.</p>

<hr>

<p>This question is not really specific to any language but if all examples could be in Java that would be great, considering this app is written in android. Does anyone see any room for improvement in this algorithm? Anything that would make it better at playing checkers? </p>
","<p>If you're trying to make a good AI for your checkers program, then the first place to look is what's known as <em>Alpha-Beta</em> game tree search.  The short version is that any AI that only takes into account static features of the current position is bound to run into trouble, especially in the early-to-mid game, because it simply can't understand what's presently happening in the game and what the threats are.  Instead, what you want to do is to write an algorithm that searches all possible moves-and-replies for some number of moves ahead (5 to 10 would be typical), evaluates the position at the end of each branch of this move-and-reply tree (in terms of 'how many pieces ahead or behind am I?), and then makes the move that gives it the best chance - in other words, the move that <em>maximizes</em> its possible value, where the possible value is calculated as the <em>minimum</em> possible value across all of your opponent's replies (assuming, in other words, that they'll make the move that's best for them), etc. - this is why this algorithm is often called the <em>Minimax</em> algorithm.</p>

<p>What you'll find is that many of the elements you're talking about - moving pieces to the side, moving pieces out of danger, etc. - will become elements of the <em>positional evaluation function</em> of the game tree search.  Essentially, instead of asking the simple question 'how many pieces ahead is one side or the other?', you'll say 'what is the value of this position?' and then give point values to various features of the board (e.g., whether a piece is on the side, whether it's vulnerable, etc.) in terms of partial pieces - for instance, you might decide that the difference between an edge and a center piece is worth possibly .1 piece, so in a position where you're a man behind but have an extra edge piece the overall value to you will be -0.9.</p>

<p>One critical advanced notion for checkers AI specifically is the concept of <em>Quiescence search</em>: imagine that you go down six moves into your tree, and at the tail end your opponent has just made a capture where your (forced) reply is an immediate recapture.  Unfortunately, the positional evaluation function can't see the recapture, so it evaluates the position as being a piece up for your opponent even though you're about to regain parity.  Quiescence search is an attempt to solve this problem by forcing the evaluator to go down into a branch until all possible forced captures have been made, and only then evaluate the position.</p>

<p>This may all sound fairly complicated, but I think you'll find it's more straightforward than it looks - once you write your evaluator function, the tree search is relatively easy; there are a lot of smart concepts (things like <em>transposition tables</em>) that you can apply to it, but it should be easy to get something working and then continue to improve it.  For more details, I suggest searching on pretty much any of the key terms (alpha-beta search, minimax, quiescence search, game tree, etc); there's plenty of good information on all of these concepts out on the web.</p>
","30033"
"What is the cost of distributing through steam?","16640","","<p>We are in Pre-alpha stage of a game development project and haven´t yet got reply from Valve about how it works to distribute through Steam. We need this information to do a business model with all the different costs of developing and distributing this game.</p>

<p>So my question is, what is the pricing structure? Do they take a per cent of our sale? If so, how much?</p>

<p>Thanks Felix </p>
","<p>I have not worked with Valve or released a game on Steam, but I attended a talk given by some guys that just released their first indie game on Steam.</p>

<p>I doubt you'll hear much from them if you're in pre-alpha. He said that when they first contacted Valve, they were told not to send screenshots or demos or anything due to legal reasons. They didn't get much attention from Valve until they ignored that and started emailing screenshots and demos anyway (they were near the end of beta). Valve liked what they saw and hooked them up.</p>

<p>From what they said, Valve is very friendly towards indie developers. They said selling on Steam has been a great experience and they made back all their development costs within a month of their game being on sale.</p>

<p>However, he said that they get tons of spam to that email address from people who just have game ideas and not an actual game, so if you are in pre-alpha my guess is you'll get the cold shoulder. They have to filter people out somehow. But go back when you've got a solid beta or a demo and they'll probably welcome you with open arms.</p>
","595"
"Whole map design vs. tiles array design","16619","","<p>I am working on a 2D RPG, which will feature the usual dungeon/town maps (pre-generated).</p>

<p>I am using tiles, that I will then combine to make the maps. My original plan was to assemble the tiles using Photoshop, or some other graphic program, in order to have one bigger picture that I could then use as a map.</p>

<p>However, I have read on several places people talking about how they used arrays to build their map <em>in the engine</em> (so you give an array of x tiles to your engine, and it assemble them as a map). I can understand how it's done, but it seems a lot more complicated to implement, and I can't see obvious avantages.</p>

<p>What is the most common method, and what are advantages/disadvantages of each?</p>
","<p>First off, let me say that 2D RPGs are near and dear to my heart and working with old DX7 VB6 MORPG engines (don't laugh, it was 8 years ago, now :-) ) is what first got me interested in game development. More recently, I started converting a game I worked on in one of those engines to use XNA.</p>

<p>That said, my recommendation is that you use a tile-based structure with layering for your map. With any graphics API you use, you're going to have a limit on the size of textures you can load. Not to mention the graphics card texture memory limits. So, considering this, if you want to maximize the size of  your maps while not only minimizing the amount and size of textures you load into memory but also decreasing the size of your assets on the user's hard drive AND the load times, you're definitely going to want to go with tiles.</p>

<p>As far as implementation goes, I've gone into detail on how I handled it on a few questions here on GameDev.SE and on my blog (both linked below), and that's not exactly what you're asking so I'll just go into the basics here. I'll also make note of the features of tiles that make them beneficial over loading several large pre-rendered images. If anything is not clear, let me know.</p>

<ol>
<li>The first thing you need to do is create a tilesheet. This is just a big image that contains all your tiles aligned in a grid. This (and maybe an extra one depending on the number of tiles) will be the only thing you need to load. Just 1 image! You could load 1 per map or one with every tile in the game; whatever organization works for you.</li>
<li>Next, you need to understand how you can take that ""sheet"" and translate each tile into a number. This is pretty straightforward with some simple math. Note that the division here is <em>integer division</em>, so the decimal places are dropped (or rounded down, if you prefer).
<img src=""https://i.stack.imgur.com/7hoDz.png"" alt=""How to convert cells to coordinates and back.""></li>
<li><p>OK, now that you've broken the tilesheet into a series of cells (numbers), you can take those numbers and plug them into whatever container you like. For the sake of simplicity, you can just use a 2D array.</p>

<pre><code>int[,] mapTiles = new int[100,100]; //Map is 100x100 tiles without much overhead
</code></pre></li>
<li><p>Next, you want to draw them. One of the ways you can make this a LOT more efficient (depending on map size) is to calculate only the cells that the camera is currently viewing and loop through those. You can do this by fetching the map tile array coordinates of the camera's top-left (<code>tl</code>) and bottom-right (<code>br</code>) corners. Then loop from <code>tl.X to br.X</code> and, in a nested loop, from <code>tl.Y to br.Y</code> to draw them. Example code below:</p>

<pre><code>for (int x = tl.X; x &lt;= br.X;x++) {
    for (int y = tl.Y; y &lt;= br.Y;y++) {
        //Assuming tileset setup from image
        Vector2 tilesetCoordinate = new Vector2((mapTiles[x,y] % 8) * 32,(mapTiles[x,y] / 8) * 32);
        //Draw 32x32 tile using tilesetCoordinate as the source x,y
    }
}
</code></pre></li>
<li>Jackpot! That's the basics of the tile engine. You can see that it's easy to have even a 1000x1000 map with not much overhead. Also, if you have less than 255 tiles, you could use a byte array cutting down the memory by 3 bytes per cell. If a byte is too small, a ushort would probably suffice for your needs.</li>
</ol>

<p>Note: I left out the concept of world coordinates (which is what your camera's position will be based on) since that, I think, is outside the scope of this answer. You can read up on that here on GameDev.SE.</p>

<p><strong>My Tile-Engine Resources</strong><br>
Note: All of these are targeted at XNA, but it pretty much applies to anything &ndash; you just need to change the draw calls.</p>

<ul>
<li>My answer to <a href=""https://gamedev.stackexchange.com/questions/17623/rendering-tiles-on-3-4-perspective/17657#17657"">this</a> question outlines how I handle the map cells and layering in my game. (See third link.)</li>
<li>My answer to <a href=""https://gamedev.stackexchange.com/questions/19657/what-is-a-good-way-to-store-tilemap-data/19660#19660"">this</a> question explains how I store the data in a binary format.</li>
<li><a href=""http://www.systemroot.ca/2011/09/fondusis-dev-blog-week-1/"" rel=""nofollow noreferrer"">This</a> is the first (well, technically second, but first ""technical"") blog post about the development of the game I was working on. The whole series contains information about things like pixel shaders, lighting, tile behaviours, movement and all that fun stuff. I actually updated the post to include the content of the my answer to the first link I posted above, so you may want to read it instead (I may have added things). If you have any questions, you can drop a comment there or here and I'd be happy to help.</li>
</ul>

<p><strong>Other Tile-Engine Resources</strong></p>

<ul>
<li>The tile engine tutorial from <a href=""http://www.xnaresources.com/default.asp?page=TUTORIALS"" rel=""nofollow noreferrer"">this</a> site gave me the basis I used for creating my maps.</li>
<li>I haven't actually watched <a href=""http://www.youtube.com/view_play_list?p=0A865073DA96A7DA"" rel=""nofollow noreferrer"">these</a> video tutorials yet because I haven't had the time, but they're probably helpful. :) They may be outdated though, if you're using XNA.</li>
<li><a href=""http://xnaexperience.wordpress.com/tile-engine-tutorials/"" rel=""nofollow noreferrer"">This</a> site has some more tutorials that (I think) are based on the above videos. It may be worth checking out.</li>
</ul>
","26373"
"Unity - Basic AI Enemy Follows Player - Prevent Flocking Of Enemies Together","16616","","<p>I'm in the process of implementing a 2D top-down shooter game. I have a basic AI script that allows enemies to follow the player around. Currently it works fine for one enemy, but as soon as there are multiple enemies, overtime they tend to flock together. How would I go about fixing this issue? I think that one possible solution would be to make the enemies move in a random direction every few frames, but I'm not sure on this.</p>

<p>Below is my C# Script that I am currently using.</p>

<pre><code>using UnityEngine;
using System.Collections;

public class AIScript : MonoBehaviour 
{
    public Transform target;
    public int moveSpeed;
    public int rotationSpeed;

    void Start() 
    {
        target = GameObject.Find(""Michael"").transform;
    }

    void Update() 
    {    
        if (target != null) 
        {
            Vector3 dir = target.position - transform.position;
            // Only needed if objects don't share 'z' value.
            dir.z = 0.0f;
            if (dir != Vector3.zero) 
                transform.rotation = Quaternion.Slerp ( transform.rotation, 
                    Quaternion.FromToRotation (Vector3.right, dir), 
                    rotationSpeed * Time.deltaTime);

            //Move Towards Target
            transform.position += (target.position - transform.position).normalized 
                * moveSpeed * Time.deltaTime;
        }
        rigidbody2D.velocity = Vector3.zero;
    }
}
</code></pre>
","<p>One simple way of doing it could be to make a few alternate versions of the script and have different AI profiles for the enemies (just give them a random one when created).
This way you could have one type that goes straight ahead like you have now, but also others that try to get the player by curving right or left. Maybe even one that makes some random moves if that works in your game.</p>

<p>I don't think this is a perfect solution, but at least it would break up the enemies in smaller flocks without too much effort on your part.</p>
","97271"
"Unity 5 missing Standard Assets","16585","","<p>I have Unity 5 and when I make a new project, there are no assets that are usually there (Character Controller, Terrain, etc.). How do I fix that?</p>
","<p>Go to <a href=""http://unity3d.com/get-unity/download?ref=personal"" rel=""nofollow"">http://unity3d.com/get-unity/download?ref=personal</a> click on ""ADDITIONAL DOWNLOADS
FOR WINDOWS"" and select ""<a href=""http://netstorage.unity3d.com/unity/5b98b70ebeb9/WindowsStandardAssetsInstaller/UnityStandardAssetsSetup.exe"" rel=""nofollow"">Standard Assets</a>"".</p>
","96592"
"Is it a waste to learn OpenGL?","16571","","<p>What I've gathered around the internet and various sources is that DirectX has pretty much taken a stronghold grip onto the graphics API domain. And to be honest, I gave learning DirectX10 a chance, but I just cannot stand how things are initialized; it made it very difficult to really learn the actual 3D portion.</p>

<p>OpenGL on the other hand makes much more sense from a ""coding"" perspective to me, but I'm not sure if I want to invest time into something that ""isn't going to last"". I don't keep up with the latest news, nor know much about the ""war"" that goes on between OpenGL and DirectX. With that being said, <strong>is OpenGL going away anytime soon?</strong> The thing I like about OpenGL is that there are many more resources available (whether through books/tutorials/samples) than for DirectX, so it's a lot easier to learn.</p>

<p>So is it still a good time to learn OpenGL, or is DirectX just the future? Now I know there are 100,000 topics talking about which is better but that's not what I'm asking. I'm just asking if OpenGL is gonna stick around.</p>
","<blockquote>
  <p>Now I know there are 100000 topics
  talking about which is better but
  thats not what I'm asking, I'm just
  asking if OpenGL is gonna stick
  around.</p>
</blockquote>

<p><strong>Yes.</strong></p>

<p>Technology never just vanishes -- once it has reached some critical mass, it's there to stay for a long time even if it never gets actively developed much any longer. It will be a very long time before the statement ""it is a waste of time to learn OpenGL"" is true.</p>

<p>Although I find your motivation and reasoning somewhat suspect, there's nothing wrong with learning OpenGL and it will allow you to learn exactly as much about 3D graphics theory and programming as D3D would. Really, in fact, it might be worthwhile to use it as a learning medium even if it were useless as a practical platform because the fundamental concepts transfer between APIs, so as long as it helps you acquire those concepts it's a good choice.</p>
","12134"
"Creating a retro-style palette swapping effect in OpenGL","16567","","<p>I'm working on a <a href=""http://en.wikipedia.org/wiki/Mega_Man"" rel=""nofollow noreferrer"">Megaman</a>-like game where I need to change the color of certain pixels at runtime. <strong><em>For reference</strong>: in <a href=""http://en.wikipedia.org/wiki/Mega_Man"" rel=""nofollow noreferrer"">Megaman</a> when you change your selected weapon then main character's palette changes to reflect the selected weapon. Not all of the sprite's colors change, only certain ones do</em>.</p>

<p>This kind of effect was common and quite easy to do on the NES since the programmer had access to the palette and the logical mapping between pixels and palette indices. On modern hardware, though, this is a bit more challenging because the concept of palettes is not the same.</p>

<p>All of my textures are 32-bit and do not use palettes.</p>

<p>There are two ways I know of to achieve the effect I want, but I'm curious if there are better ways to achieve this effect easily. The two options I know of are:</p>

<ol>
<li>Use a shader and write some GLSL to perform the ""palette swapping"" behavior.</li>
<li>If shaders are not available (say, because the graphics card doesn't support them) then it is possible to clone the ""original"" textures and generate different versions with the color changes pre-applied.</li>
</ol>

<p>Ideally I would like to use a shader since it seems straightforward and requires little additional work opposed to the duplicated-texture method. I worry that duplicating textures just to change a color in them is wasting VRAM -- should I not worry about that?</p>

<p><strong>Edit</strong>: I ended up using <a href=""https://gamedev.stackexchange.com/a/43313/974"">the accepted answer's technique</a> and here is my shader for reference.</p>

<pre><code>uniform sampler2D texture;
uniform sampler2D colorTable;
uniform float paletteIndex;

void main()
{
        vec2 pos = gl_TexCoord[0].xy;
        vec4 color = texture2D(texture, pos);
        vec2 index = vec2(color.r + paletteIndex, 0);
        vec4 indexedColor = texture2D(colorTable, index);
        gl_FragColor = indexedColor;      
}
</code></pre>

<p>Both textures are 32-bit, one texture is used as lookup table containing several palettes which are all the same size (in my case 6 colors). I use the source pixel's red channel as an index to the color table. This worked like a charm for achieving Megaman-like palette swapping!</p>
","<p>I wouldn't worry about wasting VRAM for a few character textures.</p>

<p>To me using your <strong>option 2.</strong> (with different textures or different UV offsets if that fits) is the way to go: more flexible, data-driven, less impact on the code, less bugs, less worries.</p>

<hr>

<p>This put aside, if you start to accumulate tons of characters with tons of sprite animations in memory, maybe you could start using <a href=""http://www.opengl.org/wiki/Common_Mistakes#Paletted_textures"" rel=""nofollow noreferrer""><strong>what's recommended by OpenGL</strong></a>, do-it-yourself palettes:</p>

<blockquote>
  <h3>Paletted textures</h3>
  
  <p>Support for the <a href=""http://www.opengl.org/registry/specs/EXT/paletted_texture.txt"" rel=""nofollow noreferrer"">EXT_paletted_texture</a> extension has been dropped by the
  major GL vendors. If you really need paletted textures on new
  hardware, you may use shaders to achieve that effect.</p>
  
  <p>Shader example:</p>
  
  <pre class=""lang-c prettyprint-override""><code>//Fragment shader
#version 110
uniform sampler2D ColorTable;     //256 x 1 pixels
uniform sampler2D MyIndexTexture;
varying vec2 TexCoord0;

void main()
{
  //What color do we want to index?
  vec4 myindex = texture2D(MyIndexTexture, TexCoord0);
  //Do a dependency texture read
  vec4 texel = texture2D(ColorTable, myindex.xy);
  gl_FragColor = texel;   //Output the color
}
</code></pre>
</blockquote>

<p>This is simply sampling in <code>ColorTable</code> (a palette in RGBA8), using <code>MyIndexTexture</code> (an 8 bits square texture in indexed colors). Just reproduces the way retro-style palettes work.</p>

<hr>

<p>The above-quoted example uses two <code>sampler2D</code>, where it could actually use one <strong><code>sampler1D</code></strong> + one <code>sampler2D</code>. I suspect this is for compatibility reasons (<a href=""https://stackoverflow.com/a/6219422/1005455"">no one-dimensional textures in OpenGL ES</a>)... But nevermind, for desktop OpenGL this can be simplified to:</p>

<pre class=""lang-c prettyprint-override""><code>uniform sampler1D Palette;             // A palette of 256 colors
uniform sampler2D IndexedColorTexture; // A texture using indexed color
varying vec2 TexCoord0;                // UVs

void main()
{
    // Pick up a color index
    vec4 index = texture2D(IndexedColorTexture, TexCoord0);
    // Retrieve the actual color from the palette
    vec4 texel = texture1D(Palette, myindex.x);
    gl_FragColor = texel;   //Output the color
}
</code></pre>

<p><code>Palette</code> is a one-dimensional texture of ""real"" colors (e.g. <code>GL_RGBA8</code>), and <code>IndexedColorTexture</code> is a two-dimensional textures of <a href=""http://en.wikipedia.org/wiki/Indexed_color"" rel=""nofollow noreferrer"">indexed colors</a> (typically <code>GL_R8</code>, which gives you 256 indices). To create those, there are <a href=""http://courses.washington.edu/dmwork/ps_1_lesson_3.html#indexed"" rel=""nofollow noreferrer"">several</a> <a href=""http://gimp.open-source-solution.org/manual/gimp-image-convert-indexed.html"" rel=""nofollow noreferrer"">authoring</a> <a href=""http://en.wikipedia.org/wiki/Paint_%28software%29"" rel=""nofollow noreferrer"">tools</a> and <a href=""http://en.wikipedia.org/wiki/Indexed_color#Image_file_formats_supporting_indexed_color"" rel=""nofollow noreferrer"">image file formats</a> out there that support paletted images, it should be doable to find the one that fits your needs.</p>
","43313"
"What alternatives to GLUT exist?","16558","","<p>I am trying to learn OpenGL, and I just found out that <a href=""https://gamedev.stackexchange.com/q/23644/5371"">GLUT is obsolete</a>. I already know SDL, and it seems it is a good alternative. Should I use SDL to develop games with OpenGL, or are there any better alternatives. I am new to game development, so I don't know much about the state of the art.</p>
","<blockquote>
  <p>I just found out that GLUT is obsolete.</p>
</blockquote>

<p>That's what happens when you accept the first answer you come across; you get bad information. GLUT 3.7 shouldn't be used, but FreeGLUT is completely backwards compatible with it.</p>

<p>However, your question goes elsewhere. For making an actual game, GLUT of * form is inappropriate. It doesn't give you control of the main loop, and you really need that in a game (FreeGLUT does have a way to control the main loop, but it's still odd). GLUT is for writing graphics demos. That's very important when testing new graphical effects, so it should be there in your toolbox when needed. But your main game code should never use it.</p>

<p><a href=""http://www.glfw.org/"">GLFW</a> is a game-centric lightweight alternative to GLUT. It provides basic support for things beyond creating an OpenGL window. It lets you get input, load images as textures, and a couple of other things.</p>

<p><a href=""http://www.libsdl.org/"">SDL</a>, <a href=""http://www.sfml-dev.org/"">SFML</a>, and <a href=""http://alleg.sourceforge.net/"">Allegro 5</a> are all multimedia toolkits. They can create OpenGL windows, but they do a <em>lot</em> more than that. They provide full support for input, audio, and various other stuff you need to make a game. If you're making a game, any of these are a good starting point. I personally like Allegro 5, but that's just my bias towards good documentation and a clean API.</p>
","23666"
"How can I develop Flash games without expensive software?","16530","","<p>I've been playing with writing flash games in my spare time, but up to this point, I've just been using a trial version of Adobe Flash Professional. I'm aware of <a href=""http://www.flashdevelop.org/wikidocs/index.php?title=Main_Page"">FlashDevelop</a>, but their documentation is basically <a href=""http://www.flashdevelop.org/wikidocs/index.php?title=AS3#Workflows"">non-existent when it comes to the workflow of developing purely with FlashDevelop</a>.</p>

<p>Does anyone know of any good tutorials for developing Flash games purely with FlashDevelop?</p>

<p>Alternatively, does anyone have any other free/cheap software recommendations to use in place of Flash Professional?</p>
","<p><a href=""http://devmag.org.za/2009/04/02/flash-for-free/"" rel=""nofollow"">Here is an article</a> about setting up the environment for FlashDevelop so you are purely working with it.</p>
","326"
"Unity3D, how much code do you write?","16509","","<p>I'm curious to know the workflow when creating a game in Unity3D? </p>

<p>Does it generate a lot of code for you?</p>

<p>My understanding is that you describe the game in Unity and do scripting on the back end to do the logic. Kind of like you use Unity to describe the puppets and you use a scripting language as the puppet master.</p>
","<p>Unity3D consists of a game engine plus a (fairly rudimentary) 3D editor. It provides meshes, textures, shaders, terrain, cameras, animations, particle systems, audio samples, and other kinds of object that are useful in video games. It includes <a href=""http://www.nvidia.com/page/pg_55418.html"">PHYSX</a> (a proprietary physics engine owned by Nvidia), and <a href=""http://mono-project.com/Main_Page"">Mono</a> (the open source implementation of the Common Language Runtime, aka .NET).</p>

<p>How much of this you use is up to you. You can represent all your data structures as Unity objects, build your world in Unity's editor, turn on the physics, and let events take their course, with a minimum of scripting. Alternatively, you could turn off the physics engine, construct your world algorithmically, and explicitly program all the behaviour and physics of the objects.</p>

<p>You can choose to program behaviour entirely in Mono (using one of the languages C#, JavaScript, or Boo), or you can write it in another language and link it with your Unity project. (The actual integration with the game objects must be via Mono, but this can be a fairly thin layer if you like.)</p>

<p>The workflow is much the same as with any game engine. Artists make models and textures and animations, audio specialists make the sounds, programmers write shaders and behaviour.</p>

<p>The community of Unity programmers is very helpful, both at <a href=""http://answers.unity3d.com/"">answers.unity3d.com</a> and <a href=""http://forum.unity3d.com/"">forum.unity3d.com</a>. (And maybe here at Stack Exchange?)</p>

<p>The best way to find out is to <a href=""http://unity3d.com/unity/download/"">try it out</a>: the basic version is free, and you get a 30-day trial period for the ""Pro"" version.</p>
","5417"
".XNB file reader","16508","","<p>I'd like to open an XNB file on Linux.</p>

<p>It should be an <code>XNA Game Studio Express XNA Framework Content Pipeline Binary File</code>.</p>

<p>Any tool to open it? (also for windows which I can emulate on wine)</p>
","<p>The <a href=""http://gruaz.net/?page_id=407"" rel=""nofollow"">GXView</a> program inside Gametools Suite should do the work, although I haven't tested it myself.</p>
","5841"
"How do I make a game tick method?","16497","","<p>I've seen in some other simple 2D games that a ""tick"" method is used to sync game logic and graphics rendering.  My main reason for using this is due to my collision detection malfunctioning, since the player entity will completely pass through solid objects unless I tap the controls almost pixel-by-pixel to collide the rectangles.</p>

<p>I figure a tick method will slow the games rapid updating enough to pick up these slight collision detections.</p>

<p>How do I create such a method? I've tried the code you can see below, however, it is causing the entire game to freeze:</p>

<p>The update method:</p>

<pre><code> @Override
    public void update(float deltaTime) {
        List&lt;TouchEvent&gt; touchEvents = game.getInput().getTouchEvents();
            long lastTime = 0;
            long currentTime = 0;

        if (state == GameState.Ready) {
            updateReady(touchEvents);
        }
        while (state == GameState.Running) {
                lastTime = currentTime;
                currentTime = System.currentTimeMillis();
                deltaTime = currentTime - lastTime;

                player.update(touchEvents, deltaTime);
                repaint(deltaTime);
        }
        if (state == GameState.Paused) {
            updatePaused(touchEvents);
        }
        if (state == GameState.GameOver) {
            updateGameOver(touchEvents);
        }
    }
</code></pre>

<p>The repaint method, which is updated while the regular paint method does nothing.  I've tried the while loop with both, doesn't seem to stop freezing:</p>

<pre><code>public void repaint(float deltaTime) {
        Graphics g = game.getGraphics();

        if(deltaTime &gt;= 60) {
            g.drawRect(0, 0, 805, 485, color.black);
            map.loadMap(getXScroll(), getYScroll(), g, game);
            map.loadEntities(getXScroll(), getYScroll(), g, game, map);
            g.drawImage(Assets.bitSoldier, 448, 256);
            g.drawImage(Assets.dpad, 0, 280);

            // Secondly, draw the UI above the game elements.
            if (state == GameState.Ready)
                drawReadyUI();
            if (state == GameState.Running)
                drawRunningUI();
            if (state == GameState.Paused)
                drawPausedUI();
            if (state == GameState.GameOver)
                drawGameOverUI();
        }
    }
</code></pre>
","<p>In general, there are two ways to make game logic ""tick"":</p>

<ul>
<li><strong>Fixed time steps</strong> run a fixed number of times per second, for example 100 times or maybe even 1000 times.</li>
<li><strong>Dynamic time steps</strong> run the game logic whenever possible, considering the time passed since the last update.</li>
</ul>

<p>Both approaches got their advantages and disadvantages, depending on what you're trying to achieve.</p>

<p>For movement and such, dynamic timesteps might be better, but for things such as animating pixel graphics, fixed timesteps might be more interesting. You can mix and match both as you like.</p>

<p>In general, as I mentioned in the comments, you should never let your program sleep in the game loop. This slows down the game without any reason and might even create stutter despite the computer being powerful enough to actually run the game without slowdowns.</p>

<p>Your generic game loop should look a bit like this (pseudo code):</p>

<pre><code>function mainloop() {
    double time_passed = 0;
    double delta_time = 0;

    while (running) { // keep running

        // update game logic based on time passed
        updateDynamicStep(delta_time);

        // update game logic once for every tick passed
        while (time_passed &gt;= time_per_timestep) {
            updateFixedStep();
            time_passed -= time_per_timestep;
            // You might limit the number of iterations here (like 10)
            // to not get stuck due to processing taking too long (and time adding up)
        }

        // draw screen content
        drawStuff(delta_time);

        // update timing
        delta_time = getTimePassedAndResetTimer();
        time_passed += delta_time;
    }
}
</code></pre>

<p>Doing it that way - no matter whether you use fixed time steps or not - has the advantage that your game will always run at the same speed, no matter whether you're running at 60 fps, 100 fps, 5000 fps, or only 15 fps.</p>

<p>The only reason to force sleeps could be to save battery (e.g. mobile games), but again I wouldn't sleep for fixed time, just sleep based on the time this iteration took and the time you planned for one frame. For example, if updating your game and drawing takes 10 ms and you plan on running at 60 frames per second, sleep for 5 ms (15ms total; perfect time would be 16.67ms, but you're leaving some space for other stuff like context switches and the like).</p>
","56993"
"Explaining Unity Sprite-Default Shader","16491","","<p>I would like to know why we would use alpha blending in that shader for just rendering a sprite, which is just a texture ? 
What is tint color ?
Why we multiply the alpha value by the color here ? </p>

<pre><code>fixed4 c = tex2D(_MainTex, IN.texcoord) * IN.color; // why ?
c.rgb *= c.a; // why ?
Shader ""Sprites/Default""
{
    Properties
    {
        [PerRendererData] _MainTex (""Sprite Texture"", 2D) = ""white"" {}
        _Color (""Tint"", Color) = (1,1,1,1)
        [MaterialToggle] PixelSnap (""Pixel snap"", Float) = 0
    }

    SubShader
    {
        Tags
        { 
            ""Queue""=""Transparent"" 
            ""IgnoreProjector""=""True"" 
            ""RenderType""=""Transparent"" 
            ""PreviewType""=""Plane""
            ""CanUseSpriteAtlas""=""True""
        }

        Cull Off
        Lighting Off
        ZWrite Off
        Fog { Mode Off }
        Blend One OneMinusSrcAlpha

        Pass
        {
        CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #pragma multi_compile DUMMY PIXELSNAP_ON
            #include ""UnityCG.cginc""

            struct appdata_t
            {
                float4 vertex   : POSITION;
                float4 color    : COLOR;
                float2 texcoord : TEXCOORD0;
            };

            struct v2f
            {
                float4 vertex   : SV_POSITION;
                fixed4 color    : COLOR;
                half2 texcoord  : TEXCOORD0;
            };

            fixed4 _Color;

            v2f vert(appdata_t IN)
            {
                v2f OUT;
                OUT.vertex = mul(UNITY_MATRIX_MVP, IN.vertex);
                OUT.texcoord = IN.texcoord;
                OUT.color = IN.color * _Color;
                #ifdef PIXELSNAP_ON
                OUT.vertex = UnityPixelSnap (OUT.vertex);
                #endif

                return OUT;
            }

            sampler2D _MainTex;

            fixed4 frag(v2f IN) : SV_Target
            {
                fixed4 c = tex2D(_MainTex, IN.texcoord) * IN.color;
                c.rgb *= c.a;
                return c;
            }
        ENDCG
        }
    }
}
</code></pre>
","<p>The ""tint"" color is a color that gets modulated (multiplied) with the texture color. This color is used with sprites for effects like making the player sprite blink red when hit by an enemy. To do so, you could set the tint to red when the player gets hit and leave it red for a couple frames, them restore it to white. Do that repeatedly for a few seconds and you'd have a blink effect for your sprite.</p>

<p>Multiplying the texture's <code>RGB</code> with the <code>A</code> could be used to give you a fade in/out effect. The alpha channel in the RGBA is a normalized value in the [0,1] range, so if you were to multiply the RGB with an alpha of say 0.2, you would get a very dark sprite. Multiply it by 1 and you will get the texture color as it is. You could get this same effect by multiplying the color with a back/white tint, BTW.</p>

<p>Finally, alpha blending should be on to ensure that sprites that have transparent areas get drawn properly. Most sprites have transparencies, so blending is required, otherwise the transparencies would be draw as if they where filled with some color. If you are sure you don't have transparencies in your sprites, then alpha blending could be safely disabled.</p>
","92551"
"Game state management techniques?","16419","","<p>First off, I'm not referring to scene management; I'm defining game state loosely as any sort of state in a game which has implications about whether or not user input should be enabled, or if certain actors should be temporarily disabled, etc.</p>

<p>As a concrete example, let's say it's a game of the classic Battlechess.  After I make a move to take another player's piece, a short battle sequence plays.  During this sequence, the player shouldn't be allowed to move pieces.  So how would you track this sort of state transition?  A finite state machine?  A simple boolean check?  It seems the latter would only work well for a game with very few state changes of this sort.</p>

<p>I can think of a lot of straightforward ways of handling this using finite state machines, but I can also see them quickly getting out of hand.  I'm just curious if there's a more elegant way to keep track of game states/transitions.</p>
","<p>I once came across an <a href=""http://gamedevgeek.com/tutorials/managing-game-states-in-c/"">article</a> that solves your problem quite elegantly. It is a basic FSM implementation, that is called in your main loop. I have outlined the basic rundown of the article in the rest of this answer.</p>

<p>Your basic game state looks like this:</p>

<pre><code>class CGameState
{
    public:
        // Setup and destroy the state
        void Init();
        void Cleanup();

        // Used when temporarily transitioning to another state
        void Pause();
        void Resume();

        // The three important actions within a game loop
        void HandleEvents();
        void Update();
        void Draw();
};
</code></pre>

<p>Each game state is represented by an implementation of this interface. For your Battlechess example, this could mean these states:</p>

<ul>
<li>intro animation</li>
<li>main menu</li>
<li>chess board setup animation</li>
<li>player move input</li>
<li>player move animation</li>
<li>opponent move animation</li>
<li>pause menu</li>
<li>endgame screen</li>
</ul>

<p>States are managed in your state engine:</p>

<pre><code>class CGameEngine
{
    public:
        // Creating and destroying the state machine
        void Init();
        void Cleanup();

        // Transit between states
        void ChangeState(CGameState* state);
        void PushState(CGameState* state);
        void PopState();

        // The three important actions within a game loop
        // (these will be handled by the top state in the stack)
        void HandleEvents();
        void Update();
        void Draw();

        // ...
};
</code></pre>

<p>Note that each state needs a pointer to the CGameEngine at some point, so the state itself can decide whether a new state should be entered. The article suggest passing in the CGameEngine as a parameter for HandleEvents, Update and Draw.</p>

<p>In the end, your main loop only deals with the state engine:</p>

<pre><code>int main ( int argc, char *argv[] )
{
    CGameEngine game;

    // initialize the engine
    game.Init( ""Engine Test v1.0"" );

    // load the intro
    game.ChangeState( CIntroState::Instance() );

    // main loop
    while ( game.Running() )
    {
        game.HandleEvents();
        game.Update();
        game.Draw();
    }

    // cleanup the engine
    game.Cleanup();
    return 0;
}
</code></pre>
","13245"
"How to convert a number from one min\max set to another min\max set?","16388","","<p>I'm doing terrain generation and I have a perlin library that is giving me random numbers between -1 and +1. I want to convert this to the scale of 0-255. What is the proper way to do this?</p>
","<p>Base formula is:</p>

<pre><code>Result := ((Input - InputLow) / (InputHigh - InputLow)) * (OutputHigh - OutputLow) + OutputLow;
</code></pre>

<p>Your case:</p>

<p>Result := ((<strong>Input</strong> - <strong>-1</strong>) / (<strong>1</strong> - <strong>-1</strong>) * (<strong>255</strong> - <strong>0</strong>) + <strong>0</strong>;</p>

<p>From here you can optimize the conversion if your coefficients are static, but compiler will probably do it by itself as well.</p>

<p>Result := ((<strong>Input</strong> - <strong>-1</strong>) / <strong>2</strong>) * <strong>255</strong> + <strong>0</strong>;</p>

<p>Result := <strong>Input</strong> * <strong>127.5</strong> + <strong>127.5</strong>;</p>
","33445"
"What are typical job interview questions related to game development?","16347","","<p>I've already looked at some examples from StackOverflow, but I'd like to know if any of you could show concrete examples of job interview questions... Are they different with a job related to game development?</p>
","<p>The context of the questions might change, but not really; if you are looking to program, you will still be asked questions that apply to Computer Science in general, including, but not limited to:</p>

<ul>
<li>Mathematics</li>
<li>Programming Syntax</li>
<li>Programming Methodology</li>
<li>Debugging</li>
</ul>

<p>At least, I was.  My programming methodology question was phrased in terms of game related terms, such as <code>ships</code> and <code>bullets</code>, but it was really a design question and a math question.</p>
","7682"
"The underlying mechanism in 'yield return www' of Unity3D Game Engine","16333","","<p>In the Unity3D game engine, a common code sequence for getting remote data is this:</p>

<pre><code>WWW www = new WWW(""http://remote.com/data/location/with/texture.png"");
yield return www;
</code></pre>

<p>What is the underlying mechanism here?</p>

<p>I know we use the yield mechanism in order to allow the next frame to be processed, while the download is being completed. But what is going on under the hood when we do the <code>yield return www</code> ? </p>

<p>What method is being called (if any, on the WWW class)?
Is Unity using threads?
Is the ""upper"" Unity layer getting hold of www instance and doing something?</p>

<p>EDIT:</p>

<ul>
<li>This question is specifically about Unity3D internals. I'm not interested in explanations of how <code>yield</code> statement works in C#. Instead, I'm looking for an inside view of how Unity deals with these constructions, to allow, for example, to WWW to download a piece of data in a distributed manner across several frames.</li>
</ul>
","<p>This is the C# <a href=""http://msdn.microsoft.com/en-us/library/9k7k7cf0%28v=vs.110%29.aspx"">yield keyword</a> in action - its not doing anything special with the <code>www</code> object, rather its means something special for the method its contained in.  Specifically this keyword can only be used in a method which returns an <code>IEnumerable</code> (or <code>IEnumerator</code>), and is used to indicate what object will be ""returned"" by the enumerator when <a href=""http://msdn.microsoft.com/en-us/library/system.collections.ienumerator.aspx"">MoveNext</a> is called.</p>

<p>It works because the compiler converts the entire method into a separate class which implements <code>IEnumerable</code> (or <code>IEnumerator</code>) using a state machine - the net result is that the body of the method itself is not executed until someone enumerates through return value.  This will work with any type, there is absolutely nothing special about <code>WWW</code>, rather its the containing method which is special.</p>

<p>Take a look at <a href=""http://startbigthinksmall.wordpress.com/2008/06/09/behind-the-scenes-of-the-c-yield-keyword/"">Behind the scenes of the C# yield keyword</a> for some more insight into what sort of code the C# compiler generates, or just experiment and inspect the code yourself using something like <a href=""http://ilspy.net/"">IL Spy</a></p>

<hr>

<p><strong>Update:</strong> To clarify</p>

<ul>
<li>When Unity calls a coroutine that contains a <code>yield return</code> statement all that happens is that an enumerator is returned - none of the method body is executed at this point</li>
<li>To get the method body to execute Unity must call <code>MoveNext</code> on the iterator in order to get the first value in the sequence.  This causes the method to execute up to the first <code>yeild return</code> statement, at which point the caller resumes (and presumably Unity goes on to render the rest of the frame)</li>
<li>As I understand it Unity normally then goes on to call the <code>MoveNext</code> method on the iterator once each subsequent frame, causing the method to execute again up to the next <code>yield return</code> statement once each frame, until either the end of the method or a <code>yield break</code> statement is reached (indicating the end of the sequence)</li>
</ul>

<p>The only special bit here (and in a <a href=""http://docs.unity3d.com/Documentation/ScriptReference/WaitForSeconds.html"">couple</a> of <a href=""http://docs.unity3d.com/Documentation/ScriptReference/WaitForFixedUpdate.html"">other cases</a>) is that Unity doesn't advance this particular iterator the next frame, instead it only advances the iterator (causing the method to continue executing) when the download has completed.  Although there does appear to be a base <a href=""http://docs.unity3d.com/Documentation/ScriptReference/YieldInstruction.html"">YieldInstruction</a> class which presumably contains a generic mechanism for signalling to Unity when an iterator should be advanced, the <code>WWW</code> class doesn't appear to inherit from this class so I can only assume that there is a special case for this class in the Unity engine.</p>

<p>Just to be clear - the <code>yield</code> keyword doesn't do anything special to the <code>WWW</code> class, rather its the special handling that Unity gives to the members of the returned enumeration which causes this behaviour.</p>

<hr>

<p><strong>Update the second:</strong> As for the mechanism that <code>WWW</code> uses to download web pages asynchronously it probably uses either the <a href=""http://msdn.microsoft.com/en-us/library/system.net.httpwebrequest.begingetresponse.aspx"">HttpWebRequest.BeginGetResponse Method</a> which will internally use <a href=""http://msdn.microsoft.com/en-gb/library/windows/desktop/aa365683%28v=vs.85%29.aspx"">asynchronous IO</a> or alternatively it could use threads (either creating a dedicated thread or by using a thread pool).</p>
","43755"
"Calculating Delta time , what is wrong?","16297","","<p>For 2 days now i am trying to calculate the correct delta time for my game , I am starting to getting crazy since i tried all the solutions that i found on the 5 first google pages...
What is wrong? I cant get the correct delta time ,whatever i tried is just not working , the delta goes from 1 to 4 and then back 1 and then to 3 even if i take the averange delta between many frames.Plus  the game runs way much faster(i mean the movement) on slow devices than in fast.
The game runs on android so the spikes between frames are expected.</p>

<p>My code is this:</p>

<pre><code>    void Game::render()
    {

        timesincestart=getTimeMil();

        _director-&gt;Render();
        _director-&gt;Update();


        float dif=(getTimeMil()-timesincestart);//usally its about 5 milliseconds

        lastcheck++;
        sumdelta+=dif;
        if(lastcheck&gt;20)
        {
            sumdelta=sumdelta/20;
            delta=sumdelta;
            sumdelta=0;
            lastcheck=0;
        }

        LOGI(""delta:%f"",delta);
    }
</code></pre>

<p><strong>SOLVED:</strong></p>

<pre><code>void Game::render()
{
    oldtime=newtime;
    newtime=getTimeMil();

    delta=(newtime-oldtime)/16;//divide by 16 is just making the dt closer to 1

    _director-&gt;Render();
    _director-&gt;Update();

}
</code></pre>
","<p>i am a bit confused with your delta...</p>

<p>But how i do it is like this :</p>

<pre><code>while( 1 ) 
{
    old = newTime;
    newTime = GetTime();

    DoMyGameAndUseLotsOfCyckels( newTime - old );
}
</code></pre>
","44934"
"How to create a hexagon world map in PHP from a database for a browser based strategy game","16283","","<p>I'm trying to create a hexagon world map for my PHP browser based strategy game. I've created a table in my database with the following data per row: id, type, x, y and occupied. Where type is the kind of tiles, which are defined in numbers. For example, 1 is grass. The map itself is 25 x 25.</p>

<p>I want to draw the map from the database with clickable tiles and the possibilty to navigate through the map with arrows. I don't really have a clue on how to start with this and any help would be appreciated.</p>

<p>Thank you in advance,</p>

<p>Fabian</p>
","<p>*Edit:  Fixed error in javascript that caused error on firefox *</p>

<p><em>Edit:   just added ability to scale hexes to the PHP source code.  Tiny 1/2 sized ones or 2x jumbo, it's all up to you :)</em></p>

<p>I wasn't quite sure how to put this all into writing, but found it was easier to just write the code for a full live example.  The page (link and source below) dynamically generates a hexmap with PHP and uses Javascript to handle map clicks.  Clicking on a hex highlights the hex.</p>

<p>The map is randomly generated, but you should be able to use your own code instead to populate the map.  It is represented by a simple 2d array, with each array element holding the type of terrain present in that hex.</p>

<p><a href=""http://perludus.com/examples/hexmap/"" rel=""nofollow noreferrer"">Click me to try the Hex Map Example</a></p>

<p>To use, click on any hex to highlight it. </p>

<p>Right now it's generating a 10x10 map, but you can change the map size in the PHP to be any size you want.  I'm also using a set of tiles from the game Wesnoth for the example.  They are 72x72 pixels in height, but the source also lets you set the size of your hex tiles.</p>

<p>The hexes are represented by PNG images with ""outside the hex"" areas set as transparent.  To position each hex, I am using CSS to set each tile's absolute position, calculated by the hex grid coordinate.  The map is enclosed in a single DIV, which should make it easier for you to modify the example.</p>

<p>Here is the full page code.  You can also download the <a href=""http://perludus.com/examples/hexmap/hexmap.zip"" rel=""nofollow noreferrer"">demo source</a> (including all hex images).</p>

<pre><code>&lt;?php
// ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
// :: HEX.PHP
// ::
// :: Author:  
// ::    Tim Holt, tim.m.holt@gmail.com
// :: Description:  
// ::    Generates a random hex map from a set of terrain types, then
// ::    outputs HTML to display the map.  Also outputs Javascript
// ::    to handle mouse clicks on the map.  When a mouse click is
// ::    detected, the hex cell clicked is determined, and then the
// ::    cell is highlighted.
// :: Usage Restrictions:  
// ::    Available for any use.
// :: Notes:
// ::    Some content (where noted) copied and/or derived from other 
// ::    sources.
// ::    Images used in this example are from the game Wesnoth.
// ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

// --- Turn up error reporting in PHP
error_reporting(E_ERROR | E_WARNING | E_PARSE | E_NOTICE);

// --- Define some constants
$MAP_WIDTH = 10;
$MAP_HEIGHT = 10;
$HEX_HEIGHT = 72;

// --- Use this to scale the hexes smaller or larger than the actual graphics
$HEX_SCALED_HEIGHT = $HEX_HEIGHT * 1.0;
$HEX_SIDE = $HEX_SCALED_HEIGHT / 2;
?&gt;
&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;Hex Map Demo&lt;/title&gt;
        &lt;!-- Stylesheet to define map boundary area and hex style --&gt;
        &lt;style type=""text/css""&gt;
        body {
            /* 
            margin: 0;
            padding: 0;
            */
        }

        .hexmap {
            width: &lt;?php echo $MAP_WIDTH * $HEX_SIDE * 1.5 + $HEX_SIDE/2; ?&gt;px;
            height: &lt;?php echo $MAP_HEIGHT * $HEX_SCALED_HEIGHT + $HEX_SIDE; ?&gt;px;
            position: relative;
            background: #000;
        }

        .hex-key-element {
            width: &lt;?php echo $HEX_HEIGHT * 1.5; ?&gt;px;
            height: &lt;?php echo $HEX_HEIGHT * 1.5; ?&gt;px;
            border: 1px solid #fff;
            float: left;
            text-align: center;
        }

        .hex {
            position: absolute;
            width: &lt;?php echo $HEX_SCALED_HEIGHT ?&gt;;
            height: &lt;?php echo $HEX_SCALED_HEIGHT ?&gt;;
        }
        &lt;/style&gt;
    &lt;/head&gt;
    &lt;body&gt;
    &lt;script&gt;

function handle_map_click(event) {
    // ----------------------------------------------------------------------
    // --- This function gets a mouse click on the map, converts the click to
    // --- hex map coordinates, then moves the highlight image to be over the
    // --- clicked on hex.
    // ----------------------------------------------------------------------

    // ----------------------------------------------------------------------
    // --- Determine coordinate of map div as we want the click coordinate as
    // --- we want the mouse click relative to this div.
    // ----------------------------------------------------------------------

    // ----------------------------------------------------------------------
    // --- Code based on http://www.quirksmode.org/js/events_properties.html
    // ----------------------------------------------------------------------
    var posx = 0;
    var posy = 0;
    if (event.pageX || event.pageY) {
        posx = event.pageX;
        posy = event.pageY;
    } else if (event.clientX || e.clientY) {
        posx = event.clientX + document.body.scrollLeft
            + document.documentElement.scrollLeft;
        posy = event.clientY + document.body.scrollTop
            + document.documentElement.scrollTop;
    }
    // --- Apply offset for the map div
    var map = document.getElementById('hexmap');
    posx = posx - map.offsetLeft;
    posy = posy - map.offsetTop;
    //console.log (""posx = "" + posx + "", posy = "" + posy);

    // ----------------------------------------------------------------------
    // --- Convert mouse click to hex grid coordinate
    // --- Code is from http://www-cs-students.stanford.edu/~amitp/Articles/GridToHex.html
    // ----------------------------------------------------------------------
    var hex_height = &lt;?php echo $HEX_SCALED_HEIGHT; ?&gt;;
    x = (posx - (hex_height/2)) / (hex_height * 0.75);
    y = (posy - (hex_height/2)) / hex_height;
    z = -0.5 * x - y;
    y = -0.5 * x + y;

    ix = Math.floor(x+0.5);
    iy = Math.floor(y+0.5);
    iz = Math.floor(z+0.5);
    s = ix + iy + iz;
    if (s) {
        abs_dx = Math.abs(ix-x);
        abs_dy = Math.abs(iy-y);
        abs_dz = Math.abs(iz-z);
        if (abs_dx &gt;= abs_dy &amp;&amp; abs_dx &gt;= abs_dz) {
            ix -= s;
        } else if (abs_dy &gt;= abs_dx &amp;&amp; abs_dy &gt;= abs_dz) {
            iy -= s;
        } else {
            iz -= s;
        }
    }

    // ----------------------------------------------------------------------
    // --- map_x and map_y are the map coordinates of the click
    // ----------------------------------------------------------------------
    map_x = ix;
    map_y = (iy - iz + (1 - ix %2 ) ) / 2 - 0.5;

    // ----------------------------------------------------------------------
    // --- Calculate coordinates of this hex.  We will use this
    // --- to place the highlight image.
    // ----------------------------------------------------------------------
    tx = map_x * &lt;?php echo $HEX_SIDE ?&gt; * 1.5;
    ty = map_y * &lt;?php echo $HEX_SCALED_HEIGHT ?&gt; + (map_x % 2) * (&lt;?php echo $HEX_SCALED_HEIGHT ?&gt; / 2);

    // ----------------------------------------------------------------------
    // --- Get the highlight image by ID
    // ----------------------------------------------------------------------
    var highlight = document.getElementById('highlight');

    // ----------------------------------------------------------------------
    // --- Set position to be over the clicked on hex
    // ----------------------------------------------------------------------
    highlight.style.left = tx + 'px';
    highlight.style.top = ty + 'px';
}
&lt;/script&gt;
&lt;?php

// ----------------------------------------------------------------------
// --- This is a list of possible terrain types and the
// --- image to use to render the hex.
// ----------------------------------------------------------------------
    $terrain_images = array(""grass""    =&gt; ""grass-r1.png"",
                            ""dirt""     =&gt; ""dirt.png"",
                            ""water""    =&gt; ""coast.png"",
                            ""path""     =&gt; ""stone-path.png"",
                            ""swamp""    =&gt; ""water-tile.png"",
                            ""desert""   =&gt; ""desert.png"",
                            ""oasis""    =&gt; ""desert-oasis-tile.png"",
                            ""forest""   =&gt; ""forested-mixed-summer-hills-tile.png"",
                            ""hills""    =&gt; ""hills-variation3.png"",
                            ""mountain"" =&gt; ""mountain-tile.png"");

    // ==================================================================

    function generate_map_data() {
        // -------------------------------------------------------------
        // --- Fill the $map array with values identifying the terrain
        // --- type in each hex.  This example simply randomizes the
        // --- contents of each hex.  Your code could actually load the
        // --- values from a file or from a database.
        // -------------------------------------------------------------
        global $MAP_WIDTH, $MAP_HEIGHT;
        global $map, $terrain_images;
        for ($x=0; $x&lt;$MAP_WIDTH; $x++) {
            for ($y=0; $y&lt;$MAP_HEIGHT; $y++) {
                // --- Randomly choose a terrain type from the terrain
                // --- images array and assign to this coordinate.
                $map[$x][$y] = array_rand($terrain_images);
            }
        }
    }

    // ==================================================================

    function render_map_to_html() {
        // -------------------------------------------------------------
        // --- This function renders the map to HTML.  It uses the $map
        // --- array to determine what is in each hex, and the 
        // --- $terrain_images array to determine what type of image to
        // --- draw in each cell.
        // -------------------------------------------------------------
        global $MAP_WIDTH, $MAP_HEIGHT;
        global $HEX_HEIGHT, $HEX_SCALED_HEIGHT, $HEX_SIDE;
        global $map, $terrain_images;

        // -------------------------------------------------------------
        // --- Draw each hex in the map
        // -------------------------------------------------------------
        for ($x=0; $x&lt;$MAP_WIDTH; $x++) {
            for ($y=0; $y&lt;$MAP_HEIGHT; $y++) {
                // --- Terrain type in this hex
                $terrain = $map[$x][$y];

                // --- Image to draw
                $img = $terrain_images[$terrain];

                // --- Coordinates to place hex on the screen
                $tx = $x * $HEX_SIDE * 1.5;
                $ty = $y * $HEX_SCALED_HEIGHT + ($x % 2) * $HEX_SCALED_HEIGHT / 2;

                // --- Style values to position hex image in the right location
                $style = sprintf(""left:%dpx;top:%dpx"", $tx, $ty);

                // --- Output the image tag for this hex
                print ""&lt;img src='$img' alt='$terrain' class='hex' style='zindex:99;$style'&gt;\n"";
            }
        }
    }

    // -----------------------------------------------------------------
    // --- Generate the map data
    // -----------------------------------------------------------------
    generate_map_data();
    ?&gt;

    &lt;h1&gt;Hex Map Example&lt;/h1&gt;
    &lt;a href='index.phps'&gt;View page source&lt;/a&gt;&lt;br/&gt;
    &lt;a href='hexmap.zip'&gt;Download source and all images&lt;/a&gt;

    &lt;!-- Render the hex map inside of a div block --&gt;
    &lt;div id='hexmap' class='hexmap' onclick='handle_map_click(event);'&gt;
        &lt;?php render_map_to_html(); ?&gt;
        &lt;img id='highlight' class='hex' src='hex-highlight.png' style='zindex:100;'&gt;
    &lt;/div&gt;

    &lt;!--- output a list of all terrain types --&gt;
    &lt;br/&gt;
    &lt;?php 
        reset ($terrain_images);
        while (list($type, $img) = each($terrain_images)) {
            print ""&lt;div class='hex-key-element'&gt;&lt;img src='$img' alt='$type'&gt;&lt;br/&gt;$type&lt;/div&gt;"";
        }
    ?&gt;
    &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>Here is a screenshot of the example...</p>

<p><img src=""https://i.stack.imgur.com/GygK7.png"" alt=""Hex Map Example Screenshot""></p>

<p>Definitely could use some improvements.  I noticed in a previous comment you said you were familiar with jQuery, which is good.  I didn't use it here to keep things simple, but it would be pretty useful to use.  </p>
","6450"
"Open-source 3D models easily usable in OGRE3D/jMonkeyEngine","16245","","<p>I'm looking for a source of 3D models (cars, game characters, furnitures etc.) which are usable in an open-source 3D game.</p>

<p>I found various website with free/opensource <code>.blend</code> files. However it is not easy to convert them en mass to jMonkeyEngine compatible format. You must open each one in blender, unpack the texture, and then use a python blender plugin to convert them into Ogre3DXML. It is not very convenient.</p>

<p>I want to try out many models, and find out which suits me the best. Converting each one of them by hand is not very scalable.</p>

<p>How do you get models for your 3D games?</p>

<p>Is there a standalone <code>.blend</code> => <code>usable format in jMonkeyEngine/OGRE3D</code> converted?</p>
","<p>There are one major source of open sourced models for Ogre3D available:</p>

<p><a href=""http://worldforge.org/media/documents/media_faq/#1"">WorldForge Media Repository</a></p>

<p>WorldForge assets are licensed under the GPL, meaning that you need to contribute back any changes, but you're free to use the models in any project, closed source too.</p>

<p>Then, a repository not directly available in Ogre format, but very useful none the less:</p>

<p><a href=""http://media.ryzom.com/"">Ryzom Asset Repository</a></p>

<p>Ryzom assets are licensed under the CC by Sa (Creative Commons) license.</p>
","2404"
"How does entity communication work?","16097","","<p>I have two user cases:</p>

<ol>
<li>How would <code>entity_A</code> send a <code>take-damage</code> message to <code>entity_B</code>?  </li>
<li>How would <code>entity_A</code> query <code>entity_B</code>'s HP?</li>
</ol>

<p>Here's what I've encountered so far:</p>

<ul>
<li><a href=""http://en.wikipedia.org/wiki/Message_queue"" rel=""noreferrer"">Message queue</a>  

<ol>
<li><code>entity_A</code> creates a <code>take-damage</code> message and posts it to <code>entity_B</code>'s message queue.</li>
<li><code>entity_A</code> creates a <code>query-hp</code> message and posts it to <code>entity_B</code>.  <code>entity_B</code> in return creates an <code>response-hp</code> message and posts it to <code>entity_A</code>.</li>
</ol></li>
<li><a href=""http://en.wikipedia.org/wiki/Publish/subscribe"" rel=""noreferrer"">Publish/Subscribe</a>  

<ol>
<li><code>entity_B</code> subscribes to <code>take-damage</code> messages (possibly with some preemptive filtering so only relevant message are delivered).  <code>entity_A</code> produces <code>take-damage</code> message that references <code>entity_B</code>.</li>
<li><code>entity_A</code> subscribes to <code>update-hp</code> messages (possibly filtered).  Every frame <code>entity_B</code> broadcasts <code>update-hp</code> messages.</li>
</ol></li>
<li><a href=""http://en.wikipedia.org/wiki/Signals_and_slots"" rel=""noreferrer"">Signal/Slots</a>

<ol>
<li>???</li>
<li><code>entity_A</code> connects an <code>update-hp</code> slot to <code>entity_B</code>'s <code>update-hp</code> signal.</li>
</ol></li>
</ul>

<p>Is there something better? Do I have a correct understanding of how these communication schemes would tie into a game engine's entity system?</p>
","<p>Good question!  Before I get to the specific questions you asked, I'll say: don't underestimate the power of simplicity.  Tenpn is right.  Keep in mind that all you're trying to do with these approaches is find an elegant way to defer a function call or decouple the caller from the callee.  I can recommend coroutines as a surprisingly intuitive way to alleviate some of those problems, but that's a little off-topic.  Sometimes, you're better off just calling the function and living with the fact that entity A is coupled directly to entity B.  See YAGNI.</p>

<p>That said, I've used and been happy with the signal/slot model combined with simple message passing.  I used it in C++ and Lua for a fairly successful iPhone title that had a very tight schedule.</p>

<p>For the signal/slot case, if I want entity A to do something in response to something entity B did (e.g. unlock a door when something dies) I might have entity A subscribe directly to entity B's death event.  Or possibly entity A would subscribe to each of a group of entities, increment a counter on each event fired, and unlock the door after N of them have died.  Also, ""group of entities"" and ""N of them"" would typically be designer defined in the level data.  (As an aside, this is one area where coroutines can really shine, e.g., WaitForMultiple( ""Dying"", entA, entB, entC ); door.Unlock();)</p>

<p>But that can get cumbersome when it comes to reactions that are tightly coupled to C++ code, or inherently ephemeral game events: dealing damage, reloading weapons, debugging, player-driven location-based AI feedback.  This is where message passing can fill in the gaps.  It essentially boils down to something like, ""tell all the entities in this area to take damage in 3 seconds,"" or ""whenever you complete the physics to figure out who I shot, tell them to run this script function.""  It's difficult to figure out how to do that nicely using publish/subscribe or signal/slot.</p>

<p>This can easily be overkill (versus tenpn's example).  It can also be inefficient bloat if you have a lot of action.  But despite its drawbacks, this ""messages and events"" approach meshes very well with scripted game code (e.g. in Lua).  The script code can define and react to its own messages and events without the C++ code caring at all.  And the script code can easily send messages that trigger C++ code, like changing levels, playing sounds, or even just letting a weapon set how much damage that TakeDamage message delivers.  It saved me a ton of time because I wasn't having to constantly fool around with luabind.  And it let me keep all of my luabind code in one place, because there wasn't much of it.  When properly coupled, you can use embedded languages like Lua to easily add new features/monsters/weapons/levels/etc to the game without ever recompiling the C++ code.</p>

<p>Also, my experience with use case #2 is that you're better off handling it as an event in the other direction.  Instead of asking what the entity's health is, fire an event/send a message whenever the health makes a significant change.</p>

<p>In terms of interfaces, btw, I ended up with three classes to implement all of this: EventHost, EventClient, and MessageClient.  EventHosts create slots, EventClients subscribe/connect to them, and MessageClients associate a delegate with a message.  Note that a MessageClient's delegate target doesn't necessarily need to be the same object that owns the association.  In other words, MessageClients can exist solely to forward messages to other objects.  FWIW, the host/client metaphor is kind of inappropriate.  Source/Sink might be better concepts.</p>

<p>Sorry, I kinda rambled there.  It's my first answer :)  I hope it made sense.</p>
","1449"
"How to edit key-value pairs (like a Dictionary) in Unity's inspector?","16057","","<p>I have a spell system I am creating, the principle is as follows:</p>

<ul>
<li>Each spell is an autonomous prefab. It contains a script with some properties (base damage, duration...) that can be modified in the inspector.</li>
<li>I have a Spell enum listing all possible spells in the code, which is used in the game logic</li>
<li>When I want to cast a spell, I need to be able to get this spell's prefab to instantiate it and read its informations</li>
<li>Each actor (be it players or enemies) needs to have a list of possible animations for the spells</li>
</ul>

<p>The problems with how I am trying to implement are:</p>

<ul>
<li>For listing each actor's animations I could use a <code>Dictionary&lt;Spell, Animation&gt;</code>, but dictionaries aren't supported by the inspector which makes it hard to easily edit multiple actors type.</li>
<li>I need some way to easily access a spell prefab from the corresponding enum. Here too I could use a dictionary but I can only reference to prefabs in the inspector, not in code, meaning I wouldn't be able to fill this dictionary</li>
</ul>

<p>I am looking for a way to easily associate my spells enums to the corresponding prefabs and animations</p>
","<p>One quick way to get key-value pairs in Unity's inspector is to define a serializable entry class, and then use an array or List&lt;> of them. eg...</p>

<pre><code>public class SpellAnimationMap : ScriptableObject
{
   [System.Serializable]
   public class SpellAnimationEntry
   {
       public Spell spell;
       public AnimationClip animation;
   }

   public SpellAnimationEntry[] spellAnimations;    
}
</code></pre>

<p>Automatically, this will give you a resizeable list in the inspector where you can enter the key and value, without needing to write a custom inspector.</p>

<p>The result looks like this:</p>

<p><img src=""https://i.stack.imgur.com/jXczR.png"" alt=""auto-generated inspector""></p>

<p>(One trick: if the serialized entry class contains a ""Name"" field, that string will be displayed instead of the bland ""Element 0"" headings. Useful if you have more complex data you want to be able to navigate efficiently.)</p>

<p>Making this a ScriptableObject allows you to treat it as an Asset shared between entity types/instances that need the same animation set, avoiding overhead of duplicating the list for each. (Other classes tend to be serialized per-instance in Unity). To go this route, you'll need to add a <a href=""http://www.jacobpennock.com/Blog/?p=670"" rel=""nofollow noreferrer"">small editor script to let you create instances of these in your Assets folder</a>.</p>

<hr>

<p><strong>Edit:</strong> now it's even easier - <a href=""https://docs.unity3d.com/ScriptReference/CreateAssetMenuAttribute.html"" rel=""nofollow noreferrer"">you can just add this attribute</a> above your ScriptableObject: </p>

<pre><code>[CreateAssetMenu(fileName = ""fileName.asset"", menuName = ""Some Folder/Menu Label"")]
</code></pre>

<p>This puts the ScriptableObject into your Create menu, like so:
<a href=""https://i.stack.imgur.com/LEzzl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LEzzl.png"" alt=""Screenshot showing a customized Create menu in Unity""></a></p>

<hr>

<p>You can optionally make the array private and serialized so that it still shows up in the inspector, but add a public Dictionary (or private dictionary with a public GetAnimation(Spell spell) method) for clients to consume for more efficient lookups. In its OnEnable() method, the SpellAnimationMap can iterate through its inspector-populated array to build this dictionary once, again sharing the benefit between all client instances. (Note that OnEnable() is also called in the editor when the asset is first created, so be sure to check that your array is non-null before you try to read it)</p>

<p>Finally, you can add as much into this entry datatype as you need. It could include the prefab too, for instance, or any number of other bits of data you want to link to the spell key.</p>

<p>It's also possible to write custom inspectors to populate Dictionary&lt;,> fields directly, but the impression that I get is that it's fussy to get working smoothly.</p>
","74408"
"Android: How to create fluent animations by using bitmaps and ObjectAnimator?","16041","","<p>I want a resized bitmap item to move over the screen into a house. This basically works, but the movement is not fluent and is stuttering. Since I always have to draw both the resized background and the house due to some alphas (both are exactly as big as the screen), the animation runs very slow, because <strong>invalidate()</strong> is no fast enough. At every bitmap move, <strong>invalidate()</strong> is being executed.</p>

<p>This is a very simplified example of my view to show what I'm doing. </p>

<pre><code>public class GameView extends View implements ValueAnimator.AnimatorUpdateListener
{
    //more code

    @Override
    protected void onDraw(Canvas canvas)
    {
        canvas.drawBitmap(ResizedBitmapMapping.getBackground(), 0f, 0f, null);
        canvas.drawBitmap(item.getBitmap(), item.getXY().getX(), item.getXY().getY(), null);
        canvas.drawBitmap(ResizedBitmapMapping.getHouse(), 0f, 0f, null);
    }

    @Override
    public void onAnimationUpdate(ValueAnimator animation)
    {
        invalidate();
    }

    public void setActive()
    {
        item = new Item(ResizedBitmapMapping.getItem());
        XYHolder startXY = new XYHolder(0f, height);
        XYHolder endXY = new XYHolder(width * 2 / 3, height / 4);

        animator = ObjectAnimator.ofObject(car, ""xY"", new XYEvaluator(), startXY, endXY);
        animator.setDuration(2000);
        animator.addUpdateListener(this);
        animator.setRepeatCount(ObjectAnimator.INFINITE);
        animator.start();
    }

    //more code

}
</code></pre>

<p>My questions:
Is the concept of drawing basically wrong? If yes, how does an efficient drawing concept look like?
If the concept is right, is it just a case of optimizing like drawing just ""rects"" instead of the whole background and house or something? </p>
","<p>I found a solution which works for my purposes since I don't use many bitmaps on the canvas. It's absolutely fluent when I <strong>invalidate()</strong> just once when all bitmaps (background and so on) have been loaded and then in onAnimationUpdate() I only partially invalidate the canvas by this method: </p>

<pre><code>invalidate(int l, int t, int r, int b);
</code></pre>

<p>That means I only invalidate the rect around the moving bitmap(s). Since they lie close together, I don't get such a big ""dirty rect"" and it's very fluent. If the bitmaps are scattered around the whole surface, the trick would probably be to invalidate each bitmap after another (not tested yet). That would mean that one complete move of all bitmaps would take as long as every single bitmap has been invalidated. It's some kind of a juggling act because you have to think about what is slower: A very big dirty rect invalidated just once or many invalidates of several dirty rects.</p>

<p>By the way: I wonder how all the games on Android are designed. They are always absolutely fluent. Do they all use OpenGL?</p>
","79601"
"GLM: Euler Angles to Quaternion","16034","","<p>I hope you know <strong>GL Mathematics</strong> (<a href=""http://glm.g-truc.net/"">GLM</a>) because I've got a problem, I can not break:</p>

<p>I have a set of <strong>Eular Angles</strong> and I need to perform <strong>smooth interpolation</strong> between them. The best way is converting them to <strong>Quaternions</strong> and applying <strong>SLERP</strong> alrogirthm.</p>

<p>The issue I have is how to <strong>initialize</strong> glm::quaternion with Euler Angles, please?</p>

<p>I read <a href=""http://glm.g-truc.net/api-0.9.2/index.html"">GLM Documentation</a> over and over, but I can not find appropriate <code>Quaternion constructor signature</code>, that would take three Eular Angles. The closest one I found is 
<a href=""http://glm.g-truc.net/api-0.9.0/a00184.html#a4412b01c376d9cfc9cc06b2d511d0f16"">angleAxis()</a> function, taking angle value and an axis for that angle. Note, please, what I am looking for si a way, how to parse <code>RotX, RotY, RotZ</code>.</p>

<hr>

<p>For your information, this is the above metnioned <a href=""http://glm.g-truc.net/api-0.9.1/a00279.html#ga4412b01c376d9cfc9cc06b2d511d0f16"">angleAxis()</a> <strong>function signature</strong>:</p>

<pre><code>detail::tquat&lt; valType &gt; angleAxis (valType const &amp;angle, valType const &amp;x, valType const &amp;y, valType const &amp;z)
</code></pre>
","<p>I'm not familiar with GLM, but in the absence of a function to directly convert from eular angles into quaternions, you can use the ""rotation around an axis"" functions (such as ""angleAxis"") to it yourself.</p>

<p>Here's how (pseudocode):</p>

<pre><code>Quaternion QuatAroundX = Quaternion( Vector3(1.0,0.0,0.0), EulerAngle.x );
Quaternion QuatAroundY = Quaternion( Vector3(0.0,1.0,0.0), EulerAngle.y );
Quaternion QuatAroundZ = Quaternion( Vector3(0.0,0.0,1.0), EulerAngle.z );
Quaternion finalOrientation = QuatAroundX * QuatAroundY * QuatAroundZ;
</code></pre>

<p>(Or you may need to switch those quaternion multiplies around, depending on the order in which your euler angle rotations are intended to be applied)</p>

<p>Alternately, from looking through GLM's documentation, it appears that you may be able to convert euler angles -> matrix3 -> quaternion like this:</p>

<pre><code>toQuat( orient3( EulerAngles ) )
</code></pre>
","13439"
"How to create adjustable formula for RPG level up requirements?","15980","","<p>I'm trying to create a formula that can be modified simply by changing two values: number_of_levels, and last_level_experience. This is to enable people modding the game to change the levelling requirements.</p>

<p>I've got it so that I can specify the number of XP needed for the last level up, but I want to be able to control the XP needed for the first level up, which in this case can differ wildly. For example, if I have 40 levels, and 1,000,000 XP for the last level, the first level up requirement is then 625. But if I change the levels to 80, the first  level up becomes 156. In both cases, the last level needs 1,000,000.</p>

<p>There must be some way to get the computer to work out a suitable curve given just these two basic values.</p>

<pre><code>#include &lt;iostream&gt;

int main()
{
    int levels = 40;
    if (levels &lt; 2) levels = 2;

    int experience_for_last_level = 1e6;
    float fraction = 1.0 / levels;

    {
        int i = 0;
        float fraction_counter = fraction;
        int counter = levels;
        int total = 0;

        for (i = 1; i &lt;= levels; ++i, fraction_counter += fraction, --counter)
        {
            int a = static_cast&lt;int&gt;(fraction_counter * experience_for_last_level / counter);

            std::cout &lt;&lt;""Level ""&lt;&lt;i&lt;&lt;"":  ""&lt;&lt;a&lt;&lt;"" (""&lt;&lt;counter&lt;&lt;"")""&lt;&lt;""\n"";

            total += a;
        }

        std::cout &lt;&lt; ""\nTotal Exp: "" &lt;&lt; total;
    }
}
</code></pre>

<p>Output:</p>

<pre><code>Level 1:  625   (40)      Level 15: 14423  (26)      Level 29: 60416  (12)
Level 2:  1282  (39)      Level 16: 16000  (25)      Level 30: 68181  (11)
Level 3:  1973  (38)      Level 17: 17708  (24)      Level 31: 77499  (10)
Level 4:  2702  (37)      Level 18: 19565  (23)      Level 32: 88888  (9)
Level 5:  3472  (36)      Level 19: 21590  (22)      Level 33: 103124 (8)
Level 6:  4285  (35)      Level 20: 23809  (21)      Level 34: 121428 (7)
Level 7:  5147  (34)      Level 21: 26250  (20)      Level 35: 145833 (6)
Level 8:  6060  (33)      Level 22: 28947  (19)      Level 36: 179999 (5)
Level 9:  7031  (32)      Level 23: 31944  (18)      Level 37: 231249 (4)
Level 10: 8064  (31)      Level 24: 35294  (17)      Level 38: 316666 (3)
Level 11: 9166  (30)      Level 25: 39062  (16)      Level 39: 487499 (2)
Level 12: 10344 (29)      Level 26: 43333  (15)      Level 40: 999999 (1)
Level 13: 11607 (28)      Level 27: 48214  (14)
Level 14: 12962 (27)      Level 28: 53846  (13)
</code></pre>
","<p>Though there are infinitely many ways to choose them, it is common for leveling curves to follow a <strong>power rule</strong> such as the following one:</p>

<pre><code>f(level) == A * exp(B * level)
</code></pre>

<p>The major advantage of this formula can be easily explained: for a given rule, there is a fixed value N such that <strong>each level costs N percent more than the previous one</strong>.</p>

<p>Your initial variables add the following restrictions:</p>

<pre><code>f(1) - f(0) == experience_for_first_level
f(levels) - f(levels - 1) == experience_for_last_level
</code></pre>

<p>Two equations, two unknowns. This looks good. Simple maths give <code>A</code> and <code>B</code>:</p>

<pre><code>B = log(experience_for_last_level / experience_for_first_level) / (levels - 1);
A = experience_for_first_level / (exp(B) - 1);
</code></pre>

<p>Resulting in the following code:</p>

<pre><code>#include &lt;cmath&gt;
#include &lt;iostream&gt;

int main(void)
{
    int levels = 40;
    int xp_for_first_level = 1000;
    int xp_for_last_level = 1000000;

    double B = log((double)xp_for_last_level / xp_for_first_level) / (levels - 1);
    double A = (double)xp_for_first_level / (exp(B) - 1.0);

    for (int i = 1; i &lt;= levels; i++)
    {
        int old_xp = round(A * exp(B * (i - 1)));
        int new_xp = round(A * exp(B * i));
        std::cout &lt;&lt; i &lt;&lt; "" "" &lt;&lt; (new_xp - old_xp) &lt;&lt; std::endl;
    }
}
</code></pre>

<p>And the following output:</p>

<pre><code>1 1000          9 4125          17 17012        25 70170        33 289427
2 1193          10 4924         18 20309        26 83768        34 345511
3 1425          11 5878         19 24245        27 100000       35 412462
4 1702          12 7017         20 28943        28 119378       36 492389
5 2031          13 8377         21 34551        29 142510       37 587801
6 2424          14 10000        22 41246        30 170125       38 701704
7 2894          15 11938        23 49239        31 203092       39 837678
8 3455          16 14251        24 58780        32 242446       40 1000000
</code></pre>
","20946"
"How do bullets work in video games?","15949","","<p>I came across this question when I was designing a video game in C#.</p>

<p>If we consider games such as <em>Battlefield</em> or <em>Call of Duty</em>, hundreds or even thousands of bullets are flying at the same time. Events are triggered constantly, and from what I know, this sucks a lot of processing power … or does it? I want to know how various game developers manage (2D and 3D) bullets and what the most efficient method for each is.</p>

<p>I read the question <a href=""https://gamedev.stackexchange.com/questions/13650/how-are-bullets-simulated-in-video-games"">How are bullets simulated in video games?</a> but it doesn't touch on how bullets work from a program design perspective.</p>

<p>I had a couple ideas, but each have their drawbacks:</p>

<hr>

<p>Most efficient method I could think of (for 2D games): </p>

<p>Say I was to create a class called Bullet, and for however long the user holds down a button, every 0.01 seconds a Bullet object would be made. This Bullet has:</p>

<ul>
<li><p><strong>1</strong> Velocity</p></li>
<li><p><strong>2</strong> Starting position of where it is being shot from</p></li>
<li><p><strong>3</strong> Sprite texture</p></li>
<li><p><strong>4</strong> An on-hit effect</p></li>
</ul>

<p>Since the bullet would be its own class, it could manage the drawing, moving, and action listeners itself.</p>

<p>Wouldn't it be hard on the processor to process thousands of these objects being instantiated, then destroyed (when on-hit effect is triggered)? RAM space?</p>

<hr>

<p>Efficient method for 3D games - Another thought I had was:</p>

<p>Lets say I create a weapon class. This weapon has various features, some of which:</p>

<ul>
<li><p><strong>1</strong> Detect where the weapon is aiming, and determine if it's looking at a target</p></li>
<li><p><strong>2</strong> Trigger an animation of the gun shooting</p></li>
<li><p><strong>3</strong> Has a doDamage() method that indicates something to subtract health from whatever the gun is pointed at</p></li>
<li><p><strong>4</strong> Notifies a bullet animation class when button pressed</p></li>
</ul>

<p>I could then create a static class, say BulletAnimation, that could get notification from where the gun that triggered it is, where that gun is pointed at (for the bullet destination), and information on an appropriate sprite and velocity to use for the bullet. This class then draws sprites (on a new thread maybe, idk) based on both positions and desired sprite, to simulate a bullet being fired from a gun.</p>

<hr>

<p>The latter seems much harder to code, and wouldn't it take lots of processing power to constantly call the static to do this for thousands of bullets at a time? Getting constant updates on both starting and ending positions would be hard as well.</p>

<p>My question is, what is the most efficient way game creators do it? Does this method change from 2D to 3D games?</p>
","<p>I can certainly see why you would think that it would be hard to simulate those, but there are enough constraints on bullets (all projectiles, really) to make them easier.  </p>

<ol>
<li><p>They are generally simulated as a single point, instead of as something with volume. This makes collision detection significantly easier, as now I only need to do collisions against very simple surfaces, such as a line against a circle. </p></li>
<li><p>We know how they will move, so there isn't much information we need to store or calculate for them. Your list was reasonably accurate, we'll generally have a few more things associated with it, like who shot the bullet, and what its type is.</p></li>
<li><p>Since all projectiles will be very similar, we can pre-allocate them, to avoid all the overhead of creating them dynamically. I can allocate an array of 1000 projectiles, and now they can be accessed with just an index, and they are all sequential in memory, so processing them will be quick.</p></li>
<li><p>They have a fixed lifetime/range, so I can expire old bullets and recycle the memory into new bullets very quickly.</p></li>
<li><p>Once they hit something, I can also expire them, so they have a finite lifetime.</p></li>
<li><p>Since we know when they were created, if we need new ones and we don't have any free in our pre-allocated list, I can just grab the oldest ones and recycle them, and people won't notice if bullets expire slightly early.</p></li>
<li><p>They are rendered as sprites (usually) or as low poly models, and take up very little space on screen, so they are fast to render.</p></li>
</ol>

<p>Taking all of those things into account, bullets tend to be relatively cheap. If our budget ever got consumed by bullets and rendering them, we'd generally just redesign it to limit the number of shots you can fire at a time (you'll see this in many old arcade games), use beam weapons that move instantly, or slow the fire rate down to make sure we stay within budget.</p>
","124739"
"How can I implement dialog trees into my game?","15904","","<p>What is the best way to implement a dialog tree system in my game? I want an NPC to give the player different sets of responses, some which may only appear when the Player has an item or a previous event has occurred.</p>
","<p>Dialog Trees should be done using XML. You store the conditions for the responses and the response in nested trees with a reference to a script file if you need to do something more complex.</p>

<p>You should keep the scripts and dialog separate especially if you are putting together an RPG which has a metric ton worth of conversations. You can then use a library like simpleXML to read the XML file.</p>

<p>There's a similar question over on SO with an example:
<a href=""https://stackoverflow.com/questions/372915/game-logic-in-xml-files"">https://stackoverflow.com/questions/372915/game-logic-in-xml-files</a></p>
","308"
"How do I pass vertex and color positions to OpenGL shaders?","15894","","<p>I've been trying to get this to work for the past two days, telling myself I wouldn't ask for help. I think you can see where that got me...</p>

<p>I thought I'd try my hand at a little OpenGL, because DirectX is complex and depressing. I picked OpenGL 3.x, because even with my OpenGL 4 graphics card, all my friends don't have that, and I like to let them use my programs. There aren't really any great tutorials for OpenGL 3, most are just ""type this and this will happen--the end"". </p>

<p>I'm trying to just draw a simple triangle, and so far, all I have is a blank screen with my clear color (when I set the draw type to GL_POINTS I just get a black dot). I have no idea what the problem is, so I'll just slap down the code:</p>

<p>Here is the function that creates the triangle:</p>

<pre><code>void CEntityRenderable::CreateBuffers()
{
    m_vertices = new Vertex3D[3];
    m_vertexCount = 3;

    m_vertices[0].x = -1.0f;
    m_vertices[0].y = -1.0f;
    m_vertices[0].z =  0.0f;
    m_vertices[0].r = 1.0f;
    m_vertices[0].g = 0.0f;
    m_vertices[0].b = 0.0f;
    m_vertices[0].a = 1.0f;

    m_vertices[1].x =  1.0f;
    m_vertices[1].y = -1.0f;
    m_vertices[1].z =  0.0f;
    m_vertices[1].r = 1.0f;
    m_vertices[1].g = 0.0f;
    m_vertices[1].b = 0.0f;
    m_vertices[1].a = 1.0f;

    m_vertices[2].x =  0.0f;
    m_vertices[2].y =  1.0f;
    m_vertices[2].z =  0.0f;
    m_vertices[2].r = 1.0f;
    m_vertices[2].g = 0.0f;
    m_vertices[2].b = 0.0f;
    m_vertices[2].a = 1.0f;

    //Create the VAO
    glGenVertexArrays(1, &amp;m_vaoID);
    //Bind the VAO
    glBindVertexArray(m_vaoID);

    //Create a vertex buffer
    glGenBuffers(1, &amp;m_vboID);
    //Bind the buffer
    glBindBuffer(GL_ARRAY_BUFFER, m_vboID);
    //Set the buffers data
    glBufferData(GL_ARRAY_BUFFER, sizeof(m_vertices), m_vertices, GL_STATIC_DRAW);
    //Set its usage
    glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, sizeof(Vertex3D), 0);
    glVertexAttribPointer(1, 4, GL_FLOAT, GL_FALSE, sizeof(Vertex3D), (void*)(3*sizeof(float)));

    //Enable
    glEnableVertexAttribArray(0);
    glEnableVertexAttribArray(1);
    //Check for errors
    if(glGetError() != GL_NO_ERROR)
    {
        Error(""Failed to create VBO: %s"", gluErrorString(glGetError()));
    }
    //Unbind...
    glBindVertexArray(0);
}
</code></pre>

<p>The Vertex3D struct is as such...</p>

<pre><code>struct Vertex3D
{
    Vertex3D() : x(0), y(0), z(0), r(0), g(0), b(0), a(1) {}

    float x, y, z;
    float r, g, b, a;
};
</code></pre>

<p>And finally the render function:</p>

<pre><code>void CEntityRenderable::RenderEntity()
{
    //Render...
    glBindVertexArray(m_vaoID);
    //Use our attribs

    glDrawArrays(GL_POINTS, 0, m_vertexCount);

    glBindVertexArray(0); //unbind
    OnRender();
}
</code></pre>

<p>(And yes, I am binding and unbinding the shader. That is just in a different place)
I think my problem is that I haven't fully wrapped my mind around this whole VertexAttribArray thing (the only thing I like better in DirectX was input layouts D:).</p>

<p>This is my vertex shader:</p>

<pre><code>#version 330

//Matrices
uniform mat4 projectionMatrix;
uniform mat4 viewMatrix;
uniform mat4 modelMatrix;
//In values
layout(location = 0) in vec3 position;
layout(location = 1) in vec4 color;
//Out values
out vec4 frag_color;
//Main shader
void main(void)
{
    //Position in world
    gl_Position = vec4(position, 1.0);
    //gl_Position = projectionMatrix * viewMatrix * modelMatrix * vec4(in_Position, 1.0);
    //No color changes
    frag_color = color;
}
</code></pre>

<p>Here is the fragment shader:</p>

<pre><code>#version 330
//In values
in vec4 frag_color;
//Out values
out vec4 out_color;
//main shader
void main(void)
{
    out_color = frag_color;
}
</code></pre>

<p>As you can see, I've disable the matrices, because that just makes debugging this thing so much harder. I tried to debug using glslDevil, but my program just crashes right before the shaders are created... so I gave up with that. This is my first shot at OpenGL since the good old days of LWJGL, but that was when I didn't even know what a shader was. Thanks for your help :)</p>

<p>I'd also like to add this, I only saw it in one tutorial:</p>

<pre><code>m_defaultShader-&gt;BindAttrib(0, ""position"");
m_defaultShader-&gt;BindAttrib(1, ""color"");
</code></pre>

<p>BindAttrib looks like this:</p>

<pre><code>void IShader::BindAttrib(int index, char* name)
{
    glBindAttribLocation(m_shaderProgram, index, name);
}
</code></pre>

<p>I thought maybe that may be an issue</p>
","<h3>Nitpicks</h3>

<p>Things that aren't actually your problem but you should correct anyway.</p>

<p>First, <code>Vertex3D</code> is not a POD, by the <a href=""https://stackoverflow.com/a/4178176/734069"">C++03 rules defining POD structs</a>. As such, C++03 offers no guarantees of the layout of such a struct, so you can't just shove it into OpenGL.</p>

<p>Now, that being said, your struct will likely work. Most compilers will provide the expected layout for this struct. And <a href=""https://stackoverflow.com/a/7189821/734069"">C++11 extends the rules of layout</a> such that this struct <em>is</em> guaranteed to have the expected layout.</p>

<p>Next, <code>m_vertices = new Vertex3D[3];</code>. I don't see a <code>delete[]</code> anywhere. Now yes, <code>m_vertices</code> is likely a member variable, but there's no reason to keep this array around. What happens if someone calls <code>CreateBuffers</code> twice?</p>

<p>Indeed, there's no reason to use a naked array at all. Use a <code>std::vector&lt;Vertex3D&gt;</code> instead. That way, it'll be properly scoped and everything; you won't have to worry about when it goes away.</p>

<p>Next:</p>

<pre><code>glVertexAttribPointer(1, 4, GL_FLOAT, GL_TRUE,  sizeof(Vertex3D), (void*)(3*sizeof(float)));
</code></pre>

<p>There is no such thing as a normalized <em>float</em>. Normalization specifies how <em>integer</em> values are interpreted as floats. The byte value 255, when interpreted as a normalized unsigned byte, will become 1.0f. When interpreted as a non-normalized unsigned byte, it will be 255.0f.</p>

<p>This won't actually cause an error; it'll just be ignored because it makes no sense. But you still shouldn't do it.</p>

<h3>Actual Problems</h3>

<p>Things that are actual problems, but may not be your <em>real</em> problem.</p>

<pre><code>glBufferData(GL_ARRAY_BUFFER, sizeof(m_vertices), m_vertices, GL_STATIC_DRAW);
</code></pre>

<p>That doesn't do what you think it does. <code>m_vertices</code> is a <code>Vertex3D*</code>. Therefore, <code>sizeof(m_vertices)</code> is... 4. Or 8 if you're compiling in 64-bit mode.</p>

<p>You probably wanted the size of the array. This is yet another reason to use <code>std::vector</code>; it's much easier to compute. In that it's actually <em>possible</em> to compute it ;)</p>

<pre><code>glBufferData(GL_ARRAY_BUFFER, m_vertices.size() * sizeof(Vertex3D), &amp;m_vertices[0], GL_STATIC_DRAW);
</code></pre>

<h3>Your Code Problem</h3>

<p>Your Code Problem</p>

<p>This is your vertex position data:</p>

<pre><code>m_vertices[0].x = -1.0f;
m_vertices[0].y = -1.0f;
m_vertices[0].z = -5.0f;
m_vertices[1].x =  1.0f;
m_vertices[1].y = -1.0f;
m_vertices[1].z = -5.0f;
m_vertices[2].x =  0.0f;
m_vertices[2].y =  1.0f;
m_vertices[2].z = -5.0f;
</code></pre>

<p>Notice that all of the Z values are at -5.0f. Since you are using no matrix transforms, this means that the clip-space vertices that you get will be at -5.0f in the Z direction.</p>

<p>Clip-space (or to be technical, Normalized Device Coordinate space) only extends from [-1, 1] in all directions. That includes Z. Your -5.0f Z coordinate places your vertex positions <em>outside</em> of the world.</p>

<p>I would suggest 0.0f for the Z.</p>

<h3>Your Real Problem</h3>

<p>Your Real Problem</p>

<p>It's this:</p>

<blockquote>
  <p>I'd also like to add this, I only saw it in one tutorial:</p>
</blockquote>

<p>The thought behind you making this statement is the source of your problem. You aren't coding; you're copying and pasting bits of code extracted from various online sources.</p>

<p>If you understood what, for example, OpenGLBook.com, was saying about <code>layout(location)</code>, and then read what another tutorial was saying that <code>glBindAttribLocation</code> does, then you would quickly realize that they <em>both set the same thing</em>. There's no sense in using both of them for the same shader. It's like having a getter for a <em>public</em> variable; there's no point to it and it only ends up confusing the user.</p>

<p>You should <em>never</em> do anything just because you ""saw it in one tutorial"". You use it because you <em>understand</em> what it does and see a need to do that in your application.</p>

<p>I would say that you have a strong case of ""I want to do X""itus. This is a common disease found among many programmers who are new to something. They see something and want to perform some specific task. So they go online and find information. But since none of that information tells them how to do <em>exactly</em> what they want to do, they just find bits of code and copy them into their code, building up a Frankenstein's Monster of an application.</p>

<p>It may <em>live</em>, but it's not the most pleasant form of life.</p>

<p>For example, I have <a href=""http://alfonse.bitbucket.org/oldtut/"" rel=""nofollow noreferrer"">my own series of GL 3.3 tutorials</a>. I think they're pretty decent. But they will not teach you how to write exactly what you're writing. If you try to copy and paste from them, you won't get anything more useful than you'll get from other tutorials.</p>

<p>But if you <em>read</em> them, then they will try to teach you how to be a graphics programmer. The first three chapters covers most of the mistakes and problems your codebase has. It explains about Normalized Device Coordinate space and the extents thereof. It explains how to use <code>glBufferData</code> (though it's still up to you to pass in the correct size). It doesn't explain normalized attributes, but that's because it sticks with floats; it says to leave it as <code>GL_FALSE</code>.</p>

<p>To put it another way, forget about what you <em>want</em> to learn from any tutorial. Simply learn whatever lesson it is intending to teach you. Once you understand the material, you don't need to copy their code at all; you can just write it yourself.</p>
","27415"
"Unity 5: Error when everything is okay(Object reference not set to an instance of an object)","15866","","<p>i'm getting this error when the collider colides with something:</p>

<p>Object reference not set to an instance of an object</p>

<p>It's referencing to the gamecont.Death(); from this script:
<img src=""https://i.stack.imgur.com/Th5rl.png"" alt=""obstacle collider script""></p>

<p>and the death method is on this one:</p>

<p><img src=""https://i.stack.imgur.com/ABWLz.png"" alt=""death script""></p>
","<p>I changed:</p>

<p>gameCont = GetComponent();</p>

<p>to:</p>

<p>gameCont = GameObject.FindObjectOfType();</p>

<p>and worked!</p>
","98312"
"Realistic Camera/Screen Shake from Explosion","15818","","<p>I'd like to shake the camera around a bit during an explosion, and I've tried a few different functions for rocking it around, and nothing seems to really give that 'wow, what a bang!' type feeling that I'm looking for. I've tried some arbitrary relatively high frequency sine wave patterns with a bit of linear attenuation, as well as a square wave-type pattern. I've tried moving just one axis, two, and all three (although the dolly effect was barely noticeable in that case).</p>

<p>Does anyone know of a good camera shaking pattern?</p>
","<p>I've got decent camera shake by applying Perlin noise to the camera's orientation. It gives you a decent big jolt with higher frequency shaking built in, and can look really good.</p>

<p><a href=""http://mrl.nyu.edu/~perlin/doc/oscar.html"">http://mrl.nyu.edu/~perlin/doc/oscar.html</a> has more details and sample code for generating noise.</p>
","1831"
"Creating a countdown Timer in Unity","15758","","<p>I want to create a countdown timer in a Unity game I am creating. Up until now my game was running for a specific time but I was using <code>InvokeRepeating</code> to end the game after the set time.</p>

<p>But now I want to display the time left in a GUI text. One approach could be to use <code>InvokeRepeating</code> again but this time call it every second to decrement the timer. With this approach though it would mean do extra calculations for when a minute passes in order to display time appropriately and not just display the whole time in seconds.</p>

<p>Is there a different approach? Does Unity have any timers built in?
Also which is the more efficient method?</p>
","<p>Alternatively, you could use System.Timers.Timer which is probably the most performant of any solution. The following example shows a countdown for 100 seconds.</p>

<pre><code>System.Timers.Timer LeTimer;
int BoomDown = 100;
void Start ()
{
    //Initialize timer with 1 second intervals
    LeTimer = new System.Timers.Timer (1000);
    LeTimer.Elapsed +=
        //This function decreases BoomDown every second
        (object sender, System.Timers.ElapsedEventArgs e) =&gt; BoomDown--;
}

void Update ()
{
    //When BoomDown reaches 0, BOOM!
    if (BoomDown &lt;= 0)
        Debug.Log (""Boom!"");
}
</code></pre>
","101036"
"What's the difference between displacement mapping and height mapping?","15722","","<p>What's the difference between displacement mapping and height mapping and what is the connection to adaptive tessellation?</p>
","<p>Displacement mapping and height mapping are two names for ""almost"" the same technique, they aim to do the same effect but <strong>are used in different contexts.</strong></p>

<p>To explain more:</p>

<p><strong>Displacement Mapping:</strong> Is a technique that aims to render bumps as true geometry, in a very fine mesh. Unlike bump mapping, parallax, and relief mapping which tries to ""fake"" bumps using normal maps, Displacement mapping actually displaces the surface, creating triangles between the texels. .</p>

<p><strong>Height Mapping:</strong> is the same thing, but it's usually used in the context where a  displacement map  (also called height map) is applied on a terrain where the value are only used to modify the vertex height.</p>

<p><strong>It can be implemented on the CPU or the GPU.</strong> </p>

<p><strong>One common CPU approach</strong> is to read height or displacement values from a height/displacement map(texture) where each texel directly maps to one vertex. Where each texel encodes a height/displacement value. This is then applied directly to the geometry by displacing each vertex using the looked up value in a unique direction.</p>

<p>Choosing the direction can be in the Up direction (usually in case of terrains), which results in modifying the vertex Y value, or could be in the direction of the face normal usually used on objects other than terrains.</p>

<p><strong>A GPU alternative</strong> is to use the vertex texture fetch feature (introduced in Shader Model 3.0) to have a the terrain mesh modified by accessing a displacement/height map  The height retrieved from the texture is used by the vertex shading program to modify the vertex's 
location. </p>

<p>Other uses for Using a texture allows for <em>faster manipulation of data for wave simulations and other animations to apply to the mesh.</em></p>

<p>Regarding adaptive tessellation:</p>

<p>One draw back of displacement mapping is that for large terrains you need a lot of polygons and vertices to model a detailed terrain which makes displacement maping somehow inefficient for large terrains.</p>

<p>This is where adaptive tessellation and level of detail techniques come to play to make displacement mapping more feasible, especially with the advancement of the GPUs and introducing geometry shaders, performing tessellation on the fly with this advancement has become the dominant technique. It is simple to program and on newer GPUs and has few drawbacks.</p>

<p>Other techniques like relief and bump mapping offer additional realism at a 
generally reasonable cost, but the fact that the base surface is unperturbed makes collision detection, and therefore object interaction, more challenging.</p>

<p>As a conclusion Displacement mapping and adaptive tessellation brings superior detail and quality with less draw backs at a feasible performance cost.</p>
","65762"
"ResolutionException: Cannot find candidate artifact for com.google.android.gms:play-services-games:8.1+","15712","","<p>Getting this error:</p>

<blockquote>
  <p>ResolutionException: Cannot find candidate artifact for
  com.google.android.gms:play-services-games:8.1+
  Google.JarResolver.PlayServicesSupport.DependOn (System.String group,
  System.String artifact, System.String version)
  GooglePlayGames.BackgroundResolution.AddDependencies () (at
  Assets/GooglePlayGames/Editor/BackgroundResolution.cs:53)
  GooglePlayGames.BackgroundResolution..cctor () (at
  Assets/GooglePlayGames/Editor/BackgroundResolution.cs:45) Rethrow as
  TypeInitializationException: An exception was thrown by the type
  initializer for GooglePlayGames.BackgroundResolution
  System.Runtime.CompilerServices.RuntimeHelpers.RunClassConstructor
  (RuntimeTypeHandle type) (at
  /Users/builduser/buildslave/mono-runtime-and-classlibs/build/mcs/class/corlib/System.Runtime.CompilerServices/RuntimeHelpers.cs:101)
  UnityEditor.EditorAssemblies.ProcessEditorInitializeOnLoad
  (System.Type type) (at
  C:/buildslave/unity/build/Editor/Mono/EditorAssemblies.cs:123) Rethrow
  as TargetInvocationException: Exception has been thrown by the target
  of an invocation. System.Reflection.MonoCMethod.Invoke (System.Object
  obj, BindingFlags invokeAttr, System.Reflection.Binder binder,
  System.Object[] parameters, System.Globalization.CultureInfo culture)
  (at
  /Users/builduser/buildslave/mono-runtime-and-classlibs/build/mcs/class/corlib/System.Reflection/MonoMethod.cs:519) System.Reflection.MonoCMethod.Invoke (BindingFlags invokeAttr,
  System.Reflection.Binder binder, System.Object[] parameters,
  System.Globalization.CultureInfo culture) (at
  /Users/builduser/buildslave/mono-runtime-and-classlibs/build/mcs/class/corlib/System.Reflection/MonoMethod.cs:528) System.Reflection.ConstructorInfo.Invoke (System.Object[] parameters)
  (at
  /Users/builduser/buildslave/mono-runtime-and-classlibs/build/mcs/class/corlib/System.Reflection/ConstructorInfo.cs:77)
  System.Activator.CreateInstance (System.Type type, Boolean nonPublic)
  (at
  /Users/builduser/buildslave/mono-runtime-and-classlibs/build/mcs/class/corlib/System/Activator.cs:372) System.Activator.CreateInstance (System.Type type) (at
  /Users/builduser/buildslave/mono-runtime-and-classlibs/build/mcs/class/corlib/System/Activator.cs:254) UnityEditor.AssetPostprocessingInternal.GetMeshProcessorVersions ()
  (at C:/buildslave/unity/build/Editor/Mono/AssetPostprocessor.cs:145)
  UnityEditor.AssetPostprocessingInternal:GetMeshProcessorVersions()</p>
</blockquote>

<p>How to solve this?</p>
","<p>Open SDK manager and make sure you have the latest versions of following packages:</p>

<ol>
<li>Extras / Android Support Repository </li>
<li>Extras / Google Repository</li>
</ol>

<p>This solved the problem for me.</p>
","111299"
"Loading PNG textures for use in Android OpenGL ES1","15704","","<p>I'm very new to Android and OpenGL coding (I have previously used ogre3d).  I am trying to find an efficient way to load PNG textures.  It is currently taking around 8 secs to load 3 512x512 textures on a fairly fast phone (Motorola Defy)</p>

<p>There seems to be a problem with the texture being upside-down (I used a Matrix to flip it below).  Secondly, the order of the colour channels are incompatible, therefore each pixel needs changed.  This (I believe) is the cause of the slowness, is there a way to make the BitmapFactory load it in a channel order that is compatible with opengl?   Is there a better approach here?</p>

<p>Here is the code: -</p>

<pre><code>// Will load a texture out of a drawable resource file, and return an OpenGL texture ID:
private int loadTexture(GL10 gl, Context context, int resource, boolean loadMipMaps) {
    // We need to flip the textures vertically:
    Matrix flip = new Matrix();
    flip.postScale(1f, -1f);

    // This will tell the BitmapFactory to not scale based on the device's pixel density:
    BitmapFactory.Options opts = new BitmapFactory.Options();
    opts.inScaled = false;

    // Load up, and flip the texture:
    Bitmap temp = BitmapFactory.decodeResource(context.getResources(), resource, opts);
    Bitmap bmp = Bitmap.createBitmap(temp, 0, 0, temp.getWidth(), temp.getHeight(), flip, true);
    temp.recycle();

    int id = loadTextureFromBmp(gl,bmp, true);

    bmp.recycle();

    return id;
}

protected static int loadTextureFromBmp(GL10 gl, Bitmap bmp, boolean reverseRGB) {
    ByteBuffer bb = ByteBuffer.allocateDirect(bmp.getHeight()*bmp.getWidth()*4);
    bb.order(ByteOrder.nativeOrder());
    IntBuffer ib = bb.asIntBuffer();


    for (int y=bmp.getHeight()-1;y&gt;-1;y--)
            for (int x=0;x&lt;bmp.getWidth();x++) {
                    if (reverseRGB) {
                            int px = bmp.getPixel(x,y);
                            int alpha = (px &amp; 0xFF000000) &gt;&gt; 24;
                            int red = (px &amp; 0xFF0000)&gt;&gt;16;
                            int green = (px &amp; 0xFF00)&gt;&gt;8;
                            int blue = (px &amp; 0xFF);
                            ib.put((alpha &lt;&lt; 24) | (blue &lt;&lt; 16) | (green&lt;&lt;8) | (red));
                            //ib.put(Integer.reverseBytes(bmp.getPixel(x, y)));
                    }
                    else {
                            ib.put(bmp.getPixel(x,y));
                    }
            }
    ib.position(0);
    bb.position(0);

    int[] tmp_tex = new int[1];

    gl.glGenTextures(1, tmp_tex, 0);
    int tex = tmp_tex[0];
    gl.glBindTexture(GL10.GL_TEXTURE_2D, tex);
    gl.glTexImage2D(GL10.GL_TEXTURE_2D, 0, GL10.GL_RGBA, bmp.getWidth(), bmp.getHeight(), 0, GL10.GL_RGBA, GL10.GL_UNSIGNED_BYTE, bb);
    gl.glTexParameterf(GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_MIN_FILTER, GL10.GL_LINEAR);
    gl.glTexParameterf(GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_MAG_FILTER, GL10.GL_LINEAR);

    return tex;
</code></pre>

<p>}</p>
","<p>Here's my code to load from a bitmap, which doesn't suffer from the same problems you describe, and looks  like it will accomplish the same thing:</p>

<pre><code>/**
 * Helper method to load a GL texture from a bitmap
 *
 * Note that the caller should ""recycle"" the bitmap
 *
 * @return the ID of the texture returned from glGenTextures()
 */
public static int loadGLTextureFromBitmap( Bitmap bitmap, GL10 gl ) {

    // Generate one texture pointer
    int[] textureIds = new int[1];
    gl.glGenTextures( 1, textureIds, 0 );

    // bind this texture
    gl.glBindTexture( GL10.GL_TEXTURE_2D, textureIds[0] );

    // Create Nearest Filtered Texture
    gl.glTexParameterf( GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_MIN_FILTER, GL10.GL_LINEAR );
    gl.glTexParameterf( GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_MAG_FILTER, GL10.GL_LINEAR );

    gl.glTexParameterf( GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_WRAP_S, GL10.GL_REPEAT );
    gl.glTexParameterf( GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_WRAP_T, GL10.GL_REPEAT );

    // Use the Android GLUtils to specify a two-dimensional texture image from our bitmap
    GLUtils.texImage2D( GL10.GL_TEXTURE_2D, 0, bitmap, 0 );

    return textureIds[0];
}
</code></pre>

<p>and to load from a resource, I call it via this method (i have another similar method that will create a bitmap from a file):</p>

<pre><code>/**
 * Create a texture from a given resource
 * 
 * @param resourceID the ID of the resource to be loaded
 * @param scaleToPO2 determines whether the image should be scaled up to the next highest power
 * of two, or whether it should be ""inset"" into such an image. Having textures that are
 * dimensions of some power-of-two is critical for performance in opengl.
 *
 * @return the ID of the texture returned from glGenTextures()
 */
public static int loadGLTextureFromResource( int resourceID, Context context, boolean scaleToPO2 ) {

    // pull in the resource
    Bitmap bitmap = null;
    Resources resources = context.getResources();

    Drawable image = resources.getDrawable( resourceID );
    float density = resources.getDisplayMetrics().density;

    int originalWidth = (int)(image.getIntrinsicWidth() / density);
    int originalHeight = (int)(image.getIntrinsicHeight() / density);

    int powWidth = getNextHighestPO2( originalWidth );
    int powHeight = getNextHighestPO2( originalHeight );

    if ( scaleToPO2 ) {
        image.setBounds( 0, 0, powWidth, powHeight );
    } else {
        image.setBounds( 0, 0, originalWidth, originalHeight );
    }

    // Create an empty, mutable bitmap
    bitmap = Bitmap.createBitmap( powWidth, powHeight, Bitmap.Config.ARGB_4444 );
    // get a canvas to paint over the bitmap
    Canvas canvas = new Canvas( bitmap );
    bitmap.eraseColor(0);

    image.draw( canvas ); // draw the image onto our bitmap

    int textureId = loadGLTextureFromBitmap( bitmap );

    bitmap.recycle();

    return textureId;
}
</code></pre>

<p>and lastly, here's a utility to get the next-highest-power-of-two:</p>

<pre><code>/**
 * Calculates the next highest power of two for a given integer.
 *
 * @param n the number
 * @return a power of two equal to or higher than n
 */
public static int getNextHighestPO2( int n ) {
    n -= 1;
    n = n | (n &gt;&gt; 1);
    n = n | (n &gt;&gt; 2);
    n = n | (n &gt;&gt; 4);
    n = n | (n &gt;&gt; 8);
    n = n | (n &gt;&gt; 16);
    n = n | (n &gt;&gt; 32);
    return n + 1;
}
</code></pre>
","10831"
"Best solution for multiplayer realtime Android game","15634","","<p>I plan to make multiplayer realtime game for Android (2-8 players), and I consider, which solution for multiplayer organization is the best:</p>

<ol>
<li><p>Make server on PC, and client on mobile, all communition go through server ( ClientA -> PC SERVER -> All Clients )</p></li>
<li><p>Use bluetooth, I don't used yet, and I don't know is it hard to make multiplayer on bluetooth</p></li>
<li><p>Make server on one of devices, and other devices connect ( through network, but I don't know is it hard to resolve problem with devices over NAT ? )</p></li>
<li><p>Other solution ?</p></li>
</ol>
","<p>Disclaimer; I haven't done <em>much</em> with java and the android platform.</p>

<p>However my more extensive experience with the '.net' languages on the windows mobile platforms, along with the windows platform, is that a good 75-90% of all the code required to create and maintain a Bluetooth or network data connection are maintained/supported with the OS or the libraries that would be need to access the hardware.</p>

<p>So far this also seems true with Android, with the OS exposing methods for creating data connections over Bluetooth or the internet, along with enabling/disabling the respective hardware.</p>

<p>I would imagine that Bluetooth would be the preferred method of connection, as this would be the least expensive to implement (No servers). And allow for a more local gathering/game. Bluetooth is fairly easy as to use. it functions similar to normal network sockets once you know which device you want to connect to.</p>

<p>The others are are correct in that Bluetooth v2.0/v2.1 is not currently capable of support large data loads. This will change with the eventual spread of v3.0 and higher. and there are ways of getting around this limitation.</p>

<p>For now though there is a simple concept, yet complex solution, which you may wish to try. I have been using it for awhile, It is similar to peer to peer, but it involves having the game hosted on all the devices simultaneously. That way if a connection is temporarily lost, slowed, or a player is dropped for any reason, other players will not be affected. This allows users that have been dropped to rejoin the ongoing game with little or no disruption to other players or their own game.</p>

<p><strong>CON:</strong> Each player would actually be playing their own somewhat unique instance of the game, that would be linked with the other players to keep the games from straying too far out of sync with each other.</p>

<p><strong>CON:</strong> The supporting code <em>can be</em> extensive/complex and difficult to wrap your head around depending on what you want to achieve.</p>

<p><strong>PRO:</strong> No central server or device required! No $$$ upkeep required.</p>

<p><strong>PRO:</strong> A heavy exchange of data would only occur when a player (re)joined, or a game was initialized. - Even this can be reduced by ensuring that all the games are going to be generated, and progress the same way by all the players. <strong>POTENTIALLY</strong> reducing energy consumption that occurs due to heavy network usage.</p>

<p><strong>PRO:</strong> Data becomes less time sensitive, as the devices would already have all the data they require to keep a game going without the other players. Allowing <em>you</em> to focus more on the actual game experience for the individual users, rather than a group of players.</p>

<p>I have lacked the time to implement a full in-depth game engine that utilizes this. The games I've made have been limited to recreating games similar to Monopoly, and Uno, which seemed to function extremely well.</p>

<p>The easiest was the one that emulated Uno. I essentially stacked the decks of the losers after a player won as to ensure that player won all the games. 95%+ of the time I couldn’t tell that I wasn’t playing the exact same game as everyone else.</p>

<p>I started building a game similar to Master of Orion II, but the game itself was a little much for me to undertake by myself.</p>
","19814"
"What version of OpenGL should I code for, given compatibility and performance considerations?","15561","","<p>When the OpenGL spec is updated, they only ever add features. So in theory, the latest and greatest hardware with support for the Core and Compatibility profiles should run super old OpenGL1.1 code just fine. This has turned out to be true. I've spent 12 months learning OpenGL1.1 and have a fair grasp on it.</p>

<p>I had a read of a few chapters of one of those fancy new OpenGL4.2 books. Almost all of the features that I rely on have been deprecated (like Display Lists), which lets me assume that there are better ways of doing all these things.</p>

<p>Lets consider that 1.1 is likely to be supported, in full, by ALL modern hardware. 1.1 was released in 1992. I'm not coding the hard way <strong><em>just</em></strong> to support 20 year old PCs. :-p I think its reasonable to assume most gamers are running hardware that bottoms out at about 5-year old mid range.</p>

<p>I think the newer methods are designed to universally be either one of two things: better performing, or easier to code. I read somewhere that its never both though! XD</p>

<p><strong>What version of OpenGL is most widely supported by ~5ish year old hardware? What version makes most sense to use, given these considerations?</strong></p>
","<p>Given your considerations, I then popped over to see when OpenGL specs for each version was released and also factored in some overall insight from what I've seen.</p>

<p>OpenGL 3, which introduced FBOs, VAOs and other things, was released in July 11, 2008, almost 5 years ago. Of course, you can't expect all cards after that date to immediately to have OpenGL 3 available. </p>

<p>Taking a look at the <a href=""http://store.steampowered.com/hwsurvey"">Steam Hardware Survey</a>, 40% are DirectX 10. As OpenGL 3 required a similar graphics card, it is generally safe to assume most DirectX 10 cards can run at least OpenGL 3. </p>

<p>OpenGL 3 is supported on cards all way back to GeForce 8xxx series, which were pretty popular if I recall correctly. Also interesting to note is that Intel HD 2000 and 3000 Graphics (Sandy bridge) only support up to OpenGL 3, so keep that in mind if you plan to target those.</p>

<p>Conclusion: OpenGL 3 is a good bet (also remember that most gamers, depending on your target audience, will probably have better hardware than average). </p>
","25506"
"Tips and Tools for creating Spritesheet animations","15552","","<p>I am looking for a tool that I can use to create sprite sheet easily. </p>

<p>Right now I am using Illustrator, but I can never get the center of the character in the exact position, so it looks like it is moving around(even though its always in one place), while being loop through the sprite sheet.  Is there any better tools that I can be using?</p>

<p>Also what kind of tips would you give for working with a sprite sheet?  Should I create each part of the character in individual layers (left arm, right arm, body, etc.) or everything at once?  any other tips would also be helpful! thank you</p>
","<p>From the problems that you are having I recommend that you do the following:</p>

<p>First, work with layers and folders. It really does help, Group individual sprites together in folders so that you can move the whole of them around and parts that are replicated should exist on seperate layers.</p>

<p>(So if there is a sword or something it should be on a layer, eyes should be on a layer, etc). Thats where the real power of these type of applications are for such a task. If you mess something up, you don't mess it all up just that layer.</p>

<p>Then, enable the ruler and enable the grid. (Also take the time to set them up correctly in the preferences menu). If click the ruler and drag away from it, you can create guidelines. Setting up your own limits using the guidelines will allow you to snap the sprites (which should now be in folders) to the grid lines allowing you to position them far better.</p>

<p>Then finally, if things still seem a bit out of phase when the animation is playing. If you zoom all the way in (you may need to make sure this is enabled in the preferences menu) you can see an individual per-pixel grid. Which should allow you to place things exactly where you need them to be.</p>
","4391"
"Input management techniques in large games","15498","","<p>Is there a standard technique for managing input in large games. Currently, in my project, all input handling is done in the game loop, like so: </p>

<pre><code>while(SDL_PollEvent(&amp;event)){
            switch(event.type){
                case SDL_QUIT:
                    exit = 1;
                    break;
                case SDL_KEYDOWN:
                    switch(event.key.keysym.sym){
                        case SDLK_c:
                            //do stuff
                            break;
                    }
                    break;
                case SDL_MOUSEBUTTONDOWN:
                    switch(event.button.button){
                        case SDL_BUTTON_MIDDLE:
                                //do stuff
                                break;
                            }
                    }
                    break;
            }
</code></pre>

<p>(I am using SDL, but I expect the main practice applies libraries and frameworks as well). For a large project this doesn't seem the best solution. I may have several objects all  wanting to know what the user has pressed, so it would make more sense for those objects to handle input. However, they can't all be handling input, as after one gets an event, it will be pushed off the event buffer, so another object won't receive that input. What method is most commonly used to counteract this?</p>
","<p>Since asked by the thread starter, I elaborate on event managers. I think this is a good way to handle input in a game.</p>

<p>An event manager is a global class which allows to both register callback functions to keys and to fire off those callbacks. The event manager stores registered functions in a private list grouped by their key. Each time a key gets fired, all registered callbacks are executed.</p>

<p>The callbacks could be <code>std::function</code> objects which can hold lambdas. The keys could be strings. Since the manager is global, components of your application can register to keys fired from other components.</p>

<pre><code>// in character controller
// at initialization time
Events-&gt;Register(""Jump"", [=]{
    // perform the movement
});

// in input controller
// inside the game loop
// note that I took the code structure from the question
case SDL_KEYDOWN:
    switch(event.key.keysym.sym) {
    case SDLK_c:
        Events-&gt;Fire(""Jump"");
        break;
    }
    break;
</code></pre>

<p>You could even extend this event manager to allow passing values as additional arguments. C++ templates are great for this. You could use such a system to, say, for a <code>""WindowResize""</code> event pass the new window size, so that listening components don't need to fetch it themselves. This can reduce code dependencies quite a bit.</p>

<pre><code>Events-&gt;Register&lt;int&gt;(""LevelUp"", [=](int NewLevel){ ... });
</code></pre>

<p>I've implemented such an event manger for my game. If you are interested, I'll post the link to the code here.</p>

<p>Using an event manager, you can easily broadcast input information within your application. Moreover, this allows for a nice way to let the user customize key bindings. Components listen to semantic events instead of keys directly (<code>""PlayerJump""</code> instead of <code>""KeyPressedSpace""</code>). Then you can have an input mapping component that listens for <code>""KeyPressedSpace""</code> and triggers whatever action the user bound to that key.</p>
","59627"
"Using component based entity system practically","15464","","<p>Yesterday, I've read a presentation from GDC Canada about Attribute / Behaviour entity system and I think it's pretty great. However, I'm not sure how to use it practially, not just in theory. First of all, I'll quickly explain you how this system works.</p>

<hr>

<p>Each game entity (game object) is composed of <strong>attributes</strong> (= data, which can be accessed by behaviours, but also by 'external code') and <strong>behaviours</strong> (= logic, which contain <code>OnUpdate()</code> and <code>OnMessage()</code>). So, for example, in a Breakout clone, each brick would be composed of (example!): <em>PositionAttribute</em>, <em>ColorAttribute</em>, <em>HealthAttribute</em>, <em>RenderableBehaviour</em>, <em>HitBehaviour</em>. The last one could look like this (it's just a non-working example written in C#):</p>

<pre><code>void OnMessage(Message m)
{
    if (m is CollisionMessage) // CollisionMessage is inherited from Message
    {
        Entity otherEntity = m.CollidedWith; // Entity CollisionMessage.CollidedWith
        if (otherEntity.Type = EntityType.Ball) // Collided with ball
        {
            int brickHealth = GetAttribute&lt;int&gt;(Attribute.Health); // owner's attribute
            brickHealth -= otherEntity.GetAttribute&lt;int&gt;(Attribute.DamageImpact);
            SetAttribute&lt;int&gt;(Attribute.Health, brickHealth); // owner's attribute

            // If health is &lt;= 0, ""destroy"" the brick
            if (brickHealth &lt;= 0)
                SetAttribute&lt;bool&gt;(Attribute.Alive, false);
        }
    }
    else if (m is AttributeChangedMessage) // Some attribute has been changed 'externally'
    {
        if (m.Attribute == Attribute.Health)
        {
            // If health is &lt;= 0, ""destroy"" the brick
            if (brickHealth &lt;= 0)
                SetAttribute&lt;bool&gt;(Attribute.Alive, false);
        }
    }
}
</code></pre>

<p>If you're interested in this system, you can read more <a href=""http://www.gdcvault.com/play/1911/Theory-and-Practice-of-the"">here</a> (.ppt).</p>

<hr>

<p>My question is related to this system, but generally every component based entity system. I've never seen how any of these really work in real computer games, because I can't find any good examples and if I find one, it's not documented, there are no comments and so I don't understand it.</p>

<p>So, what do I want to ask? How to design the behaviours (components). I've read here, on GameDev SE, that the most common mistake is to make many components and simply, ""make everything a component"". I've read that it's suggested to not do the rendering in a component, but do it outside of it (so instead of <em>RenderableBehaviour</em>, it should maybe be <em>RenderableAttribute</em>, and if an entity has <em>RenderableAttribute</em> set to true, then <code>Renderer</code> (class not related to components, but to the engine itself) should draw it on screen?).</p>

<p>But, how about the behaviours / components? Let's say that I've got a level, and in the level, there's a <code>Entity button</code>, <code>Entity doors</code> and <code>Entity player</code>. When player collides with the button (it's a floor button, which is toggled by pressure), it's pressed. When the button gets pressed, it opens the doors. Well, now how to do it?</p>

<p>I've come up with something like this: the player has got <em>CollisionBehaviour</em>, which checks if player collides with something. If he collides with a button, it sends a <code>CollisionMessage</code> to the <code>button</code> entity. The message will contain all necessary informations: who collided with the button. The button has got <em>ToggleableBehaviour</em>, which will receive <code>CollisionMessage</code>. It'll check who did it collide with and if the weight of that entity is big enough to toggle the button, the button gets toggled. Now, it sets the <em>ToggledAttribute</em> of the button to true. Alright, but what now?</p>

<p>Should the button send another message to all other objects to tell them that it has been toggled? I think that if I did everything like this, I'd have thousands of messages and it'd get pretty messy. So maybe this is better: the doors constantly check if the button which is linked to them is pressed or not, and changes its <em>OpenedAttribute</em> accordingly. But then it means that the doors' <code>OnUpdate()</code> method will be constantly doing something (is it really a problem?).</p>

<p>And the second problem: what if I have more kinds of buttons. One is pressed by pressure, second one is toggled by shoting at it, third one is toggled if water is poured on it, etc. This means that I'll have to have different behaviours, something like this:</p>

<pre><code>Behaviour -&gt; ToggleableBehaviour -&gt; ToggleOnPressureBehaviour
                                 -&gt; ToggleOnShotBehaviour
                                 -&gt; ToggleOnWaterBehaviour
</code></pre>

<p>Is this how real games work or am I just stupid? Maybe I could have just one <em>ToggleableBehaviour</em> and it'll behave according to the <em>ButtonTypeAttribute</em>. So if it's a <code>ButtonType.Pressure</code>, it does this, if it's a <code>ButtonType.Shot</code>, it does something else...</p>

<p>So what do I want? I'd like to ask you if I'm doing it right, or I'm just stupid and I didn't understand the point of components. I didn't find any good example of how do the components really work in games, I found just some tutorials describing how to make the component system, but not how to use it.</p>
","<p>Components are great, but it can take some time to find a solution that feels good to you. Don't worry, you'll get there. :) </p>

<p><strong><em>Organizing components</em></strong></p>

<p>You're pretty much on the right track, I'd say. I'll try to describe the solution in reverse, starting with the door and ending with the switches. My implementation makes heavy use of events; below I describe how you can use events more efficiently so they don't become a problem.</p>

<p>If you have a mechanism for connecting entities between them, I'd have the switch directly notify the door that it has been pressed, then the door can decide what to do.</p>

<p>If you can't connect entities, your solution is pretty close to what I'd do. I'd have the door listen for a generic event (<code>SwitchActivatedEvent</code>, maybe). When the switches get activated, they post this event.</p>

<p>If you have more than one type of switch, I'd have <code>PressureToggle</code>, <code>WaterToggle</code> and a <code>ShotToggle</code> behaviors too, but I'm not sure the base <code>ToggleableBehaviour</code> is any good, so I'd do away with that (unless, of course, you have a good reason for keeping it).</p>

<pre><code>Behaviour -&gt; ToggleOnPressureBehaviour
          -&gt; ToggleOnShotBehaviour
          -&gt; ToggleOnWaterBehaviour
</code></pre>

<p><strong><em>Efficient event handling</em></strong></p>

<p>As for worrying that there's too many events flying around, there's one thing you could do. Instead of having every component be notified of every single event that occurs, then have the component check if it's the right type of event, here's a different mechanism...</p>

<p>You can have an <code>EventDispatcher</code> with a <code>subscribe</code> method that looks something like this (pseudocode):</p>

<pre><code>EventDispatcher.subscribe(event_type, function)
</code></pre>

<p>Then, when you post an event, the dispatcher checks its type and only notifies those functions that have subscribed to that particular type of event. You can implement this as a map that associates types of events with lists of functions.</p>

<p>This way, the system is significantly more efficient: there's a lot less function calls per event, and components can be sure that they received the right type of event and not have to double check.</p>

<p>I've posted a simple implementation of this some time ago on StackOverflow. It's written in Python, but maybe it can still help you:<br>
&#9658; <a href=""https://stackoverflow.com/a/7294148/627005"">https://stackoverflow.com/a/7294148/627005</a></p>

<p>That implementation is quite generic: it works with any kind of function, not just functions from components. If you don't need that, instead of <code>function</code>, you could have a <code>behavior</code> parameter in your <code>subscribe</code> method &mdash; the behavior instance that needs to be notified.</p>

<p><strong><em>Attributes and behaviors</em></strong></p>

<p><a href=""https://gamedev.stackexchange.com/a/22076/6188"">I've come to use attributes and behaviors myself</a>, instead of plain old components. However, from your description of how you'd use the system in a Breakout game, I think you're overdoing it.</p>

<p>I use attributes only when two behaviors need access to the same data. The attribute helps keep the behaviors separate and the dependencies between components (be they attribute or behaviors) do not become entangled, because they follow very simple and clear rules:</p>

<ul>
<li><p>Attributes do not use any other components (neither other attributes, nor behaviors), they are self sufficient.</p></li>
<li><p>Behaviors do not use or know about other behaviors. They only know about <em>some</em> of the attributes (those that they strictly need).</p></li>
</ul>

<p>When some data is only needed by one and only one of the behaviors, I see no reason to put it in an attribute, I let the behavior hold it.</p>

<hr>

<p><strong>@<a href=""https://gamedev.stackexchange.com/questions/23755#comment38463_23759"">heishe's comment</a></strong></p>

<p>Wouldn't that problem occur with normal components as well?</p>

<p>Anyway, I don't have to check event types because every function is sure to receive the right type of event, <em>always</em>.</p>

<p>Also, the behaviors' dependencies (ie. the attributes that they need) are resolved on construction, so you don't have to go looking for attributes every on every update.</p>

<p>And lastly, I use Python for my game logic code (the engine is in C++, though), so there's no need for casting. Python does its duck-typing thing and everything works fine. But even if I didn't use a language with duck-typing, I'd do this (simplified example):</p>

<pre><code>class SomeBehavior
{
  public:
    SomeBehavior(std::map&lt;std::string, Attribute*&gt; attribs, EventDispatcher* events)
        // For the purposes of this example, I'll assume that the attributes I
        // receive are the right ones. 
        : health_(static_cast&lt;HealthAttribute*&gt;(attribs[""health""])),
          armor_(static_cast&lt;ArmorAttribute*&gt;(attribs[""armor""]))
    {
        // Boost's polymorphic_downcast would probably be more secure than
        // a static_cast here, but nonetheless...
        // Also, I'd probably use some smart pointers instead of plain
        // old C pointers for the attributes.

        // This is how I'd subscribe a function to a certain type of event.
        // The dispatcher returns a `Subscription` object; the subscription 
        // is alive for as long this object is alive.
        subscription_ = events-&gt;subscribe(event::type&lt;DamageEvent&gt;(),
            std::bind(&amp;SomeBehavior::onDamageEvent, this, _1));
    }

    void onDamageEvent(std::shared_ptr&lt;Event&gt; e)
    {
        DamageEvent* damage = boost::polymorphic_downcast&lt;DamageEvent*&gt;(e.get());
        // Simplistic and incorrect formula: health = health - damage + armor
        health_-&gt;value(health_-&gt;value() - damage-&gt;amount() + armor_-&gt;protection());
    }

    void update(boost::chrono::duration timePassed)
    {
        // Behaviors also have an `update` function, just like
        // traditional components.
    }

  private:
    HealthAttribute* health_;
    ArmorAttribute* armor_;
    EventDispatcher::Subscription subscription_;
};
</code></pre>

<p>Unlike behaviors, attributes don't have any <code>update</code> function &mdash; they don't need to,  their purpose is to hold data, not to perform complex game logic.</p>

<p>You can still have your attributes perform some simple logic. In this example, a <code>HealthAttribute</code> might ensure that <code>0 &lt;= value &lt;= max_health</code> is always true. It can also send a <code>HealthCriticalEvent</code> to other components of the same entity when it drops below, say, 25 percent, but it can't perform logic any more complex than that.</p>

<hr>

<p><strong>Example of an attribute class:</strong></p>

<pre><code>class HealthAttribute : public EntityAttribute
{
  public:
    HealthAttribute(Entity* entity, double max, double critical)
        : max_(max), critical_(critical), current_(max)
    { }

    double value() const {
        return current_;
    }    

    void value(double val)
    {
        // Ensure that 0 &lt;= current &lt;= max 
        if (0 &lt;= val &amp;&amp; val &lt;= max_)
            current_ = val;

        // Notify other components belonging to this entity that
        // health is too low.
        if (current_ &lt;= critical_) {
            auto ev = std::shared_ptr&lt;Event&gt;(new HealthCriticalEvent())
            entity_-&gt;events().post(ev)
        }
    }

  private:
    double current_, max_, critical_;
};
</code></pre>
","23759"
"Should I worry about Youtube Let's Plays when I'm creating a story-heavy game?","15460","","<p>A few years ago, I watched a full playthrough of the first three Phoenix Wright games on Youtube. I enjoyed the story and characters a lot, hence why I pretty much binge-<strong>watched</strong> what is a series of very story-heavy <strong>games</strong>. I know it sounds stupid, but that's what happened.</p>

<p>As a consequence, I had no reason to buy and play any of those games. In hindsight, I realize I pretty much pirated the games without ever even playing them. It's not like I enjoyed the games because of their <em>epic</em> gameplay, I enjoyed them because of the story, and since I know what's going to happen, I don't have a reason to play them myself.</p>

<p>I still bought them in the end out of principle (even if it's Capcom...), but how many people are seriously going to do that? I doubt very many.</p>

<p>Now, I'm in the middle of creating my own story-heavy game, and I'm unsure because of how popular gaming channels have become on Youtube. I fear some big youtuber will play my game, a big portion of my potential playerbase will see the story and not be bothered to buy the game themselves. I mean, why should they if they've seen the story? Sure, I get some free publicity/marketing for my game, but what good is that if nobody's going to buy the game?</p>

<p>Is my concern valid? Or am I too pessimistic about people?</p>
","<p>Yes, you should care about Let's Players. In fact, you should make your game as appealing to them as possible. Reach out to them and encourage them to play your game.</p>

<p>Let's Players have become one of the most important marketing channels for independent game developers. They are a great way to expose your game to a large and interested audience and most of the time they don't even want any money for it. And exposure is everything in a market as crowded as today's game market. Only those people who know your game exists will consider buying it. I am sure some games like <em>Surgeon Simulator</em> or <em>Octodad</em> would have never been as successful if they weren't played into the ground on Youtube and Twitch.</p>

<p>Regarding your fear that ""a big portion of your potential playerbase will see the story and not be bothered to buy the game"": Have you calculated how large your ""potential playerbase"" actually is? There are hundreds of millions of people in the world who regularly buy and play video games. Your ""potential playerbase"" is practically endless, even if your game only targets a niche demographic. But just as countless as your customer pool is your competition. That's why exposure is so crucial for games.</p>

<p>However, if you are afraid that watching your game is just as good as playing your game, make sure it is not. Add multiple major branches to your story and lots of minor decisions which affect later events in the game. You want the audience to constantly wonder what would have happened if the player had done something different. And do not neglect your actual gameplay. The unique strength of games as a medium is that they are interactive. If you just want to tell your story and don't want any audience interaction to interfere with it, you can just as well write a novel.</p>
","151204"
"OpenGL: Resizing Display and glOrtho/glViewport","15400","","<p>I have researched this question from several sources and have yet to find a firm answer saying that ""yes that is correct thinking"" or ""no, here is how it's done.""</p>

<p>I am trying to ensure resolution independence with OpenGL rendering.  The way I think I should go about it, is to create a projection using glOrtho with whatever I want the world coordinates to be.  For example, glOrtho(-50.0, 50.0, -50.0, 50.0, 1.0, -1.0).  Next, set the viewport to the <b>screen resolution</b>, i.e. - glViewport(0, 0, 800, 600).  Finally, whenever the the window is re-sized, make a call to glViewport with the updated screen resolution.  This will scale your figures.</p>

<p>Is this the correct way to ensure that models take the same proportion of screen-space on different resolutions?  Should I be using a projection equal to the resolution as well?  I found some answers saying glOrtho should use the resolution of your window while others said it should/can be different.</p>

<p>Thoughts?</p>
","<p>What you have described is <strong>entirely adequate and appropriate</strong> to provide resolution independence. Anything you draw will indeed always take up the same proportion of your window.</p>

<p>However, if you do nothing more than this, you will have <strong>aspect ratio</strong> problems. For example, given the numbers you wrote, if you draw a circle, it will be squashed — wider than it is tall, because your horizontal scale is 800/(50+50) = 8 and your vertical scale is 600/(50+50) = 6.</p>

<p><strong>There cannot be any automatic solution to this problem</strong>; you will have to choose what graphical result you want, and consider its effect on the gameplay. Some common examples:</p>

<ul>
<li><p>In a perspective-projection 3D game with no HUD, the usual simple solution (available in OpenGL as part of <code>gluPerspective</code>) is to fix the projection's field of view relative to the <em>vertical dimension</em>. This means that in such a game, if you resize the window horizontally, you will see more or less of the scene and the middle part of the image will not change at all.</p>

<p>The same idea can be applied to a 2D/2.5D view as well.</p>

<p>(Note that this allows the player to enlarge their field of view horizontally by making a wide but not tall window. This could be unwanted in a competitive multiplayer game.)</p></li>
<li><p>If you have viewport-filling graphics with a fixed aspect ratio (for example, a non-scrolling 2D map, or a decorative border), or if you otherwise cannot change the layout, then you have to do something like having black bars on two sides to fill the unused space.</p>

<p>Or you can make graphics which have thematically consistent filler material around the edges that they can be <em>cropped</em> to fit the display without harming gameplay.</p></li>
<li><p>If you have a HUD on top of other graphics, you can decide that each HUD element is fixed to a part of the window (top left, bottom center, etc.) and compute its coordinates; the 'stretching' of varying the aspect ratios gets absorbed by the 'white space' between HUD elements.</p></li>
</ul>

<p>As to the specific mathematics of the matter, given that you are doing resolution independence, all you need to start out with is the aspect ratio, a single number: <code>width  / height</code>. For example, if the window is square it will be 1; if it is 800 by 600 it will be 800/600 = 4/3 = 1.333̅.</p>

<p>For example, suppose you want the <em>orthographic</em> projection you have written to gain additional space on the left and right sides if the window is widened. You can do that like this:</p>

<pre><code>float aspect = width / height;
glViewport(0, 0, width, height);
glOrtho(-50.0 * aspect, 50.0 * aspect, -50.0, 50.0, 1.0, -1.0);
</code></pre>

<p>This guarantees that, for windows at least as wide as they are tall, anything you draw with x and y coordinates within -50 to 50 will be visible.</p>

<p>On the other hand, if the window is narrower than it is tall, the -50-to-50 range will be cut off. Let's say you wanted to make sure that it is always visible (so that your content is at its maximum size if the window is square, but smaller otherwise); in that case, you simply do the same thing to the height instead of the width.</p>

<pre><code>float aspect = width / height;
glViewport(0, 0, width, height);
if (aspect &gt;= 1.0)
  glOrtho(-50.0 * aspect, 50.0 * aspect, -50.0, 50.0, 1.0, -1.0);
else
  glOrtho(-50.0, 50.0, -50.0 / aspect, 50.0 / aspect, 1.0, -1.0);
</code></pre>

<p>Note that in the second case we divide rather than multiply. This is simply because we computed the aspect ratio as <code>width / height</code> rather than <code>height / width</code>; take the reciprocal if you find it easier to understand that way.</p>

<p>Again, this is not the only way to manage aspect ratio; this is just a very simple one for making sure that your content is neither squished nor cut off. Figure out <em>what you want to happen</em> when your window is wide, tall, or whatever; then work out the mathematics of it.</p>
","49698"
"How can I draw a simple 2D line in XNA without using 3D primitives and shders","15399","","<p>I would like to be able to draw arbitary lines in my sprite based 2D XNA game. How can I draw a simple line on screen in XNA without dealing with vertex arrays or shaders.</p>
","<p>You can draw a line using sprites. SpriteBatch.Draw(...) helpfully allows us to strech and rotate a sprite(texture).</p>

<p>In this code, we take a 1x1 pixel texture, strech it (by defining a rectangle of the correct shape and rotate it so it looks like a line.</p>

<pre><code>    Texture2D t; //base for the line texture


    protected override void LoadContent()
    {
        spriteBatch = new SpriteBatch(GraphicsDevice);
        // create 1x1 texture for line drawing
        t = new Texture2D(GraphicsDevice, 1, 1);
        t.SetData&lt;Color&gt;(
            new Color[] { Color.White });// fill the texture with white
    }


    protected override void Draw(GameTime gameTime)
    {


        GraphicsDevice.Clear(Color.CornflowerBlue);

        spriteBatch.Begin();
        DrawLine(spriteBatch, //draw line
            new Vector2(200, 200), //start of line
            new Vector2(100, 50) //end of line
        );
        spriteBatch.End();



        base.Draw(gameTime);
    }


    void DrawLine(SpriteBatch sb, Vector2 start, Vector2 end)
    {
        Vector2 edge = end - start;
        // calculate angle to rotate line
        float angle =
            (float)Math.Atan2(edge.Y , edge.X);


        sb.Draw(t,
            new Rectangle(// rectangle defines shape of line and position of start of line
                (int)start.X,
                (int)start.Y,
                (int)edge.Length(), //sb will strech the texture to fill this rectangle
                1), //width of line, change this to make thicker line
            null,
            Color.Red, //colour of line
            angle,     //angle of line (calulated above)
            new Vector2(0, 0), // point in line about which to rotate
            SpriteEffects.None,
            0);

    }
</code></pre>
","44016"
"OpenGL ES 2.0 Point Sprites Size","15390","","<p>I am trying to draw point sprites in OpenGL ES 2.0, but all my points end up with a size of 1 pixel...even when I set gl_PointSize to a high value in my vertex shader.</p>

<p>How can I make my point sprites bigger?</p>
","<p>OpenGL ES 2.0 supports Point Sprites; i use them for particles. Just use <code>glDrawElements</code> with <code>GL_POINTS</code>.</p>

<p>In vertex shader, you set the size with <code>gl_PointSize</code> and use <code>gl_PointCoord</code> in fragment shader for texture mapping.</p>

<p>My vertex shader:</p>

<pre><code>uniform mat4 uMvp;
uniform float uThickness;

attribute vec3 aPosition;
attribute vec2 aTexCoord; 
attribute vec4 aColor;

varying vec4 vColor;

void main() {
    vec4 position = uMvp * vec4(aPosition.xyz, 1.);
    vColor = aColor;
    gl_PointSize = uThickness;
    gl_Position =  position;  
}
</code></pre>

<p>My fragment shader:</p>

<pre><code>uniform sampler2D tex0;
varying vec4 vColor;

void main() 
{
   gl_FragColor = texture2D(tex0, gl_PointCoord) * vColor;
}
</code></pre>

<p>If you are on Android, you can look <a href=""http://www.scigems.org/downloads/Articles/Episode1.php"">my french Tutorial</a>. There is a full project with point sprites.</p>
","15528"
"How do I save files with libgdx so that users can't read them?","15377","","<p>Writing my game in libgdx, I arrived at the point when I need to save the player stats and the info of the levels. However, in libgdx it's not allowed to write the file inside folder of the application, only external (on the SD) is allowed. The point is that I don't want the file to be seen by anyone, or if they can see it, how can I convert it to a binary file so it's not human readable? I just want to hide the file.</p>
","<p>I resolved it with callbacks, with that I can use Android methods, that way I can write to the internal memory.</p>
","26633"
"Import a 3D animation into an android game","15350","","<p>I want to import a skinned and animated character model built with bender into an android game. The animations can be: idle, walk, run ...etc</p>

<p>I've seen a related question but it's only about importing a static model: <a href=""https://stackoverflow.com/questions/204363/is-there-a-way-to-import-a-3d-model-into-android"">https://stackoverflow.com/questions/204363/is-there-a-way-to-import-a-3d-model-into-android</a></p>

<p>But I don't see how to import a set of animation with tweened frames.</p>

<p>Any ideas, resources or tutorials about how this can be achieved ?</p>

<p><hr /> Edit:
After some further searching I've found this library that claim to provide model loaders for md5 files. 
<a href=""http://code.google.com/p/libgdx/"" rel=""nofollow noreferrer"">http://code.google.com/p/libgdx/</a></p>

<p>Edit2 (2011 12 16):
I tested libgdx mentionned above And it actually works well for now, I can render a walking animation from md5 models with a good framerate, but the model loading time is quite long. For a large amount of models and frames, I think switching to binary formats will become necessary.</p>
","<p>You need to look up the file format for your animated mesh and decipher it. So, you'll need a framework capable of rendering a skinned mesh; you may have to do weighted mesh transformations in software, yourself, unless you're able to use vertex shaders in your version of OpenGL ES.</p>

<p>Next, you'll need to be able to load the mesh, the skeleton and the animation. This is probably a binary file format so you'll need:</p>

<ol>
<li>The file format(s) in question, showing you the byte offsets of all data members and other relevant information.</li>
<li>You'll need to load your files, possibly using 'DataInputStream' if they're binary. Make sure the 'endianness' of the data matches your system, you may have to swap bytes around if the data has a different order to the platform you're working on.</li>
<li>Skin your weighted mesh - i.e. either in a vertex shader or on the CPU, go through each vertex and blend the position according to the vertex weights and the matrices that they refer to.</li>
<li>Profit!</li>
</ol>

<p>I'm not sure how much of that made sense because I don't know what you don't know. You could try giving a bit more information such as the file formats for your data and if you're using a 3rd party 3D engine or writing your own.</p>

<p>HTH.</p>
","10250"
"Behaviour tree code example?","15350","","<p><a href=""http://altdevblogaday.org/2011/02/24/introduction-to-behavior-trees/"">http://altdevblogaday.org/2011/02/24/introduction-to-behavior-trees/</a></p>

<p>Obviously the most interesting article I found on this website. What do you think about it ?</p>

<p>It lacks some code example, don't you know any ? I also read that state machines are not very flexible compared to behaviour trees... On top of that I'm not sure if there is a true link between state machines and the state pattern... is there ?</p>
","<p>Behaviour trees are getting pretty big in the industry right now. Halo 3 uses them extensively for their AI (<a href=""https://www.bungie.net/en-US/Forum/Post?id=725717#!"" rel=""nofollow noreferrer"">Halo 3 - Building a Better Battle</a>).</p>

<p>Alex Champandard seems to be a big fan as well (Lots of articles on it on <a href=""http://www.aigamedev.com"" rel=""nofollow noreferrer"">AIGameDev.com</a>).</p>

<p>For code examples, take a look at:<br>
<a href=""http://magicscrollsofcode.blogspot.com/2010/12/behavior-trees-by-example-ai-in-android.html"" rel=""nofollow noreferrer"">http://magicscrollsofcode.blogspot.com/2010/12/behavior-trees-by-example-ai-in-android.html</a> - The example is in Java, but self-explanatory)</p>

<p>To answer your latter question: <a href=""https://gamedev.stackexchange.com/questions/7524/state-machines-state-object-versus-sequential-check-what-are-the-pro-cons"">State Machines: State Object versus sequential check: what are the pro/cons?</a></p>
","11521"
"How can I improve rendering speeds of a Voxel/Minecraft type game?","15346","","<p>I'm writing my own clone of Minecraft (also written in Java). It works great right now. With a viewing distance of 40 meters I can easily hit 60 FPS on my MacBook Pro 8,1. (Intel i5 + Intel HD Graphics 3000). But if I put the viewing distance on 70 meters, I only reach 15-25 FPS. In the real Minecraft, I can put the viewing disntance on far (= 256m) without a problem. So my question is what should I do to make my game better?</p>

<p>The optimisations I implemented:</p>

<ul>
<li>Only keep local chunks in memory (depending on the player's viewing distance)</li>
<li>Frustum culling (First on the chunks, then on the blocks)</li>
<li>Only drawing really visible faces of the blocks</li>
<li>Using lists per chunk that contain the visible blocks. Chunks that become visible will add itself to this list. If they become invisible, they are automatically removed from this list. Blocks become (in)visible by building or destroying a neighbour block.</li>
<li>Using lists per chunk that contain the updating blocks. Same mechanism as the visible block lists.</li>
<li>Use nearly no <code>new</code> statements inside the game loop. (My game runs about 20 seconds until the Garbage Collector is invoked)</li>
<li>I'm using OpenGL call lists at the moment. (<code>glNewList()</code>, <code>glEndList()</code>, <code>glCallList()</code>) for each side of a kind of block.</li>
</ul>

<p>Currently I'm even not using any sort of lighting system. I heard already about VBO's. But I don't know exactly what it is. However, I'll do some research about them. Will they improve performance? Before implementing VBO's, I want to try to use <code>glCallLists()</code> and pass a list of call lists. Instead using thousand times <code>glCallList()</code>. (I want to try this, because I think that the real MineCraft doesn't use VBO's. Correct?)</p>

<p>Are there other tricks to improve performance?</p>

<p>VisualVM profiling showed me this (profiling for only 33 frames, with a viewing distance of 70 meters):</p>

<p><img src=""https://i.stack.imgur.com/VNfw6.png"" alt=""enter image description here""></p>

<p>Profiling with 40 meters (246 frames):</p>

<p><img src=""https://i.stack.imgur.com/DNxty.png"" alt=""enter image description here""></p>

<p><strong>Note:</strong> I'm synchronising a lot of methods and code blocks, because I'm generating chunks in another thread. I think that acquiring a lock for an object is a performance issue when doing this much in a game loop (of course, I'm talking about the time when there is only the game loop and no new chunks are generated). Is this right?</p>

<p><strong>Edit:</strong> After removing some <code>synchronised</code> blocks and some other little improvements. The performance is already much better. Here are my new profiling results with 70 meters:</p>

<p><img src=""https://i.stack.imgur.com/lMomq.png"" alt=""enter image description here""></p>

<p>I think it is pretty clear that <code>selectVisibleBlocks</code> is the issue here.</p>

<p>Thanks in advance!<br>
Martijn</p>

<p><strong>Update</strong>: After some extra improvements (like using for loops in stead of for each, buffering variables outside loops, etc...), I now can run viewing distance 60 pretty good.</p>

<p>I think I'm going to implement VBO's as soon as possible.</p>

<p>PS: All source code is available on GitHub:<br>
<a href=""https://github.com/mcourteaux/CraftMania"" rel=""noreferrer"">https://github.com/mcourteaux/CraftMania</a></p>
","<p>You mention doing frustum culling on individual blocks — try throwing that out. Most rendering chunks should be either entirely visible or entirely invisible.</p>

<p>Minecraft only rebuilds a display list/vertex buffer (I don't know which it uses) when a block is modified in a given chunk, and <a href=""https://github.com/kpreid/cubes/"">so do I</a>. If you're modifying the display list whenever the view changes, you're not getting the benefit of display lists. </p>

<p>Also, you appear to be using world-height chunks. Note that Minecraft uses <em>cubical</em> 16×16×16 chunks for its display lists, unlike for load and save. If you do that, there's even less reason to frustum cull individual chunks.</p>

<p><em>(Note: I have not examined the code of Minecraft. All of this information is either hearsay or my own conclusions from observing Minecraft's rendering as I play.)</em></p>

<hr>

<p>More general advice:</p>

<p>Remember that your rendering executes on two processors: CPU and GPU. When your frame rate is insufficient, then <em>one or the other is the limiting resource</em> — your program is either <em>CPU-bound</em> or <em>GPU-bound</em> (assuming it isn't swapping or having scheduling problems).</p>

<p>If your program is running at 100% CPU (and doesn't have an unbounded other task to complete), then your CPU is doing too much work. You should try to simplify its task (e.g. do less culling) in exchange for having the GPU do more. I strongly suspect this is your problem, given your description.</p>

<p>On the other hand, if the GPU is the limit (sadly, there aren't usually convenient 0%-100% load monitors) then you should think about how to send it less data, or require it to fill fewer pixels.</p>
","22669"
"How can I develop my Android game for different phone resolutions?","15314","","<p>For instance, the Motorola Droid is as wide as the G1, but has more height.</p>

<p>Should I try to spread the UI out across the extra height found on the Motorola Droid?  How do others handle this problem?</p>

<p>I'm not using OpenGL, but a SurfaceView for a 2D game.</p>
","<p>Be aware of density independence (basically resolution) as described here: <a href=""http://developer.android.com/guide/practices/screens_support.html"" rel=""nofollow noreferrer"">http://developer.android.com/guide/practices/screens_support.html</a></p>

<p>And as related to aspect ratio, pick your minimal target aspect ratio and design within it as sort of a safe frame. When confrontend with wider aspect ratio, show more of the game which is not critical to gameplay. I have posted a similar question here and described what I'd do: <a href=""https://gamedev.stackexchange.com/questions/34/how-do-you-approach-resolution-independence-in-raster-based-graphics-content"">How do you approach resolution independence in raster based graphics content?</a></p>
","284"
"How many ""parallel units"" does a GPU have?","15296","","<p>I'd like to know how many parallel units <em>for processing vertices</em> a GPU has.</p>

<p><a href=""http://en.wikipedia.org/wiki/Comparison_of_AMD_graphics_processing_units"">This Wikipedia page</a> provides a GFLOPS and clock speed, for example for the Radeon 5850 ""Broadway PRO"", you get 1000 GFLOPS.  Assume running a vertex shader is 100 flops, then that means you can process 1000e9 / 100 = 10e9 vertices per second.</p>

<p>Is there a manufacturer published number of <em>number of parallel processing units</em>, or a way to know that number?</p>
","<blockquote>
  <p>Assume running a vertex shader is 100 flops, then that means you can process 1000e9 / 100 = 10e9 vertices per second.</p>
</blockquote>

<p>No, it most assuredly does not.</p>

<p>Basically, you should consider any calculation of the execution speed of <em>any</em> code based solely on ""FLOPS"" count to be suspect. Indeed, it's generally best if you completely ignore FLOPS entirely.</p>

<p>You did not define the term ""parallel unit""; without that definition, we could only guess at what you're wanting.</p>

<p>Take the Radeon 5870. It has 1600 floating-point units. That means, for every cycle, it can be executing 1600 scalar floating-point operations at once. However, each VLIW opcode works on 5-way vector math registers. So the smallest possible granularity of actual code is 1600/5, or 320 (note: this is a <em>vast</em> simplification). That's 320 threads.</p>

<p><em>However</em>, that's not really how it works. You don't have 320 separate paths of execution going on. You cannot have 320 different pieces of code executing on 320 different units. See, the 5-way VLIWs are themselves grouped into 4-way SIMD cores. Each SIMD can have its own path of execution and its own source code. Each VLIW <em>within</em> an SIMD core can have separate data, so that they compute separate values. But each VLIW within an SIMD core executes the same instructions in lock-step with the other VLIWs in that core.</p>

<p>So really, you only have 320/4, or 80 total threads. But again, it depends on what kind of ""parallel unit"" you're talking about. Technically, 1600, 320, and 80 are all legitimate answers.</p>

<p>And that's just for one <em>specific</em> architecture. NVIDIA's Fermi line (GeForce 4xx and above) uses a vastly different architecture. ATI's Cayman line (Radeon 69xx) changes the 5-way VLIWs to 4-way VLIWs. Their next architecture may have some significant differences too.</p>

<p>Without knowing what you're looking for, there's just no way to answer the question.</p>
","17255"
"GLSL Light (Attenuation, Color and intensity) formula","15295","","<p>I'm implementing point lights in my Voxel engine, and I'm really struggling to get a good flow of light, from 100% near the light source to 0% at the light radius.</p>

<p>I have 5 arguments for the function:</p>

<ol>
<li>Light color (Vec3)</li>
<li>Light intensity (distance from the light till the distance where falloff is 100%)</li>
<li>Distance from the light to the fragment</li>
<li>The angle from the fragment normal to the light</li>
<li>The position of the light</li>
</ol>

<p>Can anyone push me in the right direction to create a function for the calculating of the fragment color?</p>

<p>Image of one of my experiments:</p>

<p><img src=""https://i.stack.imgur.com/uG6Rm.png"" alt=""Voxel Engine Per-Fragment Lighting Test""></p>

<p>Edit (current code requested by Byte) <strong>Note that this is just some experiment code from my side. I got the float att from a website, and it kinds works, but far from perfect.</strong>:</p>

<pre><code>void main()
{
// Light color
vec3 torchColor = vec3(1.0f, 1.0f, 1.0f);

float lightAdd = 0.0f;
for (int i=0; i&lt;5; i++) {
    vec3 pos = lights[i];
    if (pos.x == 0.0f) continue;

    float dist = distance(vertex_pos, pos);
    if (dist &lt; 9) {
        float att=1.0/(1.0+0.1*dist+0.01*dist*dist);
        vec3 surf2light = normalize(pos - vertex_pos);
        vec3 norm = normalize(normal);
        float dcont=max(0.0,dot(norm,surf2light));
        lightAdd += att*(dcont+0.4);
    }
}

vec3 textureColor = texture2D(texture, texture_coordinate).rgb;
vec3 torch_output = lightAdd * torchColor;

vec3 final_color = ((0.1+torch_output) * textureColor);

gl_FragColor = vec4(final_color, 1.0f); 
}
</code></pre>
","<p>The attenuation function you've got,</p>

<pre><code>att = 1.0 / (1.0 + 0.1*dist + 0.01*dist*dist)
</code></pre>

<p>is a fairly common one in computer graphics - or, more generally, <code>1.0 / (1.0 + a*dist + b*dist*dist))</code> for some tweakable parameters <code>a</code> and <code>b</code>.  To understand how this curve works it's helpful to <a href=""https://www.desmos.com/calculator/nmnaud1hrw"">play with the parameters interactively</a>.  This curve is nice because it approaches the physically-correct inverse square law at large distances, but it doesn't shoot up to infinity at short distances.  In fact, with <code>a = 0</code> it's a pretty good model of a spherical area light.</p>

<p>However, one disadvantage of it is that the light never quite goes to zero at any finite distance.  For practical purposes in realtime CG we generally need to cut lights off at a finite distance, as you're doing with the <code>if (dist &lt; 9)</code> clause.  However, the radius of 9 is too short - with your settings in the attenuation function, the light doesn't get close to zero until dist is around 100.</p>

<p>You can calculate the radius of the light from the <code>b</code> parameter in the attenuation function (since the quadratic term dominates at large distances).  Let's say you want to cut the light off when the attenuation reaches some value <code>minLight</code>, like 0.01.  Then set</p>

<pre><code>radius = sqrt(1.0 / (b * minLight))
</code></pre>

<p>That gives a radius of 100 for <code>b = 0.01</code> and <code>minLight = 0.01</code>.  Alternatively, you can set the radius and calculate <code>b</code> to match:</p>

<pre><code>b = 1.0 / (radius*radius * minLight)
</code></pre>

<p>For <code>radius = 9</code> and <code>minLight = 0.01</code>, that gives <code>b = 1.23</code>.  You can set it up either way, but the key is to make the radius and the attenuation function match so that you don't cut the light off until the attenuation function is already very low, so you won't see a sharp edge.</p>

<hr>

<p>All that said, there are alternative attenuation functions you can use.  Another fairly common one is:</p>

<pre><code>att = clamp(1.0 - dist/radius, 0.0, 1.0); att *= att
</code></pre>

<p>or the slightly fancier:</p>

<pre><code>att = clamp(1.0 - dist*dist/(radius*radius), 0.0, 1.0); att *= att
</code></pre>

<p><a href=""https://www.desmos.com/calculator/kp89d5khyb"">Play with the parameters</a> for those ones too.  These curves have the advantage of going <em>exactly</em> to zero at the given radius, while still looking kind of like the natural inverse square law.</p>
","56934"
"Learning To Create Better Art (2D Games)","15294","","<p>Until one of my games ""makes it"" big, or I get flooded with gold ingots, I will have to handle most or all of my game art myself. The crux of my question is: <strong>how can I learn enough art to get beyond ""programmer art"" and into something I would actually be proud of?</strong></p>

<p>The focus of my question is 2D, not 3D.</p>

<p>I already have a good grip on:</p>

<ul>
<li>Photoshop/GIMP (image maniplation and creation)</li>
<li>Flash (animation and drawing simple art)</li>
<li>Simple drawing (by hand)</li>
<li>Digitizing hand-drawn art</li>
<li>Graphic design</li>
</ul>

<p>However, games require complex and varied art; anything from backgrounds to icons, sprites, animation, and complex effects.</p>

<p>How do I bridge the gap, artistically?  I already have the experience and confidence that I can do it; I only need to know the direction in which to put my modest efforts. I know this will pay off, especially in the long term. But I'm not sure <em>how</em> to get there.</p>

<p>Using existing art is something I already do, so please don't address that in your question.</p>
","<p>Lots and lots of practice. Most artists have been doodling and drawing since they learned how to hold a pen, you need to make up for lost time. </p>

<p>My suggestion: start with hand drawn things and other basics. Having a grip on how a program works vs bringing out the fullest in a program for art are two different things so look up some online tutorials and the like and get a couple of new techniques.</p>

<p>Next: practice like crazy. My favorite way to do this is set up a list of things to make, usually simple things - get about 20 to 30 subjects (this is pretty difficult and you wont always use all of them). Then get an alarm clock you can set for 10 - 15 minute intervals set it and in that time do your best to draw up a single object. </p>

<p>When the alarm goes off thats the end of that drawing. No 'but's. You now have the option to begin the same object again (10 to 15 minutes again) or start the process all over again. (Rinse, wash, repeat until you get the desired effect)</p>
","16936"
"Where can I find fonts for my game?","15279","","<p>Where can I find fonts (preferably free, but a reasonable fee is acceptable) that I can use in my for-pay/commericial game?</p>
","<p>You can find many free and cheap fonts on <a href=""http://new.myfonts.com/"">MyFonts.com</a>, including the <a href=""http://new.myfonts.com/foundry/Larabie/"">Larabie Font Collection</a> (many of which are free for commercial use)</p>
","1636"
"Should I consider a graduate degree in game development?","15269","","<p>I am sure you guys can definitely help. Some universities, like <a href=""http://en.wikipedia.org/wiki/North_Carolina_State_University"">NCSU</a>, <a href=""http://en.wikipedia.org/wiki/University_of_Southern_California"">USC</a>, <a href=""http://en.wikipedia.org/wiki/University_of_California,_Santa_Cruz"">UCSC</a> for their master's, offer courses based on gaming and game development (some call it MS in Computer Science with an emphasis on game development). I am very interested in this field and I want to give it a shot. But since a master's degree is very costly I have to factor in the future prospects as well. I want to know if this a proper course when a career is also taken into account. Any opinions or ideas? Anyone who has followed this career line?</p>
","<p>I agree completely with mrbinary's answer. I am a student at UNC Charlotte and we have a Game Design and Development concentration with our Computer Science degree (in the Bachelor's and Masters track). Essentially you take four classes: Intro to Game Design and Development, Advanced Game Design and Development, Game Studio (a semester long project class), and an elective class pertaining to something related to games (AI, Games with a Purpose, 3D Graphics, etc.). I also work in a research lab for the University run by the professors that created the Game Design and Development concentration doing research and development of Games with a Purpose.  I have many friends who have gone through the program, and I completed it halfway through.</p>

<p>Long story short, everyone I know that has completed the program (some bachelors, some masters) and graduated, then sought out a job in the gaming industry, have failed to get a job. Due to my research work, I have travelled to many game related conferences to present work and see other work in the field, and this discussion has come up a lot. One cool thing about these conferences is that people from industry will attend, as well as academics. What I've heard from many people in industry (and this is backed up by none of my friends who went through our degree program getting jobs in the gaming industry) is that going through a Game Development program may actually hinder your ability to get a job in the gaming industry. This is because the games industry is so diverse in terms of how they develop games. Some companies may use C++ as their language of choice, but use it within a custom engine or a custom framework. Others might use C#, others a scripting language (Lua, ActionScript, etc.), others may focus solely on mobile development and use Objective-C or Java, others may build flash games. The choice of programming languages and development environments are extremely diverse. The problem with Game programs at Universities is it gets you experience in one specific framework and methodology of game development that may not always translate to a game companies needs.</p>

<p>Our program used to teach XNA and C# (which limited us to Windows and XBOX only games), and has now moved into using Unity and JavaScript, as well as WebGL with HTML5. The reason for the transition was that learning XNA and C# for 2 years was getting the graduates nowhere. The game industry has transitioned greatly in the last few years away from consoles to mobile devices and web games, so our curriculum was changed to accommodate for that. It is yet to be seen if this helps our graduates find jobs or not. From my circumstantial observations, plus what I've heard from discussions with people from industry, a Games concentration may not be beneficial when trying to get a job in industry. Of course, if you want to becomes a Games professor, then it's probably just fine! A regular Computer Science degree and some of your own portfolio projects will get you further than a degree focused on games, in my opinion.</p>
","18670"
"Skyrim Creation Kit with Xbox 360","15256","","<p>I posted this on stackoverflow but was advised to post here (<a href=""https://stackoverflow.com/questions/9355005/skyrim-creation-kit-with-xbox-360#comment11831652_9355005"">here</a> is a link to the stackoverflow question). I'm hoping for constructive feedback on its plausibility.</p>

<p><strong>Update on progress:</strong> It looks like there <em>are</em> ways to stuff files back onto the console (horizon, modio, xplorer360, etc) and they <em>do</em> require some form of signing.</p>

<p>As of now, though, I've had no luck. I was hoping I could get away with just placing the "".esp"" into the directory containing marketplace downloads for Skyrim, along with the signed "".bsa"" file (basically a zipped up file containing any extra content the .esp will need to refer that doesn't exist in the basic game). </p>

<p>This doesn't work, at least not in the ways I've tried, so next I'm going to try install the entire game to my flash drive (if possible) and attempt to traverse through the game's directory (this is probably unlikely). </p>

<p>If anyone else has suggestions or luck or wants more detail on my failures comment/answer away.</p>

<p>Here is the question:</p>

<blockquote>
  <p>I'm thinking about buying the PC version of Skyrim to get the Creation
  Kit (I already own a copy for the Xbox). I have read the faq and
  scoured plenty of forums to see if there was some way to mod Skyrim
  for a console (Xbox 360, in particular), but they are generally coming
  up negative.</p>
  
  <p>I realize the CreationKit is on the PC, but I was wondering if there
  was a way to set up the '.esp' (hopefully I'm interpreting this
  correctly) files to be placed on the Xbox 360 file system in a similar
  manner to how game add-ons are downloaded from the Xbox Live
  Marketplace.</p>
  
  <p>I believe it is possible to transfer saves between the console and the
  PC (e.g. google: 'skyrim mod xbox360'), but these are referencing
  items that already exist in the game (e.g. a console command for
  maximum carry weight does not require reference to new animations or
  models).</p>
  
  <p>It would probably be easier if one could navigate through the xbox's
  file system to see where the games' files are placed, but with the
  current setup, the file system is abstracted away.</p>
  
  <p>Any help or insight on the matter would be much appreciated. I would
  love to work on a project that would make it possible to let console
  gamers experience and enjoy all the great mods available to the PC
  community.</p>
</blockquote>
","<p>The answer is that it is probably possible with a great amount of reverse-engineering effort (but what isn't?).  There was an interview with Todd Howard on this topic and he said that identical content could run on PC/Xbox 360/PS3.  </p>

<p>The problem is that there isn't a means by which you can get the modded content back onto the console.  This has nothing to do with running signed vs unsigned code, this has to do with modifying the data files and stuffing them back into the game.  There simply isn't a way to do this on the console.  </p>

<p>You could try installing the full game on the 360 hard disk and then grab some linux FUSE drivers for the 360 filesystem (http://code.google.com/p/x360/).  This would at least give you filesystem access, from there caveats are sure to abound.</p>
","24255"
"Using Blueprint to spawn objects at runtime in Unreal Engine 4","15256","","<p>Using UE4's ""Blueprint"" visual scripting system, how can I dynamically spawn objects at runtime?</p>
","<p>I would recommend watching:
<a href=""https://www.youtube.com/watch?v=rhCGy9ceRPI"" rel=""nofollow"">https://www.youtube.com/watch?v=rhCGy9ceRPI</a></p>

<p>It will show you how to spawn something from pressing a key at a target location, I would say just replace the key press with the Initialize Level function.</p>

<p>Not sure if that might be what you are wanting.</p>
","73475"
"Is there anything like XNA for c++?","15252","","<p>I love the features of XNA but I want to get into c++ game dev. The problem is that I now have to worry about everything from loading a png file to opening a window. This is a little bit annoying.</p>

<p>I would really like a c++ version of XNA to solve these issues for me.</p>
","<p>I would recommend that you look at <a href=""http://www.sfml-dev.org/features.php"">SFML</a> and <a href=""http://polycode.org/"">Polycode</a>. </p>

<p>I think the answers here are kind of missing the point. It is annoying to have to link to ten different libraries, such as Freetype, libpng, tinyxml, Ogg, Vorbis, etc, to get some basic XNA features. </p>

<hr>

<p><strong>SFML</strong></p>

<p><a href=""http://www.sfml-dev.org/features.php"">http://www.sfml-dev.org/features.php</a></p>

<p>SFML is a free multimedia C++ API that provides you low and high level access to graphics, input, audio, etc. In a sense, its kind of similar to XNA but does not hold your hand as much. For example, SFML does not have a Model class. </p>

<hr>

<p>If you are planning on using Models in your games, you should look at using <a href=""http://assimp.sourceforge.net/"">Assimp</a>. </p>

<p>Assimp adds support for importing the following formats:</p>

<pre><code>Collada ( .dae )
Blender 3D ( .blend )
3ds Max 3DS ( .3ds )
3ds Max ASE ( .ase )
Wavefront Object ( .obj )
Stanford Polygon Library ( .ply )
AutoCAD DXF ( .dxf )
LightWave ( .lwo )
Modo ( .lxo )
Stereolithography ( .stl )
AC3D ( .ac )
Milkshape 3D ( .ms3d )
Quake I Mesh ( .mdl )
Quake II Mesh ( .md2 )
Quake III Mesh ( .md3 )
Quake III BSP ( .pk3 )
Biovision BVH ( .bvh )
DirectX X ( .x )
BlitzBasic 3D ( .b3d )
Quick3D ( .q3d,.q3s )
Ogre XML ( .mesh.xml )
Irrlicht Mesh ( .irrmesh )
Neutral File Format ( .nff )
Sense8 WorldToolKit ( .nff )
Object File Format ( .off )
PovRAY Raw ( .raw )
Terragen Terrain ( .ter )
3D GameStudio ( .mdl )
3D GameStudio Terrain ( .hmp )
Izware Nendo ( .ndo )
</code></pre>

<hr>

<p><strong>Polycode</strong></p>

<p><a href=""http://polycode.org/features/"">http://polycode.org/features/</a></p>

<blockquote>
  <p>Polycode is a free, open-source, cross-platform framework for creative
  code. You can use it as a C++ API or as a standalone scripting
  language to get easy and simple access to accelerated 2D and 3D
  graphics, hardware shaders, sound and network programming, physics
  engines and more.</p>
  
  <p>The core Polycode API is written in C++ and can be used to create
  portable native applications.</p>
  
  <p>On top of the core C++ API, Polycode offers a Lua-based scripting
  system with its own set of compilation tools. The Lua API mirrors the
  C++ API and can be used to easily create prototypes and even publish
  complete applications to multiple platforms without compiling C++.</p>
</blockquote>

<p>Polycode is opensource, meaning that you can learn from how things are done behind the scenes. Also, it uses Assimp to load models so you do not need to worry about manually linking to Assimp.</p>
","17650"
"How can I come up with a simple diminishing return equation?","15213","","<p>There are formulas out there for a diminishing return equation; however, those usually involve exponential. What other ways are there for coming up with such an equation? Take, for example, the following test case -- One farm produces 10 food, for every 10 farms produced, the production rate drops by 5%.</p>
","<p>For formulating a diminishing returns equation, I'd immediately think fractions.</p>

<p><img src=""https://i.stack.imgur.com/huOds.gif"" alt=""Graph of 1/F"">
This is a graph of <code>y=1/F</code></p>

<p><code>y</code> will get smaller as <code>F</code> gets larger. This will give you a steady drop-off that never reaches 0. From this you can transform it to get the sort of curve that you want. Using numbers > 0 will <strong>always</strong> give positive output that is <strong>never</strong> 0.</p>

<p>Honestly, I'd recommend going to <a href=""http://www.wolframalpha.com/"" rel=""nofollow noreferrer"">WolframAlpha</a> and putting in some equations and looking at the graphs that it draws to see if it gives the curve that you want. Other than that, read up of <a href=""http://en.wikipedia.org/wiki/Linear_equation"" rel=""nofollow noreferrer"">linear</a> and <a href=""http://en.wikipedia.org/wiki/Quadratic_equation"" rel=""nofollow noreferrer"">quadratic</a> equations to be able to quickly figure out what it is that you want to alter in a formula. This is because modelling graphs through equations is a bit of a big topic, and if I could explain it here perfectly I'd sell that explanation to some maths teachers first.</p>

<p>Basically, for linear graphs, remember <code>y=mx+c</code>. <code>m</code> is the gradient, and can be positive or negative depending on what you need, and <code>c</code> is the point at which it intercepts the <code>y axis</code>. <code>x</code> is your input variable and <code>y</code> is your output.</p>

<p><img src=""https://i.stack.imgur.com/lFZT3.gif"" alt=""y=mx+c""> 
This is a graph of <code>y=mx+c</code> where <code>m=1</code> and <code>c=0</code></p>

<p>For quadratic graphs, it gets a bit more complicated, so I'll be a bit vague and you'll have to read up on the specifics yourself. <a href=""https://www.khanacademy.org/math/algebra/quadratics"" rel=""nofollow noreferrer"">Khan Academy</a> is a really good resource for teaching this. It's of the general form <code>y=ax²+bx+c</code>. <code>c</code> is still the y intercept, and you can tweak it to ""lift"" the graph. <code>a</code> and <code>b</code> both affect the curve similarly, but to different degrees. </p>

<p><img src=""https://i.stack.imgur.com/ypTwR.gif"" alt=""y=-x²+2x+10"">
This is <code>y=-x²+2x+10</code>. Note the <code>-x²</code>, which makes the curve inverted.</p>

<p>Basically, play around with the graphs until you get what you want, although I highly recommend reading up on it more if you want to design the experience quickly and cleanly. Basic equations are important to games and really interesting.</p>

<p>Other things to note are <a href=""http://en.wikipedia.org/wiki/Exponential_growth"" rel=""nofollow noreferrer"">exponential</a> and <a href=""http://en.wikipedia.org/wiki/Natural_logarithm"" rel=""nofollow noreferrer"">logarithmic</a> graphs, i.e. graphs of <code>y=e^x</code> and <code>y=ln(x)</code> to get rapidly increasing and rapidly decreasing graphs depending on the transformation. As well as this, vectors and transformations are helpful, as they describe what you're doing the the ""base"" graph.</p>
","89734"
"How to learn game graphic design for non artist?","15210","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://gamedev.stackexchange.com/questions/2326/graphics-for-non-graphics-designers"">Graphics for non-Graphics Designers</a>  </p>
</blockquote>



<p>I'm more into the technical aspects of a game like programming, mechanics and algorithms.</p>

<p>I'm no artist but I like to make games independently and I'm finding it hard to make graphics for my games. Is there anything that I could do to recuperate with this?</p>
","<p>I think it depend on what kind of graphics you are looking for. People usually go with pixelart in indie development.</p>

<p>If you are looking for this kind of graphics I would recommend going to deviantart.com and searching ""pixelart"" or ""game pixelart"". It will spits out countless game sprites. Download some of them and study them at 300% zoom. Some people say its good to read some books but I would say practice makes perfect. So try some of these:</p>

<ul>
<li><p><a href=""http://gas13.ru/v3/tutorials/sywtbapa_almighty_grass_tile.php"" rel=""nofollow"">http://gas13.ru/v3/tutorials/sywtbapa_almighty_grass_tile.php</a></p></li>
<li><p><a href=""http://garmahis.com/tutorials/pixel-art-tutorials/"" rel=""nofollow"">http://garmahis.com/tutorials/pixel-art-tutorials/</a></p></li>
<li><p><a href=""http://www.derekyu.com/?page_id=218"" rel=""nofollow"">http://www.derekyu.com/?page_id=218</a></p></li>
</ul>

<p>Pixelart is not THAT time consuming. But if you are looking for some better/complex graphics. I would say choose if you want to be a coder or a designer. Making game assets is very time consuming, and it will make your progress much slower. I would recommend hiring someone OR if you don't have enough money but you have the enthusiasm. Find somebody who shares the enthusiasm and start a small ""indie studio"" and cooperate. </p>
","20856"
"What is a good way to store tilemap data?","15204","","<p>I'm developing a 2D platformer with some uni friends.  We've based it upon the XNA Platformer Starter Kit which uses .txt files to store the tile map.  While this is simple it does not give us enough control and flexibility with level design. Some examples: for multiple layers of content multiple files are required, each object is fixed onto the grid, doesn't allow for rotation of objects, limited number of characters etc. So I'm doing some research into how to store the level data and map file.</p>

<p>This concerns only the file system storage of the tile maps, not the data structure to be used by the game while it is running.  The tile map is loaded into a 2D array, so this question is about which source to fill the array from.</p>

<p>Reasoning for DB: From my perspective I see less redundancy of data using a database to store the tile data.  Tiles in the same x,y position with the same characteristics can be reused from level to level.  It seems like it would simple enough to write a method to retrieve all the tiles that are used in a particular level from the database.</p>

<p>Reasoning for JSON/XML: Visually editable files, changes can be tracked via SVN a lot easier. But there is repeated content.</p>

<p>Do either have any drawbacks (load times, access times, memory etc) compared to the other?  And what is commonly used in the industry?</p>

<p>Currently the file looks like this:</p>

<pre><code>....................
....................
....................
....................
....................
....................
....................
.........GGG........
.........###........
....................
....GGG.......GGG...
....###.......###...
....................
.1................X.
####################
</code></pre>

<p>1 - Player start point, X - Level Exit, . - Empty space, # - Platform, G - Gem  </p>
","<p>So reading through your updated question, it seems you're most concerned about ""redundant data"" on disk, with some secondary concerns about load times and what the industry uses.</p>

<p>First off, why are you worried about redundant data?  Even for a bloated format like XML, it would be pretty trivial to implement compression and get the size of your levels down.  You're more likely to take up space with textures or sounds than your level data.</p>

<p>Second, a binary format is more than likely going to load faster than a text-based one that you have to parse.  Doubly so if you can just drop it in memory and have your data structures just there.  However, there are some downsides to that.  For one, binary files are next to impossible to debug (especially for content creation people).  You can't diff or version them.  But they will be smaller, and load faster.</p>

<p>What some engines do (and what I consider an ideal situation) is implement two loading paths.  For development, you use a text-based format of some kind.  It really doesn't matter which specific format you use, as long as you use a library that's solid.  For release, you switch to loading a binary (smaller, faster loading, possibly stripped of debug entities) version.  Your tools to edit the levels spit out both.  It's a lot more work than just one file format, but you can kind of get the best of both worlds.</p>

<p>All that being said, I think you're jumping the gun a bit.  </p>

<p>Step one to these problems is always describe the problem you're running in to thoroughly.  If you know what data you need, then you know what data you need to store.  From there it's a testable optimization question. </p>

<p>If you have a use case to test against, then you can test a few different methods of storing/loading data to measure for whatever you consider to be important (loading time, memory usage, disk size, etc.).  Without knowing any of that, it's hard to be more specific.</p>
","19676"
"Pygame How To Use Collision?","15165","","<p>Can someone tell me how to implement collision in Pygame?<br>
For example I have a sprite called A and another one called B.<br>
How do I detect if they collide in Pygame?</p>
","<p>Take a look at:</p>

<p><a href=""http://www.pygame.org/docs/ref/sprite.html#pygame.sprite.collide_rect"">http://www.pygame.org/docs/ref/sprite.html#pygame.sprite.collide_rect</a></p>

<p>And the several methods following it. You can test against a rectangle, circle, mask, sprite, or group of sprites.</p>

<p>You probably want </p>

<pre><code>pygame.sprite.collide_mask(SpriteLeft, SpriteRight): return bool
</code></pre>

<p>Which checks if two sprites collide based on their bitmasks.</p>
","15146"
"How do I build a 2D physics engine?","15159","","<p>The most advanced games I've made are a 8-ball pool game made with the physics engine Box2dFlashAS3 and a platform game with levels.</p>

<p>When I did platform games, I've always wished to know how to make an engine, so that I could re-use it. When I see games that have slopes, curved slopes, perfect gravity and real-life physics, I've always wished I knew how to code the engine.</p>

<p>Please suggest techniques and articles for whatever relevant knowledge-base is necessary.</p>
","<p>While I recommend <em>against</em> rolling your own physics engine for anything other than the experience of doing it (just realize you probably should throw it away when you're done -- it's really hard to get all the edgecases and numeric limit/stability issues sorted out, and your time may be much better used by contributing to an existing engine), here are a few resources:</p>

<p><a href=""http://www.gamasutra.com/view/feature/3015/pool_hall_lessons_fast_accurate_.php"">Pool Hall Lessons: Fast, Accurate Collision Detection Between Circles or Spheres</a> discusses circle/circle and sphere/sphere collision.</p>

<p>The <a href=""http://www.metanetsoftware.com/technique.html"">N Tutorials</a> are wonderful for a basic understanding of Separating Axis Theorem-based detection and response.</p>
","4596"
"Can I use an animated gif as a texture?","15079","","<p>I want to have a plane that shows an animated Gif as it's texture, so essentially it will be a movie. Can I apply an animated Gif as a texture? If so, does it apply like a normal texture? <em>Note: I know about <a href=""http://docs.unity3d.com/Documentation/Manual/VideoFiles.html"" rel=""noreferrer"">Movie Textures</a>, but don't want to use them</em></p>
","<p>Short answer is no.  You will need to convert the GIF to an atlased texture (a single 2D image that has all the GIF frames in it) and then cycle the UV coordinates on a textured quad to change which frame is currently visible.  This is not particularly hard to do, and there are existing sprite animation packages for Unity that can do most of it for you (you'll likely have to create the atlas yourself, or at least split the GIF into separate PNG images for each frame to use an existing atlas creator).</p>
","35033"
"How to implement turn-based game engine?","15074","","<p>Let's imagine game like Heroes of Might and Magic, or Master of Orion, or your turn-based game of choice. What is the game logic behind making next turn? Are there any materials or books to read about the topic? To be specific, let's imagine game loop:</p>

<pre><code>void eventsHandler(); //something that responds to input
void gameLogic(); //something that decides whats going to be output on the screen
void render(); //this function outputs stuff on screen
</code></pre>

<p>All those are getting called say 60 times a second. But how turn-based enters here? I might imagine that in gameLogic() there is a function like endTurn() that happens when a player clicks that button, but how do I handle it all? Need insights.</p>
","<p>A turn based game is going to be governed by a <a href=""http://en.wikipedia.org/wiki/State_machine"">state machine</a>.  Basically, you would lay out a series of states that can occur in a logical order.  </p>

<p>At a high level, a player's turn could be the start of a new state, followed by all the possible actions that are allowed during that turn.</p>

<p>For instance</p>

<ul>
<li>State - change player
<ul>
<li>it is now player 1's turn</li>
</ul></li>
<li>Actions allowed
<ul>
<li>attack
<ul>
<li>select enemy to attack</li>
</ul></li>
<li>defend
<ul>
<li>select unit to defend</li>
</ul></li>
<li>move unit
<ul>
<li>select unit to move</li>
<li>check to ensure movement is allowed</li>
</ul></li>
<li>etc</li>
</ul></li>
</ul>

<p>Obviously this will balloon quite quickly, as I've only sketched out an extremely limited plan.  Having a good grasp on possible states early on will mean that you should be in a good position to implement.  I'd highly stress sketching out exactly how you want the game to run....a good turn-based game requires a lot of planning IMO.</p>
","8240"
"Word list for use in commercial game","15072","","<p>I need a word list to use in a commercial game (even though the game will be free to download)</p>

<p>Something like this</p>

<p><a href=""http://www.puzzlers.org/pub/wordlists/ospd.txt"" rel=""nofollow noreferrer"">http://www.puzzlers.org/pub/wordlists/ospd.txt</a></p>

<p>Would be perfect (needs to be formatted .txt file) but obviously allowed to be used in a commercial game. I'm happy to pay if it's not too much.</p>

<p>Thanks for any advice.</p>

<p><em>UPDATE</em></p>

<p>After some more research (google), I came across this passage. Thought this might be useful for other people, although it still seems in contradiction to what the replies are saying on stack overflow <a href=""https://stackoverflow.com/questions/2277703/license-of-popular-dictionary-word-lists-e-g-sowpods-twl-copyright-tradema"">here</a></p>

<p>""The nearest thing to a licence text for ENABLE, of which ABLE forms a part, is as follows. </p>

<p>The ENABLE master word list, WORD.LST, is herewith formally released
into the Public Domain. Anyone is free to use it or distribute it in
any manner they see fit. No fee or registration is required for its
use nor are ""contributions"" solicited (if you feel you absolutely
must contribute something for your own peace of mind, the authors of
the ENABLE list ask that you make a donation on their behalf to your
favorite charity). This word list is our gift to the Scrabble community,
as an alternate to ""official"" word lists. Game designers may feel free
to incorporate the WORD.LST into their games. Please mention the source
and credit us as originators of the list. Note that if you, as a game
designer, use the WORD.LST in your product, you may still copyright and
protect your product, but you may <em>not</em> legally copyright or in any way
restrict redistribution of the WORD.LST portion of your product. This
<em>may</em> under law restrict your rights to restrict your users' rights,
but that is only fair.</p>

<p>M Cooper and Alan Beale
""</p>

<p>From this site
<a href=""http://www.quinapalus.com/dicts.html"" rel=""nofollow noreferrer"">http://www.quinapalus.com/dicts.html</a></p>

<p>Obviously I have no way of knowing if that's legit or not, so I was wondering what other peoples advice still is.</p>
","<p>According to the site you linked your list from: </p>

<blockquote>
  <p>The official Scrabble player's dictionary, known as OSPD, is widely available on the internet. There is also a list targetted at Scrabble players known as the Enable list. This has been explicitly placed in the public domain.</p>
</blockquote>

<p>In addition, <a href=""http://www.puzzlers.org/dokuwiki/doku.php?id=solving%3awordlists%3aabout%3astart"">the page</a> the link resides on contains numerous other lists of words that are free to use.</p>

<p><strong>EDIT</strong></p>

<p>You found in your update, what I'd already said in my answer. Additionally, the SE link you've posted has plenty of alternative answers. For example: <a href=""http://dreamsteep.com/projects/53-the-english-open-word-list-eowl.html"">The English Open Word List</a>, has more words that the OSPD and it's restriction free. Beyond that, the Enable list, as I said in my answer, seems to be a very good choice and is in the public domain.</p>
","28047"
"What are the pros and cons of incorporating Lua into a C++ game?","15024","","<p>I have a C++ game programming book and it has a Lua section in it. I've started to read the Lua section, and it sounds interesting, but I can't determine the pros and cons of using Lua in my C++ game. The only benefit I can currently think of is that you can make some coding updates, via Lua, without having to recompile. Other than that, I can't think of anything. So what are the pros and cons of adding Lua to a C++ game?</p>

<p>Examples would be appreciated.</p>
","<blockquote>
  <p>The only benefit I can currently think of is that you can make some coding updates, via Lua, without having to recompile.</p>
</blockquote>

<p>Do not discount the utility of this so easily. You will <em>never</em> understand how productive you will be until you take away the recompilation step.</p>

<p>The <a href=""http://en.wikipedia.org/wiki/Flow_%28psychology%29"">""flow""</a> is a fairly well-understood psychological concept when it comes to work. The flow is that feeling you get when you're focused on an activity, when you're analyzing and solving problems almost without thinking, etc. You are at your most productive when you are ""flowing"".</p>

<p>Compile times screw all of that up. It's hard to stay in the flow if you have even a 10-second compile between testing something.</p>

<p>When you are developing gameplay, what you usually have is a ""tight loop"". You have an idea, you code up a test to see if it works, and then you try it out. If it doesn't work, you modify it and try again. The ""code-to-test"" time is very important for maintaining flow. Getting it as small as possible is crucial.</p>

<p>What Lua (or any embedded scripting language) allows you to do is to test changes, not just without ""compiling"", but <em>live in the game</em>. Depending on how you build your game, you can run a command that will restart the game with new scripts without having to stop and reload data and so forth. Not only do you not have to recompile, you don't have to re-run.</p>

<p>The ability to do this, given the proper engine support, can dramatically increase productivity.</p>

<hr>

<p>Another major benefit to scripting is the ability to just not care. If you've spent a long time writing C++, you would be amazed at how much time you spend over minutae. Where memory is deleted. Where this gets freed. Even if you're using <code>shared_ptr</code> everywhere, just the act of typing in all of those variable type names slows you down.</p>

<p>In a dynamically-typed scripting language, you don't have to care. Scoping is simple. Functions are first-class objects; you don't have to manually build functors. It is just so <em>easy</em> to do some things.</p>

<p>Now that does have negatives, if you're not a disciplined programmer. It's very easy to use globals in Lua (though there are ways to prevent that). Not caring means that you can be very sloppy when you code.</p>

<p>But then again, <a href=""http://www.laputan.org/mud/mud.html#BigBallOfMud"">being very sloppy can have advantages</a>.</p>

<hr>

<p>Another upside of Lua is that it makes a nice data description language. Much like JSON is just a JavaScript file that builds and returns an array/table, you can make Lua scripts that return tables.</p>

<p>This is useful for configuration files; Lua's table format is a lot better than .ini formats. The format is still rather clean, compact, and extensible.</p>

<p>Oh, and it's still a Lua script, so it can perform actual logic. The downside of that is... well, it's a <em>Lua script, so it can perform actual logic</em>. That could be disastrous in game, since the user could potentially start screwing things up.</p>

<p>But actually, this is easily dealt with. Lua is designed for embedding, which means that isolation is actually quite easy. Indeed, a fresh Lua state provides <em>nothing</em> by default; you have to actually do something to expose even the most basic of the standard Lua libraries. File access, game-state access, etc, is all opt-in, not opt-out. And each Lua state is separate from each other one. The Lua state you use for AI scripts does not have to be the Lua state you use for config files.</p>

<p>I actually have some code that allows you to register many Lua standard libraries, but goes through and removes all file IO. Ultimately, the worst that a Lua script-based configuration file could do is cause your game to crash immediately upon running it, by running it out of memory. And since you're not sharing these config files manually, that wouldn't be much fun for a hacker.</p>

<hr>

<p>I would say that the biggest downside of any scripting language is debugging. Most scripting languages do not have debuggers, and Lua is no different. Lua does have all of the tools one would need to build debugging tools. But it does not actually have a debugger built-in. You have to put one together. And that's going to require a reasonable degree of work.</p>

<p>Or you can make due with ""printf debugging"". It really depends on how much Lua code you write.</p>
","18288"
"How do I find artists to work on my game?","15016","","<p>I ask ""how"" rather than ""where"" because there are undoubtedly lots of artists that are just plain lousy or unreliable.</p>

<p>Let's assume both paying and non-paying (mods, free games/open-source) positions.</p>
","<p>One tip I've heard is to <strong>build as much of the game as possible before looking for artists</strong>. Build the game with placeholder art before you post about the game so that artists can get a feel for the game, its play style and environment, etc before building assets for it. They can also use the prototype to decide if it's a project they'd actually like to work on.</p>

<p>Another tip I've heard is to avoid asking for people to ""join your team"" as this seems ""noobish"". Instead post the prototype and say that you need an artist or artists to finish it. If you post at the right communities someone will almost always come along that is interested.</p>

<p>You can, of course, pay an artist per asset, etc from a more ""professional"" site. This is really a personal choice. Modelers, musicians, voice actors, etc can all be hired from sites that can be found with some quick googling. However keep in mind that you should still provide these people with as much of a game as possible so they can create something that ""fits"". You can also easily determine if a model will deform properly, light well, etc before accepting the asset if you have build as much of the game as possible beforehand.</p>

<p>One final note, if you are building any artist tools: be sure to have them rock solid and well documented before sending them to an artist, or you will waste time and money sending them revised versions of the tool or having them rebuild assets.</p>
","779"
"My game crashed... Access Violation (0xc0000005)","14992","","<p>I guess this is the first official crash I've had in Unity (that is not just an infinite loop.) The game works just fine in the editor but when build and run it, the game won't even start.</p>

<p>I just keep getting this error message:</p>

<p><a href=""https://i.stack.imgur.com/21kNR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/21kNR.png"" alt=""enter image description here""></a></p>

<p>So I check the folder specified but I have no idea what I'm looking at if I'm completely honest with my self. I see a bunch of directories and stuff but that's about it. I don't know how to read an error log but I'd like to. This whole game is a learning experience so I would to learn how but Idk what to do.  </p>

<p>this is the error log : <a href=""http://ryanmhenry1995.weebly.com/uploads/5/6/5/1/56519861/error.log"" rel=""nofollow noreferrer"">Here</a></p>

<p>If need be I'll put it in the question but I'd like to avoid making this too long. If you have any questions about my code you need to know let me know. </p>
","<p>Well this is embarrassing... I had some compiler errors showing up in the editor from me converting some game Objects to transforms. I changed them back to gameObjects and everything works fine. I was just trying to save a little memory. but thank you guys for your advise down in the comments.</p>
","110786"
"Real-time multiplayer game server development","14985","","<p>I'm an Android developer, and I want to start developing a real-time multiplayer game, like <a href=""http://pocketlegends.com/"" rel=""nofollow"">Pocket Legends</a>.</p>

<p>Would this type of server be good for a real-time multiplayer action game - <a href=""http://systembash.com/content/a-simple-java-udp-server-and-udp-client/"" rel=""nofollow"">http://systembash.com/content/a-simple-java-udp-server-and-udp-client/</a>?</p>

<p>I'm absolutly new to server development, so it would be great if you explaind even more about this stuff ...</p>
","<p>I'm working on my first multiplayer game as well. It can be daunting just learning the problems specific to multiplayer, so I highly recommend that you get good at making single player ones first.</p>

<p>First, see if any of the game/networking engines fit your needs. For an Android game especially, starting with a well-developed toolset is almost always a good idea. Here are some of the popular ones that I know of:</p>

<ul>
<li><a href=""http://unity3d.com/"">Unity</a></li>
<li><a href=""http://www.madewithmarmalade.com/"">Marmalade</a></li>
<li><a href=""http://www.jenkinssoftware.com/"">Raknet</a></li>
<li><a href=""http://www.exitgames.com/"">Photon Network Engine</a></li>
</ul>

<p>If you decide to implement the networking code yourself, or if you're curious, you'll need to start learning about the best techniques. After lots of reading myself, I've found these guides to be a cut above the rest:</p>

<ul>
<li><a href=""http://gafferongames.com/networking-for-game-programmers/"">Gaffer on Games: Networking for Game Programmers</a></li>
<li><a href=""https://developer.valvesoftware.com/wiki/Source_Multiplayer_Networking"">Source Multiplayer Networking</a></li>
<li><a href=""http://www.gabrielgambetta.com/?p=11"">Gabriel Gambetta: Fast-Paced Multiplayer</a></li>
</ul>

<p>There are many resources available for almost anything you need to learn if you search for them.</p>
","23684"
"How to enable/ disable GameObject","14974","","<p>I have child object with ParticleSystem component.
I want to have particles disabled until I press button.</p>

<p>I unchecked child object to make it disabled but when I press play it enables automatically(with no scripts attached). Then I made this script below (with .SetActive(false) part only) and it worked.</p>

<p>But then I needed to activate it somehow, which I did, but now when I press play, object is automatically enabled/ activated again.</p>

<p>Is there another way of doing this because I need it haha.</p>

<pre><code>var particle1: GameObject;
var particle2: GameObject;
var particle3: GameObject;

public var triggered : boolean = false;

function OnTriggerEnter() { triggered= true; }
function OnTriggerExit()  { triggered= false;}

function Start()
{
    particle1.SetActive(false);
    particle2.SetActive(false);
    particle3.SetActive(false);
}

function Update()
{
    if (triggered &amp;&amp; Input.GetKeyDown(KeyCode.JoystickButton1))
        particle1.SetActive(true);
        particle2.SetActive(true);
        particle3.SetActive(true);
}
</code></pre>
","<p>It might be related to your Update function:</p>

<pre><code>function Update()
{
    if (triggered &amp;&amp; Input.GetKeyDown(KeyCode.JoystickButton1))
        particle1.SetActive(true);
        particle2.SetActive(true);
        particle3.SetActive(true);
}
</code></pre>

<p>Having no brackets, only particle1.setActive(true) is in the condition. The other two will be called on each Update() loop. Try adding brackets and see if the problem persists:</p>

<pre><code>function Update()
{
    if (triggered &amp;&amp; Input.GetKeyDown(KeyCode.JoystickButton1))
    {
        particle1.SetActive(true);
        particle2.SetActive(true);
        particle3.SetActive(true);
    }
}
</code></pre>
","81323"
"Where is quality paid game music?","14966","","<p>Where may I find quality game music for reasonable fees?  I'm willing to pay for the music, but I hope it is well done.</p>
","<p><a href=""http://www.jamendo.com/"" rel=""nofollow noreferrer"">http://www.jamendo.com/</a> is a decent place, no idea on prices though.</p>

<p>EDIT: Looks like an online game is $36.</p>

<p>Eric Matyas at <a href=""http://soundimage.org/"" rel=""nofollow noreferrer"">http://soundimage.org/</a> creates custom tracks at very low cost...he also offers tons of tracks for free (with attribution.)</p>
","1054"
"What should I keep in mind when making 2D games for multiple resolutions?","14960","","<p>I'm making a 2D (Android) game. Android devices vary quite a lot in screen resolution; what do I need to keep in mind when making my game?</p>

<ul>
<li>Do I need to keep big versions of all images and scale down depending on the resolution (doesn't that waste space)?</li>
<li>Do bitmap fonts scale well or do I need to use something else?</li>
<li>Anything else I'm forgetting?</li>
</ul>
","<p>I'm the developer of an extremely portable mobile game that runs on everything from PCs, to TVs, to even the Black &amp; White Amazon Kindle (Smiles HD - <a href=""http://smileshd.com"">http://smileshd.com</a> - More devices and platforms than you see there).</p>

<p>The best way I've found to support any device is to pick a base resolution, then scale up (or down) to the current screen. If you want to cheat, you can fit to the new screen resolution, but ideally you should keep the same aspect ratio.  Fitting a game made for a 4:3 display looks hideous on a 16:9, but fitting a 16:9 on to a 16:10, nobody might notice. You'll note I refer to screens by aspect ratio and not the dimensions, which is especially helpful way to think in this era of totally random LCD sizes.</p>

<p>To make artwork that suits any screen while maintaining the aspect ratio, create backgrounds that are larger than most typical screens will ever see.  This is similar to the concept title-safe areas with Television.</p>

<p><a href=""http://en.wikipedia.org/wiki/Safe_area"">http://en.wikipedia.org/wiki/Safe_area</a></p>

<p>Generated backgrounds work really great for this. Tiled patterns, checkerboards, fractal shapes, etc. You just need generate a little bit more to fit a new screen.</p>

<p>Also, creating static images larger than what your typical user will see. Wider than widescreen (16:9), and squarer than standard def (4:3). Again back to title-safe areas, fit your important information in to a safe area, scale up a bit so your safe area touches one of the edges of your screen, and leave some run-off for devices that are just a little bigger.</p>

<p>A variation I'm working with today is creating ""title safe"" 3D objects. Since they're 3D, composed entirely of vertices, making them larger than the screen takes up practically no more memory than if they were to fit. Just as the density of pixels goes up, you may want some higher detail textures available. If not, oh well, it's a little blurry.</p>

<p>User interfaces, I like to fit the main UI within a perfect square in the middle of the screen. The corners and the middle edges also make really good places to put things; You should calculate their coordinates as such (relative the corner or the middle edges).</p>

<p><a href=""http://www.smileshd.com/press/iPad/png/UI01.png"">http://www.smileshd.com/press/iPad/png/UI01.png</a></p>

<p>If you really want to get fancy, you can support both Tall and Wide orientations. Some devices do report their screen resolutions as taller than wide (iPhone for example), so you may have to do something for those devices anyways, even if it's simply rotating all of your coordinates.</p>

<p>A User Interface that adapts to both tall and wide screens can be a pretty impressive sight.</p>

<p>Wide: <a href=""http://www.smileshd.com/press/iPad/jpg/SmilesHD01.jpg"">http://www.smileshd.com/press/iPad/jpg/SmilesHD01.jpg</a></p>

<p>Tall: <a href=""http://www.smileshd.com/press/iPad/jpg/SmilesHD02.jpg"">http://www.smileshd.com/press/iPad/jpg/SmilesHD02.jpg</a></p>

<p>On the plus side, design wise, you only really need to consider Tall and Wide, instead of Portrait+Reverse Portrait+Landscape+Reverse Landscape. When you pick the positions of things on the screen, consider having a more appropriate alternative position for the other orientation.</p>

<blockquote>
  <p>Do I need to keep big versions of all images and scale down depending on the resolution (doesn't that waste space)?</p>
</blockquote>

<p>Well you can either ""waste space"" and support a wider variety of devices with a single build, or ""waste your time"" and have to make MANY builds and resize artwork for many devices. </p>

<p>Best case, you should create your artwork at higher resolution than the final size would be on a 1080p Television (1920x1080). 2048x2048 should be a common size in your source artwork. Either that, or consider using Vector artwork tools like Flash and Adobe Illustrator.</p>

<p>I'd strongly recommend creating an automated process for resizing your artwork. Most mobile devices today, tablets included, do not exceed resolutions greater than 720p (1280x720)... at least, not by much. Come next year though, we just don't know if that will be true anymore (iPad 3?).</p>

<p>Either way, for best performance, you should get used to the idea of source artwork and source assets. You can then perform a process that optimizes the data for whatever device(s) you are targeting.</p>

<blockquote>
  <p>Do bitmap fonts scale well or do I need to use something else?</p>
</blockquote>

<p>They scale well if you're using a good filtering. If you're making your 2D game with 3D hardware (OpenGL ES), then I must strongly recommend that you use Linear Filtering combined with MipMapping (i.e. a set of scaled down images). You can get perceptively perfect results with this, and it's often faster to use mipmaps than not to.</p>

<p><a href=""http://en.wikipedia.org/wiki/Mipmapping"">http://en.wikipedia.org/wiki/Mipmapping</a></p>

<p>Anyways, I hope that helps. Best of luck with your project.</p>
","20317"
"Unity: OnCollisionEnter not called","14904","","<p>I created a sphere object, added a rigidbody component (no kinematics) and attached a script to it like this:  </p>

<pre><code>function Update () {
}

function OnCollisionEnter(collision : Collision) {
    Debug.Log(""OnCollisionEnter"");
}
</code></pre>

<p>I then created a cube under the ball, added a box collider component with no trigger of course.  </p>

<p>Then, when I run the game, the ball falls down onto the cube, but nothing happens. The <code>OnCollisionEnter</code> function isn't called.  </p>

<p>What should I do?</p>
","<p>I move the comment here, so we can eventually close the post. </p>

<p>Remember that both <code>GameObject</code> MUST have a <code>Collider</code> attached in order the <code>OnCollisionEnter</code> to be called.</p>

<p>As side notes:</p>

<ul>
<li>A <code>MeshCollider</code> cannot collide with another <code>MeshCollider</code>.</li>
<li>Even if your colliders as marked as <code>trigger</code>, at least one of the 2 <code>GameObject</code> 
involved must have a <code>RigidBody</code> attached.</li>
<li>Collision between <code>GameObject</code> can be selective enabled depending on the layer the <code>GameObject</code>'s belong to. Have a look at <a href=""http://docs.unity3d.com/Documentation/Components/LayerBasedCollision.html"" rel=""nofollow"">Layer-Based Collision Detection</a>.</li>
</ul>
","50776"
"Why do most video game guns reload without losing unused ammo in the magazine?","14902","","<p>If I have picked up 500 spare ammo and I 73/100 bullets in my current gun, why will I end up with 473 spare ammo instead of 400 (losing the 73 unused rounds in the previous magazine)?</p>

<p>Is this just to make it easier on the player?</p>

<p>I want to make a challenge shooting game and it seems like timing your reloads would be interesting.</p>

<p>Is there any reason I should stick to the norm?</p>
","<p>It's not true that ""every game ever made"" uses the reloading mechanic you've described. I can think of least one (Red Orchestra) that didn't, and others which I believe didn't as well (Day of Defeat, Rainbow Six). </p>

<p>But that's not the point.</p>

<p>This is simply a game mechanics decision, often made because the designers felt that the complexity introduced by a more complex or realistic reloading mechanic would not add any additional fun to the game (and in fact might actively annoy players). It's not all that dissimilar from the choice not to require characters to feed themselves, or stop for bathroom breaks, in most games.</p>

<p>Thus, the decision was made to opt for a simply mechanic that eschews realism in favor of a system that treats every gun as having a giant continuous ""hopper"" of bullets you just dump your spares into when you reload.</p>

<p>If you think you can build an interesting, fun mechanic by forcing players to be more careful with their reloads (and I think it's totally doable), then by all means go for it.</p>
","56821"
"Shader that ""cuts"" hole through all geometry","14898","","<p>How can I create a shader that ""cuts"" through all geometry, only rendering the clearing background in Unity? An example:</p>

<p><img src=""https://i.stack.imgur.com/1mfAz.png"" alt=""enter image description here""></p>

<p>That's a prism in a huge white box-shaped room. The surface of the prism is just rendering the skybox of the scene (a starry sky). I used multiple cameras, which is pretty inefficient... There must be a way with just shaders.</p>

<p>How can I do this?</p>
","<p>Ok, finally figured it out!</p>

<p><img src=""https://i.stack.imgur.com/rV7YH.png"" alt=""enter image description here"">
<p>
You see how the sphere mesh “cuts” through the cylinder and plane all the way to the skybox. This took me longer than expected to figure this out but thanks to a wiki page (<a href=""http://wiki.unity3d.com/index.php/DepthMask"" rel=""nofollow noreferrer"">http://wiki.unity3d.com/index.php/DepthMask</a>) I got it all sorted.</p>

<p>Before using the shader setup in the wiki page I was using three different cameras with different clearing/depth flags to achieve the same result. It worked but it totally choked on the Ouya. The above solution requires only one camera and runs much fasta.</p>

<p>So I setup the scene like such…</p>

<ol>
<li><p>added a realistic skybox (nasa)</p></li>
<li><p>added some shapes</p></li>
<li><p>added the SetRenderQueue script to the plane, sphere and cylinder</p></li>
<li><p>set the queue order on the sphere to 2999 (the other objects are at 3000)</p></li>
<li><p>then added the DepthMask shader to the sphere</p></li>
</ol>

<p>That’s it. Any questions let me know!</p>
","73000"
"How do I integrate bullet physics into my game?","14822","","<p>I downloaded the release file found <a href=""http://code.google.com/p/bullet/downloads/list"">here</a>, but I'm just not sure where to start. In my game I have a number of oblongs and a sphere, I want all of these to collide with one another. (They all have meshes and associated bounding volumes)</p>

<p>edit - I just realised the cuboids actually have AABB's associated with them. I guess I'll have to change that at least.</p>

<p>What are the steps I need to follow?</p>
","<p>Here's the basic steps you'll need to folow:</p>

<ol>
<li><p>First <strong>create a world</strong> object (i.e. <code>btDiscreteDynamicsWorld</code>) to drive your physics simulation.</p></li>
<li><p>You should already have a class such as <code>GameObject</code> that perhaps stores a model along with its bounding box and position/orientation in the world. <strong>Replace</strong> the <strong>position/orientation</strong> information <strong>with</strong> an instance of a physics <strong>body</strong> object (i.e. <code>btRigidBody</code>) and when rendering the model, use the information provided by the body instead. When creating the body you'll need to provide its mass and collision shape which should match the bounding volumes you already have. I've talked about this in <a href=""https://gamedev.stackexchange.com/a/23368/11686"">your other question</a> too.</p></li>
<li><p><strong>Add</strong> each of your game object's <strong>bodies to the world</strong> object.</p></li>
<li><p><strong>Update the simulation</strong> by stepping the world (i.e. calling <code>stepSimulation</code> on your world).</p></li>
</ol>

<p>And take some time to <a href=""http://bullet.googlecode.com/svn/trunk/Bullet_User_Manual.pdf"" rel=""nofollow noreferrer"">read the manual</a> as it has a lot of  information too.</p>

<hr>

<p><strong>Edit to address comment</strong></p>

<blockquote>
  <p>I cringe before I ask but... how do I do the very very basic stuff like simply including the right files in my game? If you need specifics I'm looking for the files that will deal with rigid body collisions. Also thank you very much for the help so far! </p>
</blockquote>

<p>Well, it would appear from your comment that you've never worked with external C++ libraries before. It's been a while since I did this, but this is how I remember the process to be (in Visual Studio).</p>

<p>For starters I quote the manual which already explains what you need:</p>

<pre><code>- #include “btBulletDynamicsCommon.h” in your source file 
- Required include path: Bullet/src folder 
- Required libraries: BulletDynamics, BulletCollision, LinearMath
</code></pre>

<p>And here's the basic steps you will have to follow to fulfill the conditions above...</p>

<p><strong>1. Preparation Step</strong></p>

<p>First of all, extract the file you downloaded into a known directory, e.g. <code>C:\Bullet</code>. You'll need to know the path to this folder later.</p>

<p>Inside there are two folders that you will need to reference in your project. The first is the <code>src</code> folder which holds the <code>.h</code> header files that you will <em>include</em> in your source code. The second is the <code>lib</code> folder which will hold the <code>.lib</code> library files that you will <em>link</em> to your project. Notice that including and linking are two different things.</p>

<p>But the <code>lib</code> folder should be empty for now, because you haven't <em>built</em> the engine yet. So refer to the manual on how to build the project using CMake and Visual Studio for instance. It's on page 7.</p>

<p>After you succeed, you should have at least three files in the <code>lib</code>folder: <code>BulletDynamics.lib</code>, <code>BulletCollision.lib</code> and <code>LinearMath.lib</code> (I am guessing from the manual). Now to make the connection between Bullet and your project...</p>

<p><strong>2. Include Headers</strong></p>

<p>First of all, you'll need to add the <code>C:\Bullet\src</code> folder to your project's include path options. You can do so in Visual Studio by right-clicking on your project, navigating to <code>Configuration Properties -&gt; C/C++ -&gt; General -&gt; Additional Include Directories</code> and writing the directory path in there.</p>

<p>After setting that up, you can simply do <code>#include “btBulletDynamicsCommon.h”</code> on your code. That header seems to serve as an hub to all features you require.</p>

<p><strong>3. Link Libraries</strong></p>

<p>Finally you'll need to link the libraries mentioned above. Frist, under <code>Configuration Properties -&gt; Linker -&gt; General -&gt; Additional Library Directories</code> add the path to the <code>lib</code> folder, or in other words, <code>C:\Bullet\lib</code>.</p>

<p>Then, under <code>Configuration Properties -&gt; Linker -&gt; Input-&gt; Additional Dependencies</code>, add the name of the libraries to the list of dependencies. Separate each library with a <code>;</code> and don't forget the file extension. So for instance, you might <em>add</em> this to the end of the list: <code>BulletDynamics.lib;BulletCollision.lib;LinearMath.lib</code>.</p>

<p>After this you should be able to build and run your project.</p>
","23370"
"What are the steps to instantiate a button in Unity?","14800","","<p>Given a Canvas <code>test_canvas</code> containing a Button <code>test_button</code> and an empty GameObject that manages instantiation and scripts and the like called <code>test_manager</code>, what are the steps to instantiate this button through code as opposed to having it already there? </p>

<p>I've tried making the button a prefab and instantiating it as I would any other object but that didn't work. I tried making the canvas a prefab and then trying the button but nothing. I've searched around for quite some time and there's mention of RectTransform and SetParent but steps or specific details would clear up my confusion </p>
","<p>Prefab your Canvas and a Button and add this script to the test_manager gameobject</p>

<pre><code>using UnityEngine;
using System.Collections;
using UnityEngine.UI;

public class TestManagerScript : MonoBehaviour {
public GameObject canvas;
public GameObject button;

    void Start () {
        GameObject newButton = Instantiate(button) as GameObject;
        newButton.transform.SetParent(newCanvas.transform, false);
    }
}
</code></pre>

<p>be sure to drag the prefab button and prefab canvas to the public field slots this creates on the test_manager gameobject.</p>

<p>If you are also Instantiating the canvas you want to keep in mind that the UI will display from top to bottom as it is listed in the hierarchy. So you would want something like this.</p>

<pre><code> void Start () {

        GameObject newCanvas = Instantiate(canvas) as GameObject;
        GameObject newButton = Instantiate(button) as GameObject;
        newButton.transform.SetParent(newCanvas.transform, false);
    }
</code></pre>
","103736"
"What is a good book on physics for game development?","14775","","<p>I'm looking for a good beginners' book on the subject of physics in game development. Something that focuses on 2D games would be preferable.</p>
","<p>I am going to make a recommendation based on what I have read and how I started. Now I am assuming that when you say <em>beginner</em> you mean a <em>beginner</em> in physics engines and not programming. I won't write details as you can get that from the Amazon reviews.</p>

<p><a href=""http://rads.stackoverflow.com/amzn/click/0123819768"">Game Physics Engine Development</a></p>

<p>This book was a very good introductory book for me. Although like every book, it has shortcomings (some code does not work as expected but that's fine, forces you to think even more!)</p>

<p><a href=""http://rads.stackoverflow.com/amzn/click/1558607323"">Real-Time Collision Detection</a></p>

<p>Absolutely wonderful book/reference but a little more advanced. You can start with this book if you like. It depends on what your <em>beginner</em> level really is.</p>

<p><a href=""http://rads.stackoverflow.com/amzn/click/0123749034"">Game Physics</a></p>

<p>This is not for beginners, but it is something to keep in mind. All of Eberly's book's are math heavy but once you understand the full subject, his books, in my opinion become indispensable simply because there are a rare few people knowledgeable enough to delve into that much detail.</p>

<p>It is not going to be an easy ride. Physics is one of the tougher topics in game development. Good luck!</p>
","16366"
"How to compute tangent and bitangent vectors","14770","","<p>I have a texture loaded in three.js, then passed to the shaders. In the vertex shader I compute the normal, and I save into a variable the uv vector.  </p>

<pre><code>&lt;script id=""vertexShader"" type=""x-shader/x-vertex""&gt;

                varying vec3 N,P;
                varying vec2 UV;

                void main() {
                    gl_Position= projectionMatrix * modelViewMatrix * vec4(position,1.0);
                    P= position;
                    N= normalMatrix * vec3(normal);
                    UV= uv;
                }
            &lt;/script&gt;
            &lt;script id=""fragmentShader"" type=""x-shader/x-fragment""&gt;

                varying vec3 N,P;
                varying vec2 UV;
                uniform sampler2D texture;

                void main() {
                    gl_FragColor= texture2D(texture,UV);
                }

            &lt;/script&gt;
</code></pre>

<p>How do I compute the T and B vectors?</p>
","<p>First of all, for every 3D vertex there is infinite tangent and bi-tangent vectors. The below image explains why there is an infinite number of tangent spaces for each vertex, the tangent and bitangent can have any direction in the shown plane.</p>

<p><img src=""https://i.stack.imgur.com/ypaD6.png"" alt=""Infinite number of tanget spaces for each vertex""></p>

<p>So inorder to properly calculate the most useful<sup>1</sup> tangent space, we want our tangent space to be aligned such that the x axis (the tangent) corresponds to the u direction in the bump map and the y axis (bitangent) corresponds to the v direction in the bump map, we should already have normal of the vertex which already corresponds to the Z direction in tangent space.</p>

<p><sub> (1) most useful because in the end we want normal vectors to be sampled from the texture </sub></p>

<p>That best be explained with pictures, we want our <a href=""https://gamedev.stackexchange.com/questions/63832/normals-vs-normal-maps/63833#63833"">tangent space</a> to be aligned like <code>(u, v)</code> shown below.</p>

<p><img src=""https://i.stack.imgur.com/i3jRFm.png"" alt=""enter image description here""></p>

<p><a href=""http://www.sedris.org/stc/2004/tu/srm/"" rel=""noreferrer"">Source of the image though not strictly related to computer graphics</a></p>

<p>In computer graphics developers usually use <code>(u,v)</code> also known as texture coordinates.
We will assume T is the tangent and B is the bitangent, and <code>P0</code> is our target vertex, that is part of the triangle <code>(P0,P1,P2)</code>.</p>

<p>First remember what we wanted to do, is to calculate tangent and bitanget that:</p>

<ol>
<li>T aligned with u and B aligned with v.</li>
<li>T and B lays in the plane with the vertex normal (the plane shown in the above image).</li>
</ol>

<p>The point is we already assumed that T and B lays in the same plane and corresponds to U and V now if we can know their values we  can cross product and the third vector to construct a transformation matrix from world to tangent space.</p>

<p><img src=""https://i.stack.imgur.com/0x3QEm.jpg"" alt=""enter image description here""></p>

<p>Given that we know that any 2D vector can be written as a linear combination of two independent vectors<sup>2</sup> and since we already have the triangle points (edges), shown in the above image. We can write:</p>

<blockquote>
  <p>E1 = (u1-u0)T + (v1-v0)B</p>
  
  <p>E2 = (u2-u0)T + (v2-v0)B</p>
</blockquote>

<p><sub>(2) actually that's is how basis matrix is derived</sub></p>

<p>The above equation can be written in a matrix form,</p>

<pre><code>| E1x E1y E1z |   | deltaU1 deltaV1 | * | Tx Ty Tz |
| E2x E2y E2z | = | deltaU2 deltaV2 |   | Bx By Bz |
</code></pre>

<p>By solving the matrixs equation we can determine T and B values we can construct a transformation matrix.</p>

<p>The full source code in C++</p>

<pre><code>#include ""Vector4D.h""


struct Triangle
{
    unsigned short  index[3];
};


void CalculateTangentArray(long vertexCount, const Point3D *vertex, const Vector3D *normal,
        const Point2D *texcoord, long triangleCount, const Triangle *triangle, Vector4D *tangent)
{
    Vector3D *tan1 = new Vector3D[vertexCount * 2];
    Vector3D *tan2 = tan1 + vertexCount;
    ZeroMemory(tan1, vertexCount * sizeof(Vector3D) * 2);

    for (long a = 0; a &lt; triangleCount; a++)
    {
        long i1 = triangle-&gt;index[0];
        long i2 = triangle-&gt;index[1];
        long i3 = triangle-&gt;index[2];

        const Point3D&amp; v1 = vertex[i1];
        const Point3D&amp; v2 = vertex[i2];
        const Point3D&amp; v3 = vertex[i3];

        const Point2D&amp; w1 = texcoord[i1];
        const Point2D&amp; w2 = texcoord[i2];
        const Point2D&amp; w3 = texcoord[i3];

        float x1 = v2.x - v1.x;
        float x2 = v3.x - v1.x;
        float y1 = v2.y - v1.y;
        float y2 = v3.y - v1.y;
        float z1 = v2.z - v1.z;
        float z2 = v3.z - v1.z;

        float s1 = w2.x - w1.x;
        float s2 = w3.x - w1.x;
        float t1 = w2.y - w1.y;
        float t2 = w3.y - w1.y;

        float r = 1.0F / (s1 * t2 - s2 * t1);
        Vector3D sdir((t2 * x1 - t1 * x2) * r, (t2 * y1 - t1 * y2) * r,
                (t2 * z1 - t1 * z2) * r);
        Vector3D tdir((s1 * x2 - s2 * x1) * r, (s1 * y2 - s2 * y1) * r,
                (s1 * z2 - s2 * z1) * r);

        tan1[i1] += sdir;
        tan1[i2] += sdir;
        tan1[i3] += sdir;

        tan2[i1] += tdir;
        tan2[i2] += tdir;
        tan2[i3] += tdir;

        triangle++;
    }

    for (long a = 0; a &lt; vertexCount; a++)
    {
        const Vector3D&amp; n = normal[a];
        const Vector3D&amp; t = tan1[a];

        // Gram-Schmidt orthogonalize
        tangent[a] = (t - n * Dot(n, t)).Normalize();

        // Calculate handedness
        tangent[a].w = (Dot(Cross(n, t), tan2[a]) &lt; 0.0F) ? -1.0F : 1.0F;
    }

    delete[] tan1;
}
</code></pre>

<p>Full source code and derivation can be found <a href=""http://www.terathon.com/code/tangent.html"" rel=""noreferrer"">here</a>.</p>
","68617"
"Blender - exporting .obj with texture coords","14762","","<p>I'm writing a game which uses obj files. I created an object in blender and I applied texture without UV coordinates and my question is: how to export this object to obj file, but with texture coordinates?</p>
","<p>As you already noticed, there's no way around UV coordinates for games. Thankfully, blender comes with some very good UV unwrapping tools.</p>

<p>The simplest way to get UV coordinates from a 3D model in blender is to use <em>Smart UV Project</em>. You can do that by pressing <kbd>U</kbd> while in edit-mode and then select ""Smart UV Project"" from the menu.</p>

<p>This creates UV ""patches"" given some angular threshold. The result can look like this:</p>

<p><img src=""https://i.stack.imgur.com/sSX7m.png"" alt=""UV coordinates created by &quot;Smart UV Project&quot;""></p>

<p>Done, you've got UV coordinates now. However, these coordinates are most likely not that useful, since you'll end up with a ton of seams. A good unwrapped mesh has less seams, preferably at places where they can easily be hidden (eg. where an uniform color meets) or where the seams will be obstructed by other geometry. That's why you usually mark the seams yourself (in edit-mode select the edges that should be a seam and press <kbd>Ctrl</kbd> + <kbd>E</kbd> and select ""Mark Seam"" in the menu). Then use the regular ""Unwrap"" (not ""Smart UV Project"") to unwrap the mesh,</p>

<p>Good UV unwrapping is hard and requires practice. This <a href=""http://www.blendercookie.com/2011/01/21/intro_uvmapping/"">video-tutorial</a> might help you getting started.</p>
","16139"
"OpenGL - Understanding the relationship between Model, View and World Matrix","14713","","<p>I am having a bit of trouble understanding how these matrixes work and how to set them up in relation to one another to get a proper system running.</p>

<p>In my understanding the Model Matrix is the matrix of a object, for example a cube or a sphere, there will be many of these in the application/game.</p>

<p>The World Matrix is the matrix which defines the origin of the 3D world. the starting point.</p>

<p>And the View Matrix is the ""camera"" everything gets translated with this to make sure you have the illusion of an actual camera when in fact everything is moving instead of this matrix?</p>

<p>I am a bit lost here. So I was hoping someone here could help me understand this properly.</p>

<p>Does every modelMatrix get translated/multiplied with the world matrix and the worldMatrix then with the viewMatrix? Or does every modelMatrix get translated/multiplied with the viewMatrix and then that with the worldMatrix?</p>

<p>How do all these matrixes relate and how do you set up a world with multiple objects and a ""camera""?</p>

<p><strong>EDIT:</strong></p>

<p>Thanks a lot for the feedback already. I did some googling aswel and I think I do understand it a bit better now, however would it be possible to get some pseudo code advice?</p>

<pre><code>projectionMatrix = Matrix;
makePerspective(45, width, height, 0.1, 1000.0, projectionMatrix);

modelMatrix = Matrix;
identity(modelMatrix);
translate(modelMatrix, [0.0, 0.0, -10.0]);  // move back 10 on z axis

viewMatrix = Matrix;
identity(viewMatrix);
// do some translation based on input with viewMatrix;
</code></pre>

<p>Do I multiply or translate the viewMatrix with the modelMatrix or the other way around? and what then? I currently have a draw method up in such a way that it only needs 2 matrixes for arguments to draw.</p>

<p>Here is my draw method:</p>

<pre><code>draw(matrix1 matrix2) {

            bindBuffer(ARRAY_BUFFER, cubeVertexPositionBuffer);
            vertexAttribPointer(shaderProgram.getShaderProgram().vertexPositionAttribute, cubeVertexPositionBuffer.itemSize, FLOAT, false, 0, 0);

            bindBuffer(ARRAY_BUFFER, cubeVertexColorBuffer);
            vertexAttribPointer(shaderProgram.getShaderProgram().vertexColorAttribute, cubeVertexColorBuffer.itemSize, FLOAT, false, 0, 0);

            bindBuffer(ELEMENT_ARRAY_BUFFER, cubeVertexIndexBuffer);

            setMatrixUniforms(shaderProgram, matrix1, matrix2);

            drawElements(TRIANGLES, cubeVertexIndexBuffer.numItems, UNSIGNED_SHORT, 0);


}
</code></pre>

<p>What are those matrixes suppose to be? 
Thanks a lot in advance again guys.</p>
","<p>Within a 3D rendered scene, there are typically three main matrices used to transform an object from its own local space (object/model space) to a homogeneous space known as screen space. </p>

<p><strong>World</strong></p>

<ul>
<li>The World matrix being the first, is unique for every object within your world, and is responsible for transforming the vertices of an object from its own local space, to a common coordinate system called world space.</li>
</ul>

<p><strong>View</strong></p>

<ul>
<li>After that, the view matrix provides the concept of a mobile camera, when it reality the camera is actually the only constant point of reference within the world. The view matrix is a transformation that is applied to every object in the scene (but is not unique to each object), and provides the illusion of a camera. The view matrix is basically the inverse of what could be considered a world matrix for the camera. Yet instead of moving the camera itself, it provides the opposite movements to the rest of the scene (the illusion ;) ).</li>
</ul>

<p><strong>Projection</strong></p>

<ul>
<li>Finally the projection matrix is responsible for converting a 3D world into the homogeneous screen space that you see on your screen. This is the matrix used to represent your view frustum, and is usually represented as an orthographic or perspective projection.</li>
</ul>

<p>At the simplest level, every one of your objects needs to contain its own world matrix, your ""scene"" or whichever context you use must contain a view matrix to represent a camera, and a projection matrix to convert world coordinates to screen coordinates. All of these then need to be passed to the vertex shader (with the world matrix changing for each object, but not necessarily the view or projection) to be transformed.</p>
","56203"
"Analysis of Mario game Physics","14692","","<p>I know there's a breakdown of Sonic the Hedgehog physics found <a href=""http://info.sonicretro.org/Sonic_Physics_Guide"">here</a>, and I was wondering, does there exist a breakdown of any of the Mario games? Something similar to this but for Mario is what I'm interested in!</p>
","<p>found a detailed breakdown of Mario Physics:</p>

<p><a href=""http://forums.mfgg.net/viewtopic.php?p=346301"">http://forums.mfgg.net/viewtopic.php?p=346301</a>
<a href=""http://i276.photobucket.com/albums/kk21/jdaster64/smb_playerphysics.png"">http://i276.photobucket.com/albums/kk21/jdaster64/smb_playerphysics.png</a></p>
","55052"
"Making a HUD/GUI with OpenGL (LWJGL)","14665","","<p>I'm at the stage in my game development where I need to make a HUD or GUI. I've never gotten to this part, so I don't know how its done. I tried rendering a simple quad at a fixed position on the screen, but there's a problem. To make my camera work with orthographic, I use this:</p>

<pre><code>public void lookThrough()
{
    GL11.glMatrixMode(GL11.GL_PROJECTION);
    GL11.glLoadIdentity();
    GL11.glOrtho(position.x, position.x + Display.getDisplayMode().getWidth()/zoom, position.y + Display.getDisplayMode().getHeight()/zoom, position.y, -1, 1);
    GL11.glMatrixMode(GL11.GL_MODELVIEW);
}
</code></pre>

<p>I don't see how I would be able to make something fixed on the screen using this method? Any way around this? Thanks :)</p>
","<p>This is from an old OpenGL-based game engine I was trying to write about seven years ago written in C++ so bare with me as I try to explain how I handled 3D world and 2D GUI rendering operations within it. I used four primary methods within my OpenGL renderer class (OGLRender) of which are:</p>

<ul>
<li><strong>ready3D()</strong> for preparing OpenGL to render the 3D world scene.</li>
<li><strong>ready2D()</strong> for preparing OpenGL to render the 2D GUI.</li>
<li><strong>render3D()</strong> for the actual 3D world scene drawing.</li>
<li><p><strong>render2D()</strong> for the actual 2D GUI drawing.</p>

<pre><code>void OGLRender::ready3D()
{
    glViewport(0, 0, m_Setup.width, m_Setup.height);
    glMatrixMode(GL_PROJECTION);

    glLoadIdentity();
    gluPerspective(45, (float) m_Setup.width / m_Setup.height, 0.1, 5000.0);

    glMatrixMode(GL_MODELVIEW);
    glLoadIdentity();

    glDepthFunc(GL_LEQUAL);
    glEnable(GL_DEPTH_TEST);
}

void OGLRender::ready2D()
{
    glMatrixMode(GL_PROJECTION);
    glLoadIdentity();

    gluOrtho2D(0.0f, m_Setup.width, m_Setup.height, 0.0f);

    glMatrixMode(GL_MODELVIEW);
    glLoadIdentity();
    glTranslatef(0.375, 0.375, 0.0);

    glDisable(GL_DEPTH_TEST);
}

void OGLRender::render3D()
{
    this-&gt;ready3D();

    // ... draw 3D world scene here ...
}

void OGLRender::render2D()
{
    this-&gt;ready2D();

    // ... draw GUI here ...
}
</code></pre></li>
</ul>

<p>And then in the main thread loop I would basically just call the methods in the following order:</p>

<pre><code>while(m_drawFrame)
{
    gm_Render-&gt;render3D(); // draw 3D scene
    gm_Render-&gt;render2D(); // draw GUI

    SDL_GL_SwapBuffers(); // make drawn frame visible
}
</code></pre>

<p>So, what I am doing is I draw my 3D world scene first and then I draw my GUI last that way the GUI is always on top of the world scene. <strong>ready3D()</strong> method gets the 3D world projection ready for world scene drawing and <strong>ready2D()</strong> method gets the 2D ortho scene ready for GUI drawing. <code>m_Setup.width</code> and <code>m_Setup.height</code> are just the view port screen dimensions.</p>

<p>What is special about the <strong>ready2D()</strong> method is that <code>gluOrtho2D()</code> function is called with arguments that tell it when we draw the GUI primitives we draw them in the screen coordinates specified to match Windows, Mac, and other desktop screen coordinate systems. Such as top-left is (0,0) in (X,Y) format while bottom-right is <code>(ViewportWidth-1, ViewportHeight-1)</code>. And <code>glTranslatef()</code> is used to correct for per-pixel accurate positioning. So that when we draw a line from (0,0) through (0,9) then the line will actually draw from the top-left and straight down ten pixels total in length and one pixel width.</p>

<p>Overall you're most likely just interested in what the <strong>ready2D()</strong> method is doing. I provided the other methods' source code examples to give you an idea as to generally how most games do 3D world scene and GUI drawing order.</p>
","18478"
"2D Tile-based Collision Detection","14654","","<p>I've been planning an indie game project for a while now. I'll summarise it for you so I can get right to the question.</p>

<p>It's done entirely using the latest version of XNA through Visual Studio. Hoping to put it on 360 and PC, but am only really looking for a PC-oriented solution at this stage.</p>

<p>It's a 2D side-scrolling shooter (think Metroidvania-style, or even Terraria). It will eventually include an in-game map editor with maps being tile-based (16x16). There will be upwards and downwards scrolling. I'm hoping to implement tile layers in the dev map editor (reason for a dev map editor is it's going to be heavily leaning towards a content-focus, so there will be a lot of maps).</p>

<p>Physical tiles will be very simple with only two major types. Block tiles, which are just a solid tile, and angled tiles, which are tiles with an incline that characters can walk on. I'm strongly considering abandoning angled tiles entirely, but not sure yet.</p>

<p>The character/NPC movement will be simple. Moving side-to-side, jumping, falling, flying (with appropriate items/situations), teleporting. All very static, no dynamic physics necessary. Only basic gravity. When a character steps off the edge of a tile, it falls. When it jumps and a tile is above it, it stops short and falls back down. When it reaches a protruding tile/wall, it can't move further unless it jumps over or flies. All the basic stuff.</p>

<p>Projectiles can be affected by gravity as well, and some situations may arise where a projectile may be manipulated mid-flight, but nothing requiring heavy physics. Some projectiles will move characters as well (think a simple ""pushing"" mechanic).</p>

<p><strong>So here's the question:</strong> I'm at the stage where I'm starting to work on movement and collision-detection but I just can't set myself on a way to go about them. I need ways to determine when character, tiles, and projectiles collide. Given what I've said about the style I'm going for and the tile-based system I'm using, <strong>can I get some recommendations+links to some tried and true collision detection methods others have used in similar situations, and maybe an example of a game using a similar approach?</strong> What I need more than anything else is inspiration.</p>

<p><em>And just a quick note, I have several years of experience as a programmer, so I'm not a total newbie :)</em></p>
","<p>I just discovered <a href=""http://higherorderfun.com/blog/2012/05/20/the-guide-to-implementing-2d-platformers/"">http://higherorderfun.com/blog/2012/05/20/the-guide-to-implementing-2d-platformers/</a> and seems a pretty good overview on 2D platformers. I haven't finished reading it, but i think it can help you a lot!</p>

<p>Also i can recommend <a href=""http://info.sonicretro.org/Sonic_Physics_Guide"">http://info.sonicretro.org/Sonic_Physics_Guide</a>, which is broad overview on physics techniques used in Sonic.</p>
","29696"
"Parse/Write JSON with Unity iOS","14631","","<p>anybody know a tutorial or maybe can help me to develop a parser/reader for JSON compatible with Unity iOS pro? I've already tried different third part libraries but without luck (i've tried json.net, jsonfx, litjson).</p>

<p>Im pretty in hurry of doing a simple parser/writer that i can use also under iOS and not only in Desktop.</p>

<p>P.s. i can also use third part library, but please, first of suggest be sure that it will work under iOS!
Thank you all</p>
","<p>I've tested a lot and finally i've found this: <a href=""https://gist.github.com/1411710"" rel=""nofollow"">https://gist.github.com/1411710</a></p>

<p>It'is not the best, but is iOS friendly and fit pretty well for now.</p>

<hr>

<p>Matt i dont have test the library that you suggest me, but when i will find some free time i will test and let you know :)</p>

<p>If someone find some other library (a porting of Json.net would be beutiful) please post :)</p>
","44727"
"How to split a 2D sprite tile set into individual sprites?","14573","","<p>I see a lot of sprite catalogs for games provided as single PNG image, like the one below.
<img src=""https://i.stack.imgur.com/1ON8a.png"" alt=""enter image description here""></p>

<p>I'm interested if I have to manually create tiles from that, or if there's some program that can split it into various tile combinations for me? For example, given the tile combination below, I will have to create a flat grass surface, and 8 other combinations with various edges. Is there something that can automate this task?</p>

<p><img src=""https://i.stack.imgur.com/tqdal.png"" alt=""enter image description here""></p>
","<p>After a bit of struggling, I found this info:</p>

<p>1) <a href=""http://renderhjs.net/shoebox/"" rel=""nofollow noreferrer"">Shoebox</a> is an app that takes the map like I listed in the question and attempts to <strong>Extract Sprites</strong>, typically a whole blob of terrain</p>

<p><img src=""https://i.stack.imgur.com/I5oK0.png"" alt=""Shoebox sprite settings""></p>

<p><img src=""https://i.stack.imgur.com/HH8I0.png"" alt=""enter image description here""></p>

<p>2) What I wanted to do next was <strong>split this image into 9 tiles</strong>, and be able to reassemble them in various combinations. Shoebox also seems to be able to do this (<strong>Extract Tiles</strong>). This creates a TMX files</p>

<p><img src=""https://i.stack.imgur.com/tEyk3.png"" alt=""Shoebox bitmap settings""></p>

<p>3) It seems that the next step is to import the resulting .TMX map into <strong>a tile map editor</strong>, like Tiled: <a href=""http://www.mapeditor.org/download.html"" rel=""nofollow noreferrer"">http://www.mapeditor.org/download.html</a> . From the video, it seems that I would be able to rearrange tiles and create various combinations I need.</p>

<p>It appears that ShoeBox has a bug on mac where it appends the folder name before the png file name (Line 4) within the TMX file, so I had to remove it manually : </p>

<pre><code>name=""[REMOVE FOLDER]base_.... 
</code></pre>

<p><img src=""https://i.stack.imgur.com/8kp3V.png"" alt="".tmx file""></p>

<p>List of frameworks that support TMX maps: <a href=""https://github.com/bjorn/tiled/wiki/Support-for-TMX-maps"" rel=""nofollow noreferrer"">https://github.com/bjorn/tiled/wiki/Support-for-TMX-maps</a></p>
","67398"
"Good Tutorial For Lua and LÖVE","14565","","<p>I want to make a very simple 2D game, and have been reading a lot of good things about <a href=""http://love2d.org/"">LÖVE</a>, so I want to try it out. However I can't seem to find any good tutorials. The ones on the LÖVE page are rather unstructured, and the other one I found by Mathew Casperson is not very useful. Does anyone know of a better tutorial?</p>
","<p>Disclaimer: I've created the two tutorials I'm going to link here</p>

<p>I've done two tutorials. None of them is complete, but will get you from 0 to 80% quickly.</p>

<p>The first one is a LÖVE-centric one called love-tile-tutorial:</p>

<p><a href=""https://github.com/kikito/love-tile-tutorial"">https://github.com/kikito/love-tile-tutorial</a></p>

<p>It's about 50% done. Starts with the basics, and deals with Images &amp; Quads, as well as an introduction to Lua.</p>

<p>love-tile-tutorial is on hold at the moment, though - I'm doing other projects, such as the second tutorial.</p>

<p>The second tutorial concentrates in Lua itself - this is, not for LÖVE specifics, but for Lua in general; it actually works entirely from the console. It's a series of exercises for learning the language itself better. It's called Lua Missions:</p>

<p><a href=""https://github.com/kikito/lua_missions"">https://github.com/kikito/lua_missions</a></p>

<p>I realize this is not exactly what you wanted (since not all LÖVE is covered), but I'm putting it here in case anyone finds it useful.</p>
","13575"
"How do we solve big video memory requirements in a 2D game?","14550","","<p>How do we solve big video memory requirements in a 2D game?</p>

<hr>

<p>We are developing a 2D game (Factorio) in allegro C/C++, and we are facing a problem with increasing video memory requirements as the game content increases.</p>

<p>We currently gather all the info about images that are going to be used first, crop all of these images as much as possible and organize them into big atlases as tightly as possible. These atlases are stored in video memory, the size of which depends on the system limitations; currently it is usually 2 images of up to 8192x8192, so they require 256Mb to 512Mb video memory.</p>

<p>This system works pretty good for us, as with some custom optimisations and splitting the render and update thread we are able to draw tens of thousands of images on the screen in 60 fps; we have many objects on the screen, and allowing a big zoom-out is a critical requirement. As we would like to add more, there is going to be some trouble with the video memory requirements, so this system can't possibly hold.</p>

<p>One of the things we wanted to try is to have one atlas with the most common images, and the second as a cache. The images would be moved there from the memory bitmap, on demand. There are two problems with this approach:</p>

<ol>
<li>The drawing from memory bitmap to video bitmap is painfully slow, in allegro.</li>
<li>It is not possible to work with video bitmap in other than the main thread, in allegro, so it is practically unusable.</li>
</ol>

<hr>

<p>Here are some additional requirements we have:</p>

<ul>
<li>The game must be determistic, so the performance issues/loading times can never alter the game state.</li>
<li>The game is real time, and soon to be multiplayer, as well. We need to avoid even the smallest stutter at all costs.</li>
<li>Most of the game is one continuous open world.</li>
</ul>

<hr>

<p>The test consisted of drawing 10 000 sprites in a batch for sizes from 1x1 to 300x300, several times for every configuration. I did the tests on the Nvidia Geforce GTX 760.</p>

<ul>
<li>Video bitmap to video bitmap drawing took 0.1us per sprite, when the source bitmap wasn't changing between individual bitmaps (the atlas variant); the size didn't matter</li>
<li>Video bitmap to video bitmap drawing, while the source bitmap was switched between drawings (non atlas variant), took 0.56us per sprite; the size didn't matter, either.</li>
<li>Memory bitmap to video bitmap drawing was really suspicious. Sizes from 1x1 to 200x200 took 0.3us per bitmap, so not so horribly slow. For larger sizes, the time started to raise very dramatically, at 9us for 201x201 to 3116us for 291x291.</li>
</ul>

<p>Using atlas increases the performance by a factor greater than 5.
If I had 10ms for the rendering, with an atlas I'm limited to 100 000 sprites per frame, and without it, a limit of 20 000 sprites. This would be problematic.</p>

<p>I was also trying to find a way to test the bitmap compression and 1bpp bitmap format for shadows, but I was unable to find a way to do this in allegro.</p>
","<p>We have a similar case with our RTS (KaM Remake). All units and houses are sprites. We have 18 000 sprites for units and houses and terrain, plus another ~6 000 for team colors (applied as masks). Long-stretched we also have some ~30 000 characters used in fonts.</p>

<p>So there are some optimizations against RGBA32 atlases you are using:</p>

<ul>
<li><p>Split your sprites pool into many smaller atlases first and use them on demand as covered in other answers. That also allows to use <strong>different optimizations techniques for each atlas individually</strong>. I suspect you will have a bit less of a wasted RAM, cos when packing to such a huge textures there are usually unused areas at the bottom;</p></li>
<li><p>Give a try to using <strong>paletted textures</strong>. If you use shaders you can ""apply"" the palette in the shaders code;</p></li>
<li><p>You might look into adding an option to use <strong>RGB5_A1 instead of RGBA8</strong> (if for example checkerboard shadows are okay for your game). Avoid 8bit Alpha when possible and use RGB5_A1 or equivalent formats with smaller precision (alike RGBA4), they take half the space;</p></li>
<li><p>Make sure you are <strong>tightly packing sprites into atlases</strong> (see Bin Packing algorithms), rotate sprites when necessary and see if you can overlap transparent corners for rhombus sprites;</p></li>
<li><p>You might try <strong>hardware compression formats</strong> (DXT, S3TC, etc.) - they can dramatically reduce RAM usage, but check for compression artifacts - on some images the difference can be unnoticeable (you can use this selectively as described in first bullet point), but on some - very pronounce. Different compression formats cause different artifacts, so you might pick one that is best for your art style.</p></li>
<li><p>Look into <strong>splitting big sprites</strong> (of course not manually, but within your texture atlas packer) into static background sprite and smaller sprites for animated parts.</p></li>
</ul>
","73997"
"Why has the industry switched from C to C++?","14549","","<p>First of all i would like to have a real answer, i'm always trying to get more from various sources and articles, and when I read things like <em>C++ is slow because it has virtual functions</em> and because of this <em>C is better</em>, i really don't know what to say and think as an human being with a brain. So please avoid to reach this level in your answer/s.</p>

<p>My question is about a massive switch to C++ that was completed, more or less, with Doom 3.</p>

<p>The interesting thing for me is that before this milestone, most of the game engines and the games itself were written in C, just like it was since the <em>Quake era</em>. It's also interesting to note that the ID software decide to completely rewrite the codebase for the IdTech 4 in C++, a massive amount of work that honestly i can't understand without a really good list of reasons.</p>

<p>I'm focusing on Doom 3 because I am mainly interested in the OpenGL world and in my journey i try to stay focused on this topic, so i read a lot about this, but i think that a question like that can be render-API-agnostic without too much problems.</p>

<p><strong>Why at a certain point in time the industry switched massively to C++ ? What are the reasons for the choice that ID made ?</strong></p>

<p>The last thing that i would like to say is that the C language is much more simple to implement and provides a less number of features, because of this has much less chance to be ""fragmented"" in pieces unlike the C++ really often does. In simplest terms i have much more chances to find a really good C compiler rather than a good C++ compiler with all the features implemented in a good way.</p>

<p>For example the NDK for Android still doesn't have a good C++ support ( with the r8b release ) with all the latest and greatest features, and it's the native toolkit for the most popular mobile OS in the world!</p>

<p>If I had wrote my code in a modern C++ I would probably be in pain now because one of the most popular OS in the world would be off-limits for me. And like Android, many other compilers are not that great.</p>

<p><strong>I should write C++ code referring to a C++ version that is 2-3 release old ?</strong></p>
","<p>C++ does everything C does.  You can trivially mix C and C++ in cases where the advantages of C outweigh those of C++.  This is a very intentional design decision of C++.</p>

<p>C++ does things that C does not.  This includes easy polymorphism, but also easy compile time code generation via templates.  This is really handy for things like containers, which are easily C's biggest weakness.  It also allows user-defined pointer-like types (smart handles) that save lots of time, as well as user-defined primitive-like types such as vectors and matrices with operator support (also saves lots of time).</p>

<p>Virtual functions are slower than non-virtual functions.  However, you must opt in to virtual functions, and a competent programmer does so only when they're beneficial.  C programmers have function pointers and often store collections of those in struct referenced by other structs; in other words, they go through extra work to recreate the exact same thing as virtual function tables.  In cases where only a single function pointer is needed and no table is required, C++ still fully allows that and is equivalent to C.  With a modern compiler, C++ is only slower than C in the specific cases the programmer is opting in to a feature.  Also, the virtual function overhead in practice is very small on modem CPUs.  Hardware today is designed for C++'s usage patterns, and is even increasingly designed for high-level interpreted langiages' needs.</p>

<p>C++ exceptions historically impose a lot of overhead, making C++ slower even if you're not using them.  Exceptions were a terrible thing to add to C++, if for no other reason than the immense increase on complexity involved in writing exception-safe code, and in fact some container designs are literally impossible to make exception safe.  Game programmers often ignore exceptions' existence, and even disable them on the compiler.  Modern compilers have zero- overhead exceptions (that is, you only pay th cost for them when you actually use them).</p>

<p>C is simpler to learn all the rules of.  C++ is a very big, complex language.  C++ allows writing higher-level code, producing easier and simpler APIs.  Some people want to understand the language easier, some people want to write advanced code easier.  It's a trade off between simplicity of understanding what the compiler is doing with a specific piece of code vs the simplicity of writing large complex inter-connected applications.  Some folks value one far more than the other, for various reasons.</p>

<p>In the end, C++ is a superset of C.  In my opinion, there is no such this as a <em>highly competent</em> C++ programmer who is not also a passable C programmer (though there are a lot of C++ programmers who fall below my bar who would be lost in pure C).  While C++ adds facilities to insulate the programmer from much of C, non- trivial C++ code often does need to use C to get things done.  This is one of the primary difference between C++ and Java and C#. There's a reason that you often see ""C/C++"" lumped together, after all.</p>

<p>My personal belief -- which is shared with most other games industry professionals I've interacted with -- is that the enhanced expressiveness and high-level programming facilities of C++ outweigh the increased complexity of the language over C, and most of the other frequent anti-C++ claims made are simply out of date with today's technology. </p>
","34544"
"Pseudo-code examples of A*?","14516","","<p>I'm looking for pseudo-code examples of the A* pathfinding algorithm that actually <strong>works</strong>. I tried plenty of different ones where it's not really clear how to implement them at all times. Keep in mind that I'm a newbie, so if everything could be detailed, that'd be great.</p>
","<p>I think the pseudocode in the <a href=""http://en.wikipedia.org/wiki/A%2a_search_algorithm#Pseudocode"" rel=""nofollow"">Wikipedia article</a> is sufficiently detailed. If you need more details and a working implementation then <a href=""http://www.policyalmanac.org/games/aStarTutorial.htm"" rel=""nofollow"">A* Pathfinding for Beginners</a> is a good article. It has C++ sample code with comments.</p>
","19436"
"Efficient way of drawing outlines around sprites","14515","","<p>I'm using XNA to program a game, and have been experimenting with various ways to achieve a 'selected' effect on my sprites. The trouble I am having is that each clickable that is drawn in the spritebatch is drawn using more than a single sprite (each object can be made up of up to 6 sprites).</p>

<p>I'd appreciate it if someone could advise me on how I could achieve adding an outline to my sprites of X pixels (so the outline width can be various numbers of whole pixels).</p>

<p>Thanks in advance,</p>

<ul>
<li>Greg.</li>
</ul>
","<p>By far the easiest way to do this (so probably the best way, unless you are really strapped for performance) is to have two copies of your sprites.</p>

<ul>
<li>The regular version</li>
<li>A""fat"", uncoloured version - basically a white version of your sprite X-many pixels ""fatter"" than the original.</li>
</ul>

<p><strong>Draw your entire object using the ""fat"" version, then draw the regular version over the top.</strong></p>

<p>By making the ""fat"" version white, you can use SpriteBatch's built-in colour tinting to change the selection colour dynamically.</p>

<p>To generate your ""fat"" verison I recommend writing a <a href=""http://msdn.microsoft.com/en-us/library/bb447754.aspx"">Content Pipeline Extension</a> that can automatically take your original sprites, read their alpha channel, create a new alpha channel by sampling the maximum alpha channel in the original image X-many pixels around each pixel, and setting RGB = (1,1,1).</p>

<p>You will have to make sure your sprites all have sufficient transparent border to add the outline (you could check this in the content processor - and even make room if necessary).</p>

<p>If you only have a few sprites, then you could just use a good image editor (GIMP, Photoshop) and do it by hand: Alpha channel to selection, expand selection, selection to alpha, fill colour channels white.</p>
","3837"
"Confusion over GLViewport","14507","","<p>I'm hoping someone can help me understand the <strong>GLViewport</strong> and what happens when we resize it</p>

<p>This will illustrate my confusion....</p>

<p><img src=""https://i.stack.imgur.com/VFlfX.png"" alt=""enter image description here""></p>

<p>So, here I have a quad stuck in the middle of the screen.  If I have my GLViewport match the device's width and height, I get what is on the first (left hand) picture.  Exactly what I would expect.</p>

<ul>
<li>Device resolution, 2560 x 1600</li>
<li>Viewport resolution 2560 x 1600</li>
<li>Quad size 200 x 200 (Note, the image above is not to scale!!! :-))</li>
<li>Quad shape, appears as square</li>
</ul>

<p>Now, for the 2nd (right hand) picture...</p>

<ul>
<li>Device resolution, 2560 x 1600</li>
<li>Viewport resolution 2560 x 1200 (and centered vertically)</li>
<li>Quad size (200, 200)</li>
<li>Quad shape, appears as rectangle</li>
</ul>

<p>My question is, why is the quad displaying as a rectangle now and not a square?  I've confirmed by logging that my quad is 200 x 200 pixes - surely the size of the physical pixels stays the same?  They can't change.  So what is going on here?</p>

<p>I thought (clearly incorrectly) that when I scaled the viewport, it literraly just chopped off pixels.</p>

<p>Would appreciate if someone could explain how this works.</p>

<p><strong>Edit</strong></p>

<p>Currently, I'm setting my viewport like this:</p>

<pre><code>width = (int) Math.min(deviceWidth, deviceHeight * 1.702127659574468);    
height = (int) Math.min(deviceHeight, deviceWidth / 1.702127659574468);

ratio = width / height;
GLES20.glViewport(offsetX, offsetY, width, height);

Matrix.orthoM(mProjMatrix, 0, -ratio, ratio, -1, 1, 3, 7);
</code></pre>

<p>offsetX and offsetY are just so that when there are letterboxes, the viewport is centered.</p>
","<p>To understand what's going on, you have to understand the rendering pipeline:</p>

<p>Your geometry (the quad) is initially defined in world space, think of this as some global coordinate system. Inside of the vertex shader those are transformed to normalised device coordinates (NDC), a virtual coordinate system defined so, that everything from -1 to 1 will get drawn to the screen. Note, that NDC is ranging from -1 to 1 in X and Y, and it's totally independent of the devices aspect ratio and resolution. This transformation from world space to NDC is done by the model, view and projection matrix (in a simple form, just one matrix for everything or the geometry was even defined in NDC to begin with!).</p>

<p>The rasterisation unit needs to know where and how large it should raster and this is what you define with the glViewport call: where to start are the first two parameters, the size are the second two. The hardware will then convert from NDC to pixel coordinates by a simple scale and shift - and this is what you see in your example: a scale in the Y axis.</p>

<p>So to make sure your quad gets rendered in the correct aspect ratio, you also need to adjust the projection matrix to include the expected aspect ratio of the glViewport call.</p>
","77992"
"Bounding box of a rotated rectangle (2d)","14504","","<p>I can see this has been asked before in various ways. I am struggling to work it out though hence asking again.</p>

<p>2d sprite that moves and rotates. I'm looking to contain it in a bounding box as it appears that is the most efficient way to do collision detection.</p>

<p>I had no problems getting it to work without rotation but that is simple! Now the sprite rotates I can't seem to find the right way of writing the code.</p>

<p>To create a bounding box for the sprite, my understanding is I need to work out the 4 corners of the sprite after rotation and use these to work out the width + height of the correctly sized bounding box.</p>

<p>I've used the article here - <a href=""http://msdn.microsoft.com/en-us/library/dd162943(v=vs.85).aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/dd162943(v=vs.85).aspx</a> - specifically the formula:</p>

<pre><code>x' = (x * cos A) - (y * sin A) 
y' = (x * sin A) + (y * cos A)
</code></pre>

<p>The code I'm currently using:</p>

<pre><code>x1 = (positionX * Math.cos(rotation)) - (positionY * Math.sin(rotation));
y1 = (positionX * Math.sin(rotation)) + (positionY * Math.cos(rotation));

x2 = (positionX+width/2 * Math.cos(rotation)) - (positionY+height/2 * Math.sin(rotation));
y2 = (positionX+width/2 * Math.sin(rotation)) + (positionY+height/2 * Math.cos(rotation));
</code></pre>

<p>positionX and positionY is the current top left hand corner position of the sprite.</p>

<p>rotation is the radians the sprite has been rotated by (and rotation is from the centre).</p>

<p>width and height are of the sprite.</p>

<p>I thought the code above would give me the co-ordinates of the top left and top right corners of the rectangle, rotated appropriately. However, on my canvas, I'm drawing a line from x1,y1 to x2,y2 and it doesn't follow the sprite at all!</p>

<p>Any suggestions? Sorry for the long post!</p>

<p>Cheers!</p>
","<p>I always try to solve these geometrical problems using transformations instead of trigonometry, because at least for me it's easier to visualize. Here's how I do it on my application in XNA.</p>

<p>Let's say I have a sprite that's been translated, rotated and scaled arbitrarily and I want to fit an AABB to it. I only need to know two things about this sprite:</p>

<ul>
<li>The world matrix containing all three transformations combined</li>
<li>The sprite's <em>untransformed</em> extents (i.e. it's <em>original</em> width and height)</li>
</ul>

<p>(BTW, these two bits of information combined are also all you need in order to represent an OBB)</p>

<p>Knowing that, I proceed to calculate an AABB like this:</p>

<pre class=""lang-cs prettyprint-override""><code>// Calculate the position of the four corners in world space by applying
// The world matrix to the four corners in object space (0, 0, width, height)
Vector2 tl = Vector2.Transform(Vector2.Zero, matrix);
Vector2 tr = Vector2.Transform(new Vector2(extents.x, 0), matrix);
Vector2 bl = Vector2.Transform(new Vector2(0, extents.y), matrix);
Vector2 br = Vector2.Transform(extents, matrix);

// Find the minimum and maximum ""corners"" based on the ones above
float minX = Min(tl.X, Min(tr.X, Min(bl.X, br.X)));
float maxX = Max(tl.X, Max(tr.X, Max(bl.X, br.X)));
float minY = Min(tl.Y, Min(tr.Y, Min(bl.Y, br.Y)));
float maxY = Max(tl.Y, Max(tr.Y, Max(bl.Y, br.Y)));
Vector2 min = new Vector2(minX, minY);
Vector2 max = new Vector2(maxX, maxY);

// And create the AABB
RectangleF aabb = new RectangleF(min, max - min);
</code></pre>

<p>Maybe it's longer but at least I understand every step of the process this way.</p>
","20732"
"Fast, accurate 2d collision","14464","","<p>I'm working on a 2d topdown shooter, and now need to go beyond my basic rectangle bounding box collision system.</p>

<p>I have large levels with many different sprites, all of which are different shapes and sizes. The textures for the sprites are all square png files with transparent backgrounds, so I also need a way to only have a collision when the player walks into the coloured part of the texture, and not the transparent background.</p>

<p>I plan to handle collision as follows:</p>

<ol>
<li>Check if any sprites are in range of the player</li>
<li>Do a rect bounding box collision test</li>
<li>Do an accurate collision (Where I need help)</li>
</ol>

<p>I don't mind advanced techniques, as I want to get this right with all my requirements in mind, but I'm not sure how to approach this. What techniques or even libraries to try. I know that I will probably need to create and store some kind of shape that accurately represents each sprite minus the transparent background.</p>

<p>I've read that per pixel is slow, so given my large levels and number of objects I 
don't think that would be suitable. I've also looked at Box2d, but haven't been able to find much documentation, or any examples of how to get it up and running with SFML.</p>
","<ol>
<li>Step one, create a grid and update it for every object that moves.</li>
<li>Only check for collisions between objects in the same squares.</li>
<li>Check if the bounding box of the objects intersects (their containing rectangle).</li>
<li>Check for pixel perfect collision using a low res version of the outline(see Game Physics).</li>
<li>Do a normal check of the outline tracing as described in Game Physics (Q 2)</li>
</ol>

<p>Step 1:</p>

<p>Create a grid 2d array. Every object knows which squares it occupies by it's x,y position and it's width and height. If an object is moved away, it clears itself from the old square and updates the new square that it's occupying.</p>

<p>This only takes O(n) in total for n objects. For any specific object O(1).</p>

<p>Step 2:</p>

<p>Run all the checks for collisions between objects in the same squares. No need to run tests for collisions between objects in different squares. An object can occupy up to four squares if it is of average size. This means very few checks.</p>

<p>Step 3:</p>

<p>Check for intersection between the objects rectangles. If no intersection exists, stop.</p>

<p>Step 4:</p>

<p>Check for pixel perfect collisions between the outlines of the objects only inside the area of intersection. It should be fast enough. If not, create a low res 2d-boolean array and check it first, if you find collisions there, you would only need to check a small segment in the high res 2d-array saving you some precious time.</p>

<p>Please read this for concept on how to split your game world into a <strong>grid</strong> of squares:</p>

<p><a href=""https://gamedev.stackexchange.com/questions/38891/making-an-efficient-collision-detection-system/38893#38893"">Making an efficient collision detection system</a></p>

<p>Please read this for intuition on how to detect <strong>pixel perfect</strong> collisions.</p>

<p><a href=""https://gamedev.stackexchange.com/questions/38613/game-physics-2d-collision-detection-as3/38635#38635"">Game physics / 2D Collision detection AS3</a></p>

<p>You can improve performance significantly:</p>

<ol>
<li><p>Saving a low res (1 / 16) version of the outline to check against first.</p></li>
<li><p>Only checking in the area where the two rects intersect.</p></li>
<li><p>by dividing the outline roughly into segments, and
only checking for collisions between segments first.</p></li>
</ol>

<p>Please feel welcome to comment and I will elaborate.</p>

<p><img src=""https://i.stack.imgur.com/bgjGx.png"" alt=""check in the area of intersection""></p>
","39932"
"Unity Android versus android SDK","14452","","<p>I am familiar with Unity and in the process of learning android SDK when the announcement about unity android basic came out.</p>

<p>What would be the advantages and disadvantages of using the android SDK directly versus development using Unity Android?</p>
","<p><strong>Update Unity 5.x</strong> There is a detailed manual on how to write native code plugins and call them from within Unity <a href=""http://docs.unity3d.com/Manual/PluginsForAndroid.html"" rel=""nofollow"">http://docs.unity3d.com/Manual/PluginsForAndroid.html</a> </p>

<p><strong>!Since Unity 4.x has been already released, and Android went through a lot of changes you should consider this answer as a reference and not state of the art since it might be outdated!</strong></p>

<p>Sorry, but Ricket is wrong: Unity provides full access via API to the Android SDK, which is also required before working on Android Games with Unity:</p>

<blockquote>
  <p>Before you can run Unity Android games
  on the actual device, you'll need to
  have your Android developer
  environment set up. This involves
  downloading and installing the Android
  SDK with the different Android
  plaforms and adding your physical
  device to your system (this is done a
  bit differently depending on whether
  you are developing on Windows or Mac).
  This setup process is explained on the
  Android developer website, and there
  may be additional information provided
  by the manufacturer of your device.
  Since this is a complex process, we've
  provided a basic outline of the tasks
  that must be completed before you can
  run code on your Android device or in
  the Android emulator. However, the
  best thing to do is follow the
  instructions step-by-step from the
  Android developer portal. Access
  Android Functionality</p>
  
  <p>Unity Android provides a scripting
  APIs to access various input data and
  settings. You can find out more about
  the new scripting classes on the
  Android scripting page. Exposing
  Native C, C++ or Java Code to Scripts</p>
  
  <p>Unity Android allows you to call
  custom functions written in C/C++
  directly (and Java indirectly) from C#
  scripts. To find out how to bind
  native functions, visit the plugins
  page.</p>
</blockquote>

<p><a href=""http://unity3d.com/support/documentation/Manual/android-GettingStarted.html"" rel=""nofollow"">source unity manual</a></p>

<p><strong>Unity:</strong></p>

<ul>
<li>if you already have assets and more complex models</li>
<li>take advantage of many file formats</li>
<li>fast progress if you already have a design and know how the game should look like</li>
</ul>

<p><strong>Android SDK:</strong></p>

<ul>
<li>might consider this for programming starter 2D games</li>
<li>good start up to learn android basics which experience can be taken into further developement with Unity</li>
</ul>

<p>If you want to start developing a game on a certain level of quality, and want quick success you should choose Unity over the pure SDK, because Unity gives you a lot of tools which make it easier to develop without worrying for little things.</p>
","9184"
"Why is the origin in computer graphics coordinates at the top left?","14404","","<p>From what I've seen almost all things use coordinates where (0, 0) is at the top left and the positive Y-axis goes in the downwards direction of your screen.</p>

<p>Why is it like this? Why not the conventional positive Y-axis going upwards like shown in graphs in simple math classes?</p>
","<p>This is caused in the history. Early computers had Cathode Ray Tubes (CRTs) which ""draw"" the image with a cathode ray from the upper left corner to the lower right.</p>

<p>To ease the interface between the graphics card memory and the CRT the memory was read from the beginning and the image was drawn from the top left (with the lowest memory address) to the lower right (with the highest memory address).</p>

<p><strong>Extension (based on the comments)</strong></p>

<p>The CRTs are based on analog TV sets that were available at that time.</p>

<p>The TV sets create the image line by line first from <a href=""http://en.wikipedia.org/wiki/Analog_television#Displaying_an_image"">left to right and then from top to bottom</a>. The reason for this can only be assumed to be based on the writing style in western contries.</p>
","83571"
"How to remove an object from a std::vector","14400","","<p>So I have a vector of bullets that show up on the screen and I do not want these bullets to live forever. I want them to ""die as soon as they go off screen or collide with an enemy. How can I make sure they are removed from the array and no longer take up memory.</p>

<p>code:</p>

<pre><code>std::vector&lt;Bullet&gt; bulletArray;

for(int i=0; i&lt;bulletArray.size(); i++)
{
    bulletArray[i].MoveBullet();
    bulletArray[i].Draw();
    if(bulletArray[i].PosY&lt;0)
    {
        //Delete object forever 
    }
}
</code></pre>
","<p>There are two ways to do it:</p>

<ol>
<li><p>You can simply remove object i from the vector using <code>bulletArray.erase(bulletArray.begin() + i)</code> and then <code>i--</code> to process everything for the new bullet in i'th position. But this way vector will move all the object after the that specific bullet, meaning this kind of removal is O(bulletArray.size()).</p></li>
<li><p>But usually order of the bullets is not important, so you can simply put the last bullet  in the i'th cell, and only remove it's spot. This way it's much more faster since these operations are O(1). And it's implemented as <code>bulletArray[i] = bulletArray.back(); bulletArray.pop_back(); i--;</code>  again you need to decrement i by one to check this new object in this i'th position in the next loop.</p></li>
</ol>
","46585"
"How does one develop a first person shooter with a one man team?","14383","","<p>I have an idea for a first person shooter game and I have plenty of free time to work on it.</p>

<p>I know java and objective-c very well and I also know autodesk inventor (which is similar to 3ds max). </p>

<p>How would I go about starting to develop a small fps? What programming language should I use? What modeling/animation software should I use?</p>
","<p><a href=""http://the-witness.net/news/2011/06/how-to-program-independent-games/"">""How to Program Independent Games""</a> is a really good presentation from Jonathan Blow (creator of Braid) about how to take on the development of a game by yourself.</p>

<p>My best advice would be to make the smallest FPS you can (with any language/engine) and then expand on that.</p>

<p>Try <a href=""http://www.unity3d.com"">Unity</a>. That seems like the fastest way to make an FPS these days. Another way to do it would be to use an engine from another FPS such as, Half-Life, Quake or Unreal and basically make a total-conversion that in no way resembles the game the engine was made for. Counter-Strike was made this way. Heavily modding/totally converting a game is game development too.</p>
","15830"
"Rotating an object when the center in not the origin - opengl","14361","","<p>I'm beginning with GLSL and I learning the basic, I  am using glm to do the matrix calculations at this point everthing ok,the problem is how I can move the origin to the center of my object, not the other way round,
for example if I have a quad whose coordinates are 
bottom left  0,0.
bottom right 2,0.
top left     0,2.
top right    2,2.
how can I move the origin to the center of the quat without re-writing my coordinates?</p>
","<p>Easy way of building the rotation matrix:</p>

<ol>
<li>Start with an identity matrix</li>
<li>Translate the matrix by -centre of the object</li>
<li>Rotate the matrix by the desired amount</li>
<li>Translate the matrix by centre of the object</li>
<li>Use the resulting matrix to transform the object that you desire to rotate</li>
</ol>
","59849"
"What causes aliasing?","14304","","<p>I always hear about aliasing and anti-aliasing and I know what it looks like but what I don't understand is what causes it. Is it a physical phenomenon? Or a numerical one?</p>

<p>If it helps to explain, I have some programming knowledge, but not in video games or graphics.</p>
","<blockquote>
  <p>Is it a physical phenomena ? or numerical ?</p>
</blockquote>

<p>This question sorta implies to me that you don't actually know what aliasing/anti-aliasing means. I mean, you say you ""know what it looks like"" but if you actually knew what the terms mean, you'd probably realize your question is nonsensical. Aliasing is a side-effect of how computer graphics are rendered, and computer graphics are pretty much <em>by definition</em> not physical phenomena.</p>

<p>""Aliasing"" just refers to the stair-step look on angled lines because computer graphics are actually comprised of lots of tiny squares in a grid. Here's an image to illustrate what I'm talking about: 
<a href=""https://i.stack.imgur.com/9E394.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/9E394.jpg"" alt=""enter image description here""></a></p>

<p>This is an issue whenever you render the pixels in an image, whether you're drawing freehand or are writing an algorithm to calculate the pixels for a 3D polygon. It's just a side-effect of the fact that the image is a square grid of pixels. ""Anti-aliasing"" is when you disguise the stair-step look by blending the colors together along the edge pixels.</p>
","105891"
"You've killed the enemy you needed to get across. Now you have to die and retry?","14297","","<p>I am designing enemies for a platformer, and want to have enemies which the player utilises to get through levels.</p>

<p>I like the idea of jumping on enemies to platform across gaps, but it's problematic if they die. It feels really bad to put the player in an unwinnable state, having killed their means to platform across a level. It just feels messed up to be like, 'You've killed the enemy you needed to get across. Now you have to die and retry'.</p>

<p>What are some ways of fixing that problematic game state?</p>
","<p>Just have them <strong>respawn</strong></p>

<p>Have an enemy spawner which will either spawn enemies that fall to their own deaths or just respawn the enemy once you killed it (e.g. drop it out of a pipe like in the original Mario Bros).</p>
","151957"
"What are the pros and cons of GameSalad versus Cocos2D?","14280","","<p>I am currently using the Cocos2D framework for creating my game but I just happened to come across GameSalad and was amazed by <a href=""http://www.youtube.com/watch?v=W9cHfhx9z9M"" rel=""nofollow"">this video</a>.</p>

<p>GameSalad claims to allow you to create games without writing a single line of code. So I ask myself, what is the catch? What makes Cocos2D better than GameSalad? What are the pros and cons of GameSalad?</p>
","<p>GameSalad is good for either quickly prototyping ideas, or if you want to develop an iPhone game on your own but don't know anything about programming. If however you have even a little familiarity with programming then GameSalad has many significant cons. The most significant con is that it is simply a very restrictive development tool; I haven't looked at it in a long time so I don't know what features it has now, but last time I looked it didn't even have arrays (if you think about it, how could you represent arrays without programming?) It's hard or impossible to access a lot of iOS features, like Game Center. And then there's poor performance.</p>

<p>Cocos2D is a much more flexible and powerful development tool, but on the downside it's also considerably more complex to use. Working with Cocos2D you will be programming in Objective C using XCode; you can implement literally any feature that iOS is capable of, but it'll be a lot of work.</p>

<p>There is a middle ground you didn't mention: mobile game development platforms like <a href=""http://www.anscamobile.com/corona/"" rel=""nofollow"">Corona</a> and <a href=""http://getmoai.com/"" rel=""nofollow"">Moai</a>. These are tools that aren't quite as flexible as Cocos2D but are considerably more flexible and powerful than GameSalad. Meanwhile they use Lua for all the programming so working with these tools is considerably simpler than using Cocos2D. If you haven't done so already, I would strongly suggest evaluating one or both of these.</p>
","22796"
"What is a good file format for saving game data?","14269","","<p>I need to save some custom game data.  Map, player, etc.</p>

<p>All of them will have ""sub objects"".  For example,  a map and map will have an ""array"" of tiles.  ie, hierarchical data.  Hopefully nothing binary.</p>

<p>What would be a good format for these?</p>

<p>So far I'ved considered:</p>

<p><strong>Serailization:</strong> This is FAST and easy, but tends to break when I change the underlying classes :(</p>

<p><strong>XML:</strong> I really hate parsing this.  My test case was over 100+ lines of code and seemed likes tons of ""busy work"" for even a very simple format.</p>

<p><strong>INI:</strong> would be really clumsy for hierarchical data.</p>

<p><strong>Protobuf:</strong> Never used it, but read you have to do a lot of manual mucking around and breaks if you change the class.</p>

<p><strong>Other options?</strong> That's why I'm here!</p>

<p>Edit: this is Java btw.</p>

<p>Edit 2: </p>

<p>I settled on ""Controlled Binary Serialization"" (see below).  </p>

<p>Pros: </p>

<ul>
<li><p>it's fast</p></li>
<li><p>it's small (on disk) and can be easily compressed/decompressed during read/write.</p></li>
<li><p>it's super easy to read/write from game and toolset. </p></li>
<li><p>I can decide what to include/exclude of the object. </p></li>
<li><p>Objects/Data can be nested.</p></li>
</ul>

<p>Cons:</p>

<ul>
<li><p>Can't edit it by hand (like XML, YAML, etc)</p></li>
<li><p>Can't easily read/modify it with scripts </p></li>
<li><p>Java Serialization by default is pretty slow/bloated compared to other implentations, but it's stable and works</p></li>
</ul>
","<p>To display hierachical data, <a href=""http://www.yaml.org/"">YAML</a>  or <a href=""http://www.json.org/"">JSON</a> would be good options. They are <em>far</em> simpler and easier to parse than XML.</p>

<p>Another option would be a ""controlled"" binary serialization process. Every object writes it's state out in a controlled way, i.e.</p>

<pre><code>void player::save(savegame &amp;sgm)
{
    sgm.write(this-&gt;position);
    sgm.write(other properties);
    inventory.save(sgm);
}
</code></pre>

<p>id Tech 4 (Quake 4 / Doom 3 engine) uses such an approach.</p>
","19049"
"Do programmers in the industry get to participate in the game design process?","14245","","<p>My main goal is to create games which is why I'm planning on studying IT so I can later on be a game developer/programmer.</p>

<p>My question is: does a game programmer get involved in the game designing process or is that only the game designer's job? Is a game designer always needed or can programmers work on game design some of the time?</p>

<p>Do programmers need to have game designing knowledge or do they just follow orders? Similarly, do game designers require programming knowledge?</p>

<p>I'm kind of confused over what I want to be which is why I'm asking here. Basically, do game programmers also get to be game designers?</p>
","<p>It depends on the company. Roles and titles vary widely across the industry, so at some companies roles will be very rigid and strict and at others they will be more flexible and allow for more cross-discipline work.</p>

<p>It also depends on the person; some developers like to explore beyond their ""technical"" role or job title, others don't.</p>

<p>You'll probably find more flexibility in a <em>smaller</em> game company, but it's certainly possible to find the role flexibility you are hoping for in a larger one. You just need to be aware that's something you want and look for it during the interview process. Or start your own company where you can be everything and do everything.</p>
","126308"
"How can I store game metadata in a .png file?","14239","","<p>Spore allows player-created creatures to be shared by exporting a <code>.png</code> file. That <code>.png</code> is a photo of the creature, but if it's imported into the game, the creature's information (such as textures, size, and shape) also come with it.</p>

<p>How can I implement such a feature?</p>
","<p>If all you truly needed was the PNG file, chances are they just simply added the information into the file. This is actually a practice of <a href=""http://en.wikipedia.org/wiki/Steganography"">Steganography</a>. A lot of the times, this is used to hide payloads or secret messages in things that are seemingly public facing. However, it is likely in this case that this method is what was used. Typical Stegongraphy will go out of the way to hide the contents, but there is no reason why one could not simply append the data out of the image in the end of the file and retrieve it.</p>

<p>Several tools encode this data for you, a google search brings up at least <a href=""http://www.hermetic.ch/stpng/stpng.htm"">this</a> and <a href=""http://www.openstego.info/"">this</a>.</p>

<p>A PNG has the byte signature <code>$89</code> at the start, so it is possible that the information was inserted after the PNG structure itself and simply parsed by the SPORE game. </p>

<p>However, further research given by the other answers and a search on google reveals that Spore was actually using just a version of Stegongraphy to hide the information in the alpha bits. With this in mind, we can rule out the possibility of appended data or meta-data. </p>

<p>It should be noted that <strong>meta data</strong> is still a very viable choice, if the data is being parsed locally. If that information might be shared around the web or re-encoded, the export is not guaranteed to keep all your information. When pixel data is used, it can survive losless conversions without an issue. </p>
","72761"
"Why do games have hats?","14227","","<p>I noticed that a lot of games tend to have hats.  I was wondering why?  Is it some sort of tradition to add hats to your games?  What makes this trend so popular in game development?</p>
","<p>Players like to personalize their characters. Players also like to show off their achievements in the game to other players. Hats are a very easy to implement way to do that.</p>

<ul>
<li>Because they are right on top of the character's head, they are a very visible feature. A hat can usually be seen from most angles other players will usually see the character.</li>
<li>They don't have any joints which require complex animations. You can simply append them statically to the head-bone. That makes them simple to produce for 3d artists.</li>
<li>Novelty hats can have almost any shape imaginable, so the artists have a lot of creative freedom.</li>
<li>They are unlikely to interfere with any other features or animations of the character model.</li>
</ul>
","128720"
"What are the cons of using DrawableGameComponent for every instance of a game object?","14217","","<p>I've read in many places that DrawableGameComponents should be saved for things like ""levels"" or some kind of managers instead of using them, for example, for characters or tiles (Like this guy says <a href=""http://www.gamedev.net/topic/517783-xna-drawable-components-what-are-the-dos-and-donts/page__p__4364768#entry4364768"">here</a>). But I don't understand why this is so. I read <a href=""http://www.progware.org/Blog/post/XNA-Game-Development-%28Decentralize%29.aspx"">this post</a> and it made a lot of sense to me, but these are the minority. </p>

<p>I usually wouldn't pay too much attention to things like these, but in this case I would like to know why the apparent majority believes this is not the way to go. Maybe I'm missing something.</p>
","<p>""Game Components"" were a very early part of the XNA 1.0 design. They were supposed to work like controls for WinForms. The idea was that you would be able to drag-and-drop them into your game using a GUI (kind of like the bit for adding non-visual controls, like timers, etc) and set properties on them.</p>

<p>So you could have components like maybe a Camera or a... FPS counter?... or...?</p>

<p>You see? Unfortunately this idea doesn't really work for real-world games. The kind of components you want for a game aren't really reusable. You might have a ""player"" component, but it will be very different to every other's game's ""player"" component.</p>

<p>I imagine it was for this reason, and for a simple lack of time, that the GUI was pulled before XNA 1.0.</p>

<p>But the API is still usable... <strong>Here's why you shouldn't use it:</strong></p>

<p>Basically it comes down to what is easiest to write and read and debug and maintain as a game developer. Doing something like this in your loading code:</p>

<pre><code>player.DrawOrder = 100;
enemy.DrawOrder = 200;
</code></pre>

<p>Is much less clear than simply doing this:</p>

<pre><code>virtual void Draw(GameTime gameTime)
{
    player.Draw();
    enemy.Draw();
}
</code></pre>

<p>Especially when, in a real-world game, you might end up with something like this:</p>

<pre><code>GraphicsDevice.Viewport = cameraOne.Viewport;
player.Draw(cameraOne, spriteBatch);
enemy.Draw(cameraOne, spriteBatch);

GraphicsDevice.Viewport = cameraTwo.Viewport;
player.Draw(cameraTwo, spriteBatch);
enemy.Draw(cameraTwo, spriteBatch);
</code></pre>

<p>(Admittedly you could share the camera and spriteBatch using the similar <code>Services</code> architecture. But that is also a bad idea for much the same reason.)</p>

<p>This architecture - or <strong>lack thereof</strong> - is so much more light weight and flexible!</p>

<p>I can easily change the draw order or add multiple viewports or add a render target effect, just by changing a few lines. To do it in the other system requires me to <em>think</em> about what all those components - spread across multiple files - are doing, and in what order.</p>

<p>It's sort of like the difference between declarative vs imperative programming. It turns out that, for game development, imperative programming is far more preferable.</p>
","9209"
"Changing the color of a sprite at runtime","14210","","<p>Is there a form to change the color of a sprite in runtime?}</p>

<p>I have a black point loaded with an image, but i dont want to load various images with different colors, is there a mode to change the color in runtime and not loading lot of images?</p>

<p>And i want to tell it what part to color of the sprite, is it possible?</p>
","<p>I had to do something like this in XNA with pixel-art sprites. The best way i've found was using pixel shader.</p>

<p>The sprites are done in gray-scale (8 bits colors without alpha), then you'll have to map each gray-color to the correspondent 32 bit color you want, using a 256 lenght array of Colors.</p>

<p>In the shader you can use the gray colors of the sprite as a look-up table to the array of 32 bit colors.</p>
","25133"
"OpenGL vs OGRE : Which is the best for beginner?","14198","","<p>I am interested in getting into game development and posses good C/C++ programming skills. I have tried OGRE before, and I am curious whether I should learn either OGRE or OpenGL as a starting point.</p>

<p>From my understanding, OGRE is a wrapper for OpenGL and DirectX. So, supposed that I learn OGRE, do I still need to learn OpenGL as well to develop a game?</p>

<p>Also, can someone points me good tutorial for OpenGL? I found that OGRE is well documented (it's even come with the distribution!) but for OpenGL, most of the tutorials I came over are outdated.</p>
","<p>Ogre is indeed a wrapper for OpenGL, however the idea of such a wrapper is that you don't have to concern yourself with the intricacies of OpenGL. It will of course help to know a bit about OpenGL, but Ogre will hide a lot of the ugly details for you.</p>

<p>I would say that Ogre is arguably easier to learn as opposed to OpenGL, or at least it will get you interesting results faster. Of course it totally depends on what you would like to do to asses if it's worth learning OpenGL.</p>

<p>About OpenGL tutorials, yes most of them are pretty outdated, however the spec hasn't been moving forward really fast so a lot of those old tutorials still apply to most of OpenGL.</p>

<p>A few of my favourites:</p>

<ul>
<li><a href=""http://www.falloutsoftware.com/tutorials/gl/gl8.htm"" rel=""nofollow"">http://www.falloutsoftware.com/tutorials/gl/gl8.htm</a> (7 years old but the theory is still very solid!)</li>
<li><a href=""http://nehe.gamedev.net/data/lessons/lesson.asp?lesson=11"" rel=""nofollow"">http://nehe.gamedev.net/data/lessons/lesson.asp?lesson=11</a></li>
<li>Or actually all of Nehe's tutorials <a href=""http://nehe.gamedev.net/"" rel=""nofollow"">http://nehe.gamedev.net/</a> (but see below comments)</li>
</ul>
","11476"
"Do I need to obtain a license to use real car brands in a game?","14195","","<p>We are small team which working on car racing game but we don't know about licensing process for branded cars like Nissan, Lamborghini, Chevrolet and etc. </p>

<p>Do we need to buy any licence for using real car brand names, models, logos,... or we can use them for free?</p>

<p>Second option we think about using not real brand with real models is it possible?
If someone have experience with that, fell free to share it. 
Any information about that is welcome.</p>
","<p>Yes.  Their names, logos, and body designs are all trademarked and cannot be used in any capacity outside those explicitly allowed by trademark law, which almost certainly excluded use in your game.  And expect to be completely incapable of acquiring those licenses for reasonable terms, as the licenses are generally very expensive and come with a mile long list of stipulations.</p>

<p>Even though you'll be paying them, the companies will be seeing your game as another advertisement for their cars.   They will completely reject working with you unless they believe your game will make their cars look awesome and make your players want to buy them.</p>

<p>There was a ""car czar"" for the Forza 4 team.  His full time job was to make sure their car models and car performance matched the various licensing agreements they had, to make sure the cars were modeled accurately, and so on.  You need a full time guy just to do that if you want to license cars.  And expect weird incompatible licensing terms to happen and look forward to wasting tons of time resolving them.  E.g., two manufacturers who want their car to be the fastest car in your game, or who refuse to allow one player selectable color to be applies to their car, or to refuse to allow damage to apply to their car, or to demand that the car can only be used if you model every little mechanical detail to a level of accuracy that your artists or your engine possivly can't handle.</p>

<p>As with all things in the small game and indie space, you are far better off being original and unique.</p>

<p>Also remember that if you try to make games that have the same selling points as AAA titles (like having real cars like Forza does), your game is going to get compared to those games, and is highly unlikely to come out with high marks.  Strive to be unique so your game can stand in its own rather than be compared to games with tens of millions of dollars put into them.</p>
","32499"
"Unity 4.3 (2D) Rendering only the parts of a sprite that are within specific bounds","14170","","<p>I'm working in Unity, using the 2D features to recreate the match-3 style of 10000000 (Ten Million).</p>

<p>I have a parent object (green square) with several children objects (blue rectangles) on top of it, as pictured in the first image. I want to only render the parts of the child objects that are over top of the parent object, as shown in the second image.</p>

<p>I can figure out the size and position of everything just fine, what I'm having trouble with is figuring out how to mask off the parts of the child objects that don't overlap with the parent.</p>

<p><img src=""https://i.stack.imgur.com/wOTmN.png"" alt=""Non-masked"">
<img src=""https://i.stack.imgur.com/nkxfq.png"" alt=""Masked""></p>
","<p>Use a shader with an alpha mask.  The Unify Community Wiki has an excellent <a href=""http://wiki.unity3d.com/index.php/TextureMask"" rel=""nofollow"">alpha mask shader</a>, and it's remarkably simple to use.  I've done a few tricks with stuff like this (such as making a ""night"" scene with lighting by putting a semi-transparent overlay over the scene, and using alpha-masking to ""cut out"" the overlay, where there was light).</p>
","72559"
"Rotating an object in OpenGL about it's centre","14157","","<p>Im writing a game for which, one of the models are loaded from an <code>.obj</code> file.</p>

<p>It's a model of a plane, and I want to rotate the propeller. The object file is broken into groups, and the propeller is identified, so that's all good.
I'm writing the game in C++ with OpenGl/GLFW
The drawing function is:</p>

<pre><code>int win_width;
int win_height;
glfwGetWindowSize(&amp;win_width, &amp;win_height);
float win_aspect = (float)win_width / (float)win_height;
glViewport(0, 0, win_width, win_height);

glMatrixMode(GL_PROJECTION);
glLoadIdentity();
gluPerspective(90, win_aspect, 1, 100.0);

glMatrixMode(GL_MODELVIEW);
glLoadIdentity();
gluLookAt(0, 0, 30.0, 0, 0, 0, 0.0, 1.0, 0.0);

glEnable(GL_DEPTH);
glEnable(GL_DEPTH_TEST);
glEnable(GL_COLOR_MATERIAL);
glEnable(GL_NORMALIZE); 
glEnable(GL_LIGHTING);
glEnable(GL_LIGHT0);
glEnable(GL_LIGHT1);
glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

glColor3f(0.0f, 0.0f, 0.0f);
int vertexIndex = 0, normalIndex;
glRotatef(90, 0, 1, 0);
glPushMatrix();
for(int a = 0; a &lt; (int)groups.size(); a++)
{
    if(groups[a].type == ""prop"")
    {
//Code for rotation
        glPopMatrix();
        glPushMatrix();
        float x,y,z;
        x = y = z = 0;
        int Count = 0;
        for(int k = 0; k &lt; groups[a].faces.size(); k++)
        {
            for(int p = 0; p &lt; groups[a].faces[k].vertices.size(); p++)
            {
                int _index = groups[a].faces[k].vertices[p];
                y += vertices[_index].Dimensions[_y] ;
                z += vertices[_index].Dimensions[_z];
                Count++;
            }
        }
        z /= Count;
        y /= Count;
        glTranslatef(0, -y, -z);
        glRotatef(angle, 1, 0, 0);
        glTranslatef(0, y, z);
    }
    for(int b = 0; b &lt; (int)groups[a].faces.size(); b++)
    {
        glBegin(GL_POLYGON);
        for(int c = 0; c &lt; (int)groups[a].faces[b].vertices.size(); c++)
        {
            vertexIndex = groups[a].faces[b].vertices[c];
            glVertex3d(vertices[vertexIndex].Dimensions[_x], vertices[vertexIndex].Dimensions[_y], vertices[vertexIndex].Dimensions[_z]);
        }
        glEnd();
    }
}
glPopMatrix();
glfwSwapBuffers();
</code></pre>

<p>Since I don't know the exact centre of the propeller, that's what the for loop before the rotation is for. It finds the average of the y and z co-ordinates.</p>

<p>After I find it, I translate to <code>-y,-z</code> , rotate it, and then translate back. This makes the propeller spin as I want it to, but it also rotates along the origin >.&lt;
<a href=""http://people.sc.fsu.edu/~jburkardt/data/obj/cessna.obj"" rel=""nofollow"">http://people.sc.fsu.edu/~jburkardt/data/obj/cessna.obj</a> &lt;- This is the object file.</p>

<p>groups is a vector of objects and each object has a vector of faces. I'm sure that the vertices and faces are being loaded correctly, since the whole model renders correctly.</p>
","<p>OpenGL uses a column vector convention, which means the matrices must be applied in the opposite of the order in which you actually want the transformations to occur.  Just replace this: </p>

<pre><code>glTranslatef(0, -y, -z);
glRotatef(angle, 1, 0, 0);
glTranslatef(0, y, z);
</code></pre>

<p>with this:</p>

<pre><code>glTranslatef(0, y, z);
glRotatef(angle, 1, 0, 0);
glTranslatef(0, -y, -z);
</code></pre>

<p>and that should fix it.</p>
","18857"
"How should I parse user input in a text adventure game?","14156","","<p>Parsing user commands in a text adventure is a spectrum from <a href=""http://en.wikipedia.org/wiki/Colossal_Cave_Adventure"">Adventure</a>'s simple ""go north"" to some mind-bogglingly clever ones in <a href=""http://www.douglasadams.com/creations/infocomjava.html"">hhgttg</a>.</p>

<p>I seem to remember reading nice how-tos in computer magazines back in the 80s, but now I find almost nothing on the 'net except a <a href=""http://en.wikipedia.org/wiki/Text_parser"">brief Wikipedia ref</a>.</p>

<p>How would <em>you</em> do it?</p>

<hr>

<p><strong>Update</strong>: I went with the simplest approach possible in <a href=""http://www.ludumdare.com/compo/ludum-dare-23/?action=preview&amp;uid=10313"">my Ludum Dare entry</a>.</p>
","<p>Did you search in the interactive fiction community? They still write parsers and some try to push the envelope by implementing new techniques such as natural language processing.</p>

<p>See for example this link for articles describing approaches used:</p>

<p><a href=""http://ifwiki.org/index.php/Past_raif_topics:_Development:_part_2#Parsing"">http://ifwiki.org/index.php/Past_raif_topics:_Development:_part_2#Parsing</a></p>
","27005"
"How can I see the height of an object within Blender?","14132","","<p>I'm fairly new to Blender. I know there is the ""Transform"" section in the Object menu of the Properties tab, which contains Location/Rotation/Scale of a selected object. What I'd like to know is if there is way to tell the height (Z) of an object, or just the selected face?</p>
","<p>In Blender 2.5 and later, select the face or edge you want to measure in Edit Mode, and turn on the Properties shelf by pressing 'N'. In here, scroll to Mesh Display > Numerics. You can select to display the edge length and the face area of the faces.</p>

<p>To get the size of an entire object, the Properties shelf in Object Mode will list the X, Y and Z dimensions. It's right in the Transform section.</p>
","18322"
"Has piracy ever resulted in a developer getting shut down?","14109","","<p><strong>Has piracy EVER resulted in a developer getting shut down?</strong> That is, has piracy <em>ever</em> been so detrimental that it brought about the downfall of a game studio? If I were to release a game, should I be extremely wary of pirates and plan accordingly, or is it safe to assume that it won't damage me or my studio whatsoever?</p>
","<p>After a little running around the internet I found an interesting article that shows a good example of how pirating can affect a game directly and shutdown a project.</p>

<p><a href=""http://www.macgasm.net/2012/12/04/ios-game-battle-dungeon-forced-to-shut-down-due-to-piracy/"">iOS Game, Battle Dungeon, Forced To Shut Down Due To Piracy</a></p>

<p>In this article, Hunted Cow, the developers behind the iOS game Battle Dungeon ended up shutting down their servers. The reason they gave as quoted:</p>

<blockquote>
  <p>“Unfortunately we have taken Battle Dungeon down for the forseeable
  future. This was due to high levels of server load created by large
  numbers of pirated copies of the game. The high load revealed
  technical issues which we don’t feel we can fix to the level that our
  paying customers deserve.”</p>
</blockquote>

<p>I found this interesting because it shows that the piracy directly affected the performance of the servers rather than the revenue the developers were receiving to continue with development. Essentially (for those just wanting to skim the article) the pirated copy of the game hit the torrents of the web and multiplied the number of active players on their servers so drastically it reduced performance to a non playable standard. This resulted in them shutting down the project on December 3rd 2012.</p>

<p>Since then they have <a href=""http://forums.huntedcow.com/index.php?showtopic=7583"">upgraded their server hardware</a> and <a href=""https://itunes.apple.com/gb/app/battle-dungeon-risen/id584488562?mt=8"">rereleased the app on the iTunes Store on April 8th 2013</a>. However the piracy is what caused them to make these changes, costing money to company, down time of more than 4 months for the paying players and a reworking of their website which would have taken up valuable resources from their planned work.</p>

<p>Piracy may not affect companies directly from losing money from the initial sale, but as with <a href=""https://www.huntedcow.com/"">Hunted Cow</a> it can really set you back and potentially enough to shut you down. Hunted Cow were able to readjust and solve the problem after it happened, potentially with user based access to servers being validated for paying customers - however that is my own assumption. </p>

<p>It is something that you can prepare for in many different ways (DRM, payment authentication, server load access restrictions) and still be affected in ways you won't predict. Do your best to estimate what can happen to your services with extra pirated copies (extra load on servers, potential player griefing etc) and account for it as best you can within your budget so it doesn't affect your fair paying customers.</p>
","54752"
"How to use rigid bodies for characters?","14098","","<p>First off, I am making a game similar to <a href=""http://en.wikipedia.org/wiki/Super_Smash_Bros._%28series%29"" rel=""nofollow noreferrer"">SSB</a>, which relies heavily on physics, even though it is a sidescroller. I am currently using Unity.</p>

<p>In Unity there are ""character controllers"" which are used for characters that move, but they don't interact with other physics objects. There are also rigid bodies, which are completely realistic physics components. I can't figure out how to use rigid bodies for human/humanoid characters. Here's some questions I have:</p>

<ul>
<li><strong><em>How should I move the character?</em></strong> Applying forces is not the way to do it, right? Would you set velocities or pixel-by-pixel movement, perhaps?</li>
<li><strong><em>What kind of collider should I use?</em></strong> I've been using a capsule collider. But is that the best way?</li>
<li><strong><em>How do you make him not fall down!?</em></strong> After some experimenting, I discovered that the character falls over (from applying force/velocity and from the capsule collider tipping it over). Would you constrain the rotation in the Z-axis?</li>
<li><p><strong><em>What do you do when he gets hit?</em></strong> If you've ever played SSBB you'll be familiar with this topic. I'm thinking that applying a force would be best in this condition? If you did constrain the rotation, would you un-constrain it?</p>

<p><img src=""https://i.stack.imgur.com/50Z0S.jpg"" alt=""Ike punching link""></p></li>
</ul>
","<blockquote>
  <p>How should I move the character? Applying forces is not the way to do
  it, right? Would you set velocities or pixel-by-pixel movement,
  perhaps?</p>
</blockquote>

<p>Apply linear (and possible angular) <em>impulse</em>. The object retains velocity and imparts force to other objects on impact.</p>

<blockquote>
  <p>What kind of collider should I use? I've been using a capsule
  collider. But is that the best way?</p>
</blockquote>

<p>The capsule collider is what you get with Unity, because it works well for most sorts of games. You could either continue to use it with adaptation (to the FirstPersonController script), or construct your character entirely out of bounding cylinders or bounding boxes (limbs, body, head etc.). The latter won't be as easy, but for a fighting game you'll have more accurate combat. I'm not sure this is really necessary as your game is actually 2D anyway, so benefits from this will be less than if your game were actual 3D.</p>

<blockquote>
  <p>How do you make him not fall down!? After some experimenting, I
  discovered that the character falls over (from applying force/velocity
  and from the capsule collider tipping it over). Would you constrain
  the rotation in the Z-axis?</p>
</blockquote>

<p>Considering you're using rigid bodies, you're going to have to find some way to constrain, yes. It's either that or you switch between kinematic and rigid bodies at given times. The problem with the latter is you still need to know when the collision between your fist and the enemy's face occurs. So better to stick with rigid body physics throughout.</p>

<blockquote>
  <p>What do you do when he gets hit? If you've ever played SSBB you'll be
  familiar with this topic. I'm thinking that applying a force would be
  best in this condition? If you did constrain the rotation, would you
  un-constrain it?</p>
</blockquote>

<p>Yes, apply a force; this could be as you switch the character back to rigid body mode (possibly based on where the character was hit, and for how much). In that case, when the character begins to recover, turn kinematics back on so he can stand up again. </p>

<hr>

<p>NB What I've said above about using a mixture of kinematic forces and dynamic ones is one way to do it, and in some ways the easiest. However you can also purely use impulses with rigid bodies to control things. In my experience, this can be less than simple, so caveat emptor.</p>
","18571"
"Why would Rigidbody.AddForce not resulting in movement of my objects?","14083","","<p>I'm trying to get my card objects to spread out randomly but nothing happens. I know the method is called cause I get the prints in the console for each card. But they don't move. No errors reported. The cards have a <code>RigidBody</code>.</p>

<pre><code>public static void CardCascade ()
{
     print (""CARD CASCADE!"");
     foreach (var card in Card.Cards) {
          float range = 500F;

          var x = Random.Range (-range, range);
          var y = Random.Range (-range, range);             
          card.rigidbody.AddForce (x, y, 0);
          print (""I just added force to card: X/Y "" + x + y);
     }
}
</code></pre>
","<p><strong>Don't miss the last argument to AddForce(), <code>ForceMode mode</code>.</strong>  The default mode <code>ForceMode.Force</code> (<em>kg·m/s²</em> or <em>N</em>) works in the most physics-natural way, but you also have the option of making the addition mass-independent (<code>ForceMode.Acceleration</code>, <em>m/s²</em>), or velocity-based instead of acceleration-based (<code>ForceMode.Impulse</code>, <em>kg·m/s</em>), or both mass-independent and velocity-based (<code>ForceMode.VelocityChange</code>, <em>m/s</em>).</p>

<p>In general, the acceleration-based pair (<code>ForceMode.Force</code> and <code>ForceMode.Acceleration</code>) are best for over-time effects (in FixedUpdate(), as suggested by @danijar), while the velocity-based pair (<code>ForceMode.Impulse</code> and <code>ForceMode.VelocityChange</code>) are best for one-time effects (in Start(), Update(), FixedUpdate(), etc.).  And it's not like either won't work in either situation, it's just that the values you'll end up using are aligned to each situation.  <em>E.G. Using <code>ForceMode.Force</code> with a force of <code>30.0 * Time.fixedDeltaTime</code> for a one-time burst should work fine, but using <code>ForceMode.Impulse</code> with just <code>30.0</code> is more semantically meaningful.</em></p>

<p>Setting the Rigidbody's <code>.velocity</code> directly is not recommended if the Rigidbody is already moving— the Rigidbody does a number of things internally that will likely cause the resulting velocity to not match what you set it to.  I suppose it's in there and settable for esoteric setups or custom physics system hacks, like setting an initial value for <code>velocity</code> within Start() in a situation where everything should be moving from the get-go.  However, the recommended way to accomplish <code>rigidbody.velocity += 5.0</code> is <code>rigidbody.AddForce(5.0, ForceMode.VelocityChange)</code>.</p>

<hr>

<p>Your code looks as if it's for a card game, so if you do indeed want the cards to move at a predictable speed in a UI-ish manner, <code>ForceMode.VelocityChange</code> may be your best bet.</p>
","68241"
"What is unit slotting?","14076","","<p>I was watching the <a href=""https://www.youtube.com/watch?v=ygp4-kmjpzI&amp;index=13&amp;list=PLIhLvue17Sd6u2akeZZdYVBxNtfWZPm5W"">""Devs Play"" S01E05</a> where JP LeBreton sat down with John Romero and played through Doom, while Romero would explain some of the game/level design choices they made.</p>

<p>There are loads of great points that both of them juggle around, though, there is one that I cannot fully understand. Maybe that's my language barrier or something, but yeah - <strong>Unit slotting</strong>.</p>

<p>It's a short segment of the video, starting at <a href=""https://www.youtube.com/watch?v=9gs5r_4eY0k&amp;t=2m56s"">2m56s</a> where Romero has a little laugh about <em>slotting</em> in modern games.</p>

<p>I cannot seem to grasp the concept of it. Is it that units are auto-swarming towards you and attack in somewhat of a queue? Or maybe it's that their attacks are synchronized as to not overwhelm you? Or... what the heck is slotting?</p>
","<p>Slotting is a technique which is used to confront the player with an overwhelming number of enemies and still give them a chance to win.</p>

<p>Instead of having all enemies attack at once, there is a limited number of ""slots"" of enemies which attack the player seriously, while the rest of the enemies keep their distance and just look threatening but do not do anything effective. In an FPS, for example, those enemies which don't have a ""slot"" might fire in the general direction of the player, but behave defensively while both their damage and aim is severely nerfed. But those enemies which got one of the limited ""slots"" will behave far more aggressively, charge the player and use far more effective attacks.</p>

<p>It is a very common technique which is surprisingly effective at allowing the player to fight large hordes of enemies while still not making single enemies so weak they don't pose a challenge at all. </p>

<p>It sounds strange, but it works surprisingly well because:</p>

<ul>
<li>In a stressfull situation, the player will concentrate their attention on immediate threats first (the slotted enemies which charge them) and not pay much attention to the behavior of minor threats (those mooks standing far away), so they will not even notice that the majority of the enemies behaves rather strange.</li>
<li>While players are often very annoyed when games obviously cheat against them, they are often very forgiving to games cheating in their favor.</li>
<li>Players like winning against seemingly impossible odds and are more likely to attribute their victory to their supposedly good skills instead of suspecting that they got help.</li>
</ul>

<p>Remember: When designing AI for a single-player game, the goal of your AI is not to win. It is designed to lose, preferably in a way which makes the player feel good about themselves.</p>
","112041"
"What is grid in Unity and how can I implement it?","14070","","<p>I'm a beginner. I need to place a grid on my map in Unity and would like to access it to place a simple object on mouse click. How can I achieve this ?</p>

<p>I am unable to understand the grid functionality, should I have to write code for a 2D array or is there something in Unity that I can access, and what is basically the grid like something when I click my background image ?</p>
","<p>This could be achieved in many ways. Unity has a pretty advanced positioning system as it is. </p>

<p>For just regular positioning look here
<a href=""https://docs.unity3d.com/Manual/PositioningGameObjects.html"" rel=""nofollow noreferrer"">https://docs.unity3d.com/Manual/PositioningGameObjects.html</a></p>

<p>But without prior knowledge of whether you are looking to do this in code, it's hard to give a good answer. Try asking more specific, precise questions that you feel others could benefit from that can't be found out with a little bit of research</p>

<p>EDIT: ADDITION
This shows how to place a tower, the towers positions are checked against in an arraylist is C#.
Hopefully this should give you an idea of how to start. </p>

<pre><code>public GameObject tower;
public GameObject tower2;
private ArrayList towerList = new ArrayList();
void Start()
{
    Vector3 towerPosition = new Vector3(1.0F, .75F, 1.0F);
    foreach (GameObject towerObject in towerList)
    {
        if (towerObject.transform.position == towerPosition)
        {
            // there is already a tower in that position
            return;
        }
    }

    tower = (GameObject)Instantiate(tower, new Vector3(1.0F, .75F, 1.0F), this.transform.rotation);
    towerList.Add(tower);

    // for proof of concept you we're going to try to place the tower
    // in the same position as the other one
    Vector3 towerPosition2 = new Vector3(1.0F, .75F, 1.0F);
    foreach (GameObject towerObject in towerList)
    {
        if (towerObject.transform.position == towerPosition2)
        {
            // there is already a tower in that position
            return;
        }
    }
    tower2 = (GameObject)Instantiate(tower2, new Vector3(1.0F, .75F, 1.0F), this.transform.rotation);
    towerList.Add(tower2);
}
</code></pre>
","17837"
"Do you know any 3D engines written in Objective-C for iOS?","14062","","<p>In the next few weeks I will start a game for iOS, most of the action will happen in 2D but a 2D engine is not enough for our idea, therefore I'm doing a small research on available 3D engines for iOS written in Objective-C (we already looked on some engines written in C++).
<br /> <br />
Do you know 3D engines written in Objective-C?</p>

<p><br /><br />
I found this one <a href=""http://nineveh.gl/"" rel=""nofollow"">http://nineveh.gl/</a> but is not yet ready :(.</p>

<p><br />
<strong>later edit (1)</strong>.......<br />
I did a research on the engines written in C++, they are nice and probably I will go with one of them, but if there is any good engine written in Objective-C, than I will go with it, because its a matter of taste and I like very much the obj-c language.
<br />
<br />
<strong>later edit (2)</strong>.......<br />
nice presentation/teaser about what I'm looking for <a href=""http://www.slideshare.net/rsebbe/designing-an-objectivec-framework-about-3d"" rel=""nofollow"">http://www.slideshare.net/rsebbe/designing-an-objectivec-framework-about-3d</a></p>
","<p>You might also want to check out iSGL3D (<a href=""http://isgl3d.com"" rel=""nofollow"">http://isgl3d.com</a>) which is an open source Objective-C iOS scene graph library. </p>

<p>It works with both OpenGL ES 1.1 and ES 2.0 with a number of features such as simple scene and object manipulation, lighting and shading, cameras, multiple views, meshes and particles, tweening, mesh skinning, vertex animation, shadows, object interactivity, etc.</p>

<p>It uses a few C++ hooks for external libraries such as Bullet physics and PowerVR POD importing but these are wrapped in Objective-C classes.</p>
","11870"
"How do I calculate speed given two xy vectors?","14021","","<p>I have some code that returns the x and y linear velocities of a moving space ship. How can I combine these to give me total speed?</p>

<pre><code>x = self.player._box2dBody.GetLinearVelocity().x;
y = self.player._box2dBody.GetLinearVelocity().y;
</code></pre>

<p>So if:<br>
x = 1.99 <br>
y = -1.63<br></p>

<p>How do I calculate the total speed?</p>
","<p>In this situation, the length of the <a href=""http://en.wikipedia.org/wiki/Euclidean_vector"" rel=""nofollow noreferrer"">vector</a> would be considered the speed, since the vector itself represents the velocity (speed and direction). This is also referred to as the <a href=""http://en.wikipedia.org/wiki/Magnitude_%28mathematics%29"" rel=""nofollow noreferrer"">magnitude</a>. The vector class you're getting <code>.x</code> and <code>.y</code> from likely already has a built in implementation for getting the magnitude or length. </p>

<p><img src=""https://i.stack.imgur.com/w19AV.png"" alt=""enter image description here""></p>

<p>Where <img src=""https://i.stack.imgur.com/HKdhh.png"" alt=""a magnitude""> is the magnitude of the vector.</p>

<p>I suggest you read up on linear algebra. Wolfire has put together a <a href=""http://blog.wolfire.com/2009/07/linear-algebra-for-game-developers-part-1/"" rel=""nofollow noreferrer"">nice series of blog posts</a> on the topic that should get you up to speed on the basics.</p>
","60080"
"What does changing GL_TEXTURE_WRAP)_(S/T) do?","14014","","<p>I am working through some beginner OpenGL tutorials, and the current one teaches how to apply a texture to a simple rectangle. The tutorial states tells me to set the texture parameters GL_TEXTURE_WRAP_S and GL_TEXTURE_WRAP_T to GL_CLAMP_TO_EDGE, however I am uncertain as to what this actually does. I am aware it is something to do with how textures larger/smaller than the space they are being mapped onto are handled, but I'm not sure what behavior this actually causes. What does GL_CLAMP_TO_EDGE do, and how is this different from GL_CLAMP, GL_CLAMP_TO_BORDER, GL_REPEAT? Thanks very much in advance, and bonus helpfulness if you can provide images for an idiot like me.</p>
","<p>Well S and T just mean U and V (or X and Y if you prefer), or in GLSL:</p>

<pre><code>vec4.xyzw == vec4.rgba == vec4.strq
</code></pre>

<p>The GL_REPEAT mode has textures repeat when you go past (0,0) to (1,1) range</p>

<p>The GL_CLAMP_TO_EDGE mode has textures stop at the last pixel when you fall off the edge.</p>

<p>The GL_CLAMP and GL_CLAMP_TO_BORDER are depreciated because all texture borders must be 0 pixels, so the modes don't make sense anymore. (somewhere around GL3 I believe)</p>

<p>There are more modes so make sure to read the docs. (Examples: GL_MIRRORED_REPEAT, GL_MIRROR_CLAMP_TO_EDGE)</p>

<hr>

<p>There are some good examples on <a href=""http://www.flipcode.com/archives/Advanced_OpenGL_Texture_Mapping.shtml"">http://www.flipcode.com/archives/Advanced_OpenGL_Texture_Mapping.shtml</a>, here is a preview:</p>

<blockquote>
  <p>Wrap S : GL_CLAMP / Wrap T : GL_CLAMP</p>
  
  <p><img src=""https://i.stack.imgur.com/McZua.png"" alt=""clamp clamp""></p>
  
  <p>Wrap S : GL_CLAMP / Wrap T : GL_REPEAT</p>
  
  <p><img src=""https://i.stack.imgur.com/O0jFi.png"" alt=""clamp repeat""></p>
  
  <p>Wrap S : GL_REPEAT / Wrap T : GL_CLAMP</p>
  
  <p><img src=""https://i.stack.imgur.com/H5zaa.png"" alt=""repeat clamp""></p>
  
  <p>Wrap S : GL_REPEAT / Wrap T : GL_REPEAT</p>
  
  <p><img src=""https://i.stack.imgur.com/XyIRH.png"" alt=""repeat repeat""></p>
</blockquote>
","62556"
"HTML5 Game (Canvas) - UI Techniques?","14007","","<p>I'm in the process of building a JavaScript / HTML5 game (using Canvas) for mobile (Android / iPhone/ WebOS) with PhoneGap. I'm currently trying to design out how the UI and playing board should be built and how they should interact but I'm not sure what the best solution is. Here's what I can think of -</p>

<p>Build the UI right into the canvas using things like drawImage and fillText
Build parts of the UI outside of the canvas using regular DOM objects and then float a div over the canvas when UI elements need to overlap the playing board canvas.
Are there any other possible techniques I can use for building the game UI that I haven't thought of? Also, which of these would be considered the ""standard"" way (I know HTML5 games are not very popular so there probably isn't a ""standard"" way yet)? And finally, which way would YOU recommend / use?</p>

<p>Many thanks in advance!</p>
","<p>Both solutions (drawing on your canvas VS. traditional HTML/CSS) are totally valid and will work just fine. Some things to consider:</p>

<ul>
<li>If you're already using a canvas-based library, your code may be cleaner/more organized by continuing to use canvas instead of having additional (DOM-based) methods for UI.</li>
<li>If your UI is extremely text-heavy (with dialogs etc.) then it may be simpler to implement via HTML/CSS. For instance, it's pretty trivial for text to flow in a DOM element (with stuff like wrapping and paragraph spacing) and comparatively difficult to implement in canvas.</li>
<li>Depending heavily on the library you're using, it could be much easier to implement click handling on DOM elements than within your canvas. For example if you want to detect a click on an ""Ok"" button, that's a trivial task in HTML/JS world. But in canvas you'd need to listen to the click on a different element and check its coordinates to see where the click took place.</li>
<li>Some user agents (especially mobile devices) can be tricky when using DOM elements containing text. For example, Mobile Safari may want to pop up a modal with the tools to copy/paste. Preventing this behavior might be difficult and would probably be easier in canvas land.</li>
</ul>

<p>Some of this will be subjective; a developer I know <strong>always</strong> prefers using canvas since he just finds DOM to be ugly and verbose. Since either solution will work fine, I'd pick a simple single screen in your app, quickly develop it separately using both methods and see which one feels easier/better.</p>

<p>Best of luck!</p>
","7109"
"Why do we use 4x4 matrices to transform things in 3D?","14005","","<p>To translate a vector by 10 unit in the X direction, why do we have to use a matrix?</p>

<p><img src=""https://i.stack.imgur.com/559yo.png"" alt=""enter image description here""></p>

<p>We can just add 10 to the mat[0][0], and we got the same result too.</p>
","<p>Yes, you can add a vector in the case of translation. The reason to use a matrix boils down to having a uniform way to handle different combined transformations.</p>

<p>For example, rotation is usually done using a matrix (check @MickLH comment for other ways to deal with rotations), so in order to deal with multiple transformations (rotation/translation/scaling/projection...etc) in a uniform way, you need to encode them in a matrix.</p>

<p>Well, more technically speaking; a transformation is mapping a point/vector to another point/vector.</p>

<pre><code>p` = T(p); 
</code></pre>

<p>where p` is the transformed point
and T(p) is the transformation function.</p>

<p>Given that we don't use a matrix we need to do this to combine multiple transformations:</p>

<blockquote>
  <p>p1= T(p);</p>
  
  <p>p<sub>final</sub> = M(p1);</p>
</blockquote>

<p>Not only can a matrix combine multiple types of transformations into a single matrix (e.g. affine, linear, projective).</p>

<p>Using a matrix gives us the opportunity to combine chains of transformations and then batch multiply them. This saves us a ton of cycles usually by the GPU (thanks to @ChristianRau for pointing it out).</p>

<blockquote>
  <p>T<sub>final</sub> = T * R * P; // translate<em>rotate</em>project</p>
  
  <p>p<sub>final</sub> = T<sub>final</sub>*p;</p>
</blockquote>

<p>It's also good to point out that GPUs and even some CPUs are optimized for vector operations; CPUs using SIMD and GPUs being data driven parallel processors by design, so using matrices fits perfectly with hardware acceleration (actually, GPUs were designed to fit matrix/vector operations). </p>
","72045"
"How do multipass shaders work in OpenGL?","13998","","<p>In Direct3D, multipass shaders are simple to use because you can literally define passes within a program.  In OpenGL, it seems a bit more complex because it is possible to give a shader program as many vertex, geometry, and fragment shaders as you want.</p>

<p>A popular example of a multipass shader is a toon shader.  One pass does the actual cel-shading effect and the other creates the outline.  If I have two vertex shaders, ""cel.vert"" and ""outline.vert"", and two fragment shaders, ""cel.frag"" and ""outline.frag"" (similar to the way you do it in HLSL), how can I combine them to create the full toon shader?</p>

<p>I don't want you saying that a geometry shader can be used for this because I just want to know the theory behind multipass GLSL shaders ;)</p>
","<p>There is no ""theory"" behind multipass. There are no ""multipass shaders"". Multipass is very simple: you draw the object with one program. Then you draw the object with a <em>different</em> program.</p>

<p>You can use D3DX stuff like FX files to hide these extra passes. But they still work that way. OpenGL simply doesn't have a hiding place for it.</p>
","25925"
"Loading .PNG file and using it for UnityEngine.UI.Image","13948","","<p>Have an Unity UI Image.</p>

<p>I want to load a .PNG file that is in my persistent data path and use it as the sprite source for the UI Image. Code:</p>

<pre><code>    byte[] bytes = File.ReadAllBytes(Application.persistentDataPath + ""/sprite.png"");
    Texture2D texture = new Texture2D(width, height);
    texture.filterMode = FilterMode.Trilinear;
    texture.LoadImage(bytes);
    Sprite sprite = Sprite.Create(texture, new Rect(0,0,width, height), new Vector2(0.5f,0.0f), 1.0f);

    myObject.GetComponent&lt;UnityEngine.UI.Image&gt; ().sprite = sprite;
</code></pre>

<p>This almost works. <strong>Only a portion of the image is displayed</strong>.</p>

<p>The initial guess would be that I didn't load the image properly. However, if you use a <code>SpriteRenderer</code> instead of <code>UnityEngine.UI.Image</code> like</p>

<pre><code>    myObject.GetComponent&lt;SpriteRenderer&gt;().sprite = sprite;
</code></pre>

<p>The image is displayed in full. So this seems to be a problem with <code>UnityEngine.UI.Image</code> specifically...</p>

<p>... However, if you drag an image from the editor into the <code>Sprite Source</code> property of <code>UnityEngine.UI.Image</code>, then such image is displayed in full - then suggesting that there is something wrong with the way I load my image bytes.</p>

<p>What should I do?</p>

<p><strong>Edit</strong>: If you set the image type to <code>Tiled</code>, you can see that it tiles with the full image... So apparently the UI Image component DOES have all the image data but for some reason it won't render all of it.</p>
","<p>I was experiencing this same issue where not all of the image was displaying.</p>

<p>I solved it by setting mipmap to false (last parameter):</p>

<pre><code>Texture2D texture = new Texture2D(900, 900, TextureFormat.RGB24, false);
</code></pre>

<p>My image then displayed as per the source PNG file.</p>
","95676"
"How can I clean up excessive player-created rubble?","13931","","<p>In my latest game I'm making, you can slice a 2D object arbitrarily, demonstrated in this gif:</p>

<p><img src=""https://i.stack.imgur.com/a4GXY.gif"" alt=""enter image description here""></p>

<p>You can continuously cut it into hundreds or thousands of pieces. This doesn't create a lot of lag, because they're always in a sleeping physics state, but there's a problem when you cause them to move.</p>

<p>I'm not really sure how to deal with making it so there's not so much rubble from cutting something apart. I don't really want to delete them after a certain amount of time; I don't like how, if you go back to something you cut up after a while, it randomly disappeared.</p>

<p>How can I clean up excessive player-created rubble?</p>
","<p>First of all, that game mechanic looks like it could be super fun, so congrats on thinking of it!  Here are two simple solutions that could be used independently or together to solve this particular issue:</p>

<h1>Remove Very Small Pieces</h1>

<p>There isn't much of a point to keeping around tiny pieces of collision that really won't impede the player or have any real effect on the environment.  Calculating the extra collision logic simply isn't worth it, so either remove these pieces or remove collision on them.</p>

<h1>Limit Player Cuts</h1>

<p>Having unlimited cuts could potentially make a lot of your puzzles really simple if you can just slice every impeding object into a pile of mush.  Give the player only a few cuts to play with (or make it slowly recharge over time) and you'll likely find that it makes your puzzles more challenging in addition to eliminating the pains of dealing with collision on a thousand fragments.</p>
","142999"
"How to rotate an object around world aligned axes?","13914","","<p>I have a Vector3 which has an euler angle for each axis.</p>

<p>Usually, when I want to create a rotation matrix I will use functions such as D3DXMatrixRotationX passing the respective angle from my rotation vector above and multiply the matrices (ZXY) to create the overall rotation matrix which is used to form the complete object transformation matrix.</p>

<p>However, this method will produce a set of rotations in object space. That is, passing a vector of (90, 0, 90) into my method will create a rotation in world space effectively of (90, 90, 0).</p>

<p>Is there a way to always ensure each component of my rotation vector results in a rotation around the respective world space aligned axes?</p>

<p>EDIT: </p>

<p>This is an animation of what is currently happening - I want a way to rotate around the blue axes, not the red.</p>

<p><img src=""https://i.stack.imgur.com/PskMY.gif"" alt=""Euler Angles""></p>

<p>EDIT 2:</p>

<p>Just to note I am not looking for a solution involving Euler angles, but simply a way in which I can represent a transformation of multiple rotations around the world axes.</p>
","<p>Based on you comments, it seems that you're <strong>storing the orientation of the object as a set of Euler angles</strong>, and in/decrementing the angles when the player rotates the object.  That is, you have something like this pseudocode:</p>

<pre class=""lang-java prettyprint-override""><code>// in player input handling:
if (axis == AXIS_X) object.angleX += dir;
else if (axis == AXIS_Y) object.angleY += dir;
else if (axis == AXIS_Z) object.angleZ += dir;

// in physics update and/or draw code:
matrix = eulerAnglesToMatrix(object.angleX, object.angleY, object.angleZ);
</code></pre>

<p><a href=""https://gamedev.stackexchange.com/a/67277"">As Charles Beattie notes</a>, because rotations don't commute, this won't work as expected unless the player rotates the object in the same order in which the <code>eulerAnglesToMatrix()</code> applies the rotations.</p>

<p>In particular, consider the following sequence of rotations:</p>

<ol>
<li>rotate object by <em>x</em> degrees around the X axis;</li>
<li>rotate object by <em>y</em> degrees around the Y axis;</li>
<li>rotate object by &minus;<em>x</em> degrees around the X axis;</li>
<li>rotate object by &minus;<em>y</em> degrees around the Y axis.</li>
</ol>

<p>In the naïve Euler angle representation, as implemented in the pseudocode above, these rotations will cancel out and the object will return to its original orientation.  In the real world, this does not happen &mdash; if you don't believe me, grab a six-sided die or a Rubik's cube, let <em>x</em> = <em>y</em> = 90&deg;, and try it out yourself!</p>

<p>The solution, as you note <a href=""https://gamedev.stackexchange.com/a/67269"">in your own answer</a>, is to <strong>store the orientation of the object as a rotation matrix</strong> (or a quaternion), and update that matrix based on user input.  That is, instead of the pseudocode above, you'd do something like this:</p>

<pre class=""lang-java prettyprint-override""><code>// in player input handling:
if (axis == AXIS_X) object.orientation *= eulerAnglesToMatrix(dir, 0, 0);
else if (axis == AXIS_Y) object.orientation *= eulerAnglesToMatrix(0, dir, 0);
else if (axis == AXIS_Z) object.orientation *= eulerAnglesToMatrix(0, 0, dir);

// in physics update and/or draw code:
matrix = object.orientation;  // already in matrix form!
</code></pre>

<p>(Technically, since any rotation matrix or quaternion can be represented as a set of Euler angles, it <em>is</em> possible to use them to store the orientation of the object.  But the physically correct rule for combining two sequential rotations, each represented as Euler angles, into a single rotation is rather complicated, and essentially amounts to converting the rotations into matrices / quaternions, multiplying them, and then converting the result back into Euler angles.)</p>
","111059"
"Implementing a skybox with GLSL version 330","13910","","<p>I am trying to get a skybox working with OpenGL 3.3 and GLSL version 330.</p>

<p>I could not find a completely modern OGL skybox tutorial anywhere on the web, so I modernised an older one (using <code>glVertexAttribPointer()</code> instead of <code>gl_Vertex</code> for vertices, etc.). It's mostly working, but for 2 major details:</p>

<p>The skyboxes are more like sky triangles, and the textures are badly warped and stretched (they are supposed to be star fields, I get while lines on a black background). I'm 99% sure that this is because I didn't port the old tutorials completely correctly.</p>

<p>Here is my skybox class:</p>

<pre><code>static ShaderProgram* cubeMapShader = nullptr;

static const GLfloat vertices[] = 
{
    1.0f, -1.0f,  1.0f,
    1.0f,  1.0f,  1.0f,
    1.0f,  1.0f, -1.0f,
    -1.0f, -1.0f,  1.0f,
    -1.0f, -1.0f, -1.0f,
    -1.0f,  1.0f, -1.0f,
    -1.0f,  1.0f,  1.0f,
    -1.0f,  1.0f, -1.0f,
    1.0f,  1.0f, -1.0f,
    1.0f,  1.0f,  1.0f,
    -1.0f,  1.0f,  1.0f,
    -1.0f, -1.0f,  1.0f,
    1.0f, -1.0f,  1.0f,
    1.0f, -1.0f, -1.0f,
    -1.0f, -1.0f, -1.0f,
    1.0f, -1.0f,  1.0f,
    -1.0f, -1.0f,  1.0f,
    -1.0f,  1.0f,  1.0f,
    1.0f,  1.0f,  1.0f,
    -1.0f, -1.0f, -1.0f,
    1.0f, -1.0f, -1.0f,
    1.0f,  1.0f, -1.0f,
    -1.0f,  1.0f, -1.0f
};

Skybox::Skybox(const char* xp, const char* xn, const char* yp, const char* yn, const        char* zp, const char* zn)
{
if (cubeMapShader == nullptr)
    cubeMapShader = new ShaderProgram(""cubemap.vert"", ""cubemap.frag"");

    texture = SOIL_load_OGL_cubemap(xp, xn, yp, yn, zp, zn, SOIL_LOAD_AUTO, SOIL_CREATE_NEW_ID, SOIL_FLAG_MIPMAPS);

    glBindTexture(GL_TEXTURE_CUBE_MAP, texture);
    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR); 
    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
    glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_R, GL_CLAMP_TO_EDGE);
    glBindTexture(GL_TEXTURE_CUBE_MAP, 0);

    glGenVertexArrays(1, &amp;vaoID);
    glBindVertexArray(vaoID);
    glGenBuffers(1, &amp;vboID);
    glBindBuffer(GL_ARRAY_BUFFER, vboID);
    glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);
    glEnableVertexAttribArray(0);
    glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 0, (void*)0);
    glBindVertexArray(0);

    scale = 1.0f;
}

Skybox::~Skybox()
{

}

void Skybox::Render()
{
    ShaderProgram::SetActive(cubeMapShader);
    glDisable(GL_DEPTH_TEST);
    glActiveTexture(GL_TEXTURE0);
    glBindTexture(GL_TEXTURE_CUBE_MAP, texture);
    cubeMapShader-&gt;Uniform1i(""SkyTexture"", 0);
    cubeMapShader-&gt;UniformVec3(""CameraPosition"", Camera::ActiveCameraPosition());
    cubeMapShader-&gt;UniformMat4(""MVP"", 1, GL_FALSE, Camera::GetActiveCamera()-&gt;GetProjectionMatrix() * Camera::GetActiveCamera()-&gt;GetViewMatrix() * glm::mat4(1.0));
    glBindVertexArray(vaoID);
    glDrawArrays(GL_QUADS, 0, 24);
    glBindVertexArray(0);
    glBindTexture(GL_TEXTURE_CUBE_MAP, 0);
}
</code></pre>

<p>Vertex Shader:</p>

<pre><code>#version 330 
layout(location = 0) in vec3 Vertex;

uniform vec3 CameraPosition;
uniform mat4 MVP;

out vec3 Position;

void main()
{
    Position = Vertex.xyz;
    gl_Position = MVP * vec4(Vertex.xyz + CameraPosition, 1.0);
}
</code></pre>

<p>Fragment Shader:</p>

<pre><code>#version 330 compatibility

uniform samplerCube SkyTexture;

in vec3 Position;

void main()
{
    gl_FragColor = textureCube(SkyTexture, Position);
}
</code></pre>

<p><a href=""https://imgur.com/a/nrZ9R"" rel=""noreferrer"">Here</a>'s an example of the glitches. If anyone could take a look who knows GLSL well (I'm still learning it), or skyboxes, I would appreciate any help you could give. Also, kudos if you can teach me how to use non-deprecated functions in the fragment shader so I don't have to use the compatibility profile of glsl 330.</p>

<hr>

<p>EDIT: Immediately found the problem with the stretching textures: I was using <code>Position = Vertex.xy</code><strong><code>x</code></strong> instead of <code>Position = Vertex.xy</code><strong><code>z</code></strong> in the vertex shader. Oops. But the triangle error still exists.</p>
","<p>While this answer does not tell what is wrong with your approach, it presents a simpler way to render skyboxes.</p>

<h1>Traditional way (textured cube)</h1>

<p>A straightforward way for creating skyboxes is to render a textured cube centered to the camera position. Each face of the cube consists of two triangles and a 2D texture (or part of an atlas). Due to texture coordinates each face requires own vertices. This approach has problems in the seams of adjacent faces, where the texture values are not interpolated properly.</p>

<h1>Cube with cubemap texture</h1>

<p>Like in the traditional way, a textured cube is rendered around the camera. Instead of using six 2D textures, a single cubemap texture is used. Because the camera is centered inside the cube, the vertex coordinates map one to one with the cubemap sampling vectors. Thus texture coordinates are not needed for the mesh data and the vertices can be shared between faces by using index buffer.</p>

<p>This approach also fixes the problem of seams when GL_TEXTURE_CUBE_MAP_SEAMLESS is enabled.</p>

<h1>Simpler (better) way</h1>

<p>When rendering a cube and the camera lies inside it, whole viewport gets filled. Up to five faces of the skybox can be partially visible at any time. The triangles of cube faces are projected and clipped to the viewport and cubemap sampling vectors are interpolated between the vertices. This work is unnecessary.</p>

<p>It's possible to fill a single quad filling the whole viewport and calculate the cubemap sampling vectors in the corners. Since the cubemap sampling vectors match the vertex coordinates, they can be calculated by unprojecting the viewport coordinates to the world space. This is the opposite of projecting world coordinates to the viewport and can be achieved by inverting the matrices. Also make sure you either disable z-buffer write or write a value that is far enough.</p>

<p>Below is the vertex shader that accomplishes this:</p>

<pre><code>#version 330
uniform mat4 uProjectionMatrix;
uniform mat4 uWorldToCameraMatrix;

in vec4 aPosition;

smooth out vec3 eyeDirection;

void main() {
    mat4 inverseProjection = inverse(uProjectionMatrix);
    mat3 inverseModelview = transpose(mat3(uWorldToCameraMatrix));
    vec3 unprojected = (inverseProjection * aPosition).xyz;
    eyeDirection = inverseModelview * unprojected;

    gl_Position = aPosition;
} 
</code></pre>

<p><code>aPosition</code> is the vertex coordinates <code>{-1,-1; 1,-1; 1,1; -1,1}</code>. The shader calculates <code>eyeDirection</code> with the inverse of model-view-projection matrix. However the inversion is split for projection and world-to-camera matrices. This is because only the 3x3 part of the camera matrix should be used to eliminate the position of the camera. This aligns the camera to the center of the skybox. In addition as my camera doesn't have any scaling or shearing, the inversion can be simplified to transposition. The inversion of the projection matrix is a costly operation and could be precalculated, but as this code is executed by the vertex shader typically just four times per frame, it's usually a non-issue.</p>

<p>The fragment shader simply performs a texture lookup using <code>eyeDirection</code> vector:</p>

<pre><code>#version 330
uniform samplerCube uTexture;

smooth in vec3 eyeDirection;

out vec4 fragmentColor;

void main() {
    fragmentColor = texture(uTexture, eyeDirection);
}
</code></pre>

<p>Note that to get rid of the compatibility mode you need to replace <code>textureCube</code> with just <code>texture</code> and specify the output variable yourself.</p>
","60377"
"What is the little dot/icon at the center of the screen in an FPS game called?","13893","","<p>So I am developing a game and trying to find one of those to use, but I don't know what to search for. If you don't know what I am taking about, look at these examples:</p>

<p><a href=""https://i.stack.imgur.com/ADLGU.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ADLGU.jpg"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/cp9iR.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/cp9iR.jpg"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/8Wlfe.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/8Wlfe.jpg"" alt=""enter image description here""></a></p>

<p>What are these called?</p>
","<p>""Crosshairs"" or an ""aiming <a href=""https://en.wikipedia.org/wiki/Reticle"" rel=""noreferrer"">reticle</a>,"" usually. Probably also ""aiming dot"" and similar variations.</p>
","150829"
"How can I stop transform.position from being modified when adding a child object?","13852","","<p>I suspect there is a well-known and easy to explain reason for the behavior I'm seeing, but I am having difficulty explaining it (and likely not able to Google for the answer).</p>

<p>When adding a child <code>GameObject</code> to a translated parent, the child's <code>localPosition</code> is modified so that the child's <code>position</code> stays the same <em>after</em>  the parent's transformation is applied. Is there a way to <em>not</em> have this be the case?</p>

<p>In the following example, I create a parent object and move it to <code>(1,1,1)</code>, and then attach the child. I would like the child's position to be <code>(1,1,1)</code>, that is <code>(0,0,0)</code> relative to the parent. However, the child's position is modified to be <code>(-1,-1,-1)</code> so that it is <code>(0,0,0)</code> relative to the world.</p>

<p>Here is a repro:</p>

<pre><code>// Create parent.
GameObject parent = new GameObject();
parent.name = ""Parent GameObject"";
parent.transform.parent = foregroundObject.transform;

// Move the parent.
parent.transform.Translate(1, 1, 1);

// Add a child under the parent GameObject.
GameObject child = (GameObject) GameObject.Instantiate(guildiePrefab);
child.name = ""Child GameObject"";

child.transform.parent = parent.transform;

// PROBLEM: localPosition is set so that the ""global"" position is (0,0,0).
// How can I add the child object and have its position be (1,1,1)?
this.Assert(child.transform.localPosition.ToString() == ""(-1.0, -1.0, -1.0)"");
this.Assert(child.transform.position.ToString() == ""(0.0, 0.0, 0.0)"");
</code></pre>

<p>Is there a different way I should be adding <code>child</code> as a child of <code>parent</code>? Or, should I <em>always</em> zero-out the position of <code>parent</code> before adding a child? If that is the case, any reason why I need to do this? What is the rational for this design choice?</p>
","<p>When you instantiate using the default constructor for <code>Instantiate</code>, the position is set to (0,0,0). You can use the alternative constructor for <a href=""http://docs.unity3d.com/Documentation/ScriptReference/Object.Instantiate.html"" rel=""nofollow""><code>Instantiate</code></a>, and supply a position and rotation. If you want the child object to be position at zero relative to the parent, you can supply the parent position as the position to instantiate to.</p>

<pre><code>GameObject child = 
   (GameObject) GameObject.Instantiate(guildiePrefab,
                                       parent.transform.position,
                                       parent.transform.rotation);
child.name = ""Child GameObject"";

child.transform.parent = parent.transform;
</code></pre>

<p>Or if you have a specific offset you're interested in simply add it to the position when you instantiate:</p>

<pre><code>GameObject child = 
   (GameObject) GameObject.Instantiate(guildiePrefab,
                                       parent.transform.position + offset,
                                       parent.transform.rotation);
</code></pre>

<p>Either way, the child's position shown in the Inspector tab will be the child's position relative to the parent. The child's position found through <code>transform.position</code> will be the world position.</p>
","68969"
"How do I generate projectiles toward the mouse pointer?","13852","","<p>I'm making a top-down space shooter where the player controls a ship and can aim and shoot using the mouse cursor. How can I fire bullets <em>from the ship</em> at the <em>angle from the ship to the mouse cursor</em>? </p>
","<p>If I understood your problem properly, you just want to shoot a bullet towards a mouse position. Here is how I would do:</p>

<p>First of all, you must find the movement required for the bullet to get to the mouse, like so:</p>

<pre><code>Vector2 movement = mousePosition - bulletStartPosition;
</code></pre>

<p>Then, you should normalize it to have a vector with a length of 1 so that you can hold a vector which tells you in which direction to go, like so:</p>

<pre><code>movement.Normalize();
</code></pre>

<p>But here you have a little problem, if the direction is equal to <code>(0, 0)</code> (meaning that the mouse is on the bullet start position), then you'll divide by zero, so make sure you check for that with the last piece of code:</p>

<pre><code>if (movement != Vector2.Zero)
    movement.Normalize();
</code></pre>

<p>So, you've got the movement required to move towards the mouse. You have to keep a <code>Vector2</code> within your bullet class which holds the <code>Direction</code> of the bullet.</p>

<p>What's next? You have to actually move the bullet!</p>

<p>In your bullet update code, do the following:</p>

<pre><code>bullet.Position += bullet.Direction * bullet.Speed * gameTime.ElapsedGameTime.TotalSeconds; // multiply by delta seconds to keep a consistent speed on all computers.
</code></pre>

<p>Where <code>bullet.Speed</code> is a float representing the bullet's speed in units per second.</p>

<p>Basically, here are the things to change:</p>

<p>Inside you bullet class, add a <code>float Speed</code> and a <code>Vector2 Direction</code>.</p>

<p>When shooting, set your <code>bullet.Direction</code> to <code>mousePosition - bullet.Position</code> and safely normalize it (by checking for equality with <code>Vector2.Zero</code> first).</p>

<p>When updating your bullet, do the following: <code>bullet.Position += bullet.Direction * bullet.Speed * gameTime.ElapsedGameTime.TotalSeconds;</code>.</p>

<p>It should work.</p>
","13332"
"Any reliable polygon normal calculation code?","13848","","<p>Do you have any reliable 3d polygonal face normal calculation code?</p>

<p>Any language will do, I'll port it to make it work. Even if you find some code in a 3d game engine and post it here I'll be more than grateful.</p>

<p><strong>Edit:</strong></p>

<p>I'm using this but it fails when faces are 90 degrees upright or similar.</p>

<pre><code>        // the normal point
        var x:Number = 0;
        var y:Number = 0;
        var z:Number = 0;

        // if is a triangle with 3 points
        if (points.length == 3) {

            // read vertices of triangle
            var Ax:Number, Bx:Number, Cx:Number;
            var Ay:Number, By:Number, Cy:Number;
            var Az:Number, Bz:Number, Cz:Number;
            Ax = points[0].x;   Bx = points[1].x;   Cx = points[2].x;
            Ay = points[0].y;   By = points[1].y;   Cy = points[2].y;
            Az = points[0].z;   Bz = points[1].z;   Cz = points[2].z;

            // calculate normal of a triangle
            x = (By - Ay) * (Cz - Az) - (Bz - Az) * (Cy - Ay);
            y = (Bz - Az) * (Cx - Ax) - (Bx - Ax) * (Cz - Az);
            z = (Bx - Ax) * (Cy - Ay) - (By - Ay) * (Cx - Ax);

        // if is a polygon with 4+ points
        }else if (points.length &gt; 3){

            // calculate normal of a polygon using all points
            var n:int = points.length;          
            x = 0;
            y = 0;
            z = 0

            // ensure all points above 0
            var minx:Number = 0, miny:Number = 0, minz:Number = 0;
            for (var p:int = 0, pl:int = points.length; p &lt; pl; p++) {
                var po:_Point3D = points[p] = points[p].clone();
                if (po.x &lt; minx) {  minx = po.x;     }
                if (po.y &lt; miny) {  miny = po.y;     }
                if (po.z &lt; minz) {  minz = po.z;     }
            }
            if (minx &gt; 0 || miny &gt; 0 || minz &gt; 0){
                for (p = 0; p &lt; pl; p++) {
                    po = points[p];
                    po.x -= minx;
                    po.y -= miny;
                    po.z -= minz;
                }
            }

            var cur:int = 1, prev:int = 0, next:int = 2;
            for (var i:int = 1; i &lt;= n; i++) {

                // using Newell method
                x += points[cur].y * (points[next].z - points[prev].z);
                y += points[cur].z * (points[next].x - points[prev].x);
                z += points[cur].x * (points[next].y - points[prev].y);
                cur = (cur+1) % n;
                next = (next+1) % n;
                prev = (prev+1) % n;
            }
        }

        // length of the normal
        var length:Number = Math.sqrt(x * x + y * y + z * z);

        // if area is 0
        if (length == 0) {
            return null;

        }else{
            // turn large values into a unit vector
            x = x / length;
            y = y / length;
            z = z / length;
        }
</code></pre>

<p><strong>Edit:</strong></p>

<p>I can somehow display 3d arrows for each calculated normal and go so far as to document test cases where it worked and failed. But I was looking for a simpler solution, simply by using code that someone else has created and found to be working. Is OpenGL all you have? Doesn't anyone have any triangle/polygonal normal calculation code at all?</p>

<p><strong>To Jari:</strong></p>

<p>I'm using this code to calculate normals, as built from OpenGL's pseudo code. Is there something I've done wrong? and what would happen if the points are not perfectly inplane? would it fail and return a random normal or just change the normal slightly?</p>

<pre><code>            n = points.length;
            x = y = z = 0;
            for (i = 0; i &lt; n; i++) {
                j = (i + 1) % n;
                x += (points[i].y - points[j].y) * (points[i].z + points[j].z);
                y += (points[i].z - points[j].z) * (points[i].x + points[j].x);
                z += (points[i].x - points[j].x) * (points[i].y + points[j].y);
            }
</code></pre>
","<p>I'm successfully using this for quads / triangles.</p>

<p>Loop through each face, and pass in 3 verticies. 
If you have a quad ABCD pass in ABD. For example for the front facing face on this cube, I would pass in, v2, v3, v0</p>

<pre><code>// cube ///////////////////////////////////////////////////////////////////////
//    v6----- v5
//   /|      /|
//  v1------v0|
//  | |     | |
//  | |v7---|-|v4
//  |/      |/
//  v2------v3
</code></pre>

<p>This is in C++ which supports operator overloading, so if in AS3 convert to Vector3d, which I notice you're not using now, might as well. ( I could see why you aren't, sometimes when trying to make found code work i also want to rule out any variables that could make it fail )</p>

<pre><code>//  Modified from http://www.fullonsoftware.co.uk/snippets/content/Math_-_Calculating_Face_Normals.pdf
Vec3f RibbonMesh::calcNormal( const Vec3f &amp;p1, const Vec3f &amp;p2, const Vec3f &amp;p3 )
{
    Vec3f V1= (p2 - p1);
    Vec3f V2 = (p3 - p1);
    Vec3f surfaceNormal;
    surfaceNormal.x = (V1.y*V2.z) - (V1.z-V2.y);
    surfaceNormal.y = - ( (V2.z * V1.x) - (V2.x * V1.z) );
    surfaceNormal.z = (V1.x*V2.y) - (V1.y*V2.x);


    // Dont forget to normalize if needed
    return surfaceNormal;
}
</code></pre>

<p>Edit: Found source where I got this from
Edit: corrected calculation of z component of surface vector</p>
","8476"
"How exactly does XNA's SpriteBatch work?","13799","","<p>To be more precise, if I needed to recreate this functionality from scratch in another API (e.g. in OpenGL) what would it need to be capable of doing?</p>

<p>I do have a general idea of some of the steps, such as how it prepares an orthographic projection matrix and creates a quad for each draw call.</p>

<p>I'm not too familiar, however, with the batching process itself. Are all quads stored in the same vertex buffer? Does it need an index buffer? How are different textures handled?</p>

<p>If possible I'd be grateful if you could guide me through the process from when SpriteBatch.Begin() is called until SpriteBatch.End(), at least when using the default Deferred mode.</p>
","<p>I have sort of replicated the behaviour of SpriteBatch in deferred mode for a cross-platform engine I'm working on, so here are the steps I have reverse engineered so far:</p>

<ol>
<li><p><strong>SpriteBatch constructor:</strong> creates a <code>DynamicIndexBuffer</code>, <code>DynamicVertexBuffer</code> and array of <code>VertexPositionColorTexture</code> of fixed size (in this case, the maximum batch size - 2048 for sprites and 8192 for vertices).</p>

<ul>
<li>The index buffer is filled with the vertex indices of the quads that will be drawn (0-1-2, 0-2-3, 4-5-6, 4-6-7 and so on).</li>
<li>An internal array of <code>SpriteInfo</code> structs is created, too. This will store temporal sprite settings to be used when batching.</li>
</ul></li>
<li><p><strong>SpriteBatch.Begin:</strong> internally stores the values of <code>BlendState</code>, <code>SamplerState</code>, etc. specified and checks if it has been called twice without a <code>SpriteBatch.End</code> in between.</p></li>
<li><p><strong>SpriteBatch.Draw:</strong> takes all the sprite info (texture, position, color) and copies it to a <code>SpriteInfo</code>. If the max batch size is reached, the entire batch is drawn to make room for new sprites.</p>

<ul>
<li><code>SpriteBatch.DrawString</code> just issues a <code>Draw</code> for each character of the string, taking into account kerning and spacing.</li>
</ul></li>
<li><p><strong>SpriteBatch.End:</strong> does the following operations:</p>

<ul>
<li>Sets the render states specified in <code>Begin</code>.</li>
<li>Creates the orthographic projection matrix.</li>
<li>Applies the <code>SpriteBatch</code> shader.</li>
<li>Binds the <code>DynamicVertexBuffer</code> and <code>DynamicIndexBuffer</code>.</li>
<li><p>Performs the following batching operation:</p>

<pre class=""lang-cs prettyprint-override""><code>startingOffset = 0;
currentTexture, oldTexture = null;

// Iterate through all sprites
foreach SpriteInfo in SpriteBuffer
{
    // Store sprite index and texture
    spriteIndex = SpriteBuffer.IndexOf(SpriteInfo);
    currentTexture = SpriteInfo.Texture;

    // Issue draw call if batch count &gt; 0 and there is a texture change
    if (currentTexture != oldTexture)
    {
        if (spriteIndex &gt; startingOffset)
        {
            RenderBatch(currentTexture, SpriteBuffer, startingOffset,
                        spriteIndex - startingOffset);
        }
        startingOffset = spriteIndex;
        oldTexture = currentTexture;
    }
}

// Draw remaining batch and clear the sprite data
RenderBatch(currentTexture, SpriteBuffer, startingOffset,
            SpriteBuffer.Count - startingOffset);
SpriteBuffer.Clear();
</code></pre></li>
</ul></li>
<li><p><strong>SpriteBatch.RenderBatch:</strong> executes the following operations for each of the <code>SpriteInfo</code> in the batch:</p>

<ul>
<li>Takes the position of the sprite and calculates the final position of the four vertices according to the origin and size. Applies existing rotation.</li>
<li>Calculates the UV coordinates and applies specified <code>SpriteEffects</code> to them.</li>
<li>Copies the sprite color.</li>
<li>These values are then stored in the array of <code>VertexPositionColorTexture</code> elements previously created. When all sprites have been calculated, <code>SetData</code> is called on the <code>DynamicVertexBuffer</code> and a <code>DrawIndexedPrimitives</code> call is issued.</li>
<li>The vertex shader only performs a tranform operation, and the pixel shader applies the tinting on the color fetched from the texture.</li>
</ul></li>
</ol>
","21230"
"How to choose how to store data?","13771","","<blockquote>
  <p><em>Give a man a fish and you feed him for a day. Teach a man to fish and you feed him for a lifetime.</em> 
  - <strong>Chinese Proverb</strong></p>
</blockquote>

<p>I could ask what kind of data storage I should use for my actual project, but I want to learn to <em>fish</em>, so I don't need to ask for a <em>fish</em> each time I begin a new project.</p>

<p>So, until I used two methods to store data on my non-game project: XML files, and relational databases. I know that there is also other kind of database, of the <em>NoSQL</em> kind. However I wouldn't know if there is more choice available to me, or how to choose in the first place, aside arbitrary picking one.</p>

<p>So the question is the following: How should I choose the kind of data storage for a game project?</p>

<p>And I would be interested on the following criterion when choosing:</p>

<ul>
<li>The size of the project.</li>
<li>The platform targeted by the game, as well as the development platform used.</li>
<li>The complexity of the data structure.</li>
<li><em>Added</em> Portability of data amongst many project.</li>
<li><em>Added2</em> Silmutaneous use of the data amongst different project. (i.e. User data)</li>
<li><em>Added</em> How often should the data be accessed</li>
<li><em>Added</em> Multiple type of data for a same application</li>
<li><em>Added2</em> Configuration with multiple data storage.</li>
<li>Any other point you think is of interest when deciding what to use.</li>
</ul>

<p><strong>EDIT</strong> I know about <a href=""https://gamedev.stackexchange.com/questions/4666/would-it-be-better-to-use-xml-json-text-or-a-database-to-store-game-content"">Would it be better to use XML/JSON/Text or a database to store game content?</a>, but thought it didn't address exactly my point. Now if I am wrong, I would gladely be shown the error in my ways.</p>

<p><strong>EDIT2</strong> Added some more points that I would consider relevant. Furthermore, I would be interested to hear what other options are available, aside flat file storage and relational database. What about non-relational database, for example? When it is relevant to use such a database over the formerly mentioned other options?</p>
","<p>Your question is <em>really</em> broad because of the sheer number of genres out there, but here's the perspective of a professional software developer.</p>

<p>You provided a list of criteria that you want to use to determine which data persistence mechanism you use. Those were:</p>

<ul>
<li>The size of the project. </li>
<li>The platform targeted by the game.</li>
<li>The complexity of the data structure.</li>
<li>Portability of data amongst many project.</li>
<li>How often should the data be accessed</li>
<li>Multiple type of data for a same application</li>
<li>Any other point you think is of interest when deciding what to use.</li>
</ul>

<p>First we need to establish which options are available to us. Since you didn't specify a language or technology, it's hard to say exactly, but you are probably trying to decide between <strong>XML</strong> and <strong>relational database</strong> storage. </p>

<p>An important distinction to make is that <strong>XML</strong> isn't really a storage <em>mechanism</em> so much as a serialization technique. It's a way to represent in-memory structures for your game. Given that, you're really talking about <strong>flat file</strong> vs. <strong>relational database</strong> storage. These aren't the only options, but they're the most common, so I'm going to use them.</p>

<p>For flat files:</p>

<ul>
<li>XML</li>
<li>JSON</li>
<li>YAML</li>
<li>XAML</li>
<li>Plain Text</li>
</ul>

<p>For databases:</p>

<ul>
<li>SQL Server</li>
<li>MySQL</li>
<li>DB2</li>
<li>Oracle</li>
<li>Many More</li>
</ul>

<p><strong>EDIT:</strong> You asked about other types of mechanisms aside from files and relational databases. The only other notable type of database that I have seen used on a regular basis are ""Berkeley-style"" databases, which are essentially key-value based. These tend to use B-trees to structure data so lookups are fast. These are great for configuration/setting lookup where you know exactly what you want (e.g., give me all the telemetry data for ""Level 1"").</p>

<p>Now that we have all the basics out of the way, let's touch on some of your criteria.</p>

<p><strong>The size of the project.</strong> </p>

<p>Some might disagree, but the size of your project won't necessarily have a huge impact on your data persistence mechanism. You will want to build a reusable library of functions that store/load data from whichever mechanism you want. I would even suggest implementing an abstraction layer (check out the <a href=""http://en.wikipedia.org/wiki/Adapter_pattern"">Adapter pattern</a>) so that you could easily change your persistence mechanism if you needed to.</p>

<p>Having said that, for small projects, using XML on the file system can potentially work well, but you will want to address some of your security concerns (i.e., encryption) so that players can't change data at will.</p>

<p><strong>The platform targeted by the game.</strong></p>

<p>Platform isn't going to be a huge issue either. You should be more concerned about your development platform than the target platform. The reason for this is that some languages handle certain types of markup or databases better than others out of the box. That isn't to say that you couldn't use any of the above in almost any language, but sometimes it's best to use the supported tools that are available to you. Any platform will support flat files and parse XML, but on mobile platforms you might want to consider binary serialization if possible, or at least optimize your XML for storage.</p>

<p><strong>The complexity of the data structure.</strong></p>

<p>This is sort of a tricky one. Relational databases are great for just that...storing entities and their relationships. You have a better ability to enforce structure using a relational storage repository than you do with files on a file system. Consider the types of relationships between your entities as well as how often you're changing them or finding related entities. For extremely complex structures, I would suggest going the database route.</p>

<p><strong>Portability of data amongst many project.</strong></p>

<p>When it comes to portability, you should consider the fact that databases are naturally more heavyweight than files. There's installation and configuration overhead, different databases will be available for different platforms, etc. SQLite is a pretty good way around this. However, when it comes to portability, you will likely have an easier time with file-based solutions like XML.</p>

<p><strong>EDIT:</strong> There are some other concerns you mentioned about portability in one of your comments. Ultimately you don't want your data to be coupled too tightly to any product or file type. It's ultimately best if you can store stock data (levels, enemies, etc.) in some kind of abstract format (tab delimited files, XML, etc.) that you can easily parse and store in a database/file system at compile or load time. This means that you can swap out your storage mechanism on a whim and just rewrite the parsing piece.</p>

<p><strong>How often should the data be accessed</strong></p>

<p>Lots of data access means lots of I/O unless you have some kind of a caching mechanism. Databases keep structures in memory and are great for data manipulation and retrieval. If you're really persisting data constantly, you might want to stick with a database.</p>

<p><strong>Multiple type of data for a same application</strong></p>

<p>Volume is certainly a consideration, but unless you're talking about persisting thousands or millions of objects, file system will still be acceptable as a solution.</p>

<p><strong>Game Type</strong></p>

<p>The type of game you're building can have a huge influence on the platform you choose. Yeah, for most client-only single-player games, you're going to be fine using a compressed or encrypted file system-based solution. If you're talking about games with an online component, though, that would be crazy. Go the database route and save yourself the headache. Let the server manage all of your data using a back-end cluster.</p>

<p>Hope some of this feedback helps. It's by no means completely comprehensive, and making the decision is ultimately up to you, but my commentary should give you some things to think about.</p>

<p><strong>EDIT:</strong> There are some times where taking a hybdrid approach makes a lot of sense. For example, let's say you are developing an MMORPG. On the client side, you might store cached data about other players in a non-relational database (as mentioned above). On the server side, you're storing all game data in a relational database to persist it. And then again on the client side you're probably storing log data, configuration data, etc. in XML/flat files for easier accessibility. </p>

<p>Another poster also mentioned that sometimes it's nice, even if you're storing data for production in a database, to have a way that you can use flat files for development instead...it can just be easier to remove another product from the mix.</p>
","8063"
"Why is an engine like Unity3D emphasized over a native library like OpenGL for beginners?","13750","","<p>I am just a beginner in 3D games, my preferred platform is Android. I posted a question in some other forum about ""What to use: OpenGL or Unity3d?"" They all emphasized Unity3D and using its built-in features and tools, which I would have to code myself if I were to use OpenGL. But then someone says most of the complex games require custom engines. Why would I use an engine like Unity3D over OpenGL?</p>
","<p>I think you've answered this question yourself already. You said <em>""I'm just a beginner in 3D games""</em>. Further you said <em>""... Unity3D and using it's built in features and tools, which I would have to code myself if I were to use OpenGL""</em>. </p>

<p>Essentially this means if you're using OpenGL alone, you're going to be writing a game engine, then, potentially years later, writing your game. If you want to focus on a game, utilize the resources available to you to get you as close to that goal as possible. Using a game engine is the best way focus your efforts on creating a game, instead of writing all the stuff required to create a game.</p>

<p>See this related question: <a href=""https://gamedev.stackexchange.com/questions/10770/whats-the-difference-between-a-library-and-an-engine"">What&#39;s the difference between a Library and an Engine</a> and this one <a href=""https://gamedev.stackexchange.com/questions/31772/what-is-a-game-framework-versus-a-game-engine?rq=1"">What is a game framework versus a game engine?</a> </p>
","74197"
"Simple framerate counter?","13739","","<p>I'm making a first person shooter, and I've seen questions like this before, but the answer is either overly complicated or they're using SDL, GLFW, GLUT, or something else. I'm not using any of that. OpenGL, C++, and GLEW for me.</p>

<p>I am just a little confused on how to do a framerate counter, so if I could get pseudo-code or some code-snippets that would point me in the right direction, that would help.</p>
","<p>To measure framerate you need two counts:</p>

<ul>
<li>How many <strong>frames</strong> (<em>not</em> draw calls) have passed, and,</li>
<li>How much time has passed.</li>
</ul>

<p>Your framerate is therefore calculated as:</p>

<pre><code>frames / time
</code></pre>

<p>There are a few subtle complexities to this.</p>

<p>First thing is that you need a good, accurate, high resolution timer.  You don't say what platform you're on so I'm not going to make any assumptions beyond:</p>

<ul>
<li>You have such a timer available, and,</li>
<li>You're <strong>not</strong> using Sleep calls to control framerate (if you are, <strong>stop it now</strong>).</li>
</ul>

<p>Let's say that you're storing the time in a variable called ""timepassed"".  It's a double and it starts at 0 and counts the time (in seconds) since the game started.  Our framerate counter begins like this:</p>

<pre><code>static int frames = 0;
static double starttime = 0;
static bool first = TRUE;
static float fps = 0.0f;
</code></pre>

<p>The first thing we do is check if this is the first time we've passed through the counter and set some stuff up:</p>

<pre><code>if (first)
{
    frames = 0;
    starttime = timepassed;
    first = FALSE;
    return;
}
</code></pre>

<p>Next we increment the number of frames that have passed; I'm assuming here that you're updating the framerate counter once per frame only:</p>

<pre><code>frames++;
</code></pre>

<p>And here we evaluate the actual FPS number.  </p>

<pre><code>if (timepassed - starttime &gt; 0.25 &amp;&amp; frames &gt; 10)
{
    fps = (double) frames / (timepassed - starttime);
    starttime = timepassed;
    frames = 0;
}
</code></pre>

<p>Here we update the FPS count every 0.25 seconds.  This isn't strictly speaking necessary but otherwise if you have a variable framerate you're going to be getting numbers wildly flashing on your screen and you won't be able to read them too good.  (It's also important that timepassed - starttime is greater than 0.)  After calculating the FPS we then update our static variables for the next pass through.</p>

<p>This is prety much my standard FPS counter (it's C heritage shows in some of the code) and I've cross-checked it with the values provided by FRAPS and found it highly accurate.</p>
","83174"
"Trying to understand light on Opengl, how to simulate a realistic sun light?","13737","","<p>I don't know if I'm doing something wrong or missing anything but I want to simulate sun light, like in a sunny day.</p>

<p>When the object is facing the directional light, it's well lit and there's no problems there. If I go around the object and look at it's back, it's dark. It's not too much dark because I'm using <code>GL_AMBIENT</code> but it's still too dark for a sunny day. If I increase the value, it will never look better because the side of the object facing the light will be too bright.</p>

<p>And there's another annoying issue with the ambient light, when looking at the back of the object, I can't see any shape, only a plain color. Hard to explain, here's some pictures:</p>

<p>Object Front: <a href=""https://i.stack.imgur.com/YW53X.png"" rel=""noreferrer"">http://i.stack.imgur.com/YW53X.png</a><br>
Object Back: <a href=""https://i.stack.imgur.com/Qufha.png"" rel=""noreferrer"">http://i.stack.imgur.com/Qufha.png</a></p>

<p>As you can easily see, the front side looks nice, you can see the shape of that red thing. On the back side, it's plain, you can't see the same shape.</p>

<p>Now, I know that I'm looking at the back of an object and I'm looking in the direction of the light and it should be darker than the front side. But it shouldn't look so plain like this. That's not what we see when going against the sun light looking at some object, we see that the objects form some shape.</p>

<p>How can I have the same (or similar) effect on OpenGL?</p>

<p>My light is currently defined like this:</p>

<pre><code>float posLight0[4] = {-1.0f, 1.0f, 1.0f, 0.0f};
float ambLight0[4] = {0.5f, 0.5f, 0.5f, 0.5f};

glLightfv(GL_LIGHT0, GL_POSITION, posLight0);
glLightfv(GL_LIGHT0, GL_AMBIENT, ambLight0);
</code></pre>
","<p>With the ambient light your objects appear too bright because the diffuse light is added to the ambient light, and the diffuse light defaults to 1.0. This adds up to 1.5, and everything above 1.0 is clamped. Set the diffuse light to 0.5:</p>

<pre><code>float difLight0[4] = {0.5f, 0.5f, 0.5f, 1.0f};
glLightfv(GL_LIGHT0, GL_DIFFUSE, difLight0);
</code></pre>

<p>The second problem is harder to solve. You can try adding some fine details to the surface such as texture or bump map. In OpenGL the ambient light is constant, but in real world that is never the case. To simulate the real world, some form of <a href=""http://en.wikipedia.org/wiki/Global_illumination"">global illumination</a> solution is needed. <a href=""http://en.wikipedia.org/wiki/Ambient_occlusion"">Ambient occlusion</a> helps a lot here, but is harder to implement than just setting OpenGL states. You could bake the ambient occlusion to the vertices of your model in your 3D modeling software or use <a href=""http://en.wikipedia.org/wiki/Screen_Space_Ambient_Occlusion"">SSAO</a>, but I'm not going to the details.</p>

<p>What you can easily do is add another dimmer light source from some other direction (e.g. opposite direction). This will not be realistic, but at least it will give some shape for the back sides of your objects as well.</p>

<p>Also consider adding specular highlights to your application. It will make objects shiny.</p>

<pre><code>float specLight0[4] = {0.5f, 0.5f, 0.5f, 1.0f};
glLightfv(GL_LIGHT0, GL_SPECULAR, specLight0);
glMaterialfv(GL_FRONT, GL_SHININESS, 10.0f); // Shininess between 0 and 128
</code></pre>

<p>You can also specify light and material colors separately, especially if the defaults are not suitable for you.</p>
","10652"
"What are the differences betwen Texture, TextureRegion, TextureAtlas, Sprite and Image in libgdx?","13708","","<p>I've searched around for tutorials. I've seen people using the above classes to load images.</p>

<p>As according to my understanding, all of the classes can read in a non-power of two images, TextureRegion/TextureAtlas are usually used to load sprite sheet, in which the sheet contains multiple images. While for Texture/Sprite/Image, they are used to load a sprite sheet with single image. </p>

<p>However, I'm not so sure in which situation I should use Texture/Sprite/Image and in which situation I should use TextureRegion/TextureAtals.</p>

<p>Please correct me if I'm wrong, as I'm a bit confused by the terminologies in the API after looking various tutorials.</p>
","<p>First, Texture vs TextureRegion:
When you do something like Texture t = new Texture(path), you are loading that into GPU. In addition, you should load power of 2 textures. You could work with other resolutions (Texture.setEnforcePotImages = false), but it's encouraged to use pow of 2.</p>

<p>Now, TextureRegion, takes a ""piece"" from a Texture, no matter it's dimension. The advantage of having one Texture and multiple TextureRegion of that Texture, is that you are NOT loading every region into GPU. </p>

<p>As you may be thinking, when you want to draw with the SpriteBatch, it's much more efficient to use TextureRegion instead of multiple Textures, I'm sorry my english is not good enough. Here is a good explanation: <a href=""https://github.com/libgdx/libgdx/wiki/Textures%2C-textureregion-and-spritebatch"" rel=""noreferrer"">Textures TextureRegion &amp; SpriteBatch</a></p>

<hr>

<p>Now, you want to use TextureRegion and one single image in power of 2 resolution with all the spritesheets and images. Do you have to create TextureRegions with all the coordinates and dimensions? Do you need to open paint to count pixels? Noooo, you don't. You can use something like <a href=""http://code.google.com/p/libgdx-texturepacker-gui/"" rel=""noreferrer"">TexturePacker</a>. It will pack every texture into one image AND create a .pack file with de dimensions and coordinates of all of them.</p>

<p><img src=""https://i.stack.imgur.com/cdfP4.png"" alt=""TexturePacker""></p>

<p>The result will be something like this:</p>

<p><img src=""https://i.stack.imgur.com/GuAge.png"" alt=""Pack""></p>

<p>Instead of creating a Texture, create a TextureAtlas, like this:</p>

<p><img src=""https://i.stack.imgur.com/KrcIV.png"" alt=""Create TextureAtlas""></p>

<p>Now, creating your TextureRegions would be as simple as:</p>

<p><img src=""https://i.stack.imgur.com/x0iXD.png"" alt=""findRegion""></p>

<p>(Note that the name of the region is the name of the original image without the extension).</p>

<hr>

<p>Sprite holds the geometry, color, and texture information for drawing 2D sprites using Batch. This mean, you can easily rotate them and move. I've created my own Entity class, and I don't need Sprite class. You would probably do the same. I don't find this class really usefull.</p>

<hr>

<p>Image class inherits from Actor. This mean you can add it into a stage. It's part of the Scene2D package. If your are new to libgdx, and you don't know about this package, this is enough information for you about this class. It's a really interesting topic, but not to answer in this question.</p>

<p>Hope it helps :)</p>
","66626"
"How can I process continuously-held keys with SDL?","13684","","<p>I have created a cube in opengl using SDL. Now I am trying to move the camera in X direction if user presses left or right arrow keys and Y direction if user presses up or down arrow keys. Right now the camera moves by a fixed amount in a particular direction if the key gets pressed once. It doesn't matter how long does a person hold the key down, it moves by that fixed amount only. I want the camera to move continuously as long as the key is pressed.</p>

<p>Below is the code for keyboard polling.</p>

<pre><code>        while ( SDL_PollEvent( &amp;event ) )
        {
            switch( event.type )
            {
            case SDL_ACTIVEEVENT:
                if ( event.active.gain == 0 )
                isActive = FALSE;
                else
                isActive = TRUE;
                break;              
            case SDL_VIDEORESIZE:
                surface = SDL_SetVideoMode( event.resize.w,
                            event.resize.h,
                            16, videoFlags );
                if ( !surface )
                {
                    fprintf( stderr, ""Could not get a surface after resize: %s\n"", SDL_GetError( ) );
                    Quit( 1 );
                }
                resizeWindow( event.resize.w, event.resize.h );
                break;
            case SDL_KEYDOWN:
                handleKeyPress( &amp;event.key.keysym );
                break;
            case SDL_QUIT:
                done = TRUE;
                break;
            default:
                break;
            }
        }
</code></pre>

<p>And below i have mentioned the keypress handler function</p>

<pre><code>void handleKeyPress( SDL_keysym *keysym )
{
    switch( (keysym-&gt;sym) ){
        case SDLK_ESCAPE:
            Quit(0);
            break;
        case SDLK_LEFT:
              eye[0] -= 0.1;
              break;
            case SDLK_RIGHT:
              eye[0] += 0.1;
              break;
            case SDLK_UP:
              eye[1] -= 0.1;
              break;
            case SDLK_DOWN:
              eye[1] += 0.1;
              break;
            default:
              break;
      }

    return;
}
</code></pre>

<p>What changes should I make in my code to handle continuous keystroke detection?</p>

<p><strong>Note:</strong>
The following code does the required job but I don't understand why</p>

<pre><code>if ( ( SDL_EnableKeyRepeat( 100, SDL_DEFAULT_REPEAT_INTERVAL ) ) )
{
        fprintf( stderr, ""Setting keyboard repeat failed: %s\n"",
             SDL_GetError( ) );
        Quit( 1 );
}
</code></pre>
","<pre><code>void Main::processInput()
{
    Uint8* keystate = SDL_GetKeyState(NULL);

    //continuous-response keys
    if(keystate[SDLK_LEFT])
    {
    }
    if(keystate[SDLK_RIGHT])
    {
    }
    if(keystate[SDLK_UP])
    {
    }
    if(keystate[SDLK_DOWN])
    {
    }

    //single-hit keys, mouse, and other general SDL events (eg. windowing)
    while(SDL_PollEvent(&amp;event))
    {
        switch (event.type)
        {
            case SDL_MOUSEMOTION:
            break;

            case SDL_QUIT:
            case SDL_KEYDOWN:
                if(event.key.keysym.sym == SDLK_ESCAPE)
                    done = true; //quit
            break;
        }
    }
}
</code></pre>

<p>Usage:</p>

<pre><code>Main::Main()
{
    //set up SDL etc.
    //set up timing variables etc.
    timeStepMs = 1000.f / yourUpdateFrequency; //eg. 30Hz
    //set up game world etc.

    //main loop, run like the wind!
    while(!done)
    {

        timeLastMs = timeCurrentMs;
        timeCurrentMs = SDL_GetTicks();
        timeDeltaMs = timeCurrentMs - timeLastMs;
        timeAccumulatedMs += timeDeltaMs;

        while (timeAccumulatedMs &gt;= timeStepMs)
        {
              processInput();
              //update world: do ai, physics, etc. here
              timeAccumulatedMs -= timeStepMs;
        }
        render(); //render update only once
    }
}
</code></pre>
","19583"
"How is a 3d perlin noise function used to generate terrain?","13673","","<p>I can wrap my head around using a 2d perlin noise function to generate the height value but I don't understand why a 3d perlin noise function would be used. In Notch's blog, <a href=""http://notch.tumblr.com/post/3746989361/terrain-generation-part-1"">http://notch.tumblr.com/post/3746989361/terrain-generation-part-1</a>, he mentioned using a 3d perlin noise function for the terrain generation on Minecraft. Does anyone know how that would be done and why it would be useful? If you are passing x,y, and z values doesn't that imply you already have the height?</p>
","<p>2D perlin noise is good for height maps, but in this case it seems that he is not using a height map. Instead he has a 3D grid, where any cell can be empty. This allows caves and such formations, where the ground height is not a single value for given 2D location.</p>
","12614"
"What language was used to write Starcraft II?","13670","","<p>Total newbie question , but what language was used by blizzard to crate the Starcraft II game play? I've been playing it for the last couple of days , and I'm constantly astonished by the complexity and the performance of the game. Is it an in-house language , or do they use some flavor of a know language? </p>
","<p>The actual game itself uses a combination of C, C++ and XML (for metadata).</p>

<p>The scripting language used called 'Galaxy'. It's a C-based language built into the game engine.<br />
It's used in the campaign and in custom maps.</p>
","2413"
"Most common resolution used in Android phones as of 2013","13665","","<p>Before making an Android app, I want to know what screen resolutions I should target. I know there are resolutions of 1280x800, 1280x720 and 800x480, but I would like to know which are most common.</p>

<p>Are there any recent stats on the distribution of Android devices' screen resolutions?</p>
","<p>A quick snapshot of the information on current android devices can be found here:</p>

<p><a href=""http://developer.android.com/about/dashboards/index.html"">http://developer.android.com/about/dashboards/index.html</a></p>

<p>The site is kept up to date every 14-days based on devices which access the Google Play Store so its a pretty decent source for information.</p>
","59556"
"LOD in modern games","13643","","<p>I'm currently working on my master's thesis about <a href=""http://en.wikipedia.org/wiki/Level_of_detail"">LOD</a> and mesh simplification, and I've been reading many academic papers and articles about the subject. However, I can't find enough information about how LOD is being used in modern games. I know many games use some sort of dynamic LOD for terrain, but what about elsewhere? </p>

<p><a href=""http://lodbook.com/"">Level of Detail for 3D Graphics</a> for example points out that discrete LOD (where artists prepare several models in advance) is widely used because of the performance overhead of continuous LOD. That book was published in 2002 however, and I'm wondering if things are different now. There has been some research in performing dynamic LOD using the geometry shader (<a href=""http://www.cs.princeton.edu/gfx/pubs/DeCoro_2007_RMS/index.php"">this paper</a> for example, with its implementation in ShaderX6), would that be used in a modern game? </p>

<p>To summarize, my question is about the state of LOD in modern video games, what algorithms are used and why? In particular, is view dependent continuous simplification used or does the runtime overhead make using discrete models with proper blending and impostors a more attractive solution? If discrete models are used, is an algorithm used (e.g. <a href=""http://www.gvu.gatech.edu/%7Ejarek/papers/VertexClustering.pdf"">vertex clustering</a>) to generate them offline, do artists manually create the models, or perhaps a combination of both methods is used?</p>
","<p>For now it seems that discrete LOD is still preferred, but it remains to be seen if this will change with the next generation of console hardware.</p>

<p>For what it's worth Tom Forsyth has written a lot about continuous LOD, which he calls ""progressive meshing"".  Game Programming Gems 2 purports to have one of these articles, but it appears to be mirrored <a href=""http://home.comcast.net/~tom_forsyth/papers/papers.html"">here</a>.</p>

<p>I believe one of Tom's games shipped using progressive meshing on last-gen console hardware.  I don't think it's the computation overhead people are worried about with continuous LOD.  I think it's more that discrete LOD is easier.  Continuous LOD does heavier lifting in the tools pipeline and does not have enough clear advantages.</p>

<p>As for generation of discrete LODs, we use a combination of automatic tools and artist creation.  The DirectX SDK comes with some stuff to auto-reduce geometry and I believe we use that as a first pass, if the quality is not good enough then artists generate the discrete LODs by hand or using additional tools in Maya.</p>
","2773"
"What are the typical day-to-day tasks of an entry level games programmer?","13582","","<p>What I would like to know is: What are the daily duties of a graduate programmer in the games industry workplace? Is it mostly coding, analysing, designing, or what?</p>

<p>Thank you.</p>

<p>P.S. I am in my second year of University at the moment and am working towards specialising in games programming, specifically gameplay, tools or UI programming.</p>
","<p>Based on my experience (in the United States, hired out of college onto a project that had just gotten out of prototyping and was a team of about 50, was then cancelled, then we went on to make two more games over the four years I was there with a total developer base of about 200),</p>

<ul>
<li>You'll probably spend about 50-70% of your time programming. In this time, I'm including the 'fun stuff' like getting to make a really clever feature, as well as the times you're staring at a memory dump for 8 hours straight trying to figure out what crashed. Maybe 25-50% of that is actual sit-down-at-your-keyboard-and-get-in-the-zone long-form programming.</li>
<li>Another 15-25% in meetings and administrative tasks, like bug triage, meetings about bug triage, scheduling, high-level documentation for other programmers and producers, email, whole project/company status updates, and so on. This depends on how much autonomy you have - if you have no autonomy, then you'll get to spend more time programming, because you'll spend less time setting your own schedule. If you take more control of your schedule, you might get to work on more interesting things, but then you need to spend time doing this stuff.</li>
<li>Another 15-25% helping designers/artists, attending creative meetings actually about the game, keeping up to date with game design documents, and so on.</li>
</ul>

<p>As you go up in pay grade, the time you spend programming is probably going to <em>go down</em>. You're going to have to make more administrative decisions, be called upon to help less experienced people on the team, and spend more time doing documentation and code / architecture review. On the plus side, the <em>quality</em> of the programming will probably go up; you'll get to work on more interesting features (and more frustrating bugs).</p>

<p>Whether the time you spend in helping designers and artists goes up, down, or doesn't really change, depends on the area you want to work in. If you want to work on UI, tools, and gameplay, expect that time to increase to upwards of 50% as you gain more experience. You'll be sitting down with senior designers to plan and demo new tools and see how they use the existing ones. Unfortunately, this time also comes out of your programming schedule.</p>
","5540"
"How can I create a 'flaming' effect like in Ocarina of Time's title screen?","13557","","<p>I'd like to recreate a flaming effect like the one from the logo on the title screen of the N64 game 'The Legend of Zelda: Ocarina of Time,' shown below:</p>

<p><a href=""https://i.stack.imgur.com/amoBr.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/amoBr.gif"" alt=""enter image description here""></a></p>

<p>A quick look into the textures used in the ROM provide a single 32x32 texture that looks similar to the effect but I don't know how that image (assuming that's the right one) is transformed into the effect seen on the logo.</p>

<p>How can I implement something similar?</p>
","<p>First make a white-on-black mask of your logo/text and blur it.</p>

<p><a href=""https://i.stack.imgur.com/8rLkI.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/8rLkI.png"" alt=""blurred shape of logo""></a></p>

<p>Then create a repeating (tileable) solid noise texture (GIMP used here)</p>

<p><a href=""https://i.stack.imgur.com/BvMq9.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/BvMq9.png"" alt=""noise texture""></a></p>

<p>Use the Map->Tile... filter to create a 3x3 tiled pattern (in this example, 128x128 x 3 = 384x384) for the next step to ensure our texture is still repeatable - we'll keep only the center part.</p>

<p><a href=""https://i.stack.imgur.com/NjGg3.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/NjGg3.png"" alt=""previous image tiled 3 by 3""></a></p>

<p>Use Blur->Motion Blur... to blur the texture upward and keep only the center 1/3rd (back to 128x128)</p>

<p><a href=""https://i.stack.imgur.com/gGgeD.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/gGgeD.png"" alt=""noise plus motion blur""></a></p>

<p><strong>Multiply</strong> both textures together on the GPU and use this for opacity.</p>

<p><a href=""https://i.stack.imgur.com/XqQEQ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/XqQEQ.png"" alt=""mask combined with noise""></a></p>

<p>Then animate it by moving the pattern texture upward over the mask texture:</p>

<p><a href=""https://i.stack.imgur.com/XQof0.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/XQof0.gif"" alt=""mask combined with moving noise""></a></p>

<p>Done for the animation part.</p>

<p>Then you can apply a <strong>gradient map</strong> (black -> red -> yellow -> white) to give it fire colours:</p>

<p><a href=""https://i.stack.imgur.com/qg4xI.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qg4xI.gif"" alt=""logo shape with fire colours""></a></p>

<p>Other colours can be used create a ghastly blue fire, a light yellow aura field, a more smoky effect, etc. </p>

<p>Now if you combine this as <strong>additive</strong> over your logo and the 3D render you get the wanted effect:</p>

<p><a href=""https://i.stack.imgur.com/BLMoH.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/BLMoH.png"" alt=""background""></a> + <a href=""https://i.stack.imgur.com/57QRH.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/57QRH.png"" alt=""logo""></a> + <a href=""https://i.stack.imgur.com/qg4xI.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qg4xI.gif"" alt=""fire""></a> = <a href=""https://i.stack.imgur.com/oE5SZ.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/oE5SZ.gif"" alt=""flaming logo over background""></a></p>

<p>The effect can darkened by adjusting the mask and/or pattern brightness, and/or vertex color, and/or gradient color map to the designed level.</p>

<p>You can even use two textured patterns together (Mask * Fire Pattern * Fire Pattern) at different speeds and directions to create a more complex fire effect.</p>

<hr>

<p>Technically on the N64 they may have created an approximation of the mask using a triangle mesh and vertex color instead of the mask texture due to the N64's hardware limitation regarding textures but the end result is the same ((vertex color * pattern texture) vs (mask texture * pattern texture)). </p>

<p><a href=""https://i.stack.imgur.com/kWMyN.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/kWMyN.png"" alt=""Vertex color mock-up""></a></p>

<p>We can still use vertex colour but 20 years later we can make our lives easier and just use 2 textures or more, even today's mobile GPUs can handle an extra 256x128 gray texture without problem.</p>
","149927"
"Is there a way to display navmesh agent path in Unity?","13551","","<p>I'm currently making a prototype for a game I plan to develop. As far as I did, I managed to set up the navigation mesh and my navmeshagents.</p>

<p>I would like to display the path they are following when <code>setDestination()</code> is fired.</p>

<p>I did some researches but didn't find anything about it.</p>

<p>EDIT 1 : So I instantiate an empty object with a LineRenderer and I have a line bewteen my agent and the destination. Still I've not all the points when the path has to avoid an obstacle. Furthermore, I wonder if the agent.path does reflect the real path that the agent take as I noticed that it actually follow a ""smoothier"" path.</p>

<p>Here is the code so far :</p>

<pre><code>GameObject container = new GameObject();
container.transform.parent = agent.gameObject.transform;
LineRenderer ligne = container.AddComponent&lt;LineRenderer&gt;();
ligne.SetColors(Color.white,Color.white);
ligne.SetWidth(0.1f,0.1f);
//Get def material

ligne.gameObject.renderer.material.color = Color.white;
ligne.gameObject.renderer.material.shader = Shader.Find(""Sprites/Default"");
ligne.gameObject.AddComponent&lt;LineScript&gt;();
ligne.SetVertexCount(agent.path.corners.Length+1);
int i = 0;
foreach(Vector3 v in p.corners)
{
    ligne.SetPosition(i,v);
    //Debug.Log(""position agent""+g.transform.position);
    //Debug.Log(""position corner = ""+v);
    i++;
}
ligne.SetPosition(p.corners.Length,agent.destination);
ligne.gameObject.tag = ""ligne"";
</code></pre>

<p>So How can I get the real coordinates my agent is going to walk throught ?</p>
","<p><strong>It's actually really simple.</strong> First you put a line renderer component on your nav mesh agent object. If you notice, there is an array called positions. So if you attach the following script to your nav mesh agent, it will create a path between the nav mesh agent's origin and the destination.</p>

<pre><code>var line : LineRenderer; //to hold the line Renderer
var target : Transform; //to hold the transform of the target
var agent : NavMeshAgent; //to hold the agent of this gameObject

function Start(){
    line = GetComponent(LineRenderer); //get the line renderer
    agent = GetComponent(NavMeshAgent); //get the agent
    getPath();
}

function getPath(){
    line.SetPosition(0, transform.position); //set the line's origin

    agent.SetDestination(target.position); //create the path
    yield WaitForEndOfFrame(); //wait for the path to generate

    DrawPath(agent.path);

    agent.Stop();//add this if you don't want to move the agent
}

function DrawPath(path : NavMeshPath){
    if(path.corners.Length &lt; 2) //if the path has 1 or no corners, there is no need
        return;

    line.SetVertexCount(path.corners.Length); //set the array of positions to the amount of corners

    for(var i = 1; i &lt; path.corners.Length; i++){
        line.SetPosition(i, path.corners[i]); //go through each corner and set that to the line renderer's position
    }
}
</code></pre>

<p>So that will create a path in the game view.</p>

<p>Hope this helps.</p>
","86255"
"How do I make an entity move in a direction?","13545","","<p>I have an <code>Entity</code> instance which is updated every game tick. Let's just assume that entity moves forward constantly. I'd like to be able to give the entity's angle to a function that makes it move in that direction:</p>

<p><code>moveForward(90);</code> should make them move to the right. If I declared my rotation as a global <code>int</code>, then doing</p>

<pre><code>moveForward(rotation);
rotation++;
</code></pre>

<p>would make it trace a small circle with its movement.</p>

<p>How can I do this? I assume this involves vector math; I don't know any, so a brief explanation would be nice.</p>
","<p>Well in the simplest sense you have something like this.</p>

<pre><code>   y  |\
      | \
   m  |  \         s
   o  |   \        p
   v  |(a) \       e
(y)e  |angle\      e
   m  |      \     d
   e  |       \
   n  |        \
   t  |         \
      |__________\
      x movement
        (x)
</code></pre>

<p>The speed is however fast the enemy is, and you can determine how much they should move in the x direction and how much they move in the y direction by taking the sin or cos of the angle and multiplying by speed. Because...</p>

<pre><code> sin(a) = x / speed
</code></pre>

<p>So:</p>

<pre><code> x = speed * sin(a)
</code></pre>

<p>And:</p>

<pre><code>cos(a) = y / speed
</code></pre>

<p>So:</p>

<pre><code>y = speed * cos(a)
</code></pre>

<p>In your example <code>moveForward(90)</code> would yield <code>speed * sin(90)</code> or <code>speed * 1</code> in the x direction and <code>speed * cos(90)</code> or <code>0</code> in the y direction (It should move to the right as you specified).  That should get you started in the basic sense.</p>

<p>Making it general:</p>

<pre><code>moveForward(float angle)
{
    x += speed * sin(angle);
    y += speed * cos(angle);
}
</code></pre>
","36047"
"Optimizing an XNA 2D game","13474","","<p>Does it make sense to implement the logic to skip rendering objects outside the viewport or should I not care about it and let the Framework do it?</p>
","<p>Culling is a performance optimisation. So it doesn't make sense to just do it just for the sake of it. You have to have a reason.</p>

<hr>

<p>The GPU (not the XNA Framework) culls triangles and pixels at blindingly fast speed. Every triangle you submit must be transformed (via your vertex shader). Then it culls the ones that land off screen. Then it fills the remaining triangles, culling pixels that are off-screen. The remaining pixels are then drawn to the back buffer (via your pixel shader).</p>

<p>(When I say ""then"" - it actually does all this in a massively parallel pipeline.)</p>

<p>So it's very rare and unusual that you might have to cull individual triangles. To hit vertex limits you have to be drawing an absurdly large number of triangles. To hit fill-rate, texture-fetch or pixel-shading limits, you generally need to have a high depth-complexity (in which case viewport/frustum culling will not help).</p>

<hr>

<p>So there's usually little or no cost to having geometry off-screen.</p>

<p>The cost - particularly in the context of drawing ""objects"" (usually 3D objects) - is actually <strong>in submitting those objects to the GPU in the first place</strong>. Submit too many objects and you hit your batch limit (you get a few thousand<a href=""https://gamedev.stackexchange.com/questions/37789/information-about-rendering-batches-the-graphical-card-performance-etc-xna#comment119911_37794"">*</a> batches per frame).</p>

<p>I recommend reading <a href=""https://gamedev.stackexchange.com/questions/8521/the-practical-cost-of-swapping-effects/8533#8533"">this answer</a> and this linked <a href=""http://ce.u-sys.org/Veranstaltungen/Interaktive%20Computergraphik%20(Stamminger)/papers/BatchBatchBatch.pdf"" rel=""nofollow noreferrer"">slide deck</a> for an in depth description of batches.</p>

<p>Because of this, if you implement frustum culling, you can reduce the number of batches you submit to the GPU. If you're batch limited - this can get you under the limit.</p>

<hr>

<p>Now - your question is about 2D XNA - so presumably you are using <code>SpriteBatch</code>. <strong>This is a bit different.</strong></p>

<p>It is no mistake that it is called ""Sprite <em>Batch</em>"". What it is doing is taking the sprites you draw and doing the best it can to submit those sprites to the GPU in <em>as few batches as possible</em> by batching them together.</p>

<p>But SpriteBatch will be forced to start a new batch if:</p>

<ul>
<li>You draw more sprites than it can fit into a single batch (2048 sprites in XNA 4)</li>
<li>You change texture (this is why there is a sort-by-texture option)</li>
</ul>

<p>So culling is a suitable optimisation if you are running into the first one. If you are sending such a huge number of sprites that you end up with too many batches (you're probably using up bandwidth as well - but I'm pretty sure you'll hit the batch limit first). This will generally only happen if you have a truly enormous world - so you can generally get away with very simplistic, fast-but-inaccurate culling in this case.</p>

<p>Now - If you are drawing with enough texture-swaps to take you over the batch limit, <em>and</em> lots of them are actually off-screen <strong><em>and</em></strong> culling them would get you under the batch limit. Then yes - culling is an optimisation that will work.</p>

<p><strong>However</strong> - a better optimisation to pursue in this case is to use <strong>texture atlases</strong> (aka: sprite sheets). This allows you to reduce the number of texture-swaps and therefore batches - <em>regardless</em> of what is on screen or off. (This is the main reason you can specify a source rectangle for your sprites.)</p>

<hr>

<p>(As always: this is advice on performance optimisation. So you should measure and understand your game's own performance, and what limits you are hitting, before spending effort on adding optimisations.)</p>
","9289"
"How can I make this style of 2D ""glowing"" graphics?","13450","","<p>I'm comfortable with the basics of building a 2d sprite based game in XNA, where all my objects are simply .png images that I move around.</p>

<p>What things do I need to learn next to be able to develop a 2d game that utilizes an art style similar to Super Laser Racer for example.</p>

<p><img src=""https://i.stack.imgur.com/UvH5q.jpg"" alt=""enter image description here""></p>

<p>Other examples of this style would include Frozen Synapse, Geometry Wars, etc.</p>

<p>I would describe this style ""2D abstract glowing geometry"" or something like that.</p>

<p>I can see that a lot of the effects in these types of games are achieved via particle systems and also that maybe some things are still just sprites that were maybe drawn in a graphics editor to look all ""glowing"" etc.</p>

<p>But then the rest is possibly done by making draw calls to DirectX and implementing custom shaders, etc? </p>

<p>Is that right? I'm not really sure of what to learn next to be able to go in this direction or what questions to ask.</p>
","<p>The simplest way to achieve the effect is to draw a bunch of particles in Additive mode, so when they are superimposed their color values are added up, becoming brighter.</p>

<p>Some samples:</p>

<p><a href=""http://www.youtube.com/watch?v=_sx0KDO-ZbA"">http://www.youtube.com/watch?v=_sx0KDO-ZbA</a></p>

<p><a href=""http://www.youtube.com/watch?v=-OZOdQHLiiI"">http://www.youtube.com/watch?v=-OZOdQHLiiI</a></p>
","18597"
"Orienting a model to face a target","13445","","<p>I have two objects (target and player), both have Position (Vector3) and Rotation (Quaternion).  I want the target to rotate and be facing right at the player.  The target, when it shoots something should shoot right at the player.  </p>

<p>I've seen plenty of examples of slerping to the player, but I don't want incremental rotation, well, I suppose that would be ok as long as I can make the slerp be 100%, and as long as it actually worked.</p>

<p>FYI - Im able to use the position and rotation to do plenty of other things and it all works great except this last piece I cant figure out.</p>

<p>Code samples run in the Target's class, Position = the targets position, Avatar = the player.</p>

<p><strong>EDIT</strong></p>

<p>Im now using Maik's c# code he has provided and it works great!</p>
","<p>There are more than one ways to do it. You can calculate the absolute orientation or the rotation relative to your avatar, that means your new orientation = avatarOrientation * q. Here is the latter one:</p>

<ol>
<li><p>Calculate the rotation axis by taking the cross product of your avatar's unit forward vector and the unit vector from avatar to target, the new forward vector:</p>

<pre><code>vector newForwardUnit = vector::normalize(target - avatarPosition);
vector rotAxis = vector::cross(avatarForwardUnit, newForwardUnit);
</code></pre></li>
<li><p>Calculate the rotation angle using the dot-product</p>

<pre><code>float rotAngle = acos(vector::dot(avatarForwardUnit, newForwardUnit));
</code></pre></li>
<li><p>Create the quaternion using rotAxis and rotAngle and multiply it with avatar's current orientation</p>

<pre><code>quaternion q(rotAxis, rotAngle);
quaternion newRot = avatarRot * q;
</code></pre></li>
</ol>

<p>If you need help finding the avatar's current forward vector, the input for 1. just shoot :)</p>

<p><strong>EDIT:</strong> Calculating the absolute orientation is actually a bit easier, use the forward vector of the identity-matrix instead of avatars forward vector as input for 1) and 2). 
And don't multiply it in 3), instead use it directly as the new orientation: <code>newRot = q</code></p>

<hr>

<p><strong>Important to note:</strong> The solution has 2 anomalies caused by nature of the cross-product:</p>

<ol>
<li><p>If the forward vectors are equal. Solution here is simply return the identity quaternion</p></li>
<li><p>If the vectors point exactly in the opposite direction. The solution here is to create the quaternion by using avatars up axis as rotation axis and the angle 180.0 degrees.</p></li>
</ol>

<p>Here is the implementation in C++ that takes care of those edge cases. Converting it to C# should be easy.</p>

<pre><code>// returns a quaternion that rotates vector a to vector b
quaternion get_rotation(const vector &amp;a, const vector &amp;b, const vector &amp;up)
{   
    ASSERT_VECTOR_NORMALIZED(a);
    ASSERT_VECTOR_NORMALIZED(b);

    float dot = vector::dot(a, b);    
    // test for dot -1
    if(nearly_equal_eps_f(dot, -1.0f, 0.000001f))
    {
        // vector a and b point exactly in the opposite direction, 
        // so it is a 180 degrees turn around the up-axis
        return quaternion(up, gdeg2rad(180.0f));
    }
    // test for dot 1
    else if(nearly_equal_eps_f(dot, 1.0f, 0.000001f))
    {
        // vector a and b point exactly in the same direction
        // so we return the identity quaternion
        return quaternion(0.0f, 0.0f, 0.0f, 1.0f);
    }

    float rotAngle = acos(dot);
    vector rotAxis = vector::cross(a, b);
    rotAxis = vector::normalize(rotAxis);
    return quaternion(rotAxis, rotAngle);
}
</code></pre>

<hr>

<p><strong>EDIT:</strong> Corrected version of Marc's XNA code</p>

<pre><code>// the new forward vector, so the avatar faces the target
Vector3 newForward = Vector3.Normalize(Position - GameState.Avatar.Position);
// calc the rotation so the avatar faces the target
Rotation = Helpers.GetRotation(Vector3.Forward, newForward, Vector3.Up);
Cannon.Shoot(Position, Rotation, this);


public static Quaternion GetRotation(Vector3 source, Vector3 dest, Vector3 up)
{
    float dot = Vector3.Dot(source, dest);

    if (Math.Abs(dot - (-1.0f)) &lt; 0.000001f)
    {
        // vector a and b point exactly in the opposite direction, 
        // so it is a 180 degrees turn around the up-axis
        return new Quaternion(up, MathHelper.ToRadians(180.0f));
    }
    if (Math.Abs(dot - (1.0f)) &lt; 0.000001f)
    {
        // vector a and b point exactly in the same direction
        // so we return the identity quaternion
        return Quaternion.Identity;
    }

    float rotAngle = (float)Math.Acos(dot);
    Vector3 rotAxis = Vector3.Cross(source, dest);
    rotAxis = Vector3.Normalize(rotAxis);
    return Quaternion.CreateFromAxisAngle(rotAxis, rotAngle);
}
</code></pre>
","15078"
"Create fog (smoke) on Unity3D?","13442","","<p>I'm creating a game where you are inside a boiler room, the problem is I want to create the fog (smoke) to make this more realistic.</p>
","<p>There's particle effects, global fog and custom shader effects such as volumetric fog. A few helpful links are below:</p>

<ul>
<li><a href=""http://docs.unity3d.com/Documentation/Components/script-GlobalFog.html"" rel=""nofollow"">http://docs.unity3d.com/Documentation/Components/script-GlobalFog.html</a></li>
<li><a href=""http://www.gamedev.net/blog/633/entry-2254758-volumetric-objects-in-unity/"" rel=""nofollow"">http://www.gamedev.net/blog/633/entry-2254758-volumetric-objects-in-unity/</a></li>
<li><a href=""http://docs.unity3d.com/Documentation/Components/SL-Fog.html"" rel=""nofollow"">http://docs.unity3d.com/Documentation/Components/SL-Fog.html</a></li>
<li><a href=""http://forum.unity3d.com/threads/17034-fog"" rel=""nofollow"">http://forum.unity3d.com/threads/17034-fog</a></li>
</ul>

<p>Check the Unity Asset Store for alternate fog solutions.</p>
","63167"
"Do I need the 'w' component in my Vector class?","13430","","<p>Assume you're writing matrix code that handles rotation, translation etc for 3d space.</p>

<p>Now the transformation matrices have to be 4x4 to fit the translation component in.</p>

<p>However, you don't actually <em>need</em> to store a <code>w</code> component in the vector do you?</p>

<p>Even in perspective division, you can simply compute and store <code>w</code> outside of the vector, and perspective divide before returning from the method.</p>

<p>For example:</p>

<pre><code>// post multiply vec2=matrix*vector
Vector operator*( const Matrix &amp; a, const Vector&amp; v )
{
  Vector r ;
  // do matrix mult
  r.x = a._11*v.x + a._12*v.y ...

  real w = a._41*v.x + a._42*v.y ...

  // perspective divide
  r /= w ;

  return r ;
}
</code></pre>

<p>Is there a point in storing <code>w</code> in the Vector class?</p>
","<p><strong>EDIT Disclaimer</strong>: For convenience in this answer vectors with w==0 are called vectors and with w==1 are called points. Although as FxIII pointed out, that is not a mathematically correct terminology. However, since the point of the answer is not the terminology, but the need to distinguish both types of vectors, I'll stick to it. For practical reason this convention is widely used in game-development.</p>

<hr>

<p>It is not possible to distinguish between vectors and points without a 'w' component. It is 1 for points and 0 for vectors.</p>

<p>If vectors are multiplied with a 4x4 affine transformation-matrix that has a translation in its last row/column, the vector would also be translated, which is wrong, only points must be translated. The zero in the 'w' component of a vector takes care of that. </p>

<p>Highlighting this part of the matrix-vector multiplication makes it more clear:</p>

<pre><code>    r.x = ... + a._14 * v.w; 
    r.y = ... + a._24 * v.w; 
    r.z = ... + a._34 * v.w; 
    r.w = ... + a._44 * v.w;

a._14, a._24 and a._34 is the translational part of the affine matrix.
Without a 'w' component one has to set it implicitly to 0 (vector) or to 1 (point) 
</code></pre>

<p>I.e. it would be wrong to translate a vector, for instance a rotation axis, the result is simply wrong, By having it's 4th component zero you can still use the same matrix that transforms the points to transform the rotation axis and the result will be valid and its length is preserved as long as there is no scale in the matrix. That is the behavior you want for vectors. Without the 4th component you would have to create 2 matrices (or 2 different multiplication functions with an implicit 4th parameter. and make 2 different function calls for points and vectors.</p>

<p>In order to use the vector registers of modern CPUs (SSE, Altivec, SPUs) you have to pass 4x 32 bit floats anyway (its a 128 bit register), plus you have to take care of the alignment, usually 16 bytes. So you don't have the chance to safe the space for the 4th component anyway.</p>

<hr>

<p><strong>EDIT:</strong>
The answer to the question is basically</p>

<ol>
<li><strong>Either store the w-component: 1 for positions and 0 for vectors</strong></li>
<li><strong>Or call different matrix-vector multiplication functions and implicitly pass the 'w' component by choosing one of either functions</strong></li>
</ol>

<p>One must pick one of them, it is not possible to store only {x, y, z} and still use only one matrix-vector multiplication function.
XNA for example uses the latter approach by having 2 Transform functions in its <a href=""http://msdn.microsoft.com/en-us/library/bb199673%28v=XNAGameStudio.20%29.aspx"">Vector3</a> class, called <code>Transform</code> and <code>TransformNormal</code></p>

<p>Here is a code example that shows both approaches and demonstrates the need to distinguish both kind of vectors in 1 of the 2 possible ways. We will move a game-entity with a position and a look-direction in the world by transforming it with a matrix. If we don't use the 'w' component, we can't use the same matrix-vector multiplication anymore, as this example demonstrates. If we do it anyway, we will get a wrong answer for the transformed <code>look_dir</code> vector:</p>

<pre><code>#include &lt;cstdio&gt;
#include &lt;cmath&gt;

struct vector3
{
    vector3() {}
    vector3(float _x, float _y, float _z) { x = _x; y = _y; z = _z; }
    float x, y, z;    
};

struct vector4
{
    vector4() {}
    vector4(float _x, float _y, float _z, float _w) { x = _x; y = _y; z = _z; w = _w; }
    float x, y, z, w;
};

struct matrix
{
    // convenience column accessors
    vector4&amp;        operator[](int col)         { return cols[col]; }
    const vector4&amp;  operator[](int col) const   { return cols[col]; }
    vector4 cols[4];
};

// since we transform a vector that stores the 'w' component, 
// we just need this one matrix-vector multiplication
vector4 operator*( const matrix &amp;m, const vector4 &amp;v )
{
    vector4 ret;
    ret.x = v.x * m[0].x + v.y * m[1].x + v.z * m[2].x + v.w * m[3].x;
    ret.y = v.x * m[0].y + v.y * m[1].y + v.z * m[2].y + v.w * m[3].y;
    ret.z = v.x * m[0].z + v.y * m[1].z + v.z * m[2].z + v.w * m[3].z;
    ret.w = v.x * m[0].w + v.y * m[1].w + v.z * m[2].w + v.w * m[3].w;
    return ret;
}

// if we don't store 'w' in the vector we need 2 different transform functions
// this to transform points (w==1), i.e. positions
vector3 TransformV3( const matrix &amp;m, const vector3 &amp;v )
{
    vector3 ret;
    ret.x = v.x * m[0].x + v.y * m[1].x + v.z * m[2].x + 1.0f * m[3].x;
    ret.y = v.x * m[0].y + v.y * m[1].y + v.z * m[2].y + 1.0f * m[3].y;
    ret.z = v.x * m[0].z + v.y * m[1].z + v.z * m[2].z + 1.0f * m[3].z;
    return ret;
}

// and this one is to transform vectors (w==0), like a direction-vector
vector3 TransformNormalV3( const matrix &amp;m, const vector3 &amp;v )
{
    vector3 ret;
    ret.x = v.x * m[0].x + v.y * m[1].x + v.z * m[2].x + 0.0f * m[3].x;
    ret.y = v.x * m[0].y + v.y * m[1].y + v.z * m[2].y + 0.0f * m[3].y;
    ret.z = v.x * m[0].z + v.y * m[1].z + v.z * m[2].z + 0.0f * m[3].z;
    return ret;
}

// some helpers to output the results
void PrintV4(const char *msg, const vector4 &amp;p )  { printf(""%-15s: %10.6f %10.6f %10.6f %10.6f\n"",  msg, p.x, p.y, p.z, p.w ); }
void PrintV3(const char *msg, const vector3 &amp;p )  { printf(""%-15s: %10.6f %10.6f %10.6f\n"",         msg, p.x, p.y, p.z); }

#define STORE_W     1

int main()
{
    // suppose we have a ""position"" of an entity and its 
    // look direction ""look_dir"" which is a unit vector

    // we will move this entity in the world

    // the entity will be moved in the world by a translation 
    // in x+5 and a rotation of 90 degrees around the y-axis 
    // let's create that matrix first

    // the rotation angle, 90 degrees in radians
    float a = 1.570796326794896619f;
    matrix moveEntity;
    moveEntity[0] = vector4( cos(a), 0.0f, sin(a), 0.0f);
    moveEntity[1] = vector4(   0.0f, 1.0f,   0.0f, 0.0f);
    moveEntity[2] = vector4(-sin(a), 0.0f, cos(a), 0.0f);
    moveEntity[3] = vector4(   5.0f, 0.0f,   0.0f, 1.0f);

#if STORE_W

    vector4 position(0.0f, 0.0f, 0.0f, 1.0f);
    // entity is looking towards the positive x-axis
    vector4 look_dir(1.0f, 0.0f, 0.0f, 0.0f);

    // move the entity using the matrix
    // we can use the same function for the matrix-vector multiplication to transform 
    // the position and the unit vector since we store 'w' in the vector
    position = moveEntity * position;
    look_dir = moveEntity * look_dir;

    PrintV4(""position"", position);
    PrintV4(""look_dir"", look_dir);

#else

    vector3 position(0.0f, 0.0f, 0.0f);
    // entity is looking towards the positive x-axis
    vector3 look_dir(1.0f, 0.0f, 0.0f);

    // move the entity using the matrix
    // we have to call 2 different transform functions one to transform the position 
    // and the other one to transform the unit-vector since we don't 
    // store 'w' in the vector
    position = TransformV3(moveEntity, position);
    look_dir = TransformNormalV3(moveEntity, look_dir);

    PrintV3(""position"", position);
    PrintV3(""look_dir"", look_dir);

#endif

    return 0;
}
</code></pre>

<p>Initial Entity state:</p>

<pre><code>position       :   0.000000   0.000000   0.000000   1.000000
look_dir       :   1.000000   0.000000   0.000000   0.000000
</code></pre>

<p>Now a transformation with a translation of x+5 and a rotation of 90 degrees around the y-axis will be applied to this entity.
The correct answer after the tranformation is:</p>

<pre><code>position       :   5.000000   0.000000   0.000000   1.000000
look_dir       :   0.000000   0.000000   1.000000   0.000000
</code></pre>

<p>We will only get the correct answer if we distinguish vectors with w==0 and positions with w==1 in one of the above presented ways.</p>
","14144"
"What is a good book to start programming a 2D C++ game?","13418","","<p>I have a degree in Computer Science and while I was in college, I created a simple 2D game in Game Maker.  I would like to recreate this game in C++ as a start to learning how to create games in C++.  What would be a good book to start out on programming games in C++ for someone who has a bit of C++ experience (My CS Major classes were taught using Java and I had a class in C++ to learn syntax) and knowing the concepts behind objects, methods, inheritance, etc?</p>

<p>This would be a hobby of mine while I build up experience until I one day could work in the Vide Game Industry.</p>
","<p>Seeing as you were using Game maker, I'm assuming you're on Windows, so jump in at the deep end with the direct-x SDK. The samples provide source code, and also give you a taste of the power available to you. Just because you want to do a 2D game doesn't mean you should stick with a 2D library, at some point you'll probably want to do something the library doesn't implement in itself (shaders or rotations or something random that you just NEED for your project).</p>

<p>SDL -and probably SFML and Cinder- provides a high level <em>""got the basics out of the way""</em> approach to being an engine, so you would have all the power of doing it from scratch (so you could have pixel shaders in SDL), but you'd not learn how things got done. You'd then be doing real C++ inside a helper framework, which will help get stuff done, but won't be a great help in teaching you how to develop games if you're ever going to be working at a game dev company.</p>

<p>SDL, SFML, and even Cinder are all clever ways of avoiding learning about the difficult stuff in C++. They normally wrap OpenGL, which is useful to learn if you want to code graphics for non-windows machines, but there's tonnes of resources for getting work done in Direct-X too (probably more as the Windows virus has spread to every corner of the world). </p>

<p>If you don't want to learn the gritty stuff, then fine, but otherwise, don't be afraid to start from a raw Win32 app.</p>

<p>I'd suggest, for comfort, you start out with all the different helper packages you can find, but head towards writing your own rendering engine. Writing an engine is good fun and can provide you with a resource to look back on in your future projects. Nothing creates good code like the wisdom from doing it wrong in the past.</p>
","3648"
"Variable height jumping in side scrollers","13401","","<p>How can I have the player jump higher if the jump key is held down longer? I am currently just reducing gravity as long as the key is held and the player is jumping, but this looks odd.</p>
","<p>First you need to decide what you want the jump to look like.</p>

<p>In real life, the jump height is decided at the moment that you leave the ground. You can't keep jumping higher while you're already in mid-air.</p>

<p>So if you can control your jump height while you're already in the air, you're going to get some sort of ""jet-pack""-like effect.</p>

<p>I seem to remember a sidescroller that had two different jump heights, I think it was one of the super mario games. The higher jump occured when you held the jump button, and the jump was then actually a two part jump, starting with the initial regular jump, followed by a second impulse that took you higher.</p>

<p>So, what do you want your jump to look like? What sort of control do you want the player to have over the jump?</p>

<p>What I would start with is this:</p>

<p>Leave gravity alone (i.e. never change it). When a player presses the jump button, apply the jump force as long as the player is pressing the jump button (up to some time limit). Then when the player releases the jump button, he cannot apply any jump force again (i.e. he can't initiate a jump again) until he touches the ground first, at which point jumps are re-enabled. </p>
","13279"
"How to detect collision in Unity3D without rigid bodies?","13387","","<p>The target platform of my game is mobile devices therefore I try to develop it performance oriented. It will be a strategy game so I don't really need physics in it, consequently I did not add RigidBody to my object to avoid unnecessary computations. 
However according to the <a href=""http://docs.unity3d.com/Documentation/Components/class-BoxCollider.html"" rel=""nofollow"">Box Collider</a> reference page, the collison event cannot be triggered, unless one of the objects is a RigidBody. Is there a simple way to check collision between objects other than using RigidBodies?
Or can it be that I'm overreacting this performance thing and the physics engine won't slow my game down?</p>
","<p>What you're doing sounds a lot like premature optimization to me. Did you try using the physics-engine and did it actually turn out to cause performance issues?</p>

<p>If you don't need the physics-simulation and just care for the collisions, why not use sensors (or ""triggers"", as they are called in Unity). For stationary objects, use a collider with the <code>Is Trigger</code> checkbox ticked. For moving objects do the same, but also add a rigidbody and set it to be kinematic.</p>

<p>That way you'll only get collisions out of the engine and no other simulation is necessary (use the <code>OnTrigger...</code> callbacks instead of the <code>OnCollision...</code> ones).</p>

<p>If you only need to detect collisions in 2D and the physics engine really turns out to cause performance issues (I highly doubt that, but I have no clue how your game looks like), then you could probably get away by representing your entities as circles and just do a very fast circle vs. circle test?</p>
","34979"
"Is it legal to sell or monetize games created with the Unity 3D free edition?","13329","","<p>Is it okay to use Unity 3D programming and gaming software to create mobile game apps for Android and iOS? I am using a free version of Unity 3D and planning it to sell my current game app I've created by publishing it to Google Play. I also use this method for earning money by setting as a free app with ads on it. </p>

<p>I saw some developers relied on using free version of Unity 3D to create games and published it via App Store or Google Play. If it does, should I have to pay or share contribution to the Unity development team for earnings since I use the free version in order to rely for producing several game apps for business?</p>
","<p>From the <a href=""http://unity3d.com/unity/faq"">Unity FAQ</a>:</p>

<blockquote>
  <h2>Can we sell games and make money with the free version of Unity?</h2>
  
  <p>Yes you can create and sell a game with the free version of Unity,
  without paying royalties or any revenue share. However, the free
  version of Unity may not be licensed by a commercial entity with
  annual gross revenues (based on fiscal year) in excess of US$100,000,
  or by an educational, non-profit or government entity with an annual
  budget of over US$100,000.</p>
  
  <p>Please also be aware that the feature set of the free version is not
  intended for the production of professional games and interactive
  content. Lastly, games made with our Pro trial licenses may not be
  distributed nor used for commercial purposes.</p>
</blockquote>
","93136"
"Given a RGB color x, how to find the most contrasting color y?","13304","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://gamedev.stackexchange.com/questions/5997/making-a-symbol-appear-on-any-colour"">Making a symbol appear on any colour</a>  </p>
</blockquote>



<p>I have to mark a certain item in a way that will make it stick-out in the background. I need it to be surrounded with the color that contrasts the background as much as possible so it will pop out and easily noticeable by the player.</p>

<p>Lets say I know the background is color 'x', how do I find 'y' such that it will be very contrasting to 'x' and easy to notice in a background where 'x' is a dominant color?</p>

<p>I first thought about inverting color 'x' and then I noticed that when 'x' is a medium shade of gray, if I invert 'x' to get 'y', then 'y' is also a medium shade of gray which does not work.</p>
","<p>A quick and easy way - though not 100% precise one - is to consider just the five extreme points white, black, red, green and blue.</p>

<p>First, let's transform RGB into linear space. Officially this is usually done by this formula (assuming the source data is in sRGB, which is the default for most graphic card operations on 8-bit data and nearly every image you see displayed on the web):</p>

<p><img src=""https://i.stack.imgur.com/D6QIr.png"" alt=""enter image description here""></p>

<p>... where <i>a</i> = 0.055 for <i>C</i> = {R, G, B}</p>

<p>Or, if you just want a quick approximation, use <i>C</i><sub>linear</sub> = <i>C</i><sub>srgb</sub><sup>2.2</sup>.</p>

<h2>Black or White?</h2>

<p>You can then calculate two helpful values, luminance <i>Y</i> and saturation <i>S</i>. Useful formulas (for our linear-space RGB values) are:</p>

<p><i>Y</i> = 0.2126 <i>R</i> + 0.7152 <i>G</i> + 0.0722 <i>B</i></p>

<p><i>S</i> = (max(<i>R</i>, <i>G</i>, <i>B</i>) - min(<i>R</i>, <i>G</i>, <i>B</i>)) / max(<i>R</i>, <i>G</i>, <i>B</i>)</p>

<p>The second one is the calculation from the HSV colour space.</p>

<p>If the saturation is low enough (pick any value you like; something between 0.3 and 0.5 would work fine), check the luminance; if that's > 0.5, your contrasting colour is <strong>black</strong>, else if it's &lt; 0.5  the colour is <strong>white</strong>. For exactly <i>Y</i> = 0.5, both work.</p>

<h2>Red, Green or Blue?</h2>

<p>For colours with high saturation, you can calculate a hue <i>H</i> and decide according to it. Since I'm lazy, I'll just copy the calculation from Wikipedia (hue is named H<sub>2</sub>):</p>

<p><img src=""https://i.stack.imgur.com/6caQf.png"" alt=""enter image description here""></p>

<p><img src=""https://i.stack.imgur.com/Aowg6.png"" alt=""enter image description here""></p>

<p>If your hue is between 60° and 180°, your colour is <strong>green</strong>, if it's between 180° and 300°, it's <strong>blue</strong>, else it's <strong>red</strong>. Extend it to yellow, turquoise and magenta for more variation, or just use the opposite of the just-calculated hue at maximum saturation and lightness.</p>
","38542"
"Why don't game developers release their source code?","13298","","<p>I was wondering why don't developers of AAA games release their source codes after their game has sold out and support is long gone?</p>

<p>Of course there is this <a href=""http://en.wikipedia.org/wiki/List_of_commercial_video_games_with_available_source_code"">list</a>, where you can find a lot of AAA games with available source code. </p>

<p>I just don't seem to understand why don't other companies do this with their old games? They certainly don't support it any more, and sales are negligible. I am not even sure, if releasing the source would negatively impact a games sells.  </p>

<p>I am sure a lot of games, that are doomed by <a href=""http://www.ign.com/articles/2014/04/03/gamespy-multiplayer-shutting-down-hundreds-of-games-at-risk"">gamespy's closure</a>, could be saved by the community, had their source codes been released.</p>
","<p>The short answer is because it's usually a legal minefield, and there's usually little or no return on the investment a company would need to put in to the effort.</p>

<p>The source code and assets of a game are intellectual property. It isn't always true that <em>all</em> of the source code and assets are the property of a <em>single</em> development studio. For example, the studio may have licensed source code to some engine and made modifications to that code. </p>

<p>That means that the studio would need to identify and remove any source code or assets they do not have the license to redistribute or re-release. Similarly, they would need to vet the entire code base for references to trade secrets or other concepts that they are still bound by legal agreements to keep secret or contained. They'd probably want to scrape the source code for potentially offensive comments or references that may reflect poorly on the company.</p>

<p>That's a lot of work for a non-trivial code base, and that's still only presuming the legal ownership of the code is clear. In many cases with these sorts of games, the original IP holder is out of business or otherwise dissolved, and then you have the mess of who owns what of the remnants of the studio. This can be an extremely complex legal mess depending on how the studio went under and what the initial incorporation agreements were.</p>

<p>Given that, in these contexts, the games in question are usually no longer popular, it's unlikely a studio (or the postmortem IP holder) would see any kind of return on the investment necessary to clean up and solve all the legal and other issues with the code. Failure to <em>properly</em> vet all the outstanding intellectual property legalities in a source code release could result in the IP holder of some violated property filing a lawsuit or taking other legal action against the company, as well.</p>

<p>Of course, all that being said, there's another quite common reason that's relatively orthogonal to the legal issues: they just don't <em>want</em> to. Maybe they don't care, maybe they are hoping to re-use some of the code later in a re-vitalization of the original game, et cetera. It's their IP, they can choose how to distribute it. Or whether to distribute it at all.</p>
","73412"
"For voxel rendering, what is more efficient: pre-made VBO or a geometry shader?","13276","","<p>Given a fairly static voxel array, what is more efficient: using the CPU to pre-generate a VBO to render the voxel faces (ignoring more advanced forms of rendering like marching cubes for now) or using a geometry shader on the GPU to generate the faces on the fly?</p>

<p>I'm not that worried about updating changing voxels but of course that is a benefit of the GPU-version since you don't have to rebuild the VBOs. Also, the GS approach feels a bit more modern :)</p>

<p>On the other hand, I haven't looked at the details on how a GS actually works with the rasterization pipeline in modern GPUs. Does it output the vertices into a sort of stream-cache or is the vertices written to the normal GPU memory in between? If it's the latter, then on-the-fly generating could reduce the available bandwidth and processing power from the rest of the GPU tasks I guess and then it would be more beneficial to do it on the CPU..</p>
","<p>I'm thinking of a minecraft type scene, where by voxel you mean a world of blocks that are actually rendered using polygons:</p>

<p>If you use a geometry shader it will be difficult to avoid having exactly three faces (or whatever) per voxel.</p>

<p>If you have lots of adjacent blocks that are of the same texture then you can use tiling of the textures to have much less triangles in your (degenerate) strip in a VBO approach.  I mean, if there is a nice big flat 6x6 area of grass voxels, you can draw the entire top in just 2 triangles rather than 64.</p>

<p>With the GS approach you can't do the trivial culling of faces occluded by adjacent voxels that is very straightforward with a VBO approach either.</p>

<p>I have not tried the GS approach, but I can say that the VBO approach with combining of repeating adjacent tiles works very well.  I found messing with element indices to be much slower than just repeating the vertices.  If you split your world into nice small cubes you can typically use just one byte per component per vertice and even pack the texture info and normals (a face on an axis-aligned cube has only 3 possible normals) etc into a forth byte to make 4 bytes per vertex which is nice and fast.</p>

<p>I have used separate VBOs for each of the 6 faces - you only ever need to draw at most 3 of them obviously.  This fits nicely with the different texturing usually used on the top-parts of minecraft-style voxels.  Because for each set the normal and such is then uniform.</p>

<p>With use of vertically-tiled pixmaps in an atlas with <code>GL_REPEAT</code> on the horizontal axis and having 90-deg rotated versions of the pixmaps in the same atlas I found I can draw massive amounts of apparently different blocks using the same VBO in the same call.  In the 6x6 grass area example, I'd have split that into 12 triangles as I only have repeat on one dimension in my atlas.</p>

<p>I've mostly been getting this to work on the very low end of integrated graphics chips and mobile, where GS is just something I can dream about one day playing with.</p>
","17225"
"Unity on Facebook?","13221","","<p>Hey, I know Flash works using Facebook, and I think I've seen some Java stuff on there too, but does anyone know if the Unity Player can be used in Facebook?</p>
","<p>The Unity Player can be used on facebook. </p>

<p>One relevant thread on integration: <a href=""http://forum.unity3d.com/threads/7812-Unity3D-meet-Facebook"" rel=""nofollow"">http://forum.unity3d.com/threads/7812-Unity3D-meet-Facebook</a>!</p>

<p>And one very popular game: <a href=""https://www.facebook.com/uberstrike"" rel=""nofollow"">https://www.facebook.com/uberstrike</a></p>

<p>Here's a thread on Unity Answers that also has some more details: <a href=""http://answers.unity3d.com/questions/82/how-can-i-make-my-unity-application-work-inside-facebook"" rel=""nofollow"">http://answers.unity3d.com/questions/82/how-can-i-make-my-unity-application-work-inside-facebook</a></p>
","5661"
"Which opcodes are faster at the CPU level?","13189","","<p>In every programming language there are sets of opcodes that are recommended over others. I've tried to list them here, in order of speed.</p>

<ol>
<li>Bitwise</li>
<li>Integer Addition / Subtraction</li>
<li>Integer Multiplication / Division</li>
<li>Comparison</li>
<li>Control flow</li>
<li>Float Addition / Subtraction</li>
<li>Float Multiplication / Division</li>
</ol>

<p>Where you need high-performance code, C++ can be hand optimized in assembly, to use SIMD instructions or more efficient control flow, data types, etc. So I'm trying to understand if the data type (int32 / float32 / float64) or the operation used (<code>*</code>, <code>+</code>, <code>&amp;</code>) affects performance at the CPU level.</p>

<ol>
<li>Is a single multiply slower on the CPU than an addition?</li>
<li>In MCU theory you learn that speed of opcodes is determined by the number of CPU cycles it takes to execute. So does it mean that multiply takes 4 cycles and add takes 2? </li>
<li>Exactly what are the speed characteristics of the basic math and control flow opcodes? </li>
<li>If two opcodes take the same number of cycles to execute, then both can be used interchangeably without any performance gain / loss?</li>
<li>Any other technical details you can share regarding x86 CPU performance is appreciated</li>
</ol>
","<p><a href=""http://agner.org/optimize/"" rel=""nofollow noreferrer"">Agner Fog's optimization guides</a> are excellent.  He has guides, tables of instruction timings, and docs on the microarchitecture of all recent x86 CPU designs (going back as far as Intel Pentium).  See also some other resources linked from <a href=""https://stackoverflow.com/tags/x86/info"">https://stackoverflow.com/tags/x86/info</a></p>

<p>Just for fun, I'll answer some of the questions (numbers from recent Intel CPUs).  Choice of ops is not the major factor in optimizing code (unless you can avoid division.)</p>

<blockquote>
  <p>Is a single multiply slower on the CPU than an addition?</p>
</blockquote>

<p>Yes (unless it's by a power of 2).  (3-4x the latency, with only one per clock throughput on Intel.)  Don't go far out of your way to avoid it, though, since it's as fast as 2 or 3 adds.</p>

<blockquote>
  <p>Exactly what are the speed characteristics of the basic math and control flow opcodes?</p>
</blockquote>

<p>See Agner Fog's instruction tables and microarchitecture guide if you want to know <em>exactly</em> :P.  Be careful with conditional jumps.  Unconditional jumps (like function calls) have some small overhead, but not much.</p>

<blockquote>
  <p>If two opcodes take the same number of cycles to execute, then both can be used interchangeably without any performance gain / loss?</p>
</blockquote>

<p>Nope, they might compete for the same execution port as something else, or they might not.  It depends on what other dependency chains the CPU can be working on in parallel.  (In practice, there's not usually any useful decision to be made.  It occasionally comes up that you could use a vector shift or a vector shuffle, which run on different ports on Intel CPUs.  But shift-by-bytes of the whole register (<code>PSLLDQ</code> etc.) runs in the shuffle unit.)</p>

<blockquote>
  <p>Any other technical details you can share regarding x86 CPU performance is appreciated</p>
</blockquote>

<p>Agner Fog's microarch docs describe the pipelines of Intel and AMD CPUs in enough detail to work out exactly how many cycles a loop should take per iteration, and whether the bottleneck is uop throughput, a dependency chain, or contention for one execution port.  See some of my answers on StackOverflow, like <a href=""https://stackoverflow.com/questions/31555260/fast-vectorized-rsqrt-and-reciprocal-with-sse-avx-depending-on-precision/31559382"">this one</a> or <a href=""https://stackoverflow.com/questions/30364084/avx2-winner-take-all-disparity-search/30702101"">this one</a>.</p>

<p>Also, <a href=""http://www.realworldtech.com/haswell-cpu/"" rel=""nofollow noreferrer"">http://www.realworldtech.com/haswell-cpu/</a>  (and similar for earlier designs) is fun reading if you like CPU design.</p>

<p>Here's your list, sorted for a Haswell CPU, based on my best guestimates.  This isn't really a useful way of thinking about things for anything but tuning an asm loop, though.  Cache / branch-prediction effects usually dominate, so write your code to have good patterns.  Numbers are very hand-wavey, and try to account for high latency, even if throughput is not an issue, or for generating more uops which clog up the pipe for other things to happen in parallel.  Esp. the cache / branch numbers are very made-up.  Latency matters for loop-carried dependencies, throughput matters when each iteration is independent.</p>

<p><strong>TL:DR these numbers are made-up</strong> based on what I'm picturing for a ""typical"" use-case, as far as tradeoffs between latency, execution-port bottlenecks, and front-end throughput (or stalls for things like branch misses).  <strong>Please don't use these numbers for any kind of serious perf analysis</strong>.</p>

<ul>
<li>0.5 to 1  Bitwise / Integer Addition / Subtraction /<br>
shift and rotate (compile-time const count) /<br>
vector versions of all of these (1 to 4 per cycle throughput, 1 cycle latency)</li>
<li>1  vector min, max, compare-equal, compare-greater (to create a mask)</li>
<li>1.5 vector shuffles.  Haswell and newer only have one shuffle port, and it seems to me it's common to need a lot of shuffling if you need any, so I'm weighting it slightly higher to encourage thinking about using fewer shuffles.  They're not free, esp. if you need a pshufb control mask from memory.</li>
<li>1.5  load / store (L1 cache hit.  throughput better than latency)</li>
<li>1.75  Integer Multiplication (3c latency/one per 1c tput on Intel, 4c lat on AMD and only one per 2c tput).  Small constants are even cheaper <a href=""https://stackoverflow.com/questions/40564004/multiplication-with-constant-imul-or-shl-add-combination"">using LEA and/or ADD/SUB/shift</a>.  But of course compile-time constants are <em>always</em> good, and can often optimize into other things. (And multiply in a loop can often be strength-reduced by the compiler to <code>tmp += 7</code> in a loop instead of <code>tmp = i*7</code>)</li>
<li>1.75 some 256b vector shuffle (extra latency on insns that can move data between 128b lanes of an AVX vector).  (Or 3 to 7 on Ryzen where lane crossing shuffles need many more uops)</li>
<li>2 fp add/sub  (and vector versions of the same)  (1 or 2 per cycle throughtput, 3 to 5 cycle latency).  Can be slow if you bottleneck on latency, e.g. summing an array with only 1 <code>sum</code> variable.  (I could weight this and fp mul as low as 1 or as high as 5 depending on use-case).</li>
<li>2 vector fp mul or FMA.  (x*y + z is as cheap as either a mul or an add if you compile with FMA support enabled).</li>
<li>2  inserting/extracting general-purpose registers into vector elements (<code>_mm_insert_epi8</code>, etc.)</li>
<li>2.25  vector int mul (16-bit elements or pmaddubsw doing 8*8 -> 16-bit).  Cheaper on Skylake, with better throughput than scalar mul</li>
<li>2.25  shift / rotate by variable count (2c latency, one per 2c throughput on Intel, faster on AMD or with BMI2)</li>
<li>2.5  Comparison without branching (<code>y = x ? a : b</code>, or <code>y = x &gt;= 0</code>)  (<code>test / setcc</code> or <code>cmov</code>)</li>
<li>3  int-> float conversion</li>
<li>3  perfectly predicted Control flow (predicted branch, call, return).</li>
<li>4  vector int mul (32-bit elements) (2 uops, 10c latency on Haswell)</li>
<li>4  integer division or <code>%</code> by a compile-time constant (non-power of 2).</li>
<li>7  vector horizontal ops (e.g. <code>PHADD</code> adding values within a vector)</li>
<li>11  (vector)FP Division  (10-13c latency, one per 7c throughput or worse).  (Can be cheap if used rarely, but <a href=""https://stackoverflow.com/questions/4125033/floating-point-division-vs-floating-point-multiplication/45899202#45899202"">throughput is 6 to 40x worse than FP mul)</a></li>
<li>13?  Control Flow (poorly-predicted branch, maybe 75% predictable)</li>
<li>13  int division  (<a href=""https://stackoverflow.com/questions/31575833/fastest-method-of-vectorized-integer-division-by-non-constant-divisor/31587758#31587758"">yes really</a>, it's slower than FP division, and can't vectorize).  (note that compilers <a href=""https://stackoverflow.com/questions/26047196/is-there-any-way-to-write-mod-31-without-modulus-division-operators/26047426#26047426"">divide by a constant using mul/shift/add with a magic constant</a>, and div/mod by powers of 2 is very cheap.)</li>
<li>16  (vector)FP sqrt  </li>
<li>25?  load (L3 cache hit).  (cache-miss stores are cheaper than loads.)</li>
<li>50?  FP trig / exp / log.  If you need a lot of exp/log and don't need full accuracy, you can trade accuracy for speed with a shorter polynomial and/or a table.  <a href=""https://stackoverflow.com/questions/45770089/efficient-implementation-of-log2-m256d-in-avx2"">You can also SIMD vectorize.</a></li>
<li>50-80?  <em>always</em>-mispredicted branch, costing 15-20 cycles</li>
<li>200-400? load/store (cache miss)</li>
<li>3000???  read page from file (OS disk cache hit)  (making up numbers here)</li>
<li>20000???  disk read page (OS disk-cache miss, fast SSD) (totally made-up number)</li>
</ul>

<p><strong>I totally made this up based on guesswork</strong>.  If something looks wrong, it's either because I was thinking of a different use-case, or an editing error.</p>

<p>The relative cost of things on AMD CPUs will be similar, except they have faster integer shifters when the shift-count is variable.  AMD Bulldozer-family CPUs are of course slower on most code, for a variety of reasons.  (Ryzen is pretty good at a lot of stuff).</p>

<p>Keep in mind that it's really <strong>impossible to boil things down to a one-dimensional cost</strong>.  Other than cache-misses and branch mispredicts, the bottleneck in a block of code can be latency, total uop throughput (frontend), or throughput of a specific port (execution port).</p>

<p>A ""slow"" operation like FP division <a href=""https://stackoverflow.com/questions/4125033/floating-point-division-vs-floating-point-multiplication/45899202#45899202"">can be very cheap if the surrounding code keeps the CPU busy with other work</a>.  (vector FP div or sqrt are 1 uop each, they just have bad latency and throughput.  They only block the divide unit, not the whole execution port that it's on.  Integer div is several uops.)  So if you only have one FP divide for every ~20 mul and add, and there's other work for the CPU to do (e.g. an independent loop iteration), then the ""cost"" of the FP div could be about the same as an FP mul.  This is probably the best example of something that's low throughput when it's all you're doing, but mixes very well with other code (when latency isn't a factor), because of low total uops.</p>

<p>Note that integer division is not nearly as friendly to surrounding code: On Haswell, it's 9 uops, with one per 8-11c throughput, and 22-29c latency.  (64bit division is <em>much</em> slower, even on Skylake.)  So the latency and throughput numbers are somewhat similar to FP div, but FP div is only one uop.</p>

<p>For examples of analysing a short sequence of insns for throughput, latency, and total uops, see some of my SO answers:</p>

<ul>
<li><strong><a href=""https://stackoverflow.com/questions/45113527/why-does-mulss-take-only-3-cycles-on-haswell-different-from-agners-instruction/45114487#45114487"">The ""performance analysis"" section of this answer</a></strong> summarizes things.  The rest of the answer is about optimizing a loop that does <code>sum += x[i] * y[i]</code> by unrolling with multiple vector accumulators to hide FMA latency.  It's pretty technical and low-level, but shows you the kind of assembly-language output you want to get your compiler to make, and why it matters.</li>
<li><strong><a href=""https://stackoverflow.com/questions/40354978/why-is-this-c-code-faster-than-my-hand-written-assembly-for-testing-the-collat/40355466#40355466"">Why is this C++ code faster than my hand-written assembly for testing the Collatz conjecture?</a></strong>: this popular answer I wrote explains how to hand-hold the compiler into making better asm when possible.  Also some asm optimization details that let you beat the compiler for small functions / loops in that case.  IDK why it has so many more upvotes than any of my other answers.</li>
<li><a href=""https://stackoverflow.com/a/34410357/224132"">What is the efficient way to count set bits at a position or lower?</a>: A perf analysis of a sequence of 6 insns for an interesting problem where some hand-holding in the C source led to gcc making better code.  Some of my other answers are for even shorter sequences of instructions.</li>
<li><a href=""https://stackoverflow.com/questions/32408665/fastest-absolute-value-calculator-using-sse/32422471#32422471"">Fastest absolute value calculator using SSE</a></li>
<li><a href=""https://stackoverflow.com/questions/32084204/problems-with-adc-sbb-and-inc-dec-in-tight-loops-on-some-cpus/32087095#32087095"">Problems with ADC/SBB and INC/DEC in tight loops on some CPUs</a></li>
<li><a href=""https://stackoverflow.com/questions/31555260/fast-vectorized-rsqrt-and-reciprocal-with-sse-avx-depending-on-precision/31559382#31559382"">Fast vectorized rsqrt and reciprocal with SSE/AVX depending on precision</a></li>
<li><a href=""https://stackoverflow.com/questions/31486942/sorting-64-bit-structs-using-avx/31487698#31487698"">Sorting 64-bit structs using AVX?</a></li>
<li><a href=""https://stackoverflow.com/search?q=user%3A224132+throughput+latency+cycles"">https://stackoverflow.com/search?q=user%3A224132+throughput+latency+cycles</a></li>
</ul>

<p>IDK if other people write SO answers including this kind of analysis.  I have a much easier time finding my own, because I know I go into this detail often, and I can remember what I've written.</p>
","104534"
"What is the benefit of triple buffering?","13183","","<p>I read everything written in a <a href=""https://gamedev.stackexchange.com/questions/26722/multiple-buffering-in-opengl-on-windows"">previous question</a>. From what I understand in double buffering the program must wait until the finished drawing is copied or swapped before starting the next drawing. In triple buffering the program has two back buffers and can immediately start drawing in the one that is not involved in such copying.</p>

<p>But with triple buffering if you're in a situation where you can take advantage of the third buffer doesn't that suggest that you are drawing frames faster than the monitor can refresh. So then you don't actually get a higher frame rate. So what is the benefit of triple buffering then?</p>
","<p>Both Double and Triple buffering solve the problem of black redraws on the screen. Triple buffering, however, solves a problem of concurrency when the current draw buffer is being memcpy-ed to the screen, and your game scene can start drawing already.</p>

<p>This article is the best way to explain the benefits of triple buffering ... 
<a href=""http://remis-thoughts.blogspot.in/2012/01/triple-buffering-as-concurrency.html"">http://remis-thoughts.blogspot.in/2012/01/triple-buffering-as-concurrency.html</a></p>
","30378"
"Rotate an object smoothly by 90 degrees on key press in unity3D","13178","","<p>[I saw few similar question on stackexchange but none is solving the purpose.]</p>

<p>I want to rotate a 3D object by 90 degrees on different axis on respective inputs. For example if 'a' is pressed, the object should rotate left by 90 degrees. <code>transform.Rotate(0,90,0);</code> is working but it is not rotating the object smoothly.</p>

<p>I am new to C# and js so cannot manually code but I tried the codes given in this answer at <a href=""https://gamedev.stackexchange.com/questions/61381/rotate-an-object-smoothly-on-the-y-axis-in-unity"">Rotate an object smoothly on the Y axis in Unity</a>. The below code works but it it has two problems - 
code:</p>

<pre><code>void Update () {
SwingOpen();
}

void SwingOpen()
{   
    Quaternion newRotation = Quaternion.AngleAxis(90, Vector3.up);
    transform.rotation= Quaternion.Slerp(transform.rotation, newRotation, .05f);      
}
</code></pre>

<p>Problem 1: The above code rotates object without any keyboard inputs.
I added the condition <code>if (Input.GetKeyDown (KeyCode.RightArrow))</code> but now the object rotates partially on every keyboard input. I want to rotate it by 90 degrees on a single key press.</p>

<p>Problem 2: It will never actually rotate the object by 90 deg. It will always be tending towards 90 deg. I want exact 90 deg rotation to allow multiple 90 deg rotations for 'n' number if inputs.</p>

<p>How can I solve this? Please help. Please let me know if the question isn't clear enough. </p>

<p>[EDIT]</p>

<p>I applied the below script but it is giving me some totally unexpected output</p>

<p>Code:</p>

<pre><code>public float speed = 1;
private int xtimesHit = 0;
private int ytimesHit = 0;
private int ztimesHit = 0;

void Update () {
    if( Input.GetKeyDown( KeyCode.RightArrow ) ){
        ztimesHit--;
    }
    if( Input.GetKeyDown( KeyCode.LeftArrow ) ){
        ztimesHit++;
    }


    if( Input.GetKeyDown( ""a"" ) ){
        ytimesHit++;
    }
    if( Input.GetKeyDown( ""d"" ) ){
        ytimesHit--;
    }


    if( Input.GetKeyDown( ""w"" ) ){
        xtimesHit++;
    }
    if( Input.GetKeyDown( ""s"") ){
        xtimesHit--;
    }

    this.transform.rotation = Quaternion.Lerp(this.transform.rotation, Quaternion.Euler(xtimesHit*90,ytimesHit*90,ztimesHit*90), Time.deltaTime*speed);

}
</code></pre>

<p>On running this script
If I press rightarrow once followed by 's' the object rotates on 'z' axis and 'x' axis  correctly but there after if I press arrowkeys or 'a/s' in both the cases the object rotates on y axis. I dont understand why this is happening. </p>

<p>I want it to rotate w.r.t. the world axis always. </p>
","<p>This is how I would do it</p>

<pre><code>private Quaternion startingRotation;
public float speed = 10;

void Start(){
    //save the starting rotation
    startingRotation = this.transform.rotation;
}

void Update () {
    //return back to the starting rotation
    if( Input.GetKeyUp( KeyCode.RightArrow ) || Input.GetKeyUp( KeyCode.LeftArrow ) ){
        StopAllCoroutines();
        StartCoroutine(Rotate(0));
    }

    //go to 90 degrees with right arrow
    if( Input.GetKeyDown( KeyCode.RightArrow ) ){
        StopAllCoroutines();
        StartCoroutine(Rotate(90));
    }

    //go to -90 degrees with left arrow
    if( Input.GetKeyDown( KeyCode.LeftArrow ) ){
        StopAllCoroutines();
        StartCoroutine(Rotate(-90));
    }

}

IEnumerator Rotate(float rotationAmount){
    Quaternion finalRotation = Quaternion.Euler( 0, rotationAmount, 0 ) * startingRotation;

    while(this.transform.rotation != finalRotation){
        this.transform.rotation = Quaternion.Lerp(this.transform.rotation, finalRotation, Time.deltaTime*speed);
        yield return 0;
    }
}
</code></pre>

<hr>

<p>Edit # 1</p>

<pre><code>public float speed = 1;
private int timesHit = 0;

void Update () {
    if( Input.GetKeyDown( KeyCode.RightArrow ) ){
        timesHit++;
    }
    if( Input.GetKeyDown( KeyCode.LeftArrow ) ){
        timesHit--;
    }

    this.transform.rotation = Quaternion.Lerp(this.transform.rotation, Quaternion.Euler(0,timesHit*90,0), Time.deltaTime*speed);

}
</code></pre>

<hr>

<p>Edit #2</p>

<p>Perhaps like this?</p>

<pre><code>public float speed = 1;
private GameObject endRotation;

void Start(){
    endRotation = new GameObject();
}

void Update () {
    if( Input.GetKeyDown( KeyCode.RightArrow ) ){
        endRotation.transform.Rotate(Vector3.forward, 90, Space.World);
    }
    if( Input.GetKeyDown( KeyCode.LeftArrow ) ){
        endRotation.transform.Rotate(Vector3.forward, -90, Space.World);
    }


    if( Input.GetKeyDown( ""a"" ) ){
        endRotation.transform.Rotate(Vector3.up, 90, Space.World);
    }
    if( Input.GetKeyDown( ""d"" ) ){
        endRotation.transform.Rotate(Vector3.up, -90, Space.World);
    }


    if( Input.GetKeyDown( ""w"" ) ){
        endRotation.transform.Rotate(Vector3.left, 90, Space.World);
    }
    if( Input.GetKeyDown( ""s"") ){
        endRotation.transform.Rotate(Vector3.left, -90, Space.World);
    }

    this.transform.rotation = Quaternion.Lerp(this.transform.rotation, endRotation.transform.rotation, Time.deltaTime*speed);

}
</code></pre>
","101747"
"Create a trailing, ghosting effect of a sprite","13156","","<p>I want to create a trailing, ghosting like effect of a sprite that's moving fast. Something very similar to this image of Sonic (apologies of bad quality, it's the only example I could find of the effect I'm looking to achieve)</p>

<p><img src=""https://i.stack.imgur.com/CCYOb.png"" alt=""Ghost trail""></p>

<p>However, I don't want to do this at the sprite sheet level, to avoid having to essentially double (or possibly quadruple) the amount of sprites in my atlas. It's also very labor intensive.  </p>

<p>So is there any other way to achieve this effect? Possibly by some shader voodoo magic? I am using Unity and 2D Toolkit, if that helps.</p>
","<p>While the particle system solution provided by LVBen does work, it's not the best suited solution when using 2D Toolkit for your sprites. The primary reason being is that it's impossible to sync up the ghost trail material in the particle system to the current sprite animation of the main prefab.</p>

<p>Here's the 2D Toolkit friendly solution I ended up using.</p>

<p>For the prefab in which you want the ghost trail to come from, attach an empty game object to it to act as the root. Under this root, attach any number of tk2dSprite or tk2dSpriteAnimator (depending if you want animated sprites or not) game objects (I added 4) and adjust their color alpha values as appropriate to achieve the ghosting/fading away effect.</p>

<p>In the top parent Update</p>

<pre><code>// AmountToMove is a Vector3 of the amount we will translate this gameobject.
float y = (int)AmountToMove.y == 0 ? 0 : -AmountToMove.y;
float distanceFactor = 0.05f;
for (int i = 0; i &lt; GhostingRoot.childCount; ++i) {
    // Based on the player's current speed and movement along the x and y axes,
    // position the ghost sprites to trail behind.
    Vector3 ghostSpriteLocalPos = Vector3.Lerp(
                                      GhostingRoot.GetChild(i).localPosition,
                                      new Vector3((-CurrentSpeed * distanceFactor * i),
                                                  (y * distanceFactor * i), 0),
                                      10f * Time.deltaTime);
    // GhostingRoot is the root gameobject that's parent to the ghost sprites.
    GhostingRoot.GetChild(i).localPosition = ghostSpriteLocalPos;
    // Sync the animations.
    // _ghostSprites is a List of the tk2dSpriteAnimator ghost sprites.
    _ghostSprites[i].Play(SpriteAnimator.CurrentClip.name);
    _ghostSprites[i].Sprite.FlipX = Sprite.FlipX;
}
</code></pre>

<p>This solution will create the trailing ghosting effect while syncing the animations of the ghost sprites with the main sprite.</p>
","75726"
"How to protect source code when game is developed in HTML5/Javascript","13137","","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://gamedev.stackexchange.com/questions/3695/how-do-you-prevent-your-javascript-html5-web-game-from-being-copied-or-altered"">How do you prevent your JavaScript / HTML5 web game from being copied or altered?</a>  </p>
</blockquote>



<p>If a game client is developed in Javascript, the source code can be found in browser. It's dangerous, because it's easy to hack the game, and patent can't be protected. </p>

<p>Are there any good ways to avoid this, e.g Javascript can be compiled to binary file then browser load and run the compiled javascript?</p>
","<p>The bottom line is there's no bullet-proof way to protect your HTML5/Javascript code.
Obfuscation and minification will act as a deterrent. <a href=""http://code.google.com/closure/compiler/"">Closure Compiler</a> is one such minifier.</p>

<p>If you really want to prevent people from cheating, store the state of the game on the server and turn the web page into a presentation/input layer that communicates with the server.</p>
","14757"
"How do I render a PNG with transparency in LibGDX?","13128","","<p>I'm building a simple tic-tac-toe example with LibGDX. I have simple images: cross, circle and board, all <code>png</code>s created with GIMP with a transparent background.</p>

<p>How can I render them as a <code>Texture</code> with transparency? </p>

<p>I've tried with GL10 enable feature, but it seems not to work.</p>
","<p><a href=""http://libgdx.badlogicgames.com/nightlies/docs/api/com/badlogic/gdx/graphics/g2d/SpriteBatch.html#enableBlending%28%29"" rel=""noreferrer"">SpriteBatch#enableBlending</a></p>

<p>before rendering:</p>

<pre><code>batch.enableBlending();
batch.begin();
//draw stuff
batch.end();
</code></pre>
","67829"
"Complete Math Library for use in OpenGL ES 2.0 Game?","13121","","<p>Are you aware of a <strong>complete</strong> (or almost complete) <strong>cross platform math library</strong> for use in OpenGL ES 2.0 games?</p>

<p>The library should contain: </p>

<ul>
<li>Matrix2x2, Matrix 3x3, Matrix4x4 classes</li>
<li>Quaternions</li>
<li>Vector2, Vector3, Vector4 Classes</li>
<li>Euler Angle Class</li>
<li>Operations amongh the above mentioned classes, conversions, etc..</li>
<li>Standardly used math operations in 3D graphics (Dot Product, Cross Product, SLERP, etc...)</li>
</ul>

<p>Is there such Math API available either <strong>standalone</strong> or as a <strong>part of any package</strong>?</p>

<p><em>Programming Language: Visual C++ but planned to be ported to OS X and Android OS.</em></p>
","<p>Have you considered the <a href=""http://cmldev.net/"">Configurable Math Library</a>?</p>
","8235"
"Should I learn 3DS Max or Maya?","13102","","<p>I have two options to choose from: 3DS Max or Maya. I am not going into the commercial line. </p>

<p>I need to get advice from users on which thing I should choose provided I am really not going in to character animation. I just want building, landscapes, moving objects, et cetera.</p>

<p>I have to start, so I think its better to ask.</p>
","<p>Judging by the fact that you can arbitrarily choose between two $3500 tools to work with, I guess the price doesn't really matter. I don't really think it matters which of the two you use -- I'm sure some UIs/workflows will just click better with some than others.</p>

<p>It seems like you're asking for advice between using a mechanical pencil or a wooden pencil for sketching. I'm sure there are advocates for both who will give you contradictory opinions on why one is better suited than the other for the task. There isn't really a strong reason that I've seen to prefer either of these tools over the other for the task of ""just modeling"". You can probably use any number of other tools: Milkshape, Wings3D, Blender, etc.</p>

<p>Why don't you find tutorials on how to use one tool and follow them -- get a feel for each program. There are trials available from Autodesk for both. In other words, if 10,000 people tell you here ""Use 3DS Max"" but it just doesn't click with you the way that Maya does, why use 3DS Max? Vice versa for any tools listed. Do what works, and master your tool. Any of them are sufficient to do what you want.</p>
","11854"
"How to decompose sprite sheet","13096","","<p>I have a lot of spritesheets that are poorly formatted that I want to decompose, or split out into many small images, one for each sprite.
If I can do that, I can use my custom texture packer tool to build my game assets with.</p>

<p>My development tools are XNA and C# targetting Windows.
How can I decompose the images?</p>
","<p>Try <a href=""http://sourceforge.net/projects/spritedecompose/"">Sprite Decomposer</a> or <a href=""http://spritevortex.codeplex.com/"">Sprite Vortex</a>, I believe both of them have automatic sprite cutting based on alpha.</p>
","35874"
"Why is it bad to hard-code content?","13079","","<p>I know most games store dialogue text in files, but I've also seen a few text-based games actually program the content (map, choices, possible player commands, story text) into the game code.</p>

<p>I can think of a few reasons, but what is the major reason why even text games keep everything in files outside the program?</p>

<p>The implementation details differ little between holding content in something like the popular XML format, parsing it, then rendering maps/displaying text based on the variables created from XML file, and simply forgoing the XML file entirely. They both end up with strings which output to the screen. Isn't the difference just notation?</p>

<p>Some games even hold the graphics (ASCII art?) inside the code. I know this isn't right, and I can guess a few reasons why it is bad, but don't know the major reason why either.</p>

<p>It is very popular to have most of the content outside the program. Even <em>Dwarf Fortress</em> doesn't use actual ASCII characters, but images of ASCII characters loaded into memory.</p>

<p>I primarily ask because it is a bit of a PITA to create, parse, and work with XML files. You know... compared to the lazy alternative of just making every unique dungeon (content) its own class.</p>
","<p>There are several reasons for that. I'm just gonna touch on a few:</p>

<ol>
<li>It makes your source code a mess. If you have a lot of dialog (trees), a huge part of your codebase is just text that has nothing to do with your actual game code.</li>
<li>You'd need to recompile every time you change so much as a single character.</li>
<li>The dialog itself is hard to navigate. I imagine trying to implement a whole dialog tree, let alone several, completely inside your source will result in a nested mess of spaghetti and nested <code>if</code>s, <code>switch</code>es and so on. Which then results in code that is prone to errors, hard to read and harder to debug.</li>
<li>If you want to enable people to mod or expand your game, that's far easier if they don't have to deal with the source code to change something.</li>
<li>The above point is even more important if you work in a team. You don't want your writer to have to mess with the code just to enter a piece of dialog.</li>
<li>Parsing XML or other standard file formats is pretty easy to do if you use existing libraries, so the cost of implementing it that way is very low while giving you lots of advantages and avoiding the problems mentioned above and lots more.</li>
<li>As @MiloPrice pointed out below, it's also far easier to localize the game if your text is in external files. You can add a language by adding a file, your team can take care of translation without having to touch the source (which is especially important if you let people translate who are not supposed to see all of your code - think freelancers, people from the community that don't belong to your team etc).</li>
</ol>
","84224"
"Best (Most Popular?) Image Format For Texturing","13058","","<p>Okay, so I am using C++ with OpenGL, and I am going to create a loader to load in textures for my 3D game. (But the textures are 2D). I want the option of transparency, even if I decide not to use it. I need decent quality, although it doesn't have to be top notch. What do you guys suggest for format (PNG, TGA, etc.). Also, maybe make it something that is easy to create a loader for (I'm not going to use an already created one.). And also, if you have any links/tips to help out with the loader, that would be appreciated.</p>
","<p>I don't understand why you wouldn't want to use an off-the-shelf loader. <a href=""http://www.w3.org/TR/PNG/"">PNG</a>, for example, is a good choice for a format but is complex to write a general purpose loader for (and probably not worth the effort of writing one that only loads the specific subset of PNG formats you care about).</p>

<p>Given that somewhat unusual requirement, <a href=""http://paulbourke.net/dataformats/tga/"">TGA</a> is probably your best bet. TGA 2.0 has an alpha channel and is relatively simple compared to PNG.</p>
","15335"
"Collision Resolution","13032","","<p>I know quite well how to check for collisions, but I don't know how to handle the collision in a good way.</p>

<p>Simplified, if two objects collide I use some calculations to change the velocity direction. If I don't move the two objects they will still overlap and if the velocity is not big enough they will still collide after next update. This can cause objects to get stuck in each other.</p>

<p>But what if I try to move the two objects so they do not overlap. This sounds like a good idea but I have realised that if there is more than two objects this becomes very complicated. What if I move the two objects and one of them collides with other objects so I have to move them too and they may collide with walls etc.</p>

<p>I have a top down 2D game in mind but I don't think that has much to do with it. How are collisions usually handled?</p>

<p><em>This question is asked on behalf of Wooh</em></p>
","<p>Daniel Kodicek covers this topic in great detail in his book, <a href=""http://rads.stackoverflow.com/amzn/click/1435457331"" rel=""noreferrer"">Mathematics &amp; Physics for Programmers</a>.</p>

<p>Kodicek does two things to achieve natural-looking collision resolution:</p>

<ul>
<li>His collision detection function calculates the exact time two objects will collide.</li>
<li>He recalculates new velocities at the time of collision, so objects never overlap.</li>
</ul>

<p>I uploaded a <a href=""http://www.coolcases.com/asteroids/"" rel=""noreferrer"">demo based on Kodicek's collision detection and resolution</a>.</p>

<p><strong>update:</strong> Here's a <a href=""http://www.plasmaphysics.org.uk/print/collision2d.htm"" rel=""noreferrer"">collision detection &amp; resolution algorithm</a> that is very similar to Kodicek's method. With <a href=""http://www.plasmaphysics.org.uk/programs/coll2d_cpp.htm"" rel=""noreferrer"">source code</a>. I still recommend Kodicek's book, as his algorithm is implemented slightly differently and much more thoroughly explained.</p>
","5949"
"What is the difference between a game framework and a game engine?","12978","","<p>What is the difference between a game framework (for example, XNA with C#, SDL for c++) and a game engine?</p>

<p>Do game frameworks use engines? Does a game engine encapsulate sub-engines like physics engines, particle engines etc? Should they be used together, or are they mutually exclusively?</p>

<p>I take it there are separate engines for both 2D and 3D?</p>
","<p>There really aren't strict definitions for ""engine"" or ""framework."" </p>

<p>Generally speaking, an engine is considered to ""do more"" or have more tools and related support than a framework, which is itself is often just a loose collection of related functionality exposed through some unified API.</p>

<p>To that end, things that claim to be engines may use things that claim to be frameworks to achieve functionality, but that does not always need to be the case. Similarly, a thing claiming to be a game engine can claim that it's constituent parts (the physics and rendering, et cetera) are implemented with a physics engine or a physics framework. The kinds of technology referred by both terms can be used interchangeably, or not. </p>

<p>There can be ""engines"" or ""frameworks"" for just about anything -- physics, sound, and yes, even 2D or 3D graphics.</p>

<p>It's really just a terminology issue, and it doesn't generally matter much. From a functionality perspective, a perspective focused on making your game, what should matter is whether or not the technology in question delivers what you need to make your game. Whether it calls itself an engine or a framework won't have any bearing on that.</p>
","31774"
"As an indie game developer, how can I have (quality) music/sound done?","12968","","<p>Besides the story itself, a game needs code, graphics and music/sound effect. I can program and I knew a few graphics designers in the web app era. However, I don't know whether to find music and sound freelancers/professionals/partners.</p>

<p>So how's music/sound typically done? Do you finish a game and hand it to some musicians? Seek help via Facebook? Call the secondary school music teacher? .. Please advise. Thanks!</p>

<p>EDIT:</p>

<p>I'd like to rephrase the question a bit to clarify the objective. Let's start with example. Say, there is designer which have finish a great UI concept design, and ask: ""how can I find programmers to transform this design into an app?""</p>

<p>It won't help him much by telling where github is and how much great codes can be learned from... He needs the judgement of what are good code, in addition to how to use the code, and most importantly, the ability to modify/enhance the code to fit his need.</p>

<p>As a programmer, all I know a game needs some good music. The question is not about where to find music. The question is how to find musician who knows music, the music which fits my game. It's similar to the design is looking for a programmer who can turn Photoshop into .app rather and programming books and code samples.</p>

<p>Simply put, where did you find your game's musician? ;-) </p>

<p>p.s. I found my graphics designer on <a href=""http://deviantart.com"">deviantart.com</a> Where is the deviant <em>music</em>.com? XD </p>
","<p>I don't see how being an indie developer changes the problem set other than probably having a smaller budget.</p>

<p>Your list of options probably fall something like this:</p>

<ul>
<li>Have a sound guy on staff to do all custom stuff</li>
<li>Contract out a sound guy from one of the many sound studios</li>
<li>Get lucky and ""know a guy"" (online or in meatspace) who does music who will do it for free</li>
<li>License existing music (the popular indie game Braid did this with a lot of success): <a href=""https://gamedev.stackexchange.com/questions/1045/where-is-quality-paid-game-music"">Where is quality paid game music?</a></li>
<li>Use free music: <a href=""https://gamedev.stackexchange.com/questions/14/where-can-i-find-free-music-for-my-game"">Where can I find free music for my game?</a></li>
</ul>

<p>There are also threads here about where you can find sounds.  Like this one: <a href=""https://gamedev.stackexchange.com/questions/8/where-can-i-find-free-sounds-for-my-game"">Where can I find free sounds for my game?</a></p>

<p>Honestly the ""know a guy"" is probably the least likely to pan out.  More than likely you'll get better free music that already exists.  It's mostly just going to take time to sort through the gobs of stuff already out there and seeing if it applies to your needs.</p>
","5905"
"What technology should I use for a web-based game?","12909","","<p>What's the best technology for an online game, i.e playable through a web browser? I think the only choices are:</p>

<ul>
<li>Java applets</li>
<li>Flash</li>
<li>Silverlight</li>
</ul>

<p>I'm leaning towards Java applets, simply because they seems to have better programming features than Flash, and graphics for a java applet game may be cheaper than graphics for Flash. I don't know much about Silverlight.</p>
","<p>Just because Java applets aren't popular doesn't mean they aren't powerful or worthy of gaming. In fact I am focused on Java game development at the moment; I like the high-level nature of the language, its cross-platform-ness (as compared to C#), the <a href=""http://jogamp.org/"">JOGL</a> library which provides a very C-like OpenGL experience for the Java platform (or its alternative, <a href=""http://lwjgl.org/"">LWJGL</a>, or an engine like <a href=""http://www.jmonkeyengine.com/"">jMonkeyEngine</a>), and its speed (obviously slower than C++, but considerably faster than scripting languages like Python).</p>

<p>With Java you can deploy your application as an Applet to run in the browser and even provide a <a href=""http://en.wikipedia.org/wiki/Java_Web_Start"">JNLP</a> alternative for those who prefer installing something.</p>

<p>You can take advantage of all the tools that have been created for Java; the wonderful <a href=""http://www.eclipse.org/"">Eclipse IDE</a> (or any of the other IDEs out there), testing tools, continuous integration, the huge community of Java programmers, etc.</p>

<p>The statistic for what percentage of computers Java is installed in varies (and the version varies even more) but I've seen <a href=""http://www.statowl.com/java.php"">pretty high numbers</a> for Java market penetration. And the installation process remains pretty simple, so that if any users don't yet have Java installed, they can be up and ready to run your game in very little time.</p>

<p>I personally feel less hesitant to install the Java plugin than the Unity one. In fact, I am yet to install the Unity game plugin on my computer; I just don't quite trust it. Java is proven; it had a rocky beginning but now, many years later, it is stable and fast and, well, it continues to have some security issues (but so does Flash) but for the most part it's trustworthy. I will continue to avoid Unity web games until the Unity web plugin is a little more widespread and proven.</p>

<p>So <strong>I absolutely recommend Java</strong>, whether through an applet or through Java Web Start or an executable JAR.</p>

<p>P.S. The world's most popular free online MMO, as <a href=""http://services.runescape.com/m=news/newsitem.ws?id=1386"">recognized</a> by the Guinness World Records, is <a href=""http://www.runescape.com/"">RuneScape</a>, which runs as a Java applet and recently has a desktop version. It supports both DirectX and OpenGL as well as a software 3D renderer, and has approximately <a href=""http://www.techradar.com/news/gaming/mmo-developers-jagex-outline-mechscape--617551?artc_pg=1"">10 million active accounts</a>.</p>
","3007"
"In 2D, how do I efficiently find the nearest object to a point?","12890","","<p>I have a sizable game engine and I'd like a feature for finding the nearest of a list of points.</p>

<p>I could simply use the <a href=""http://en.wikipedia.org/wiki/Pythagoras_theorem"">Pythagorean theorem</a> to find each distance and choose the minimum one, but that requires iterating through all of them.</p>

<p>I also have a collision system, where essentially I turn objects into smaller objects on a smaller grid (kind of like a minimap) and only if objects exist in the same gridspace do I check for collisions. I could do that, only make the grid spacing larger to check for closeness. (Rather than checking every single object.) However, that would take additional setup in my base class and clutter up the already cluttered object. Is it worth it? </p>

<p>Is there something efficient and accurate I could use to detect which object is closest, based on a list of points and sizes?</p>
","<p>The problem with a <a href=""http://en.wikipedia.org/wiki/Quadtree"" rel=""nofollow noreferrer"">quad</a>/<a href=""http://en.wikipedia.org/wiki/Octree"" rel=""nofollow noreferrer"">octree</a> in nearest-neighbor searches is that the closest object may be sitting right across the division between nodes. For collisions, this is okay, because if it's not in the node, we don't care about it. But consider this 2D example with a quadtree:</p>

<p><img src=""https://i.stack.imgur.com/JkQCY.png"" alt=""Quadtree example""></p>

<p>Here, even though the black item and green item are in the same node, the black item is closest to the blue item. <a href=""https://gamedev.stackexchange.com/q/14373/7881"">ultifinitus' answer</a> can only guarantee the nearest-neighbor only every item in your tree is placed in the smallest possible node that could contain it, or in a unique node - this leads to more inefficient quadtrees. (Note that there are many different ways to implement a structure which could be called a quad/octree - more strict implementations may work better in this application.)</p>

<p>A better option would be a <a href=""http://en.wikipedia.org/wiki/Kd-tree"" rel=""nofollow noreferrer"">kd-tree</a>. Kd-trees have a very efficient <a href=""http://en.wikipedia.org/wiki/Kd-tree#Nearest_neighbour_search"" rel=""nofollow noreferrer"">nearest-neighbor search</a> algorithm you can implement, and can contain any number of dimensions (hence ""k"" dimensions.)</p>

<p>A great and informative animation from Wikipedia:
<img src=""https://i.stack.imgur.com/OWDEX.gif"" alt=""kd-tree nearest-neighbor search""></p>

<p>The biggest problem with using kd-trees, if I recall correctly, is that they are more difficult to insert/remove items from while maintaining balance. Therefore, I would recommend using one kd-tree for static objects such as houses and trees which is highly balanced, and another which contains players and vehicles, which needs balancing regularly. Find the nearest static object and the nearest mobile object, and compare those two.</p>

<p>Lastly, kd-trees are relatively simple to implement, and I'm sure you can find a multitude of C++ libraries with them. From what I remember, R-trees are much more complicated, and probably overkill if all you need is a simple nearest-neighbor search.</p>
","14384"
"Designing a ResourceManager class","12846","","<p>I've decided I want to write a central ResourceManager/ResourceCache class for my hobby game engine, but am having trouble designing a caching scheme. </p>

<p>The idea is that the ResourceManager has a soft target for the total memory used by all the game's resources combined. Other classes will create resource objects, which will be in an unloaded state, and pass them to the ResourceManager. The ResourceManager then decides when to load / unload the given resources, keeping the soft limit in mind.</p>

<p>When a resource is needed by another class a request is sent to the ResourceManager for it, (either using a string id or a unique identifier). If the resource is loaded, then a read-only reference to the resource is passed to the calling function, (wrapped in a referenced counted weak_ptr). If the resource isn't loaded, then the manager will mark the object to be loaded at the next opportunity, (usually at the end of drawing the frame). </p>

<p>Note that, although my system does do some reference counting, it only counts when the resource is being read, (so the reference count may be 0, but an entity might still be keeping track of it's uid).</p>

<p>It is also possible to mark resources for loading well in advance of first use.
Here is a bit a sketch of the classes I am using:</p>

<pre><code>typedef unsigned int ResourceId;

// Resource is an abstract data type.
class Resource
{
   Resource();
   virtual ~Resource();

   virtual bool load() = 0;
   virtual bool unload() = 0;
   virtual size_t getSize() = 0; // Used in determining how much memory is 
                                 // being used.
   bool isLoaded();
   bool isMarkedForUnloading();
   bool isMarkedForReload();
   void reference();
   void dereference();
};

// This template class works as a weak_ptr, takes as a parameter a sub-class
// of Resource. Note it only hands give a const reference to the Resource, as
// it is read only.
template &lt;class T&gt;
class ResourceGuard
{
   public:
     ResourceGuard(T *_resource): resource(_resource)
     {
        resource-&gt;reference();
     }

     virtual ~ResourceGuard() { resource-&gt;dereference();}
     const T* operator*() const { return (resource); }
   };

class ResourceManager
{
   // Assume constructor / destructor stuff
   public:
      // Returns true if resource loaded successfully, or was already loaded.
      bool loadResource(ResourceId uid);

      // Returns true if the resource could be reloaded,(if it is being read
      // it can't be reloaded until later).
      bool reloadResource(ResourceId uid)

      // Returns true if the resource could be unloaded,(if it is being read
      // it can't be unloaded until later)
      bool unloadResource(ResourceId uid);

      // Add a resource, with it's named identifier.
      ResourceId addResource(const char * name,Resource *resource);

      // Get the uid of a resource. Returns 0 if it doesn't exist.
      ResourceId getResourceId(const char * name);

      // This is the call most likely to be used when a level is running, 
      // load/reload/unload might get called during level transitions.
      template &lt;class T&gt;
      ResourceGuard&lt;T&gt; &amp;getResource(ResourceId resourceId)
      {
         // Calls a private method, pretend it exits
         T *temp = dynamic_cast&lt;T*&gt; (_getResource(resourceId));
         assert(temp != NULL);
         return (ResourceGuard&lt;T&gt;(temp));
      }

      // Generally, this will automatically load/unload data, and is called
      // once per frame. It's also where the caching scheme comes into play.
      void update();

};
</code></pre>

<p>The trouble is, to keep the total data usage hovering around / under the soft limit, the manager will have to have a smart way of determining which objects to unload. </p>

<p>I'm thinking of using some kind of priority system, (eg. Temporary Priority, Frequently Used Priority, Permanent Priority), combined with the time of the last dereference, and the size of the resource, to determine when to remove it. But I can't think of a decent scheme to use, or the right data-structures required to quickly manage them. </p>

<p>Could someone who has implemented a system like this give an overview of how their's worked. Is there an obvious design pattern I am missing out on? Have I made this too complicated? Ideally I need an efficient, and hard to abuse system. Any ideas?</p>
","<p>I'm not sure if this pertains to your question 100% but a few advice tips are the following:</p>

<ol>
<li>Wrap your resources in a handle.
Your resources should be split into two: their description (usually in XML) and actual data. The engine should load ALL resource descriptions at the start of the game and create all handles for them. When a component requests a resource the handle is returned. That way functions can proceed as normal (they can still request the size etc..).
Now what if you haven't loaded the resource yet? Make a 'null resource' that is used to replace any resource that is attempted to be drawn but hasn't been loaded yet.</li>
</ol>

<p>There's a bunch more. I recently read this book ""<a href=""http://rads.stackoverflow.com/amzn/click/0763784516"">Game Engine Design and Implementation</a>"" and a has very nice section where it goes and designs a resource manager class.</p>

<p>Without the ResourceHandle and Memory Budget functionality here is what the book recommends:</p>



<pre><code>typedef enum
{
    RESOURCE_NULL = 0,
    RESOURCE_GRAPHIC = 1,
    RESOURCE_MOVIE = 2,
    RESOURCE_AUDIO = 3,
    RESOURCE_TEXT =4,
}RESOURCE_TYPE;


class Resource : public EngineObject
{
public:
    Resource() : _resourceID(0), _scope(0), _type(RESOURCE_NULL) {}
    virtual ~Resource() {}
    virtual void Load() = 0;
    virtual void Unload()= 0;

    void SetResourceID(UINT ID) { _resourceID = ID; }
    UINT GetResourceID() const { return _resourceID; }

    void SetFilename(std::string filename) { _filename = filename; }
    std::string GetFilename() const { return _filename; }

    void SetResourceType(RESOURCE_TYPE type) { _type = type; }
    RESOURCE_TYPE GetResourceType() const { return _type; }

    void SetResourceScope(UINT scope) { _scope = scope; }
    UINT GetResourceScope() const { return _scope; }

    bool IsLoaded() const { return _loaded; }
    void SetLoaded(bool value) { _loaded = value; }

protected:
    UINT _resourceID;
    UINT _scope;
    std::string _filename;
    RESOURCE_TYPE _type;
    bool _loaded;
private:
};

class ResourceManager : public Singleton&lt;ResourceManager&gt;, public EngineObject
{
public:
    ResourceManager() : _currentScope(0), _resourceCount(0) {};
    virtual ~ResourceManager();
    static ResourceManager&amp; GetInstance() { return *_instance; }

    Resource * FindResourceByID(UINT ID);
    void Clear();
    bool LoadFromXMLFile(std::string filename);
    void SetCurrentScope(UINT scope);
    const UINT GetResourceCount() const { return _resourceCount; }
protected:
    UINT _currentScope;
    UINT _resourceCount; //Total number of resources unloaded and loaded
    std::map&lt;UINT, std::list&lt;Resource*&gt; &gt; _resources; //Map of form &lt;scope, resource list&gt;

private:
};
</code></pre>

<p>Notice that the SetScope functionality refers to a Scene-Layered Engine Design where the ScopeLevel refers to the Scene#. Once a scene has been entered/exited, all resources according to that scope are loaded and any not in the global scope are unloaded.</p>
","17082"
"Determining Poker Hands","12829","","<p>I have been making a Texas Hold'Em game as a part of an assessment, and I have been mulling over how to examine the 7 available cards and determine if hands exist.</p>

<p>The only possible method I can think of is to sort the cards numerically, then examine each possible group of 5 cards and check if they match a list of every single possible hand. That would take a long time snd would only be feasible for determining pairs, as the suit is irrelevant.</p>

<p>The cards are each strings, made up of a number/a/j/q/k, and a suit <code>(char)3</code> (that makes a little spades symbol).</p>

<p>Does anyone have any suggestions, formulas, or links I could use to help create a hand-analysing system?</p>

<p>Don't worry about ranking hands against each other yet, that's a different kettle of fish.</p>
","<p>I think you can find the majority of poker hands by simply making a couple of tables of how many cards in the hand there are of each rank and suit.</p>

<p>In other words, create an array mapping card ranks (numbers and A/J/Q/K) to the count of cards of that rank in your hand.  If the player has a pair or three-of-a-kind, there will be an element in this array equal to 2 or 3, etc.  They have a full house if there's one element that's 2 and another that's 3, and a straight if there are five consecutive elements equal to 1 in this array.</p>

<p>Likewise you can make a similar array of the count of cards of each suit, and use it to detect flushes.</p>

<p>Once you've detected the presence of a specific hand it's pretty easy to then go back and find the specific cards in the hand, for highlighting them in the UI or whatever you need to do.</p>

<p>In pseudocode:</p>

<pre><code>int countByRank[13] = { 0 };        // Initialize counter to zero for each rank
for (cards in hand)
    countByRank[card.rank] += 1;    // Increment counter for this card's rank
if (countByRank.find(2))
    // There's a pair
else if (countByRank.find(3))
    // There's a three-of-a-kind
// etc...
</code></pre>
","49304"
"Procedural river or road generation for infinite terrain","12803","","<p>I should say paths, not roads as I'm thinking more medieval-like. Also, not looking for realism. The answer I'm looking for will be to fit into the mold I describe rather than realism.</p>

<p>I am looking for a method to generate procedural roads/rivers in a curvy sort of fashion, but I'm wanting to do so for a infinite terrain type system. Just like how perlin noise generates blobs, I'm wanting to generate random length line segments (possibly infinite length).</p>

<p>I'm aware of strategies like the suggested answer found <a href=""https://gamedev.stackexchange.com/questions/31263/road-river-generation-on-2d-grid-map?lq=1"">here</a>, however it relies on a specified start and end point to work, I don't have a specified start and end point. I'd like to be able to simply call a function using arbitrary coordinates and have it return whether the specific coordinates are part of the river/road.</p>

<p><strong>I am not wanting to require terrain to be generated in advance. That includes a heightmap (like used for rainfall simulations or similar). I would also not want to require a start/end point.</strong> </p>

<p>Is there such an algorithm or tweak to a noise algorithm someone might know of to accomplish what I'm trying to explain? </p>

<p>The closest I've came to so far is multi-ridged fractals, if I'm using the name properly. I'm just taking the absolute value of value noise (assuming it is scaled to -1 to +1) and setting a threshold. My primary issue with this is the lines overlap way too often, are mostly circular, sometimes converge to form large lakes which is neat but undesired, and often times the thickness of the lines vary too much. </p>

<p>Here's a picture of what I have so far in 2D, but at a very high frequency to show more detail:</p>

<p><img src=""https://i.stack.imgur.com/gRqs2.png"" alt=""enter image description here""></p>
","<p>Just my idea to archive this what you want without (much) precomputation and the possibility for an infinite world.</p>

<p>The first pice of the algorithm is the usage of <a href=""http://de.wikipedia.org/wiki/Voronoi-Diagramm"" rel=""nofollow noreferrer"">Voronoi-Diagramms</a>.
You divide your world into grids, each grid does have an adress in the form (xgrid, ygrid).
For each cell in which you need to create roads you put the xgrid and ygrid variables into a hash function which returns a number <em>CellSeed</em>.
You use <em>CellSeed</em> as the seed for a random number generator which generates the coordinates of the points for the Voronoi Diagramm.</p>

<p>Now you need to search the edges of the diagram and the nodes where multiple edges collide.
You can also store the information into a graph for more easy access.</p>

<p>After this step you can search paths through the network which are valid.</p>

<p>For valid paths you can now create the roads (they do have sharph edges).</p>

<p><em>Note</em>: You also need to generate the coordinates of the Voronio diagram for all neightbor cells so you don't have borders on the edges of the cell.</p>

<p>If you don't want sharph edges you can calculate the middlepoint of each connection and use the direction as a tangent for a bezier interpolation between two edges in the graph.</p>

<p><strong>About the usage of Voronoi-Diagramms</strong></p>

<p>To archive city like road structures the points from the pseudo random function can be aligned on a grid, so the ways are rectangle shaped.</p>

<p>For more county like roads the points have to be more unordered.</p>

<p><img src=""https://i.stack.imgur.com/RC3nc.png"" alt=""diagramm from wikipedia""></p>

<p><strong>About the Pseudo Random function to generate the positions of the points for the Voronoi-Diagramms</strong></p>

<p>It can be a normal random function or a <a href=""http://en.wikipedia.org/wiki/Constructions_of_low-discrepancy_sequences#The_Hammersley_set"" rel=""nofollow noreferrer"">Hammersley set</a> for a more uniform non-clumpy distribution of the points.</p>
","59499"
"How to achieve a Neon-Light effect?","12796","","<p>I'm wondering how to achieve a neon-light type effect. For example, in <a href=""http://www.youtube.com/watch?v=fUHZj-PGjk4"">Pac-Man Chamipnship Edition</a>:</p>

<p><img src=""https://i.stack.imgur.com/Jn39S.jpg"" alt=""PacMan CE""></p>

<p>Or in <a href=""http://www.youtube.com/watch?v=pv-sJxv5uMs&amp;hd=1"">Geometry Wars</a>:</p>

<p><img src=""https://i.stack.imgur.com/chmEr.jpg"" alt=""Geometry Wars""></p>

<p>Is that a Bloom Effect? Or what techniques would I have to look for?</p>
","<p>Here you go :)</p>

<p><a href=""https://developer.nvidia.com/gpugems/GPUGems/gpugems_ch21.html"" rel=""nofollow noreferrer"">GPU Gems - Glow Effect</a></p>

<p>With that many entities with a glowing effect on the screen (especially in Geometry Wars), it's more often than not a shader effect that's similar to the shader described in that paper.</p>
","6856"
"How can I implement a main menu?","12734","","<p>I have been following the tutorials at <a href=""http://lazyfoo.net/tutorials/SDL/index.php"" rel=""noreferrer""><a href=""http://lazyfoo.net/tutorials/SDL/index.php"" rel=""noreferrer"">http://lazyfoo.net/tutorials/SDL/index.php</a></a> and although they are all very well written and I have learned more than I would have on my own, I am not sure how to go about building a basic main menu that has the normal ""new game,"" ""settings"" and ""exit"" options.</p>

<p>How would I handle such a menu inside of a normal game loop?</p>
","<p>As congusbongus notes in his answer, many games benefit from dividing content into ""scenes"".  A scene might represent a particular level, a room, a minigame, or lots of other possibilities, depending on the game.  In such a system, menus can be implemented as scenes as well, and this works well for simple games with only a few menus.</p>

<p>Personally, I like to think of menus as overlays.  Most games don't need more than one scene active at a time, but benefit from having a menu open while the game is running, and knowing what menu you came from if there are sub-menus.  If you treat menus and scenes the same and don't allow multiple scenes to coexist, it's difficult to make a pause menu, or have menus that can be reached in multiple ways.</p>

<p>I find the most useful representation for menus is a stack.  Such an implementation might look like this:</p>

<ul>
<li>When the game (application) starts, push the main menu onto the stack.</li>
<li>When a sub-menu is selected, push it onto the stack.</li>
<li>When a ""back"" button is pressed, pop the top menu from the stack.</li>
<li>When the actual game begins (scene is loaded), pop all menus.</li>
<li>If the stack is not empty, render its top menu after you render your current scene (if there is one).  Of course, if the top menu is opaque, you can skip drawing the current scene to save time, but having a pause menu with a transparent/translucent background can be nice.</li>
<li>If the menu stack is empty, dispatch input events to the current scene, otherwise, dispatch them to the top menu in the stack.</li>
</ul>

<p>For example, if you have a main menu, high scores menu, settings menu, pause menu, and end-of-game summary menu, you might be able to get to the settings menu via the main menu or pause menu, but you can return to wherever you came from without having to deal with any special cases or complex state tracking.  You can even return to the main menu from a paused game and later return to the game by having a ""return to game"" option on the main menu that is deactivated and invisible if the menu stack has a size of 1 (the main menu)</p>
","72888"
"How do i create bounding boxes with XNA 4.0?","12675","","<p>I am having some trouble making bounding boxes for my models I am using within XNA 4.0. The way it was done in XNA 3.1 seems to be obsolete as you can no longer access parameters that were used before in XNA 3.1. Has anyone got any decent links I have been looking around the net for a while now and all I am finding is things for XNA 3.1 or below.</p>

<p>Help much apprechiated.
Regards
Mark</p>

<p><strong>EDIT:</strong></p>

<p>Hey, the problem i am having is getting the min and max points for my model i load through the content pipeline. as articles i have seen on how to do it tell you to do such things as <code>VertexPositionNormalTexture[] vertices= new VertexPositionNormalTexture[mesh.VertexBuffer.SizeInBytes / mesh.MeshParts[0].VertexStride;</code> but i can no longer call size in bytes and vertex strides within XNA 4.0 </p>
","<p>I have encountered the same problem yesterday. My solution is this one, it is vertex type independent and works quite good.</p>

<pre><code>protected BoundingBox UpdateBoundingBox(Model model, Matrix worldTransform)
{
    // Initialize minimum and maximum corners of the bounding box to max and min values
    Vector3 min = new Vector3(float.MaxValue, float.MaxValue, float.MaxValue);
    Vector3 max = new Vector3(float.MinValue, float.MinValue, float.MinValue);

    // For each mesh of the model
    foreach (ModelMesh mesh in model.Meshes)
    {
        foreach (ModelMeshPart meshPart in mesh.MeshParts)
        {
            // Vertex buffer parameters
            int vertexStride = meshPart.VertexBuffer.VertexDeclaration.VertexStride;
            int vertexBufferSize = meshPart.NumVertices * vertexStride;

            // Get vertex data as float
            float[] vertexData = new float[vertexBufferSize / sizeof(float)];
            meshPart.VertexBuffer.GetData&lt;float&gt;(vertexData);

            // Iterate through vertices (possibly) growing bounding box, all calculations are done in world space
            for (int i = 0; i &lt; vertexBufferSize / sizeof(float); i += vertexStride / sizeof(float))
            {
                Vector3 transformedPosition = Vector3.Transform(new Vector3(vertexData[i], vertexData[i + 1], vertexData[i + 2]), worldTransform);

                min = Vector3.Min(min, transformedPosition);
                max = Vector3.Max(max, transformedPosition);
            }
        }
    }

    // Create and return bounding box
    return new BoundingBox(min, max);
}
</code></pre>

<p>All calculations are done in world space, this gives you world space bounding boxes (which is quite common for AABBs). Since it is quite expensive (but still performs good in real-time) just update it on dynamic objects and only when a rotation is performed (you can just translate AABBs with objects if that is the only transform).</p>
","2733"
"How can I implement fast, accurate 2D collision detection?","12641","","<p>I'm well aware of how to detect if two or more 2D objects collide but I'm interested in how to decide whether to check for a collision. In previous projects, I just had every object check against every other object (I know, O(n^2) level of stupidity) and it created a less than fluid gameplay.</p>

<p>Various forums hail the greatness of Quadtrees, B-Trees, and any other kind of tree or structure you can think of.</p>

<p>What is the most efficient structure for determining whether a collision should be checked?</p>
","<p>For a 2d game, unless the 2D objects have a very heavy distribution to one side of your map, a uniform grid is almost always the way to go. The memory complexity is straight forward, (proportional to the dimensions of your map), and with a reasonable distribution, has O(1) look-up time and an average of log(numberOfObjects / (rows * columns)) ^ 2 intersection tests done per cell. You might decide to only check cells which have had an object move in them, which makes static geometry much more efficient. It's easy to modify a uniform grid on the fly, (much less of a pain than in tree based solutions), and it is simpler to implement. The only time I would say not to use it in a 2D game is when the memory requirements of a uniform grid become too large, (say a space sim where the levels are sparse but enormous).</p>
","18271"
"Quad tree vs Grid based collision detection","12639","","<p>I'm making a 4 player co-op r-type game, and I'm about to implement the collision detection code. I've read a lot of articles and stuff about how to handle collision detection, but I'm having a hard time figuring out what to go with.
It seems the quad tree is the most common way to go, but in some resources they mention the grid based solution. For having used a grid for detections in a previous game, I'm comfortable with that, but is it actually better than a quad tree ?
I'm not sure which offers best performance, and I've also ran a little benchmark, there is not much difference between both solutions.</p>

<p>Is one better than the other ? or more elegant ? I'm really not sure which one I should use.</p>

<p>Any advice is welcome.
Thanks.</p>
","<p>The right answer depends a little bit on the actual game you're designing, and choosing one over the other is really going to require implementing both and doing profiling to find out which one is more time or space efficient on your specific game.  </p>

<p>Grid detection seems to only apply to detecting collisions between moving objects and a static background.  The biggest advantage to this is that the static background is represented as a contiguous memory array, and each collision lookup is O(1) with good locality if you need to do multiple reads (because entities cover more than one cell in the grid).  The disadvantage, if the static background is large, is that the grid can be rather wasteful of space.  </p>

<p>If instead you represent the static background as quadtree, then the cost of individual lookups goes up, but because large blocks of the background take up a small amount of space, the memory requirements go down, and so more of the background can sit in the cache.  even if it takes 10 times as many reads to do a lookup in such a structure, if it's all in the cache, it'll still be 10 times faster than a single lookup with a cache miss.  </p>

<p>If I were faced with the choice?  I'd go with the grid implementation, because it's stupid simple to do, better spend my time on other, more interesting problems.  If I notice that my game is running a little slow, I'll do some profiling and see what could use some help.  If it looks like the game is spending a lot of time doing collision detection, I'd try another implementation, like a quadtree (after exhausting all easy fixes first), and find out if that helped.</p>

<p><strong>Edit:</strong> I haven't got a clue how grid collision detection relates to detecting collisions of multiple, mobile entities, but instead, i'll answer how a spatial index (Quadtree) improves detection performance over the iterative solution. The naive (and typically perfectly fine) solution looks sort of like this: </p>

<pre><code>foreach actor in actorList:
    foreach target in actorList:
        if (actor != target) and actor.boundingbox intersects target.boundingbox:
            actor.doCollision(target)
</code></pre>

<p>This obviously has performance around O(n^2), with n the number of actors that are currently alive in the game, including bullets and spaceships and aliens.  It can also include small static obstacles.  </p>

<p>This works fantastically well so long as the number of such items is reasonably small, but starts to look a little poor when there's more than a few hundred objects to check against.  10 objects results in just 100 collision checks, 100 results in 10,000 checks.  1000 results in one million checks.  </p>

<p>A spatial index (like quadtrees) can efficiently enumerate the items it collects according to geometric relationships.  this would change the collision algorithm to something like this:</p>

<pre><code>foreach actor in actorList:
    foreach target in actorIndex.neighbors(actor.boundingbox):
       if (actor != target) and actor.boundingbox intersects target.boundingbox:
            actor.doCollision(target)
</code></pre>

<p>The efficiency of this (assuming a uniform distribution of entities): is usually O(n^1.5 log(n)), since the index takes about log(n) comparisons to traverse, there will be about sqrt(n) neighbors to compare, and there are n actors to check.  Realistically, though, the number of neighbors is always quite limited, since if a collision does occur, most of the time one of the objects is deleted, or moved away from the collision.  thus you get just O(n log(n)).  For 10 entities, you do (about) 10 comparisons, for 100, you do 200, for 1000 you do 3000.  </p>

<p>A really clever index can even combine the neighbor search with the bulk iteration, and perform a callback on each intersecting entity.  This will give a performance of about O(n), since the index is being scanned once rather than queried n times.</p>
","6347"
"How do I calculate how an object will move from one point to another?","12621","","<p>Here's the problem: A player starts the game in the 0 coordinate (x=0,y=0).
When the user clicks on the screen, it returns the coordinates of the destination.
Now the player has to move from its current position A(0.0) to B(x,y).
Take into account that B is in the first Quadrant so x>0 and y>0.</p>

<p>How will the player move?
I know that I will have to use this:
<code>atan2(positionY-destinationY, positionX-destinationX)</code>
to get the angle.</p>

<p>Now what? How will the player move with a fixed velocity (which by the way will be a variable, so a player may move faster while using some ""items"")?</p>

<p>Whose answer is better? What is more accurate? Trigonometry or Linear Algebra?</p>
","<p><strong>Basic trigonometry example</strong></p>

<p>cosine for x axis</p>

<p>sine for y axis</p>

<p>speed is whatever you would like the movement each time to increment by... Obviously the higher the number the more pixels it will move at any given time so the quicker it will be.</p>

<pre><code>dx = (double) (Math.cos(angle) * speed);
dy = (double) (Math.sin(angle) * speed);            

A.x += dx;
A.y += dy;
</code></pre>

<p><strong>Linear algebra example</strong></p>

<p>Check Sidar's answer :).. Explains it way better than I could.</p>

<p>This is in java... You can easily convert it to C++ though.</p>
","48120"
"Value of the Game Institute Courses","12611","","<p>I'm considering purchasing courses from <a href=""http://www.gameinstitute.com/courses.php"" rel=""nofollow"">Game Institute</a>, specifically, the <a href=""http://www.gameinstitute.com/packages.php"" rel=""nofollow"">Foundation Studies Package</a>. Has anyone here taken their courses? If so, do you feel they are a good value? If you can, please be specific as to what you benefited from them, and their strengths and weaknesses.</p>

<p>Though I am most interested in reinforcing computer science fundamentals with respect to game development, I would also like to know if the material is relevant to today's technologies.</p>

<p>I'm especially interested in responses from working professionals who have taken their courses or reviewed their materials.</p>

<p>Background: My work week is spent mostly with SQL Server ETL and some C# web forms development. I have ideas for 2D and 3D platformers, but I don't have the skills to build them to completion yet.</p>

<p>TIA!</p>
","<p>I'll give my input since I've used their package before (and no, I'm in no way affiliated with them). You may have noticed that they're currently having a sale where for 99$ you get access to most of their content across a lot of different topics. For instance:</p>

<ul>
<li>C++ Programming for Game Developers - Module I and II</li>
<li>Graphics Programming with DirectX 9 - Module I and II</li>
<li>Game Mathematics and Math Primer</li>
<li>Artificial Intelligence for Game Developers</li>
<li>Introduction to Robotics</li>
<li>Video Game Console Design</li>
</ul>

<p>I honestly believe that for that price, that's one of the best deals of this kind I've ever come across.</p>

<p>I haven't completed all of the courses yet, but from what I've seen so far, the amount of content and detail packed into each of them is <em>at least</em> as high as most books you could buy for each individual topic. For instance, just the textbook/workbook for the first DX9 Module is over 1000 pages long, and that's not including the actual presentations which also have a full voice recording.</p>

<p>I've also found the content to be very complete and useful. For instance, about 3 years ago, right after working through the first few lessons (including the workbook chapter) of the graphics programming module, I stepped away for a moment and implemented my first basic 3D graphics pipeline from scratch (on an old 2D Javascript Canvas) with the things I had learnt. I think that was probably the first time matrices and transformations really started making sense to me.</p>

<p>To put it shortly, I believe that the value in this case (for the 99$ deal) is <em>ridiculously high</em> for the amount of content you'll get. I've built up quite a large library of game developments books over the course of the past few years, and this package still ranks up there on the list as one of the best investments I've made.</p>

<p>The only drawback I see is that the courses (at least the ones I have) are mostly aimed at beginners, and are a bit outdated in terms of dealing with some more recent techniques. But that's usually the sort of thing you will only learn after reaching a more advanced level anyway, so the courses serve as an excellent starting point from beginner to intermediate level. Although more recent techniques are being researched every day, the basics still apply so in my opinion all of these courses are still very relevant.</p>

<p><strong>Edit</strong></p>

<p>I just noticed the following disclaimer on the site:</p>

<blockquote>
  <p>Advanced Graphics Programming with DirectX course content (coming 2012)</p>
</blockquote>

<p>So I think that will probably address the concerns on my last paragraph.</p>
","22266"
"Would it be better to use XML/JSON/Text or a database to store game content?","12609","","<p>I'm considering how to implement a component-based game, as that seems to be the hot thing and I like the idea of such a flexible design.  One of the features of such a design is that adding new things to the game can be done through data, often presented as loading content through text files such as XML.  This has the advantage of being human readable and easily editable in any text editor.  On the downside, text can be slower to deal with, and you have to manage a large collection of data files.  Similar text-based formats like JSON or config files would have similar benefits.</p>

<p>On the other side, there are small, portable databases like SQLite or Tokyo Cabinet.  While not directly human readable, these files are easy to interface with, and I'd imagine some kind of editing tool would be preferable for game content design anyway.  Using a DB allows for a consistent storage of config information and easy retrieval.  You could serialize data into a DB for save games as well.  </p>

<p>Performance wise, I think generally XML is faster for small files but a database scales better to large amounts of data.  I'd imagine any real game is going to have a whole lot of game objects.</p>

<p>So the question:
Which is the preferable approach?  I'm leaning towards the DB, but I want to know if there are hidden pitfalls or real strong advantages to text files.  Or if there are other alternatives besides these (serialize to binary format I guess?)</p>
","<p>It might not come up so much for a small personal game, but one hard problem when it comes to game data is multi-user editing/versioning. We use a lot of small text files that get baked down to a small number of binary blobs by a build process. This makes life easier for designers since they have a lot of flexibility in their workflow. CCP, as a counter example, uses a central editing database that all designers connect to. This makes the build step unneeded (or at least a lot simpler) but it means you need to implement all the versioning and workflow features yourself, so they are bound to be simpler than other tools out there. You can deal with performance in either case, so the real question is what do you want for a designer workflow and how can you get there?</p>
","4668"
"Time based movement Vs Frame rate based movement?","12603","","<p>I'm new to Game programmming and SDL, and I have been following <a href=""http://www.lazyfoo.net/SDL_tutorials"">Lazyfoo's SDL tutorials</a>. My question is related to time based motion and frame rate based motion, basically which is <em>better</em> or <em>appropriate</em> depending on situations?. Could you give me an example where each of these methods are used?.</p>

<p>Another question I have is that, in lazyfoo's two Motion tutorials (<a href=""http://www.lazyfoo.net/SDL_tutorials/lesson16/index.php"">FPS based</a> and <a href=""http://www.lazyfoo.net/SDL_tutorials/lesson32/index.php"">time based</a>) The time based method showed a much smoother animation while the Frame rate based one was a little hiccupy, meaning you could clearly see the gap between the previous location of the dot and its current position when you compare the two programs.</p>

<p>As beginner which method should I stick to?(all I want is smooth animations). </p>
","<p>What's being shown as ""FPS based"" there is . . . well, basically, it's awful. It's pinning the game's speed to the performance of one particular computer. If you upgrade to a nice fast computer, your game will suddenly run in turbo speed, if you downgrade to a slower computer you'll be grinding around in slo-mo.</p>

<p>The real choice is fixed time step vs. variable time step, and at that point I will defer to <a href=""https://gamedev.stackexchange.com/questions/1589/fixed-time-step-vs-variable-time-step"">this excellent post</a> which goes into great depth.</p>
","6827"
"Which language and tools should I choose for creating 2D games?","12597","","<p>Recently I have returned to my childhood hobby (programming games) and found it quite enjoyable. I've been tinkering with PyGame (for Python) for a few months, made a couple of projects for educational purposes. PyGame is nice, however there is not an awful lot of commercial games using PyGame, and I'd like to invest my time in the best way and <strong>ideally</strong> to make an extra buck in the future. </p>

<p>What I like:</p>

<ul>
<li>doing things alone. I do not dream about working at huge corporation and making one tiny bit of World of Duty-7 </li>
<li>frameworks like LÖVE (for Lua) or PyGame. I doubt I am able to figure out
how to draw those fancy pixels without it</li>
<li>cross-platform things.</li>
<li>free stuff.</li>
</ul>

<p>What I don't like:</p>

<ul>
<li>C++ scares me, however feel free to tell me how stupid I am</li>
<li>IDEs like GameMaker, RPGmaker etc. I like making my own tools.</li>
</ul>

<p>My goal is to make 2D games like Terraria, Super Meat Boy, DefCon, etc. Which language and tools should I choose to accomplish my goal?</p>
","<p><a href=""http://www.gamefromscratch.com/post/2011/08/04/I-want-to-be-a-game-developer.aspx"" rel=""nofollow"">I want to be a game developer... now what?</a>  </p>

<p>This is a pretty comprehensive guide to starting out in game development, covering what languages are available, then a list of the most popular tools and libraries, as well as free and commercial book suggestions.  Most of what is inside is completely free and provides direct download links.   However, it is a long read, but I promise you that you will be much more knowledgeable when you finish!</p>

<p>There is nothing directly wrong with C++, but it is not a very approachable language and there is a level of difficulty in just getting up and running that adds another level of complexity that a new developer doesn't need.  It is a language to consider in the future, but in my humble opinion, not one to learn with!  Then again, nobody listens and they start with C++ anyways! :)</p>
","18454"
"How can I properly access the components in my C++ Entity-Component-Systems?","12572","","<p><em>(What I'm describing is based on this design: <a href=""http://www.richardlord.net/blog/what-is-an-entity-framework"">What is an entity system framework?</a>, scroll down and you'll find it)</em></p>

<p>I'm having some problems creating an entity-component system in C++.  I have my Component class:</p>

<pre><code>class Component { /* ... */ };
</code></pre>

<p>Which is actually an interface, for other components to be created.  So, to create a custom component, I just implement the interface and add the data that will be used in-game:</p>

<pre><code>class SampleComponent : public Component { int foo, float bar ... };
</code></pre>

<p>These components are stored inside an Entity class, which gives each instance of Entity a unique ID:</p>

<pre><code>class Entity {
     int ID;
     std::unordered_map&lt;string, Component*&gt; components;
     string getName();
     /* ... */
};
</code></pre>

<p>Components are added to the entity by hashing the component's name (this probably isn't such a great idea).  When I add a custom component, it is stored as a Component type (base class).</p>

<p>Now, on the other hand, I have a System interface, which uses a Node interface inside.  The Node class is used to store some of a single entity's components (as the System isn't interested in using all of the entity's components).  When the System has to <code>update()</code>, it only need to iterate through the Nodes it stored created from different entities.  So:</p>

<pre><code>/* System and Node implementations: (not the interfaces!) */

class SampleSystem : public System {
        std::list&lt;SampleNode&gt; nodes; //uses SampleNode, not Node
        void update();
        /* ... */
};

class SampleNode : public Node {
        /* Here I define which components SampleNode (and SampleSystem) ""needs"" */
        SampleComponent* sc;
        PhysicsComponent* pc;
        /* ... more components could go here */
};
</code></pre>

<p>Now the problem: let's say I build the SampleNodes by passing an entity to the SampleSystem.  The SampleNode then ""checks"" if the entity has the required components to be used by the SampleSystem.  The problem appears when I need access the desired component inside the Entity: the component is stored in a <code>Component</code> (base class) collection, so I can't access the component and copy it over to the new node.  I've temporarily solved the problem by casting the <code>Component</code> down to a derived type, but I wanted to know if there is a better way of doing this.  I understand if this would mean re-designing what I already have.  Thanks.</p>
","<p>If you are going to be storing the <code>Component</code>s in a collection all together then you must use a common base class as the type stored in the collection, and thus you must cast to the correct type when you try to access the <code>Component</code>s in the collection. The problems of trying to cast to the wrong derived class can be eliminated by clever use of templates and the <code>typeid</code> function, however:</p>

<p>With a map declared like so:</p>

<pre><code>std::unordered_map&lt;const std::type_info* , Component *&gt; components;
</code></pre>

<p>an addComponent function like:</p>

<pre><code>components[&amp;typeid(*component)] = component;
</code></pre>

<p>and a getComponent:</p>

<pre><code>template &lt;typename T&gt;
T* getComponent()
{
    if(components.count(&amp;typeid(T)) != 0)
    {
        return static_cast&lt;T*&gt;(components[&amp;typeid(T)]);
    }
    else 
    {
        return NullComponent;
    }
}
</code></pre>

<p>You will not get a miscast. This is because <code>typeid</code> will return a pointer to the type info of the runtime type (the most derived type) of the component. Since the component is stored with that type info as it's key, the cast can not possibly cause issues because of mismatched types. You also get compile time type checking on the template type as it has to be a type derived from Component or the <code>static_cast&lt;T*&gt;</code> will have mismatched types with the <code>unordered_map</code>.</p>

<p>You do not need to store the components of different types in common collection, though. If you abandon the idea of an <code>Entity</code> containing <code>Component</code>s, and instead have each <code>Component</code> store an <code>Entity</code> (in reality, it will probably be just an integer ID), then you can store each derived component type in its own collection of the derived type instead of as the common base type, and find the <code>Component</code>s ""belonging to"" an <code>Entity</code> through that ID. </p>

<p>This second implementation is a bit more unintuitive to think about than the first, but it could probably be hidden as implementation details behind an interface so the users of the system don't need to care. I won't comment on which is better as I have not really used the second, but I don't see using static_cast as a problem with as strong a guarantee on types as the first implementation provides. Note that it requires RTTI which may or may not be an issue depending on platform and/or philosophical convictions.</p>
","55951"
"Why doesn't my C#6 code compile in Unity?","12568","","<p>Why can't Unity work with <a href=""http://www.codeproject.com/Tips/1023426/Whats-New-in-Csharp"" rel=""noreferrer"">C# 6</a> code? It always gives me compiler errors. Here are some code examples:</p>

<pre><code>using static System.Convert;
using static System.Environment;

$""€{punten}{NewLine}€{Money}{NewLine}€{KilledEnemies}{NewLine}€{bonus}{NewLine}€{total}"";
</code></pre>

<p>I use Visual Studio as my code editor and build with no errors. If I press play in Unity it won't build. </p>
","<p>Unity uses an old version of Mono runtime which is based on .NET3.5. It uses something between C# 3 and 4 in terms of features.</p>

<p>I found <a href=""http://www.unityninjas.com/new-technology/c-6-in-unity/"">this</a> by googling around. Not sure if it works but might be something worth investigating.</p>
","114206"
"How can I modify PlayStation 1 games?","12557","","<p>Is it possible to modify Sony PlayStation 1 games?</p>

<p>For example I'm planning to modify a soccer game called <em>Winning Eleven 3</em>. What I'm exactly trying to modify is player properties such as speed, shot power and so on.</p>
","<p>No, you can't really do this.</p>

<p>First of all, PlayStation 1 games were shipped on CD, which is read-only media.  By definition you can't write to it, so modifications are out of the question.</p>

<p>So you may be thinking that you could grab an emulator and a CD image and modify that, but again you're stuck.  You don't have the source code to the game, you don't have a PlayStation 1 development kit, and even if you did, you may be missing certain other tools and libraries that the original authors used.</p>

<p>So you can't write to the CD, you can't rebuild the game, you're stuck with trying to hex-edit a CD image file on your hard disk and running that through an emulator.  I suppose you could call that ""modifying"", for certain definitions of ""modifying""; you may be able to change a few constants or nop out a few instructions, but it's a process of trial and error (and the trial will be farcical, the errors comedic).</p>

<p>If you've ambitions to modify a game, then you're going to be better off choosing a game that's set up to be modified in the first place, and using a platform that enables modification.</p>
","62158"
"How many and which axes to use for 3D OBB collision with SAT","12546","","<p>I've been implementing the SAT based on: <a href=""http://www.geometrictools.com/Documentation/DynamicCollisionDetection.pdf"">http://www.geometrictools.com/Documentation/DynamicCollisionDetection.pdf</a> for 3D collisions</p>

<p>On page 7, in the table, it refers the 15 axis to test so we can find a collision, but with just Ax, Ay and Az, I'm already getting collisions.</p>

<p>Why do i need to test all the other cases? Is there any situation where just Ax, Ay and Az are not enough?</p>
","<p>You may be geting false positives. Collisions detected but not really colliding.</p>

<p>The number 15  comes from</p>

<ul>
<li>3 axes from object A (face normals)</li>
<li>3 axes from object B (face normals)</li>
<li>9 axes from  all the pairs of edges of A and edges of B (3x3)</li>
<li>=15 in total</li>
</ul>

<p>The 9 axes are made up of cross products of edges of A and edges of B</p>

<ol>
<li>Ae1 x Be1 (Edge 1 of A cross edge 1 of B)</li>
<li>Ae1 x Be2</li>
<li>Ae1 x Be3</li>
<li>Ae2 x Be1</li>
<li>... and so on</li>
</ol>

<p>The first 6 axes (from the face normals) are used to check if there a corner of one object is intersecting a face of the other object. (or more correctly to eliminate these kinds of collisions)</p>

<p>The set of 9 axes formed by the cross products of edges are used to consider edge on edge collision detection, where there is not a vertex penetrating the other object. Like the 'almost' collision in the photo below. Lets assume for the rest of this answer that the two boxes  in the picture are not actually colliding, but are separated by a tiny distance.</p>

<p><img src=""https://i.stack.imgur.com/gaSg1.jpg"" alt=""enter image description here""></p>

<p>Lets look at what happens if we just use the 6 face normals for SAT. The first image below shows one axis from the blue box and 2 axes from the yellow box. If we project both objects on to these axes, we will get an overlap on all three. The second image below shows the remaining two axes of the blue box and the remaining axis of the yellow box. Again projecting on these axes will show overlaps on all 3.</p>

<p>So just only checking the 6 face normals will show overlaps on all 6 axes, which, according to the SAT, means that the objects are colliding, because we have not been able to find a separation. But of course, these object are not colliding. The reason we have not found a separation is because we have not looked hard enough!</p>

<p><img src=""https://i.stack.imgur.com/mQo4a.png"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/8Q7k8.png"" alt=""enter image description here""></p>

<p>So how are we to find this gap? The image below show an axis on which projection of both objects will reveal a separation. </p>

<p><img src=""https://i.stack.imgur.com/z0pDg.png"" alt=""enter image description here""></p>

<p>Where do we get this axis from?</p>

<p>If you imagine sliding a piece of stiff card into the gap, that card will be part of the separating plane. If we project on to the normal of that plane (black arrow in picture above), we will see the separation. We know what that plane is because we have two vectors which lie on that plane) One vector is aligned with the edge of blue and the other vector is aligned with the edge of yellow and as we all know the normal to a plane is simply the cross product  of two vectors lying on the plane.</p>

<p>So for OOBBs we need to check every combination(9 of them) of cross products of the edges of the two objects to make sure we are not missing any edge-edge separations.</p>
","44501"
"Can Xcode be used to create very simple games?","12527","","<p>I am brand new to Xcode, and I am also brand new Objective-C programmer.</p>

<p>I was wondering if it is possible to create simple Mac games with Xcode. If it's not possible, could you recommend me some good, cheap game engines?</p>
","<p>Xcode can indeed be used to create games. You can do anything a Mac/iOS device is capable of by programming in Xcode.</p>

<p>I think you should focus on what part of the project you want to focus on. As you state you are a brand new Objective-C programmer (welcome). In my opinion it would be quite a mouth full to try and just into Objective-C programming whilst taking on Xcode AND game development (starting with engine design continuing with game design).</p>

<p>If the purpose is to write great games - get a nice engine that fits your needs (3D/2D/??) - have a look at Unity if you like. If the focus is actually learning programming Objective-C and/or Xcode I'd recommend that you make some small utility programs before jumping on to game development. If the point is to simply do game programming consider the alternatives to Objective-C and Xcode - pure C/C++ or even Java.</p>

<p>All that said - I wish you the best of luck in your adventure!</p>
","20716"
"Hero/Character sprite size in comparison to tile size?","12516","","<p>So I'm making this simple platformer where the Hero is 16x16 in size, but also, the tile size is 16x16. Which sounds fine right? But my game window/world is 800x416, which makes the Hero is really really tiny in comparison. This really surprised me, but given Ive never made a platformer before it is also a new discovery.</p>

<p>Is there a rule set for scale in platformer games?</p>

<p>I'd like to have my game window remain the size it is (800x416), cause the game involves large levels. But how big should my hero be?</p>

<p>I hope I was clear with the question, and I appreciate any insight.</p>

<p>Thanks </p>
","<p>It's mostly a subjective question, and it depends a lot on your intended game aesthetic and mechanics.</p>

<p>The important ratio is feature size to screen size, not feature size to tile size. Some numbers are given here : <a href=""http://kotiro.petermichaud.com/visual/resolution/"">http://kotiro.petermichaud.com/visual/resolution/</a>. As you might notice, the original Mario Bro featured a really small mario, not only in terms of pixel resolution, but also in terms of screen real-estate (1/20 of the height). You barely knew what your character was supposed to be, and it's hard to build attachment to something that small. Later games in the series (whether it was Mario 3 or Mario World or Paper Mario) had a character roughly 1/8 the height of the screen, regardless of the resolution.</p>

<p>I'd also argue that the speed of your game somewhat influences the size. For example, Super Meat Boy features a fast-moving blob in a unforgiving environment. The view is zoomed out further and the features and characters smaller, but with how fast Meat Boy moves, it would be claustrophobic and deadly obstacles would severely test player reflexes. There's still a lot of times when the camera zooms in, so that you can identify with the character better. For contrast, Castlevania features a slow-moving protagonist and the game centers around interaction between you and nearby enemies, so the larger feature size works well. </p>
","19631"
"How to implement an experience system?","12512","","<p>I'm currently writing a small game that is based on earning experience when killing enemies. As usual, each level requires more experience gain than the level before, and on higher levels, killing enemies awards more experience.</p>

<p>But I have a problem balancing this system. Are there any prebuilt algorithms that help to calculate how the experience curve required for each level should look like? And how much experience an average enemy on a specific level should provide?</p>
","<p>You would want some kind of exponential curve, probably something like:</p>

<pre><code>base_xp * (level_to_get ^ factor)
</code></pre>

<p>base_xp is a constant that decides how much xp you need to go up a level.<br>
level_to_get is the level you are aiming for; at level 1, this will be level 2.<br>
factor is another constant that decides how much of an increase of xp you need for each level.</p>

<p>Having a base_xp of 200 and a factor of, say, 2 gives something like this:</p>

<p><img src=""https://i.stack.imgur.com/gW3yU.gif"" alt=""enter image description here""></p>

<p>Whereas a base_xp of 50 and a factor of 2.6 gives:  </p>

<p><img src=""https://i.stack.imgur.com/21GNO.gif"" alt=""enter image description here""></p>

<p>The second has a much lower starting xp rate, but you need more xp very quickly.</p>

<p>As for monster xp, this is something you want to test. Try out various values. You want something that is not too high (you'll quickly become overpowered) yet not too low (players don't want to grind). Think about how many 'standard' enemies you would want the player to kill for level 10->11, for example.</p>
","8967"
"Handling keyboard and mouse input (Win API)","12502","","<p>There is a number of ways to catch mouse or keyboard under Windows. So I tried some of them, but every of them has some advantages and drawbacks. I want to ask you: Which method do use?  </p>

<p>I've tried these:  </p>

<ol>
<li><p>WM_KEYDOWN/WM_KEYUP - Main disadvantage is that, I can't distinguish between left and right-handed keys like ALT, CONTROL or SHIFT.  </p></li>
<li><p>GetKeyboardState - This solves problem of first method, but there is new one. When I get that the Right-ALT key is pressed, I also get that the Left-Control key is down. This behaviour happens only when using localized keyboard layout (Czech - CS).  </p></li>
<li><p>WM_INPUT (Raw Input) - This method also doesn't distinguish left and right-handed keys (if I can remember) and for mouse movement sometimes generates message with zero delta values of mouse position.</p></li>
</ol>
","<p>The best and simplest way to do it is to use your first idea and handle the WM_KEYUP/WM_KEYDOWN messages as well as the WM_SYSKEYUP/WM_SYSKEYDOWN messages. These can handle detecting the difference between left and right shift/control/alt keys, you just need the appropriate <a href=""http://msdn.microsoft.com/en-us/library/dd375731%28v=VS.85%29.aspx"" rel=""nofollow"">virtual key codes</a>. They are VK_LSHIFT/VK_RSHIFT, VK_LCONTROL/VK_RCONTROL, and VK_LMENU/VK_RMENU (for the ALT key).</p>

<p>I wrote up a post about how I did this, and I was handling both the WM_KEYUP/WM_KEYDOWN and WM_SYSKEYUP/WM_SYSKEYDOWN in the same handler. (Unfortunately, the blog is no longer available.)</p>

<p>The only complication that I can see is that because you're using a non-US keyboard you'll need to add in some additional logic to handle the sequence described in the <a href=""http://msdn.microsoft.com/en-us/library/ms646287%28VS.85%29.aspx"" rel=""nofollow"">WM_SYSKEYUP article</a> on MSDN. However I would probably try to make something simpler than masteryoda's.</p>
","1873"
"How to disable play automatically on animation in Unity3d 4.5.1","12493","","<p>Where is the option to disable the 'Play Automatically' function for animations in Unity3d 4.5.1. In previous versions, there was a button under the Animation tab to disable the play automatically:<br> <img src=""https://i.stack.imgur.com/Wkrvz.png"" alt=""enter image description here""></p>

<p>But now in Unity3d 4.5.1, there is no 'Play Automatically' checkbox, instead this is here:<br><img src=""https://i.stack.imgur.com/Q0IOc.png"" alt=""enter image description here""></p>

<p>If anyone knows how to disable the play automatically in this version of Unity, I would really appreciate if you could explain how to do it and where to go to do it because I am pretty new to Unity and am not too sure where things are. Thanks!</p>
","<p>With new animation system, animations are handled by <code>AnimatorController</code> component. </p>

<p>If your animation start automatically, it means that the clip is the default one (orange color) in the controller graph. To prevent this on Behavior on start you have 2 way:</p>

<ol>
<li>Keep AnimatorController component disabled until you don't need it.</li>
<li>Use an empty state with no clip as default (inside the controller): transition to your animation clip must be explicitly activated</li>
</ol>
","79499"
"Problem to match font size to the screen resolution in libgdx","12490","","<p>I'm having problems to show text on my game at same size on different screens, and I did a simple test.</p>

<p>This test consists to show a text fitting at the screen, I want the text has the same size independently from the screen and from DPI.</p>

<p>I've found <a href=""https://gamedev.stackexchange.com/a/77674/48732"">this</a> and <a href=""https://gamedev.stackexchange.com/a/63718/48732"">this answer</a> that I think should solve my problem but don't. In desktop the size is ok, but in my phone is too big.</p>

<p>This is the result on my Nexus 4: (768x1280, 2.0 density)</p>

<p><img src=""https://i.stack.imgur.com/EX2FD.png"" alt=""Nexus 4 calculating density""></p>

<p>And this is the result on my MacBook: (480x800, 0.6875 density)</p>

<p><img src=""https://i.stack.imgur.com/F94Sf.png"" alt=""enter image description here""></p>

<p>I'm using the <a href=""https://www.google.com/fonts/specimen/Open+Sans+Condensed"" rel=""nofollow noreferrer"">Open Sans Condensed (link to google fonts)</a></p>

<p>As you can see on desktop looks good, but on the phone is so big.</p>

<p>Here the code of my test:</p>

<pre><code>public class TextTest extends ApplicationAdapter
{
    private static final String TAG = TextTest.class.getName();
    private static final String TEXT = ""Tap the screen to start"";

    private OrthographicCamera camera;
    private Viewport viewport;

    private SpriteBatch batch;
    private BitmapFont font;

    @Override
    public void create ()
    {
        Gdx.app.log(TAG, ""Screen size: ""+Gdx.graphics.getWidth()+""x""+Gdx.graphics.getHeight());
        Gdx.app.log(TAG, ""Density: ""+Gdx.graphics.getDensity());

        camera = new OrthographicCamera();
        viewport = new ExtendViewport(Gdx.graphics.getWidth(), Gdx.graphics.getWidth(), camera);
        batch = new SpriteBatch();

        FreeTypeFontGenerator generator = new FreeTypeFontGenerator(Gdx.files.internal(""fonts/OpenSans-CondLight.ttf""));
        font = createFont(generator, 64);
        generator.dispose();
    }

    private BitmapFont createFont(FreeTypeFontGenerator generator, float dp)
    {
        FreeTypeFontGenerator.FreeTypeFontParameter parameter = new FreeTypeFontGenerator.FreeTypeFontParameter();

        int fontSize = (int)(dp * Gdx.graphics.getDensity());
        parameter.size = fontSize;

        Gdx.app.log(TAG, ""Font size: ""+fontSize+""px"");

        return generator.generateFont(parameter);
    }

    @Override
    public void render ()
    {
        Gdx.gl.glClearColor(1, 1, 1, 1);
        Gdx.gl.glClear(GL20.GL_COLOR_BUFFER_BIT);

        int w = -(int)(font.getBounds(TEXT).width / 2);

        batch.setProjectionMatrix(camera.combined);
        batch.begin();
        font.setColor(Color.BLACK);
        font.draw(batch, TEXT, w, 0);
        batch.end();
    }

    @Override
    public void resize(int width, int height)
    {
        viewport.update(width, height);
    }

    @Override
    public void dispose()
    {
        font.dispose();
        batch.dispose();
    }
}
</code></pre>

<p>I'm trying to find a neat way to fix this.
What I'm doing wrong? is the camera? the viewport?</p>

<p>UPDATE:</p>

<p>What I want is to keep the same margins in proportion, independently of the screen size or resolution. This image illustrates what I mean.</p>

<p><img src=""https://i.stack.imgur.com/VYSAs.png"" alt=""enter image description here""></p>
","<p>You seem to want to keep the same textsize/screensize ratio. Basically what you do is develop at one resolution and let that be scale 1.0. Then you divide the new screen width by the old width and that is your scale factor.</p>

<p>For example.
Developing on 2560x1440 with font size 16 and running on 1920x1080.</p>

<p>Font size will be: 1920 * 16 / 2560 = 12</p>

<p>I do the same in my interface library and it works perfectly.</p>
","79497"
"How to display text and numbers in SFML 2.0","12489","","<p>I want to display some text and numerical data over my OpenGL scene in SFML 2.0. I've looked at the SFML 1.6 text tutorials <a href=""http://www.sfml-dev.org/tutorials/1.6/graphics-fonts.php"">here</a>. But I can't get the code to work.
There is (as of yet) no text tutorial for 2.0</p>
","<p>A lot of the method names have changed in the transition from SFML 1.6 to 2.0. So the 1.6 tutorials will not work without modification.</p>

<p>First you will need to creat a font, you can do this using a .ttf file </p>

<pre><code>//create a font
sf::Font font;

// Load it from a file
if (!font.loadFromFile(""../sansation.ttf""))
    //find this file in the ""pong"" example in the SFML examples folder
{
    std::cout &lt;&lt; ""Error loading font\n"" ;
}
</code></pre>

<p>Inside your render loop, after drawing your scene, you can add this code to render some text and numerical data:</p>

<pre><code>//Draw scene
//.........Draw Scene stuff......


//save the openGLstate if using OpenGL
//becase text drawing may well change some OpenGL settings
window.pushGLStates();

static float frameCount=0;
frameCount++;

std::ostringstream ss; //string buffer to convert numbers to string
ss &lt;&lt; ""Hello World , frame count is: "" &lt;&lt; frameCount;// put float into string buffer


//set up text properties
sf::Text atext;
atext.setFont(font);
atext.setCharacterSize(20);
atext.setStyle(sf::Text::Bold);
atext.setColor(sf::Color::White);
atext.setPosition(0,0);

atext.setString(ss.str()); //ss.str() converts the string buffer into a regular string 

//draw the string
window.draw(atext);

//restore OpenGL setting that were saved earlier
window.popGLStates();
window.display();
</code></pre>
","43432"
"Where can I find a programmer/game developer to team up with?","12451","","<p>I'm a pixel artist looking for an ametuer programmer/game developer to team up with, But I'm not sure where to start!</p>

<p>I'm not particularly worried about profit, I'm only interested in making the game as a hobby.
Where can I find potential partners?</p>
","<p><strong>Show What You Can Do</strong></p>

<p>When looking to start or join a team online, people are always interested in seeing what work you've produced beforehand. The work doesn't necessarily have to be done in a game, but it should showcase your ability to create game quality assets.</p>

<p><strong>Talk About What You Want To Do</strong></p>

<p>If you're looking to recruit people for a team, talk about the project you're wanting to work on. You don't have to have all the details fleshed out, but it is important that potential applicants understand the scale and scope of work you're wanting to accomplish. As an example, there is a big difference in the programming skill and amount of effort required to produce an <a href=""http://en.wikipedia.org/wiki/Asteroids_%28video_game%29"">Astroids</a> clone and a <a href=""http://en.wikipedia.org/wiki/Shoot_%27em_up#Types"">Bullet Hell</a> style game with online networking capabilities.</p>

<p><strong>Read and Follow The Rules</strong></p>

<p>A lot of communities that have job/recruitment boards have specific rules about posting in them. In many cases, they require you to fill out a template when posting, to help ensure you hit on all the major pitch points. Be sure to read the rules for each site before you post.</p>

<p><strong>Resources</strong></p>

<p>Here are links to a few communities you may find useful for recruiting game developer talent:</p>

<ul>
<li>GameDev.net Hobbyist:
<a href=""http://www.gamedev.net/classifieds/category/5-hobbyist-projects/"">http://www.gamedev.net/classifieds/category/5-hobbyist-projects/</a></li>
<li>IndieDB Recruiting:
<a href=""http://www.indiedb.com/forum/board/recruiting-resumes"">http://www.indiedb.com/forum/board/recruiting-resumes</a></li>
<li>ModDB
Recruiting: <a href=""http://www.moddb.com/forum/board/recruiting-resumes"">http://www.moddb.com/forum/board/recruiting-resumes</a></li>
<li>TIGSource Unpaid Work: <a href=""http://forums.tigsource.com/index.php?board=41.0"">http://forums.tigsource.com/index.php?board=41.0</a></li>
</ul>
","37520"
"Rotate to a set degree then stop Unity","12431","","<p>I'm trying to make an object rotate up on the Y axis 90 degrees, then stop. I've got the rotating up bit working fine, it's getting it to stop once it hits 90. </p>

<p>Some of the things I've tried include the following: </p>

<pre><code>float i = rotateSpeed * Time.deltaTime; 
while ( x != 90 )
        {
        transform.Rotate( i, 0, 0);
        }   

        int x = 0; 
x++;

        if( x == 90 )
        {
            transform.Rotate( 0, 0, 0 );
        }
</code></pre>

<p>For some reason I can't get this simple thing to work. What am I missing / not doing?</p>
","<p>You may want to study your basic <a href=""http://en.wikipedia.org/wiki/Control_flow"">control flow</a> structures and learn about <a href=""http://en.wikipedia.org/wiki/Scope_%28computer_science%29"">scope</a>. Also, using a <code>float</code> to rotate and an <code>int</code> to count the number of times you rotated would only work if your <code>i</code> was exactly <code>1</code>, which is very unlikely.</p>

<p>Depending on where this code is and how you want things to be displayed, you probably don't even want a <code>while</code> loop. A while loop would just run through all your rotation in one go, without updating whatever you're rotating on screen in-between. Basically having:</p>

<pre><code>float totalRotation = 0; 
float rotationAmt = rotateSpeed * Time.deltaTime;
while(totalRotation &lt; 90) 
{
    transform.Rotate(rotationAmt, 0, 0);
    totalRotation += rotationAmt; 
}
</code></pre>

<p>is the same (though less accurate) as :</p>

<pre><code>transform.Rotate(90, 0, 0);
</code></pre>

<p>Likely what you really want, to have your object be updated on screen while it rotates is to store the objects current rotation somewhere and also store it's <em>target rotation</em>:</p>

<pre><code>//stored in the object you're rotating
float rotation = 0; 
float targetRotation = 0;

...

//inside our update for the object check the rotation to see if we're where we want to be
float rotationAmt = rotateSpeed * Time.deltaTime;
if(rotation!= targetRotation) 
{
    //first we check to see if there's just a small amount of rotation to shave off
    // this check keeps us from never reaching the target rotation
    if(abs(rotation-targetRotation) &lt; rotationAmt) {
        transform.Rotate(rotation-targetRotation, 0, 0);
        rotation += rotation-targetRotation;
    } else {
        transform.Rotate(rotationAmt, 0, 0);
        rotation += rotationAmt;
    }
}
</code></pre>

<p>Now I know what you're going to do. You're going to copy and paste this code, and tell me it doesn't work. Don't do that. Just look at the code and see how it works. Then implement it yourself to fit your project. There are improvements that can be made to this code as well. Like checking which way to rotate to be fastest. Check <a href=""https://bitbucket.org/byte56/ld21/src/af3dfc2c4c48/src/Byte56_LD21/Entity/Entity.java"">this class</a> to see how you might do that.</p>
","38200"
"HTML5 or Javascript game engine to develop a browser game","12416","","<p>I would like to start developing a MMO browser game, like Travian or Ogame, probably involving also a bit of more sophisticated graphical features such as players interacting in real time with a 2d map or something like that.</p>

<p>My main doubt is what kind of development tools I should use: I've a good experience with PHP and MySQL for the server side and Javascript (and jQuery) regarding the client side. Coding everything from scratch would be of course really painful so I was wondering if I should use a javascript game engine or not. Are there (possibly free) game engine you would recommend? Are they good enough to develop a big game?</p>

<p>Also, I saw a lot of HTML5 games popping up lately but I'm now sure if using HTML5 is a good idea or not. Would you recommend it? What are the pro and cons about using HTML5? If you'd recommend it, do you have any good links regarding game development with HTML5?</p>

<p>(PS: I know that HTML5 and a Javascript engine are not mutually exclusive, I just didn't know how to formulate a proper title since English is not my main language. So, please, answer addressing HTML5 and a game engine pro and cons separately)</p>
","<p>HTML5 game engines are really designed more for ""single page"" games, basically, re-creating Flash games (load the entire game once, and play it on a single page in the browser).  Travian and Ogame consist of multiple pages, and existing HTML5 game engines really aren't designed to handle that sort of setup.  If you're going to create a game like Travian or Ogame, then it's probably fine to simply use jQuery or whatever other Javascript DOM manipulation library you're familiar with.</p>

<p>That said, if you do want to make your game a ""single page game"" as it were, any of the options in <a href=""https://gamedev.stackexchange.com/questions/4277/what-are-good-js-libraries-for-game-dev-html5"">this related question</a> would be good choices.</p>
","20024"
"How can you visualize a quaternion?","12403","","<p>When I visualise a three dimensional rotation matrix, or scaling matrix I visualize it as three axes.</p>

<p><strong>Is there a similar way that I can visualize a rotation quaternion?</strong></p>
","<p>There is an entire 600 page book on ""Visualizing Quaternions"": 
<a href=""http://books.google.ca/books?id=CoUB09xzme4C&amp;lpg=PP1&amp;ots=uEdJHsni9y&amp;dq=Visualizing%20Quaternions&amp;pg=PP1#v=onepage&amp;q&amp;f=false"">http://books.google.ca/books?id=CoUB09xzme4C&amp;lpg=PP1&amp;ots=uEdJHsni9y&amp;dq=Visualizing%20Quaternions&amp;pg=PP1#v=onepage&amp;q&amp;f=false</a></p>

<p>The book is actually quite good, covering a wide range of topics. It starts with a good introduction to game related linear algebra, it talks about matrices and vectors, their shortcomings and why you would want to use Quaternions. It then explains what they are and how to make use of them. If you are interested you might want to pick it up: <a href=""http://rads.stackoverflow.com/amzn/click/0120884003"">http://www.amazon.com/Visualizing-Quaternions-Kaufmann-Interactive-Technology/dp/0120884003</a> </p>
","4829"
"Forcing a game to use Direct3D WARP","12386","","<p>I am making a study for a research project that involves measuring the performance and quality impact of rendering 3d games using a software rasterizer (like WARP). </p>

<p>I wonder if there is a way to force games to use WARP. Maybe something easier would be to just use games that support using warp or the reference rasterizer. Are there any relatively new game (no more than 8 years old) that supports that? I don't remember seeing that option in games in a long time.</p>

<p>If there is no tool or setting to do that, I was thinking I could use something like Detours (http://research.microsoft.com/en-us/projects/detours/) or EasyHook (http://easyhook.codeplex.com/), and perform binary rewriting on the code. For DirectX 10 games I think it should be enough to intercept the CreateDevice call and change the device. For DirectX9 games is it enough to change the D3D9CreateDevice for a D3D10CreateDevice? I tried with samples from the SDK and it seems it is not the case. Any suggestions on what to do there?</p>
","<p>There is a way to force a game to use WARP without disabling Display Driver,
Just install the direct X SDK. <a href=""http://www.microsoft.com/en-us/download/details.aspx?id=6812"" rel=""nofollow"">http://www.microsoft.com/en-us/download/details.aspx?id=6812</a>
Go to C:/windows/system32
Run dxcpl.exe
In ""Scope"" click ""Edit list""
Add The Path To Your Application
Go to your game / application directory And Launch It.</p>
","84522"
"How would I make a bullet shoot from my player to my mouse.","12373","","<p>So far I've created an object called obj_mouse. And my plan is whenever the player left clicks, it spawns a bullet from him toward where ever the mouse is pointing. I've got the concept down, but I'm struggling getting it to work. </p>

<p>Extra bits of code I'm messing around with to try and get it to work:</p>

<pre><code>    bullet=instance_create(x,y,obj_bullet)
with (bullet) {
move_towards_point(mouse_x,mouse_y,5)
image_angle=direction
}

point_direction(obj_mouse,obj_mouse,obj_mouse,obj_mouse)
image_angle=direction
</code></pre>

<p>(In the above code, I havent attempted to specify to the program that I want the bullet to go in the direction of obj_mouse, or rather, just the mouse. The above code works, and bullets do shoot, however the player must have the mouse on the players sprite for it to work.)</p>

<p>Thank you in advance for any advice given. </p>
","<p>You need to use <code>Global Mouse</code> events.</p>

<p>Btw, your code</p>

<pre><code>point_direction(obj_mouse,obj_mouse,obj_mouse,obj_mouse)
</code></pre>

<p>is very strange. You need store result, and you need use coords (not objects names)</p>

<pre><code>direction = point_direction(x, y, obj_mouse.x, obj_mouse.y);
</code></pre>

<p>just for example</p>

<p><code>Step End</code> event:</p>

<pre><code>direction = point_deirection(x, y, mouse_x, mouse_y);
image_angle = direction;
</code></pre>

<p><code>Mouse Global Left Pressed</code> event:</p>

<pre><code>with (instance_create(x, y, obj_bullet))
{
    direction = other.direction;
    image_angle = direction;
    speed = 5;
}
</code></pre>
","100542"
"Does Windows 8 still support DirectX 9?","12295","","<p>Is Windows 8 supporting DirectX 9? Because I was looking through some samples written in C++ and DirectX 9 made for Windows 8. It wasn't that, like I know it ( look here <a href=""http://directxtutorial.com/Lesson.aspx?lessonid=111-4-2"">http://directxtutorial.com/Lesson.aspx?lessonid=111-4-2</a> ). E.g. Inizialising DirectX with COM:</p>

<pre><code>ComPtr&lt;ID3D11Device1&gt; dev;
ComPtr&lt;ID3D11DeviceContext1&gt; devcon;
</code></pre>

<p>It's just weird because I know it with the old way:</p>

<pre><code>ID3D11Device *dev;                  
ID3D11DeviceContext *devcon;  
</code></pre>

<p>( I hope you understand what I want to tell )  </p>

<p>I hope it hasn't change completely due the released their new OS.       </p>
","<p><strong>Yes</strong>, Windows 8 does support DirectX 9.</p>

<p>For development, the old <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/ee663275.aspx"">DirectX SDK is now deprecated</a>, but you'll have all the libraries and headers you need within the new Windows 8 SDK, which comes included with Visual Studio 2012. You can go for the ""old way"" with no problem. If you need PIX for some debugging, or the high level D3DX library, you'll have to install the old DXSDK again, as this is <em>not</em> in the Windows 8 SDK.</p>

<p><strong>However</strong> this is only valid for plain old desktop apps. For Metro-style apps, I'll let <a href=""http://social.msdn.microsoft.com/Forums/en-US/wingameswithdirectx/thread/d16bd98b-1872-4775-aafd-2de8ff6a970a/"">Chuck Walbourn from Microsoft speak</a>:</p>

<blockquote>
  <p>Direct3D9 and Direct3D9Ex are not supported for Metro style
  applications. Use of the DirectX SDK with Metro style applications is
  not recommended or supported. See
  <a href=""http://msdn.microsoft.com/en-us/library/ee663275.aspx"">http://msdn.microsoft.com/en-us/library/ee663275.aspx</a>.</p>
  
  <p>There are a number of resources available to help you in porting a
  Direct3D 9 codebase to Direct3D 11. The majority of the material for
  porting from Direct3D 9 to Direct3D 10.x applies fully here since
  Direct3D 11's API is very similiar to Direct3D 10.</p>
  
  <p>See
  <a href=""http://blogs.msdn.com/b/chuckw/archive/2011/07/11/getting-started-with-direct3d-11.aspx"">http://blogs.msdn.com/b/chuckw/archive/2011/07/11/getting-started-with-direct3d-11.aspx</a>.
  Be sure to review the Windows to Reality: Getting the Most out of
  Direct3D 10 Graphics in Your Games presentation as it covers numerous
  pitfalls and performance issues developers have hit in the past, and
  DirectX 11 Technology Update for a summary of the differences between
  Direct3D 10.x and Direct3D 11.</p>
  
  <p>MSDN has a porting guide as well
  <a href=""http://msdn.microsoft.com/en-us/library/ff476190.aspx"">http://msdn.microsoft.com/en-us/library/ff476190.aspx</a> which points you
  to <a href=""http://msdn.microsoft.com/en-us/library/bb205073.aspx"">http://msdn.microsoft.com/en-us/library/bb205073.aspx</a> for going
  directly from Direct3D 9 to Direct3D 11.</p>
</blockquote>

<p>Sorry, you can't use D3D9 directly for Metro-style apps. But you can use D3D11 and limit yourself to some feature level (e.g. <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/ff476329%28v=vs.85%29.aspx""><code>D3D_FEATURE_LEVEL_9_3</code></a>) if you want to support legacy hardware.</p>
","43865"
"How can i use A star pathfinding algorithm","12279","","<p>How would i implement an A star algorithm for a game that i'm making on the android in java? i'm looking for a pre-made A star API in java with classes and methods to call. i don't want to have to code from scratch.</p>
","<p>Like others have commented, it might be easier (not to mention fun) to write your own implementation of A* (use the link jhocking provided, I learned it from there, and highly recommend it - <a href=""http://www.policyalmanac.org/games/aStarTutorial.htm"" rel=""nofollow"">http://www.policyalmanac.org/games/aStarTutorial.htm</a>).</p>

<p>However if you definitely want a pre-existing library, here are some alternatives:
- <a href=""http://www.stackframe.com/software/PathFinder"" rel=""nofollow"">http://www.stackframe.com/software/PathFinder</a> (scroll to the bottom for the download)
- <a href=""http://www.ludumdare.com/compo/2011/12/16/java-pathfinding-library/"" rel=""nofollow"">http://www.ludumdare.com/compo/2011/12/16/java-pathfinding-library/</a> (probably not an ideal solution, but it would help you in writing your own)</p>

<p>But the one I like best is Critter AI, which is a port of Recast for .NET and Java. The one for Java is more intended for study, but is still awesome.
<a href=""http://www.critterai.org/"" rel=""nofollow"">http://www.critterai.org/</a></p>

<p>Good luck! :)</p>
","23435"
"Best open-source 3D game engine for a first person shooting game?","12256","","<p>What is the best opensource 3D game engine suitable for 1st person shooting game? This engine should be script-able with lua.</p>
","<p>You haven't told us your skill level. But, you can even try integrating Lua scripting functionality with any open source engine of your choice. There are libraries like Luabind &amp; toLua++ for this.</p>

<p>After quick google search there are some interesting results,</p>

<ol>
<li><p><a href=""http://irrlua.sourceforge.net/"" rel=""nofollow"">IrrLua</a> is a Lua binding for the Irrlicht 3D rendering engine. Last update : 08/23/06 </p></li>
<li><p><a href=""http://www.ogre3d.org/tikiwiki/Scripting+with+LuaBind+in+Ogre"" rel=""nofollow"">Scripting with LuaBind in Ogre</a></p></li>
<li><p><a href=""http://www.crystalspace3d.org/main/Luaplugin_tutorial"" rel=""nofollow"">Plugin development tutorial</a> for integrating Lua scripting with Crystal Space Engine. But, I would suggest to stay away form this engine.</p></li>
<li><p><a href=""http://blendelf.com/"" rel=""nofollow"">BlendElf</a> is a good choice.But, I don't think the developer isn't maintaining it any more.</p></li>
<li><p>If you see <a href=""http://www.horde3d.org/home.html"" rel=""nofollow"">Horde 3d</a> feature list, you will see <code>Strong modularity and high abstraction through flat C-style DLL API (also makes it possible to use Horde3D from virtually any programming language)</code>, just like Leadwerks Engine.</p></li>
</ol>

<p><em>If you are not satisfied yet, <a href=""http://content.gpwiki.org/index.php/Game_Engines"" rel=""nofollow"">GPWiki</a> &amp; <a href=""http://www.devmaster.net/engines/"" rel=""nofollow"">DevMaster</a> have a huge list of game engines and scripting feature is specified there. Many well/less known engines has Lua with it. Check it out.</em></p>
","18304"
"How to detect and prevent abuse (botting) of online game API?","12252","","<p>I have been ocassionally working on a game idea in my free time. The gameplay and content renders it to be implemented as a online multiplayer game built with well established web technologies. You should know that it falls into the strategy and simulation genre. That means: No running around with characters or similar but only atomic actions (regarding client-server communication) like ""build thing A on location X"".</p>

<p>At one point I realized there is a huge problem: having a browser based front end relying on a REST API back end makes it a more than excellent target for bots. While automation is desireable for business it is poison to a game which is about fun. I experienced it first hand in a browser game in the past were the most successful players were bots which subdued everybody.</p>

<p>From my current point of view I do not see any possibility to protect against bots when building a multiplayer online game based on  a REST API. Exception: Making it open source so everybody can host his own instance for private groups or even just oneself (to not get annoyed by jerks with bots).</p>

<p>Is there any way to differenciate between an honest player who just set an alarm for the next possible action and a bot automatically taking every chance on appearance of it? Besides such show stoppers like captchas. If not, I would think about another technology stack which makes it at least much harder to mess with client-server communication (proprietary encrypted binary protocol in a native code client).</p>

<p><strong>Edit</strong>: Thank you, your answers are inspiring but also made me realize that specific countermeasures cannot be made by going further into details of the game. However, that would be too much for a question on Stack Exchange. So I just want to point out the most important points:</p>

<ul>
<li>Players are exploring, developing and managing whenever they want to. Their businesses still run fine when they are offline (it is a peaceful game, no weapons involved). Only expansion and progress need the players action. Those actions are limited by:</li>
<li><em>time</em> is one of the key resources (like in EVE Online skill training). All processes in game require it. There is no point in being online 24/7. The average player should be successful already with spending not more than an hour every day in one or two sessions (<em>roughly</em>, the concept is still in development).</li>
</ul>
","<p>If people want to bot, I don't think you can really stop them.</p>

<p>You can of course implement many measures that make botting more or less of a pain. But you can only do so much before your codebase turns into a gigantic mess that's hell to maintain, error prone, and annoys legitimate users. Meanwhile the botters will always find a way to defeat your countermeasures:</p>

<ul>
<li>There's more of them than you</li>
<li>They have more free time on their hands (you have to split time between actual development and bot proofing, they can hack their bot code all day long)</li>
<li>As you create outlandish, challenging safeguards the bot authors will be further encouraged because it's fun to break your bot protection</li>
<li>If there is a black market of people commercially profiting from bots, the harder you make it to write a bot the more valuable working bots become, so you incentivize botting</li>
</ul>

<p>You will basically be trapped in an arms race with the botters, and based on logic along the lines of the above points, as well as my experience with such games, you will not be able to keep up.</p>

<p>Some game developers employ extremely aggressive anti-cheating measures: For instance, Steam will scan memory and the file system to look for hacks, and offenders can be punished by losing accounts worth hundreds of dollars. Yet there are still bots and other hacks for Steam games, and some of them even work half the time. Unlike them, you have an API that's wide open to the user, and no control over the users computer. It's an uphill battle from the start.</p>

<p>The problem you are trying to solve is essentially a Turing test: Except it is a very easy Turing test, because you cannot cheat by requiring hard AI problems like language. No matter how many heuristics you create, it would be trivial for a botter to add a little randomness to the bot's action to have it mimic almost exactly a human. It wouldn't even be very hard to have the bot watch you play for a bit, and learn how to time actions exactly like you. Then when you ban the bot, the botter posts a huge rant on the forum about how he's just a dedicated player (and maybe he <em>is</em> actually a false positive) and your core audience of hardcore players will rise up in arms against you.</p>

<h2>Make the game too fun to bot</h2>

<p>The main reason someone uses a bot is because there is a part of the game they want to skip. If they enjoyed the game and found it fun, they wouldn't have the bot play it, they'd play it themselves.</p>

<p>But if the game is so boring, why play it at all? Presumably, some parts of the game are boring and mandatory to get to parts that are fun. For instance, in MMOs everyone loves going up a level, but nobody wants to kill 42,324 dire undead poison rats to get the XP. So they let the bot grind and drop in to play the fun part.</p>

<p>This is not a criticism of you or your game, but clearly at least some players find some parts of your game tedious. You should see if you can reduce these tedious parts, and look into adding more difficult, meaningful decisions: Bots aren't good at deep strategy or lateral thinking compared to human intelligence, and besides humans enjoy making difficult game decisions.</p>

<p>From your description, I get the impression that this is a browser game similar to Travian, where there is a build queue with a single best build order and certain ""maintenance"" (such as keeping farming raids going) tasks that must be done. You say there is no conflict, but in any MMO drama and petty politics is inevitable (IMO it's the main attraction) so I'm sure your players find ways to butt heads. With these sorts of games, a lot of the tedium comes from these ""maintenance"" tasks - what players really want to do is make alliances and play the diplomacy game with rival clans, the maintenance then becomes a sort of tax where you have to wake up to an alarm at odd hours to be allowed to get into that fun diplomatic part. So cut out the tedium: Automate boring things yourself (but maybe imperfectly to keep it interesting), so that players can focus on the parts they like.</p>

<p>This approach may not always work, unfortunately. Not all players have the same tolerance to tedium or the same concept of fun. You could have a prominent mechanic that 99% of your players enjoy, but the 1% find boring. What if the 1% then start writing bots, ruining the fun for the 99%? But ultimately, it is a matter of degree. You can never remove botting completely, but you can minimize the damage.</p>

<h2>Undercut botters</h2>

<p>A lot of the really negative effects of bots come from bot authors commercializing their work. If this is the case for you, you could simply compete with the bots. Many real-time based online games already have premium features that allow time-skipping and automation (such as extended build queues). These amount to a developer-sanctioned official bot. If you have these, and price them appropriately, players will buy your premium instead of buying bots. The good news is, you are in charge of the API, so you always have a strong advantage at developing quality automation for your own game, so this time it's a losing battle for botters.</p>

<p>This will not eliminate amateur botters, or people who feel that your premium is not good value for the money, so again the effectiveness of this approach depends on the situation.</p>

<h2>Manually look for them</h2>

<p>As I said above, what you are doing is essentially a Turing test. Since interaction with humans is famously considered a difficult Turing test challenge, you can try to leverage that.</p>

<p>Manually inspect top-level players and see if you find anything suspicious. You might even be able to get away with occasionally probe them in ways restricted only to your imagination, to see if you can trick the bot into doing something it wouldn't do.</p>

<p>While it is hard to write an algorithm that will detect bots reliably, it isn't so hard for a human to learn how to spot them. I think a lot of browser games use this strategy, and it can be pretty effective. The disadvantage is that either you need to do a lot of boring work all the time, or you need to pay game masters to do regular bot patrol.</p>
","99115"
"GLSL - Declaring global variables outside of the main function scope","12242","","<p>Does it help to declare variables outside of your main function scope in GLSL? Do these variables actually get reused and is it more efficient?</p>

<p>Here is the code in question:</p>

<pre><code>varying vec2 vposition;
uniform float seed;
uniform float top;
uniform float bottom;
uniform float phi;
uniform float theta;
uniform float scaledPI;
uniform float yn;
uniform float ym;
uniform float rx;
uniform float ry;
uniform float radius;

const float PI = 3.141592653589793238462643383;

float left;
float right;
float mscaled;
float xn;
float xm;
void main() {
    float t = vposition.y * yn + ym;

    if(t &lt;= 0.0 || t &gt;= PI){
        left = phi - PI;
        right = phi + PI;
    }else{
        mscaled = scaledPI / (1 - abs(Math.cos(theta)));
        mscaled = mscaled &lt; PI ? mscaled : PI;
        left = phi - mscaled;
        right = phi + mscaled;
    }
    xn = (left - right) / ((-rx / 2.0) - (rx / 2.0));
    xm = left - ((-rx/2.0) * xn);
    float p = vposition.x * xn + xm;

    vec3 coords = vec3( sin(p) * sin(t), cos(t), cos(p) * sin(t) );
    float nv = surface( vec4( coords, seed ) );
    gl_FragColor = vec4( vec3( nv, nv, nv ), 1.0 );
}
</code></pre>
","<p>I think I get what you're trying to ask.  I assume your primary concern are the non-uniform variables defined outside of <code>main()</code>:</p>

<pre><code>float left;
float right;
float mscaled;
float xn;
float xm;
</code></pre>

<p>Let's take a look at how the GPU and GLSL work.  The GPU does not have a stack or a call activation records.  There is not a way to simulate scope or local variablaes in GLSL like a C compiler can do on most CPUs.  All that exists are the registers, which are either uniform registers, shader stage inputs, outputs, and the local register file unique to that shader invocation.</p>

<p>In other words, as there is no such thing as a function or the stack or a heap, all variables declared anywhere live in a register.  Whether they're local to some scope in GLSL or global to the whole file makes no difference.  They're just registers.</p>

<p>However, the register allocator is not part of the GLSL standard.  Different OpenGL implementations can have varying levels of quality when it comes to converting high-level GLSL code into the low-level machine code the GPU understands.  One of the more complicated parts of a compiler (GLSL or otherwise) is <em>register allocation</em>.  This is the part of the compiler that determines which registers a given variable occupies.  C has it a bit harder as it usually has to deal with very tiny register files (especially on x86) and it has to deal with register spilling (moving variables to the stack) and aliasing (saving variables back to RAM before calling functions) and odd instructions which demand the output be in a particular register (x86's <code>idiv</code> for instance).  GPUs have a large-ish register file on account of having no stack or heap, so the allocator can be simpler.</p>

<p>However, the register file is not infinite.  If you have more variables than registers supported by your hardware the compiler will have to try fit all your variables in the registers.  This usually requires some form of <em>liveness range</em> checking.  That is, if you use a variable <code>xn</code> for one calculation then never use it again, the compiler can determine this and then know that the register occupied by <code>xn</code> could be used by another variable later on, thus allowing more variables than there are registers (so long as there's not too many live variables at once).</p>

<p>The compiler might not do this, however.  It doesn't have.  Or it might do it only in some cases.  Scopes given simpler compilers a much easier problem to solve.  All the registers allocated to local function variables can be reused after that function exits because it knows the variables are dead.  Global variables have no such easy guarantee.  Hence, some less capable compilers may not optimize their lifetimes as well, and the global variables will always eat up a register.  This won't make anything <em>slower</em> but it may on some drivers limit the size of the shader you can write.</p>

<p>In general, I would highly recommend keeping all variables localized.  Keep the definition as close to the use of the variable as makes sense.  This applies to all programming languages, not just GLSL.  I would also recommend making every ""variable"" const in every case you possible can.  It can again be a hint to certain less-capable compilers that certain optimizations are possible, and more importantly, it makes your code more self-documenting and easy to maintain.</p>

<p>And of course, here's your obligatory ""just profile to test and find out for sure"" advice.  Write your shader with and without your globals and profile it. Any and all performance advice online should be mistrusted and assumed to either be steeped in supposition or out of date.</p>
","61262"
"How much to pay for artwork in an indie game?","12236","","<p>I am an indie developer and I need some detailed artwork. How much is reasonable to pay an artist for say 20 character designs? I know it depends on the artist's skills, etc, but I am wondering what to expect so that I can budget it.</p>

<p>Edit:</p>

<p>Let's say cartoon-ish art (<a href=""http://www.creativeuncut.com/gallery-01/dis-laharl1.html"">Example</a> - not necessarily in that level of detail but that kind of cartoony-art style). No 3-d modelling - The art will be used as still images in game and for promotional reasons. I'd provide a base sprite design for them to expand on and detail. </p>

<p>Also, some numbers would be nice - I like numbers. Even a range is helpful. </p>

<p>Like: expect to spend $x2 ~ $x1 for top-notch and $y2 ~ $y1 for decent quality.</p>

<p>I understand I can ask at some indie-help site but, if an artist says something like $1000 for 20 designs, I wouldn't have any idea if it's reasonable / good deal / bad idea etc.</p>
","<p>The <a href=""http://forum.deviantart.com/jobs/offers/"">DeviantArt Job Offers Forum</a> is a place where people often request such projects from designers. You can probably find proposals with prices, but from what I can tell, they're very disparate. </p>
","7426"
"Rotate vector by matrix?","12231","","<p>If I have a Vector, say (1,1), how can I rotate it around the origin (0,0)?</p>

<p>I'm working in XNA if that helps.</p>
","<p>Just multiply the vector by a rotation matrix:</p>

<pre><code>| fx |     | cos a    -sin a | | sx |
| fy |  =  | sin a    -cos a | | sy |
</code></pre>

<p>where <code>fx</code> and <code>fy</code> are final coordinates of the object after the rotation and <code>sx</code>, <code>sy</code> are starting one. Obviously <code>a</code> is the angle involved.</p>
","6553"
"Libgdx ShapeRenderer rectangles","12177","","<p>I'm trying to draw a filled rectangle in Libgdx and according to the API this should work: </p>

<p><code>shapeRenderer.begin(ShapeRenderer.ShapeType.FilledRectangle);</code></p>

<p>But it gives me an error and tells me to change <code>FilledRectangle</code> to <code>Filled</code>, <code>Point</code>or <code>Line</code>. </p>

<p>imports: <code>import com.badlogic.gdx.graphics.glutils.ShapeRenderer;</code></p>

<p>Any ideas on what is causing this?</p>
","<p>If you read <a href=""http://libgdx.badlogicgames.com/nightlies/docs/api/com/badlogic/gdx/graphics/glutils/ShapeRenderer.ShapeType.html"">the documentation</a>, you'll see that <code>ShapeRenderer.ShapeType</code> is an enum with the following values defined:</p>

<pre><code>Filled 
Line 
Point 
</code></pre>

<p>So the error message you're receiving is accurate. </p>

<p>If you want to draw a filled rectangle, choose the <code>Filled</code> enum type, then use shape rederer to draw a rectangle:</p>

<pre><code> shapeRenderer.begin(ShapeType.Filled);
 shapeRenderer.identity();
 shapeRenderer.translate(20, 12, 2);
 shapeRenderer.rotate(0, 0, 1, 90);
 shapeRenderer.rect(-width / 2, -height / 2, width, height);
 shapeRenderer.end();
</code></pre>
","58539"
"Which data structure should be used to represent voxel terrain?","12172","","<p>According to the <a href=""http://en.wikipedia.org/wiki/Voxel"">Wikipedia page</a> about voxels, ""[...] the position of a voxel is inferred based upon its position relative to other voxels (i.e., its position in the data structure that makes up a single volumetric image).""</p>

<p>How should one implement such a data structure?  I was thinking about an octree but I'm wondering if there's something else that I never heard about.</p>
","<p>First. Lets write what do we know about each voxel :</p>

<pre><code>voxel = (x, y, z, color) // or some other information
</code></pre>

<h2>General storage</h2>

<p>General way is simply this:</p>

<pre><code>set of voxels = set of (x,y,z, color)
</code></pre>

<p>Note, that triplet (x,y,z) identify each voxel uniquely, since voxel is point in space and there is no way two points occupy one place (I believe we are talking about static voxel data).</p>

<p>It should be fine for simple data. But it is by no means a fast data structure.</p>

<p>Rendering is AFAIK done by scanline algorithm. <a href=""http://www.tomshardware.com/reviews/voxel-ray-casting,2423-2.html"" rel=""nofollow noreferrer"">Tom's Hardware article on voxels has image of scanline algorithm</a>.</p>

<h2>Fast lookup</h2>

<p>If fast lookup is needed, then the fastest data structure for lookup is hash (aka array, map ...). So You have to make hash out of it. So, naively we want just fastest way to get arbitrary element:</p>

<pre><code>array [x][y][z] of (color)
</code></pre>

<ul>
<li><p>This has O(1) for looking up voxel by x,y,z coordinates. </p></li>
<li><p>Problem is, that it's space requirements are O(D^3), where D is range of each x,y and z numbers (forget Real number, since if they were Chars, which have range of 256 values, there would be 256^3 = 2^24 == 16 777 216 elements in array). </p></li>
</ul>

<p>But it depends on what You want to do with voxels. If rendering is what You want, then it is probably this array what You want. But problem of storage still remains ...</p>

<h2>If storage is the problem</h2>

<p>One method is to use RLE compression in the array. Imagine a slice of voxels (set of voxels, where voxels have one coordinate constant value .... like plane where z = 13 for example). Such <a href=""http://blog.wolfire.com/2009/11/Triangle-mesh-voxelization"" rel=""nofollow noreferrer"">slice of voxels would be looking like some simple drawing in MSPaint</a>. Voxel model, I'd say, usually occupy fraction of all the possible places (D^3 space of all possible voxels). I believe, that ""take a pair from triplet of coordinates and compress the remaining axis"" would do the trick (for example take [x][y] and for each element compress the all voxels at z axis at given x,y ... there should be 0 to few elements, RLE would do fine here):</p>

<pre><code>array [x][y] of RLE compressed z ""lines"" of voxel; each uncompressed voxel has color 
</code></pre>

<ul>
<li>It is used by Ken Silverman in his Voxlap. His <a href=""http://en.wikipedia.org/wiki/RLE_Compression"" rel=""nofollow noreferrer"">RLE compression</a> might be differend from mine variation.</li>
<li>Carmack mentioned doing RLE compression on voxels somewhere too. Btw, <a href=""http://www.gamers.org/dEngine/quake/papers/ddjpvs.html"" rel=""nofollow noreferrer"">John Carmack optimized PVS in Quake by compressing it by RLE</a>.</li>
<li>It might not be best way to store arbitrary voxel data, like this one.</li>
</ul>

<p>Other method to solve storage problem would be instead of array using tree data structure: </p>

<pre><code>tree data structure  = recursively classified voxels
for octrees: recursively classified by which octant does voxel at (x,y,z) belong to
</code></pre>

<ul>
<li>Octree, as mentioned by Nick. It should compress voxels. Octree has even a decent speed for lookup, I guess it is some O(log N), where N is number of voxels.</li>
<li>Octree should be able to store decently arbitrary voxel data.</li>
</ul>

<p>If voxels are some simplistic heightmap You might store just that. Or You might store parameters to function which generates the heightmap, aka procedurally generate it ...</p>

<p>And of course You can combine all possible approaches. But don't overdo it, unless You test that Your code works and measure that it is REALLY faster (so it is worth the optimization).</p>

<h2>TL;DR</h2>

<p>Other than Octrees is RLE compression with voxels, google ""voxlap"", ""ken silverman"" ...</p>

<h2>Resources</h2>

<p>There is list of <a href=""https://web.archive.org/web/20120331083615/http://www.jonof.id.au/forum/index.php?topic=1381.0"" rel=""nofollow noreferrer"">resources and discussion on how to make fast voxel renderer, includes papers and source code</a>.</p>
","17120"
"How can I completely hide and protect strings from the player in Unity?","12162","","<p>I have been using Unity to create a 2D game which will be completely offline (which is the problem), the game-play needs you to enter certain strings at certain levels and Unity compiles to DLLs, which can be easily reverse engineered, so is there a way to protect those strings (the game is offline so I can't retrieve from other source)?</p>

<p>The game relies heavily on those strings, and yes I'm aware of Obfuscation but I want something more robust. And I know that the easy way out would be doing everything online from a data-source but I was wondering if it's possible.</p>

<p>It can be decompiled like this:
<a href=""https://i.stack.imgur.com/LGXMB.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/LGXMB.png"" alt=""enter image description here""></a></p>
","<p>Do not store those strings, store the (cryptographic) hash of them.</p>

<p>A (cryptographic) hash function, like encryption, is a way to turn a string into ""gibberish"" (called hash), but unlike encryption, you cannot get the original string from this hash (unless you can brute-force it or the hash function is broken). Most (if not all) hash functions takes a string of arbitrary length and returns a string of a constant length (depends on the function).</p>

<p>How do you check that a string that the user has entered is the correct one? Since you cannot get the valid string from the hash, the only thing you can do is to hash the user's guess and compare it to the correct hash.</p>

<p>Warning (by Eric Lippert): DO NOT USE the built in function <code>GetHashCode</code> as such a function - its result can differ between different .NET versions and platforms, making your code work only on specific .NET framework versions and platform.</p>
","151365"
"Road / river generation on 2d grid map","12156","","<p>This is a newbie question, but here it goes:</p>

<p>My map is a 2d grid, and I want to generate roads and rivers. The route from the starting to ending point must not be the optimal route in number of tiles. Instead, they should have a certain level of randomness (turns).</p>

<p>Is there a standard algorithm for this kind of thing?</p>

<p>Cheers!</p>

<p><strong>UPDATE:</strong></p>

<p>This is the result of playing with weights on the grid, and applying a shortest path algorithm (Bellman-Ford) using the jgrapht library. I went with Donutz' answer after all.</p>

<p><a href=""http://pastebin.com/AGQGK5ik"">http://pastebin.com/AGQGK5ik</a></p>
","<p>You can generate the optimal path using A*, then distort it with midpoint displacement. </p>

<p><img src=""https://i.stack.imgur.com/7wBFi.gif"" alt=""enter image description here""></p>

<p>This will ensure your endpoints are met and allow you to control the randomness to a great degree. For example, I would not randomize roads as much as rivers. Whatever intelligence is building roads typically attempts to be optimal about it.</p>

<p>Take care to ensure that if your map has obstacles, you check after each iteration that you're not crossing through those obstacles. </p>

<p>Another method would be to generate <a href=""http://en.wikipedia.org/wiki/Perlin_noise"" rel=""nofollow noreferrer"">Perlin noise</a> after finding the optimal path, then shift your points based on the noise generated. For example, using this noise:</p>

<p><img src=""https://i.stack.imgur.com/ky23q.jpg"" alt=""enter image description here""></p>

<p>Then show with the optimal path in red and the shifted path in blue:</p>

<p><img src=""https://i.stack.imgur.com/jDiGv.png"" alt=""enter image description here""></p>

<p>Notice how the shifted path has ""settled"" into the darker areas of the noise. The same way a river might flow through a valley. </p>

<p>One benefit of the Perlin noise choice is you can factor in your obstacles and avoid them as part of the algorithm.</p>
","31264"
"How can I design good continuous (seamless) tiles?","12127","","<p>I have trouble designing tiles so that when assembled, they <strong>don't</strong> look like tiles, but look like a homogeneous thing. For example, see the image below:</p>

<p><img src=""https://i.stack.imgur.com/8j5no.jpg"" alt=""enter image description here""></p>

<p>Even though the main part of the grass is only one tile, you don't ""see"" the grid; you know where it is if you look a bit carefully, but it is not obvious. Whereas when I design tiles, you can only see ""oh, jeez, 64 times the same tile,"" like in this image:</p>

<p><img src=""https://i.stack.imgur.com/Sv2dJ.png"" alt=""enter image description here"">
(I took this from another GDSE question, sorry; not be critical of the game, but it proves my point. And actually has better tile design that what I manage, anyway.)</p>

<p>I think the main problem is that I design them so they are independent, there is no junction between two tiles if put closed to each other. I think having the tiles more ""continuous"" would have a smoother effect, but can't manage to do it, it seems overly complex to me.</p>

<p>I think it is probably simpler than I think once you know how to do it, but couldn't find a tutorial on that specific point. Is there a known method to design continuous / homogeneous tiles? (My terminology might be totally wrong, don't hesitate to correct me.)</p>
","<p><em>Disclaimer: I'm not an artist so this is just programmer's art knowledge.</em></p>

<p>You're having the grid effect in your example mostly because of that lighter patch of grass on the bottom edge of the tile:</p>

<p><img src=""https://i.stack.imgur.com/no9fq.png"" alt=""enter image description here""></p>

<p>Details like that that are easily recognizable instantly give it away that you're just repeating the same tile.</p>

<p>Check <strong><a href=""http://psd.tutsplus.com/articles/how-a-turn-a-texture-into-a-seamlessly-tiled-background/"" rel=""nofollow noreferrer"">this article</a></strong> which has a lot of useful tips on the subject. In particular, using Photoshop:</p>

<ul>
<li>Use the Patch Tool to get rid of glaring details.</li>
<li>Use the Doge or Burn tool to get uniform luminosity everywhere.</li>
<li>Make the edges seamless by offseting the image and then using the Patch Tool to blend the edges together. I've also seen people duplicate and mirror the image four times before for this purpose.</li>
</ul>

<p>Also in the image you linked there seems to be an implementation problem too because when zooming in on the image you can see some gaps between tiles:</p>

<p><img src=""https://i.stack.imgur.com/QBM7r.png"" alt=""enter image description here""></p>
","26154"
"How to animate objects with bobbing up and down motion in Unity?","12116","","<p>I have created a 2D platform game with Unity and C# where I have collectable items that can be picked up by the player. What I want is to give the items more focus by having them bobbing up and down.</p>

<p>I came up with the following version:</p>

<pre><code>Vector2 floatY;

public float FloatStrength; // Set strength in Unity

void Update () {
    floatY = transform.position;
    floatY.y = (Mathf.Sin(Time.time) * FloatStrength);
    transform.position = floatY;
}
</code></pre>

<p>But, this makes the object float in the middle of the level instead of where the object is positioned. How can I fix that?</p>

<p>Here is a screenshot of the prototype of the game:</p>

<p><img src=""https://i.stack.imgur.com/cBztB.png"" alt=""enter image description here""></p>

<p>The player can collect the wood stumps which should be bobbing up and down in space just above the ground.</p>
","<p>You have a pretty simple solution. What your problem here is that you are not preserving the original y position. Essentially, you need to store the original y position in a variable, that would look like this: (Don't forget to set the variable in the Start() function.)</p>

<pre><code>Vector2 floatY;
float originalY;

public float floatStrength;

void Start ()
{
    this.originalY = this.transform.position;
}

void Update () {
    floatY = transform.position;
    floatY.y = (Mathf.Sin(Time.time) * floatStrength);
    transform.position = floatY;
}
</code></pre>

<p>After that, I suggest that instead of directly setting the y value of the floatY to <code>Mathf.Sin(Time.time) * floatStrength</code>, you set it based on the sum of that value and the original transform position. The final code should look something like this:</p>

<pre><code>Vector2 floatY;
float originalY;

public float floatStrength;

void Start ()
{
    this.originalY = this.transform.position;
}

void Update () {
    floatY = transform.position;
    floatY.y = originalY + (Mathf.Sin(Time.time) * floatStrength);
    transform.position = floatY;
}
</code></pre>

<p>Finally, instead of storing floatY as a Vector, you could store it as a float. Alternatively, you could use <code>transform.position</code> directly, doing something like this:</p>

<pre><code>Vector2 floatY;
float originalY;

public float floatStrength;

void Start ()
{
    this.originalY = this.transform.position;
}

void Update () {
    /* Old code:
    floatY = transform.position;
    floatY.y = originalY + (Mathf.Sin(Time.time) * floatStrength);
    transform.position = floatY;
    */
    transform.position = new Vector2(transform.position.x, 
        originalY + (Math.Sinf(Time.time) * floatStrength));
}
</code></pre>

<p>Finally, the last step is to do some minor refactoring as to remove some errors that have popped up along the way. <code>Math.Sin</code> (Note: not <code>Math.Sinf</code>) yields a <code>double</code> instead of the desired <code>float</code>, so we have to explicitly convert that value. Next, we can remove the <code>Vector2 floatY</code> completely. Note that this would need to actually be a Vector3 to store <code>transform.position</code>, as that also has a <code>z</code> component, if we were to actually have kept using that. Finally, we must fix that same problem in the <code>Update()</code> function, and change:</p>

<pre><code>    transform.position = new Vector2(transform.position.x, 
        originalY + (Math.Sinf(Time.time) * floatStrength));
</code></pre>

<p>to:</p>

<pre><code>    transform.position = new Vector3(transform.position.x,
        originalY + (Math.Sinf(Time.time) * floatStrength), transform.position.z);
</code></pre>

<p>That code segment does not implement the other changes that I mentioned. In the end the complete code is as follows:</p>

<pre><code>using UnityEngine;
using System;
using System.Collections;

public class FloatBehavior : MonoBehaviour
{
    float originalY;

    public float floatStrength = 1; // You can change this in the Unity Editor to 
                                    // change the range of y positions that are possible.

    void Start()
    {
        this.originalY = this.transform.position.y;
    }

    void Update()
    {
        transform.position = new Vector3(transform.position.x,
            originalY + ((float)Math.Sin(Time.time) * floatStrength),
            transform.position.z);
    }
}
</code></pre>

<p>Note that this code can be attached to an object either through <code>New Object &gt;&gt; 2D &gt;&gt; Sprite</code> and then by adding this code as a script, or through the following code programmatically:</p>

<pre><code>    GameObject object = new GameObject();
    object.name = ""Floating Box"";
    object.AddComponent&lt;SpriteRenderer&gt;().sprite = SOME_SPRITE;
    object.AddComponent&lt;FloatBehavior&gt;();
</code></pre>

<p>Here's an example of what this could look like:</p>

<p><img src=""https://i.stack.imgur.com/fkrPM.gif"" alt=""Sample Image illustrating code""></p>
","96880"
"Random number hlsl","12112","","<p>How do you generate a random number in HLSL?</p>

<p>I'm asking because I want to try <a href=""http://madebyevan.com/webgl-path-tracing/"">gpu ray tracing</a>.  You need to generate random directions in a pixel shader.  So I want <code>randFloat()</code>, where the result is a random number between -1 and +1.</p>

<p>Also, what is the deal with the hlsl <a href=""http://msdn.microsoft.com/en-us/library/bb509629%28v=vs.85%29.aspx"">noise</a> instruction?  The docs say it was <em>removed</em> from HLSL 2.0 and up. <strong>Why</strong>?</p>

<p>I read about an approach where you fill a texture with random values, then have a texture coordinate in each vertex that has an index into that texture.  But that's <em>per vertex</em>, I need an instruction I can call in the pixel shader. Plus this approach requires ""reseeding"" the per-vertex texcoords if you want different values each frame, and that requires a vertex buffer update each frame (which can be expensive!)</p>

<p>With detail, how can you cheaply generate a random number on the GPU?</p>
","<p>Pseudo random numbers in a pixel shader aren't easy to obtain. A pseudo random number generator on the CPU will have some state which it both reads from and writes to, on every call to the function. You can't do that in a pixel shader.</p>

<p>Here's some options:</p>

<ol>
<li><p>Use a compute shader instead of a pixel shader - they support read-write access to a buffer, so you can implement any standard PRNG.</p></li>
<li><p>Sample from one or more textures containing random data, based on a parameter like screen space position. You can also do some maths on the position before using it to look up into the texture, which should let you reuse the texture if the maths involves a random-per-draw-call shader constant.</p></li>
<li><p>Find some mathematical function of screen space position, that gives results that are 'random enough'.</p></li>
</ol>

<p>A quick google search found <a href=""http://obge.paradice-insight.us/wiki/Includes_%28Effects%29"">this page</a> with these functions:</p>

<pre><code>float rand_1_05(in float2 uv)
{
    float2 noise = (frac(sin(dot(uv ,float2(12.9898,78.233)*2.0)) * 43758.5453));
    return abs(noise.x + noise.y) * 0.5;
}

float2 rand_2_10(in float2 uv) {
    float noiseX = (frac(sin(dot(uv, float2(12.9898,78.233) * 2.0)) * 43758.5453));
    float noiseY = sqrt(1 - noiseX * noiseX);
    return float2(noiseX, noiseY);
}

float2 rand_2_0004(in float2 uv)
{
    float noiseX = (frac(sin(dot(uv, float2(12.9898,78.233)      )) * 43758.5453));
    float noiseY = (frac(sin(dot(uv, float2(12.9898,78.233) * 2.0)) * 43758.5453));
    return float2(noiseX, noiseY) * 0.004;
}
</code></pre>
","32688"
"What data-type should I use for in-game currency?","12111","","<p>In a simple business simulation game (built in Java + Slick2D), should a player's current amount of money be stored as a <code>float</code> or an <code>int</code>, or something else?</p>

<p>In my use-case, most transactions will use cents ($0.50, $1.20, etc.), and simple interest rate calculations will be involved.</p>

<p>I've seen people saying you should never use <code>float</code> for currency, as well as people saying you should never use <code>int</code> for currency. I feel like I should use <code>int</code> and round any necessary percentage calculations. What should I use?</p>
","<p>You can use <code>int</code>, and consider everything in cents.  $1.20 is just 120 cents.  At display, you put the decimal in where it belongs.</p>

<p>Interest calculations would just be either truncated or rounded up.  So</p>

<pre><code>newAmt = round( 120 cents * 1.04 ) = round( 124.8 ) = 125 cents
</code></pre>

<p>This way you don't have messy decimals always sticking around.  You could <a href=""http://en.wikipedia.org/wiki/Salami_slicing"">get rich by adding the unaccounted for money (due to round-downs) into your own bank account</a></p>
","46005"
"Implementing a camera / viewport to a 2D game","12094","","<p>What is the most practical way to implement camera/viewport to a 2D-game?</p>

<p>I've read, that I should store the object <em>world position</em> instead of position relative to the screen?</p>

<p><strong>Current situation:</strong></p>

<p>I have implemented a simple 2D-game where I load objects and levels from XML-files. Currently the level XML-file looks like this:</p>

<pre><code>&lt;map&gt;
   &lt;tile obj=""ground"" x=""0"" y=""555"" /&gt;
   &lt;tile obj=""ground"" x=""16"" y=""555"" /&gt;
   &lt;tile obj=""ground"" x=""32"" y=""555"" /&gt;
   ...
&lt;/map&gt;
</code></pre>

<p>All objects have a 2d-vector ""position"" storing their current location on the screen.</p>

<p><strong>What I want it to be:</strong></p>

<p><img src=""https://i.stack.imgur.com/plY5Q.png"" alt=""Viewport/gameworld illustration""></p>

<p>In the picture:</p>

<ul>
<li>Camera is either 800x600 or 640x480</li>
<li>Blocks and sprites are 16x16 pixels.</li>
<li>World size may vary</li>
<li>The coordinates probably should be normalized relative to the world, not to the screen?</li>
<li>Viewport position relative to player's x, y and moves when the player reaches camera dead zone (similar to <a href=""http://www.youtube.com/watch?v=89TRXUm8jMI"" rel=""noreferrer"">this video</a>).</li>
</ul>

<p>I'm asking pseudo examples / articles, but if you need to know what I'm using for the development: SDL &amp; C/C++.</p>
","<p>You need to have every object positioned relative to the world instead of the screen. Your camera should also have its own world coordinates so it can be drawn at a relative position in the world. It may also be convenient to have your camera follow an object, so wherever the object is, the camera just uses its coordinates. Typically the camera's coordinates will position it from the upper left corner. This means the camera would have a world position of approximately (0,24) in the <a href=""https://i.imgur.com/kBiSn.png"" rel=""nofollow noreferrer"">picture</a>.</p>

<p>As for actually drawing the objects the camera can ""see"", you must draw all objects relative to the camera's world coordinates. To compute an object's screen position relative to the camera, simply do:</p>

<pre><code>int screenX, screenY; //screen position of the object being drawn

screenX = object.x-camera.x;
screenY = object.y-camera.y;
</code></pre>

<p>Obviously some objects are not actually visible to the camera, so you may want to implement a view culling system.</p>
","46230"
"Hue, saturation, brightness, contrast effect in hlsl","12090","","<p>I am new to pixel shader, and I am trying to write a simple brightness, contrast, hue, saturation effect. I have written a shader for it but I doubt that my shader is not providing me correct result, Brightness, contrast, saturation is working fine, problem is with hue. if I apply hue between -1 to 1, it seems to be working fine, but to make things more sharp, I need to apply hue value between -180 and 180, like we can apply hue in Paint.NET.</p>

<p>Here is my code.</p>

<pre><code>// Amount to shift the Hue, range 0 to 6
float Hue;
float Brightness;
float Contrast;
float Saturation;
float Alpha;

sampler Samp : register(S0);

// Converts the rgb value to hsv, where H's range is -1 to 5
float3 rgb_to_hsv(float3 RGB)
{
    float r = RGB.x;
    float g = RGB.y;
    float b = RGB.z;

    float minChannel = min(r, min(g, b));
    float maxChannel = max(r, max(g, b));

    float h = 0;
    float s = 0;
    float v = maxChannel;

    float delta = maxChannel - minChannel;

    if (delta != 0)
    {
        s = delta / v;

        if (r == v) h = (g - b) / delta;
        else if (g == v) h = 2 + (b - r) / delta;
        else if (b == v) h = 4 + (r - g) / delta;
    }

    return float3(h, s, v);
}

float3 hsv_to_rgb(float3 HSV)
{
    float3 RGB = HSV.z;

    float h = HSV.x;
    float s = HSV.y;
    float v = HSV.z;

    float i = floor(h);
    float f = h - i;

    float p = (1.0 - s);
    float q = (1.0 - s * f);
    float t = (1.0 - s * (1 - f));

    if (i == 0) { RGB = float3(1, t, p); }
    else if (i == 1) { RGB = float3(q, 1, p); }
    else if (i == 2) { RGB = float3(p, 1, t); }
    else if (i == 3) { RGB = float3(p, q, 1); }
    else if (i == 4) { RGB = float3(t, p, 1); }
    else /* i == -1 */ { RGB = float3(1, p, q); }

    RGB *= v;

    return RGB;
}

float4 mainPS(float2 uv : TEXCOORD) : COLOR
{
    float4 col = tex2D(Samp, uv);

    float3 hsv = rgb_to_hsv(col.xyz);

    hsv.x += Hue;
    // Put the hue back to the -1 to 5 range
    //if (hsv.x &gt; 5) { hsv.x -= 6.0; }
    hsv = hsv_to_rgb(hsv);
    float4 newColor = float4(hsv,col.w);

    float4 colorWithBrightnessAndContrast = newColor;

    colorWithBrightnessAndContrast.rgb /= colorWithBrightnessAndContrast.a;
    colorWithBrightnessAndContrast.rgb = colorWithBrightnessAndContrast.rgb + Brightness;
    colorWithBrightnessAndContrast.rgb = ((colorWithBrightnessAndContrast.rgb - 0.5f) * max(Contrast + 1.0, 0)) + 0.5f;  
    colorWithBrightnessAndContrast.rgb *= colorWithBrightnessAndContrast.a;

    float greyscale = dot(colorWithBrightnessAndContrast.rgb, float3(0.3, 0.59, 0.11)); 
    colorWithBrightnessAndContrast.rgb = lerp(greyscale, colorWithBrightnessAndContrast.rgb, col.a * (Saturation + 1.0));       
    return colorWithBrightnessAndContrast;
}

technique TransformTexture {
    pass p0 {
        PixelShader = compile ps_2_0 mainPS();
    }
}
</code></pre>

<p>Please If anyone can help me learning what am I doing wrong or any suggestions?
Any help will be of great value.</p>

<p>EDIT:
Images of the effect at hue 180:</p>

<p><img src=""https://i.stack.imgur.com/qa1wp.jpg"" alt=""effect"">
On the left hand side, the effect I got with @teodron answer. On the right hand side, The effect Paint.NET gives and I'm trying to reproduce.</p>
","<pre><code>Finally I figured it out.
This shader worked for me.

// Amount to shift the Hue, range 0 to 6
float Hue;
float Brightness;
float Contrast;
float Saturation;

sampler Samp : register(S0);
float3x3 QuaternionToMatrix(float4 quat)
{
    float3 cross = quat.yzx * quat.zxy;
    float3 square= quat.xyz * quat.xyz;
    float3 wimag = quat.w * quat.xyz;

    square = square.xyz + square.yzx;

    float3 diag = 0.5 - square;
    float3 a = (cross + wimag);
    float3 b = (cross - wimag);

    return float3x3(
    2.0 * float3(diag.x, b.z, a.y),
    2.0 * float3(a.z, diag.y, b.x),
    2.0 * float3(b.y, a.x, diag.z));
}

const float3 lumCoeff = float3(0.2125, 0.7154, 0.0721);

float4 mainPS(float2 uv : TEXCOORD) : COLOR
{
    float4 outputColor = tex2D(Samp, uv);
    float3 hsv; 
    float3 intensity;           
        float3 root3 = float3(0.57735, 0.57735, 0.57735);
        float half_angle = 0.5 * radians(Hue); // Hue is radians of 0 tp 360 degree
        float4 rot_quat = float4( (root3 * sin(half_angle)), cos(half_angle));
        float3x3 rot_Matrix = QuaternionToMatrix(rot_quat);     
        outputColor.rgb = mul(rot_Matrix, outputColor.rgb);
        outputColor.rgb = (outputColor.rgb - 0.5) *(Contrast + 1.0) + 0.5;  
        outputColor.rgb = outputColor.rgb + Brightness;         
        intensity = float(dot(outputColor.rgb, lumCoeff));
        outputColor.rgb = lerp(intensity, outputColor.rgb, Saturation );            

    return outputColor;
}
technique TransformTexture {
    pass p0 {
        PixelShader = compile ps_2_0 mainPS();
    }
}
</code></pre>
","29050"
"OpenGL ES 2 on Android: native window","12065","","<p>According to OGLES specification, we have the following definition:</p>

<pre><code>EGLSurface eglCreateWindowSurface(EGLDisplay display,
                                  EGLConfig config,
                                  NativeWindowType native_window,
                                  EGLint const * attrib_list)
</code></pre>

<p>More details, here: <a href=""http://www.khronos.org/opengles/documentation/opengles1_0/html/eglCreateWindowSurface.html"" rel=""nofollow"">http://www.khronos.org/opengles/documentation/opengles1_0/html/eglCreateWindowSurface.html</a></p>

<p>And also by definition:</p>

<pre><code>int32_t ANativeWindow_setBuffersGeometry(ANativeWindow* window, int32_t width, 
                                         int32_t height, int32_t format);
</code></pre>

<p>More details, here: <a href=""http://mobilepearls.com/labs/native-android-api"" rel=""nofollow"">http://mobilepearls.com/labs/native-android-api</a></p>

<p>I am running Android Native App on OGLES 2 and debugging it in a Samsung Nexus device. For setting up the 3D scene graph environment, the following variables are defined:</p>

<pre><code>struct android_app {
    ...
    ANativeWindow* window;
};
android_app* mApplication;
...
mApplication=&amp;pApplication;
</code></pre>

<p>And to initialize the App, we run the commands in the code:</p>

<pre><code>ANativeWindow_setBuffersGeometry(mApplication-&gt;window, 0, 0, lFormat);
mSurface = eglCreateWindowSurface(mDisplay, lConfig, 
                                  mApplication-&gt;window, NULL);
</code></pre>

<p>Funny to say is that, the command ANativeWindow_setBuffersGeometry behaves as expected and works fine according to its definition, accepting all the parameters sent to it. But the eglCreateWindowSurface does no accept the parameter mApplication->window, as it should accept according to its definition. Instead, it looks for the following input:</p>

<pre><code>EGLNativeWindowType hWnd;
mSurface = eglCreateWindowSurface(mDisplay,lConfig,hWnd,NULL);
</code></pre>

<p>As an alternative, I considered to use instead:</p>

<pre><code>NativeWindowType hWnd=android_createDisplaySurface();
</code></pre>

<p>But debugger says:</p>

<pre><code>Function 'android_createDisplaySurface' could not be resolved
</code></pre>

<p>Is 'android_createDisplaySurface' compatible only for OGLES 1 and not for OGLES 2?</p>

<p>Can someone tell if there is a way to convert mApplication->window? In a way that the data from the android_app get accepted to the window surface?</p>
","<p>Are you sure you are using egl.h header from Android NDK?
In Android NDK EGLNativeWindowType is defined in eglplatform.h file (it is included from egl.h):</p>

<pre><code>#elif defined(__ANDROID__) || defined(ANDROID)
#include &lt;android/native_window.h&gt;
...
typedef struct ANativeWindow*           EGLNativeWindowType;
</code></pre>

<p>As you can see EGLNativeWindowType has correct type - ANativeWindow*</p>
","27036"
"Cocos2d-x Finding if a CCPoint is inside a sprite rect","12064","","<p>I'm afraid that I'm missing something. This is what I've done:</p>

<ol>
<li>I've made a scene using layers (Gimp), then I've exported the layers
with the image size, that way I thought would be more easy to add
the images and have the offsets in the right way.</li>
<li>I made a spritesheet with TexturePacker, trimming the images.</li>
</ol>

<p>Then I have in the plist file something like:</p>

<pre><code>&lt;dict&gt;
   &lt;key&gt;frame&lt;/key&gt;
   &lt;string&gt;{{1028,360},{326,382}}&lt;/string&gt;
   &lt;key&gt;offset&lt;/key&gt;
   &lt;string&gt;{-316,110}&lt;/string&gt;
   &lt;key&gt;rotated&lt;/key&gt;
   &lt;false/&gt;
   &lt;key&gt;sourceColorRect&lt;/key&gt;
   &lt;string&gt;{{33,83},{326,382}}&lt;/string&gt;
   &lt;key&gt;sourceSize&lt;/key&gt;
   &lt;string&gt;{1024,768}&lt;/string&gt;
&lt;/dict&gt;
</code></pre>

<p>Then in my code I've made a CCSprite:</p>

<pre><code>granero = CCSprite::createWithSpriteFrameName(""04_Granero.png"");
capaGrafica-&gt;addChild(granero);
pDirector-&gt;getTouchDispatcher()-&gt;addTargetedDelegate(this, 0, false);
</code></pre>

<p>And the ccTouchBegan:</p>

<pre><code>bool Escena00::ccTouchBegan(CCTouch* touch, CCEvent* event)
{
    // This point has the touch location info
    CCPoint touchPoint = CCPoint(touch-&gt;getLocationInView().x, touch-&gt;getLocationInView().y);

    // Now I want to set a rect, where a little house in the screen is located
    CCRect *graneroRect = new CCRect(granero-&gt;getOffsetPosition().x, granero-&gt;getOffsetPosition().y,granero-&gt;getTextureRect().size.width,granero-&gt;getTextureRect().size.height);

    if (graneroRect-&gt;containsPoint(touchPoint))
    {
        CCLog(""The little house in the left was touched"");
    }

    return true;
}
</code></pre>

<p>If you take a look now to the plist extract that I've posted you'll read the ""sourceColorRect"" key. Those coords are the right numbers that I need to use to create my CCRect (33,83, 326, 382). With those numbers I've been able to correctly get the touch over the little house.
However, I don't want to use those numbers with a ""hard way"".
Using granero->getOffsetPositionX(), I get the ""33"" number, and using the ""getTextureRect()"" I can get the third and fourth numbers (size of the rect).
The big issue is the getOffsetPositionY(), or any ""y"" coordinate. I can't read the ""83"" number. How can I solve this? Or what am I doing wrong?</p>

<p>Thanks a lot in advance.</p>
","<p>I'll answer my question, but @akg is the answer that guided me. I've made the code in cocos2d-x, and I didn't used boundingBox() method. Hope this helps someone, :) I didn't found something like this in other site, so I hope not be doing something wrong...</p>

<pre><code>bool SceneGame::ccTouchBegan(CCTouch* touch, CCEvent* event)
{
    CCPoint touchPoint = CCDirector::sharedDirector()-&gt;convertToGL(touch-&gt;getLocationInView());

    touchPoint = littleHouse-&gt;convertToNodeSpace(touchPoint);

    CCRect *littleHouseRect= new CCRect(littleHouse-&gt;getOffsetPosition().x
                                    ,littleHouse-&gt;getOffsetPosition().y
                                    ,littleHouse-&gt;getTextureRect().size.width
                                    ,littleHouse-&gt;getTextureRect().size.height);

    if (littleHouseRect-&gt;containsPoint(touchPoint))
    {
        CCLog(""The little house in the left was touched"");
    }

    return true;
}
</code></pre>
","60073"
"DirectX11, how do I manage and update multiple shader constant buffers?","12057","","<p>Alright, I'm having a hard time grasping how constant buffers are bound to a pipeline stage and updated. I understand that DirectX11 can have up to 15 shader-constant buffers per stage and each buffer can hold up to 4096 constants. However, I don't understand whether the ID3D11Buffer COM used to interact with the constant buffers is just a mechanism (or handle) used for fill these buffer slots or if the object actually references a particular instance of buffer data that is pushed back and forth between the GPU and CPU.</p>

<p>I think my confusion on the topic is the cause of a problem I'm having using two different constant buffers.</p>

<p>Here is some example shader code.</p>

<pre><code>cbuffer PerFrame : register(b0) {
    float4x4 view;
};

cbuffer PerObject : register(b1) {
    float4x4 scale;
    float4x4 rotation;
    float4x4 translation;
};
</code></pre>

<p>The way my code is organized, the camera will be handling updating the relevant per frame data and GameObjects will be updating their own per object data. Both classes have their own ID3D11Buffer that is used to do this (Using a hub architecture, so one GameObject class will handle the rendering of all the instanced GameObjects in the world).</p>

<p>The problem is I can only get one updated at a time, depending on the slot and I presume the update order one buffer gets filled while the other gets zero'd out.</p>

<p>This is essentially my code. Both classes use identical update logic.</p>

<pre><code>static PerObjectShaderBuffer _updatedBuffer; // PerFrameShaderBuffer if Camera class
_updatedBuffer.scale       = _rScale;
_updatedBuffer.rotation    = _rRotation;
_updatedBuffer.translation = _rTranslation;
pDeviceContext-&gt;UpdateSubresource(pShaderBuffer, 0 , 0, &amp;_updatedBuffer, 0, 0);

pDeviceContext-&gt;VSSetShader(pVShader-&gt;GetShaderPtr(), 0, 0);
pDeviceContext-&gt;PSSetShader(pPShader-&gt;GetShaderPtr(), 0, 0);
pDeviceContext-&gt;VSSetConstantBuffers(1, 1, &amp;pShaderBuffer);
pDeviceContext-&gt;IASetVertexBuffers(0, 1, &amp;pVertexBuffer, &amp;vStride, &amp;_offset );
pDeviceContext-&gt;IASetPrimitiveTopology(topologyType);
pDeviceContext-&gt;Draw(bufSize, 0);
</code></pre>

<p>My main questions are -</p>

<ul>
<li>Do I need to set or bind the ShaderBuffer in order to update it with the UpdateSubresource call? (Meaning manipulate it only when it is in the pipeline) Or is it a blob of data that will be sent in with the VSSetConstantBuffer call? (Meaning the order of binding and updating data doesn't matter, I can update it in the pipeline or somehow on the cpu)</li>
<li>When setting or binding the buffer, do I need to reference slot 0 to update the PerFrame buffer and slot 1 to update the PerObject buffer? Could some kind of confusion with this call in my code cause all the buffers to be overwritten?</li>
<li>How does D3D11 know which buffer I want to update or map? Does it know from the ID3D11Buffer COM used?</li>
</ul>

<p>Edit -</p>

<p>Changed the constant buffer register tags in the example above. Using (cb#) instead of (b#) was affecting the buffers from updating correctly for some reason. Not sure where I picked up the original syntax or if it's valid at all, but it appears to of been my main problem.</p>
","<p>The ID3D11Buffer references an actual chunk of memory that holds your data, whether it's a vertex buffer, constant buffer, or whatever.</p>

<p>Constant buffers work the same way as vertex buffers and other kinds of buffers.  Namely, the data in them isn't accessed by the GPU until it actually renders the frame, so the buffer has to remain valid until the GPU is done with it.  You should double-buffer each constant buffer, so you have one copy to update for the next frame, and one copy for the GPU to read while rendering the current frame.  This is similiar to how you would do dynamic vertex buffers for a particle system or suchlike.</p>

<p>The <code>register(cb0)</code>, <code>register(cb1)</code> settings in the HLSL correspond with the slots in VSSetConstantBuffers.  When you update the per-frame constants you'd do <code>VSSetConstantBuffers(0, 1, &amp;pBuffer)</code> to set CB0 and when you update the per-object ones you'd do <code>VSSetConstantBuffers(1, 1, &amp;pBuffer)</code> to set CB1.  Each call updates only the buffers referred to by the start/count parameters, and doesn't touch the others.</p>

<p>You do not need to bind the buffer to update it with UpdateSubresource.  In fact, it <em>shouldn't</em> be bound when you update it, or this may force the driver to make extra memory copies internally (see the <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/ff476486%28v=vs.85%29.aspx"">MSDN page</a> for UpdateSubresource, notably the remarks on contention about a page down).</p>

<p>I'm not sure what you mean by ""How does D3D11 know which buffer I want to update or map?""  It updates or maps the one whose pointer you passed in.</p>
","18029"
"What's the best way to create animations when doing Android development?","12020","","<p>I'm trying to create my first Android game and I'm currently trying to figure out (with someone that will do the drawings and another programmer) what the best way to create animation is. (Animations such as a character moving, etc.)</p>

<p>At first, the designer said that she could draw objects/characters and animate them with flash so she didn't have to draw every single frame of an action. The other programmer and I don't know Flash too much so I suggested extracting all the images from the Flash animation and making them appear one after the other when the animation is to start.</p>

<p>He said that would end up taking too much resource on the CPU and I tend to agree, but I don't really see how we're supposed to make smooth animations without it being too hard on the hardware and, if possible, not have the designer draw every single frame on Adobe Illustrator.</p>

<p>Can an experienced Android game developper help me balance this out so we can move on to other parts of the game as I have no idea what the best way to create animations is.</p>
","<p>If you're considering 2D animation, rendering one sprite and then another will not be a problem for the device (unless your sprites are huge).</p>

<p>Below is a typical animation sprite that is the first one I found with a little searching. This is a commonly used technique and there are lots of websites that offer free (and otherwise, always check the license) spritesheets.</p>

<p><img src=""https://i.stack.imgur.com/xr2Za.png"" alt=""Image source: [here](http://gaminggroundzero.com/?page_id=31)""></p>

<p>Image + author source: <a href=""http://gaminggroundzero.com/?page_id=31"" rel=""nofollow noreferrer"">here</a></p>

<p>The green is set as the transparent colour of the image so that you don't have any unwanted areas of colour. You will need to know the coordinates of each animation in the animation sequence in the spritesheet in order to play them.</p>

<p>For Android, we can take a look at an open source game engine by Chris Pruett (formerly of Google) called <a href=""http://replicaisland.net/"" rel=""nofollow noreferrer"">Replica Island</a>. The source code is available, and we can look at his <a href=""http://code.google.com/p/replicaisland/source/browse/trunk/src/com/replica/replicaisland/SpriteAnimation.java"" rel=""nofollow noreferrer"">SpriteAnimation.java</a> and <a href=""http://code.google.com/p/replicaisland/source/browse/trunk/src/com/replica/replicaisland/SpriteComponent.java"" rel=""nofollow noreferrer"">SpriteComponent.java</a>.</p>

<p>A <code>SpriteAnimation</code> is simply created with a frame count and a unique ID and each actor in the game can have multiple animations. The <code>SpriteAnimation</code> can be given a number of <code>AnimationFrame</code>s, each with a duration in milliseconds. This means that different animations can be swapped in and out depending on if the character moves or attacks etc (see in <code>AnimationComponent.playAnimation(int id)</code>).</p>

<p>Each iteration of the game loop, the <code>AnimationFrame</code>'s <code>getFrame(float time)</code> is called, and it checks how much time has passed since the last main loop iteration and decides which frame to play next, then returns the frame to get sent off to the rendering system. This allows it to skip animation frames if the animation is going too slowly.</p>

<p>I hope this example works, and you can see it being used in the actual game on the Android Marketplace <a href=""https://market.android.com/details?id=com.replica.replicaisland&amp;hl=en"" rel=""nofollow noreferrer"">here</a>.</p>
","18006"
"How can I prevent false score reports to global highscore tables?","11996","","<p>Browser and mobile games commonly have global highscore tables. It's also common for those tables to contain scores of 2,147,483,647 &mdash; where people have figured out the webservice call that reports scores and used it to record a fictitious score.</p>

<p>For simple puzzle games, we can defend against this by including a record of every move the player made (and any random seeds used to generate the level) with the score-reporting call. The entire game can then be reproduced and verified on the server.</p>

<p>However, this quickly becomes infeasible for anything larger than Pac-man.</p>

<p>How else can cheating of this kind be prevented?</p>
","<p>The internal system we used for Moblox (later replaced with OpenFeint) worked like this:</p>

<ul>
<li>Send a JSON message over plain HTTP (not HTTPS). Include a MD5-hash of all fields plus a magic string.</li>
<li>On the server, check the integrity of the message with the same operation.</li>
</ul>

<p>To crack the system, you'd have to find this magic string. It is possible with reverse engineering, but painful.</p>

<p>OpenFeint, ScoreLoop and CocosLive all use the same trick, but with HTTPS. Very easy to implement.</p>
","4185"
"Adding an existing script to a gameobject programmatically","11962","","<p>Is there a way to take a script and apply that specific script to an object through code?
In pseudocode, what I'm trying to do is essentially as follows:</p>

<pre><code>ObjectOne.MyScript = ObjectTwo.GetComponent&lt;MyScript&gt;();
</code></pre>

<p>The closest thing I've found to doing this is <code>AddComponent()</code>, but that only takes either a string or a type and I'd assume it just finds the relavant script and instantiates a clean copy of it. That could work for what I want to do as I could just fill in the relevant information, but that would be tiresome and there should be an easier way to do this.</p>
","<p>Yes, the only way is using <code>AddComponent()</code>:</p>

<pre><code>var myScript = gameObject.AddComponent&lt;MyScript&gt;();
</code></pre>

<p>I don't see how this can be tiresome. There's no way to instantiate a <em>MonoBehaviour</em> so you cannot have multiple instances of your script instantiated by yourself and added them to the game objects on the go - if that's what you thought.</p>

<hr>

<p><em>Update</em></p>

<p>There's really no way to reparent or move a component, so you'll probably have to copy. </p>

<p>However, there's another approach! Instead of having this component in your main Game Object you could instantiate a child Game Object that would just act as a container for your component, and you would move this child to other Game Objects as necessary. Of course the viability of this idea depends on the complexity of the relationship between the main Game Object and the component: if the component uses too many variables of the main Game Object it may be tiresome to reposition it to a child Game Object.</p>
","75382"
"Alternative to pyGame?","11956","","<p>i'm learning something about game programming from a book about ""pyGame"". pyGame is simple, but... python is a little complex and different from my previous knoweledge about programming. </p>

<p>I know ""classical"" language: C# (also C/C++), Java ... I know a lot of people love Python but for me is a little harder to learn!</p>

<p>So I'm looking something like ""pyGame"" but for java or for c# ... A library with which I can do almost the same thing i can do with pygame (so .. do more with less code ... and headache).</p>
","<p><a href=""http://love2d.org/"" rel=""nofollow"">Love</a> offers a similar level of complexity as PyGame, though I'm not sure you will find Lua much easier than Python. If you want to just go with something more direct, look for bindings for SDL (<a href=""http://cs-sdl.sourceforge.net/index.php"" rel=""nofollow"">SDL.NET</a> for example) for your favorite language, or even just use it directly in C. Many PyGame APIs are just thin wrappers for SDL functionality.</p>
","4463"
"Browser-based MMOs (WebGL, WebSocket)","11944","","<p>Do you think it is technically possible to write a fully-fledged 3D MMO client with Browser JavaScript - WebGL for graphics, and WebSocket for Networking?</p>

<ul>
<li>Do you think future MMOs (and games generally) will be written with WebGL?</li>
<li>Does today's JavaScript performance allow this?</li>
<li>Let's say your development team was you as a developer, and another model creator (artist). Would you use a library like <a href=""http://scenejs.org/"" rel=""noreferrer"">SceneJS</a> for the game, or write straight WebGL? If you would use a library, but not SceneJS, please specify which.  </li>
</ul>

<p><strong>UPDATE (September 2012):</strong> RuneScape, which is a very popular 3D browser-based MMORPG that used Java Applets so far has announced that it will use HTML5 for their client (<a href=""http://services.runescape.com/m=news/mod-mmg-on-runescape-micro-payments"" rel=""noreferrer"">source</a>).</p>

<p><a href=""http://services.runescape.com/m=rswikiimages/en/2012/8/b4aft-29173657.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/m0taV.png"" alt=""Runescape HTML5""></a></p>

<p>Java (left) and HTML5 (right)</p>

<p><strong>UPDATE (June 2013):</strong> I have wrriten a prototype of a WebGL/WebSocket based MMO:
<a href=""https://github.com/alongubkin/xylose"" rel=""noreferrer"">https://github.com/alongubkin/xylose</a></p>
","<blockquote>
  <p>Do you think it is technically possible to write a fully-fledged 3D MMO client with Browser JavaScript - WebGL for graphics, and WebSocket for Networking?</p>
</blockquote>

<p>Yes, absolutely. There is no reason WebGL or WebSocket technology would prevent you from making a 3D MMOG client, or any game client for that matter.</p>

<blockquote>
  <p>Do you think future MMOs (and games generally) will wrriten with WebGL?</p>
</blockquote>

<p>Yes. I believe within the next five years, most 3D browser games will be written using WebGL. The reason is simple - WebGL is the only standardized 3D technology that will have implementations available in every major web browser (Chrome 9, Firefox 4, Safari 6, and Internet Explorer via Chrome Frame).</p>

<blockquote>
  <p>Does today's JavaScript performance allow this?</p>
</blockquote>

<p>Yes. JavaScript performance in modern browsers has increased to the point where 3D game development is feasible. For example, see the <a href=""https://github.com/mrdoob/three.js/"">Three.js project</a>.</p>

<blockquote>
  <p>Let's say your development team was you as a developer, and another model creator (artist). Would you use a library like SceneJS for the game, or write straight WebGL? If you would use a library, but not SceneJS, please specify which.
  Thanks!</p>
</blockquote>

<p>Use a library to save time. There is no reason to write your own WebGL graphics code unless an existing library is missing features that you need. Even in that case, it would probably be more time efficient to extend the existing library.</p>

<p>For my project, I am using <a href=""http://www.glge.org/"">GLGE</a> as it supports many different graphics effects and is constantly being updated with new ones.</p>
","9104"
"smooth movement pygame","11937","","<p>Hello im trying to learn more about smoother movement in games. I have created a little program to hopefully help me understand this. As far as i can tell i am suppose to track time, and update positions accordingly. However, for some reason, this concept is very hard for me to understand. I am using python and pygame at the moment for my games, and in none of them i have been able to come up with the smoothness i wanted. Ive also tried several games off of the pygame website and so far none of them have had the smoothness i prefer.</p>

<p>like i said, i understand you have to track time, and update positions accordingly instead of just +1'ing location each frame/iteration. By doing it the 'wrong way' as far as i understand then it doesnt neccesarily sync up with the monitor thus creating the sense of jittery motion, even at high FPS.</p>

<p>i have read a few articles on the subject of time steps, however i have been unable to fully understand the concept and incorporate it in my game. so i would like to ask, if someone can explain how to implement a timestep and create smooth motion. i am not going to incorporate physics in my first games, so the accuracy of the timer does not matter too much, what is most important right now is a game that can run as smooth as a proffesional game. i am sure a revisit if not simplified explanation of timestepping, and even how to do it in a simple way with python will be of benefit to any programmer hoping to use pygame/python for his games.</p>

<p>Anyway this is the program i was able to write, that doesent have smooth motion. Perhaps someone can modify it, so we can get a working example with time stepping and see how it improves the smoothness. PS. you need python 2.7 and a python 2.7 pygame compatible version to run the program/game</p>

<p><a href=""http://bpaste.net/show/qmE362O29sq6GPGBK3fg/"" rel=""nofollow"">http://bpaste.net/show/qmE362O29sq6GPGBK3fg/</a></p>
","<p>First we need to clarify what ""smooth movement"" is.</p>

<p>Let's first talk about <strong>smooth movement in a pixelated space</strong>.</p>

<p>Not taking into account motion blur and sub-pixel movement, the smoothest <strong>amount</strong> of movement you can have on a pixel screen is <strong>one pixel</strong>. So your code</p>

<pre><code>pygame.draw.circle(SCREEN, (255, 255, 255), (newx, SCREENRECT.centery), 30)
pygame.display.update()
newx+= 1    
</code></pre>

<p>actually procudes the smoothest movement in space possible.</p>

<p>Your code produces a smooth movement of roughly <em>60 pixels per second</em> because of the <code>clock.tick(60)</code> call. This is smooth, but not very fast.</p>

<p>To get <strong>fast</strong> movement, you now could increase the amount of pixels your image jumps per step by using <code>newx+= 2</code> or <code>newx+= 5</code>. But this, in line with the above definition, will <em>no longer produce smooth movement</em>. Why? Because you move more than 1px in one step, which we percieve as stuttering.</p>

<p>So, what can be done? If we want <strong>fast</strong> movement, but can only get it <strong>smooth</strong> by moving one pixel at a time, <em>we need to move 1px at a time more often per second</em>. And that means: increasing the renderings per second, or, more common, frames per second.</p>

<p>(Note that we have not yet talked about timesteps here at all.)</p>

<p>So as a first step, decrease the waiting time between frames (<code>Clock.tick()</code> essentially is a pause function with dynamic duration) by increasing the argument. Try <code>clock.tick(120)</code> or <code>clock.tick(360)</code>.</p>

<p>At some point you will notice that the perceived speed of the motion does no longer increase. This is because you reach the limit of how long your rendering actually takes to compute. At this point, <strong>optimization</strong> has to happen if the movement is still to slow.</p>

<p>Your drawing routine is inefficient for various reasons:</p>

<ul>
<li><p>It clears the whole screen to black every frame with <code>SCREEN.fill((0, 0, 0))</code>, although technically you would just neet to clear the area where the circle is.</p></li>
<li><p>You compute and draw a circle in every frame using <code>pygame.draw.circle()</code>. It would be more efficient to pre-render the circle to a surface an blit that surface to the background.</p></li>
</ul>

<p>These would be starting points to get your simple animation smooth and fast. You can optimize further by abandoning Pygame Surfaces and switching to OpenGL. But it is important to note that <strong>there is always a limit to the speed of smooth, i.e. 1px movement</strong>. Most of the time the practical limit is the <em>monitor refresh rate</em>. If your monitor updates the application's display from the frame buffer memory, say, at 90 times per second (90 Hz), then 90 px / s is the most of smooth movement in space that you can get.</p>

<p>Now you were asking about timesteps, so let's talk about <strong>smooth movement in time</strong>.</p>

<p>We perceive an object moving smoothly if it moves by <em>equal amounts of space</em> in <em>equal amounts of time</em>. If you have tuned up the FPS in the above example to 360, you might have noticed that the circle stutters and moves irregularily. This is because at some frames Pygame manages to draw everything in less than 1/360 s, and in some frames not. This means that some times the circle does move 360px in one second, and some times the circle takes longer than one second <em>wall clock time</em> to move 360 px. This is because rendering time <em>is not guaranteed</em>. And this is where timesteps come in.</p>

<p>The principle of timestepping is to keep the movement in sync with the wall clock time. That means, instead of blindly moving a fixed amount of pixels per frame, you <em>measure the time</em> your frames take, and adjust the amount of movement (and possibly the time to pause) accordingly. The answer of Yos233 shows one way to do this using the return value of <code>clock.tick()</code>.</p>

<p>Timestepping requires that there is a target speed of your animation. Say an object shall move 50 px per second. The basic procedure is</p>

<ol>
<li><p>Draw the object.</p></li>
<li><p>Wait until 1/50 s has passed.</p></li>
<li><p>Update position by 1 px.</p></li>
<li><p>Repeat.</p></li>
</ol>

<p>The critical point is when in 2. you see that actually <em>more</em> than 1/50 s has already passed. Here, to keep the movement smooth in time, you have to <em>quantify how much time over 1/50 s has passed</em>, and <em>add to the amount of space to move accordingly</em>.</p>

<p>Note that in this case you inevitably will have to move <strong>more than 1px</strong> to stay in sync; this means that your movement will be <strong>smooth in time</strong>, but no longer <strong>smooth in space</strong>.</p>

<p>To sum up:</p>

<ol>
<li><p>1px movement is the smoothest you can get, and it is limited by the frame rate your whole setup can achieve.</p></li>
<li><p>Timestepping will smooth out your movement over time, but will actually increase jumps and stutter if the target speed can not be met.</p></li>
</ol>

<p>For further reading on timesteps, check out the excellent article <a href=""http://gafferongames.com/game-physics/fix-your-timestep/"" rel=""nofollow"">Fix Your Timestep!</a>.</p>
","48795"
"How does hardware tessellation work?","11936","","<p>I would just like someone to explain in relativly clear terms how hardware tessellation works considering it is the new buzzword with DX11. </p>

<p>Thanks. </p>
","<p>I'll give you the ""simple"" version and let someone else fill you in on the details if you're interested :).</p>

<p>There are basically two ways to model 3D objects.  The first is one you don't see a lot of in games, and it involves using precise, mathematically defined curves to define the shape of an object.  Using this method, the level of detail is (practically speaking) ""infinite"".  Take a cylinder for example.  A cylinder can be defined in very simple mathematical terms: all you really need to know is the radius at the ends and the length of the cylinder.  In terms of the geometry, this information is all we need in order to render the cylinder in a 3D scene.  Moreover, we can easily scale the cylinder to make it larger or smaller; all we need to do is maintain the ratio of the length to the radius.  We can use the same formulas to represent the geometry, but with different parameters.  We can represent a torus (""donut"" shape) easily as well: we simply need to know the inner radius and outer radius.  From that, we can compute the diameter (and therefore the radius) of the donut's body (the ""cake"") by subtracting the inner radius from the outer radius.  The circular body wraps along the arc defined by the inner radius.  This type of 3D definition is nice because it is relatively simple (resulting in a small model file), and there is no significant limit to the level of detail.  The downside is that today's video hardware isn't designed to process these types of models efficiently (if at all).</p>

<p>The other way is to combine simple geometry to approximate the shape we want to represent.  We do this with a process called <em>tessellation</em>.  We could <em>tessellate</em> a cylinder by breaking it down into more primitive shapes: two circles and a series of long rectangles, which wrap around the outer edge.  The circles can be further broken down into many tiny triangles, as can the rectangles along the edge.  The end result is a model comprised <em>only</em> of triangles:</p>

<p><img src=""https://i.stack.imgur.com/3JdnH.png"" alt=""Image of Triangulated Cylinder""></p>

<p>Or, for the torus:</p>

<p><img src=""https://i.stack.imgur.com/nNWMH.jpg"" alt=""Image of Triangulated Torus""></p>

<p>The good news is that video hardware is optimized to handle this sort of geometry.  Today's GPUs have no trouble churning out tons and tons of triangles every second.  However, there's an obvious problem: we are trying to represent curved surfaces using shapes that have flat edges.  In order for our cylinder to <em>look</em> like a cylinder (as opposed to a cube), we want to break it down into a <em>lot</em> of little triangles.  Well, how many do we want?  It depends.  What kind of hardware will be used to render the scene?  Faster hardware can render triangles faster than slower hardware, producing faster frame rates.  There are other factors to consider, like how many other objects will be present in the scene, and how complex will they be?  In games, there are typically a lot of objects in a given scene.  Moreover, objects may travel through different scenes, each with different levels of visual complexity.  It's hard to figure out the <em>level of detail</em> to use when we tessellate our models.</p>

<p>Another problem is that of geometric complexity: whereas a curve-based definition of a cylinder is very simple (radius and length), a tessellated definition likely combines hundreds of triangles, each of which needs to be defined independently.  Consequently, our tessellated model file will be much, much larger.  Let's say we have a mathematically defined model of something complex, like a person.  Our model file may be a mere 24kb in size.  Well, once that model is tessellated, the resulting file could be 24mb (24,000kb).  That's quite a difference.</p>

<p>Hardware tessellation takes advantage of <em>geometry shaders</em> to perform hardware-assisted tessellation <em>in real time</em> (or in nearly real time).  Essentially, it provides a mechanism to take a mathematically defined 3D model and transform it into a tessellated format that the video card can render efficiently.  Traditionally, game developers have performed tessellation at the studio and shipped the tessellated models with the game.  Hardware tessellation allows us to defer this process until the game is <em>actually running</em> on the player's computer.  This has some serious benefits:</p>

<ol>
<li><p>The size of the game's 3D content decreases dramatically (fewer discs or smaller downloads, and less hard disk space required).</p></li>
<li><p>We can control the level of detail <em>in real time</em>.  Are we running on a cutting-edge beast of a gaming machine?  If so, we can tessellate using a very high level of detail.  Are we running on an old laptop with integrated graphics?  No problem; we can simply reduce the level of detail to boost performance.</p></li>
</ol>

<p>So that's the gist of it.  It's probably not 100% accurate, as I am not a 3D programmer, but that should give you a better idea of what all the fuss is about :).</p>

<p>Cheers,<br>
Mike</p>
","238"
"What is ""procedural generation"" and how is it done?","11859","","<p>I hear a lot about ""procedural maps"" and ""procedural textures"". What does that mean exactly, and what resources are there for learning these techniques in a game?</p>
","<p>The textbook definition of ""procedural"" is something that's generated from some kind of algorithm instead of predefined, i.e. from a level editor or image editing program.</p>

<p>See also this question, specifically for procedural textures: <a href=""https://gamedev.stackexchange.com/questions/327/what-happened-to-procedurally-generated-textures"">What happened to procedurally generated textures?</a></p>

<p>For procedural maps, there are a lot of techniques you can use.  In a basic example, you can do things like create some kind of grid that you pseudo-randomly lay down paths for.  You can set up a bunch of prefabricated pieces that have certain areas tagged as doors, etc, and just randomly throw them together.</p>

<p>In a way, you're writing an AI to design your levels on the fly.</p>

<p>If you're planning on doing this at run time on the user's machine, you lose the ability to precompute things across the map.  For example, you have to lose or find alternate solutions to things like visibility, navigation data, and lightmaps.   </p>

<p>However there is a benefit to procedurally generate content during production and then use that as a seed to making data.  For example, you can procedurally place trees on a terrain to create a forest, and then save that as your map, instead of placing all the trees by hand.</p>

<p>At the end of the day, though, how you do it is heavily dependent on what your game design needs are.  I'm personally of the opinion that procedural maps are usually not worth it as a level designer can make more fun, better looking, maps in less time than it would be to set up a system to make anything close, but there's room for debate on that.</p>
","757"
"How can I avoid having many singletons in my game architecture?","11856","","<p>I use cocos2d-x game engine for creating games. The engine already uses many singletons. If someone used it, then they should be familiar with some of them:</p>

<pre><code>Director
SimpleAudioEngine
SpriteFrameCache
TextureCache
EventDispatcher (was)
ArmatureDataManager
FileUtils
UserDefault
</code></pre>

<p>and many more with overall about 16 classes. You can find a similar list on this page: <a href=""http://www.cocos2d-x.org/docs/manual/framework/html5/v3/singleton-objs/en"" rel=""nofollow noreferrer"">Singleton objects in Cocos2d-html5 v3.0</a> But when I want to write I game I need much more singletons:</p>

<pre><code>PlayerData (score, lives, ...)
PlayerProgress (passed levels, stars)
LevelData (parameters per levels and level packs)
SocialConnection (Facebook and Twitter login, share, friend list, ...)
GameData (you may obtain some data from server to configure the game)
IAP (for in purchases)
Ads (for showing ads)
Analytics (for collecting some analytics)
EntityComponentSystemManager (mananges entity creation and manipulation)
Box2dManager (manages the physics world)
.....
</code></pre>

<p>Why I think they should be singletons? Because I will need them in very different places in my game, and shared access would be very handy. In other words, I don't what to create them somewhere and pass pointers down to my all architecture as it will be very difficult. Also these are kind of things I need only one. In any case I will need several, I can use a Multiton pattern too. But the worst thing is that Singleton is the most heavily criticized pattern because of:</p>

<pre><code> - bad testability
 - no inheritance available
 - no lifetime control
 - no explicit dependency chain
 - global access (the same as global variables, actually)
 - ....
</code></pre>

<p>You can find some thoughts here: <a href=""https://stackoverflow.com/questions/137975/what-is-so-bad-about-singletons"">https://stackoverflow.com/questions/137975/what-is-so-bad-about-singletons</a> and <a href=""https://stackoverflow.com/questions/4074154/when-should-the-singleton-pattern-not-be-used-besides-the-obvious"">https://stackoverflow.com/questions/4074154/when-should-the-singleton-pattern-not-be-used-besides-the-obvious</a></p>

<p>So, I think, I am doing something wrong. I think my <a href=""https://en.wikipedia.org/wiki/Code_smell"" rel=""nofollow noreferrer"">code smells</a>. :) I wounder how more experienced game developers solve this architectural problem? I want to check, maybe it is still normal in game development to have <strong>more than 30 singletons</strong>, considered the ones that are already in game engine. </p>

<p>I have thought to use a Singleton-Facade which will have instances of all these classes I need, but each of them would not be singletons already. This will eliminate a lots of problems, and I would have only one singleton which would be the Facade itself. But in this case I will have another design problem. The Facade will become a GOD OBJECT. I think this <strong>smells too</strong>. So I can't find a good design solution for this situation. Please advice.</p>
","<p>Reading all these answers, comments and articles pointed out, especially these two brilliant articles,</p>

<ul>
<li><a href=""http://gameprogrammingpatterns.com/singleton.html"" rel=""nofollow"">http://gameprogrammingpatterns.com/singleton.html</a></li>
<li><a href=""http://gameprogrammingpatterns.com/service-locator.html"" rel=""nofollow"">http://gameprogrammingpatterns.com/service-locator.html</a></li>
</ul>

<p>eventually, I have come to the following conclusion, which is kind of an answer to my own question. The best approach is not to be lazy and pass dependencies directly. This is explicit, testable, there is no global access, can indicate wrong design if you have to pass delegates very deep and in many places and so on. But in programming one size does not fit all. Thus, there are still cases that it is not handy to pass them directly. For example in case we create a game framework (a code template which will be re-used as a base code to develop different kinds of games), and include there lots of services. Here we don't know how deep each service can be passed, and how many places it will be necessary. It dependents on a particular game. So what do we do in this kind of cases? We use Service Locator design pattern instead of Singleton, which is actually the same Singleton, with the following very important improvements:</p>

<ol>
<li>You don't program to the implementations but to the interfaces. This is very essential in terms of OOP principals. At runtime you can change or even disable the service using Null Object pattern. This is not only important in terms of flexibility, but it directly helps in testing. You can disable, mock, also you can use Decorator pattern, to add some logging and other functionality as well. This is very important property, which Singleton does not have.</li>
<li>Another huge advantage is that you can control the lifetime of the object. In Singleton you only control the time the object will be spawned by Lazy Initialization pattern. But once the object is spawned, it will live until the end of the program. But in some cases you would like to change the service. Or even shut it down. Especially in gaming this flexibility is very important.</li>
<li>It combines/wraps several Singletons into one compact API. I think you may also use some Facade like Service Locators, which for a single operation might use several services at once.  </li>
<li>You may argue that we still have the global access which is the main design problem with the Singleton. I agree, but we will need this pattern only and only if we want some global access. <strong>We should not complain about global access, if we think that direct dependency injection is not handy for our situation, and we need a global access.</strong> But even for this problem, an improvement is available (see the second article above). You can make all the services private, and you can inherit from Service Locator class all the classes you think they should use the services. This can significantly narrow the access. And please consider that in case of Singleton you cannot use inheritance because of the private constructor. </li>
</ol>

<p>Also we should consider that this pattern was used in Unity, LibGDX, XNA. This is not an advantage, but this is kind of a proof of the usability of the pattern. Consider that these engines were developed by lots of smart developers a long time and during the evolution phases of the engine they still didn't find any better solution. </p>

<p>In conclusion, I think Service Locator can be very useful for the scenarios described in my question, but still should be avoided if it is possible. As a rule of thumb - use it if you have to.</p>

<p>EDIT: After a year of work and using direct DI and having problems with huge constructors and lots of delegations, I have done more research and have found a good article that talks about pros and cons about DI and Service Locator methods. Citing this article (<a href=""http://www.martinfowler.com/articles/injection.html"" rel=""nofollow"">http://www.martinfowler.com/articles/injection.html</a>) by Martin Fowler that explains when actually Service locators are bad:</p>

<blockquote>
  <p>So the primary issue is for people who are writing code that expects
  to be used in applications outside of the control of the writer. In
  these cases even a minimal assumption about a Service Locator is a
  problem.</p>
</blockquote>

<p>But anyways, if you want to us DI first time, you should read this <a href=""http://misko.hevery.com/2008/10/21/dependency-injection-myth-reference-passing/"" rel=""nofollow"">http://misko.hevery.com/2008/10/21/dependency-injection-myth-reference-passing/</a> article (pointed out by @megadan), by paying very careful attention to the <a href=""https://en.wikipedia.org/wiki/Law_of_Demeter"" rel=""nofollow"">Law of Demeter (LoD) or principle of least knowledge</a>.</p>
","84245"
"Teamwork in Unity","11850","","<p>I have a Unity project without any version control, and I need to share it with another developer so that both of us can work on the project.</p>

<p>What strategies should be use that play nice with Unity Assets?</p>
","<p>Unity has a built in facility for supporting version control properly.</p>

<p>Just go into the File->Project Settings->Editor and enable external version control.</p>
","45"
"What is the best method to update shader uniforms?","11838","","<p>What is the most accepted way for keeping a shader's matrices up to date, and why?</p>

<p>For example, at the moment I have a <code>Shader</code> class that stores the handles to the GLSL shader program &amp; uniforms. Every time I move the camera I then have to pass the new view matrix to the shader, then every different world object I must pass it's model matrix to the shader.</p>

<p>This severely limits me as I can't do anything without having access to that shader object.</p>

<p>I thought of creating a singleton <code>ShaderManager</code> class that is responsible for holding all active shaders. I can then access that from anywhere and a world object wouldn't have to know about what shaders are active just that it needs to let the <code>ShaderManager</code> know the desired matrices but I'm not sure this is the best way and there's probably some issues that will arise from taking this approach.</p>
","<p>Use <em>uniform buffers</em> (ie <em>constant buffers</em> in D3D lingo).</p>

<p>So long as all your shaders agree on the layout and binding point of each such buffer then updating becomes a breeze.  Models have no need to know anything about shaders at all.  They need only update the model-view matrix in their constant buffer and the rendering pipeline will use it automatically.</p>

<p>At a minimum I would argue you should have two such buffers.  The first should store your projection matrix, camera matrix, the concatenated camera-projection matrix, viewport information, frustrum details, and matrix inverses.  You only need to update this buffer once per scene.</p>

<p>Then give each model another buffer to store its model-view matrix, normal matrix, inverses, and material properties.  This is updated once for each model and can be done in a different update pass (if/when appropriate).  The material information can/should be moved to a third material-specific buffer if you have the ability to share materials between multiple objects.</p>

<p>In a forward-shading setup it makes some sense to put all the lights in another buffer and in deferred-shading it likewise makes sense to use a per-light buffer for the light pass (in place of a model/material buffer used in the geometry pass).</p>

<p>Note that you need a moderately up-to-date version of GL to use uniform buffers at all (3.1 or an extension; common enough today except on some older but still-in-service laptops) and you need a fairly recent version to be able to bind uniform buffers to specific binding locations from inside the shader code (4.2; still uncommon but getting better) otherwise you have to do more work in your CPU-side code to set things up (your CPU code needs to know the right binding points anyway, so it's more of an API smell than a serious issue).  OpenGL|ES didn't add uniform buffers until 3.0 which is still unsupported on most popular mobile platforms, unfortunately.</p>

<p>If buffers aren't an option then you will need some global place to store index locations for the active shader.  You can use <code>glGetUniformLocation</code> after loading your shader to find the indices for well-known names (like <code>ModelViewMatrix</code> or the like) then store these indices.  Your render can map enum values like <code>MODEL_VIEW</code> passed to a <code>SetUniform</code> wrapper function to look into the bound shader, find the index, and call <code>glUniform</code> properly.  It's not a particular huge change in client code usage from buffers other than needing to set each uniform individually if you get it all wrapped up nicely.</p>

<p>See <a href=""http://www.opengl.org/wiki/GLSL_Interface_Block"">GLSL Inteface Blocks</a> and <a href=""http://www.opengl.org/wiki/Uniform_Buffer_Object"">Uniform Buffer Objects</a>.</p>
","57120"
"Is it possible to give an animated GIF a transparent background?","11832","","<p>I'm making a Fire Emblem-esque game. There are very cute 2D frames I made for each character, and, like a game like Fire Emblem, I want these characters to animate constantly.</p>

<p>To circumvent the graphics programming involved I came up with a novel idea! I would make each character an animated gif, and only in special conditions ever halt their constant movement - in that case just change what image is being displayed. </p>

<p>Simple enough.  But I have a dilemma - I want the background of my .gifs to be transparent (so that the ""grass"" behind each character naturally shows, as per the screenshot - which has them as still images with transparent backgrounds). I know how to make a background transparent in numerous tools (GIMP, Photoshop). But it seems every .gif creator replaces the transparent background with something and I can't edit it back to transparent.</p>

<p>Is it possible to have a .gif with a transparent ""background""? Perhaps my knowledge of file formats is limiting me here.</p>

<p><img src=""https://i.stack.imgur.com/o1XDB.png"" alt=""enter image description here""></p>
","<p>It's certainly possible (as in the, format supports it), the exact process by which the desired result is achieved will differ from tool to tool. For example, <a href=""http://www.youtube.com/watch?v=O8eLAPVxzXk"" rel=""nofollow"">here is a video that purports to illustrate how</a> to make transparent animated GIF images with <a href=""http://www.gimp.org/"" rel=""nofollow"">GIMP</a>. Similarly, <a href=""http://blog.ciuly.com/general/internet/making-animated-gif-transparent-with-gimp/"" rel=""nofollow"">this blog post</a> also describes the process. </p>

<p>It largely comes down to making sure your image frames have alpha channels in them before you combine and export them into the final format, regardless of which tool you use.</p>
","32108"
"Where to attach global scripts in Unity?","11812","","<p>As far as Iknow in Unity, every script must be attached to an object. But what is the case with global scripts? For example in a tetris-like game to which object should I attach the element spawner and mover scripts? Or should a the element handle its movement for itself? Is there any best practice for this problem?</p>
","<p>To expand on Tetrad's answer, consider a script like this:</p>

<pre><code>public class GameSystem : MonoBehavior
{
  private GameSystem m_Instance;
  public GameSystem Instance { get { return m_Instance; } }

  void Awake()
  {
    m_Instance = this;
  }

  void OnDestroy()
  {
    m_Instance = null;
  }

  void Update()
  {
    // global game update logic goes here
  }

  void OnGui()
  {
    // common GUI code goes here
  }

  // etc.
}
</code></pre>

<p>You can then create an object called ""GameSystem"" in the root of your scene.  The only components it would have would be the built-in transform component (set its position to the origin, its rotation to identity, and its scale to one; not that it matters, but it's good practice).  Attached the GameSystem component to that object.</p>

<p>You can now access your global object by simply using GameSystem.Instance.blah().  Its event handler methods are invoked automatically by Unity since it derives from MonoBehavior and exists as a component.  You can add fields to it that reference other game objects or components and connect them in the Unity object hierarchy view.</p>

<p>Yes, this is all a little ""weird.""  It can feel a little dirty to have to create an object (that even has a transform) which is always just a global singleton.  It's what Unity requires to create global objects that get an Update message and are manipulable with the default Unity property editor, though.</p>
","34879"
"Sending POST data with WWW in Unity C#","11803","","<p>I would like to use Unity's WWW class to send a an HTTP request with POST data. So in my server, my PHP script can do something like</p>

<pre><code>$number = $_POST[""NUMBER""];
</code></pre>

<p>According to <a href=""http://docs.unity3d.com/ScriptReference/WWW-ctor.html"" rel=""nofollow"">http://docs.unity3d.com/ScriptReference/WWW-ctor.html</a>, I can provide a byte array in the constructor to represent such data.</p>

<p>I'm a bit puzzled - suppose I want to send a mapping from ""NUMBER"" to <code>200</code> - how would I create a byte array compatible with my PHP script in Unity C#?</p>
","<p>Actually using the overloaded construct that take a <a href=""http://docs.unity3d.com/ScriptReference/WWWForm.html"" rel=""nofollow"">WWWForm</a> as second parameter, WWW class is automatically considered as an http post request.</p>

<p>Your code can be something like:</p>

<pre><code>WWWForm form = new WWWForm();
form.AddField( ""NUMBER"", aNumber );

WWW postRequest = new WWW( server_url, form );
</code></pre>
","84285"
"How are deterministic games possible in the face of floating-point non-determinism?","11799","","<p>To make a game like an RTS networked, I've seen a number of answers here suggest to make the game completely deterministic; then you only have to transfer the users' actions to each other, and lag what's displayed a little bit in order to ""lock in"" everyone's input before the next frame is rendered.  Then things like unit's positions, health, etc. don't need to be constantly updated over the network, because every player's simulation will be exactly the same.  I've also heard the same thing suggested for making replays.</p>

<p>However, since <a href=""http://gafferongames.com/networking-for-game-programmers/floating-point-determinism/"">floating-point calculations are non-deterministic</a> between machines, or even between different compilations of the same program on the same machine, is this really possible to do?  How do we prevent that fact from causing small differences between players (or replays) that <a href=""http://en.wikipedia.org/wiki/Butterfly_effect"">ripple throughout the game</a>?</p>

<p>I've heard some people suggest avoiding floating-point numbers altogether and using <code>int</code> to represent the quotient of a fraction, but that doesn't sound practical to me - what if I need to, for example, take the cosine of an angle?  Do I seriously need to rewrite an entire math library?</p>

<p>Note that I am mainly interested in C#, which as far as I can tell, has exactly the same problems as C++ in this regard.</p>
","<h2>Are floating-points deterministic?</h2>

<p>I did a lot of reading on this issue a few years back when I wanted to write an RTS using the same lockstep architecture you do.</p>

<p>My conclusions about hardware floating-points were:</p>

<ul>
<li>The same native assembly code is most likely deterministic provided you're careful with floating point flags and compiler settings.</li>
<li>There was one open source RTS project that claimed they got deterministic C/C++ compiles across different compilers using a wrapper library. I didn't verify that claim. (If I recall correctly it was about the <code>STREFLOP</code> library)</li>
<li>The .net JIT is allowed quite a bit of leeway. In particular it is allowed to use higher accuracy than requires. Also it uses different instruction sets on x86 and AMD64 (I think on x86 it uses the x87, AMD64 it uses some SSE instructions whose behavior differs for denorms).</li>
<li>Complex instructions (including trigonometric function, exponentials, logarithms) are especially problematic.</li>
</ul>

<p>I concluded that it's impossible to use the built in floating point types in .net deterministically.</p>

<h2>Possible Workarounds</h2>

<p>Thus I needed workarounds. I considered:</p>

<ol>
<li>Implement <code>FixedPoint32</code> in C#. While this is not too hard(I have a half finished implementation) the very small range of values makes it annoying to use. You have to be careful at all times so you neither overflow, nor lose too much precision. In the end I found this not easier than using integers directly.</li>
<li>Implement <code>FixedPoint64</code> in C#. I found this rather hard to do. For some operations intermediate integers of 128bit would be useful. But .net doesn't offer such a type.</li>
<li>Use native code for the math operations which is deterministic on one platform. Incurs the overhead of a delegate call on every math operation. Loses ability to run cross platform.</li>
<li>Use <code>Decimal</code>. But it's slow, takes a lot of memory and easily throws exceptions (division by 0, overflows). It's very nice for financial use, but no good fit for games.</li>
<li>Implement a custom 32 bit floating-point. Sounded rather difficult at first. The lack of a BitScanReverse intrinsic causes a few annoyances when implementing this.</li>
</ol>

<h2>My SoftFloat</h2>

<p>Inspired by <a href=""https://stackoverflow.com/questions/6683059/are-floating-point-numbers-consistent-in-c-can-they-be/6685966#6685966"">your post on StackOverflow</a>, I've just started implementing a 32 bit floating-point type in software and the results are promising.</p>

<ul>
<li>The memory representation is binary compatible with IEEE floats, so I can reinterpret cast when outputting them to graphics code.</li>
<li>It supports SubNorms, infinities and NaNs.</li>
<li>The exact results are not identical to the IEEE results, but that usually doesn't matter for games. In this kind of code it only matters that the result is the same for all users, not that it's accurate to the last digit.</li>
<li>Performance is decent. A trivial test showed that it can do about 75MFLOPS compared 220-260MFLOPS with <code>float</code> for addition/multiplication(Single thread on a 2.66GHz i3). If anybody has good floating point benchmarks for .net please send them to me, since my current test is very rudimentary.</li>
<li>Rounding can be improved. Currently it truncates, which roughly corresponds to rounding towards zero.</li>
<li>It's still very incomplete. Currently division, casts and complex math operations are missing.</li>
</ul>

<p>If anybody want to contribute tests or improve the code, just contact me, or issue a pull request on github. <a href=""https://github.com/CodesInChaos/SoftFloat"" rel=""nofollow noreferrer"">https://github.com/CodesInChaos/SoftFloat</a></p>

<h2>Other sources of indeterminism</h2>

<p>There are also other sources of indeterminism in .net. </p>

<ul>
<li>iterating over a <code>Dictionary&lt;TKey,TValue&gt;</code> or <code>HashSet&lt;T&gt;</code> returns the elements in an undefined order.</li>
<li><code>object.GetHashCode()</code> differs from run to run.</li>
<li>The implementation of the built in <code>Random</code> class is unspecified, use your own.</li>
<li>Multithreading with naive locking leads to reordering and differing results. Be very careful to use threads correctly.</li>
<li>When <code>WeakReference</code>s lose their target is indeterministic because the GC may run at any time.</li>
</ul>
","14909"
"How do I render terrain in a 2.5D perspective, like in the game Don't Starve?","11789","","<p>I have experience in making 2D side scroller games such as Terraria, but now I want to challenge myself and make a game that has a <a href=""http://en.wikipedia.org/wiki/2.5D"">2.5D perspective</a>. The game I am trying to mimic is Don't Starve. Right now my focus is on figuring out how to render the ground. I am having a hard time figuring out how they generated the ground, and then rendered it. The way I think they rendered the ground is by first painting the ground in some paint program, and then somehow manipulating that flat image so that it appears to have depth.</p>

<p>I am completely confused by how you would actually render that type of terrain. I want the terrain to have the following features:</p>

<ul>
<li>Look like the terrain in Don't Starve, <a href=""http://www.youtube.com/watch?v=MsWm_gWyk4s"">here is a video showing the terrain in Don't Starve</a></li>
<li>The terrain will be flat, and the camera's angle and perspective will be fixed</li>
</ul>

<p>Any tips and hints will be appreciated, Thank you in advance.</p>

<p>(I am working in Java, using the Light Weight Java Game Library (LWJGL).)</p>
","<p>I'm actually one of the Don't Starve devs (Kevin on our forums). I don't usually handle the rendering stuff, but I can tell you that the game is in 3D. The ground is just a regular 2D tile map with special transition pieces to make corners look better. There's no special Deathspank-style rounding going on, although we have talked about doing that in the past.</p>

<p>There are two types of game entities - upright and ground. The upright entities are kindof halfways billboarded to the camera, although not fully because with the camera angle this made them look like they were laying down. The ground stuff is just plain drawn on the ground.</p>

<p>The look that this gives works for a somewhat small range of camera angles. If you go too high, the upright stuff gets all weirdly foreshortened. Going really low works a bit better, but it's too hard to play the game because you can't see behind things or anything 'south' of your character. Finding the right trade-off between these two extremes took a bunch of experimentation.</p>

<p>Anyway, if you have any other questions about the tech behind the game, we're pretty friendly and forthcoming about such things over at the klei forums :)</p>
","44863"
"How do I disable texture filtering for sprite scaling in XNA 4.0?","11763","","<p>I have a sprite that I'm trying to scale up in XNA, but XNA is applying some sort of texture filtering that smooths it and makes it look ugly. I'd like it to just do pixel doubling instead of interpolation. How would I accomplish that?</p>
","<p>You need to set the sampler state. The default for SpriteBatch is <code>SamplerState.LinearClamp</code> (ie: linear interpolation - the smooth/blurry one).</p>

<p>Choose one of the <a href=""http://msdn.microsoft.com/en-us/library/microsoft.xna.framework.graphics.spritebatch.begin.aspx""><code>SpriteBatch.Begin</code></a> calls that takes a <code>SamplerState</code> and pass in <code>SamplerState.PointClamp</code> (selects the pixel at that precice ""point"").</p>
","6822"
"Normalization of Vectors: Return a copy of the result or alter the object itself?","11744","","<p>When calculating the normal of a vector, which is considered canon:</p>

<p>Returning a copy:</p>

<pre><code>Vector2D Vector2D::Normalize() const {
    double a1 = GetX();
    double a2 = GetY();
    double a3 = GetZ();
    double length = GetLength();
    assert(Math::IsEqual(length, 0.0) == false);
    if(Math::IsEqual(length, 0.0)) {
        throw Exception(""Can not normalize a Null Vector."");
    }
    return Vector2D(a1 / length, a2 / length, a3 / length);
}
</code></pre>

<p>Or altering the object itself?:</p>

<pre><code>void Vector2D::Normalize() {
    double a1 = GetX();
    double a2 = GetY();
    double a3 = GetZ();
    double length = GetLength();
    assert(Math::IsEqual(length, 0.0) == false);
    if(Math::IsEqual(length, 0.0)) {
        throw Exception(""Can not normalize a Null Vector."");
    }
    SetTerminal(a1 / length, a2 / length, a3 / length);
}
</code></pre>

<p>P.S.
<code>IsEqual</code> verifies the following: <code>(std::fabs(a - b) &lt;= 0.0001)</code></p>
","<p>You should have both versions, but not in the same place.</p>

<p>A function that takes a simple object like a vector generally should not modify it. Why? Because then you couldn't do this:</p>

<pre><code>normalize(vec3(0.3, 0.0, 0.0));
</code></pre>

<p>If <code>normalize</code> takes a <code>vec3&amp;</code>, then you can't pass it as a temporary in C++. You must use a named variable, for no real reason. It's also a lot harder to use it as part of an expression:</p>

<pre><code>normalize(someVec + someVec);
</code></pre>

<p>At the same time, if you have a vector, it's not a bad idea to want to be able to normalize it in-place. For that, you use a member function, which is your indication that you're <em>modifying</em> the object, not simply returning a new one.</p>

<p>So your member <code>normalize</code> should be non-const, but your free function version should take its argument by <code>const&amp;</code>.</p>
","33145"
"Javascript and PHP for real-time multiplayer?","11715","","<p>I'm wondering if combining Javascript clientside with PHP/mysql serverside is a good idea for HTML5 real-time multiplayer (small scale) browser games?</p>

<p>My technical knowledge is very limited, and even though I plan on learn node.js in the future, the learning curve is rather huge right now.</p>

<p>Since I'm already familiar with PHP I feel I would get it functioning much faster.</p>

<p>The scale I'm thinking is 2-8 players at the time. And trying to keep the client to server message count as low as possible.</p>

<p>The values I intend to store/handle are:</p>

<ul>
<li>Player name and ID.</li>
<li>X and Y position.</li>
<li>Health.</li>
<li>Equipped items (maximum 8 slots, probably less).</li>
<li>Actions (walk, attack, use etc but only 1 action/player at a time).</li>
<li>Bullet X,Y coordinates and trajectory.</li>
<li>Guild/Clan name.</li>
<li>And some basic chat/mailing function.</li>
</ul>

<p>My guess is even though it's not the best solution, but aslong as I keep the logic small, that this is completely doable.
Am I right?</p>
","<p>For a real-time game, you want to minimize latency. Here's two tips for achieving it, with notes about PHP and Node: </p>

<ol>
<li>Use WebSockets. They allow fast two-way communication between the server and the client. Using node.js here has the advantage that you can use the same JavaScript API on both ends of the pipe. There's also the wonderful socket.io module for node.js that provides fallback technologies to lesser browsers that don't support WebSockets. Googling a bit, it seems you can also use WebSockets from PHP if you really want to.</li>
<li>Don't involve database in time critical data such as coordinates of fast moving objects. This means keeping them in memory, which is not particularly well suited for the traditional PHP use model of having it fire once for each request to apache (or whatever web server), but you can launch your PHP server app also as standalone. I'd guess <a href=""http://shootout.alioth.debian.org/u32/benchmark.php?test=all&amp;lang=v8&amp;lang2=php"">Node, with its V8 core, is going to be faster than PHP</a> though. Whether that's an issue depends on how demanding your game is and how powerful the server is.</li>
</ol>

<p>I myself find node.js very easy to pick up and since you are going to need to code quite a bit of JavaScript anyway, I'd recommend you try it. At least take a quick look at the <a href=""http://socket.io/"">socket.io</a> tutorials to see how trivial it is to set up a real-time communication channel.</p>
","33341"
"How do I generate a 3D race track from a spline?","11700","","<p>I want to generate a 3-dimensional race track around a spline that describes its shape.  <a href=""http://www.youtube.com/watch?v=uQwn7Ufypqo"" rel=""nofollow"">Here's an illustrative video</a>.</p>

<p>The track should be an endless tunnel that sweeps along a 3D spline, with some obstacles thrown in.  My best idea so far has been to loft a circle shape along the spline.</p>

<p>I would also like some pointers into how to manage the geometry i.e. how to create it from the loft operation, manage its 'lifecycle' in memory, collision and texturing.</p>
","<p>I'm not sure what language you are working in but there is a procedural mesh extrusion example for Unity3D located here:</p>

<p><a href=""http://unity3d.com/support/resources/example-projects/procedural-examples"" rel=""nofollow noreferrer"">http://unity3d.com/support/resources/example-projects/procedural-examples</a></p>

<p>I'm sure you could look at the code and rework it for your situation. </p>

<p>EDIT:
I'm working on a game that uses a procedural extruded rail system like the one you are starting but it's in C# in Unity3d. I'll give you an overview of how I create my rail extrusion based on a Cubic Bezier path so although the rail's mesh is procedurally generated, it's based on the Bezier path that I define ahead of time in an editor. It would be like a level editor in the case of your game, in my case, it's designing pinball tables.  Listed below is an example of how I'm doing it:</p>

<p>1.) Build/Find and Implement a Bezier Path Class. This will give you the source data for your mesh extrusion. There is one in C# here that you can port to c++.</p>

<p><a href=""http://forum.unity3d.com/threads/32954-Waypoints-and-constant-variable-speed-problems?p=213942"" rel=""nofollow noreferrer"">http://forum.unity3d.com/threads/32954-Waypoints-and-constant-variable-speed-problems?p=213942</a></p>

<p>2.) Once you have a Bezier Path created, data points from this path are sampled. This can be done via the Interp method on the class provided above. This will give you a list/array of Vector3 points along the Bezier path.</p>

<p>3.) Create a helper class to convert the Vector3 Bezier path data from step 2. In this case, I have a simple class called ExtrudedTrailSection as defined below:</p>

<pre><code>public class ExtrudedTrailSection
{
    public Vector3 point;
    public Matrix4x4 matrix;
    public float time;

    public ExtrudedTrailSection() { }
}
</code></pre>

<p>4.) Iterate through your Vector3 sample data and convert to an array of ExtrudedTrailSections supplying it with the sample data and a base matrix that would be the root location of your extruded mesh.</p>

<ol start=""5"">
<li>) Use the array of ExtrudedTrailSections to create an array of final Matrix4x4[] using the following code:</li>
</ol>

<p>Matrix4x4 worldToLocal = rootTransform.worldToLocalMatrix;</p>

<pre><code>    for (int i = 0; i &lt; trailSections.Count; i++)
    {
            if (i == 0)
            {
                direction = trailSections[0].point - trailSections[1].point;
                rotation = Quaternion.LookRotation(direction, Vector3.up);
                previousRotation = rotation;
                finalSections[i] = worldToLocal * Matrix4x4.TRS(position, rotation, Vector3.one);
            }
            // all elements get the direction by looking up the next section
            else if (i != trailSections.Count - 1)
            {
                direction = trailSections[i].point - trailSections[i + 1].point;
                rotation = Quaternion.LookRotation(direction, Vector3.up);

                // When the angle of the rotation compared to the last segment is too high
                // smooth the rotation a little bit. Optimally we would smooth the entire sections array.
                if (Quaternion.Angle(previousRotation, rotation) &gt; 20)
                    rotation = Quaternion.Slerp(previousRotation, rotation, 0.5f);

                previousRotation = rotation;
                finalSections[i] = worldToLocal * Matrix4x4.TRS(trailSections[i].point, rotation, Vector3.one);
            }
            // except the last one, which just copies the previous one
            else
            {
                finalSections[i] = finalSections[i - 1];
            }
        }
</code></pre>

<p>6.) Now you have an array of Matrix4x4[] and can extrude a mesh but first we need a reference mesh to extrude from.  I have a utility class that will create a circular mesh face that we will supply to the mesh extrusion method.</p>

<pre><code>public static List&lt;Vector2&gt; CreateCircle (double radius, int sides)
{
    List&lt;Vector2&gt; vectors = new List&lt;Vector2&gt; ();

    const float max = 2.0f * Mathf.PI;
    float step = max / sides;

    for (float theta = 0.0f; theta &lt; max; theta += step) {
        vectors.Add (new Vector2 ((float)(radius * Mathf.Cos (theta)), (float)(radius * Mathf.Sin (theta))));
    }


    return vectors;
}
</code></pre>

<p>7.) Find the center of this data:</p>

<pre><code>    public static Vector2 CalculateCentroid(List&lt;Vector2&gt; vectorList)
    {
        //////////////////////////////////////////////////////////////////////////
        // Local variables.
        float fArea = 0.0f, fDistance = 0.0f;
        Vector2 vCenter = Vector2.zero;
        int nIndex = 0, nLastPointIndex = vectorList.Count - 1;
        //
        //////////////////////////////////////////////////////////////////////////

        //////////////////////////////////////////////////////////////////////////
        // Run through the list of positions.
        for (int i = 0; i &lt;= nLastPointIndex; ++i)
        {
            //////////////////////////////////////////////////////////////////////////
            // Cacluate index.
            nIndex = (i + 1) % (nLastPointIndex + 1);

            // Calculate distance.
            fDistance = vectorList[i].x * vectorList[nIndex].y - vectorList[nIndex].x * vectorList[i].y;

            // Acculmate area.
            fArea += fDistance;

            // Move center positions based on positions and distance.
            vCenter.x += (vectorList[i].x + vectorList[nIndex].x) * fDistance;
            vCenter.y += (vectorList[i].y + vectorList[nIndex].y) * fDistance;
        }
        //
        //////////////////////////////////////////////////////////////////////////

        //////////////////////////////////////////////////////////////////////////
        // Calculate the final center position.
        fArea *= 0.5f;
        vCenter.x *= 1.0f / (6.0f * fArea);
        vCenter.y *= 1.0f / (6.0f * fArea);
        //
        //////////////////////////////////////////////////////////////////////////

        return vCenter;
    }
</code></pre>

<p>8.) Now that we have the edge and center data for a radial face mesh, you can construct a mesh object using your data. The final vertex in the mesh is the center point we calculated. The final mesh is just a face that is supplied to the mesh extrusion method that I provided an example of in the Procedural mesh extrusion class of the Unity package. Again, this is my method and obviously you would have to feed this data into OpenGL. If you have a 3d utility library that you are using or can write your own mesh class, it would probably work better to generate your final extruded mesh as this data isn't really needed by opengl for rendering. This face mesh is just used as the reference  for the mesh extrusion.</p>

<pre><code>    List&lt;Vector3&gt; levelVerts = new List&lt;Vector3&gt;();
    List&lt;Vector2&gt; levelUVBary = new List&lt;Vector2&gt;();
    List&lt;Vector2&gt; levelUVs = new List&lt;Vector2&gt;();
    List&lt;int&gt; levelTris = new List&lt;int&gt;();

    int verticesPerNode = 4;
    int edgeCount = sourceMeshData.Count;

    List&lt;Vector3&gt; sourceVerts = new List&lt;Vector3&gt;();
    //Debug.Log(""smd.c:"" + sourceMeshData.Count);
    for (int i = 0; i &lt; edgeCount; i++)
    {
        //Debug.Log(""adding:""+levelShapeData[i].x+""/""+levelShapeData[i].y);
        sourceVerts.Add(new Vector3(sourceMeshData[i].x, sourceMeshData[i].y, 0));
        levelUVs.Add(new Vector2(0, 0));
        //sourceVerts.Add(new Vector3(levelShapeData[i].x, levelShapeData[i].y, modelLength / 2f));
    }

    sourceVerts.Add(new Vector3(sourceMeshCenter.x, sourceMeshCenter.y, 0));
    levelUVs.Add(new Vector2(0, 0));

    for (int i = 0; i &lt; edgeCount - 1; i++)
    {                                       //0, 1, 2, 3
        levelTris.Add(sourceVerts.Count - 1); //4, 4, 4, 4 
        levelTris.Add(i);                   //0, 1, 2, 
        levelTris.Add(i + 1);               //1, 2, 3,
    }

    levelTris.Add(sourceVerts.Count - 1);
    levelTris.Add(edgeCount - 1);
    levelTris.Add(0);
</code></pre>

<p>9.) Find the outside edges of the circular mesh as needed by the mesh extrusion method. Again, this code is provided in the unity package.</p>

<pre><code>public class Edge
{
    // The indiex to each vertex
    public int[]  vertexIndex = new int[2];
    // The index into the face.
    // (faceindex[0] == faceindex[1] means the edge connects to only one triangle)
    public int[]  faceIndex = new int[2];
}

public static Edge[] BuildManifoldEdges (Mesh mesh)
{
    // Build a edge list for all unique edges in the mesh
    Edge[] edges = BuildEdges(mesh.vertexCount, mesh.triangles);

    // We only want edges that connect to a single triangle
    ArrayList culledEdges = new ArrayList();
    foreach (Edge edge in edges)
    {
        if (edge.faceIndex[0] == edge.faceIndex[1])
        {
            culledEdges.Add(edge);
        }
    }

    return culledEdges.ToArray(typeof(Edge)) as Edge[];
}
</code></pre>

<p>10.) Feed all of this data into the Mesh Extrusion method..</p>

<pre><code>public static void ExtrudeMesh (Mesh srcMesh, Mesh extrudedMesh, Matrix4x4[] extrusion, Edge[] edges, bool invertFaces)
{
    int extrudedVertexCount = edges.Length * 2 * extrusion.Length;
    int triIndicesPerStep = edges.Length * 6;
    int extrudedTriIndexCount = triIndicesPerStep * (extrusion.Length -1);

    Vector3[] inputVertices = srcMesh.vertices;
    Vector2[] inputUV = srcMesh.uv;
    int[] inputTriangles = srcMesh.triangles;

    //Debug.Log(""inputUV:"" + inputUV.Length);

    Vector3[] vertices = new Vector3[extrudedVertexCount + srcMesh.vertexCount * 2];
    Vector2[] uvs = new Vector2[vertices.Length];
    int[] triangles = new int[extrudedTriIndexCount + inputTriangles.Length * 2];

    // Build extruded vertices
    int v = 0;
    for (int i=0;i&lt;extrusion.Length;i++)
    {
        Matrix4x4 matrix = extrusion[i];
        float vcoord = (float)i / (extrusion.Length -1);
        foreach (Edge e in edges)
        {
            //Debug.Log(e.vertexIndex.Length);
            vertices[v+0] = matrix.MultiplyPoint(inputVertices[e.vertexIndex[0]]);
            vertices[v+1] = matrix.MultiplyPoint(inputVertices[e.vertexIndex[1]]);

            uvs[v+0] = new Vector2 (inputUV[e.vertexIndex[0]].x, vcoord);
            uvs[v+1] = new Vector2 (inputUV[e.vertexIndex[1]].x, vcoord);

            v += 2;
        }
    }       

    // Build cap vertices
    // * The bottom mesh we scale along it's negative extrusion direction. This way extruding a half sphere results in a capsule.
    for (int c=0;c&lt;2;c++)
    {
        Matrix4x4 matrix = extrusion[c == 0 ? 0 : extrusion.Length-1];
        int firstCapVertex = c == 0 ? extrudedVertexCount : extrudedVertexCount + inputVertices.Length;
        for (int i=0;i&lt;inputVertices.Length;i++)
        {
            vertices[firstCapVertex + i] = matrix.MultiplyPoint(inputVertices[i]);
            uvs[firstCapVertex + i] = inputUV[i];
        }
    }

    // Build extruded triangles
    for (int i=0;i&lt;extrusion.Length-1;i++)
    {
        int baseVertexIndex = (edges.Length * 2) * i;
        int nextVertexIndex = (edges.Length * 2) * (i+1);
        for (int e=0;e&lt;edges.Length;e++)
        {
            int triIndex = i * triIndicesPerStep + e * 6;

            triangles[triIndex + 0] = baseVertexIndex + e * 2;
            triangles[triIndex + 1] = nextVertexIndex  + e * 2;
            triangles[triIndex + 2] = baseVertexIndex + e * 2 + 1;
            triangles[triIndex + 3] = nextVertexIndex + e * 2;
            triangles[triIndex + 4] = nextVertexIndex + e * 2 + 1;
            triangles[triIndex + 5] = baseVertexIndex  + e * 2 + 1;
        }
    }

    // build cap triangles
    int triCount = inputTriangles.Length / 3;
    // Top
    {
        int firstCapVertex = extrudedVertexCount;
        int firstCapTriIndex = extrudedTriIndexCount;
        for (int i=0;i&lt;triCount;i++)
        {
            triangles[i*3 + firstCapTriIndex + 0] = inputTriangles[i * 3 + 1] + firstCapVertex;
            triangles[i*3 + firstCapTriIndex + 1] = inputTriangles[i * 3 + 2] + firstCapVertex;
            triangles[i*3 + firstCapTriIndex + 2] = inputTriangles[i * 3 + 0] + firstCapVertex;
        }
    }

    // Bottom
    {
        int firstCapVertex = extrudedVertexCount + inputVertices.Length;
        int firstCapTriIndex = extrudedTriIndexCount + inputTriangles.Length;
        for (int i=0;i&lt;triCount;i++)
        {
            triangles[i*3 + firstCapTriIndex + 0] = inputTriangles[i * 3 + 0] + firstCapVertex;
            triangles[i*3 + firstCapTriIndex + 1] = inputTriangles[i * 3 + 2] + firstCapVertex;
            triangles[i*3 + firstCapTriIndex + 2] = inputTriangles[i * 3 + 1] + firstCapVertex;
        }
    }

    if (invertFaces)
    {
        for (int i=0;i&lt;triangles.Length/3;i++)
        {
            int temp = triangles[i*3 + 0];
            triangles[i*3 + 0] = triangles[i*3 + 1];
            triangles[i*3 + 1] = temp;
        }
    }

    extrudedMesh.vertices = vertices;
    extrudedMesh.uv = uvs;
    extrudedMesh.triangles = triangles;
}
</code></pre>

<p>The final output in my case looks like this..</p>

<p><img src=""https://i.stack.imgur.com/hkL6h.png"" alt=""enter image description here""></p>

<p>Good luck, your game looks really cool! Let me know if you figure it out?</p>

<p>Chuck</p>
","23214"
"How do C# and UnityScript differ in Unity development?","11695","","<p>Other than the obvious language differences, how do UnityScript and C# differ when developing games in Unity3D?</p>

<ul>
<li>Is there a noticable performance difference?</li>
<li>Is the UnityScript code packaged as-is? If yes, does this help the game's moddability?</li>
<li>Is it possible to use libraries developed for one language while developing in the other one?</li>
<li>Can the two languages be mixed in the same Unity project; coding some parts in C# and others in UnityScript?</li>
</ul>
","<p><strong>Is there a noticable performance difference?</strong></p>

<p>No. There technically is a <a href=""http://dentedpixel.com/developer-diary/c-vs-unityscript-which-is-faster/"">very small performance difference</a>, but it is not significant enough to base your choice of language on in most cases.</p>

<p><strong>Is it possible to use libraries developed for one language while developing in the other one?</strong></p>

<p>Yes. As long as you make sure to keep the folder structure recommended by the developer of the library, that library can be accessed from any language. This has to do with the <a href=""http://docs.unity3d.com/412/Documentation/ScriptReference/index.Script_compilation_28Advanced29.html"">Unity compilation order</a>. Some features in IDEs, like autocomplete, may not work for the chosen library though. (EDIT: this can be fixed by using the free plugin <a href=""http://unityvs.com"">UnityVS</a> for Visual Studio.)</p>

<p><strong>Is it possible to mix the two languages in the same Unity project by coding some parts in C# and others in Javascript?</strong></p>

<p>Again, yes. It gets complicated quickly though, as you have to make sure everything is compiled in the right order. While it is technically possible, I'd recommend you pick one language and stick with it.</p>

<p><strong>Which language has better game dev specific resources available (books, websites, forums)?</strong></p>

<p>Hard to say. From browsing the forums, I'd say Javascript has slightly more tutorials and code examples. Code is generally pretty easy to port to the other language though, and since libraries are usable cross-language, this will most likely not be a major issue.</p>
","71223"
"Generating island terrains with Simplex Noise (C#/XNA)","11686","","<p>I've got one little question: Is there any code or sample which shows how the simplex noise works? I cannot find anything about it... How should I implement it, without the knowledge how the algorithm works?...</p>

<p>The other question is: Is the simplex noise a good algorithm for island generation? I need huge islands (really huge), with different layers (sand, gras, stone) and clearly visible height-differences, which have soft-edges, so you can go out/into water without jumping over uneven surfaces.</p>
","<p>Ok thanks to all for the help :)</p>

<p>2 days ago i found ""Libnoise"" and a good C# port. I will take this one, because there´s a renderer which renders smoother heightmaps :)</p>
","13520"
"Do you need a license for weapon models?","11676","","<p>When creating your own model for a weapon, say the M4 carbine, and using the model in your game. Do you need a license to use it commercially?
I know that racing games like GT5 has a license for each and every car, but the same apply for weapons?</p>
","<p><strong>I am not a lawyer and you should consult one for real, accurate legal advice.</strong></p>

<p>The name and design are likely trademarked (you can see <a href=""http://en.wikipedia.org/wiki/M4_carbine#Trademark_issues"" rel=""nofollow noreferrer"">here</a> for example that there have been trademark issues with the M4 in the past; other guns will likely have similar issues).</p>

<p>EDIT: It is possible that as far as a trademark is concerned I may have been misinterpreting things, and it may be okay depending on your circumstances. However, you will still potentially need to worry about other intellectual property restrictions (such as any copyrights held in relation to the item in question) which do apply regardless of whether or not your product is commercially available.</p>

<p>At the end of the day, if you violate somebody's intellectual property laws and they call you on it you can be in a world of hurt so it's best to get real legal advice because the risk is pretty severe. There's <a href=""http://maientertainmentlaw.com/category/intellectual-property/"" rel=""nofollow noreferrer"">a good set of articles on intellectual property issues by a Real Lawyer here</a>.</p>
","10048"
"What is ""game state?""","11642","","<p>The terminology ""game state"" is a bit vague to me. Could anybody clarify what is included in the game state, please? </p>

<p>Is it a state of all the variables and objects within the game at particular moment?</p>
","<blockquote>
  <p>An Introduction: Just what in the
  world is state?</p>
  
  <p>Game state can be used to mean a
  variety of things and you'll find it
  used in many different ways in the
  game industry. In this case I'm using
  ""game state"" to provide a description
  of an object at a given point in time
  in a game. Clear as mud to you now?
  Don't worry, I'll try to describe it
  in a different way, one as a geek like
  me you might identify with a little
  better.</p>
  
  <p>Comic books. When buying used comic
  books, they often say what ""state"" or
  condition the comic book is in. The
  current state of the comic book gives
  you some indication of how the comic
  book is going to look when you
  purchase it. Mint, Fine and Poor all
  give an image in your mind of just how
  battered  or worn the comic book is.</p>
  
  <p>The same is true for objects in your
  game. By defining the various valid
  states for your objects, your game
  will know just what to do when it is
  in that state. And just like the comic
  book industry has defined the various
  valid states for comic books, you as
  the governing board for your game must
  define valid states for your objects
  and just exactly how the game should
  respond when those objects are in any
  given state.</p>
</blockquote>

<p>Since this Game State introduction has a very nice way to explain it, i quoted it and you can find the complete article at <a href=""http://www.xnadevelopment.com/tutorials/thestateofthings/thestateofthings.shtml"">http://www.xnadevelopment.com/tutorials/thestateofthings/thestateofthings.shtml</a></p>
","4006"
"Starting out with OpenGL when most tutorials are out of date","11630","","<p>I'm sure there are already a bunch of questions like this asked, but the constant updating of the OpenGL library throws them all away, and in a month or two, the answers here will be worthless again.</p>

<p>I am ready to start programming in OpenGL using C++. I've got a working compiler (DevCpp; do NOT ask me to switch to VC++, and don't ask me why). Now I'm just looking for a solid tutorial on how to program with OpenGL. My assistant found the tutorial provided by NeHe Productions, but as I've come to find out, it's WAY OUT OF DATE! (although I did pull together a basic window to support an OpenGL canvas)</p>

<p>Then I went online, and found the OpenGL SuperBible, which apparently uses freeglut? But what I'd like to know is whether or not SuperBible 5th edition is up to date any longer. The suggestion to freeglut I found said the latest version was 2.6.0 but now it's 2.8.0!</p>

<ul>
<li>Is the OpenGL SuperBible still a good, and fairly up-to-date place to start?</li></li>
<li>Is there a better place to go to learn OpenGL?</li>
<li>Am I allowed to simply store freeglut in the DevCpp include directory (maybe in GL), or is there some important procedure?</li>
<li>Are there any comments or suggestions that I didn't think to ask since I'm only just beginning?</li>
</ul>

<hr>

<p>@dreta cleared some things up for me, so now I have a better idea of what to ask:</p>

<p>I think I'd like to start out with OpenGL using a wrapper library instead of directly accessing OpenGL.<br/>I just think that, for a beginner, it would be easier for me to program and get good results, while I don't yet have to understand all the grimy details (as @stephelton mentioned).</p>

<p>The problem is, I can't find any library that doesn't have undefined references to no longer supported functions. Freeglut sounds operational, but it still uses GLU.<br/>Does anyone know what I can do?<br/>Also, I tried compiling the first SuperBible's source, but I got errors since GLAPI is not being defined as a type, the error originating in the GLU library.</p>

<p>I'd like to use the SuperBible, but I don't know how to fix this.</p>
","<p>Our resident Nicol Bolas maintains an <a href=""http://alfonse.bitbucket.org/oldtut/index.html"" rel=""nofollow"">on-line book about modern graphics programming</a>. It uses modern OpenGL, everything is introduced at an easy to consume pace, it's a good place to start. I've been using it to learn modern OpenGL and it's been doing me wonders in the past 2 months.</p>

<p>Beside that there are bits of knowledge here and there. <a href=""http://www.opengl.org/wiki/Main_Page"" rel=""nofollow"">The OpenGL wiki</a> is quite well maintained. The code isn't ""best practices"" and sometimes there's ambiguity when it comes to OpenGL version, but outside of those rare occasion, it's a great resource.</p>

<p>If you want to learn about GLSL, there's the <a href=""http://www.lighthouse3d.com/tutorials/glsl-core-tutorial/glsl-core-tutorial-index/"" rel=""nofollow"">GLSL Core Tutorial</a> from lighthouse3D. Though this is the only core knowledge i'd ""trust"" on the site, rest tends to be outdated.</p>

<p>Once you start to understand how modern OpenGL is done, you'll have an easy time looking for specific information, filtering out outdated code and most importantly reading the specification. You just have to start somewhere.</p>

<p>Most, if not all actually, of the OpenGL books availible are outdated. The new SuperBible is a freak of some sort and i wouldn't recommend it to anybody. The OpenGL Programming Guide for OpenGL 4.1 comes out September 16th, unfortunetly the 7th edition uses deprecated code, so you just have to wait, i sure am.</p>

<p>And ofcourse, you can always ask questions here.</p>
","28816"
"How does Flow Field pathfinding work?","11564","","<p>Supreme Commander 2 has something called <em>flow field</em> path finding. How does it work? Is there some article available I can read up on how it works?</p>
","<p>I wrote flow fields for sup com 2, and I wrote an article explaining the details. It can be found in the upcoming book ""Game AI Pro: Collected Wisdom of Game AI Professionals"".</p>

<p>Also, I recently did a video stream talking about flow fields for Planetary Annihilation. I show some debug views and explain how it works at a high level. 
<a href=""http://youtu.be/5Qyl7h7D1Q8?t=24m24s"">http://youtu.be/5Qyl7h7D1Q8?t=24m24s</a></p>

<p>Hope this helps</p>
","52940"
"How do I create a wide-angle / fisheye lens with HLSL?","11557","","<p>What are the concepts that need to be implemented in order to achieve the effect of a wide angle lens of varying extremities?</p>

<p>Pseudocode and specific explanation referring to the various stages of the content pipeline, as well as what information needs to be passed in from the source code to HLSL would be very useful.   </p>

<p>Also, what are the differences between implementing a wide-angle lens, and a fisheye?</p>
","<p>A wide-angle lens should not behave differently than other regular lens models. They just have a larger FOV (in the <code>D3DXMatrixPerspectiveFovLH</code> sense -- I'm assuming you use DirectX), or larger left/right and bottom/top values (in the OpenGL <code>glFrustum</code> sense).</p>

<p>I believe the really interesting part lies in modeling the fisheye lens. There's <a href=""http://strlen.com/gfxengine/fisheyequake/"">Fisheye Quake</a> that you can study, it comes with source.</p>

<h2>The true fisheye projection</h2>

<p>The projection of a fisheye lens, however, is highly non-linear. In the more common (to my knowledge, which is limited to surveillance cameras) kind of lens, a point <code>M</code> in space is projected onto the surface of a unit hemisphere, then that surface undergoes a parallel projection onto the unit disc:</p>

<pre><code>           M
             x                 M: world position
              \                M': projection of M on the unit hemisphere
               \  ______       M"": projection of M' on the unit disc (= the screen)
             M'_x'      `-.
             ,' |\         `.
            /   | \          \
           /    |  \          \
          |     |   \          |
__________|_____|____\_________|_________
                M""    O        1
</code></pre>

<p>There are other <a href=""http://en.wikipedia.org/wiki/Fisheye_lens"">fisheye mappings</a> that may give more interesting effects. It's up to you.</p>

<p>I can see two ways to implement the fisheye effect in HLSL.</p>

<h2>Method 1: perform the projection on the vertex shader</h2>

<p><strong>Advantage</strong>: almost nothing needs to be changed in the code. The fragment shader is extremely simple. Rather than:</p>

<pre><code>...
float4 screenPoint = mul(worldPoint, worldViewProjMatrix);
...
</code></pre>

<p>You do something like this (can probably be simplified a lot):</p>

<pre><code>...
// This is optional, but it computes the z coordinate we will
// need later for Z sorting.
float4 out_Point = mul(in_Point, worldViewProjMatrix);

// This retrieves the world position so that we can project on
// the hemisphere. Normalise this vector and you get M'
float4 tmpPoint = mul(in_Point, worldViewMatrix);

// This computes the xy coordinates of M"", which happen to
// be the same as M'.
out_Point.xy = tmpPoint.xy / length(tmpPoint.xyz);
...
</code></pre>

<p><strong>Drawbacks</strong>: since the whole rendering pipeline was thought for linear transformations, the resulting projection is exact for vertices, but all the varyings will be wrong, as well as texture coordinates, and triangles will still appear as triangles even though they should appear distorted.</p>

<p><strong>Workarounds</strong>: it could be acceptable to get a better approximation by sending a refined geometry to the GPU, with more triangle subdivisions. This might also be performed in a geometry shader, but since this step happens after the vertex shader, the geometry shader would be quite complex because it would have to perform its own additional projections.</p>

<h2>Method 2: perform the projection on the fragment shader</h2>

<p>Another method would be to render the scene using a wide angle projection, then distort the image to achieve a fisheye effect using a fullscreen fragment shader.</p>

<p>If point <code>M</code> has coordinates <code>(x,y)</code> in the fisheye screen, it means it had coordinates <code>(x,y,z)</code> on the hemisphere surface, with <code>z = sqrt(1-x*x-y*y)</code>. Which means it had coordinates <code>(ax,ay)</code> in our scene rendered with a FOV of <code>theta</code> such that <code>a = 1/(z*tan(theta/2))</code>. (Not 100% sure about my maths here, I will check again tonight).</p>

<p>The fragment shader would therefore be something like this:</p>

<pre><code>void main(in float4 in_Point : POSITION,
          uniform float u_Theta,
          uniform sampler2D u_RenderBuffer,
          out float4 out_FragColor : COLOR)
{
    z = sqrt(1.0 - in_Point.x * in_Point.x - in_Point.y * in_Point.y);
    float a = 1.0 / (z * tan(u_Theta * 0.5));
    out_FragColor = tex2D(u_RenderBuffer, (in_Point.xy - 0.5) * 2.0 * a);
}
</code></pre>

<p><strong>Advantage</strong>: you get a perfect projection with no distortions apart from those due to the pixel accuracy.</p>

<p><strong>Drawback</strong>: you cannot physically view the whole scene, since the FOV cannot reach 180 degrees. Also, the larger the FOV, the worse the precision in the center of the image... which is precisely where you want maximum precision.</p>

<p><strong>Workarounds</strong>: the loss of precision can be improved by performing several rendering passes, for instance 5, and do the projection in the manner of a cube map. Another very simple workaround is to simply crop the final image to the desired FOV -- even if the lens itself has a 180-degree FOV, you may wish to render only a part of it. This is called ""full-frame"" fisheye (which is kinda ironic, since it gives the impression that you get the ""full"" something while it actually crops the image).</p>

<p>(Note: if you found this useful but not clear enough, please tell me, I feel like writing a more detailed article about this).</p>
","20642"
"When several classes need to access the same data, where should the data be declared?","11556","","<p>I have a basic 2D tower defense game in C++.</p>

<p>Each map is a separate class which inherits from GameState. The map delegates the logic and drawing code to each object in the game and sets data such as the map path.
In pseudo-code the logic section might look something like this:  </p>

<pre><code>update():
  for each creep in creeps:
    creep.update()
  for each tower in towers:
    tower.update()
  for each missile in missiles:
    missile.update()
</code></pre>

<p>The objects (creeps, towers and missiles) are stored in vector-of-pointers. The towers must have access to the vector-of-creeps and the vector-of-missiles to create new missiles and identify targets.</p>

<p>The question is: where do I declare the vectors? Should they be members of the Map class, and passed as arguments to the tower.update() function? Or declared globally? Or are there other solutions I'm missing entirely?</p>

<p>When several classes need to access the same data, where should the data be declared?</p>
","<p>When you need a single instance of a class throughout your program, we call that class a <strong>service</strong>.  There are several standard methods of implementing services in programs:</p>

<ul>
<li><strong>Global variables</strong>. These are the easiest to implement, but the worst design.  If you use too many global variables, you will quickly find yourself writing modules that rely on each other too much (<a href=""http://en.wikipedia.org/wiki/Coupling_%28computer_science%29"" rel=""nofollow noreferrer"">strong-coupling</a>), making the flow of logic very difficult to follow.  Global variables are not multithreading-friendly.  Global variables make tracking the lifetime of objects more difficult, and clutter the namespace.  They are, however, the most performant option, so there are times when they can and should be used, but use them spareingly.</li>
<li><p><strong>Singletons</strong>.  About 10-15 years ago, singletons were <em>the</em> big design-pattern to know about.  However, nowadays they are looked down upon.  They are much easier to multi-thread, but you must limit their use to one thread at a time, which is not always what you want.  Tracking lifetimes is just as difficult as with global variables.<br>
A typical singleton class will look something like this:</p>

<pre><code>class MyClass
{
private:
    static MyClass* _instance;
    MyClass() {} //private constructor

public:
    static MyClass* getInstance();
    void method();
};

...

MyClass* MyClass::_instance = NULL;
MyClass* MyClass::getInstance()
{
    if(_instance == NULL)
        _instance = new MyClass(); //Not thread-safe version
    return _instance;

    //Note that _instance is *never* deleted - 
    //it exists for the entire lifetime of the program!
}
</code></pre></li>
<li><p><strong>Dependency Injection (DI)</strong>.  This just means passing the service in as a constructor parameter.  A service must already exist in order to pass it into a class, so there's no way for two services to rely on each other; in 98% of the cases, <a href=""http://en.wikipedia.org/wiki/Circular_dependency"" rel=""nofollow noreferrer"">this is what you want</a> <em>(and for the other 2%, you can always create a <code>setWhatever()</code> method and pass in the service later)</em>.  Because of this, DI doesn't have the same coupling problems as the other options.  It can be used with multithreading, because each thread can simply have its own instance of every service (and share only those it absolutely needs to).  It also makes code unit-testable, if you care about that.</p>

<p>The problem with dependency injection is that it takes up more memory; now every instance of a class needs references to every service it will use.  Also, it gets annoying to use when you have too many services; there are frameworks that mitigate this problem in other languages, but because of C++'s lack of reflection, DI frameworks in C++ tend to be even more work than just doing it manually.</p>

<pre><code>//Example of dependency injection
class Tower
{
private:
    MissileCreationService* _missileCreator;
    CreepLocatorService* _creepLocator;
public:
    Tower(MissileCreationService*, CreepLocatorService*);
}

//In order to create a tower, the creating-class must also have instances of
// MissileCreationService and CreepLocatorService; thus, if we want to 
// add a new service to the Tower constructor, we must add it to the
// constructor of every class which creates a Tower as well!
//This is not a problem in languages like C# and Java, where you can use
// a framework to create an instance and inject automatically.
</code></pre>

<p><em>See <a href=""https://github.com/ninject/ninject/wiki/Dependency-Injection-By-Hand"" rel=""nofollow noreferrer"">this page</a> (from the documentation for Ninject, a C# DI framework) for another example.</em></p>

<p>Dependency injection is the usual solution for this problem, and is the answer you will see most highly upvoted to questions like this on StackOverflow.com.  DI is a type of <a href=""http://en.wikipedia.org/wiki/Inversion_of_Control"" rel=""nofollow noreferrer"">Inversion of Control</a> (IoC).  </p></li>
<li><p><strong>Service Locator</strong>.  Basically, just a class that holds an instance of every service.  You can <a href=""http://www.codinginlondon.com/2009/05/cheap-ioc-in-native-c.html"" rel=""nofollow noreferrer"">do it using reflection</a>, or you can just add a new instance to it every time you want to create a new service.  You still have the same problem as before - <em>How do classes access this locator?</em> - which can be solved in any of the above ways, but now you only need to do it for your <code>ServiceLocator</code> class, rather than for dozens of services.  This method is also unit-testable, if you care about that sort of thing.  </p>

<p>Service Locators are another form of Inversion of Control (IoC).  Usually, frameworks that do automatic dependency injection will also have a service locator.</p>

<p>XNA <em>(Microsoft's C# game programming framework)</em> includes a service locator; to learn more about it, see <a href=""https://gamedev.stackexchange.com/questions/13723/xna-static-classes-from-game-libraries-executing-after-content-pipeline-extensi/13763#13763"">this answer</a>.</p></li>
</ul>

<hr>

<p>By the way, IMHO the towers should not know about the creeps.  Unless you are planning on simply looping over the list of creeps for every tower, you'll probably want to implement some nontrivial <a href=""http://en.wikipedia.org/wiki/Nearest_neighbour_search"" rel=""nofollow noreferrer"">space partitioning</a>; and that sort of logic doesn't belong in the towers class.</p>
","14232"
"Where is the ""Scripts Window"" menu in Blender 2.59?","11523","","<p>I'm trying to import a script into Blender, and I have the script in my directory and I pushed F8 to reload scripts, but the instructions for running this script say:</p>

<blockquote>
  <p>In the ""Scripts Window"" run ""Scripts → Export → OGRE Meshes"". </p>
</blockquote>

<p>I've seen other similar instructions for other scripts. But the toolbar only contains ""File/Add/Render/Help."" Changing the ""screen layout"" to Scripting doesn't reveal any additional options, either.</p>

<p>I'm sure I'm just missing something obvious. Please help!</p>
","<p>Those instructions are for Blender 2.49 and before. Scripting API is completely different (and much better) since 2.5.
Import and export is in the file menu. What you are looking for is the add-on list, where you can enable them and see where are they located. File -> User preferences... -> Add-ons.</p>

<p>Maybe you need to install the appropiate add-on for blender 2.5x, if it exists.</p>

<p>Edit: it's still in development but here it is: <a href=""http://www.ogre3d.org/tikiwiki/Blender+2.5+Exporter"">http://www.ogre3d.org/tikiwiki/Blender+2.5+Exporter</a></p>
","18586"
"How does client-side prediction work?","11518","","<p>I've read Valve + Gafferon and hundreds of pages from Google, but for whatever reason I can't get my head around client prediction.</p>

<p>To my understanding, the basic problem is:</p>

<ul>
<li>Client A sends input at <code>T0</code></li>
<li>Server receives input at <code>T1</code></li>
<li>All clients receive the change at <code>T2</code></li>
</ul>

<p>At <code>T2</code> however, using client prediction, Client A is now at a position appropriate to <code>T4</code>.</p>

<p>How do you ensure that the Client A, when predicting that the server will accept the movement request, won't be ahead of the server? Obviously all the time they are ahead, this results in snapping back to where the server last saw them. With all corrections I've tried, this is still noticeable when you stop, because the server stops behind you</p>
","<p>I wrote <a href=""http://www.gabrielgambetta.com/fpm1.html"">a series of articles</a> on this. It is based on the same ideas you've read elsewhere, but explained in a very detailed and (I hope) accessible way.</p>
","22462"
"How can I render a texture to the screen in SDL2?","11505","","<p>I've recently started upgrading my SDL version from 1.2 to 2.0.3, and while on the SDL Wiki, I've come across SDL_Renderer, SDL_Window, and SDL_Texture. I did some research and found a link at <a href=""https://stackoverflow.com/questions/21007329/what-is-a-sdl-renderer"">StackExchange</a> to be particularly informative. However, I'd like to know more about the process of getting a texture on the screen with this new software version.</p>

<h2>My Question</h2>

<p>By what process does SDL2 display a texture to the user's screen?</p>

<h2>My Current Understanding</h2>

<p>My current understanding is that a renderer is tied to a single window, which allows the coder to blit a texture (or multiple) to a renderer, which is then displayed to the window. Is this approximation correct?</p>
","<p>I know how you feel, SDL2 is somewhat different from the earlier one, to make it easier, I'll explain how SDL_Renderer, SDL_Window, and SDL_Texture works.</p>

<pre><code>//CREATE WINDOW
SDL_Window *window = SDL_CreateWindow(""Title"", 100, 100, 400, 600,SDL_WINDOW_SHOWN);
/*You have created a variable named window which is in the type of SDL_Window,
SDL_Create Window creates a window and it's attributes are inside the (), the first 
one is the title, next is the x coordinate, then the y coordinate, then the width 
of the window, the height of the window, then the command that the window could 
understand you can put SDL_WINDOW_RESIZABLE if you want the window to be resizable etc.*/
//Mind you that the (0,0) coordinate is in the top left of the screen so the greater the x value, the it moves to the right and the greater the y value, the more it moves down.


//CREATE RENDERER
SDL_Renderer *renderer = SDL_CreateRenderer( window, -1, SDL_RENDERER_ACCELERATED);
/*You created a variable named renderer which is a type of SDL_Renderer, as you can
see, SDL is very literal, SDL_CreateRenderer creates a renderer, the values inside
the parentheses are (name of the window, the rendering drive, the command the 
renderer would understand), the renderer needs to know what or where your window 
is, thus, it asks for it then it needs to know what drive would work on it, you can
put -1 to use the default one/the one you previously used, then the command.*/


//CREATE TEXTURE
SDL_Texture* texture = IMG_LoadTexture(renderer, ""FILE"");
/*You created a texture variable, IMG_LoadTexture has the ability to load a picture
and immediately convert it into a texture, it asks for your renderer since the 
renderer is the one that would works on it and it also asks for the file name
let's say your file's name is ""texture.png"" then you just input that in that area,
the file should be placed inside the the folder that contains the other header files.

//Now just loading a texture won't give you power over it, what you want now is to
//gain control over it, that is why we create an rect

SDL_Rect texture_rect;
texture_rect.x = 0;  //the x coordinate
texture_rect.y = 0; // the y coordinate
texture_rect.w = 50; //the width of the texture
texture_rect.h = 50; //the height of the texture

/*Now, our texture should display the the top left corner since the coordinate is at
(0,0) and it should be 50x50, which would make the texture be shaped like a square*/

GAME LOOP AREA 
SDL_RenderClear(renderer); //clears the renderer

SDL_RenderCopy(renderer, texture, NULL, &amp;texture_rect); 
/*SDL_RenderCopy is responsible for making the gameloop understand that there's 
something that wants to be rendered, inside the parentheses are (the renderer's name,
the name of the texture, the area it wants to crop but you can leave this as NULL
if you don't want the texture to be cropped, and the texture's rect)*/

SDL_RenderPresent(renderer); //updates the renderer
</code></pre>

<p>Hope you understood the code, Happy Coding :) and don't forget to detroy the texture in the end to avoid memory leaks ( use something like SDL_DestroyTexture(texture) ) &lt;-put this outside the gameloop so that when the gameloop exits, then this would be read.</p>
","73048"
"How do I find all game objects with particular name?","11463","","<p>I'm trying to mimic <code>FindGameObjectsWithTag</code> with <code>FindGameObjectsWithName</code>. I know using tags is faster, but I'm trying create a way to search for objects I spawn with a child object I name on instantiation through the inspector.</p>

<p>My goal is create multiple enemy spawners. My current spawner has a drag and drop variable for enemy prefabs. It looks for enemies tagged ""ReSpawn"", then checks if that length is below a value, to start spawning more. I would like to upgrade my current single spawner to still check for enemies named ""ReSpawn"", but then check if those respawns have a child object a name specified in the editor.  This way, I can set the enemy spawners anywhere (e.g. near water, tall grass, forests, etc), and when I defeat one, the specific spawner will instantiate one of its opponents for that area.</p>

<hr>

<p>Here is my code, so far:</p>

<pre><code>var ThisSpot:String;
var Oppos : GameObject[];
var OppoCount : GameObject[];

var HowMany = 3;
var spawnSizeArea = 25;

function Start() {
    StartCoroutine (""Spawn"");
}

function Update () {
    OppoCount = GameObject.FindGameObjectsWithTag(""Respawn"");
    // OppoCount = GameObject.FindWithName(ThisSpot);  This is what I am trying to achieve

    if(OppoCount.length &lt; HowMany) {
        StartCoroutine (""Spawn"");
    }
}

function Spawn() {
    var length = Oppos.length-1;
    var index = Mathf.Round(length*UnityEngine.Random.value);
    curSpawn = Oppos[index];

    var xz = Random.insideUnitCircle * spawnSizeArea;
    var newPosition = Vector3(xz.x,0,xz.x)+transform.position;

    yield WaitForSeconds(Random.Range(70,120));

    Instantiate(curSpawn, newPosition, transform.rotation);

    // Then I could use these 2 lines of code below to use multiple spawners      
    //var newOp : GameObject = Instantiate(curSpawn, newPosition, transform.rotation);
    //newOp.transform.Find(""fighter"").gameObject.name=ThisSpot;

    StopCoroutine(""Spawn"");
}
</code></pre>
","<p>Unity best practices are to <em>never</em> use <code>Find</code> in any of its incarnations at run time.  It's slow and unnecessarily ties the name of the object with its functionality.  </p>

<p>Any time you call <code>Instantiate</code> you can save off the return value and store it somewhere (i.e. a <code>List</code> in some component your write).  Then you can just iterate over the elements of that list to get what you want.</p>

<p>So for your spawner example, your spawner could have a list of game objects that it has spawned.  In <code>Update</code> you can iterate over that list and count the number of non-null gameobjects (to check for destroyed objects).  Alternatively the enemy can have a reference to its spawner and remove itself from that list in <code>OnDestroy</code>.  Then if that number is less than a certain value spawn a new one.</p>
","15617"
"Transform coordinates from 3d to 2d without matrix or built in methods","11463","","<p>Not to long ago i started to create a small 3D engine in javascript to combine this with an html5 canvas.</p>

<p>One of the issues I run into is how can you transform 3d to 2d coords.
Since I cannot use matrices or built in transformation methods I need another way.</p>

<p>I've tried implementing the next explanation + pseudo code:
<a href=""http://freespace.virgin.net/hugo.elias/routines/3d_to_2d.htm"" rel=""nofollow"">http://freespace.virgin.net/hugo.elias/routines/3d_to_2d.htm</a></p>

<p>Unfortunately no luck there. I've replace all the input variables with data from my own camera and object classes.</p>

<p>I have the following data:
An object with a rotation, position vector and an array of 4 3d coords (its just a plane)
a camera with a position and rotation vector
the viewport -> a square 600 x 600 surface.
The example uses a zoom factor which I've set as 1</p>

<p>Most hits on google use either matrix calculations or don't implement camera rotation.
Basic transformation should  be like this:
screen.x = x / z * zoom
screen.y = y / z * zoom</p>

<p>Can anyone point me in the right direction or explain to me howto achieve this?</p>

<p>edit:
Thanks for all your posts, I haven't been able to apply all this to my project yet but I hope to do this soon.</p>

<hr>

<p>Ok after playing around a while some issues still remain.
I've created a new projection matrix:</p>

<pre><code>    var w = (2 * nearPlane) / viewportWidth;
    var h = (2 * nearPlane) / viewportHeight;
    var q = farPlane / (farPlane - nearPlane);

    this.ProjectionMatrix = $M([
      [w, 0, 0, 0],
      [0, h, 0, 0],
      [0, 0, q, 1],
      [0, 0, (nearPlane * farPlane) / (nearPlane - farPlane), 0]
    ]);
</code></pre>

<p>where viewport = 600 * 450</p>

<p>and near plane = 0.5 and far plane = 500</p>

<p>the original code for drawing the vertices is this:</p>

<pre><code> var comboMatrix = world.WorldMatrix.x(camera.ViewMatrix);
    for (i = 0; i != this.NumberOfPolygons; i++) {
        var transformedVertices = new Array(verticesPerPolygon);
        var valid = new Boolean(1);
        for (j = 0; j != verticesPerPolygon; j++) {

            currentVertex = this.Mesh[i][j].x(comboMatrix);

            currentVertex.elements[0][0] = currentVertex.elements[0][0] / currentVertex.elements[0][2];
            currentVertex.elements[0][1] = currentVertex.elements[0][1] / currentVertex.elements[0][2];

            if (currentVertex.elements[0][0] &lt; -1 || currentVertex.elements[0][0] &gt; 1 || currentVertex.elements[0][1] &lt; -1 || currentVertex.elements[0][1] &gt; 1) {
                valid = new Boolean(0);
                break;
            }

            // Process Viewport Mapping Transformation
            currentVertex.elements[0][0] = currentVertex.elements[0][0] * 300 + 300;
            currentVertex.elements[0][1] = -currentVertex.elements[0][1] * 300 + 300;

            transformedVertices[j] = currentVertex;
        }

        // Draw the polygon
        if (valid == true) {
            this.DrawQuad(context, transformedVertices, true, new Boolean(0), new Boolean(1));
        }
    }
</code></pre>

<p>which kinda works since the letter H is drawn on my screen. Moving the camera however makes parts of the letter stop being drawn whenever one of the vertices is outside a 300 * 300 region. 
I'm assuming this has something to do with a very basic implementation of a projection in these lines:</p>

<pre><code>            currentVertex.elements[0][0] = currentVertex.elements[0][0] * 300 + 300;
            currentVertex.elements[0][1] = -currentVertex.elements[0][1] * 300 + 300;
</code></pre>

<p>Can anybody help me out howto change this piece of code so it works with my projection matrix?</p>

<p>I've tried removing the last 2 lines and changing transformedVertices[j] = currentVertex; into transformedVertices[j] = currentVertex.x(projection);
with no result.</p>
","<p><strong>Linear Algebra Library</strong></p>

<p>Although you can do all the calculations without using matrices, using them makes everything <em>significantly</em> easier.  For starters, if you don't want to implement matrices and vectors yourself, I've successfully used the following library before:</p>

<p><a href=""http://sylvester.jcoglan.com/"">Sylvester - Vector and Matrix Math for Javascript</a></p>

<p>You can just copy and paste the packed version of the library at the top of your code - it's a one liner.</p>

<p>If after this you still intend to do this without matrices, the process is pretty much the same as I'm going to show, but you'll have to unroll all of the matrices multiplications yourself into their own separate expressions, and run them separately.</p>

<p><strong>Example</strong></p>

<p>As for an example of how to use it, I've digged up some old code of mine which you can try below:</p>

<p><a href=""http://jsfiddle.net/JMa9b/"">http://jsfiddle.net/JMa9b/</a></p>

<p>I'm not sure how much that will be helpful to you though. The code is a mess - it was done many years ago when I was just starting to learn about 3D, and it was pretty much just me messing around trying to get some 3D image rendered from scratch. Also, I didn't even know Javascript, so I was just making it up as I progressed, so disregard anything that looks wrong language wise.</p>

<p><strong>More Info</strong></p>

<p>The most relevant is the way I calculate the world matrix that is rotating the object:</p>

<pre class=""lang-js prettyprint-override""><code>var cx = Math.cos(rotX);
var sx = Math.sin(rotX);
var cy = Math.cos(rotY);
var sy = Math.sin(rotY);
var cz = Math.cos(rotZ);
var sz = Math.sin(rotZ);

var rotXMatrix =$M([
  [1,0,0,0],
  [0,cx,sx,0],
  [0,-sx,cx,0],
  [0,0,0,1]
]);

var rotYMatrix = $M([
  [cy,0,-sy,0],
  [0,1,0,0],
  [sy,0,cy,0],
  [0,0,0,1]
]);

var rotZMatrix = $M([
  [cz,sz,0,0],
  [-sz,cz,0,0],
  [0,0,1,0],
  [0,0,0,1]
]);

var translationMatrix = $M([
  [1,0,0,0],
  [0,1,0,0],
  [0,0,1,0],
  [posX,posY,posZ,1]
]);    

worldMatrix = Matrix.I(4);
worldMatrix = worldMatrix.x(rotXMatrix);
worldMatrix = worldMatrix.x(rotYMatrix);
worldMatrix = worldMatrix.x(rotZMatrix);
worldMatrix = worldMatrix.x(translationMatrix);
</code></pre>

<p>Adding scaling would have been pretty easy too. For instance, for a uniform scale, it would be something like:</p>

<pre><code>var scaleMatrix=$M([
  [scale,0,0,0],
  [0,scale,0,0],
  [0,0,scale,0],
  [0,0,0,1]
]);
</code></pre>

<p>The most important thing is that when creating the <code>World Matrix</code> for your objects, you must multiply these individual matrices in the correct order, which is scale, rotation and translation.</p>

<p>As for the <code>View Matrix</code> for your camera, it's somewhat similar to the World Matrix, but everything is done the other way around. You negate the rotation angles and the positions , and multiply the matrices together in the <em>inverse</em> order as the one above.</p>

<p>I got the formulas from <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/bb206269%28v=vs.85%29.aspx"">here</a> by the way (they can be slightly different in OpenGL though).</p>

<p><strong>Notes on Perspective</strong></p>

<p>For the perspective projection I'm simply taking the view space X and Y components and dividing by Z. That works in a simple ""toy"" case like this, but if you want to deal with other parameters such as the aspect ratio, field of view, near and far planes, etc, you'll want to do it with a matrix too. For example, a matrix such as this (taken from DX documentation):</p>

<pre><code>2*zn/w  0       0              0
0       2*zn/h  0              0
0       0       zf/(zf-zn)     1
0       0       zn*zf/(zn-zf)  0
</code></pre>

<p>The way to use such a matrix is that you take your coordinates in view space (after applying the world and view matrix) with an added 1 as the fourth component, i.e. <code>(x,y,z,1)</code>, multiply that by the projection matrix, and then <em>homogenize</em> the result back into 3D by dividing everything by W, i.e. <code>(x,y,z,w)=(x/w,y/w,z/w)</code>.</p>

<p>And by the way, the simplest perspective matrix possible is something like:</p>

<pre><code>1 0 0 0
0 1 0 0
0 0 1 1
0 0 0 0
</code></pre>

<p>Which basically discards the W component and stores Z on it. Then when you homogenize the result is the same as dividing by Z, which is what I did directly in my code.</p>
","25588"
"Any tips for creating cross-platform games?","11434","","<p>Do you have any tips/recommendations when creating a cross-platform game in C/C++?</p>
","<p><strong>Hide anything platform-specific behind abstraction layers</strong></p>

<p>This means stuff like rendering, audio, user input, and file IO. One common trick to abstracting that without inducing a run-time performance penalty is platform-agnostic headers with platform-specific implementation files:</p>

<pre><code>// FileSystem.h
class FileSystem {
public:
    FileHandle OpenFile(const char * path);
    // other stuff...
}

// FileSystemWindows.cpp
FileHandle FileSystem::OpenFile(const char * path) {
    // call windows API...
}
</code></pre>

<p>Then configure the builds for each platform to build against the proper .cpp file.</p>

<p><strong>Make your content pipelines read in platform-independent assets and output platform-specific content for each platform</strong></p>

<p>For example, author your textures as .tga or just .psd, then have a pipeline that can automatically convert those to the different platform-specific formats you need.</p>

<p><strong>Don't assume a specific memory layout or endianness in your data</strong></p>

<p>Platforms may vary in byte order, padding, alignment, and word size. Any code that cares about that must be thoroughly tested on all platforms.</p>

<p><strong>Test on all platforms, all the time</strong></p>

<p>You <em>will</em> get bitten by platform-specific bugs. Would you rather get bitten now, or right when you're trying to get the game out the door?</p>
","212"
"Get points on a line between two points","11417","","<p>I'm making a simple space game in JavaScript, but now I've hit a wall regarding vectors.</p>

<p>The game view is top-down on a 2d grid.  When the user clicks on the grid, the space ship will fly to that spot.</p>

<p>So, if I have two sets of points:</p>

<pre><code>{ x : 100.2, y : 100.6 }; // the ship
{ x : 20.5,  y : 55.95 }; // the clicked coordinates
</code></pre>

<p>If the game loop ticks at 60 iterations per second, and the desired ship velocity is 0.05 points per tick (3 points per second), how do I calculate the new set of coordinates for the ship for each tick of the game loop?</p>

<p>p.s. I do not want to account for inertia, or multiple vectors affecting the ship, I just want the ship to stop whatever it is doing (i.e. flying one way) and move to the clicked coordinates at a static speed.</p>
","<p>In Pseudocode:</p>

<pre><code>speed_per_tick = 0.05
delta_x = x_goal - x_current
delta_y = y_goal - y_current
goal_dist = sqrt( (delta_x * delta_x) + (delta_y * delta_y) )
if (dist &gt; speed_per_tick)
{
    ratio = speed_per_tick / goal_dist
    x_move = ratio * delta_x  
    y_move = ratio * delta_y
    new_x_pos = x_move + x_current  
    new_y_pos = y_move + y_current
}
else
{
    new_x_pos = x_goal 
    new_y_pos = y_goal
}
</code></pre>
","23432"
"How can I reverse the effect of a transformation matrix?","11414","","<p>I have recently been working on a game with using OpenGL and C++ through GLFW. </p>

<p>In the game I have an airship with a turret mounted on it. The airship moves around in world space coordinates and the turret 'follows' it.</p>

<p>The turret has it's own coordinate space for its look/aim direction. Basically, when the turret aims in direction <code>(0,0,1)</code>, it aims parallel to the airships direction of movement. </p>

<p>To give the turret a world space target, I have a matrix that takes world space coordinates and transforms these to turret space coordinates.</p>

<p>As the turret fires, I want it to spawn projectiles in world space, so is there an elegant way of using my transformation matrix to convert turret space coordinates back to world space?</p>

<p>A more general way of asking the question might be: if I have a matrix <code>M</code> that takes coordinates from space <code>A</code> to space <code>B</code>. Is there an easy way to use <code>M</code> to get the coordinates from <code>B</code> to <code>A</code>?</p>
","<p>So long as the matrix <code>M</code> is <a href=""http://en.wikipedia.org/wiki/Invertible_matrix"">invertible</a> (which it generally will be, unless you're doing something very unusual), then computing the <a href=""http://mathworld.wolfram.com/MatrixInverse.html"">matrix inverse</a> of <code>M</code> will give you a matrix that does what you want.</p>

<p>That is, if <code>M</code> performs some transformation, <code>inverse(M)</code> performs the ""opposite"" transformation. </p>

<p>Most matrix/vector libraries provide a means for computing the inverse.</p>
","88485"
"How do I properly check if a particular OpenGL version is available?","11393","","<p>I can't find any information on glCreateContextAttribsARB returning errors if a version is unsuported by the driver. So how do i check if it is? I don't want the program to hard crash because glCreateContextAttribsARB failed and i had no chance to check why it did.</p>

<p>Here's my code, i try to keep it minimalistic, the OpenGLVersion uses the glGetIntegerv to get the major and minor didgits and creates a number out of it. It checks if the version is 'least 3.3, though i've no idea if this actually does anything unless i set up glCreateContextAttribsARB with the wrong numbers.</p>

<p>So when does OpenGL ""get a version"", so that the glGetIntegerv returns a valid information? Is it something built in or does it return something valid only after i set up the context? How do i check if the OpenGL version i want to use is supported?</p>

<pre><code>void CreateOpenGLContext(HWND hWnd){

    //Set the pixel format

    PIXELFORMATDESCRIPTOR pfd =
    {
        sizeof(PIXELFORMATDESCRIPTOR),
        1,
        PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER,
        PFD_TYPE_RGBA,
        32,
        0, 0, 0, 0, 0, 0,
        0,
        0,
        0,
        0, 0, 0, 0,
        24,
        8,
        0,
        PFD_MAIN_PLANE,
        0,
        0, 0, 0
    };

    hDC = GetDC( hWnd );
    GLuint PixelFormat = ChoosePixelFormat( hDC, &amp;pfd );
    SetPixelFormat( hDC, PixelFormat, &amp;pfd );

    //Create an OpenGL context to get access to the WGL extensions

    hRC = wglCreateContext( hDC );
    wglMakeCurrent( hDC, hRC );

    //Load functions

    if(glload::LoadFunctions() == glload::LS_LOAD_FAILED){
        MessageBox( NULL, TEXT(""Failed to load OpenGL extensions.""), TEXT(""Error""), MB_OK | MB_ICONEXCLAMATION );
        PostQuitMessage(0);
    }

    //Load WGL extensions

    if(glload::LoadWinFunctions(hDC) == glload::LS_LOAD_FAILED){
        MessageBox( NULL, TEXT(""Failed to load WGL extensions.""), TEXT(""Error""), MB_OK | MB_ICONEXCLAMATION );
        PostQuitMessage(0);
    }

    //Use WGL extensions to create an OpenGL 3.3 context

    const int contextAttributes[] =
    {
        WGL_CONTEXT_MAJOR_VERSION_ARB, 3,
        WGL_CONTEXT_MINOR_VERSION_ARB, 3,
        WGL_CONTEXT_FLAGS_ARB, WGL_CONTEXT_FORWARD_COMPATIBLE_BIT_ARB,
        0
    };

    HGLRC hRC3 = wglCreateContextAttribsARB( hDC, hRC, contextAttributes);

    wglMakeCurrent( hDC, hRC3 );
    wglDeleteContext( hRC );
    hRC = hRC3;

    //Check if the system supports OpenGL version 3.3

    if(OpenGLVersion() &lt; 33){
        MessageBox( NULL, TEXT(""Your system doesn't support OpenGL version 3.3""), TEXT(""Error""), MB_OK | MB_ICONEXCLAMATION );
        PostQuitMessage(0);
    }
}
</code></pre>
","<blockquote>
  <p>I'd like to know if the way i'm checking if the OpenGL version of choice (3.3) is availible.</p>
</blockquote>

<p>Allow me to state this more clearly:</p>

<p>The <em>only way</em> to know if your OpenGL implementation supports a particular version is to attempt to create a context with that version and see if you get a valid context as a result. <code>wglCreateContextAttribsARB</code> will either return the version you requested (or a backwards-compatible higher version), or it will <em>fail</em>. And failure is the only way to know what is and is not supported.</p>

<hr>

<blockquote>
  <p>I can't find any information on glCreateContextAttribsARB returning errors if a version is unsuported by the driver.</p>
</blockquote>

<p><a href=""http://www.opengl.org/registry/specs/ARB/wgl_create_context.txt"" rel=""noreferrer"">Ahem:</a></p>

<blockquote>
  <p>On failure wglCreateContextAttribsARB returns NULL. Extended error information can be obtained with GetLastError. Conditions that cause failure include:</p>
  
  <p>...</p>
  
  <p>If the pixel format associated with  does not support OpenGL contexts providing the requested API major and minor version, forward-compatible flag, and/or debug context flag, then <code>ERROR_INVALID_PIXEL_FORMAT</code> is generated.</p>
</blockquote>

<p>So just check to see if you got an actual context. If you didn't, then it failed.</p>

<p>But really, there's not much point to having a check/fail/retry cycle. You wrote your code expecting some minimum version of OpenGL. That version is what you should ask for. If you happen to get a version higher than this version, great. But no matter what, you will get a version of OpenGL that is backwards compatible with what you asked for.</p>
","28457"
"How do I change the material of an object with Script in Unity?","11388","","<p>I was making a game with Unity and I want to change an object's material using UnityScript when the player collects 5 collectables that I made. The collectables get stored in an int variable called Score.</p>
","<p>If you want to change a Material in Unity you have to retrieve it first.</p>

<p>If your GameObject uses a <a href=""http://docs.unity3d.com/ScriptReference/Material.html"" rel=""nofollow"">Material</a> it means that it uses a <a href=""http://docs.unity3d.com/ScriptReference/Renderer.html"" rel=""nofollow"">Renderer</a>.</p>

<p>You can retrieve your object renderer using the internal variable <code>renderer</code> or get it using the <code>GetComponent</code> function. On the renderer object you will find a <a href=""http://docs.unity3d.com/ScriptReference/Renderer-material.html"" rel=""nofollow"">material</a> property containing the active <code>Material</code>.</p>

<p>For example:</p>

<pre><code>MeshRenderer my_renderer = GetComponent&lt;MeshRenderer&gt;();
if ( my_renderer != null )
{
   Material my_material = my_renderer.material;
}
</code></pre>

<p>If you want to change the current material, you can use the same access. For example:</p>

<pre><code>my_renderer.material = other_material;
</code></pre>

<p>I suggest to make <code>other_material</code> a <code>public Material</code> variable of your game object. However if you want to load it at runtime you should have a look at <a href=""http://docs.unity3d.com/ScriptReference/Resources.Load.html"" rel=""nofollow"">Resources.Load</a>.</p>

<p>I hope it helps.</p>
","84162"
"How might I eliminate asymmetrical gameplay caused by turn order?","11323","","<p>I'm designing a turn based game in which players profit from buying, transporting, and selling resources. Each turn, the map has to produce a certain number of resources and different locations, and resource prices have to be updated. Because of this, each round, after every player has taken their turn, the game state has to be updated; resources are consumed/produced, prices in each cell of the map need to be updated, etc. Originally, I was going to have a simple turn order, where each player took their turn, then the map is updated, then the cycle repeats in the same order. However, after a little bit of testing, it became clear that this gave a significant advantage to players who have their turn right after the map is updated. They're able to collect the newly produced resources before any one else has a chance to.</p>

<p>The easiest way I could think of to balance out the gameplay for all players is to randomize the turn order after each round. While this would give everyone a fair chance, I'm worried that this might be too big of a shift away from strategy and towards luck.</p>

<p>How might I eliminate asymmetrical gameplay caused by turn order?</p>
","<p>Have the players take their turns simultaneously. This also has the added benefit of speeding up the game, because players don't sit idle while waiting for the other players to make their moves. In that case you might want to separate each round into an interactive ""planning"" phase and an automatic ""execution"" phase. </p>

<p>During the planning phase, all players give orders, but no orders get executed yet. The other players do not see what orders the other players are giving. Players are free to take back any actions during that phase. When a player is satisfied with their plan, they click on ""end turn"". </p>

<p>When all players clicked on ""end turn"", the game goes into an ""execution"" phase. The orders of the players get executed and the results are resolved. This requires some game design considerations for handling cases where two players make moves which contradict each other, for example two players try to collect the same resource, move onto the same space (which can only hold one of them) or buy the same unique item. There are several ways to resolve such situations. Which one is most interesting depends on your overall game design.</p>

<p>When this just doesn't fit into your game design, do a game-state update before every individual player's turn, and not just when all players have finished. That way every player has the opportunity to snatch a resource which got spawned on the start of their turn.</p>
","143062"
"How much memory does a texture take up on the GPU?","11301","","<p>A large png on disk may only take up a couple megabytes but I imagine that on the gpu the same png is stored in an uncompressed format which takes up much more space. Is this true? If it is true, how much space?</p>
","<p>JPG and PNG files will almost always be smaller on-disk than in memory; they need to be decompressed on-the-fly to acquire raw RGB data, thus requiring more processing power for the loading and more RAM afterwards. So many modern engines opt to store the same format on disk as they do in memory, leading to files that are the same size as the texture's memory requirements (but also larger than a PNG or JPG). RGB/RGBA and S3TC/DXTn/BCn are the most widely used formats, because they are read straight into memory without any processing (DXT textures are precompressed).</p>

<p>So, these are the sizes for different common texture formats:</p>

<ul>
<li>L (luminance, e.g. greyscale): width * height * 1 byte.</li>
<li>LA (luminance and alpha, common for fonts): width * height * 2 bytes.</li>
<li>RGB (color, no alpha): width * height * 3 bytes.</li>
<li>RGBA (color with alpha): width * height * 4 bytes.</li>
<li>DXT1/BC1 (color, binary alpha): (width * height * 4 bytes) / 8 (8:1 compression ratio).</li>
<li>DXT3/BC2 (color, sharp alpha)/DXT5/BC3 (color, gradient alpha): (width * height * 4 bytes) / 4 (4:1 compression ratio).</li>
</ul>

<p>If you use a image with <a href=""http://en.wikipedia.org/wiki/Mipmap"">mipmaps</a>, the texture will require 4/3 as much memory. Additionally, the texture width and height may be rounded up internally to be a power of two on old or less capable hardware, and on some very limited hardware, also forced to be a square.</p>

<p>More info on DXT: it's a lossy compression; this means, some color data is lost when compressing the texture. This has a negative impact on your texture, distorting sharp borders and creating ""blocks"" on gradients; but the benefits are far better than the disadvantages (if you have a texture that looks horribly bad in DXT, just keep it uncompressed; the other ones will make up for the size loss). Also, since the pixels are compressed by fixed-size blocks, the texture width and height must be a multiple of four.</p>
","5177"
"Examples of faking 3D","11291","","<p>Does anyone know of any good examples of 3D being faked in 2D (not necessarily code, but games I could look up)? The player has the perspective that they are going 'into' the screen and things are coming out at them. At the moment, I'm simply scaling the 2D enemies to give the illusion that they're coming closer, but it still feels quite flat. Are there any tips on how to give it more of a 3D illusion without actually using a 3D engine? </p>

<p><strong>Edit</strong>: Just came across the term 'Mode7' and <a href=""http://www.youtube.com/watch?v=M2bcOUQrvrU"">this video</a> which shows pretty much what I'm trying to figure out. (especially the games at 0:13 and 1:03). What's a good way of implementing something like this?</p>
","<p>One of my favorite classic arcade games also happened to do fake 3D: <a href=""http://www.youtube.com/watch?v=34JbhA154To"">Space Harrier</a></p>

<p>In that video you can see a few tricks they used, but one of the most effective visual effects is so seamless that you might not even notice it happening: when the player (or importantly the camera) moves, they use <a href=""http://en.wikipedia.org/wiki/Parallax"">parallax</a> to give objects in the scene a feeling of depth.</p>

<p>That is, closer objects move side to side faster than distant objects. The classic example of parallax is looking out the window of a moving car: nearby stuff like street signs whip by in a blur, trees further away move more slowly, while distant things like mountains barely appear to be moving.</p>

<p>In addition, objects don't scale linearly as they get closer. That is, objects only scale a little while far away and scale up faster when close; scaling linearly would be if they scale up at the same rate the entire time. You say you're already scaling your objects as they get closer, but you may be scaling them linearly and that looks flat.</p>

<p>ADDITION: <a href=""http://www.youtube.com/watch?v=-IFIVFbR1fM"">Afterburner</a> is another classic arcade game that used a lot of the same graphics tricks.</p>
","17506"
"Object-Oriented OpenGL","11244","","<p>I have been using OpenGL for a while and have read a large number of tutorials.  Aside from the fact that a lot of them still use the fixed pipeline, they usually throw all the initialisation, state changes and drawing in one source file.  This is fine for the limited scope of a tutorial, but I’m having a hard time working out how to scale it up to a full game.</p>

<p>How do you split your usage of OpenGL across files?  Conceptually, I can see the benefits of having, say, a rendering class that purely renders stuff to screen, but how would stuff like shaders and lights work?  Should I have separate classes for things like lights and shaders? </p>
","<p>I think OO OpenGL is not that necessary. It is different when you talk about shader, model, etc class.</p>

<p>Basically you would do game/engine initialization first (and other things). Then you would load textures, models and shaders to RAM (if needed) and Buffer Objects, and upload/compile shaders. After that, you, in your data structure or class of shader, model, have <em>int</em> IDs of shaders, model and texture buffer objects.</p>

<p>I think most engines have engine components and everyone of them has certain interfaces. All engines I have looked into have some component such as Renderer or <em>SceneManager</em> or both (depends on complexity of game/engine). Than you can have <em>OpenGLRenderer</em> class and/or DXRenderer which implement Renderer interface. Then if you have <em>SceneManager</em> and <em>Renderer</em> you can do some of the following things: </p>

<ul>
<li>Traverse <em>SceneManager</em> and send each object to <em>Renderer</em> for rendering  </li>
<li>Encapsulate upper case in some <em>SceneManager</em> method</li>
<li>Send <em>SceneManager</em> to <em>Renderer</em> so it handles it</li>
</ul>

<p>Renderer would probably call object's draw function which would call draw function of each mesh that is composed of and mesh would bind texture object, bind shader, call OpenGL draw function and then unuse shaders, texture and object data buffer objects. </p>

<p><strong>NOTE: this is just example, you should study <em>SceneManager</em> in more detail and analyze your use case to see what is best implementation option</strong></p>

<p>You would of course, have other components of engine, such as <em>MemoryManager</em>, <em>ResourceLoader</em> etc, which would take care of both video and RAM memory usage, so they could load/unload certain models/shaders/textures as needed. Concepts for this include memory caching, memory mapping etc etc. There are lot of details and concepts about each components.</p>

<p>Take a look at more detailed description of other game engines, there are a lot of them and their documentation is pretty much available.</p>

<p>But yes, classes make life easier; you should totally use them and remember about encapsulation, inheritance, interfaces, and more cool stuff.</p>
","25738"
"Map and fill texture using PBO (OpenGL 3.3)","11236","","<p>I'm learning OpenGL 3.3 trying to do the following (as it is done in D3D)...</p>

<ul>
<li>Create Texture of Width, Height, Pixel Format</li>
<li>Map texture memory</li>
<li>Loop write pixels</li>
<li>Unmap texture memory</li>
<li>Set Texture</li>
<li>Render</li>
</ul>

<p>Right now though it renders as if the entire texture is black. </p>

<p>I can't find a reliable source for information on how to do this though. Almost every tutorial I've found just uses glTexSubImage2D and passes a pointer to memory. </p>

<p>Here is basically what my code does... (In this case it is generating an 1-byte Alpha Only texture but it is rendering it as the red channel for debugging)</p>

<pre><code>GLuint pixelBufferID;
glGenBuffers(1, &amp;pixelBufferID);
glBindBuffer(GL_PIXEL_UNPACK_BUFFER, pixelBufferID);
glBufferData(GL_PIXEL_UNPACK_BUFFER, 512 * 512 * 1, nullptr, GL_STREAM_DRAW);
glBindBuffer(GL_PIXEL_UNPACK_BUFFER, 0);

GLuint textureID;
glGenTextures(1, &amp;textureID);
glBindTexture(GL_TEXTURE_2D, textureID);
glTexImage2D(GL_TEXTURE_2D, 0, GL_R8, 512, 512, 0, GL_RED, GL_UNSIGNED_BYTE, nullptr);
glBindTexture(GL_TEXTURE_2D, 0);

glBindTexture(GL_TEXTURE_2D, textureID);
glBindBuffer(GL_PIXEL_UNPACK_BUFFER, pixelBufferID);
void *Memory = glMapBuffer(GL_PIXEL_UNPACK_BUFFER, GL_WRITE_ONLY);
// Memory copied here, I know  this is valid because it is the same loop as in my working D3D version
glUnmapBuffer(GL_PIXEL_UNPACK_BUFFER);
glBindBuffer(GL_PIXEL_UNPACK_BUFFER, 0);
</code></pre>

<p>And then here is the render loop.</p>

<pre><code>// This chunk left in for completeness
glUseProgram(glProgramId);
glBindVertexArray(glVertexArrayId);
glBindBuffer(GL_ARRAY_BUFFER, glVertexBufferId);
glEnableVertexAttribArray(0);
glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 20, 0);
glVertexAttribPointer(0, 2, GL_FLOAT, GL_FALSE, 20, 12);
GLuint transformLocationID = glGetUniformLocation(3, 'transform');
glUniformMatrix4fv(transformLocationID , 1, true, somematrix)

// Not sure if this is all I need to do
glBindTexture(GL_TEXTURE_2D, pTex-&gt;glTextureId);
GLuint textureLocationID = glGetUniformLocation(glProgramId, ""texture"");
glUniform1i(textureLocationID, 0);

glDrawArrays(GL_TRIANGLES, Offset*3, Triangles*3);
</code></pre>

<p>Vertex Shader</p>

<pre><code>#version 330 core

in vec3 Position;
in vec2 TexCoords;
out vec2 TexOut;
uniform mat4 transform;

void main()
{
    TexOut = TexCoords;
    gl_Position = vec4(Position, 1.0) * transform;
}
</code></pre>

<p>Pixel Shader</p>

<pre><code>#version 330 core

uniform sampler2D texture;
in vec2 TexCoords;
out vec4 fragColor;

void main()
{
   // Output color
   fragColor.r = texture2D(texture, TexCoords).r;
   fragColor.g = 0.0f;
   fragColor.b = 0.0f;
   fragColor.a = 1.0;
}
</code></pre>
","<p>If you think about this conceptually, you'll see that all that mapping and filling a PBO does is map and fill a PBO - it does absolutely nothing to a texture object and you must handle that yourself in your own code.</p>

<p>The way to do this is via a glTexImage or glTexSubImage call, with the last (data) parameter handled in the same way as for other buffer object types; i.e. rather than being a pointer to system memory it is overloaded to function as an offset into the currently bound PBO.</p>

<p>So, to update a texture, you need to do the following:</p>

<pre><code>glBindBuffer (GL_PIXEL_UNPACK_BUFFER, pboid);
byte *ptr = glMapBuffer (GL_PIXEL_UNPACK_BUFFER, ...);
// fill ptr here
glUnmapBuffer (GL_PIXEL_UNPACK_BUFFER);
// use while PBO is still bound, assumes GL_TEXTURE_2D and offset 0
glBindTexture (GL_TEXTURE_2D, textureid);
glTexSubImage2D (GL_TEXTURE_2D, ..., (void *) 0);
glBindBuffer (GL_PIXEL_UNPACK_BUFFER, 0);
</code></pre>

<p>Regarding your specific use case, I suspect that this is not going to give you great performance.  PBOs are really most useful where you can take advantage of the asynchronous nature of the transfer, i.e. by using the texture for drawing a frame or two <em>after</em> the texture is filled from the PBO.  Since you're using the texture in the same frame you don't get that and OpenGL may need to stall until the transfer completes, as well as incurring the extra overhead of binding and mapping a PBO.</p>

<p>Using glMapBuffer itself is also likely to be a suboptimal path; see <a href=""http://www.stevestreeting.com/2007/03/16/glmapbuffer-how-i-mock-thee/"" rel=""nofollow"">this link</a> for a further discussion (it's somewhat out of date but I believe still relevant - especially since the advent of glMapBufferRange (see next point) I believe that glMapBuffer is not likely to be anything of a candidate for optimization or sensible implementation for driver writers).  You will likely obtain a better result with <a href=""http://www.opengl.org/sdk/docs/man3/xhtml/glMapBufferRange.xml"" rel=""nofollow"">glMapBufferRange</a> if your driver supports it.</p>

<p>What I would do instead of all this however is just use stock glTexSubImage2D with a system memory pointer as source, and see how that performs.  You may well find (particularly with a texture that's only 512X512X1) that it's more than fast enough for you.  The worst case should be no worse than what I've just described above, your driver may very well have it's own optimal path for replacing the entire texture rect (it could double-buffer internally, for example), or you could double-buffer the texture yourself if needed.  You shouldn't need to consider any alternate options unless this process proves to be a definite and measurable bottleneck.</p>
","35492"
"Is there a successor to RenderMonkey?","11212","","<p>I'm starting with GLSL shader programming and have been looking into <a href=""http://developer.amd.com/archive/gpu/rendermonkey/pages/default.aspx"">RenderMonkey</a>. Sadly, AMD no longer supports it. Why? Is there a successor to it? </p>
","<p><em>The bulk of this answer is going to be a response to the ""Why?"" part of your question, alas.</em></p>

<p>Well, there's <a href=""http://developer.nvidia.com/object/fx_composer_home.html"">FX Composer</a>, from NVIDIA, which is a similar product -- it doesn't support GLSL but the languages it does support are quite similar. But it was last updated in 2009 and I know of no plans to update it further. Most high-end 3D modelling packages have material construction tools in them as well, which may or may not support GLSL.</p>

<p>I think the reason you see these products reaching end-of-life (and nothing coming out to replace them) is that <strong>the direction that shader development has taken doesn't lend itself well to generalized IDEs</strong> like this.</p>

<p>Even back when we just had vertex and pixel shaders, there tended to be a strong coupling between the game/engine-side data formats (and how that data is processed) and the shader input layouts and operations programmed within the shaders -- at least for the more interesting, complex effects.</p>

<p>Consider water-related effects, for example, which often involve deforming the geometry slightly in response to sums of sine waves (in addition to running a computation that sums similar waves into a texture to be bound to the pipeline as a bump map), as well as needing framebuffer copy textures to bind in order to simulation reflection, and so on. Most of that data comes from the CPU, and isn't built in to the shader itself.</p>

<p>As the nature of that coupling increased (due to increases in parallelism on the CPU side, allowing us to balance the interesting computations more evenly between CPU and GPU), it got harder and harder to design a general-purpose shader IDE because that IDE also has to have a way to script and replicate the data pipeline that a game is going to send to shader -- essentially it needed to be a plugin to an engine. <strong>As we added extra programmable stages to the pipeline -- geometry shaders, hull shaders, et cetera -- this only compounded the issue.</strong></p>

<p>D3D tried to alleviate the problem with <a href=""http://msdn.microsoft.com/en-us/library/bb173004%28v=vs.85%29.aspx"">SAS</a>, but I don't think that ever really caught on and it certainly hasn't scaled with advances in GPU technology.</p>

<p><strong>As a result, specialized in-house or in-engine tools for building shaders evolved, and tools like FX Composer and RenderMonkey fell into disuse</strong> and were ultimately abandoned.</p>
","10140"
"Are there any games that contain a machine learning AI?","11208","","<p>Can anybody here give a reference to commercial AAA games that implement a machine learning AI?</p>
","<p>The most common approach is to train the AI off-line or pre-release, and to ship that final result. As such the game arguably doesn't contain a machine-learning AI. </p>

<p>This is because machine learning can traditionally take many hours of training to produce a usable result, and as it's by definition emergent, it's probably a good idea to put any result through a full QA pass to make sure there aren't any exploitable edge cases.</p>

<p>For the above reasons, and because gameplay changes and balancing even late on might mean that the AI has to be retrained and retested, not many studios use this approach. </p>
","17450"
"Drawing a dynamic indicator for a field of view","11148","","<p>My goal is to draw a dynamic indicator for a cube, which represents the field of view. The ideal indicator would look the same as in Metal Gear Solid(the blue ones):</p>

<p><img src=""https://i.stack.imgur.com/ESaz3.png"" alt=""enter image description here""></p>

<p>From what I have gathered, I need an angle and a length for the indicator as such for a 50° FoV:
<img src=""https://i.stack.imgur.com/pBr39.png"" alt=""enter image description here""></p>

<p>Now my issue is what method should I use to draw the indicator? A procedural mesh or is there a less demanding way of doing this?</p>
","<p>I can't give you a Unity-specific answer (sorry!), but I can tell how I would solve this. I would generate a bunch of points on a circle using the blue vector.</p>

<p>First, what is a circle? Well, a circle looks like this:</p>

<p><img src=""https://i.stack.imgur.com/3Lx58.png"" alt=""Circle""></p>

<p>However, graphics hardware can't really draw perfect circles. You're always going to end up with a polygon approximation:</p>

<p><img src=""https://i.stack.imgur.com/zMSzq.png"" alt=""Approximation""></p>

<p>We do this approximation by using sine and cosine functions. If you remember from trigonometry, a circle is 360 degrees or 2 pi. Sine and cosine functions take a value out of 2 pi and give you a distance either in the x (cosine) or y (sine) axis. A very useful property indeed.</p>

<p>In code:</p>

<pre><code>x = (cos(degrees_to_radians(angle));
y = (sin(degrees_to_radians(angle));
</code></pre>

<p>Now, what you want is not a circle, but a half-circle. Specifically, you want this:</p>

<p><img src=""https://i.stack.imgur.com/ZwGPx.png"" alt=""Bit of circle""></p>

<p>This can be achieved by using an <code>angle_start</code> and an <code>angle_end</code>. We then loop over this using an <code>angle_delta</code> that is calculated by dividing the difference between <code>angle_start</code> and <code>angle_end</code> over the <code>quality</code> we want.</p>

<p>Another useful property of approximating circles with sine and cosine (also known as the ""unit circle"") is that it can be shrunk or grown using a radius value. So let's add a radius to our pseudo-code:</p>

<pre><code>x = (cos(degrees_to_radians(angle)) * radius;
y = (sin(degrees_to_radians(angle)) * radius;
</code></pre>

<p>How can we use this for our field-of-view cone? Well, we can use the same circle but draw it at different distances:</p>

<p><img src=""https://i.stack.imgur.com/tVCNc.png"" alt=""Almost a cone""></p>

<p>And when I add a dotted line to connect the two half-circles, it's starting to look like a cone!</p>

<p><img src=""https://i.stack.imgur.com/mTz8f.png"" alt=""Cone!""></p>

<p>Here, we have two radii: <code>dist_min</code> and <code>dist_max</code>. Our code becomes:</p>

<pre><code>x_min = (cos(degrees_to_radians(angle)) * dist_min;
y_min = (sin(degrees_to_radians(angle)) * dist_min;

x_max = (cos(degrees_to_radians(angle)) * dist_max;
y_max = (sin(degrees_to_radians(angle)) * dist_max;
</code></pre>

<p>However, we also need <em>two</em> angles: one for the current step and one for the next step. We'll call these <code>angle_curr</code> and <code>angle_next</code>. Now our code becomes:</p>

<pre><code>x_curr_min = (cos(degrees_to_radians(angle_curr)) * dist_min;
y_curr_min = (sin(degrees_to_radians(angle_curr)) * dist_min;

x_curr_max = (cos(degrees_to_radians(angle_curr)) * dist_max;
y_curr_max = (sin(degrees_to_radians(angle_curr)) * dist_max;

x_next_min = (cos(degrees_to_radians(angle_next)) * dist_min;
y_next_min = (sin(degrees_to_radians(angle_next)) * dist_min;

x_next_max = (cos(degrees_to_radians(angle_next)) * dist_max;
y_next_max = (sin(degrees_to_radians(angle_next)) * dist_max;
</code></pre>

<p>Now we have four points on our half-circles. Let's store these points as triangles. Here's a diagram that should help clear up how can make triangles out of these four points:</p>

<p><img src=""https://i.stack.imgur.com/WOX2P.png"" alt=""Triangles yo""></p>

<p>So, what do we need to do draw a cone?</p>

<ul>
<li>Determine the start angle and the end angle. This is done using the enemy's direction and field of view variable.</li>
<li>Determine the quality of our approximation. 15 steps should be good enough for most purposes.</li>
<li>Loop over the difference between start and end using the delta ((end - start) / quality).</li>
<li>Convert our angles to four points.</li>
<li>Convert the four points to two triangles.</li>
</ul>

<p>When we combine these steps, here's what we will end up with:</p>

<p><img src=""https://i.stack.imgur.com/GP5cv.png"" alt=""Finished product""></p>

<p>In full pseudo-code:</p>

<pre><code>int quality = 15;

float dist_min = 0.5f;
float dist_max = 15.f;

vec2 pos = GetEnemyPosition();
float angle_lookat = GetEnemyAngle();
float angle_fov = GetEnemyFieldOfView();

float angle_start = angle_lookat - angle_fov;
float angle_end = angle_lookat + angle_fov;
float angle_delta = (angle_end - angle_start) / quality;

float angle_curr = 0.f;
float angle_next = angle_delta;

for (int i = 0; i &lt; quality - 1; i++)
{
    vec2 sphere_curr;
    sphere_curr.x = cos(degrees_to_radians(angle_curr));
    sphere_curr.y = sin(degrees_to_radians(angle_curr));

    vec2 sphere_next;
    sphere_next.x = cos(degrees_to_radians(angle_next));
    sphere_next.y = sin(degrees_to_radians(angle_next));

    vec2 pos_curr_min = pos + sphere_curr * dist_min;
    vec2 pos_curr_max = pos + sphere_curr * dist_max;

    vec2 pos_next_min = pos + sphere_next * dist_min;
    vec2 pos_next_max = pos + sphere_next * dist_max;

    WriteTriangle(pos_curr_min, pos_curr_max, pos_next_max);
    WriteTriangle(pos_next_max, pos_curr_min, pos_next_min);

    angle_curr += angle_delta;
    angle_next += angle_delta;
}
</code></pre>

<p>This should create the cone you want. Try playing with the parameters (<code>dist_min</code>, <code>dist_max</code> and <code>quality</code>) to get the effect you want. It should only be a few triangles per enemy, I don't think it's much of a problem to generate this every frame. Only consider optimizing it when it becomes a problem.</p>
","31171"
"How To: Java Game to Steam Greenlight","11112","","<p>I am planning to create an indie game using <strong>Java</strong> and <strong>Eclipse IDE</strong> and I want to put the finished product to <strong>Steam Greenlight</strong>.</p>

<p>How does the whole process work <strong>after</strong> the game is finished and running <strong>only</strong> on <strong>Eclipse</strong>?</p>
","<p>I assume you really want to know two things:</p>

<ol>
<li>Will Steam accept my Java game?</li>
<li>What do I need to do to make it work on Steam?</li>
</ol>

<p>The answer to #1 is ""yes."" Steam hosts other Java games (like Spiral Knights).</p>

<p>For #2, I suggest you package your game using <a href=""http://launch4j.sourceforge.net/"">launch4j</a>. This will provide you with native (Windows, Linux) wrappers around your application. Other benefits include (from their home page):</p>

<blockquote>
  <p>The wrapper also provides better user experience through an application icon, a native pre-JRE splash screen, and a Java download page in case the appropriate JRE cannot be found.</p>
</blockquote>

<p>You can get the latest version from Maven for your maven/gradle builds.</p>

<p>Also, note: Greenlight is not some magic marketing machine. You have to market your game really, <em>really</em> well to get it greenlit.</p>
","79064"
"In an Entity-Component-System Engine, How do I deal with groups of dependent entities?","11081","","<p>After going over a few game design patterns, I have settle with Entity-Component-System  (ES System) for my game engine.  I've reading articles (mainly <a href=""http://t-machine.org/index.php/2007/09/03/entity-systems-are-the-future-of-mmog-development-part-1/"">T=Machine</a>) and review some source code and I think I got enough to get started.</p>

<p>There is just one basic idea I am struggling with.  How do I deal with groups of entities that are dependent on each other?</p>

<p>Let me use an example:</p>

<p>Assume I am making a standard overhead shooter (think <a href=""http://finalformgames.com/jamestown/"">Jamestown</a>) and I want to construct a ""boss entity"" with multiple distinct but connected parts.  The break down might look like something like this:</p>

<ul>
<li>Ship body: Movement, Rendering</li>
<li>Cannon: Position (locked relative to the Ship body), Tracking\Fire at hero, Taking Damage until disabled</li>
<li>Core: Position (locked relative to the Ship body), Tracking\Fire at hero, Taking Damage until disabled, Disabling (er...destroying) all other entities in the ship group</li>
</ul>

<p>My goal would be something that would be identified (and manipulated) as a distinct game element without having to rewrite subsystem form the ground up every time I want to build a new aggregate Element. </p>

<p>How do I implement this kind of design in ES System?</p>

<ol>
<li>Do I implement some kind of parent-child entity relationship (entities can have children)? This seems to contradict the methodology that Entities are just empty container and makes it feel more OOP.</li>
<li>Do I implement them as separate entities, with some kind of connecting Component (BossComponent) and related system (BossSubSystem)?  I can't help but think that this will be hard to implement since how components communicate seem to be a big bear trap.</li>
<li>Do I implement them as one Entity, with a collection of components (ShipComponent, CannonComponents, CoreComponent)?  This one seems to veer way of the ES System intent (components here seem too much like heavy weight entities), but I'm know to this so I figured I would put that out there.</li>
<li>Do I implement them as something else I have mentioned?</li>
</ol>

<p>I know that this can be implemented very easily in OOP, but my choosing ES over OOP is one that I will stick with.  If I need to break with pure ES theory to implement this design I will (not like I haven't had to compromise pure design before), but I would prefer to do that for performance reason rather than start with bad design.</p>

<p>For extra credit, think of the same design but, each of the ""boss entities"" were actually connected to a larger ""BigBoss entity"" made of a main body, main core and 3 ""Boss Entities"".  This would let me see a solution for at least 3 dimensions (grandparent-parent-child)...which should be more than enough for me.</p>

<p>Links to articles or example code would be appreciated.  Thanks for your time.</p>
","<p>If I were in this situation, I would create each part of the boss as a separate entity. These ""sub-entities"" would include some kind of <code>AttachmentPoint</code> or <code>ParentEntity</code> component. This component would include a reference to the parent entity and an offset from the parents position. When updating the position, they check the parent position and apply the offset to generate their own position. Additionally, it could make checks to ensure the parent entity still exists. Further, you can have a <code>SubEntity</code> component that tracks the existence of sub entities for the parent entity. This allow you to do things like only make the core of the boss vulnerable when the arms with shields are destroyed. </p>

<p>I currently use a <code>TargetEntity</code> component in my game, which is used for turret tracking and when goblins are going to pick up a resource. It can check the target entity's position and change it's behavior accordingly. Entities that have no position are never added as a target, so there's no worries there. However, when getting to be more in depth, like checking the parent or child entity health, shield, power reserves or whatever, you'll have to ensure the parent or child entity actually has the related component.</p>

<p>Making each part it's own entity maintains the flexibility of the entity/component framework by allowing you to add additional and different components to each part of the boss. For example, one part of the boss might have a gun component and a health component while another would have a shield component and a health component.</p>

<p>I found another discussion on this topic <a href=""https://github.com/alecmce/xember/issues/12"">here</a>. In which the users are discussing adding multiple components of the same type to one entity (which seems like a bad idea to me). It seems like a useful conversation, though I haven't read the whole discussion.</p>
","31891"
"Cave generation with Perlin worms","11076","","<p>I'm currently trying to generate a Minecraft like voxel terrain with 3D Simplex Noise and also want to implement caves.</p>

<p>I found the method of Perlin Worms in <a href=""https://gamedev.stackexchange.com/questions/33590/how-to-generate-caves-like-minecraft"">this</a> thread, which generates really nice results.
However, I have no clue on how to generate it on a chunk by chunk basis.
Is this possible or are there any alternatives that produce a similar worm like cave on a chunk by chunk basis?</p>

<p>Edit: <a href=""https://i.imgur.com/b72cw05.png"" rel=""nofollow noreferrer"">This</a> is the problem which I don't know how to solve.</p>

<p>Edit2: <a href=""https://i.imgur.com/mGFOHMk.png"" rel=""nofollow noreferrer"">This</a> is the result from combining 2D Ridged Multifractal Noise with a Simplex Noise heightmap. Still needs some tweaking, but this is pretty much the result I wanted. Thanks to Byte56.</p>
","<p>Most perlin noise algorithms will allow you to retrieve the noise value at any given location, with something like <code>noise(x,y,z)</code>. This makes it fairly trivial to generate noise on a chunk by chunk basis. All you need to do is pass the global position, instead of the chunk position.</p>

<pre><code>for(int i = 0; i &lt; CHUNKMAX_X; i++)
    for(int j = 0; j &lt; CHUNKMAX_Y; j++)
        for(int k = 0; k &lt; CHUNKMAX_Z; k++)
            if(isSolid(perlinNoise.get(chunkPosition.x + i,
                                         chunkPosition.y + j,
                                         chunkPosition.z + k))
                thisChunk[i,j,k] = new Voxel(solid);
            else
                thisChunk[i,j,k] = new Voxel(air);
</code></pre>

<p>So you can see, we're generating terrain for the chunk, by iterating over the chunk bounds, and checking to see if that global position is solid or not. This is likely the same methodology you're using to generate the terrain in general.</p>

<p><code>perlinNoise.get</code> takes a global position and returns its density. Where <code>isSolid</code> would just be a simple test to see if the voxel is ""dense enough"" to qualify for solid. </p>

<p><code>perlinNoise.get</code> can be more complex than just a simple noise algorithm. You can have checks based on the depth of the voxel in your world. For example, if the voxel is below what you've decided is ""absolute base ground level"" then it can use the perlin worms algorithm to return a density, if it's above the absolute base, it can use a normal density function to give you more varied terrain. I would recommend some blending between the two however.</p>

<p>Combining different Perlin noise functions is just something you have to play with and see what works. It's best to set up your environment so that you can just change some values and hot-swap the terrain without needing to reload your game. Happy experimenting.</p>
","53407"
"How much lines of code is 1kB?","11059","","<p>My friend told me that it's something about 40 lines of code for 1kB. </p>

<p>For an old 8-bit computers with 48kB of RAM it is only 1920 lines of code!</p>

<p>Then when I think about it, it seems to me incredible that sometimes my CSS files have more than 2000 lines of code.</p>

<p>How can somebody create something like a game e.g. Dizzy on the ZX Spectrum within 2000 lines available?</p>

<p>Even if they have used assambly or machine code for some parts it seems to me incredible.</p>

<p>Is really 1kB about 40 lines of code or is it different?</p>
","<p>1 kB = 1024 Bytes.</p>

<p>Most of programming languages have 1 Byte = 1 character, so:</p>

<ul>
<li>If your lines are 1 character long, 1 kB = 1024 lines </li>
<li>If your lines are 1024 characters long, 1 kB = 1 line</li>
<li>If your lines are 25 characters long, 1 kB = about 40 lines</li>
</ul>

<p>BTW. if your programming language is compiled, it has nothing to do with memory-efficiency.</p>

<p>BTW2: There is a very interesting site <a href=""http://js1k.com/"" rel=""noreferrer"">JS1K</a>, where people submit cute things that use 1024 Bytes of Javascript code.</p>
","53919"
"How do I programmatically access single sprites when Sprite Mode is Multiple?","11034","","<p>Unity 4.3 newly brings an ability to cut up a sprite sheet into multiple individual sprites. This is useful since you then only need one master spritesheet, but nevertheless get references to individual sprites. It's done by setting <em>Sprite Mode</em> to <em>Multiple</em>.</p>

<p>Can all the sprites generated from the master file be programmatically accessed from the Unity Sprite Editor?</p>

<p>For example: I have a spritesheet with a grid of 50x50 sprites. Using the Unity Sprite Editor, I now have 250 sprites: <code>spritesheet_0, spritesheet_1, ..., spritesheet_249</code>. How can I get a handle to <code>spritesheet_102</code> without having to manually drag and drop it in the Unity editor?</p>
","<p>You need to create a sprite array <code>Sprite[] sprites</code> and fill it using <code>sprites = Resources.LoadAll&lt;Sprite&gt;(""Location"");</code> inside Awake().</p>
","72931"
"Library to load images into textures, Linux, C and OpenGl","11028","","<p>I am looking for simple, self-contained C library for Linux to load images from files into OpenGL textures. The licence should be quite liberal: zlib, bsd, mit or something. I have found <a href=""http://www.lonesock.net/soil.html"">SOIL</a>, however it hasn't been updated for a long time. Is there something else, or do I have to write my own?</p>

<p>P.S.
I use glfw. There are only deprecated functions for loading images.</p>
","<p>I use <a href=""https://github.com/nothings/stb"" rel=""nofollow"">STB Image</a> for most image loading. A small self contained no strings attached implementation of png and other file formats.</p>
","9092"
"2D graphics - why use spritesheets?","11026","","<p>I have seen many examples of how to render sprites from a spritesheet but I havent grasped why it is the most common way of dealing with sprites in 2d games.</p>

<p>I have started out with 2d sprite rendering in the few demo applications I've made by dealing with each animation frame for any given sprite type as its own texture - and this collection of textures is stored in a dictionary. This seems to work for me, and suits my workflow pretty well, as I tend to make my animations as gif/mng files and then extract the frames to individual pngs.</p>

<p>Is there a noticeable performance advantage to rendering from a single sheet rather than from individual textures? With modern hardware that is capable of drawing millions of polygons to the screen a hundred times a second, does it even matter for my 2d games which just deal with a few dozen 50x100px rectangles?</p>

<p>The implementation details of loading a texture into graphics memory and displaying it in XNA seems pretty abstracted. All I know is that textures are bound to the graphics device when they are loaded, then during the game loop, the textures get rendered in batches. So it's not clear to me whether my choice affects performance.</p>

<p>I suspect that there are some very good reasons most 2d game developers seem to be using them, I just don't understand why.</p>
","<p>A strong argument for using spritesheets is that the number of available textures on a graphic card can be limited. Therefore your graphics library would constantly have to remove texture and re-allocate textures on the GPU. It's much more efficient to just allocate a large texture once.</p>

<p>Also consider that texture sizes are usually power of 2. So if you have a 50x100px Sprite, you'll allocate textures with the size 64x128px or in the worse case 128x128px. That's just wasting graphics memory. Better pack all the sprites into a 1024x1024px texture, which would allow 20x10 sprites and you'll only lose 24 pixels horizontally and vertically. Sometimes even sprites of different sizes are combined into one huge sprite-sheet to use the texture as efficient as possible.</p>

<p><strong>Addendum:</strong> A very important reason to use sprite-sheets is to reduce the amount of draw-calls on your GPU, which can have a notable impact on performance. This has been stated in other answers and I'm adding this for the sake of completeness so that this gets some more visibility.</p>
","7070"
"Unity procedural TileMap generation without creating gameobject per tile","11024","","<p>I've been searching internet to find an efficient way to create a procedural tilemap without creating a GameObject per tile. 
All the TileMap tutorials I've found are creating tiles by creating hundreds of GameObjects. Thus the hierarchy in Unity is expanding unexpectedly.</p>

<p>I'm pretty sure this is not the ""right"" way to do it. Especially after seeing the new Unity 2D tools that supports tilemaps. Unity made it so, you can create tiles in ""one"" gameobject, not for each tile.</p>

<p>So, how do I do it in the right and effiecent way?</p>
","<p>Here's what I'm aware of:</p>

<p>Option 1. GameObject per tile. It's not completely horrible in certain cases. Depending on your needs, it could work.. well enough.</p>

<p>Option 2. A single quad or plane referencing a texture you create at run-time. You would essentially use your tile atlas texture to ""paint"" your map as one new texture. Depending on the size of your map of course, you might want to have multiple quads/planes each representing portions of your map.</p>

<p>Option 3. Create your own mesh. This would more than likely be the method you'll like most once implemented. It'll give you tons of flexibility and probably the highest performance. You would essentially create a quad per tile and set each vertex UV to map to the tiles in your tile atlas.</p>

<p>For Option 2, I'd suggest watching this video series by quill18creates: <a href=""https://www.youtube.com/watch?v=bpB4BApnKhM"" rel=""noreferrer"">3D TileMap tutorial series by quill18creates</a></p>

<p>For Option 3, this is my code, with tweaks, so it may not be perfect:</p>

<pre><code>//For this, your GameObject this script is attached to would have a
//Transform Component, a Mesh Filter Component, and a Mesh Renderer
//component. You will also need to assign your texture atlas / material
//to it. 

void Start() {
    meshFilter = GetComponent&lt;MeshFilter&gt;();

    BuildMesh();
}

public void BuildMesh() {
    int numTiles = mapSizeX * mapSizeY;
    int numTriangles = numTiles * 6;
    int numVerts = numTiles * 4;

    Vector3[] vertices = new Vector3[numVerts];
    UVArray = new Vector2[numVerts];

    int x, y, iVertCount = 0;
    for (x = 0; x &lt; mapSizeX; x++) {
        for (y = 0; y &lt; mapSizeY; y++) {
            vertices[iVertCount + 0] = new Vector3(x, y, 0);
            vertices[iVertCount + 1] = new Vector3(x + 1, y, 0);
            vertices[iVertCount + 2] = new Vector3(x + 1, y + 1, 0);
            vertices[iVertCount + 3] = new Vector3(x, y + 1, 0);
            iVertCount += 4;
        }
    }

    int[] triangles = new int[numTriangles];

    int iIndexCount = 0; iVertCount = 0;
    for (int i = 0; i &lt; numTiles; i++) {
        triangles[iIndexCount + 0] += (iVertCount + 0);
        triangles[iIndexCount + 1] += (iVertCount + 1);
        triangles[iIndexCount + 2] += (iVertCount + 2);
        triangles[iIndexCount + 3] += (iVertCount + 0);
        triangles[iIndexCount + 4] += (iVertCount + 2);
        triangles[iIndexCount + 5] += (iVertCount + 3);

        iVertCount += 4; iIndexCount += 6;
    }

    mesh = new Mesh();
    //mesh.MarkDynamic(); if you intend to change the vertices a lot, this will help.
    mesh.vertices = vertices;
    mesh.triangles = triangles;
    meshFilter.mesh = mesh;

    UpdateMesh(); //I put this in a separate method for my own purposes.
}


//Note, the example UV entries I have are assuming a tile atlas 
//with 16 total tiles in a 4x4 grid.

public void UpdateMesh() {
    int iVertCount = 0;

    for (int x = 0; x &lt; mapSizeX; x++) {
        for (int y = 0; y &lt; mapSizeY; y++) {
            UVArray[iVertCount + 0] = new Vector2(0, 0); //Top left of tile in atlas
            UVArray[iVertCount + 1] = new Vector2(.25f, 0); //Top right of tile in atlas
            UVArray[iVertCount + 2] = new Vector2(.25f, .25f); //Bottom right of tile in atlas
            UVArray[iVertCount + 3] = new Vector2(0, .25f); //Bottom left of tile in atlas
            iVertCount += 4;
        }
    }

    meshFilter.mesh.uv = UVArray;
}
</code></pre>
","108394"
"Packaging Jar with External Libraries in Eclipse","11019","","<p>I have a class called Game in the package net.aGameName and am trying to export a runnable Jar using eclipse.  In the project I have two external Jar files added, lwjgl.jar and lwjgl_util.jar.</p>

<p>When I go to File->Export->Runnable Jar File and choose the Launch configuration I use for testing (which works successfully) I am able to export the Jar file without any errors.  Finally I open cmd and use <code>java aGameName.jar</code> and receive the following error:</p>

<pre><code>Exception in thread ""main"" java.lang.NoClassDefFoundError: aGameName/jar
Caused by: java.lang.ClassNotFoundException: aGameName.jar
        at java.net.URLClassLoader$1.run(Unknown Source)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(Unknown Source)
        at java.lang.ClassLoader.loadClass(Unknown Source)
        at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)
        at java.lang.ClassLoader.loadClass(Unknown Source)
Could not find the main class: aGameName.jar.  Program will exit.
</code></pre>

<p>When I open the manifest file it says:</p>

<pre><code>Manifest-Version: 1.0
Class-Path: .
Main-Class: net.aGameName.Game
</code></pre>

<p>Can anyone easily spot the error that would be causing this?  Thanks</p>
","<p>I actually found a small little program that would allow me to join multiple jar files together.  I used this along with all the dependencies I needed and the jar that Eclipse generated to create a runable jar.  Simple enough and for this small project it works fine.</p>

<p><a href=""http://ninjacave.com/jarsplice"" rel=""nofollow"">http://ninjacave.com/jarsplice</a></p>
","19473"
"Game planning and software design? I feel that UML is not convenient","11008","","<p>In my university, they always emphasize and hype about UML design and stuff, in which I feel it is not going to work well with game structure design. Now, I just want a professional advice on how should I begin my game designing? The story is I have some skill in programming and have done many minor game such as getting some 2D platformer working to some extend. The problems that I find about my program is the poor quality design. After coding for a while, things start to break down due to poor planning (When I add new feature, it tends to make me have to recode the whole program). However, to plan everything out without a single design flaw is a bit too ideal. Therefore, any advice to how should I plan my game? How should I put it into visible pictures, so that me and my friends are able to overview the designs?</p>

<p>I planned to start coding a game with my friend. This is going to be my first teamwork, so any professional advices would be a pleasure. Is there any other alternatives than UML?</p>

<p>Another question is how does ""prototyping"" normally looks like?</p>
","<blockquote>
  <p>I just want a professional advice on how should I begin my game designing? </p>
</blockquote>

<p>Game design is the specification of the gameplay, the assets, the scoring systems, etc - these are not software-specific. As such, UML is the wrong tool for that task.</p>

<p>When it comes to designing the code to implement these systems, UML is a good tool for the task, providing your team know it, and stick to the more common diagram types. Normally, when trying to design a feature, you will know whether you need to use a description or a diagram. If you do need to use a diagram, UML gives you a standard way of drawing it, which is a good thing.</p>

<blockquote>
  <p>After coding for a while, things start to break down due to poor planning (When I add new feature, it tends to make me have to recode the whole program).</p>
</blockquote>

<p>That is generally a problem with the way you program, rather than how you plan. Good software usually is easy to extend and reuse. If you stick to good programming practices, this problem will decrease. But better planning will help also, and you don't need complex diagrams for this. Just having a list of features will mean that when you code one thing, you have the other features in mind and can consider them as you code.</p>

<blockquote>
  <p>Therefore, any advice to how should I plan my game? How should I put it into visible pictures, so that me and my friends are able to overview the designs?</p>
</blockquote>

<p>It sounds like you're mixing 2 problems here, the game design, and the code design.</p>

<p>I suggest first writing out a basic game design, specifying the features you need, the graphics and sounds you need, how the game is won and lost, etc. Look up 'design documents' if you need some help there.</p>

<p>From there, you will have an idea of the features that you need to code up. You can look at each feature in turn and try to think about how to implement them. Diagrams can help to show the relationships between different classes and objects in your game but the skill of knowing which objects need to exist is something that you have to learn through practice and/or further reading.</p>

<p>Also, try working on smaller, less ambitious projects. That will get you used to writing good, working code, without needing extensive planning or rewrites.</p>
","27827"
"Why do I get this file loading exception when trying to draw sprites with libgdx?","11004","","<p>I'm having trouble with the ""Drawing Images"" section on the <a href=""http://code.google.com/p/libgdx/wiki/SpriteBatch"" rel=""nofollow"">libgdx tutorial</a>.  I set up the documents completely and I typed the code as follows:</p>

<pre><code>public class Game implements ApplicationListener {
        public static final String LOG = Game.class.getSimpleName();
        private FPSLogger fpsLogger;
        private SpriteBatch batch;
        private Texture texture;
        private Sprite sprite;
        private TextureRegion region;

        //removed irrelevant code for this question...

        @Override
        public void render() {
                texture = new Texture(Gdx.files.internal(""android.png""));
                region = new TextureRegion(texture, 20, 20, 50, 50);
                sprite = new Sprite(texture, 20, 20, 50, 50);
                sprite.setPosition(10, 10);
                sprite.setRotation(45);

                Gdx.gl.glClearColor(0f, 1f, 0f, 1f);
                Gdx.gl.glClear(GL20.GL_COLOR_BUFFER_BIT);
                batch.begin();
                batch.draw(texture,10,10);
                batch.draw(region,10,10);
                sprite.draw(batch);
                batch.end();

                // output the current FPS
                fpsLogger.log();
        }
}
</code></pre>

<p>I went through the tutorial on the website but when I run the code I get errors:</p>

<blockquote>
<pre><code>Exception in thread ""LWJGL Application""
com.badlogic.gdx.utils.GdxRuntimeException: Couldn't load file: android.png at
com.badlogic.gdx.graphics.Pixmap.&lt;init&gt;(Pixmap.java:137)  at
com.badlogic.gdx.graphics.glutils.FileTextureData.prepare(FileTextureData.java:55) at
com.badlogic.gdx.graphics.Texture.load(Texture.java:175)  at
com.badlogic.gdx.graphics.Texture.create(Texture.java:159)    at
com.badlogic.gdx.graphics.Texture.&lt;init&gt;(Texture.java:133)    at
com.badlogic.gdx.graphics.Texture.&lt;init&gt;(Texture.java:122)    at
com.game.Game.render(Game.java:46)    at
com.badlogic.gdx.backends.lwjgl.LwjglApplication.mainLoop (LwjglApplication.java:163) at
com.badlogic.gdx.backends.lwjgl.LwjglApplication$1.run(LwjglApplication.java:113)
Caused by: com.badlogic.gdx.utils.GdxRuntimeException: File not found: android.png (Internal)     at
com.badlogic.gdx.files.FileHandle.read(FileHandle.java:108)   at
com.badlogic.gdx.files.FileHandle.length(FileHandle.java:364)     at
com.badlogic.gdx.files.FileHandle.readBytes(FileHandle.java:156)  at
com.badlogic.gdx.graphics.Pixmap.&lt;init&gt;(Pixmap.java:134)  ... 8 more
</code></pre>
</blockquote>

<p>I set the android.png in my assests folder in my android project linking it to the desktop one, I don't understand what I'm doing wrong.  What is making these errors?</p>
","<p>The relevant part of that stack trace appears to be the message about not being able to find the <code>android.png</code> file. Since you assert the file does exist on-disk, the problem is likely an issue with the working directory of your application at the time you attempt to load the file and the file's location relative to that working directory.</p>

<p>I'm not entirely sure if this is true of Java applications, but the working directory is generally going to default to that of the application itself or the working directory of the shell that invoked the application (if launching it from a console). So, if your image is in an ""assets"" subfolder relative to the application, you'd have to attempt to load ""assets/android.png"" and not just ""android.png"".</p>

<p>Also note that because the image appears in an assets subfolder in your project structure, that does not necessarily mean it will be deployed with the final built application unless you've configured your IDE/toolchain (which you don't specify) to do so.</p>

<p>In a pinch, you may be able to use the <code>getAbsoluteFile</code> method of the <code>File</code> object to print the absolute path of the image at runtime to the console or in your debugger. That may help you diagnose where your program <em>expects</em> the image to be versus where it actually is.</p>
","26214"
"How much assembly is really used in modern game code?","11002","","<p>On average, how often is assembly used in modern game code?</p>

<p>Specifically on platforms that already have good C++ compilers, like x86, PPC, or ARM--because I assume games on embedded systems make extensive use of assembly.</p>
","<p>The answer depends a bit on what you mean by ""game"", and on ""used"". I'll assume ""used"" means ""written during the course of the specific game project"".</p>

<p>In my experience and anecdotal data from people I've talked to:</p>

<ul>
<li>in browser based games? None.</li>
<li>in typical PC games? None. (But you might see some in low level libraries.)</li>
<li>in iOS and Android games? None.</li>
<li>""AAA"" PC games and console games? Maybe a little, perhaps 0.05% of the code base. (With a bit more in the libraries.)</li>
</ul>

<p>Knowledge of assembly language is not expected for work in the games industry, but depending on the type of games you make, it might come in advantageous.</p>

<p>There used to be an argument that the compiler does a better job at optimising C code than a human would with hand-written assembly. Usually that's true, sometimes it's false. But these days a combination of ever-growing CPU complexity and the need to scale 'out' (ie. to separate processors) means that optimisation efforts are usually spent elsewhere.</p>

<p>In recent years the only time I've seen assembly in game code was <code>__asm int 3</code> statements to force breakpoints, and my only personal use of assembly was in looking at the disassembly of a function to diagnose unusual crash bugs.</p>
","31988"
"How can I avoid giant player classes?","10988","","<p>There is almost always a player class in a game. The player can generally do a lot in the game which means for me this class ends up being huge with a ton of variables to support each piece of functionality the player can do. Each piece is fairly small on its own but combined I end up with thousands of lines of code and it becomes a pain to find what you need and scary to make changes. With something that is basically a general control for the entire game how do you avoid this issue?</p>
","<p>You'd usually use an entity component system (An entity component system is a component based architecture). This also makes creating other entities way easier, and can also make the enemies/NPCs have the same components as the player.</p>

<p>This approach goes in the exact opposite direction as an object oriented approach. Everything in the game is an entity. The entity is just a case without any game mechanics built into it. It has a list of components and a way to manipulate them.</p>

<p>For example, the player has a position component, an animation component and an input component and when user presses space, you want the player to jump.</p>

<p>You can achieve this by giving the player entity a jump component, which when called makes the animatiom component change to the jumping animation and you make the player have a positive y velocity in the position component. In the input component you listen for the space key and you call the jump component. (This is just an example, you should have a controller component for movement).</p>

<p>This helps breaking up the code into smaller, reusable modules, and can result in a more organized project.</p>
","137714"
"How to dynamically create an UI text Object in Unity 5?","10987","","<p>I have been searching for something that should be simple, but Unity 5's documentation on that is fairly outdated. What I want to achieve is to be able to create UI Text totally from script, i.e. fully dynamically - in my real case application, I will do that in a loop of not pre defined number of iterations.</p>

<p>A search using Google will find quite many examples on how to do that, but all I saw either use methods that are already deprecated (are from before Unity version 5) or are simply wrong (no surprise here...). I already know that I should first add a Canvas to my project, then I should include <code>using UnityEngine.UI</code> in my C# code, and also that I could declare a UI Text like <code>Text _guitext</code>.</p>

<p>However, the code below does not work. I mean, it's not that it crashes, but rather that nothing is shown:</p>

<pre><code>using UnityEngine;
using System.Collections;
using UnityEngine.UI;


public class MyClass: MonoBehaviour {

Text _guitext;

// Use this for initialization
void Start () {
    _guitext.text = ""testing"";
}

// Update is called once per frame
void Update () {
}
}
</code></pre>

<p>Worse than that, it seems that while game is played, no new object appears in the object hierarchy list.</p>

<p>Could you please point me out in the right direction here? Thanks.</p>
","<p>I think what you are looking for is something like following:</p>

<pre><code>GameObject CreateText(Transform canvas_transform, float x, float y, string text_to_print, int font_size, Color text_color)
{
    GameObject UItextGO = new GameObject(""Text2"");
    UItextGO.transform.SetParent(canvas_transform);

    RectTransform trans = UItextGO.AddComponent&lt;RectTransform&gt;();
    trans.anchoredPosition = new Vector2(x, y);

    Text text = UItextGO.AddComponent&lt;Text&gt;();
    text.text = text_to_print;
    text.fontSize = font_size;
    text.color = text_color;

    return UItextGO;
}
</code></pre>

<p>It means, you first create an Empty GameObject. Then you add a Text component, with the specific local and/or anchored parameters, set the desired text and its color, then you make this object a child of the empty game object.</p>

<p>You want to retrieve the UI Text information from or set variable of that object you've created via script, you can then just use <code>yourGOname.GetComponent&lt;Text&gt;().text</code>, <code>yourGOname.GetComponent&lt;Text&gt;().font</code>, etc.</p>

<p>And of course, for that to work you need to be <code>using UnityEngine.UI</code>.</p>
","116224"
"Lag compensation with networked 2D games","10983","","<p>I want to make a 2D game that is basically a physics driven sandbox / activity game. There is something I really do not understand though. From research, it seems like updates from the server should only be about every 100ms. I can see how this works for a player since they can just concurrently simulate physics and do lag compensation through interpolation.</p>

<p>What I do not understand is how this works for updates from other players. If clients only get notified of player positions every 100ms, I do not see how that works because a lot can happen in 100ms. The player could have changed direction twice or so in that time. I was wondering if anyone would have some insight on this issue.</p>

<p>Basically how does this work for shooting and stuff like that?</p>

<p>Thanks</p>
","<p>Summary for those that don't like long answers...</p>

<p>It can be done but it's impossible to do <em>perfect</em> multiplayer physics if there is any latency.  Why latency impacts physics is explained, and then tips for reducing the impact of latency on your physics simulation are offered.</p>

<hr>

<p>Creating a multiplayer physics game can be fraught with peril.  It is impossible to create a ""perfect"" online multiplayer physics experience.  There are things you can do to make it better, but there is no way to make perfect physics assuming any latency.  </p>

<p>The problem is, physics has to be fast and responsive to be realistic, but at the same time has to be calculated based on the combined actions of ALL factors -- meaning the combined actions of all players.  And if there is latency, this can't be done in real time.</p>

<p>It is up to you as a developer to decide if you can keep the different factors under control, and to understand that the player's experience will degrade if the latency becomes too high.  If you can live with that (and your players can), then go for it.  See towards the end of this post for some notes about how you can keep things running smoother.  </p>

<p><strong>An example to show how things can get messed up</strong></p>

<p>Imagine a game where two players (clients) are connected to a server.  It takes 100 milliseconds (1/10th second) for a message to go across the internet from client to server.  When a player does something, a message is sent to the server saying what they did.  The server then broadcasts the message out to the other players so they all know what the acting player did.</p>

<p>Now create a scenario where two players have a crate on the ground which is a physics object.  Player A hits it on one side, sending it moving in some direction.  However at the same time, player B hits it on another side, sending it another direction.</p>

<p>Let's look at different ways to handle this and what the results would be...</p>

<p><strong>What if physics is calculated just on the server?</strong></p>

<p>Suppose we have the physics calculated only on the server.  Player A sends ""I hit crate this way"" message to server, 1/10th second later server gets message.  Player B sends their ""I hit crate this other way"" message.  The server calculates physics change from the combination of the two actions, and sends message back to both players saying, ""OK it moves like this.""  Perfect physics is performed, based on the actions of both players combined.</p>

<p>But the problem is, it will be 2/10th of a second before either player sees the crate react.  The messages from both players take 1/10th of a second to reach the server, then another 1/10th of a second for the servers calculation results to be sent for both players.</p>

<p>Bottom line, laggy gameplay.</p>

<p><strong>What if physics is just calculated on the client?</strong></p>

<p>Suppose we have physics calculated on just the client. Let's look at it from Player A's point of view.  Player A hits crate and it immediately starts going their direction.  A message is also sent to the server saying what Player A did. </p>

<p>At the same time though, B has done their hit and seen the crate going in <em>their</em> direction and sent a message to the server about what they did.</p>

<p>2/10th of a second later, a message arrives from the server to the clients.  A is told what B did, and B is told what A did.  The problem is, both clients say, ""Well player X may have done that hit at this spot, but there is no longer a crate at that location, so their hit did nothing.""</p>

<p>Bottom line is, two games out of sync and players not having a shared experience.  What's the point of multiplayer if they both see different things?</p>

<p><strong>What if physics is calculated on both client and server?</strong></p>

<p>In this case, physics is calculated on the client so players see an immediate no-lag reaction, but it's also calculated on the server so it is ""correct"" for all players.</p>

<p>Both players hit the crate their respective directions and each sees the crate move based on their hit only.  But then 2/10th of a second later, the server comes back and says, ""Well actually, you are both wrong.  The crate went this way.""   Suddenly both players see the crate drastically change directions and glitch to a new location.</p>

<p>Bottom line is, a glitchy game.</p>

<p><strong>Conclusion</strong></p>

<p>Basically there is no way to make a <em>perfect</em> physics game with multiple players when any kind of latency exists.  You can make a pretty good game, but you always will have the risk of excessive latency creating a bad experience for some players.  However there are things you can do to keep your game experience a good one.</p>

<p><strong>Things you can do to make a multiplayer game run well</strong></p>

<p>Use simple collision volumes.  Don't bother modeling every detail of a shape with physics when a simple cube shape will do.  A spikey ball doesn't have to be modeled as a spikey ball for physics.  Instead just model it as a sphere.</p>

<p>Make small inconsequential objects client-only items.  An example might be bits of broken glass from a broken window.  You can let each client simulate it on their own, and it won't really matter if they are different.</p>

<p>Only make objects physics objects if they need to be physics objects to keep the number of active physics objects low.</p>

<p>Run your game in slow motion when doing multiplayer physics.  Think ""bullet time"" maybe.  Slow motion games compensate for latency and allow multiple players to interact with physics together.</p>

<p>Allow players to setup a situation of some kind together, and then on some cue, the physics is simulated for both players and both watch the result of their combined actions.  Players may not interfere with the sequence until it is completed.</p>

<p>Separate players phsyics so they can't interfere with each other.  This would be great for a game like bowling or pool, where only one player at a time has control, or each player has their own ""sandbox"" (like a bowling lane).</p>

<p>If you can't beat 'em, join 'em and make physics lag be part of your game. Imagine a story about being in a glitchy universe with broken physics laws or something :)</p>

<p><strong>Appendix:  How shooting games deal with it</strong></p>

<p>Shooting games deal with it by not doing overly complex physics.  They do use client side effects so players see things quickly, but then the server makes the final call on what has happened.</p>

<p>Imagine a scenario where player A shoots player B.  Your typical shooter game will do something like this...</p>

<ol>
<li>A will locally calculate if they hit B, and if it looks like there is a hit, it plays a ""hit"" effect like a blood puff.  This is done client side so that the player immediately sees a reaction to their action.  If you don't do this, the game feels laggy.</li>
<li>A also sends a message to the server saying, ""I shot along this vector""</li>
<li>When the server gets the message, it looks at where IT thinks the players are, and decides if A's shot vector hits B.</li>
<li>If the server decides A hit B, it decides B is hit, and sends a message to BOTH clients saying what happened.</li>
<li>If the server decides A did NOT hit B, B is fine, and A ""misses"".  It may look to A like they hit (""I saw the blood puff!"") but it's the servers call that they missed.</li>
</ol>

<p>So how could A miss B when it looked like they hit them?  Because B may have moved, but A hasn't seen it yet because the server hasn't sent a, ""B moved to here"" message yet to the client.</p>

<p>Valve has a good writeup on their site about this.  See <a href=""http://developer.valvesoftware.com/wiki/Source_Multiplayer_Networking"">http://developer.valvesoftware.com/wiki/Source_Multiplayer_Networking</a></p>
","6653"
"Most efficient way to convert Vector3 to Vector2","10979","","<p>What is the most efficient and fastest way to convert a Vector3 to a Vector2?</p>

<p><em>Casting:</em></p>

<pre><code>Vector2 vector2 = (Vector2)vector3;
</code></pre>

<p><em>Initializing a new Vector2:</em></p>

<pre><code>Vector2 vector2 = new Vector2(vector3.x, vector3.y);
</code></pre>

<p>Or is there another method that I don't know?</p>
","<pre><code>Vector3 v3 = Vector3.one;
Vector2 v2 = v3;
</code></pre>

<blockquote>
  <p>Vector3s can be implicitly converted to Vector2 (z is discarded).</p>
</blockquote>

<p><a href=""http://docs.unity3d.com/ScriptReference/Vector2-operator_Vector3.html"" rel=""noreferrer"">http://docs.unity3d.com/ScriptReference/Vector2-operator_Vector3.html</a></p>

<p>If you have to make a lot of conversions you may have to change the way you use your vectors. Make two tests and time them to see which one works for you. </p>

<p><strong>UPDATE WITH TESTS:</strong>
Since you asked which one is the <strong>fastest</strong> I created a test running 10000000 conversions of each in Unity. It appears that the Initializing version is quickest in this case. <strong>BUT, you should always use the one that suits your own context, so I advise you to run your own tests in your game.</strong> </p>

<blockquote>
  <p>TestConvertByOperation 10000000 instances: 0.2714049s </p>
  
  <p>TestConvertByCasting 10000000 instances: 0.286027s </p>
  
  <p>TestConvertByInitializing 10000000 instances: <strong>0.1458781s</strong> </p>
</blockquote>

<pre><code>using UnityEngine;

public class TestVector3Conversion : MonoBehaviour
{

    readonly int iterations = 10000000;
    Vector3 testVector = new Vector3(3f, 14f, 42f);

    void Start()
    {
        Debug.Log(string.Format(""TestConvertByOperation {0} instances: {1}s"", iterations, TestConvertByOperation()));
        Debug.Log(string.Format(""TestConvertByCasting {0} instances: {1}s"", iterations, TestConvertByCasting()));
        Debug.Log(string.Format(""TestConvertByInitializing {0} instances: {1}s"", iterations, TestConvertByInitializing()));
    }

    float TestConvertByOperation()
    {
        var timeStart = Time.realtimeSinceStartup;

        for (int i = 0; i &lt; iterations; i++)
        {
            Vector2 v2 = testVector;
        }

        return Time.realtimeSinceStartup - timeStart;
    }

    float TestConvertByCasting()
    {
        var timeStart = Time.realtimeSinceStartup;

        for (int i = 0; i &lt; iterations; i++)
        {
            Vector2 v2 = (Vector2)testVector;
        }

        return Time.realtimeSinceStartup - timeStart;
    }

    float TestConvertByInitializing()
    {
        var timeStart = Time.realtimeSinceStartup;

        for (int i = 0; i &lt; iterations; i++)
        {
            Vector2 v2 = new Vector2(testVector.x, testVector.y);
        }

        return Time.realtimeSinceStartup - timeStart;
    }

}
</code></pre>
","114122"
"how to ignore physics collision of some objects in box2d","10973","","<p>I know this sounds silly but I would like some objects to follow physics while others not to collide each other. </p>

<p>I tried to achieve them by setting their position exclusively. But then it will ignore all physics. </p>

<p>Is what I am trying to do even possible?</p>
","<p>Read up on collision filtering in the Box2D manual:</p>

<blockquote>
  <p>Collision filtering allows you to prevent collision between fixtures.
  For example, say you make a character that rides a bicycle. You want
  the bicycle to collide with the terrain and the character to collide
  with the terrain, but you don't want the character to collide with the
  bicycle (because they must overlap). Box2D supports such collision
  filtering using categories and groups.</p>
  
  <p>Box2D supports 16 collision categories. For each fixture you can
  specify which category it belongs to. You also specify what other
  categories this fixture can collide with. For example, you could
  specify in a multiplayer game that all players don't collide with each
  other and monsters don't collide with each other, but players and
  monsters should collide</p>
</blockquote>

<p>Link to manual <a href=""http://box2d.org/manual.pdf"" rel=""nofollow"">here</a>.  (Search for Filtering)
. </p>
","22542"
"What should a game engine do?","10970","","<p>I'd like to improve my skills/try something new and I'd like to start with 3D. I have read <a href=""https://gamedev.stackexchange.com/questions/5465/starting-programming-in-3d-with-c"">Starting programming in 3D with C++</a> but I have question about engines:</p>

<ul>
<li>What should engine do? I know it is abstraction layer above 3D API (i.e. OpenGL or DirectX) but what should it exactly do?</li>
</ul>
","<p>You're right in saying that a game engine is abstracting away from the low level graphics APIs, but a fully fledged game engine does a lot more.</p>

<p>Game engines are intended to make everything with regards to game development easier. They do each have their own unique features, but generally they provide easy abstraction layers for graphics, audio, input, scene management, collision detection, maths and general useful utilities. Some provide wrappers and plugins for physics APIs and some even have some AI support (mostly limited to FSMs, pathfinding and - the current trend - behaviour trees). A lot of them support, and pride themselves, on cross-platform functionality.</p>

<p>A game engine's purpose is to make it easier for the user to create a game, without having to deal with the small annoyances in creating a game from scratch or having to install a whole bunch of libraries and writing your own wrappers for them to suit your game.</p>

<p>There are a lot of engines out there, but beware of the difference between a graphics engine and a games engine (For example, Unity would be a games engine, whereas Ogre would be a graphics engine).</p>

<p>I've got two books on the subject, but they provide a good overview on the subject:  </p>

<ul>
<li><p>3D Game Engine Architecture by David
H Eberly</p></li>
<li><p>Game Coding Complete by Mike
McShaffry</p></li>
</ul>

<p>They're not too in depth as you would need several books on each component to get the depth of knowledge you'd need to create a full, professional game engine, but they explain the concepts very well, I think.</p>

<p>If you're starting out game dev, don't make an engine. I refer you to the following page: <a href=""http://geometrian.com/programming/tutorials/write-games-not-engines/"" rel=""nofollow"">http://geometrian.com/programming/tutorials/write-games-not-engines/</a></p>

<p>Engines are a tricky thing to get right. If you write a load of games, you'll find you have a lot of reusable code after a while which you can use to make your own personal engine to help you out. And having a lot of (complete) games under your belt is a lot more impressive than a single engine.</p>

<p>Hope that helps.</p>

<p>Ray</p>
","7872"
"How do I discourage ""loot from party members who are about to leave"" behavior?","10958","","<p>In my RPG, I have companion characters that can potentially leave the party. A behavior I have witnessed among testers is something that I think many RPGs deal with, namely that players will strip the party members of all equipment before they leave the party. For instance:</p>

<ul>
<li>One tester removed all gear from a companion, then talked to them and chose the ""I want you to leave"" dialogue option.</li>
<li>Another tester saw that a companion was removed from the party via a scripted event, then loaded to an earlier save, stripped the gear from the companion, then re-played the scripted event.</li>
</ul>

<p>I want to avoid this behavior because it encourages meta-gaming/save-scumming and breaks immersion. If this were a real life group of medieval adventurers, one of the group members wouldn't be ordered to strip down to their underwear moments before being ambushed and captured.</p>

<p>I don't want gear to be ""stuck"" on a character so that it can never be upgraded (I once played an RPG where I was frustrated that my companion had mediocre armor, but I wasn't permitted to swap it for superior armor I found later). </p>

<p>Is there any way that I can get the best of both worlds by allowing character equipment to be improved, while preventing (or at least limiting the incentive) to meta-game/save-scum and loot characters who are about to leave?</p>
","<p>As Charanor and Philipp point out in other comments &amp; answers, there is a school of thought in game design (called ""Love the Player"" in my studio) that says if the player wants to do something that doesn't break the game for other players, err on the side of letting them do it. Players who see a kidnapping twist coming and strategically prepare for it get to feel smart, rather than powerless, and you avoid creating a situation where the player's one-of-a-kind ultra-rare gear can be lost forever without recourse, without needing to create extra systems to protect against this. That's a valid approach to this design problem.</p>

<p>There's another school of thought, <a href=""https://www.designer-notes.com/?p=369"" rel=""noreferrer"">articulated in Soren Johnson's article ""Water Finds a Crack,""</a> that says that players are drawn to choices that give them a material benefit in games, even to the detriment of their own enjoyment. Players tend to undervalue their subjective experience and time investment relative to things they can quantify in a game, like the value of gear. This means that some players who would normally leave the gear on - for reasons of role-playing immersion, or just to avoid extra menu fiddling - can feel pressured to play differently because that's the ""wrong"" choice according to the numbers.</p>

<p>If this proves to be a concern for your target audience (validate this by polling testers on their subjective impressions - if they're engaging in gameplay you'd consider ""wrong,"" but enjoying it all the same, then maybe it's not a problem for them), there are things we can do to address this dissonance.</p>

<p>The other answers do a great job covering several different approaches, so I want to suggest just one more: <strong>narrow the gap between the player's reality and the character's.</strong></p>

<blockquote>
  <p>If this were a real life group of medieval adventurers, one of the
  group members wouldn't be ordered to strip down to their underwear
  moments before being ambushed and captured.</p>
</blockquote>

<p>Why not? What consequences lead the characters to make different decisions than players in this case? And how can we reintroduce those consequences into the player's view of the situation? Some thoughts:</p>

<ul>
<li><p><strong>Morality:</strong> taking all your ally's stuff and leaving them to rot is a pretty dick move. It could sit poorly with a character's conscience or moral code (alignment system) or affect how likely other people are to trust them (reputation system) or possibly even invite retribution from the wronged party and their allies (revenge system)</p></li>
<li><p><strong>Uncertainty:</strong> the characters don't know when the ambush will happen, so they can't plan for it. Taking away useful gear on just the possibility that a character might get abducted means their utility and survivability in fights leading up to that event are greatly reduced. Set the abduction scene to happen sometime randomly within a gauntlet of several encounters with no save point in-between, and you put even a player with access to walkthroughs in a similar position. It's still possible to savescum it, but the increased difficulty/time investment can help players who aren't really there for the hyper-optimization to resist the temptation.</p></li>
<li><p><strong>Future Payoff:</strong> If I leave a companion with good gear, I can hope they'll survive long enough to meet &amp; help me again. Or for them (or their next of kin) to repay my generosity in other ways. Make the gear the character left with matter in some way - maybe you play a short vignette mission as that character while they're separated from the group, so stripping them down before that actually makes this harder to proceed (just beware of trapping a hasty player in an unwinnable situation if they can't backtrack/reload to before the split). Or maybe you model the chance the character survives, or their prosperity while they're away from the group, based on a function of the gear they were left with. A sidekick let loose with good gear is more successful in developing their skills and is higher-level / has even better gear when you next meet them, for example.</p></li>
</ul>
","152636"
"How to improve batching performance","10957","","<p>I am developing a sprite based 2D game for mobile platform(s) and I'm using OpenGL (well, actually Irrlicht) to render graphics. First I implemented sprite rendering in a simple way: every game object is rendered as a quad with its own GPU draw call, meaning that if I had 200 game objects, I made 200 draw calls per frame. Of course this was a bad choice and my game was completely CPU bound because there is a little CPU overhead assosiacted in every GPU draw call. GPU stayed idle most of the time.</p>

<p>Now, I thought I could improve performance by collecting objects into large batches and rendering these batches with only a few draw calls. I implemented batching (so that every game object sharing the same texture is rendered in same batch) and thought that my problems are gone... only to find out that my frame rate was even lower than before. </p>

<p>Why? Well, I have 200 (or more) game objects, and they are updated 60 times per second. Every frame I have to recalculate new position (translation and rotation) for vertices in CPU (GPU on mobile platforms does not support instancing so I can't do it there), and doing this calculation 48000 per second (200*60*4 since every sprite has 4 vertices) simply seems to be too slow.</p>

<p>What I could do to improve performance? All game objects are moving/rotating (almost) every frame so I really have to recalculate vertex positions. Only optimization that I could think of is a look-up table for rotations so that I wouldn't have to calculate them. Would point sprites help? Any nasty hacks? Anything else?</p>

<p>Thanks.</p>
","<p>Did you use <a href=""http://gitorious.org/irrlichtandroid/irrlichtandroid"">my port of irrlicht</a> for android ? For 2d sprites on Android and iphone, i use the same tricks as you: batching. I try many solutions in OpenGL ES 1.x and 2.x:</p>

<ul>
<li>sort by z (parallax) and by texture, do the transformations on the CPU and call glDrawArrays or glDrawElements (fastest way). Use one big texture if you can.</li>
<li>same trick with VBO, not faster because for each frame you refresh all informations. It can be useful for statics sprites.</li>
<li>use OpenGL ES 2.x and use Vertex shader to compute positions (slower)</li>
<li>use PointSprites (no solution if it is not a square and too many transparent pixels kill fillrate)</li>
<li>use gldrawtexoes extension...</li>
<li>use a drawcall for each sprite (slowest method)</li>
</ul>

<p>So as you, all transformations are done by the CPU for OGLES 1.x or OGLES 2.x. If you have neon instructions, you can use them to speed your computations.</p>

<p>Ps: on iphone or android devices, i'm not CPU limited but fill rate limited. So it is very important to limit overdraw.</p>
","9142"
"Memory allocation patterns used in game development","10957","","<p>I have been researching creating my own allocator methods (that will support things such as a memory pool and profiling), however, as I continue my research I have been looking for how this was done in game development. </p>

<p>What memory allocation technique could I use, and why is it a good technique?</p>
","<p><a href=""http://rads.stackoverflow.com/amzn/click/1568814135"">Game Engine Architecture</a> has some information regarding this topic.  The basics are that you need to do some analysis to understand what your memory requirements per level/frame/etc. are like, but there are a few patterns the author mentions having seen several times:</p>

<ul>
<li><strong>Stack-based allocators:</strong>  These allocate a large segment of memory once, and then allocate pointers within that block of memory in response to requests from elsewhere in the game.  This is useful to avoid context switches required by memory allocation, and also because you can use your own techniques to enforce contiguity, or specific alignment for SIMD operations.  Some engines also use a double-ended stack where one kind of resource is loaded from the top and the other is loaded from the bottom.  Perhaps LSR (Load and Stay Resident, the kind of thing that will be needed throughout the entirety of your game) from the top, and per-level data from the bottom.</li>
<li><strong>Single frame memory, or double-buffered frame memory:</strong>  Memory for operations that occur within one or two frame cycles.  This is useful because rather than having to allocate/deallocate every frame, you can simply blow away last frame's data by resetting the pointer you use to keep track of memory to the beginning of the block.</li>
<li><strong>Object Pools:</strong>  A block of memory for many same-size objects, such as particles, enemies, projectiles.  These are useful because you can easily achieve contiguity by finding the first unused segment in your pool.  They also make iteration easy, because each object is at a known offset from the last.</li>
</ul>

<p>The biggest thing the author mentions to look out for is memory fragmentation.  This is less of an issue if you're developing for e.g. a PC where you have some kind of memory paging backup that you can count on, but in a fixed memory context like a console, there's the risk of being ""out of memory"" when trying to allocate for a large object because your memory is fragmented in such a way that only small contiguous blocks are available.  To that end, he recommends that a stack-based allocator as above also include a method of periodically defragmenting its contents.</p>

<p>For more information on the actual code involved in this, I highly recommend <a href=""http://www.swedishcoding.com/2008/08/31/are-we-out-of-memory/"">Christian Gyrling's article, ""Are we out of memory?""</a>, which covers techniques for custom allocators, mostly from a perspective of analyzing memory usage patterns, but this is also applicable to devising a custom solution for memory management.</p>
","25788"
"How do I make an 8 bit sprite sheet using GIMP or Paint.NET?","10957","","<p>I'm looking to create a sprite sheet for an 8 bit, 2D RPG I'm making. All I need to do at the moment is render in some textures. To do this, I want to make an 8x8 sprite sheet. Now, I am really bad at using anything to do with GIMP or Paint.NET, so I came here for some help. </p>

<p><em>Are there any ways to create an 8x8 blank sprite sheet using either GIMP or Paint.NET?</em></p>

<p>I have some other info you might need for whatever reason down here:</p>

<ul>
<li>I'm using Java to code this game.</li>
<li>I'm following Ryan van Zeben's (DesignsByZephyr) tutorials, and I'm trying to make the same sprite sheet he made in Episode two of his series.</li>
<li>At the moment, I don't have access to Photoshop or anything that requires a lot of money (I'm quite young).</li>
<li>I'm willing to use plugins and/or other free photo-editing programs.</li>
<li>I am using Windows 7 as my OS, and Eclipse Luna as my IDE.</li>
</ul>
","<p>Sure, this is quite simple really.
I'll guide you through Paint.net.</p>

<ol>
<li>Open the application and go to New.</li>
<li>In the dimensions, put 8 for width and 8 for height.</li>
<li>A new 8x8 canvas will open, typically I zoom in all the way to
3200%.</li>
<li>I'll also get rid of the white background layer, by making a new
layer, then deleting the background one.</li>
<li>Now you have the canvas to work on, you can save it as a .pdn file.</li>
<li>When you are ready to save the tile/image/sprite, go to File -> Save
As, and choose file type: PNG.</li>
<li>A ""Save Configuration"" box will open up and you can choose ""Bit
Depth: 8-bit"" to save the completed work.</li>
</ol>
","84665"
"Enter Key press event detect from textbox - Unity3D - C#","10953","","<p>i am doing a project with Unity3D . in the interface there is a textbox. once user input some text and and press enter key then i want to read the text in text box. so please tell me how to  programmatically detect the key press event in unity3D - C# using MonoDeveloper. </p>
","<p>It's a little tricky. It's pretty confusing if you have a solid background with the web platform, JavaScript and DOM Events in partcular, where most of the events are abstractized in closures for each control.</p>

<p>In Unity, the Events are fired globally on <code>GUI</code>. You must then check them, and act accordingly.</p>

<h3>Theory</h3>

<ul>
<li>while the <code>GUIWindow</code> is drawn, listen for your <a href=""http://docs.unity3d.com/Documentation/ScriptReference/EventType.html"" rel=""nofollow"">EventType</a> on <code>Event.current</code> (the event that just happened).</li>
<li>if needed, check it against your GUI controls. </li>
<li>if all the requirements have been matched, do something.</li>
</ul>

<h3>Implementation</h3>

<pre><code>using UnityEngine;

public class Somegui : MonoBehaviour
{

private string inputValue = """";
private bool windowShouldBeDrawnCondition = false;

void Update()
{
    // open dialog upon Enter
    if (Input.GetKeyDown(KeyCode.Return))
    {
        windowShouldBeDrawnCondition = !windowShouldBeDrawnCondition;
    }
}

void OnGUI()
{
    if (windowShouldBeDrawnCondition)
    {
        // draw dialog
        GUILayout.Window(0, new Rect(100, 100, 200, 0), DrawMyWindow, ""Window Title"");
    }
}

void DrawMyWindow(int windowID)
{
    // check for keydown event
    if (Event.current.type == EventType.KeyDown)
    {
        // no matter where, but if Escape was pushed, close the dialog
        if (Event.current.keyCode == KeyCode.Escape)
        {
            windowShouldBeDrawnCondition = false;
            return; // no point in continuing if closed
        }

        // we look if the event occured while the focus was in our input element
        if (GUI.GetNameOfFocusedControl() == ""input"" &amp;&amp; Event.current.keyCode == KeyCode.Return)
        {
            SubmitInputValue();
        }
    }

    GUI.SetNextControlName(""input"");
    inputValue = GUILayout.TextField(inputValue);

    // in case nothing else if focused, focus our input
    if (GUI.GetNameOfFocusedControl() == string.Empty)
    {
        GUI.FocusControl(""input"");
    }
}

private void SubmitInputValue()
{       
    // do not proceed if empty
    if (inputValue.Length &gt; 0)
    {
            // do something
        Debug.Log(inputValue);

        inputValue = """"; // usually, upon sending, the field should be reset
    }
}
}
</code></pre>

<p>Cannot test this at the moment, but it should work.</p>

<p>I have given, I hope, pretty understandable and reasonable comments to grasp what is fully going on there.</p>
","56840"
"Should I learn 2d game development before 3d?","10952","","<p>I'm an iPhone app developer. I want to get into iOS gaming. The question is-should I start with learning 2D like Cocos 2D or Corona SDK before learning 3D gaming like Unity? I'm more interested in 3D gaming, but do you think that knowing 2D gaming is a prerequisite to learning 3D development?</p>
","<p><strong>It depends on how strong you are with mathematics,</strong> <em>and</em> <strong>3D game programming concepts</strong>.</p>

<p>2D you can get by using only concepts of x,y positions and velocities (and adding and subtracting them - basically vectors) and 2D box collision.</p>

<p>In 3D, you have to worry about a lot more math:  projection matrices, viewing matrices, frusta..</p>

<p>In addition, you have to interact with a <strong><em>much richer set of functions</em></strong> from the drawing API you're using, (just by virtue of the fact that you're doing 3D, so you have to learn a lot more functions that deal with 3D).</p>

<p>Microsoft XNA has <strong>excellent</strong> support for starting out in 2D, and makes rendering easy using <a href=""http://msdn.microsoft.com/en-us/library/microsoft.xna.framework.graphics.spritebatch.aspx"">SpriteBatch</a>.  As soon as you venture into 3D, you automatically have to learn <a href=""http://msdn.microsoft.com/en-us/library/microsoft.xna.framework.graphics.vertexbuffer.aspx"">VertexBuffer</a>, or <a href=""http://msdn.microsoft.com/en-us/library/microsoft.xna.framework.graphics.model.aspx"">Model</a>, and then comes ModelBones and everything else that goes with it.</p>

<p>You're best off starting 2D just because the concepts you need to grasp is less (2D sprites? A cakewalk!).  After you have some experience under your belt, then you should be fine doing 3D.</p>
","16100"
"How can I implement a ""20 Questions"" algorithm?","10885","","<p>Ever since childhood, I've wondered how the <em>20Q</em> electronic game worked. You think of an object, thing, or animal (e.g. <em>potato</em> or <em>donkey</em>). The device then asks you a series of questions such as:</p>

<ul>
<li>Is it larger than a loaf of bread?</li>
<li>Is it found outdoors?</li>
<li>Is it used for recreation?</li>
</ul>

<p>For each question, you can answer <em>yes</em>, <em>no</em>, <em>maybe</em>, or <em>unknown</em>. I always imagined it work with immense, nested conditionals (<code>if</code>-statements). However, I think that's an unlikely explanation because of its complexity for the programmer.</p>

<p>How would I implement such a system?</p>
","<p>I don't know how 20Q did it specifically, but there is plenty of information on how to implement a game of <a href=""https://stackoverflow.com/questions/887533/how-do-20-questions-ai-algorithms-work"">20 questions</a>. </p>

<p>There are lots of ways of solving this, but I'll describe one way. These games can implement some sort of <a href=""http://en.wikipedia.org/wiki/Decision_tree"" rel=""nofollow noreferrer"">decision tree</a>. For an electronic game like 20Q, this tree would be precomputed and fairly easy to traverse. There are methods for using <a href=""http://en.wikipedia.org/wiki/Decision_tree_learning"" rel=""nofollow noreferrer"">learning decision trees</a> where the game can accept new objects at the end of it's questions if it's unable to guess what the user is asking.</p>

<p>When the questions are a series of yes or no answers, you end up with a binary tree. Each node is a question and the leaves are answers. When questions are answered with unknown or not sure, the child nodes can be combined and their questions asked in series to further cull the possible answers.</p>

<p><img src=""https://i.stack.imgur.com/zq1hX.jpg"" alt=""enter image description here""></p>

<p>Basically this is the process:</p>

<ol>
<li>Start with a full list of the objects. These can all start at equally likely, or they can be sorted by how likely the object was to be chosen in testing.</li>
<li>Start with the first question in the decision tree. Push it onto the question queue.</li>
<li>Ask the question on top of the queue.</li>
<li>Process response:

<ol>
<li>Yes/No answers removes/adds a predetermined amount of probability from each answer based on the question.</li>
<li>""Maybe"" answer removes/adds a fraction of the predetermined amount of a ""yes"".</li>
<li>""Unknow"" does not change probabilities </li>
</ol></li>
<li>An ""Unknown"" or ""Maybe"" response pushes both of the next nodes questions onto the question queue. A ""Yes"" or ""No"" response just adds the one respective yes/no node onto the question queue.</li>
<li>Go to step 3 until out of questions or probability of a single answer is beyond a predefined ""certainty"" threshold. </li>
<li>Provide most probable answer.</li>
</ol>

<p>Generating the tree is probably the topic of another question. But basically it's choosing questions that split the answers as much as possible. Put the questions that divide the questions most equally near the beginning so that the most number of questions can be culled the fastest.</p>
","40032"
"How are game cinematics made?","10875","","<p>How is a game cinematic made? I can't find a decent article anywhere to give at least starting point into understanding what it takes to create a cinematic.</p>

<p>I don't mean typical scripted game play, rather, the really nice cut scenes games have, like the ones Blizzard has for almost every game they develop.</p>

<p><a href=""http://www.youtube.com/watch?v=OGwCU_qA22U"" rel=""nofollow"">http://www.youtube.com/watch?v=OGwCU_qA22U</a></p>

<p>Note: I'm not sure what to tag this under.</p>
","<p><strong>Blood, sweat and <strike>tears</strike> beers</strong></p>

<p>For the movie-quality cinematics you see from companies like Blizzard, they are often following a process similar (albeit on a smaller scale) to the processes of professional movie studios like Pixar. This involves professional 3D artists, modellers, animators, etc, as well as various high-end technologies like 3DS Max, Maya, etc.</p>

<p>For the teaser trailer for Starcraft II, <a href=""http://eu.starcraft2.com/features/interviews/cinematicteaser.xml"">this interview with Blizzard</a> (Part III particularly) mentions how the Marine 3D model had 5 million polygons, and the cinematic broke their renderer.</p>

<p>The Australian magazine Atomic also have a good article on Blizzard's cinematic development process <a href=""http://www.atomicmpc.com.au/Feature/146035,eye-of-the-storm-blizzards-cinematics-team.aspx/1"">here</a></p>
","4646"
"How does A* pathfinding work?","10874","","<p>I would like to understand on a fundamental level the way in which A* pathfinding works. Any code or psuedo-code implementations as well as visualizations would be helpful.</p>
","<h3>Disclaimer</h3>

<p>There are tons of code-examples and explanations of A* to be found online. This question has also received lots of great answers with a lot of useful links. In my answer I'll try to provide an illustrated example of the algorithm, which might be easier to understand than code or descriptions.</p>

<hr>

<h3>Dijkstra's algorithm</h3>

<p>To understand A*, I suggest you first have a look at <a href=""http://en.wikipedia.org/wiki/Dijkstra%27s_algorithm"" rel=""noreferrer"">Dijkstra's algorithm</a>. Let me guide you through the steps Dijkstra's algorithm will perform for a search.</p>

<p>Our start-node is <code>A</code> and we want to find the shortest path to <code>F</code>. Each edge of the graph has a movement cost associated with it (denoted as black digits next to the edges). Our goal is to evaluate the minimal travel cost for each vertex (or node) of the graph until we hit our goal node. </p>

<p><img src=""https://i.stack.imgur.com/mwQak.png"" alt=""Dijkstra&#39;s illustrated, part 1""></p>

<p>This is our starting point. We have a list nodes to examine, this list currently is:</p>

<pre><code>{ A(0) }
</code></pre>

<p><code>A</code> has a cost of <code>0</code>, all other nodes are set to <em>infinity</em> (in a typical implementation, this would be something like <code>int.MAX_VALUE</code> or similar).</p>

<p><img src=""https://i.stack.imgur.com/I2f7F.png"" alt=""Dijkstra&#39;s illustrated, part 2""></p>

<p>We take the node with the lowest cost from our list of nodes (since our list only contains <code>A</code>, this is our candidate) and visit all its neighbors. We set the <em>cost</em> of each neighbor to: </p>

<pre><code>Cost_of_Edge + Cost_of_previous_Node
</code></pre>

<p>and keep track of the previous node (shown as small pink letter below the node). <code>A</code> can be marked as solved (red) now, so that we don't visit it again. Our list of candidates now looks like this:</p>

<pre><code>{ B(2), D(3), C(4) }
</code></pre>

<p><img src=""https://i.stack.imgur.com/dfFNf.png"" alt=""Dijkstra&#39;s illustrated, part 3""></p>

<p>Again, we take the node with the lowest cost from our list (<code>B</code>) and evaluate it's neighbors. The path to <code>D</code> is more expensive than the current cost of <code>D</code>, therefore this path can be discarded. <code>E</code> will be added to our list of candidates, which now looks like this:</p>

<pre><code>{ D(3), C(4), E(4) }
</code></pre>

<p><img src=""https://i.stack.imgur.com/XfELZ.png"" alt=""Dijkstra&#39;s illustrated, part 4""></p>

<p>The next node to examine is now <code>D</code>. The connection to <code>C</code> can be discarded, as the path isn't <em>shorter</em> than the existing cost. We did find a shorter path to <code>E</code> though, therefore the cost for <code>E</code> and it's previous node will be updated. Our list now looks like this:</p>

<pre><code>{ E(3), C(4) }
</code></pre>

<p><img src=""https://i.stack.imgur.com/aDZlt.png"" alt=""Dijkstra&#39;s illustrated, part 5""></p>

<p>So as we did before, we examine the node with the lowest cost from our list, which is now <code>E</code>. <code>E</code> only has one unsolved neighbor, which is also the target node. The cost to reach the target node is set to <code>10</code> and it's previous node to <code>E</code>. Our list of candidates now looks like this:</p>

<pre><code>{ C(4), F(10) }
</code></pre>

<p><img src=""https://i.stack.imgur.com/Ww2wa.png"" alt=""Dijkstra&#39;s illustrated, part 6""></p>

<p>Next we examine <code>C</code>. We can update the cost and previous node for <code>F</code>. Since our list now has <code>F</code> as node with the lowest cost, we're done. Our path can be constructed by backtracking the previous shortest nodes.</p>

<hr>

<h3>A* algorithm</h3>

<p>So you might wonder why I explained Dijkstrato you instead of the <a href=""http://en.wikipedia.org/wiki/A-star_algorithm"" rel=""noreferrer"">A* algorithm</a>? Well, the only difference is in how you weigh (or sort) your candidates. With Dijkstrait's:</p>

<pre><code>Cost_of_Edge + Cost_of_previous_Node
</code></pre>

<p>With A* it's:</p>

<pre><code>Cost_of_Edge + Cost_of_previous_Node + Estimated_Cost_to_reach_Target_from(Node)
</code></pre>

<p>Where <code>Estimated_Cost_to_reach_Target_from</code> is commonly called a <em>Heuristic</em> function. This is a function that will try to estimate the cost to reach the target-node. A good heuristic function will achieve that less nodes will have to be visited to find the target. While Dijkstra's algorithm would expand to all sides, A* will (thanks to the heuristic) search in the direction of the target.</p>

<p><a href=""http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html"" rel=""noreferrer"">Amit's page about heuristics</a> has a good overview over common heuristics.</p>
","23760"
"How can I rotate about an arbitrary point in 3D (instead of the origin)?","10862","","<p>I have some models that I want to rotate using quaternions in the normal manner, except instead of rotation about the origin, I want it to be offset slightly. I know that you don't say, in 3d space, that you rotate about a point; you say you rotate about an axis. So I'm visualizing it as rotating about a vector whose tail is positioned not at the local origin.</p>

<p>All affine transformations in my rendering / physics engine are stored using SQT (scale, quaternion, translation; an idea borrowed from the book <em>Game Engine Architecture</em>.) So I build a matrix each frame from these components and pass it to the vertex shader. In this system, translation is applied, then scale, then rotation.</p>

<p>In one specific case, I need to translate an object in world space, scale it, and rotate it about a vertex not centered at the object's local origin.</p>

<p><strong>Question:</strong> Given the constraints of my current system described above, how can I achieve a local rotation centered about a point other than the origin? <em>Automatic upvote to anyone who can describe how to do this using only matrices as well :)</em></p>
","<h3>In short</h3>

<p>You only need to change T in your SQT form.</p>

<p>Replace the translation vector <code>v</code> with <code>v' = v-invscale(p-invrotate(p))</code> where <code>v</code> is the initial translation vector, <code>p</code> is the point around which you want the rotation to occur, and <code>invrotate</code> and <code>invscale</code> are the inverses of your rotation and scale.</p>

<h3>Quick demonstration</h3>

<p>Let <code>p</code> be the point around which you apply rotation <code>r</code>. Let <code>s</code> be your scaling parameters and <code>v</code> your translation vector. The final matrix transformation is <code>T(p)R(r)T(-p)S(s)T(v)</code> instead of <code>R(r)S(s)T(v)</code>.</p>

<p>What you want is new transformation parameters <code>v'</code>, <code>r'</code> and <code>s'</code> such that the final matrix transformation is <code>R(r')S(s')T(v')</code> and we have:</p>

<pre><code>T(p)R(r)T(-p)S(s)T(v) = R(r')S(s')T(v')
</code></pre>

<p>Behaviour at infinity indicates that rotation parameters and scaling parameters cannot change (this could be demonstrated). We thus have <code>r = r'</code> and <code>s = s'</code>. The only missing parameter is therefore <code>v'</code>, your new translation vector:</p>

<pre><code>T(p)R(r)T(-p)S(s)T(v) = R(r)S(s)T(v')
</code></pre>

<p>If these matrices are equal, their inverses are equal:</p>

<pre><code>T(-v)S(-s)T(p)R(-r)T(-p) = T(-v')S(-s)R(-r)
</code></pre>

<p>This especially holds true for origin <code>O</code>:</p>

<pre><code>T(-v)S(-s)T(p)R(-r)T(-p)O = T(-v')S(-s)R(-r)O
</code></pre>

<p>Scaling and rotating the origin yields the origin, whe thus get:</p>

<pre><code>T(-v)S(-s)T(p)R(-r)(-p) = -v'
</code></pre>

<p><code>v'</code> is the new translation vector you are looking for that lets you store your transformation in SQT form. It is probably possible to simplify the computation; but at least the required <em>storage</em> is not increased.</p>
","19307"
"Trap mouse in SDL","10846","","<p>How can I trap the user's mouse inside my game? It's not a fullscreen game, but I want it so that the user cannot drag the mouse to outside the screen.</p>

<p>Do I have to check the coordinates of the mouse and SDL_WarpCursor to make it say inside the window (manually), or is there an automatic way?</p>

<p>Thank you.</p>
","<p>While you can implement this using SDL_WarpCursor(), I've run into problems with that method on some platforms.  I've had real problems with some platforms not reliably performing the WarpCursor() action, particularly when I've been calling it every frame.  </p>

<p>Also, remember that on many platforms, the cursor is handled at a higher frequency than your app.  This is particularly true if you're running below 60fps!  So even if the platform is successfully warping the mouse on every frame of your game, the cursor could still get away from your window if it's receiving updates in between your rendered frames.</p>

<p>The correct method for trapping the mouse under SDL is:</p>

<pre><code>SDL_WM_GrabInput( SDL_GRAB_ON );
</code></pre>

<p>This tells SDL that your intention is to actually grab full control of mouse + keyboard (see <a href=""http://sdl.beuc.net/sdl.wiki/SDL_WM_GrabInput"" rel=""noreferrer"">the documentation</a>), and to therefore keep the mouse inside the window no matter what.  From this point on, the mouse will not move outside of the window, regardless of your frame rate, and you should not call SDL_WarpCursor, except if you really do intend to teleport the cursor somewhere, rather than spamming it continuously.</p>

<p>While in this ""grabbing"" mode, you will continue to receive mouse motion events as though the mouse was not being constrained inside the window.  (So if the cursor is at the right edge of the screen, and the user moves his mouse further right, you'll receive a mouse motion event showing motion to the right, though the cursor position will not change).  This is really useful for (for example) turning controls for FPS games, where you only care about relative motion of the cursor, not its absolute position.</p>

<p><strong>Update for SDL2 -- 9 December, 2013</strong></p>

<p>This interface has changed for SDL2.  If you're using SDL1.2, the answer above is still correct.  However, under SDL2 the <code>SDL_WM_GrabInput(SDL_GrabMode)</code> function is no longer available.  SDL2's new way to capture the mouse is:</p>

<pre><code>SDL_SetRelativeMouseMode(SDL_TRUE);
</code></pre>

<p>Otherwise, this is identical to the earlier function -- in this mode you will continue to receive <code>SDL_MOUSEMOTION</code> events as though the mouse wasn't being constrained inside the window.</p>
","33554"
"How do Action RPGs make different weapon types feel unique?","10828","","<p>I'm getting feedback on my game which has Action RPG elements (think Diablo, Torchlight, etc.) but you control a team of heroes.  When you kill enemies sometimes new weapons will drop.  In my game the DPS of the weapon will be randomized but stronger the further you get.  Each weapon type has a hard coded range and rate of attack, but it differs between types.  As an example, every Pistol will attack once per second and every Machine Gun will attack 5 times per second.</p>

<p>A common complaint I'm getting is:</p>

<blockquote>
  <p>The weapons needs more variety, there's not really many reasons to change weapons because they all have the same speed and small damage differences.</p>
</blockquote>

<p>I'm struggling to achieve this.  I can vary speed and range for each type, and this seems like an ""ok"" solution but it's not good enough.  This just feels like a sliding scale that looks like this:</p>

<pre><code>range &lt;-----|-----------------&gt; rate of attack
dps: 10
</code></pre>

<p>Here you can change the range and the rate of attack, but the DPS is still going to be based on the level of the enemies.  In the end, it's <em>still</em> not going to matter which weapon you choose because they'll all have about the same DPS.  </p>

<p>If I make it so they don't have the same DPS, then yeah, there will be reasons to change weapons, but it'll be because some weapons suck and some weapons are good.  I don't think this puts me in a better place.</p>

<p><strong>I want the player to feel like weapon type X has pros and cons over weapon type Y.  How can I achieve this?</strong></p>
","<p>By giving them <em>actual</em> pros and cons. </p>

<p>Damage and attack speed are one way to provide a pro/con relationship -- high damage/slow rate of fire versus low damage/high rate of fire -- for example. But that relationship can be a mathematical no-op if the resulting DPS is the same. If you put weapons out of alignment, such that the DPS is not always the same, then as you said you have an obviously better weapon.</p>

<p>So, consider adding further attributes or effects to weapon types, or to the combat system in general. For example, if your game supports the idea of ""% chance to do X on hit"" effects, that can allow you to drop the overall DPS of ""fast"" weapons, since ""fast"" weapons would make up for that by affording more opportunities for the ""% chance"" roll to trigger. Thus, the player has a choice between a weapon that offers a higher pure DPS or one that has a lower DPS but a higher overall chance of triggering on-hit effects.</p>

<p>You can also apply certain kinds of effects exclusively to certain kinds of attacks. For example, in Skyrim, each flavor of magic (fire, ice, lightning) has a unique side-effect. Fire magic causes additional damage over time via burning, whereas cold magic slows the target and lightning magic reduces the target's own mana pool. This provides a choice for players, even though the overall DPS (ignoring resistances) may be the same: they get to choose a style that complements how they want to play, either a brute force approach via fire damage or a more subtle one via cold spells.</p>

<p>Consider allowing certain kinds of skills only with certain kinds of weapons; relate those skills to the nature of the weapon in real-life. Daggers, for example, could feasibly be thrown and might have a few range-related skills (but you're not likely to be hurling your giant two-handed sword around; perhaps it would have instead skills for rendering foes immobile by damaging or destroying their limbs).</p>

<p>And then there's damage <em>type</em> you could model: piercing versus slashing versus bludgeoning damage. In D&amp;D, certain creatures could only be hurt with certain kinds of damage. While that might be too draconian for modern games, you could incorporate some amount of that flavor.</p>

<p>What you really need to do is force players to <em>make an interesting choice</em>; games are all about interesting choices.</p>
","79555"
"An object twice as close appears twice as big?","10825","","<p>So I was thinking about creating a 2D game where you can also move along the Z-axis, by changing in which layer you are. Depending on the depth I want to scale my 2D sprites.</p>

<p>Once, someone had shown me a demo in which he had a lot of 2d sprites, and by scrolling he could change the depth of the camera. So when zooming in, the objects would come closer to the player, and appear bigger. Then I wondered, how much bigger should an object be when it gets 1 unit closer. How would you calculate that?
So the guy told me: There is one basic rule I am using: ""objects twice as close, appear twice as big.""</p>

<p>Now, by testing it myself, I know that rule doesn't apply in the real world ;)
But is there some constant that is used in real world calculations for perspective or something? Or a formula?</p>

<p>I know this might not be the best place to ask such a question,
but since this is the only site I use for game-related questions, and my context is a game, I thought I'd give it a try. Also, I am kind of expecting that there is this person here that knows everything about 3D perspectives and matrices or something, since it might relate to 3D games ;) </p>

<p>tl;dr:</p>

<p>""an object twice as close, appears twice as big""
That is not true in the real world.
But which constant or formula is correct?</p>
","<p>Generally it is true, depending on your view point and in which direction it has moved, as well as the viewing angle.</p>

<p><img src=""https://i.stack.imgur.com/eaY3X.png"" alt=""Example of perspectives for objects""></p>

<p>Note how in the first camera view, as the Red block is perpendicular to the camera view, the object seems to be twice as large in a perfect 1:2 ratio (Note the arrow pointing that it hits the edge of the view after being moved twice as close)</p>

<p>The second is the same size block rotated at 45 degrees. As it is rotated, the bottom edge is no longer at the same distance from the camera as the top edge, so it does not SEEM correctly scale to a 1:2 ratio but it in actual fact is twice as large (as it is at the same angle on the further away blue block as it is in the close blue block.)</p>

<p>In conclusion this actually means your friend was correct and a 1:1 ratio <em>(""objects twice as close, appear twice as big."")</em> for your objects is a good choice.</p>
","51111"
"Update and render in separate threads","10824","","<p>I'm creating a simple 2D game engine and I want to update and render the sprites in different threads, to learn how it is done. </p>

<p>I need to synchronise the update thread and the render one. 
Currently, I use two atomic flags. The workflow looks something like:</p>

<pre><code>Thread 1 -------------------------- Thread 2
Update obj ------------------------ wait for swap
Create queue ---------------------- render the queue
Wait for render ------------------- notify render done
Swap render queues ---------------- notify swap done
</code></pre>

<p>In this setup I limit the render thread's FPS to the update thread's FPS.
Besides I use <code>sleep()</code> to limit both render and update thread's FPS to 60, so the two wait functions won't wait much time. </p>

<p>The problem is:</p>

<p>The average CPU usage is around 0.1%.
Sometimes it's go up to 25% (in a quad core PC). It means that a thread is waiting for the other because the wait function is a while loop with a test and set function, and a while loop will use all your CPU resources.</p>

<p>My first question is: is there another way to synchronise the two threads?
I noticed that <code>std::mutex::lock</code> don't use the CPU while it is waiting to lock a resource so it isn't a while loop. How does it work? 
I can't use <code>std::mutex</code> because I will need to lock them in one thread and unlock in another thread. </p>

<p>The other question is; since the program runs always at 60 FPS why does sometimes its CPU usage jumps to 25%, meaning that one of the two wait is waiting a lot? (the two threads are both limited to 60fps so they ideally won't need a lot of synchronisation).</p>

<p>Edit:
Thanks for all the replies. 
First I want to say I don't start a new thread each frame for render. I start both update and render loop at the beginning. I think multithreading can save some time :
I have the following functions:
FastAlg()  and Alg(). 
Alg() is both my Update obj and render obj and
Fastalg() is my ""send render queue to"" renderer"" "".
In a single thread :</p>

<pre><code>Alg() //update 
FastAgl() 
Alg() //render
</code></pre>

<p>In two thread:</p>

<pre><code>Alg() //update  while Alg() //render last frame
FastAlg() 
</code></pre>

<p>So maybe multithreading can save same time. 
(actually in a simple math application it does, where alg is a long algorithm amd fastalg a faster one) </p>

<p>I know that sleep isn't a good idea, although I ve never have problems. 
Will this will better? </p>

<pre><code>While(true) 
{
   If(timer.gettimefromlastcall() &gt;= 1/fps)
   Do_update()
}
</code></pre>

<p>But this will be a infinite while loop that will use all the CPU. Can I use sleep(a number &lt; 15) to limit the usage? In this way it will run at, for example, 100 fps, and the update function will be called just 60 times per second. </p>

<p>To synchronise the two threads I will use waitforsingleobject with createSemaphore so I will able to lock and unlock in different thread (whitout using a while loop), won't I?</p>
","<p>For a simple 2D engine with sprites, a single-threaded approach is perfectly good. But since you want to learn how to do multithreading, you should learn to do it correctly. </p>

<h2>Do not</h2>

<ul>
<li>Use 2 threads that run more or less lock-step, implementing a single-threaded behavior with several threads. This has the same level of parallelism (zero) but adds overhead for context switches and synchronization. Plus, the logic is harder to grok.</li>
<li>Use <code>sleep</code> to control the frame rate. Never. If someone tells you to, hit them.<br>
First, not all monitors run at 60Hz. Second, two timers ticking at the same rate running side by side will always eventually get out of sync (drop two pingpong balls on a table from the same height, and listen). Third, <code>sleep</code> is <em>by design</em> neither accurate nor reliable. Granularity may be as bad as 15.6ms (in fact, the default on Windows<sup>[1]</sup>), and a frame is only 16.6ms at 60fps, which leaves a mere 1ms for everything else. Plus, it's hard to get 16.6 to be a multiple of 15.6...<br>
Also, <code>sleep</code> is allowed to (and will sometimes!) return only after 30 or 50 or 100 ms, or an even longer time.</li>
<li>Use <code>std::mutex</code> to notify another thread. This is not what it's for.</li>
<li>Assume that TaskManager is any good at telling you what's going on, especially judging from a number like ""25% CPU"", which could be spent in your code, or within the usermode driver, or somewhere else.</li>
<li>Have one thread per high level component (there are of course some exceptions).</li>
<li>Create threads at ""random times"", ad hoc, per task. Creating threads can be surprisingly expensive and they can take a surprisingly long time before they are acutally doing what you told them (especially if you have a lot of DLLs loaded!).</li>
</ul>

<h2>Do</h2>

<ul>
<li>Use multithreading to have things run <em>asynchronously</em> as much as you can. Speed is not the main idea of threading, but doing things in parallel (so even if they take longer alltogether, the sum of all is still less).</li>
<li>Use vertical sync to limit the frame rate. That is the only correct (and non-failing) way to do it. If the user overrides you in the display driver's control panel (""force off""), then so be it. After all it's his computer, not yours.</li>
<li>If you need to ""tick"" something at regular intervals, <em>use a timer</em>. Timers have the advantage of having a much better accuracy and reliability as compared to <code>sleep</code><sup>[2]</sup>. Also, a recurring timer accounts for time correctly (including time that passes in between) whereas sleeping for 16.6ms (or 16.6ms minus measured_time_elapsed) doesn't.  </li>
<li>Run physics simulations that involve numeric integration at a fixed time step (or your equations will explode!), interpolate graphics between steps (this <em>may</em> be an excuse for a separate per-component-thread, but it can also be done without).</li>
<li>Use <code>std::mutex</code> to have only one thread access a resource at a time (""mutually exclude""), and to comply with the weird semantics of <code>std::condition_variable</code>.</li>
<li>Avoid having threads compete for resources. Lock as little as necessary (but none less!) and hold locks only as long as absolutely necessary.</li>
<li>Do share read-only data between threads (no cache issues, and no locking necessary), but do not concurrently modify data (needs sync and kills the cache). That includes modifying data that is <em>nearby</em> a location someone else might read.</li>
<li>Use <code>std::condition_variable</code> to block another thread until some condition is true. The semantics of <code>std::condition_variable</code> with that extra mutex are admittedly pretty weird and twisted (mostly for historic reasons inherited from POSIX threads), but a condition variable is the correct primitive to use for what you want.<br>
In case you find <code>std::condition_variable</code> too weird to be comfortable with it, you can as well simply use a Windows event (slightly slower) instead or, if you are courageous, build your own simple event around NtKeyedEvents (involves scary low level stuff). As you use DirectX, you're already bound to Windows anyway, so loss of portability shouldn't a biggie.</li>
<li>Break work into reasonably-sized tasks that are run by a fixed-size worker thread pool (no more than one per core, not counting hyperthreaded cores). Let finishing tasks enqueue dependent tasks (free, automatic synchronization). Make tasks that have at least a few hundred non-trivial operations each (or one lenghty blocking operation like a disk read). Prefer cache-contiguous access.</li>
<li>Create all threads at program start.</li>
<li>Take advantage of asynchronous functions that the OS or the graphics API offers for better/additional parallelism, not only on the program level but also on the hardware (think PCIe transfers, CPU-GPU parallelism, disk DMA, etc.).</li>
<li>10,000 other things that I've forgotten to mention.</li>
</ul>

<p><hr />
[1] Yes, you can set the scheduler's rate down to 1ms, but this is frowned upon as it causes a lot more context switches, and consumes a lot more power (in a world where more and more devices are mobile devices). It also isn't a solution since it still does not make sleep any more reliable.<br>
[2] A timer will boost the thread's priority, which will allow it to interrupt another equal-priority thread mid-quantum and be scheduled first, which is a quasi-RT behavior. It is of course not true RT, but it comes very close. Waking from sleep merely means that the thread becomes ready to be scheduled at some time, whenever that may be.</p>
","80077"
"How to use modern OpenGL for 2D games?","10812","","<p>I've found a plethora of ""modern"" OpenGL (3.0+) tutorials for 3D, but I have found next to nothing when looking for information on how to use it for 2D game development. How can I get started using OpenGL for 2D gamedev?</p>

<p>Specifically, I'm interested in getting answers to the following topics:</p>

<ul>
<li>How should I set up my various matrices for orthographic projection?</li>
<li>Are shaders as heavily used in 2D applications as in 3D ones? If so, what is their purpose in the 2D setting?</li>
<li>How should I handle the massive number of textures obviously required for a 2D game?</li>
</ul>

<p>I apologize for the relatively broad question, but I've spent a long time searching and I've found very little useful information that applies to modern OpenGL.</p>
","<ul>
<li>How should I set-up my various matrices for Orthographic projection?</li>
</ul>

<p>Your goal is 2D, right? So you don't need any projection. Projection is the act of condensing a 3D world to a 2D plane. Set the shader so it defaults the Z coordinate of every vertex to <code>0.0</code> and you should be set.</p>

<p>You might use a scale matrix for the X and Y coordinates though. Scaling it so <code>-10.0</code> to <code>10.0</code> becomes <code>-1.0</code> to <code>1.0</code>. For references sake, the matrix to do that is:</p>

<pre><code>0.1   0.0   0.0
0.0   0.1   0.0
0.0   0.0   1.0
</code></pre>

<ul>
<li>Are shaders as heavily used in 2D applications as in 3D ones? If so, what is their purpose in the 2D setting?</li>
</ul>

<p>They can be. They can still be used for Per-Pixel lighting, giving some fake depth to objects. They can also be used for texture effects, water effects, image-generation... you could even use them to do physics calculations with a bit of trickery.</p>

<p>Another way to put that is: Everything they are used for in 3D. It's just applied differently, and isn't as well documented. Though the people playing 2D games probably aren't going to be getting on your case if you don't have lifelike effects, so they're not required either.</p>

<p>Though you're going to need to know the basics of shaders to render a sprite anyway.</p>

<ul>
<li>How should I handle the massive number of textures obviously required for a 2D game?</li>
</ul>

<p>Just as you do in 3D. Bunches of Texture Objects, PBO's, and a Texture Atlas or a few. Probably a few structures/classes, and headaches as-well. I think that would be called ""Asset Management"", or something similar.</p>

<ul>
<li>How can I get started with 2D gamedev?</li>
</ul>

<p>There are probably a few tutorials out there. Though, since the 3D version is more common, I would say to learn OpenGL for 3D and then apply what you learn to it's 2D counterpart. 3D and 2D are very similar, 2D just doesn't keep track of the Z coordinate.</p>
","62351"
"Pygame surface rotation, rect rotation or sprite rotation?","10808","","<p>i seem to have a conceptual misunderstanding of the surface and rect object in pygame.</p>

<p>I currently observe these objects this way:</p>

<p><strong>Surface</strong></p>

<ul>
<li>Just the loaded image</li>
</ul>

<p><strong>rect</strong></p>

<ul>
<li>the 'hard' representation of the ingame object (sprite). Used for simplifying object moment and collision detection</li>
</ul>

<p><strong>sprite</strong></p>

<ul>
<li>rect and surface grouped together</li>
</ul>

<p>What i want to do is rotate my sprite. The only available method i found for rotation is  <em>pygame.transform.rotate</em>.</p>

<p>How do i rotate the rectangle, or even better, the whole sprite?</p>

<p>Below is the image of how i visualize this problem.</p>

<p><img src=""https://i.stack.imgur.com/xKChb.gif"" alt=""enter image description here""></p>
","<p>Conceptually you've got it, just think of the rectangle as a helper for you to deal with position and collision detection of your image. To implement it you could use:</p>

<pre><code>  mySprite.image = pygame.transform.rotate(Surface, angle)
</code></pre>

<p>This will give you a rotated Surface (image), then you can use:</p>

<pre><code>mySprite.rect = mySprite.image.get_rect()
</code></pre>

<p>To give you your new rectangle; this won't be a rotated rectangle, it will be a orthogonal one that is big enough to fit your image in, i.e. its sides will remain vertical and horizontal. This should serve most purposes, and be satisfactory for most collision detection, if it's not some people shrink the rectangle a bit, doing it pixel perfect is a lot more complexed and cpu hungry and often not worth it. </p>

<p>NB:keep a copy of your original image (with no rotation) and do all your rotations from that one, otherwise there is potential for your rectangle to keep getting bigger and bigger.</p>
","44677"
"Displaying a particular sprite from spritesheet using Phaser","10801","","<p>I am trying to make a card game using Phaser, the HTML5 JS framework.  Because I'm a terrible artist and can't design my own, I'm using a free spritesheet of playing card images I found online.  The problem is, I can't seem to figure out how to display individual cards using Phaser. </p>

<p>In the previous framework I used, I was able to create individual smaller sprites from the larger sprite sheet that I used.  But I can't figure out how to do that in Phaser, if it's possible at all.  </p>

<p>So I looked into loading the image as a spritesheet, but it seems that spritesheets are used for animation only and you can't really display a particular 'frame' of the spritesheet (please correct me if I'm wrong).</p>

<p>I think what I need to do is load the image as a tilemap, however, the particular image that I'm using did not come with a json file specifying the layout (nor could I find one that did).  Being new to javascript I'm having trouble reading the Phaser source code to see how the json file should be formatted.  </p>

<p>So in summary, what's the best way to display an individual card of a spritesheet of playing cards in Phaser given that I don't have a json file specifying the map data? </p>
","<pre><code>var sprite = game.add.sprite(x, y, 'spritesheet_name');
sprite.frame = 0;
</code></pre>

<p>Spritesheets aren't limited to animations, that's just one way to use them. An animation is just a way to display different frames at different times. By manually setting the frame of a sprite, you can display a specific part of the spritesheet.</p>
","86869"
"Steps/tutorials to get into Android Game Development","10779","","<p>Hi i want to get into android game development,</p>

<p>I m interested in racing,fighting,target games(penalty shootout etc).</p>

<p>can anyone post links/urls for tutorial(videos etc).</p>

<p>I am familiar with java,javascript and oops concepts.</p>

<p>Thanks in advance.</p>
","<p>You can find some basic introduction to game development on Android <a href=""http://www.javacodegeeks.com/p/java-tutorials.html#Android%20Game%20Tutorials"" rel=""nofollow"">here</a></p>
","31419"
"Why are some games using some dithering pattern instead of traditional alpha for transparency?","10775","","<p>Recently, I have seen some 3D games (eg: <code>GTA IV</code>)  to use some kind of <a href=""http://en.wikipedia.org/wiki/Ordered_dithering"" rel=""noreferrer"">ordered dithering</a> to simulate transparency / alpha. </p>

<p>The polygons are not transparent as usual, but instead render a dithering texture that gradually switch from left to right to simulate transparency :</p>

<p><img src=""https://i.stack.imgur.com/sqHEB.png"" alt=""enter image description here""></p>

<p>The effect is not unpleasant but rather surprising to see at first (vs traditional alpha blending)</p>

<p>Except for the visual aesthetic effect it produce, <strong>is there any reason some games do this</strong> (better performance, saving bandwidth or any else i do not think about) ? </p>

<p>I have searched on the web but cannot found anything about this technique.</p>
","<p>This is a fairly common approach to transparency in games that use deferred shading.  Proper transparency doesn't work well at all with deferred shading, since only one surface's data (depth, normal vector, color, etc.) can be stored at each pixel, and proper transparency involves multiple surfaces overlapping at a pixel, each requiring independent lighting.</p>

<p>There are a few ways game engines can deal with this:</p>

<ul>
<li>Use forward shading (possibly with a reduced lighting model) for transparent surfaces, and deferred shading for the opaque surfaces.  The transparent surfaces have to be drawn in a separate pass with back-to-front sorting.</li>
<li>Use dithering, more commonly known as stippling or screen-door transparency, which works with deferred shading since it gives just one surface per pixel.  This works particularly well for LOD transitions, since they usually finish in a fixed amount of time, limiting how long the stippling is visible.  It doesn't work very well for, say, glass windows on a building.</li>
<li>It's also possible to use stippling but then apply a post-process blur that recombines the stippled pixels, giving an approximation of proper transparency.  Volition does this in Saints Row the Third (and perhaps some of their other games too), under the name of ""<a href=""http://www.slideshare.net/ozlael/inferred-lighting-4950586"" rel=""nofollow noreferrer"">inferred lighting</a>"".  This can look quite nice, but the post-process blur is expensive.</li>
<li>And of course, there are all the <a href=""https://gamedev.stackexchange.com/questions/43635/what-is-the-order-less-rendering-technique-that-allows-partial-transparency"">order-independent transparency</a> methods out there, although I don't know of any game that uses them.  They are just for tech demos so far.</li>
</ul>

<p>One can also use a combination of these approaches, e.g. forward shading for glass windows and stippling for LOD transitions.</p>

<p>It's also worth noting that some games use stippling for soft shadows.  This is a performance tradeoff; nicer shadows require more texture samples in the pixel shader, which takes longer, but you can get okay-looking results by using fewer samples and offsetting their positions randomly.  The random offset produces the stippling effect.</p>
","47847"
"Making an indie with friends: Legal considerations","10773","","<p>I am close to finishing a game I am making with 3 friends. 1 other coder, and 2 graphic designers. We agreed from the start to split revenue (40/40/10/10). </p>

<p>However we have no contract, and I know that I don't own the graphics/sounds in my game just because ""my friend made it"". What steps should we take to make sure that all graphics/sounds that were provided by my friends, are actually owned by me (the company).</p>

<p>We have a budget of $0 so hiring a lawyer is not an option, should we draft our own contract regarding the revenue share?</p>
","<p>Verbal agreements are usually considered valid contracts. But there is an old saying among lawyers:</p>

<blockquote>
  <p>A verbal contract isn’t worth the paper it’s written on.</p>
</blockquote>

<p>The problem with verbal contracts is that when push comes to shove and someone goes to court, you have a word-against-word situation where everyone can claim that you agreed on something different and nobody can prove what you really agreed on. That's why it is usually a good idea to write your agreement down.</p>

<p>A few of the things you need to agree on:</p>

<ul>
<li>How do you split revenue?</li>
<li>How do you split costs? And yes, if you want to promote your game, you will have to invest a bit of money sooner or later, even if it is just the subscription fee for the distribution platform.</li>
<li>Who owns what copyright? Keep in mind that you don't necessarily need to transfer copyright. You can agree to grant a non-exclusive perpetual license for using the work in the game.</li>
<li>Games are never finished, just abandoned. What if some of you want to invest more work into the game to make it even more successful, but others don't feel like contributing anymore? Does that affect your revenue splitting agreement in any way?</li>
<li>How do you make executive decisions about the game? Like where and when to release it, how to promote it, if you sell it to a publisher, etc.</li>
<li>What do you do if you decide to recruit more people for further development of the project? Do they also get a share (which would reduce the share of the others)? Or do they get paid a fixed amount? From whose shares does that payment come?</li>
<li>...and a couple hundred more things I am not thinking about right now...</li>
</ul>

<p>A lawyer's contribution is not required for a contract to be valid. But getting a lawyer to write that contract with you might still be a good idea. Legal writing requires a lot of attention to detail. It is easy to write something into a contract which doesn't actually mean what you all think it means. When you get into an argument and one of you decides to sue the others, the contract will be interpreted as written, not as what you thought it meant.</p>
","137377"
"Resource Managers - Are they any good?","10766","","<p>I've seen many a time in source code, things like this [well, this is more of a pseudo C++ idea of mine]  </p>

<pre><code>typedef shared_ptr&lt;Resource&gt; ResourcePtr;// for ease  
ResourcePtr sound1 = resourceManager.Get&lt;SoundResource&gt;(""boom.ogg"");  
sound1-&gt;Play();  
ResourcePtr sprite = resourceManager.Get&lt;Image&gt;(""sprite.png"");
</code></pre>

<p>I was just wondering how useful a class like this was, something that:</p>

<ul>
<li>Loaded media files</li>
<li>Stored them in memory</li>
<li>Did this at the start of a level - loading screen.</li>
<li>Cleaned up  </li>
</ul>

<p>Rather than having a system of:</p>

<ul>
<li>Resources are held by entities only, or loose.</li>
<li>Responsible for own load into memory.</li>
</ul>

<p>The first is a 'manager' as such; something I feel indicates it's wrong to use. However, it allows for something like a vector of resource names to be passed, rather than having to scramble around finding everything that needs to be loaded.</p>
","<p>A good resource manager is key to how well - and how flexible - your game 'engine' is going to be.</p>

<p>Not only does it solve a lot of problems with low level resource management, but it also helps to ensure that resources are loaded only once, and then reused if they are already loaded.</p>

<p>If the resource system is abstracted well, the underlying details can wary between file system, physfs storage, sql even...</p>

<p>You just request a resource, and it's given to you.</p>

<p>No need to worry about resource IDs and stuff like that.</p>

<p>Duplicate resource conflict handling, etc.</p>

<p>Let the resource manager sort that out.</p>

<p>Depending on how you design it - if C++ then make friends with your scenemanaging class(es) to ensure that ownership is properly handled.</p>

<p>Resource pool ?</p>

<p>No problem.</p>

<p>Forgetting to release resources?</p>

<p>No problem.</p>

<p>Same interface to resources no matter where they are: memory, disk, archive, network.</p>

<p>No problem.</p>

<p>Do you want streaming?</p>

<p>Threading?</p>

<p>Let your resource management hub take care of that.</p>

<p>And you can rest assured that it will inform you when the resources are ready to be used.</p>

<p>Ogre 3D has a very flexible resource management system, but I am sure there are others 'out there'.</p>
","2188"
"How to make a Realtime 3D Eulerian Fluid Simulation like ""From Dust"" in C#/Unity3D?","10758","","<p>So, for a game project I'm going to be working on I need to make a fully working 3D fluid simulator in Unity3D using C#, that can work in real time.</p>

<p>The only problem is, I've never done anything like fluid simulation. I've been doing tons of research on it, and I think a Eulerian based fluid simulator would fit my needs best (just like <a href=""http://www.youtube.com/watch?v=Jl54WZtm0QE"" rel=""nofollow"">this</a>).</p>

<p>Basically what I need is something that can react to changing terrain and move realistically.</p>

<p>The people that made that simulator have a research paper online, and I've read through it. I understand the basics, but I have no idea how I could get that in to C# or Unity3D. So I was wondering if any of you could help me, either by linking to other fluid-simulators where the code is open source, so I can pick it apart and change it to my needs, or by giving me tips on where to start/what I would need to do.</p>

<p>I've spent hours looking online for fluid simulators, but haven't found a single one programmed in C# as of yet, I have a program that can convert C++ to C#, but I don't understand C++ well enough to know where to put the scripts in Unity once they're converted.</p>

<p>Any help at all would be extremely appreciated, I'm really interested in teaching myself how to make this system, but I just have no clue where I should start, or what has already been done that I could build off of.</p>
","<p>Disclaimer: I haven't heard of a paper describing how <em>From Dust</em> was done, so this is entirely guess-work.</p>

<p>A few things I noticed about <em>From Dust</em>:</p>

<ul>
<li>Anything on the landscape is a fluid (notice what happens when you drop a lot of sand at once) - everything just has different viscosities.</li>
<li>You never get overhangs (at least on my computer) - this would be a cliff in terms of landscape.</li>
</ul>

<p>This means that it isn't a proper 3D fluid simulation (I doubt you could do a 3D one in realtime at that scale) - I did some research into the topic myself a while back and pretty-much every post/article/paper I came across dealt with accurate 3D fluid dynamics: you just don't need this.</p>

<p>If was to actually implement this I would do the following:</p>

<ul>
<li>A large amount of particles. These would have to be simulated on the GPU - in order and not simultaneously (so first landscape and then water). Each simulation would be aware of the result of the previous one, so in your first run landscape would be aware of nothing and water aware of landscape. During any subsequent run landscape would be aware of water and water would be aware of landscape. This means the landscape would erode one frame behind, <em>but the user won't notice it anyway.</em>
<ul>
<li>The simulation for each is quite simple: particles avoid each other and react to gravity. They can never fall below the particles of the previous simulation (e.g. water particles can't go under landscape). Their viscosity determines the springiness between particles of the same type.</li>
</ul></li>
<li>Create a rough surface with marching cubes (these would be relatively big).</li>
<li>Use a geometry shader and NURBS to smooth out the geometry on the GPU.</li>
<li>In both physics and mesh generation skip processing particles that are under the current surface.</li>
<li>If two particles settle (stop moving) close to each other combine them into one bigger one.</li>
</ul>

<p>You could also do a full 3D fluid dynamic simulation, but at a much lower resolution than the level and use marching cubes to generate the mesh; and then NURBS to smooth it out. Alternatively:</p>

<ul>
<li>Possibly have a quad-tree-like structure of simulations.</li>
<li>If one system becomes to complex create a split in the structure. Essentially you want something like a gamut alarm; but for fluid dynamics.</li>
<li>If the user interacts with an area create a split in the structure.</li>
<li>If one of the systems stabilizes merge it into it's parent.</li>
<li>You could also tie the simulation accuracy to the camera position - but it might result in odd scenarios. Alternatively if you start running out of bandwidth you could start merging the simulation furthest from the camera.</li>
</ul>

<p>This might get you close to what you want - but I never tackled it because I didn't have a concept to back the technology; and it's no small under-taking.</p>

<p>Finally, remember that once you get past the fluid simulation <em>From Dust</em> is a really simple game - I don't think they had much bandwidth left after implementing the technology.</p>
","21808"
"Java vs Javascript for Web-based games","10748","","<p>With all the recent interest in developing HTML5 apps and games, and I am curious why all the focus is on Javascript, and not on Java.</p>

<p>Minecraft is a great example of what can be accomplished in a browser, and it's written in Java, not JS. I doubt if it is even possible/practical to attempt such a complex project in JS.</p>

<p>Java is clearly a more powerful platform, and it probably runs significantly faster (this is just my guess, though). About the only drawback of Java I can think of is that it runs as a plugin, and with the trend towards plugin-free browsers (e.g. IE10 metro) Java applets may become obsolete in mobile environments. This has already happened with Flash on iOS.</p>

<p>What do you think? Is there a future in developing Java-based Web apps (especially for mobile devices)?</p>

<p>Thanks</p>
","<p>Java's main draw currently appears to be as native apps for Android devices. On the web, apps are done primarily using HTML5 and Javascript, while games are primarily for mobile on native (Java/Objective C) and for desktop it is Flash and to a lesser extent HTML5.</p>

<p>Since you limited yourself to only Java or Javascript, I'll say that you choose Javascript. While you might face some issues achieving performance, its future appears more optimistic than Java.</p>
","18536"
"How does one prevent homing missiles from orbiting their targets?","10727","","<p>I am developing a 2D space game with no friction, and I am finding it very easy to make a homing missile orbit its target. I am curious about anti-orbiting strategies.</p>

<p>A simple example is a homing missile that simply accelerates directly toward its target. If that target were to move perpendicular to the missile's trajectory then stop, the missile's acceleration toward the target would not be enough to overcome it's own velocity, and the missile could be driven into orbit around the target, as depicted:</p>

<p><img src=""https://i.stack.imgur.com/NfXJq.png"" alt=""Orbiting Problem""></p>

<ul>
<li>In frame 1, the missile is heading straight for its target, no problems.</li>
<li>In frame 2, the target has moved to a new position as demonstrated. The missile continues to accelerate directly toward the target (in red), while still moving toward where the target used to be (in black) due to its existing velocity.</li>
<li>In frame 3, the missile's velocity continues to carry the missile around the side of the target (black) while the acceleration vector tries desperately to pull the missile toward the target.</li>
<li>In frames 4 and beyond, the missile falls into a potentially stable orbit around the target and never reaches its goal. The black arrows indicate a velocity vector while the red lines indicate acceleration vectors at the same moment in time.</li>
</ul>

<p>Considering that there is no friction in space, there is nothing to slow the velocity of the missile down and collapse the orbit. A possible solution would be to aim ""behind"" the target, and this would cause the orbit to close, but how is this done from a programming point of view?</p>

<p>How do I make a homing missile reach its target?</p>
","<p>First of all, you should make all calculations about what acceleration to apply in the <em>missile's</em> frame of reference (that's where the missile is stationary and everything else moves around it, also often called ""object coordinates"" or ""local coordinates"" in game engines, though in our case we want the velocity to be exactly zero as well).</p>

<p>The idea then is not to aim for the target, but to aim for the place where the target will be at the estimated time of impact. So the general algorithm looks like this:</p>

<ol>
<li><p>Estimate how much time it will take for the missile to reach the target. If the target is flying directly at it (remember, the missile is <em>stationary</em>), it can be as simple as calculating <em>distance</em> / <em>speed</em>, in other cases it can be more complicated. If the target can try and evade you won't be able to make a perfect estimate anyway, so it's ok to not be very precise.</p></li>
<li><p>Assuming constant speed (1st degree estimate) or constant acceleration (2nd degree estimate) of the target, calculate where it will be at the estimated time above.</p></li>
<li><p>Calculate acceleration which will lead to the missile to be at roughly the same spot at the same time.</p></li>
<li><p>Re-project the acceleration back from the missile's frame of reference to the global one, use that.</p></li>
</ol>

<p>The important part here is to get the time estimate in the rough ballpark, and to not forget the missile's acceleration capabilities while doing so. For example, a better estimate for ""the target is straight ahead of us and flying in our direction"" would be to solve the equation ..</p>

<p><em>distance</em> = <em>speed</em> x <em>time</em> + 1/2 x <em>acceleration</em> x <em>time</em><sup>2</sup></p>

<p>... for <em>time</em> (use negative speed for objects flying straight <em>away</em> from the missile), with the solution you're looking for using the standard <a href=""http://en.wikipedia.org/wiki/Quadratic_equation#Quadratic_formula"">quadratic formula</a> being ...</p>

<p><em>time</em> = (√(<em>speed</em><sup>2</sup> + 2 x <em>acceleration</em> x <em>distance</em>) - <em>speed</em>) / <em>acceleration</em></p>

<p>Adding additional parameters - drag, for example - quickly turns this into differential equations with no algebraic solutions. <em>This</em> is why rocket science is so hard.</p>
","17315"
"Does `yield return false;` have special meaning in Unity3d C# scripts?","10692","","<p>In Unity, we have some special things for coroutines that are additional to normal C#.</p>

<p>for example, we can use</p>

<p><code>yield return WaitForSeconds(5.f);</code></p>

<p>to have a coroutine wait 5 seconds before continuing.</p>

<p>What do <code>yield return false;</code> and <code>yield return true;</code> do?</p>
","<blockquote>
  <p>The only possible yield values the scheduler understands are:</p>
  
  <ul>
  <li>Classes derived from <code>YieldInstruction</code> (<code>WaitForSeconds</code>, <code>WaitForEndOfFrame</code>, <code>WaitForFixedUpdate</code>, <code>AssetBundleCreateRequest</code>, <code>AssetBundleRequest</code> and Coroutine</li>
  <li>a <code>WWW</code> object</li>
  <li><strong>""any other value""</strong> which isn't one of the above.</li>
  </ul>
  
  <p>If <strong>""any other value""</strong> is yielded (which includes ""null"" a string value any other basic type such as int, <strong>bool</strong>, ... or a reference to an arbitrary object which isn't one of the above mentioned) the scheduler will <strong>""schedule"" the coroutine for the next frame</strong>.</p>
  
  <p><em>- <a href=""http://answers.unity3d.com/questions/636109/yieldinstructions-from-unmanaged-land-eg-waitforse.html#answer-container-636147"">Bunny83 answer: Prominent member on Unity Answers</a></em></p>
</blockquote>

<p>The <code>WaitForEndOfFrame</code> and others of the like, are just blank functions that tag the <a href=""http://docs.unity3d.com/ScriptReference/YieldInstruction.html""><code>YieldInstruction</code></a> in order to decide what to do in the engine.</p>

<p>The default case seems to be <a href=""http://docs.unity3d.com/ScriptReference/WaitForEndOfFrame.html""><code>WaitForEndOfFrame</code></a>. So if you <code>yield return</code> something that doesn't have a special meaning, such as a bool, it is the same as <a href=""http://docs.unity3d.com/ScriptReference/WaitForEndOfFrame.html""><code>WaitForEndOfFrame</code></a>.</p>

<p>There doesn't seem to be any official documentation on this behavior.</p>

<hr>

<h2>Update</h2>

<p><strong><a href=""https://gamedev.stackexchange.com/users/33377/rutter"">rutter</a></strong> commented about another special case: <code>yield return null</code></p>

<p>All of the Unity Coroutines including <code>yield return null</code>, run before the frame renders except for <code>WaitForEndOfFrame</code>. You can find <strong><a href=""https://gamedev.stackexchange.com/users/33377/rutter"">rutter</a></strong>'s <a href=""http://answers.unity3d.com/questions/755196/yield-return-null-vs-yield-return-waitforendoffram.html#answer-container-755208"">awesome answer over at Unity Answers</a> explaining this further (nice diagrams included).</p>
","81390"
"When would a mesh collider be better than primitive colliders","10645","","<p>I have been reading through the Unity Manual and have come across some interesting information about mesh colliders and primitive colliders. It got me wondering if using many primitive colliders would be better than using a mesh collider for say a character object?</p>

<p>I was also wondering if there was any information on exactly how inefficient a mesh collider is to say having 20 box or cylinder colliders on a character mesh. I am guessing that the number of polygons on the mesh would be a factor but it would be interesting to see some raw comparisons between how this efficiency scales per polygon (or per 100 polys or some unit of measurement)</p>
","<p>In my experience writing collision detection, mesh-based collision (triangles versus other triangles) are the most expensive form of collision in physics engines (PhysX, Havok). Unity uses PhysX internally, so this is no different. Because each computer and platform perform differently, exact numbers cannot be provided, but generally speaking the relative costs of collision detection of types are in the following order, from most expensive to least: triangle mesh, convex hull, box, capsule, sphere, plane, point. </p>

<p>Triangle meshes have the least-helpful characteristics for writing efficient collision detection. As a mesh, they don't guarantee convexivity, are not solid, and cannot be described implicitly through an equation. As a result, any detection is performed with each triangle individually.</p>

<p>To expand on triangle mesh collisions, and without direct knowledge of the source code, I would think Unity does collision detection against triangle mesh in the following way: a spatial data structure wraps the triangles. Likely a KD-tree, bounding volume hierarchy (BVH) or some other form of hierarchical structure. This accelerates queries between primitives and the mesh, yielding a list of candidate triangles for what is called narrow-phase collision algorithm. Then primitive-v-triangle tests are performed. For spheres, the basic sphere-v-triangle test calculates the distance of point from triangle testing if the distance is less than the radius of the sphere. More complicated primitives against the triangle use the GJK algorithm, or SAT algorithm against the triangle.</p>

<p>To address the high cost of triangle meshes, most games that require high fidelity collision detection with characters resort to using a combination of primitives to approximate the character - spheres, capsules or convex hulls bound to the joints of the skeleton hierarchy. The actual number of shapes used to represent the character are determined by requirements and the hardware the platform running on. </p>

<p>So to answer your question, I don't think there is always an objective answer to your question about 'exactly how inefficient a mesh collider is...'. But a handful of simple primitives is always faster then a deforming mesh geometry. </p>
","87372"
"Is there a sound library for C to generate sound samples from code?","10618","","<p>I'm working on an engine for a retro-style game in C.  I'm looking for a sound library that would produce chip sounds from code...I want to make my own simple chiptune tracker for the engine to create music.  Does such a thing exist?</p>

<p>I'd also be interested in a library to use .nsf files in my project.</p>

<p>I'm using Linux for development.</p>
","<p>Probably not a correct answer but <a href=""http://content.gpwiki.org/index.php/Libraries"" rel=""nofollow"">here is a library of various audio engines</a></p>

<p>(Scroll down to the second segment for audio libraries)</p>

<p>At least 9 out of 12 engines go with C.
Most of them also support tracker files. Which is not so different than nsf ( I assume these are NES music files ) files.</p>
","47011"
"HTML5 - check if font has loaded","10614","","<p>At present I load my font for my game in with <code>@font-face</code></p>

<p>For instance:</p>

<pre><code>@font-face {
    font-family: 'Orbitron';
    src: url('res/orbitron-medium.ttf');
}
</code></pre>

<p>and then reference it throughout my JS implementation as such:</p>

<pre><code>ctx.font = ""12pt Orbitron"";
</code></pre>

<p>where ctx is my 2d context from the canvas.</p>

<p>However, I notice a certain lag time while the font is downloaded to the user.  Is there a way I can use a default font until it is loaded in?</p>

<hr>

<p>Edit -</p>

<p>I'll expand the question, because I hadn't taken the first comment into account.  What would the proper method of handling this be in the case that a user has disabled custom fonts?</p>
","<p>I am not sure if it is possible to detect this, the browser will download the font when it see's the CSS. You could draw the text using a default font, then use something like <a href=""http://ajaxian.com/archives/javascriptcss-font-detector"" rel=""nofollow"">this</a> to detect if the font has loaded outside your canvas. If it is detected as having loaded, you could then refresh your canvas.</p>

<p>Edit; ""What would the proper method of handling this be in the case that a user has disabled custom fonts"" - You would have to let the default parent font remain present</p>

<p><strong>EDIT:</strong></p>

<p>OK, So after digging into this further (and playing alot with <a href=""http://jsfiddle.net/zMKge/"" rel=""nofollow"">this</a>), it would appear it is not as simple to handle this as first thought. However, after searching for a solution as if this were my own problem, I have located the following which is what I recommend using to detect if the browser supports font face. If the browser doesn't support font face, just set it to use a standard local font, otherwise the user would have to wait for the font to load, unfortunately any delay you may be experiencing is most likely down to file size and really isn't is something I can help you with, other than by advising you load the font at the start of your page, and assign it at the end of the page.</p>

<p><a href=""https://github.com/Modernizr/Modernizr/blob/master/modernizr.js"" rel=""nofollow"">detect HTML5 and CSS3 features</a> (search for tests['fontface'])</p>

<p>Also take a look at these:
<a href=""http://paulirish.com/2009/font-face-feature-detection/"" rel=""nofollow"">http://paulirish.com/2009/font-face-feature-detection/</a>
<a href=""http://news.ycombinator.com/item?id=1347011"" rel=""nofollow"">http://news.ycombinator.com/item?id=1347011</a></p>

<p>I hope you find this more useful.</p>

<p>Regards,Chris</p>
","7248"
"Teamviewer doesn't show my game screen","10595","","<p>I've been building a 3D engine from scratch using C# and I've tried to show the result to a friend of mine using Teamviewer. When my demo game starts he doesn't see it.
He can only see the last active program on my screen (for example visual studio from which I started the game)</p>

<p>The game engine launches a windows form at start, then directx binds to this form.
It's a fullscreen application with no windows forms borders etc.</p>

<p>Why doesn't teamviewer pick this up?</p>
","<p>Probably the same reason you can't use the Print key to capture the screen while running a fullscreen game: It's in exclusive mode, other programs can't access it (and will only grab the standard desktop you can't see while in the game).</p>

<p>Probably the easiest solution for this would be not using fullscreen mode. If you don't want window borders, remove those and essentially render in a borderless window filling the desktop. Just keep in mind that you won't be able to control refresh rate while being in this mode (and VSync might be dictated/forced by the window manager).</p>
","62884"
"How to Color.Lerp between multiple colors?","10594","","<p>I have found it rather difficult to find a solution to this in the Unity documents.</p>

<p><code>Color.Lerp(Color a, Color b, float t)</code> is a function that gradually changes a color according to a step t, giving it the final value of the Color b.</p>

<p>How do I Lerp between multiple colors one after another?</p>
","<p>let <strong>Arr</strong> be an array of Colour
let <strong>N</strong> be the number of colors in the array
let <strong>t</strong> be the 0..1 float value</p>

<pre><code>float scaledT = t* (float)(N-1);
Color prevC = Arr[(int)scaledT];
Color nextC = Arr[(int)(scaledT+1f)];
float newt = scaledT - (float)((int)scaledT); 
</code></pre>

<p>finaly you can use Lerp</p>

<pre><code>Color.Lerp(prevC, nextC, newT)
</code></pre>
","98750"
"Rotate object to always face camera","10588","","<p>I'm trying to make a TextMesh appear when ever an enemy prefab is hit.</p>

<p>I currently have this functionality working. However, the text doesn't face the direction the players camera is looking.</p>

<p>At the moment my OnCollisionEnter method contains the following line of code:</p>

<pre><code>GameObject _go = (GameObject)Instantiate(_hitPrefab, collision.gameObject.transform.position, Camera.mainCamera.transform.rotation);
</code></pre>

<p>This line happily creates my TextMesh whenever my enemy is hit. I know my issue has something to do with my rotation quaterion, but I have no idea what pass in so it faces my camera. As you can see, I tried setting it Quaterion.Idenitiy thinking it'll show the same way as the enemy it's associated to, but that doesn't work either.</p>

<p>Each time the textmesh appears, its back to front for the player and at a slight angle. </p>

<p>Could someone please help me in getting it so the score always faces the players camera no matter what way he is facing?</p>
","<p>You are simply copying the main camera's rotation in your code snippet, try this method:</p>

<pre><code>GameObject _go = (GameObject)Instantiate(_hitPrefab, 
        collision.gameObject.transform.position, Quaternion.identity);
_go.transform.LookAt(Camera.main.transform);
</code></pre>

<p><a href=""http://docs.unity3d.com/Documentation/ScriptReference/Transform.LookAt.html"" rel=""nofollow"">http://docs.unity3d.com/Documentation/ScriptReference/Transform.LookAt.html</a></p>

<p>You should also have a look into Quaternion.LookRotation.</p>

<p><a href=""http://docs.unity3d.com/Documentation/ScriptReference/Quaternion.LookRotation.html"" rel=""nofollow"">http://docs.unity3d.com/Documentation/ScriptReference/Quaternion.LookRotation.html</a></p>

<p>Edit:</p>

<p>This is a very useful community script for camera facing, the results may be slightly better: <a href=""http://wiki.unity3d.com/index.php?title=CameraFacingBillboard"" rel=""nofollow"">http://wiki.unity3d.com/index.php?title=CameraFacingBillboard</a></p>
","51020"
"SIMD C++ library","10587","","<p>In the past, I've used Visual Studio with the DirectX XNA math library. Now, I'm using the GNU compiler collection. Can anyone advise a SIMD math library with a good documentation?</p>
","<p>You can also do it ""yourself"" using the <strong>SSE (Streaming SIMD Extensions) instructions</strong> and the <strong>intrinsics</strong> ( *mmintrin.h files ) of your compiler/proc.</p>

<hr>

<p><strong>Tutorials</strong></p>

<p>Here is an example of how to use SSE instructions with assembly:<br>
<a href=""http://neilkemp.us/src/sse_tutorial/sse_tutorial.html"" rel=""nofollow noreferrer"">http://neilkemp.us/src/sse_tutorial/sse_tutorial.html</a></p>

<p>And here is a tutorial on how to use SSE instructions with intrinsics:<br>
<a href=""http://www.codeproject.com/KB/recipes/sseintro.aspx"" rel=""nofollow noreferrer"">http://www.codeproject.com/KB/recipes/sseintro.aspx</a></p>

<p>A practical guide to using SSE SIMD with C++:<br>
<a href=""http://sci.tuomastonteri.fi/programming/sse/printable"" rel=""nofollow noreferrer"">http://sci.tuomastonteri.fi/programming/sse/printable</a></p>

<hr>

<p><strong>Useful informations</strong></p>

<p>Intel C++ Intrinsics reference (useful to get the list of instructions):<br>
<a href=""http://cache-www.intel.com/cd/00/00/34/76/347603_347603.pdf"" rel=""nofollow noreferrer"">http://cache-www.intel.com/cd/00/00/34/76/347603_347603.pdf</a></p>

<p>SSE &amp; SSE2 Intrinsic support for the enhanced instruction sets supported by Intel and AMD processors (useful to all kinds of informations relative to SSE and SIMD):<br>
<a href=""http://msdn.microsoft.com/en-us/library/y0dh78ez%28v=vs.71%29.aspx"" rel=""nofollow noreferrer"">http://msdn.microsoft.com/en-us/library/y0dh78ez%28v=vs.71%29.aspx</a></p>

<p>Overall instructions list and informations about SSE, SSE2, SSE3, SSSE3, SSE4, 3DNow etc (different versions of SSE for different proc architecture):<br>
<a href=""http://softpixel.com/~cwright/programming/simd/sse.php"" rel=""nofollow noreferrer"">http://softpixel.com/~cwright/programming/simd/sse.php</a></p>

<hr>

<p>If you prefer a <strong>linear algebra framework</strong> I eared about Eigen: <br>
<a href=""http://eigen.tuxfamily.org/"" rel=""nofollow noreferrer"">http://eigen.tuxfamily.org/</a><br>
<a href=""http://eigen.tuxfamily.org/index.php?title=FAQ#Vectorization"" rel=""nofollow noreferrer"">http://eigen.tuxfamily.org/index.php?title=FAQ#Vectorization</a> (about SIMD support)</p>

<p>And finally if you need more answers about C++ SIMD Frameworks, here is a <strong>StackOverflow link</strong>. (C++ SSE SIMD framework) :<br>
<a href=""https://stackoverflow.com/questions/4953121/c-sse-simd-framework"">https://stackoverflow.com/questions/4953121/c-sse-simd-framework</a></p>
","12606"
"How do I structure a 2D platform level?","10581","","<p>I'm doing a 2D platformer but I don't know how they are usually built.</p>

<p>The approach I'm looking at is making it tilebased, with ground tiles on bottom row, then platforms on some places in ""mid-air"" within the array.</p>

<p>Then some physics to add gravity to pull the player down if airborn, and just scroll the map horizontally and check for collisions.</p>

<p>Am I on the right track? Thank you.</p>
","<p>I'm going to share a link with you that someone else had shared with me:</p>

<p><a href=""http://higherorderfun.com/blog/2012/05/20/the-guide-to-implementing-2d-platformers/"">http://higherorderfun.com/blog/2012/05/20/the-guide-to-implementing-2d-platformers/</a></p>

<p>This page covers several approaches as to how one might implement 2d platformers with both basic and some more advanced mechanics. It doesn't give you straight up code but it does a fantastic job at explaining the techniques so that you should be able to code it without too much trouble.</p>
","31182"
"Fastest way to render lines with AA, varying thickness in DirectX","10577","","<p>So I'm doing some DirectX development, using SharpDX under .NET to be exact (but DirectX/C++ API solutions are applicable). I'm looking for the fastest way to render lines in an orthogonal projection (e.g. simulating 2D line drawing for scientific apps) using DirectX. </p>

<p>A screenshot of the sorts of plots I'm trying to render follows:
<img src=""https://i.stack.imgur.com/cTfVK.png"" alt=""enter image description here""></p>

<p>It's not uncommon for these sorts of plots to have lines with millions of segments, of variable thickness, with or without antialiasing per-line (or full screen AA on/off). I need to update the vertices for the lines very frequently (e.g. 20 times/second) and offload as much to the GPU as possible. </p>

<p>So far I have tried:</p>

<ol>
<li>Software rendering, e.g. GDI+ actually not bad performance but obviously is heavy on the CPU</li>
<li>Direct2D API - slower than GDI, especially with Antialiasing on</li>
<li>Direct3D10 using <a href=""http://www.codeproject.com/Articles/199525/Drawing-nearly-perfect-2D-line-segments-in-OpenGL"" rel=""nofollow noreferrer"">this method to emulate AA using vertex colours</a> and tessellation on the CPU side. Also slow (I profiled it and 80% of time is spent computing vertex positions)</li>
</ol>

<p>For the 3rd method I'm using Vertex Buffers to send a triangle strip to the GPU and updating every 200ms with new vertices. I'm getting a refresh rate of around 5FPS for 100,000 line segments. I need millions ideally!</p>

<p>Now I'm thinking that the fastest way would be to do the tessellation on the GPU, e.g. in a Geometry Shader. I could send the vertices as a line-list or pack in a texture and unpack in a Geometry Shader to create the quads. Or, just send raw points to a pixel shader and implement Bresenham Line drawing entirely in a pixel shader. My HLSL is rusty,  shader model 2 from 2006 so I don't know about the crazy stuff modern GPUs can do. </p>

<p>So the question is: 
 - has anyone done this before, and do you have any suggestions to try? 
 - Do you have any suggestions to improve performance with rapidly updating geometry (e.g. new vertex list every 20ms)? </p>

<p><strong>UPDATE 21st Jan</strong></p>

<p>I have since implemented method (3) above using Geometry shaders using LineStrip and Dynamic Vertex Buffers. Now I'm getting 100FPS at 100k points and 10FPS at 1,000,000 points. This is a huge improvement but now I'm fill-rate and compute limited, so I got thinking about other techniques/ideas. </p>

<ul>
<li>What about Hardware Instancing of a Line Segment geometry? </li>
<li>What about Sprite Batch? </li>
<li>What about other (Pixel shader) oriented methods?</li>
<li>Can I efficiently cull on the GPU or CPU?</li>
</ul>

<p>Your comments &amp; suggestions much appreciated!</p>
","<p>If you are going to render <code>Y = f(X)</code> graphs only, then I suggest trying the following method.</p>

<p>The curve data is passed as <strong>texture data</strong>, making it persistent, and allowing for partial updates through <code>glTexSubImage2D</code> for instance. If you need scrolling you could even implement a circular buffer and only update a few values per frame. Each curve is rendered as a <strong>fullscreen quad</strong> and all the work is done by the pixel shader.</p>

<p>The one-component texture contents could look like this:</p>

<pre><code>+----+----+----+----+
| 12 | 10 |  5 | .. | values for curve #1
+----+----+----+----+
| 55 | 83 | 87 | .. | values for curve #2
+----+----+----+----+
</code></pre>

<p>The work of the pixel shader is as follows:</p>

<ul>
<li>find the X coordinate of the current fragment in the dataset space</li>
<li>take eg. the 4 closest data points that have data; for instance if the X value is <code>41.3</code> it would choose <code>40</code>, <code>41</code>, <code>42</code> and <code>43</code>.</li>
<li>query the texture for the 4 Y values (make sure the sampler does no interpolation of any kind)</li>
<li>convert the <code>X,Y</code> pairs to screen space</li>
<li>compute the distance from current fragment to each of the <strong>three segments</strong> and <strong>four points</strong></li>
<li>use the distance as an alpha value for the current fragment</li>
</ul>

<p>You may wish to substitute 4 with larger values depending on the potential zoom level.</p>

<p>I have written a very quick and dirty <a href=""http://lol.zoy.org/browser/trunk/tutorial/04_texture.lolfx?rev=2190"" rel=""nofollow noreferrer"">GLSL shader implementing this feature</a>. I may add the HLSL version later, but you should be able to convert it without too much effort. The result can be seen below, with different line sizes and data densities:</p>

<p><img src=""https://i.stack.imgur.com/DvIJT.png"" alt=""curves""></p>

<p>One clear advantage is that the amount of data transferred is very low, and the number of drawcalls is only one.</p>
","46582"
"OnCollisionEnter2D not being called","10570","","<p>I'm fairly new to the world of Unity, and am adding collision detection for the first time through RigidBody2D (as this game is 2D). First of all, here is some relevant information:</p>

<ul>
<li><strong>Unity Version:</strong> 4.2.5f</li>
<li><strong>Operating System:</strong> Windows 8.1 Update 1</li>
</ul>

<h1>The Problem</h1>

<p>I have two objects that could collide, let's call one <code>Bullet</code> and one <code>Enemy</code>. Both <code>Bullet</code> and <code>Enemy</code> have <code>RigidBody2D</code> components attached to them, as well as the following method in an attached script:</p>

<pre><code>void OnCollisionEnter2D(Collision2D collision){
    print(""Hit!"");
}
</code></pre>

<p>However, nothing is printed to the console (I have checked that <code>print</code> works in other situations).</p>

<h1>The Question</h1>

<p>What is going wrong here? I must be missing something simple. I have checked that Physics 2D has collisions enabled between layers, I have tried the 3D equivalent to this and still no joy.</p>

<h1>Additional Info</h1>

<p><img src=""https://i.stack.imgur.com/kyU1l.png"" alt=""Enemy""></p>

<p><img src=""https://i.stack.imgur.com/OuDvF.png"" alt=""Bullet""></p>
","<p>You need to add a <code>BoxCollider2D</code> component to your <code>GameObject</code>s.</p>

<p><a href=""http://docs.unity3d.com/ScriptReference/BoxCollider2D.html"" rel=""nofollow"">http://docs.unity3d.com/ScriptReference/BoxCollider2D.html</a></p>

<p>From the <a href=""http://docs.unity3d.com/ScriptReference/Collider2D.OnCollisionEnter2D.html"" rel=""nofollow"">Unity docs</a> for <code>OnCollisionEnter2D</code></p>

<blockquote>
  <p>Sent when an incoming collider makes contact with this object's
  collider</p>
</blockquote>

<p>A <code>Rigidbody2D</code> just tells a GameObject how to interact with the physics engine. It doesn't provide a collider for collision. </p>

<p>From the <a href=""http://docs.unity3d.com/ScriptReference/Rigidbody2D.html"" rel=""nofollow"">Unity docs</a> for <code>RigidBody2D</code></p>

<blockquote>
  <p>By adding the appropriate collider component, the sprite will also
  respond to collisions with other sprites.</p>
</blockquote>
","80861"
"How to capture the screen in DirectX 9 to a raw bitmap in memory without using D3DXSaveSurfaceToFile","10559","","<p>I know that in OpenGL I can do something like this</p>

<pre><code>glReadBuffer( GL_FRONT );
glReadPixels( 0, 0, _width, _height, GL_RGB, GL_UNSIGNED_BYTE, _buffer ); 
</code></pre>

<p>And its pretty fast, I get the raw bitmap in _buffer.
When I try to do this in DirectX. Assuming that I have a D3DDevice object I can do something like this</p>

<pre><code>if (SUCCEEDED(D3DDevice-&gt;GetBackBuffer(0, 0, D3DBACKBUFFER_TYPE_MONO, &amp;pBackbuffer))) {
   HResult hr = D3DXSaveSurfaceToFileA(filename, D3DXIFF_BMP, pBackbuffer, NULL, NULL); 
</code></pre>

<p>But D3DXSaveSurfaceToFile is pretty slow, and I don't need to write the capture to disk anyway, so I was wondering if there was a faster way to do this.</p>

<p>EDIT: I am targeting only DirectX applications. Actually DX9 apps. I am doing this through a hook to Present. (I am using Detours if that is relevant), and I am doing this for every frame. I don't need (or want) a particular bitmap format like BMP PNG JPEG etc, and a colorspace of RGB24 is OK. Getting it as YUV480p would be better but definitely not necessary. Thanks everyone for the very helpful answers</p>
","<p>The way I do this is as follows.</p>

<p><strong>IDirect3DDevice9::GetBackBuffer</strong>:
Get access to the IDirect3DSurface9 representing the back buffer, same as you've currently got.  Don't forget to Release this surface when done as this call will increment the reference count!</p>

<p><strong>IDirect3DSurface::GetDesc</strong>:
Get the description of the back buffer surface, which will give you it's width, height and format.</p>

<p><strong>IDirect3DDevice9::CreateOffscreenPlainSurface</strong>:
Create a new surface object in D3DPOOL_SCRATCH; you commonly want to use the same width, height and format (but you don't actually have to with this method).  Again, Release when done.  If you're doing this operation every frame (in which case you're better off looking at alternatives such as a shader-based approach to what you're trying to do) you could just create the offscreen plain surface once at startup and reuse it, instead of creating it every frame.</p>

<p><strong>D3DXLoadSurfaceFromSurface</strong>:
Copy from the back buffer surface to the offsceen plain surface.  This will do a resize and format conversion automatically for you.  Alternatively, if you don't want to or need to resize or change the format you could use <strong>IDirect3DDevice9::GetRenderTargetData</strong>, but if so then create the offscreen plain surface in D3DPOOL_SYSTEMMEM instead.</p>

<p><strong>IDirect3DSurface9::LockRect</strong>:
Get access to the data in the offscreen plain surface and have your own evil way with it; UnlockRect when done.</p>

<p>This looks like a lot more code but you'll find that it's just as fast as glReadPixels, and can even be faster if you don't need to do a format conversion (which glReadPixels using GL_RGB almost certainly does).</p>

<p>Edit to add: some (rought 'n' ready) helper functions I also have which may be useful for using this method for screenshots:</p>

<pre><code>// assumes pitch is measured in 32-bit texels, not bytes; use locked_rect.Pitch &gt;&gt; 2
void CollapseRowPitch (unsigned *data, int width, int height, int pitch)
{
    if (width != pitch)
    {
        unsigned *out = data;

        // as a minor optimization we can skip the first row
        // since out and data point to the same this is OK
        out += width;
        data += pitch;

        for (int h = 1; h &lt; height; h++)
        {
            for (int w = 0; w &lt; width; w++)
                out[w] = data[w];

            out += width;
            data += pitch;
        }
    }
}


void Compress32To24 (byte *data, int width, int height)
{
    byte *out = data;

    for (int h = 0; h &lt; height; h++)
    {
        for (int w = 0; w &lt; width; w++, data += 4, out += 3)
        {
            out[0] = data[0];
            out[1] = data[1];
            out[2] = data[2];
        }
    }
}

// bpp is bits, not bytes
void WriteDataToTGA (char *name, void *data, int width, int height, int bpp)
{
    if ((bpp == 24 || bpp == 8) &amp;&amp; name &amp;&amp; data &amp;&amp; width &gt; 0 &amp;&amp; height &gt; 0)
    {
        FILE *f = fopen (name, ""wb"");

        if (f)
        {
            byte header[18];

            memset (header, 0, 18);

            header[2] = 2;
            header[12] = width &amp; 255;
            header[13] = width &gt;&gt; 8;
            header[14] = height &amp; 255;
            header[15] = height &gt;&gt; 8;
            header[16] = bpp;
            header[17] = 0x20;

            fwrite (header, 18, 1, f);
            fwrite (data, (width * height * bpp) &gt;&gt; 3, 1, f);

            fclose (f);
        }
    }
}
</code></pre>
","41973"
"How many threads should an Android game use?","10541","","<p>At minimum, an OpenGL Android game has a UI thread and a Renderer thread created by <code>GLSurfaceView</code>.  <code>Renderer.onDrawFrame()</code> should be doing a minimum of work to get the higest FPS.  The physics, AI, etc. don't need to run every frame, so we can put those in another thread.  Now we have:</p>

<ol>
<li>Renderer thread - Update animations and draw polys</li>
<li>Game thread - Logic &amp; periodic physics, AI, etc. updates</li>
<li>UI thread - Android UI interaction only</li>
</ol>

<p>Since you don't ever want to block the UI thread, I run one more thread for the game logic.  Maybe that's not necessary though?  Is there ever a reason to run game logic in the renderer thread?</p>
","<p>Google's Chris Pruett talks about this issue in his <a href=""http://replicaisland.blogspot.com/2009/10/rendering-with-two-threads.html"">Replica Island blog</a>. Because eglSwapBuffers() is a blocking call in the GLSurfaceView thread, having game logic code in another thread allows it to run while the swap buffers call is blocking. This is important if your game is complex and you want to achieve 60 frames per second. </p>

<p>You can download the <a href=""http://code.google.com/p/replicaisland/"">source code</a> for Replica Island and see how they did it. I've implemented something similar for my game (with the three threads you talked about) and it works great.</p>
","148"
"Basics of drawing in 2d with OpenGL 3 shaders","10537","","<p>I am new to OpenGL 3 and graphics programming, and want to create some basic 2d graphics.  I have the following scenario of how I might go about drawing a basic (but general) 2d rectangle.  I'm not sure if this is the correct way to think about it, or, if it is, how to implement it.</p>

<p>In my head, here's how I imagine doing it:</p>

<ol>
<li><code>t = make_rectangle(width, height)</code>
<ul>
<li>build general VBO, centered at 0, 0</li>
</ul></li>
<li>optionally: <code>t.set_scale(2)</code></li>
<li>optionally: <code>t.set_angle(30)</code> </li>
<li><code>t.draw_at(x, y)</code>
<ul>
<li>calculates some sort of scale/rotate/translate matrix (or matrices), passes the VBO and the matrix to a shader program</li>
</ul></li>
<li>Something happens to clip the world to the view visible on screen.</li>
</ol>

<p>I'm really unclear on how 4 and 5 will work.  The main problem is that all the tutorials I find either: use fixed function pipeline, are for 3d, or are unclear how to do something this ""simple"".</p>

<p>Can someone provide me with either a better way to think of / do this, or some concrete code detailing performing the transformations in a shader and constructing and passing the data required for this shader transformation?</p>
","<p>The basics of drawing are really not much different than with 3D.  You need a set of vertices, a transformation matrix, and material properties.  For a sprite-based game, the vertices will always be a simple quad, and the material will usually just be a texture (though there are often other properties, e.g. to make sprites blink different colors when an enemy takes damage, or the like).</p>

<p>In this case, you can create a single VBO for all sprites, and reuse it.</p>

<p>If you have complex shapes, you're going to want to use a batching approach.  Push all your pre-transformed vertices into a single large VBO and render them all in one go.  Doing a separate GL draw call for each object is slow.</p>

<p>The transformation matrix at its simplest is a 3x3 matrix representing the homogeneous transformation.  You have your translate (location), rotation, and scale.  The matrix is composed by concatenating (multiplying) the matrices together.  GL prefers column-major column matrices (but you are free to use any other representation, if you wish, but I won't get into how).</p>

<p>Your 2D transformation then is the combination of the Rotation, Scale, and Translation matrices:</p>

<pre><code>|1, 0, tx|   |cos(theta), -sin(theta), 0|   |sx, 0,  0|
|0, 1, ty| * |sin(theta), cos(theta),  9| * |0,  sy, 0|
|0, 0, 1 |   |0,          0,           1|   |0,  0,  1|
</code></pre>

<p>The matrix can either be applied to your vertices on the CPU before uploading, if you're pushing all your vertices into a single VBO.</p>

<p>If you're using raw sprites, instancing can be a lot faster.  In this case, you will use a single draw call to render a number of copies of your quad VBO.  To access the matrices, they must be stored in either a texture or what's called a Texture Buffer Object.  The latter is better.  The idea there is that you upload all your transformation matrices for your objects into a VBO, which is bound to a Texture, which is then bound to the shader.  The vertex shader uses the special variable gl_InstanceID and the texelFetch() command to read the matrices out of the Buffer Texture, and then you apply it to the vertices.</p>

<p>You can read more about how to use Buffer Texture Objects here:</p>

<p><a href=""http://www.opengl.org/wiki/Buffer_Texture"" rel=""nofollow"">http://www.opengl.org/wiki/Buffer_Texture</a></p>

<p>You can read more about instancing here:</p>

<p><a href=""http://www.opengl.org/wiki/Vertex_Specification#Instancing"" rel=""nofollow"">http://www.opengl.org/wiki/Vertex_Specification#Instancing</a></p>

<p>With the instancing approach, you also want to pack in the UV coordinates, and you'll need to use a texture atlas for rendering.  I recommend using 2D texture arrays for your atlases, assuming all your sprites have the same width and height.  It has a lot of advantages over a traditional texture atlas.  The traditional kind works just fine in many cases, if that's what you'd prefer.</p>

<p>The end result is that you'll only have a single draw call for every ""material"" (e.g. texture), which with atlasing might well be hundreds or thousands of individual objects.</p>

<p>A rough pseudo-code overview then:</p>

<pre><code>init():
  vbo_quad = createVBO()
  pushQuadVerts(vbo_quad)

  tex_atlas = createTextureAtlas()

  vbo_objects = createVBO()
  tex_objects = createTextureBuffer(vbo_objects)

  shader = loadShaders(""vertex.glsl"", ""fragment.glsl"")

update():
  for each object:
    calculateObjectTransform()
    pushTransformOntoVBO(vbo_objects)

draw():
  bindVBO(vbo_quad)
  bindTexture(UNIT0, tex_atlas)
  bindTexture(UNIT1, tex_objects)

  drawArraysInstanced(GL_QUADS, 0, 4, number_of_objects)
</code></pre>

<p>As a final hint, if you're going the instanced route, you might find it a bit quicker and easier to avoid calculating the entire transformation matrix on the CPU, and instead calculate it on the GPU.  You can pass in the rotation, scale, and translation.  If you do the math, you can take those inputs and calculate the matrix directly.  Then instead of needing to eat up 9 floats in memory bandwidth to the GPU and doing a lot of work on the serial CPU, you can pass in 5 floats (4 if you only have uniform scale) and do the work on the parallel GPU.</p>

<p>The math comes out something like this (off the top of my head, so double check):</p>

<pre><code>|sx * cos(theta), -sy * sin(theta), tx|
|sx * sin(theta),  sy * cos(theta), ty|
|0,                0,               1 |
</code></pre>

<p>Nice and easy.</p>
","25745"
"3D Camera Rotation","10528","","<p>Please, forgive me, but I need help and I've been stuck on this for a few weeks now, I'm making no progress and everywhere I go and I see a different answer, everything I try doesn't work. I've had enough tips and advice, now I really just need someone to give me the answer for me to work backwards from because I can't understand this.</p>

<p>What has made this subject most confusing is the way everyone uses a different set of conventions or rules, and their answers are based on their own conventions without defining what they are.</p>

<p>So here is the set of conventions I've formed based on what seems to be most common and logical:</p>

<ol>
<li>Right Hand Rule for axis.</li>
<li>Positive Y is up, Positive Z is towards the viewer, Positive X is to the right.</li>
<li>Row Major matrixes, transposed when sent to shaders.</li>
<li><ul>
<li>Pitch:     rotation about the X axis</li>
<li>Yaw: rotation about the y axis</li>
<li>Roll:    rotation about the z axis</li>
</ul></li>
<li>Rotation order: Roll, Pitch, Yaw (is this correct? can someone check me on this?)</li>
<li>Positive rotation values, looking down from positive end of an axis, results in clockwise rotation.</li>
<li>Default direction for 0 rotation across all axis is a vector pointing down to negative Y.</li>
</ol>

<p>.. given those conventions (by all means correct me if they are wrong!), how does one:</p>

<ul>
<li>Write a LookAt function? (lookAt(vector position, vector eyefocus, vector up))</li>
<li>Calculate a rotation matrix. (rotation(x, y, z)) </li>
</ul>

<p>I've tried answering these two questions myself at least over the past 3 weeks, I've re-written my LookAt &amp; Rotation Matrix function at least 30 times, I've tested dozens of methods and read through material I've seen on hundreds of websites and read many answered questions, copied other people's code, and nothing I've made so far has worked, everything has produced the wrong result. Some of which have produced some hilariously bizarre outputs not even close to correct rotation.</p>

<p>I've been working on this every night with the exception of last night because I was getting so frustrated with the repeated failure that I had to stop and take a break.</p>

<p>Please, just show me what the correct method is so I can work backwards from that and figure out how it works, I'm just not getting the correct answer and this is driving me a little crazy!</p>

<p>I'm writing in Java but I'll take code written in any language, most of my 3D rendering code is actually working quite brilliantly, it's just the maths I can't understand.</p>

<p>UPDATE: SOLVED</p>

<p>Thankyou for your help! I now have a working LookAt function that I actually understand and I couldn't be happier (if anyone would like to see it by all means ask).</p>

<p>I did try again at creating a rotation matrix based off pitch/yaw/roll variables and it again seemed to fail, but I've decided to dump attempting to use euler angles for the freelook camera as it seems to be ill-suited for the role, instead I'm going to create a quaternion class, might have better luck going down that path, otherwise I'll resort to using the pitch/yaw as spherical coordinates and rely on the new working LookAt function for rotation.</p>

<p>If anyone else is facing a similar problem and wants to ask me questions, feel free to.</p>

<p>At least I'm not stuck anymore, thanks for the help!</p>
","<p>What you are looking for can be found in this very good explanation: <a href=""http://www.songho.ca/opengl/gl_transform.html"" rel=""nofollow noreferrer"">http://www.songho.ca/opengl/gl_transform.html</a></p>

<p>But since I found it sort of confusing without hand holding I will try to explain it here.  </p>

<p>At this point you need to consider 5 coordinate systems and how they relate to each other. These are the window coordinates, the normalized device coordinates, the eye coordinates, the world coordinates and the object coordinates.</p>

<p>The window coordinates can be seen as the ""physical"" pixels on your screen. They are the coordinates that the windowing system refers to and if you operate in your monitors native resolution, these are actually individual pixels. The window coordinate system are 2D integers and is relative to your window. Here the x+ is left and y+ is down with the origin at the top left corner. You encounter these when you for example call <code>glViewport</code>. </p>

<p>The second set are the normalized device coordinates. These refer to the space setup by the active view port. The visible area of the view port goes from -1 to +1 and thus has
the origin in the center. The x+ is left and the y+ is up. You also have the z+ is ""out"" of the scene. This is what you describe in 1.</p>

<p>You have no control how you get from the normalized device coordinates to the window coordinates, this is done implicitly for you. The only control you have is through <code>glViewport</code> or similar. </p>

<p>When working with openGL, your final result will always be in normalized device coordinates. As a result you need to worry how to get your scene rendered in these. If you set the projection and model-view matrix to the identity matrix you can directly draw in these coordinates. This is for example done when applying full screen effects.</p>

<p>The next is the eye coordinates. This is the world as seen from the camera. As a result the origin is in the camera and the same axis aliments like the device coordinates apply. </p>

<p>To get from the eye coordinates to the device coordinates you build the projection matrix. The simplest is the orthographic projection that just scales the values appropriately. The perspective projection is more complicated and involves simulation perspective.</p>

<p>Finally you have the world coordinate system. This is the coordinate system in which your world is defined and your camera is part of this world. Here it is important to note that <strong>the axis orientations is just as you define them</strong>. If you prefer z+ as up, that is totally fine.</p>

<p>To get from world coordinates to eye coordinates you define the view matrix. This can be done with something like <code>lookAt</code>. What this matrix does is ""move"" the world so that the camera is at the origin and looking down the z- axis. </p>

<p>To compute the view matrix is surprisingly simple, you need to unto the camera's transformation. You basically need to formulate the following matrix:</p>

<p>$$ 
M = 
\begin{matrix} 
x[1] &amp; y[1] &amp; z[1] &amp; -p[1] \\ 
x[2] &amp; y[2] &amp; z[2] &amp; -p[2] \\ 
x[3] &amp; y[3] &amp; z[3] &amp; -p[3] \\ 
0 &amp; 0 &amp; 0 &amp; 1 
\end{matrix} 
$$</p>

<p>The x, y and z vectors can be directly takes from the camera. In the case from look at you would derive them from the target, eye(center) and up values. Like so:</p>

<p>$$ 
z = normalize(eye - target) \\
x = normalize(up \times z) \\
y = z \cdot x
$$</p>

<p>But if you happen to have these values just lying around you can just take them as they are. </p>

<p>Getting p is a bit more tricky. It is not the position in world coordinates but the position in camera coordinates. A simple workaround here is to initialize two matrixes, one with only x, y and z and a second one with -eye and multiply them together. The result is the view matrix.</p>

<p>For how this may look in code:</p>

<pre><code>mat4 lookat(vec3 eye, vec3 target, vec3 up)
{
    vec3 zaxis = normalize(eye - target);    
    vec3 xaxis = normalize(cross(up, zaxis));
    vec3 yaxis = cross(zaxis, xaxis);     

    mat4 orientation(
       xaxis[0], yaxis[0], zaxis[0], 0,
       xaxis[1], yaxis[1], zaxis[1], 0,
       xaxis[2], yaxis[2], zaxis[2], 0,
         0,       0,       0,     1);

    mat4 translation(
              1,       0,       0, 0,
              0,       1,       0, 0, 
              0,       0,       1, 0,
        -eye[0], -eye[1], -eye[2], 1);

    return orientation * translation;
}
</code></pre>

<p><a href=""https://github.com/rioki/glm/blob/master/src/projection.h#l40"" rel=""nofollow noreferrer"">full code</a></p>

<p>And finally for the sake of completeness, you also have the object coordinate system. This is the coordinate system in which meshes are stored. With the help of the model matrix the mesh coordinates are converted into the world coordinate system. In practice the model and view matrices are combined into the so called model-view matrix.</p>
","72586"
"Do games need installation these days?","10511","","<p>I wonder why games need installation at all. I can understand that some software like a browser needs it so it can associate some file types with it and start an executable, or add the icon to the Programs/Features component on Windows. But what's the purpose of installing, say, a Steam game? The Steam itself handles installation/removal of a game, updating, starting etc. If I develop my own game launcher (which will use installation) what are the reasons for me to use also an installer for my games?</p>
","<p>There are quite a few reasons you'd want to use an installer. Some of them, off the top of my head:</p>

<ul>
<li><p>Most games (and indeed, most applications) these days require the use of some supporting DLLs (such as a dynamically-linked C++ runtime or the Direct3D runtimes). Sometimes these DLLs <em>cannot legally</em> be distributed directly and must be installed via redistributable installers. This used to be the case for D3DX DLLs, for example. It's important to read and understand the licensing terms for your dependencies. If you have such a dependency, wrapping up its installation in your own installer can smooth the process out for end-users.</p></li>
<li><p>A well-behaved modern program will not require elevated (admin) access to run. However, it might require such access to be <em>installed</em>, and an installer provides a reasonably simple process for doing so that users are more-or-less familiar with.</p></li>
<li><p>Similarly, some games will want to generate registry entries to associate file types and the like, as you noted. This can also require elevation. </p></li>
<li><p>If a game relies on system-wide installed versions of some of its dependencies (as above) it can benefit from security updates and hotfixes made to those dependencies more easily (the OS takes care of them, not the game developer). But installing those dependencies in system-wise locations <em>also</em> requires elevation, and can be very easy to get wrong if you ask a user (particularly a non-technical user) to do it manually.</p></li>
<li><p>Finally, don't forget how easy it is, as somebody who is a tech-savvy user, to underestimate the non-tech-savvy view of computing. Sometimes ""double-click to open"" is the only skill you can assume (sometimes not even that much); double-clicking an installer launches a program the user can usually ""okay, okay, okay"" through. Double-clicking a .zip just extracts it (""well where did my game go?"") or worse, opens it like a folder, where users will double-click on the .exe and it will fail to run correctly. Users don't always understand installers either, but it is closer to the paradigm they tend to get than ""decompress archive and put files in 'the right spot.'""</p></li>
</ul>

<p>As for Steam... Steam provides facilities for helping install and uninstall a game, but it does not do <em>everything</em> for you. It's also worth noting that not all games are distributed on Steam or exclusively on Steam, so relying entirely on Steam's installation services will mean those games end up duplicating work for non-Steam distribution channels.</p>
","125840"
"Material tiling and offset in unity","10495","","<p><strong><em>Ambiguity:</em></strong>
What exactly is the difference between Tiling the material and Offset of material?</p>

<p><strong><em>Need to do:</em></strong></p>

<p>I need the material to be repeated <code>n</code> times on the object where I need to set the value of <code>n</code> via script.How do I do it?</p>

<p>It seems to happen through Tiling(tried via inspector) but again what is difference between <code>mainTextureOffset</code> and <code>setTextureOffset</code>?</p>

<p><em>Tried:</em></p>

<p>Following is the line of code that I tried to repeat the texture <code>n</code> number of times on an object(repeat across the width of object), but it does nothing significant that I can see.</p>
","<blockquote>
  <p>What exactly is the difference between Tiling the material and Offset
  of material?</p>
</blockquote>

<p>Those parameters set by the inspector are used inside the shader to scale the texture coordinates.
A <code>uniform float4</code> in the shader with the name of the texture and <code>_ST suffix</code> is populated with those values.
For example considered the main texture:</p>

<pre><code>float2 scaled_uv = tex.uv * _MainTex_ST.xy + _MainTex_ST.zw;
</code></pre>

<p>Let's say the offset basically translate the texture in the uv space meanwhile the scale, scales it.  </p>

<p><strong>mainTextureOffset</strong>: set the texture offset of the main texture (texture binded to the name <code>_MainTex</code> inside a shader)</p>

<p><a href=""http://docs.unity3d.com/ScriptReference/Material.SetTextureOffset.html"" rel=""nofollow"">SetTextureOffset</a> let you specify the texture name. <code>SetTexureOffset(_MainTex, offset);</code>is equivalent to use the facility <code>mainTextureOffset</code>.</p>

<p>An alternative is setting directly the uniform vector. The used convention for built-in shaders is using the suffix _ST to the texture name. So you can also use <a href=""http://docs.unity3d.com/ScriptReference/Material.SetVector.html"" rel=""nofollow"">SetVector</a>:</p>

<pre><code>material.SetVector(""_MainTex_ST"", scaleAndOffset);
</code></pre>

<hr>

<p>EDIT</p>

<p>For repeat the texture you have to modify the scale not the offset. If you set for example a scale of 2 along an uv axis you will obtain to repeat the texture twice along it.</p>
","82365"
"2D Planet Gravity","10476","","<p>I'm trying to make a simple game where a spaceship is launched and then its path is effected by the gravity of planets.</p>

<p>Similar to this game: <a href=""http://sciencenetlinks.com/interactives/gravity.html"">http://sciencenetlinks.com/interactives/gravity.html</a></p>

<p>I wish to know how to replicate the effect the planets have on the spaceship in this game so a spaceship can 'loop' around a planet to change direction.</p>

<p>I have managed to achieve some bogus results where the spaceship loops in a huge ellipse around the planet or is only slightly affected by the gravity of a planet using Vectors.</p>

<p>Thanks in advance.</p>

<p>p.s I have plenty of coding experience just none to do with game dev.</p>
","<p>In your case there is an spaceship, which moves affected by the gravity of all the planets.
Each planet applies force equal to 'm1*m2/ r^2' in which m1 and m2 represent masses of spaceship and planet, and r is equal to euclidean distance of planet and space ship. you just have to calculate sum of all the forces applied to ship. from the rules of newton we know 'f = m*a' where f is total force applied to an object, m is it's mass and a is it's acceleration. from this point you can read <a href=""http://gafferongames.com/game-physics/integration-basics/"">this page</a> to learn how to use acceleration to compute velocity and position over time.</p>
","21064"
"Rolling my own scene graph","10472","","<p>Hello Game Development SE!</p>

<p>I'm crawling my way through OpenGL with the hopes of creating a <em>simple</em> and very lightweight game engine. I view the project as a learning experience that might make a little money in the end, but will be fun either way. </p>

<p>So far I've used GLFW to gain some basic I/O, a window (with a oh so fancy F11 fullscreen key) and of course an OpenGL context. I've also used GLEW to expose the rest of the OpenGL extensions because I'm using Windows and I want to use all of OpenGL 3.0+.</p>

<p>Which brings me to the scene graph. In short, I'd like to roll my own. This decision came after looking at OSG and reading a few articles on how the concept of a scene graph has become twisted, bent and broken. One such <a href=""http://www.realityprime.com/blog/2007/06/scenegraphs-past-present-and-future/"" rel=""nofollow noreferrer"">article</a> described how scene graphs have developed as...</p>

<blockquote>
  <p>Then we added in all this extra stuff, like hanging ornaments on a Christmas tree, except that some of the ornaments are nice juicy steaks and some are whole live cows. </p>
</blockquote>

<p>Following the analogy, I'd like the steak, the meat of what a scene graph should be, without having to strap on piles of extra code, or any whole cows. </p>

<p>So with that in mind, I find myself wondering exactly what a scene graph should be and how a simple scene graph should be implemented? Here's what I have so far...</p>

<p>A one parent, n-children tree or DAG which...</p>

<ul>
<li>Should keep track of game object transformations (position, rotation, scale)</li>
<li>Should hold render states for optimizations</li>
<li>Should provide a means of culling objects not within the view frustum</li>
</ul>

<p>With the following properties...</p>

<ul>
<li><p>All nodes should be treated as renderable (even if they don't render) This means they...</p>

<ul>
<li>Should all have cull(), state() and draw() methods (return 0 if non-visible)</li>
<li>cull() recursively calls cull() on all children, thus generating a complete cull mesh for the entire node, and all children. Another method, hasChanged() could allow so-called static meshes to not need to have their culling geometry computed each frame. This would work such that if any node in the sub-tree has changed then all geometry down to root is rebuilt. </li>
</ul></li>
<li><p>Render states will be held in a simple enumeration, each node will select from this enumeration an OpenGL state set that it requires and that state will be setup before draw() is called on that node. This allows for batching, all nodes of a given state set will be rendered together, then the next state set is setup and so on.</p></li>
<li><p>No node should directly hold geometry/shader/texture data, instead nodes should point to shared objects (perhaps managed by some singleton object like a resource manager).</p></li>
<li><p>Scene graphs should be able to reference other scene graphs (maybe using a proxy node) to allow situations like <a href=""https://gamedev.stackexchange.com/questions/27697/scene-graph-theory"">this</a>, thus allowing complex multi-mesh models/objects to be copied around the scene graph without adding a ton of data. </p></li>
</ul>

<p>I'm hoping to get some valuable feedback on my current design. Is it missing functionality? Is there a vastly better way/design pattern? Am I missing some larger concept that will be necessary to include in this design for a somewhat simple 3D game? Etc.</p>

<p>Thanks, -Cody</p>
","<p><strong>The Concept</strong></p>

<p>Fundamentally, a scene graph is nothing more than a bi-directed acyclic graph which serves to represent a hierarchically-structured set of spatial relationships. </p>

<p>Engines in the wild tend to include other goodies into the scene graph, as noted. Whether you see that as the meat or the cow probably depends on your experience with engines and libraries out there.</p>

<p><strong>Keeping it Lightweight</strong></p>

<p>I favour the Unity3D style of having your scene graph node (which at it's heart is a topological rather than a spatial / topographical structure) inherently include spatial parameters and functionality. In my engine, my nodes are even lighter-weight than Unity3D, where they inherit a lot of unncessary junk members from superclasses / implemented interfaces: Here's what I have -- about as light as you can get:</p>

<ul>
<li>parent / child pointer members.</li>
<li>pre-transform spatial parameter members: xyz position, pitch, yaw and roll.</li>
<li>a transform matrix; the matrices in a hierarchical chain can very quickly &amp; easily multiply out by walking recursively up/down the tree, giving you the hierarchical spatial transformations which are a scene graph's main feature;</li>
<li>an <code>updateLocal()</code> method which updates <em>only this</em> node's transform matrices</li>
<li>an <code>updateAll()</code> method which updates <em>this and all descendant</em> nodes' transform matrices</li>
</ul>

<p>...I also include equations-of-motion logic and thus velocity / acceleration members (linear &amp; angular) in my node class. You can forego that, and handle it in your main controller instead if you wish. But that is it -- very lightweight indeed. Remember, you could have these on thousands of entities. So as you've suggested, keep it light.</p>

<p><strong>Constructing Hierarchies</strong></p>

<p>What you say about a scene graph referencing other scene graphs... I'm waiting for the punchline? Of course they do. That's their main use. You can add any node to any other node, and transformations should automatically occur within the new transform's local space. All you're doing is changing a pointer, it's not like you're copying data around! By changing a pointer, you then have a deeper scene graph. If using Proxies makes things more efficient then by all means, but I've never seen the need.</p>

<p><strong>Avoid Render-related Logic</strong></p>

<p>Forget about rendering as you write your scene graph node class, or you will confound things for yourself. All that matters is that you have a data model -- whether it's the scene graph or not doesn't matter -- and that some renderer is going to inspect that data model and render objects in the world accordingly, whether it's in 1, 2, 3 or 7 dimensions. The point I am making is: Do not contaminate your scene graph with render logic. A scene graph is about topology and topography -- i.e. connectivity and spatial characteristics. These are the true state of the simulation and exist even in the absence of rendering (which can take any form under the sun from a first person view to a statistical graph to a textual description). Nodes don't point to rendering-related objects -- however the reverse may well be true. Also consider this: Not every scene graph node in your entire tree will be renderable. Many will be just containers. So why even allocate memory for a pointer-to-render-object? Even a pointer member that is never used, is still taking up memory. So reverse the pointer direction: Render-related instance references the data model (which might be, or include, your scene graph node), NOT vice versa. And if you want an easy way to do run through your list of controller yet get access to the related view, then use a dictionary / hashtable, which approaches O(1) read access time. That way there is no contamination, and your simulation logic doesn't care what renderers are in place, which makes your days and nights of coding <em>worlds</em> easier.</p>

<p>As for culling, refer back to the above. Area-of-interest culling is a simulation logic concept. That is, you don't process the world outside of this (usually boxed, circular or spherical) area. This takes place in the main controller / game loop, before rendering happens. On the other hand, frustum culling is <em>purely</em> render-related. So forget about culling right now. It has nothing to do with scene graphs, and by focusing on it you will be obscuring the true purpose of what you are trying to achieve.</p>

<p><strong>A Final Note...</strong></p>

<p>I get the strong feeling you are coming from a Flash (specifically AS3) background, given all the details about rendering included here. Yes, Flash Stage/DisplayObject paradigm includes all the render logic as part of the scenegraph. But Flash makes a lot of assumptions that you don't necessarily want to make. For a fully-fledged game engine, it is better not to mix the two, for reasons of performance, convenience and controlling code complexity through proper <a href=""http://en.wikipedia.org/wiki/Separation_of_concerns"">SoC</a>. </p>
","46454"
"Difference between Arcade, P2 and Ninja physics in Phaser","10464","","<p>I am a beginner and trying to learn game development using <em>Phaser</em>. Currently Phaser is providing three physics systems namely Arcade, P2 and Ninja. But I don't know the differences between them and I would also like to know in which scenario we should use a particular physics system? </p>

<p>Please give me some insight for these physics systems.</p>
","<p>As mentioned in the comments, their site already explains what the three systems are and what they can be used for.</p>

<blockquote>
  <p>Arcade Physics is for high-speed AABB collision only.</p>
</blockquote>

<p>AABB means axis-aligned bounded rectangles; it means you have objects without rotation, and you're only checking if the image (which is a rectangle) overlaps with another image (so there's a potential collision). This is cheap to compute, and fast, which is probably why they recommend it for high-speed collisions.</p>

<p>One issue with AABB is that it doesn't guarantee that there really is a collision; you may have a completely transparent area overlapping.</p>

<blockquote>
  <p>Ninja Physics allows for complex tiles and slopes, perfect for level scenery, [...]</p>
</blockquote>

<p>Remember how AABB is non-rotated? Ninja Physics will handle rotations (so it can do slopes and complex tiles). This is a more flexible (and probably more accurate) physics model; it's probably slower.</p>

<blockquote>
  <p>[...] P2.JS is a full-body physics system, with constraints, springs, polygon support and more.</p>
</blockquote>

<p>If you need to model springs (eg. something swinging like a pendulum), constraints on forces, and arbitrary polygon shapes (eg. tetrahedron), this sounds like what you want. If you want a frame of reference, think of something like Angry Birds.</p>

<p>Based on your game, you can pick which is the best-fit to your needs. It sounds like a spectrum of speed versus accuracy/complexity (Arcade Physics being the fastest but simplest).</p>
","72941"
"After a succesful glLinkProgram, should I delete / detach my shaders?","10454","","<p>After I have a linked program, and thinking about defensive programming, should I delete and detach the shaders used to link this program? </p>

<p>If yes, is that going to free any resources? Or do these shader objects only going to be freed after a glDeleteProgram call? </p>

<p>edit: Just for clarification what I am doing is (which is consistent with the answer):</p>

<blockquote>
  <p>glCreateShader -> glShaderSource -> glCompileShader -> glCreateProgram -> glAttachShader -> glLinkProgram -> glDetachShader -> glDeleteShader -> draw using this shader program -> and when I don't need this shader anymore glDeleteProgram</p>
</blockquote>
","<p>Yes, you should always do this. I didn't find out about this until just recently, but a shader won't actually be deleted by <code>glDeleteShader</code> until it's been detached. It's mentioned on the <a href=""https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/glDetachShader.xhtml"" rel=""nofollow noreferrer"">man page for <code>glDetachShader</code></a></p>

<p><strong>EDIT</strong>: Almost missed the bit about deleting the shaders too. Yes, you should do this as it frees up the memory used to store the shader source and unlinked object code. This is explained in more detail in <a href=""https://stackoverflow.com/questions/9113154/proper-way-to-delete-glsl-shader"">this StackOverflow question</a>.</p>
","47912"
"Unity GUITexture or GUIText not showing up","10446","","<p>Currently I've got a little 2.5D platformer with the camera tracking the player. Now when I go to insert a GUITexture or GUIText game object into the scene, it comes up absolutely fine in the Editor view, but when I go to play it there's absolutely nothing to be seen!</p>

<p>At first I thought it may have been a script I was using on the GUI, but I've tried it out with a completely bland GUITexture object that has no interaction with the rest of the game and I still get the same effect. I'm wondering if my camera is messing it up somehow, but I assumed that all GUI objects are drawn to screen space and just stay with the camera.</p>

<p>I've been really stuck for the past few hours so if any one could offer some insight, I'd be very, very grateful!</p>

<p>~Ray</p>
","<p>I can safely say that I am an idiot :)</p>

<p>Somehow, my camera got rid of the GUILayer component. Creating a new camera from scratch with all the prefabricated components fixed it.</p>

<p>I'll leave this here for posterity's sake, since this would be a pretty obscure thing to go wrong and there isn't any documentation I found on it.</p>

<p>But if a moderator feels differently, then they can close it :)</p>
","20663"
"How do I draw a tilemap within unity3d?","10425","","<p>I'm pretty new to Unity and after a bit of googling around I have come up with this code to draw my tilemap (the script is attached to my camera).</p>

<p>I am simply trying to use nested for-loops to draw a grid of grass tiles, here is my code:</p>

<pre><code>public class DrawMap : MonoBehaviour {

    // Use this for initialization
    void Start () {

        Sprite grass = (Sprite)Instantiate(Resources.Load(""Grass""));
        float x, y;

        for (int i = 0; i &lt; 20; i++) {  
                        for (int j = 0; j &lt; 20; j++) {
                            x = i * 1.28f;
                            y = j * -1.28f;
                            Instantiate(grass, new Vector3 (x, y, 0f), Quaternion.identity);

                        }
                }
    }

    // Update is called once per frame
    void Update () {

    }
}
</code></pre>

<p>I keep getting an error where I initialize ""grass"" saying the it cannot cast the source type from the destination type. I created ""grass"" to be a prefab from a slice of a spritesheet that i imported.</p>

<p>Any help would be greatly appreciated</p>
","<p>Ok seems as no one is replying to you, I will provide you with a basic commented example.</p>

<p>I assume you have a ""Resources"" folder inside of your ""Assets"" folder.
I also assume you have a ""Prefabs"" folder inside of your ""Resources"" folder.</p>

<p>You will need to create an empty GameObject in your scene. Attach a SpriteRenderer component to that object and then drag your desired grass sprite into the Sprite section of the SpriteRenderer. Drag that object into your ""Resources/Prefabs"" folder. The destination is important because we will be loading it from script later. Delete the initial (not prefab in folder) GameObject in your scene because we already have a copy of it.</p>

<p>Now you have created a tile prefab which can be used for the basic example tile map. Please note that this is for explanation purposes and would need some slight modifications to have multiple tiles instead of just one.</p>

<p>Now you will need to create a new GameObject in your scene and name it ""TileMap"" or whatever you want… </p>

<p>Create a new C# script and name that ""TileMap"" or ""Map"" or whatever you want… Attach that script to the ""TileMap"" GameObject.</p>

<p>Open up the C# script and insert the below code into it.</p>

<p><strong>NOTE</strong> the code is commented and I shouldn't have to re-explain it to you. Good luck.</p>

<pre><code>//Place a gameobject with a sprite renderer attached and the grass tile in that. 
//Create it into a prefab and place it into your ""Resources"" folder.
public Transform tilePrefab;

//Tilemap width and height
public int mapWidth = 5;
public int mapHeight = 5;

//Size you want your tile in unity units
public float tileSize = 1.28f;

//2D array to hold all tiles, which makes it easier to reference adjacent tiles etc.
public Transform[,] map;

void Start () 
{
    //Load prefab ""Grass"" from ""Resources/Prefabs/"" folder.
    tilePrefab = Resources.Load &lt;Transform&gt; (""Prefabs/Grass"");

    //If we can't find the prefab then log a warning.
    if (!tilePrefab)
        Debug.LogWarning (""Unable to find TilePrefab in your Resources folder."");

    //Initialize our 2D Transform array with the width and height
    map = new Transform[mapWidth, mapHeight];

    //Iterate over each future tile positions for x and y
    for (int y = 0; y &lt; mapHeight; y++)
    {
        for (int x = 0; x &lt; mapWidth; x++)
        {
            //Instantiate tile prefab at the desired position as a Transform object
            Transform tile = Instantiate (tilePrefab, new Vector3 (x * tileSize, y * tileSize, 0), Quaternion.identity) as Transform;
            //Set the tiles parent to the GameObject this script is attached to
            tile.parent = transform;
            //Set the 2D map array element to the current tile that we just created.
            map[x, y] = tile;
        }
    }
}

//Returns a tile from the map array at x and y
public Transform GetTileAt (int x, int y)
{
    if (x &lt; 0 || y &lt; 0 || x &gt; mapWidth || y &gt; mapHeight)
    {
        Debug.LogWarning (""X or Y coordinate is out of bounds!"");
        return null;
    }
    return map[x, y];
}

void Update () 
{

}
</code></pre>
","87736"
"How can I easily create cloud texture maps?","10418","","<p>I am making 3d planets in my game; these will be viewed as ""globes"". Some of them will need cloud layers. I looked at various Blender <a href=""http://www.blenderguru.com/videos/create-a-realistic-earth"">tutorials for creating ""earth""</a>, and for their cloud layers they use <a href=""http://www.planetaryvisions.com/Texture_map.php?pid=4302"">earth cloud maps from NASA</a>. </p>

<p>However I will be creating a fictional universe with many procedurally-generated planets. So I would like to use many variations. </p>

<p>I'm hoping there's a way to procedurally generate cloud maps such as the NASA link. I will also need to create gas giants, so I will also need <a href=""http://www.jpl.nasa.gov/spaceimages/details.php?id=PIA07782"">other kinds of cloud texture maps</a>.</p>

<p>If that is too difficult, I could fall back to creating several variations of cloud maps. For example, 3 for earth-like, 3 for gas giants, etc.</p>

<p>So how do I statically create <strong><em>or</em></strong> programmatically generate such cloud maps?</p>
","<p>Cloud generation is fun! I'll cover both offline and runtime methods.</p>

<h2>Pre-rendered clouds</h2>

<p>If you want to pre-render your cloud textures offline, look no further than Photoshop (or <a href=""http://www.gimp.org/"" rel=""noreferrer"">Gimp</a>, if you prefer). Both programs can easily generate cloud patterns. Menu items tend to move around between releases, but as of Gimp 2.8.2 the core command you're looking for is <code>Filters -&gt; Render -&gt; Clouds -&gt; Solid Noise</code>. You'll need to create a new blank image before the command is enabled. I encourage you to experiment with the noise parameters, but just as one example, here's what happens if you set ""Random Seed"" to 1, ""Detail"" to 4, ""X Size"" to 4.0, ""Y Size"" to 8.0, disable ""Randomize"" and ""Turbulent"", and enable ""Tilable"":
<img src=""https://i.stack.imgur.com/PNdtb.jpg"" alt=""Raw output of Gimp &quot;Solid Noise&quot; command""></p>

<p>One further step I definitely recommend is editing the image's levels (<code>Colors -&gt; Levels...</code> in Gimp). By dragging the endpoints around, you can effectively change the level of cloud cover from ""fully overcast"" to ""not a cloud in the sky"".
<img src=""https://i.stack.imgur.com/wSx1I.jpg"" alt=""Thresholded clouds""></p>

<p>Other interesting possibilities:</p>

<ul>
<li>Use the ""Dodge"" and ""Burn"" tools to manually brighten/darken portions
of the image.</li>
<li>Warp the cloud image to suggest wind patterns. Try Gimp's <code>Filters -&gt; Distorts -&gt; Whirl and Pinch...</code> command, or for more control use <code>Filters -&gt; Distorts -&gt; IWarp...</code> with the Deform Mode set to ""Swirl"". Keep it subtle, though -- too much warping tends to blur the high-frequency detail out of the image.</li>
<li>Add multiple independent cloud layers to simulate different types of clouds, from thin and wispy to big &amp; chunky (I'm sure they have proper scientific names, but damnit Jim, I'm a programmer, not a meteorologist!). In this case, you'd probably want to save each layer as a separate image so you can animate them independently at runtime.</li>
</ul>

<p>It really depends on your artistic vision. Go nuts! When you're finished, remember to export the texture as a single-channel grayscale image, so you can use the same cloud data for your color and alpha channel at runtime.</p>

<h2>Runtime cloud generation</h2>

<p>Generating unlimited cloud patterns at runtime is a bit more involved, but still totally feasible. It's a huge topic, and this will only cover the broad strokes.</p>

<p>Basically you're going to replicate Gimp's ""Solid Noise"" command in your shader code, using a noise function like the canonical <a href=""https://en.wikipedia.org/wiki/Perlin_noise"" rel=""noreferrer"">Perlin Noise</a> to generate infinite, smooth, deterministic, (optionally) periodic noise volumes. Your question didn't specify which rendering API you're targeting, so I can't get too specific here; <a href=""http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter26.html"" rel=""noreferrer"">chapter 26 of ""GPU Gems 2""</a> covers a variant of Perlin noise in (somewhat dated) HLSL and CgFX, or you can use <a href=""http://www.opengl.org/news/comments/drop-in-replacement-noise-for-glsl/"" rel=""noreferrer"">this drop-in GLSL noise function</a>. By sampling a 2D slice of a 3D noise volume, you get something like the Gimp ""Solid Noise"" command with Detail=0. The lower the distance between your noise volume samples, the lower-frequency (""smoother"") your noise will be. To increase the level of high-frequency detail, start with a base low-frequency noise pattern and add additional higher-frequency ""octaves"" of noise, where each ""octave"" is a different slice of the 3D noise volume with a larger sampling distance and lower amplitude. A visual example of this process (which I found by Googling ""multi-octave Perlin noise"") can be found <a href=""http://freespace.virgin.net/hugo.elias/models/m_perlin.htm"" rel=""noreferrer"">here</a>.</p>

<p>As a huge added bonus, cloud textures generated in this fashion can very easily be animated! Add a time-based offset to your 3D noise function sample coordinates, and you'll get extremely convincing cloud motion (as seen in <a href=""https://www.youtube.com/watch?v=Juq2rBjnRSU"" rel=""noreferrer"">this video</a>, for example). This is because the noise function is smooth in all three dimensions; scrolling the texture in the U/V direction causes the clouds to move around the planet, while scrolling in the W (perpendicular) direction has the effect of slowly ""evolving"" the clouds.</p>

<p>Warping clouds at runtime is possible as well, for hurricane-like effects. Results can actually be much higher quality than the naïve Gimp warp filters, which (as mentioned earlier) can lead to an overly blurry texture. One technique you definitely want to look into is ""flow maps"", as described by Alex Vlachos of Valve (<a href=""http://www.valvesoftware.com/publications/2010/siggraph2010_vlachos_waterflow.pdf"" rel=""noreferrer"">SIGGRAPH 2010 slides</a>) or Carlos Gonzalez of Naughty Dog (<a href=""https://cgzoo.files.wordpress.com/2012/04/water-technology-of-uncharted-gdc-2012.pdf"" rel=""noreferrer"">GDC 2012 slides</a>). The basic idea is that you paint a vector field (the ""flow map"") and use it to distort and scroll the cloud texture at runtime, while periodically cross-fading between two different cloud textures when the distortion distance gets too high.</p>

<h2>Which method to use?</h2>

<p>Pre-rendering cloud textures in Gimp/Photoshop is extremely easy; you can generate a new texture in a few seconds once you get the hang of it. The runtime code is trivial, and very fast. However, more unique cloud textures means higher disk space requirements (also, a larger/slower download) and more VRAM usage at runtime.</p>

<p>Runtime cloud generation is much more difficult at first, but once you get it working it has several clear advantages over pre-rendered cloud textures. You can generate an infinite variety of realistic animated cloud patterns without using any additional disk space or VRAM. However, the runtime cost of evaluating multiple 3D noise functions per-pixel can be steep; your cloud pixel shaders will be much slower than they in the pre-rendered case.</p>

<p><strong>TL;DR:</strong> definitely start by using pre-rendered clouds, and switch to runtime procedural clouds if you need the extra variety (or want an extra programming challenge).</p>
","35789"
"What does ddx (hlsl) actually do?","10415","","<p>I'm a bit confused.  The official documentation (<a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/bb509588(v=vs.85).aspx"">http://msdn.microsoft.com/en-us/library/windows/desktop/bb509588(v=vs.85).aspx</a>) says that ddx(input) is the partial derivative of the input with respect to the ""screen-space x-coordinate.""</p>

<p>My calculus is fine, but how can it tell what the input is coming from?  If I passed it a function, fine, I can imagine what it would do, but the derivative of a number is always zero...?</p>

<p>Is it just a scaling?  Like, this would get scaled to one tenth of its size at this distance, so it returns one tenth?  But then it doesn't need an input...</p>

<p>Can someone give a quick explanation of what's actually happening?</p>
","<p>Internally, GPUs never run one instance of a pixel shader at a time.  At the finest level of granularity, they are always running 32-64 pixels at the same time using a SIMD architecture.  Within this, the pixels are further organized into 2x2 quads, so each group of 4 consecutive pixels in the SIMD vector corresponds to a 2x2 block of pixels on screen.</p>

<p>Derivatives are calculated by taking differences between the pixels in a quad.  For instance, <code>ddx</code> will subtract the values in the pixels on the left side of the quad from the values on the right side, and <code>ddy</code> will subtract the bottom pixels from the top ones.  The differences can then be returned as the derivative to all four pixels in the quad.</p>

<p>Since the pixel shader is running in SIMD, it's guaranteed that the corresponding value is in the same register at the same time for all the pixels in the quad.  So whatever expression or value you put into <code>ddx</code> or <code>ddy</code>, it will be evaluated in all four pixels of the quad, then the values from different pixels subtracted as described above.</p>

<p>So taking the derivative of a constant value will give zero (as you'd expect from calculus, right?) because it's the same constant value in all four pixels.</p>

<p>Also note that there are ""coarse"" and ""fine"" derivatives, <code>ddx_coarse</code>/<code>ddy_coarse</code> and <code>ddx_fine</code>/<code>ddy_fine</code>.  An explanation of the distinction is given <a href=""http://fgiesen.wordpress.com/2011/07/10/a-trip-through-the-graphics-pipeline-2011-part-8/#comment-1990"">here</a>.  Just plain <code>ddx</code>/<code>ddy</code> are aliases for the coarse versions.</p>

<p>BTW, the reason this functionality exists is that GPUs internally have to take derivatives of texture coordinates in order to do mipmap selection and anisotropic filtering.  Since the hardware needs the capability anyway (you can use any arbitrary expression for texture coordinates in a shader), it was easy enough to also expose it to shader programmers directly.</p>
","62650"
"Retrieve the original prefab from a game object","10410","","<p>How would one proceed to retrieve the original prefab used for instantiating an object?</p>

<p>In the editor these two functions work : </p>

<pre><code>        Debug.Log(PrefabUtility.GetPrefabParent(gameObject));
        Debug.Log(PrefabUtility.GetPrefabObject(gameObject));
</code></pre>

<p>But I need something that works in the release version.</p>

<p>I have objects that can be transported between scenes ands I need to save their data and original prefab to be able to instantiate them outside of the scene they have been originally instantiated.</p>

<hr>

<p>ie:</p>

<ul>
<li>Game designers create new prefabs.</li>
<li>Game designers create objects from prefabs and place them in scenes (50 to 150 scenes).</li>
<li>Game is played and objects are moved across scenes.</li>
<li>Game is saved and infos about objects which have moved are saved in the save streams (files or network).</li>
</ul>

<p>This is where I got stuck. Currently, to palliate to the shortcomings, we're saving the name of the prefab in the prefab. But each time a prefab is moved, renamed or duplicated the string must be changed too, sometimes the objects created from the prefab keep the original name (game designer might have edited the prefabPath field).</p>

<p>Maybe there is a better way to achieve proper save games without having to access to the original prefab/name. But currently we keep the saves segmented on a per level basis (easier and safer to save/load to files and transfer the save games to/from servers)</p>
","<p><strong>Simple Answer</strong></p>

<p>Use a class to load the original prefab from <code>Resources.Load(string prefabPath, typeof(GameObject));</code></p>

<p>Store this returned prefab into a resource pool class by path key. For instance: <code>Dictionary&lt;string, GameObject&gt; prefabLookup;</code></p>

<p>You can then grab the original prefab anytime you need it.</p>

<p>Use a helper method to automatically load at runtime.  </p>

<pre><code>public static GameObject GrabPrefab(string path)
{
     if(!prefabLookup.ContainsKey(path))
     {
          // Load prefab and add to dictionary...
     }

     return prefabLookup[path];
}
</code></pre>

<p>I would also suggest unloading un-used assets from memory on level change. This will keep you from hitting a memory limit.</p>
","80464"
"Button stays highlighted after being clicked - Unity3D 4.6 GUI","10409","","<p>Sometimes, after clicking a button created by unity's new UI Button, the button stays in its highlight state. Note that Button script has <code>Color Tint</code> set as it's <code>Transition</code> property and the <code>Interactable</code> checkbox is checked.</p>

<p>How can I solve this?</p>
","<p>The <code>Navigation</code> property of buttons are set to <code>Automatic</code> by default, which means you will be able to navigate through buttons using arrow keys. If you disable this by changing the <code>Navigation</code> property to <code>None</code>, buttons will not stay highlighted.</p>
","92147"
"Changing coordinate system from Z-up to Y-up","10376","","<p>Blender's coordinate system is different from what I'm used to, in that Z points upwards instead of Y. What would be the simplest way of converting all the world data (so that all animations, texture coordinates, etc still work) so that Y points upwards?</p>

<p>Clarification:</p>

<p>Object positions are defined as matrices, so just switching translation/rotation/scale information in matrices is not a trivial task. (at least it does not seem like a trivial task to me)</p>
","<p>Why can't you just make the rotation matrix to orient it correctly the first part of your World matrix?</p>

<p>If you want to fix it when loading, create the rotation matrix to orient it correctly (i.e. 90 degrees around the X axis).  Apply this to all vertices, then change all existing matrices to (rotation * existing).</p>
","7928"
"How can I acheive a smooth 2D lighting effect?","10370","","<p>I'm making a 2D tile based game in XNA.</p>

<p>Currently my lightning looks like <a href=""https://i.imgur.com/dC3WYE7.png"" rel=""nofollow noreferrer"">this</a>.</p>

<p>How can I get it to look like <a href=""http://playstarbound.com/wp-content/uploads/2012/04/Dungeon.jpg"" rel=""nofollow noreferrer"">this</a>?</p>

<p>Instead of each block having its own tint, it has a smooth overlay.</p>

<p>I'm assuming some sort of shader, and to pass the lighting values for the surrounding tiles to the shader, but I'm a beginner with shaders so I'm not sure.</p>

<p>My current lighting calculates the light, and then passes it to a <code>SpriteBatch</code> and draws with the tint parameter. Each tile has a <code>Color</code> that is calculated before draw in my lighting algorithm, which is used for the tint.</p>

<p>Here is an example on how I currently calculate lighting (I do this from left, right, and bottom too, but I got really tired of doing this frame by frame...)</p>

<p><img src=""https://i.stack.imgur.com/RBfKa.gif"" alt=""enter image description here""></p>

<p>So actually getting and drawing the light so far is <strong>no problem</strong>!</p>

<p>I have seen countless tutorials on fog of war and using gradient circular overlays to create smooth lightning, but I already have a nice method to assign each tile a lightning value, it just needs to be smoothed between them. </p>

<p>So to review</p>

<ul>
<li>Calculate Lighting (Done)</li>
<li>Draw Tiles (Done, I know I will need to modify it for the shader)</li>
<li>Shade tiles (How to pass values and apply ""gradient)</li>
</ul>
","<p><strike>How about something like this?</p>

<p>Don't draw your lighting by tinting your tile sprites.  Draw your <strong>unlit</strong> tiles to a render target, then draw the tile lights to a second render target, representing each one as a grayscale rectangle covering the area of the tile.  To render the final scene, use a shader to combine the two render targets, darkening each pixel of the first according to the value of the second.</p>

<p>This will produce exactly what you have now.  That doesn't help you, so let's change it a bit.</p>

<p>Change the dimensions of your lightmap render target so that each <em>tile</em> is represented by a single <em>pixel</em>, rather than a rectangular area.  When compositing the final scene, use a sampler state with linear filtering.  Otherwise leave everything else the same.</p>

<p>Assuming you've written your shader correctly the lightmap should be effectively ""scaled up"" during compositing.  This will get you a nice gradient effect for free via the graphics device's texture sampler.</p>

<p>You may also be able to cut out the shader and do this more simply with a 'darkening' BlendState, but I'd have to experiment with it before I could give you the specifics.</strike></p>

<p><strong>UPDATE</strong></p>

<p>I had some time today to actually mock this up.  The answer above reflects my habit of using shaders as my first answer to everything, but in this case they're not actually necessary and their use needlessly complicates things.  </p>

<p>As I suggested, you can accomplish exactly the same effect using a custom BlendState.  Specifically, this custom BlendState:</p>

<pre><code>BlendState Multiply = new BlendState()
{
    AlphaSourceBlend = Blend.DestinationAlpha,
    AlphaDestinationBlend = Blend.Zero,
    AlphaBlendFunction = BlendFunction.Add,
    ColorSourceBlend = Blend.DestinationColor,
    ColorDestinationBlend = Blend.Zero,
    ColorBlendFunction = BlendFunction.Add
}; 
</code></pre>

<p>The blending equation is </p>

<pre><code>result = (source * sourceBlendFactor) blendFunction (dest * destBlendFactor)
</code></pre>

<p>So with our custom BlendState, that becomes </p>

<pre><code>result = (lightmapColor * destinationColor) + (0)
</code></pre>

<p>Which means that a source color of pure white (1, 1, 1, 1) will preserve the destination color, a source color of pure black (0, 0, 0, 1) will darken the destination color to pure black, and any shade of gray in between will darken the destination color by a middling amount.</p>

<p>To put this into practice, first do whatever you need to do to create your lightmap:</p>

<pre><code>var lightmap = GetLightmapRenderTarget();
</code></pre>

<p>Then just draw your <strong>unlit</strong> scene directly to the backbuffer as you normally would:</p>

<pre><code>spriteBatch.Begin(SpriteSortMode.Deferred, BlendState.AlphaBlend);
/* draw the world here */
spriteBatch.End();
</code></pre>

<p>Then draw the lightmap using the custom BlendState:</p>

<pre><code>var offsetX = 0; // you'll need to set these values to whatever offset is necessary
var offsetY = 0; // to align the lightmap with the map tiles currently being drawn
var width = lightmapWidthInTiles * tileWidth;
var height = lightmapHeightInTiles * tileHeight;

spriteBatch.Begin(SpriteSortMode.Immediate, Multiply);
spriteBatch.Draw(lightmap, new Rectangle(offsetX, offsetY, width, height), Color.White);
spriteBatch.End();
</code></pre>

<p>This will multiply the destination color (unlit tiles) by the source color (lightmap), appropriately darkening unlit tiles, and creating a gradient effect as a result of the lightmap texture being scaled up to the necessary size.</p>
","56502"
"How can a game handle all characters at once?","10370","","<p>This question is just to gain knowledge about how a game can handle so many characters at once. I am new to gaming so I beg your pardon in advance.</p>

<h2>Example</h2>

<p>I am creating a tower defense game in which there are <strong>15 tower slots</strong> where towers are built and each tower ejects projectile at a certain rate; lets say that <strong>every second, 2 projectiles</strong> are created by each of the towers and there are <strong>enemies marching on the battlefield, lets say 70</strong> (each with 10 types of attributes like HP, mana, etc., which will change as they move around the battlefield). </p>

<h2>Summary</h2>

<p><strong>Tower Count</strong> = 15<br>
<strong>Projectiles Created By Each Tower Per Second</strong> = 2<br>
<strong>Total Number of Projectiles Created Per Second</strong> = 30<br>
<strong>Units in Battlefield Count</strong> = 70<br></p>

<p>Now, does the game handle those <strong>30 projectiles and 70 units</strong> by handling them on <strong>100 different threads</strong> (which is too much for a PC) or <strong>1 thread that moves all of them, reduces their value, etc.</strong> (which will be kind of slow, I think)? </p>

<p>I do not have a clue about this so can anyone guide me on how this will work out?</p>
","<blockquote>
  <p>Now how does the game handle those 30 Projectile and 70 units by
  handling them on 100 different threads</p>
</blockquote>

<p>No, never do that. Never create a new thread per resource, this doesn't scale in networking, neither does it in updating entities. (Anyone remember the times when you had one thread for reading per socket in java?)</p>

<blockquote>
  <p>1 thread that moves all of them reduces their value etc?</p>
</blockquote>

<p>Yes, for starters, this is the way to go. The ""big engines"" split some work between threads, but this is not needed to start a simple game like a tower-defense game. There's probably even more work to do every tick which you'll also do in this one thread. Oh yeah, and the rendering of course.</p>

<blockquote>
  <p>(which will be kind of slow i think)</p>
</blockquote>

<p>Well... What is your definition of <em>slow</em>? For 100 entities, it shouldn't take more than half a millisecond, probably even less, depending on your code-quality and the language you're working with. And even if it takes two full milliseconds, it's still good enough to hit the 60 tps (ticks per seconds, not talking about frames in this case).</p>
","119897"
"Should I use an SQL database to store data in a desktop game?","10365","","<h3>Developing a Game Engine</h3>

<p>I am planning a computer game and its engine. There will be a 3 dimensional world with first person view and it will be single player for now. The programming language is C++ and it uses OpenGL.</p>

<h3>Data Centered Design Decision</h3>

<p>My design decision is to use a data centered architecture where there is a global <strong>event manager</strong> and a global <strong>data manager</strong>. There are many components like physics, input, sound, renderer, ai, ... Each component can trigger and listen to <strong>events</strong>. Moreover, each component can read, edit, create and remove <strong>data</strong>.</p>

<p>The question is about the data manager.</p>

<h3>Whether to Use a Relational Database</h3>

<p>Should I use a SQL Database, e.g. SQLite or MySQL, to store the game data? This contains virtually all game content like items, characters, inventories, ... Except of meshes and textures which are even more performance related, so I will keep them in memory.</p>

<p>Is a SQL database fast enough to use it for realtime reading and writing game informations, like the position of a moving character? I also need to care about cross-platform compatibility. Aside from keeping everything in memory, what alternatives do I have?</p>

<h3>Advantages Would Be</h3>

<p>The advantages of using a relational database like MySQL would be the data orientated structure which allows fast computation. I would not need objects for representing entities. I could easily query data of objects near the player needed for rendering. And I don't have to take care about data of objects far away. Moreover there would be no need for savegames since the hole game state is saved in the database. Last but not least, expanding the game to an online game would be relative easy because there already is a place where the hole game state is stored.</p>
","<p>An SQL database is not nearly fast enough to use for realtime reading and writing game information. Such data is almost always kept in memory, in traditional data structures. </p>

<p>There may be some benefit to using an embedded database such as SQLite for certain types of data, eg. static data that doesn't change during gameplay but does change during development. This could then be deployed as part of the final game where SQLite is only really used when loading up the game for the first time, or when starting a new level, etc.</p>

<p>However there are many downsides too - it is hard to patch individual parts of the data when they're stored in a single database file, it is not ideal for many types of complex data that games need (and which you said you'd store outside - but will have references to and from things inside), it is not very flexible when you need to change the schema, it is not necessarily backwards compatible after you change the schema, etc.</p>

<p>For these reasons, most game developers will just use their own format. Professional developers who are performance conscious sometimes go one step further and save the in-memory data structure directly to disk so that it can be loaded in with a minimum of processing.</p>

<p>And if you really need text-based tabular data that is easily edited, you could use a simple text based format, such as CSV, XML, JSON, YAML, etc.</p>
","40218"
"How to handle a Block World like Minecraft","10364","","<p>I want to write a simple game with a block world like in Minecraft. My theoretical question is what is the best way to handle this block informations during playing. My first Idea was a huge array but this will cause running out of memory I think. Maybe I have to only load the blocks near the player.</p>

<p>How can I handle the loading of needed block informations from a file and the holding only of needed ones in memory?</p>
","<p>There are a couple different ways to store the data for a game with blocks like Minecraft.</p>

<p>The way I believe Minecraft does it is breaks the world up in the 16x16x256 Chunks. The chunks around the player are loaded into memory when the player starts the game, then a background thread loads more as you walk around. Here is a video that shows it: <a href=""http://www.youtube.com/watch?v=oR_ZdJH9eho"" rel=""nofollow"">http://www.youtube.com/watch?v=oR_ZdJH9eho</a>.</p>

<p>Another way to do it is to break the world up into an Octree. Michael Goodfellow wrote a blog about implementing a cube world with this data structure: <a href=""http://www.sea-of-memes.com/LetsCode1/LetsCode1.html"" rel=""nofollow"">http://www.sea-of-memes.com/LetsCode1/LetsCode1.html</a>. The Octree is nice because it gives you some built in compression, but it will probably be a little harder to work with then an Array.</p>

<p>About keeping the ""only needed ones in memory?"" This is a little harder since you have to ask what is ""needed"". If you have NPCs that live in another part of the world with AI that interacts with the environment then you ""need"" a lot more of the world to be in memory. Voxel world data can get very large very fast, so it is best to try to keep the least possible amount in memory. (IE, only have NPCs near the player). </p>

<p>The graphics engine will ""need"" every block not completely surrounded by other non-transparent blocks. The usual way to render the world is to build a single mesh that contains the vertices for every visible block. This is much faster to draw since you are only making 1 call to the draw methods for 65,536 blocks (in Minecraft size chunks). Since the graphics engine will need to build this mesh, it generally needs to know all the cubes in a chunk. Note that this is why when you see through the floor in Minecraft, a lot of the world is invisible. This is because every block that is surrounded on all six sides is skipped. I believe Minecraft also reduces the number of vertices by combining horizontal sides of the same kind of texture into one box with the texture repeating.</p>

<p>My advice would be to go with the 16x16x256 chunks. Store them in an Array since you will need fast iteration and editing due to building the mesh and game logic (collision detection, adding/removing blocks, ect). Then load as many chunks in a circle around the player as you can. Scale the number of chunks up or down for better or worse computers.</p>

<p>The loading of Chunks will be a huge hit on performance, so put it in a thread that runs it over time. Make it so you can completely load 3 new Chunks during the time it takes a player to walk from one end of a chunk to the other.</p>
","32933"
"How do I find the angle between two vectors?","10360","","<p>I have 3 points on my screen:</p>

<pre><code>a = a point which is (c.x, 0) makes a line pointing straight up
b = a user input touch, can be anywhere on the screen
c = a moving object

       a
_______.________
|      |       |
|      |       | 
|   b  |       |
|  .   |       |
|   \  |       |
|    \ |       | 
|     \|       |
|      | c     |
|______._______|
</code></pre>

<p>I have drawn some lines so that you can see the vectors.</p>

<p>I want to be able to get the angle between a and b. I have tried this, but it doesn't work, does anyone know what I'm doing wrong?:</p>

<pre><code>//v1 moving object
float boxX = this.mScene.getLastChild().getX(); 
float boxY = this.mScene.getLastChild().getY();

//v2 user touch
float touchX = pSceneTouchEvent.getX();
float touchY = pSceneTouchEvent.getY();     

//v3 top of screen
float topX = boxX;
final float topY = 0;

float dotProd = (touchX * topX) + (touchY * topY);

float sqrtBox = (touchX * touchX) + (touchY * touchY);
float sqrtTouch = (topX * topX) + (topY * topY);

double totalSqrt = sqrtBox * sqrtTouch;
double theta = Math.acos(dotProd / Math.sqrt(totalSqrt));
</code></pre>

<p>The answer I usually get is between 0 and 1.
How do I fix this so that I get the angle in degrees?</p>
","<p>You are looking for the wondrous <a href=""http://en.wikipedia.org/wiki/Atan2"">atan2</a>.</p>

<pre><code>// v1 moving object
float boxX = this.mScene.getLastChild().getX(); 
float boxY = this.mScene.getLastChild().getY();

// v2 user touch
float touchX = pSceneTouchEvent.getX();
float touchY = pSceneTouchEvent.getY();     

double theta = 180.0 / Math.PI * Math.atan2(boxX - touchX, touchY - boxY);
</code></pre>

<p>Normally it is used as <code>atan2(y,x)</code> but since you are looking for the angle with the vertical line, you need to use <code>atan2(-x,y)</code> instead.</p>
","28144"
"Is there a good cross-platform C++ vector graphics library out there?","10358","","<p>I'm making a game and want to use vector graphics. I started re-coding it using Cairo and the performance is horrific. So, I'm looking for a different library. It needs to be for C++ and cross-platform (e.g. no Direct2D). There's another question someone asked before like this, but there weren't any suitable answers. There's got to be something...?</p>
","<p>I fear the subject is quite tricky, few multi platform solutions seem to have launched, and even fewer seem to have survived on their own. I was looking into the subject a few months ago. I had a constraint as I needed the engine to run on iOS and Android. Didn't find anything that suited me really at the time.</p>

<p>But a few pointers from what I remember: each GUI system has some form of drawing API. So you might find something of interest within the ones that are cross platform like <a href=""http://doc.qt.nokia.com/4.7-snapshot/paintsystem-drawing.html"">QT</a>.</p>

<p>An equivalent of cairo would be <a href=""http://www.antigrain.com/"">AntiGrain</a> You might want to compare the performance.</p>

<p><a href=""http://www.openframeworks.cc/"">OpenFrameworks</a> has support for vector graphics.</p>

<p>A very big library which has some vector graphics support - and a language dedicated to it - is <a href=""http://www.imagemagick.org/script/magick-vector-graphics.php"">ImageMagick</a>.</p>

<p>Lower level you'll find <a href=""http://www.gnu.org/software/libxmi/libxmi.html"">Libxmi</a> and <a href=""http://www.levien.com/libart/"">Libart</a> from the gnome project.</p>

<p>Not a high level API - and I'm not sure what are the odds it will suit you - but there is the standard <a href=""http://www.khronos.org/openvg/"" title=""OpenVG"">OpenVG</a>. There are multiple ports of OpenVG over software OpenGL and OpenGL ES renderers. Mesa 3D also seems to have an OpenVG implementation. But for some platforms only commercial solutions will be available.</p>

<p>There are way higher level libraries which integrate APIs for vector graphics. Among these there is an open source one named <a href=""http://www.clutter-project.org/"">Clutter</a> for GUI design and used in serious game design there is <a href=""http://www.scaleform.com/"">scaleform</a> (Not Open Source).
This game engine has some functions to draw vector graphics: <a href=""http://2dengine.com/"">2DEngine</a></p>

<hr>

<p><strong>EDIT</strong>: clutter uses cairo apparently.</p>
","18798"
"What is the purpose of the stencil buffer ? More precisely, what is a stencil in computer graphics?","10325","","<p>I read the stencil word a lot, and I don't have a clue what is its real purpose in computer graphics.</p>

<p>Seeing the picture in black and white on wikipedia, I'm still having problem with it.</p>

<p>Why do we use a stencil or a stencil buffer, and what is the difference with a Z-buffer ? Why using this word which seems to have some meaning in graphic design ?</p>
","<p>In its original incarnation, a stencil buffer was a one-bit-per-pixel (i.e. black or white, but no grays) framebuffer. You could render to it whatever you wanted like any other framebuffer. Then, later, you could use the contents of that buffer to ""stencil"" or mask out when drawing to your regular buffer.</p>

<p>An example: Let's say you're making a driving game. You want to have a little rear-view mirror onscreen that shows you what's behind the car. You'll need to render a view pointing behind the car, but you only want to render that within the little rounded rectangle of the rear-view mirror. The typical solution is:</p>

<ol>
<li>Render the rounded rectangle shape to the stencil buffer.</li>
<li>Enable stencilling.</li>
<li>Render the backwards pointing view onto the regular buffer.</li>
</ol>

<p>The stencil will then mask it out so that you only draw into the shape of the mirror.</p>

<p>Now that render pipelines are much more flexible and programmable, stencil buffers are used as just a generic 1-bit framebuffer that you can do whatever you want with. Shadows are a common use case.</p>
","3772"
"League of Legends Spectator Stream Format","10320","","<h1>Intro</h1>

<p>I have been fiddling around with the spectator system for LoL in hopes of eventually scraping data from the streams and building a dataset with it for analysis.  I understand that there are already some unofficial APIs and techniques, but I am looking for really specific game events (champion kills, turret kills, item puchases, jungle mob kills, champion co-ords for particular events, etc).</p>

<h1>What I have figured out so far</h1>

<p>When you begin spectating a game (in NA), your client connects to the following host:</p>

<p><em>spectator.na.lol.riotgames.com:8088</em></p>

<p>I assume this host is backed by Amazon AWS or similar.  Anyways, the next thing that happens is the client sends a version request to the spectate server:</p>

<p><em>GET /observer-mode/rest/consumer/version</em></p>

<p>This returns whatever the current spectator server version is. Ex: '1.80.54'</p>

<p>Next, the client sends a request for the game metadata:</p>

<p><em>GET /observer-mode/rest/consumer/getGameMetaData/NA1/[gameid]/[some random nonce]/token</em></p>

<p>This returns metadata about the game. An example of this data: <a href=""http://pastebin.com/3N4qs0hx"">http://pastebin.com/3N4qs0hx</a></p>

<p>The client now knows the parameters by which the spectate session should progress. It tries to locate the latest data chunk by calling:</p>

<p><em>GET /observer-mode/rest/consumer/getLastChunkInfo/NA1/[gameid]/30000/token</em></p>

<p>Sample of this data: <a href=""http://pastebin.com/Cj7dEAr9"">http://pastebin.com/Cj7dEAr9</a></p>

<p>Once the data chunks have been identified, they are requested:</p>

<p><em>GET /observer-mode/rest/consumer/getGameDataChunk/NA1/[gameid]/[token#]/token</em></p>

<p>Sample of a token's data (binary converted to hex): http:// pastebin.com /GyqPRP5J</p>

<p>The game cycles between calling getLastChunkInfo and getGameDataChunk as data becomes available from the replay stream. There is also a call which occurs after about 5 chunks are grabbed to the following:</p>

<p><em>GET /observer-mode/rest/consumer/getKeyFrame/NA1/[gameid]/[somechunkid]/token</em></p>

<p>I believe this call only occurs at the replay start up and whenever the user seeks to a different time.</p>

<p>I know the game uses encryption at some level. I believe it to be Blowfish ECB, with the actual key specified on the command line. I have attempted to decrypt these tokens using the session's key, but they still look pretty random.</p>

<h1>Edit 3/23/2013</h1>

<ul>
<li>I have determined that the tokens are most likely not encrypted by modifying the command line argument containing the key and re-launching the game from debugger (it loaded the replay correctly).</li>
<li><p>The tokens seem to be compressed. There is a call to a subroutine which if returns non-zero integer will trigger the following:</p>

<pre><code>if ( sub_B71120(v21, v15, (int *)&amp;Size, *(_DWORD *)(v6 + 108)) )
{
sub_BAD700(
(int)""!\""Error Decompressing data chunk.\"""",
(int)""D:\\jenkins\\workspace\\Code-CI-Releases-Public\\code\\HeroWars_clientServer\\Sources\\ReplaySystem\\ReplayServerConnection.cpp"",
6,
(int)""Riot::Replay::ReplayServerConnection::GetChunk"",
(int)""Assert occurred, game may crash."");
sub_9BB750(""ReplayServerConnection GetChunk error. Error decompressing chunk data. Error: %d\n"");
}
</code></pre></li>
<li><p>Upon investigation of sub_B71120 I have located a call which eventually enters a fairly large function. This function contains strings like:</p>

<ul>
<li>""incorrect header check""</li>
<li>""unknown compression method""</li>
<li>""invalid window size"" </li>
</ul></li>
<li><p>A quick Google search of these strings reveals the following: 
<a href=""http://www.opensource.apple.com/source/zlib/zlib-22/zlib/inflate.c"">http://www.opensource.apple.com/source/zlib/zlib-22/zlib/inflate.c</a></p></li>
<li><p>I have also found the string reference ""1.2.3"" in a function call just before the call to inflate.c method, as well as another reference ""inflate 1.2.3 Copyright 1995-2005 Mark Adler"". It definitely looks like they are using Zlib version 1.2.3 for the decompression of the tokens. I just can't get them to decompress regardless of what file offset I start at.</p></li>
</ul>

<h1>My question(s)</h1>

<p>Does anyone know how these 'tokens' might be formatted or if there is some type of compression/encryption I am unaware of? I have a suspicion that they are some compressed or packed form of the ethernet packets used during live play which are simply played back internally to the client.</p>

<p>Alternatively, can anyone think of some other method by which to scrape this data without running the actual game client? Keep in mind I would like to grab data from many streams simultaneously.</p>
","<p>I've been researching the same thing and I found <a href=""https://github.com/robertabcd/lol-ob"">this repo</a> to be extremely helpful. The file decrypt.rb decrypts both chunks and keyframes.</p>

<p>Edit: check out <a href=""http://www.reddit.com/r/ReverseEngineering/comments/19fqm9/decoding_binary_files/"">this reddit thread</a> too.</p>
","51610"
"How to determine the point of intersection of two lines?","10304","","<p>I have two lines say P1( 0, -1, 0, -1 ) and P2( -1, 0, 0, -1 ). Since I'm working in 2D, there is no Z component. The x,y,z components are normals and the w component is the distance from origin. I am not given the origin or any points on the line.</p>

<p>What method should I use to programmatically determine the point of intersection for these two lines?</p>
","<p>This <em>is</em> a plane intersection problem.  You have two plane definitions in the point-normal form.  The normal is given, and the point is the distance value <code>w</code> multiplied by the normal.  </p>

<p><a href=""http://en.wikipedia.org/wiki/Plane_%28mathematics%29#Definition_with_a_point_and_a_normal_vector"" rel=""nofollow"">Wikipedia says</a>:  </p>

<blockquote>
  <p>a point <code>P</code> with position vector <code>r</code> is in the plane if and only if the vector drawn from <code>P_0</code> to <code>P</code> is perpendicular to (normal vector) <code>n</code>. </p>
</blockquote>

<p>(<code>P_0</code> is your plane's point, <code>n</code> is its normal)</p>

<p>If two vectors are perpendicular, their dot product is zero.  Your solution is point <code>P</code>.  So you have this equation twice, once for each plane:  </p>

<pre><code>n.x * (P.x - P_0.x) + n.y * (P.y - P_0.y) + n.z * (P.z - P_0.z) = 0;
</code></pre>

<p>So that leaves you with 3 unknowns and two equations.  But lucky you, you happen to know that <code>P.z</code> is zero.  Solve the remaining portion of the <a href=""http://en.wikipedia.org/wiki/System_of_linear_equations"" rel=""nofollow"">system of equations</a> and you are done.   </p>
","63314"
"Why not pre-render story parts in a game?","10293","","<p>When playing games nowadays there are often story related cut-scenes, during which you cannot interact with the game, you can only listen to it or watch it while it plays.</p>

<p>However in a lot of games these story scenes are rendered live with the game engine, and not with pre-rendered videos. I can't seem to understand why the story scenes aren't pre-rendered during game development</p>

<p>My question is: </p>

<p>Why not pre-render a story cut-scene during game development as a video with the highest settings so the user doesn't need to render it on his/her end?</p>

<p>My guess is that game developers don't choose to do this because videos and real-time game rendering need a smooth transition a lot.</p>
","<p>I can think of a couple of reasons:</p>

<ul>
<li>Pre-rendering and recording the video cost a LOT more space on the disk that animating it live with bone animations. </li>
<li>Visual aspects. If you pre-rendered half of what you see in the game with ""better"" quality, the transition could make the game lose its flow. I can image following the main character of a game which is rendered with 1000 polygons during normal game play, but suddenly seeing him rendered with 2000 polygons, nice skin smoothing and 25 shader effects, this for two minutes then jump back with the low-res character... this would look odd. </li>
<li>Internal approbation/modification process. I would guess that the pipeline to simply modify an animation for a cut scene from within a game company is much simpler than modifying the original asset of the animation, render it and make have it approved. </li>
<li>No need for it (or 'because they can'). Game engines and hardware are getting more and more sophisticated and powerful, so the quality of what they produce is getting closer to cinema quality graphics, so since the end user machine can do it, why bother doing pre-rendering?</li>
<li>Flow. As you suggested, unless you push your engine to do that, there could be a small loading time before showing a video, whereas a transition to a cut-scene imply loading a smaller amount of data and a small game state transition.</li>
</ul>

<p>Suggested from the comments:</p>

<ul>
<li><p>Cost. Using a software with its architecture that optimize the pre-rendered scenes (such as Rad Game Tool's ""Bink Video"") can be costly to licence and implement. (Thanks @Honeybunch)</p></li>
<li><p>Customization. If the player can change their character's appearance, equipment, or party composition, then either these choices are not reflected in the pre-rendered sections (e.g. a canonical character/loadout/party is always shown) or a number of pre-rendered videos are required to cover all possible combinations (which quickly becomes impractical if the player has many choices). (@DMGregory &amp; @Kevin)</p></li>
</ul>
","111179"
"How to fight against memory editing cheat software?","10293","","<p>What is the best way to protect run-time memory from such software?</p>

<p>We just published an online game (written on AS3, Flash, published on a social network), and pretty much all of the players got <code>max_int</code> money just using a simple memory editor (""ArtMoney"").</p>
","<p>Simple ways to protect your game:</p>

<ul>
<li>Duplicate your data: store some information twice and compare the copies. If they are different, something is going wrong. You don't have to do it per variable, you can also make CRC's on some big areas of memory (ex: on a struct that contains all player information).</li>
<li>Encrypt your data before its written to memory (and unencrypt after reading). A simple xor could be effective. This will make finding the addresses of some interesting variables a LOT harder.</li>
<li>Never declare sensitive data ""static"" (with a fixed memory address) but rather use pointers. If someone find the address of interesting variable, the address will change next time process is run, making it harder to create a trainer (but not impossible).</li>
</ul>

<p>In some professional games (like GTA IV), the game is split in two parts:</p>

<ul>
<li>One main process for rendering, input and processing game logic, which is unprotected (like most games).</li>
<li>Another process that keep sensitive data (ex: player health, money, weapons, ...). This process has several protections against cheating (memory regions are readonly, data is encryted and so on). It's not possible to modify these values directly by writing in them, but only by using a set of functions that the process provide. These functions are only available after you have been authenticated using a set of keys/challenges. I guess other sensitive stuff like load/save savegames is also done here.</li>
</ul>

<p>I guess this has some costs. Every modification of game data require some interprocess communication and some other checks (instead of a single read/write to memory).</p>

<p>However, all protections can be defeated: someone could disassemble your game to figure out exactly where and how data is stored. Or even better, modify the .exe himself to directly remove the protections. Anyway, I think using what I described above will stop most cheaters.</p>

<hr>

<p>EDIT: </p>

<p>If it's a Flash game, you can regularly send some game events to a server (eg: ""+50 points at frame 41, lose one life at frame 1231""). Then analyze these events and some statistics (eg: total seconds the game was played, number of player actions (mouse moves, key presses)) and compare to the submitted score to see if it appears to be possible...</p>
","23802"
"What's the difference between UnityEngine.Random and System.Random?","10288","","<p>What's the different between this</p>

<pre><code>int randomNumber = UnityEngine.Random.Range(0, 10);
</code></pre>

<p>and this</p>

<pre><code>// on top of the class
private System.Random _rnd = new System.Random();

// inside a methode of the same class
int randomNumber = _rnd.Next(0, 10);
</code></pre>

<p>I know <code>System.Random</code> must always be initialized on the top of your class what's by <code>UnityEngine.Random</code> is not needed. I know also that <code>System.Random</code> works with a intern ""clock"" and the ""random"" number is based on that.</p>

<p>My question is now are there some other difference between <code>UnityEngine.Random</code> and <code>System.Random</code> and witch code is better to use for an Unity project?</p>
","<p>Arguably the most important difference is that Unity's <code>Random.Range</code> is slightly easier to use, being static. The C# base class library <code>System.Random</code>, however, offers you more <em>control</em> and isolation.</p>

<p>It's possible they also use different under-the-hood implementations (although my guess would be that Unity's <code>Random</code> is just implemented in terms of the system <code>Random</code>), but that's probably not a notable concern. Fundamentally they're both likely the same <em>kind</em> of random number generator: a pseudo-random generator based on iterating a sequence defined by some seed).</p>

<p>The control issue is more relevant, because in some contexts you may want to use different random streams for different things. For example, in a lock-step networking networking context, you may want to fix the seed used to generate random gameplay-affecting events across all players in the game, but you may not care so much about the stream of random numbers used for purely visual events and can allow that stream to be seeded in a more traditional fashion (with the system uptime at game launch, for example).</p>

<p>Similarly, if you are going to be generating random numbers in multiple threads you may want to use distinct random objects for each thread in order to prevent race conditions. This may come up if your game logic runs across many threads and you also have a gameplay replay system, for example.</p>

<p>In the end, it's not necessarily <em>better</em> to use one or the other in general, rather there are pros and cons. When you need to isolate the sequence of numbers from other potential random sequences that may be happening, or when you need localized control over the seed of the sequence, use an instance of <code>System.Random</code>. If you just need a quick-and-dirty random value for a throw-away use or some other non-impactful scenario, Unity's simplified <code>Random</code> is probably fine.</p>
","114266"
"How do dialog trees work?","10241","","<p>That is, what is connected to what and how to move between lines of speech when a sub-conversation ends?</p>

<p>If you have any examples of a basic dialog tree in C#, please post them.</p>
","<p>The name ""dialogue tree"" is a bit misleading - they usually are <a href=""http://en.wikipedia.org/wiki/Directed_graph"">simple directed graphs</a>, not just <a href=""http://en.wikipedia.org/wiki/Tree_data_structure"">trees</a>. The basic data structure of such graphs usually consists of some kind of ""data"" for the nodes, which represent the points we are at in the conversation, and links from them to other nodes, which represent what is being said and done by the participants and optionally have conditions on them to limit their visibility or scripts to perform various additional actions. Usually one of the nodes is the default starting node (typical labels for that are ""ROOT"", ""START"" and ""GREETING""), and nodes which have no valid links leading from them end the conversation.</p>

<p>In most cases, the graph is represented in-memory as a list of <code>Node</code> data structures, each having at least an ID and a list of 0..n <code>Link</code> data structures. The list can be local to the NPC or a global one; the second case is preferred if you have lots of generic NPCs which can be talked to for information, but offer no specific conversations on their own. The system itself finds the starting conversation node for the NPC, remembers its ID as the current conversation ID, presents the currently valid links for the player to chose from (or ""[end conversation]"" if there are no valid links) and waits for input. When the player chooses a link, the associated dialogue lines get displayed and any associated scripts run.</p>

<p>Instead of having complex rules and conditions on links, you can instead get by with a simple ""valid"" boolean variable, which can be then changed from either the scripts of other conversation links (including the default one from the starting node) or by outside mechanisms. In general, this approach is simpler but only suitable for games with very few such conversations, since it moves the logic of ""When is this response possible?"" <em>away</em> from the response data itself.</p>

<hr>

<p>Note that the structure I describe here is slightly different from Byte56's in that the nodes don't need to have any dialogue lines; the links can have them all. In the most basic variant, this translates to the following structure.</p>

<p><img src=""https://i.stack.imgur.com/nugx3.png"" alt=""enter image description here""></p>
","40524"
"Creating a simple 2d engine (C++), best way to create an Sprite class?","10239","","<p>Since MS announced that they are not give more support to XNA , for me was an opportunity to start to learn DirectX , so i wanted to learn DX11,
i was following this tutorials </p>

<p><a href=""http://www.rastertek.com/tutdx11.html"" rel=""nofollow"">http://www.rastertek.com/tutdx11.html</a></p>

<p>i want to build a simple 2D engine while im learning with basic thing,like render an sprite based on a spritesheet, ,animate it, scale, rotation, flip image</p>

<p>I started creating some simple basic structure, </p>

<ul>
<li>Engine Class, this hold the initialization of the Window basically</li>
<li>RenderManager class, this hold all the DX stuff, initialize it, create the swapchain, store the device , etc</li>
</ul>

<p>So now my next step is create the Sprite class , i wanted to create an method called ""Quad2D"" inside my RenderManager, so i can use it on my render method in my sprite class</p>

<pre><code>//This is not actual code, is just oh i want to approach this
class Sprite{

public void Render(RenderManager *rm){

    rm-&gt;Quad2D(Texture,Position,Width,Height);

}
}
</code></pre>

<p>i have some experience with OpenGL and Directx9 and with those, it was easy to approach this, i just needed to create an Array with the vertices, send to the VertexBuffer, bind the Texture, and done</p>

<p>but because now DX10 and DX11 not used fixed pipeline, and you need create this with more advanced stuff (Shaders)</p>

<p>i stopped in here <a href=""http://www.rastertek.com/dx11tut11.html"" rel=""nofollow"">http://www.rastertek.com/dx11tut11.html</a> , i can see how to render the image and everything, but i was thinking, do i need to create an separate Class just to render a Quad? if so, is this going to compile the shader everytime is used?, well one solution maybe is just declare an static atribute for the ps and vs and it will shared the same compiled shader within the instances</p>

<p>so i would like to hear how do you manage your Sprite class? </p>

<p>if is it necessary, i can attach my source code, but it doesnt has too much, just open a window</p>

<p>Note: i want to know how to do it in DX11, please dont reply, (used DX9,OpenGL,DX10, etc..)</p>
","<p>I based a good deal of my Engine from the Rastertek tutorials too.
For the shaders, I don't see why you'd need to compile them for each Quad...
My solution was to store the shader in a Graphics class, and pass the information into the render function of the shader.</p>

<p>This is my layout (Sorry for the length of this, I'll try to trim out lots.)</p>

<pre><code>bool TextureShader::render(ID3D11DeviceContext* deviceContext, int indexCount, const     XMMATRIX&amp; worldMatrix, const XMMATRIX&amp; viewMatrix, 
                                               const XMMATRIX&amp; projectionMatrix, VEngine::Graphics::DirectX11::Material* material)
{
    bool result;


    // Set the shader parameters that it will use for rendering.
    result = setShaderParameters(deviceContext, worldMatrix, viewMatrix, projectionMatrix, material);
    if(!result)     
            return false;   

    // Now render the prepared buffers with the shader.
    renderShader(deviceContext, indexCount);

    return true;
}

bool TextureShader::setShaderParameters(ID3D11DeviceContext* deviceContext, const      XMMATRIX&amp; worldMatrix, 
                                       const XMMATRIX&amp; viewMatrix, const XMMATRIX&amp; projectionMatrix, ID3D11ShaderResourceView* texture)
{
    HRESULT result;
    D3D11_MAPPED_SUBRESOURCE mappedResource;
    MatrixBuffer* dataPtr;
    unsigned int bufferNumber;

    // Transpose the matrices to prepare them for the shader.
    XMMATRIX tWorldMatrix(XMMatrixTranspose(worldMatrix));
    XMMATRIX tViewMatrix(XMMatrixTranspose(viewMatrix));
    XMMATRIX tProjectionMatrix(XMMatrixTranspose(projectionMatrix));

    // Lock the constant buffer so it can be written to.
    result = deviceContext-&gt;Map(_matrixBuffer, 0, D3D11_MAP_WRITE_DISCARD, 0, &amp;mappedResource);
    if(FAILED(result))
    {
            return false;
    }

    // Get a pointer to the data in the constant buffer.
    dataPtr = (MatrixBuffer*)mappedResource.pData;

    // Copy the matrices into the constant buffer.
    dataPtr-&gt;world = tWorldMatrix;
    dataPtr-&gt;view = tViewMatrix;
    dataPtr-&gt;projection = tProjectionMatrix;

    // Unlock the constant buffer.
    deviceContext-&gt;Unmap(_matrixBuffer, 0);

    // Set the position of the constant buffer in the vertex shader.
    bufferNumber = 0;

    // Finanly set the constant buffer in the vertex shader with the updated values.
    deviceContext-&gt;VSSetConstantBuffers(bufferNumber, 1, &amp;_matrixBuffer);

    deviceContext-&gt;PSSetShaderResources(0, 1, &amp;texture);

    return true;
}
</code></pre>

<p>And, for the Graphics class which calls it.</p>

<pre><code>bool DX11::render()
{
    XMMATRIX viewMatrix;    

    cleanRenderQueues();

    // Generate the view matrix based on the camera's position.
    _camera-&gt;render();

    // Get the world, view, and projection matrices from the camera and d3d objects.
    viewMatrix = _camera-&gt;getViewMatrix();

    XMMATRIX projectionMatrix = getProjectionMatrix();

    XMMATRIX orthoMatrix = getOrthoMatrix();
    bool result;

    disableZBuffer();
    enableAlphaBlending();
    for(unsigned int i(0); i &lt; _renderQueue2d.size(); i++)
    {
            XMMATRIX worldMatrix = getWorldMatrix();

            _renderQueue2d[i]-&gt;render(_deviceContext);
            result = _textureShader-&gt;render(_deviceContext, _renderQueue2d[i]-&gt;getIndexCount(), worldMatrix, viewMatrix, orthoMatrix,
                    _renderQueue2d[i]-&gt;getTexture());
            if(!result)     
                    return false;
    }

//...More here for 3d

    return true;
}
</code></pre>

<p>As you mentioned, I've created a Sprite class, which contains a simple Quad, and a texture that I pass through to the shader.</p>

<p>Sprite class is essentially this (Update buffers is pretty much identical to the one in the Rastertek tutorials. Ignore the namespaces and the interface.</p>

<p>Header</p>

<pre><code>/*--------------------
----INCLUDES
----------------------*/
#include &lt;d3d11.h&gt;
#include &lt;xnamath.h&gt;

/*--------------------
----MY INCLUDES
----------------------*/
#include ""Texture.h""
#include ""../IBitmap.h""

namespace VEngine
{
    namespace Graphics
    {
            namespace DirectX11
            {
                    class Bitmap : public IBitmap
                    {
                    private:
                            struct VertexType
                            {
                                    XMFLOAT3 position;
                                    XMFLOAT2 texture;
                            };

                    public:
                            Bitmap();
                            Bitmap(const Bitmap&amp;);
                            ~Bitmap();

                            bool initialise(ID3D11Device*, int, int, const char*, int, int);
                            void shutdown();
                            bool render(ID3D11DeviceContext*);

                            int getIndexCount();
                            ID3D11ShaderResourceView* getTexture();

                            std::array&lt;int, 2&gt; getPosition();
                            std::array&lt;float, 2&gt; getRotation();
                            void setPosition(const int&amp;, const int&amp;);
                            void setRotation(const float&amp;, const float&amp;);
                            void setImageWidth(const int&amp;);
                            int getImageWidth();
                            void setImageHeight(const int&amp;);
                            int getImageHeight();

                            void setTextureFile(const char*);

                    private: //functions
                            bool initialiseBuffers(ID3D11Device*);
                            void shutdownBuffers();
                            bool updateBuffers(ID3D11DeviceContext*);
                            void renderBuffers(ID3D11DeviceContext*);

                            bool loadTexture(ID3D11Device*, const char*);
                            void releaseTexture();

                            bool createVertexBuffer(ID3D11Device* device, VertexType* vertices);
                            bool createIndexBuffer(ID3D11Device* device, unsigned long* indices);

                    private: // variables
                            ID3D11Device* _device;
                            ID3D11Buffer* _vertexBuffer;
                            ID3D11Buffer* _indexBuffer;
                            Texture* _texture;
                            int _vertexCount;
                            int _indexCount;

                            int _screenWidth;
                            int _screenHeight;
                            int _bitmapWidth;
                            int _bitmapHeight;

                            int _x;
                            int _y;
                            XMFLOAT2 _rotation;
                            int _previousPosX;
                            int _previousPosY;
                    };
            }
    }
}
</code></pre>

<p>Implementation</p>

<pre><code>bool Bitmap::render(ID3D11DeviceContext* deviceContext)
{
    bool result;
    result = updateBuffers(deviceContext);
    if(!result)     
            return false;

    renderBuffers(deviceContext);

    return true;
}

void Bitmap::renderBuffers(ID3D11DeviceContext* deviceContext)
{
    unsigned int stride;
    unsigned int offset;

    stride = sizeof(VertexType); 
    offset = 0;
    deviceContext-&gt;IASetVertexBuffers(0, 1, &amp;_vertexBuffer, &amp;stride, &amp;offset);

    deviceContext-&gt;IASetIndexBuffer(_indexBuffer, DXGI_FORMAT_R32_UINT, 0);

    deviceContext-&gt;IASetPrimitiveTopology(D3D11_PRIMITIVE_TOPOLOGY_TRIANGLELIST);

    return;
 }
</code></pre>

<p>I'd recommend going through the Rastertek in order. There are a few issues I have with the tutorial, and I've drifted away from quite a bit of it's architecture in my newer builds, but they're incredibly useful.</p>
","51104"
"What's the 'proper' way to get unit vectors?","10229","","<p>My apologies if I've misunderstood the term 'unit vector' or misapplied it in concept, but I <em>think</em> that is the term for an object's heading when expressed as <code>[x, y]</code> when <code>x</code> and <code>y</code> are a value between -1 and 1; so if an object were moving 'south' on a computer screen, it would have a unit vector of</p>

<pre><code>[0, 1]
</code></pre>

<p>...right?</p>

<p>Anyway, I've been using this concept to move my objects and rotate their images (when needed), but I think the math I'm using to determine the unit vector is... suboptimal.</p>

<pre><code>def set_heading(self, goal):
    """"""Uses a 'goal' (x, y) to set the object's heading.
    Returns list of 0s and 1s for 'straight' headings.
    Diagonal headings are + and/or - math.sqrt(2)/2.
    """"""
    vals = [a - b for a, b in zip(goal, self.pos)]
    self.heading = [i / abs(i) if i != 0 else 0 for i in vals]
    if 0 not in self.heading:
        self.heading = [i * (sqrt(2)/2) for i in self.heading]
</code></pre>

<p><em>(If you're not familiar with Python ternary syntax, the second line contains <code>i / abs(i) if i != 0 else 0</code> which is Python's way of saying <code>x if Condition else y</code> as opposed to the usual <code>Condition? x : else y</code> syntax in other languages. Basically I'm just trying to avoid dividing by zero!)</em></p>

<p>So as you can see, this method of doing this sort of 'locks' the object into eight directions; if a 0 is not present in the heading, the method assumes that we're traveling diagonally and so multiplies the values by <code>sqrt(2) / 2</code> to ensure that the object doesn't travel faster than it should when moving diagonally.  In this way I can move the object by simply adding the result of the unit vector times its speed to its current x and y coordinates.</p>

<pre><code>def move(self):
    """"""Moves the object by changing self.pos.""""""
    self.pos = [a + (b * self.speed) for a, b in zip(self.pos, self.heading)]
</code></pre>

<p>I can't help but feel like the method for getting the unit vector (if that's what it's correctly called) is sophomoric. Especially since it is locked into eight directions - it's fine for the little project I'm working with currently, but I'm not sure of the right method for getting a more precise unit vector. What is the correct method for doing so - and is it more or less performant than the weirdness I have come up with independently?</p>
","<p>A <a href=""http://en.wikipedia.org/wiki/Unit_vector"" rel=""nofollow noreferrer"">Unit Vector</a> is of length 1.</p>

<p>A given vector can be converted to a unit vector by dividing it by it's magnitude. (With the exception of course that a zero length vector can not be converted).</p>

<p>Note that magnitude can be calculated using the <a href=""http://en.wikipedia.org/wiki/Pythagorean_theorem"" rel=""nofollow noreferrer"">Pythagorean theorem</a> </p>

<p>For example if a vector has components: (<code>x, y, z</code>)</p>

<p><code>magnitude  = sqrt( x</code><sup><code>2</code></sup><code>+ y</code><sup><code>2</code></sup><code>+ z</code><sup><code>2</code></sup><code>)</code></p>

<p><code>unit vector  = ( x / magnitude ,  y / magnitude,  z / magnitude )</code></p>

<hr>

<p><a href=""https://gamedev.stackexchange.com/questions/84203/whats-the-proper-way-to-get-unit-vectors/84205#comment240120_84205"">Annan</a> raises an interesting point that for vectors with a magnitude larger than <code>math.sqrt(sys.float_info.max)</code> (approximately  1.3e+154 on my machine) this will fail when using floats in the normal manner.  In this case a workaround using longs to hold the working values and then finding the square root manually will be functional but relatively slow.</p>

<pre class=""lang-py prettyprint-override""><code>def isqrt(n):
    x = n
    y = (x + 1) // 2
    while y &lt; x:
        x = y
        y = (x + n // x) // 2
    return x

def large_magnitude(x, y, z):
    long_magnitude_squared = pow(long(x), 2) + pow(long(y), 2) + pow(long(z), 2)
    return float(isqrt(long_magnitude_squared))
</code></pre>

<p>Credit for this implementation of <a href=""https://en.wikipedia.org/wiki/Newton%27s_method"" rel=""nofollow noreferrer"">Newton's Method</a> goes to <a href=""https://stackoverflow.com/questions/15390807/integer-square-root-in-python#15391420"">user448810</a>.</p>
","84205"
"shader tutorial for unity","10208","","<p>I would like to start developing my own shaders within unity. </p>

<p>For starters I would like to do a screen spaced blur. </p>

<p>Are there any good tutorials to learn shader development besides the official unity documentation, which i find a bit hard to understand?</p>
","<p>I think this is what you are looking for: <a href=""http://en.wikibooks.org/wiki/Cg_Programming/Unity"">http://en.wikibooks.org/wiki/Cg_Programming/Unity</a>.
The tutorials are organized in an increasing difficulty order and each was written with Unity in mind.</p>
","35930"
"A way to store potentially infinite 2D map data?","10202","","<p>I have a 2D platformer that currently can handle chunks with 100 by 100 tiles, with the chunk coordinates are stored as longs, so this is the only limit of maps (maxlong*maxlong).
All entity positions etc etc are chunk relevant and so there is no limit there.</p>

<p>The problem I'm having is how to store and access these chunks without having thousands of files. Any ideas for a preferably quick &amp; low HD cost archive format that doesn't need to open everything at once?</p>
","<p>Create a custom map format for your game. It's easier than you might think.
Just use the BinaryWriter class.
First write the header in a few ints or uints. Information to include in the header:</p>

<ul>
<li>The magic string / magic number of you file format.</li>
<li>The start/end/size of the chunks described in this file</li>
</ul>

<p>and also (and here comes the performance critical part</p>

<ul>
<li>ints that describe the starting position inside the file. So you don't have to search for specific chunks.</li>
</ul>

<p>With the above methode you can (and should) create an index of your files contents, containing some sort of description(a user specified name for the region/chunk, or just the coordinates) and as a second value the position in the file.</p>

<p>Then, when you want to load a specific chunk, you'll just have to search inside the index. When you got the position just set fileStream.Position = PositionOfChunkFromIndex
and you can load it.</p>

<p>It's all about the design of the fileformat with the header describing the contents of the file most efficiently.</p>

<p>Just save the files with a custom extension you made up and there you go.</p>

<p>BONUS: Add BZip2 compression to specific regions of the file / the whole contents (not the header!!), so you can unpack specific chunks from the file, for a very small memory footprint.</p>
","13355"
"Breakout Collision: Detecting the side of collision","10199","","<p>I am writing a breakout clone (my first game) and am totally stuck as to how I figure out which side of the brick was hit.</p>

<p>I have a collision detection method that looks like this:</p>

<pre><code>DetectCollision(Object a, Object b)

   x = distance(a.x, b.x);
   y = distance(a.y, b.y);

   if (x is smaller than the combined width &amp;  y is smaller is than combined height {
       return true;
   }
return false;  
</code></pre>

<p>This works totally fine, but I need to know the side of the collision, and location relative to the center in order to respond properly.</p>

<p>I've spent the past few days snooping around but am lost.</p>
","<p>This can all be gleaned from the position of the ball relative to the position of the brick it collided with.</p>

<p>Once you have detected a collision:</p>

<pre><code>if(ballPosition.y &lt;= brickPosition.y - (brickHeight/2))
  //Hit was from below the brick

if(ballPosition.y &gt;= brickPosition.y + (brickHeight/2))
  //Hit was from above the brick

if(ballPostion.x &lt; brickPosition.x)
  //Hit was on left

if(ballPostion.x &gt; brickPosition.x)
  //Hit was on right
</code></pre>

<p>The first two check to see if the ball is above or below the brick. If neither than it must be next to the brick, so check which side it's on.
This will need to be tweeked to fit where you're taking the location from, i.e. brickPosition is the center of the brick or brickPosition is the top left corner.</p>
","22612"
"Turn-based strategy games where action happens in real-time?","10172","","<p>Okay, this idea has come up for the 3rd time in conversation now, and it's been bugging me for years. The idea is a game where all players make decisions/issue orders to units while the game is in a paused state, and all the actions are executed at once, in real-time. This could be at any level from a TRPG (i.e. Final Fantasy Tactics), to a small-scale skirmish (i.e. Worms), to a game with bases and many units (i.e. Advance Wars), to a Risk-type game (i.e. Risk).</p>

<p>The main disadvantage to this I can see is that the player doesn't see the result of an action immediately. In a traditional turn-based or real-time strategy game, the user clicks ""attack that fool"" and there's an explosion straight away. There also might be weird situations (you send your unit to melee a unit running in the opposite direction, for example), but that's a low-level detail; a good game designer should be able to get around these things. Finally, there's the general paucity of turn-based games, but they offer a level of tactical depth impossible in real-time strategy games, and there's always a market for them (dozens of new TBSes appear each year).</p>

<ul>
<li>Are there any games out there that use this paradigm?</li>
<li>Why aren't there more?</li>
<li>What would be necessary to make this work?</li>
<li>What potential issues could you foresee?</li>
</ul>

<p>To clarify, I mean pure strategy. The commands are input beforehand, and the <em>resolution</em> is realtime, but it doesn't require realtime ""twitch"" input by players.</p>

<p><strong>EDIT:</strong> <a href=""https://gamedev.stackexchange.com/questions/2996/turn-based-strategy-games-where-action-happens-in-real-time/3001#3001"">Iain's answer</a> pointed me to <a href=""http://www.lasersquadnemesis.com/"" rel=""nofollow noreferrer"">Laser Squad Nemesis</a>, which basically answered the 2nd and 4th question ;-P -- If you want to know why this won't work, download the demo (It's 9MB) and click the first tutorial. OUCH! Of course, Laser Squad Nemesis's UI doesn't help (play and pause buttons? seriously? and why do I have to click ""issue orders"" every turn if that's the only thing I'm going to be doing?)</p>

<p>For simpler things (like the board games mentioned in a couple answers, or <a href=""http://zwok-game.com/en_GB/"" rel=""nofollow noreferrer"">Zwok</a> that Iain created), this paradigm works great! Issues seem to arise with a more traditional tactics/strategy game, because the lag between the entry of a command and the execution of the command is apparent. In fact Zwok - and some of the board games mentioned - work <em>because</em> off this lag, not in spite of it. You're encouraged to guess what your opponent will do next and ""think ahead"". However in a more traditional small-scale tactical strategy game, the frustration factor isn't worth it.</p>

<p>It might be interesting to see a game like this on a <em>really</em> large scale. For example, Lee and Napoleon didn't order their troops around in real-time, but rather made decisions based on information that was often hours old -- and it often took hours for those orders to get executed. Even today, generals don't have real-time top-down maps. But taking that ""frustration factor"" out would require some seriously deft game design.</p>
","<p>I first encountered this technique on a game called <a href=""http://www.lasersquadnemesis.com/"">Laser Squad Nemesis</a>. I always thought it was a great idea, and used it when I developed <a href=""http://zwok-game.com/en_GB/"">Zwok</a> for Sony. It allows Zwok to have 6 player multiplayer without ever having to wait in turn.</p>
","3001"
"GUI Library for MonoGame","10150","","<p>Is there any GuiLibrary available, which works with MonoGame? I know there are some GUI Libraries for XNA but I assume most will not work with MonoGame.</p>

<p>Even simple stuff like Buttons and Inputfields would help me...</p>

<p>Thanks.</p>
","<p>I asked myself the exact same question a few weeks ago. Unfortunately, I didn't find anything that suited my needs but what I did find might help.</p>

<p>Here are a few XNA GUI projects I've found that might be compatible with MonoGame. I'm not really sure which ones are better than others and I haven't really tried them, but I've collected a few options.</p>

<p>Sorry, I don't have enough rep to post hyperlinks.</p>

<p>xWinForms (<a href=""http://sourceforge.net/projects/xwinforms/"" rel=""nofollow"">sourceforge.net/projects/xwinforms/</a>)</p>

<p>XNA Simple GUI (<a href=""http://simplegui.codeplex.com"" rel=""nofollow"">simplegui.codeplex.com</a>)</p>

<p>Window System for XNA (<a href=""http://wsx.codeplex.com"" rel=""nofollow"">wsx.codeplex.com</a>)</p>

<p>Squid (<a href=""http://www.ionstar.org"" rel=""nofollow"">www.ionstar.org</a>)</p>

<p>Ruminate XNA 4.0 GUI (<a href=""http://xnagui.codeplex.com"" rel=""nofollow"">xnagui.codeplex.com</a>)</p>

<p>Nuclex Framework (<a href=""http://nuclexframework.codeplex.com"" rel=""nofollow"">nuclexframework.codeplex.com</a>)</p>

<p>CEGUI# (<a href=""http://sourceforge.net/projects/ceguisharp/"" rel=""nofollow"">sourceforge.net/projects/ceguisharp/</a>) a port of CEGUI (<a href=""http://www.cegui.org.uk"" rel=""nofollow"">http://www.cegui.org.uk</a>)</p>

<p>MQuickGUI (<a href=""http://www.ogre3d.org/tikiwiki/tiki-index.php?page=MQuickGUI"" rel=""nofollow"">www.ogre3d.org/tikiwiki/tiki-index.php?page=MQuickGUI</a>) made for the Ogre / Mogre engine but could be adapted to XNA.</p>

<p>Xpf by Red Badger (<a href=""http://red-badger.com/blog/2012/07/05/xpf-to-be-open-sourced/"" rel=""nofollow"">red-badger.com/blog/2012/07/05/xpf-to-be-open-sourced/</a>) - An implementation of WPF for mobile devices. It looks good but I can't see a way to download it. It was announced to be open sourced on 5 July 2012 but I don't think that has happened yet.</p>
","42164"
"How to draw a smooth circle in Android using OpenGL?","10142","","<p>I am learning about OpenGL API on Android. I just drew a circle. Below is the code I used.</p>

<pre><code>public class MyGLBall {

private int points=360;
private float vertices[]={0.0f,0.0f,0.0f};
private FloatBuffer vertBuff;


//centre of circle

public MyGLBall(){

    vertices=new float[(points+1)*3];
    for(int i=3;i&lt;(points+1)*3;i+=3){
      double rad=(i*360/points*3)*(3.14/180);
      vertices[i]=(float)Math.cos(rad);
      vertices[i+1]=(float) Math.sin(rad);
      vertices[i+2]=0;
    }     
      ByteBuffer bBuff=ByteBuffer.allocateDirect(vertices.length*4);    
      bBuff.order(ByteOrder.nativeOrder());
      vertBuff=bBuff.asFloatBuffer();
      vertBuff.put(vertices);
      vertBuff.position(0);


}

public void draw(GL10 gl){
    gl.glPushMatrix();
    gl.glTranslatef(0, 0, 0);
//  gl.glScalef(size, size, 1.0f);
    gl.glColor4f(1.0f,1.0f,1.0f, 1.0f); 
    gl.glVertexPointer(3, GL10.GL_FLOAT, 0, vertBuff);
    gl.glEnableClientState(GL10.GL_VERTEX_ARRAY);
    gl.glDrawArrays(GL10.GL_TRIANGLE_FAN, 0, points/2);
    gl.glDisableClientState(GL10.GL_VERTEX_ARRAY);
    gl.glPopMatrix();
 }  

 }
</code></pre>

<p>It is actually taken directly from <a href=""https://gamedev.stackexchange.com/questions/26232/drawing-a-circle-in-opengl-es-android-squiggly-boundaries"">here</a>
The circle looks pretty good. But now I want to make the boundary of the circle smooth. What changes do I need to make to the code? Or do I need to use some other technique for drawing the circle?</p>

<p>Thanks.</p>
","<p>With polygon-based graphics, the only option you have to better approximate a circle is to subdivide further. 720 triangles will result in a smoother circle, but 1440 will give you an even smoother circle, but 2880...</p>

<p>A perfect circle, created using polygons, would require an infinite amount of infinitesimally small polygon sections (in other words, it just isn't possible, in theory). Practically, however, if you subdivide enough times, you may reach a point where the length of the polygon section is equal to or smaller in size than a pixel, meaning that, for purposes of your framebuffer, you have achieved a ""perfect"" circle.</p>

<p>The other option, of course, is to cheat: render a flat quadrilateral oriented perpendicular to the camera, and texture it with an image of a sphere. 2 triangles, 1 texture of sufficient resolution: smooth circle, and a hell of a lot less vertices for your GPU to worry about.</p>
","47587"
"How to update libgdx scene2d Label text dynamically?","10134","","<p>I display a <code>BitmapFont</code> on the screen, update its text and the font is updated dynamically on the screen as well.<br>
I seem to fail to do the same with a scene2d <code>Label</code> added as actor to a <code>Stage</code>.<br>
The <code>act(delta)</code> and <code>draw()</code> methods are being called in the <code>render()</code> method.<br>
My code basically looks as follows:  </p>

<pre><code>public void init() {
    Label label = new Label(text, labelStyle);
    stage.addActor(label);
}

public void update() {
    updateText(text);
}

@Override
public void resize(int width, int height) {
    /* do some resizing */
    label.setPosition(newPositionX, newPositionY);
}

@Override
public void render(float delta) {
    /* do some rendering */
    stage.act(delta);
    stage.draw();
    update();
}
</code></pre>

<p>Do I need to do anything other than setting the <code>Label</code> text, adding it to the <code>Stage</code> as actor, and then updating the text elsewhere? The label displays its original text, though the text updating works fine.</p>

<p>Thanks.</p>
","<p>I have decided to answer my own question to provide the solution I have come up with, in case someone may find it useful:</p>

<p>I have extended the <code>Label</code> class and overridden the <code>act(float delta)</code> method of the new custom label:</p>

<pre><code>public class CustomLabel extends com.badlogic.gdx.scenes.scene2d.ui.Label {
    private String text;

    public CustomLabel(final CharSequence text, final LabelStyle style) {
        super(text, style);
        this.text = text.toString();
    }

    @Override
    public void act(final float delta) {
        this.setText(text);
        super.act(delta);
    }

    public void updateText(final String text) {
        this.text = text;
    }
}
</code></pre>

<p>The <code>updateText(String text)</code> method is then called from outside whenever the text of the label should be updated.</p>
","72059"
"Is it possible to overlay EditText box on a GLSurfaceView on Android?","10118","","<p>I am trying to add a ""PlayerName"" box on top of a opengl menu background, is this possible?  I've tried various layouts, but they don't seem to allow an EditText box to appear on top</p>

<p>What is the typical way of doing something like this?  Do I need to manually render the text and handle input or is there a better way?  It seems like it should be possible to show the EditText on top of the GLSurfaceView somehow.</p>
","<p>I found the correct way of doing this (This code is in the Activity class)</p>

<pre><code>view = new MyGLSurfaceView(this, gameHandler);
editBox = new EditText(context);
editBox.setText(""Hello Matron"");

view.setRenderer(new OpenGLRenderer(gameHandler));
setContentView(view);

addContentView(editBox, new ViewGroup.LayoutParams(ViewGroup.LayoutParams.WRAP_CONTENT, ViewGroup.LayoutParams.WRAP_CONTENT));
</code></pre>

<p>The key is using <strong>addContentView</strong> method on the Activity class to add the editBox on top of the GLSurfaceView.</p>

<p>Hope this helps some googlers :)</p>

<p>Thanks!
Ash</p>
","11534"
"Max texture size Android : which settings for 2048x2048?","10101","","<p>I want to use a texture atlas of 2048 x 2048 in my game, and I would like to warn the users with a ""too low"" device to not download the game. </p>

<p>With a texture atlas of this size, what requirements should I say, on ANDROID ?</p>

<p>This image (source : <a href=""https://stackoverflow.com/questions/10392027/recommended-limit-for-memory-management-in-cocos2d"">https://stackoverflow.com/questions/10392027/recommended-limit-for-memory-management-in-cocos2d</a> ) shows the requirements for IPHONE, what about for ANDROID : 512Mo minimum, with a 1GHz, is a correct requirement ?</p>

<p><img src=""https://i.stack.imgur.com/S6DZw.png"" alt=""enter image description here""></p>

<p>Thanks for your answer</p>
","<p>You'll be okay to ship your game to majority of your users with a configuration like that. Even the fairly old (nearly 3 years now) old <a href=""http://www.glbenchmark.com/phonedetails.jsp?benchmark=glpro25&amp;D=Samsung%20SGH-I897%20Captivate&amp;testgroup=gl"" rel=""nofollow"">Samsung Galaxy Captivate</a> will run with a texture resolution of that size. You won't have too many issues supporting almost any device like that (I can't think of any off the top of my head. Okay, that's a lie... maybe the <a href=""http://www.glbenchmark.com/phonedetails.jsp?benchmark=glpro25&amp;D=HTC%20Dream%20%28Google%20G1%29&amp;testgroup=gl"" rel=""nofollow"">HTC Drean</a>. However, that being said if you want to prevent random crashes and the like when a user OPENS your app - do yourself a favour and query for <strong>GL_MAX_TEXTURE_SIZE</strong>. This will return the maximum texture dimension you can use and if it's less than 2048 you can throw a warning to your user stating gameplay probably won't work or you can load some alternative assets if that's possible for your game that might work for the game at a lower resolution, scale, or with some effects missing. The choice is yours!</p>

<p><strong>Edit:</strong> We're in 2015 now; nearing 2016. You can safely assume most devices will support such an atlas.</p>
","49969"
"which is the best physics engine for flash as3?","10095","","<p>i am a game programmer and i use actionscript to do all my collision checking, boundary checking etc...but recently i noticed there are things called ""physics engines"" that help me concentrate more on game making rather than physics making. so i would like to know more. i heard there are few engines called ""box2dflash"" and ""APE"". </p>
","<p>There's no such thing as <em>best</em> physics engine. It heavily depends on what you need. Take <a href=""http://www.box2dflash.org/"">Box2D</a> as an Example: It is a fully featured 2D Physics Engine, originally developed in C++ and ported to ActionScript. It is great for realistic 2D physics simulation, including gravity, forces, friction, continuous collision detection and much more.</p>

<p>An Engine like Box2D is going to use quite a lot of your CPU cycles, especially when using it in Flash. It is also not trivial to set up and to create appropriate <em>collider-bodies</em> for your Entities.</p>

<p>If you wanted to create a game like <em>Breakout</em>, an Engine like Box2D would be overkill. A game that heavily uses physics for gameplay like <a href=""http://armorgames.com/play/1871/totem-destroyer"">Totem-Destroyer</a>, is probably easier to implement when you can make use of a good Physics-Engine though :-)</p>

<p>There are also other implementations like the one provided with the <a href=""http://flixel.org/"">Flixel</a> Game-Engine. It isn't a physics-engine per se, but it contains a solid collision-detection algorithm. The engine also updates entity velocity and gravity.</p>

<p>In most cases, the tools provided by Flixel or similar engines are good enough. Just keep in mind that using a physic engine is going to be CPU intensive and you should choose the implementation that best fits your game.</p>
","2744"
"GUI Elements - How to go about them?","10089","","<p>Note: I plan on making my own GUI system. It will be good for learning, lightweight, only have bits I need, ties in with the game, etc.  </p>

<p>I was thinking about how to do it. The elements I mean are:  </p>

<ul>
<li>Radio buttons</li>
<li>Enter text here boxes</li>
<li>Buttons</li>
<li>Sliders</li>
<li>Checkboxes</li>
</ul>

<p>I'm not looking as to how to make them, yet. But more of how they would go.  </p>

<h2>Idea</h2>

<p>I would have each state that needed stuff, so almost all, have a container of Elements. Each Element is-a GUI piece.<br>
These each have position, a graphic, etc.<br>
The bit I get more stuck on is the logic of them.<br>
My idea for that, to allow for modularity and simplicity was to avoid a MainMenuStartButton; a OptionsOneBackButton, etc. and instead be able to do Slider slider1; or Button start;.<br>
Instead, each would have a boost::function to a function in a GUI namespace, such like Gui::StartButtonClick, or GUI::ColourSliderHover.<br>
I was just wondering whether this would be exceptionally slow or not.<br>
And for that matter, is there any <em>easy, simple</em> way of doing GUI for games? No Qt, wxWidgets or anything.</p>
","<p>GUI isn't an easy or simple problem, especially when you get into games and their desire to have dynamic, interesting menus.</p>

<p>One ""easy"" thing you can do is try to use middleware.  There's a question on that <a href=""https://gamedev.stackexchange.com/questions/1086/what-c-gui-library-can-you-suggest"">here</a>.</p>

<p>If you're going to roll it yourself, there are a few things I would suggest.</p>

<ul>
<li><p>GUI elements generally have a ""parent"", either another GUI element or a ""window"", or something like that.  Either by pointing up or having the parent point down means you can set state/position/etc on everything that's a child.</p></li>
<li><p>You can build GUI elements by composition.  A lot of widgets have labels (pretty much all of them), and it might make sense to make the concept of a label a component or a child of your other UI elements than copy/pasting the code or trying to inherit from a base class with label functionality.</p></li>
<li><p>A lot of so-called specialized widgets are just buttons in disguise.  Checkboxes are just buttons with states and special images.  Radio buttons are just checkboxes that have meta-state (one and only one is active at any given time) with other radio buttons.  Use this to your advantage.  In one game I worked on, ""checkboxes"" were done with regular buttons entirely through scripting and art.</p></li>
<li><p>For your first project, consider taking the more direct route.  Yes, make your actionable events delegates and assign what you need on element creation (i.e. onMouseButtonDown, onMouseButtonUp, onHover etc), but consider just hard coding what you want to happen otherwise (i.e. hover color changes, button press sounds) until you get something functional.  Once you're at that point, consider making that behavior data (i.e. have a variable on button for ""press sound"", or maybe consider having components that your UI elements use to define behavior that you just attach to them when you create them.</p></li>
<li><p>delegates aren't that slow, you probably won't have so many widgets that it would be an issue, and menu code generally isn't that high impact anyway.  I wouldn't worry too much about performance at this point in the game.  Don't pick naive algorithms and profile once you get your code up and running.</p></li>
</ul>
","1976"
"Mesh with quads to triangle mesh","10077","","<p>I want to use Blender for making models yet realize some of the polygons are not triangles but contain quads or more (example: cylinder top and bottom). I could export the the mesh as a basic mesh file and import it in to an openGL application and workout rendering the quads as tris, but anything with more than 4 vert indices is beyond me. Is it typical to convert the mesh to a triangle-based mesh inside blender before exporting it? I actually tried this through the quads_convert_to_tris method within a blender py script and the top of the cylinder does not look symmetrical. What is typically done to render a loaded mesh as a tri?</p>
","<p>Yes, it's typical to convert into triangles. When reading the mesh in, it's simple to convert a quad into a triangle. It will depend on the format you're exporting to. For example, the format I use, Blender will export all the vertices, then it will export index information for triangles and quads. So it's a simple matter of arranging the indices to take a quad and create two triangles.</p>

<pre><code>if (indexCount == 3) { //triangle face
    int one = readNextIndex();
    int two = readNextIndex();
    int three = readNextIndex();
    indicies.add(one);
    indicies.add(two);
    indicies.add(three);

} else if (indexCount == 4) { //quad face
    int one = readNextIndex();
    int two = readNextIndex();
    int three = readNextIndex();
    int four = readNextIndex();

    indicies.add(one);
    indicies.add(two);
    indicies.add(three);

    indicies.add(three);
    indicies.add(four);
    indicies.add(one);
}
</code></pre>

<p>Where the index information looks like:</p>

<pre><code>//NumberOfElements;Element1;...;ElementN;,
4;40;41;42;43;,
3;44;45;46;,
</code></pre>

<p>Alternatively, using Blender: </p>

<ol>
<li>Go into Edit Mode</li>
<li>Press A to select all</li>
<li>Press Ctrl+T to convert Quads to Triangles</li>
<li>Re-export mesh with triangles</li>
</ol>
","45685"
"Taking advantage of multithreading between game loop and openGL","10076","","<p>Talking in context of a game based on openGL renderer :</p>

<p>Let's assume there are two threads :</p>

<ol>
<li><p>Updates the game logic and physics etc. for the in game objects</p></li>
<li><p>Makes openGL draw calls for each game object based on data in the game objects (that thread 1 keeps updating)</p></li>
</ol>

<p>Unless you have two copies of each game object in the current state of the game you'll have to pause Thread 1 while Thread 2 makes the draw calls otherwise the game objects will get updated in the middle of a draw call for that object, which is undesirable!</p>

<p>But stopping thread 1 to safely make draw calls from thread 2 kills the whole purpose of multithreading/concurrency</p>

<p>Is there a better approach for this other than using hundreds or thousands or sync objects/fences so that the multicore architecture can be exploited for performance?</p>

<p>I know I can still use multithreading for loading texture and compiling shaders for the objects which are yet to be the part of the current game state but how do I do it for the active/visible objects without causing conflict with draw and update?</p>

<p>What if I use separate sync lock in each of the game object? This way any thread would only block on one object (ideal case) rather than for the whole update/draw cycle!
But how costly is taking locks on each object (game may have a thousand objects)?</p>
","<p>The approach you've described, using locks, would be very inefficient and most likely slower than using a single thread. The other approach of keeping copies of data in each thread would probably work well ""speed-wise"", but with a prohibitive memory cost and code complexity to keep the copies in sync. </p>

<p>There are several alternative approaches to this, one popular solution for multi-threaded rendering is by using a double-buffer of commands. This consists of running the renderer back-end in a separate thread, where all draw calls and communication with the rendering API are performed. The front-end thread that runs the game logic communicates with the back-end renderer via a <strong>command buffer (double-buffered)</strong>. With this setup, you only have one synchronazation point at the completion of a frame. While the front-end is filling one buffer with render commands, the back-end is consuming the other. If both threads are well balanced, none should starve. This approach is suboptimal however, since it introduces latency in the frames rendered, plus, the OpenGL driver is likely to be already doing this in its own process, so performance gains would have to be carefully measured. It also only uses two cores, at best. This approach has been used in several successful games though, such as <a href=""http://fabiensanglard.net/doom3_bfg/threading.php"" rel=""nofollow noreferrer"">Doom 3</a> and <a href=""http://fabiensanglard.net/quake3/renderer.php"" rel=""nofollow noreferrer"">Quake 3</a></p>

<p>More scalable approaches that make better use of multi-core CPUs are the ones based on <a href=""https://stackoverflow.com/questions/20434220/threading-vs-task-based-vs-asynchronous-programming"">independent tasks</a>, where you fire an asynchronous request that gets serviced in a secondary thread, while the thread that fired the request continues with some other work. The task should ideally have no dependencies with the other threads, to avoid locks (also avoid shared/global data like the plague!). A task-based architectures is more usable in localized parts of a game, such as computing animations, AI pathfinding, procedural generation, dynamic loading of scene props, etc. Games are naturally event-full, most kinds of events are async, so it is easy to make them run in separate threads.</p>

<p>Finally, I recommend reading:</p>

<ul>
<li><p><a href=""https://software.intel.com/en-us/articles/threading-basics-for-games"" rel=""nofollow noreferrer"">Threading Basics for Games</a> by Intel.</p></li>
<li><p><a href=""http://herbsutter.com/2010/07/12/effective-concurrency-prefer-using-active-objects-instead-of-naked-threads/"" rel=""nofollow noreferrer"">Effective Concurrency</a> by Herb Sutter (several links to other good resources in this page).</p></li>
</ul>
","90765"
"Enemy Spawning method in a Top-Down Shooter","10072","","<p>I'm working on a top-down shooter akin to <em>DoDonPachi</em>, <em>Ikaruga</em>, etc. The camera movement through the world is handled automatically with the player able to move inside of the camera's visible region.</p>

<p>Along the way, enemies are scripted to spawn at particular points along the path. While this sounds straightforward, I could see two ways to define these points:</p>

<ol>
<li>Camera's position: 'trigger' spawning as the camera passes by the points</li>
<li>Time along path: ""30 seconds in, spawn 2 enemies""</li>
</ol>

<p>In both cases, the camera-relative positions would be defined as well as the behavior of the enemy.</p>

<p>The way I see it, the way you define these points will directly affect how the 'level editor', or what have you, will work.</p>

<p>Would there be any benefits of one approach over the other?</p>
","<p>I would suggest placing the spawn positions actually ON the background map as nodes that are visible from some sort of map editor. You can represent a shmup spawn with two variables:</p>

<ol>
<li>Position they are first visible from, which is best visualized as a point</li>
<li>Distance from bottom screen when you should spawn them.</li>
</ol>

<p>Then you can visualize the distance from bottom of screen as a vertical line pointing downward from the spawn node (which could be visualied as a greyed out version of the enemy or some such). When the bottom of the screen touches that line it will spawn. This allows you to do all of enemy editing completely in some sort of visual editor, and give you an overview of the entire flow of the game.</p>
","2722"
"What is a good technique for 2D tile-based terrain generation meeting these requirements?","10072","","<p>As a summer project I decided it would be fun to make a Flash game.  Right now I'm going for something like the look of <a href=""http://www.terraria.org/"" rel=""nofollow"">Terraria</a>.  It's been a lot of fun, but today I've hit a snag.  I need a way to generate my worlds.  I've read up <a href=""http://freespace.virgin.net/hugo.elias/models/m_perlin.htm"" rel=""nofollow"">Perlin noise</a> as a possibility, but I my attempts have given me sporadic looking results.  What are some techniques used to generate these 2D tile-based worlds?</p>

<p>Ideally I would like to be able to generate mountains, plains, and caves.</p>
","<p>It sounds like you're looking to generate a ""side view"" of the generated terrain.</p>

<p>There are plenty of terrain generation algorithms discussed on the web. You could probably adapt many of them by cutting out all but one dimension from the calculations. This would give you information about the primary surface/underground boundary. If you want to be more directed in your search, you probably want to look for ""1D"" terrain generation or ""Worms-style"" terrain generation. You'll get results like <a href=""http://forums.tigsource.com/index.php?topic=5174.0"" rel=""nofollow noreferrer"">this thread on procedural terrain (including caves)</a>, and <a href=""http://zacharydenton.com/labs/1d-terrain-generator/"" rel=""nofollow noreferrer"">this interesting web demo</a>.</p>

<p>Perlin noise alone would work well for the areas where you want to generate plains, since it's very smooth. It doesn't work so well for mountains and craggy areas with sharp discontinuities -- you'd want to combine it with something else for that. Consider <a href=""http://www.gameprogrammer.com/fractal.html"" rel=""nofollow noreferrer"">the first portion of this page</a> on fractal terrain, or applying random cuts and displacements to the terrain.</p>

<p>Caves can be done by randomly punching holes in your terrain as a simple first pass, but you can also look for information on <a href=""https://gamedev.stackexchange.com/questions/2663/what-are-some-ideal-algorithms-for-rogue-like-2d-dungeon-generation"">how rooms in Rogue-like games are generated</a> and apply that. You might also consider looking into <a href=""http://pcg.wikidot.com/pcg-algorithm:cellular-automata"" rel=""nofollow noreferrer"">cellular automata</a>.</p>
","14259"
"Creating sideways friction in a 2D top down racer","10061","","<p>I've been playing around with trying to create some kind of top down racer but I'm having trouble getting the car to turn properly. At the moment this is the code I have to update the position of the car:</p>

<pre><code>var power;
    if (keyboard.upKeyDown) {
        power = 1;
    } else {
        power = 0;
    }

if (keyboard.leftKeyDown) {
    this.rotate -= 0.05;
} else if (this.keyboard.rightKeyDown) {
    this.rotate+= 0.05;
}

this.velocityX += Math.cos(this.rotate) * power;
this.velocityY += Math.sin(this.rotate) * power;

var cDrag = 0.98;
this.velocityX *= cDrag;
this.velocityY *= cDrag;

this.positionX += this.velocityX;
this.positionY += this.velocityY;
</code></pre>

<p>At the moment the code is very simple, you hold down UP and force is applied in the direction you're pointing which makes it feel like the ship in asteroids.</p>

<p>It seems to me the next thing I need to do is compare the direction the car is pointing with the direction it's actually travelling and apply some sideways force to make it slow down in the sideways direction but also transfer some of that force to the forward direction so it keeps going in the direction it's now pointing.</p>

<p>I'm a bit confused as to how I go about doing this so any advice would be most welcome.</p>
","<p><em>Disclaimer: There are probably other, and better ways to do this. Either way I'll share and describe the way I approached this problem a while back, which ended up working okay for me.</em></p>

<p>I've implemented a 2D top-down car game a couple of years ago for a university project, and if I remember correctly I used <a href=""http://www.emanueleferonato.com/2009/04/06/two-ways-to-make-box2d-cars/"">this article</a> as a starting point, although I ended up simplifying it a lot, and dropped all of that ""wheel"" modeling stuff in favor of a single body for the car. What I did use however was something similar to the <code>KillOrthogonalVelocity</code> method which you can find there, to take care of applying lateral friction.</p>

<p>So, here's <a href=""http://www.youtube.com/watch?v=scnl-THcCvo""><strong>a little video</strong></a> of what it turned out like. There's a certain amount of sideways friction being applied which also depends on whether I'm using the handbrake button or not, and the car I used for the video also drifts significantly more than the others. This was controllable though. It also had a truck with zero sideways motion and very stiff controls.</p>

<p>I was never completely satisfied with the results, but it was enough for my needs. Bear in mind that I didn't base any of my physics on real vehicle movement or anything. I just tweaked and tried things out until It felt right.</p>

<p><strong>Sideways Friction</strong></p>

<p>So, to give a few details on the implementation, basically, when I adapted that method to my project, I added a variable which allowed me to control exactly <em>how much</em> of the lateral velocity I would kill, as a value between 0 and 1. This allowed me to fine tune the handling of the car and how much it could drift. Here's the method translated to XNA and simplified:</p>

<pre class=""lang-cs prettyprint-override""><code>public static void KillOrthogonalVelocity(Car car, float drift = 0f)
{
    Vector2 forwardVelocity = car.Forward * Vector2.Dot(car.Velocity, car.Forward);
    Vector2 rightVelocity = car.Right * Vector2.Dot(car.Velocity, car.Right);
    car.Velocity = forwardVelocity + rightVelocity * drift;
}
</code></pre>

<p>As you can see I'm using vectors and linear algebra though, not trigonometry, so you'll have to adapt it to your needs. Both <code>car.Forward</code> and <code>car.Right</code> are normalized vectors pointing in that particular direction. </p>

<p><strong>Throttle, Brakes, Steering</strong></p>

<p>Other than that the only other relevant part was how I applied the forces to the car to make it move and steer:</p>

<ul>
<li><em>Accelerating</em> and braking was simple. Just a matter of applying a force in the direction the car was currently facing, or its inverse.</li>
<li><p><em>Steering</em> on the other hand had a couple of tricks. Steering was done by applying a torque to the car (I used Box2D so this was a simple method call) but the power of that torque depended on a few factors, in particular:</p>

<ol>
<li>When breaking I increased the torque by 25% to make it possible to make sharper turns. <code>if(braking || handbraking) torque *= 1.25</code></li>
<li>When going in reverse, I also reversed the torque in order to get the correct controls. <code>if(reverse) torque *= -1</code></li>
<li>Finally, if the car was going under a certain speed threshold, I made it steer less than usual. <code>if(speed &lt; 2.0f) torque *= (speed / 4.0f)</code></li>
</ol></li>
</ul>

<p>Then just call the <code>KillOrthogonalVelocity()</code> method to adjust the final velocity and make it behave less like a spaceship and more like a car.</p>
","23096"
"Make pygame's frame rate faster","10054","","<p>By profiling my game, I see that the vast majority of the execution time of my hobby game is between the blit and the flip calls. Currently, it's only running at around 13fps. My video card is fairly decent, so my guess is that pygame is not using it.</p>

<p>Does anyone know of any graphics/display options I need to set in pygame to make this faster? Or is this just something that I have to live with since I've chosen pygame?</p>
","<p>If you're running in full-screen mode, you can use the <code>pygame.HWSURFACE</code> flag when you initialise the display to tell pygame to try to use a hardware surface. I believe that if a hardware surface can't be used, pygame will silently use a software surface.</p>

<p>If you're not using a hardware surface, consider using <code>pygame.display.update(rectangle)</code> rather than <code>pygame.display.flip()</code>. This will only update the given rectangle rather than the whole display, which can increase your performance quite a bit unless your game actually needs to update the whole display.</p>

<p>If you are using a hardware or OpenGL surface, there's also the <code>pygame.DOUBLEBUF</code> which uses hardware double buffering, meaning that your drawing functions will draw to one of the two buffers and <code>flip()</code> will swap which buffer is visible.</p>
","561"
"Recommend a game engine with 2D GUI for a UI-intensive strategy game","10030","","<p>Yes, this is another recommend game engine request; the 'twist' is I am doing a strategy game and on top of sprites, animation and abstraction of input controls, it has to have GUI support for rather complex controls, such as scroll-bars, select boxes, buttons and such.</p>

<p>I  have tried XNA with various GUI libraries, but the problem is that those libraries was not 'completed'.
 I am just wondering if there are other engines which I can look at?</p>
","<p><a href=""http://librocket.com/"" rel=""nofollow noreferrer"">libRocket</a> recently went open source.</p>

<p>It's not a game engine.  They describe themselves as middleware.  But the library is pretty well done, with focus on removing boilerplate code from you GUI design.  It's based on XHTML and CSS, so if you're already familiar with Web developoment it might be a great fit.</p>

<p>But it is not a game engine you'll still need to solve those issues separately.  You might find some guidance with this question.<br>
<a href=""https://gamedev.stackexchange.com/questions/536/recommended-2d-game-engine-for-prototyping"">Recommended 2D Game Engine for prototyping</a></p>
","3812"
"What tools are available for developing 2D games like Tetris or Angry Birds for Android?","10028","","<p>I would like to ask the following regarding developing Tetris- and Angry Birds-like 2D games for Android:</p>

<ol>
<li>Is Java the official development language for Android?</li>
<li>What free or commercial Android development environments (like <a href=""http://developer.apple.com/xcode/"" rel=""nofollow"">Xcode</a> is for iOS) are available?</li>
<li>What open source game development engines, like <a href=""http://www.cocos2d-iphone.org/"" rel=""nofollow"">cocos2D</a>, are available for Android?</li>
<li>Are there any great tutorials available for developing such games?</li>
</ol>
","<ol>
<li><p>Java is the default language to develop on Android, although you can use NDK (native C) for performance issues on specific parts. But basically, Java + OpenGL is fast enough for most 2D games. </p></li>
<li><p>One of the best (in my opinion) development environments for Java/Android is Eclipse : you can download plugins for Android from <a href=""http://developer.android.com/sdk/installing.html"">the official website</a>.</p></li>
<li><p>You have Andgine, a free 2D game engine : <a href=""http://www.andengine.org/"">http://www.andengine.org/</a></p></li>
<li><p>You'll find many tutorials for Andgine on their website. If you're missing something, maybe ask for a specific topic here or on their forum. </p></li>
</ol>
","14496"
"How can I import FBX animations using the FBX SDK?","10027","","<p>I got the meshes loaded in correctly with all of their vertices, indices, UV's, and normals. I am just now trying to get the Animations working correctly. I have looked at the FBX SDK documentation with little help. If someone could just help me get started or point me in the right direction I would greatly appreciate it. I added some code so you can kinda get an idea of what I am doing. I should be able to place that code anywhere in the load FBX function and have it work. </p>

<pre><code>//GETTING ANIMAION DATA
for(int i = 0; i &lt; scene-&gt;GetSrcObjectCount&lt;FbxAnimStack&gt;(); ++i)
{
    FbxAnimStack* lAnimStack = scene-&gt;GetSrcObject&lt;FbxAnimStack&gt;(i);

    FbxString stackName = ""Animation Stack Name: "";
    stackName += lAnimStack-&gt;GetName();
    string sStackName = stackName;

    int numLayers = lAnimStack-&gt;GetMemberCount&lt;FbxAnimLayer&gt;();
    for(int j = 0; j &lt; numLayers; ++j)
    {
        FbxAnimLayer* lAnimLayer = lAnimStack-&gt;GetMember&lt;FbxAnimLayer&gt;(j);

        FbxString layerName = ""Animation Stack Name: "";
        layerName += lAnimLayer-&gt;GetName();
        string sLayerName = layerName;

        queue&lt;FbxNode*&gt; nodes;

        FbxNode* tempNode = scene-&gt;GetRootNode();

        while(tempNode != NULL)
        {
            FbxAnimCurve* lAnimCurve = tempNode-&gt;LclTranslation.GetCurve(lAnimLayer, FBXSDK_CURVENODE_COMPONENT_X);

            if(lAnimCurve != NULL)
            {
                //I know something needs to be done here but I dont know what.
            }

            for(int i = 0; i &lt; tempNode-&gt;GetChildCount(false); ++i)
            {
                nodes.push(tempNode-&gt;GetChild(i));
            }

            if(nodes.size() &gt; 0)
            {
                tempNode = nodes.front();
                nodes.pop();
            }
            else
            {
                tempNode = NULL;
            }
        }               
    }       
}
</code></pre>

<p>Here is the full function</p>

<pre><code>bool FBXLoader::LoadFBX(ParentMeshObject* _parentMesh, char* _filePath, bool _hasTexture)
{
    FbxManager* fbxManager = FbxManager::Create();
if(!fbxManager)
{
    printf( ""ERROR %s : %d failed creating FBX Manager!\n"", __FILE__, __LINE__ );
}

FbxIOSettings* ioSettings = FbxIOSettings::Create(fbxManager, IOSROOT);
fbxManager-&gt;SetIOSettings(ioSettings);

FbxString filePath = FbxGetApplicationDirectory();
fbxManager-&gt;LoadPluginsDirectory(filePath.Buffer());

FbxScene* scene = FbxScene::Create(fbxManager, """");

int fileMinor, fileRevision;
int sdkMajor, sdkMinor, sdkRevision;
int fileFormat;

FbxManager::GetFileFormatVersion(sdkMajor, sdkMinor, sdkRevision);
FbxImporter* importer = FbxImporter::Create(fbxManager, """");

if(!fbxManager-&gt;GetIOPluginRegistry()-&gt;DetectReaderFileFormat(_filePath, fileFormat))
{
    //Unrecognizable file format. Try to fall back on FbxImorter::eFBX_BINARY
    fileFormat = fbxManager-&gt;GetIOPluginRegistry()-&gt;FindReaderIDByDescription(""FBX binary (*.fbx)"");
}

bool importStatus = importer-&gt;Initialize(_filePath, fileFormat, fbxManager-&gt;GetIOSettings());
importer-&gt;GetFileVersion(fileMinor, fileMinor, fileRevision);

if(!importStatus)
{
    printf( ""ERROR %s : %d FbxImporter Initialize failed!\n"", __FILE__, __LINE__ );
    return false;
}

importStatus = importer-&gt;Import(scene);

if(!importStatus)
{
    printf( ""ERROR %s : %d FbxImporter failed to import the file to the scene!\n"", __FILE__, __LINE__ );
    return false;
}

FbxAxisSystem sceneAxisSystem = scene-&gt;GetGlobalSettings().GetAxisSystem();
FbxAxisSystem axisSystem( FbxAxisSystem::eYAxis, FbxAxisSystem::eParityOdd, FbxAxisSystem::eLeftHanded );

if(sceneAxisSystem != axisSystem)
{
    axisSystem.ConvertScene(scene);
}

TriangulateRecursive(scene-&gt;GetRootNode());

FbxArray&lt;FbxMesh*&gt; meshes;
FillMeshArray(scene, meshes);

unsigned short vertexCount = 0;
unsigned short triangleCount = 0;
unsigned short faceCount = 0;
unsigned short materialCount = 0;

int numberOfVertices = 0;
for(int i = 0; i &lt; meshes.GetCount(); ++i)
{
    numberOfVertices += meshes[i]-&gt;GetPolygonVertexCount();
}



Face face;
vector&lt;Face&gt; faces;
int indicesCount = 0;

int ptrMove = 0;

float wValue = 0.0f;

if(!_hasTexture)
{
    wValue = 1.0f;
}

for(int i = 0; i &lt; meshes.GetCount(); ++i)
{
    int vertexCount = 0;
    vertexCount = meshes[i]-&gt;GetControlPointsCount();
    if(vertexCount == 0)
        continue;

    VertexType* vertices;
    vertices = new VertexType[vertexCount];

    int triangleCount = meshes[i]-&gt;GetPolygonVertexCount() / 3;
    indicesCount = meshes[i]-&gt;GetPolygonVertexCount();

    FbxVector4* fbxVerts = new FbxVector4[vertexCount];
    int arrayIndex = 0;
    memcpy(fbxVerts, meshes[i]-&gt;GetControlPoints(), vertexCount * sizeof(FbxVector4));

    for(int j = 0; j &lt; triangleCount; ++j)
    {
        int index = 0;
        FbxVector4 fbxNorm(0, 0, 0, 0);
        FbxVector2 fbxUV(0, 0);
        bool texCoordFound = false;
        face.indices[0] = index = meshes[i]-&gt;GetPolygonVertex(j, 0);
        vertices[index].position.x = (float)fbxVerts[index][0];
        vertices[index].position.y = (float)fbxVerts[index][1];
        vertices[index].position.z = (float)fbxVerts[index][2];
        vertices[index].position.w = wValue;
        meshes[i]-&gt;GetPolygonVertexNormal(j, 0, fbxNorm);
        vertices[index].normal.x = (float)fbxNorm[0];
        vertices[index].normal.y = (float)fbxNorm[1];
        vertices[index].normal.z = (float)fbxNorm[2];
        texCoordFound = meshes[i]-&gt;GetPolygonVertexUV(j, 0, ""map1"", fbxUV);
        vertices[index].texture.x = (float)fbxUV[0];
        vertices[index].texture.y = (float)fbxUV[1];

        face.indices[1] = index = meshes[i]-&gt;GetPolygonVertex(j, 1);
        vertices[index].position.x = (float)fbxVerts[index][0];
        vertices[index].position.y = (float)fbxVerts[index][1];
        vertices[index].position.z = (float)fbxVerts[index][2];
        vertices[index].position.w = wValue;
        meshes[i]-&gt;GetPolygonVertexNormal(j, 1, fbxNorm);
        vertices[index].normal.x = (float)fbxNorm[0];
        vertices[index].normal.y = (float)fbxNorm[1];
        vertices[index].normal.z = (float)fbxNorm[2];
        texCoordFound = meshes[i]-&gt;GetPolygonVertexUV(j, 1, ""map1"", fbxUV);
        vertices[index].texture.x = (float)fbxUV[0];
        vertices[index].texture.y = (float)fbxUV[1];

        face.indices[2] = index = meshes[i]-&gt;GetPolygonVertex(j, 2);
        vertices[index].position.x = (float)fbxVerts[index][0];
        vertices[index].position.y = (float)fbxVerts[index][1];
        vertices[index].position.z = (float)fbxVerts[index][2];
        vertices[index].position.w = wValue;
        meshes[i]-&gt;GetPolygonVertexNormal(j, 2, fbxNorm);
        vertices[index].normal.x = (float)fbxNorm[0];
        vertices[index].normal.y = (float)fbxNorm[1];
        vertices[index].normal.z = (float)fbxNorm[2];
        texCoordFound = meshes[i]-&gt;GetPolygonVertexUV(j, 2, ""map1"", fbxUV);
        vertices[index].texture.x = (float)fbxUV[0];
        vertices[index].texture.y = (float)fbxUV[1];

        faces.push_back(face);
    }

    meshes[i]-&gt;Destroy();
    meshes[i] = NULL;

    int indexCount = faces.size() * 3;
    unsigned long* indices = new unsigned long[faces.size() * 3]; 
    int indicie = 0;
    for(unsigned int i = 0; i &lt; faces.size(); ++i)
    {
        indices[indicie++] = faces[i].indices[0];
        indices[indicie++] = faces[i].indices[1];
        indices[indicie++] = faces[i].indices[2];
    }
    faces.clear();
    _parentMesh-&gt;AddChild(vertices, indices, vertexCount, indexCount);
}

return true;
}
</code></pre>
","<p>The FBX documentation is painful at times, and this is definitely one of them.</p>

<p>There are two ways I've used to access animation data. The first is used in the ImportScene sample that comes with the SDK, and it's the way you seem to be trying to do things. In your sample, now that you have a valid lAnimCurve, you would need to query the number of keyframes that are stored in that curve, and then access them one at a time. It's a fairly complex process, I would refer you to the DisplayAnimation.cxx file in the ImportScene sample to see how they do it.</p>

<p>The problem with this is that you then will need to go through and determine any missing information. In the animation I'm working with, I have keyframe data for frame 0, 35, and 70. So now I would need to determine if the interpolation is linear or cubic, which involves more complicated and error-prone programming.</p>

<p>I also don't know at this point how fast the animation runs - 30fps, 24fps, 60fps, or some custom number - so even though I know I have 70 frames, I don't actually know how long the animation is supposed to last.</p>

<p>Instead, I would suggest digging into the KFbxAnimEvaluator class. This makes life much easier, because it will figure out all sorts of animation stuff for you. Really, that's the SDK page to keep an eye on.</p>

<p>So here's some sample code for how I break the times down.  Assume lAnimStackCount is the number of animation stacks my file has.</p>

<pre><code>for(i = 0; i &lt; lAnimStackCount; i++) {
   KFbxTakeInfo* lTakeInfo = lImporter-&gt;GetTakeInfo();

   KTime start = lTakeInfo-&gt;mLocalTimeSpan.GetStart();
   KTime end = lTakeInfo-&gt;mLocalTimeSpan.GetStop();

   // now you know how many seconds the animation runs, and can figure out how many
   // keyframes you need. I usually export animations as 30fps
}
</code></pre>

<p>From here, you can use the GetNodeLocalTransform() function in KFbxAnimEvaluator to get the transform matrix at specific times. It will give you a final answer matrix that you can pull the TRS info out of.</p>

<p>I know that's vague, but my specific code is not on this computer. Hopefully it's high-level enough to help though.</p>
","59441"
"Difference between Material and Shader","10008","","<p>In games, materials often only influence the visual appearance of objects. The visual appearance is effected by shaders. So regarding to terminology is there a difference between materials and shaders? Should you write one shader for one material?</p>
","<p>A material is a combination of attributes which describe how a surface of the given material should look like.</p>

<p>Some engines use different shaders for different materials, in which case a material definition could look like this:</p>

<pre><code>[Material]
Shader=NormalMappedSpecular.glsl
Texture1=Rock.png
Texture2=RockNormal.png
Texture3=RockSpecular.png
</code></pre>

<p>Other engines use one shader for all objects (or rather the engines decides what shader to use dependent on the parameters, the capabilities of the GPU and other factors such as distance), in which case a material would look more like this:</p>

<pre><code>[Material]
Ambient=0.5
Specularity=0.7
DiffuseMap=Rock.png
NormalMap=RockNormal.png
SpecularMap=RockSpecular.png
</code></pre>
","45845"
"What are some techniques for designing fun, challenging Mario-style platformer levels?","10002","","<p>I have everything I need to make a Mario type game. I just have no idea how to design the levels to make it challenging or fun. Any tips? </p>

<p>The only way to kill enemies is by jumping on them, so I thought it would be too hard to make a boss. I was just going to make the last level long. Is this a bad idea?</p>
","<p>Just a short list of things I could come up with.</p>

<p>If jumping on enemies and jumping in general are your only two gameplay mechanics:</p>

<ul>
<li>Gradually introduce new enemies with new movement patterns.</li>
<li>Gradually introduce new obstacles.</li>
<li>Gradually increase jump precision / speed / timing requirements</li>
<li>Consider making the game harder by having your character move faster or with less precision. Or make character movement super-tight and the levels super difficult (Super Meat Boy).</li>
<li>Instead of bosses you could have hard jump sequences. Just remember not to frustrate the player too much.</li>
<li>Introduce things as walljump or gravity manipulation to spruce things up?</li>
<li>Make sure that the player dies because he's bad not because you trick him. (eg. one hit kill spikes that teleport out of nowhere(I Want To Be The Guy))</li>
</ul>
","15896"
"Should I be using Lua for game logic on mobile devices?","9982","","<p>As above really, </p>

<p>I'm writing an android based game in my spare time (android because it's free and I've no real aspirations to do anything commercial).</p>

<p>The game logic comes from a very typical component based model whereby entities exist and have components attached to them and messages are sent to and fro in order to make things happen.</p>

<p>Obviously the layer for actually performing that is thin, and if I were to write an iPhone version of this app, I'd have to re-write the renderer and core driver (of this component based system) in Objective C.</p>

<p>The entities are just flat files determining the names of the components to be added, and the components themselves are simple, single-purpose objects containing the logic for the entity. </p>

<p>Now, if I write all the logic for those components in Java, then I'd have to re-write them on Objective C if I decided to do an iPhone port. As the bulk of the application logic is contained within these components, they would, in an ideal world, be written in some platform-agnostic language/script/DSL which could then just be loaded into the app on whatever platform.</p>

<p>I've been led to believe however that this is not an ideal world though, and that Lua performance etc on mobile devices still isn't up to scratch, that the overhead is too much and that I'd run into troubles later if I went down that route?</p>

<p>Is this actually the case? Obviously this is just a hypothetical question, I'm happy writing them all in Java as it's simple and easy get things off the ground, but say I actually enjoy making this game (unlikely, given how much I'm currently disliking having to deal with all those different mobile devices) and I wanted to make a commercially viable game - would I use Lua or would I just take the hit when it came to porting and just re-write all the code?</p>
","<p>As far as scripting languages go, Lua is very fast, but like anything it varies depending on the processor. For example, Lua would not be great on a console platform because it tends to be very branchy, and some console platforms branch very slowly. To best answer your question, I would suggest running some benchmarks. See how fast Lua performs some various algorithms on the device. I suspect you'd be fine as long as you're not doing any heavy math or iteration in your script code. (You shouldn't be doing that anyway. They're scripts. Do calculations in the engine.)</p>

<p>That said, scripting isn't a silver bullet for platform independence. You may need to rewrite in Obj-C anyway if you port to iPhone due to Apple's restrictions on executing dynamic code. I don't have a link offhand, but it may be worth reading into. Apple <em>barely</em> allows managed code (you have to get special permission to run a special distribution). They most certainly will not allow a Lua implementation into the app store.</p>

<p>[edit] Apparently I was mistaken about the Lua on iphone thing. Take a look at the comments below.</p>
","436"
"How to create a projection matrix in OpenGL ES 2.0","9979","","<p>So I have the following...</p>

<pre><code>float s = 0.5f;

void renderFrameLine() {
  glClearColor(0.0f, 0.0f, 0.0f, 1.0f);
  glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
  GLfloat vVertices[] = { s, s, 0.0f, s, -s, 0.0f, -s, s,
    0.0f};
  glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 0, vVertices);
  glEnableVertexAttribArray(0);
  glDrawArrays(GL_TRIANGLES, 0, 3);
}
</code></pre>

<p>This works great so now I want to add depth so I get ready by changing my vertex shader as following...</p>

<pre><code>GLbyte vShaderStr[] =
""attribute vec4 vPosition;   \n""
""uniform mat4 Projection;   \n""
""void main()                 \n""
""{                           \n""
""     gl_Position = Projection * vPosition; \n""
""}                           \n"";
</code></pre>

<p>And based on this code in GLM...</p>

<pre><code>template &lt;typename valType&gt;
    GLM_FUNC_QUALIFIER detail::tmat4x4&lt;valType&gt; perspectiveFov
    (
            valType const &amp; fov,
            valType const &amp; width,
            valType const &amp; height,
            valType const &amp; zNear,
            valType const &amp; zFar
    )
    {
#ifdef GLM_FORCE_RADIANS
            valType rad = fov;
#else
            valType rad = glm::radians(fov);
#endif
            valType h = glm::cos(valType(0.5) * rad) / glm::sin(valType(0.5) * rad);
            valType w = h * height / width; ///todo max(width , Height) / min(width , Height)?

            detail::tmat4x4&lt;valType&gt; Result(valType(0));
            Result[0][0] = w;
            Result[1][1] = h;
            Result[2][2] = - (zFar + zNear) / (zFar - zNear);
            Result[2][3] = - valType(1);
            Result[3][2] = - (valType(2) * zFar * zNear) / (zFar - zNear);
            return Result;
    }
</code></pre>

<p>I create the following function to create a perspective matrix...</p>

<pre><code>void glFrustumf(float near, float far){
        float aspectRatio = .5;
        float DEG2RAD = 3.14159f / 180.0f;
        float fov = 90*DEG2RAD;
        float h = cosf(0.5f*fov)/sinf(0.5f*fov);
        float w = h * aspectRatio;
        float a =  - (near+far)/(near - far);
        float b = - ((2*far*near)/(far-near));

        float proj[16] = {
                        w, 0, 0, 0,
                        0, h, 0, 0,
                        0, 0, a, 1,
                        0, 0, b, 0
                    };
        GLint projectionUniform = glGetUniformLocation(programObject, ""Projection"");
        glUniformMatrix4fv(projectionUniform, 1, 0, &amp;proj[0]);
}
</code></pre>

<p>This doesn't seem to work and instead returns a blank screen. Can anyone tell me what I am doing wrong?</p>

<p><strong>Update</strong></p>

<p>I also tried </p>

<pre><code>void glFrustumf(float near, float far, float left, float right, float bottom, float top){
        float deltaX = right - left;
        float deltaY = top - bottom;
        float deltaZ = far - near;

        float a = 2.0f * near / deltaX;
        float b = 2.0f * near / deltaY;
        float c = (right + left) / deltaX;
        float d = (top + bottom) / deltaY;
        float e = -(near + far) / deltaZ;
        float f = -2.0f * near * far / deltaZ;

        float proj[16] = {
                        a, 0, 0, 0,
                        0, b, 0, 0,
                        c, d, e, -1.0f,
                        0, 0, f, 0
                    };
        GLint projectionUniform = glGetUniformLocation(programObject, ""Projection"");
        glUniformMatrix4fv(projectionUniform, 1, GL_FALSE, &amp;proj[0]);
}
</code></pre>

<p>but no dice...</p>

<p><strong>Per previous comment</strong></p>

<p>Based on this line...</p>

<blockquote>
  <p>2 ⁢ nearVal right - left 0 A 0 0 2 ⁢ nearVal top - bottom B 0 0 0 C D 0 0 -1 0</p>
  
  <p>A = right + left right - left</p>
  
  <p>B = top + bottom top - bottom</p>
  
  <p>C = - farVal + nearVal farVal - nearVal</p>
  
  <p>D = - 2 ⁢ farVal ⁢ nearVal farVal - nearVal</p>
</blockquote>

<p>I changed to this...</p>

<pre><code>float proj[16] = {
                        a, 0, c, 0,
                        0, b, d, 0,
                        0, 0, e, f,
                        0, 0, -1, 0
};
</code></pre>

<p>But still just black...</p>

<p>Also tried...</p>

<pre><code>void glFrustumf(float near, float far){
    float aspectRatio = .5;
    float DEG2RAD = 3.14159f / 180.0f;
    float fov = 90*DEG2RAD;
    float w = fov/aspectRatio;
    float a =  - (near+far)/(near - far);
    float b = - ((2*far*near)/(near - far));

    float proj[16] = {
                    w, 0, 0, 0,
                    0, fov, 0, 0,
                    0, 0, a, b,
                    0, 0, -1, 0
                };
    GLint projectionUniform = glGetUniformLocation(programObject, ""Projection"");
    glUniformMatrix4fv(projectionUniform, 1, 0, &amp;proj[0]);
}
</code></pre>

<p>Also tried ...</p>

<pre><code>void glFrustumf(float near, float far){
    float aspectRatio = .5;
    float DEG2RAD = 3.14159f / 180.0f;
    float fov = 90*DEG2RAD;
    float cot = (1 / (tanf(fov)/2));
    float cota = cot /aspectRatio;
    float a =  - (far+near)/(near - far);
    float b = - ((2*far*near)/(near-far));

    float proj[16] = {
                    cota, 0, 0, 0,
                    0, cot, 0, 0,
                    0, 0, a, b,
                    0, 0, -1, 0
                };
    GLint projectionUniform = glGetUniformLocation(programObject, ""Projection"");
    glUniformMatrix4fv(projectionUniform, 1, 0, &amp;proj[0]);
}
</code></pre>
","<p>Per previous this works...</p>

<pre><code>void glFrustumf(float near, float far){
  float aspectRatio = .5;
  float DEG2RAD = 3.14159f / 180.0f;
  float fov = 90*DEG2RAD;
  float h = cosf(0.5f*fov)/sinf(0.5f*fov);
  float w = h * aspectRatio;
  float a =  - (near+far)/(near - far);
  float b = - ((2*far*near)/(far-near));

  float proj[16] = {
    w, 0, 0, 0,
    0, h, 0, 0,
    0, 0, a, 1,
    0, 0, b, 0
  };
  GLint projectionUniform = glGetUniformLocation(programObject, ""Projection"");
  glUniformMatrix4fv(projectionUniform, 1, 0, &amp;proj[0]);
}
...
glFrustumf(0.1f, nf);
</code></pre>

<p>This now seems to work, I think Wolfgang's advice about the book is pretty solid. It helped a lot. </p>

<p>more info...</p>

<p><a href=""https://github.com/jrgleason/CrossGLESMobile"" rel=""nofollow"">https://github.com/jrgleason/CrossGLESMobile</a></p>
","56681"
"What is ""game logic code?""","9954","","<p>I'm using C#/XNA and have been told quite a few times not to mix update code with draw code -- and I'm certain I'm not! But could anyone please describe what exactly is 'logic code'?</p>

<p>As seen here: <a href=""http://blogs.msdn.com/b/shawnhar/archive/2007/07/25/understanding-gametime.aspx"">http://blogs.msdn.com/b/shawnhar/archive/2007/07/25/understanding-gametime.aspx</a></p>

<blockquote>
  <p>[...] make sure you put all your game logic inside the Update method (not in Draw!) and everything will run at a nice constant speed.</p>
</blockquote>

<p>I'm asking this since my game's speed is fluctuating relative to the FPS. Slow FPS equals slow-moving objects and visa versa. And yes, I am including the expected <code>position += speed * (float)gt.ElapsedGameTime.TotalSeconds;</code> code.</p>

<p>This is probably a big rookie question, but I just want to be absolutely clear on the definition of this.</p>
","<p>Does it change the state of your game world? It's logic code.</p>

<p>Does it display the state of the game world? It's rendering code.</p>
","115572"
"Design sprites for games (iPhone game)","9945","","<p>I'm not the very best at design, but I have looked for tutorials to design normal sprites for games (mobile devices), like background, ground and all that stuff in 2D. Are there any inspirations/tutorials for this?</p>

<p>Thanks in advance!</p>
","<p>I am not an artist but I read this tutorials and watched some method used there</p>

<p><a href=""http://garmahis.com/tutorials/pixel-art-tutorials/"" rel=""nofollow"">Pixel art tutorials list - must be viewed</a></p>

<p><a href=""http://www.natomic.com/hosted/marks/mpat/"" rel=""nofollow"">Methods used creating art</a></p>

<p><a href=""http://www.pixeljoint.com/pixels/tutorials.asp"" rel=""nofollow"">One more site</a></p>
","7322"
"How do I detect the direction of 2D rectangular object collisions?","9940","","<p>After <a href=""https://gamedev.stackexchange.com/q/13756/5495"">this question</a>, I need some more help.</p>

<p>How can I find out which side of a rectangle a collision came from and react accordingly?  </p>

<p><img src=""https://i.stack.imgur.com/23ve7.png"" alt=""rectangles being collided with from all sides""></p>

<p>The blue arrows are the paths that some circular objects would follow if before and after colliding with the box.</p>

<p>How can I calculate this?</p>
","<p>Since this is based on your other question I'll give a solution for when the rectangle is axis-aligned.</p>

<p>First, you build up you current object's rectangle with the following values:</p>

<pre><code>int boxLeft = box.X;
int boxRight = boxLeft + box.Width;
int boxTop = box.Y;
int boxBottom = boxTop + box.Height;
</code></pre>

<p>Next, you must have the old object's position (which you can store on each object or simply pass to a function) to create the old object's rectangle (when it was not colliding):</p>

<pre><code>int oldBoxLeft = box.OldX;
int oldBoxRight = oldBoxLeft + box.Width;
int oldBoxTop = box.OldY;
int oldBoxBottom = oldBoxTop + box.Height;
</code></pre>

<p>Now, to know where the collision was from, you must find the side where the old position was not in the collision area and where its new position is. Because, when you think of it, this is what happens when you collide: a side that was not colliding enters an other rectangle.</p>

<p>Here is how you could do so (these functions assume that there is a collision. They should not be called if there is no collision):</p>

<pre><code> bool collidedFromLeft(Object otherObj)
{
    return oldBoxRight &lt; otherObj.Left &amp;&amp; // was not colliding
           boxRight &gt;= otherObj.Left;
}
</code></pre>

<p>Rince and repeat.</p>

<pre><code>bool collidedFromRight(Object otherObj)
{
    return oldBoxLeft &gt;= otherObj.Right &amp;&amp; // was not colliding
           boxLeft &lt; otherObj.Right;
}

bool collidedFromTop(Object otherObj)
{
    return oldBoxBottom &lt; otherObj.Top &amp;&amp; // was not colliding
           boxBottom &gt;= otherObj.Top;
}

bool collidedFromBottom(Object otherObj)
{
    return oldBoxTop &gt;= otherObj.Bottom &amp;&amp; // was not colliding
           boxTop &lt; otherObj.Bottom;
}
</code></pre>

<p>Now, for the actual use with the collision response from the other question:</p>

<pre><code>if (collidedFromTop(otherObj) || collidedFromBottom(otherObj))
    obj.Velocity.Y = -obj.Velocity.Y;
if (collidedFromLeft(otherObj) || collidedFromRight(otherObj))
    obj.Velocity.X = -obj.Velocity.X;
</code></pre>

<p>Again, this may not be the best solution but that's the way I usually go for collision detection.</p>
","13781"
"What is the difference between a sprite sheet and a texture atlas?","9940","","<p>I wondering what the difference is between a sprite sheet and a texture atlas?</p>

<p>Aren't both the same? In a sprite sheet you have some Sprites and in a texture atlas you also have some sprites, so what's the difference?</p>
","<p>A sprites-sheet (often refers to a large image that) is supposed to contain the <strong>animation frames</strong> of a specific <em>2d</em> character or projectile in a game. You can almost think of it as the <em>model</em> of a 2d-character. It stores all the various animations created for a specific character.</p>

<p><a href=""https://i.stack.imgur.com/lWm0b.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/lWm0b.png"" alt=""enter image description here""></a></p>

<p>A texture-atlas (is often taken to mean a large 2d image that) contains many <strong>textures</strong>. You can think of these as 2d images ""painted"" over 3d objects or otherwise applied to them as part of a shader to explain to the renderer (the part that converts 3d data into a 2d image) how they reflect light (normal map) or if there are any grooves, bumps or cracks on their surface (bump map) or possibly something else altogether like opacity and what not.
This term (texture atlas) will often be used in a <code>3d</code> game environment. Any 3d object (e.g a weapon, a garbage can) or character can have a texture applied to it. Especially 3d levels may require multiple different textures for various walls and elements in the 3d scenery. All these textures can be contained accessibly and effectively in a single large image composed of many squares (subregions) devoted to a specific model.</p>

<p><a href=""https://i.stack.imgur.com/iD6Gi.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/iD6Gi.jpg"" alt=""enter image description here""></a></p>

<p>Also, it may be important to note a texture atlas often contains character skins (character textures) and that the actual animation is (stating the obvious) not stored as 2d imagery as the animation in such cases is generally based on deformation of the mesh with tools like bones.</p>
","69898"
"Repeat texture in libgdx","9939","","<p>How to fill region with repeated texture? Now I'm using next method:</p>

<pre><code>spriteBatch.begin();

final int tWidth = texture.getWidth();
final int tHeight = texture.getHeight();

for (int i = 0; i &lt; regionWidth / tWidth; i++) {
    for (int k = 0; k &lt; regionHeight / tHeight; k++) {
        spriteBatch.draw(texture, i*tWidth, k);
    }
}

spriteBatch.end();
</code></pre>

<p>It's very obvious. Maybe is there any built in method?</p>
","<p>You want to set the texture's <code>TextureWrap</code> setting to <code>Repeat</code>. See <a href=""https://libgdx.badlogicgames.com/nightlies/docs/api/com/badlogic/gdx/graphics/Texture.TextureWrap.html"" rel=""nofollow"">the documentation</a> for more information, and the <a href=""https://libgdx.badlogicgames.com/nightlies/docs/api/com/badlogic/gdx/graphics/GLTexture.html#setWrap-com.badlogic.gdx.graphics.Texture.TextureWrap-com.badlogic.gdx.graphics.Texture.TextureWrap-"" rel=""nofollow"">texture method</a>.</p>

<p>Specifically:</p>

<pre><code>setWrap(Repeat, Repeat);
</code></pre>
","34655"
"Polling vs event driven input","9933","","<p>I'm developing a game using polling for the input method. However, now that I'm delving deeper into the game menus and other UI components, I'm finding that I'd probably like to have event driven input. Perhaps even having both, using event driven for the UI and polling for the ""world"" input. I'm curious on what the best way to go is.</p>

<p>I'm defining polling as: each update loop I check what keys are press, where the mouse is, buttons pressed, then run through them and do actions based on the info collected.</p>

<p>I'm defining event driven as: interrupt based events, when an event happens and interrupt is triggered and a code block is run based on the event.</p>

<p>Do you think it's best to go all event driven, all polling, or is a combination of both acceptable? If you have pros and cons for either please list them. Thanks.</p>

<p><strong>EDIT</strong></p>

<p>The game is Java/OpenGL based, so will be released to Windows/Mac/Linux. The possibility of extending that to mobile devices is low. The game is RTS style, 3rd person 3D.</p>

<p><strong>EDIT 2</strong></p>

<p>I'm still not totally happy with the way I've implemented this, but what I'm moving toward is catching events in my UI and if they're not handled by any of my UI components, I pass the event on to the ""World"" for picking/selection. Something like:</p>



<pre class=""lang-java prettyprint-override""><code>@Override  
private boolean handleEvent(Event event) {  
    if(hud.handleEvent(event)) {  
        return true;  
    }  
    return WORLD.handleEvent(event);  
}
</code></pre>

<p>This way I don't get clicks leaking through the UI to select objects behind buttons and what not.</p>

<p>Currently my camera controls are still based on polling, and that seems to be working for now, but I may update that later on.</p>

<p>I appreciate all the answers, sorry I could only pick one!</p>
","<p>It depends on the requirements of your game and hardware. Most games are usually interested in changes to input state, i.e. user presses the fire key and their weapon starts firing, user releases the fire key and their weapon stops firing, user presses the move key and starts moving, releases the move key and stops moving, etc., so an event-driven input system makes the most sense in those cases since the information is already in a suitable format. Plus on the Windows platform, you already receive events for changes to keyboard and mouse state, so it's often a 1:1 conversion from low-level input events to high-level game events. With polling, you'll often find yourself having to generate such events manually by comparing state between the current and last frame. Basically, ""which buttons are pressed now?"" tends to be far less useful information than ""which buttons have been pressed/released this frame?"", and given an initial keyboard/mouse state when you initialize your input subsystem, the former can be inferred from the latter anyway for those cases when you need it.</p>

<p>That being said, on certain platforms you're stuck with polling input at a low-level and there's no way around doing the edge checking yourself. However, I've always achieved the best results using events for all high-level logic since that's naturally how those systems tend to operate.</p>
","12148"
"Heightmap, Voxel, Polygon (geometry) terrains","9920","","<p>In relation to Heightmap, Voxel and Polygon (geometry) terrains:</p>

<ol>
<li>What are the main differences between all these three?</li>
<li>Can you form a ""smooth"" terrain with Voxels, I mean, can you for example get a smooth mountain with Voxels, or Voxels are limited to cubes?</li>
<li>Performance wise, a world 2000x2000 units, what would be faster Heightmap terrain, Voxel terrain or Polygon based, geometry terrain? (Assuming that there is ""reasonable"" performance gains/optimization done for rendering for every of possibilities)</li>
<li>Are there any more techniques used for terrain creation?</li>
<li>Any good titles representing each of types?</li>
</ol>

<p>P.S. Polygon based terrain should be fully traingulated, no squareish stuff.</p>
","<h1>Heightmaps</h1>

<p>With a heightmap, you store only the height component for each vertex (usually as 2D texture) and provide position and resolution only once for the whole quad. The landscape geometry is generated each frame using the geometry shader or hardware tessellation. Heightmaps are the fastest way to store landscape data for collision detection.</p>

<h2>Pros:</h2>

<ul>
<li><p><strong>Relatively low memory usage</strong>: You only need to store one value per vertex and no indices. It's possible to improve this further by using detail maps or a noise filter to increase perceived detail.</p></li>
<li><p><strong>Relatively fast</strong>: The geometry shader for heightmaps is small and runs fast. It's not as fast as geometry terrain though.<br>
On systems without triangle based 3D acceleration, ray marching heightmaps is the fastest way to render terrain. This was referred to as voxel graphics in older games.</p></li>
<li><p><strong>Dynamic LOD/terrain</strong>: It's possible to change the resolution of the generated mesh based on distance from the camera. <a href=""http://www.youtube.com/watch?v=7jUGPFRt4bg"">This will cause the shifting geometry if the resolution drops too far (around 0:40), but can be used for interesting effects.</a></p></li>
<li><p><strong>Easy terrain generation/creation</strong>: Heightmaps can easily be created by blending noise functions like fractal <a href=""http://en.wikipedia.org/wiki/Perlin_noise"">Perlin Noise</a> and heightmap editors are fast and easy to use. Both approaches can be combined. They are also easy to work with in an editor.</p></li>
<li><p><strong>Efficient physics</strong>: A horizontal position maps directly to (usually) one to four positions in memory, so geometry lookups for physics are very fast. </p></li>
</ul>

<h2>Cons:</h2>

<ul>
<li><p><strong>Exactly one height per x/y coordinate</strong>: There usually can't be holes in the ground or overhanging cliffs.</p></li>
<li><p><strong>Less control</strong>: You can only control the precise height of each point if the grid size matches the texture coordinates.</p></li>
<li><p><strong>Artifacts</strong>: If the four vertices that define a sub-quad aren't on the same plane, the split between the two vertices will become visible. This usually happens on steep cliffs with edges that don't follow a cardinal direction.</p></li>
</ul>

<p>Heightmaps are the most efficient way of rendering terrain by far and are used in many newer games that don't rely on advanced terrain features and have large outdoor areas. <a href=""http://en.wikipedia.org/wiki/Heightmap#Programs_that_use_heightmaps"">Wikipedia has a list of programs that use heightmaps</a>, but I'm not sure if that means they only use them as resources or also for rendering, so here a some games that are <em>likely</em> to use them:</p>

<ul>
<li><p>Just Cause 2: Regions are loaded in square sectors and there are no holes in the terrain. In the demo, there's a deep hole with stretched triangles along the edges where there normally would be a building. (The area is normally inaccessible, but there are mods to remove some of the demo's limitations...)</p></li>
<li><p>Sims 2 (<em>maybe</em>): Neighborhood terrain is loaded as heightmap, but there are holes where lots (building sites) are placed. There are typical artifacts if you create cliffs on a lot, though, and it's quite tedious to add a cellar to a house (and hide the cliff under a veranda).</p></li>
<li><p>Valve's Source engine games: Rectangular brushes (static level geometry) can have heightmapped terrain on their faces. In these games, the usual quirks are often hidden with other brushes or props.</p></li>
</ul>

<p>It's impossible to tell for sure without looking at the shaders because every heightmap terrain can be rendered as mesh.</p>

<h1>Voxels</h1>

<p>Voxel terrain stores terrain data for each point in a 3D grid. This method always uses the most storage per meaningful surface detail, even if you use compression methods like sparse octrees.</p>

<p>(The term ""voxel engine"" was often used to describe a method of ray marching terrain heightmaps common in older 3D games. This section applies only to terrain stored as voxel data.)</p>

<h2>Pros:</h2>

<ul>
<li><p><strong>Continuous 3D data</strong>: Voxels are pretty much the only efficient way to store continuous data about hidden terrain features like ore veins.</p></li>
<li><p><strong>Easy to modify</strong>: Uncompressed voxel data can be changed easily.</p></li>
<li><p><strong>Advanced terrain features</strong>: It's possible to create overhangs. Tunnels are seamless.</p></li>
<li><p><strong>Interesting terrain generation</strong>: <a href=""http://www.minecraft.net/"">Minecraft</a> does this by overlaying noise functions and gradients with predefined terrain features (trees, dungeons). (Read <a href=""http://notch.tumblr.com/post/3746989361/terrain-generation-part-1"">Terrain Generation, Part 1</a> in Notch's blog for more info. There is no part 2 as of 05.8.2011.)</p></li>
</ul>

<h2>Cons:</h2>

<ul>
<li><p><strong>Slow</strong>: To render voxel data, you either have to <a href=""http://www.youtube.com/watch?v=lpfaFrazOn4"">use a ray tracer</a> or compute a mesh, for example with <a href=""http://de.wikipedia.org/wiki/Marching_Cubes"">marching cubes</a> (There will be artifacts). Neighboring voxel aren't independent for mesh generation and the shaders are more complicated and usually produce more complex geometry. Rendering voxel data with high LOD can be very slow.</p></li>
<li><p><strong>Huge storage requirements</strong>: Storing voxel data uses <strong>lots of memory</strong>. It's often not practicable to load the voxel data into VRAM for this reason, as you'd have to use smaller textures to compensate for it, even on modern hardware.</p></li>
</ul>

<p>It's not practical to use voxels for games that don't rely on voxel features like deformable terrain, but it can allow interesting game mechanics in some cases. <a href=""http://en.wikipedia.org/wiki/Voxel#Computer_gaming"">Voxel engines are more common in older games</a>, but there are also newer examples:</p>

<ul>
<li><p><a href=""http://atomontage.com/"">Atomontage engine</a>: Voxel rendering.</p></li>
<li><p>Worms 4: Uses ""poxels"". According to Wikipedia it's a mix of voxels and polygons.</p></li>
<li><p>Minecraft: Uses voxel to represent the terrain in RAM, the graphics are polygon graphics. It's mostly software calculated though.</p></li>
<li><p>Terraria: An example for 2D voxels. I don't know how it renders.</p></li>
<li><p><a href=""http://www.youtube.com/watch?v=eQMBGLMtdFE"">Voxels combined with physics</a>: Not a game. but it nicely showcases the destruction potential.</p></li>
<li><p><a href=""http://www.lexaloffle.com/voxatron.php"">Voxatron</a>: A game using voxels for almost all of the graphics, including menus and HUD.</p></li>
</ul>

<h1>Meshes</h1>

<p>Polygon meshes are the most flexible and precise way of storing and rendering terrain. They are often used in games where precise control or advanced terrain features are needed.</p>

<h2>Pros:</h2>

<ul>
<li><p><strong>Very fast</strong>: You only have to do the usual projection calculation in the vertex shader. A geometry shader isn't needed.</p></li>
<li><p><strong>Very precise</strong>: All coordinates are store individually for each vertex, so it's possible to move them horizontally and increase mesh density in places with finer details.</p></li>
<li><p><strong>Low memory impact</strong>: This also means the mesh will usually need less memory than a heighmap, because vertices can be more sparse in areas with less small features.<br>
(See <a href=""http://en.wikipedia.org/wiki/Triangulated_irregular_network"">Triangulated irregular network</a> on Wikipedia).</p></li>
<li><p><strong>No artifacts</strong>: The mesh is rendered as-is, so there won't be any glitches or strange-looking borders.</p></li>
<li><p><strong>Advanced terrain features</strong>: It's possible to leave holes and create overhangs. Tunnels are seamless.</p></li>
</ul>

<h2>Cons:</h2>

<ul>
<li><p><strong>Poor dynamic LOD</strong>: Only possible with precomputed meshes. This will cause ""jumps"" when switching without additional data to map old to new vertices.</p></li>
<li><p><strong>Not easy to modify</strong>: Finding vertices that correspond to an area that should be modified is slow.</p></li>
<li><p><strong>Not very efficient for collision detection</strong>: Unlike in heightmaps and voxel data, the memory address for a certain location usually can't be calculated directly. This means physics and game logic that depend on the exact surface geometry will most likely run slower than with the other storage formats.</p></li>
</ul>

<p>Polygon terrain is often uses in games that don't have large open areas or can't use heightmap terrain because of its lack of precision and overhangs. I don't have a list, but I'm pretty sure that</p>

<ul>
<li><p>every 3D Zelda and</p></li>
<li><p>every 3D Mario game</p></li>
</ul>

<p>use this.</p>

<h1>Other methods</h1>

<p>It's possible to create a terrain entirely in the shader pipeline. If the algorithm runs only in the fragment/pixel shader, the detail can be virtually unlimited while memory impact is almost zero. The obvious downsides are almost no control over the shape and problems when the camera intersects the original rendering surface. It's still useful in space games where players don't interact with the surface of a planet.
Parameter animations work best with this kind of terrain.</p>

<p>It should be possible to download the generated terrain geometry from the graphics card to use it for the rest of the game engine, but I don't know how the performance of that is or whether this has been done so far.</p>

<h1>Conclusion</h1>

<p>There is no method that works well for every scenario, but it's fairly easy to choose one for a certain task:</p>

<ul>
<li><p><strong>Heightmaps</strong> are the best solution if you don't need overhangs or holes in the terrain surface and use physics or dynamic terrain. They are scalable and work well for most games.</p></li>
<li><p><strong>Meshes</strong> have the highest precision and can describe overhangs, holes and tunnels. Use them if you have complex terrain that doesn't change often.</p></li>
<li><p><strong>Voxels</strong> are good for describing very dynamic terrain with many complex features. Avoid rendering them directly as they need large amounts of memory and processing.</p></li>
<li><p><strong>Other methods</strong> may be better than any of the above if you don't have to interact with the terrain or need very detailed graphics. They usually work only for very specific scenarios.</p></li>
</ul>

<p>It's possible to combine different methods to get features from more than one, for example by tessellating mesh terrain with a heightmap to increase the detail structure of a cliff.</p>

<p>Dynamic terrain generation is heavily used in <a href=""http://freegamer.blogspot.com/2011/01/oh-my-god-its-full-of-stars-free-and.html"">procedural space simulation</a> and <a href=""http://www.infinity-universe.com/"">some have become really advanced in the last years</a>. The forums of these projects should have some resources on the topic.</p>
","15628"
"How can I implement lighting in a voxel engine?","9919","","<p>I am creating the MC like terrain engine, and I have thought that lighting would make it look a whole lot nicer.The problem is that the blocks are not being lit properly when a block which emits light is placed (see the screenshots at the bottom on the page.</p>

<p>So far I want to implement minecraft's ""blocky"" lighting. So I created a VertexFormat:</p>

<pre><code> struct VertexPositionTextureLight
    {
        Vector3 position;
        Vector2 textureCoordinates;
        float light;

        public readonly static VertexDeclaration VertexDeclaration = new VertexDeclaration
        (
            new VertexElement(0, VertexElementFormat.Vector3, VertexElementUsage.Position, 0),
            new VertexElement(sizeof(float) * 3, VertexElementFormat.Vector2, VertexElementUsage.TextureCoordinate, 0),
            new VertexElement(sizeof(float) * 5, VertexElementFormat.Single, VertexElementUsage.TextureCoordinate, 1)
        );

        public VertexPositionTextureLight(Vector3 position, Vector3 normal, Vector2 textureCoordinate, float light)
        {
            // I don't know why I included normal data :)
            this.position = position;
            this.textureCoordinates = textureCoordinate;
            this.light = light;
        }
    }
</code></pre>

<p>I guess if I want to implement lighting I have to specify a light for each vertex... And now in my effect file I want to be able to take that value and light up the vertex accordingly:</p>

<pre><code>float4x4 World;
float4x4 Projection;
float4x4 View;

Texture Texture;

sampler2D textureSampler = sampler_state  {
    Texture = &lt;Texture&gt;;
    MipFilter = Point;
    MagFilter = Point;
    MinFilter = Point;
    AddressU = Wrap;
    AddressV = Wrap;
};

struct VertexToPixel  {
    float4 Position     : POSITION;
    float4 TexCoords    : TEXCOORD0;
    float4 Light        : TEXCOORD01;
};

struct PixelToFrame  {
    float4 Color        : COLOR0;
};

VertexToPixel VertexShaderFunction(float4 inPosition : POSITION, float4 inTexCoords : TEXCOORD0, float4 light : TEXCOORD01)  {
    VertexToPixel Output = (VertexToPixel)0;

    float4 worldPos = mul(inPosition, World);
    float4 viewPos = mul(worldPos, View);

    Output.Position = mul(viewPos, Projection);
    Output.TexCoords = inTexCoords;
    Output.Light = light;

    return Output;
}

PixelToFrame PixelShaderFunction(VertexToPixel PSIn)  {
    PixelToFrame Output = (PixelToFrame)0;

    float4 baseColor = 0.086f;
    float4 textureColor = tex2D(textureSampler, PSIn.TexCoords);
    float4 colorValue = pow(PSIn.Light / 16.0f, 1.4f) + baseColor;

    Output.Color = textureColor;

    Output.Color.r *= colorValue;
    Output.Color.g *= colorValue;
    Output.Color.b *= colorValue;
    Output.Color.a = 1;

    return Output;
}

technique Block  {
    pass Pass0  {
        VertexShader = compile vs_2_0 VertexShaderFunction();
        PixelShader = compile ps_2_0 PixelShaderFunction();
    }
}

VertexToPixel VertexShaderBasic(float4 inPosition : POSITION, float4 inTexCoords : TEXCOORD0)  {
    VertexToPixel Output = (VertexToPixel)0;

    float4 worldPos = mul(inPosition, World);
    float4 viewPos = mul(worldPos, View);

    Output.Position = mul(viewPos, Projection);
    Output.TexCoords = inTexCoords;

    return Output;
}

PixelToFrame PixelShaderBasic(VertexToPixel PSIn)  {
    PixelToFrame Output = (PixelToFrame)0;

    Output.Color = tex2D(textureSampler, PSIn.TexCoords);

    return Output;
}


technique Basic  {
    pass Pass0  {
        VertexShader = compile vs_2_0 VertexShaderBasic();
        PixelShader = compile ps_2_0 PixelShaderBasic();
    }
}
</code></pre>

<p>And this is an example on how i apply lighting:</p>

<pre><code>            case BlockFaceDirection.ZDecreasing:
                light = world.GetLight((int)(backNormal.X + pos.X), (int)(backNormal.Y + pos.Y), (int)(backNormal.Z + pos.Z));

                SolidVertices.Add(new VertexPositionTextureLight(bottomRightBack, backNormal, bottomLeft, light));
                SolidVertices.Add(new VertexPositionTextureLight(bottomLeftBack, backNormal, bottomRight, light));
                SolidVertices.Add(new VertexPositionTextureLight(topRightBack, backNormal, topLeft, light));
                SolidVertices.Add(new VertexPositionTextureLight(topLeftBack, backNormal, topRight, light));
                AddIndices(0, 2, 3, 3, 1, 0);
                break;
</code></pre>

<p>And last of all here is the algorythim that calculates it all:</p>

<pre><code>    public void AddCubes(Vector3 location, float light)
    {
        AddAdjacentCubes(location, light);
        Blocks = new List&lt;Vector3&gt;();
    }

    public void Update(World world)
    {
        this.world = world;
    }

    public void AddAdjacentCubes(Vector3 location, float light)
    {
        if (light &gt; 0 &amp;&amp; !CubeAdded(location))
        {
            world.SetLight((int)location.X, (int)location.Y, (int)location.Z, (int)light);
            Blocks.Add(location);

            // Check ajacent cubes
            for (int x = -1; x &lt;= 1; x++)
            {
                for (int y = -1; y &lt;= 1; y++)
                {
                    for (int z = -1; z &lt;= 1; z++)
                    {
                        // Make sure the cube checked it not the centre one
                        if (!(x == 0 &amp;&amp; y == 0 &amp;&amp; z == 0))
                        {
                            Vector3 abs_location = new Vector3((int)location.X + x, (int)location.Y + y, (int)location.Z + z);

                            // Light travels on transparent block ie not solid
                            if (!world.GetBlock((int)location.X + x, (int)location.Y + y, (int)location.Z + z).IsSolid)
                            {
                                AddAdjacentCubes(abs_location, light - 1);
                            }
                        }
                    }
                }
            }

        }
    }

    public bool CubeAdded(Vector3 location)
    {
        for (int i = 0; i &lt; Blocks.Count; i++)
        {
            if (location.X == Blocks[i].X &amp;&amp;
                location.Y == Blocks[i].Y &amp;&amp;
                location.Z == Blocks[i].Z)
            {
                return true;
            }
        }

        return false;
    }
</code></pre>

<p>Any suggestions and help would be much appreciated </p>

<p><strong>SCREENSHOTS</strong>
Notice the artifacts on the top on the terrain and how only the left part is partically lit...
<img src=""https://i.stack.imgur.com/2z2XS.png"" alt=""Attempt at lighting 1"">
For some reason only certain sides of the cube is being lit and it doesn't light the ground
<img src=""https://i.stack.imgur.com/xCvDM.png"" alt=""Attempt at lighting 2""></p>

<p><img src=""https://i.stack.imgur.com/TwMRi.png"" alt=""Another example of the previous""></p>

<p>Figured out my problem! I was not checking if that block was already lit and if so to what degree (if it is lower light it higher)</p>

<pre><code>    public void DoLight(int x, int y, int z, float light)
    {
        Vector3 xDecreasing = new Vector3(x - 1, y, z);
        Vector3 xIncreasing = new Vector3(x + 1, y, z);
        Vector3 yDecreasing = new Vector3(x, y - 1, z);
        Vector3 yIncreasing = new Vector3(x, y + 1, z);
        Vector3 zDecreasing = new Vector3(x, y, z - 1);
        Vector3 zIncreasing = new Vector3(x, y, z + 1);

        if (light &gt; 0)
        {
            light--;

            world.SetLight(x, y, z, (int)light);
            Blocks.Add(new Vector3(x, y, z));

            if (world.GetLight((int)yDecreasing.X, (int)yDecreasing.Y, (int)yDecreasing.Z) &lt; light &amp;&amp;
                world.GetBlock((int)yDecreasing.X, (int)yDecreasing.Y, (int)yDecreasing.Z).BlockType == BlockType.none)
                DoLight(x, y - 1, z, light);
            if (world.GetLight((int)yIncreasing.X, (int)yIncreasing.Y, (int)yIncreasing.Z) &lt; light &amp;&amp;
                world.GetBlock((int)yIncreasing.X, (int)yIncreasing.Y, (int)yIncreasing.Z).BlockType == BlockType.none)
                DoLight(x, y + 1, z, light);
            if (world.GetLight((int)xDecreasing.X, (int)xDecreasing.Y, (int)xDecreasing.Z) &lt; light &amp;&amp;
                world.GetBlock((int)xDecreasing.X, (int)xDecreasing.Y, (int)xDecreasing.Z).BlockType == BlockType.none)
                DoLight(x - 1, y, z, light);
            if (world.GetLight((int)xIncreasing.X, (int)xIncreasing.Y, (int)xIncreasing.Z) &lt; light &amp;&amp;
                world.GetBlock((int)xIncreasing.X, (int)xIncreasing.Y, (int)xIncreasing.Z).BlockType == BlockType.none)
                DoLight(x + 1, y, z, light);
            if (world.GetLight((int)zDecreasing.X, (int)zDecreasing.Y, (int)zDecreasing.Z) &lt; light &amp;&amp;
                world.GetBlock((int)zDecreasing.X, (int)zDecreasing.Y, (int)zDecreasing.Z).BlockType == BlockType.none)
                DoLight(x, y, z - 1, light);
            if (world.GetLight((int)zIncreasing.X, (int)zIncreasing.Y, (int)zIncreasing.Z) &lt; light &amp;&amp;
                world.GetBlock((int)zIncreasing.X, (int)zIncreasing.Y, (int)zIncreasing.Z).BlockType == BlockType.none)
                DoLight(x, y, z + 1, light);
        }
    }
</code></pre>

<p>Altough the above works, would anyone know how I would make it more performace efficent?</p>
","<p>I've implemented something similar to this. I wrote up a post about it on my blog: <a href=""http://www.byte56.com/2011/06/a-light-post.html"" rel=""noreferrer"">byte56.com/2011/06/a-light-post</a>. But I'll go into a little more detail here.</p>

<p>While the codeflow article linked in another answer is pretty interesting. From what I understand, it's not how Minecraft does its lighting. Minecraft lighting is more cellular automata then traditional light source.</p>

<p>I assume you're familiar with water flow in MC. Lighting in MC is essentially the same thing. I'll walk you through a simple example.</p>

<p>Here are a few things to keep in mind.</p>

<ul>
<li>We're going to keep a list of cubes that need their lighting values checked</li>
<li><strong>Only transparent cubes and light emitting cubes have lighting values</strong></li>
</ul>

<p>The first cube we add is the light source. A source is a special case. It's light value is set accordingly to the light source type (for example torches get a brighter value than lava). If a cube has its light value set above 0, we add all the transparent cubes adjacent to that cube to the list. For each cube on the list, we set its light value to its brightest neighbor minus one. This means that all the transparent cubes (this includes ""air"") next to the light source get a light value of 15.  We continue walking the cubes around the light source, adding cubes that need to be checked and taking lit cubes off the list, util we no longer have any to add. That means that all the latest values set have been set to 0, which means we've reached the end of our light.</p>

<p>That's a fairly simple explanation of lighting. I've done something a little more advanced, but I started with the same basic principle. This is an example of what it produces:</p>

<p><img src=""https://i.stack.imgur.com/JKVCQ.jpg"" alt=""enter image description here""></p>

<p>Now that you have all your light data set. When you're building the color values for your vertices, you can reference this brightness data. You could do something like this (where light is an int value between 0 and 15):</p>

<pre><code>float baseColor = .086f;
float colorValue = (float) (Math.pow(light / 16f, 1.4f) + baseColor );
return new Color(colorValue, colorValue, colorValue, 1);
</code></pre>

<p>Basically I'm taking the light value from 0 to 1 to the power of 1.4f. This gives me a slightly darker darks than a linear function. Ensure that your color value never goes above 1. I did that by dividing by 16, instead of 15 so I'd always have a little extra room. Then moved that extra to the base so I'd always have a little texture and not pure blackness.</p>

<p>Then in my shader (similar to an effects file), I get the fragment color for the texture and multiply that by the lighting color I create above. This means full brightness gives the texture as it was created. Very low brightness gives the texture as very dark (but not black because of the base color). </p>

<p><strong>EDIT</strong></p>

<p>To get the light for a face, you look at the cube in the direction of the normal of the face. For example, top face of cube gets the light data from the cube above.</p>

<p><strong>EDIT 2</strong></p>

<p>I'll attempt to address some of your questions.</p>

<p><em>So what I would do is something like recursion in this case?</em></p>

<p>You can use a recursive algorithm or iterative. It's up you you how you want to implement it. Just ensure you're keeping track of which cubes have been added already, otherwise you'll keep going forever.</p>

<p><em>Also how would the algorithm ""light downwards""?</em></p>

<p>If you're talking about sunlight, sunlight is a bit different, since we don't want it to decrease in brightness. My cube data includes a SKY bit. If a cube is marked as SKY that means it has clear access to the open sky above it. SKY cubes always get full lighting minus the darkness level. Then cubes next to sky, that are not sky, like cave entrances or overhangs, the normal lighting procedure takes over.
If you're just talking about a point light shining down... it's the same as any other direction.</p>

<p><em>How would I specify the light for a single face only?</em></p>

<p>You don't specify light for a single face only. Each transparent cube specifies the light for all the solid cubes that share a face with it. If you want to get the light for a face, simply check the light value for the transparent cube it's touching. If it's not touching a transparent cube, then you wouldn't be rendering it anyway.</p>

<p><em>Code samples?</em></p>

<p>Nope.</p>
","21247"
"What state is stored in an OpenGL Vertex Array Object (VAO) and how do I use the VAO correctly?","9905","","<p>I was wondering what state is stored in an OpenGL VAO. I've understood that a VAO contains state related to the vertex specifications of buffered vertices (what attributes are in the buffers, and what buffers are bound, ... ). To better understand the correct usage of VAO's, I'd like to know exactly what state they hold. </p>

<hr>

<h1>How I assume VAO's should be used</h1>

<p>From simple examples, I've understood that correct usage of VAO's is as follows:</p>

<p><strong>Setup</strong></p>

<pre><code>Generate VAO
BindVAO
---- Specify vertex attributes
---- Generate VBO's
---- BindVBO's
-------- Buffer vertex data in VBO's
---- Unbind VBO's
Unbind VAO
</code></pre>

<p><strong>Rendering</strong></p>

<pre><code>Bind VAO
---- Draw
Unbind VAO
</code></pre>

<p>From this, I assume that at least the <strong>vertex buffer bindings</strong> and the <strong>vertex attribute specifications</strong> are stored in the VAO. I'm unsure however how this usage pattern extends to situations where (multiple) textures and (multiple) shader programs come into play. Is the <strong>active shader program</strong> stored in the VAO? And are the <strong>texture bindings</strong> (with their <strong>sampling/ wrapping settings</strong>) stored in the VAO as well? Ditto for <strong>uniforms</strong>? </p>

<hr>

<p>Therefore, my questions are:</p>

<ul>
<li>What exact <strong>state</strong> is stored in an <strong>OpenGL VAO</strong>? (VBO bindings, attribute specifications, active shader program, texture bindings, texture sampling/wrapping settings, uniforms ... ?)</li>
<li>How do I <strong>correctly use VAO's</strong> in a more <strong>complex rendering setup</strong> where (multiple) textures with associated sampling/wrapping settings, (multiple) shader programs and uniforms are involved?</li>
</ul>
","<p>VAO stores data about vertex attribute locations. (And some other data related to them.)<br>
<code>""VBO bindings, active shader program, texture bindings, texture sampling/wrapping settings, uniforms""</code> are completely unrelated to it.</p>

<p>You may ask why it doesn't remember VBO binding. Because you don't need to bind VBO to draw something, you only need to bind it when creating VAO: When you call <code>glVertexAttribPointer(...)</code>, VAO remembers what VBO is currently bound. And VAO will take attributes from these VBOs when you draw it, even if these VBOs are not bound currently.</p>

<hr>

<p>Also, VAOs and VBOs must be used slighty differently:</p>

<p>This will not work</p>

<pre><code>Generate VAO
BindVAO
---- Specify vertex attributes
---- Generate VBO's
---- BindVBO's
-------- Buffer vertex data in VBO's
---- Unbind VBO's
Unbind VAO
</code></pre>

<p>because you need to bind VBO to specify attribute locations.</p>

<p>So, you should do it like this:</p>

<pre><code>Generate VAO
BindVAO
Generate VBO's
BindVBO's
Specify vertex attributes
</code></pre>

<p>You can change VBO's data whenever you want, but you must bind it before.</p>

<p>And drawing should look like this:</p>

<pre><code>Bind VAO
Draw
</code></pre>

<p><br>
As you may noticed, I removed <code>unbind</code> calls from your lists. They are almost completely useless and they will slightly slow down your program, so I see no reason to call them.</p>
","99238"
"Transparent parts of texture are opaque black instead","9895","","<p>I render a sprite twice, one on top of the other.  The sprites have transparent parts, so I should be able to see the bottom sprite under the top sprite.  The transparent parts are black (the clear colour) and opaque instead though and the topmost sprite blocks the bottom sprite.</p>

<p>My fragment shader is trivial:</p>

<pre><code>uniform sampler2D texture;
varying vec2 f_texcoord;
void main()
{
    gl_FragColor = texture2D(texture, f_texcoord);
}
</code></pre>

<p>I have <code>glEnable(GL_BLEND)</code> and <code>glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA)</code> in my initialization code.  My texture comes from a PNG file that I load with libpng.  I'm sure to use <code>GL_RGBA</code> when initializing the texture with <code>glTexImage2D</code> (otherwise the sprites look like noise).</p>

<p><strong>Edit:</strong> Here's a screenshot.</p>

<p><img src=""https://i.stack.imgur.com/fkNm7.png"" alt=""enter image description here""></p>
","<p>What do you get if you try and swap the order you draw them in?</p>

<p>Transparent pixels still create depth buffer entries. If you're drawing the back one after the first it's not processing the pixels behind the front image, making it look like there's no alpha.</p>

<p>For reference, take a look at the <a href=""http://en.wikipedia.org/wiki/Painter%27s_algorithm"">Painter's alogrithm</a>.</p>
","32066"
"How to design a server for a multiplayer game?","9879","","<p>I'm trying to write a multiplayer game where players join small matches with other players. What I also want is a way for players to login and go online. How would I design the a server that could handle logging in, matchmaking and the actual running of the match? I'd like to have multiple threads on the server to handle input from all the players, but I'm not exactly sure what I want to put in a single process and what I want to split apart. How would I set up the sockets for something like this? </p>

<p>I'd probably end up having this run on Amazon EC2 or something similar if that makes a difference.</p>

<p>I was planning on making the game a MOBA where there would be a small number of players (6-10) and latency would be relevant. </p>
","<p>Depending on what language you are using, the answer can vary.</p>

<p>However, if you know any Java, or can at least get the gist of it, here's some old code I wrote to handle something like this.</p>

<p><a href=""https://github.com/TheDudeFromCI/WraithEngine/tree/5397e2cfd75c257e4d96d0fd6414e302ab22a69c/WraithEngine/src/wraith/library/Multiplayer"" rel=""nofollow"">https://github.com/TheDudeFromCI/WraithEngine/tree/5397e2cfd75c257e4d96d0fd6414e302ab22a69c/WraithEngine/src/wraith/library/Multiplayer</a></p>

<p>Basically it works like this. First, on your server, wherever it's being hosted, you have it open a socket on a port you choose. This should go on a dedicated thread, and handle ONLY this task. This should always be open, and listening for anyone trying to connect. When someone finally does connect, create a new dedicated thread, with a socket connecting to that client. When that client loses connection, (logs off, or force quits) kill the thread.</p>

<p>For the client, it's even simpler. Just have 1 thread, and have it try to connect to the server ip, (if you have only one server, hard code it in. If multiple, then you can have the player type it in.) And use the same port as you chose for the server. If a socket is able to be opened, connect, and that thread will be dedicated with chatting with the server. If you want to avoid delays in gameplay, this should not be your main thread, but in addition to. Then when a message is sent or received, pass it asynchronously to the main thread. To avoid stalling, make sure the main thread is never ""waiting"" on the server thread. (A waiting screen is fine for times where waiting is needed, because it doesn't cancel rendering events, or input events. So the program won't be marked as unresponsive.)</p>

<p>Now you should be able to handle an infinite number of new clients trying to connect.</p>

<p>Now, each thread is a seperate client. So keep these all in a list. Most likely in some kind of thread wrapper to handle easier packet sending and receiving. If you want some security, use a handshake packet. This means that the server ""asks a question"" sort of speak, and if the client doesn't answer, or answers incorrectly, it kicks them. Also, banned ips should be kicked before even the handshake.</p>

<p>Now, in your list of clients, wait for a match request to be called, however you want to do that, then take those clients that request it to be moved into a queue. Once you have enough players, start a match with that list of clients. When a packet is received, send it back to all other players in the list. For example, a player moves, a packet is sent, the server receives it, and sends it to all other players in the list, the render the move, and poof. If that's not fast enough, you can have players actually act like mini servers, and connect to each other fully. This will make pings twice as fast, but may be harder to detect hacking. So be careful.</p>

<p>Once the match is over, send a packet to the clients saying the match has ended, and make their clients render a game over screen when that packet is received.</p>

<p>I hope all of that makes sense.</p>
","114175"
"How to design an AssetManager?","9875","","<p>What is the best approach to designing an AssestManager that will hold references to graphics, sounds, etc. of a game?</p>

<p>Should these assets be stored in a key/value Map pair?  I.e. I ask for ""background"" asset and the Map returns the associated bitmap?  Is there an even better way?</p>

<p>Specifically I'm writing an Android/Java game, but answers can be generic.</p>
","<p>It depends on the scope of your game. An asset manager is absolutely essential for larger titles, less so for smaller games.</p>

<p>For larger titles you have to manage problems such as the following:</p>

<ul>
<li>Shared assets - is that brick texture being used by multiple models?</li>
<li>Asset lifetime - is that asset you loaded 15 minutes ago no longer needed? Reference counting your assets to make sure you know when something is finished with etc</li>
<li>In DirectX 9 if certain asset types are loaded and your graphics device gets 'lost' (this happens if you press Ctrl+Alt+Del amongst other things) - your game will need to recreate them</li>
<li>Loading assets in advance of needing them - you couldn't build big open world games without this</li>
<li>Bulk loading assets - We often pack lots of assets into a single file to improve loading times - seeking around the disc is very time consuming</li>
</ul>

<p>For smaller titles these things are less of an issue, frameworks like XNA have asset managers within them - there is very little point in re-inventing it.</p>

<p>If you find yourself needing an asset manager, there is no one-size-fits-all solution really, but I've found that a hash map with the key as a hash* of the filename (lowered and separators all 'fixed') works well for the projects I've worked on.</p>

<p>It is usually not advisable to hardcode filenames in your app, it is usually better to have another data format (such as xml) depict filenames to 'IDs'.</p>

<ul>
<li>As an amusing side note, you normally get one hash collision per project.</li>
</ul>
","1709"
"How should I develop my Android game efficiently?","9848","","<p>I have attached a image of a flow chart that I made in paint. <img src=""https://i.stack.imgur.com/M9v1X.png"" alt=""Flow Chart of game concept""></p>

<p>The image shows how I want to develop my game. I want a game that runs great with smart coding that is easy to update and ad features over time. My target platform is the Android smartphone and all code will be written in java with XML inflated resources, if that matters. I am not looking for hard code,although pseudo code will help, I would more so prefer suggestions and advise from the pros.</p>

<p>My questions are : </p>

<p>Is this a good way to program a game or are there better ways to do this? Are there any modifications that need to be made? Any suggestions would be useful because I am not experienced in game programming so I would prefer the advice from someone who has written several games and knows from experience how one should go about setting their code up to run efficiently.</p>
","<p>A lot of android games are not even large enough in scope to justify save/load or options/preferences, never mind custom characters and the like simply because they are played offhand for 10 minutes on the train home. </p>

<p>Don't make the mistake I did of embarking on something with a large scope for a first android game. Make a bunch of smaller games then go for something larger</p>

<p>Android specifics wise:</p>

<p><strong>Structure:</strong></p>

<p>I would recommend having almost all the game in one activity class. Android works on the idea that each activity is like a mini-app, semi-independent of the other activities in the app. The app is essentially a stack of activities, with the user seeing which ever is on the top. </p>

<p>When you pop one off the top, it generally gets destroyed and will be recreated next time the user starts a new activity (startActivity intent). This makes it hard to maintain states between activities and leads to a single activity architecture</p>

<p>You may want to have a Home screen type activity with a ""New Game/Load Game/Options"" menu on it, and make that the launch activity. However, you will end up having to have an in-game menu as well in your game activity, which will have most of the same functions in it</p>

<p>My own app, I made a ""MenuActivity"" that has the functions that launch a new game, save, load, change options. Then my HomeActivity extends that, as does my GameActivity.</p>

<p>Since everything is in one Activity class, I would recommend making a heirarchy of activity classes and using private, protected and default scope lots. Doing it this way, you at least can split things up into different file to stop from having one unmanageable Activity file. E.g. for my own app:</p>

<p><code>GraphicsEngine extends MenuActivity</code>.</p>

<p><code>PhysicsEngine extends GraphicsEngine</code>.</p>

<p><code>GameLogicActivity extends PhysicsEngine</code>.</p>

<p><code>UIActivity extends GameLogicActivity</code>.</p>

<p>Since my app is 3D opengl-es, a lot of stuff I do doesn't work cross-activities so everything is in the same activity, so maybe I'm biased towards using one activity architecture</p>

<p>--</p>

<p><strong>Threading</strong></p>

<p>For the game activity, You have two threads (or 3 if you are doing 3D opengl stuff). One thread is the UI/main thread. This is the thread the activity gets started and runs in and is given to you by android. </p>

<p>This UI thread is the only one you can update UI elements (views, layouts etc) in. It is also the one where any listeners for user input will run. You don't see any of the mechanics of the UI thread, just that it runs in a loop in the background somewhere.</p>

<p>The second thread, you make yourself (I would recommend using <a href=""http://developer.android.com/reference/android/os/AsyncTask.html"" rel=""nofollow noreferrer"">AsyncTask</a>, despite all its shortcomings). This does all the non-UI things you do in a normal game loop, such as updating movement, calculating collisions, combat calculations and so on.</p>

<p>You make this AsyncTask thread/class as an inner class of your activity. That way, you can have some activity-wide-scope objects (<code>Vector&lt;Spaceship&gt;</code>) that can be accessed by both UI thread and game loop thread.</p>

<p>Since the game logic is going on in the game loop thread, that is the only thread that will need to actually change the values of variables (update tank speed, reduce player HP). The UI thread just reads values, so there should be minimal concurrency issues.</p>

<p>The tricky bit is getting the UI thread to do updates on request of the game loop thread. There are a couple of ways to do this. If you read the AsyncTask documentation, it has publishProgress()/onProgressUpdate() method. This is actually adding stuff to the UI thread's queue of things to do next loop.</p>

<p>Handler does exactly the same thing, where you implement handleMessage() method and that method is actually executed by the UI thread next loop.</p>

<p>Finally, any user-input, being in the UI thread, you can update UI elements immediately from it (so inside the implementation of any onClick / onTouch listeners). If you need to update the game objects, you can either use things like synchronise, or you can implement your own queue of updates into AsyncTask that like the UI thread, it goes through next time it executes the game loop</p>

<p><a href=""http://developer.android.com/resources/articles/painless-threading.html"" rel=""nofollow noreferrer"">Android Threading Guide</a>.</p>

<p>--</p>

<p><strong>UI</strong></p>

<p>As for the actual UI structure within the single activity, I recommend having a frame layout as your base layout. The child elements in a frame layout work like a queue. First element gets drawn first, second gets drawn on top of first, third on top of second.</p>

<p>This way, you can have multiple XML layout files and by managing the frame layout's children, can easily swap sets of views in and out.</p>

<p>If you always have the SurfaceView at the bottom (first child in the frame layout), then you can use all the usual android views/widgets (buttons, text views, scroll views) etc over the top of the surface view, which just does the graphics part of the game.</p>

<p>So for example, if something is loading, you can pause the game loop / just get it to skip everything, add an opaque 'loading' screen as the last child to the frame layout and the user will see 'loading' appear on their screen, quite unaware that other views are behind it. This way you don't have to remove views that take a long time to set up or cause complications each time they are added / removed.</p>

<p>I would also recommend using View.setVisibility lots. You could for example, add a whole 'inventory' layout to your base frame layout and then just setVisibility(View.Visible) on it when the user clicks to view their inventory, and setVisibility(View.Gone) when they close it again. That way, you aren't even managing the children of the frame layout so much as just adding everything and making things visible/invisible as and when the user does different things</p>

<p>This helps with threading again; as the user clicks to open their inventory, the onCLickListener is handled in the UI thread, the inventory is made visible therein, and the updateInventory method is called, again from the UI thread, with just getters on all the game objects being called</p>

<p>Here's the diagram I made for an <a href=""https://stackoverflow.com/questions/8128896/mixing-android-views-and-glsurfaceview/8231526#8231526"">earlier question</a> about the single activity / frame layout idea:</p>

<p><img src=""https://i.stack.imgur.com/DdUPM.png"" alt=""enter image description here""></p>
","21205"
"Is a voxel engine appropriate for a Minecraft-like game?","9840","","<p>Why does Minecraft use polygons to draw the world terrain instead of voxels?  Would a voxel based rendering engine be appropriate for a fully destructible game world built out of cubes like Minecraft?  Would it be more efficient than using polygons?</p>
","<blockquote>
  <p>Why does Minecraft use polygons to
  draw the world terrain instead of
  voxels?</p>
</blockquote>

<p>Graphics hardware works with and renders triangles, so you have to use triangles if you want hardware acceleration. Most voxel renderers employ something like <a href=""http://en.wikipedia.org/wiki/Marching_cubes"">Marching Cubes</a> to extract a polygonal mesh from a voxel representation and present that; direct volume rendering is typically computational expensive.</p>

<blockquote>
  <p>Would a voxel based rendering engine
  be appropriate for a fully
  destructible game world built out of
  cubes like Minecraft?</p>
</blockquote>

<p>Yes.</p>

<blockquote>
  <p>Would it be more efficient than using
  polygons?</p>
</blockquote>

<p>Probably, but not because voxels are faster or cheaper to render (in fact, they're more expensive to render since you must convert the data set). Voxel representation lends itself to <em>manipulation</em> easier than polygons -- so it's much easier to add and remove chunks, bits and pieces of the world represented by the data set.</p>
","11978"
"When should vector/list be used?","9826","","<p>I can understand when to use lists, but I don't understand when it is better to use vectors than using lists in video games: when it is better to have fast random access ?</p>

<p>(And I understand why it's faster to insert/delete in lists because it just removes/adds pointers, but it still has to find the corresponding item...)</p>
","<p>My rule of thumb, and I'm sure there will be debate on this, is to <em>never</em> use lists (unless you need to very, very frequently remove things from the middle of large lists).</p>

<p>The speed you'll gain by having all your elements in your container in contiguous memory (and therefore more cache-friendly) is worth the offset of the additional costs of adding/removing/resizing the vector.</p>

<p>Edit: Just to clarify a bit more, of course it should go without saying that any kind of ""which is faster"" question should be tested on whatever platform with whatever data sets are pertinent to your particular needs.  If I just need a collection of elements I just use vector (or deque, which is almost the same thing) unless there's a good reason <em>not</em> to.  </p>
","4888"
"Box2D physics editor for complex bodies","9816","","<p>Is there any editor out there that would allow me to define complex entities, with joins connecting their multiple bodies, instead of regular single body entities? For example, an editor that would allow me to 'define' a car as having a main body with two circles as wheels, connected through joints.</p>

<p><strong>Clarification:</strong></p>

<p>I realize I haven't been clear enough about what I need. I'd like to make my engine data-driven, so all entities (and therefore their Box2D bodies) should be defined externally, not in code.</p>

<p>I'm looking for a program like Code 'N' Web's <a href=""http://www.physicseditor.de/"" rel=""noreferrer"">PhysicsEditor</a>, except that one only handles single body entities, no joints or anything like that. Like PhysicsEditor, the program should be configurable so that I can save the data in whatever format I want to. Does anyone know of any such software? </p>
","<p>You may be interested in <a href=""http://code.google.com/p/box2d-editor/"" rel=""nofollow noreferrer"">Physics Body Editor</a>. That's an open-source tool handling bodies with multiple fixtures.</p>

<p>A big update is in progress, and next revision will support complex dynamic objects made of multiple rigid bodies linked with custom joints, as well as a scripting support for directly testing your bodies.</p>

<p>Hope you'll like it ;)</p>

<p><img src=""https://i.stack.imgur.com/vj3Pn.jpg"" alt=""""></p>
","22049"
"Separating game data/logic from rendering","9811","","<p>I'm writing a game using C++ and OpenGL 2.1.
I was thinking how could I separate the data/logic from rendering.
At the moment I use a base class 'Renderable' that gives a pure virtual method to implement drawing. But every object has so specialized code, only the object knows how to properly set shader uniforms and organize vertex array buffer data. I end up with a lot of gl* function calls all over my code.
Is there any generic way to draw the objects?</p>
","<p>An idea is to use the Visitor design pattern. You need a Renderer implementation that knows how to render props. Every object can call the renderer instance to handle the render job. </p>

<p>In a few lines of pseudocode:</p>

<pre><code>class Renderer {
public:
    void render( const ObjectA &amp; obj );
    void render( const ObjectB &amp; obj );
};


class ObjectA{
public:
    void draw( Renderer &amp; r ){ r.render( *this ) };
}

class ObjectB{
public:
    void draw( Renderer &amp; r ){ r.render( *this ) };
}
</code></pre>

<p>The gl* stuff is implemented by the renderer's methods, and the objects only store the data needed to be rendered, position, texture type, size ...etc.</p>

<p>Also, you can setup different renderers (debugRenderer, hqRenderer, ...etc) and use these dynamically, without changing the objects.</p>

<p>This also can be easy combined with Entity/Component systems.</p>
","62992"
"Difference between ""staggered"" isometric and ""normal"" isometric tilemaps?","9802","","<p>The <a href=""http://mapeditor.org"">Tiled Map Editor v0.9</a> recently added support for <em>staggered</em> tilemaps in addition to its usual isometric tilemap support. </p>

<p>What are the exact technical differences between these two types of isometric tilemaps? What are their advantages/disadvantages?</p>
","<p>""Staggered"" refers to the jagged edges of isometric maps that have an overall rectangular shape. These maps emphasize the north/south and west/east axes, and often have North up (example: Civilization 2). Diamond maps on the other hand emphasize the diagonal orientation and movement. North is often at the top right (example: Simcity 2000). Also notice the different coordinate systems:</p>

<p><img src=""https://i.stack.imgur.com/yHZi9.jpg"" alt=""Comparison""></p>

<p><strong>""Normal"" or ""diamond"" isometric map:</strong></p>

<p><img src=""https://i.stack.imgur.com/rh1cx.gif"" alt=""Simcity 2000 screenshot""><br>
Notice the overall shape of the map is a diamond.</p>

<p><strong>""Staggered"" isometric map:</strong></p>

<p><img src=""https://i.stack.imgur.com/bkgMk.png"" alt=""Civ 2 screenshot"">
Notice the overal shape of the map is a (rough) rectangle</p>

<p>See also <a href=""http://legendofmazzeroth.wikidot.com/staggered-isometric-maps"" rel=""nofollow noreferrer"">this explanation</a>:</p>

<blockquote>
  <p>The math in terms of rendering both types of maps is similar but has its differences. Diamond maps are a bit more tricky particularly in terms of optimizing the render loop.</p>
  
  <p>Diamond maps are typically used in RTS and Tactical Combat types games whereas Staggered/Block maps tend to be used for RPG's and Turn-Based Strategy games.</p>
</blockquote>

<p>In terms of the Tiled XML, staggered adds a new possible value for the attribute ""orientation"" of the map.</p>

<p>Finally, don't confuse these staggered maps with staggered <em>square</em> maps. The latter are a way to get pseudo-hexes:</p>

<p><img src=""https://i.stack.imgur.com/58fvO.png"" alt=""pseudo hexgrid""><br>
Note how the tiles are squares, but movement and adjacencies conform to those of a hexgrid.</p>
","49848"
"Toggle Fullscreen at Runtime","9785","","<p>Using the library <a href=""http://www.glfw.org/"" rel=""nofollow"">GLFW</a>, I can create a fullscreen window using this line of code.</p>

<pre><code>glfwOpenWindow(Width, Height, 8, 8, 8, 8, 24, 0, GLFW_FULLSCREEN);
</code></pre>

<p>The line for creating a standard window looks like this.</p>

<pre><code>glfwOpenWindow(Width, Height, 8, 8, 8, 8, 24, 0, GLFW_WINDOW);
</code></pre>

<p>What I want to do is letting the user switch between standard window and fullscreen by a keypress, let's say <code>F11</code>.</p>

<p><strong>It there a common practice of toggling fullscreen mode? What do I have to consider?</strong></p>
","<p>I'm not sure about common practices, but lacking a <code>glfwToggleFullscreen</code>, this seems one way to toggle <em>fullscreen</em> mode:</p>

<pre><code>// On input handling, check if F11 is down.
if ( glfwGetKey( GLFW_KEY_F11 ) ) {

    // Toggle fullscreen flag.
    fullscreen = !fullscreen;

    // Close the current window.
    glfwCloseWindow();

    // Renew calls to glfwOpenWindowHint.
    // (Hints get reset after the call to glfwOpenWindow.)
    myGLFWOpenWindowHints();

    // Create the new window.
    glfwOpenWindow(Width, Height, 8, 8, 8, 8, 24, 0,
                   fullscreen ? GLFW_FULLSCREEN : GLFW_WINDOW);

}
</code></pre>

<p>Another method, this time for <em>fullscreen windowed</em> mode:</p>

<pre><code>// Create your window in windowed mode.
glfwOpenWindow(originalWidth, originalHeight, 8, 8, 8, 8, 24, 0, GLFW_WINDOW);
glfwSetWindowPos(originalPosX, originalPosY);

// Get the desktop resolution.
GLFWvidmode desktopMode;
glfwGetDesktopMode(&amp;desktopMode);
desktopHeight = desktopMode.Height;
desktopWidth = desktopMode.Width;

// --8&lt;--

// On input handling, check if F11 is down.
if ( glfwGetKey( GLFW_KEY_F11 ) ) {
    // Toggle fullscreen flag.
    fullscreen = !fullscreen;

    if ( fullscreen ) {
        // Set window size for ""fullscreen windowed"" mode to the desktop resolution.
        glfwSetWindowSize(desktopWidth, desktopHeight);
        // Move window to the upper left corner.
        glfwSetWindowPos(0, 0);
    } else {
        // Use start-up values for ""windowed"" mode.
        glfwSetWindowSize(originalWidth, originalHeight);
        glfwSetWindowPos(originalPosX, originalPosY);            
    }
}
</code></pre>
","38628"
"What's the technology that allows programming inside a game?","9778","","<p>There are some games which allow the player to write/create scripts in-game, for example: <a href=""http://www.spaceengineerswiki.com/Programmable_Block"" rel=""nofollow noreferrer"">Space engineers</a> or <a href=""http://psi.vazkii.us/"" rel=""nofollow noreferrer"">Psi</a>.</p>

<p>I want to use something similar to either one, but I've had a hard time finding information so my question is:</p>

<p><strong>Is there a branch of programming that covers the ability of a software once compiled to run new code created by the user?</strong></p>

<p>By branch of programming I mean something like PTG (Procedural Terrain Generation).</p>

<p>To avoid the <em>too broad of a question</em> or <em>opinion based</em>, let me clearly state that I'm not looking for guides or places to learn, I want the name or definition (if one exists) of the technology involved.</p>
","<p>Scripts written in <strong>scripting / embedded / interpreted languages</strong> such as ""Lua"", ""Lisp"" or ""AngelScript"" (<a href=""https://en.wikipedia.org/wiki/List_of_programming_languages_by_type#Interpreted_languages"" rel=""nofollow noreferrer"">more here</a>) can be updated during the game <strong>[*]</strong> and then are interpreted (= executed) on the fly.</p>

<p>You can bind elements from those scripts to your native compiled coding (C++, etc.) so that the scripts can then execute logic from your application. E. g. a specific command that the user can put in the script, as a result moves the in-game character by a given distance in the game world.</p>

<p>Some relevant linked questions:</p>

<ul>
<li><p><a href=""https://gamedev.stackexchange.com/questions/11/what-scripting-language-should-i-choose-for-my-game"">What scripting language should I choose for my game?</a></p></li>
<li><p><a href=""https://gamedev.stackexchange.com/questions/13880/what-do-you-look-for-in-a-scripting-language?noredirect=1&amp;lq=1"">What do you look for in a scripting language?</a></p></li>
<li><p><a href=""https://gamedev.stackexchange.com/questions/421/how-do-you-add-a-scripting-language-to-a-game?noredirect=1&amp;lq=1"">How do you add a scripting language to a game?</a></p></li>
</ul>

<hr>

<p><strong>[*]</strong> <em>either by the user as part of the game play or also by devs for fast iteration/testing without restarting the application</em></p>
","130521"
"Collision resolution in case of collision with multiple objects","9756","","<p>I have static objects and movable objects. The collisions are detected using the separating-axis-theorem. </p>

<p>For example, in this situation I have two static objects (in red):</p>

<p><img src=""https://i.stack.imgur.com/xMWzm.png"" alt=""enter image description here""></p>

<p>and a movable object between the two:</p>

<p><img src=""https://i.stack.imgur.com/kz9ev.png"" alt=""enter image description here""></p>

<p>My algorithm is able to compute the collision between two of these objects, and it also spits out a perfect resolution vector (meaning a minimum-displacement-vector) to the collision. </p>

<p>So for example, when I check the collision between the green rectangle and the right red rectangle, the algorithm spits out a vector that tells me how I need to move the green rectangle in order to resolve the collision:</p>

<p><img src=""https://i.stack.imgur.com/5AWeg.png"" alt=""enter image description here""></p>

<p>Notice that I just quickly drew this in MSPaint, so in that picture it could actually be that the minimum-translation-vector pushes the green rectangle out on the top, but I'm going to assume here that pushing it out to the left/right is actually shorter.</p>

<p>The general way of approaching this would be to only resolve the collision of one collision per frame, instead of all at once. But in my case, this would result in flip-flopping:</p>

<p>First, the solver detects two collisions but only resolves the collision between the right rectangle and the green rectangle:</p>

<p><img src=""https://i.stack.imgur.com/ryRn8.png"" alt=""enter image description here""></p>

<p>Then, in the next frame, it detects only one collision which is between the left red rectangle and the green rectangle, and resolves it:</p>

<p><img src=""https://i.stack.imgur.com/HiI7R.png"" alt=""enter image description here""></p>

<p>As you can see, this doesn't actually resolve the collision (for example by pushing the green rectangle out to the top), and instead just flip flops between the two states infinitely.</p>

<p>How can I solve this?</p>
","<p>Depending on exactly what you are trying to achieve (high physical accuracy or just a close-enough real-time simulation), you could try using speculative contacts.</p>

<p>Here are the details:
<a href=""http://www.wildbunny.co.uk/blog/2011/03/25/speculative-contacts-an-continuous-collision-engine-approach-part-1/"">http://www.wildbunny.co.uk/blog/2011/03/25/speculative-contacts-an-continuous-collision-engine-approach-part-1/</a></p>

<p>He describes in that article what you need to know to implement it, and it's very simple compared to other approaches (such as sphere casting and then sorting collision resolutions by time of impact).</p>

<p>If you need/want more, you can purchase his source code for (IIRC) $7.</p>

<p>Here is a video of my implementation in 3D:
<a href=""http://www.youtube.com/watch?v=JvT2H1RmOas"">http://www.youtube.com/watch?v=JvT2H1RmOas</a></p>

<p>Notice how stable the simulation is with just a single iteration. You could easily use multiple iterations per frame to resolve multiple collisions to a stable state, which would be more accurate.</p>
","15853"
"Can I use GLFW and GLEW together in the same code","9749","","<p>I use the g++ compiler, which could be causing the main problem, but I'm using GLFW for window and input management, and I am using GLEW so that I can use OpenGL 3.x functionality. I loaded in models and then tried to make Vertex and Index buffers for the data, but it turned out that I kept getting segmentation faults in the program. I finally figured out that GLEW just wasn't working with GLFW included. Do they not work together?</p>

<p>Also I've done the context creation through GLFW so that may be another factor in the problem.</p>
","<p>GLFW can be used with GLEW:</p>

<p><a href=""http://www.glfw.org/faq.html#2_15"">http://www.glfw.org/faq.html#2_15</a></p>

<blockquote>
  <p>2.15 - Can I use GLEW with GLFW?</p>
  
  <p>Yes, as long as you include the GLEW header before the GLFW one. The
  GLEW header defines all the necessary magic macros to make sure the
  gl.h that GLFW attempts to include doesn't interfere.</p>
</blockquote>
","37483"
"LibGDX simple button with image","9716","","<p>I want to make two image buttons (play, restart) in my main menu screen but I dont know how to do it. I tried this:</p>

<pre><code>Texture playTexture = new Texture(...)
Image playImage = new Image(playTexture)
ImageButton playButton = new ImageButton(drawable?)
</code></pre>

<p>but I have no idea what is drawable.</p>
","<p>A drawable has information about its size and how to draw itself. It's used to determine size and position by ui components. Since you are using a texture, you can use a TextureRegionDrawable.</p>

<pre><code>Drawable drawable = new TextureRegionDrawable(new TextureRegion(playTexture);
ImageButton playButton = new ImageButton(drawable);
</code></pre>
","121121"
"Water/Ocean simulation and physics","9693","","<p>I'm looking for some references about water simulation, and how to model it's interaction with bodies (like boats, ships, submarines).</p>

<p>I've found a lot of references on the visual aspects of water (waves, reflection, etc), but very little about how to deal with the way it should interact with bodies. My experience with game development is very limited, and I'm really stuck here.</p>

<p>Bascally I would like to be able to make the position of a ship variates according to the waves. How can I do this?</p>

<p>I'm using Panda3D, but hope to hear about techniques and implementations used in any available technology.</p>
","<p>Basically you're looking at modeling 6 things for a ship:  pitch, yaw, roll, heave, sway and surge.</p>

<p><img src=""https://i.stack.imgur.com/odMH9.gif"" alt=""alt text""></p>

<p>Pitch, yaw and roll are rotations the ship can make as it twists and turns going up and down the slope of the waves.  Heave, sway and surge are movements induced by the waves pushing the ship around and/or the ship sliding down the face of a wave.</p>

<p><strong>""Like a Car Driving on Hills...""</strong></p>

<p>Imagine a boat on the water like a car driving over hilly ground.  If the car drives over rolling hills (like a ship going over waves) it is going to tilt and angle as it goes up and down the hills.  This is the pitch, yaw and roll.  If the hills (waves) are big, the car (ship) will drive up and down, pitching, yawing and rolling as it goes.  If the hills (waves) are really small (smaller than the car/ship), then the car (ship) is just going to drive over them and not pitch, yaw or roll much.</p>

<p>A big ship can just plow through smaller waves, whereas a small ship will move up and down the waves.  Taking our car example, imagine someone riding a bicycle (small ship) over a set of small hills (waves).  They will roll up and down as they go.  Then someone drives a big truck (ship) over them.  The truck is bigger than the hills, so doesn't really pitch up and down as it goes over them.</p>

<p>Unlike the car though, a ship is part way into the water, so it's movements are going to be dampened somewhat.  Imagine a car with really soft spongey tires. When it drives over tiny hills, the spongey tires just smooth it out.  A ship's movements are also dampened, so little waves won't make it bounce up and down like a car on a rocky road.  A submarine is sort of the ultimate dampened ship, as when submerged it is pretty much immune to the surface waves.  But if it's on the surface it's going to be moved by the waves.</p>

<p>A ship will also slide on waves.  A ship going down the face of a wave will surge forward for example.  So to extend our car example, make it a car with big spongey wheels driving on a somewhat slippery surface. Unless the car is running the engine to compensate for the slip, it's going to slide down the side of a hill.  Even if it is running the engine, there is going to be some slip.</p>

<p>The one place where the car and hill analogy has problems is the fact that the waves change shape over time.  A stationary ship will bob up and down as the waves go up and down.  </p>

<p><strong>Waves Moving the Ship</strong></p>

<p>If there is no wind blowing on the ship to move it along, and the waves are a perfect sine wave shape, then the ship basically won't move anywhere as it bobs in the waves.  It slides one way as it goes up the face of a wave, then slides back the other way as it goes down the back face of a wave.  </p>

<p>However if the waves are NOT symetrical (like the picture below), then the waves are going to move the ship.  Because one side of the wave is steep, the ship is going to slide quickly down that face as well as be pushed by the face of the wave.  The gentle back slope of the wave however won't have much motion.</p>

<p><img src=""https://i.stack.imgur.com/Bz2oU.jpg"" alt=""alt text""></p>

<p>This isn't the most perfect model of wave motion and shape affecting a ship's motion, but it will probably do for a rough simulation.</p>

<p><strong>Wind Effects</strong></p>

<p>Wind is also going to push your ship around in ways independent of the wave motion or ship motion.  The direction and force of the wind can be different than the direction and force of the waves.  </p>

<p><strong>Buoyancy</strong></p>

<p>Buoyancy is how well your ship floats.  Very buoyant ships float up high in the water, and ones that aren't buoyant sink.  Neutrally buoyant ships (submarines) can basically ""hover"" at any point underwater, neither sinking nor rising.  If you want to simulate a ship sinking, make it become negatively buoyant and it will begin to sink.</p>

<p>Buoyancy also affects dampening of the ship's motion.  A ship that is extremely buoyant will bob around on the water surface and be strongly affected by waves.  A ship that is less buoyant will be partially submerged and not be affected as much.  Think of the difference between a pingpong ball floating on the surface versus an apple, which floats but is partially underwater.  The pingpong ball bobs up and down with every wave motion.  The apple on the other hand doesn't respond to every wave detail.</p>

<p><strong>Capsizing</strong></p>

<p>If the pitch, yaw and/or roll exceed some value, your ship is going to tip over.  When it tips over, it might fill with water, reducing the buoyancy, thus making it not float any more.</p>

<p><strong>Getting Sea Sick :o~</strong></p>

<p>A ship that is traveling parallel to the direction of wave motion is ""in the trough"", and will produce the most nauseating effects at least in my experience :)  If you are traveling in the direction the waves are going, you can have a very smooth ride - like having the wind at your back.  If you are traveling in the opposite direction as the waves, you will have a pretty harsh ride as you are hitting each wave ""hill"" as it comes at you.  Makes for a pretty exciting ride though!</p>

<p><strong>Further Reading</strong></p>

<p>Here are three articles that cover the science behind this, which might give you some insights.  Though heavy on the math and science, they could give you an idea of what the different factors are.</p>

<p>Article 1: <a href=""http://www.hindawi.com/journals/mpe/2010/934714.html"" rel=""noreferrer"">Modeling of Ship Roll Dynamics and Its Coupling with Heave and Pitch</a></p>

<p>Article 2:  <a href=""http://www.marinecontrol.org/pdf/Tutorial/CAMS_M1_intro.pdf"" rel=""noreferrer"">Modelling and Simulation of Marine Surface Vessel Dynamics</a></p>

<p>Article 3:  <a href=""http://www.marinecontrol.org/pdf/Tutorial/CAMS_M10_HydroSW.pdf"" rel=""noreferrer"">Modelling and Simulation of Marine Surface Vessel Dynamics</a></p>

<p><strong>The Author Doing Field Research</strong></p>

<p>Here's me about 15 years ago when I worked on research ships :)</p>

<p><img src=""https://i.stack.imgur.com/39x5A.jpg"" alt=""alt text""></p>
","6506"
"What is the proper way to get input from the motion controllers touch pads?","9688","","<p>I've been trying to figure out how to get the inputs from the touch pads on the motion controllers but have yet to find out how to do so. Initially I tried doing the following (as it was how I accessed the triggers and the side buttons)...</p>

<pre><code>private Valve.VR.EVRButtonId gripButton = Valve.VR.EVRButtonId.k_EButton_Grip; //Essentially this is accessing
                                                                               //SteamVR_TrackedObject.cs and telling our script
                                                                               //and defining it here.


private Valve.VR.EVRButtonId triggerButton = Valve.VR.EVRButtonId.k_EButton_SteamVR_Trigger;
private Valve.VR.EVRButtonId Axis0 = Valve.VR.EVRButtonId.k_EButton_Axis0;
private Valve.VR.EVRButtonId Axis1 = Valve.VR.EVRButtonId.k_EButton_Axis1;
private Valve.VR.EVRButtonId Axis2 = Valve.VR.EVRButtonId.k_EButton_Axis2;
private Valve.VR.EVRButtonId Axis3 = Valve.VR.EVRButtonId.k_EButton_Axis3;
private Valve.VR.EVRButtonId Axis4 = Valve.VR.EVRButtonId.k_EButton_Axis4;
</code></pre>

<p>I know I got the buttons right but I'm not sure if I'm getting the touch pad inputs properly. Also the other issue I'm having is how do I differentiate between controllers?</p>

<p>For context here is my script in full (which is based upon <a href=""https://www.youtube.com/watch?v=LZTctk19sx8"" rel=""nofollow"">this</a> video)...</p>

<pre><code>public class WandController : MonoBehaviour {
    private Valve.VR.EVRButtonId gripButton = Valve.VR.EVRButtonId.k_EButton_Grip; //Essentially this is accessing
                                                                                   //SteamVR_TrackedObject.cs and telling our script
                                                                                   //and defining it here.


    private Valve.VR.EVRButtonId triggerButton = Valve.VR.EVRButtonId.k_EButton_SteamVR_Trigger;
    private Valve.VR.EVRButtonId Axis0 = Valve.VR.EVRButtonId.k_EButton_Axis0;
    private Valve.VR.EVRButtonId Axis1 = Valve.VR.EVRButtonId.k_EButton_Axis1;
    private Valve.VR.EVRButtonId Axis2 = Valve.VR.EVRButtonId.k_EButton_Axis2;
    private Valve.VR.EVRButtonId Axis3 = Valve.VR.EVRButtonId.k_EButton_Axis3;
    private Valve.VR.EVRButtonId Axis4 = Valve.VR.EVRButtonId.k_EButton_Axis4;

    private SteamVR_Controller.Device controller { get { return SteamVR_Controller.Input((int)trackedObj.index); } }
    private SteamVR_TrackedObject trackedObj;

    private GameObject pickup;

    // Use this for initialization
    void Start ()
    {
        trackedObj = GetComponent&lt;SteamVR_TrackedObject&gt;();
    } 

    // Update is called once per frame
    void Update ()
    {
        if (controller == null)
        {
            Debug.Log(""Controller not initalized"");
            return;
        }

        if (controller.GetPressDown(gripButton) &amp;&amp; pickup != null)
        {
            pickup.transform.parent = this.transform;
        }
        if (controller.GetPressUp(gripButton) &amp;&amp; pickup != null)
        {
            Debug.Log(""Grip button was unpressed"");
        }

        if (controller.GetAxis(Axis0).x &gt;= 1)
        {
            Debug.Log(""Axis0 detected"");
        }
        if (controller.GetAxis(Axis1).x &gt;= 1)
        {
            Debug.Log(""Axis1 detected"");
        }
        if (controller.GetAxis(Axis2).x &gt;= 1)
        {
            Debug.Log(""Axis2 detected"");
        }
        if (controller.GetAxis(Axis3).x &gt;= 1)
        {
            Debug.Log(""Axis3 detected"");
        }
        if (controller.GetAxis(Axis4).x &gt;= 1)
        {
            Debug.Log(""Axis4 detected"");
        }
    }

    private void OnTriggerEnter(Collider collider)
    {
        pickup = collider.gameObject;
    }
    private void OnTriggerExit(Collider collider)
    {
        pickup = collider.gameObject;
    }
}
</code></pre>

<p>Also here is the script where I retrieved all the inputs...</p>

<pre><code>//========= Copyright 2015, Valve Corporation, All rights reserved. ===========
//
// Purpose: Wrapper for working with SteamVR controller input
//
// Example usage:
//
//  var deviceIndex = SteamVR_Controller.GetDeviceIndex(SteamVR_Controller.DeviceRelation.Leftmost);
//  if (deviceIndex != -1 &amp;&amp; SteamVR_Controller.Input(deviceIndex).GetPressDown(SteamVR_Controller.ButtonMask.Trigger))
//      SteamVR_Controller.Input(deviceIndex).TriggerHapticPulse(1000);
//
//=============================================================================

using UnityEngine;
using Valve.VR;

public class SteamVR_Controller
{
    public class ButtonMask
    {
        public const ulong System           = (1ul &lt;&lt; (int)EVRButtonId.k_EButton_System); // reserved
        public const ulong ApplicationMenu  = (1ul &lt;&lt; (int)EVRButtonId.k_EButton_ApplicationMenu);
        public const ulong Grip             = (1ul &lt;&lt; (int)EVRButtonId.k_EButton_Grip);
        public const ulong Axis0            = (1ul &lt;&lt; (int)EVRButtonId.k_EButton_Axis0);
        public const ulong Axis1            = (1ul &lt;&lt; (int)EVRButtonId.k_EButton_Axis1);
        public const ulong Axis2            = (1ul &lt;&lt; (int)EVRButtonId.k_EButton_Axis2);
        public const ulong Axis3            = (1ul &lt;&lt; (int)EVRButtonId.k_EButton_Axis3);
        public const ulong Axis4            = (1ul &lt;&lt; (int)EVRButtonId.k_EButton_Axis4);
        public const ulong Touchpad         = (1ul &lt;&lt; (int)EVRButtonId.k_EButton_SteamVR_Touchpad);
        public const ulong Trigger          = (1ul &lt;&lt; (int)EVRButtonId.k_EButton_SteamVR_Trigger);
    }

    public class Device
    {
        public Device(uint i) { index = i; }
        public uint index { get; private set; }

        public bool valid { get; private set; }
        public bool connected { get { Update(); return pose.bDeviceIsConnected; } }
        public bool hasTracking { get { Update(); return pose.bPoseIsValid; } }

        public bool outOfRange { get { Update(); return pose.eTrackingResult == ETrackingResult.Running_OutOfRange || pose.eTrackingResult == ETrackingResult.Calibrating_OutOfRange; } }
        public bool calibrating { get { Update(); return pose.eTrackingResult == ETrackingResult.Calibrating_InProgress || pose.eTrackingResult == ETrackingResult.Calibrating_OutOfRange; } }
        public bool uninitialized { get { Update(); return pose.eTrackingResult == ETrackingResult.Uninitialized; } }

        // These values are only accurate for the last controller state change (e.g. trigger release), and by definition, will always lag behind
        // the predicted visual poses that drive SteamVR_TrackedObjects since they are sync'd to the input timestamp that caused them to update.
        public SteamVR_Utils.RigidTransform transform { get { Update(); return new SteamVR_Utils.RigidTransform(pose.mDeviceToAbsoluteTracking); } }
        public Vector3 velocity { get { Update(); return new Vector3(pose.vVelocity.v0, pose.vVelocity.v1, -pose.vVelocity.v2); } }
        public Vector3 angularVelocity { get { Update(); return new Vector3(-pose.vAngularVelocity.v0, -pose.vAngularVelocity.v1, pose.vAngularVelocity.v2); } }

        public VRControllerState_t GetState() { Update(); return state; }
        public VRControllerState_t GetPrevState() { Update(); return prevState; }
        public TrackedDevicePose_t GetPose() { Update(); return pose; }

        VRControllerState_t state, prevState;
        TrackedDevicePose_t pose;
        int prevFrameCount = -1;
        public void Update()
        {
            if (Time.frameCount != prevFrameCount)
            {
                prevFrameCount = Time.frameCount;
                prevState = state;

                var system = OpenVR.System;
                if (system != null)
                {
                    valid = system.GetControllerStateWithPose(SteamVR_Render.instance.trackingSpace, index, ref state, ref pose);
                    UpdateHairTrigger();
                }
            }
        }

        public bool GetPress(ulong buttonMask) { Update(); return (state.ulButtonPressed &amp; buttonMask) != 0; }
        public bool GetPressDown(ulong buttonMask) { Update(); return (state.ulButtonPressed &amp; buttonMask) != 0 &amp;&amp; (prevState.ulButtonPressed &amp; buttonMask) == 0; }
        public bool GetPressUp(ulong buttonMask) { Update(); return (state.ulButtonPressed &amp; buttonMask) == 0 &amp;&amp; (prevState.ulButtonPressed &amp; buttonMask) != 0; }

        public bool GetPress(EVRButtonId buttonId) { return GetPress(1ul &lt;&lt; (int)buttonId); }
        public bool GetPressDown(EVRButtonId buttonId) { return GetPressDown(1ul &lt;&lt; (int)buttonId); }
        public bool GetPressUp(EVRButtonId buttonId) { return GetPressUp(1ul &lt;&lt; (int)buttonId); }

        public bool GetTouch(ulong buttonMask) { Update(); return (state.ulButtonTouched &amp; buttonMask) != 0; }
        public bool GetTouchDown(ulong buttonMask) { Update(); return (state.ulButtonTouched &amp; buttonMask) != 0 &amp;&amp; (prevState.ulButtonTouched &amp; buttonMask) == 0; }
        public bool GetTouchUp(ulong buttonMask) { Update(); return (state.ulButtonTouched &amp; buttonMask) == 0 &amp;&amp; (prevState.ulButtonTouched &amp; buttonMask) != 0; }

        public bool GetTouch(EVRButtonId buttonId) { return GetTouch(1ul &lt;&lt; (int)buttonId); }
        public bool GetTouchDown(EVRButtonId buttonId) { return GetTouchDown(1ul &lt;&lt; (int)buttonId); }
        public bool GetTouchUp(EVRButtonId buttonId) { return GetTouchUp(1ul &lt;&lt; (int)buttonId); }

        public Vector2 GetAxis(EVRButtonId buttonId = EVRButtonId.k_EButton_SteamVR_Touchpad)
        {
            Update();
            var axisId = (uint)buttonId - (uint)EVRButtonId.k_EButton_Axis0;
            switch (axisId)
            {
                case 0: return new Vector2(state.rAxis0.x, state.rAxis0.y);
                case 1: return new Vector2(state.rAxis1.x, state.rAxis1.y);
                case 2: return new Vector2(state.rAxis2.x, state.rAxis2.y);
                case 3: return new Vector2(state.rAxis3.x, state.rAxis3.y);
                case 4: return new Vector2(state.rAxis4.x, state.rAxis4.y);
            }
            return Vector2.zero;
        }

        public void TriggerHapticPulse(ushort durationMicroSec = 500, EVRButtonId buttonId = EVRButtonId.k_EButton_SteamVR_Touchpad)
        {
            var system = OpenVR.System;
            if (system != null)
            {
                var axisId = (uint)buttonId - (uint)EVRButtonId.k_EButton_Axis0;
                system.TriggerHapticPulse(index, axisId, (char)durationMicroSec);
            }
        }

        public float hairTriggerDelta = 0.1f; // amount trigger must be pulled or released to change state
        float hairTriggerLimit;
        bool hairTriggerState, hairTriggerPrevState;
        void UpdateHairTrigger()
        {
            hairTriggerPrevState = hairTriggerState;
            var value = state.rAxis1.x; // trigger
            if (hairTriggerState)
            {
                if (value &lt; hairTriggerLimit - hairTriggerDelta || value &lt;= 0.0f)
                    hairTriggerState = false;
            }
            else
            {
                if (value &gt; hairTriggerLimit + hairTriggerDelta || value &gt;= 1.0f)
                    hairTriggerState = true;
            }
            hairTriggerLimit = hairTriggerState ? Mathf.Max(hairTriggerLimit, value) : Mathf.Min(hairTriggerLimit, value);
        }

        public bool GetHairTrigger() { Update(); return hairTriggerState; }
        public bool GetHairTriggerDown() { Update(); return hairTriggerState &amp;&amp; !hairTriggerPrevState; }
        public bool GetHairTriggerUp() { Update(); return !hairTriggerState &amp;&amp; hairTriggerPrevState; }
    }

    private static Device[] devices;

    public static Device Input(int deviceIndex)
    {
        if (devices == null)
        {
            devices = new Device[OpenVR.k_unMaxTrackedDeviceCount];
            for (uint i = 0; i &lt; devices.Length; i++)
                devices[i] = new Device(i);
        }

        return devices[deviceIndex];
    }

    public static void Update()
    {
        for (int i = 0; i &lt; OpenVR.k_unMaxTrackedDeviceCount; i++)
            Input(i).Update();
    }

    // This helper can be used in a variety of ways.  Beware that indices may change
    // as new devices are dynamically added or removed, controllers are physically
    // swapped between hands, arms crossed, etc.
    public enum DeviceRelation
    {
        First,
        // radially
        Leftmost,
        Rightmost,
        // distance - also see vr.hmd.GetSortedTrackedDeviceIndicesOfClass
        FarthestLeft,
        FarthestRight,
    }
    public static int GetDeviceIndex(DeviceRelation relation,
        ETrackedDeviceClass deviceClass = ETrackedDeviceClass.Controller,
        int relativeTo = (int)OpenVR.k_unTrackedDeviceIndex_Hmd) // use -1 for absolute tracking space
    {
        var result = -1;

        var invXform = ((uint)relativeTo &lt; OpenVR.k_unMaxTrackedDeviceCount) ?
            Input(relativeTo).transform.GetInverse() : SteamVR_Utils.RigidTransform.identity;

        var system = OpenVR.System;
        if (system == null)
            return result;

        var best = -float.MaxValue;
        for (int i = 0; i &lt; OpenVR.k_unMaxTrackedDeviceCount; i++)
        {
            if (i == relativeTo || system.GetTrackedDeviceClass((uint)i) != deviceClass)
                continue;

            var device = Input(i);
            if (!device.connected)
                continue;

            if (relation == DeviceRelation.First)
                return i;

            float score;

            var pos = invXform * device.transform.pos;
            if (relation == DeviceRelation.FarthestRight)
            {
                score = pos.x;
            }
            else if (relation == DeviceRelation.FarthestLeft)
            {
                score = -pos.x;
            }
            else
            {
                var dir = new Vector3(pos.x, 0.0f, pos.z).normalized;
                var dot = Vector3.Dot(dir, Vector3.forward);
                var cross = Vector3.Cross(dir, Vector3.forward);
                if (relation == DeviceRelation.Leftmost)
                {
                    score = (cross.y &gt; 0.0f) ? 2.0f - dot : dot;
                }
                else
                {
                    score = (cross.y &lt; 0.0f) ? 2.0f - dot : dot;
                }
            }

            if (score &gt; best)
            {
                result = i;
                best = score;
            }
        }

        return result;
    }
}
</code></pre>

<p>So anyone know what I am missing here?</p>
","<p>Stumbled upon this looking for something else.</p>

<p><code>SteamVR_Controller.Device</code> has a method <code>GetAxis()</code> (as you have already tried using) and the default parameter is the touchpad so you don't want to pass any value. That will return the <code>Vector2</code> position on the touchpad that you are touching.</p>

<p><code>controller.GetAxis()</code> should be all you need. The returned <code>Vector2</code> goes from <code>(-1, -1)</code> to <code>(1,1)</code> so just check the value isn't <code>(0,0)</code>:</p>

<pre><code>Vector2 value = controller.GetAxis();
if(value != Vector2.zero)
    DoSomething(value);
</code></pre>
","121576"
"Should collision detection be done server-side or cooperatively between client/server?","9684","","<p>I am working on an online game that will have very heavy collision detection processing. Player models will collide with other players, mobs, structures, terrain, and solid objects that only exist server side (not stored in client data files).</p>

<p>For security purposes, should I do all collision detection server-side? Or should I have the client do the detection and have the server follow up on it somehow? I feel like it will be too much for the server to do by itself (I am designing the engine for hundreds of players on one server).</p>

<p>Does anyone know how mainstream MMOs do it? I know that almost all MMOs right now are susceptible to physics hacks and usually deal with them by detecting hacks and banning people. I would rather the hacks did not work at all, at least for the physics component.</p>
","<p>It seems like the obvious answer is to do most of your detection client-side (for smoothness), and then you interpolate to what the server says if your client is too far off.  The server will tick at a less frequent rate than the client (like, say, 10hz), and would probably need to have some basic ""can this player have reached where he says he currently is from his last known location"" code, which implies some kind of nav mesh-type solution and pathfinding.</p>

<p>That might be prohibitively slow depending on what your needs are.  You might make a design decision, for example, to not care about player-player collision on the server.  Most games, as far as I know, don't even care about that on the client.  It really depends on what your needs are.</p>

<p>But the rule of thumb is that you should never trust the client.  It if impacts gameplay, you have to at least verify it on the server.</p>
","3885"
"How to check for cube collisions?","9679","","<p>I want a method, which takes two ""ObjectBox"" objects (A ""ObjectBox"" has <code>.getX()</code> <code>.getY()</code> <code>.getZ()</code> <code>.getSizeX()</code> <code>.getSizeY()</code> <code>.getSizeZ()</code> methods) as a parameter and return true if the two Boxes are colliding and false if they aren't.</p>

<p>So it should be something like this:</p>

<pre><code>public static boolean checkCollision(ObjectBox box1, ObjectBox box2){
return //TRUE IF COLLIDING - FALSE IF NOT COLLIDING
}
</code></pre>

<p>I tried figuring it out but it seemed pretty hard to me.</p>
","<p>This is called an AABB (Axis Aligned Bounding Box). The collision checks for these are pretty fast and simple. Basically you just check their relative positions and see if all three axes overlap:</p>

<pre><code>public static boolean checkCollision(ObjectBox a, ObjectBox b){
{
   //check the X axis
   if(Math.abs(a.getX() - b.getX()) &lt; a.getSizeX() + b.getSizeX())
   {
      //check the Y axis
      if(Math.abs(a.getY() - b.getY()) &lt; a.getSizeY() + b.getSizeY())
      {
          //check the Z axis
          if(Math.abs(a.getZ() - b.getZ()) &lt; a.getSizeZ() + b.getSizeZ())
          {
             return true;
          }
      }
   }

   return false;
} 
</code></pre>

<p>Only if all three axes overlap there is a collision. For example, if the cubes were overlapping on the X and Z axes and not the Y, it means that the cubes are above or below each other and not colliding. You can optimize the code above slightly, if there's an axis you're more likely to be colliding on, put that check first so you don't need to check the others.</p>

<p>Keep in mind, the above code assumes that the position is the center of the cube and the size is getting the half extents of the cube. If your <code>getSize_</code> functions are returning the full dimension, you'll need to half them for the above to work properly.</p>
","60514"
"Which is the best LOD method for planet rendering?","9677","","<p>I'm currently working on my thesis, it is an engine to render terrains of planetary size.</p>

<p>I'm still finishing my research and I have encountered a lot of stuff about this subject, the problem is that I can't decide on which Level of Detail (LOD) method I should use.</p>

<p>I know about geomipmapping, geometry clipmaps (GPU) and chunked LOD by Ulrich that work good on large terrains and can be used to render 6 faces of a cube and then ""spherify"" the cube by <a href=""http://mathproofs.blogspot.com/2005/07/mapping-cube-to-sphere.html"">this method</a> and I understand how to implement all of these methods on GPU using C++/OpenGL/GLSL (using methods like ROAM or any other method that doesn't use a cube is out of my reach because of texturing is a pain). Also I recently got into a tutorial of rendering terrains using tessellation shaders <a href=""http://www.kdab.com/opengl-in-qt-5-1-part-5/"">here</a></p>

<p>So, I don't have the time to implement ALL the methods and see which one is the best and more suitable for a planetary scale and I'm asking here to see if someone has made this kind of comparison and help me decide which method should I implement and use (my tutor is kind of crazy and wants me to do something with an icosahedron, but I can't understand that method unless using ROAM)</p>

<p>Anyways, if you can help me decide or have any other suggestion or method I really will appreciate. One condition is that the method should be able to implement GPU side (at least most of it) to prevent CPU bottleneck.</p>

<p>Another request is that I know there are numerical problems about precision with floats when getting a lot of detail in the terrain, I don't know how to solve it, I read a solution in a forum but can't get to understand how to implement, I lost track of that thread and I would like to know how to solve this precision problem.</p>

<p>I'm currently reading about some matrix transformations to solve the float precision, z-fighting issues, frustum culling with dynamic z-values, and data representation for chunks (using patch space with floats and its position in the world coordinates as double) so I think I can solve the precision problem easily. I still need a comparison between LOD methods with your opinions and suggestions to decide which is better for this project. Take in count difficulty of implementation vs visual quality vs performance, I want the best.</p>

<p>Something I forgot to mention is that the generation is hybrid, I mean, I should be able to render the planet entirely using GPU (heights calculated on the fly) and/or using a base height-map image and add details with GPU (vertex shader). Texturing will be a side part I will trouble latter, right now I'm happy using just colors depending on the height, or maybe using some kind of noise texture generated on the fragment shader.</p>
","<p>Finally, after a lot of researching I can conclude that, as some one said before, There is not universally ""best"" method. But my research led me to the knowledge of the following things:</p>

<p>Depending on the mesh you will finally use:</p>

<ul>
<li><strong>Spherified Cube:</strong> any LOD method with quadtree implementation will work just fine, you just have to take care on special cases like borders between faces, in wich case, your quadtree has to have a pointer to the neighbor in the adyacent face in each level.</li>
<li><strong>Any other:</strong> I think that ROAM (newer version 2.0 or any other extension as BDAM, CABTT or RUSTIC) will do well, however, these algorithms are hard to work with, require more memory and are a bit slower than other aproaches with cubes.</li>
</ul>

<p>There are many LOD methods that can fit well, but my personal top 5 are:</p>

<ol>
<li><a href=""http://vertexasylum.com/2010/07/11/oh-no-another-terrain-rendering-paper/"">Continous Distance-Dependent LOD (CDLOD)</a></li>
<li><a href=""http://research.microsoft.com/en-us/um/people/hoppe/gpugcm.pdf"">GPU Based Geomety Clipmaps (GPUGCM)</a></li>
<li><a href=""http://tulrich.com/geekstuff/sig-notes.pdf"">Chunked LOD</a> </li>
<li>Rendering Terrains with OpenGL GPU Tessellation (Book: OpenGL Insight, Chapter 10)</li>
<li><a href=""http://www.flipcode.com/archives/article_geomipmaps.pdf"">Geometrical MipMapping</a></li>
</ol>

<p>Each one offers an unique way to render terrains, for example, CDLOD has a very easy implementation using shaders (GLSL or HLSL) but is also capable to be implemented on CPU (for legacy hardware) however the goal on Planet Rendering is to explode the best on moderns GPUs, so GPUGCM is the best when you want to squeeze your GPU. They both work very well with data-based, procedural or mixed (terrain based on fixed data or heightmaps and detail added with procedural work) rendering of large terrains.</p>

<p>Also Spherical extension to the basic Geometrical Clipmaps method exists but has some problems because the planar samples of the heightmap has to be parametrized using spherical coordinates.</p>

<p>Chunked LOD, in the other hand, is perfect for legacy hardware, doesn't need any GPU side calculations to work, it's perfect for large datasets but can't handle procedural data in real time (maybe with some modifications, it could)</p>

<p>Using Tessellation shaders is another technique, very new, since OpenGL 4.x came out, in my opinion it could be the best, but, we are talking about Planet Rendering, we encounter a problem that other methods can handle very easy and it is about precision.</p>

<p>Unless you only want your precision to be 1Km between verticies, go for Tessellation shaders. The problem with really big terrains with this method is that jitter is kind of hard to solve (or at least for me, since I'm new to tessellation shaders).</p>

<p>Geomipmapping is a great technique, takes advantage of the quadtree and has a low projected pixel error, but, for planetary rendering you will need to set at least 16+ levels of details, that means you will need (for stitching pourposes) some extra patches to connect different levels and take care of your neighbor's level, this can be tedious to solve, especially using 6 terrain faces.</p>

<p>There is another method, very particular in its own: <a href=""http://www.cse.unr.edu/hpcvis/pgm"">""Projective Grid Mapping for Planetary Terrain""</a> excellent for visualization, but has its disadvantages, if you want to know more, go to the link.</p>

<p><strong>Problems:</strong></p>

<ul>
<li><p><strong>Jitter</strong>: Most of today’s GPUs support only 32-bit floating-point values, which
does not provide enough precision for manipulating large positions in planetary scale terrains. Jitter occurs when the viewer zooms in and rotates or moves, then the polygons start to bounce back and forth.</p>

<p>The best solution for this is to use ""Rendering Relative to Eye Using
the GPU"" method. This method is described in the book ""3D Engine
Design for Virtual Globes"" (I'm sure you can find it on the internet
aswell) in where basically you have to set all your positions with
doubles on CPU (patches, clipmaps, objects, frustrum, camera, etc)
and then MV is centered around the viewer by setting its translation
to (0, 0, 0)T and the doubles are encoded in a fixed-point
representation using the fraction (mantissa) bits of two floats, low
and high by some method (read about Using Ohlarik’s implementation
and The DSFUN90 Fortran library).</p>

<p>Although the vertex shader requires only an additional two
subtractions and one addition, GPU RTE doubles the amount of vertex
buffer memory required for positions. This doesn’t necessarily double
the memory requirements unless only positions are stored.</p></li>
<li><p><strong>Depth Buffer Precision</strong>: Z-fighting. As we are rendering very large terrains, in this case: planets, the Z-buffer has to be HUGE, but it doesn't matter wich values you set for znear and zfar, there will always be problems.</p>

<p>As the Z-buffer depends on a float point interval, and also it is
linear (although perspective projection is non linear) values near
the eye suffer from Z-fighting because the lack of precision 32-bit
floats have.</p>

<p>The best way to solve this problem is to use a ""Logarithmic Depth
Buffer""
<a href=""http://outerra.blogspot.com/2012/11/maximizing-depth-buffer-range-and.html"">http://outerra.blogspot.com/2012/11/maximizing-depth-buffer-range-and.html</a></p>

<p>A logarithmic depth buffer improves depth buffer precision for
distant objects by using a logarithmic distribution for zscreen. It
trades precision for close objects for precision for distant objects.
Since we are rendering with a LOD method, far objects require less
precision because they have less triangles.</p></li>
</ul>

<p>Something important to mention is that all the methods listed (except for the projective grid) are very good when doing physics (collisions mostly) because of the Quadtree base, that is something mandatory if you plan to make a game.</p>

<p>In conclusion, just check all the options available and go for the one you feel more confortable, in my opinion CDLOD does a great work. Don't forget to solve the jitter and Z-buffer problems, and most important: have fun making it!</p>

<p>For more information about LOD check <a href=""http://geoinformatics.fsv.cvut.cz/gwiki/Modern_Algorithms_for_Real-Time_Terrain_Visualization_on_Commodity_Hardware"">this link</a>.</p>

<p>For a complete demostration about spherifying a cube check <a href=""http://mathproofs.blogspot.com/2005/07/mapping-cube-to-sphere.html"">this link</a>.</p>

<p>For a better explanation about solving jittering and Z-Buffer precisions, check <a href=""http://www.virtualglobebook.com/"">this book</a>.</p>

<p>I hope you find this little review useful.</p>
","57825"
"Is there a faster sine function?","9674","","<p>I am working on generation 3d perlin noise. The C# Math library seems like overkill for what I need since most of its functions use double percision. I use Math.Sin() in several places to generate the noise. Does anyone know of a faster sine function?</p>
","<p>You can use a parabola to aproximate the value of the sine function. This has the advantage of having the roots at exactly -pi/2 and pi/2 which is usually not the case with other fast approximations based on the <a href=""http://mathworld.wolfram.com/TaylorSeries.html"" rel=""nofollow noreferrer"">TaylorSeries</a> or <a href=""http://mathworld.wolfram.com/MaclaurinSeries.html"" rel=""nofollow noreferrer"">MaclaurinSeries</a>. </p>

<pre><code>public float Sin(float x)
{
    const float B = 4 / PI;
    const float C = -4 / (PI*PI);

    return -(B * x + C * x * ((x &lt; 0) ? -x : x));
} 
</code></pre>

<p>Here is a comparison to the actual sine function:</p>

<p><img src=""https://i.stack.imgur.com/TSYQu.gif"" alt=""alt text""></p>
","4780"
"How to implement explosion in OpenGL with a particle effect?","9660","","<p>I'm relatively new to OpenGL and I'm clueless how to implement explosion. So could anyone give me some ideas how to start? Suppose the explosion occurs at location $(x, y, z)$, then I'm thinking of randomly generate a collection of vectors with $(x, y, z)$ as origin, then draw some particle (<code>glutSolidCube</code>) which move along this vector for some period of time, says after 1000 updates, it disappear. Is this approach feasible? A minimal example would be greatly appreciated. </p>
","<p>You are on the right track. </p>

<p>Typically for particle effects, flat triangles or quads are used for the particles as opposed to  something like glutSolidCube. Often the quad are billboarded so that they are always oriented to the camera (so you never see them edge on). Having said that, there is no reason why you can't use cubes for your particles (apart from performance)</p>

<p>The outline for a particle effect is something like this;</p>

<ol>
<li><p>create a buch of particles, each particle will have its own velocity, position etc (see below)</p></li>
<li><p>each particle is drawn as a textured quad, usually blended, with transparent edges. The texture and colour of the quad depends on the effect you are trying to achieve.</p></li>
<li><p>When the particles are spawned at they explosion point,they will be launched out a random velocities, they will be initially very small, but are scaled larger over time. Usually each particle will also have some random angular velocity so the will also rotate as they move away from the spawn point.</p></li>
<li><p>As a particle grows older, at some point it will be forced to fade away, once it is are completely transparent they will be removed.</p></li>
</ol>

<p>There are a lot of properties to control to get the effect you want</p>

<ul>
<li>range of initial velocities</li>
<li>rate of spawning</li>
<li>response to gravity &amp; wind</li>
<li>range of angular velocities</li>
<li>rate of fading</li>
<li>time to live</li>
<li>rate of growing</li>
<li>particle texture(s) [often same texture  is used for all particles]</li>
<li>potentially many more</li>
</ul>

<p>Here is <a href=""http://3dgep.com/?p=1057"">another opengl particle effect tutorial</a> in OpenGL/glut</p>
","40251"
"How can auto-click software be detected to stop botting/cheating?","9651","","<p>I have to completely change my question, because it was far too general. I now want to focus on how I can detect one type of cheating method.</p>

<p>How can auto-clicking be detected? In general, I am referring to software that will simulate mouse clicks or keyboard input automatically. It seems this would be useful for botting behaviour.</p>

<p>Can my software see other software the user's computer is running. If so, how does the software know what the other program is doing? Will it need to check the byte code for routines that simulate mouse/keyboard input?</p>

<p>Would it be useful for my software to detect if the mouse is jumping across the screen in a non-human-like behaviour? That is the first thing I can think of to stop it, as it would be the simplest but also the cheater might be able to simulate mouse movement that is human-like.</p>

<p>I should probably mention that I am most comfortable with Python and C++, and I am currently learning the Windows API.</p>
","<p>That can be tricky if the auto clicker has a Random var for the interval inbetween the clicks. </p>

<p>There are a few things you can do to detect/stop these guys:
1) Disable the part were the clicking occurs, if people need a bot to do some action it is simply too boring for a human being. (my no.1 suggestion, as it is not in your business to bannish players, and if the game itself is boring it is only your fault)</p>

<p>2) As for the detection of an auto clicker. There are a few types of auto clicking bots (I scripted bots for RuneScape) and there you would have:</p>

<p>Clicking on a specific 3d game object mesh inside the editor, all objects have an id. (ultra hard to detect).</p>

<p>Clicking on one specific gamespot for eg. the minimap, always one exact pixel in the players current pos. Players can set up an auto mouse to click in one point.
(less complex)</p>

<p>1)</p>

<blockquote>
  <p>First thing you want to set, is the player online time table. - if
  a player has an ""insomniac"" entry (playing over 20h/day) mark him
  automatically as suspicious. In the game Tibia there is a fan website Pskonejott.com
  where anyone can see the online time of all players. Some stay up for 40
  hours, I hardly believe it is Redbull rather than C++ :)
  Add it to his record if he plays over X hours.</p>
  
  <p><a href=""http://www.pskonejott.com/otc_insom.php"" rel=""noreferrer"">http://www.pskonejott.com/otc_insom.php</a></p>
</blockquote>

<p>2)</p>

<blockquote>
  <p>Make up a Log for actions and if the time between the actions is
  nearly identical mark that person as a bot. Player clicks on
  something, then after some time he clicks again. if he repeats this
  action every five minutes +- (1-2)% for 5hours, mark him as
  suspicious.</p>
</blockquote>

<p>3)</p>

<blockquote>
  <p>Try to implement the web Captcha once every few hours if it is a browser game it will be easy to do. For instance the player gets> teleported and then he is supposed to type in the Captcha. No bot so far has been able to handle that. (Some humans got problems with that too)
  <a href=""http://areyouahuman.com/demo/"" rel=""noreferrer"">http://areyouahuman.com/demo/</a> Doesn't matter how many mistakes he
  makes, If he can't do it for 10 minutes/loggs out add this to his
  record.</p>
  
  <p><a href=""http://areyouahuman.com/demo/"" rel=""noreferrer"">http://areyouahuman.com/demo/</a></p>
</blockquote>

<p>4)</p>

<blockquote>
  <p>Set up a quick report abuse system. With an ingame report abuse
  button. Encourage players to report suspicious actions, tell them to
  ask the suspicious characters if they are alive. If the player
  responds immediately/the reporter doesn't speak to him directly using
  his name ""Hey Player, you there?"" it likely means that the report is
  fake.</p>
</blockquote>

<p>5) </p>

<blockquote>
  <p>Give all your workers ingame characters as Moderators/Game Masters
  along with volountary game masters. They actually should sometimes log
  into the game to know what is going on, and get a real bio from the
  players not just forums, if a player has a feeling that he might
  actually meet a Moderator it could prevent some of them from botting.</p>
</blockquote>

<p>6)</p>

<blockquote>
  <p>Have a community manager to manage the bans, there always should be a
  judge to make sure no one gets deleted without an important issue. He
  should look through the player logs marked as suspicious and define if
  his actions can actually be botting.</p>
</blockquote>
","51168"
"glCreateShader causes segmentation fault","9625","","<p>I can't create a shader when trying to use shaders with sfml. The function glCreateShader(GL_VERTEX_SHADER); causes a segmentation fault. At first I googled it and found that it does that when the program does not have an opengl context. I tried SDL first but the poor documentation and ""look at the header to know what to do"" made me go for sfml</p>

<p>the code that causes the seg fault is bellow</p>

<pre><code>    sf::Window App(sf::VideoMode(800, 600, 32), ""SFML OpenGL"");

// Set color and depth clear value
glClearDepth(1.f);
glClearColor(0.f, 0.f, 0.f, 0.f);

// Enable Z-buffer read and write
glEnable(GL_DEPTH_TEST);
glDepthMask(GL_TRUE);

// Setup a perspective projection
glMatrixMode(GL_PROJECTION);
glLoadIdentity();

GLuint vertShader = glCreateShader(GL_VERTEX_SHADER);

    //...
</code></pre>

<p>I'm including glew, gl.h, sfml-window, sfml-system, using opengl 2.1 on gcc linux.</p>

<p>What is missing?</p>
","<p>You're not checking OpenGL extensions, version, or etc.</p>

<pre><code>GLenum err = glewInit();
if (err != GLEW_OK)
  exit(1); // or handle the error in a nicer way
if (!GLEW_VERSION_2_1)  // check that the machine supports the 2.1 API.
  exit(1); // or handle the error in a nicer way
</code></pre>

<p>This code needs to happen <strong>after</strong> creating the OpenGL context, but <strong>before</strong> using any potentially-not-existing functions.  More details on the <a href=""http://glew.sourceforge.net/basic.html"">GLEW web page</a></p>
","22788"
"Understanding Unity 5 Car controller","9616","","<p>As with all Unity versions Unity 5 comes with a set of Standard Assets. This new set of Standard Assets comes with a Car Controller. Either by attaching a Car user controller script or a Car A.I. script the Car is ready to be used within a game. I am using that said Car controller to create my own car in a game. What I am trying to do is increase the cars acceleration and top speed. I did not find any documentation on the mechanics behind the car controller (and since I do not know much about cars) I did not find a way on how to do this. I am reading the script and understand the flow of code but do not understand which variables affect what in the script. </p>

<p>Now for Top speed the car controller exposes a public variable responsible for that precise task.
But what about acceleration?</p>
","<p>In order to increase the car's acceleration, you need to increase the torque variable.
There are two torque variables in Unity's official car controller, one for the forward movement and one for the reverse.</p>

<p>Keep in mind that the torque variable also controls how gears change (f.e. more torque = earlier gear changes) and too low of a torque can make certain speeds pretty hard to attain.</p>
","98402"
"Anti-cheat Javascript for browser/HTML5 game","9616","","<p>I'm planning on venturing on making a single player action rpg in js/html5, and I'd like to prevent cheating. I don't need 100% protection, since it's not going to be a multiplayer game, but I want some level of protection. </p>

<p>So what strategies you suggest beyond minify and obfuscation?</p>

<p>I wouldn't bother to make some server side simple checking, but I don't want to go the Diablo 3 path keeping all my game state changes on the server side.</p>

<p>Since it's going to be a rpg of sorts I came up with the idea of making a stats inspector that checks abrupt changes in their values, but I'm not sure how it consistent and trusty it can be.</p>

<p>What about variables and functions escopes? Working on smaller escopes whenever possible is safer, but it's worth the effort?</p>

<p>Is there anyway for the javascript to self inspect it's text, like in a checksum? </p>

<p>There are browser specific solutions? I wouldn't bother to restrain it for Chrome only in the early builds. </p>
","<p>The short answer is you can't do it. Anything that runs client side, especially from source, can be modified to defeat your tactics trivially. If you put in place a client side checker to look for abrupt changes, a user can just disable the checker.</p>

<p>The good news is that, generally, there is very little cheating on single-player games. The only major exception being for games that have large ""youtube highscore"" communities like Line Rider, where players compete with each other over YouTube.</p>

<p>If you are aiming for that, or are just too stubborn to accept that people might cheat in the game, or are keeping high-scores yourself (which is a form of multiplayer) then what you must do is all of the calculations server-side. Yes, everything that matters. You can't even repeat the calculation client side to try to give the user the score and then 'verify' it with the server because the user can then just disable the check and disable any system that ensures there are checks.</p>

<p>I wish there was a better answer to this, but there isn't.</p>

<p>That said, there are things you can do to make it a little harder to cheat. They will not stop anyone serious from doing it and releasing a toolkit to cheat, but it will slow them down:</p>

<ul>
<li>Minify and Obfuscate your JS, which absolutely will make the code harder to read. You can de-minify and sort-of de-obfuscate but you can never get back the right variable and function names, nor comments.</li>
<li>Bake in values with a different language. In this case you can use PHP or other server side languages to handle static setup variables. If the jump distance is always supposed to be 2 spaces, normally you'd define a jump distance for the player object. Don't, handle that with PHP so that the JS source ends up with 2s plastered all over the code in a million places. This has the happy additional side effect of being able to speed up your JS too. </li>
<li>With some practice, you'll get proficient with the mix and you can even custom-build your JS for each player. Which is another way to prevent cheating. If each player's code is different somehow, then it is harder to write a cheat that can be part of a toolkit.</li>
<li>Finally, you can checksum the source based on the player's identity. Say their IP address and/or username. You know what the player-specific version of the JS will be, you can bake in a checksum and require that it be the same on the other end. Easy to disable like any client-side JS, but once again makes it a little harder to make a toolkit.</li>
</ul>

<p>So. As you see, it is probably not worth it to go this route. It is hard. Requires a lot of really silly coding practices to do, and is ultimately still relatively easy to defeat. You'll need to do all the calculations server-side to prevent cheating. Or let go, and accept that cheating will happen.</p>
","37395"
"Ogre vs. Irrlicht","9603","","<p>I've experimented a bit with the Ogre (http://www.ogre3d.org) and Irrlicht (http://irrlicht.sourceforge.net) engines, both of which are open source and are trying to fill similar niches.  From what I've seen so far they're both well-written and easy to use.</p>

<p>I could use an informed compare-and-contrast of the strong and weak points of those two game engines and the engine-specific challenges related to going from start to released product.  I'm interested in anything from asset management to configuration tools to audio/network/videoplayback framework integration to rendering/polygon constraints.</p>
","<p>Ogre3D and Irrlicht are both rendering engines. As such they will not help you with audio, networking etc. There are other engines for sound and networking such as OpenAL, FMOD, Irrklang, RakNet that you will have to integrate (or use a framework that is already wraps up the engines). </p>

<p>As for the compare-contrast, this has been asked many many times and instead of repeating them I will refer you to the following links</p>

<ol>
<li><a href=""http://www.nuclex.org/blog/2-gamedev/24-seven-engines-you-should-know"" rel=""nofollow"">http://www.nuclex.org/blog/2-gamedev/24-seven-engines-you-should-know</a></li>
<li><a href=""http://www.blitzbasic.co.nz/Community/posts.php?topic=73978"" rel=""nofollow"">http://www.blitzbasic.co.nz/Community/posts.php?topic=73978</a></li>
<li><a href=""http://www.ogre3d.org/forums/viewtopic.php?t=33791"" rel=""nofollow"">http://www.ogre3d.org/forums/viewtopic.php?t=33791</a></li>
</ol>

<p>When I started I wasted quite a bit of time asking the same question and reached no conclusion. If engine A has a weak point discussed in one thread, in another, Engine B will have the same weak point. It is all based on opinion.</p>

<p>However, there are <em>some</em> differences that are repeated, such as Irrlicht running faster on older hardware as it does not utilize modern techniques whereas Ogre3D is optimized for the latest hardware. </p>

<p>I personally chose Ogre3D after spending a few days trying both engines through their shipped examples and trying out various tutorials of both the engines. I chose Ogre3D based on my constraints and personal preference, I highly suggest you do the same instead of relying on conclusions based on other people's opinion.</p>
","5622"
"How would you handle different aspect ratios in a 2d platformer?","9593","","<p>A long time ago, 4:3 was pretty much the only apect ratio you would find on a PC. Today the most common one is 16:10, but most new monitors (especially laptops) are 16:9</p>

<p>I'm writing a 2D platformer, and I can't decide how I should handle all the different ratios.</p>

<p>Here are some ideas:</p>

<ol>
<li>4:3 gets more content, widescreens are cut on top and bottom</li>
<li>16:9 gets more content, the others are cut left and right</li>
<li>The game is in 16:9 with black horizontal bars for other ARs</li>
<li>The game is in 4:3 with black vertical bars for other ARs</li>
</ol>
","<p>If you have no compelling reason to make your game ""wide"" (in which case use approach 3) or narrow (in which case use approach 4), go with a <strong>combination of 1 and 2</strong> (or possibly 3 and 4 if you want to hide things off-screen).</p>

<p>Select a compromise aspect ratio (16:10 is a good one, or even 16:11). If the user is on 16:9 give them more content to the side, and if they're on 4:3 give them more content at the top and bottom.</p>

<p>In any case - I find it best to implement it with something like this in your camera class:</p>

<pre><code>float scaleToFitWidth = viewport.Width / nominalWorldSize.Width;
float scaleToFitHeight = viewport.Height / nominalWorldSize.Height;
float scale = Math.Min(scaleToFitWidth, scaleToFitHeight); // world to client
</code></pre>

<p>At which point you can simply experiment with different nominal world sizes (ie: the size of the camera in world units) and simply select the best one.</p>
","2083"
"Can I achieve a torchlight effect (lighter area around a light source) in a 2D game?","9588","","<p>I am thinking of writing myself a simple 2D game. It will not shine with perfect graphics or gameplay at first, but I'd consider it my first step in PC game development. So, imagine such simple sprite-based 2D game (like Heroes IV or Startcraft BroodWar).</p>

<p>I want the gameplay to support day/night with the according lighting changes and at the same time it will be madness to have to create sprites for every lighting nuance. So, I decided adding a semi-transparent layer on top of other objects will be enough. </p>

<p>The issue with this solution is if I have a light source object in the game (like the hero wearing a torch, or a burning building), there must be a lighter area around it, right? Since I am putting my semi-transparent layer over everything, how would you suggest to achive the torchligt visual effect I want? Maybe redraw that layer adding 'gaps' or differently colored areas based on the lighting effect?</p>
","<p>I don't know what you're programming in, but this is how I handled it in XNA:</p>

<ol>
<li>On the draw call, a <code>List&lt;Light&gt;</code> object is created/cleared.</li>
<li>During the tile draw loop, each tile is checked to see if it has any Lights associated with it. If it does, the <code>Light</code> objects are appended to the <code>List&lt;Light&gt;</code>.</li>
<li>The tiles are drawn onto their own <code>RenderTarget2D</code>.</li>
<li>After the tile loop, the list of <code>Light</code>s is iterated through and drawn on their own <code>RenderTarget2D</code> using a texture I made that looks like this:<br>
<img src=""https://i.stack.imgur.com/NaD6F.png"" alt=""Light Texture""> (Note: I used the R, G and B values here but you should probably use the alpha channel in your actual texture.)</li>
<li>Using a custom shader, I render the tile surface to the screen and pass in the lighting surface as a parameter which gets sampled for the ""darkness"" value at each pixel.</li>
</ol>

<p><hr />
Now, there's a few things to note:</p>

<p><strong>Regarding Point 4:</strong></p>

<p>I actually have two custom shaders, one to draw the lights to the lighting render target (step 4) and another to draw the tile render target to the screen using the lighting render target (step 5).<br>
The shader used at point 4 allows me to add (what I call) a ""luminosity"" value. This value is a <code>float</code> that gets multiplied against each pixel in the texture 
before it's added to the render target so that I can essentially make lights brighter or darker.<br>
At this point, I also take into account the light's ""scale"" value which means that I can have large or small lights using only one texture.</p>

<p><strong>Regarding Point 5:</strong></p>

<p>Think of the lighting render target as essentially having a value for each pixel from 0 (black) to 1 (white). The shader essentially multiplies that value against the RGB values for a pixel in the tile render target to make the final drawn image.</p>

<p>I also have some more code here where I pass in (to the shader) a value to be used as the day/night overlay colour. This is also multiplied into the RGB values and included in the lighting render target calculations.
<hr />
Now, this won't allow you to do things like block light from going around objects and whatnot but, at least for my purposes, it's simple and works well.</p>

<p>I've written more detailed blog posts <a href=""http://www.systemroot.ca/2011/09/fondusis-dev-blog-week-4/"" rel=""noreferrer"">here</a> and <a href=""http://www.systemroot.ca/2011/10/fondusis-dev-blog-week-5/"" rel=""noreferrer"">here</a> which may help you. I don't have time right now, but if you want I can go into more detail here on gamedev.</p>

<p>Oh, and here's a look at it in my map editor:<img src=""https://i.stack.imgur.com/xrkTa.png"" alt=""enter image description here""></p>
","22163"
"How do you approach resolution independence in raster based graphics content?","9586","","<p>Those games that are not fortunate enough to run on a locked platform spec, like handhelds, need to run across various resolution formats and aspect ratios. </p>

<p>In a 3D game you might have a HUD or menu GUI based on raster graphics, and in a 2D game you might have a bunch of quads which are vessels for sprites. </p>

<p>So my question is, how do you approach designing and operating content across various resolutions and aspect ratio? Let's assume you have a sprite character that is 300x400 pixels sprite and surrounded by a level made of tiles. On different resolutions/aspect ratios you'd see a different FOV altogether. Or if you have a HUD or a GUI menu, you'd want to keep some stuff at same positions and of same size relative to the screen. Yet, graphics source is raster bitmaps, not vector. </p>

<p>Obviously, problem has been addressed numerous times. I'm interested to hear abut various approaches that worked for you so far. Do you keep an arbitrary dimension agnostic 'pixel' unit that you magically transform into needed dimensions via formula based on res and aspect ratio or other approaches?</p>

<p><strong>edit:</strong></p>

<p>So, conclusion is to enumerate your aspect ratios. Lowest combination of aspect:resolution is the one you design important stuff into. A safe area if you will. Same aspect ratios, but higher resolutions are simple scaling issues. Art content is designed for highest resolution. Larger aspect ratios simply show more of level/FOV with information presented which is not critical as is the one in safe area. <a href=""https://imgur.com/5XHnl.png"" rel=""noreferrer"">Something like in this image I made</a>.
<img src=""https://imgur.com/5XHnl.png"" alt=""alt text""></p>
","<p>If your resolutions are similar to each other, you can just use the same art across all of them with maybe some downscaling at runtime for the smaller screens. If they differ by more than say a factor of 2x, you're going to need to author (or at least have an artist tweak) separate assets for the different resolutions.</p>

<p>With 2D, resolution has a huge affect on how you design images. A sprite that looks richly detailed and realistic at high-res will be muddy and indecipherable scaled down. Likewise, a sprite that's clean and sharp looking at low-res will look cheap and overly-simple at high-res.</p>
","228"
"Unity - OnDestroy - When is it called?","9582","","<p>I was wondering about the method called <a href=""http://docs.unity3d.com/ScriptReference/MonoBehaviour.OnDestroy.html"" rel=""nofollow"">OnDestroy</a> in Unity (4.5.2f1) on Windows 8.1 Update 1. I know garbage collection in C# in non-deterministic, so I was wondering if game objects had <a href=""http://docs.unity3d.com/ScriptReference/MonoBehaviour.OnDestroy.html"" rel=""nofollow"">OnDestroy</a> called the moment I called <a href=""http://docs.unity3d.com/ScriptReference/Object.Destroy.html"" rel=""nofollow"">Destroy</a> on them, or when the garbage collector was invoked?</p>

<p>If this is not the case, what are my alternatives? I could of course just call a method inside of the object to be destroyed just before I invoke destroy, but there may be a more elegant solution available that I don't know about.</p>

<p>Note: I did try checking this myself, but being non-deterministic I may not be able to rely on that behavior occurring every time.</p>
","<p><code>Destroy();</code> is an explicit command to remove the object from the game scene immediately* or after a set time increment. As soon as you call it - the item is destroyed in context of the scene.</p>

<p>Garbage collection will take it <strike>as soon as there are no more </strike> when it is ready assuming there are no more hard references to that item. However, this is not controllable in Unity without calling the GC system object.</p>

<p><a href=""http://docs.unity3d.com/ScriptReference/Object.Destroy.html"" rel=""nofollow"">Unity3D - Object.Destroy()</a></p>

<p><strong>* clarification - immediately meaning in that frame. After the Update loop the item is destroyed, it will always be done before rendering</strong></p>
","80990"
"Can I get around a Pokemon copyright with new art and minor changes?","9575","","<p>If I develop a game that is essentially pretty much Pokemon (you're a trainer, you catch ""monsters"" and put them to fight and level up etc), and I do the next things:</p>

<ul>
<li>I'm a trainer with a 6-""Monsters"" party.</li>
<li>Mechanics like the PC, Gym Leaders and ""tall grass"" will be used.</li>
<li>I will throw an ""ball"" to catch the weakened ""monster"".</li>
<li>I will use common item names, like ""potion"", ""high potion"".</li>
<li>The battles are almost the same as Pokemon in terms of mechanics (four moves, elements, critical, evasion etc)</li>
<li>I will NOT use Pokemon names nor graphics... artwork is mine.</li>
<li>Some of the attack names will match Pokemon attack names. I think it is okay, like ""ember"". Come on.</li>
</ul>

<p>With all these points, I shouldn't run into copyright issues or anything right? Even if the game feels a lot like Pokemon itself?</p>
","<p>First, I am not a lawyer, this is not legal advice, if you follow my advice and get sued then it's your fault not mine.</p>

<p>That said, you've talked about ""copyright issues"". I'm going to break this down into two questions:</p>

<p>1) If I get sued for copyright infringement, will I win?</p>

<p>Probably! Game mechanics can't be copyrighted, so you're safe there. If ""potion"" isn't officially in the public domain then it's only one court case away from being so. ""Ember"" should be reasonably easy to defend - I know that ability name is used elsewhere. The ""ball"" is probably the sketchiest thing you've got, and if you just change the ball you're probably gold.</p>

<p>2) Will I get sued?</p>

<p>Maybe.</p>

<p>Unless you have a nice big legal war chest to rely on, getting sued is almost as bad as losing. You can't hope to match Nintendo's legal funds. It will not happen. You'll go to court, and you'll probably blow thousands of dollars <em>just on prep work</em>. And then even, if you win, there's no way you're getting that money back without a second court case - more money, and you're not even guaranteed to win that one.</p>

<p>So, as I see it, you have two realistic approaches ahead of you.</p>

<p>First, you can change things up enough so it's not as sketchy. Give your game a feeling of its own, not one copied from Pokemon. Don't use ""gym trainer"" and ""tall grass"", invent stuff. Instead of four abilities, use six. Give your PC a seven-monster party, and do something new with the monsters. Throw out two thirds of the Pokemon elements and make your own. (You're probably safe with ""fire"", but if you have ""psychic"", ""bug"", ""rock"", and ""ghost"", people will look at you a bit odd.) ""Inspired by Pokemon"" is safe. ""Exact copy of Pokemon"" isn't safe.</p>

<p>Alternatively: get legal counsel, get legal insurance, <em>and</em> form an official company to get at least a slight hint of the corporate veil going on. It'll cost you money, but it'll be a lot cheaper than being sued into oblivion by Nintendo, who will probably cheerfully drop the suit the instant you sign over all your intellectual property to them, and not a moment before.</p>

<p>Again, not a lawyer, not legal advice, get a lawyer.</p>
","10214"
"circle - rectangle collision in 2D, most efficient way","9571","","<p>Suppose I have a circle intersecting a rectangle, what is ideally the least cpu intensive way between the two?</p>

<ol>
<li><p>method A</p>

<ol>
<li>calculate rectangle boundaries</li>
<li>loop through all points of the circle and, for each of those, check if inside the rect.</li>
</ol></li>
<li><p>method B</p>

<ol>
<li>calculate rectangle boundaries</li>
<li>check where the center of the circle is, compared to the rectangle</li>
<li><p>make 9 switch/case statements for the following positions:</p>

<ul>
<li>top, bottom, left, right</li>
<li>top left, top right, bottom left, bottom right</li>
<li>inside rectangle</li>
</ul></li>
<li><p>check only one distance using the circle's radius depending on where the circle happens t be.</p></li>
</ol></li>
</ol>

<p>I know there are other ways that are definitely better than these two, and if could point me a link to them, would be great but, exactly between those two, which one would you consider to be better, regarding both performance and quality/precision?</p>

<p>Thanks in advance.</p>
","<p>Method B is more precise for a perfect circle. You are talking about running through every point in the circle, in Method A, and I'm assuming that's not small number of points (probably at least 12). Consider, then, that you are looping through points -- and conditionals are slower than non-conditional operations.</p>

<p>On the other hand, method B uses square roots. This is not cheap, but a single square root is almost certainly better than <code>n</code> conditionals.</p>

<p>Having said all of that, I'm pretty certain method B is going to be your best bet if you want both accuracy and good speed.</p>

<p>The correct and standard approach is actually this:</p>

<p>Method C</p>

<ol>
<li>Calculate rectangle bounds (either their own bounds if no rectangle rotation, or their bounding boxes if they are rotated in the plane).</li>
<li>Calculate each circle's rectangular bounds.</li>
<li>Apply a <a href=""https://stackoverflow.com/questions/306316/determine-if-two-rectangles-overlap-each-other"">fast range overlap test</a> in each of x and y axes to check for intersection of bound between object A and B (maybe a rectangle and a circle). If overlap, continue, else break as there is no way they can overlap if their bounds don't overlap.</li>
<li>Apply the more expensive test circle-circle or rect-circle intersection test to see if they <em>actually do</em> overlap. This is where the somewhat costly square root ops come in, to determine whether each of the 4 points of the given rect are within the radius of the circle.</li>
</ol>

<p>A hierarchical approach like this, where you test successive possibilities for elimination, by order of increasing cost (of conditional), is ubiquitous in all forms of collision detection.</p>

<p>Ultimately, you want to avoid conditionals, particularly lengthy loops, inasmuch as possible. See <a href=""http://www.gamedev.net/topic/531535-computationally-expensive-operations/"" rel=""nofollow noreferrer"">this thread</a> for an idea of precedence. This is why lower level languages such as C offer loop-unrolling as a compile-time optimisation.</p>

<p><strong>EDIT</strong> opatut has kindly noted that square roots are not a requirement for methods B &amp; C (see comments), leaving method A as the clear worst method.</p>
","44930"
"Blur effect on background to make the forground more clear unity","9564","","<p>I'm making a game in unity and I'm trying to add a background blur effect to my game to make things a bit more clear.</p>

<p>Here is an example of what I am looking to do:
<img src=""https://i.stack.imgur.com/PIjle.jpg"" alt=""Background image blur""></p>

<p>I'm trying to get the background blurriness and cloudy effect, but I have no idea how to go about getting a similar effect. It looks like a blur + cloudiness of some sort, but I've tried blurring my background objects and it just looks terrible.</p>

<p>Here is what I currently have:
<img src=""https://i.stack.imgur.com/6feoZ.png"" alt=""Current Game Without background effects""></p>

<p>I'm using Unity, it's all 2D sprites so I don't think I can use shaders, which is the only solution I could find people talking about, and have no idea how to proceed. Any help would be appreciated, Thanks.</p>

<p>Edit: Even knowing the terms I could use to search for a solution would help as I'm not quite sure what it is called.</p>
","<p>Shaders are what you need to use to make this happen, if you don't want to use pre-blurred art.</p>

<p>Basically what you'd do is render each layer to it's own texture every frame, then blur each layer the amount that it should be blurred, then combine all the layers into a single image, which is the output image you see on the screen.</p>

<p>For blurring, you are probably going to be best off using a 2 pass gaussian blur, where the first pass is X axis, and the second pass is Y axis.  Doing it in two one dimensional passes is way more efficient than doing a single two dimensional pass.</p>

<p>Here's a good looking tutorial on writing shaders in unity:
<a href=""https://cgcookie.com/unity/cgc-courses/noob-to-pro-shader-writing-for-unity-4-beginner/"" rel=""nofollow"">https://cgcookie.com/unity/cgc-courses/noob-to-pro-shader-writing-for-unity-4-beginner/</a></p>

<p>Hope that helps!</p>
","101742"
"Why is programmable pipeline( GLSL ) faster than fixed pipeline?","9561","","<p>So I'm teaching myself GLSL and am trying to figure out why it's suppose to be faster than the fixed function pipeline. </p>

<p>The reason I am having a problem is that from my understanding , the shaders you create are replacing sections of the pipeline that were there before. So, how's simply providing your own version speeding things up?</p>

<p>The only thing I can think is if you tried to supply say your own lighting equation before, you would have to do the calculation on the CPU, but now you can do the calculations on the GPU which will be faster. </p>

<p>Am I understanding this correctly?</p>
","<p>Shaders you create aren't going to be your own version of fixed-function pipeline(FFP), but a custom vertex- and pixel-manipulating operations to achieve something cool and complex. </p>

<p>Many things you do via programmable pipeline(PP) will work faster than their possible FFP implementations, because PP reduces the number of passes or amount of combiner and cubemap magic required to render these hypothetical things in FFP. </p>

<p>Imagine implementing such a common thing as per-pixel lighting in FFP with only interpolated vertex data and sample texture in your hands. It's not even possible to do it ""honestly"", only hacks for special cases depending on faithful precalculated cubemaps and some serious blending. With PP it becomes a matter of colorizing a dot product between light direction and vertex normal. </p>

<p>All in all, PP turns slow and impossible into fast and possible. But if you decide to write a shader to implement the same algorithms used in FFP, you would find out that FFP will be slightly faster because it's very hardware-optimised.</p>
","16427"
"Frame Independent Movement","9560","","<p>I've read two other threads here on movement:
<a href=""https://gamedev.stackexchange.com/questions/6825/time-based-movement-vs-frame-rate-based-movement"">Time based movement Vs Frame rate based movement?</a>, and 
<a href=""https://gamedev.stackexchange.com/questions/1589/fixed-time-step-vs-variable-time-step"">When should I use a fixed or variable time step?</a></p>

<p>but I think I'm lacking a basic understanding of frame independent movement because I don't understand what either of those threads are talking about.</p>

<p>I'm following along with lazyfoo's SDL tutorials and came upon the frame independent lesson. <a href=""http://lazyfoo.net/SDL_tutorials/lesson32/index.php"" rel=""nofollow noreferrer"">http://lazyfoo.net/SDL_tutorials/lesson32/index.php</a></p>

<p>I'm not sure what the movement part of the code is trying to say but I think it's this (please correct me if I'm wrong):
In order to have frame independent movement, we need to find out how far an object (ex. sprite) moves within a certain time frame, for example 1 second. If the dot moves at 200 pixels per second, then I need to calculate how much it moves within that second by multiplying 200 pps by 1/1000 of a second.</p>

<p>Is that right? The lesson says:</p>

<p>""velocity in pixels per second * time since last frame in seconds.
So if the program runs at 200 frames per second: 200 pps * 1/200 seconds = 1 pixel""</p>

<p>But...I thought we were multiplying 200 pps by 1/1000th of a second. What is this business with frames per second?</p>

<p>I'd appreciate if someone could give me a little bit more detailed explanation as to how frame independent movement works.</p>

<p>Thank you.</p>

<p>ADDITION:</p>

<pre><code>SDL_Rect posRect;
posRect.x = 0;
posRect.y = 0;

float y, yVel;
y = 0;
yVel = 0;

Uint32 startTicks = SDL_GetTicks();

bool quit = false;
SDL_Event gEvent;

while ( quit == false )
{
    while ( SDL_PollEvent( &amp;gEvent ) )
    {
        if ( gEvent.type == SDL_QUIT )
            quit = true;
    }

    if ( y &lt;= 580 )
    {
        yVel += DOT_VEL;
        y += (yVel * (SDL_GetTicks() - startTicks)/1000.f);
        posRect.y = (int)y;
    }

    startTicks = SDL_GetTicks();
    SDL_BlitSurface( bg, NULL, screen, NULL );
    SDL_BlitSurface( dot, NULL, screen, &amp;posRect );
    SDL_Flip( screen );
}
</code></pre>

<p>That's code that moves a dot down the screen. I think I have everything correct so far. It moves down the screen but there is a bit of an odd thing that happens that I can't explain. The dot is supposed to stay at the y=580 when it gets to greater than that y-value. However, every time I run the program, the dot will end up in a different location, meaning a little bit to a lot more than 580, so the dot is halfway or more than halfway off the screen (the dot is 20 pixels, screen dimensions 800x600). If I do something like click and hold the title-bar of the program, and then release, the dot disappears off the screen. How come it's variable each time?
As for the titlebar problem I think it's because when I hold on to the titlebar, the timer is still running, and the time elapsed gets larger, resulting in a larger distance the dot moves in the next frame. Is that right?</p>
","<p>NOTE: All fractions are meant to be floats.</p>

<p>Frame independent movement works by basing movement off of time. You get the amount of time that is spend since the last frame (so if there are 60 frames in one second, each frame takes 1.0/60.0 seconds, if all the frames took the same amount of time) and find out how much movement that translates into. </p>

<p>If you want your entity to move a certain amount of space for a specified unit of time (we will say 100 pixels for every second of time) then you can find out how many pixels you should move per frame by multiplying the amount of movement per second (100 pixels) by the amount of time passed in seconds (1.0/60.0) in order to figure out how much movement should take place in the current frame.</p>

<p>It works by figuring out how much movement you should perform per frame by using the amount of time elapsed and a speed that is defined with some unit of time (seconds or milliseconds are preferable). So your calculation might look like: <code>movementPerSecond * (timeElapsedInMilliseconds / 1000.0)</code></p>

<p>I hope that made some kind of sense to you.</p>

<p>I want to move my guy 200 pixels to the right every second. If the current frame is run 50 milliseconds after the previous frame, then I should move my guy a fraction of the speed previously specified (which was 200 pixels).
I should move him 50/1000th of the distance because only a 1/20th (50/1000 = 1/20) of time has passed. Therefore it would make sense to only move him 10 pixels (if 19 more frames occurred, 50 milliseconds apart from each other, then the total amount of movement in that second would be 200 pixels, the amount we wanted).</p>

<p>The way frame independent movement works is that frames usually occur at variable time steps (there is a different amount of time that takes place between subsequent frames). If we constantly move an entity a constant distance every frame, then the movement is based on the frame rate. If there is a lot of time between frames, the game will seem to move too slow and if there is not a lot of time between frames, the game will seem to be going to fast. (too little time between frames = a lot of frames = more movement) To overcome this, we use a speed in terms of time and keep track of the time between frames. That way we know how long it's been since we last updated the position and how much further we should move the entity. By using time we can eliminate the dependence on the frame rate and our game will look more or less the same on different frame rates.</p>

<p>Frames per second : This is the amount of frames that take place per second. Usually a frame rate is either how many times the game is drawn/rendered a second or how many times the game loop is completed a second.</p>

<p>Fixed Verse Variable Time Step : This refers to the amount of time between frames. Usually, the time between frames will not be constant. Certain systems/cores like physics will need some unit of time in order to simulate/run something. Usually, physics systems are more stable/scalable if the time step is fixed. The difference between fixed/variable time steps are in the names. Fixed time steps are what they sound like: time steps that occur at a fixed rate of time. Variable time steps are time steps that occur at varying/different rates of time.</p>
","9518"
"Is it possible to export a simulation (animation) from Blender to Unity?","9543","","<p>I created an explosion animation within Blender, something as shown in <a href=""http://www.youtube.com/watch?v=_lbgEOiz2pg&amp;feature=player_detailpage#t=305s"">this video</a>. To achieve this I used a particle-system, together with the ""Explode"" modifier.</p>

<p>This kind of animation (simulation) doesn't get exported to other file-formats though and I'd like to export the animation as FBX, so that I can use it in Unity. So I basically need some way to ""bake"" the animation to keyframes. I wonder if there's a way to achieve this?</p>

<p>After some testing I found out, that the only way the simulation gets exported is by writing a sequence of <code>obj</code> files. So an answer on how to integrate/animate such a sequence of <code>obj</code> files in Unity would also be welcome.</p>

<p><em>Side note:</em> I also tried to get an answer to this over at the <a href=""http://blenderartists.org/forum/showthread.php?245798-How-can-I-export-convert-an-explosion-as-animated-mesh"">blender community</a>. </p>
","<p>After countless tests (and some coding) I was able to find two valid approaches to the problem. Both aren't optimal solutions, but apparently there is none (exporting a simulation from Blender to Unity simply doesn't work).</p>

<h3>Approach 1: Export as obj sequence and swap meshes in Unity</h3>

<p>Pretty straight-forward. Exporting a simulation using the <code>obj</code> exporter generates a separate file for every frame of the animation (if the ""Animation"" option has been toggled in the export options). Drag all these files into your Unity project (eg. into <code>Assets/Models/MyAnimation</code>). Then write a simple script to swap the mesh of the GameObject at runtime.</p>

<p><strong>Pros:</strong></p>

<ul>
<li>Animation is the same as in Blender</li>
</ul>

<p><strong>Cons:</strong></p>

<ul>
<li>I haven't tested this with hi-poly meshes or multiple concurrently playing animations, but most likely it's going to have an impact on performance.</li>
<li>It's really cumbersome to drag each mesh file separately onto the script component. Not really feasible for an animation with lots of frames. See image below (each <code>Element</code> in the <code>Meshes</code> array is a file with the mesh for that frame):<br/><img src=""https://i.stack.imgur.com/tVi0K.png"" alt=""Ouch, mesh animation in Unity""></li>
</ul>

<h3>Approach 2: Create the explosion procedurally within Unity</h3>

<p>This approach is a mixture of the approach proposed by Jonathan Dickinson and the way the explode-modifier works in Blender. In Blender, the explode-modifier uses a particle-system to determine the movement of shards/shrapnels caused by the explosion. </p>

<p>I wrote a script that splits the mesh into triangles and uses a <code>ParticleSystem</code> to animate the triangles.</p>

<p><strong>Pros:</strong></p>

<ul>
<li>Works with any mesh.</li>
<li>Behavior/animation can easily be tweaked by modifying the particle-system. For best results, the simulation has to be in world-space and the particle-renderer should be turned off (see screenshot below). 
<img src=""https://i.stack.imgur.com/0SK6L.png"" alt=""Particle settings in Unity""></li>
</ul>

<p><strong>Cons:</strong></p>

<ul>
<li>Explodes into plain old triangles, which doesn't look very natural.</li>
<li>With hi-poly meshes it hits the CPU hard when the mesh is being split into triangles. This could be optimized though.</li>
</ul>

<h3>Comparison</h3>

<p>Here's a <a href=""http://youtu.be/QVVVyHl-Iro"" rel=""nofollow noreferrer"">video</a> that shows both types of animation in effect. The used scripts (both written in C#) can be found here:</p>

<ul>
<li><a href=""http://pastie.org/3414261"" rel=""nofollow noreferrer"">MeshAnimation script</a></li>
<li><a href=""http://pastie.org/3414275"" rel=""nofollow noreferrer"">Explode script</a></li>
</ul>

<h3>Update: MetaMorph</h3>

<p>Thanks to the <a href=""http://blenderartists.org/forum/showthread.php?245798-How-can-I-export-convert-an-explosion-as-animated-mesh"" rel=""nofollow noreferrer"">Blender Community</a> (especially the users <em>chipmasque</em> and <em>enzyme69</em>) I was pointed towards a third possible solution, which is <a href=""http://rezzable.com/metamorph/"" rel=""nofollow noreferrer"">MetaMorph</a>. It's a Unity script and a Blender export addon which allows you to export shape-keys from Blender and play them in Unity. While there seems to be some issues with getting a shape-key animation from an explosion, it should work fine for other types of simulations and other shape-key driven animations (eg. facial animations/morphs etc.).</p>
","24175"
"How to utilize miniMax algorithm in Checkers game","9541","","<p>I am sorry...as there are too many articles about it.But I can't simple get this.</p>

<p>I am confused in the implementation of AI. I have generated all possible moves of computer's type pieces. Now I can't decide the flow. Whether I need to start a loop for the possible moves of each piece and assign score to it.... or something else is to be done.</p>

<p>Kindly tell me the proper flow/algorithm for this. Thanks  </p>

<p><strong>UPDATE:</strong></p>

<p><a href=""https://gamedev.stackexchange.com/questions/31509/minimax-not-working-properlyfor-checkers-game"">MiniMax code</a></p>

<p>Now I coded the algorithm but not getting correct moves. Please help me find out the logical error.</p>
","<p>One useful thing to understand about minimax for a game like Checkers is that it's traditionally viewed (to first approximation) as <em>symmetric</em> - this means that both players can share the same evaluation function, but simply with the signs flipped, or put another way that it's a zero-sum game: if you evaluate the position as being 4/10ths of a checker in your favor, you know that your opponent's evaluation will be -4/10ths of a checker.  This means that you can use the <em>same</em> loop structure for both sides and simply multiply by a 'sign flip', rather than having to have different control structures for min and max (or switching within the loop).  In simplest form, the minimax can be done as a classic recursive function, with a termination once you've reached your maximum depth:</p>

<pre><code>float EvaluatePositionRecursive(int depth, Board curBoard, float signFactor)
{
  if ( depth &gt;= MAX_DEPTH )
    return EvaluatePositionStatic(curBoard);
  MoveList moves = GenerateMoveList(curBoard);
  float posValue = -FLT_MAX;
  for (move in moves) do {
    Board newBoard = MakeMove(curBoard, move);
    float newValue = signFactor*EvaluatePositionRecursive(depth+1, newBoard, -signFactor);
    if ( newValue &gt; posValue ) posValue = newValue;
  }
  return signFactor*posValue;
}

[...]

  val = EvaluatePositionRecursive(0, thisBoard, 1.0f);
</code></pre>

<p>This code has the property/requirement that the value returned from the EvaluatePosition functions will always be in terms of one side's evaluation - that is, a positive value of EvaluatePositionRecursive will always be better for (e.g.) black; this is why it (re-)multiplies by signFactor before returning its value.</p>

<p>Note that there's a <em>lot</em> that this (pseudo)code doesn't do: it doesn't do any <a href=""http://en.wikipedia.org/wiki/Alpha-beta_pruning"">alpha-beta pruning</a>, it doesn't use <a href=""http://en.wikipedia.org/wiki/Transposition_table"">transposition tables</a> to cut down on re-evaluating the same position, and it doesn't do any sort of <a href=""http://en.wikipedia.org/wiki/Quiescence_search"">quiescence search</a> or similar adaptive-depth techniques to avoid misevaluating positions where a forced-capture is on the horizon of your search.  What's more, for practical considerations you might not want to use explicit recursion for the minimax, and instead maintain a stack yourself, and there are plenty of other object-management optimizations that you would want to make for a practical implementation of the algorithm (rather than a quick-and-dirty one).  Still, this code should show the core of the algorithm: to evaluate a position, evaluate all of the subpositions from the current side's point of view, pick the 'best', and return that value.</p>
","31196"
"Cast ray to select block in voxel game","9532","","<p>I am developing a game with a Minecraft-like terrain made out of blocks. Since basic rendering and chunk loading is done now, I want to implement block selecting.</p>

<p>Therefore I need to find out what block the first person camera is facing. I already heard of unprojecting the whole scene but I decided against that because it sounds hacky and isn't accurate. Maybe I could somehow cast a ray in view direction but I do not know how to check the collision with a block in my voxel data. Of course this calculations must be done on the CPU since I need the results to perform game logic operations.</p>

<p>So how could I find out which block is in front of the camera? If it is preferable, how could I cast a ray and check collisions?</p>
","<p>When I had this problem while working on my <a href=""https://github.com/kpreid/cubes"">Cubes</a>, I found the paper <a href=""http://www.cse.yorku.ca/~amana/research/grid.pdf"">""A Fast Voxel Traversal Algorithm for Ray Tracing"" by John Amanatides and Andrew Woo, 1987</a> which describes an algorithm which can be applied to this task; it is accurate and needs only one loop iteration per voxel intersected.</p>

<p>I have written an implementation of the relevant parts of the paper's algorithm in JavaScript. My implementation adds two features: it allows specifying a limit on the distance of the raycast (useful for avoiding performance issues as well as defining a limited 'reach'), and also computes which face of each voxel the ray entered.</p>

<p>The input <code>origin</code> vector must be scaled such that the side length of a voxel is 1. The length of the <code>direction</code> vector is not significant but may affect the numerical accuracy of the algorithm.</p>

<p>The algorithm operates by using a parameterized representation of the ray, <code>origin + t * direction</code>. For each coordinate axis, we keep track of the <code>t</code> value which we would have if we took a step sufficient to cross a voxel boundary along that axis (i.e. change the integer part of the coordinate) in the variables <code>tMaxX</code>, <code>tMaxY</code>, and <code>tMaxZ</code>. Then, we take a step (using the <code>step</code> and <code>tDelta</code> variables) along whichever axis has the least <code>tMax</code> — i.e. whichever voxel-boundary is closest.</p>

<pre><code>/**
 * Call the callback with (x,y,z,value,face) of all blocks along the line
 * segment from point 'origin' in vector direction 'direction' of length
 * 'radius'. 'radius' may be infinite.
 * 
 * 'face' is the normal vector of the face of that block that was entered.
 * It should not be used after the callback returns.
 * 
 * If the callback returns a true value, the traversal will be stopped.
 */
function raycast(origin, direction, radius, callback) {
  // From ""A Fast Voxel Traversal Algorithm for Ray Tracing""
  // by John Amanatides and Andrew Woo, 1987
  // &lt;http://www.cse.yorku.ca/~amana/research/grid.pdf&gt;
  // &lt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.3443&gt;
  // Extensions to the described algorithm:
  //   • Imposed a distance limit.
  //   • The face passed through to reach the current cube is provided to
  //     the callback.

  // The foundation of this algorithm is a parameterized representation of
  // the provided ray,
  //                    origin + t * direction,
  // except that t is not actually stored; rather, at any given point in the
  // traversal, we keep track of the *greater* t values which we would have
  // if we took a step sufficient to cross a cube boundary along that axis
  // (i.e. change the integer part of the coordinate) in the variables
  // tMaxX, tMaxY, and tMaxZ.

  // Cube containing origin point.
  var x = Math.floor(origin[0]);
  var y = Math.floor(origin[1]);
  var z = Math.floor(origin[2]);
  // Break out direction vector.
  var dx = direction[0];
  var dy = direction[1];
  var dz = direction[2];
  // Direction to increment x,y,z when stepping.
  var stepX = signum(dx);
  var stepY = signum(dy);
  var stepZ = signum(dz);
  // See description above. The initial values depend on the fractional
  // part of the origin.
  var tMaxX = intbound(origin[0], dx);
  var tMaxY = intbound(origin[1], dy);
  var tMaxZ = intbound(origin[2], dz);
  // The change in t when taking a step (always positive).
  var tDeltaX = stepX/dx;
  var tDeltaY = stepY/dy;
  var tDeltaZ = stepZ/dz;
  // Buffer for reporting faces to the callback.
  var face = vec3.create();

  // Avoids an infinite loop.
  if (dx === 0 &amp;&amp; dy === 0 &amp;&amp; dz === 0)
    throw new RangeError(""Raycast in zero direction!"");

  // Rescale from units of 1 cube-edge to units of 'direction' so we can
  // compare with 't'.
  radius /= Math.sqrt(dx*dx+dy*dy+dz*dz);

  while (/* ray has not gone past bounds of world */
         (stepX &gt; 0 ? x &lt; wx : x &gt;= 0) &amp;&amp;
         (stepY &gt; 0 ? y &lt; wy : y &gt;= 0) &amp;&amp;
         (stepZ &gt; 0 ? z &lt; wz : z &gt;= 0)) {

    // Invoke the callback, unless we are not *yet* within the bounds of the
    // world.
    if (!(x &lt; 0 || y &lt; 0 || z &lt; 0 || x &gt;= wx || y &gt;= wy || z &gt;= wz))
      if (callback(x, y, z, blocks[x*wy*wz + y*wz + z], face))
        break;

    // tMaxX stores the t-value at which we cross a cube boundary along the
    // X axis, and similarly for Y and Z. Therefore, choosing the least tMax
    // chooses the closest cube boundary. Only the first case of the four
    // has been commented in detail.
    if (tMaxX &lt; tMaxY) {
      if (tMaxX &lt; tMaxZ) {
        if (tMaxX &gt; radius) break;
        // Update which cube we are now in.
        x += stepX;
        // Adjust tMaxX to the next X-oriented boundary crossing.
        tMaxX += tDeltaX;
        // Record the normal vector of the cube face we entered.
        face[0] = -stepX;
        face[1] = 0;
        face[2] = 0;
      } else {
        if (tMaxZ &gt; radius) break;
        z += stepZ;
        tMaxZ += tDeltaZ;
        face[0] = 0;
        face[1] = 0;
        face[2] = -stepZ;
      }
    } else {
      if (tMaxY &lt; tMaxZ) {
        if (tMaxY &gt; radius) break;
        y += stepY;
        tMaxY += tDeltaY;
        face[0] = 0;
        face[1] = -stepY;
        face[2] = 0;
      } else {
        // Identical to the second case, repeated for simplicity in
        // the conditionals.
        if (tMaxZ &gt; radius) break;
        z += stepZ;
        tMaxZ += tDeltaZ;
        face[0] = 0;
        face[1] = 0;
        face[2] = -stepZ;
      }
    }
  }
}

function intbound(s, ds) {
  // Find the smallest positive t such that s+t*ds is an integer.
  if (ds &lt; 0) {
    return intbound(-s, -ds);
  } else {
    s = mod(s, 1);
    // problem is now s+t*ds = 1
    return (1-s)/ds;
  }
}

function signum(x) {
  return x &gt; 0 ? 1 : x &lt; 0 ? -1 : 0;
}

function mod(value, modulus) {
  return (value % modulus + modulus) % modulus;
}
</code></pre>

<p><a href=""https://github.com/kpreid/cubes/blob/c5e61fa22cb7f9ba03cd9f22e5327d738ec93969/world.js#L307"">Permanent link to this version of the source on GitHub</a>.</p>
","49423"
"How can I put my game on an NES cartridge?","9523","","<p>How can I create an NES cartridge? Is there any tutorial? I need to put a game that runs in an emulator and put it on a cartridge. How to do that? Is this possible from scratch? Or at least could I use an existing cartridge and overwrite the content there?</p>
","<p>You need to ensure your game will run properly on the NES hardware. With many 8 and 16 bit consoles, there are limited times you can access the hardware registers. Accessing registers outside the allowed time often results in the program not displaying any output. One emulator to consider is <a href=""http://nocash.emubase.de/nes.htm"" rel=""noreferrer"">no$nes</a>, another is <a href=""http://www.fceux.com/web/home.html"" rel=""noreferrer"">fceux</a>. The no$nes will warn you if you violate many of the rules. The fceux emulator is probably more accurate but will fail silently if you violate the rules.</p>

<p>The next, or possibly first, thing is to determine which mapper mode you will support. This basically determines how rom or ram are mapped into the CPU and PPU (graphics chip) space, the number of memory banks available, and how the scrolling tilemap will be repeated. When you're ready for the technical details, check out the <a href=""http://tuxnes.sourceforge.net/mappers-0.80.txt"" rel=""noreferrer"">Comprehensive NES Mapper Document</a>. It's quite technical, but is required knowledge in developing a NES cartridge.</p>

<p>The final step is getting it on the cartridge. There are a few options, one is the <a href=""http://www.infiniteneslives.com/aux4.php"" rel=""noreferrer"">INL-ROM NES board</a>, which can be purchased with a flash rom for easier testing. Once your game is running, you can buy the same board and program and solder your own EPROMS into the board.</p>

<p>If you're really interested in NES development, visit the <a href=""http://forums.nesdev.com/index.php"" rel=""noreferrer"">NesDev forums</a>.</p>

<p>I developed a game, called Frog Feast, that ran on the SNES, Genesis, Atari Jaguar, and Neo Geo. A friend created physical versions from old game boards.</p>
","73415"
"Why are normal maps predominantly blue?","9485","","<p>Why normal maps are predominantly blue instead of a random color?</p>

<p>I guess normal vectors of a 3D object can point in every direction, like:</p>

<pre><code>(1.0, 0.1, 0.5), (0.1, -0.5, 0.3), (-0.51, 0.46, -1.0) ... 
</code></pre>

<p><img src=""https://i.stack.imgur.com/8ckF1.jpg"" alt=""enter image description here""></p>
","<p>There are two types of normal maps commonly used in game development.  The way you are thinking they should work is the way one type works (model-space normal maps), but most games use another type (tangent-space normal maps) which is why you associate mostly-blue textures with normal maps.</p>

<p><img src=""https://i.stack.imgur.com/Knzcm.jpg"" alt=""Model-space normal map example""></p>

<p>With <strong>model-space normal maps</strong>, each channel encodes the precise value of the normal using the same coordinate system as the vertices of the model it's used with.  This means different parts of the normal map will have different hues, but pixels near each other will usually have similar colors.  An example of a model-space normal map appears above (<a href=""http://www.zbrushcentral.com/printthread.php?t=64122&amp;pp=15&amp;page=10"" rel=""nofollow noreferrer"">source</a>).</p>

<p><strong>Tangent-space normal maps</strong> are usually light blue.  This type of map defines normals in a coordinate space unique to each pixel's position on the surface of the mesh.  It uses the (interpolated) vertex normal as the Z axis, and two other orthogonal vectors, called the tangent and bitangent, as the X and Y axes.  Essentially, you can think of the normals in the map as an ""offset"" from the normal for that pixel calculated by interpolating the vertex normals.  The tangent and bitangent vectors are also interpolated from vertex data, and determine which direction on the mesh corresponds to ""up"" and ""left"" in the normal map.  The image provided in the question provides an excellent example of what a typical tangent-space normal map looks like, so I won't provide another example here.</p>

<p>The components of a normal normally (no pun intended) range from <code>[-1, 1]</code>.  But components of a color in an image range from <code>[0, 1]</code> (or <code>[0, 255]</code> but usually they're normalized to <code>[0, 1]</code>).  So normals are scaled and offset such that the normal <code>(0, 0, 1)</code> becomes the color <code>(0.5, 0.5, 1)</code>.  This is the light blue color you see in normal maps, and it indicates no deviation from the interpolated vertex normal when using tangent-space normals.</p>

<p>The reason tangent-space normals are preferred over model-space normals is due to the fact that they are easier to create, and can be used for multiple meshes.  Additionally, if used with an animated mesh, tangent-space normals are always used, because the normals are constantly changing.</p>
","88356"
"Collision detection - Smooth wall sliding, no bounce effect","9480","","<p>I'm working on a basic collision detection system that provides point - OBB collision detection. I have around 200 cubes in my environment and I check (for now) each of them in turn and see if it collides. If it does I return the colliding face's normal, save the old player position and do some trigonometry to return a new player position for my wall sliding. </p>

<p><strong>edit</strong><br>
I'll define my meaning of wall sliding: If a player walks in a vertical slope and has a slight horizontal rotation to the left or the right and keeps walking forward in the wall the player should slide a little to the right/left while continually walking towards the wall till he left the wall. Thus, sliding along the wall.</p>

<p>Everything works fine and with multiple objects as well but I still have one problem I can't seem to figure out: <strong>smooth wall sliding</strong>. In my current implementation sliding along the walls make my player bounce like a mad man (especially noticable with gravity on and moving forward).</p>

<p>I have a velocity/direction vector, a normal vector from the collided plane and an old and new player position. First I negate the normal vector and get my new velocity vector by substracting the inverted normal from my direction vector (which is the vector to slide along the wall) and I add this vector to my new Player position and recalculate the direction vector (in case I have multiple collisions).</p>

<p>I know I am missing some step but I can't seem to figure it out. </p>

<p>Here is my code for the collision detection (run every frame):</p>

<pre><code>Vector direction;
Vector newPos(camera.GetOriginX(), camera.GetOriginY(), camera.GetOriginZ());
direction = newPos - oldPos; // Direction vector
// Check for collision with new position
for(int i = 0; i &lt; NUM_OBJECTS; i++)
{
    Vector normal = objects[i].CheckCollision(newPos.x, newPos.y, newPos.z, direction.x, direction.y, direction.z);
    if(normal != Vector::NullVector())
    {
        // Get inverse normal (direction STRAIGHT INTO wall)
        Vector invNormal = normal.Negative();
        Vector wallDir = direction - invNormal; // We know INTO wall, and DIRECTION to wall. Substract these and you got slide WALL direction
        newPos = oldPos + wallDir;
        direction = newPos - oldPos;
    }
}
</code></pre>

<p>Any help would be greatly appreciated!</p>

<p><hr/>
<strong>FIX</strong>
I eventually got things up and running how they should thanks to Krazy, I'll post the updated code listing in case someone else comes upon this problem!</p>

<pre><code>for(int i = 0; i &lt; NUM_OBJECTS; i++)
{
    Vector normal = objects[i].CheckCollision(newPos.x, newPos.y, newPos.z, direction.x, direction.y, direction.z);
    if(normal != Vector::NullVector())
    {
        Vector invNormal = normal.Negative();
        invNormal = invNormal * (direction * normal).Length(); // Change normal to direction's length and normal's axis
        Vector wallDir = direction - invNormal;
        newPos = oldPos + wallDir;
        direction = newPos - oldPos;
    }
}
</code></pre>
","<p>I think you need to multiply invNormal by the length of direction before making the subtraction.</p>

<pre><code>Vector invNormal = normal.Negative();
invNormal *= direction.length
Vector wallDir = direction - invNormal;
</code></pre>
","49996"
"How can I prevent seams from showing up on objects using lower mipmap levels?","9455","","<p>Disclaimer: kindly right click on the images and open them separately so that they're at full size, as there are fine details which don't show up otherwise. Thank you.</p>

<p>I made a simple Blender model, it's a cylinder with the top cap removed:</p>

<p><img src=""https://i.stack.imgur.com/G2yQK.jpg"" alt=""enter image description here""></p>

<p>I've exported the UVs:</p>

<p><img src=""https://i.stack.imgur.com/VIbWq.jpg"" alt=""enter image description here""></p>

<p>Then imported them into Photoshop, and painted the inner area in yellow and the outer area in red. I made sure I cover well the UV lines:</p>

<p><img src=""https://i.stack.imgur.com/vYRZ4.jpg"" alt=""enter image description here""></p>

<p>I then save the image and load it as texture on the model in Blender. Actually, I just reload it as the image where the UVs are exported, and change the viewport view mode to textured. When I look at the mesh up-close, there's yellow everywhere, everything seems fine:</p>

<p><img src=""https://i.stack.imgur.com/PxWgH.jpg"" alt=""enter image description here""></p>

<p>However, if I start zooming out, I start seeing red (literally and metaphorically) where the texture edges are:</p>

<p><img src=""https://i.stack.imgur.com/8chyr.jpg"" alt=""enter image description here""></p>

<p>And the more I zoom, the more I see it:</p>

<p><img src=""https://i.stack.imgur.com/MkdMN.jpg"" alt=""enter image description here""></p>

<p>Same thing happends in Unity, though the effect seems less pronounced. Up close is fine and yellow:</p>

<p><img src=""https://i.stack.imgur.com/xcSsB.jpg"" alt=""enter image description here""></p>

<p>Zoom out and you see red at the seams:</p>

<p><img src=""https://i.stack.imgur.com/pMkZH.jpg"" alt=""enter image description here""></p>

<p>Now, obviously, for this simple example a workaround is to spread the yellow well outside the UV margins, and its fine from all distances. However this is an issue when you try making a complex texture that should tile seamlessly at the edges. In this situation I either make a few lines of pixels overlap (in which case it looks bad from upclose and ok from far away), or I leave them seamless and then I have those seams when seeing it from far away.</p>

<p>So my question is, is there something I'm missing, or some extra thing I must do to have my texture look seamless from all distances?</p>
","<p>You can't.</p>

<p>All right, that was a bit harsh. Let me illustrate this with two examples.</p>

<ol>
<li><p>Let's get outside of the computer graphics world. Suppose you are given a piece of paper with the texture you gave us printed on it. There's a faintly printed millimeter grid in the paper as well.</p>

<p>Now you get some scissors and some paste, and your task is to make a cylinder out of the piece of paper, but you can only cut exactly through the millimeter grid. No problem! the printed paper was originally created in such a way the yellow and red parts fall exactly on the millimeter grid, so you make your cylinder with no problem.</p>

<p>Now your task is to make a cylinder half the size. To do this, you get a piece of paper half the size with everything printed half the size. This is where your problems start. Some of the yellow-red borders will fall on the millimeter grid, but others won't. And for those that don't, you can either cut on the yellow or the red parts. Which one is more correct? It depends. Sometimes it's the yellow one, sometimes it's the red one, sometimes it's neither...</p></li>
<li><p>So let's get back into the computer graphics world. Let's try to do what you're asking the GPU to do when you're asking it to create mipmaps. Take your large texture and resize it into a texture exactly half the size of the original one. What happens at the yellow-red borders? Well, it depends. It depends on the filtering algorithm you use when scaling your texture down.</p>

<p>If you use ""Nearest neighbor"", you will preserve your abrupt yellow-red changes, but some borders (to be precise, those that fall in an odd coordinate in the original texture) will be forced to either side of the pixel grid, and the texture coordinates you originally carefully chose will no longer match the yellow-red border.</p>

<p>If you use ""Bilinear filtering"", things are not really better. When the yellow-red border doesn't fall in the pixel grid as before (once again, when the border lies on an odd coordinate in the original texture), the resulting pixel will neither be red or yellow. It will be more like orange! Is this acceptable? I don't know.</p></li>
</ol>

<p>You will notice that the problem is limited to the yellow-red borders that fall in odd coordinates. You can say ""no problem!"" and make sure all the yellow-red borders fall in even coordinates, and problem solved! Or is it?</p>

<p>Actually not. The problem will be solved when creating the first mip level. But when you create the next mip level, which is a texture one quarter of the size of the original, you will experience the same problem with the yellow-red borders that don't fall in an even coordinate in the half-size texture, which happen to be those that don't fall in a multiple of 4 coordinate in the original texture.</p>

<p>So even if you fix it for the second mip level, you will never solve the entire problem. You will just be taking it to a lower mip level.</p>

<p>As you can see this is not a problem with the game engine you're using. It's a problem with mipmapping in general. So does this mean that mipmapping is useless and should be disabled? Actually no. Mipmapping is very useful. You're just using it wrong. Actually, you said the answer yourself:</p>

<blockquote>
  <p>spread the yellow well outside the UV margins, and its fine from all distances</p>
</blockquote>

<p>It seems like an ugly hack, but it's actually not. However, I have a more general solution I hereby call the ""First Panda Pajama Rule of 3D skinning"".</p>

<blockquote>
  <p>Don't map abrupt UV coordinate changes to abrupt texture changes.</p>
</blockquote>

<p>You're experiencing this problem because you're matching an abrupt texture change (yellow to red) to an abrupt texture coordinate change (the change between the cylinder and the void (or the cap, when you close the cylinder). You want to avoid this when skinning, precisely to avoid the problem you're describing.</p>

<p>Corollary:</p>

<blockquote>
  <p>If you must make an abrupt UV coordinate change, don't put an abrupt texture change (like your proposed solution of spreading the yellow). If you must make an abrupt texture change, make it so it doesn't require an abrupt UV coordinate change (you should usually prefer doing this)</p>
</blockquote>

<p>You can take advantage of the fact that, unlike when you're making models out of paper and paste, the shape of your texture does not have to match the shape of your model. When making the texture for the cap of your cylinder, you don't have to make it round. In fact, I'd make it rectangular so I can match it to the texture of the sides of the cylinder precisely to avoid abrupt UV coordinate changes between the sides and the caps (look for ""Filters->Distort->Polar Coordinates"" in Photoshop).</p>

<p>I'd also align the left and right borders of the cylinder texture to the left and right borders of the texture, and set the texture mapping to wrap, so the texture wraps nicely around the cylinder.</p>
","50037"
"How to render axometric/isometric tiles that are a 2d array in logic, but inclined 45º visually?","9455","","<p>I am making a tile-based strategy game which i plan to have 2.5D visuals in an axometric/isometric fashion.</p>

<p>Right now i'm programming it's logic and rendering it as a literal 2-dimensional array (perfect squares, like an isometric top-down-view).</p>

<p>In short, i have something like this:</p>

<p><img src=""https://i.stack.imgur.com/A6yKo.gif"" alt=""Isometric Top-Down Grid""></p>

<p>And i want to turn it to something like this:</p>

<p><img src=""https://i.stack.imgur.com/hfCUT.jpg"" alt=""Axometric Grid""></p>

<hr>

<p>Do i keep going on the 2d-array logic?</p>

<p>Is it all just a change in rendering behavior, as i'm thinking it is? or 2d-array is the wrong approach for my objective and I should change before it's too late?</p>

<p>What are the ways of doing it, anyways? How should i apply the 2.5D axometric/isometric view (45º rotation to the side, and 45º rotation upwards)?</p>
","<p>Yes, that's exactly what you should do! Only a few days ago I answered another guy, suggesting him such logic here:
<a href=""https://gamedev.stackexchange.com/questions/37893/free-movement-in-a-tile-based-isometric-game/37901#37901"">Free movement in a tile-based isometric game</a></p>

<p>This is a simple MVC approach. Keep your model and controller simple, every 3D game with objects on flat surface with same height and on same height is really 2D underneath it's view.</p>
","37992"
"How to implement a basic arcball camera in OpenGL with GLM","9451","","<p>I only just started learning <code>OpenGL</code> and even things like vector maths etc a couple of days ago, so I am having a bit of trouble figuring out exactly what to do to implement an arcball camera system.</p>

<p>I am using <code>GLM</code> to do things like get the cross product of two vectors etc, and I am using the <code>glm::lookAt(position, target, up)</code> method to set the view matrix.</p>

<p>I have looked around on Google and the search on this site and even StackOverflow but since I am new to this I'm not exactly sure what I'm doing wrong (probably a lot of things) and what I should be searching for.</p>

<p>At the moment I am trying to follow the general steps outlined in this answer: <a href=""https://gamedev.stackexchange.com/questions/20758/how-can-i-rotate-a-camera-about-its-target-point"">How can I orbit a camera about it&#39;s target point?</a></p>

<p>But I am not sure if I am doing it correctly (well, actually, I know I'm not doing it correctly because it's not working).</p>

<p>I can get the camera's normalized <code>up</code> and <code>right</code> vectors without any problem, and I can get a vector from the camera's target point to the camera position.</p>

<p>I can then easily decide the angle of rotation in radians, but my main points of trouble come after that; creating a new vector to translate the camera with from a rotation matrix and then actually translating camera to get a new camera position.</p>

<p>I'm not sure exactly what information you would need to help me, but here is a general overview.</p>

<p>Currently I have a cube that is drawn around the origin, three <code>glm::vec3</code> objects which describe camera position, camera target and camera up, and the usual <code>projection</code>, <code>view</code> and <code>model</code> matrices which are multiplied together and given to <code>glUniformMatrix4fv()</code>.</p>

<p>Apart from <code>glUniformMatrix4fv()</code> this is all declared before the main loop.</p>

<pre><code>glm::mat4 projection_matrix = glm::perspective(45.f, 4.f / 3.f, 0.1f, 100.f);

glm::vec3 camera_position = glm::vec3(0.f, 1.f, 5.f);
glm::vec3 camera_target = glm::vec3(0.f, 0.f, 0.f);
glm::vec3 camera_up_vector = glm::vec3(0.f, 1.f, 0.f);

glm::mat4 view_matrix = glm::lookAt(
    camera_position,
    camera_target,
    camera_up_vector
);

glm::mat4 model_matrix = glm::mat4(1.f);

glm::mat4 mvp = projection_matrix * view_matrix * model_matrix;
</code></pre>

<p>Just before the main loop I also declare two <code>glm::mat4</code> matrices to rotate with <code>yaw</code> and <code>pitch</code> and two more <code>glm::vec3</code> objects to store the target to camera and camera right vectors, since that was one of the steps in the answer I linked above.</p>

<pre><code>glm::vec3 target_to_camera_vector;
glm::vec3 camera_right_vector;

glm::mat4 rotate_yaw_matrix = glm::mat4(1.f);
glm::mat4 rotate_pitch_matrix = glm::mat4(1.f);
</code></pre>

<p>Now, within the main loop I re-calculate the <code>target_to_camera_vector</code>, <code>camera_right_vector</code> and <code>camera_up_vector</code> before I try to do any more calculations.</p>

<pre><code>target_to_camera_vector = camera_position - camera_target;
camera_right_vector = glm::normalize(glm::cross(target_to_camera_vector, camera_up_vector));
camera_up_vector = glm::normalize(glm::cross(camera_right_vector, target_to_camera_vector));
</code></pre>

<p>After this is where I think I am going horribly wrong.</p>

<p>The answer I linked above says:</p>

<blockquote>
  <p>Create two rotation matrices. The 1st rotation matrix will use the up
  of the camera as the axis and yaw angle that you decided. The 2nd
  rotation matrix will use the right of the camera as the axis and pitch
  angle that you decided.</p>
</blockquote>

<p>So I try to rotate the two <code>glm::mat4</code> matrices I had created earlier, even though I'm not 100% sure this is how you do it in <code>GLM</code>.</p>

<pre><code>rotate_yaw_matrix = glm::rotate(rotate_yaw_matrix, yaw_angle_radians, camera_up_vector);
rotate_pitch_matrix = glm::rotate(rotate_pitch_matrix, pitch_angle_radians, camera_right_vector);
</code></pre>

<p>The answer linked above then says:</p>

<blockquote>
  <p>Now rotate the camFocusVector with the new rotation matrices. This is
  now your new position of the camera relative to the origin. We of
  course, want it to be relative to the focus point...</p>
</blockquote>

<p>This is where I am really just guessing what to do.</p>

<pre><code>target_to_camera_vector = glm::vec3(rotate_yaw_matrix * glm::vec4(target_to_camera_vector, 0.f));
target_to_camera_vector = glm::vec3(rotate_pitch_matrix * glm::vec4(target_to_camera_vector, 0.f));
</code></pre>

<p>After that it says:</p>

<blockquote>
  <p>Add the focus point position to camFocusVector. This is now your
  camera's new position. Translate your camera accordingly.</p>
</blockquote>

<p>So, once again, since I'm not exactly sure what this means, I guess, of course.</p>

<pre><code>target_to_camera_vector += camera_target;
</code></pre>

<p>And having no idea how I should use this result to translate the vector, I make the, most likely wrong, assumption that I am supposed to do this.</p>

<pre><code>camera_position += target_to_camera_vector;
</code></pre>

<p>Afterwards I use the <code>glm::lookAt()</code> method and recalculate the model view projection matrix to pass to <code>glUniformMatrix4fv()</code>.</p>

<pre><code>view_matrix = glm::lookAt(
    camera_position,
    camera_target,
    camera_up_vector
);

mvp = projection_matrix * view_matrix * model_matrix;
</code></pre>

<p>As I said, I only just started learning about OpenGL and 3D/Vector maths a couple of days ago, so a lot of my learning at this stage is experimenting and guessing etc.
But I think I mostly went wrong around the point where I had to rotate the matrices and translate the camera position.</p>

<p>So my question is (finally), am I following the right path to implement an arcball camera (it seems like it should be ok), and if so, how can I properly implement the steps to rotate the <code>target_to_camera_vector</code> and then use that to translate the <code>camera_position</code>?</p>

<p>Any help would be appreciated.</p>
","<p>Place your camera target at the center of the arc rotation (That's usually where you want the camera to look anyway). Then simply transform the camera's position around the target with a rotation that uses the appropriate axis.</p>

<pre><code>pseudo code:
//some angle &amp; some other angle = only the amount you want the camera to rotate since last frame.

//pitch
position = (Rotate(some angle, cameraRight) * (position - target)) + target;


//yaw, Y-up system
position = (Rotate(some other angle, (0,1,0)) * (position - target)) + target;

view = LookAt(position, target, up);
</code></pre>

<p>Edit: fixed missing parenthesis</p>
","53356"
"MUD source code","9448","","<p>I haven't been able to find a lot of the old, open source mud source codes.  I find the way they did things very applicable to text-based/browser based games, and I'd love to be able to skim through parts of 'em for inspiration.</p>

<p>For instance, we have this huge list of muds and the relationships between them, but little by way of access to source code.
<a href=""http://en.wikipedia.org/wiki/MUD_trees"">http://en.wikipedia.org/wiki/MUD_trees</a></p>

<p>Often (I'm looking at you, dikumud, <a href=""http://www.dikumud.com/links.aspx"">http://www.dikumud.com/links.aspx</a> ) the sites of the mud itself doesn't even have a working link to the source.</p>

<p><a href=""https://github.com/alexmchale/merc-mud"">https://github.com/alexmchale/merc-mud</a> has a copy of merc that I found, which certainly contains other works within it's history, but the pickings seems sparse.</p>

<p>Does anyone have better resources for gaining access to MUD source code than these?</p>
","<p><a href=""http://mudbytes.net/"">http://mudbytes.net/</a> was established for exactly the purpose you're looking for.</p>
","6776"
"Drawing large 2D sidescroller level terrain","9443","","<p>I'm a relatively good programmer but now that it comes to add some basic levels to my 2D game I'm kinda stuck.</p>

<p>What I want to do: An acceptable, large (8000 * 1000 pixels) ""green hills"" test level for my game.</p>

<ul>
<li>What is the best way for me to do this?</li>
</ul>

<p>It doesn't have to look great, it just shouldn't look like it was made in MS paint with the line and paint bucket tool.</p>

<p>Basically it should just mud with grass on top of it, shaped in some form of hills.</p>

<p>But how should I draw it, I can't just take out the pencil tool and start drawing it pixel per pixel, can I?</p>
","<p>Photoshop has layer-effects which can be used to draw good looking levels really fast. I don't know if that would work with GIMP, but here are some steps how to get something on screen fast using Photoshop:</p>

<h2>Instructions</h2>

<ol>
<li>Get some dirt and grass textures. The one I'm using in my example are from this <a href=""http://opengameart.org/content/wall-grass-rock-stone-wood-and-dirt-480"" rel=""nofollow noreferrer"">freetexture set</a>.</li>
<li>Open a dirt texture in Photoshop. Select all <kbd>Ctrl-A</kbd> and copy <kbd>Ctrl-C</kbd>. Then select <code>Edit &gt; Define Pattern...</code> from the Menu. Name your Pattern ""Dirt"".</li>
<li>Do the same for the Grass texture, name it ""Grass"".</li>
<li>Create a new Layer in Photoshop and apply the <code>Pattern Overlay</code> and <code>Stroke</code> Effect to your layer. Select the ""Dirt"" pattern for the overlay and the ""Grass"" pattern for your Stroke (see images below).</li>
<li>Paint with any brush on your layer... instead of having a boring single color, it should render as a landscape, thanks to the layer effects. The beauty of this is, that you can freely add/remove parts of your landscape by using regular drawing tools like the brush or eraser.</li>
<li><em>(optional)</em> Draw a gradient from dark blue (top) to light blue (bottom) on the background layer for your sky (you could also use layer-effects for that).</li>
<li><em>(optional)</em> Add some more layer-effects like a gradient and drop-shadow to your ""landscape"" layer in order to achieve a better look.</li>
</ol>

<h2>Images</h2>

<h3>Pattern Overlay settings</h3>

<p><img src=""https://i.stack.imgur.com/2oVMj.png"" alt=""Photoshop pattern overlay settings""></p>

<h3>Stroke settings</h3>

<p><img src=""https://i.stack.imgur.com/dwXDu.png"" alt=""Photoshop stroke settings""></p>

<h3>Final result</h3>

<p>With some more layer effects and a background.</p>

<p><img src=""https://i.stack.imgur.com/uG572.jpg"" alt=""final image""></p>

<p>You can also download the PSD file <a href=""http://www.filesavr.com/AWG0GR75X2ULVN8"" rel=""nofollow noreferrer"">here</a> to have a look at it.</p>
","8714"
"Most common 3D model format for opengl","9425","","<p>I'm a novice that is starting to play with OpenGL ES on Android devices. To practice OpenGL I wanted to create a small game engine and so I was wondering what the best 3D model file format would be.</p>

<p>I'm also interested in free models of the same format.</p>

<p>What do you suggest?</p>
","<p>There are two that are really easy to use. First is wavefront (.obj) <a href=""http://en.wikipedia.org/wiki/Wavefront_.obj_file"">http://en.wikipedia.org/wiki/Wavefront_.obj_file</a> and the second is stanford (.ply) <a href=""http://en.wikipedia.org/wiki/PLY_%28file_format%29"">http://en.wikipedia.org/wiki/PLY_(file_format)</a></p>

<p>Both store data in normal text/ascii format so you can read the content in a normal text editor which will help you understand the content and how to read it. </p>

<p>There are more advanced and methods that supports more functions (animation, skinning etc), one of those is the Collada which is developed by the khronos group</p>
","15007"
"Random number in a range, biased toward the low end of the range","9411","","<p>I have an input of two values, let's say 1 and 10.
Lesser numbers should overall occur more often in the output than higher numbers, while there is a peak in the probability at #2:</p>

<pre class=""lang-none prettyprint-override""><code>1: very common
2: extremely common       
3: very common     
4: common              
5: somewhat common  
...                  
10: extremely rare   
</code></pre>

<p>How do I achieve this? My code until now looks like this:</p>

<pre><code>function getValue($min, $max) {
    return random($min, $max);
}
</code></pre>
","<p>Assuming you have a <code>random()</code> function that returns a uniformly-distributed numeric value in the interval [0, 1)...</p>

<p>(I see the edit attempt to ""fix"" the mismatched bracket above, but <a href=""https://en.wikipedia.org/wiki/Interval_(mathematics)#Notations_for_intervals"" rel=""nofollow noreferrer"">this is deliberate and carries specific meaning</a>)</p>

<pre><code>random() - random()
</code></pre>

<p>Gives a distribution that peaks at 0 and falls off toward -1 and 1.</p>

<pre><code>abs(random() - random())
</code></pre>

<p>Peaks around 0 and falls off toward 1</p>

<pre><code> floor(abs(random() - random()) * (1 + max - min) + min)
</code></pre>

<p>Gives you a random number between <code>min</code> and <code>max</code>, with outputs closer to <code>min</code> being more common, falling off linearly toward the max.</p>

<hr>

<p>Note as pointed out by Logan Pickup in the comments below, there's a slight mathematical artifact here if you're using this to generate continuous random numbers (ie. without the <code>floor</code>): the only way to get zero out of <code>abs</code> is to start with zero, but you can get a value of epsilon if the input is either positive <em>or</em> negative epsilon. So you have about half the chance of getting <em>exactly</em> zero as you have of getting the next larger representable number. If you're using this with <code>floor</code> after the <code>abs</code> to generate random integers, then this little quirk will be swamped and not noticeably affect the result.</p>

<hr>

<p>Using <a href=""https://en.m.wikipedia.org/wiki/Inverse_transform_sampling"" rel=""nofollow noreferrer"">inverse transform sampling</a> you can get this same linear distribution (without the 0 artifact) with one random sample via the formula:</p>

<pre><code>1 - sqrt(1 - random())
</code></pre>

<p>(and we can apply the same scale/offset/floor approach to get a corresponding discrete distribution)</p>

<p>You can find <a href=""https://gamedev.stackexchange.com/questions/113935/accurately-simulating-the-lots-of-dice-rolls-without-loops/114034#114034"">methods to get custom-shaped probability distributions in this answer</a> or the links suggested in comments above.</p>
","116837"
"File format for static and animated 3D models","9406","","<p>I'm currently writing a 3D game in C++ with OpenGL and I'm coming to the part where to load 3D models in. Therefore I'm looking for popular file formats and techniques to</p>

<ul>
<li>display static meshs and</li>
<li>render animated meshs.</li>
</ul>

<p>I've already found quite a large number of possible formats and techniques, like keyframe animations, skeletal animation, MD2 up to MD5, 3DS, X, Collada etc. pp.</p>

<p>For simplicity I'd like to use a format (and technique) that allows both, namely static and animated meshs. So my question is if <em>one</em> format is suitable for that task and which one you'd suggest. And to clarify a bit: I don't need super-smooth animations or brandnew features.</p>

<p>Sidenote: Because I'm a blender fan (but <em>not</em> an expert ;-)) it'd be helpful if it can be used with that -- but of course that shouldn't be the show stopper, here.</p>
","<p>Let me propose you to use <strong>Collada</strong>.</p>

<p>It's widely supported by DCC tools and well standardized. It supports skeletal animations and .. well, it does almost everything, including shaders and physics - those won't be relevant for you. </p>

<p>Vertex-based animations such as in the MDL or MD2 formats are more or less a relict of the past. Today, most animations are skeletal animations (i.e. think if smoothly-rigged characters) and the content creation tools are optimized for them.</p>

<p>Blender has a working Collada exporter, but as always, exporting stuff from Blender can be annoying. You may need to try alternative exporters or file formats or hack the scripts manually should you experience problems.</p>

<p>To load Collada, use libraries such as <a href=""https://collada.org/mediawiki/index.php/FCollada"">FCollada</a> or <a href=""http://sourceforge.net/projects/collada-dom/"">ColladaDOM</a> (Don't try to parse it on your own, Collada is a <em>really</em> fat XML monster ...). There's also <a href=""http://assimp.sourceforge.net/"">Open Asset Import Library</a>, which loads ~25 file formats, including Collada (and all the other formats you mention). It would be an excellent choice since it aims especially towards game developers and provides its output in a format suitable for real-time rendering. But to be honest: I'm one of its co-authors, so I'm probably a <em>bit</em> biased.</p>

<p><strong>Last but not least</strong>: The file format you use to import your assets should not define the abilities of your engine and the techniques it uses - it should rather be the other way round. Whether your animations are super-smooth is not a question of the import format, it's about which technique you use to animate meshes and how good they are modeled in the first place. The import format should just help you bring your data from Blender into your game.</p>
","10395"
"networking without port forwarding","9405","","<p>I'm trying to add networking functionality to my game. I want any user to be able to host the game, and anyone to be able to connect as a client. The client sends info to the host about their player's position, etc. When the host receives a message, it validates it and then broadcasts it to its other clients. I will primarily be dealing with UDP, but will also need TCP for chat &amp; lobby stuff.</p>

<p>The problem is that I can't seem to get a packet sent from the client to the host or the other way around without enabling port forwarding on my router. But I don't think this is necessary. I believe the reason I need port forwarding is because I want to send a packet from 1 computer on a LAN to another computer on a different LAN, but neither of them have a global ip address since they're in a LAN. So really, I can only send packets targeting the other network's router, which must forward it on to the machine I want to reach. So how can I do this without port forwarding? Somehow a web server can communicate with my computer, which doesn't have a global ip, without port forwarding. And I've played plenty of multi-player games that don't require me to enable port forwarding. So it must be possible.</p>

<p>Btw, I'm using SDL_Net. I don't think this will change anything though.</p>
","<p>Many to one NAT (many computers with private addresses behind one public address) works like this: The router keeps track of outbound packets and when an answer is received it can send it to the internal computer which sent the original request. So this works fine, if you visit a website with a public ip-address.</p>

<p>It is, however, not possible to send an initial packet from the outside to one specific computer on the inside, unless a forwarding rule is defined on the router: There is no way to address a specific computer and the router does not have information in his connection table because it is not an reply.</p>

<p>Skype made a technique popular that is called <a href=""http://en.wikipedia.org/wiki/UDP_hole_punching"">firewall hole punching</a>: A server with a public address is contacted by the clients. Then it sends an answer back to client A telling it to send udp packages to the router of client B on a port it expect the router of client B to use as source port for the next outbound packet. And it tells client B to send a packet to the router to client A on a port it expects the router of A to use as source port for its next outbound packet. If the prediction is correct, A and B can now talk directly which each other.</p>

<p>Firewall hole punching requires a server with a public ip address to act as a moderator. And it requires a lot of knowledge about the implementations of common NAT router to predict the outbound source ports correctly. Although there are <a href=""http://linide.sourceforge.net/nat-traverse/"">open source implementations</a> available, you should try to avoid this technique because it is unreliable and causes lots of headache. Skye falls back to using the server with the public ip address to relay all packets if the predictions fail.</p>
","9973"
"Rotating a Quad around it center","9397","","<p>How can you rotate a quad around its center?</p>

<p>This is what im trying to do but it aint working:</p>

<pre><code>    GL11.glTranslatef(x-getWidth()/2, y-getHeight()/2, 0);      
    GL11.glRotatef(30, 0.0f, 0.0f, 1.0f);
    GL11.glTranslatef(x+getWidth()/2, y+getHeight()/2, 0);  
        DRAW
</code></pre>

<p>my main problem is that it renders it off the screen..</p>

<p>draw code:</p>

<pre><code>    GL11.glBegin(GL11.GL_QUADS);
    {
        GL11.glTexCoord2f(0, 0);
        GL11.glVertex2f(0, 0);
        GL11.glTexCoord2f(0, getTexture().getHeight());
        GL11.glVertex2f(0, height);
        GL11.glTexCoord2f(getTexture().getWidth(), getTexture().getHeight());
        GL11.glVertex2f(width,height);
        GL11.glTexCoord2f(getTexture().getWidth(), 0);
        GL11.glVertex2f(width,0);
    }
    GL11.glEnd();
</code></pre>
","<p>The quad's center is the position (0, 0, 0) in local space. Local space is the space in which you define your vertex positions.</p>

<p>For instance, if you draw your quad using the opengl glvertex* commands, you should specify each vertex relative to (0, 0, 0):</p>

<pre><code>glBegin(GL_QUADS);                  // Draw A Quad
glVertex3f(-1.0f, 1.0f, 0.0f);      // Top Left
glVertex3f( 1.0f, 1.0f, 0.0f);      // Top Right
glVertex3f( 1.0f,-1.0f, 0.0f);      // Bottom Right
glVertex3f(-1.0f,-1.0f, 0.0f);      // Bottom Left
glEnd();                            // Done Drawing The Quad
</code></pre>

<p>The code was taken from the NeHe website: <a href=""http://nehe.gamedev.net/tutorial/your_first_polygon/13002/"" rel=""nofollow"">Your First Polygon</a> </p>

<p>If you draw your quad like this, each rotate command will rotate the quad around it's center. That's because the rotation matrix will be multiplied with each vertex position, which will result in the vertex being rotated around (0, 0, 0).</p>

<p>You should have a look at the NeHe article, it's a good starting point. Also have a look at the other articles there: <a href=""http://nehe.gamedev.net/tutorial/lessons_01__05/22004/"" rel=""nofollow"">http://nehe.gamedev.net/tutorial/lessons_01__05/22004/</a> ( there's one dealing with rotations in particular ).</p>

<p><strong>EDIT:</strong></p>

<p>You're drawing the quad relative to the lower left corner, so in order to match the center of the quad with the object space origin, you should first translate it by ( -width()/2, -height()/2, 0 ). Keeping in mind that matrices are multiplied in the reverse order, I would try something like:</p>

<pre><code>GL11.glTranslatef(x+getWidth()/2, y+getHeight()/2, 0); // M1 - 2nd translation
GL11.glRotatef(30, 0.0f, 0.0f, 1.0f);                  // M2
GL11.glTranslatef( -getWidth()/2, -getHeight()/2, 0);  // M3 - 1st translation
</code></pre>

<p>Matrices are multiplied in order, and then multiplied on the left side with the vertex. So the resulting formula would be M1 * M2 * M3 * V. Notice that V is first multiplied by M3, so that's the matrix we use to translate the quad into the origin.</p>
","43845"
"Tips for Component Based Entity System message handling","9395","","<p>I'm trying to implement a component-based entity system but am a bit confused on how I should handle the messaging. There are two problems I'd like to resolve so I can test the system. Below is the code I have so far,</p>

<p><strong>The Entity class:</strong></p>

<pre><code>class Entity{
public:
    Entity(unsigned int id):
    id_(id)
    {};
    void handleMessage(BaseMessage &amp;message){
        for(auto element: components_){
            element.second-&gt;handleMessage(message);
        }
    }
    template&lt;class T&gt;
    void attachComponent(T *component){
        //Consider making safer in case someone tries to attach same component type twice
        components_[typeid(T).hash_code()] = component;
    }
    template&lt;class T&gt;
    void detachComponent(void){
        components_.erase(typeid(T).hash_code());
    }
    template&lt;class T&gt;
    T* getComponent(void)const{
        return *components_.find(typeid(T).hash_code());
    }
    unsigned int getInstanceID(void)const{
        return id_;
    }
private:
    unsigned int id_;
    std::map&lt;size_t, BaseComponent*&gt; components_;
};
</code></pre>

<p><strong>The Base Component and Message classes:</strong></p>

<pre><code>class BaseComponent{
public:
    virtual void handleMessage(BaseMessage &amp;message){};
};

class BaseMessage{
public:
    virtual int getType(void) = 0;
};
</code></pre>

<h2>1. Message Type Handling</h2>

<p>My first question is how I should handle the different (derived from BaseMessage) message types.</p>

<p>I have thought of two ways for handling the message types of the derived message types. One is to generate a hash (i.e. using FNV) from a string that names the message type and use that hash to determine the message type. So the <code>handleMessage(BaseMessage &amp;message)</code> function, would first extract this hash from the message and then do a static_cast to the appropriate type.</p>

<p>The second method is to use a template as follows (similar to the <code>attachComponent</code> methods of the entity class),</p>

<pre><code>template&lt;class T&gt;
handleMessage(T&amp; message){};
</code></pre>

<p>and make specializations for each message type the specific component is going to make.</p>

<p>Are there any drawbacks using the second method? What about performance-wise, why don't I see this kind of use more often?</p>

<h2>2. Input Handling</h2>

<p>My second question is what would be the optimal (in terms of latency and ease of use) way to handle input?</p>

<p>My thought was to create an <code>InputHandlerComponent</code> which registers with the keyboard class to listen to specific key presses defined possibly in some file. For example</p>

<pre><code>keyboard.register( player.getComponent&lt;InputHandler&gt;() , 'W')
</code></pre>

<p>I wish there was a more concise guide to component based systems but I guess there are many different ways to do the same things. I have more questions but I think it'd be wiser to first try implementing what I can.</p>
","<p>In a typical entity system you leave systems to have all the logic for your game and components to store data <strong><em>only</em></strong>, and your entities are just a simple identifier. Input handling would be much easier that way and not to mention the flexibility of your game. </p>

<p>There are plenty of ways to handle events, such as: the observer pattern, or signals/slots. You could do message handling with templates/virtual functions or function pointers, however it'd probably be easier to use <a href=""http://www.boost.org/doc/libs/1_52_0/doc/html/signals.html"" rel=""nofollow"">boost::signals</a>, even known it's not that great for performance. If you want performance*, I suggest you use templates and virtual functions or function pointers.</p>

<p>*I noticed that your code could really be optimised. There are alternatives to the <code>typeid</code> operator, which are actually faster than using <code>typeid</code>. Such as using templates/macros and simple integers to define a class's ID.</p>

<p>You can look at my <a href=""https://github.com/miguelmartin75/anax"" rel=""nofollow"">Entity System</a> if you need some inspiration (which is inspired from the Java framework <a href=""https://code.google.com/p/artemis-framework/"" rel=""nofollow"">Artemis</a>). Although I haven't implemented a way to handle events (other than entity-related events), I left that up to the user, but after sussing out the <a href=""https://github.com/alecthomas/entityx"" rel=""nofollow"">entityx</a> library, which I found on reddit. I figured I might be able to add an event system to my library. Please do note that my entity system isn't 100% complete on what features I want, but it works and has decent performance (but I could optimize, especially with the way I'm storing entities).</p>

<p>Here's what you could possibly do to handle events (inspired from <a href=""https://github.com/alecthomas/entityx"" rel=""nofollow"">entityx</a>):</p>

<h3>BaseReceiver/BaseListener</h3>

<ul>
<li>A base class so you may store listeners/receivers.</li>
</ul>

<h3>Receiver/Listener</h3>

<ul>
<li>This is a template class and requires you to override the virtual function <code>recieve(const T&amp;)</code>, where T is event information.</li>
<li>Classes that want to be notified by events that send specific information when an event occurs must inherit from this class. </li>
</ul>

<h3>EventHandler</h3>

<ul>
<li>Emits/fires events</li>
<li>Has a list of Receivers/Listeners objects that will be notified by fired events</li>
</ul>

<p>I've implement this design in C++, just now, without the use of <a href=""http://www.boost.org/doc/libs/1_52_0/doc/html/signals.html"" rel=""nofollow"">boost::signals</a>.
You can see it <a href=""http://ideone.com/GIa77s"" rel=""nofollow"">here</a>.</p>

<h2>Pros</h2>

<ul>
<li>Statically typed</li>
<li>Virtual functions (faster than boost::signals, well it should be)</li>
<li>Compile-time errors if you didn't emit notifications correctly</li>
<li>C++98 compatible (I believe)</li>
</ul>

<h2>Cons</h2>

<ul>
<li>Requires you to define functors (you can't handle events in a global function)</li>
<li>No event queue; just register &amp; fire away. (which may be not what you want)</li>
<li>Not direct calls (shouldn't be that bad for events)</li>
<li>No multiple event handling on the same class (this could be modified so it does allow multiple events, via multiple inheritance, but may take some time to implement)</li>
</ul>

<p>Also, I have an <a href=""https://github.com/miguelmartin75/anax/tree/master/examples/3%20Movement"" rel=""nofollow"">example</a> in my entity system, which does deal with rendering and input handling, it's quite simple but it presents many concepts to understand my library.</p>
","47483"
"What animation technique is used in 'Dont Starve'?","9379","","<p>While playing a few games in my personal time off development I've stumbled across a survival 2D/3D survival game. The game was apparently made in SDL and GLUT (Dont starve) but what really amazed me was the animations in the game.</p>

<p>The animations are extremely smooth and fluent. There is no distortion while animating, what usually happens in hand-made animations is that pixels get removed, animations are jaggy and they simply aren't as smooth. That got me thinking on how they managed to accomplish such a quality of animations. Were they really handmade (If they were, then it must've taken a very talented artist), is it bone animation or are they using another technique?</p>
","<p>My name is Kevin, and I'm a programmer/designer at Klei. I wrote a bunch of the animation stuff that we used in the Shank series, Mark of the Ninja, and Don't Starve.</p>

<p>Our animators work in Flash. We have a concept of a character 'build' which is a set of body-part symbols with multiple views. Depending upon the fidelity of the given game, there are more or less body parts with more or less 'view'. I think that Shank had about 30 body parts with 1-2 dozen views each, while Wilson from Don't Starve has about a dozen body parts with only about the same number of views. Custom JSFL scripts are used to analyze the flash symbol timelines, and then bake out the relevant images as a series of high-res PNG files, along with a bunch of metadata that we stick in an XML. </p>

<p>Given a character build, our animators create a new root symbol in another file to contain a chunk of animation for that character. In that timeline, they create the character out of build symbols and move it around, tween it, etc. to create individual animations (which are demarcated using frame labels). The exporter script exports these timelines into XML, taking note of the 2d transform of every build piece, and which view it is showing.</p>

<p>With all of this information exported to XML and PNG, we run a series of Python scripts to convert them into run-time data. One script downsizes, atlases, and mips all of the textures and convert them to (one or more) compressed, platform-specific formats. Another script processes the XML animation data into a more efficient to load binary format.</p>

<p>At run time, It's really just a matter of showing the right build symbols with the right transforms and view.</p>

<p>This system took a long time to build, and has been refined as we've moved it from game to game. There are a lot of details that I'm glossing over (like how we handle layering and run-time costume swapping), but that's the general outline.</p>

<p>Of course, the technology that we use is probably the least important aspect of the 'Klei
Look'. The most important part is that we have a bunch of really, really good animators. :)</p>

<p>Anyway, I hope this helps. If you have any more questions about Don't Starve, you can stop by our forums, where I'm usually quite happy to talk shop.</p>
","44871"
"Drawing a circle in OpenGL ES Android, squiggly boundaries ","9347","","<p>I am new to OpenGL ES and facing a hard time drawing a circle on my GLSurfaceView.  Here's what I have so far. </p>

<p><strong>The circle class</strong></p>

<pre><code>public class MyGLBall {

private int points=40;
private float vertices[]={0.0f,0.0f,0.0f};
private FloatBuffer vertBuff;


//centre of circle

public MyGLBall(){

    vertices=new float[(points+1)*3];
    for(int i=3;i&lt;(points+1)*3;i+=3){
      double rad=(i*360/points*3)*(3.14/180);
      vertices[i]=(float)Math.cos(rad);
      vertices[i+1]=(float) Math.sin(rad);
      vertices[i+2]=0;
    }     
      ByteBuffer bBuff=ByteBuffer.allocateDirect(vertices.length*4);    
      bBuff.order(ByteOrder.nativeOrder());
      vertBuff=bBuff.asFloatBuffer();
      vertBuff.put(vertices);
      vertBuff.position(0);


}

public void draw(GL10 gl){
    gl.glPushMatrix();
    gl.glTranslatef(0, 0, 0);
//  gl.glScalef(size, size, 1.0f);
    gl.glColor4f(1.0f,1.0f,1.0f, 1.0f); 
    gl.glVertexPointer(3, GL10.GL_FLOAT, 0, vertBuff);
    gl.glEnableClientState(GL10.GL_VERTEX_ARRAY);
    gl.glDrawArrays(GL10.GL_TRIANGLE_FAN, 0, points/2);
    gl.glDisableClientState(GL10.GL_VERTEX_ARRAY);
    gl.glPopMatrix();
 }  

 }
</code></pre>

<p>I couldn't retrieve the screenshot of my image but here's what it looks like
<img src=""https://i.stack.imgur.com/C4pTC.png"" alt=""enter image description here""> </p>

<p>As you can see the border has <strong>crests</strong> and <strong>troughs</strong> thereby rendering it squiggly, which I do not want. All I want is a simple curve.</p>
","<p>I can't imagine how your code would produce the image you linked. I could however, imagine how it might produce an image like this:</p>

<p><img src=""https://i.stack.imgur.com/eUaMX.png"" alt=""enter image description here""></p>

<p>With flat sides. So really what you want to do is increase the number of sides. Try setting:</p>

<pre><code>private int points=40;
</code></pre>

<p>to something larger like</p>

<pre><code>private int points=360;
</code></pre>

<p>If you wanted a loop like your image instead of a circle you can do something like this:</p>

<pre><code>public float[] DrawLoop(float centerX, float centerY, float sides, float innerRadius, float outerRadius) {
    float[] vertices = new float[(sides+1)*4];
    for (int i = 0; i &lt;= sides; i+=4) {
        verticies[i+0] = centerX + (sin(toRadians(360f * (i / sides))) * innerRadius);
        verticies[i+1] = centerY - (cos(toRadians(360f * (i / sides))) * innerRadius);
        verticies[i+2] = centerX + (sin(toRadians(360f * (i / sides))) * outerRadius);
        verticies[i+3] = centerY - (cos(toRadians(360f * (i / sides))) * outerRadius);
    }
    return vertices;
}
</code></pre>
","26288"
"HTML5 - Dynamic canvas grid for scrolling a big map","9344","","<p>I've been working on different scrolling algorithms for my JS-based game. My main problem is that I need to draw a huge map and also have it scroll smoothly. I've made a few attempts and while they're efficient (code and framerate wise) they still look jumpy and have to redraw constantly (though not each frame, it's still too much redrawing for my taste).</p>

<p>My latest idea is to implement some kind of 3x3 grid around the camera which will scroll with delay. What do I mean ""with delay"" ? well, if you have played Diablo II before, try to get a Maphack app and enable the Automap Screen Area feature: You see, Diablo II's map is made through a concept of ""rooms"" and those adjacent to the player in a specific area (usually screen size) are drawn offscreen to allow the scrolling.</p>

<p>I want to implement that in an orthogonal perspective (this is, 2D zelda-like), just like this:</p>

<p>The blue grid is made out of canvases around my camera's position. I know I can position them with the simple x+(floor(camera.x / tile_size) * tile_size) formula and with some offsets have them move around the camera like this:</p>

<p><img src=""https://i.stack.imgur.com/cxTKH.gif"" alt=""Concept idea""></p>

<p>THE PROBLEM arises when the drawn offscreen areas must remain in the same position to allow the scrolling. I've made a second image which illustrates this:</p>

<p><img src=""https://i.stack.imgur.com/lhrb1.gif"" alt=""Scolling example""></p>

<p>Notice how the colored tiles (or offscreen areas of screen size) remain in the same position UNTIL they get ""too far"" from the camera (the red dot). HOWEVER, while they have the same position, notice the Tile # (below each blue grid tile) change. I can't do it that way because it would require to redraw, and my goal is to avoid such redraw if the position hasn't changed.</p>

<p>This means however, that, taking in example blue tile 6 (located at 0,1 at the first animation frame) it changes to tile 5 and then to tile 1. While this is true, the idea is to keep it at tile 6, and only re-use the farthest canvases in the closest ones that need to be redrawn.</p>

<p>I'm illustrating my problem this way because my previous question didn't even get a single comment ( <a href=""https://stackoverflow.com/questions/22185858/infinite-scroll-a-canvas-with-a-tiled-map-without-redrawing/22277681"">https://stackoverflow.com/questions/22185858/infinite-scroll-a-canvas-with-a-tiled-map-without-redrawing/22277681</a> ) so I had to work and answer my own question... something that doesn't even help either because someone else might have had a better idea, but nobody did, it seems.</p>

<p>That's why I'm asing here in gamedev, maybe here are some more skilled people who can have an idea or a shot at what I'm attempting to do. Also, please, I'm not interested in using other game or JS engines. If I were I wouldn't be asking this here as I know they implement tile scrolling and such, but this is both for my own learning and for creating a custom engine suited for my own game's needs.</p>

<p>Any help then, is really welcome.</p>

<p>Thanks in advance!
- DARKGuy</p>

<p><strong>EDIT:</strong> Well alright, after struggling for like 2 days straight on this issue I finally managed to do it. I didn't want to do it with this kind of coords, so I wonder is there any way to optimize this code or to avoid it to do those increments and instead use a formula that would absolutely position them?</p>

<p><img src=""https://i.stack.imgur.com/5t1Sg.jpg"" alt=""Proof""></p>

<p>Here's the code I'm using (cv = canvas, cx = context(""2d""), grid = 3x3 array of canvases. Also, I'm using a 32x32 ""grid"" just to see how it works. The size should be screen size (or region size, in my engine's case)):</p>

<pre><code>for(ix = 0; ix &lt; grid.length; ix++)
for(iy = 0; iy &lt; grid.length; iy++) {
    cv = grid[iy][ix];
    if(cam.x - cv.x &gt; 48)
        cv.x += 32 * 3;
    if(cam.x - cv.x &lt; -48)
        cv.x -= 32 * 3;
    if(cam.y - cv.y &gt; 48)
        cv.y += 32 * 3;
    if(cam.y - cv.y &lt;- 48)
        cv.y -= 32 * 3;
    cx.fillStyle = cv.color;
    cx.fillRect(cv.x, cv.y, 32, 32);
}
</code></pre>
","<p>Well fine, after 4 days and 62 views and only ONE comment (thanks @Anko), I managed to do the formula on my own. I don't know if it's as optimized as it should be, but who cares anyways? I can't believe that out of 62 views I only got one user interested in helping...very disappointing.</p>

<p>Anyways, here are the formulas for those interested (<code>ix/iy</code> = absolute world coordinates):</p>

<pre><code>X = ( (SCREEN_WIDTH * 3) * (Math.floor( (ix+(SCREEN_WIDTH*(1-j))) / (SCREEN_WIDTH * 3) ) ) + SCREEN_WIDTH * j ) - ix;
Y = ( (SCREEN_HEIGHT * i) + ( (SCREEN_HEIGHT * 3) * Math.floor( ( (iy+(SCREEN_HEIGHT*(1-i))) / (SCREEN_HEIGHT * 3)) )) ) - iy;```
</code></pre>

<p><em>Usage:</em></p>

<pre><code>for(var i = 0; i &lt; 3; i++)
for(var j = 0; j &lt; 3; j++) {
    var cvg = grid[i][j];
    cx.fillStyle = cvg.color;
    var vy = ( (SCREEN_HEIGHT * i) + ( (SCREEN_HEIGHT * 3) * Math.floor( ( (iy+(SCREEN_HEIGHT*(1-i))) / (SCREEN_HEIGHT * 3)) )) ) - iy;
    var vx = ( (SCREEN_WIDTH * 3) * (Math.floor( (ix+(SCREEN_WIDTH*(1-j))) / (SCREEN_WIDTH * 3) ) ) + SCREEN_WIDTH * j ) - ix;
    cx.fillRect(vx, vy, SCREEN_WIDTH, SCREEN_HEIGHT);
}
</code></pre>

<p>Working <a href=""http://jsfiddle.net/B7Jm6/3/"" rel=""nofollow"">JSFiddle</a>.</p>
","71870"
"Getting error GL_FRAMEBUFFER_INCOMPLETE_ATTACHMENT","9336","","<p>I am getting error code GL_FRAMEBUFFER_INCOMPLETE_ATTACHMENT when creating framebuffer on Mac (using glCheckFramebufferStatus).</p>

<p>I am using same code for rendering on Mac and iOS both. Maybe problem is in the buffers initialization. On iOS I am doing it this way:</p>

<pre><code>    CAEAGLLayer* eaglLayer = (CAEAGLLayer*) super.layer;
    eaglLayer.opaque = YES;

    EAGLRenderingAPI api = kEAGLRenderingAPIOpenGLES2;
    m_context = [[EAGLContext alloc] initWithAPI:api];

    if (!m_context) {
        [self release];
        return nil;
    }

    if (!m_context || ![EAGLContext setCurrentContext:m_context]) {
        [self release];
        return nil;
    }

    [self layoutIfNeeded];


    NSLog(@""Using OpenGL ES 2.0"");

    [m_context
        renderbufferStorage:GL_RENDERBUFFER
        fromDrawable: eaglLayer];
</code></pre>

<p>Variable <code>m_context</code> is object <code>EAGLContext</code></p>

<p>On the Mac this way:</p>

<pre><code>NSOpenGLPixelFormat *nsglFormat;

NSOpenGLPixelFormatAttribute attr[] = 
{
    NSOpenGLPFADoubleBuffer,
    NSOpenGLPFAAccelerated,
    NSOpenGLPFAColorSize, m_colorBits, //16
    NSOpenGLPFADepthSize, m_depthBits, //16
    0 
};


[self setPostsFrameChangedNotifications: YES];

///&lt; Next, initialize the NSOpenGLPixelFormat itself
nsglFormat = [[NSOpenGLPixelFormat alloc] initWithAttributes:attr];

///&lt; Check for errors in the creation of the NSOpenGLPixelFormat
if(!nsglFormat) { 
    NSLog(@""Invalid format... terminating.""); 
    return nil; 
}


///&lt; Now create the the CocoaGL instance, using initial frame and the NSOpenGLPixelFormat
self = [super initWithFrame:frame pixelFormat:nsglFormat];
[nsglFormat release];

///&lt; If there was an error, we again should probably send an error message to the user
if(!self) { 
    NSLog(@""Self not created... terminating.""); 
    return nil; 
}



///&lt; Now  set this context to the current context

[[self openGLContext] makeCurrentContext];
</code></pre>

<p>Maybe I am doing anything wrong when I initialize NSOpenGLContext. Can you see any error? Thankyou
<strong>UPDATE</strong>: Initialization of the OpenGL I am doing this way: </p>

<pre><code>int m_width, m_height;


glGetRenderbufferParameteriv(GL_RENDERBUFFER,
                             GL_RENDERBUFFER_WIDTH, &amp;m_width);
glGetRenderbufferParameteriv(GL_RENDERBUFFER,
                             GL_RENDERBUFFER_HEIGHT, &amp;m_height);

// Create the depth buffer.
glGenRenderbuffers(1, &amp;m_depthRenderbuffer);
glBindRenderbuffer(GL_RENDERBUFFER, m_depthRenderbuffer);
glRenderbufferStorage(GL_RENDERBUFFER,
                      GL_DEPTH_COMPONENT16,
                      m_width,
                      m_height);

// Create the framebuffer object; attach the depth and color buffers.
glGenFramebuffers(1, &amp;m_framebuffer);
glBindFramebuffer(GL_FRAMEBUFFER, m_framebuffer);
glFramebufferRenderbuffer(GL_FRAMEBUFFER,
                          GL_COLOR_ATTACHMENT0,
                          GL_RENDERBUFFER,
                          m_colorRenderbuffer);
glFramebufferRenderbuffer(GL_FRAMEBUFFER,
                          GL_DEPTH_ATTACHMENT,
                          GL_RENDERBUFFER,
                          m_depthRenderbuffer);

// Bind the color buffer for rendering.
glBindRenderbuffer(GL_RENDERBUFFER, m_colorRenderbuffer);


// Set up some GL state.
glViewport(0, 0, 640, 480);
glEnable(GL_DEPTH_TEST);
</code></pre>
","<p>Finally I have found the solution. It is necessary NOT to use renderbuffer. So I have to DELETE code to init renderbuffer. </p>
","11624"
"cocos3d versus Unity for simple IOS 3D games?","9336","","<p>Wondering if anyone here happens to have experience in doing some simple 3D based games/apps for IOS, using cocos3d &amp; Unity and could give some pointers....questions I have are:</p>

<p>GENERAL</p>

<p>1) It seems currently cocos3d has the most traction in terms of a free 3D games engine for IOS development?</p>

<p>2) If one wanted to step up from the free IOS games engine, to a commercial one it would seem Unity is a popular choice, however you would then not really be doing apple/objective-c development, but rather unity development and pushing a button to pop out an IOS deployable artifact correct?</p>

<p>FOR MY SPECIFIC REQUIREMENT - If I was interested in doing the following:</p>

<ul>
<li>develop a relatively simple 3D application for iPhone/iPad</li>
<li>have a small 'world' such as a room with a few basic items in it (table, cupboard)</li>
<li>ability to 'drop' a basket ball in the room and have it bounce around based on a physics engine &amp; perhaps some user input (not sure what, lets say control wind direction)</li>
<li>monitor it and react accordingly - e.g. say if it goes into a net which is in the room then add a point to the scoreboard</li>
</ul>

<p>At a high level how would one do this using Unity versus using cocos3d, for example:</p>

<p>3) Which would be quicker to develop such a basic iPhone/iPad game/simulation out of Unity/cocos3d?</p>

<p>4) Would 'building your world/room' approach be different? Like in Unity would you build tables/cupboards within a Unity IDE which would make it very quick, whereas with cocos3d would you have to do this programmatically?</p>

<p>5) Would the programming aspect of letting the ball go and monitoring it be different between the two? Or would you roughly in both cases just be setting up world, release ball in certain position, and then engaging physics engine?</p>

<p>6) Any advice/guidance re which tool/approach to use? (Unity versus cocos3d)</p>

<p>7) Re using cocos3d for my requirement, what additional tools would you recommend above/beyond XCode? (e.g. just perhaps some sort of 3D design tool to help model the room and import/save somehow for us in cocos3d)</p>

<p>Basically I'm a hobbyist iOS developer who wants to do some 3d, so the concept of using a free/open-source approach such as cocos3d sounds great as (a) it's free, (b) keep using existing skill set re objective-c etc, BUT the biggest unknown to me is whether by chosing cocos3d would I be giving myself say 20 hours of work to develop a 3d app/animation that could be developed in 1 hour in one of these commercial product (e.g. Unity)?</p>
","<p>Both are valid choices, but with Unity3D it's going to be much simpler to achieve what you want, mainly because:</p>

<ul>
<li>Unity3D has a much easier content-pipeline. You can simply drop a lot of different image- and 3D formats into Unity and work with them, while cocos3d requires models to be in PowerVR POD format.</li>
<li>Unity3D has/is a visual editor, which makes it much easier to create your game-world. In cocos3d you would have to come up with your own scene-format and parser.</li>
<li>Unity3D comes with a 3D physics engine. In cocos3d you would have to integrate the physics engine yourself (for example <a href=""http://bulletphysics.org"" rel=""nofollow"">Bullet</a>).</li>
</ul>

<p>I really like cocos2d (and 3d), but Unity3D is a much more mature tool for 3D game development than cocos3d is. The 3 points above alone will save you so much time that it's worth buying the Unity license.</p>

<p>Since you can get Unity for free, there's nothing stopping you to try both tools and see what suits you best.</p>
","21047"
"Smooth Sprite Movement - Don't Add Velocity to Position?","9331","","<p>I am trying to figure out if there is a way to move a sprite smoothly on the screen at different speeds without stuttering, but keeping the effect that it's moving smoothly; especially at faster velocities.</p>

<p>Below is a basic version of what I have with all of the object specific logic stripped out for readability. </p>

<pre><code>void MoveableGameObject::update(double time)
{
    //maxVelocity is 10
    currentVelocity = min&lt;float&gt;(currentVelocity + acceleration * time, maxVelocity);
    location.x += currentVelocity;
}

void MoveableGameObject::draw()
{
    sprite-&gt;draw(location.x, location.y)
}
</code></pre>

<p>The part that I do not like is that the next time the frame renders and max velocity has been achieved, the sprite jumps 10 pixels and looks stuttery. If I tone down the numbers then it is of course smoother, but also slower.</p>

<p>I need to find a way to still have the speed, but give a smooth transition somehow. I am having a hard time wrapping my head around trying to implement movement speeds. Am I just using the wrong scale in terms of velocity to pixels?</p>

<p>My brain hurts, but I am still having a blast tinkering around with this and is a nice change of pace from doing nothing but business applications for the past 7 years.</p>

<p>I do have the ability to say run the game logic 20 times a second while rendering at 60 frames a second. Figured I would mention that in case that helps with an answer. Currently they are both just set to 60 since I am only running a single sprite and wanted to test the movement and check the sprite location on <code>update()</code> vs. <code>draw()</code>.</p>

<p>Thanks in advance for any help.</p>

<p>EDIT: I forgot to mention and not sure if it matters or not, but I am currently using SDL to render.</p>
","<p>Is that update(time) or update(dt)?</p>

<p>You would have something like:</p>

<pre><code>void frameUpdate(){
   dt = time - oldTime;
   time = oldTime;

   // FPS at that specific frame would be 1.0/dt assuming time is in seconds
   // Normally you get the time in microseconds or at least milliseconds
   //   so it would be 1.0/(dt*1e6) or 1.0/(dt*1e4)

   update(dt);
}
</code></pre>
","49054"
"Should I tell the player they have no chance of completing the level?","9308","","<p>Suppose a player has reached a point where they have absolutely no chance of completing the current level, and must restart it and try again. </p>

<p>Should I notify them that they will gain nothing by continuing the level and needs to restart? If so, how should I tell them that? Would a message box of some sort saying something like ""No chance, start again"" be good? Or should I let them continue to play and find out themselves?</p>

<p>Note that the levels are not huge, and mostly take about a minute each to complete. So for example, if the user missed the opportunity to level up after 30 seconds or so, should I stop the game and make them restart?</p>
","<p>Depends on the game.</p>

<p>In a obstacle course/parkour type game against a time limit it's common to add checkpoints that add to a time limit which is tight enough to that a big mistake will cause failure.</p>

<p>In a puzzle game however like your example then just letting the time run out is a better idea. It's probably also a good idea to let them undo actions that were wrong and let the player find out that they were wrong for themselves. If there is only 1 solution and you warn the player as soon as he makes a mistake then it becomes a not-fun game of trial and error. Rather than the mental challenge you are going for.</p>
","112249"
"Semi-fixed or Fully-fixed timestep?","9308","","<p>I am making an iphone shmup and am trying to decide what type of game loop to use. I want to use either semi-fixed timestep or fully-fixed timestep.</p>

<p>With semi-fixed timestep I will make zero or more update(FIXED_INTERVAL) calls followed by one update(dt) call where dt &lt;= FIXED_INTERVAL per game loop. As I understand it the drawbacks with this method are that my physics update(dt) logic is going to be more difficult to program because I basically have to assume a variable dt for every update. And then I've also heard that each run of my game will be slightly different due to floating point values not being the same every time.</p>

<p>Then with fully-fixed timestep I am making zero or more update(FIXED_INTERVAL) calls followed by one interpolation(dt/FIXED_INTERVAL) call where dt &lt; FIXED_INTERVAL per game loop.</p>

<p>So it seems like the big decision I really have to make is: do I want to tackle the challenge of implementing an update(dt) with a variable dt or do I want to tackle the challenge of implementing interpolation?</p>

<p>Now from what I've read the majority of people are saying to use fully-fixed and do the interpolation. But when I think about implementing interpolation it seems like I'd be a lot more complex than an update(dt) with variable dt. This is because if I use interpolation I have to remember both the previous state and the current state. So if I want to use interpolation I have to come up with an additional layer of indirection that abstracts out entire individual game states. Whereas with semi-fixed timestep where I don't have to use interpolation I don't have to come up with a game state abstraction because there's always only one game state and it's simply the ""global arrays"" that represent my enemies, and enemy bullets etc.</p>

<p>So what's the more practical choice: do I implement it semi-fixed knowing that my physics updates could get complicated with the variable dt. Or do I use fully-fixed and try to come up with a game state abstraction so that I can keep track of previous state and current state in order to perform interpolation?</p>
","<p><strong>Fully Fixed</strong></p>

<p>You loose most of the benefits of a fixed timestep when you throw in a variable step once each frame.</p>

<p>Noel Lopis has a <a href=""http://gamesfromwithin.com/casey-and-the-clearly-deterministic-contraptions"">great write up</a> on how he implemented a fixed time step in his game <a href=""http://www.caseyscontraptions.com/"">Casey's Contraptions</a>.  As bonus to you he is an iphone developer, though his technique is not iphone specific.</p>

<p>Some highlights from the article</p>

<ul>
<li>Use a time accumulator.</li>
<li>Use 120Hz physics rate for a 60Hz frame rate.</li>
<li>Simulate one fixed step into future and use left over time accumulation to lerp drawing code between current physics state and future physics state.</li>
<li>various gotchas</li>
</ul>
","12368"
"How can I convert an OBJ model into arrays of vertices and indices?","9306","","<p>I'm writing a simple model loader just to learn how models are loaded. I wrote a program to convert .OBJ files in a custom format. (It's virtually exactly the same as .OBJ, I wrote it once again just for learning). I can load all the data into <code>std::vector</code>s but I don't know how to put it into an array of vertices and indices, so it's rendering wrong. Here's how it turns out with no culling and wireframe enabled (it's supposed to be a sphere, and that L shape in the middle isn't part of the model):</p>

<p><img src=""https://i.stack.imgur.com/HZX5v.png"" alt=""http://i.imgur.com/eMK4I.png""> </p>

<p>When I tell it to render a point list, all the vertices are there in the right places. However, they don't seem to form faces correctly... </p>

<p>This is the code that renders them:</p>

<pre><code>    //=========================================================
    // CONVERT THE DATA INTO SOMETHING USABLE
    //=========================================================

    bool isDuplicate;
    for(int i = 0; i &lt; polygonCount; i++)
    {
        for(int i2 = 0; i2 &lt; 3; i2++)
        {
            isDuplicate = false;
            isCreated = false;
            selectedVertex = faceDefinitions[i].vertexIndexes[i2];

            for(int i3 = 0; i3 &lt; vertexCount; i3++)
            {
                if(modelData-&gt;vertices[i3].position == vertexPositions[selectedVertex])
                {
                    if(modelData-&gt;vertices[i3].texture == D3DXVECTOR2(0,0))
                    {
                        indices[selectedVertex] = i3; 
                        isDuplicate = true;
                        break;
                    }
                }
            }

            if(isDuplicate)
                continue;

            indices[selectedVertex] = selectedVertex;

            modelData-&gt;vertices[selectedVertex].position = vertexPositions[selectedVertex];
            modelData-&gt;vertices[selectedVertex].normal = vertexNormals[faceDefinitions[i].normalIndexes[i2]];
            modelData-&gt;vertices[selectedVertex].texture = D3DXVECTOR2(0,0);
        }
    }

    modelData-&gt;indices = indices;
</code></pre>

<p>I know there's a way to do it but I can't seem to wrap my head around it. I've rewritten it probably 5 times, but I always get the same result.</p>

<p>Here's the ModelData structure:</p>

<pre><code>struct ModelData
{
    int vertexCount;
    int normalCount;
    int faceCount;
    unsigned long* indices;
    EntityBase::VertexType* vertices;
    int errorCode;
};
</code></pre>

<p>The FaceDefinition structure contains the the indices of the vertices positions, normals, and texture coords. I haven't implemented texture coords yet, though.</p>

<pre><code>struct FaceDefinition
{
    int vertexIndexes[3];
    int textureIndexes[3];
    int normalIndexes[3];
};
</code></pre>

<p>Here is the entire function, just for clarity:</p>

<pre><code>ModelData* CModelLoader::LoadModel(WCHAR* modelName)
{
    ifstream loaderStream(Application::FileSystem::GetFileLocation(FILE_TYPE_MODEL,modelName));

    ModelData* modelData = new ModelData;

    vector&lt;D3DXVECTOR3&gt; vertexPositions;
    vector&lt;D3DXVECTOR3&gt; vertexNormals;
    vector&lt;D3DXVECTOR3&gt; vertexTextureCoords;
    vector&lt;int&gt; setVertices;
    vector&lt;FaceDefinition&gt; faceDefinitions;
    vector&lt;string&gt; tokens;
    vector&lt;string&gt; faceToken;
    int vertexCount = 0, normalCount = 0, polygonCount = 0;
    unsigned long *indices;
    int selectedVertex;
    bool isCreated;

    string input;
    string currentToken;
    string currentFaceToken;
    std::istringstream streamReader;
    std::istringstream faceReader;
    D3DXVECTOR3 tempVector;
    FaceDefinition tempFace;

    modelData-&gt;errorCode = ERR_NO_ERROR;

    if(!loaderStream)
        modelData-&gt;errorCode = ERR_COULD_NOT_OPEN;
    else
    {
        while(std::getline(loaderStream, input))
        {
            streamReader.clear();
            streamReader.str(input);
            tokens.clear();
            while(std::getline(streamReader, currentToken, ' '))
            {
                tokens.push_back(currentToken);
            }
            if(tokens.size() &lt; 1)
                continue;

            if(tokens[0] == ""VERTEX"")
            {
                vertexCount++;
                if(tokens.size() &gt;= 4)
                {
                    tempVector = D3DXVECTOR3(0,0,0);
                    tempVector.x = (float) atof(tokens[1].c_str());
                    tempVector.y = (float) atof(tokens[2].c_str());
                    tempVector.z = (float) atof(tokens[3].c_str());
                    vertexPositions.push_back(tempVector);
                    continue;
                }
                else
                {
                    vertexPositions.push_back(D3DXVECTOR3(0,0,0)); //give it a bad vertex, because we received a bad vertex
                }
            }
            if(tokens[0] == ""VERTEX_NORMAL"")
            {
                normalCount++;
                if(tokens.size() &gt;= 4)
                {
                    tempVector = D3DXVECTOR3(0,0,0);
                    tempVector.x = (float) atof(tokens[1].c_str());
                    tempVector.y = (float) atof(tokens[2].c_str());
                    tempVector.z = (float) atof(tokens[3].c_str());
                    vertexNormals.push_back(tempVector);
                    continue;
                }
                else
                {
                    vertexNormals.push_back(D3DXVECTOR3(0,0,0)); //give it a bad normal, because we received a bad normal
                }
            }
            if(tokens[0] == ""FACE"")
            {
                polygonCount++;
                if(tokens.size() == 4) //sorry, but non triangles aren't worth the time
                {
                    tempFace = FaceDefinition();

                    //vertex 1
                    faceReader.clear();
                    faceReader.str(tokens[1]);
                    faceToken.clear();
                    while(std::getline(faceReader, currentFaceToken, ','))
                    {
                        faceToken.push_back(currentFaceToken);
                    }
                    if(faceToken.size() == 3) //should have all the info, or, same as above, its not worth the time
                    {
                        tempFace.vertexIndexes[0]  = atoi(faceToken[0].c_str()) - 1;
                        tempFace.textureIndexes[0] = atoi(faceToken[1].c_str()) - 1;
                        tempFace.normalIndexes[0]  = atoi(faceToken[2].c_str()) - 1;
                    }

                    //vertex 2
                    faceReader.clear();
                    faceReader.str(tokens[2]);
                    faceToken.clear();
                    while(std::getline(faceReader, currentFaceToken, ','))
                    {
                        faceToken.push_back(currentFaceToken);
                    }
                    if(faceToken.size() == 3) //should have all the info, or, same as above, its not worth the time
                    {
                        tempFace.vertexIndexes[1]  = atoi(faceToken[0].c_str()) - 1;
                        tempFace.textureIndexes[1] = atoi(faceToken[1].c_str()) - 1;
                        tempFace.normalIndexes[1]  = atoi(faceToken[2].c_str()) - 1;
                    }

                    //vertex 3
                    faceReader.clear();
                    faceReader.str(tokens[3]);
                    faceToken.clear();
                    while(std::getline(faceReader, currentFaceToken, ','))
                    {
                        faceToken.push_back(currentFaceToken);
                    }
                    if(faceToken.size() == 3) //should have all the info, or, same as above, its not worth the time
                    {
                        tempFace.vertexIndexes[2]  = atoi(faceToken[0].c_str()) - 1;
                        tempFace.textureIndexes[2] = atoi(faceToken[1].c_str()) - 1;
                        tempFace.normalIndexes[2]  = atoi(faceToken[2].c_str()) - 1;
                    }

                    faceDefinitions.push_back(tempFace);
                }
                //if we receive a bad face, we just wont read it
            }
        }
    }

    indices = new unsigned long[vertexCount];

    modelData-&gt;faceCount = polygonCount;
    modelData-&gt;normalCount = normalCount;
    modelData-&gt;vertexCount = vertexCount;
    modelData-&gt;vertices = new EntityBase::VertexType[vertexCount];

    //&lt; ^^everything up here works^^ &gt;
    //=========================================================
    // CONVERT THE DATA INTO SOMETHING USABLE
    //=========================================================

    //now is the boring part, creating the vertex list...

    bool isDuplicate;
    for(int i = 0; i &lt; polygonCount; i++)
    {
        for(int i2 = 0; i2 &lt; 3; i2++)
        {
            isDuplicate = false;
            isCreated = false;
            selectedVertex = faceDefinitions[i].vertexIndexes[i2];

            for(int i3 = 0; i3 &lt; vertexCount; i3++)
            {
                if(modelData-&gt;vertices[i3].position == vertexPositions[selectedVertex])
                {
                    if(modelData-&gt;vertices[i3].texture == D3DXVECTOR2(0,0))
                    {
                        indices[selectedVertex] = i3; 
                        isDuplicate = true;
                        break;
                    }
                }
            }

            if(isDuplicate)
                continue;

            indices[selectedVertex] = selectedVertex;

            modelData-&gt;vertices[selectedVertex].position = vertexPositions[selectedVertex];
            modelData-&gt;vertices[selectedVertex].normal = vertexNormals[faceDefinitions[i].normalIndexes[i2]];
            modelData-&gt;vertices[selectedVertex].texture = D3DXVECTOR2(0,0);
        }
    }

    modelData-&gt;indices = indices;

    return modelData;
}
</code></pre>

<p>This is there sphere models file:</p>

<pre><code>#Vertex Info

VERTEX_COUNT:62
NORMAL_COUNT:62
FACE_COUNT:120

VERTEX 0 19.5 0
VERTEX 0 -19.5 0
VERTEX 9.75 -16.887495 0
VERTEX 8.443748 -16.887495 4.875
VERTEX 4.875 -16.887495 8.443748
VERTEX 0 -16.887495 9.75
VERTEX -4.875 -16.887495 8.443748
VERTEX -8.443748 -16.887495 4.875
VERTEX -9.75 -16.887495 0
VERTEX -8.443748 -16.887495 -4.875
VERTEX -4.875 -16.887495 -8.443748
VERTEX 0 -16.887495 -9.75
VERTEX 4.875 -16.887495 -8.443748
VERTEX 8.443748 -16.887495 -4.875
VERTEX 16.887497 -9.75 0
VERTEX 14.625001 -9.75 8.443748
VERTEX 8.443748 -9.75 14.625
VERTEX 0 -9.75 16.887497
VERTEX -8.443748 -9.75 14.625
VERTEX -14.625001 -9.75 8.443748
VERTEX -16.887497 -9.75 0
VERTEX -14.625001 -9.75 -8.443748
VERTEX -8.443748 -9.75 -14.625
VERTEX 0 -9.75 -16.887497
VERTEX 8.443748 -9.75 -14.625
VERTEX 14.625001 -9.75 -8.443748
VERTEX 19.5 1E-06 0
VERTEX 16.887495 1E-06 9.75
VERTEX 9.75 1E-06 16.887495
VERTEX 0 1E-06 19.5
VERTEX -9.75 1E-06 16.887495
VERTEX -16.887495 1E-06 9.75
VERTEX -19.5 1E-06 0
VERTEX -16.887495 1E-06 -9.75
VERTEX -9.75 1E-06 -16.887497
VERTEX 0 1E-06 -19.5
VERTEX 9.75 1E-06 -16.887497
VERTEX 16.887495 1E-06 -9.75
VERTEX 16.887495 9.750001 0
VERTEX 14.624999 9.750001 8.443748
VERTEX 8.443748 9.750001 14.625
VERTEX 0 9.750001 16.887495
VERTEX -8.443748 9.750001 14.625
VERTEX -14.624999 9.750001 8.443748
VERTEX -16.887495 9.750001 0
VERTEX -14.624999 9.750001 -8.443748
VERTEX -8.443748 9.750001 -14.625
VERTEX 0 9.750001 -16.887497
VERTEX 8.443748 9.750001 -14.625
VERTEX 14.624999 9.750001 -8.443748
VERTEX 9.750001 16.887495 0
VERTEX 8.443748 16.887495 4.875
VERTEX 4.875 16.887495 8.443748
VERTEX 0 16.887495 9.750001
VERTEX -4.875 16.887495 8.443748
VERTEX -8.443748 16.887495 4.875
VERTEX -9.750001 16.887495 0
VERTEX -8.443748 16.887495 -4.875
VERTEX -4.875 16.887495 -8.443748
VERTEX 0 16.887495 -9.750002
VERTEX 4.875 16.887495 -8.443748
VERTEX 8.443748 16.887495 -4.875

# Vertex Normals!

VERTEX_NORMAL 0 -1 0
VERTEX_NORMAL 0.573584 -0.819147 0
VERTEX_NORMAL 0.431481 -0.867044 0.249116
VERTEX_NORMAL 0 1 0
VERTEX_NORMAL 0.431481 0.867044 0.249116
VERTEX_NORMAL 0.573584 0.819147 0
VERTEX_NORMAL 0.286792 -0.819147 0.496738
VERTEX_NORMAL 0.286792 0.819147 0.496738
VERTEX_NORMAL 0 -0.867044 0.498231
VERTEX_NORMAL 0 0.867044 0.498231
VERTEX_NORMAL -0.286792 -0.819147 0.496738
VERTEX_NORMAL -0.286792 0.819147 0.496738
VERTEX_NORMAL -0.431481 -0.867044 0.249116
VERTEX_NORMAL -0.431481 0.867044 0.249116
VERTEX_NORMAL -0.573584 -0.819147 0
VERTEX_NORMAL -0.573584 0.819147 0
VERTEX_NORMAL -0.431481 -0.867044 -0.249116
VERTEX_NORMAL -0.431481 0.867044 -0.249116
VERTEX_NORMAL -0.286792 -0.819147 -0.496738
VERTEX_NORMAL -0.286792 0.819147 -0.496738
VERTEX_NORMAL 0 -0.867044 -0.498231
VERTEX_NORMAL 0 0.867044 -0.498231
VERTEX_NORMAL 0.286792 -0.819147 -0.496738
VERTEX_NORMAL 0.286792 0.819147 -0.496738
VERTEX_NORMAL 0.431481 -0.867044 -0.249116
VERTEX_NORMAL 0.431481 0.867044 -0.249116
VERTEX_NORMAL 0.865033 -0.501714 0
VERTEX_NORMAL 0.749141 -0.501714 0.432517
VERTEX_NORMAL 0.432517 -0.501714 0.749141
VERTEX_NORMAL 0 -0.501714 0.865033
VERTEX_NORMAL -0.432517 -0.501714 0.749141
VERTEX_NORMAL -0.749141 -0.501714 0.432517
VERTEX_NORMAL -0.865033 -0.501714 0
VERTEX_NORMAL -0.749141 -0.501714 -0.432517
VERTEX_NORMAL -0.432517 -0.501714 -0.749141
VERTEX_NORMAL 0 -0.501714 -0.865033
VERTEX_NORMAL 0.432517 -0.501714 -0.749141
VERTEX_NORMAL 0.749141 -0.501714 -0.432517
VERTEX_NORMAL 1 0 0
VERTEX_NORMAL 0.866025 0 0.5
VERTEX_NORMAL 0.5 0 0.866025
VERTEX_NORMAL 0 0 1
VERTEX_NORMAL -0.5 0 0.866025
VERTEX_NORMAL -0.866025 0 0.5
VERTEX_NORMAL -1 0 0
VERTEX_NORMAL -0.866025 0 -0.5
VERTEX_NORMAL -0.5 0 -0.866025
VERTEX_NORMAL 0 0 -1
VERTEX_NORMAL 0.5 0 -0.866025
VERTEX_NORMAL 0.866025 0 -0.5
VERTEX_NORMAL 0.865033 0.501714 0
VERTEX_NORMAL 0.749141 0.501714 0.432517
VERTEX_NORMAL 0.432517 0.501714 0.749141
VERTEX_NORMAL 0 0.501714 0.865033
VERTEX_NORMAL -0.432517 0.501714 0.749141
VERTEX_NORMAL -0.749141 0.501714 0.432517
VERTEX_NORMAL -0.865033 0.501714 0
VERTEX_NORMAL -0.749141 0.501714 -0.432517
VERTEX_NORMAL -0.432517 0.501715 -0.749141
VERTEX_NORMAL 0 0.501714 -0.865033
VERTEX_NORMAL 0.432517 0.501715 -0.749141
VERTEX_NORMAL 0.749141 0.501714 -0.432517

# Face Definitions!

FACE 2,1,1 3,2,2 4,3,3
FACE 1,4,4 52,5,5 51,6,6
FACE 2,7,1 4,3,3 5,8,7
FACE 1,9,4 53,10,8 52,5,5
FACE 2,11,1 5,8,7 6,12,9
FACE 1,13,4 54,14,10 53,10,8
FACE 2,15,1 6,12,9 7,16,11
FACE 1,17,4 55,18,12 54,14,10
FACE 2,19,1 7,16,11 8,20,13
FACE 1,21,4 56,22,14 55,18,12
FACE 2,23,1 8,20,13 9,24,15
FACE 1,25,4 57,26,16 56,22,14
FACE 2,27,1 9,24,15 10,28,17
FACE 1,29,4 58,30,18 57,26,16
FACE 2,31,1 10,28,17 11,32,19
FACE 1,33,4 59,34,20 58,30,18
FACE 2,35,1 11,32,19 12,36,21
FACE 1,37,4 60,38,22 59,34,20
FACE 2,39,1 12,36,21 13,40,23
FACE 1,41,4 61,42,24 60,38,22
FACE 2,43,1 13,40,23 14,44,25
FACE 1,45,4 62,46,26 61,42,24
FACE 2,47,1 14,44,25 3,48,2
FACE 1,49,4 51,50,6 62,46,26
FACE 3,2,2 15,51,27 16,52,28
FACE 3,2,2 16,52,28 4,3,3
FACE 4,3,3 16,52,28 5,8,7
FACE 16,52,28 17,53,29 5,8,7
FACE 5,8,7 17,53,29 18,54,30
FACE 5,8,7 18,54,30 6,12,9
FACE 6,12,9 18,54,30 7,16,11
FACE 18,54,30 19,55,31 7,16,11
FACE 7,16,11 19,55,31 20,56,32
FACE 7,16,11 20,56,32 8,20,13
FACE 8,20,13 20,56,32 9,24,15
FACE 20,56,32 21,57,33 9,24,15
FACE 9,24,15 21,57,33 22,58,34
FACE 9,24,15 22,58,34 10,28,17
FACE 10,28,17 22,58,34 11,32,19
FACE 22,58,34 23,59,35 11,32,19
FACE 11,32,19 23,59,35 24,60,36
FACE 11,32,19 24,60,36 12,36,21
FACE 12,36,21 24,60,36 13,40,23
FACE 24,60,36 25,61,37 13,40,23
FACE 13,40,23 25,61,37 26,62,38
FACE 13,40,23 26,62,38 14,44,25
FACE 14,44,25 26,62,38 3,48,2
FACE 26,62,38 15,63,27 3,48,2
FACE 15,51,27 27,64,39 16,52,28
FACE 27,64,39 28,65,40 16,52,28
FACE 16,52,28 28,65,40 29,66,41
FACE 16,52,28 29,66,41 17,53,29
FACE 17,53,29 29,66,41 18,54,30
FACE 29,66,41 30,67,42 18,54,30
FACE 18,54,30 30,67,42 31,68,43
FACE 18,54,30 31,68,43 19,55,31
FACE 19,55,31 31,68,43 20,56,32
FACE 31,68,43 32,69,44 20,56,32
FACE 20,56,32 32,69,44 33,70,45
FACE 20,56,32 33,70,45 21,57,33
FACE 21,57,33 33,70,45 22,58,34
FACE 33,70,45 34,71,46 22,58,34
FACE 22,58,34 34,71,46 35,72,47
FACE 22,58,34 35,72,47 23,59,35
FACE 23,59,35 35,72,47 24,60,36
FACE 35,72,47 36,73,48 24,60,36
FACE 24,60,36 36,73,48 37,74,49
FACE 24,60,36 37,74,49 25,61,37
FACE 25,61,37 37,74,49 26,62,38
FACE 37,74,49 38,75,50 26,62,38
FACE 26,62,38 38,75,50 27,76,39
FACE 26,62,38 27,76,39 15,63,27
FACE 27,64,39 39,77,51 40,78,52
FACE 27,64,39 40,78,52 28,65,40
FACE 28,65,40 40,78,52 29,66,41
FACE 40,78,52 41,79,53 29,66,41
FACE 29,66,41 41,79,53 42,80,54
FACE 29,66,41 42,80,54 30,67,42
FACE 30,67,42 42,80,54 31,68,43
FACE 42,80,54 43,81,55 31,68,43
FACE 31,68,43 43,81,55 44,82,56
FACE 31,68,43 44,82,56 32,69,44
FACE 32,69,44 44,82,56 33,70,45
FACE 44,82,56 45,83,57 33,70,45
FACE 33,70,45 45,83,57 46,84,58
FACE 33,70,45 46,84,58 34,71,46
FACE 34,71,46 46,84,58 35,72,47
FACE 46,84,58 47,85,59 35,72,47
FACE 35,72,47 47,85,59 48,86,60
FACE 35,72,47 48,86,60 36,73,48
FACE 36,73,48 48,86,60 37,74,49
FACE 48,86,60 49,87,61 37,74,49
FACE 37,74,49 49,87,61 50,88,62
FACE 37,74,49 50,88,62 38,75,50
FACE 38,75,50 50,88,62 27,76,39
FACE 50,88,62 39,89,51 27,76,39
FACE 39,77,51 51,6,6 40,78,52
FACE 51,6,6 52,5,5 40,78,52
FACE 40,78,52 52,5,5 53,10,8
FACE 40,78,52 53,10,8 41,79,53
FACE 41,79,53 53,10,8 42,80,54
FACE 53,10,8 54,14,10 42,80,54
FACE 42,80,54 54,14,10 55,18,12
FACE 42,80,54 55,18,12 43,81,55
FACE 43,81,55 55,18,12 44,82,56
FACE 55,18,12 56,22,14 44,82,56
FACE 44,82,56 56,22,14 57,26,16
FACE 44,82,56 57,26,16 45,83,57
FACE 45,83,57 57,26,16 46,84,58
FACE 57,26,16 58,30,18 46,84,58
FACE 46,84,58 58,30,18 59,34,20
FACE 46,84,58 59,34,20 47,85,59
FACE 47,85,59 59,34,20 48,86,60
FACE 59,34,20 60,38,22 48,86,60
FACE 48,86,60 60,38,22 61,42,24
FACE 48,86,60 61,42,24 49,87,61
FACE 49,87,61 61,42,24 50,88,62
FACE 61,42,24 62,46,26 50,88,62
FACE 50,88,62 62,46,26 51,50,6
FACE 50,88,62 51,50,6 39,89,51
</code></pre>
","<p>Ok, I solved it...</p>

<p>I simply had to change the code that fills the buffers to this:</p>

<pre><code>    bool isDuplicate;
    indices.clear();
    for(int i = 0; i &lt; polygonCount; i++)
    {
        for(int i2 = 0; i2 &lt; 3; i2++)
        {
            indices.push_back(faceDefinitions[i].vertexIndexes[i2]);
        }
    }

    modelData-&gt;indices = new unsigned long[indices.size()];
    modelData-&gt;indexCount = indices.size();

    for(int i = 0; i &lt; vertexCount; i++)
    {
        modelData-&gt;vertices[i].position = vertexPositions[i];
    }

    for(unsigned long i = 0; i &lt; indices.size(); i++)
    {
        modelData-&gt;indices[i]  = indices[i];
    }
</code></pre>

<p>So it was an indexing error in the end...</p>
","21320"
"how to get width and height of TiledMap in the latest Version of Libgdx","9298","","<p>I am making a tiled based game, I want not to let the camera show places, where there is no map... this is a obvious solution I got from a tutorial </p>

<pre><code>if(camera.position.x&lt;400){
    camera.position.x=400;
}else if(camera.position.x&gt;map.width*map.tileWidth-400){
    camera.position.x=map.width*map.tileWidth-400;
}

if(camera.position.y&lt;240){
    camera.position.y=240;
}else if(camera.position.y&gt;map.height*map.tileHeight-240){
    camera.position.y=map.height*map.tileHeight-240;
}

camera.update();
</code></pre>

<p>but I don't know how to get width &amp; height of the tiledMap in the latest version of libgdx</p>

<p><a href=""https://github.com/libgdx/libgdx/blob/master/gdx/src/com/badlogic/gdx/maps/tiled/TiledMap.java"" rel=""noreferrer"">https://github.com/libgdx/libgdx/blob/master/gdx/src/com/badlogic/gdx/maps/tiled/TiledMap.java</a></p>

<p>Seems strange... I even tried the Super classes but couldn't find. Please help.</p>
","<pre><code>TiledMap tiledMap = new TmxMapLoader().load(""path/to/tiled/map.tmx"");   
MapProperties prop = tiledMap.getProperties();

int mapWidth = prop.get(""width"", Integer.class);
int mapHeight = prop.get(""height"", Integer.class);
int tilePixelWidth = prop.get(""tilewidth"", Integer.class);
int tilePixelHeight = prop.get(""tileheight"", Integer.class);

int mapPixelWidth = mapWidth * tilePixelWidth;
int mapPixelHeight = mapHeight * tilePixelHeight;
</code></pre>

<p>The <code>mapWidth</code> and <code>mapHeight</code> are the dimensions of the map in tiles. So they would both be 10 in a 10x10 grid. The <code>tilePixelWidth</code> and <code>tilePixelHeight</code> are the dimensions of the tiles in pixels. In a 32x32 tileset they would both be 32. Multiplying the dimensions together you will get the map dimensions in pixels.</p>
","57350"
"How to implement SDL Button/Menu GUI with callbacks?","9298","","<p>I have been reading Bjarne Stroustrup's Programming Principles and Practice Using C++ for a while now and am nearing the end of the book. I have to tried to make a very simple game using the SDL libraries as a little exercise to practice programming and utilize techniques from the book. </p>

<p>I've attempted to implement a rather crude GUI system that sort of resembles the one described in the book. The problem that I am having is implementing a callback system so that when a button is constructed it takes a member function as an argument so that it can be called when the button pressed. The reason why it needs to be a member function is that the game has a state system very similar to this <a href=""http://gamedevgeek.com/tutorials/managing-game-states-in-c/"" rel=""nofollow"">http://gamedevgeek.com/tutorials/managing-game-states-in-c/</a> since I followed the tutorial when crafting my own game state system.</p>

<p>The existing code looks like this:</p>

<pre><code>class Button : public Widget {
private:
    SDL_Surface* m_image;
    SDL_Rect* m_clip;
    bool m_pressed;
    bool m_released;
    int frame;
public:
    Button(int x, int y, int w, int h, SDL_Surface* img, SDL_Rect* clip);
    void handle_events(SDL_Event&amp; event);
    void show(SDL_Surface* screen, GameState* state);
    bool released();
};

Button::Button(int x, int y, int w, int h, SDL_Surface* img, SDL_Rect* clip)
   :Widget(x,y,w,h), 
   m_image(img), 
   m_pressed(0), 
   m_released(0),
   m_clip(clip),
   frame(0)
{
}
</code></pre>

<p>So my question is: <em>How do you pass a function in the constructor and call it when the button is pressed?</em> (Like a callback). Currently each state, for example a Menu state, will just look if a button is pressed and perform a corresponding task which is pretty bad and hardly readable.</p>

<p>Stroustrup's code for the GUI system in the PPP book can be found here:
<a href=""http://www.stroustrup.com/Programming/Graphics/"" rel=""nofollow"">http://www.stroustrup.com/Programming/Graphics/</a>
in the two GUI files.</p>

<p>Thanks in advance.</p>
","<p>If you want simple callbacks, you can just use normal C function pointers. You can see here a small tutorial on them: <a href=""http://www.learncpp.com/cpp-tutorial/78-function-pointers/"" rel=""nofollow"">http://www.learncpp.com/cpp-tutorial/78-function-pointers/</a></p>

<p>So, in your case you'd add a parameter like <code>void (*clickedCallback)()</code> in the ctor of the Button. Then, when it is clicked you'd call the function your saved before: <code>m_clickedCallback();</code></p>

<p>Optionally, you might want to send the button which called the callback as argument. The definition/calling will become:</p>

<pre><code>void (*m_clickedCallback)(const Button&amp;);
// ...
m_clickedCallback(*this); 
</code></pre>

<p>LE: On a second read, it seems you might want a member function (not a simple one). That is slightly more complicated, because you'd have to pass the <strong>object</strong> instance around when you want to call its method. More info on this topic you can find on Parashift's superb website: <a href=""http://www.parashift.com/c++-faq/pointers-to-members.html"" rel=""nofollow"">http://www.parashift.com/c++-faq/pointers-to-members.html</a>. </p>

<p>Basically you'd need some sort of wrapper/struct that holds both the function to a member (similarly to the C one, but with the class specified) and the member instance where to call the callback function on.</p>
","56372"
"How do I properly implement zooming in my game?","9277","","<p>I'm trying to implement a zoom feature but I have a problem. I am zooming in and out a camera with a pinch gesture, I update the camera each time in the render, but my sprites keep their original position and don't change with the zoom in or zoom out.</p>

<p>The Libraries are from libgdx.</p>

<p>What am I missing?</p>

<pre><code>private void zoomIn()
{
    ((OrthographicCamera)this.stage.getCamera()).zoom += .01;
}

public boolean pinch(Vector2 arg0, Vector2 arg1, Vector2 arg2, Vector2 arg3) 
{
    // TODO Auto-generated method stub
    zoomIn();
    return false;
}

public void render(float arg0) 
{
    this.gl.glClear(GL10.GL_DEPTH_BUFFER_BIT | GL10.GL_COLOR_BUFFER_BIT);
    ((OrthographicCamera)this.stage.getCamera()).update();
    this.stage.draw();  
}

public boolean touchDown(int arg0, int arg1, int arg2) 
{
    this.stage.toStageCoordinates(arg0, arg1, point);
    Actor actor = this.stage.hit(point.x, point.y);

    if(actor instanceof Group)
    {
        ((LevelSelect)((Group) actor).getActors().get(0)).touched();
    }

    return true;
}
</code></pre>

<p><strong>Zoom In</strong>
<img src=""https://i.stack.imgur.com/ix2e5.jpg"" alt=""Zoom In""></p>

<p><strong>Zoom Out</strong>
<img src=""https://i.stack.imgur.com/JmZu4.jpg"" alt=""Zoom Out""></p>
","<p>My best guess is that your sprites reside in the same world space as the camera does while your hit boxes (collision rects) reside in screen space. Your world space sprites are affected by the camera's zoom but screen space collision boxes are not.</p>

<p>Your best shot it to quantify your collision boxes in world space like your sprites are instead of screen space and then you will not have this problem.</p>
","26516"
"How can I generate a 2d navigation mesh in a dynamic environment at runtime?","9277","","<p>So I've grasped how to use A* for path-finding, and I am able to use it on a grid.  However, my game world is huge and I have many enemies moving toward the player, which is a moving target, so a grid system is too slow for path-finding.  I need to simplify my node graph by using a navigational mesh.</p>

<p>I grasp the concept of ""how"" a mesh works (finding a path through nodes on the vertices and/or the centers of the edges of polygons).</p>

<p>My game uses dynamic obstacles that are procedurally generated at run-time.</p>

<p>I can't quite wrap my head around how to take a plane that has multiple obstacles in it and programatically divide the walkable area up into polygons for the navigation mesh, like the following image.</p>

<p><img src=""https://i.stack.imgur.com/heCYy.png"" alt=""navigational mesh""></p>

<p>Where do I start?  How do I know when a segment of walk-able area is already defined, or worse, when I realize I need to subdivide a previously defined walk-able area as the algorithm ""walks"" through the map?</p>

<p>I'm using javascript in nodejs, if it matters.</p>
","<p><em>@Stephen</em>  - <em>Long Comment</em> - That paper looks like it might be worth a read when I have some time. Basically what I would have suggested is something along the lines of the Hertel-Mehlhorn Algorithm which is mentioned in the paper (a reference for this specific algorithm can be found here <a href=""http://www.bringyou.to/compgeom/"" rel=""nofollow"">http://www.bringyou.to/compgeom/</a>) with the addition of subdividing the map sides (outside boundary of the play area) some number of time to reduce the occurrences of multiple small triangles formed in the corners. Those small triangles can be problematic as they can end up being smaller than the thing you’re preforming path-finding for. The Hertel-Mehlhorn is for the reduction of the polygons produced by a triangular partitioning if you’re interested here is more on triangulation: <a href=""http://www.personal.kent.edu/~rmuhamma/Compgeometry/MyCG/PolyPart/polyPartition.htm"" rel=""nofollow"">http://www.personal.kent.edu/~rmuhamma/Compgeometry/MyCG/PolyPart/polyPartition.htm</a>. </p>

<p>Also, if you’d rather not reinvent the wheel, I think this library will actually do everything you need: <a href=""http://code.google.com/p/polypartition/"" rel=""nofollow"">http://code.google.com/p/polypartition/</a>. It preforms the triangulations and reductions with one of a number of different options including Hertel-Mehlhorn. It’s an MIT License which means it can be used for closed-source and commercial projects if that is an issue. </p>

<p>If you do decide to keep working on your own implementation, I’d love to see what you come up with.</p>
","31828"
"How to solve ArrayList outOfBoundsExeption?","9273","","<p>I'm getting:</p>

<pre><code>    09-02 17:15:39.140: E/AndroidRuntime(533): java.lang.IndexOutOfBoundsException: Invalid index 1, size is 1
    09-02 17:15:39.140: E/AndroidRuntime(533):  at java.util.ArrayList.throwIndexOutOfBoundsException(ArrayList.java:251)
</code></pre>

<p>when I'm killing enemies using this method:</p>

<pre><code>    private void checkCollision() {
    Rect h1 = happy.getBounds();
    for (int i = 0; i &lt; enemies.size(); i++) {
        for (int j = 0; j &lt; bullets.size(); j++) {
            Rect b1 = bullets.get(j).getBounds();
            Rect e1 = enemies.get(i).getBounds();
            if (b1.intersect(e1)) {
                enemies.get(i).damageHP(5);
                bullets.remove(j);
                Log.d(""TAG"", ""HERE: LOLTHEYTOUCHED"");
            }
            if (h1.intersect(e1)){
                happy.damageHP(5);
            }
            if(enemies.get(i).getHP() &lt;= 0){
                enemies.remove(i);
            }
            if(happy.getHP() &lt;= 0){
                //end-screen                           !!!!!!!
            }
        }
    }
}
</code></pre>

<p>using this ArrayList:</p>

<pre><code>        private ArrayList&lt;Enemy&gt; enemies = new ArrayList&lt;Enemy&gt;();
</code></pre>

<p>and adding to array like this:</p>

<pre><code>   public void createEnemies() {
    Bitmap bmp = BitmapFactory.decodeResource(getResources(),
            R.drawable.female);
    if (enemyCounter &lt; 24) {
        enemies.add(new Enemy(bmp, this, controls));
    }
    enemyCounter++;
}
</code></pre>

<p>I don't really understand what the problem is, I've been looking around for a while but can't really find anything that helps me. If you know or if you can link me someplace where they have a solution for a similar problem I'll be a very happy camper!</p>
","<p>The problem is the removal of elements from the <code>enemies</code> list. If the condition <code>enemies.get(i).getHP() &lt;= 0</code> becomes true for an enemy object it may remove more than the intended object since your inner loop will continue to run.
The fix is to break out of the inner loop and start checking the next enemy object:</p>

<pre><code>if(enemies.get(i).getHP() &lt;= 0){
    enemies.remove(i);
    break;
}
</code></pre>
","35441"
"How can I create animated card graphics like in Hearthstone?","9269","","<p>In the game Hearthstone, there are cards with animated images on them. A few examples:</p>

<ol>
<li><a href=""http://www.hearthhead.com/card=281/argent-commander"">http://www.hearthhead.com/card=281/argent-commander</a></li>
<li><a href=""http://www.hearthhead.com/card=469/blood-imp"">http://www.hearthhead.com/card=469/blood-imp</a></li>
</ol>

<p>The animations seem to be composed of multiple effects:</p>

<ul>
<li>Particle systems.</li>
<li>Fading sprites in and out/rotating them</li>
<li>Simple scrolling textures</li>
<li>A distortion effect, very evident in the cape and hair of example 1.</li>
<li>Swirling smoke effects, the light in example 1 and the green/purple glow in example 2.</li>
</ul>

<p>The first three elements are trivial, what I'd like to know is how the last two could be done. Can this even be done realtime in a game, or are they pre-rendered animations?</p>
","<p>I don't know if its relevant any more, But Doug answer's got it right</p>

<p>I just wanted to add that I myself managed to recreate the animations exactly as they are built in the game it self using the same assets, take a look here</p>

<p><a href=""http://hearthforge.co.nf/magni/"" rel=""noreferrer"">Magni</a>:</p>

<pre><code>precision highp float;

uniform float uTime;
uniform sampler2D uSampler0;
uniform sampler2D uSampler1;
uniform sampler2D uSampler2;
uniform sampler2D uSampler3;
uniform sampler2D uSampler4;
uniform sampler2D uSampler5;
varying vec2 texCoords;

void main(void) {
  float t = uTime;
  vec3 mask = texture2D(uSampler1,texCoords).rgb;
  vec4 img = texture2D(uSampler0,texCoords);
  img.rg*=1.1;
  vec2 flow = texture2D(uSampler3,texCoords).gr;
  flow.y+=t*3.;
  vec4 plas = texture2D(uSampler2,flow*1.2) * mask.r;
  plas *= 15.5;
  plas *= vec4(0.239, 0.224,0.488,1.);
  vec2 ct = texCoords;
  ct.y -=t*0.5;
  vec4 clouds = texture2D(uSampler4,ct*2.);
  float clouds_a = clouds.a;
  clouds *= 4.5;
  clouds *= vec4(0.275,0.23,0.161,1.);
  clouds_a *= mask.b;
  img += clouds * mask.b;
  img += plas * mask.r ;
  img += (sin(t*15.)+1.) * mask.g * vec4(0.239, 0.224,0.488,1.)*2.;
  ct.x += t * 0.5;
  vec4 clouds_overall = texture2D(uSampler5,ct  * 0.5);
  clouds_overall *= vec4(0.275,0.23,0.161,1.);
  gl_FragColor = img +clouds_overall;
}
</code></pre>

<p><a href=""http://hearthforge.co.nf/medivh/"" rel=""noreferrer"">Medivh</a>: <br /></p>

<pre><code>precision highp float;

uniform float uTime;
uniform sampler2D uSampler0;
uniform sampler2D uSampler1;
uniform sampler2D uSampler2;
uniform sampler2D uSampler3;
uniform sampler2D uSampler4;
uniform sampler2D uSampler5;
varying vec2 texCoords;

void main(void) {
  float t = uTime;
  vec2 tc = texCoords;
  tc.x-=t*2.;
  vec4 mask = texture2D(uSampler1,texCoords);
  float bump = texture2D(uSampler4,tc*0.5).r; 
  vec4 img = texture2D(uSampler0,vec2(texCoords.x,texCoords.y+bump* 0.055 * mask.g));
  tc = texCoords;
  tc.x-=0.05;
  tc.y+= 0.05;
  vec2 flow = texture2D(uSampler3,tc).rg;
  flow.y+=t;
  flow.y*=2.;
  vec4 plasma = texture2D(uSampler2,flow*1.5);
  plasma.rgb *= vec3(0.52,0.26,0.54);
  plasma *= 3.;
  flow = texture2D(uSampler5,texCoords).rg;
  flow.g+=t;
  vec4 plasma2 = texture2D(uSampler2,flow);
  plasma2 *= 4.;
  plasma2.rgb *= vec3(0.52,0.26,0.54);
  gl_FragColor =img+plasma*mask.r+bump*mask.a*0.35+plasma2*mask.b;
}
</code></pre>
","104330"
"Clickable hex grid in c#.net","9268","","<p>I want to create a Windows Form-based adventure game where the player clicks a hex on a static map to bring up their next encounter. I have the map already and plan to scan it and convert it to a .bmp file. My problem is that I'm not sure how to tie the map image in with the game code. Unless I'm mistaken, I think I need to use some kind of imagemap control. If that's the case, do I need to plot each hex individually, or is there a way to plot the whole map in bulk? I found <a href=""http://www.gamedev.net/reference/articles/article1800.asp"">this</a> article, but I'm not sure if it's relevant to what I want to do or not. I'm just looking for general information or links to relevant articles. Thanks.</p>
","<p>I really like <a href=""http://www-cs-students.stanford.edu/~amitp/gameprog.html"">Amit's Game Programming Information</a>, and it has a whole section on <a href=""http://www-cs-students.stanford.edu/~amitp/gameprog.html#hex"">hexagon grids</a>. Perhaps you'd find any of those links to be informative?</p>

<p>Here is the list of links he gives:</p>

<blockquote>
  <ul>
  <li><a href=""http://www-cs-students.stanford.edu/~amitp/game-programming/grids/"">Amit’s Thoughts on Grids</a> includes squares, hexagons, and triangles</li>
  <li><a href=""http://sc.tri-bit.com/Hex_Grids"">Overview of hex grid coordinates</a></li>
  <li><a href=""http://www.gamedev.net/reference/articles/article1800.asp"">Hexagonal coordinates explained</a>, including hex/pixel coordinate conversion</li>
  <li><a href=""http://www-cs-students.stanford.edu/~amitp/Articles/Hexagon1.html"">Numbering Systems; Distances; Angles</a></li>
  <li><a href=""http://www-cs-students.stanford.edu/~amitp/Articles/Hexagon2.html"">Isometric Cube Coordinates</a></li>
  <li><a href=""http://www.webwargaming.com/hexpart/hexpart.html"">The HexPart numbering system</a> with algorithms for range, bearing, offset, and line of sight</li>
  <li><a href=""http://playtechs.blogspot.com/2007/04/hex-grids.html"">Comparison of Hexagonal coordinate systems</a>, including pixel to hex coordinates, and hex distances</li>
  <li><a href=""http://www-cs-students.stanford.edu/~amitp/Articles/GridToHex.html"">Pixel Location to Hex Coordinates</a></li>
  <li><a href=""http://www-cs-students.stanford.edu/~amitp/Articles/HexLOS.html"">Line of Sight and Distance</a>, plus <a href=""http://www.sable.mcgill.ca/~clump/Hex/HGAT.html"">a Java applet demonstrating field of view</a></li>
  <li><a href=""http://blog.devstone.com/aaron/archive/2004/04/18/152.aspx"">Pixel coordinate to hex coordinates</a></li>
  <li><a href=""http://web.archive.org/web/20080223153151/http://www.drking.plus.com/hexagons/misc/grid.html"">Distances in a Hexagonal Grid</a></li>
  <li><a href=""http://www-cs-students.stanford.edu/~amitp/Articles/Identifying-directions-from-a-central-hex.pdf"">Identifying directions in a hex grid</a> [PDF]</li>
  <li><a href=""http://jmz.iki.fi/blog/programming/hexagonal_maps"">Coordinate system that makes distances easy</a></li>
  <li><a href=""http://cell-auto.com/neighbourhood/"">Grids used in Cellular Automata</a></li>
  <li><a href=""http://www.sable.mcgill.ca/~clump/Hex/HGAT.html"">Computing Field of View on a Hexagonal Grid</a> (source code and Java applet)</li>
  </ul>
</blockquote>

<p>I apologize if this isn't helpful. Windows Form isn't the ideal platform to develop a game, but I assume you would have one image per grid square and give it an OnClick event. There would be the issue of overlapping corners though... (the transparent corners of the square image that the grid image is on). In a traditional game you would use the above information to figure out how to translate click coordinates (screen space) to the hexagonal grid coordinates (which your link details nicely), and then handle it appropriately.</p>
","2342"
"Maya 3D model to iOS OpenGL ES","9261","","<p>I need to display, rotate, and zoom a 3D model in OpenGL ES (iPhone/iPad).  The 3D graphic artists are using Maya (on OS/X).  What export format should I be looking at to use their 3D models in the app?</p>

<p>Also, a number of Maya plug-ins don't work on the Mac (apparently it doesn't handle plug-ins the same way as Windows and Linux), so I may need an external tool to handle the conversion.</p>

<p>I'm still learning my way around the 3D dev-world, so any advice is appreciated.</p>

<p>Thanks!</p>
","<p>One thing to know about OpenGL is that it doesn't have native model loaders. That is, there is no glLoadModel() function or similar. Instead, you must either use an existing loader that converts the coords into something OpenGL can read. It doesn't really matter what you use as a format, but .obj is probably the simplest and most popular to go with.</p>

<p><a href=""http://iphonedevelopment.blogspot.com/2009/03/wavefront-obj-loader-open-sourced-to.html"" rel=""nofollow"">The wavefront .obj loader</a>  </p>
","6277"
"Balancing Player vs. Monsters: Level-Up Curves","9259","","<p>I've written a fair number of games that have RPG-like ""levelling up,"" where the player gains experience for killing monsters/enemies, and eventually, reaches a new level, where their stats increase.</p>

<p><strong>How do you find a balance between player growth, monster strength, and difficulty?</strong> The extreme ends of this spectrum are:</p>

<ul>
<li>Player levels up really fast and blows away monsters without much effort</li>
<li>Monsters are incredibly strong and even at low levels, are very difficult to beat</li>
</ul>

<p>I've also tried a strange situation of making enemies relative to players, i.e. an enemy will always be at 50% or 100% or 150% of player stats (thus requiring the player to use other techniques instead of brute strength to succeeed).</p>

<p>But where's the balance, and how do you find it?</p>

<p><strong>Edit:</strong> For example, I am expecting to hear things like:</p>

<ul>
<li>Balance high instead of balance low (200 HP and 20 str is easier to balance than 20 HP and 2 str)</li>
<li>Look at easiest vs. hardest monsters, and see what you have in terms of a range</li>
</ul>
","<p>Playtest. No, really, just playtest your balance until you get it right, or rather mostly right (there's no such thing as perfect balance).</p>

<p>Write automated tests and run them hundreds of times. Even very simple automated tests, like ""level 2 player always hits with shortsword, goblin always hits with club, player should win"" can really help, if you run these tests often (generally, whenever you change anything). 
Also, test balance by playing. Whenever you find some new potentially balance-changing tactic, write an automated test for it.</p>
","10701"
"What do these STATE_CREATION warnings mean in the DX11 debug output?","9258","","<p>So I've been fighting my way through learning the DirectX 11 API with what little documentation there is out there and noticed some new D3D11 warnings in my debug output. (Atleast I think they are new, been rearranging my draw calls to try and solve another problem I'm experiencing at the moment) Anywho, with some Google-fu I've been unable to find any documentation on the error codes or anything but the general consensus of forums seems to be that the COM objects aren't properly being released.</p>

<p>Now the question is, if that is indeed what the warnings mean, what else do I need to do to kill these things other then call their Release() functions? And is there somewhere this kind of information is posted? I sure can't find it on MSDN or Google. Just lots of confused DX11 post with unanswered questions.</p>

<p>Here is the debug output.</p>

<pre><code>D3D11: WARNING: Live Device: Name=""unnamed"", Addr=0x004C6488, ExtRef=5 [ STATE_CREATION WARNING #2097297: LIVE_DEVICE ]
D3D11: WARNING: Live Texture2D: Name=""unnamed"", Addr=0x04552E94, ExtRef=0, IntRef=1 [ STATE_CREATION WARNING #2097235: LIVE_TEXTURE2D ]
D3D11: WARNING: Live Buffer: Name=""unnamed"", Addr=0x04552A64, ExtRef=1, IntRef=0 [ STATE_CREATION WARNING #2097229: LIVE_BUFFER ]
D3D11: WARNING: Live Buffer: Name=""unnamed"", Addr=0x04566ECC, ExtRef=1, IntRef=0 [ STATE_CREATION WARNING #2097229: LIVE_BUFFER ]
D3D11: WARNING: Live InputLayout: Name=""unnamed"", Addr=0x0455280C, ExtRef=1, IntRef=0 [ STATE_CREATION WARNING #2097265: LIVE_INPUTLAYOUT ]
D3D11: WARNING: Live PixelShader: Name=""unnamed"", Addr=0x004CDDE4, ExtRef=1, IntRef=0 [ STATE_CREATION WARNING #2097262: LIVE_PIXELSHADER ]
D3D11: WARNING: Live VertexShader: Name=""unnamed"", Addr=0x04553944, ExtRef=1, IntRef=0 [ STATE_CREATION WARNING #2097250: LIVE_VERTEXSHADER ]
D3D11: WARNING: Live RenderTargetView: Name=""unnamed"", Addr=0x0455269C, ExtRef=0, IntRef=0 [ STATE_CREATION WARNING #2097244: LIVE_RENDERTARGETVIEW ]
D3D11: WARNING: Live Texture2D: Name=""unnamed"", Addr=0x04552214, ExtRef=4294967295, IntRef=1 [ STATE_CREATION WARNING #2097235: LIVE_TEXTURE2D ]
D3D11: WARNING: Live Query: Name=""unnamed"", Addr=0x004C84AC, ExtRef=0, IntRef=1 [ STATE_CREATION WARNING #2097280: LIVE_QUERY ]
D3D11: WARNING: Live Sampler: Name=""unnamed"", Addr=0x004C8274, ExtRef=0, IntRef=1 [ STATE_CREATION WARNING #2097268: LIVE_SAMPLER ]
D3D11: WARNING: Live RasterizerState: Name=""unnamed"", Addr=0x004C804C, ExtRef=0, IntRef=1 [ STATE_CREATION WARNING #2097277: LIVE_RASTERIZERSTATE ]
D3D11: WARNING: Live DepthStencilState: Name=""unnamed"", Addr=0x004C7E24, ExtRef=0, IntRef=1 [ STATE_CREATION WARNING #2097274: LIVE_DEPTHSTENCILSTATE ]
D3D11: WARNING: Live BlendState: Name=""unnamed"", Addr=0x004C7C6C, ExtRef=0, IntRef=1 [ STATE_CREATION WARNING #2097271: LIVE_BLENDSTATE ]
D3D11: WARNING: Live Context: Name=""unnamed"", Addr=0x0453006C, ExtRef=0, IntRef=1 [ STATE_CREATION WARNING #2097226: LIVE_CONTEXT ]
D3D11: WARNING: Live Device Child Summary: Device Addr=0x004C6488
Using ID3D11Debug::ReportLiveDeviceObjects with D3D11_RLDO_DETAIL will help drill into object lifetimes. Objects with ExtRef=0 and IntRef=0 will be eventually destroyed through typical Immediate Context usage. However, if the application requires these objects to be destroyed sooner, ClearState followed by Flush on the Immediate Context will realize their destruction.
</code></pre>

<p>Note: Clearing and Flushing the device context doesn't seem to affect anything.</p>

<p>Thanks in advance!</p>

<p><strong>Solution</strong></p>

<p>A slight tweak in my code prevented objects from being shut down and releasing their COM objects.</p>
","<p>The warnings are informing you of live (unreleased) objects, as you've discovered. Releasing the objects you retain references to is the proper way to clean them up, but you have to release the right objects. There are several ways you can get help tracking down which objects are being retained and from there you can follow the lifetime of those objects through your code and determine where you are missing calls to decrement the COM reference count.</p>

<p>The first thing to do is look at the <code>ExtRef</code> and <code>IntRef</code> columns. <code>IntRef</code> refers to the number of internal references to the object, within D3D itself. These aren't your responsibility to free, but they are an indicator that you're probably holding an external reference to something that is itself holding an <em>internal</em> reference to those objects. </p>

<p>The <code>ExtRef</code> column indicates the number of references that your holding. In this case, you appear to have five outstanding references to the D3D device itself, and the device is probably holding references to all the objects with internal reference counts, leaking them. Tracking down where you need to add additional calls to <code>Release</code> on your device will probably solve most of your problems. You also appear to have outstanding references to some shader and buffer objects.</p>

<p>You can also, as the last line of the output suggests, use the <a href=""http://msdn.microsoft.com/en-us/library/ff476366%28v=vs.85%29.aspx"">ID3D11Debug interface</a>'s <a href=""http://msdn.microsoft.com/en-us/library/ff476370%28v=vs.85%29.aspx"">ReportLiveDeviceObjects</a> method to get more information on where these objects are coming from and what might be holding on to a reference to them. </p>

<p>Finally, take a look at <a href=""http://blogs.msdn.com/b/chuckw/archive/2010/04/15/object-naming.aspx"">this post</a> by Chuck Walbourn which details giving your objects unique names to replace the ""unnamed"" strings in the output, which may also help narrow down the problem.</p>

<p>Without code -- and I presume you have too much of it to reasonably post here -- it's hard to provide more specific direction, unfortunately.</p>

<p>Two other notes:</p>

<ul>
<li>The message's talk of clearing and flushing refers to objects with zero internal <em>and</em> external references -- most of the objects in your report wouldn't be cleaned up by doing that, as you've discovered.</li>
<li>""STATE_CREATION"" is one of the predefined message categories used by the <a href=""http://msdn.microsoft.com/en-us/library/ff476538%28v=VS.85%29.aspx"">D3D11 InfoQueue</a> class. I don't know for sure why this category is used for leak messages instead of the seemingly more appropriate ""CLEANUP"" category; I suspect it's a bug.</li>
</ul>
","14635"
"How to avoid the GameManager god object?","9254","","<p>I just read <a href=""https://gamedev.stackexchange.com/a/27448/14808"">an answer to a question about structuring game code</a>. It made me wonder about the ubiquitous <code>GameManager</code> class, and how it often becomes an issue in a production environment. Let me describe this.</p>

<p>First, there's prototyping. Nobody cares about writing great code, we just try to get something running to see if the gameplay adds up.</p>

<p>Then there's a greenlight, and in an effort to clean things up, somebody writes a <code>GameManager</code>. Probably to hold a bunch of <code>GameStates</code>, maybe to store a few <code>GameObjects</code>, nothing big, really. A cute, little, manager.</p>

<p>In the peaceful realm of pre-production, the game is shaping up nicely. Coders have proper nights of sleep and plenty of ideas to architecture the thing with Great Design Patterns.</p>

<p>Then production starts and soon, of course, there is crunch time. Balanced diet is long gone, the bug tracker is cracking with issues, people are stressed and the game has to be released yesterday.</p>

<p>At that point, usually, the <code>GameManager</code> is a <em>real big</em> mess (to stay polite).</p>

<p>The reason for that is simple. After all, when writing a game, well... all the source code is actually here to <em>manage</em> the <em>game</em>. It's easy to just add this little extra feature or bugfix in the <code>GameManager</code>, where everything else is already stored anyway. When time becomes an issue, no way to write a separate class, or to split this giant manager into sub-managers.</p>

<p>Of course this is a classical anti-pattern: the <a href=""http://en.wikipedia.org/wiki/God_object"" rel=""nofollow noreferrer"">god object</a>. It's a bad thing, a pain to merge, a pain to maintain, a pain to understand, a pain to transform.</p>

<p>What would you suggest to prevent this from happening?</p>

<p><strong>EDIT</strong></p>

<p>I know it's tempting to blame the naming. Of course creating a <code>GameManager</code> class ain't such a great idea. But the same thing can happen to a clean <code>GameApplication</code> or <code>GameStateMachine</code> or <code>GameSystem</code> that ends up being the duct-tape-favorite by the end of a project. No matter the naming, you have that class somewhere in your game code, it's just an embryo for now: you just don't know yet what monster it will become. So I'm not expecting ""blame the naming"" answers. I want a way to prevent this from happening, a coding architure and/or a process a team can follow knowing that this will happen at some point in production. It's just too bad to throw away say, one month of bugfixes and last-minute features, just because all of them are now in one huge unmaintainable manager.</p>
","<blockquote>
  <p>Then there's a greenlight, and in an effort to clean things up, somebody writes a GameManager. Probably to hold a bunch of GameStates, maybe to store a few GameObjects, nothing big, really. A cute, little, manager.</p>
</blockquote>

<p>You know, as I was reading this, I had little alarms going off in my head.  An object with the name ""GameManager"" is never going to be cute, or little.  And someone did this to clean up the code?  What did it look like before?  OK, jokes aside: a class's name should be a clear indication of what the class does, and this should be one thing (aka: <a href=""http://en.wikipedia.org/wiki/Single_responsibility_principle"" rel=""nofollow noreferrer"">single responsibility principle</a>).</p>

<p>Also, you may still end up with an object like GameManager, but clearly, it exists at a very high level, and it should concern itself with high level tasks.  Maintaining a catalogue of game objects?  Perhaps.  Facilitating communication between game objects?  Sure.  Calculating collisions between objects?  No!  This is also why the name <em>Manager</em> is frowned upon - it's too broad, and allows for much abuse under that banner.</p>

<p>A quick rule of thumb on class sizes:  if you are running into several hundred lines of code per class, something is starting to go wrong.  Without being overzealous, anything over, say, 300 LOC is a code smell to me, and if you are going over 1000, warning bells should be going off.  By believing that somehow that 1000 lines of code is simpler to understand than 4 well structured classes of 250 each, you are deluding yourself.</p>

<blockquote>
  <p>When time becomes an issue, no way to write a separate class, or to split this giant manager into sub-managers.</p>
</blockquote>

<p>I think this is the case only because the problem is allowed to propagate to the point where everything is a complete mess.  The practice of <a href=""http://en.wikipedia.org/wiki/Code_refactoring"" rel=""nofollow noreferrer"">refactoring</a> is really what you are looking for - <strong>you need to continuously improve the design of the code in tiny increments</strong>.</p>

<blockquote>
  <p>What would you suggest to prevent this from happening?</p>
</blockquote>

<p>The problem isn't a technological one, so you shouldn't look for technological fixes for it.  The problem is this:  there is a tendency in your team to create monolithic pieces of code, and the belief that it's somehow beneficial in the medium / long term to work like this.  It also seems that the team is lacking a strong architectural lead, who would steer the architecture of the game (or at least, this person is too busy to perform this task).  Basically, the only way out is to have team members recognise that this thinking is wrong.  It does nobody favours.  The quality of the product will worsen, and the team will only spend even more nights fixing things.  </p>

<p>The good news is that the immediate, tangible benefits of writing clean code are so great, that almost all developers realise their benefits very quickly.  Convince the team to work this way for a while, the results will do the rest.</p>

<p>The difficult part is that developing a feel for what constitutes bad code (and a talent for quickly coming up with a better design) is one of the more difficult skills to learn in development.  My suggestion hinges around the hope that you have someone senior enough in the team who can do this - it is much easier to convince people that way.</p>

<p>Edit - A bit more info:</p>

<p>In general, I don't think your problem is limited to game development.  At its core, it's  a software engineering problem, hence my comments in that direction.  What may be different is the nature of the game development industry, whether its more results and deadline oriented than other types of development, I am not sure.</p>

<p>Specifically for game development though, the accepted answer to <a href=""https://stackoverflow.com/questions/1201361/3d-game-development-tips-especially-game-architecture"">this question</a> on StackOverflow regarding ""especially game architecture"" tips, says:</p>

<blockquote>
  <p>Follow the <a href=""http://www.butunclebob.com/ArticleS.UncleBob.PrinciplesOfOod"" rel=""nofollow noreferrer"">Solid principles of object oriented design</a>....</p>
</blockquote>

<p>This is essentially exactly what I am saying.  When I'm under pressure, I also find myself writing large pieces of code, but I've drilled it into my head that that is technical debt.  What tends to work well for me, is to spend the first half (or three-quarters) of the day producing a large amount of medium-quality code, and then to take a sit back, and think about it for a while; do a bit of design in my head, or on paper / whiteboard, about how to improve the code a bit.  Often, I notice repetitive code, and am able to actually reduce the total lines of code by breaking things up, all the while improving readability.  This time invested pays for itself so quickly, that calling it an ""investment"" sounds silly - quite often I'll pick up bugs that might have wasted half my day (a week later), had I allowed it to go on.  What I am saying is very simply:</p>

<ul>
<li>Fix things on the same day you code them.</li>
<li>You will be glad you did within hours.</li>
</ul>

<p>Coming to actually believe the above is difficult; I've managed to do it for my own work only because I've experienced, over and over again, the effects.  Even so, it's still difficult for me to justify fixing up code when I could be churning out more...  So I definitely understand where you're coming from.  Unfortunately, this advice is perhaps too generic, and not easy to do.  I strongly believe in it, however! :)</p>

<p>To answer your specific example:</p>

<p>Uncle Bob's <a href=""http://rads.stackoverflow.com/amzn/click/0132350882"" rel=""nofollow noreferrer"">Clean Code</a> does an amazing job of summarising what good quality code is like.  I happen to agree with almost all of its contents.  So, when I think of your example of a 30 000 LOC manager class, I can't really agree with the ""good reason"" part.  I don't want to sound offensive, but thinking that way will lead to the problem.  There is no good reason for having that much code in a single file - it's almost 1000 pages of text!  Any benefit of locality (execution speed, or design ""simplicity"") will immediately be nullified by the developers being completely bogged down trying to navigate that monstrosity, and that's even before we discuss merging, etc.</p>

<p>If you aren't convinced, my best suggestion would be to grab a copy of the above book, and have a look through it.  Applying that type of thinking to leads to people voluntarily creating clean, self-explanatory code, which is nicely structured.</p>
","27493"
"How do I start writing an MMO game server?","9254","","<p>I am developing a multi-player on-line game.</p>

<p>I just started coding the server but I have no idea how to do it. Do I have to use threads ?</p>

<p>And if i do, do I need one thread for every client?</p>

<p>Knowing that I am using UDP, can I use multiple sockets in different threads to send packets on the same port?</p>

<p>edit:</p>

<pre><code>server does:

-listen for client connections

-when a client connects:

    -update files (send new files to the client)

    -retrieve data from database

    -loop to retrieve and update live data

-when client disconnects:

    -update data in database
</code></pre>
","<p>I may be wrong, but your question makes it seem like you are missing a lot of knowledge in order to successfully write an MMO server. I know this message will likely fall on deaf ears because I was in your position when I started programming.</p>

<p><strong>My answer:</strong>
If I were you I would start smaller. If you want to learn to write an MMO server I would do the following.</p>

<ul>
<li>Write a TCP based p2p chat client. </li>
<li>Extend that chat client to work with NAT routers</li>
<li>Extend the chat client to have a central server that authenticates and stores message history</li>
<li>Extend it to have a secure handshake with the server to verify the client software and server software/location</li>
<li>Write a high level architecture of what you would want your MMO server to be</li>
<li>Read some articles on MMO server architectures</li>
<li>Start expanding your high level architecture into more and more detail</li>
<li>Write essential user stories for your architecture</li>
<li>start implementing your server</li>
</ul>

<p><strong>The answer you probably want:</strong></p>

<ul>
<li>Write a thread for the listener to accept incoming connections using TCP</li>
<li>Once the player is connected, use TCP for chat messages and sector changes</li>
<li>Use UDP for in-sector movement</li>
<li>Each connection gets its own thread for the messaging</li>
<li>UDP can be implemented with threads (if you really want) but I would probably use some sort of queue on one thread that accepts movement messages. Or spread it out depending on how many connections you get.</li>
</ul>
","21598"
"Simple 2D Collision Detection Algorithm Library","9253","","<p>I'm building a simple OpenGL game and I was looking for some simple collision detection library for objects like squares, triangles and circles. Any suggestions?</p>

<p><em>PS: Preferably a library that is very well documented and provide examples of 2D collision detections.</em></p>
","<p><a href=""http://box2d.org/"">Box2D</a> is very popular and well <a href=""http://code.google.com/p/box2d/wiki/FAQ"">documented</a> with lots of examples. Of course it's a full on physics library so it'll give you a good amount of flexibility for expanding later if you want. But you don't need to use those features if you don't want them.</p>

<p>For learning more about the algorithms and how to implement them yourself you can check <a href=""http://www.gamespp.com/algorithms/collisiondetection/"">this</a> out.</p>

<p>Additionally <a href=""http://www.realtimerendering.com/intersections.html"">this</a> is a nice resource for showing how to detect intersections between various shapes. Which plays an important role in collision detection.</p>
","33535"
"Difference between Update method and FixedUpdate in Unity?","9244","","<p>i am starting to learn Unity3d and one of the confusion i get is difference between <code>Update()</code> and <code>FixedUpdate()</code>. </p>

<p>I am following Lynda Unity 2D game development tutorial there, the instructor uses <code>Update</code> method, the player has RigidBody2D component and Box collider, he uses the <code>Update</code> method to translate the player, but when i do same in <code>Update</code> the player doesn't move but when i do it in <code>FixedUpdate</code>, everything works. He is giving tutorial from Unity 4.3 and i am taking the course in Unity 4.6. </p>

<p>Where should i use <code>Update</code> and <code>FixedUpdate</code>?</p>
","<p>I was going to write this as a comment, but it ended up being rather long winded so I've turned it into an answer.</p>

<p>The current answers are mostly correct, but a few things mentioned are misleading/wrong. </p>

<p>In general, <em>most</em> game-play related tasks will go in <code>Update</code>.</p>

<p>For example, you don't want to be polling for input in <code>FixedUpdate</code> (not because of performance, but because the calls simply won't work correctly). AI falls in the same boat. </p>

<p><em>Continuously</em> updated physics are the <em>only</em> gameplay related task that <code>FixedUpdate</code> should be used for. <em>Non-continuous/once-in-a-while</em> calls to things like <code>Physics.Raycast</code>, or even <code>Rigidbody.AddForce</code> belong in <code>Update</code>. My mention of <code>Rigidbody.AddForce</code> is seemingly contrary to what might be implied by the documentation, but the key is Continuous vs Non-continuous.</p>

<p>One huge reason why only continuous physics belong in <code>FixedUpdate</code> is the actual nature of <code>FixedUpdate</code>. Other answers have mentioned how FixedUpdate is called at a fixed <code>interval, but that's slightly misleading. In reality, a script is passed a time in Time.deltaTime</code>/<code>Time.fixedDeltaTime</code>* which doesn't correspond directly to the actual time between calls, but rather the <em>simulated</em> time between calls. </p>

<p>(*<code>Time.deltaTime</code> and <code>Time.fixedDeltaTime</code> are the same value when called in <code>FixedUpdate</code> [Unity is able to tell if the current call to <code>Time.deltaTime</code> originated during <code>FixedUpdate</code> and returns <code>Time.fixedDeltaTime</code>])</p>

<p>Naturally the same way <code>Update</code> can't be called in a constant manner because of varying performance, neither can <code>FixedUpdate</code>. The key difference is, each frame, if <code>FixedUpdate</code> hasn't been getting called often enough to average out to the correct interval between calls, it gets called multiple times (or isn't called the average is too high). This is what the <a href=""http://docs.unity3d.com/Manual/ExecutionOrder.html"">docs on Execution Order</a> refer to in saying that FixedUpdate can be called multiple times a frame:</p>

<blockquote>
  <p>...  FixedUpdate: FixedUpdate is often called more frequently than Update. It can be called multiple times per frame, if the frame rate is low and it may not be called between frames at all if the frame rate is high...</p>
</blockquote>

<p>This doesn't affect Physics because of the nature of the rest of the execution order and the engine, but just about anything else you put in <code>FixedUpdate</code> will be affected, and it will cause issues. </p>

<p>For example, if you put AI processing inside <code>FixedUpdate</code> there's no reason to assume that the AI won't skip updates for multiple frames in a row. Additionally, each time `FixedUpdate falls behind, your AI will update multiple times in a single frame before things like physics and player input/movement are processed, which is a waste of processing at the very least, but is also extremely likely to cause hard to track down bugs and erratic behavior.</p>

<p>If you need to do something at a fixed interval use other methods Unity provides such as <code>Coroutines</code> and <code>InvokeRepeating</code>.</p>

<p>And a small note on <code>Time.deltaTime</code> and when to use it:</p>

<p>The easiest way to describe the effect of Time.deltaTime is it changes a number from unit per frame, to unit <em>per second</em>. For example, if you have a script with something like <code>transform.Translate(Vector3.up * 5)</code> in Update, you're essentially moving the transform at a rate of 5 meters <em>per frame</em>. That means if framerate is low the movement is slower, and if framerate is high, the movement is faster.</p>

<p>If you take that same code and change it to <code>transform.Translate(Vector3.up * 5 * Time.deltaTime)</code> , the object is being moved at a rate of 5 meters <em>per second</em>. That means no matter the framerate, the object will move 5 meters every second (but the slower the framerate, the jumpier the object's movement will appear since it still moves the same amount every X seconds)</p>

<p>In general, you want your movement to be per second. That way no matter what speed the computer is going at, your physics/movement will behave the same way, and you won't have strange bugs popping up on slower devices.</p>

<p>And there's no point in using it in <code>FixedUpdate</code>. Because of what I mentioned above, you'll get the same value each call (the Fixed Update Timestep value), and it won't do anything to your values. Movement/Physics defined in <code>FixedUpdate</code> is already going to be in units per second so you don't need it.</p>
","94030"
"How detect which OpenGL texture formats are natively supported?","9239","","<p>For example, how detect if my videocard doesn’t support ""bgr8"" and convert it to another format, such as ""rgba8"" in software mode.</p>

<p>UPDATE: Sorry for the confusion. This question more about situation when I set <em>internalFormat</em> in <em>glTexImage2D</em> to something like ""bgra8"" but videodriver internally convert data to another format, like ""rgba8"".</p>
","<p>Your question seems to confuse certain concepts, so let's take things from the top. This is the definition of the function <code>glTexImage2D</code>:</p>

<pre><code>void glTexImage2D( GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, void *data );
</code></pre>

<p>There are two things that you might call ""texture formats"". The first is the <code>internalformat</code> parameter. This is the <em>real</em> <a href=""http://www.opengl.org/wiki/Image_Formats"">format of the image</a> as OpenGL stores it. The <code>format</code> parameter <a href=""http://www.opengl.org/wiki/Pixel_Transfer#Pixel_transfer_arguments"">describes part of the format of the pixel data</a> you are providing with the <code>data</code> parameter.</p>

<p>To put it another way, <code>format</code> and <code>type</code> define what <em>your</em> data looks like. <code>internalformat</code> is how you're telling OpenGL to <em>store</em> your data. Let us call <code>format</code> and <code>type</code> the ""pixel transfer format"", while <code>internalformat</code> will be the ""image format"".</p>

<p>The image format of a texture can <em>never</em> be ""bgr8"". There is no GL_BGR8 image format enumerator. There <em>is</em> a GL_BGR enum, but that is for the pixel transfer format, not the image format.</p>

<p>Or to put it another way, your pixel data that you give OpenGL can be stored in BGR order. But the OpenGL implementation decides on its own how to actually store that pixel data. Maybe it stores it in little-endian order. Maybe it stores it big-endian. Maybe it just arbitrarily rearranges the bytes. You don't know, and OpenGL does not provide a way to find out.</p>

<p><del>There is no way to tell if a particular set of pixel transfer format parameters matches how the OpenGL implementation will store them given the image format.</del></p>

<p>There <strong><em>is a way</em></strong> to tell now. And by ""now"", I mean in OpenGL 4.3 and/or ARB_internalformat_query2. Coming to a graphics card near you:</p>

<pre><code>GLenum format, type;
glGetInternalformativ(texture_target, GL_RGBA8, GL_TEXTURE_IMAGE_FORMAT, 1, &amp;format);
glGetInternalformativ(texture_target, GL_RGBA8, GL_TEXTURE_IMAGE_TYPE, 1, &amp;type);
</code></pre>

<p><code>format</code> and <code>type</code> now have the implementation's preferred <code>format</code> and <code>type</code> for using <code>glTex(Sub)Image</code> calls to <code>GL_RGBA8</code> images. There are separate <code>format</code> and <code>type</code> queries for <code>glReadPixels</code> downloads.</p>

<p>There are <a href=""http://www.opengl.org/wiki/GLAPI/glGetInternalFormat"">other queries you can make</a>.</p>

<p>If you don't have access to these, you can use some general rules of thumb that most hardware will adhere to:</p>

<ul>
<li>will store pixel data for 8-bit-per-channel data in BGRA order. So if you want to match the format with your pixel data, so as to more quickly upload texture data, you want to use <code>GL_BGRA</code> for the <code>format</code>, and <code>GL_UNSIGNED_INT_8888</code> or <code>GL_UNSIGNED_BYTE</code> for the <code>type</code>.</li>
<li>will not actually store 24-bit colors as 24-bits. It will always pad them out to 32-bits; the alpha will just be ignored when it reads the data. So if you want to match formats, always use <code>GL_BGRA</code> <code>format</code> with <code>GL_RGB8</code> image formats, even if you have to put dummy data in the alpha component.</li>
</ul>
","17589"
"Input handling in component based design","9227","","<p>I know this question has been asked several times, but I'm still not sure how to implement input handling in a component based engine.</p>

<p>The component based design I used was based on <a href=""http://t-machine.org/index.php/2007/09/03/entity-systems-are-the-future-of-mmog-development-part-1/"">T=Machine</a>'s blog series and on <a href=""http://gamadu.com/artemis/"">Artemis</a> in which Entities are just ids.</p>

<p>There are three main ideas I have in implementing input handling:</p>

<ol>
<li>The input component will hold events it's interested. The input system will translate key and mouse events to game events and loop through the entities with the input component and if they are interested in the event an appropriate action will be taken by the input system. This action would be hard coded to the input system.</li>
<li>No input component. You would register entities with specific events to the input system. The input system would then send messages (with the entity id and event type) to other systems so that these can take the appropriate action. Or as in the first case, the actions would be hard-coded to the input system.</li>
<li>Similar to the first method, but instead of hard coding the action to the input system, the component would contain a map of events to functions (i.e. <code>std::map&lt;std::function&gt;</code>) which would be called by the input system. This has the added effect of being able to couple the same event to different actions.</li>
</ol>

<p>Would you recommend any of the above methods or do you have any suggestions that would help me implement a flexible input handling system? Also, I'm not yet familiar with multi-threading but any suggestions that would make the implementation thread-friendly are also welcome. </p>

<p>Note: One added requirement I'd like the implementation to fulfill is that 
I'd be able to pass the same input to many entities, like for example moving a camera entity and the player at the same time.</p>
","<p>I think that, just like <a href=""https://gamedev.stackexchange.com/questions/47117/how-to-handle-materials-in-an-entity-component-system/47118#47118"">my answer regarding <em>materials</em> in a component system</a>, you're running in to a problem where you're trying to shove everything into a ""component."" You don't need to do this and in doing so you're probably creating a really cumbersome interface by trying to fit a bunch of square pegs into round holes.</p>

<p>It sounds like you already have a system that handles the acquisition of input from the player. I'd opt for an approach that then translates that input into actions (""move forward,"" or ""move backwards"") or events and dispatches those to interested parties. In the past, I've disallowed components from registering <em>themselves</em> for these events, preferring an approach where the higher-level system explicitly selected the ""controlled entity."" But it could work that other way if you prefer, especially if you're going to re-use the same messages for taking actions that were not stimulated directly by input.</p>

<p>I wouldn't necessarily suggest implementing camera-following behavior by having both the camera entity and the player entity respond to the ""move forward"" (et cetera) message, though. This creates an extremely rigid connection between the two objects that will likely not feel good to the player, and it also makes it a bit trickier to handle things like having the camera orbit the player when the player rotates left or right: you have an entity responding to ""rotate left"" by assuming it is slaved to the player, but that means it can't correctly respond if it were ever unslaved... unless you introduce that concept as some state you can check. And if you're going to do that, you may as well implement a proper system for slaving two physical objects together, complete with appropriate elasticity tweakables and so on.</p>

<p>Regarding multi-threading, I don't really see a need to employ it here as it would likely cause more complication than it's worth, and you're dealing with an inherently serial problem so you'd just need to involve a lot of thread synchronization primitives.</p>
","49232"
"How do I find the intersections between colliding circles?","9223","","<p>I want to find whether 2 circles with radii <code>r1</code> and <code>r2</code> intersect, and if so, <em>where they do so</em>. Is there a simple solution?</p>
","<p>Tetrad covered general intersection in his post. Here I'll cover an algorithm that returns the specific points of intersection based on the formulae in <a href=""http://local.wasp.uwa.edu.au/~pbourke/geometry/2circle/"" rel=""noreferrer"">this concise article</a>. I'm matching my variable names to those in the article, so keep this diagram in mind - and probably in view too!</p>

<p><a href=""http://local.wasp.uwa.edu.au/~pbourke/geometry/2circle/"" rel=""noreferrer"">2 http://local.wasp.uwa.edu.au/~pbourke/geometry/2circle/2circle1.gif</a></p>

<p>The language is Python. You can verify your results in <a href=""http://www.wolframalpha.com/"" rel=""noreferrer"">Wolfram Alpha</a> by running a query to determine the intersection of two circles like this:</p>

<p><code>intersection ((x - 0)^2 + (y - 0)^2 = 2^2), ((x - 1)^2 + (y - 0)^2 = 2^2)</code></p>

<p>or in the general case</p>

<p><code>intersection ((x - h)^2 + (y - k)^2 = r^2), ((x - h)^2 + (y - k)^2 = r^2)</code></p>

<p>where for each of the two circles, h = the x-coordinate of the centre of the circle, k = the y-coordinate, and r is the radius.</p>

<pre><code>from math import sqrt

# Determines whether two circles collide and, if applicable,
# the points at which their borders intersect.
# Based on an algorithm described by Paul Bourke:
# http://local.wasp.uwa.edu.au/~pbourke/geometry/2circle/
# Arguments:
#   P0 (complex): the centre point of the first circle
#   P1 (complex): the centre point of the second circle
#   r0 (numeric): radius of the first circle
#   r1 (numeric): radius of the second circle
# Returns:
#   False if the circles do not collide
#   True if one circle wholly contains another such that the borders
#       do not overlap, or overlap exactly (e.g. two identical circles)
#   An array of two complex numbers containing the intersection points
#       if the circle's borders intersect.
def IntersectPoints(P0, P1, r0, r1):
    if type(P0) != complex or type(P1) != complex:
        raise TypeError(""P0 and P1 must be complex types"")
    # d = distance
    d = sqrt((P1.real - P0.real)**2 + (P1.imag - P0.imag)**2)
    # n**2 in Python means ""n to the power of 2""
    # note: d = a + b

    if d &gt; (r0 + r1):
        return False
    elif d &lt; abs(r0 - r1):
        return True
    elif d == 0:
        return True
    else:
        a = (r0**2 - r1**2 + d**2) / (2 * d)
        b = d - a
        h = sqrt(r0**2 - a**2)
        P2 = P0 + a * (P1 - P0) / d

        i1x = P2.real + h * (P1.imag - P0.imag) / d
        i1y = P2.imag - h * (P1.real - P0.real) / d
        i2x = P2.real - h * (P1.imag - P0.imag) / d
        i2y = P2.imag + h * (P1.real - P0.real) / d

        i1 = complex(i1x, i1y)
        i2 = complex(i2x, i2y)

        return [i1, i2]

def CompToStr(c):
    return ""("" + str(c.real) + "", "" + str(c.imag) + "")""

def PairToStr(p):
    return CompToStr(p[0]) + "" , "" + CompToStr(p[1])

def Test():
    ip = IntersectPoints

    i = ip(complex(0,0), complex(1, 0), 2, 2)
    s = ip(complex(0,0), complex(4, 0), 2, 2)

    print ""Intersection:"", PairToStr(i)
    print ""Wholly inside:"", ip(complex(0,0), complex(1, 0), 5, 2)
    print ""Single-point edge collision:"", PairToStr(s)
    print ""No collision:"", ip(complex(0,0), complex(5, 0), 2, 2)

Test()
</code></pre>

<p>Note that this algorithm uses the readily-available <a href=""http://docs.python.org/library/cmath.html"" rel=""noreferrer"">complex</a> class for Python which can mimic a 2D Vector's <code>x</code> and <code>y</code> via the <code>complex.real</code> and <code>complex.imag</code> attributes respectively. Mathematically speaking a complex <em>is</em> a 2D vector on the <a href=""http://en.wikipedia.org/wiki/Complex_plane"" rel=""noreferrer"">complex plane</a>, which is why this works, so programmatically only the syntax is different. It's not optimal but I don't think Python natively has a proper geometric vector class.</p>

<p><em>Whether this was useful to you or not it was still fun. ;)</em></p>
","7175"
"Advantages and disadvantages of libgdx","9221","","<p>I've been an android developer for a while and am thinking about getting into gaming. While looking for a game dev framework, I thought libgdx provides very friendly documentation and functionality. So I would like to use it if there is no big obstacle.</p>

<p>But when I tried to see how many developers employ this library, I could find not that many. Is there anything wrong with this library? In other words, I would like to know its advantages or disadvantages from any experienced developer.</p>

<p>UPDATE: After reviewing its documentations and trying to build simple games with libgdx, I decided to go with it as its documentations are good enough and its community is very active. What I liked the most is that it provides a bunch of demo games that I can learn a lot from.</p>
","<p>I decided to go with libGDX for similar reasons. To expound on my comment, I will mention what I find are the pros and cons.</p>

<p>Pros:</p>

<ul>
<li>Works on Android and desktop (no need for emulator)</li>
<li>Active user community on forums</li>
<li>Lots of robust functionality</li>
<li>Works on iOS too (via RoboVM => free)</li>
</ul>

<p>Cons:</p>

<ul>
<li>Lack of documentation and information</li>
<li>Quite low-level (I prefer writing less code to get things done)</li>
</ul>

<p>All in all, if you're sticking to just Android, it's great. But if you want to do iOS too, I would move to something else, like Unity or Corona SDK.</p>
","23693"
"How can I build a game in Unity with minimum/no use of the visual editor?","9216","","<p>I'd like to write a game completely in C#. In my search for an engine, I found Unity3D, but all the tutorials and documentation are speaking about a visual editor and the Unity IDE in which you click and point around to create scenes and scripts.</p>

<p>I don't want to do that. I prefer full code coverage over designers abstracting things away from me. I'd like to only write pure C# code from scratch or if required the Unity scripts as an addition. I couldn't find any explanation or documentation about doing so; how can I build a game using Unity and making minimum (or no) use of the visual editor?</p>
","<p>I am a complete beginner in Unity, but this is how I do it at the moment, and it reduces the editor usage to minimum:</p>

<p>In editor, I only have three objects: An empty GameObject called ""main"", a camera, and a light. And this is only because so far I only work with a single camera and a single light, so it was faster this way. Later I will probably remove them, and only the ""main"" will remain.</p>

<p>In ""Assets/MyScripts"" I have a class ""Main"", which is added to the ""main"" GameObject as a behavior. Which means that when the program starts, the ""Main"" class in instantiated and its method is called. The ""Main"" class is like this:</p>

<pre><code>using UnityEngine;

public class Main : MonoBehaviour
{

    void Start ()
    {
        // initialize the game
    }

    void Update ()
    {
        // update physics
    }

}
</code></pre>

<p>In the game I dynamically build the environment like this:</p>

<pre><code>GameObject floor = GameObject.CreatePrimitive (PrimitiveType.Cube);
floor.renderer.material.color = RandomGreen ();
</code></pre>

<p>But this is because so far I am only making a prototype. Later I will want to replace the cubes with some nice things edited in Blender. Which will require making them in Blender, and importing them to Units as ""prefabs"". Then, I will similarly instantiate the ""prefabs"" from the C# code.</p>

<p>If you want to make an object react to events, such as collisions with other objects, you can instantiate the object and add them dynamically a behavior class, which is a C# class derived from MonoBehavior. For example, if you want to have a car, you make a car prefab, and write a ""CarBehavior"" class for its behavior in the game.</p>

<p>This way you can reduce the interaction with the editor to a minimum, although probably not completely to zero. Now it depends on whether this is an acceptable solution for you.</p>
","81699"
"What scripting language would you recommend for a C++ game project?","9214","","<p>By scripting here I mean not just putting config data in a script, but scripting parts of the project like some class methods, test specific game loop, etc. This would be not just to accelerate development, but also allow players to see some of these scripts to tweak some aspects of the game.</p>

<p>Some language like Lua have some wrappers like luabind, but when I've used it in the past it had problems because it didn't support method redefinition in a context of inheritance.</p>

<p>What are your suggestions of language / wrappers to use or not to use? </p>
","<p><a href=""http://en.wikipedia.org/wiki/Category%3aLua-scripted_video_games"">Lua-scripted video games</a><br>
<a href=""http://en.wikipedia.org/wiki/Category%3aLua-scriptable_game_engines"">Lua-scriptable game engines</a></p>

<p>I think Lua is the best shot.</p>

<p><a href=""http://www.codeproject.com/KB/cpp/luaincpp.aspx"">This article</a> is about integrating Lua and C++. It says:</p>

<blockquote>
  <p>LuaBind is great product but for me it looked too complicated. For one the code is not easy to follow where the classes and objects are. Also seeing that I wanted to integrate Lua into a wxWidgets application, using templates was a bit of a no no (you can read cross-platform issues on the wxWidgets site).</p>
</blockquote>

<p>There are many other binding libraries:</p>

<p><a href=""http://luabridge.sourceforge.net/"">http://luabridge.sourceforge.net/</a><br>
<a href=""http://www.stackedboxes.org/~lmb/diluculum/"">http://www.stackedboxes.org/~lmb/diluculum/</a><br>
<a href=""http://cpplua.sourceforge.net/"">http://cpplua.sourceforge.net/</a><br>
<a href=""http://www.tecgraf.puc-rio.br/~celes/tolua/"">http://www.tecgraf.puc-rio.br/~celes/tolua/</a></p>

<p><a href=""http://www.gamedev.net/community/forums/topic.asp?topic_id=301533"">What is the best C++/Lua wrapper?</a></p>

<p>Just select and enjoy.</p>
","4717"
"How to match font size with screen resolution?","9213","","<p>So I'm working on a game using LibGDX, and I have a problem.</p>

<p>To make my game fit most resolutions, I created a base asset for each aspect ratio, for example, a main menu background image, I made it in 800X600 for 4:3, 1280X720 for 16:9 etc. </p>

<p>Now I am trying to incorporate <code>TextButton</code>s into the game, for the options; My problem is that I can't figure out which font sizes match with which screen resolutions. Is there a way to figure this out, or do I have to go one by one through each of the resolutions I have and just manually match the text to the resolution?</p>
","<p>It's easy: Fonts do not need to match resolution, they need to match <strong>pixel density</strong>.</p>

<p>Pixel density is measured as pixels per inch(<em>PPI</em>), or pixels per centimeter. There's also a measure unit called <strong>density independent pixels(<em>DP</em>)</strong>. It is defined that <code>1dp</code> is the size one pixel has on a <code>160 PPI</code> screen.</p>

<p>Now coming back to fonts, try to make this test: put your laptop to run on 720p. Take a look on the size of the font. Now plug it into the 1080p 42"" monitor of your desktop. If your monitor outputs the right information about its size, then the font should have EXACTLY the same size it had on the 720p screen. Imagine how weird it would be if text in your laptop had a different size than the text on your desktop monitor. With that said, larger resolutions should give more detail to the font, larger screens should give more content to be shown.</p>

<p>The same fact can be observed on text editors. A <code>72pt</code> font should look on the screen the same it would when printed on paper.</p>

<p>All this means you probably should want the same size across all display sizes (with some exceptions). If you want to base yourself somewhere, websites usually use <code>12pt</code> fonts, MS Windows uses <code>11pt</code> and <code>12pt</code> fonts.</p>

<p><a href=""http://reeddesign.co.uk/test/points-pixels.html"" rel=""nofollow noreferrer"">This chart</a> (also included in the bottom of the answer) tell us <code>12pt</code> in CSS is roughly equal to <code>16px</code> also in CSS (As if this wasn't confusing enough, a <em>px</em> in CSS is the same as <em>dp</em> everywhere else), so let's say you'll make your fonts <code>16dp</code> on LibGDX.</p>

<p>On your game, use the <a href=""http://www.badlogicgames.com/wordpress/?p=2300"" rel=""nofollow noreferrer""><code>FreeTypeFontGenerator</code></a> to generate fonts dynamically, this way you can consider the screen density when creating them:</p>

<pre><code>BitmapFont createFont(FreeTypeFontGenerator ftfg, float dp)
{
    return ftfg.generateFont((int)(dp * Gdx.graphics.getDensity()));
}
//On Init
BitmapFont buttonFont = createFont(arial, 16); //16dp == 12pt
</code></pre>

<p>This works because <code>Gdx.graphics.getDensity()</code> is equal to <code>YourScreenDensity/160</code> thus, is a ""scale factor"" to bring things to the size they would be on a 160ppi screen.</p>

<p>About the exceptions I mentioned earlier: you'll probably want fonts re-sizing accordingly to screen size in case of logos, promos, etc. But keep in mind that you'll be better off making these on a graphics editor like Photoshop or Gimp, anyway.</p>

<p>The other exception is text on tiny screens. 4.5"" or smaller phone screens, wearables. Usually you won't have time to make scrolling content, or you just won't be able to afford putting so much content on that screen. You may try to scale the font <code>1dp</code> down, as the reader will probably have the phone very close to their face, they probably won't have a problem reading. Keep in mind you may annoy the player reading unreadable small text.</p>

<p>TL;DR:</p>

<ul>
<li>Physical size roughly won't change directly with screen size or resolution, but with a combination of both (<code>screenSize/resolution</code> the famous PPI)</li>
<li>Think of <em>pt</em> and <em>dp</em>. Forget about screen pixels until you have to draw the final result.</li>
<li>Create your font at runtime with a reasonable size.</li>
<li>Converting <em>dp</em> to screen pixels: <code>pixels = dp * Gdx.graphics.getDensity();</code></li>
<li>If you are using a engine which does no give you converter to <em>dp</em> like LibGDX's <code>Gdx.graphics.getDensity()</code>, you can try: <code>densityFactor = Screen.getPixelsPerInch() / 160.0f</code>, then <code>pixels = dp * densityFactor</code></li>
</ul>

<p>EDIT:</p>

<p>2014, Jun 25 on Google IO, Matias announced a new style guidelines for Android, it includes a new Roboto font and typography guidelines. Take this table as a guide:</p>

<p><img src=""https://i.stack.imgur.com/Jpu5Q.png"" alt=""Android font size guidelines, taken fron google.com/design""></p>

<p>EDIT2:</p>

<p>Included CSS font size chart in case the link goes rot:
<img src=""https://i.stack.imgur.com/Ptfuo.png"" alt=""CSS font sizes""></p>
","77674"
"What is the difference between a HUD and a GUI in a game?","9212","","<p>Does anyone know the difference between a graphical HUD (head-up display) and a GUI (graphical user interface) in a game? Is a HUD part of the GUI and just displaying information? That would mean that I can not technically interact with a HUD while I could with the GUI (e.g. clicking a button)? Or are both terms basically describing the same thing?</p>

<p>Note: I'm talking about these words while being ingame.</p>

<p>See the following example:</p>

<p><a href=""https://i.stack.imgur.com/P4AUS.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/P4AUS.jpg"" alt=""overwatchguiorhud?""></a></p>

<p>What would be described as GUI in this image and what as HUD?</p>
","<p>I'd argue that HUDs <em>are</em> graphical user interfaces: they're ways to present information back to the user graphically.</p>

<p>In contrast to what some other answers say, the term GUI doesn't require that every element be directly interactive - the label next to a control on a form is still part of the GUI, guiding the player in how to interact with the system, even if clicking the label itself doesn't accomplish anything.</p>

<p>What distinguishes HUD elements is the particular <em>way this information is displayed</em> to the user: ""Heads-Up Display"" was coined in contrast to a light or dial on a control panel, where the user would need to look down / away from the window and world in front of them to check on it. The defining feature of being ""Heads-Up"" is that the information is overlaid over the world, rather than in its own separate dashboard, and it often tracks with the user's camera or head rather than needing them to turn to a particular location to see it (particularly notable in VR games).</p>

<p>So for example, in this StarCraft screenshot, I would argue that the selection and health overlays on the units, and resource counters in the corner, all constitute HUD, being overlaid on the game world. The map, order buttons, and selection readouts in the chrome below would not be HUD because they exist outside the world viewport.</p>

<p><a href=""https://i.stack.imgur.com/D5g2i.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/D5g2i.jpg"" alt=""Screenshot of Starcraft contrasting different types of GUI""></a></p>

<p>It's more common to see the term HUD applied in 1st person and 3rd person over-the-shoulder perspectives than to top-down/isometric games like this one, but I wanted to find an example that would contrast both styles. First person examples with both HUD and non-HUD chrome are harder to find, but old-school dungeon crawlers sometimes use this kind of mix too. Here the ""Small Cave Troll"" label, level, and health bar are HUD since they're overlaid on the world, while the rest of the GUI sits (mostly) outside the player's window to the world and isn't ""heads-up"" in this sense.</p>

<p><a href=""https://i.stack.imgur.com/1bZi0.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/1bZi0.jpg"" alt=""Screenshot of The Nights &amp; Candles""></a></p>

<p>Some games will also have floating windows or panels, like inventory management interfaces, that sit on top of the viewport. When these are mostly opaque, I'd generally consider them to be non-HUD GUI elements because they obscure a sizeable chunk of the game world in much the same way as the dashboard chrome examples.</p>
","150998"
"Is there an XNA-like library for Java?","9196","","<p>I'm curious to know if there is an XNA-like library for Java; that is, a library that</p>

<ol>
<li>Handles the game loop - i.e. you just implement an existing method, and it will get called every frame.</li>
<li>Handles the rendering - i.e. you just tell it what to render, it will take care of displaying it to the monitor, hiding implementation details such as hardware acceleration.</li>
<li>Contains many useful methods for graphic, sound and user input options.</li>
</ol>

<p>I'm interested in a library which supports both 2D and 3D options.</p>
","<p>According to your first requirement, you are looking for a <strong>framework</strong> rather than a library.</p>

<p><a href=""http://www.jmonkeyengine.com/"">jMonkeyEngine</a> is a framework for 3D games (i.e. it provides the main loop as you ask for, similar to XNA) but it wouldn't be a good choice for 2D.</p>

<p>However, <strong>a game loop isn't a hard thing to write</strong>, and existing Java libraries handle your 2nd and 3rd requirements, so I highly suggest looking into a scene graph 3D library/engine or any 2D library, depending on if you're making a 2D or a 3D game.</p>

<p><a href=""http://aviatrix3d.j3d.org/"">Aviatrix3D</a>, <a href=""http://www.ardor3d.com/"">Ardor3D</a>, <a href=""http://en.wikipedia.org/wiki/Java3d"">Java3D</a> and <a href=""http://www.jmonkeyengine.com/"">jMonkeyEngine</a> are my recommendations for scene graph 3D engines.</p>

<p>For 2D libraries, you have <a href=""http://www.13thmonkey.org/~boris/jgame/"">JGame</a>, or you can choose to use OpenGL for max speed and use <a href=""http://www.lwjgl.org/"">LWJGL</a> or <a href=""http://jogamp.org/jogl/www/"">JOGL</a>. You could also just go with Java's built-in <a href=""http://download.oracle.com/javase/tutorial/2d/index.html"">Graphics2D</a> library, which would be an especially good option if you plan to deploy your game as an applet.</p>

<hr>

<p>For going the built-in Graphics2D route, look at the <a href=""http://www.mojang.com/compo/metagun/metagun-source.zip"">source code</a> to <a href=""http://www.mojang.com/compo/metagun/"">Metagun</a> (click to play in applet form). It's a small but very well-written 2D Java game, and I think it's an excellent example of a small game; copy its structure and you have your optimal game loop/framework.</p>
","3479"
"How ""fake"" do invented names of a football game have to be in order to avoid copyright infringement?","9193","","<p>I know that real player names cannot be used in videogames unless the authorization (generally very expensive) has been given by the holders of the rights (players, teams etc.)</p>

<p>as explained <a href=""https://gamedev.stackexchange.com/questions/25873/legal-issues-around-using-real-players-names-and-team-emblems-in-an-open-source"">here</a> and <a href=""https://gamedev.stackexchange.com/questions/23064/does-it-require-any-license-to-use-soccer-players-and-teams-names-in-a-paid-or-f"">here</a>.
<a href=""https://gamedev.stackexchange.com/questions/14941/what-resources-can-i-use-to-determine-if-the-name-of-my-game-violates-any-copyri"">There is a discussion here about possible sources</a> that can be consulted in order to figure out whether you are infringing any copyright issue, but it does not say anything specific about my problem (at least as far as I understood it, given my poor comprehension and expertise on the matter).</p>

<p><em>my question is very simple</em>: <strong>is there any rule that determines the amount of difference (in characters, sound, length, phonological features, whatever) from a real name to a fictitious (or fake) name in order for the latter to be considered really fake?</strong></p>

<p>For example, if I created a football videogame in which there is a strong offensive midfielder that has Cristiano Ronaldo's features (with respect to characteristics, statistics etc. not physical appearance) how could I call this player to avoid copyright infringement?</p>

<p>Cristian Ronald?
Cristo Romaldi?
Christiano Ronnaldo?</p>

<p>there was a famous release of ISS PRO (football game) employing <a href=""https://www.gamefaqs.com/ps/578030-iss-pro-evolution/faqs/7074"" rel=""nofollow noreferrer"">fake names - here's the list -</a> that were very similar to real ones.</p>

<p>Is there a specific rule/law that says which is good and which is not?</p>
","<blockquote>
  <p><em>I'm not a lawyer, this is not a legal advice site, this opinion is offered as is. You should consult with a lawyer to have a definitive answer.</em></p>
</blockquote>

<p>There are no specific rules that govern this. </p>

<p>The ultimate decision will be done by a judge in a court. </p>

<p>But you will not be able to get to that point. </p>

<p>What's most likely to happen is that the FIFA's legal team will send you a letter asking you to do whatever they want (it can range from a smooth 'change the names', to 'take down your game from the stores and give us all money made from it', to 'cease all game creation activities', etc).</p>

<p>They can send you that letter because you don't have money to defend against it in court. This would have cost them only 1000$, but it will be enough to scare you. Legal battles can be long and extremely expensive. They'll assume you don't want to go that path because they have more money that you do to prove them they're wrong.</p>

<p>In any case, it can cost you a lot of money, either in lawyer fees to defend yourself in court, or in money you'd have to pay them as 'compensations'. </p>

<hr>

<p>I'd create original characters and not get inspired by real players. </p>
","124963"
"What to send to server in real time FPS game?","9190","","<p>What is the right way to tell the position of our local player to the server? Some documents say that it is better to send the inputs whenever they are produced. And some documents say the client sends its position in a fixed interval.</p>

<p>With the sending the inputs approach: What should I do if the player is holding down the direction keys? It means I need to send a package to the server in every frame. Isn't it too much? And there is also the rotation of the player from the mouse input. Here is an example:</p>

<blockquote>
  <p><a href=""http://www.gabrielgambetta.com/fpm_live.html"">http://www.gabrielgambetta.com/fpm_live.html</a></p>
</blockquote>

<p>What about sending the position in fixed interval approach. It sends too few messages to the server. But it also reduces responsiveness.</p>

<p>So which way is better?</p>
","<p>Simple answer: cheat or don't be that accurate!</p>

<p>If you've played some shooter online, you'll most likely have experienced the so called ""rubber banding"" if your connection to the server is bad.</p>

<p>This is caused by your client correcting your position from time to time.</p>

<p>Basically, what happens on the two sides:</p>

<ul>
<li><p>The server will track your movement and send updates to the clients as expected. These don't always have to be full updates. Every x frames there could be a full update, all other frames you only send new velocity vectors (if there are any changes).</p></li>
<li><p>Your own client will allow you to move freely but will use the updates provided by the server to correct/adjust your position. This will ensure the game to feel responsive, even if you don't update the position frame by frame.</p></li>
</ul>

<p>But how is input handled? Your client will send your position to the server ""I moved there."". The server will verify this update (e.g. should you be able to move there that fast?) and if it's valid move you (or rejecting your update, resulting in ""rubber banding"").</p>

<p>So yes, your fixed interval approach will most likely work and be enough.</p>

<p>But even if you want to send input and handle movement on both sides, keep in mind that you don't have to send ""button is still pressed"". Instead, send one event when the button is pressed and another once the button is released.</p>
","74656"
"Is game development a no-money field?","9190","","<p>I'm in Israel, about to graduate from high school and thinking about the future. I'd really like to make videogames for a living. I have been playing with some tools (about to finally start a real Unity project now) and have some good programming experience.</p>

<p>The career risks worry me: Just to get started, I'll probably have to emigrate. There are few game dev companies here and most just make cash cows for dumbphones and interactive TVs. (I'm thinking of going to England.)</p>

<p>THE dream is to work in a medium sized company for a couple of years, return to Israel with some experience, then try to go indie.</p>

<p>Will I survive? Many say videogame jobs barely make money. Is it a field worth pursuing, considering the risks? Are indie games profitable? What about big companies?</p>
","<blockquote>
  <p>A lot of people say you barely make money in videogame jobs</p>
</blockquote>

<p>Pretty much all game programmers I know here in the UK earn more than the national median wage. There are no starving employed game programmers.</p>

<blockquote>
  <p>Is there anyone here who develops indie games and can vouch for ANY money making?</p>
</blockquote>

<p>That's quite a different proposition. Thousands of people want to be able to make their own games and sell them, but probably only 5% of them actually finish their games, and maybe only 1/5 of those are able to make a profit, due to failings in promotion, distribution, the absence of a target audience, etc.</p>
","12922"
"Game Update in Libgdx","9185","","<p>In libgdx, the game loop is the render() method. But why is that, and is there a way where I can make an update() method that is called 60 times a second? As in the update() method, I would add the game logic, and leave the rendering to the render method.
Basically, separate methods, and the update() method called 60 times per second using Libgdx with java.</p>
","<p>There is no specific game loop in libGDX because it is event-driven. And still, you can see the render method as the main loop. </p>

<p>You've got it right - usually, this is where you update the game logic before you do the rendering.</p>

<p>What you can do is to create a class responsible for the logic and a class responsible for the rendering. Then in your render method you write</p>

<pre><code>@Override
public void render(float deltaTime) {
    if(!paused)
        LogicClass.update(deltaTime);
    Gdx.gl.glClearColor(0, 0, 0, 0);
    Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);
    RenderClass.render(deltaTime);
}
</code></pre>

<p>You can read more about the life cycle in libGDX in its wiki on github:
<a href=""https://github.com/libgdx/libgdx/wiki/The-life-cycle"" rel=""nofollow"">https://github.com/libgdx/libgdx/wiki/The-life-cycle</a>. </p>
","71885"
"Using The Box2D Polygon ""Set()"" function?","9182","","<p>I'm using the Box2D physics engine. And there's a type of shape for box2D called b2PolygonShape.</p>

<p>In this class, you can create polygons. There is also a Set() function that takes an array of points and a vertex count.</p>

<p>Box2D has an example like this: </p>

<pre><code>// This defines a triangle in CCW order.

b2Vec2 vertices[3];

vertices[0].Set(0.0f, 0.0f);

vertices[1].Set(1.0f, 0.0f);

vertices[2].Set(0.0f, 1.0f);

int32 count = 3;



b2PolygonShape polygon;

polygon.Set(vertices, count);
</code></pre>

<p>This works. Yet when I tried to practice and mess with this function, I did this:</p>

<pre><code>  b2Vec2 vertices[4];

  vertices[0].Set(0, 0);
  vertices[1].Set(0,10);
  vertices[2].Set(10,10);
  vertices[3].Set(10,0);

  int32 count = 4;

  b2PolygonShape polygon;

  polygon.Set(vertices, count);
</code></pre>

<p>When I compiled and ran this, it crashed after the Set() function. Wouldn't this create a square?</p>

<p>Also in the console I got this:</p>

<pre><code>Assertion failed: s &gt; 0.0f
</code></pre>

<p>What did I do wrong?</p>
","<p>That's because the four vertices you provided are in clockwise order and Box2D assumes they're  in counter-clockwise, like in your first example. So it should work fine if you change it to:</p>

<pre><code>  b2Vec2 vertices[4];

  vertices[0].Set(0, 0);
  vertices[1].Set(10,0);
  vertices[2].Set(10,10);
  vertices[3].Set(0,10);

  int32 count = 4;

  b2PolygonShape polygon;

  polygon.Set(vertices, count);
</code></pre>

<p>And by the way, if you're just creating a box-shaped polygon, you can use the convenience function </p>

<pre><code>void b2PolygonShape::SetAsBox(float32 hx, float32 hy, const b2Vec2&amp; center, float32 angle)
</code></pre>
","1499"
"Exporting the frames in a Flash CS5.5 animation and possibly creating the spritesheet","9164","","<p>Some time ago, I asked a question <a href=""https://gamedev.stackexchange.com/questions/18003/whats-the-best-way-to-create-animations-when-doing-android-development"">here</a> to know what would be the best way to create animations when making an Android game and I got great answers.</p>

<p>I did what people told me there by exporting each frame from a Flash animation manually and creating the spritesheet also manually and it was very tedious.</p>

<p>Now, I changed project and this one is going to contain a lot more animations and I feel like there has to be a better way to to export each frame individually and possibly create my spritesheets in an automated manner.</p>

<p>My designer is using Flash CS5.5 and I was wondering if all of this was possible, as I can't find an option or code examples on how to save each frame individually.</p>

<p>If this is not possible using Flash, please recommend me another program that can be used to create animations without having to create each frame on its own. I'd rather keep Flash as my designer knows how to use it and it's giving great results.</p>
","<p>First of all, let me say that there's absolutely no need to build your sprite-sheets manually. There are some very good tools for this purpose. Also exporting animations from Flash should be easy and straight-forward. Here's how you do it:</p>

<p>You can export your animations by selecting <code>File</code> > <code>Export</code> > <code>Export Movie...</code>. Then you select <code>PNG Sequence</code> as format and it will export to a series of PNG files.</p>

<p>Then you can head over to <a href=""https://gamedev.stackexchange.com/questions/27214/is-there-a-tool-to-make-a-spritesheet-out-of-1000-pngs"">this question</a> where you'll find lots of good answers on how to create sprite-sheets from these PNGs. </p>

<p>Flash CS6 will have a feature to directly export animations to sprite-sheets. Older versions will have to use the procedure outlined above.</p>
","29844"
"How to install Unreal Engine 4?","9156","","<p>As soon as I found out that <a href=""https://www.unrealengine.com/blog/ue4-is-free"">Unreal Engine 4 is now free</a>, I decided to get it in order to tinker with it.</p>

<p>So I clicked on the blue ""<em>Get Unreal</em>"" button, signed up, and downloaded (and installed) the MSI installer (working on Windows here).</p>

<p>After the installation completed, the ""<em>Epic Games Launcher</em>"" launched, asking me to log in. Once logged in, I selected the ""<em>Unreal Engine</em>"" tab and was greeted by a page with several tutorials and demo projects for download, while the left side offered an orange button saying ""<em>No engine installed</em>"" and no option to click on it to install one.</p>

<p>After some time, I found <a href=""https://docs.unrealengine.com/latest/INT/GettingStarted/Installation/index.html"">this Unreal documentation</a> explaining how to install the engine. According to it, the engine should start downloading the moment I log in to the launcher, which didn't happen.</p>

<p>What am I doing wrong? How can I install the Unreal Engine?</p>
","<p>After spending 10 minutes rummaging through documentations and Google, I finally succeeded in downloading the actual engine.</p>

<p>I was too focused on the orange button in the left pane, that I didn't try clicking on ""<em>Library</em>"", which is where I can choose to download the <em>Unreal Engine</em> version of my choice.</p>

<p>Simply click on ""<em>Add Versions</em>"" (hard to miss with its orange + sign) next to ""<em>Engine Versions</em>"". All that's left to do is selecting a version and clicking on the orange ""<em>Install</em>"" button, then wait for the download to complete.</p>
","95961"
"What is some good examples about creating 2D fluids?","9145","","<p>Anyone have any good examples, tutorials, or snippets to share that preferably in C# or C/C++?</p>
","<p>PixelJunk shooter from Q-Games has nice set of fluids. There is a GDC paper they have published here: <a href=""http://fumufumu.q-games.com/gdc2010/shooterGDC.pdf"">http://fumufumu.q-games.com/gdc2010/shooterGDC.pdf</a> (PDF!)</p>

<p>Jos Stam from Alias Maya fame (now Autodesk) wrote paper on real time fluids in games here: <a href=""http://www.dgp.toronto.edu/people/stam/reality/Research/pdf/GDC03.pdf"">http://www.dgp.toronto.edu/people/stam/reality/Research/pdf/GDC03.pdf</a> (PDF!)</p>

<p>And he wrote a simple FFT fluid solver here: <a href=""http://www.dgp.toronto.edu/people/stam/reality/Research/pdf/jgt01.pdf"">http://www.dgp.toronto.edu/people/stam/reality/Research/pdf/jgt01.pdf</a> (PDF!) where he included source in that PDF at the end.</p>
","183"
"Math topics for 3D graphics programming","9128","","<p>I understand that the following math topics are required for 3D graphics programming. I have started doing some of them in my math course. Can someone point me in the direction of a resource that explains <strong>how</strong> they apply? What graphics/game problems are they used to solve?</p>

<ul>
<li>vector math</li>
<li>matrix math</li>
<li>quaternions</li>
<li>linear algebra</li>
</ul>

<p>As far as I can see these are all linear algebra/matrix topics. Are there any other topics required?</p>
","<p>Linear Algebra is the foremost discipline for 3d graphics programming simply <em>because</em> it's the mathematical language for describing spatial geometry.  Your other three topics are really just subsets of linear algebra:</p>

<ul>
<li>Vectors are a way of thinking about points in space</li>
<li>Matrices are ways of thinking about transformations of space and objects: translating objects, scaling them, etc. </li>
<li>Quaternions are a natural representation for a specific subgroup of those transformations, the rotations</li>
<li>etc, etc.</li>
</ul>

<p>As far as other relevant pieces of mathematics for 3d graphics programming, the one I'd recommend that doesn't get nearly enough love is computational geometry.  A lot of natural problems boil down to topics in computational geometry:</p>

<ul>
<li>One of the most natural ways of defining a volume from a set of points (for instance, to define an audio volume where a specific background noise will play, or a fog volume, or the like) is to find the <em>Convex Hull</em> of the points; there are good algorithms for doing that in 2 and 3 dimensions, but even the 2d algorithms aren't immediately obvious.</li>
<li>The problem of being able to determine what objects are near a given point or are near each other (for instance, to reduce the number of objects that have to be checked for possible collisions, or to figure out which enemies will notice the players at a given point) gets into the field of <em>Geometric query</em> problems and to spatial partitioning schemes (and thus into structures like BSP trees and octrees).  The same general ideas are also used to answer 'line tracing' queries (for instance, 'what does this laser beam hit?')</li>
</ul>

<p>After that, I'd encourage looking into basic calculus and particularly numerical methods for differential equations; these are less relevant to 3d graphics per se than they are to 3d physics, but in general the two topics are pretty tightly coupled (even for simple problems of kinematics - for instance, for character animations and the like) and some knowledge of both will substantially enhance your knowledge of either; it's difficult if not impossible to work the relevant physics without the same core linear algebra knowledge as graphics uses, but at the same time having the physics knowledge provides another point of reference for understanding the topics in graphics.</p>
","11409"
"What are the advantages of tangent space normals over object space normals?","9124","","<p>What are the advantages of normals in tangent space to normals in object space for calculation of bump mapping?</p>
","<p>Everything, really.</p>

<p>The only benefit to object-space normals is simplicity. They're easier to use.</p>

<p>Tangent-space normals require a tangent-space basis, but offer:</p>

<ol>
<li><p>The ability to use the same texture for different surfaces. Object-space normal maps can only ever be used on the surface for which they were created. By regularizing normals in tangent-space, you gain the freedom to use the same bump texture for different surfaces. As long as the surface has a tangent-space basis, you'll get reasonable results.</p></li>
<li><p>The ability to modify the texture mapping, with UV animation for example. Since object-space normal maps store normals in object-space, you can't just add 0.5 to all of the texture coordinates and expect to get proper normals from the texture. You can with tangent-space bump mapping.</p></li>
<li><p>Smaller component representation. Object-space normal maps must have 3 components; you can't drop one and reconstitute it in the shader. Tangent-space normals will always have a positive Z component, so you can only store the XY of the normal. So you can either get greater precision by using a <code>GL_RG16_SNORM</code> or <code>GL_RG16F</code> <a href=""http://www.opengl.org/wiki/Image_Format"">formats</a> (32-bits per texel), or employ compression by using an <a href=""http://www.opengl.org/wiki/Red_Green_Texture_Compression"">RG-compressed image format</a> (<code>GL_COMPRESSED_SIGNED_RG_RGTC1​</code>, 8-bits per texel) format. You can try to use S3TC on an object-space normal map, but good luck with what you get back.</p></li>
</ol>

<p>The absolute most you get with object-space normal maps is less computation time (not having to transform the light direction into tangent space, or alternatively, transforming the normal from tangent space into model space). But that's not a big deal, especially nowadays with deferred renderers running around.</p>
","31502"
"How to give the player the feeling of being chased by enemies and force him/her to rush","9089","","<p>I have already asked a question about the difficulty progression in my endless runner game: <a href=""https://gamedev.stackexchange.com/questions/114803/how-to-make-difficulty-progression-in-my-endless-runner-game"">How to make difficulty progression in my endless-runner game?</a></p>

<p>Now I have to decided that it is a good approach to make the following:</p>

<ol>
<li><p>Camera is always drifting up, slowly, but preventing the player from idling. </p></li>
<li><p>If squirrels jump, the camera follows them and the spiders also update their position to be slightly below visible area. Their speed is a little bit faster than the camera's drifting speed, so the player will panic out of the fear of the spiders catching them.</p></li>
<li><p>Something else?</p></li>
</ol>

<p>I want to make feel of constant chase by spiders and force player to run, make quick decisions and make mistakes. Player need to know exactly how close the spiders to squirrels are. </p>

<p>P.S: You can see earlier version of this game here: <a href=""http://ludumdare.com/compo/ludum-dare-34/?action=preview&amp;uid=66055"" rel=""nofollow noreferrer"">http://ludumdare.com/compo/ludum-dare-34/?action=preview&amp;uid=66055</a></p>

<p><strong>EDIT</strong>: The problem is that spiders are always relatively close to player and distance between them and the spiders matters. Once spiders have left the visible area, player feels safe. Firstly, spiders run with constant speed and if the player runs a little bit faster, he is always in the safe area and doesn't see any spiders. </p>

<p>The idea is to have player under pressure all time. The difficulty is that the visible area between the spiders and squirrels is small</p>

<p><strong>FINAL DECISION</strong>: The final decision was made because of majority votes, and I suppose this answer suits for many games. But there is more than one good answer, and most of the answers are worth reading and implementing. That is what I am going to do.</p>

<p>Thanks everyone for your great answers!</p>
","<ol start=""3"">
<li>Music.</li>
</ol>

<p>Music is probably the most effective way to express feelings. </p>

<p>If you manage to use the appropiate song that tells ""Danger, run!"", that is better than any camera movement (If you combine music with those kind of effects, it gets even better, of course).</p>

<p>Imagine playing Silent Hill with david guetta music, that would make Silent Hill a joke, you would laugh at every monster you see.</p>

<p><strong>Edit:</strong> As some other users have mentioned, a lot of people play mobile games without sound, music is still my favourite option, but the second one would be:</p>

<ol start=""4"">
<li>Color</li>
</ol>

<p>Color is easy to understand and easy to implement as visual feedback, you can make the environment get different color tones depending on the distance from the spiders to the player. Usually, Red/Orange toned colors symbolize ""Danger"" and Blue/Green toned colors symbolize ""Peace/Calm"".</p>

<p>(Color blind people might have problems with this if not implemented correctly (It is not easy though, be careful)).</p>
","115172"
"Binding C++ and V8 Javascript from Google","9086","","<p>The examples are quite challenging to grasp if you are still getting your head around other things, so the simplest example would be great.</p>

<p>Is there a simpler example?</p>
","<p>Some links : </p>

<p>1) A series of tutorials i wrote : <a href=""https://github.com/underscorediscovery/v8-tutorials"" rel=""nofollow"">https://github.com/underscorediscovery/v8-tutorials</a></p>

<p>2) CProxyV8 extends on the point/line samples by using their binding code</p>

<p>3) v8Juice is also a binding system for v8, has some simpler examples</p>

<p>4) Find other v8 projects and have a look inside their code (if possible)</p>

<p>5) Ask on gamedev.stackexchange.com</p>

<p>6) Ask on the v8 channel on iRC, freenode server</p>
","2797"
"Unity map size limit?","9076","","<p>Does Unity have a map size limit and if there is what is the limit? Is there a way to work around it? I am making a open world zombie survival world and I want to make a really big map. Thanks!</p>
","<p>The limit for a single map is 2000, you can merge them until your pc allows you. I have copied a fully painted terrain around 4048~ times and everything was working properly. The rendering view ends at 2km. The terrains area does't affect performance, the LOD does, grass etc. </p>

<p>Somebody has actually made a map which was the size of Alaska, was funny to watch videos of people who tried running across the map. The only problem in creating a persistant world is the fact that when there are two terrains next to each other. They can not be edited at once, this creates many places for the holes in the ground where players could fall. In order to avoid this, you'd need to get a seamless terain plugin that allows you to merge terrains so that their lelevation level is the same.</p>

<p>To work around the limit you should use 4 terrains that are 2km/2km instead of a 4km/4km.</p>

<p>Search the terrain plugin directory on the unity asset store.</p>

<p>FYI. Don't make the world too big. A standard game human character will need over 10 minutes of running to cross 2 kilometres.</p>
","57387"
"Play videos with LibGDX","9071","","<p>Is there a way to play videos with LibGDX?</p>

<p>I want to put a video as my splash screen in Android, but I dont want to use the Android SDK, because I am using LibGDX and I am almost finished :/</p>
","<p>Playing video with LibGDX has been <a href=""http://code.google.com/p/libgdx/issues/detail?id=146"">defined as out of scope</a> for the project. So <strong>no</strong>, you cannot play videos using LibGDX. </p>

<p>This does not preclude the possibility of writing code specific to Android to play videos though. It just means your application won't maintain the portability of LibGDX.</p>
","30611"
"Efficient Tile-based collision detection for a lot of squares?","9053","","<p>currently I am working on my own take of a tile-based game (think Terraria, but less fantastical (I think that's a word? Sorry if it isn't)). </p>

<p>Anyway, I currently have collision detection working (for corner cases even!) which was a big step for me. There is something extremely gratifying about seeing a sprite not run through a block. But then I had the idea to benchmark. Bad idea.</p>

<p>1,000 squares, no problem.
10,000 squares, for 3 characters was kind of laggy.
100,000 squares (really huge map), for 3 characters was unplayable.</p>

<p>I'm having the issue where I don't want to even consider the blocks that are too far from the player, characters, items, etc., but I don't want to load those in-out of memory constantly. </p>

<p>Here's my algorithm so far, feel free to criticize.</p>

<pre><code>foreach (Block in level)
{
    if (distance from block to player &gt; a specified amount)
        ignore this block;
    else
    {
        get the intersection depth between the two bounding boxes
        if (depth of intersection != Zero-vector)
        {
            check y size vs x size
            resolve on smallest axis
        }
    }
}
</code></pre>

<p>As you will note, when the level size get's bigger, the Order of this algorithm grows by N blocks. I would like to not even consider blocks that aren't even near the player. </p>

<p>I'm thinking maybe use a (0,0) to (mapWidth,mapHeight) double-array of blocks instead of a list, calculating a danger-zone depending on the person's position e.g., if player's position is at (10, 20) it will look from (0, 10) to (20, 30), or so on. </p>

<p>Any thoughts and considerations are awesome, thank you. </p>
","<p>Yes, you're thinking correctly. You should be using a 2D array of tiles since that allows you to index tiles by position.</p>

<pre class=""lang-cs prettyprint-override""><code>Block[,] level = new Block[width, height];
</code></pre>

<p>And since the player can only collide with its surrounding tiles, the number of collision checks you need to do is very small. This of course depends on the size of the player. The <a href=""http://create.msdn.com/en-US/education/catalog/sample/platformer"">Platformer sample</a> does it like this:</p>

<pre class=""lang-cs prettyprint-override""><code>int leftTile = (int)Math.Floor((float)characterBounds.Left / tileWidth);
int rightTile = (int)Math.Ceiling(((float)characterBounds.Right / tileWidth)) - 1;
int topTile = (int)Math.Floor((float)characterBounds.Top / tileHeight);
int bottomTile = (int)Math.Ceiling(((float)characterBounds.Bottom / tileHeight)) - 1;

for (int y = topTile; y &lt;= bottomTile; ++y)
{
    for (int x = leftTile; x &lt;= rightTile; ++x)
    {
        // Handle collisions with the tile level[x,y] just like you were doing!
    }
}
</code></pre>

<p>Check the sample if you still have any problems.</p>
","21653"
"Which university shall I choose in UK? ( game programming )","9053","","<p>I'm starting my undergraduate studies soon, but as I'm not from UK, I completly don't have idea what university should I choose.</p>

<p>Do you know any good game programming universities?</p>

<hr>

<p>Is it good idea to make computer science as undergraduate studies and game-programming as postgraduate one? I'm thankfull for all your replies, as they help me alot.</p>
","<p>When I think of people I've interviewed that have done games courses, the one that sticks in my mind is <a href=""http://www.abertay.ac.uk/studying/find/ug/"">Abertay</a> (in Scotland).</p>

<p>That said, I have to agree with U62. Doing a games course doesn't mean you'll come out the other side and fall into a job in games. I've interviewed people (and the odd lecturer) who's been on games courses from various institutions and the quality seems to vary wildly. I would expect good games ""people"" to be good no matter what course they do. I don't think many people I've interviewed and then been offered a job have come from games courses, the majority have done other courses and have a strong love of playing and writing games, with them being able to demonstrate this love via some sort of game related demo.</p>
","9139"
"Why are so many games not fully voiced?","9047","","<p>I'm wondering why so many MMOs are only partially voiced? I asked makers of games (Thimbleweed Park, in their Q&amp;A) how expensive voiceover is, and they said it wasn't especially expensive unless you hire A-list stars. So why would so much game dialogue be only present as text to be read onscreen?</p>

<p>The only reason I can think of is the same that exists for localization in all software: You can't record VO until all the dialogue is finished and frozen, so it is another fixed delay between finishing the rest of the game and shipping. So it doesn't seem like it's not manageable.</p>

<p>To be clear: I'm not looking for opinions or theories (that would only make the mods close this question) but actual reasons and experiences from people who have shipped games with partial voiceover.</p>
","<p>Because voice acting is more expensive than just the payment for the actors.</p>

<p>It's not just the voice actors you need to hire. First, you need to find voice actors which are suitable for your roles. That means you will have to do a casting with many actors, which takes you a lot of time. Then when you have picked the actors and made contracts with them, you need a professional sound studio with professional sound technicians to record their lines. These can be quite expensive too.</p>

<p>Also, voice-acted lines are a lot less flexible. Say you find out during pre-release QA testing that a certain line of text is confusing, doesn't have the effect you thought it had or is just plain wrong after you changed a few things in the game. When it's just text, then changing it is just a few keystrokes. But when the line is voiced, you need to re-hire the actor (hope he got time in his schedule), get him back into the studio and have him re-record that one line.</p>

<p>There is the problem with releasing additional content after release. Artists, writers and programmers are replaceable, but voice actors are not. When the voice actor for an important character got a different obligation, your whole DLC project might have to be cancelled.</p>

<p>And then there is the problem with dynamic text. When you have procedurally generated sentences like ""Pick up [item] from [person] in [location]"", adding a voice-over means you have to record the segments individually and then cut them together at runtime, which can sound quite strange and artificial. When your game is fully voice-acted but that line is not, then it might sound quite strange, so you better cut down the voice acting in general.</p>
","119260"
"game state saving/loading?","9031","","<p>what is the most used method or algorithm for saving game state (profiles), databases text files how there encryption goes and things related.</p>

<p>I have seen Caesar IV used mySQL.</p>

<p>any suggestions.</p>
","<p>I'm pretty sure it is most often done in a proprietary (binary) format, just writing each variable from whatever game state struct you use into a file, or reading that file back into an instance of the struct. In C++ for example you can treat an object like an array of bytes and just fwrite() it into a file, or fread() from the file and cast it back into its object form.</p>

<p>If you are using Java or another language you can opt to use <strong>serialization</strong> to make the task really easy. The Java explanation is at the bottom of this answer; other languages (higher-level than C++) surely have their own serialization libraries or built-in functions as well, which you should opt to use. No matter how inefficient the serialization routine might be, hard drive space nowadays is cheap, especially when the game state shouldn't be very large at all, and it prevents you from writing and <em>maintaining</em> your own serialization routines.</p>

<p>You should absolutely <strong>not</strong> use MySQL (just read the first sentence of <a href=""http://www.eurogamer.net/articles/r_caesariv_pc"">this review</a>). If you really need a <a href=""http://en.wikipedia.org/wiki/Relational_database"">relational database</a> for some reason, use <a href=""http://www.sqlite.org/"">SQLite</a>; it is a lightweight database system and exists in a single database file. But for most games, relational databases are not the way to go, and companies which try to use them usually end up using them as a key-value lookup table rather than a true relational database.</p>

<p><strong>Any sort of encryption of local disk files is only obfuscation</strong>; any hacker will just sniff the data right after your program decrypts it. I'm personally against that sort of thing, ESPECIALLY with one-player games. My view is that the owners of the game (paying customers, mind you) should be allowed to hack at the game if they want to. In some cases it can create a greater sense of community, and ""mods"" can be developed for your game which drive more customers to you. The most recent example that comes to mind is the <a href=""http://www.pcgamer.com/2010/08/09/portal-in-minecraft/"">Portal in Minecraft</a> mod that was recently released. It's published in gamer news sites all over the internet, and you can bet it drove up sales of Minecraft.</p>

<hr>

<p>If for some reason you are actually crazy enough to be using Java for game development like I am, here's a quick explanation of serialization in Java:</p>

<blockquote>
  <p>Keep all of your game state data in one class, make the class serializable by implementing <code>Serializable</code>, use the <code>transient</code> keyword if you mix special instantiated variables into the class (transient objects are not serialized), and simply use <code>ObjectOutputStream</code> to write to file and <code>ObjectInputStream</code> to read from file. That's it.</p>
</blockquote>
","2622"
"Why did the old 3D games have ""jittery"" graphics?","9002","","<p>I've been playing <em>""MediEvil""</em>, lately, and it got me wondering: what causes some of the old 3D games to have ""flowing"" graphics, when moving? It's present in games like <em>""Final Fantasy VII""</em>, <em>""MediEvil""</em>, and I remember <em>""Dungeon Keeper 2""</em> having the same thing in zoom mode. However, examples like <em>""Quake 2""</em> didn't have this ""issue"", and it's just as old. The resolution doesn't seem to be the problem, everything is rendered perfectly fine when you stand still. Is the game refreshing slowly, or is it something to do with buffering?</p>
","<p>I have only the <a href=""http://tvtropes.org/pmwiki/pmwiki.php/Main/Playstation"">most bizarre of citations</a> for this, but it appears on the original PlayStation, the vector unit (which was usually used to transform vertices) was capable of fixed-point operations, and the rasterizer also used fixed-point math, but only integers could be passed between the two. So you're seeing quantization artifacts: polygon corners are getting snapped to the nearest grid point. Perfectly stable for a still scene, but fairly disconcerting in motion.</p>

<p>From a little bit of additional research, it appears that the original PlayStation had different resolutions at which the rasterizer could work, from 256x224 to 740x480. So you could pick lower resolutions to get better fill rate, but you'd see these sorts of artifacts, as the grid at low resolutions is coarse enough to easily detect with the naked eye.</p>
","26826"
"How can I stop players from cheating on puzzle levels by finding solutions on the web?","8994","","<p>In a level based, puzzle-like, game, how can we prevent the gamers to be searching on the Internet for solutions to a specific level? I'd like to let players fairly compare their scores.</p>

<p>I've thought about adding some randomness to the levels, but that has the downside of losing control over how hard the level is, and how it feels.</p>

<p>Are there specific strategies to solve this issue?</p>
","<p>People reading about a game in the net is a problem for all games, not just level-based puzzle ones. For instance a simple search can give you detailed walkthrough/cheatsheet/solutions/guides to any game you can think of. Even games like Fifa or LoL that obviously has no definite solution in the first place. But that being said you can more or less control people checking for online material. Here are the few tricks I've seen being used:</p>

<ol>
<li><p>As you said adding some random elements to your levels. And it really depends on your game how it can be achieved. For example a game about guessing numbers can choose a random number each run, and give different hints about that hint, while maintaining the general idea of how to solve that puzzle. Another option is to have multiple variations of each level having minor but critical differences, and ask player to solve one of them each time. Obviously it's the best if each player has a single set of levels persistent through his own play meaning a single player shouldn't see two different variations of same level. The list continues and you can think of your own solutions, but this really is the hard answer.</p></li>
<li><p>Some games offer solution guides themselves, either online or in-game. This will reduce the change of players looking online for solutions, or others offering detailed walkthroughs. An example of this would be ""machinarium"" in which you could play a short minigame and get the solution to each chapter. You also can purposely miss some few details in the solutions you provide, this will kinda force people to solve the puzzles themselves, while discouraging them from looking online.</p></li>
<li><p>Perfecting your difficultly curve. Most people don't want to use online guides, They only ask for help if they are forced to. Since playing puzzle games in more about proving yourself you can do it. By perfecting your difficulty curve you can decrease the chance of people getting frustrated with puzzles and thus, reducing the chance of them seeking solutions from other sources.</p></li>
</ol>

<p>All that being said, people will cheat, whether you like it or not. But using these methods you can only reduce the number of times they cheat and that's the best you can hope for.</p>
","110115"
"How can I apply an outline effect in Unity?","8990","","<p>I want to apply an outline effect for several objects on the scene. Nope, the standard outline shader from the toon-shader package don't met my criteria.
I want to create an effect like this: 
<img src=""https://i.stack.imgur.com/tont5.jpg"" alt=""enter image description here""></p>

<p>To implement this effect I want to:</p>

<p>1) Render all my selected objects into a texture, taking the depth into attention. So if my selected object is occluded by another objects it must be displayed in my render texture, like this:
<img src=""https://i.stack.imgur.com/UZJrW.jpg"" alt=""enter image description here""></p>

<p>2) Render the scene.</p>

<p>3) Blur my render texture and then copy all non-null (null is empty scene) and non-one (1 is the object itself) to the screen to make it look like this: 
<img src=""https://i.stack.imgur.com/wd7tY.jpg"" alt=""enter image description here""></p>

<p>So, I have the question: How can I render the separate objects to the texture, taking care about occluders (depth)? Yep, I know about <code>Graphics.SetRenderTarget</code> <code>Graphics.DrawMeshNow</code>, but I also need to take care about the depth, because without it, it will look like this:
<img src=""https://i.stack.imgur.com/TMFhF.png"" alt=""enter image description here"">
Please help, I feel stuck.</p>
","<p>The Unity team published a nice <a href=""http://blogs.unity3d.com/2011/09/08/special-effects-with-depth-talk-at-siggraph/"" rel=""nofollow"">slide deck at SIGGRAPH 2011</a> with a whole palette of special effects that can be achieved with depth. These are low-cost when using deferred rendering, but still available when using forward rendering at the cost of a pass to create the depth texture.</p>

<p>Their outline effect is described on slides 46-47, and should be possible to adapt to your needs.</p>

<p>Instead of the Sobel Filter on depth as they suggest, just read the depth buffer at the current fragment position. If it agrees with the depth of the fragment you're rendering (within a rounding tolerance), it's your object, so output 1. If it's substantially closer, it's an occluder, so output 0. (You can also choose to output 1 only for fragments adjacent to the edges, leaving the interior 0 if you prefer)</p>

<p>After that, you can continue with the approach you've described above.</p>
","71707"
"How can I make my main character move in a parabolic arc when jumping?","8986","","<p>I'm entering Android game development, and I already have a computer version of a game I want to publish. The thing is, I want to make this as good as it can be. With that said, I need a physics engine, really to only do one thing: make a parabolic movement of my main character as he's jumping in the air. Currently, my computer version simply makes the guy move up at a 45 degree angle, and as soon as it hits the ceiling, down at a 45 degree angle. I need a physics engine/library that would accomplish that, it has to be in java since that's my best language, it has to be 2D, and it has to be able to work on Android. Which physics engine/library could accomplish all of that?</p>
","<p>You don't need a physics engine for this because the calculations required are extremely simple! All you have to do is to apply some gravity to your player's vertical velocity, and he will automatically follow an arc when jumping.</p>

<p>For a detailed explanation of how it works, including a demo that runs in the browser, read the following answer:</p>

<p><a href=""https://gamedev.stackexchange.com/a/29618/11686"">https://gamedev.stackexchange.com/a/29618/11686</a></p>

<p>But I'll transcribe the two most important points to this answer. This is all the physics you need to add to your game:</p>

<pre><code>float positionX, positionY;     // Position of the character
float velocityX, velocityY;     // Velocity of the character
float gravity = 0.5f;           // How strong is gravity

void Update(float time)
{
    velocityY += gravity * time;        // Apply gravity to vertical velocity
    positionX += velocityX * time;      // Apply horizontal velocity to X position
    positionY += velocityY * time;      // Apply vertical velocity to X position
}
</code></pre>

<p>And this is how you initiate a jump, i.e. apply a vertical impulse to the player to get him off the floor, and let gravity take care of bringing him down:</p>

<pre><code>void OnJumpKeyPressed()
{
    velocityY = -12.0f;   // Give a vertical boost to the players velocity to start jump
}
</code></pre>
","30749"
"Should I use ""conventional"" colors to represent item rarity?","8953","","<p>I'm making a new RPG that has loot. In fact, a majority of the game is based around loot. It's going to have colored borders to denote the rarity of the loot as it's drawn.</p>

<p>WoW uses Grey, White, Green, Blue, Purple, Orange and some others. GW2 uses Gray, Black, Blue, Green, Yellow, Orange, Pink, Purple. The colors don't match but you can see some distinct overlap.</p>

<p>I'm wondering if those colors are important or intuitive to users understanding of the rarity or if they can be messed with? If they can be changed how do you determine what colors to put in what order?</p>

<p>For instance, if I went with White, Blue, Green, Yellow, and Red, would that be fine as long as I made it clear in other ways or would those colors be confusing?</p>
","<p>Generally when there's a common convention that your audience may already be familiar with, the question isn't whether it's mandatory, but whether there's any reason to deviate from it.</p>

<p>If you use a colour scheme compatible with the ones used in WoW, GW2, Destiny, etc. then players who have played one of those games will have one less thing to learn to understand your game. And players who play both your game and one of those others will be less likely to get mixed up and make mistakes than if you arbitrarily swapped some of the colours.</p>

<p>That said, if you have a compelling reason to change the colours (say your entire world is under ""the violet curse"" and all low-grade common items have to be purple for narrative reasons), there's nothing to prevent you from doing so.</p>

<p>In the absence of such a reason though, sticking with a similar colour sequence costs nothing, and potentially gets you some ease-of-use wins, so sticking with the familiar convention is often worthwhile.</p>
","140588"
"Importing a .x file to 3D Studio Max?","8931","","<p>I've been googling this for a while and haven't been able to find anything (blenders importer does not work). How can I import a .x file to 3D Studio Max? There are heaps of resources in converting formats readable by Max to .x but not the other way around.</p>
","<p>If you download <a href=""http://chumbalum.swissquake.ch"" rel=""nofollow"">Milkshape</a>, you can import the DirectX file and export it as a Collada, Fbx, or Obj, which can be imported into 3DS Max.</p>
","5045"
"Unity3d NullReferenceException: Object reference not set to an instance of an object","8923","","<p>I'm making a script to climb ladders in my game.
These are the variables used in the function.</p>

<pre><code>private Vector3 climbDirection = Vector3.zero;
private Ladder currentLadder = null;
private bool latchedToLadder = false;
</code></pre>

<p>And here is the function</p>

<pre><code>void LatchLadder (GameObject latchedLadder, Collider collisionWaypoint){
    currentLadder = latchedLadder.GetComponent&lt;Ladder&gt;();
    latchedToLadder = true;
    climbDirection = currentLadder.ClimbDirection();
    gameObject.SendMessage(""OnLadder"",null,SendMessageOptions.RequireReceiver);

}
</code></pre>

<p>Everytime I collide with the ladder in playmode i get </p>

<pre><code>NullReferenceException: Object reference not set to an instance of an object
UseLadder.LatchLadder (UnityEngine.GameObject latchedLadder, UnityEngine.Collider collisionWaypoint) 
UseLadder.OnTriggerEnter (UnityEngine.Collider other) 
</code></pre>

<p>at </p>

<pre><code>climbDirection = currentLadder.ClimbDirection();
</code></pre>

<p>Anyone can see what's the cause ?</p>
","<p>The object you're colliding with does not have the Ladder component. If you try to get a component from an object that doesn't have it, <code>GetComponent</code> will return null. You should check to make the sure component isn't <code>null</code> before doing anything with it, but you should probably make sure the object you're trying to latch on to is a ladder in the first place. You can do that by checking to see if it has the ladder component.</p>

<p>Before you call <code>LatchLadder</code>, perform a check similar to:</p>

<pre><code>//inside your collide function
if(collidedGameObject.GetComponent&lt;Ladder&gt;() != null) {
    //it has the ladder component, it's a ladder
    LatchLadder(collidedGameObject, collisionWaypoint);
} else {
    //we've collided with something that isn't a ladder, do something else.

}
</code></pre>
","67373"
"What is the purpose of the canonical view volume?","8913","","<p>I'm currently learning OpenGL and haven't been able to find an answer to this question.</p>

<p>After the projection matrix is applied to the view space, the view space is ""normalized"" so that all the points lie within the range [-1, 1]. This is generally referred to as the ""canonical view volume"" or ""normalized device coordinates"". </p>

<p>While I've found plenty of resources telling me about how this happens, I haven't seen anything about <em>why</em> it happens.</p>

<p>What is the purpose of this step?</p>
","<p>The most important is that it converts yours points(vertices) from 3D world space to 2D screen space. </p>

<p>That means that after vertex is multiplied with this matrix X and Y coords are position on the screen (between [-1, 1]) and Z is the depth. Z is used for depth-buffer and identifies how far is vertex (or fragment) from your cameras near plane. </p>

<p>Projection means that vertices which are more near from near plane are more far from middle of the screen -> triangle more near to camera appears to be bigger that one that is far. And this is based on yours field of view - you are entering it in some createProjectionMatrix function or createFrustum. It works that it shears and scales yours camera frustum and vertices in it into unit cube. Values that are greater than 1 and smaller than -1 are not displayed.</p>

<p>Also keeps pixel aspect ratio, so pixel can be sqaure. That is simple. It just shears camera frustum like this: more wider screen -> more vertical shear and vice versa.</p>

<p><strong>Simple answer:</strong><br>
It defines yours camera frustum and is good to:</p>

<ul>
<li>make objects which are near to you look bigger than objects that are far from you.</li>
<li>keep pixel aspect ratio - Everybody likes square pixel right? :)</li>
</ul>
","6284"
"What popular/famous games are written in C?","8910","","<p>It is very similar to this question: <a href=""https://gamedev.stackexchange.com/questions/3789/famous-games-written-in-java"">https://gamedev.stackexchange.com/questions/3789/famous-games-written-in-java</a></p>

<p>Does anyone know of any popular or famous games only written in C?</p>
","<p>Doom, Quake, pretty much all id games up until id Tech 4.</p>
","15391"
"How should multiplayer games handle authentication?","8902","","<p>I've been lurking around to understand how an authentication system would work in games, but after many searches, it seems that working with ssl/certificates could be a little complicated for just a multiplayer game with a lot less capacity than an MMO. </p>

<p>I know that successful multiplayer games need this, but I'd like to check if other multiplayer games commonly take this precautions.</p>

<p><strong>EDIT</strong>: I'll describe what I have in mind. The server not only handles game logic, but also authentication. So, in order to play on a specific server (that everyone could start), you first need to register an account on the server, and each time you want to play there, login as usual (password/name user).</p>

<p>My question is, would not providing a secure channel for logging in/registering an account be forgivable/understandable in this context? Also I'm interested to know how games with a similar architecture would handle this matter.</p>
","<p>Specifically regarding the last bit of your question: No, it is never forgivable to have an insecure authentication system.  Users are rarely enlightened when it comes to computer security.  Users use the same password for your little game as they do for their Google account, Facebook account, bank account, and so on.  Even if you can claim that it's their fault for using poor Internet security habits, you're the one who will be held responsible if your game is used as an attack vector to steal users' login credentials.  As a developer who knows better, the only ethical options are to properly secure your authentication process or to not have one at all.</p>

<p>As some unsolicited but related advice, users don't want to be required to sign up for your game anyway.  They might do so if they want to play your game badly enough, but having Yet Another Freaking Login to sign up for is going to just drive away many potential players.  Users are sick to death of making a new account for every single site, service, and game out there, <em>especially</em> if they require any kind of email validation or the like.  If you can, either avoid having a login at all, or use an existing third-party authentication service that users likely already have an account with.  You will have more players that way.  This goes triple if you plan on having any kind of in-app purchases.</p>

<p><strong>Web Games</strong></p>

<p>A popular option -- particularly for Web games, though it also works for traditional games -- is to use a Web-based third-party authentication service.  Facebook and Google both have well-documented APIs (both based on standardized APIs, iirc) for authentication.  They do require the ability to open a browser window and direct the user towards their services, but this is pretty easy to do on most non-console platforms, and of course trivial for Web games.</p>

<p>Those services take care of all the messy details of encrypting login traffic over the wire, securely storing login credentials, and validating user logins.  Your game server then needs only implement the portion of the protocol that receives a cookie from the user and asks the authentication service if the cookie is valid or not, which can be done with a simple HTTP in most cases.</p>

<p>I won't claim most traditional multiplayer games do this, because they don't, but I will claim that most online casual Web games do this.</p>

<p>For traditional (non-Web) games, facilitating this login procedure is possible by either embedding a browser (Awesomium, Chromium Embedded Framework, or straight up Webkit being popular choices) or by calling out to an external browser (this takes some more fanagling to get the auth cookie out of though, and isn't really any easier than embedding one of the aforementioned libraries).</p>

<p>A typical example of this approach is any Facebook game.</p>

<p><strong>Traditional Games using HTTPS</strong></p>

<p>Having a simple HTTPS service for login is increasingly normal.  Many games use custom protocols, but most of these are incomplete (they have secure login, but no secure way to create/update an account, so they need the HTTPS service anyway) or are simply horrifically insecure.</p>

<p>You don't even need to go about getting a custom SSL cert.  There are online app hosting providers that give you a subdomain and use a wildcard SSL cert.  You can put your authentication service at mygame.someservice.com, which is covered by the *.someservice.com wildcard cert that Some Service maintains, and you're good to go.</p>

<p>The idea here is that the user logs in to your service, which generates a unique session cookie, which the user can then pass into your main game server.  The server then asks the login system if the cookie is valid for the requested user.  There's usually a <em>very</em> short timeout on the cookie, on the order of seconds (15-30, for example), and it's generally invalidated once used, making replay attacks impossible.</p>

<p>Note that HTTPS is my most recommended option if you plan on sending payment information over the wire from inside the client itself.  However, it's significantly better to use a third-party for this.  If you think securing something as simple as a password is too much work, you don't even want to even think about trying to meet the minimum (and honestly quite inadequate) PCI compliance rules for storing and processing credit card numbers.  You'll have better sales uptake anyway if you have users use trusted third-party payment services that they're already on file with.</p>

<p>One strong advantage of separating your login service from the main game server is that it allows external functionality to be tied to user accounts independent of the game.  You might have some account features (viewing avatars or such) on your website, or perhaps you allow linking Facebook accounts into your accounts, or perhaps you have multiple games sharing a single underlying account platform (e.g., the Galaxy at War features of Mass Effect 3).</p>

<p>A popular example game using HTTPS for authentication is Minecraft.</p>

<p><strong>Third-Party Web Authentication with Native Client Games</strong></p>

<p>It is possible to use third-party services like Facebook Connect or Google with a native client.  Facebook for example has a native SDK for iOS and Android, as does Google.  Some services likewise have native SDKs for traditional PC clients.</p>

<p>If the target service does not having a native SDK and requires the use of a Web browser, you could just embed a browser in your game.  However, some users may be distrustful of using an embedded browser to enter login information.</p>

<p>You can also use an external browser.  There are a few ways to pull this off.  Some require a little bit more OS-integration than others.  Some require you to have an external Web service running alongside (or at least reachable by) your main game server.  Note that since Facebook and Google generally require a URL that is authenticated, you will need a public website landing page to use these protocols in (almost) all cases.</p>

<p>The most fool-proof and reliable, if not quite the easiest, is to bounce your login request from your client through your main website.  Your client connects to the main game server as an authenticated guest user and receives a unique session token.  The game server does not allow the client to actually do much while in this state; the game doesn't know who the player is, so the player cannot yet chat, start a match, or so on.</p>

<p>The client then launches the external browser pointing at the login URL of your game's domain, passing this session token as a parameter in the URL.  The site then goes through the usual login handshake for Facebook/Google.</p>

<p>At this point, your webserver knows that the user has logged in, and can associate that with the session token it received from the client.  This verification can then communicated to the game server, elevating the client's unauthenticated guest connection into an authenticated user session.  This can be done by having the webserver directly communicate with the game server, if possible.  Or the game server can periodically poll the webserver for authentication status of pending guest connections.  Or the client can periodically poll the webserver to see if login is complete and, when it is, signal the game server to request verification from the webserver.</p>

<p>All of these require that your game server and webserver be able to communicate, but <em>any</em> third party authentication service will require your game server to be able to communicate with the outside world, so this shouldn't be a surprise.</p>

<p>This authentication method is found in some small-to-mid-sized MMOs.</p>

<p>Note that this all also works for making payment requests through an external service, like PayPal, Amazon Payments, Google Wallet, etc.</p>

<p><strong>Direct TLS Connection</strong></p>

<p>It is not too difficult to start a TLS session over a custom stream protocol.  Libraries like OpenSSL, GnuTLS, NSS, and various OS-specific libraries provide a stream wrapper API that layers over a low-level transport/protocol. You generally just need to feed bytes through the wrapper API and it deals with the handshake and encryption.</p>

<p>The tricky parts here are ensuring your use of TLS is safe.  Some of the common libraries for example will by default require a valid signed certificate from a trusted authority.  Some of the common libraries require that, but by default don't trust any authorities.  Some of them do not require that the cert be valid at all.</p>

<p>It is recommended that you always require a valid cert.  Allowing invalid certs will not allow an attacker who is merely eavesdropping to steal a password, but it will still allow man-in-the-middle attacks.</p>

<p>This approach requires the absolute least in terms of external dependencies while still allowing maximum security.</p>

<p>Examples of games using this now include most big traditional MMOs.</p>

<p><strong>Secure(ish) Traditional Games</strong></p>

<p>Games that don't use a separate service and don't use TLS typically have to implement some kind of nonce-based login protocol in their main game protocol.  With this method, the server generates a random number (a nonce) and sends that to the client.  The client then hashes that nonce with the user's password (and username, possibly some other data) and sends that response to the server.  The server then compares this hashed value with the credentials it has on file.  This keeps the user's password secrete over the wire and ensures that you can't use a simple replay attack on the hashed password, like many other weak hash-based login schemes.</p>

<p>A problem is that the user has no way to submit a new password to the service over this protocol securely.  Typical implementations also store the user's password in plaintext on the server, which is a horrible practice (if your server gets hacked, your user probably just had his email/facebook/bank password stolen, because he was using the same password for your game as everywhere else, because users tend to do that).</p>

<p>There are enhanced versions of that basic login scheme.  The most basic -- though still not ideally secure -- is for the server to send the password hash salt with the nonce value during login.  This allows the server to stored a hashed (and salted) password securely while allowing the client to generate the same hash during login.  This does allow an attacker to get the salt for a particular user's password, but this is not particularly useful without also getting the original hashed password (which is not sent over the wire during login).  During creation/updating of the password, the client sends the whole hashed password (with salt), which the attacker can sniff.  If the hash function used is strong enough (say, sha-2/512) then pure brute forcing is not feasible, though the attacker can still easily brute-force weak passwords (which is why enforcing some minimum password length, minimum distribution of letters/numbers/symbols, and comparing to a dictionary of known/obvious/weak passwords is important).  The fact that the attacker can still get the hashed password is why it still more secure to do the entire password exchange over a secured, encrypted channel.</p>

<p>A number of popular game networking libraries implement some optional form of this protocol.  I believe SmartFox is one such example, though I haven't looked at it in depth (I generally ignore any such library auth system and use the HTTPS method, since it's dead simple to implement and significantly stronger).  A number of early non-Web Internet games also used this approach, particularly before Steam, XBL, and so on came around.</p>

<p><strong>Unsecure Traditional Games</strong></p>

<p>A lot of games unfortunately just send a username/password in plaintext.  Maybe they hash the password, which vaguely kind-of protects the users actual password (not nearly well enough) but a replay attack makes logging into the game service trivial.</p>

<p>Don't do this.  It's irresponsible and lazy.  The Internet naiveté of the 1990's that popularized these login methods is no longer a viable excuse.</p>

<p>Many early pre-Facebook Flash and web games took this approach.  I don't know of any specific examples off the top of my head; I'd like to believe they're all long dead, but the world just isn't that lucky.</p>

<p><strong>No Authentication</strong></p>

<p>Most games just don't do authentication.  The player connects, sends over some handle to uniquely identify himself, and a match starts.  There is no global server that tries to validate that only one real human is ever allowed to claim to be ""CaptainMisterDude"".  The local server just ensures that only one currently connected player has any particular handle, and that's the end of it.  Local servers use name-based and IP-based blacklisting for trouble makers.  This is common for FPS deathmatch style games even today.</p>

<p>If you don't need any permanent state for accounts, this is by far the easiest solution, and quite ""secure"" since there's nothing there to actually hack or steal.  Obviously this doesn't work too well if you do need to store account information between game sessions.</p>

<p>Quake is an example of a game using this method of ""authenticating"" users.</p>
","46595"
"Mapping a Vertex Buffer in DirectX11","8901","","<p>I have a VertexBuffer that I am remapping on a per frame base for a bunch of quads that are constantly updated, sharing the same material\index buffer but have different width/heights. However, currently right now there is a really bad flicker on this geometry.</p>

<p>Although it is flickering, the flicker looks correct. I know it is the vertex buffer mapping because if I recreate the entire VB then it will render fine. However, as an optimization I figured I would just remap it. Does anyone know what the problem is?</p>

<p>The length (width, size) of the vertex buffer is always the same.</p>

<p>One might think it is double buffering, however, it would not be double buffering because it only happens when I map/unmap the buffer, so that leads me to believe that I am setting some parameters wrong on the creation or mapping.</p>

<p>I am using DirectX11, my initialization and remap code are:</p>

<h3>Initialization code</h3>

<pre><code>  D3D11_BUFFER_DESC bd;
  ZeroMemory( &amp;bd, sizeof(bd) );
  bd.Usage = D3D11_USAGE_DYNAMIC;
  bd.ByteWidth = vertCount * vertexTypeWidth;
  bd.BindFlags = D3D11_BIND_VERTEX_BUFFER;
  //bd.CPUAccessFlags = 0;
  bd.CPUAccessFlags = D3D11_CPU_ACCESS_WRITE;

  D3D11_SUBRESOURCE_DATA InitData;
  ZeroMemory( &amp;InitData, sizeof(InitData) );
  InitData.pSysMem = vertices;

  mVertexType = vertexType;

  HRESULT hResult = device-&gt;CreateBuffer( &amp;bd, &amp;InitData, &amp;m_pVertexBuffer );

  // This will be S_OK
  if(hResult != S_OK)
     return false;
</code></pre>

<h3>Remap code</h3>

<pre><code>  D3D11_MAPPED_SUBRESOURCE resource;
  HRESULT hResult = deviceContext-&gt;Map(m_pVertexBuffer, 0,
     D3D11_MAP_WRITE_DISCARD, 0, &amp;resource);

  // This will be S_OK
  if(hResult != S_OK)
     return false;

  resource.pData = vertices;

  deviceContext-&gt;Unmap(m_pVertexBuffer, 0);
</code></pre>
","<p>When you invoke Map with D3D11_MAP_WRITE_DISCARD, Direct3D considers the whole buffer contents invalid and will replace it with the data that exists inside the memory that the new data buffer points at when invoking Unmap.</p>

<p>Your problem is that instead of copying your data into the memory that Direct3D provides to you when you map the buffer, you instead change the pointer to point somewhere else.</p>

<p>Direct3D does not expect that, nor will care about where the pointer points. It will just assume that you've filled in the buffer that the pData pointer originally pointed at.</p>

<p>The reason for your flicker is because the buffer may contain bogus uninitialized data, as it expects you to fill it in completely.</p>
","15655"
"How do I make magenta in my PNG transparent in HTML5/Canvas/JS?","8894","","<p>I'm putting together a simple hex map to use within an HTML5 / Canvas / JS game and before I get round to sorting any custom graphics, I was wondering if anybody knew how to make the pink/magenta backgrounds transparent so that I can overlap my tiles?</p>

<p>Cheers!</p>
","<p>As thedaian mentioned in his comment, converting the magenta pixels to transparent in JavaScript is going to be slow. You should convert your images to a suitable format beforehand.</p>

<p><a href=""http://www.imagemagick.org/"">ImageMagick</a> can be really useful for this kind of tasks. Converting your tile with magenta background to an image with transparency is as simple as this:</p>

<pre><code>convert myOpaqueTile.png -transparent ""#FF00FF"" myTransparentTile.png
</code></pre>

<p>This will convert your file with magenta background (<code>myOpaqueTile.png</code>) to a file with a transparent background (will be saved as <code>myTransparentTile.png</code>).</p>

<p>Of course you could also use Photoshop, GIMP or something like Paint.NET for this.</p>

<hr>

<p><strong>Update:</strong> If you want to do the whole thing in code (JavaScript), then look into the <code>getImageData</code> function of the HTML5 canvas element. Here's an <a href=""http://beej.us/blog/2010/02/html5s-canvas-part-ii-pixel-manipulation/"">article about canvas image manipulation</a>.</p>

<p>And here's some sample code that will convert magenta pixels to transparent ones in JavaScript:</p>

<pre class=""lang-js prettyprint-override""><code>// source file to load
var file = ""testData.png"";

// color to make transparent. Magenta here...
var transparentColor = {
    r : 255,
    g : 0,
    b : 255
};

var img = new Image();
img.src = file;
img.onload = function(){
    // create a source canvas. This is our pixel source
    var srcCanvas = document.createElement(""canvas"");
    srcCanvas.width = img.width;
    srcCanvas.height = img.height;

    // create a destination canvas. Here the altered image will be placed
    var dstCanvas = document.createElement(""canvas"");
    dstCanvas.width = img.width;
    dstCanvas.height = img.height;

    // append the canvas elements to the container
    document.getElementById('container').appendChild(srcCanvas);
    document.getElementById('container').appendChild(dstCanvas);

    // get context to work with
    var srcContext = srcCanvas.getContext(""2d"");
    var dstContext = dstCanvas.getContext(""2d"");

    // draw the loaded image on the source canvas
    srcContext.drawImage(img, 0, 0);

    // read pixels from source
    var pixels = srcContext.getImageData(0, 0, img.width, img.height);

    // iterate through pixel data (1 pixels consists of 4 ints in the array)
    for(var i = 0, len = pixels.data.length; i &lt; len; i += 4){
        var r = pixels.data[i];
        var g = pixels.data[i+1];
        var b = pixels.data[i+2];

        // if the pixel matches our transparent color, set alpha to 0
        if(r == transparentColor.r &amp;&amp; g == transparentColor.g &amp;&amp; b == transparentColor.b){
            pixels.data[i+3] = 0;
        }
    }

    // write pixel data to destination context
    dstContext.putImageData(pixels,0,0);
}
</code></pre>
","19258"
"Convert Screen coords to World Coords LIBGDX","8889","","<p>I'm working on a tile based platformer game in libgdx. I'm having trouble getting the actual touch input coordinates when the aspect ratio of device is different from the virtual fixed aspect ratio that I'm working on. I'm using a virtual resolution of 480x800. All the rendering work and camera work is being done in GameRenderer class and the input is being handled in InputHandler class. I've tried implementing the camera.unproject() method but it won't do any good. I've added the unproject method in GameRenderer class since my camera is defined here. Then I've sent the screen touch coords from the InputHandler class to the GameRenderer class and returned the converted coords back to InputHandler.</p>

<p>I'm posting the relevant code from both classes.</p>

<p>GameRenderer:</p>

<pre><code>public class GameRenderer 
{
    public static OrthographicCamera cam;
    private ShapeRenderer shapeRenderer;
    private SpriteBatch batcher;
    private static Player player=GameWorld.getPlayer();

    private static final int VIRTUAL_WIDTH = 800;
    private static final int VIRTUAL_HEIGHT = 480;
    private static final float ASPECT_RATIO = (float)VIRTUAL_WIDTH/(float)VIRTUAL_HEIGHT;
    private Rectangle viewport;
    public static Vector2 crop = new Vector2(0f, 0f); 
    public static float scale = 1f;
    public static int Case=0;
    public static float width;
    public static float height;
    public static float w;
    public static float h;

    public GameRenderer(GameWorld world) 
    {
        cam = new OrthographicCamera();
        cam.setToOrtho(true, 800, 480);
        batcher=new SpriteBatch();
        batcher.setProjectionMatrix(cam.combined);
        shapeRenderer = new ShapeRenderer();
        shapeRenderer.setProjectionMatrix(cam.combined);
    }


    public void render()
    {
        cam.update();
        Gdx.gl.glClearColor(0, 0, 0, 1);
        Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);

        height=Gdx.graphics.getHeight();
        width=Gdx.graphics.getWidth();

        float aspectRatio = (float)width/(float)height;


        if(aspectRatio &gt; ASPECT_RATIO)
        {
            scale = (float)height/(float)VIRTUAL_HEIGHT;
            crop.x = (width - VIRTUAL_WIDTH*scale)/2f;
            Case=1;
        }
        else if(aspectRatio &lt; ASPECT_RATIO)
        {
            scale = (float)width/(float)VIRTUAL_WIDTH;
            crop.y = (float)(height - VIRTUAL_HEIGHT*scale)/2f;
            Case=2;
        }
        else
        {
            scale = (float)width/(float)VIRTUAL_WIDTH;
        }

        w = (float)VIRTUAL_WIDTH*scale;
        h = (float)VIRTUAL_HEIGHT*scale;


        viewport = new Rectangle(crop.x, crop.y, w, h);

        Gdx.gl.glViewport((int) viewport.x, (int) viewport.y, (int) viewport.width, (int) viewport.height);

        switch(GameWorld.state)
        {
            case Running: renderRunning(); break;
            case GameOver: renderGameOver(); break;
            case Paused: renderPaused(); break;
            default: break;
        }

    }

    public static Vector3 unprojectCoords(Vector3 coords)
    {
        cam.unproject(coords);
        return coords;
    }

}
</code></pre>

<p>InputHandler:</p>

<pre><code>public class InputHandler implements InputProcessor 
{

    @Override
    public boolean touchDown(int screenX, int screenY, int pointer, int button) 
    {

        Vector3 coords=new Vector3(screenX,screenY,0);
        Vector3 coords2=GameRenderer.unprojectCoords(coords);

        screenX=(int) coords2.x;
        screenY=(int) coords2.y;

        switch(GameWorld.state)
        {
            case Running:
            {
                if(GameRenderer.jumpButton.isTouchDown((int)screenX, (int)screenY))
                {
                    if(player.isJumped() == false)
                    {
                        player.jump();
                        if(!GameWorld.soundMuted) AssetLoader.jump.play(AssetLoader.SOUND_VOL);
                    }

                }




        return false;
    }

    @Override
    public boolean keyDown(int keycode) 
    {
        switch(GameWorld.state)
        {
            case Running:
            {
                if(keycode==Keys.SPACE)
                {
                    if(player.isJumped() == false)
                    {
                        player.jump();
                        if(!GameWorld.soundMuted) AssetLoader.jump.play(AssetLoader.SOUND_VOL);
                    }
                }

                if(keycode==Keys.LEFT)
                {
                    leftDown=true;
                }

                if(keycode==Keys.RIGHT)
                {
                    rightDown=true;
                }

                if(keycode==Keys.CONTROL_RIGHT)
                {
                    player.shoot();
                }
                break;
            }

            default: break;
        }

        return false;
    }



}
</code></pre>
","<p>Try using this <code>Camera:unproject</code> method:</p>

<p><code>unproject(Vector3 screenCoords, float viewportX, float viewportY, float viewportWidth, float viewportHeight)</code></p>

<p>from the <a href=""http://libgdx.badlogicgames.com/nightlies/docs/api/com/badlogic/gdx/graphics/Camera.html#unproject-com.badlogic.gdx.math.Vector3-float-float-float-float-"" rel=""noreferrer"">documentation:</a></p>

<blockquote>
  <p>Function to translate a point given in screen coordinates to world space. It's the same as GLU gluUnProject, but does not rely on OpenGL. The x- and y-coordinate of vec are assumed to be in screen coordinates (origin is the top left corner, y pointing down, x pointing to the right) as reported by the touch methods in Input. A z-coordinate of 0 will return a point on the near plane, a z-coordinate of 1 will return a point on the far plane. This method allows you to specify the viewport position and dimensions in the coordinate system expected by GL20.glViewport(int, int, int, int), with the origin in the bottom left corner of the screen.</p>
</blockquote>
","79127"
"Why does my machine render OpenGL using my onboard chipset instead of my graphics card?","8867","","<p>I'm following an OpenGL tutorial series at opengl-tutorial.org, but have run into a problem:</p>

<p>The following lines:</p>

<pre><code>glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3);
glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3);
glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE);
</code></pre>

<p>cause my <code>glfwCreateWindow()</code> call to return null.</p>

<p>As I understand, this is caused by lack of support for OpenGL 3.3.</p>

<p>Why is my machine trying to render OpenGL 3.3 using my onboard graphics chipset (Intel HD Graphics 3000, which only supports OpenGL 3.1) instead of using my dedicated graphics card (GeForce 520M, which supports OpenGL 4.x)? I think this has something to do with power saving.</p>

<p>Note: I have newly updated nVidia drivers, installed as of yesterday. I know they are working because if I right-click my desktop I get a context menu for nVidia Control Panel.</p>

<p>Running OpenGL Extensions Viewer 4.x also displays that I'm using Intel HD Graphics 3000, supporting OpenGL &lt;= 3.1, which is consistent with my theory regarding power saving.</p>

<p>Regards,</p>
","<p><a href=""http://developer.download.nvidia.com/devzone/devcenter/gamegraphics/files/OptimusRenderingPolicies.pdf"" rel=""nofollow"">This</a> is the NVidia manual to their Optimus, the driver which is responsible of switching between integrated GPU and NVidia GPU. From a quick look, it seems they describe how to set the default GPU for a program. I haven't tried it yet though.</p>
","72506"
"OpenGL ES 2.0: Controlling Transparency in Fragment Shader","8855","","<p>The following is the OpenGL ES 2.0 simple <strong>GLSL Fragment Shader</strong>, I use to place textures on polygons, to render 2D sprites.</p>

<pre><code>varying mediump vec2 TextureCoordOut;
uniform sampler2D Sampler;

void main()
{
gl_FragColor = texture2D(Sampler, TextureCoordOut);
//gl_FragColor = vec4(texture2D(Sampler, TextureCoordOut).xyz, TextureCoordOut.w * 0.5);

}
</code></pre>

<p>The fragment shader places voxels with alpha information taken from the source 2D texutre(.png image). Apart from alpha information, I need to control overall polygon/sprite transparency to achieve <strong>Fade In/Fade Out</strong> effects.</p>

<p>Could you show me, please, how to <strong>modify the above shader</strong> to control the overall transparency, besides the alpha information?</p>

<p><em>Note: The commented out line is used for my attempts to achieve the transparency. I wish to <strong>combine</strong> both the alpha information with the overall polygon/sprite transparency.</em>  </p>

<p>Thanks.</p>
","<p>This is probably cleaner solution, which also doesn't require to ask texture unit two times. </p>

<pre><code>void main()
{
  gl_FragColor = texture2D(Sampler, TextureCoordOut);
  gl_FragColor.a *= 0.5;
}
</code></pre>

<p>(maybe compiler does that for you, but what if not. Especially on the opengl-es device performance difference <em>may be observed</em>)</p>
","12762"
"How to place a sprite in the center of the world in Phaser","8850","","<p>I am very new to Phaser. Here is what I did:</p>

<pre><code>  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
    &lt;body&gt;
    &lt;script src=""phaser.js""&gt;&lt;/script&gt;
    &lt;script&gt;
        var game = new Phaser.Game(500, 500, Phaser.AUTO, '', {
            preload : preload,
            create : create,
            update : update
        });

        function preload() {
            game.load.image('dog', 'assets/dog.png');
        }

        function create() {
            game.stage.backgroundColor = ""#1BDCFF"";
            game.physics.startSystem(Phaser.Physics.ARCADE);
            game.physics.startSystem(Phaser.Physics.ARCADE);
            dog = game.add.sprite(game.world.centerX, game.world.centerY, 'dog');
            game.physics.arcade.enable(dog);
        }

        function update() {

        }

    &lt;/script&gt;
&lt;/body&gt;
</code></pre>

<p></p>

<p>Shouldn't the dog appear in the center of the ""world""?
Here is how it looks like :
<img src=""https://i.stack.imgur.com/BYXD7.png"" alt=""dog image""></p>

<p>I then tried something like this :</p>

<pre><code>var dogImage = game.cache.getImage('dog'); 
dog = game.add.sprite(game.world.centerX-dogImage.width/2, game.world.centerY-  dogImage.height/2, 'dog');
</code></pre>

<p>And now that I edited in this way the create function it does place the dog in the center. Is this the way of doing it or there's a more elegant way ?</p>
","<p>Valkea has the right idea, but I recommend you modify the <code>anchor</code> of your Sprite to what you intend - in this case, the center of the sprite. If you were using P2 or Ninja physics, this is done automatically for you, but with Arcade physics, this defaults to the top-left corner. Simply call <code>&lt;your sprite&gt;.anchor.setTo(0.5);</code> to set both the x and y anchors to the middle.</p>

<p>Doing this will save you from having to account for the top left corner everywhere. The anchor point is used when transforming (flips, rotations, scales), measuring distances, when specifying a different collision box size than your sprite, and many more.</p>

<p>Have a look at the <a href=""http://phaser.io/examples/v2/sprites/anchor"">Phaser anchor example</a> for a visual representation of the anchor and how it affects sprite positioning.</p>

<p><strong>Update:</strong> the <code>anchor</code> property now belongs to <code>Sprite</code>.</p>
","81299"
"How to render a retro-like pixel graphics from 3d models?","8845","","<p>I was wondering if there's a possibility to render a retro-pixel-like graphics from 3d model in real time?</p>

<p>I'm talking about the <a href=""http://fractalsoftworks.com/media/"" rel=""nofollow"">Starfarer-like</a> graphics.
I know it's hand drawn, and it's 2d.
But if I need a 3d objects with the same aesthetics?</p>

<p>I'm currently working with Flash. But I don't need any ready-solutions, I just want to understand the principle from any other platform if there is one.
So if anybody met anything like this I would appreciate your help.
(If it's not possible to do in real time, I could at least pre-render a sequence of sprites. It would be much better than creating hundreds of hand-drawn ones)</p>
","<p>In 3D those kind of aesthetic effects can be done via a combination of shaders and textures.  From the photos you provided, you could probably replicate the effect in 3D using cel-shading (essentially a toon-shader).  Cel-shading basically defines hard-cutoffs for colors when computing lighting, giving the object a hand-drawn look.  <a href=""http://en.wikipedia.org/wiki/Cel-shaded_animation"" rel=""nofollow"">Here's a few examples.</a>.  The most important part of getting the effect you're looking for though would be in the texturing of the models.  I would say texture them with the same art style and it would look great.</p>

<p>Definitely something you can do in real-time :)</p>
","26643"
"How to move an object along a circumference of another object?","8836","","<p>I am so out of math that it hurts, but for some of you this should be a piece of cake.
I want to move an object around another along its ages or circumference on a simple circular path. At the moment my game algorithm knows how to move and position a sprite just at the edge of an obstacle and now it waits for the next point to move depending on various conditions. </p>

<p>So the mathematical problem here is how to get <strong>(aX, aY)</strong> and <strong>(bX, bY)</strong> positions, when I know the Centre <strong>(cX, cY),</strong> the object position <strong>(oX, oY)</strong> and the distance required to move <strong>(d)</strong></p>

<p><img src=""https://i.stack.imgur.com/unuYv.jpg"" alt=""enter image description here""></p>
","<p>(<strong>CAVEAT:</strong> I'm using two approximations here: the first takes d as an arc length, and the second takes it as an orthogonal length.  Both of these approximations should be good for relatively small values of d, but they don't fulfill the precise question as clarified in comments.)</p>

<p>The math on this, fortunately, is relatively straightforward.  First of all, we can find the relative vector from our center position to our current position:</p>

<pre><code>deltaX = oX-cX;
deltaY = oY-cY;
</code></pre>

<p>And once we have this relative vector, then we can know the radius of the circle we're working on by finding the length of it:</p>

<pre><code>radius = sqrt(deltaX*deltaX+deltaY*deltaY);
</code></pre>

<p>What's more, from our relative vector we can find the precise angle that the line from cX to oX is at:</p>

<pre><code>curTheta = atan2(deltaX, deltaY);
</code></pre>

<p>Now things get a little bit trickier.  First of all, understand that the circumference of a circle &mdash; that is, the 'arc length' of an arc with an angular measure of 2&pi; &mdash; is 2&pi;r.  In general, the arc length of an arc with an angular measure of &theta; along a circle of radius r is just &theta;r.  If we were to use the d in your diagram as the arc length, and since we know the radius, we can find the change in theta to get us to the new position by just dividing out:</p>

<pre><code>deltaTheta = d/radius; // treats d as a distance along the arc
</code></pre>

<p>For the case where d needs to be a linear distance, things are a little more complicated, but fortunately not much.  There, d is one side of an isoceles triangle whose other two sides are the radius of the circle (from cX/cY to oX/oY and aX/aY respectively), and bisecting this isoceles triangle gives us two right triangles, each of which has d/2 as one side and radius as the hypotenuse; this means that the sine of half our angle is (d/2)/radius, and so the full angle is just twice this:</p>

<pre><code>deltaTheta = 2*asin(d/(2*radius)); // treats d as a linear distance
</code></pre>

<p>Notice how if you took the asin out of this formula, and cancelled the 2s, this would be the same as the last formula; this is the same as saying that sin(x) is approximately x for small values of x, which is a useful approximation to know.</p>

<p>Now we can find the new angle by just adding or subtracting:</p>

<pre><code>newTheta = curTheta+deltaTheta; // This will take you to aX, aY. For bX/bY, use curTheta-deltaTheta
</code></pre>

<p>Once we have the new angle, then we can use some basic trig to find our updated relative vector:</p>

<pre><code>newDeltaX = radius*cos(newTheta);
newDeltaY = radius*sin(newTheta);
</code></pre>

<p>and from our center position and our relative vector we can (finally) find the target point:</p>

<pre><code>aX = cX+newDeltaX;
aY = cY+newDeltaY;
</code></pre>

<p>Now, with all this, there are some <em>big</em> caveats to be aware of.  For one, you'll notice that this math is mostly floating-point, and in fact it almost has to be; trying to use this method to update in a loop and rounding back to integer values at every step can do everything from making your circle not close (either spiralling inward or outward every time you go around the loop) to not getting it started in the first place!  (If your d is too small, then you might discover that the rounded versions of aX/aY or bX/bY are exactly where your start position oX/oY was.)  For another, this is very expensive, especially for what it's trying to do; in general, if you know your character is going to be moving in a circular arc, you should plan out the whole arc in advance and <em>not</em> tick it from frame to frame like this, since many of the most expensive calculations here can be front-loaded to cut down on costs.  Another good way to trim back the costs, if you really want to update incrementally like this, is to not use trig in the first place; if d is small and you don't need it to be <em>exact</em> but just very close, then you can do a 'trick' by adding a vector of length d to oX/oY, orthogonal to the vector towards your center (note that a vector orthogonal to (dX, dY) is given by (-dY, dX) ), and then shrink it down to the right length.  I won't explain this code quite so step-by-step, but hopefully it'll make sense given what you've seen so far.  Note that we 'shrink down' the new delta vector implicitly in the last step, where we add it to our center to get the updated point:</p>

<pre><code>deltaX = oX-cX; deltaY = oY-cY;
radius = sqrt(deltaX*deltaX+deltaY*deltaY);
orthoX = -deltaY*d/radius;
orthoY = deltaX*d/radius;
newDeltaX = deltaX+orthoX; newDeltaY = deltaY+orthoY;
newLength = sqrt(newDeltaX*newDeltaX+newDeltaY*newDeltaY);
aX = cX+newDeltaX*radius/newLength; aY = cY+newDeltaY*radius/newLength;
</code></pre>
","31222"
"FrameBuffer Render to texture not working all the way","8817","","<p>I am learning to use Frame Buffer Objects. For this purpose, I chose to render a triangle to a texture and then map that to a quad.</p>

<p>When I render the triangle, I clear the color to something blue. So, when I render the texture on the quad from fbo, it only renders everything blue, but doesn't show up the triangle. I can't seem to figure out why this is happening. Can someone please help me out with this ? </p>

<p>I'll post the rendering code here, since <code>glCheckFramebufferStatus</code> doesn't complain when I setup the FBO. I've pasted the setup code at the end. Here is my rendering code:</p>

<pre><code>void FrameBufferObject::Render(unsigned int elapsedGameTime)
{
    glBindFramebuffer(GL_FRAMEBUFFER, m_FBO);
    glClearColor(0.0, 0.6, 0.5, 1);
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

    // adjust viewport and projection matrices to texture dimensions
    glPushAttrib(GL_VIEWPORT_BIT);
    glViewport(0,0, m_FBOWidth, m_FBOHeight);

    glMatrixMode(GL_PROJECTION);
    glLoadIdentity();
    glOrtho(0, m_FBOWidth, 0, m_FBOHeight, 1.0, 100.0);

    glMatrixMode(GL_MODELVIEW);
    glLoadIdentity();

    DrawTriangle();

    glPopAttrib();
    // setting FrameBuffer back to window-specified Framebuffer
    glBindFramebuffer(GL_FRAMEBUFFER, 0);       //unbind

    // back to normal viewport and projection matrix
    //glViewport(0, 0, 1280, 768);

    glMatrixMode(GL_PROJECTION);
    glLoadIdentity();
    gluPerspective(45.0, 1.33, 1.0, 1000.0);

    glMatrixMode(GL_MODELVIEW);
    glLoadIdentity();

    glClearColor(0, 0, 0, 0);
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

    render(elapsedGameTime);
}
</code></pre>

<hr>

<pre><code>void FrameBufferObject::DrawTriangle()
{
    glPushMatrix();

    glBegin(GL_TRIANGLES);
        glColor3f(1, 0, 0);

        glVertex2d(0, 0);
        glVertex2d(m_FBOWidth, 0);
        glVertex2d(m_FBOWidth, m_FBOHeight);

    glEnd();

    glPopMatrix();
}
</code></pre>

<hr>

<pre><code>void FrameBufferObject::render(unsigned int elapsedTime)
{
    glEnable(GL_TEXTURE_2D);
    glBindTexture(GL_TEXTURE_2D, m_TextureID);

    glPushMatrix();

        glTranslated(0, 0, -20);

    glBegin(GL_QUADS);
        glColor4f(1, 1, 1, 1);

        glTexCoord2f(1, 1);  glVertex3f(1,1,1);
        glTexCoord2f(0, 1);  glVertex3f(-1,1,1);
        glTexCoord2f(0, 0);  glVertex3f(-1,-1,1);
        glTexCoord2f(1, 0);  glVertex3f(1,-1,1);

    glEnd();
    glPopMatrix();

    glBindTexture(GL_TEXTURE_2D, 0);
    glDisable(GL_TEXTURE_2D);

}
</code></pre>

<hr>

<pre><code>void FrameBufferObject::Initialize()
{
    // Generate FBO
    glGenFramebuffers(1, &amp;m_FBO);
    glBindFramebuffer(GL_FRAMEBUFFER, m_FBO);

    // Add depth buffer as a renderbuffer to fbo
    // create depth buffer id

    glGenRenderbuffers(1, &amp;m_DepthBuffer);
    glBindRenderbuffer(GL_RENDERBUFFER, m_DepthBuffer);

    // allocate space to render buffer for depth buffer
    glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, m_FBOWidth, m_FBOHeight);

    // attaching renderBuffer to FBO
    // attach depth buffer to FBO at depth_attachment
    glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, m_DepthBuffer);

    // Adding a texture to fbo
    // Create a texture
    glGenTextures(1, &amp;m_TextureID);
    glBindTexture(GL_TEXTURE_2D, m_TextureID);
    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA8, m_FBOWidth, m_FBOHeight, 0, GL_RGBA, GL_UNSIGNED_BYTE, 0); // onlly allocating space
    glBindTexture(GL_TEXTURE_2D, 0);

    // attach texture to FBO
    glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, m_TextureID, 0);

    // Check FBO Status
    if( glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE)
        std::cout &lt;&lt; ""\n Error:: FrameBufferObject::Initialize() :: FBO loading not complete \n"";

    // switch back to window system Framebuffer
    glBindFramebuffer(GL_FRAMEBUFFER, 0);
}
</code></pre>

<p>Thanks!</p>
","<p>Everything was fine. The triangle I was rendering for the FBO was getting clipped which is why I was not seeing anything. A translate Z of -20 is all it took to get the triangle rendering properly.</p>

<p>A (obvious) thing I learnt: When the user FBO is not working properly, render it to the normal framebuffer and see if what you expect to show up in the user FBO, actually shows up there. If not, you have a problem in the way you are rendering to the user FBO.</p>

<p>Hope it helps someone.</p>
","8852"
"How to use XML files as content files in XNA?","8811","","<p>I have an XML file representing different car manufactures that will be available in my game. The file looks like this:</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""utf-8"" ?&gt;
&lt;XnaContent&gt;
  &lt;Asset Type=""List[string]""&gt;
    &lt;car&gt;Audi&lt;/car&gt;
    &lt;car&gt;BMW&lt;/car&gt;
    &lt;car&gt;Nissan&lt;/car&gt;
    &lt;car&gt;Volvo&lt;/car&gt;
  &lt;/Asset&gt;
&lt;/XnaContent&gt;
</code></pre>

<p>When adding it into my content folder, the compiler return this error:</p>

<pre><code>There was an error while deserializing intermediate XML. Cannot find type ""List`1""
</code></pre>

<p>How can I create a list of strings, put it into XML and read it from XNA?</p>
","<p>I haven't tried to find out exactly what is wrong with your XML - it's probably the lack of a namespace. <strong>But here is the correct XML:</strong></p>

<pre><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;XnaContent xmlns:Generic=""System.Collections.Generic""&gt;
  &lt;Asset Type=""Generic:List[string]""&gt;
    &lt;Item&gt;Audi&lt;/Item&gt;
    &lt;Item&gt;BMW&lt;/Item&gt;
    &lt;Item&gt;Nissan&lt;/Item&gt;
    &lt;Item&gt;Volvo&lt;/Item&gt;
  &lt;/Asset&gt;
&lt;/XnaContent&gt;
</code></pre>

<p>Under the hood the <code>XmlImporter</code> uses the <code>IntermediateSerializer</code> class. So a small program like the following can be used to determine what your XML <em>should</em> look like:</p>

<pre><code>var test = new List&lt;string&gt;(){ ""Audi"", ""BMW"", ""Nissan"", ""Volvo"" };
var sb = new StringBuilder();
using(XmlWriter writer = XmlWriter.Create(sb))
{
    IntermediateSerializer.Serialize(writer, test, null);
}
Console.Write(sb.ToString());
</code></pre>

<p>(You can even convert the output to a stream, pass it to the <code>Deserialize</code> method, and reconstruct the object - just to be doubly-sure it's working. Also it is probably worth putting the right encoding in the header - eg: <code>StringBuilder</code> is utf-16.)</p>

<p>For some in-depth information about <code>IntermediateSerializer</code>, take a look at Shawn Hargreaves' blog, starting with <a href=""http://blogs.msdn.com/b/shawnhar/archive/2008/05/30/xml-and-the-content-pipeline.aspx"">this post</a> and continuing through the archives until August 2008.</p>
","11241"
"Keyboard input system handling","8810","","<p>Note: I have to poll, rather than do callbacks because of API limitations (SFML). I also apologize for the lack of a 'decent' title.</p>

<p>I think I have two questions here; how to register the input I'm receiving, and what to do with it.</p>

<h2>Handling Input</h2>

<p>I'm talking about after the fact you've registered that the 'A' key has been pressed, for example, and how to do it from there.</p>

<p>I've seen an array of the whole keyboard, something like:</p>

<p><code> bool keyboard[256];  //And each input loop check the state of every key on the keyboard
</code></p>

<p>But this seems inefficient. Not only are you coupling the key 'A' to 'player moving left', for example, but it checks every key, 30-60 times a second. </p>

<p>I then tried another system which just looked for keys it wanted.</p>

<p><code>std::map&lt; unsigned char, Key> keyMap; //Key stores the keycode, and whether it's been pressed. Then, I declare a load of const unsigned char called 'Quit' or 'PlayerLeft'.<br>
input->BindKey(Keys::PlayerLeft, KeyCode::A);  //so now you can check if PlayerLeft, rather than if A.
</code></p>

<p>However, the problem with this is I cannot now type a name, for example, without having to bind every single key. </p>

<p>Then, I have the second problem, which I cannot really think of a good solution for:</p>

<h2>Sending Input</h2>

<p>I now know that the A key has been pressed or that playerLeft is true. But how do I go from here? </p>

<p>I thought about just checking 
<code> if(input->IsKeyDown(Key::PlayerLeft) { player.MoveLeft(); }</code><br>
This couples the input greatly to the entities, and I find it rather messy. I'd prefer the player to handle its own movement when it gets updated. I thought some kind of event system could work, but I do not know how to go with it. (I heard signals and slots was good for this kind of work, but it's apparently very slow and I cannot see how it'd fit).</p>

<p>Thanks.</p>
","<p>What I'd do is use the <a href=""http://en.wikipedia.org/wiki/Observer_pattern"">observer pattern</a> and have an input class that maintains a list of callbacks or input handling objects. Other objects can register themselves with the input system to be notified when certain things happen. There are different types of callbacks you could register, based on the type of input events observers would like to be notified about. This could be as low level as 'key x is down/up' or more game-specific like 'a jump/shooting/movement event happened'. </p>

<p>Generally game objects have an input handling <a href=""http://gameprogrammingpatterns.com/component.html"">component</a> that is responsible for registering itself with the input class and providing methods to handle the events it is interested in. For movement, I have an input mover component that has a move(x, y) method. It registers itself with the input system and gets notified on movement events (where x and y would be -1 and 0 to signify moving left), the mover component then changes its parent game object coordinates based on movement direction and object velocity.</p>

<p>I don't know if this is a good solution but it works for me so far. In particular it allows me to provide different kinds of input system that map to the same logical game events so that gamepad button x and keyboard space both generate a jump event for example (it's a bit more complicated than that, allowing the user to reassign key mappings).</p>
","3084"
"boolean operations on meshes","8798","","<p>given a set of vertices and triangles for each mesh. Does anyone know of an algorithm, or a place to start looking( I tried google first but haven't found a good place to get started) to perform boolean operations on said meshes and get a set of vertices and triangle for the resulting mesh? Of particular interest are subtraction and union.</p>

<p>Example pictures: <a href=""http://www.rhino3d.com/4/help/Commands/Booleans.htm"">http://www.rhino3d.com/4/help/Commands/Booleans.htm</a></p>
","<p>I think of this as Constructive-Solid-Geometry (CSG). Hopefully you can find some help here.</p>

<p><a href=""http://www.alsprogrammingresource.com/csg.html"">http://www.alsprogrammingresource.com/csg.html</a></p>

<p><a href=""http://createuniverses.blogspot.com/2009/09/qtcsg-constructive-solid-geometry.html"">http://createuniverses.blogspot.com/2009/09/qtcsg-constructive-solid-geometry.html</a></p>

<p><a href=""http://www.nigels.com/research/"">http://www.nigels.com/research/</a></p>

<p>Also search google for Constructive Solid Geometry as a start.</p>

<p>HTH</p>
","2321"
"What happened to procedurally generated textures?","8792","","<p>I recall some time ago that procedurally generated textures were becoming a big deal that a lot of people/companies were really interested in with some serious benefits (smaller deployments, potentially faster loading, higher quality, scalable textures, potentially cheaper to produce, etc.).</p>

<p>From what I can tell, the buzz is dead and no games on my radar are using them. What happened?</p>

<p>I was hoping I'd see procedural textures go the way that NaturalMotion's stuff has (slow but steady adoption).</p>
","<p>Content creation tools for procedural texturing have been the biggest roadblock. Artist are very fast putting things together in Photoshop and the potential gains with procedural texturing haven't outweighed the increased content creation time.</p>

<p>Allegorithmic (<a href=""http://www.allegorithmic.com/"">http://www.allegorithmic.com/</a>) has some interesting tools they've developed to try and make procedural options more user friendly. Haven't played with them enough to really comment on their usability though.</p>
","333"
"Tools for 2D skeletal animation","8790","","<p>What good free and widely used tools are there for editing 2D skeletal animations? Preferably, one that allows me to write custom animation exporters.</p>

<p>One pretty good indie tool that I know of <a href=""http://demina.codeplex.com/"">Demina</a>, but it's not ideal. It doesn't allow you to export the data as you want (although, it is open source, so you can change that) and I find it clunky in how you edit individual joints.</p>

<p>What other tools would you recommend?</p>
","<p>Personally I would just use a 3D tool and ignore one of the dimensions.  Something like Maya is likely going to be a lot more robust than some custom tool just to do 2D animations.</p>

<p>There are a handful of games that I've worked on and that I know about that have used this approach.  As an example, here's an article that talks about Zombieville USA (iOS game) and how they do it.  <a href=""http://www.thecareergamer.com/braaaains-zombieville-usa-tech-review/"">http://www.thecareergamer.com/braaaains-zombieville-usa-tech-review/</a>  Scroll down to the first picture to see what they're doing.</p>
","22007"
"Rotating an object with quaternion","8789","","<p>I have a question in regards to using quaternions for the rotation of my graphics object.</p>

<p>I have a <code>Transform</code> class which has the following constructor with default parameters:</p>

<pre><code>Transform(const glm::vec3&amp; pos = glm::vec3(0.0), const glm::quat&amp; rot = glm::quat(1.0, 0.0, 0.0, 0.0),
    const glm::vec3&amp; scale = glm::vec3(1.0))
{
    m_pos = pos;
    m_rot = rot;
    m_scale = scale;
}
</code></pre>

<p>In my <code>Transform</code> class calculate the <code>MVP</code> as follows:</p>

<pre><code>glm::mat4 Transform::GetModelMatrix() const
{
    glm::mat4 translate = glm::translate(glm::mat4(1.0), m_pos);
    glm::mat4 rotate = glm::mat4_cast(m_rot);
    glm::mat4 scale = glm::scale(glm::mat4(1.0), m_scale);

    return translate * rotate * scale;
}
</code></pre>

<p>The issue I'm facing is that when I use <code>const glm::quat&amp; rot = glm::quat(1.0, 0.0, 0.0, 0.0)</code> my object appears normal on screen. The following image shows it:
<img src=""https://i.stack.imgur.com/nLQVQ.png"" alt=""enter image description here""></p>

<p>However if I try to use for example <code>const glm::quat&amp; rot = glm::quat(glm::radians(90.0f), 0.0, 1.0, 0.0)</code> (rotating on y axis by 90 degrees) my object appears as if it has been scaled. The following image shows it:
<img src=""https://i.stack.imgur.com/XJqaT.png"" alt=""enter image description here""></p>

<p>I can't figure out what is causing it to become like this when I try to rotate it. Am I missing something important? </p>

<p>If it's of any relevance, the following is how I calculate my view matrix:</p>

<pre><code>glm::mat4 Camera::GetView() const
{
    glm::mat4 view = glm::lookAt(m_pos, m_pos + m_forward, m_up);

    return view;
}
</code></pre>
","<p>the <code>glm::quat(float, float, float, float);</code> constructor doesn't do what you think it does. It sets the values directly.</p>

<p>The values of the quaternion <code>(w, x, y, z)</code> are in order: the cosine of half the angle, the sine of half the angle times the x coordinate of the normalized rotation axis, and the same for the y ans z components.</p>

<p>So instead you want to use <code>glm::quat(cos(glm::radians(90.0f/2)),0,sin(glm::radians(90.0f/2))*1,0);</code> or after inlining the result of the trig: <code>glm::quat(sqrt(1/2),0,sqrt(1/2),0);</code> </p>
","94062"
"Problem trying to lock framerate at 60 FPS","8782","","<p>I've written a simple class to limit the framerate of my current project.
But it does not work as it should. Here is the code:</p>

<pre><code>void FpsCounter::Process()
{
    deltaTime = static_cast&lt;double&gt;(frameTimer.GetMsecs());
    waitTime = 1000.0/fpsLimit - deltaTime;
    frameTimer.Reset();

    if(waitTime &lt;= 0)
    {
        std::cout &lt;&lt; ""error, waittime: "" &lt;&lt; waitTime &lt;&lt; std::endl;
    }
    else
    {
        SDL_Delay(static_cast&lt;Uint32&gt;(waitTime));
    }

    if(deltaTime == 0)
    {
        currFps = -1;
    }
    else
    {
        currFps = 1000/deltaTime;
    }

    std::cout &lt;&lt; ""--Timings--"" &lt;&lt; std::endl;
    std::cout &lt;&lt; ""Delta: \t"" &lt;&lt; deltaTime &lt;&lt; std::endl;
    std::cout &lt;&lt; ""Delay: \t"" &lt;&lt; waitTime &lt;&lt; std::endl;
    std::cout &lt;&lt; ""FPS: \t"" &lt;&lt; currFps &lt;&lt; std::endl;
    std::cout &lt;&lt; ""--       --"" &lt;&lt; std::endl;
}

Timer::Timer()
{
    startMsecs = 0;
}

Timer::~Timer()
{
    // TODO Auto-generated destructor stub
}

void Timer::Start()
{
    started = true;
    paused = false;
    Reset();
}

void Timer::Pause()
{
    if(started &amp;&amp; !paused)
    {
        paused = true;

        pausedMsecs = SDL_GetTicks() - startMsecs;
    }
}

void Timer::Resume()
{
    if(paused)
    {
        paused = false;

        startMsecs = SDL_GetTicks() - pausedMsecs;

        pausedMsecs = 0;
    }
}

int Timer::GetMsecs()
{
    if(started)
    {
        if(paused)
        {
            return pausedMsecs;
        }
        else
        {
            return SDL_GetTicks() - startMsecs;
        }
    }
    return 0;
}

void Timer::Reset()
{
    startMsecs = SDL_GetTicks();
}
</code></pre>

<p>The ""FpsCounter::Process()"" Method is called everytime at the end of my gameloop.</p>

<p>I've got the problem that the loop is correctly delayed only every second frame, so it runs one frame delayed at 60 FPS and the next without delay at over 1000 fps.</p>

<p>I am searching the error quite a while now, but I do not find it.</p>

<p>I hope somebody can point me in the right direction.</p>
","<p>You need to reset the timer <strong>after</strong> you have waited. Otherwise, the wait time will be part of the duration of the next frame and the algorithm will think it is running slowly.</p>
","27371"
"Where can i get the openal sdk for c++?","8772","","<p>The OpenAL site I'm looking at is a crappy outdated and broken sharepoint portal and the SDK in the downloads section give me a 500 html code when i request it.</p>

<p><a href=""http://connect.creativelabs.com/openal/Downloads/OpenAL11CoreSDK.zip"">http://connect.creativelabs.com/openal/Downloads/OpenAL11CoreSDK.zip</a></p>

<p>I found an OpenAL SDK on a softpedia and it has headers but not alu.h or alut.h which the tutorials I'm looking at apparently require for loading wavs etc.</p>

<p>What am I missing? Is OpenAL dead or something?</p>
","<p><a href=""http://kcat.strangesoft.net/openal.html"">http://kcat.strangesoft.net/openal.html</a> is the OpenAL Soft library, which is what you use on almost every platform besides Windows by default anyway.  It doesn't expose the hardware-accelerated EAX extensions, but not a lot of people use those.  If the Creative Windows SDK doesn't come back online shortly, OpenAL Soft is the only real option remaining.</p>

<p>Not that this is an answer to your question, but... you might consider just using FMOD or Wwise.  They are free for hobbyist usage and very reasonably priced for commercial usage, they have a bazillion and one more features than any version of OpenAL, have a much cleaner and less error-prone API, and have designed-oriented tools and support rather than being purely a low-level sound abstraction API.</p>

<p>While I don't know if OpenAL is dead on Creative's site permanently or it's just a hiccup, I really wouldn't be surprised if it was dead.  It's very very rarely used in the industry commercially, and is decreasingly used in the indie/hobby scenes from what I've seen.  The only platform that really stresses use of OpenAL anymore is Linux.  Windows has its own API, iOS and OS X have their own APIs, the consoles have their APIs, and even Android prefers OpenSL over OpenAL.  And of course, FMOD/Wwise abstract all those away and give you a single unified high-level API.</p>
","34547"
"Where is the Aves game engine?","8771","","<p>The <a href=""http://www.youtube.com/watch?v=Ol3qQ4CEUTo"">Aves game engine</a> made a splash last spring/summer, with very impressive demo videos. I went back to check on them, and it looks like their site has long since died. Google also doesn't seem to know anything new about them.</p>

<p>Where can I find news about Aves? Is the project dead?</p>
","<p>Dextrose was acquired by Zynga ( creators of Farmville, mafia wars )</p>

<p><a href=""http://www.insidesocialgames.com/2010/09/24/zynga-acquires-dextrose-aves-engine-html5/"" rel=""nofollow"">http://www.insidesocialgames.com/2010/09/24/zynga-acquires-dextrose-aves-engine-html5/</a></p>
","14455"
"Where can I find free md2 models and .obj objects for a boxing game?","8769","","<p>I'm creating a first person boxing game in Opengl as a school project and I want textures and models to apply to it. A look like Wii Sport's Boxing is what I'm aiming for. </p>

<p>Something like <a href=""http://www.turbosquid.com/3d-models/boxing-arena-3d-c4d/413889"" rel=""nofollow"">this</a> (but, you know, <strong>free</strong>) </p>
","<p>The problem with free is, as the saying goes, you often get what you paid for :)</p>

<p>A good place to find 3D models (from the good to the unbelievably ugly) is the <a href=""http://sketchup.google.com/3dwarehouse/"" rel=""nofollow noreferrer"">Google 3D Warehouse</a>.  It's a huge collection of free models that can be loaded with Google's Sketchup program plus be loaded in to Google Earth if geo-referenced.  </p>

<p>From the site, here is a model of a boxing ring that can be downloaded in Collada format as well as for Google Sketchup.  You ought to be able to find a way to convert Collada to OBJ.</p>

<p><img src=""https://i.stack.imgur.com/YbGnG.jpg"" alt=""alt text""></p>

<p><a href=""http://sketchup.google.com/3dwarehouse/details?mid=1579926f4237c91137494d2d6fb60eef&amp;prevstart=0"" rel=""nofollow noreferrer"">http://sketchup.google.com/3dwarehouse/details?mid=1579926f4237c91137494d2d6fb60eef&amp;prevstart=0</a></p>
","6550"
"Play vs. PlayOneShot","8764","","<p>For Unity <code>AudioSource</code> objects, what is the difference between the <code>Play</code> and <code>PlayOneShot</code> methods, besides their method signatures?</p>

<p>Is it simply that <code>PlayOneShot</code> won't stop an already playing sound from the <code>AudioSource</code>? So given a scenario where you can guarantee that a call to <code>AudioSource.Play()</code> won't occur again until its <code>isPlaying</code> boolean value is false, is there any reason to use <code>PlayOneShot</code>?</p>
","<p>You've already identified the main difference: PlayOneShot can play multiple sounds without cutting each other off. On the flipside however that means* you can't stop the audio clip either; it'll just play all the way through, with no way to stop it early.</p>

<p>*I think; I can't test this at the moment, but I recall that calling Stop() after PlayOneShot() does nothing.</p>
","95277"
"How to achieve uniform speed of movement on a bezier curve?","8763","","<p>I'm trying to move an image along Bezier curve. This is how I do it:</p>

<pre><code>- (void)startFly
{    
 [self runAction:[CCSequence actions:
             [CCBezierBy actionWithDuration:timeFlying bezier:[self getPathWithDirection:currentDirection]],
             [CCCallFuncN actionWithTarget:self selector:@selector(endFly)],
             nil]];

}
</code></pre>

<p>My issue is that the image moves not uniformly. In the beginning it's moving slowly and then it accelerates gradually and at the end it's moving really fast. What should I do to get rid of this acceleration?</p>
","<p>It is possible to approximate a solution to this problem for most parametric trajectories. The idea is the following: if you zoom deep enough on a curve, you cannot tell the curve itself from its tangent at that point.</p>

<p>By making this assumption, there is no need to precompute anything more than two vectors (three for cubic Bezier curves, <em>etc.</em>).</p>

<p>So for a curve \$M(t)\$ we compute its tangent vector \$\frac{dM}{dt}\$ at point \$t\$. The norm of this vector is \$\lVert \frac{dM}{dT} \rVert\$ and thus the distance traveled for a duration \$\Delta t\$ can be approximated as \$\lVert \frac{dM}{dT} \rVert \Delta t \$. It follows that a distance \$L\$ is traveled for a duration \$L \div \lVert \frac{dM}{dT} \rVert\$.</p>

<h3>Application: quadratic Bezier curve</h3>

<p>If the control points of the Bezier curve are \$A\$, \$B\$ and \$C\$, the trajectory can be expressed as:</p>

<p>$$
\begin{align}
M(t) &amp;= (1-t)^2A + 2t(1-t)B + t^2C \\
     &amp;= t^2(A - 2B + C) + t(-2A + 2B) + A
\end{align}
$$</p>

<p>So the derivative is:</p>

<p>$$
\frac{dM}{dt} = t(2A - 4B + 2C) + (-2A + 2B)
$$</p>

<p>You just need to store vectors \$\vec v_1 = 2A - 4B + 2C\$ and \$\vec v_2 = -2A + 2B\$ somewhere. Then, for a given \$t\$, if you want to advance of a length \$L\$, you do:</p>

<p>$$
t = t + {L \over length(t \times v_1 + v_2)}
$$</p>

<h3>Cubic Bezier curves</h3>

<p>The same reasoning applies to a curve with four control points \$A\$, \$B\$, \$C\$ and \$D\$:</p>

<p>$$
\begin{align}
M(t) &amp;= (1-t)^3A + 3t(1-t)^2B + 3t^2(1-t)C + t^3D \\
     &amp;= t^3(-A + 3B - 3C + D) + t^2(3A - 6B + 3C) + t(-3A + 3B) + A
\end{align}
$$</p>

<p>The derivative is:</p>

<p>$$
\frac{dM}{dt}  = t^2(-3A + 9B - 9C + 3D) + t(6A - 12B + 6C) + (-3A + 3B)
$$</p>

<p>We precompute the three vectors:</p>

<p>$$
\begin{align}
\vec v_1 &amp;= -3A + 9B - 9C + 3D \\
\vec v_2 &amp;= 6A - 12B + 6C \\
\vec v_3 &amp;= -3A + 3B
\end{align}
$$</p>

<p>and the final formula is:</p>

<p>$$
\begin{align}
t &amp;= t + {L \over length(t \cdot t \cdot \vec v_1 + t \cdot \vec v_2 + \vec v_3)} \\
  &amp;= t + {L \over length(t^2 \cdot \vec v_1 + t \cdot \vec v_2 + \vec v_3)}
\end{align}
$$</p>

<h3>Accuracy issues</h3>

<p>If you are running at a reasonable framerate, \$L\$ (which should be computed according to the frame duration) will be sufficiently small for the approximation to work.</p>

<p>However, you may experience inaccuracies in extreme cases. If \$L\$ is too large, you can do the computation piecewise, for instance using 10 parts:</p>

<pre><code>for (int i = 0; i &lt; 10; i++)
    t = t + (L / 10) / length(t * v1 + v2);
</code></pre>
","27138"
"Is storing all game objects in a single list an acceptable design?","8747","","<p>For every game I've made, I just end up placing all my game objects (bullets, cars, players) in a single array list, which I loop through to draw and update. The update code for each entity is stored within it's class.</p>

<p>I've been wondering, is this the right way to go about things, or is a faster more efficient way?</p>
","<p>There is no one right way. What you're describing works, and is presumably fast enough that it doesn't matter since you seem to be asking because you're concerned about the design and not because it's caused you performance issues. So it is <em>a</em> right way, sure.</p>

<p>You could certainly do it differently, by for example keeping a homogenous list for each object type or by ensuring everything in your heterogenous list is grouped together such that you have improved coherency for the code that is in-cache or to allow parallel updates. Whether you'd see any appreciable performance improvement by doing this is difficult to say without knowing the scope and scale of your games.</p>

<p>You could also further factor out the responsibilities of your entities -- it sounds like entities both update and render themselves at the moment -- to better follow the Single Responsibility Principle. This can increase the maintainability and flexibility of your individual interfaces by decoupling them from one another. But again, whether or you'd see a benefit from the extra work that would entail is hard for me to say knowing what I know of your games (which is basically nothing).</p>

<p>I would recommend not stressing too much about it, and keep in the back of your head that it might be a potential area for improvement if you ever notice performance or maintainability issues.</p>
","22561"
"How do I implement features in an entity system?","8745","","<p>After asking two questions about entity systems (<a href=""https://gamedev.stackexchange.com/q/32582/9736"">1</a>, <a href=""https://gamedev.stackexchange.com/q/32627/9736"">2</a>), and reading some <a href=""http://t-machine.org/index.php/category/entity-systems/"" rel=""nofollow noreferrer"">articles</a> on them, I think that I understand them much better than before. I still have some uncertainties, mainly about building a particle emitter, an input system, and a camera. I obviously still have some problems understanding entity systems, and they might apply to a whole other range of objects, but I chose these three because they are very different concepts, should cover a pretty broad ground, and help me understand entity systems and how to handle problems like these, myself, as they come along.</p>

<p>I am building an engine in JavaScript, and I've implemented most of the core features, which include: input handling, flexible animation system, particle emitter, math classes and functions, scene handling, a camera and a render, and a whole bunch of other things that engines usually support. I read Byte56's answer, that got me interested into making the engine into an entity system. It would still remain a HTML5 game engine, with the basic scene philosophy, but it should support dynamic creation of entities from components.</p>

<hr>

<p>The problem I have, now, is fitting my old engine concept into this new programming paradigm. These are some of the definitions from the previous questions, updated:</p>

<ul>
<li><p>An <strong>Entity</strong> is an identifier. It doesn't have any data, it's not an object, it's a simple id that represents an index in the scenes list of all entities (which I actually plan to implement as a component matrix).</p></li>
<li><p>A <strong>Component</strong> is a data holder, but with methods that can operate on that data. The best example is a <code>Vector2D</code>, or a ""Position"" component. It has data: <code>x</code> and <code>y</code>, but also some methods that make operating on the data a bit easier: <code>add()</code>, <code>normalize()</code>, and so on.</p></li>
<li><p>A <strong>System</strong> is something that can operate on a set of entities that meet the certain requirements; usually the entities need to have a specified set of components, to be operated upon. The system is the ""logic"" part, the ""algorithm"" part, all the functionality supplied by components is purely for easier data management.</p></li>
</ul>

<hr>

<h3>Camera</h3>

<p>The camera has a <code>Vector2D</code> position property, a rotation property and some methods for centering it around a point. Each frame, it is fed to a renderer, along with a scene, and all the objects are translated according to its position. The scene is then rendered.</p>

<p>How could I represent this kind of an object in an entity system? Would the camera be an entity, a component, or combination (as per my <a href=""https://gamedev.stackexchange.com/a/32694/9736"">answer</a>)?</p>

<h3>Particle Emitter</h3>

<p>The problem I have with my particle emitter is, again, what should be what. I'm pretty sure that particles themselves shouldn't be entities, as I want to support over 10,000 of them, and I believe that creating that much entities would be a heavy blow on my performance.</p>

<p>How could I represent this kind of an object in an entity system?</p>

<h3>Input Manager</h3>

<p>The last one I want to talk about is how input should be handled. In my current version of the engine, there is a class called <code>Input</code>. It is a handler that subscribes to the browsers events, such as key presses and mouse position changes, and also maintains an internal state. Then, the player class has a <code>react()</code> method, which accepts an input object as an argument. The advantage of this is that the input object could be serialized into .JSON, and then shared over the network, allowing for smooth multiplayer simulations. </p>

<p>How does this translate into an entity system?</p>
","<ul>
<li><p><strong>Camera:</strong> Making this a component would be pretty neat. It would just have a <code>isRendering</code> flag and depth range like Sean said. In addition to ""field of view"" (I guess you might call it scale in 2D?) and an output zone. The output zone could define the portion of the game window that this camera gets rendered to. It wouldn't have a separate position/rotation like you mention. The entity you create that has a camera component would use the position and rotation components of that entity. Then you'd have a camera system that looks for entities that have a camera, position and rotation components. The system takes that entity and draws all the entities it can ""see"" from it's position, rotation, depth of view and field of view, to the specified portion of the screen. That gives you lots of options for simulating multiple view ports, ""character view"" windows, local multiplayer, different layers of GUI and so on.</p></li>
<li><p><strong>Particle Emitter:</strong> This too should just be a component. The particle system would look for entities that have a position, rotation and particle emitter. The emitter has all the properties needed to reproduce your current emitter, I'm not sure what all those are, stuff like: rate, initial velocity, decay time and so on. You wouldn't have to make multiple passes. The particle system knows which entities have that component. I imagine you could re-use a good deal of your existing code.</p></li>
<li><p><strong>Inputs:</strong> I'd have to say making this into a component makes the most sense given the suggestions I make above. Your <code>input system</code> would get updated every frame with the current input events. Then when it's going through all it's entities that have the input component, it will apply those events. The input component would have a list of keyboard and mouse events all associated method callbacks. I'm not really sure where the method callbacks would live. Perhaps some input controller class? Whatever makes the most sense for later modification by users of your engine. But this would give you the power to easily apply input control to camera entities, player entities or whatever you needed. Want to synchronize the movement of a bunch of entities with the keyboard? Just give them all input components that respond to the same inputs and the input system applies those move events to all the components asking for them.</p></li>
</ul>

<p>So most of this is just off the top of my head, so it probably won't make sense without further explanation. So just let me know what you're not clear on. Basically, I've given you a lot to work on :)</p>
","32719"
"Geometry instancing in OpenGL ES 2.0","8739","","<p>I am planning to do geometry instancing in OpenGL ES 2.0
Basically I plan to render the same geometry(a chair) maybe 1000 times in my scene.</p>

<p>What is the best way to do this in OpenGL ES 2.0?</p>

<p>I am considering passing model view mat4 as an attribute. Since attributes are per vertex data do I need to pass this same mat4, three times for each vertex of the same triangle(since modelview remains constant across vertices of the triangle).</p>

<p>That would amount to a lot of extra data sent to the GPU( 2 extra vertices*16 floats*(Number of triangles) amount of extra data).</p>

<p>Or should I be sending the mat4 only once per triangle?But how is that possible using attributes since attributes are defined as ""per vertex"" data?</p>

<p>What is the best and efficient way to do instancing in OpenGL ES 2.0?</p>
","<p>ES2 has neither glVertexAttribDivisor nor floating point textures so your options are quite limited.</p>

<p>Definitely put your chair model into a VBO if you're not doing so already.  From there you're more or less restricted to individual draw calls - one per chair - so it's a question of getting the transformation matrix for each chair to the GPU as efficiently as possible.</p>

<p>You could do this with regular glUniform calls, or you could abuse some extra vertex attrib slots and make some glVertexAttrib (note: not glVertexAttribPointer) calls before drawing each chair, specifying the matrix using 4 such slots, and these values will ""stick"" for each subsequent vertex in the chair.  That can be a fast enough path on some hardware but slower on other so you're going to have to experiment.</p>

<p>If your chairs don't rotate one other thing you can do is just send position to your shader and construct a new transformation matrix on the fly there.  That sounds horrible but it's actually incredibly fast (it's just setting 3 floats) and might do the job.</p>

<p>On the whole though, and assuming that you're aiming for a typical mobile platform, I'm thinking that whatever you do, draw calls are going to kill you.</p>
","31545"
"Do I need an Indie Studio Name?","8738","","<p>I've recently been making a mobile game which I'm going to publish to Google Play. Google Play requires a Developer Name. Most Google Play Developer use their game studio name like Gameloft, Supercell, etc. But some indies use their names as the developer name like Scott Cowthon, FNAF Developer. I was wondering what are the advantages and disadvantages of each type to me as the only developer of my game?</p>
","<p>The name is the centre focus of your entire brand, so it's something to think over carefully before you publish your first product. </p>

<p>Using your real name can show that personable touch you apply to your software but also has the increased risk of exposing your identity in a way that gives new meaning to the word public. I favour real names because it tends to be a lot more sensible/coherent than ""Deadly Dinosaur Designs"", ""Banana BreadBox Banana Boom Games Bah!"" or any of the other usual indie dev studio names. The most important thing though is <strong>if your real name alliterates then you have to use it.</strong> Scott Scotty is the kind of branding I want to see at the top of the app store tomorrow.</p>

<p>At the end of the day it's your call and although it represents the flag your games hoist it's not going to make or break you as a dev. The pain and permanence of naming things is why most major studios adopt a codename for their next title so they don't have to weep over what they're going to call the Unity Project for a week.   </p>
","133009"
"Rendering multiline text with SDL_TTF","8737","","<p>Can you use any function to render more than a line of text in a surface?</p>

<p>If you can't do this, what whould be the way to go? 
I am doing the following: Create a surface (not sure if should be a software or a hardware one) and then create as many surfaces as lines my text have, then blitting all the surfaces, and freeing all the surfaces. But this turns to be very slow. This is the code:</p>

<pre><code>void Text::updateSurface() {
    if (surface != NULL) {
        SDL_FreeSurface(surface);
    }

    TTF_Font * font = TTF_OpenFont(fontPath.c_str(),size);
    if (font == NULL) {
        ERROR(""Null font""&lt;&lt;TTF_GetError());
    }

    int maxWidth = 0;
    int totalHeight = 0;

    std::vector&lt;SDL_Surface *&gt; surfaces;
    for (size_t i=0; i&lt;lines.size(); i++) {
        SDL_Surface * partialSurface = TTF_RenderText_Solid(font, lines[i].c_str(), color);
        if (partialSurface == NULL) {
            ERROR(""surface == NULL: ""&lt;&lt;TTF_GetError());
        }
        surfaces.push_back(partialSurface);
        totalHeight += partialSurface-&gt;h;
        maxWidth = std::max(maxWidth, partialSurface-&gt;w);
    }

    TTF_CloseFont(font);

    surface = SDL::allocateSurface(maxWidth,totalHeight);
    if (backgroundColor != NULL) {
        SDL_FillRect(surface, NULL, SDL_MapRGB(surface-&gt;format,backgroundColor-&gt;r, backgroundColor-&gt;g, backgroundColor-&gt;b));
    }
    totalHeight = 0;
    for (size_t i = 0; i &lt; surfaces.size(); i++) {
        SDL_Rect dst = {0, totalHeight, 0, 0};
        switch(aligment) {
        case ALIGMENT_RIGHT:
            dst.x = maxWidth - surfaces[i]-&gt;w;
            break;
        case ALIGMENT_CENTER:
            dst.x = (maxWidth - surfaces[i]-&gt;w) / 2;
            break;
        case ALIGMENT_LEFT:
        default:
            break;
        }
        totalHeight += surfaces[i]-&gt;h;
        SDL_BlitSurface(surfaces[i],NULL,surface,&amp;dst);
        SDL_FreeSurface(surfaces[i]);
    }
}
</code></pre>

<p>This is the code for SDL::allocateSurface(...)</p>

<pre><code>static SDL_Surface * allocateSurface(int width, int height, int bpp = -1, Uint32 flags = 0)

SDL_Surface * SDL::allocateSurface(int width, int height, int bpp, Uint32 flags) {
    if (bpp == -1) {
        bpp = SDL::bpp; //SDL_GetVideoInfo()-&gt;vfmt-&gt;BitsPerPixel;
    }

    if (flags == 0) {
        flags = SDL_HWSURFACE;
    }

    Uint32 rmask, gmask, bmask, amask;

    #if SDL_BYTEORDER == SDL_BIG_ENDIAN
        rmask = 0xff000000;
        gmask = 0x00ff0000;
        bmask = 0x0000ff00;
        amask = 0x000000ff;
    #else
        rmask = 0x000000ff;
        gmask = 0x0000ff00;
        bmask = 0x00ff0000;
        amask = 0xff000000;
    #endif

    return SDL_CreateRGBSurface(flags, width, height, bpp, rmask, gmask, bmask, amask);
}
</code></pre>
","<p>Don't render text directly with SDL_TTF.  It's not efficient, at all.  Use SDL_TTF to generate a glyph atlas, or use a tool like AngelCode BMFont.  You can get glyph metrics (Width, Height, x advance, etc.) using TTF_LineSkip to find the vertical distance, and TTF_GlyphMetrics.</p>

<p>At this point, you can render text yourself.  By putting the font glyphs into an atlas, and storing glyph metrics, you can easily render multiple lines, render each glyph in a different style or even font, do various effects, etc.  By batching your glyph draws, you can be way more efficient than using SDL_TTF naively.  There's no need to copy whole lines into temporary SDL buffers which are copied to your real output.</p>

<p>It's harder, but worth it.  Easy toy render APIs are just that: toys.</p>
","48139"
"What is the difference between PBR and SSR","8733","","<p>I am very new to game development and I have been trying to understand the difference between Screen Space Reflection and Physically Based Rendering.</p>

<p>I have read about PBR, and from what I understand, it tries to mimic how light reflects in real life, which is it usually gets split to two components, specular and diffuse depending on the type of material.</p>

<p>As for SSR, pls correct me if i am wrong, it is how reflections look on a surface. </p>

<p>If my understanding of SSR is correct, then aren't they in a way the same? I mean, isn't the way reflections look on a surface dependent on the surface roughness and etc. This will then affect how much light is specularly reflected and how much is diffusely reflected. Again, please correct me anywhere I am wrong.</p>
","<h2>Physically-Based Rendering</h2>

<p>You're on the right track when you say ""it tries to mimic how light reflects in real life, which is it usually gets split to two components, specular and diffuse depending on the type of material.""</p>

<p>But we've been modelling materials with specular and diffuse in games &amp; computer graphics for a long time. The trick is that we used to handle these things as completely independent - changing the specularity didn't change the diffuse:</p>

<p><a href=""https://i.stack.imgur.com/pzE1c.png""><img src=""https://i.stack.imgur.com/pzE1c.png"" alt=""Example of Phong shading commonly used in games""></a></p>

<p>This is an example of <a href=""https://en.wikipedia.org/wiki/Phong_shading"">Phong shading</a> <a href=""http://wiki.blender.org/index.php/User:Sculptorjim/Materials/Properties/Specular"">from the Blender wiki</a>. You can see that it offers two parameters of specular intensity and specular hardness, and these parameters only change the whitish part of the reflection. The blue diffuse reflection doesn't change at all.</p>

<p>The way games would use this is an artist would be tasked with hand-tuning these values for each material until it ""looked right."" Because ""specular hardness"" isn't a real physical property of materials that we can measure precisely, it had to be done by eye.</p>

<p>This method is a bit brittle. As you change the illumination (say, a dynamic object moving through different areas, or in an environment with time of day and weather) it can look subtly wrong - too bright or too dark - as the viewing conditions aren't the same as the ones its specular parameters were tuned for.</p>

<p>Enter Physically-Based Rendering, which is an attempt to ground our material descriptions in more objective, measurable properties of real surfaces. One of the most apparent properties is conservation of energy - a rougher surface will scatter light diffusely, and a smoother/more metallic surface will reflect light more directly, but it's the same pool of light they're both drawing from. So other things being equal, as we make a material shinier, the diffuse component should get darker:</p>

<p><a href=""https://i.stack.imgur.com/BtvgN.png""><img src=""https://i.stack.imgur.com/BtvgN.png"" alt=""Example of increasing reflectivity with a constant albedo""></a></p>

<p>This example is from a <a href=""https://www.marmoset.co/toolbag/learn/pbr-theory"">Marmoset article explaining PBR</a> originally shared by <a href=""https://gamedev.stackexchange.com/users/32978/syntac"">Syntac_</a></p>

<p>There's more to physically-based rendering than energy conservation, but this is probably the most telltale sign that you're working with a physically-based system.</p>

<p>By keeping the reflection models similar to how materials work in real life, we reduce the need for fudge factors and artist subjectivity to get a real-world material like wood or concrete or leather to <em>look</em> real under a wide variety of lighting conditions.</p>

<p>Note that another answer described this in terms of indirect illumination from light bouncing off other objects in the scene. While many lighting systems that use physically-based models will also include tools to model this, it's usually known under a separate name of <strong>Global Illumination</strong>. This is the effect that makes one side of the diffuse head in this image appear green, illuminated by light bouncing off the green wall:</p>

<p><a href=""https://i.stack.imgur.com/guqa8.jpg""><img src=""https://i.stack.imgur.com/guqa8.jpg"" alt=""Example of a typical global illumination test scene""></a></p>

<p>Image from this <a href=""http://traipse.com/global_illumination/"">article on global illumination</a></p>

<h2>Screenspace Reflection</h2>

<p>While PBR tries to model how the material reflects light, Screenspace Reflection tries to capture what is being reflected - specifically, for a shiny, mirror-like surface, what should I see in the reflection?</p>

<p>Again this is a relatively recent rendering technique that's probably clearest to understand by contrast to how games did it before:</p>

<p><strong>Flipped Rendering</strong> - common for water planes or flat mirrors, we literally render all the reflected geometry a second time mirrored across the plane of the reflective surface. This gives high-quality reflections (full detail, objects in contact with the surface line up with their reflections) but only works correctly for flat surfaces. The more wavy or bumpy a surface is, the less this behaves like real reflections, which should distort or blur in complex ways.</p>

<p><strong>Cube Maps</strong> - let us store the colour that would be seen by any view ray radiating out from their center point. By dynamically rendering cube maps from selected points in the scene, we can estimate what colour should be reflected off any arbitrarily curved surface. The trouble here is that the cube map is only completely correct at its center point - as the point where we're simulating reflection moves around the scene, it should see some parallax, which isn't present in the cube map. This means objects don't tend to line up with their reflections.</p>

<p>Screen Space reflection tries to address these limitations by using the rendered scene itself as the source for reflection information. It <a href=""https://gamedev.stackexchange.com/questions/67719/how-do-raymarch-shaders-work/67745#67745"">ray-marches</a> a reflected view ray, using the scene's depth, until it would intersect something in the rendered scene.</p>

<p><a href=""https://i.stack.imgur.com/A89fa.png""><img src=""https://i.stack.imgur.com/A89fa.png"" alt=""Slide describing screenspace reflections with a side-view diagram""></a></p>

<p>Here's a <a href=""http://www.slideshare.net/DICEStudio/stochastic-screenspace-reflections"">slide from an EA DICE presentation about their approach to reflections in the Frostbite engine</a>.</p>

<p>This means (with some smart algorithmic work) we can get reflections with reasonably raytracing-like accuracy off of arbitrary surfaces in games, having correct alignment of surfaces in contact, distortion and blurring, <em>as long as the reflected part of the surface is visible on-screen</em> (ie. not offscreen or occluded by something else). Where the reflection can't be accurately determined by the raymarching, it's usually approximated using nearby samples or a fallback cubemap representing the scene beside/behind the camera's view.</p>

<p><a href=""https://i.stack.imgur.com/i3VJP.jpg""><img src=""https://i.stack.imgur.com/i3VJP.jpg"" alt=""Example project using screenspace reflection""></a></p>

<p>You can see in this <a href=""http://hub.jmonkeyengine.org/t/july-2014-monthly-wip-screenshot-thread/30035"">example of screenspace reflection</a>, the impression can be very convincing, although small errors are noticeable (see the reflection of the undersides of the cubes, which are not visible in the rendered frame and so simply smear &amp; repeat adjacent pixels, or the holes in the right green curtain's reflection beside the flower pot and at the bottom of the screen, where the raymarching failed to find the right reflected pixels). It's common to use this technique for moderately shiny/slightly rough surfaces to help make the occasional error less visible.</p>
","114378"
"RPG Maker XP Style (2D Top-Down RPG) Sprites and Tilesets Collection","8732","","<p>I'm creating a bunch of games similar in style to <a href=""http://www.rpgmakerweb.com/product/rpg-maker-xp"" rel=""nofollow noreferrer"">RPG Maker XP</a> -- 2D, top-down style adventure/action/RPG. I used RPG Maker XP in the past, and their sprites are great. Their content is packaged into something called an ""RTP"", which is a collection of sprites, tilesets, etc. which is available for <em>exclusive</em> for use with their tool.</p>

<p>Is there an alternative, free RTP I can use out there? Or, is there a large collection of freely-available material I can use? The standard RTP comes with most common tilesets (forest, grassland, desert, snow, 100 types of people, etc.) so I need something similarly comprehensive.</p>

<p><img src=""https://i.stack.imgur.com/m1VQA.gif"" alt=""enter image description here""></p>

<p>(To summarize, my question is: <strong>is there an existing, free to use collection of RPG Maker XP style assets I can use somewhere out on the web?</strong>)</p>
","<p>If you can muster to pay 9$, there is a bulk of 1000+ legal sprites here you can use :
<a href=""http://graphicriver.net/item/ultimate-game-sprite-set/121857?ref=sirgecko"" rel=""nofollow"">RPG Sprite Set</a></p>

<p>(Not made by me tho, but i have bought a copy myself and they look fair enough.)</p>
","13001"
"How to implement trading card game's ""special effects cards""?","8731","","<p>I am trying to write a kind of a trading card game here, in some way, it is similar to <em>Magic The Gathering</em>, or the <a href=""http://www.yugioh-card.com/uk/rulebook/""><em>Yu-Gi-Oh!</em></a> card game.</p>

<p>For those of you who are not familiar with it, basically, in the game, there is a special kind of card (Spell cards/ Trap cards/ etc.), which have special effects that can bend the rules of the game. What I totally have no idea is, how to implement the logic of these cards. I have some idea of storing the card's data with some flags that can signal what kind of ability it has, but that would be very limited in what it can do (only some simple stats modification, maybe).</p>

<p>To give you an idea of what kind of effects these cards can have, here is some example of the spell card effects that are present in the <em>Yu-Gi-Oh!</em> card game:</p>

<ul>
<li>Revive a creature that has been destroyed </li>
<li>Take control of the opponent's creature </li>
<li>Modify stats of the creature based on some conditions (e.g. Number of creature with certain names that have been
destroyed) </li>
<li>Special summon a certain creatures if the some conditions are fulfilled.</li>
<li>Fuse two or more creatures into a stronger creature.</li>
<li>Immunity to some of the special cards' effect.</li>
</ul>

<p>Konami has made several video games of the game, complete with the AI and thousands of cards variety. I don't think it is actually possible to hard-code the entire database, is it?</p>

<p>Now, of course what I am trying to do is in no where as complex as those games, but I am curious, how do they implement these?</p>
","<p>There are several open-source projects of this nature, with different approaches to implementing the rules. <a href=""http://mtgrares.blogspot.de/2011/04/list-of-all-magic-programs.html"">Here is a blog entry</a> from the creator of one of the more well-known MtG implementations, CardForge. It may not be a complete list, but it contains several open-source projects where you can simply browse the code, or visit the forums for specific questions.</p>

<p>As an actual answer: Your best bet for a robust framework is to strictly employ Object-Oriented Programming. Every Action, every Trigger, every Ability is an object. Zones like Hand, Library are objects too, needless to say. In the Rules engine, never pass around dumb objects like strings or integers to describe game objects, but your objects only.</p>

<p>Every action puts a number of trigger on a stack, where every other ability can check whether or not they care about that particular trigger, and if they do, they fire their own actions, potentially creating new triggers, and so on. </p>

<p>Then you work down those stacks according to the game's rules, until the stack is empty, at which point new actions can be taken etc.</p>

<p>Ideally, if you perfectly implement the game's rules, your rules code does not contain a single hardcoded card. Hardcoding cards can create convenient shortcuts, but in the long run, this will bloat your code and create potential pitfalls, such as when new cards are released that interact with those cards in a novel way. In a game like MtG with over 12,000 unique cards and no end in sight, there are MANY such interactions.</p>
","28076"
"How do I come up with the game mechanics for a puzzle game?","8722","","<p>I want to make a puzzle game, but I don't know how to start. I have observed that each puzzle game has a core mechanic that enables opportunity for numerous puzzles. I'm not sure how to think of ideas. I was wondering how to come up with ideas for my game. I do not want any of your ideas because I want the game to be original.</p>
","<p>Those released games you play, they are finished games, obviously, and have gone through countless iterations. The gameplay mechanics you're enjoying might not even have been a part of the original idea. They can be happy accidents, or at the very least, iterated to ""perfection"". Most likely a combination. Judging ones own work against finished products is never easy, you should have seen those games when they were in their first stages: might not have been that impressive.</p>

<p>What I'm saying, great ""ideas"" take work, they don't magically appear from some void. You start with something simple, and you build from there. Think of a few core gameplay mechanics, experiment, and see what you come up with.</p>

<p>I don't know what kind of game you want to do, but if I wanted to do a game with say, physics and puzzles, I'd start simple. I'd make a player I could move. I'd facilitate a way he could manipulate objects. Maybe he could pick them up, push them, throw them, run into. Or perhaps some sort of gravity gun like in Half-Life. Maybe something completely different. Then I'd throw some obstacles into the mix, and some other moving parts, that Braid trick, where you rewind time, that was great, huh? </p>

<p>If you can't come up with some ideas, take some ideas from other places, experiment, be inspired, and maybe out of that something ""magic"" and original happens!</p>

<p><strong>The prototype</strong></p>

<p>Starting development on a new game isn’t writing the story, making assets, or even the game engine. You want to make a game, you need gameplay mechanics, that’s where you should start. If you can get your mechanics to work, if they are fun, even if your graphics are all stick figures and blank textures, then you know this game is worth more effort. Now you’re ready to make it look nice. But how to get here? The answer is of course prototyping mechanics, and it’s the most important phase of development. </p>

<p>A prototype should be more than just drawings on paper — although paper prototyping might be a stage in your game development — I’d strongly advice you should have made several playable prototypes before starting on anything more concrete. It should be very simple and small of course, but a playable game nonetheless: rudimentary controls and mechanics so you can get a fairly realistic impression of what the finished gameplay might be like. You need to have enough in your prototype for it to be of value.</p>

<p>The whole point of a prototype is to find out if an idea works in practice. Since we’re talking about video games, we might say that the point is to find out if the idea is fun in practice. But the prototype should also give you insights into game design, I’m not talking about visuals or story here, but game design in terms of game rules and mechanics. In fact, prototyping is game design. You want to test out as many ideas and mechanics as possible, to find several that works great, but each prototype should have a narrow focus. Be very specific about what you are actually testing.</p>

<p>When making a prototype, don’t worry much about anything, because you’re not going to keep anything except for the core mechanics, which will all be redesigned and iterated. You don’t need to think about how to structure your code, your architecture, you use whatever language or engine or whatever tools that gets the job done in the shortest amount of time possible.</p>

<p><a href=""http://www.gamasutra.com/view/feature/2438/how_to_prototype_a_game_in_under_7_.php"" rel=""nofollow"">http://www.gamasutra.com/view/feature/2438/how_to_prototype_a_game_in_under_7_.php</a></p>
","47779"
"What is the difference between GetComponent() and Find() in Unity?","8721","","<p>I'm just learning to develop in Unity. One simple thing I'd like to do is change the colors of objects programmatically.  I have a compound asteroid prefab object, in which the meshrenderer and material is inside the child component asteroid_prop_01.</p>

<p>After reading the Unity docs and previous programming posts, I was able to do this successfully with <code>GameObject.transform.Find()</code>, but I don't understand why <code>GameObject.Find()</code>, <code>GameObject.transform.Find()</code> and <code>GameObject.GetComponent()</code> are not equivalent. </p>

<p>I'd really appreciate an understanding of the difference.  E.g. all these methods are based on the particular GameObject instance assigned to clone, so why aren't they all returning the same specific instance of clone.prop_asteroid_01.renderer.material.color?</p>

<pre><code>eGameObject clone = (GameObject) Instantiate (hazard, spawnPosition, spawnRotation);
// This works
clone.transform.Find(""prop_asteroid_01"").renderer.material.color = Color.blue;
// This fails at compile time: ""Static member `UnityEngine.GameObject.Find(string)' cannot be accessed with an instance reference, qualify it with a type name instead""
clone.Find(""prop_asteroid_01"").renderer.material.color = Color.blue;
// Fails with runtime error ""Object reference not set to an instance of an object""
clone.GetComponent(""prop_asteroid_01"").renderer.material.color = Color.blue;
</code></pre>

<p>Thanks for your help.</p>
","<p>So <code>GameObject.Find()</code> and <code>Transform.Find()</code> are used to find an <strong>active</strong> game object, or child, within your scene(and in that respective order). Before we go any further, recognize the difference between a GameObject, Component, and the relationship between parents and children when using Unity.</p>

<h1><strong>Getting our Definitions Straight</strong></h1>

<p>Think of a GameObject as an empty container. You can fill this container with whatever you want.   Let's say a MeshFilter and MeshRenderer. These are components. They are components of the object. Scripts? Those are components too(they are referred to as behavior components)! You can also attach other GameObjects to this game object creating a parent - child relationship and thus creating a hierarchy. </p>

<h2>I kinda get it</h2>

<p>Let me attempt to make this explanation a bit more easier to visualize:</p>

<p>Hierarchy: </p>

<pre><code>Parent Object (Character)
       [   Transform     ] (Component)
       [   Mesh Renderer ] (Component)
       [   Mesh Filter   ] (Component)
       [ Movement Script ] (Behavior Component)
                          .../RHand (GameObject/Child/Prefab)
                          .../LHand (GameObject/Child/Prefab)
                          .../Eye   (GameObject/Child/Prefab)
                          .../RLeg  (GameObject/Child/Prefab)
                          .../LLeg  (GameObject/Child/Prefab)
</code></pre>

<p>So you have a GameObject. A container to store the children(GameObjects or Prefabs), the components(provided out of the box by Unity) and the behavior components that you make. The GameObject at the highest level is considered the parent and the objects that fall in line below are, you guessed it, child objects! Pretty simple concept to grasp, right?</p>

<h3>OK, OK, but why doesn't that code run!?</h3>

<p>Finding out why your code doesn't work is the first step to a solid understanding, besides having correct definitions of course! I'll start from the top.</p>

<p>You do:</p>

<pre><code>GameObject clone = (GameObject) Instantiate (hazard, spawnPosition, spawnRotation);
</code></pre>

<p>You probably know why this works. You have a variable, clone,  which is of type GameObject and you are ""cloning"" or ""duplicating"" the GameObject hazard into the clone variable. That's what Instantiate does. It makes a copy.</p>

<pre><code>    // This fails at compile time: ""Static member `UnityEngine.GameObject.Find(string)' 
    // cannot be accessed with an instance reference, qualify it with a 
    // type name instead""
    clone.Find(""prop_asteroid_01"").renderer.material.color = Color.blue;
</code></pre>

<p>Now would be a great time to talk about instance methods, and <a href=""http://docs.unity3d.com/Documentation/ScriptReference/GameObject.Find.html"">static methods</a>. Static Methods can be accessed without having an initialized instance of said type. You just need the type name, and the correct function name and it will allow you to use it without error. What you're doing in this line is attempting to use a non-existent instance function. GameObject.Find is a static function, not an instance function! gameObject is an instance of GameObject. ""GameObject"" alone is the type, and can be used to access those static methods! Not only that - but this is the incorrect use of <code>GameObject.Find</code>. This particular function does not concern itself with child object. That is the job of <a href=""https://docs.unity3d.com/Documentation/ScriptReference/Transform.Find.html"">transform.Find</a>  </p>

<pre><code>// Fails with runtime error ""Object reference not set to an instance of an object""
clone.GetComponent(""prop_asteroid_01"").renderer.material.color = Color.blue;
</code></pre>

<p>Remember those definitions? Is a component a gameObject(of course this varies from engine to engine, but we are talking about Unity). <strong>No!</strong> So what would you use to find the child of the parent object(clone)?? I told you in the paragraph above. Use transform.Find. This is not a static method, so it requires an instance of type Transform!</p>
","72678"
"Why do we use the Pythagorean theorem in game physics?","8695","","<p>I've recently learned that we use Pythagorean theorem a lot in our physics calculations and I'm afraid I don't really get the point. </p>

<p>Here's an example from <a href=""http://www.packtpub.com/game-development-with-three-js/book"">a book</a> to make sure an object doesn't travel faster than a <code>MAXIMUM_VELOCITY</code> constant in the horizontal plane:</p>

<pre><code>MAXIMUM_VELOCITY = &lt;any number&gt;;
SQUARED_MAXIMUM_VELOCITY = MAXIMUM_VELOCITY * MAXIMUM_VELOCITY; 

function animate(){
    var squared_horizontal_velocity = (x_velocity * x_velocity) + (z_velocity * z_velocity);

    if( squared_horizontal_velocity &lt;= SQUARED_MAXIMUM_VELOCITY ){

        scalar = squared_horizontal_velocity / SQUARED_MAXIMUM_VELOCITY;

        x_velocity = x_velocity / scalar;
        z_velocity = x_velocity / scalar;
    }
}
</code></pre>

<p>Let's try this with some numbers:</p>

<p><strong>An object is attempting to move 5 units in x and 5 units in z. It should only be able to move 5 units horizontally in total!</strong></p>

<pre><code>MAXIMUM_VELOCITY = 5;
SQUARED_MAXIMUM_VELOCITY = 5 * 5;
SQUARED_MAXIMUM_VELOCITY = 25;

function animate(){
    var x_velocity = 5;
    var z_velocity = 5;

    var squared_horizontal_velocity = (x_velocity * x_velocity) + (z_velocity * z_velocity);
    var squared_horizontal_velocity = 5 * 5 + 5 * 5;
    var squared_horizontal_velocity = 25 + 25;
    var squared_horizontal_velocity = 50;

//  if( squared_horizontal_velocity &lt;= SQUARED_MAXIMUM_VELOCITY ){
    if( 50 &lt;= 25 ){
        scalar = squared_horizontal_velocity / SQUARED_MAXIMUM_VELOCITY;
        scalar = 50 / 25;
        scalar = 2.0;

        x_velocity = x_velocity / scalar;
        x_velocity = 5 / 2.0;
        x_velocity = 2.5;

        z_velocity = z_velocity / scalar;
        z_velocity = 5 / 2.0;
        z_velocity = 2.5;

        // new_horizontal_velocity = x_velocity + z_velocity
        // new_horizontal_velocity = 2.5 + 2.5
        // new_horizontal_velocity = 5
    }
}
</code></pre>

<p>Now this works well, but we can do the same thing without Pythagoras:</p>

<pre><code>MAXIMUM_VELOCITY = 5;

function animate(){
    var x_velocity = 5;
    var z_velocity = 5;

    var horizontal_velocity = x_velocity + z_velocity;
    var horizontal_velocity = 5 + 5;
    var horizontal_velocity = 10;

//  if( horizontal_velocity &gt;= MAXIMUM_VELOCITY ){
    if( 10 &gt;= 5 ){
        scalar = horizontal_velocity / MAXIMUM_VELOCITY;
        scalar = 10 / 5;
        scalar = 2.0;

        x_velocity = x_velocity / scalar;
        x_velocity = 5 / 2.0;
        x_velocity = 2.5;

        z_velocity = z_velocity / scalar;
        z_velocity = 5 / 2.0;
        z_velocity = 2.5;

        // new_horizontal_velocity = x_velocity + z_velocity
        // new_horizontal_velocity = 2.5 + 2.5
        // new_horizontal_velocity = 5
    }
}
</code></pre>

<p>Benefits of doing it without Pythagoras: </p>

<ol>
<li>Less lines</li>
<li>Within those lines, it's easier to read what's going on</li>
<li>...and it takes less time to compute, as there are less multiplications</li>
</ol>

<p>Seems to me like computers and humans get a better deal without Pythagorean theorem! However, I'm sure I'm wrong as I've seen Pythagoras' theorem in a number of reputable places, so I'd like someone to explain me the benefit of using Pythagorean theorem to a maths <strong>newbie</strong>. </p>

<p>Does this have anything to do with unit vectors? To me a unit vector is when we normalize a vector and turn it into a fraction. We do this by dividing the vector by a larger constant. I'm not sure what constant it is. The total size of the graph? Anyway, because it's a fraction, I take it, a unit vector is basically a graph that can fit inside a 3D grid with the x-axis running from -1 to 1, z-axis running from -1 to 1, and the y-axis running from -1 to 1. That's literally everything I know about unit vectors... not much :P And I fail to see their usefulness.</p>

<p>Also, we're not really creating a unit vector in the above examples. Should I be determining the scalar like this:</p>

<pre><code>// a mathematical work-around of my own invention. There may be a cleverer way to do this! I've also made up my own terms such as 'divisive_scalar' so don't bother googling
var divisive_scalar = (squared_horizontal_velocity / SQUARED_MAXIMUM_VELOCITY);
var divisive_scalar = ( 50 / 25 );
var divisive_scalar = 2;

var multiplicative_scalar = (divisive_scalar / (2*divisive_scalar));
var multiplicative_scalar = (2 / (2*2));
var multiplicative_scalar = (2 / 4);
var multiplicative_scalar = 0.5;

x_velocity = x_velocity * multiplicative_scalar
x_velocity = 5 * 0.5
x_velocity = 2.5
</code></pre>

<p>Again, I can't see why this is better, but it's more ""unit-vector-y"" because the multiplicative_scalar is a unit_vector? As you can see, I use words such as ""unit-vector-y"" so I'm really not a maths whiz! Also aware that unit vectors might have nothing to do with Pythagorean theorem so ignore all of this if I'm barking up the wrong tree.</p>

<p>I'm a very visual person (3D modeller and concept artist by trade!) and I find diagrams and graphs really, really helpful so as many as humanely possible please!</p>
","<p>Your Pythagoras-free code doesn't compute a length as we normally think of it.</p>

<p>Normally in 3D games we model the world as a Euclidean space, and we use a <a href=""http://en.wikipedia.org/wiki/Euclidean_metric"" rel=""nofollow noreferrer"">Euclidean distance metric</a> (<a href=""https://gamedev.stackexchange.com/a/75543/39518"">also known as Pythagorean Theorem</a>) to calculate the total length of a vector v with components v.x and v.y. Namely:</p>

<pre><code>EuclideanLength(v) = sqrt(v.x * v.x + v.y * v.y)
</code></pre>

<p>(Note that this square root is missing in your sample code above, which is why the two approaches appear to give the same answer. More on that shortly...)</p>

<p>The code you've described uses the <a href=""http://en.wikipedia.org/wiki/Taxicab_geometry"" rel=""nofollow noreferrer"">Manhattan distance metric</a>:</p>

<pre><code>ManhattanLength(v) = abs(v.x) + abs(v.y)
</code></pre>

<p>(Although you didn't include the absolute values, which may make it behave unexpectedly for negative numbers)</p>

<p>It's easy to see that these two distance functions match-up when v.x or v.y is zero, and we're only moving along one axis. How do they compare though when we move diagonally?</p>

<p>Let's say v.x = v.y = 1. How long is this vector (equivalently, how fast is the velocity it describes)?</p>

<pre><code>Euclidean                              Manhattan

sqrt(v.x*v.x + v.y * v.y)              abs(v.x) + abs(v.y)
sqrt(1 * 1 + 1 * 1)                    abs(1) + abs(1)
sqrt(2)                                1 + 1
1.414...                               2
</code></pre>

<p>You can see these metrics don't actually agree for diagonal lines.</p>

<p>Let's plot on a graph the set of points that each metric says are a distance of 1 away from the origin:</p>

<p><img src=""https://i.stack.imgur.com/jDlvI.png"" alt=""Distance metrics""></p>

<p>Our familiar Euclidean metric is the red circle. This is the set of all points x,y such that x^2 + y^2 = 1. You can see that it's rotationally-symmetric, and that's why we like it: it neatly represents the idea that distance doesn't change with direction.</p>

<p>The Manhattan metric is the blue diamond. Not a great match for our intuitive idea of distance - but that doesn't make it bad. In many tile-based games where you move in discrete steps in the four cardinal directions, the Manhattan metric gives the correct distance between points (in terms of ""how many moves will it take to get there?"")</p>

<p>Finally, I threw in the <a href=""http://en.wikipedia.org/wiki/Chebyshev_distance"" rel=""nofollow noreferrer"">Chebyshev metric</a> for fun - it's the green square:</p>

<pre><code>ChebyshevLength(v) = max(abs(v.x), abs(v.y))
</code></pre>

<p>It's also good for tile-based games, where you're allowed to move on diagonals. A King in Chess moves according to the Chebyshev metric.</p>

<p>I hope that clears up what the difference is between typical Pythagorean-style code and the example you provided above.</p>
","75631"
"How can I make particles glow and cast light on its surroundings?","8688","","<p>Im currently attempting to make a firefly effect on a dark forest. The level has very low light and the player is one of the few light sources. To let the player see the level better, I am attempting to making glowing fireflies appear randomly on the map. One way is to use a particle system. But I cant make the particles cast light one the surroundings. Is there a way to do this?</p>
","<hr>

<h2>Heads-Up:</h2>

<p><strong>This answer is outdated. Unity now supports point light particles natively.</strong> Please see Sam's answer on this page for full details.</p>

<p>I'll leave post this here for anyone curious, or using old versions of Unity, or needing more manual control than the native method offers - just note that the native support is likely to be much more efficient and scalable than the approach presented below.</p>

<hr>

<p>I'm not sure why so many answers claim this is difficult or impossible. Handling a few dozen dynamic point lights is pretty conventional for a <a href=""http://docs.unity3d.com/Manual/RenderTech-DeferredShading.html"" rel=""nofollow noreferrer"">modern deferred rendering pipeline</a> running on PC.</p>

<p>Here's a quick example I cooked up:
<a href=""https://i.stack.imgur.com/uj7dL.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/uj7dL.gif"" alt=""Example of fireflies with lights""></a></p>

<p>I use this script to dynamically spawn enough lights for my max particles (make sure you adjust your Particle System settings so the max is reasonable - the default of 1000 will not make your graphics card very happy), and then updates them to follow the active particles:</p>

<pre><code>[RequireComponent(typeof(ParticleSystem))]
public class ParticleLights : MonoBehaviour {

    public Light lightPrefab;

    ParticleSystem _system;
    ParticleSystem.Particle[] _particles;
    Light[] _lights;


    void Start () {
        _system = GetComponent&lt;ParticleSystem&gt;();
        _particles = new ParticleSystem.Particle[_system.maxParticles];

        _lights = new Light[_system.maxParticles];
        for(int i = 0; i &lt; _lights.Length; i++)
        {
            _lights[i] = (Light)Instantiate(lightPrefab);
            _lights[i].transform.parent = transform;
        }
    }

    void Update () {

        int count = _system.GetParticles(_particles);
        for(int i = 0; i &lt; count; i++)
        {
            _lights[i].gameObject.SetActive(true);
            _lights[i].transform.localPosition = _particles[i].position;

            // Looks like the GetCurrentColor function was added in 5.3.
            // You can use other methods in earlier Unity versions.
            _lights[i].color = _particles[i].GetCurrentColor(_system);
        }

        for (int i = count; i &lt; _particles.Length; i++)
        {
            _lights[i].gameObject.SetActive(false);
        }
    }
}
</code></pre>

<p><strong>Edit:</strong> you can create a <a href=""http://docs.unity3d.com/Manual/Prefabs.html"" rel=""nofollow noreferrer"">prefab</a> by first creating a game object (in this case, Create -> Light -> Point Light), setting it up with the name/parameters/scripts/children you want, then dragging it from your Hierarchy into your Project explorer. This saves the object as an asset you can reuse across multiple scenes &amp; scripts, with a degree of inheritance. You can delete the copy in your scene and the asset will remain in your Assets folder to be referenced when needed.</p>

<p>Make sure the lightPrefab has a relatively small range and is not shadowcasting, to give you the most performance headroom for everything going on in your scene. You don't need to make the lightPrefab itself green (or the colour of your fireflies) - it will pick it up from the particles' colour.</p>

<p>You might find though that you have better control over the fireflies' flight if you make each one its own GameObject, with a billboarded quad and a light attached with a custom movement/blinkig script, since getting a convincing wander takes more particle system artistry than I know. ;)</p>
","113449"
"Translate object in world space usings it's local rotation","8677","","<p>I'm using <a href=""https://github.com/mrdoob/three.js/"" rel=""nofollow"" title=""three.js"">Three.JS</a> to render some objects. I'm struggling with some very simple object rendering and translation.</p>

<p>The scenario is that I spawn an object at 0,0,0 in world space with 0,0,0 rotation.</p>

<pre><code>var scene, camera, cube;

...

function change() {
  var degrees = 90
  var zTranslation = 5;

  cube.rotation.y = degrees * Math.PI / 180;
  cube.rotation.z = zTranslation;

  var newCubeMatrix = cube.matrix;        
  newCubeMatrix.identity();
  newCubeMatrix.multiplySelf(THREE.Matrix4.rotationYMatrix(cube.rotation.y));
  newCubeMatrix.multiplySelf(THREE.Matrix4.translationMatrix(cube.position.x, cube.position.y, cube.position.z));

  cube.updateMatrix();
}

function loop() {
  renderer.render( scene, camera );
}

...
</code></pre>

<p>What now happens is that the cube is rotation 90 degrees and translated 5 points on the Z axis in world space, not 5 points on the Z axis in the cube's local space.</p>

<p>How do I make the cube translate 5 points in it's local space?</p>
","<p>The order of the transforms is important. </p>

<p>Rotating around Y and then translating along Z rotates the object around its Y and then translates along world Z.</p>

<p>Translating along Z and then rotating around Y rotates <em>the scene</em> around Y, that is, the cube is already 5 units from the origin, and the whole scene rotates.</p>

<p>First of all you need to determine which you're trying to achieve. It may be useful to forget about different coordinate spaces, just assume the cube starts at the scene's origin and you then apply several transforms to its vertices, all in scene space.</p>

<p>Once you've figured out the correct order of operations, figure out (either by trial and error or reading the documentation (!)) whether the API premultiplies or postmultiplies the vertices and the matrices. Then make sure you concatenate the transforms in the correct order, because P*T*R will yield a different P' (transformed P) than T*R*P, even if the composite transform T*R is the same.</p>
","7495"
"How do I fix this weird lighting problem?","8664","","<p>I'm making a small game in Unity, and some models are displaying very ugly shading.  The shading usually looks funky along the edges between triangles.  I'm pretty new to working in 3D; I bet this is an artifact of vertex lighting, but I'm not sure, and I'm not sure how to fix it.</p>

<p>Here you can see the worst example of this problem: <img src=""https://i.stack.imgur.com/wVHyL.jpg"" alt=""alt text""></p>

<p>Low-quality lightmapping is visible in that shot, but I'm asking about the visible bands and weird shapes visible on the surface of the orange mesh in the foreground.  The mesh was built and UV-mapped in Blender, and is using a standard bumped diffuse shader.  There is a light behind and above the camera; all other lights in the scene are pretty far away.  What am I doing wrong, and how can I do better?</p>

<p>EDIT: Below is the wireframe for this model in Blender.</p>

<p><img src=""https://i.stack.imgur.com/Yyg43.jpg"" alt=""alt text""></p>
","<p>It looks like your vertex normals might be messed up. Each vertex's normals should be perpendicular to its face (parallel with the face normals that your wireframe image shows), and you'll need separate vertices for the corners, one for each face that meets at a corner.</p>
","7505"
"Why do game developers develop games for exclusive contracts?","8655","","<p>There are several companies that develop their games for one console only (Playstation or XBox). Why and how are they doing this? Shouldn't there be more sales when they publish it for PC/PS/Xbox?</p>

<p><strong>Why are they signing such contracts? What are the benefits?</strong></p>

<p>Note: As long as these games are full funded by the console company I totally understand this exclusivity - but are there cases where these companies do not fund a game and it is still exclusive?</p>
","<p>The benefits are often money related. </p>

<p>From a console manufacturer perspective, an exclusive title means their console becomes more attractive if a high profile game is only available to them. Thus to them it is a marketing opportunity (and probably comes from their marketing budget). It may also be an opportunity to sell specific hardware (example Playstation VR). </p>

<p>For the development team, it may limit their sales, however there may be some benefits  out of the deal that outweighs the lost sales.</p>

<p>These may be:</p>

<ul>
<li>Access to development resources that otherwise may be hard to get (reducing time and saving money). </li>
<li>Access to prototype hardware that may otherwise be hard to get (opportunity to break into an emerging market - launch titles may achieve greater sales due to limited competition).</li>
<li>Console manufacturer may pay for the exclusivity up front (reduces the risk of a game since part of the budget is covered).</li>
<li>Assistance from the console partner in terms of marketing the game (less time/money required for the developer and possibly increased visibility).</li>
<li>Exclusivity may save developers time in supporting the game in multiple formats (this may not be a ""deal"", but is a consideration that could lead to a developer to launch a game exclusively).</li>
<li>Related: not needing to develop for multiple hardware stacks for which may be partially incompatible. </li>
<li>Some developer programmes are more accessible than others (a firm might get accepted to ID@Xbox but be told ""not yet"" by Sony and Nintendo).</li>
</ul>

<p>In the end, the benefits are often driven by cash.</p>
","124700"
"How do I implement a quaternion based camera?","8651","","<p><strong>UPDATE</strong> The error here was a pretty simple one. I have missed a radian to degrees conversion. No need to read the whole thing if you have some other problem.</p>

<p>I looked at several tutorials about this and when I thought I understood I tried to implement a quaternion based camera. The problem is it doesn't work correctly, after rotating for approx. 10 degrees it jumps back to -10 degrees. I have no idea what's wrong. I'm using openTK and it already has a quaternion class. I'm a noob at opengl, I'm doing this just for fun, and don't really understand quaternions, so probably I'm doing something stupid here. Here is some code: (Actually almost all the code except the methods that load and draw a vbo (it is taken from an OpenTK sample that demonstrates vbo-s))</p>

<p>I load a cube into a vbo and initialize the quaternion for the camera</p>

<pre><code>protected override void OnLoad(EventArgs e) {
    base.OnLoad(e);

    cameraPos = new Vector3(0, 0, 7);
    cameraRot = Quaternion.FromAxisAngle(new Vector3(0,0,-1), 0);

    GL.ClearColor(System.Drawing.Color.MidnightBlue);
    GL.Enable(EnableCap.DepthTest);

    vbo = LoadVBO(CubeVertices, CubeElements);
}
</code></pre>

<p>I load a perspective projection here. This is loaded at the beginning and every time I resize the window.</p>

<pre><code>protected override void OnResize(EventArgs e) {
    base.OnResize(e);

    GL.Viewport(0, 0, Width, Height);

    float aspect_ratio = Width / (float)Height;

    Matrix4 perpective = Matrix4.CreatePerspectiveFieldOfView(MathHelper.PiOver4, aspect_ratio, 1, 64);
    GL.MatrixMode(MatrixMode.Projection);
    GL.LoadMatrix(ref perpective);
}
</code></pre>

<p>Here I get the last rotation value and create a new quaternion that represents only the last rotation and multiply it with the camera quaternion. After this I transform this into axis-angle so that opengl can use it. (This is how I understood it from several online quaternion tutorials)</p>

<pre><code>protected override void OnRenderFrame(FrameEventArgs e) {
    base.OnRenderFrame(e);

    GL.Clear(ClearBufferMask.ColorBufferBit | ClearBufferMask.DepthBufferBit);

    double speed = 1;
    double rx = 0, ry = 0;

    if (Keyboard[Key.A]) {
        ry = -speed * e.Time;
    }

    if (Keyboard[Key.D]) {
        ry = +speed * e.Time;
    }

    if (Keyboard[Key.W]) {
        rx = +speed * e.Time;
    }

    if (Keyboard[Key.S]) {
        rx = -speed * e.Time;
    }

    Quaternion tmpQuat = Quaternion.FromAxisAngle(new Vector3(0,1,0), (float)ry);
    cameraRot = tmpQuat * cameraRot;
    cameraRot.Normalize();

    GL.MatrixMode(MatrixMode.Modelview);
    GL.LoadIdentity();

    Vector3 axis;
    float angle;

    cameraRot.ToAxisAngle(out axis, out angle);
    //////////////////////////////////////////////////////////////////////
    // THIS IS WHAT I DID WRONG: I NEED TO CONVERT FROM RADIANS TO DEGREES
    //////////////////////////////////////////////////////////////////////
    //BEFORE
    //GL.Rotate(angle, axis);
    //AFTER
    GL.Rotate(angle * (float)180.0/(float)Math.PI, axis);
    GL.Translate(-cameraPos);

    Draw(vbo);
    SwapBuffers();
}
</code></pre>

<p>Here are 2 images to explain better:
I rotate a while and from this:</p>

<p><img src=""https://i.stack.imgur.com/5jCbA.jpg"" alt=""this""></p>

<p>it jumps into this</p>

<p><img src=""https://i.stack.imgur.com/OKseI.jpg"" alt=""enter image description here""></p>

<p>Any help is appreciated.</p>

<p><strong>Update1</strong>: I add these to a streamwriter that writes into a file:</p>

<pre><code>    sw.WriteLine(""camerarot: X:{0} Y:{1} Z:{2} W:{3} L:{4}"", cameraRot.X, cameraRot.Y, cameraRot.Z, cameraRot.W, cameraRot.Length);
    sw.WriteLine(""ry: {0}"", ry);
</code></pre>

<p>The log is available here: <a href=""http://www.pasteall.org/26133/text"" rel=""nofollow noreferrer"">http://www.pasteall.org/26133/text</a>. At line 770 the cube jumps from right to left, when camerarot.Y changes signs. I don't know if this is normal.</p>

<p><strong>Update2</strong> <a href=""http://dl.dropbox.com/u/42672139/OpenTKCameraQuat.zip"" rel=""nofollow noreferrer"">Here</a> is the complete project.</p>
","<p>While you haven't shown the necessary code to verify my assumption here, I can almost guarantee that your problem is actually that this line:</p>

<pre><code>cameraRot.ToAxisAngle(out axis, out angle);
</code></pre>

<p>is returning an <em>angle</em> value expressed in <strong>radians</strong>, while</p>

<pre><code>GL.Rotate(angle, axis);
</code></pre>

<p>wants <em>angle</em> to be provided in <strong>degrees</strong>.</p>

<p>To fix it, you need to convert the <em>angle</em> value when passing it to GL.Rotate(), like this:</p>

<pre><code>GL.Rotate(angle * 180.0/3.141593, axis);
</code></pre>
","20429"
"How do I optimize searching for the nearest point?","8650","","<p>For a little project of mine I'm trying to implement a <a href=""http://algorithmicbotany.org/papers/colonization.egwnp2007.html"">space colonization algorithm</a> in order to grow trees.</p>

<p>The current implementation of this algorithm works fine. But I have to optimize the whole thing in order to make it generate faster. I work with 1 to 300K of random attraction points to generate one tree, and it takes a lot of time to compute and compare distances between attraction points and tree node in order to keep only the closest treenode for an attraction point.</p>

<p>So I was wondering if some solutions exist (I know they must exist) in order to avoid the time loss looping on each tree node for each attraction point to find the closest... and so on until the tree is finished.</p>
","<p><a href=""http://conkerjo.wordpress.com/2009/06/13/spatial-hashing-implementation-for-fast-2d-collisions/"" rel=""nofollow noreferrer"">Spatial hashing</a>, <a href=""http://en.wikipedia.org/wiki/Quadtree"" rel=""nofollow noreferrer"">quadtrees</a> or <a href=""http://en.wikipedia.org/wiki/Octree"" rel=""nofollow noreferrer"">octrees</a> can be used to find candidates for the nearest neighbour quickly: and then you can use the loop on that candidate set to get the actual nearest neighbour.</p>

<p><strong>Initial Premature Optimization</strong></p>

<ul>
<li><code>sqrt(n) &gt; sqrt(y) if n &gt; y and n &gt; 0 and y &gt; 0</code></li>
<li><code>sqrt(n) &lt; sqrt(y) if n &lt; y and n &gt; 0 and y &gt; 0</code></li>
<li><code>sqrt(n) = sqrt(y) if n = y and n &gt; 0 and y &gt; 0</code></li>
<li><code>x*x + y*y &gt; 0</code></li>
</ul>

<p>This means you don't need to find the square roots of the distance squared (so compare <code>dx*dx + dy*dy + dz*dz</code> instead of <code>sqrt(dx*dx + dy*dy + dz*dz)</code>).</p>

<p><strong>Spatial Hashing</strong></p>

<ol>
<li>Get the items in the bucket that contains the item you are interested in, as well as the buckets surrounding it (in 3D that would mean you would need to get the items in 9 buckets).</li>
<li>Eliminate the original item from the set.</li>
<li>Loop through those items and find the nearest neighbour.</li>
</ol>

<p><strong>Quadtree</strong></p>

<p>Consider the following diagram of a 2D quadtree.</p>

<p><img src=""https://i.stack.imgur.com/X8XBE.png"" alt=""Quadtree Nearest Neighbour""></p>

<p>Basically ""the check"" means:</p>

<pre><code>// numberOfPointsSeen is the number of points seen in quads so far.
if numberOfPointsSeen &gt; 0 then
   return nearestNeighbourUsingLoop(numberOfPointsSeen)
else
   continueToNextConcentricSquare()
</code></pre>

<p>If you organise your quadtree so that each quadnode can only contain one item (this might not make sense in terms of memory usage though):</p>

<pre><code>if currentQuadContainsItem then
   return itemInCurrentQuad
else
   continueSearching()
</code></pre>
","27270"
"Daz3D for creating game assets","8649","","<p>Are the <a href=""http://daz3d.com"" rel=""nofollow"">Daz</a> products viable for 2D/3D game asset creation or are they geared more towards creating art?  I am thinking of the products: Daz Studio 3D, Bryce and Carrara. </p>

<p>If you have used any of these products for 2D or 3D asset creation please provide input on any export issues you have encountered.</p>
","<p>I know this was asked a while back but i've spent some time on this for my own project so in case anyone else wants to know here are the results of my experiments (assuming you are thinking of skinned characters):</p>

<p><strong>On Licensing</strong><br>
Daz is venturing (tentatively) into the 3d assest market and as such their new EULA does permit use of their models (&amp; derived) in computer games with a couple of restrictions:</p>

<blockquote>
  <p>SUMMARY: </p>
  
  <p>Summary of section 5 – INCORPORATION
  OF 3D MODEL(S) INTO OTHER WORKS </p>
  
  <p>You may use the 3D content/models or
  derivatives thereof when embedded in a
  single game or other project if you
  have purchased the “single-use”
  license. By purchasing the
  “multiple-use” license, you may use
  the content/models or derivatives
  thereof when embedded in the number of
  games or projects authorized by the
  multiple-use license. </p>
  
  <p>You may publish, market, distribute,
  transfer or sell any games or projects
  that contain DAZ content/models as
  long as the DAZ content/models are not
  accessible to end users in their
  native formats and are protected by
  asset protection technology,
  encryption or whatever means necessary
  to protect them from theft or
  copyright infringement.</p>
</blockquote>

<p>(<a href=""https://helpdaz.zendesk.com/entries/123880-what-is-daz-3d-s-real-time-game-content-end-user-license-agreement-eula"" rel=""nofollow"">https://helpdaz.zendesk.com/entries/123880-what-is-daz-3d-s-real-time-game-content-end-user-license-agreement-eula</a>)</p>

<p>In regards to open source projects I am not sure (I emailed and haven't had a response yet).
Bear in mind however that most of the content sold in Daz's store and in other marketplaces like Renderosity have their own licenses.</p>

<p><em>[See update 1]</em></p>

<p><strong>File Formats</strong><br>
Daz Studio is free and can import/export OBJ and COLLADA files as standard. Plugins can be purchased to export to CR2 (Poser Characters) and FBX.</p>

<p>In my experience OBJ transports fine between 3DS Max &amp; Daz Studio but the associated MTL material files do not; I am not sure whether this is due to Daz or Max (probably a bit of both). The problems can be resolved easily with a text editor - but it is still another stage in your pipeline no matter how small.</p>

<p>An important point to consider is rigging. As opposed to vertex weighting, Daz models consist of many distinct poly groups which correspond to bones. These groups deform with respect to a single bone based on spherical falloff zones defined for each axis of rotation.
(I think this is used to maintain compatibility with Poser; certainly i've seen posts on their forums of people saying vertex weighting would be easier when creating clothing)</p>

<p>The OBJ format does not support vertex weights, or skeletons (though I suppose you may be able to pack one in with something like empty poly groups, I doubt it would be pretty).</p>

<p>Daz can convert these falloff zones to vertex weights when exporting to FBX and the results are pretty good - I'm sure a modeller could do better if they were working with vertex weighting natively but its unlikely you'll notice unless the limbs are at extremes.</p>

<p>Poser CR2 files support the poly group rigging but are horrifically complex. Check out Kuroyume's CR2 spec (http://www.kuroyumes-developmentzone.com/poser/poserfilespec/products_poser_cr2.html) to see what I mean.<br>
CR2 files make liberal use of external references so you will need to process OBJs in full to support CR2s. Further that spec is for an older format. The latest version (8 I believe) had about 5 new sections when I tried to import it using the CR2 importer I've been working on.</p>

<p>I haven't seen any open source CR2 importers you could modify easily for your project - it looks as if usually people start on one then give up halfway through and writing one myself I can see why!   </p>

<p><strong>Performance</strong><br>
Daz models are very high poly but I dont think this is as much of an issue as people make out. Daz has 'Decimator', a plugin which can reduce the poly count, though I don't even use it on the Daz models I use in my XNA project as they render perfectly fast; the count is about ~130,000 polys for V4 (base female human model).</p>

<p>Whats more of a concern is the textures.</p>

<ol>
<li><p>They are very large (esp. third party products), so you will need to resize them in the pipeline depending on your engine/api.</p></li>
<li><p>They are numerous. (I'm talking 3 different textures for the EYE!)</p></li>
<li><p>Most importantly the materials have all sorts of 'odd' configurations - things like bump and transparency maps with no diffuse map. Its not that they are hard to support, its that there are so many different combinations you either need a very comprehensive importer or very comprehensive shader set and model class.<br>
My importer combines the trans and diffuse maps (creating if necessary), and adds vertex colour and normal data if missing - as a result I pack alot of 'white' structures into the resultant file but I only need 4 shaders.</p></li>
</ol>

<p><strong>Alpha Sorting</strong><br>
Daz models (like probably most organic models) makes liberal use of transparency maps; further the nature of the models prohibits depth sorting before drawing.</p>

<p>Let me pose a question: When you model an eye, do you surround the completed model eye with an extraneous sphere that has a solid diffuse colour (no map) but a transparency map that turns it invisible? So when the unsuspecting prospective game developer loads up the model the eyes appear black from the outside while from the inside are textured fine? Daz does. (Its to create the glossy wet sheen effect - turn the opacity setting of the material 7_EyeSurface down to 0 on the default V4 to see what I mean)</p>

<p>I use 2-pass alpha sorting which is best for the 'cutout' transparency maps (which is what Daz models use it for mostly). This is built right into my model base class and engine from the start.</p>

<p><strong>Customizing the character</strong><br>
Clothes don't have to have a loose fit to deform properly once exported with bone weights, but beware that those ~90,000+ polys they are obscuring will still be there.</p>

<p><strong>Animation</strong><br>
FBX supports animation (in theory). Daz does have a keyframe animation editor but its a little 'light' and not easy to use. Daz also has plugins such as AniMate Lite which allow you to drag and drop animation segments into a timeline and then bake the keyframes into an animation to be exported.</p>

<p>I've found extracting animations from FBX to be a little hit and miss, especically when baked from AniMate. For example, the walking animation 'block' will acctually move the model in model space so you couldn't simply pop that into the timeline, bake, export and then move your character around in time with it in an FPS.</p>

<p>Further I've found that sometimes the exported animation causes the mesh, or a prop, to deform incorrectly; and since FBX files are accessed with an Autodesk SDK as opposed to with a custom importer like most formats its not trivial to look inside and see where the problem lies. (On the plus side I've worked out where the Dead Space developers got the ideas for all their monsters.)</p>

<p><strong>To Summarise</strong>  </p>

<ol>
<li><p>If you want to use Daz models you
will need the FBX exporter because
OBJ is not comprehensive enough and
CR2s are too complex to import, and
even if you did your shader would
need to support a new type of
rigging*.</p></li>
<li><p>Do not be concerned with poly counts
or texture sizes until you need to
be. Textures can be resized (and
also combined into one texture for
the whole character using Daz's
Texture Atlas) and Daz has plugins
for reducing poly counts IF you need
them.</p></li>
<li><p>Do be aware that the models will
have quirks that a game artist would
never dream of putting in - 3x
texture for 1x eye and 'specular
surface sphere' for example.</p></li>
</ol>

<p>I think Daz models are a super resource, esp. for hobbyist developers, but to be used seriously they would be best utilized <em>as</em> a resource as opposed to a complete asset - design your characters, clothe them, <em>then</em> cull unseen polys, bake and animate in the modeller of your choice. 
Also, while Studio itself is free, to create and equip characters to a resonable standard, and export them in useful formats, you will need ~£70-100 worth of content and plugins minimum.</p>

<p>*Not saying that would be prohibitively hard though - maybe have say a single 'vertex distance' plugged in by the importer as opposed to four vertex weights, and set the falloff zones &amp; transform shader wide for each poly group (geometry segment).</p>

<p><strong>Update 1:</strong>
When purchasing Daz models for use in realtime rendering environments, it needs to be done via Daz's Developer Store at <a href=""http://developer.daz3d.com"" rel=""nofollow"">http://developer.daz3d.com</a>; this site has the option to buy a Single or Multiple Use license.
The V4 Base in the developer store starts at ~$60 so it may be worth prototyping with the free V4 Base from the regular store first.</p>

<p>According to <a href=""http://forum.daz3d.com/viewtopic.php?t=134701&amp;start=0&amp;postdays=0&amp;postorder=asc&amp;highlight=&amp;sid=7de96a0b6e6edf3178cb93acadc430b3"" rel=""nofollow"" title=""Daz Developer Store FAQ"">the Daz Developer Store FAQ</a> models may not be given away for free, i.e. distributed as a part of any free project such as an open source game or mod.</p>
","10151"
"How to make Line Renderer lines stay flat?","8648","","<p>I've noticed that as I add more vertexes to a Line Renderer line the line twists and stops being a smooth line. </p>

<p><img src=""https://i.stack.imgur.com/hOguO.jpg"" alt=""enter image description here""></p>

<p>.GIF Here: <a href=""https://i.imgur.com/hRAhCXM.gif"" rel=""noreferrer"">http://i.imgur.com/hRAhCXM.gif</a></p>

<p>All lines are on the same z level, even if I remove the materials the lines still seem to twist.</p>

<p>I have no idea why it does this, or how to go about resolving it, any suggestions?C#</p>
","<p>The problem is basically this:</p>

<p><img src=""https://i.stack.imgur.com/ojuM3.png"" alt=""enter image description here""></p>

<p>The LineRenderer is trying to connect the red dot positions. It's creating the green vertices to make a mesh. So the top line segment looks great. But then the LineRenderer tries to be economical, it reuses the vertices from the end of one line segment in the end of the second line segment. When there's a sharp angle, you get the problem you're seeing. The second line segment is pinched at the intersection because its 'end cap' is not perpendicular with its other 'end cap'.</p>

<p>The solution is to create your own line renderer, and not make it so economical. You can do this by generating a dynamic <a href=""http://docs.unity3d.com/ScriptReference/Mesh.html"" rel=""noreferrer"">mesh</a>. The mesh will consist of a series of thin quads. For each line segment, you can compute the four corners of the quad by calculating the normal of the line and a specified line width:</p>

<pre><code>Vector3 normal = Vector3.Cross(start, end);
Vector3 side = Vector3.Cross(normal, end-start);
side.Normalize();
Vector3 a = start + side * (lineWidth / 2);
Vector3 b = start + side * (lineWidth / -2);
Vector3 c = end + side * (lineWidth / 2);
Vector3 d = end + side * (lineWidth / -2);
</code></pre>

<p>Here, <code>a</code>, <code>b</code>, <code>c</code> and <code>d</code> make up the four corners of a single line segment, just like the green dots in the image above. These vertices would be added to the mesh, and you'd also add the indices to make the four vertices into two triangles (so, six indices would be added, a-b-c and b-d-c).</p>

<p>This can obviously get rather complex. I believe another reason Unity implemented their LineRenderer the way they did was because doing it that way avoids another problem, corners. When you start drawing each line segment you'll start to see where the two line segments come together and form an ugly joint. There are ways to deal with this by calculating the shared normal between both lines and updating their vertices to the shared normal, but this only partially solves the problem, since you can still easily end up with pinched lines. The most robust solution is to generate additional vertices at the joints to act as corners.</p>
","93895"
"Tile map/terrain implementation with differing heights of neighbouring tiles","8646","","<p>Ahoy!</p>

<p>I'm looking for some information about tile maps, or rather, what a specific type of tile map is called.</p>

<p>I'm interested in the kind of implementation used in rollercoaster tycoon, or the transport tycoon series of games and have been looking into vector field terrain and height map terrain but i'm not sure they're suitable for what i'm looking to develop.</p>

<p>It's been a struggle to find any decent info as most people refer to it as an isometric tile map, but I'm looking to create something in 3D with a fixed orthographic perspective. I understand that the underlying storage of the tile map has nothing to do with how it is rendered but i'm not looking to create a 2D tile map like old school pokemon/zelda games, more along the lines of diablo with the capability to include overhanging cliffs and sloping terrain.</p>

<p>I'm just trying to find the right terms to search google and stackoverflow for resources to help me decide which path to proceed.</p>

<p>So far i've managed to flesh out a basic tile map without using the height/y component stored in a VBO and rendered as a wireframe. This looks fine so far but I envisage that I will encounter problems when trying to manipulate a single vertex to create cliffs and slopes without affecting a neighbouring tile.</p>

<p>Is there a specific type of implementation I should be looking into? I thought i'd cracked it when I found a fair amount if info on vector field terrain but i'm not sure this would yield the correct results either.</p>

<p>If anyone can shed some light on this for me please, the help would be greatly appreciated :)</p>

<p><strong>Update</strong></p>

<p>I've included an image for further clarification as to what i'd like to achieve:</p>

<p><img src=""https://i.stack.imgur.com/rzqj8.jpg"" alt=""2.5D tile map""></p>

<p>Image borrowed from <a href=""https://gamedev.stackexchange.com/questions/28396/how-to-create-tilted-height-isometric-tiles"">How to create tilted (height) isometric tiles</a></p>

<p>This image shows the type of terrain i'd like to generate but doesn't include the ""cliffs"" or overhanging terrain types i'm interested in modelling. It does however raise a few other questions I hadn't considered, namely;</p>

<ul>
<li>How would 'layers' such as the water (top left of the image) be handled to include the visible ground underneath the water?</li>
<li>How would the ""edges"" of the map be catered for so that the earth/mud is rendered to depict the world as a non-flat entity?</li>
<li>Could the underlying storage for this kind of terrain be used to model physics such as a ball rolling down a hill or movement speeds of a player traversing a slope?</li>
</ul>

<p>I had an idea in that each tile of the terrain could be modelled with 8 vertices where the 4 main vertices cover the actual tile itself and the remaining 4 vertices are used to model the sides/walls of each tile. The two problems I see with this implementation is that a) the world map is essentially doubled in size and b) given that not all tiles will include ""walls"", some tiles will end up with redundant vertices which are not used.</p>

<p>I'd like to create a terrain editor which allows for each tile to be deformed as well as including the ability to change the terrain during game play. This in itself poses additional questions such as; Can a VBO be used to store and render the terrain whilst being modified on the fly and also, is it possible to modify vertices without affecting neighbouring tiles?</p>

<p>I'm under the impression that i'm either over-complicating things or running into analysis-paralysis in that i'm neglecting to write any code to solve the problem without having a clear idea of how I would achieve what I want.</p>

<p>Again, i'm really just looking for a shove in the right direction with this. Is there a specific type of tilemap/terrain implementation that would cater for a 3D map to be deformed by both a map editor as well as during gameplay or do I have to roll my own, so to speak? I'm not trying to reinvent the wheel here but I am struggling to find any resources given that I'm not sure what to be searching for.</p>

<p>If anyone can provide any info, resources or snippets of code, that would be hugely appreciated as i'm eager to get my hands dirty and start producing something other than the flat wireframe I currently have. </p>

<p>Thanks for reading!</p>
","<p>If I were you I'd look into voxels, more specifically <a href=""http://minecraft.net"" rel=""nofollow"">Minecraft</a>-type cube rendering.  Unlike heightmaps, they can handle overhangs, caverns, buildings with multiple floors, etc.</p>

<p>You'd store your terrain in a 3D array of integers, where numbers are mapped to a certain type of terrain: 0=air, 1=dirt, 2=water, etc.  Then, to create the mesh to render, you'd create the faces of a cube for each non-empty voxel.</p>

<p><a href=""http://dave.uesp.net/wiki/Block_Land"" rel=""nofollow"">This tutorial</a> is a great explanation of how to do this in C++ using Ogre3D.  I presume you'd have to go a little more low-level in OpenGL.</p>

<p>After creating the cubes, you'd want to smooth the edges to create the kind of fluid terrain shown in your image.  I believe <a href=""http://www.volumesoffun.com/polyvox-about/"" rel=""nofollow"">PolyVox</a> (also in C++) does this; you could take a look at their code.  I think you basically do in 3D what the image shows in 2D: average the surrounding cube positions to know where to place each vertex.</p>

<p><strong>EDIT:</strong></p>

<ul>
<li>Generate the faces for the cubes adjacent to water as if the water tile was empty, and render the water faces transparently.</li>
<li>Faces on the ""edge"" can be generated just like regular faces, if you consider voxels outside the world to be empty.</li>
<li>Physics: You can probably feed the rendered mesh to your physics engine as a static object.</li>
<li>Map editor: You'd want to edit the underlying voxel data, not the mesh itself!  (The mesh should mirror the data, so editing the voxels should produce changes in your mesh.)  You might want to look up Model, View, Controller (MVC) if you're not familiar with it.</li>
</ul>

<p>If you have more questions, feel free to leave a comment.  Welcome to gamedev.SE!</p>
","29131"
"How can I give the illusion of height to a ball in 2D?","8639","","<p>In 2D top down soccer games, sometimes a ball is given the illusion of being in the air, like below:</p>

<p><a href=""https://i.stack.imgur.com/RzYkh.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/RzYkh.gif"" alt=""example""></a></p>

<p>How can I achieve this?</p>
","<p>Give the ball a height value. Draw a shadow at the ball's actual 2D position; the shadow will help spatially orient the ball for the player.</p>

<p>When you draw the ball <em>itself</em>, offset the Y position by the ""height"" of the ball. If you want to implement more than just an illusion, use this height value in computations as well -- for example, you can implement the ability for the ball to go over a player's head in a game like you showed by checking if the height is geater than than a player's height.</p>
","123604"
"3D game engines for XNA games","8624","","<p>Before I start development of an XNA game, I need to choose a 3D game engine to develop upon. Is this belief unfounded? Does XNA have basic object transformation, lighting and mesh/texture importing functionality by which you can develop a decent 3D side-scrolling game?</p>

<p>Chances are I'm going to need a 3D engine such as <a href=""http://www.torquepowered.com/products/torque-x"">Torque X</a> to handle most of the special effects, animation and sound for me. What are the engines that you recommend building an XNA game with? What work reliably in your experience? Is XNA alone enough? do you have repositories of code that work directly with XNA to create effects and other game environments with sunlight, fog and rain?</p>
","<p>In short, the most <strong>usable</strong> 3D game engines written in fully managed C# code (which allows you to develop for the Windows and Xbox 360) are:</p>

<ul>
<li><strong><a href=""http://www.codeplex.com/OxGameEngine"" rel=""nofollow noreferrer"">Ox Game Engine</a></strong> - a 3d version of the ButterMilk 2d engine - excellent features, Jiggle physics, reasonable scene editor, shadows. <strong>Free</strong>.</li>
</ul>

<p><img src=""https://i.stack.imgur.com/dW9Zi.png"" alt=""alt text""></p>

<ul>
<li><strong><a href=""http://www.synapsegaming.com/products/sunburn/engine/"" rel=""nofollow noreferrer"">SunBurn</a></strong> - AAA rendering with dynamic lighting &amp; shadowing, occulusion, HDR rendering, spectacular, diffuse and bump maps, and includes a 3D Game world editor to edit models, lights, materials. <strong>$150</strong> or more. <strong>Free</strong> version also <a href=""http://www.synapsegaming.com/products/sunburn/framework/"" rel=""nofollow noreferrer"">available</a>.</li>
</ul>

<p><img src=""https://i.stack.imgur.com/ta32d.png"" alt=""alt text""></p>

<p>I would have mentioned <strong>Torque X</strong> on the top list but the negative response has been so overwhelming that I'm quite convinced it really a mess.</p>

<p>The other engines are listed here:</p>

<p><strong>Open Source</strong></p>

<p>3D</p>

<ul>
<li><a href=""http://txnagameengine.sourceforge.net/"" rel=""nofollow noreferrer"">TXna Game Engine</a> - Includes lighting, camera controllers</li>
<li><a href=""http://axiom3d.net/wiki/index.php/Main_Page"" rel=""nofollow noreferrer"">Axiom3d</a> - port of the native Ogre. Multi platform.</li>
<li><a href=""http://www.codeplex.com/QuickStartEngine"" rel=""nofollow noreferrer"">QuickStart 3D Game Engine</a> - particles, rain, fog, water, terrain</li>
<li><a href=""http://nine.codeplex.com/"" rel=""nofollow noreferrer"">Engine Nine</a> - animation, terrain, sky, post processing screen effects </li>
<li>The <a href=""http://creators.xna.com/en-us/starterkit/shipgame"" rel=""nofollow noreferrer"">Ship Game</a> and the <a href=""http://creators.xna.com/en-us/minigame/robotgame"" rel=""nofollow noreferrer"">Robot Game</a> starter kits contain enough code to make a decent 3d engine though they are not documented as such. </li>
<li><a href=""http://attollo3d.codeplex.com/"" rel=""nofollow noreferrer"">Attolo 3D XNA Engine</a> - Includes particle effects, model loading, terrain, etc.</li>
<li><a href=""http://www.reactor3d.com/forums/index.php?www"" rel=""nofollow noreferrer"">Reactor 3D</a> - development stopped</li>
<li><a href=""http://txnage.codeplex.com/"" rel=""nofollow noreferrer"">Titanium XNA Game Engine</a> - fog, lighting</li>
<li><a href=""http://www.assembla.com/wiki/show/tomahawkengine"" rel=""nofollow noreferrer"">Tomahawk</a> - Pretty well supported engine.</li>
<li><a href=""http://phoenixxna.codeplex.com/"" rel=""nofollow noreferrer"">Phoenix</a> - still in development</li>
</ul>

<p>2D</p>

<ul>
<li><a href=""http://www.flatredball.com/frb/"" rel=""nofollow noreferrer"">Flat Red Ball</a> - 2.5d game engine thats been around since the Managed DirectX days. Very well updated and supported. </li>
<li><a href=""http://jemgine.codeplex.com/"" rel=""nofollow noreferrer"">Jemgine</a> - 2D game engine with level editor, components, visual scripting language</li>
<li><a href=""http://box2dxna.codeplex.com/"" rel=""nofollow noreferrer"">Box2D.XNA</a> - A C# port of the Box2D engine</li>
<li><a href=""http://dengine.codeplex.com/"" rel=""nofollow noreferrer"">DEngine</a> - 2D tile engine with basic editor</li>
</ul>

<p><strong>Commercial game engines</strong></p>

<ul>
<li><a href=""http://www.nullcity.com/Default.aspx?section=Kitae"" rel=""nofollow noreferrer"">Kitae</a> - 2D game engine with tile/level editor, collision detection, sprites, fonts, etc.</li>
<li><a href=""http://www.garagegames.com/products/torque/x/"" rel=""nofollow noreferrer"">TorqueX</a> - <a href=""https://gamedev.stackexchange.com/questions/2934/what-has-your-experience-been-with-torque-products/2950#2950"">(not recommended)</a>

<ul>
<li>2D - TorqueX Game Builder to edit levels from a drag and drop UI. </li>
<li>3D - TorqueX World Builder to build 3D game levels with objects and lighting</li>
</ul></li>
<li><a href=""http://www.visual3d.net/"" rel=""nofollow noreferrer"">Visual3d.net</a> - (Windows only)</li>
</ul>

<p><strong>Specialist</strong></p>

<ul>
<li><a href=""http://www.codeplex.com/mpe"" rel=""nofollow noreferrer"">Mercury Particle Engine</a></li>
<li><a href=""http://dpsf.danskingdom.com/"" rel=""nofollow noreferrer"">Dynamic Particle System Framework</a></li>
<li><a href=""http://simpleai.codeplex.com/"" rel=""nofollow noreferrer"">Simple AI</a> - path finding, path following, behaviours</li>
</ul>

<p><strong>Physics Engines</strong></p>

<p>If you require code that will run on Xbox 360 or Zune then you need a 100% managed engine.</p>

<p>Most of these are free, or are free wrappers around commercial products.</p>

<ul>
<li><a href=""http://www.codeplex.com/FarseerPhysics"" rel=""nofollow noreferrer"">Farseer</a> - 2d only. Source and Silverlight port available </li>
<li><a href=""http://www.codeplex.com/JigLibX"" rel=""nofollow noreferrer"">JigLibX</a> - Source available, port of C++ <a href=""http://www.rowlhouse.co.uk/jiglib/index.html"" rel=""nofollow noreferrer"">JigLib</a>, formerly JiggleX </li>
<li><a href=""http://bulletphysics.com/"" rel=""nofollow noreferrer"">Bullet</a>  

<ul>
<li><a href=""http://www.codeplex.com/xnadevru/Wiki/View.aspx?title=Managed%20Bullet%20Physics%20Library&amp;referringTitle=Home"" rel=""nofollow noreferrer"">BulletX</a>: By XnaDevRu: Supports Xbox360 as well as windows. Updated recently (dec 21 2007). </li>
<li><a href=""http://chriscavanagh.wordpress.com/2007/04/24/xbap-3d-physics-source/"" rel=""nofollow noreferrer"">XBAP</a>: By Chris Cavanagh, buildt on BulletX above. </li>
</ul></li>
<li><a href=""http://www.tamedtornado.com/devblog/?p=58"" rel=""nofollow noreferrer"">Newton</a> </li>
<li><a href=""http://www.codeplex.com/OopsFramework"" rel=""nofollow noreferrer"">Oops! 3D Physics Framework</a> </li>
<li><a href=""http://www.bepu-games.com/BEPUphysics/"" rel=""nofollow noreferrer"">Bepu physics</a> - commercial but free for non commercial use </li>
<li><a href=""http://walaber.com/index.php?action=showitem&amp;id=16"" rel=""nofollow noreferrer"">Jello Physics</a> - soft body physics. Used in <a href=""http://walaber.com/index.php?action=showitem&amp;id=17"" rel=""nofollow noreferrer"">JelloCar</a> and other fun <a href=""http://walaber.com/"" rel=""nofollow noreferrer"">Walaber</a> games. </li>
<li><a href=""http://physics2d.googlepages.com/"" rel=""nofollow noreferrer"">Physics2D.Net</a> - see demo video </li>
<li><a href=""http://henge3d.codeplex.com/"" rel=""nofollow noreferrer"">Henge3D Physics Library</a> - Rigid body physics with constraints and joints</li>
<li><a href=""http://sourceforge.net/projects/xnahavok/"" rel=""nofollow noreferrer"">XnaHavok</a> - C# port of Havok</li>
<li><a href=""http://www.codeplex.com/xengine"" rel=""nofollow noreferrer"">X-Engine</a> - rigid body physics (development stopped)</li>
</ul>

<p>If you are only targetting <strong>windows</strong> then you can use any of these:</p>

<ul>
<li><a href=""http://www.ageia.com/"" rel=""nofollow noreferrer"">PhysX</a> 

<ul>
<li><a href=""http://code.google.com/p/physxdotnet/"" rel=""nofollow noreferrer"">PhysX.NET</a></li>
<li><a href=""http://msdn2.microsoft.com/en-us/robotics/default.aspx"" rel=""nofollow noreferrer"">Wrapper</a> for MS Robotics Studio but check the license. </li>
</ul></li>
<li><a href=""http://ode.org/"" rel=""nofollow noreferrer"">ODE</a> (Open Dyamics Engine) 

<ul>
<li><a href=""http://www.codeplex.com/xnadevru/Wiki/View.aspx?title=XNA%20Physics%20API%20%28XPA%29&amp;referringTitle=Home"" rel=""nofollow noreferrer"">XPA</a> (XNA Physics lib): XnaDevRu has a nice wrapper for, but it's majorly outdated and ODE is rumored to be bad/unstable. There's very little information about it, but the API is pretty friendly. Pretty easy to get up and running with simple collisions (even I made it!), but its hard to find what you need when problems occur, and its updated very slowly.</li>
</ul></li>
<li><a href=""http://www.newtondynamics.com/"" rel=""nofollow noreferrer"">Newton Game Dynamics</a></li>
</ul>
","5253"
"Open Source Engine for RTS","8621","","<p>I must write a cross-platform real-time-strategy game within 2-3 months. I want use C++ and OpenGL and am looking for an engine.</p>

<p>The engine must be open source and work under both Linux and Windows. Preferably it should work with 3ds Max models. I do not know the game engines. Which engine would you recommend?</p>
","<p>I know of three that still seem reasonably actively developed: <a href=""http://springrts.com/"">Spring</a>, <a href=""http://openra.res0l.net/"">OpenRA</a> and <a href=""http://stratagus.sourceforge.net/"">Stratagus</a>. Wikipedia has a <a href=""http://en.wikipedia.org/wiki/List_of_game_engines#Free_and_open_source"">list of open source game engines</a>, some of which may be appropriate for an RTS game (such as <a href=""http://fifengine.net/"">FIFE</a>, which used to bill itself as a Fallout-style engine, but should still be appropriate for RTS games).</p>

<p>Some of these engines may work directly with 3DS Max model files, but that file format (.3ds) is actually pretty archaic, cumbersome, and suboptimal for direct consumption by a game engine, so you may find that the engines instead support some other model format that Max can export to (or supply their own conversion tools).</p>

<p>Also, it's not open source (<s>and does in fact cost money</s> might cost if you need certain features), but <a href=""http://forum.unity3d.com/threads/17634-C-amp-C-style-RTS-Community-Project-Generals"">people have used Unity</a> to make RTS games as well.</p>
","12002"
"What is meant by ""System Programming""?","8605","","<p>I am preparing for an internship as game programmer at a world-renowned game development company. When I searched their website for necessary prerequisites, it showed me this:</p>

<blockquote>
  <h3>Added Advantage</h3>
  
  <ul>
  <li>Knowledge of DirectX/OpenGL.</li>
  <li>Strong command on 3D Maths and Physics.</li>
  <li>Visual Studio IDE for C++ development.</li>
  <li>System Programming and OS concepts.</li>
  </ul>
</blockquote>

<p>What exactly do they mean by system programming and OS concepts?</p>

<p>Should I be studying Windows programming? Or should I be going with Linux programming (meaning they want me to know the important concepts). Or is it something totally different?</p>
","<p>""System programming"" (or ""systems programming"") tends to mean programming done at a lower level of abstraction than (for example) gameplay programming. Gameplay programming is usually about building the actual game mechanics and front-facing features that a user might see, whereas systems programming is more about building the frameworks upon which gameplay programmers work.</p>

<p>This might mean graphics, resource loading and streaming, audio, memory management, file IO, platform abstraction APIs, et cetera. The details vary quite a bit, and because there are no standards for job titles in the games industry there are similarly no standards for the names of programming domains. At one studio, you may find that ""systems programming"" means everything I listed above. At another, you may find that they distinguish ""graphics programming"" as a separate domain and call every other non-gameplay-programming task ""systems programming."" In yet another, they might not use the term at all and just call it ""engine programming.""</p>

<p>Since it's a lower-level domain, and typically involves interfacing more directly with the platform-specific APIs for whatever platforms the game is being built for, having knowledge of those platforms will be helpful, as will having knowledge of the more general domain (e.g., of OS concepts without regard to how specific OS's work, such as what virtual memory is, or how threads work, how IO buffering works, et cetera).</p>
","147529"
"In HLSL pixel shader , why is SV_POSITION different to other semantics?","8596","","<p>In my HLSL pixel shader, SV_POSITION seems to have different values to any other semantic I use. I don't understand why this is. Can you please explain it?</p>

<p>For example, I am using a triangle with the following coordinates:</p>

<pre><code>(0.0f, 0.5f)
(0.5f, -0.5f)
(-0.5f, -0.5f)
</code></pre>

<p>The w and z values are 0 and 1, respectively.</p>

<p>This is the pixel shader.</p>

<pre><code>struct VS_IN
{
    float4 pos : POSITION;
};

struct PS_IN
{
    float4 pos : SV_POSITION;
    float4 k : LOLIMASEMANTIC;
};

PS_IN VS( VS_IN input )
{
    PS_IN output = (PS_IN)0;
    output.pos = input.pos;
    output.k = input.pos;
    return output;
}

float4 PS( PS_IN input ) : SV_Target
{
    // screenshot 1
    return input.pos;

    // screenshot 2
    return input.k;
}

technique10 Render
{
    pass P0
    {
        SetGeometryShader( 0 );
        SetVertexShader( CompileShader( vs_4_0, VS() ) );
        SetPixelShader( CompileShader( ps_4_0, PS() ) );
    }
}
</code></pre>

<p><img src=""https://i.stack.imgur.com/onO8z.png"" alt=""Screenshot 1""></p>

<p><img src=""https://i.stack.imgur.com/x5wFl.png"" alt=""Screenshot 2""></p>

<p>When I use the first statement (result is first screenshot), the one that uses the <code>SV_POSITION</code> semantic, the result is completely unexpected and is yellow, whereas using any other semantic will produce the expected result. Why is this?</p>
","<p>SV_Position gives you the position in screen coordinates, not in a [0,1] range though but basically in pixel coordinates.
The range will correspond to the <code>D3D11_VIEWPORT</code> you set, possibly something along the lines of:</p>

<pre><code>D3D11_VIEWPORT viewport = {0};
viewport.Width = 1280;
viewport.Height = 720;
</code></pre>

<p>So in order to get a [0,1] range again, for the colors, you could do:</p>

<pre><code>return float4(input.pos.r/1280, input.pos.g/720, 0, 1);
</code></pre>

<p><img src=""https://i.stack.imgur.com/2STai.jpg"" alt=""""></p>
","44421"
"Moving ships between two planets along a bezier, missing some equations for acceleration","8593","","<p>OK, I already posted this over at math.stackechange.com but didn't get any answers :(</p>

<p>First of here's a picture of my problem, the description follows afterwards:  </p>

<p><img src=""https://i.stack.imgur.com/hXQea.png"" alt=""alt text""></p>

<p>So I got all the points and values set up.</p>

<p>The ship starts out moving around the left planet <code>P1</code> with <code>S=0.27 Degrees</code> per gametick, when it reaches <code>Point A</code> it starts following the bezier curve till it reaches <code>Point D</code>, then it travels around the right planet <code>P2</code> with <code>S=0.42 Degrees</code> per game tick. The difference in <code>S</code> is so that the travel with the same movement speed around the planets.</p>

<p>So far so good, I got that up and running, now my problem.</p>

<p>When <code>S P1</code> and <code>S P2</code> differ to much, the ship jumps between the two speeds when it reaches it's destination, which looks pretty bad. So I need to accelerate the ship between <code>Point A</code> and <code>Point D</code> from <code>S P1</code> to <code>S P2</code>.</p>

<p>The thing I'm missing are in purple, those are:  </p>

<ul>
<li><p>A way to calculate the ticks it takes the ship to move along the bezier considering the acceleration.</p></li>
<li><p>And a way to find a position on the bezier curve based on T, again considering the acceleration.</p></li>
</ul>

<p>ATM I calculate the length of the bezier by calculating the distance between <code>N</code> of its points. So what I <em>think</em> I need, is a way to scale the <code>T</code> I need to put into my bezier calculation accordingly to the acceleration.</p>
","<p>OK, I've got everything working, it took forever, so I'm going to post my detailed solution here.<br>
<em>Note: All code samples are in JavaScript.</em></p>

<p><strong>So let's break down the problem into the basic parts:</strong>  </p>

<ol>
<li><p>You need to compute the length of, as well as points between <code>0..1</code> on the bezier curve</p></li>
<li><p>You now need to adjust the scaling of your <code>T</code> to accelerate the ship from one speed to another</p></li>
</ol>

<h2><strong>Getting the Bezier right</strong></h2>

<p>Finding some code for drawing a Bezier curve is easy, there are a number of different approaches though, one of them is the <a href=""http://www.cubic.org/docs/bezier.htm"">DeCasteljau Algorithm</a>, but you can also just use the <a href=""http://www.efg2.com/Lab/Graphics/Jean-YvesQueinecBezierCurves.htm"">equation</a> for cubic Bézier curves:  </p>

<pre><code>// Part of a class, a, b, c, d are the four control points of the curve
x: function (t) {
    return ((1 - t) * (1 - t) * (1 - t)) * this.a.x
           + 3 * ((1 - t) * (1 - t)) * t * this.b.x
           + 3 * (1 - t) * (t * t) * this.c.x
           + (t * t * t) * this.d.x;
},

y: function (t) {
    return ((1 - t) * (1 - t) * (1 - t)) * this.a.y
           + 3 * ((1 - t) * (1 - t)) * t * this.b.y
           + 3 * (1 - t) * (t * t) * this.c.y
           + (t * t * t) * this.d.y;
}
</code></pre>

<p>With this, one can now draw a bezier curve by calling <code>x</code> and <code>y</code> with <code>t</code> which ranges from <code>0 to 1</code>, let's take a look:  </p>

<p><img src=""https://i.stack.imgur.com/TljZY.png"" alt=""alt text""></p>

<p>Uh... that's not really an even distribution of the points, is it?<br>
Due to the nature of the Bézier curve, the points on <code>0...1</code> have different <code>arc lenghts</code>, so segments near the beginning and the end, are longer than the ones which are near to the middle of the curve.</p>

<h2><strong>Mapping T evenly on the curve AKA arc-length parameterization</strong></h2>

<p>So what to do? Well in simple terms we need a function to map our <code>T</code> onto the <code>t</code> of the curve, so that our <code>T 0.25</code> results in the <code>t</code> that's at <code>25%</code> of the length of the curve.</p>

<p>How do we do that? Well, we Google... but it turns out that the term isn't that <em>googleable</em>, and at some point you'll hit this <a href=""http://www.geometrictools.com/Documentation/MovingAlongCurveSpecifiedSpeed.pdf"">PDF</a>. Which sure is a great read, but in the case that you've already forgotten all the math stuff you learned back in school(or you just don't like those mathematical symbols) it's pretty useless.</p>

<p>What now? Well go and Google some more(read: 6 hours), and you finally find a <strong>great</strong> article on the topic(including nice pictures! ^_^""):<br>
<a href=""http://www.planetclegg.com/projects/WarpingTextToSplines.html"">http://www.planetclegg.com/projects/WarpingTextToSplines.html</a></p>

<h2><strong>Doing the actual code</strong></h2>

<p>In case you just couldn't resist downloading that PDF's <em>although</em> you'd already lost your mathematical knowledge a long, long, time ago(and you managed to skip the <em>great</em> article link), you might now think: ""God, this will take hundreds of lines of code and tons of CPU""</p>

<p>No, it will not. Because we do what all programmers do, when it comes to math stuff:<br>
<strong>We simply cheat.</strong></p>

<h2><strong>Arc-length parameterization, the lazy way</strong></h2>

<p>Let's face it, we don't need endless precision in our game, do we? So unless you're working at Nasa and planning on sending people the the Mars, you won't need a <code>0.000001 pixel</code> perfect solution.</p>

<p>So how do we map <code>T</code> onto <code>t</code>? It's simple and only consists of 3 steps:  </p>

<ol>
<li><p>Calculate <code>N</code> points on the curve using <code>t</code> and store the <code>arc-length</code>(aka the length of the curve) at that position into an array</p></li>
<li><p>To map <code>T</code> onto <code>t</code>, first multiply <code>T</code> by the total length of the curve to get <code>u</code> and then search the array of lengths for the index of the largest value that's smaller than <code>u</code></p></li>
<li><p>If we had an exact hit, return the array value at that index divided by <code>N</code>, if not interpolate a bit between the point we found and the next one, divide the thing once again by <code>N</code> and return.</p></li>
</ol>

<p>That's all! So now let's take a look at the complete code:  </p>

<pre><code>function Bezier(a, b, c, d) {
    this.a = a;
    this.b = b;
    this.c = c;
    this.d = d;

    this.len = 100;
    this.arcLengths = new Array(this.len + 1);
    this.arcLengths[0] = 0;

    var ox = this.x(0), oy = this.y(0), clen = 0;
    for(var i = 1; i &lt;= this.len; i += 1) {
        var x = this.x(i * 0.05), y = this.y(i * 0.05);
        var dx = ox - x, dy = oy - y;        
        clen += Math.sqrt(dx * dx + dy * dy);
        this.arcLengths[i] = clen;
        ox = x, oy = y;
    }
    this.length = clen;    
}
</code></pre>

<p>This initializes our new curve and computes the <code>arg-lenghts</code>, it also stores the last of the lengths as the <code>total length</code> of the curve, key factor here is <code>this.len</code> which is our <code>N</code>. The higher, the more precise the mapping will be, for a curve of the size in the picture above <code>100 points</code> seem to be enough, if you just need a good length estimate, something like <code>25</code> will already do the job with being only 1 pixel off in our example, but then you will have a less precise mapping which will result in not so even distribution of <code>T</code> when mapped to <code>t</code>.</p>

<pre><code>Bezier.prototype = {
    map: function(u) {
        var targetLength = u * this.arcLengths[this.len];
        var low = 0, high = this.len, index = 0;
        while (low &lt; high) {
            index = low + (((high - low) / 2) | 0);
            if (this.arcLengths[index] &lt; targetLength) {
                low = index + 1;

            } else {
                high = index;
            }
        }
        if (this.arcLengths[index] &gt; targetLength) {
            index--;
        }

        var lengthBefore = this.arcLengths[index];
        if (lengthBefore === targetLength) {
            return index / this.len;

        } else {
            return (index + (targetLength - lengthBefore) / (this.arcLengths[index + 1] - lengthBefore)) / this.len;
        }
    },

    mx: function (u) {
        return this.x(this.map(u));
    },

    my: function (u) {
        return this.y(this.map(u));
    },
</code></pre>

<p>The actual mapping code, first we do a simple <code>binary search</code> on our stored lengths to find the largest length that's smaller then <code>targetLength</code>, then we just return or do the interpolation and return.</p>

<pre><code>    x: function (t) {
        return ((1 - t) * (1 - t) * (1 - t)) * this.a.x
               + 3 * ((1 - t) * (1 - t)) * t * this.b.x
               + 3 * (1 - t) * (t * t) * this.c.x
               + (t * t * t) * this.d.x;
    },

    y: function (t) {
        return ((1 - t) * (1 - t) * (1 - t)) * this.a.y
               + 3 * ((1 - t) * (1 - t)) * t * this.b.y
               + 3 * (1 - t) * (t * t) * this.c.y
               + (t * t * t) * this.d.y;
    }
};
</code></pre>

<p>Again this computes <code>t</code> on the curve.</p>

<h2><strong>Time for results</strong></h2>

<p><img src=""https://i.stack.imgur.com/CfhLZ.png"" alt=""alt text""></p>

<p>By now using <code>mx</code> and <code>my</code> you get an evenly distributed <code>T</code> on the curve :)</p>

<p>Wasn't that hard, was it? Once again, it turns out that a simple(although not perfect solution) will be enough for a game.</p>

<p>In case you want to see the complete code, there's a Gist available:<br>
<a href=""https://gist.github.com/670236"">https://gist.github.com/670236</a></p>

<h2><strong>Finally, accelerating the ships</strong></h2>

<p>So all that's left now is to accelerate the ships along their path, by mapping the position onto <code>T</code> which we then use to find the <code>t</code> on our curve.</p>

<p>First we need two of the <a href=""http://en.wikipedia.org/wiki/Equations_of_motion"">equations of motion</a>, namely <code>ut + 1/2at²</code> and <code>(v - u) / t</code></p>

<p>In actual code that would look like this:  </p>

<pre><code>startSpeed = getStartingSpeedInPixels() // Note: pixels
endSpeed = getFinalSpeedInPixels() // Note: pixels
acceleration = (endSpeed - startSpeed) // since we scale to 0...1 we can leave out the division by 1 here
position = 0.5 * acceleration * t * t + startSpeed * t;
</code></pre>

<p>Then we scale that down to <code>0...1</code> by doing:  </p>

<pre><code>maxPosition = 0.5 * acceleration + startSpeed;
newT = 1 / maxPosition * position;
</code></pre>

<p>And there you go, the ships are now moving smoothly along the path.</p>

<h2><strong>In case it doesn't work...</strong></h2>

<p>When you're reading this, everything works fine and dandy, but I initially had some problems with the acceleration part, when explaining the problem to someone in the gamedev chatroom I found the final error in my thinking.</p>

<p>In case you haven't forgotten already about the picture in the original question, I mention <code>s</code> there, turns out that <code>s</code> is speed in <strong><em>degrees</em></strong>, but the ships move along the path in <strong><em>pixels</em></strong> and I had forgotten about that fact. So what I needed to do in this case was to convert the displacement in degrees into a displacement in pixels, turns out that this is rather easy:  </p>

<pre><code>function rotationToMovement(planetSize, rotationSpeed) {
    var r = shipAngle * Math.PI / 180;
    var rr = (shipAngle + rotationSpeed) * Math.PI / 180;
    var orbit = planetSize + shipOrbit;
    var dx = Math.cos(r) * orbit - Math.cos(rr) * orbit;
    var dy = Math.sin(r) * orbit - Math.sin(rr) * orbit;
    return Math.sqrt(dx * dx + dy * dy);
};
</code></pre>

<p>So and that's all! Thanks for reading ;)</p>
","5427"
"How do PC/Mac games detect piracy?","8591","","<p>I was recently reading an article about clever ways programmers have protected their games from pirates, such as the creators of <a href=""http://www.greenheartgames.com/2013/04/29/what-happens-when-pirates-play-a-game-development-simulator-and-then-go-bankrupt-because-of-piracy/"">Game Dev Tycoon</a>. This made me curious: how do they detect that the copy of the game running is in fact a pirated version on a technical level? The closest answer I was able to find through some research was <a href=""http://earthboundcentral.com/2011/05/earthbounds-copy-protection/"">how SNES cartridges can detect if they're pirated</a>, but that tactic obviously doesn't apply to PCs.</p>
","<p>First thing first: there is no way for a computer to know whether a file is pirated or not. Piracy is a legal/moral term, and as so, it has no meaning on a file, which is only composed of ones and zeroes.</p>

<p>That said, piracy prevention and countermeasures usually focus on finding out whether or not a user has something (usually an object) which can only be obtained if a copy of the game was purchased, and make that difficult to duplicate. There are tons of ways to do this, each one with advantages as well as flaws. I'll mention a few:</p>

<ul>
<li><p>Early games asked users to input a word from the game manual, which you should only get if you bought a game box. A photocopier or a scanner easily defeats this technique though.</p></li>
<li><p>More recently, media checks are more common. The idea is that you require the game CD to be in the drive for the game to run. To implement this, you can for example access critical data files from the CD without which the game cannot run, or simply check for the existence of a file in the CD. This worked pretty well when CDs were difficult to duplicate, but CD copiers, and more recently drive emulators can be used to easily defeat these technique.</p></li>
<li><p>However, CD copies are not perfect, so many other techniques focus on detecting whether the CD is the original pressed CD, or a copy. To implement this, a game can check for <a href=""https://en.wikipedia.org/wiki/Compact_Disc_and_DVD_copy_protection"">non-standard elements</a> that are inserted on the game disc during press time, but cannot be easily and reliably replicated by a CD burner, on a CD-R. Some common ways to do this are:</p>

<ul>
<li><p>Creating dummy ""ghost"" files in the CD during mastering, which are not accessible from the CD filesystem, but do exist, and can be read if you know where to find them. This data is absent on file-by-file disc copies. Copying the entire disc image will copy these files though.</p></li>
<li><p>Another way is to intentionally insert errors in the disc. CDs contain error correction codes. By inserting errors in the data, which can be transparently corrected by a disc reader, the disc will work normally, but the errors won't be copied to the CD-R. By looking for these intentional errors, a game can consider a CD to be an original pressed copy. RAW disc image copies defeat this though.</p></li>
<li><p>Inserting twin sectors, with the same address but different data will yield different results when seeking data forward and backward. Checking for the existence of this is possible, and duplicating a CD with these twin sectors is very difficult.</p></li>
<li><p><a href=""https://en.wikipedia.org/wiki/SecuROM"">Measuring</a> the actual position of the pits in the CD. Once again, duplicating a CD with the pits in the same positions is very difficult.</p></li>
</ul>

<p>However, many CD emulators, like <a href=""https://en.wikipedia.org/wiki/Daemon_Tools"">Daemon Tools</a>, or Alcohol 120% can actually emulate these features. Because of this, many publishers choose to include a CD emulator detection step, and prevent the game from running if an emulator is detected. The implementation of an emulator detector is outside of the scope of this answer though.</p></li>
<li><p>Instead of, or in addition to checking for a physical CD, a game can request the user to input some data, like a <a href=""https://en.wikipedia.org/wiki/Product_key"">product key</a>. Some ways to use product keys are:</p>

<ul>
<li><p>Checking for mathematical features in the key. However, this doesn't prevent key duplication, and if the checking algorithm is discovered or reverse-engineered, a pirate may be able to create new keys at will which will appear to be legitimate to the game. Software that creates keys at will are called ""<a href=""https://en.wikipedia.org/wiki/Keygen"">keygens</a>"".</p></li>
<li><p>Generating a hash based on the user's hardware, send this hash and the product key (usually a combination, called the ""installation key"") to a server owned by the game company, and based on the hash and serial, create an <a href=""https://en.wikipedia.org/wiki/Product_activation"">activation key</a>. Using one-way numeric methods (like modular arithmetic, or some methods with elliptic curves), a game can see if the activation key matches the hash and serial code, and only run if they match. This technique is called ""activation"".</p></li>
</ul>

<p>With activation, a server may refuse to provide activation keys for multiple hardware hashes with the same serial code. Because of this, even if the serial code, and activation key are copied, the activation key won't match and the game won't run on other computers.</p></li>
</ul>

<p>All of these measures are meant to find whether or not the user owns a purchased copy of the game. However, implementing them requires program code that checks for this. It is possible for a pirate to modify the game code to <a href=""https://en.wikipedia.org/wiki/Software_cracking"">disable or bypass the checks</a> instead of attacking the copy protection mechanisms themselves. The act of modifying game binaries to remove anti-piracy checks is called ""cracking"".</p>

<p>Cracking can simply consist of disassembling the game executable, finding the place where the relevant checks are made, modifying it to disable the checks, or ignore the results, and reassembling it. Some ways to counter cracking are:</p>

<ul>
<li><p>Checking the binary with some hash. However, there must be a program that checks the hash, which can in turn be cracked as well.</p></li>
<li><p>Encrypting the program, or simply the check routine, and decrypting it in runtime. This makes disassembly more difficult, as it involves one or more additional decryption steps. IF the decryption key is included in the program (as it must be, because without it, the game cannot be decrypted), then the pirate can reverse engineer the decryption, find the routine, and crack the copy protection.</p>

<p>Because of this, as a game publisher, you want to make the key as hard to find as possible, and optionally make the decryption algorithm hard to understand. Some ways to make the key hard to find are:</p>

<ul>
<li><p>Obscure it by creating it in strange ways. This simply slows the cracking process.</p></li>
<li><p>Create per-machine master keys similar to the serial protection mentioned above.</p></li>
</ul>

<p>However, regardless of the method you use to create your keys, the keys themselves will be in memory while decryption is in progress. Memory inspectors, debuggers and emulators can help a pirate find and copy the key while it is in memory. Memory peeking can be attacked in several ways:</p>

<ul>
<li><p>Having a privileged service that detects memory accesses in the specified region, and redirect the addressing somewhere else. As this requires ring 0 access, and programs that do this are more commonly used for <a href=""https://en.wikipedia.org/wiki/Rootkit"">not-so-legitimate purposes</a>, antivirus software usually block them. (this is why many games and other software ask to turn off virus protection when running). Writing software that correctly does this is <em>extremely</em> difficult, and can easily compromise the stability and security of the host OS. The <a href=""https://en.wikipedia.org/wiki/2005_Sony_BMG_CD_copy_protection_scandal"">XCP scandal</a> is a good example of an implementation of this method gone wrong.</p></li>
<li><p>Modern hardware and operating systems provide some tools, like <a href=""https://en.wikipedia.org/wiki/Trusted_Computing#Memory_curtaining"">memory curtains</a>, <a href=""https://en.wikipedia.org/wiki/Protected_Media_Path"">secure media paths</a> and <a href=""https://en.wikipedia.org/wiki/Trusted_Platform_Module"">TP modules</a>, to make it easier to make a program that decrypts data, while being resistant to memory inspection.</p></li>
</ul></li>
</ul>

<p>There are many many more techniques to attack piracy, ranging from the trivial to the esoteric. Unfortunately, it is possible for all of these techniques to fail to recognize a genuine copy, and it's usually the more aggressive techniques that have higher false positive ratios.</p>

<p>As a game publisher, you usually want to choose a set of techniques whose cost of implementation, expected cracking time, and false positive ratio are in line with your expectations.</p>

<p>It is a common misconception that piracy protection is meant to be completely unbreakable. Most game sales happen in the first few months after release, so a piracy protection scheme is usually considered effective if breaking it consumes enough time for the game publisher to collect a large amount of profits before it gets broken.</p>

<p>Regarding Game Dev Tycoon, they did not use any anti-piracy technologies. They simply created a ""broken"" build, and distributed it over BitTorrent, as is stated in the beginning of the article you mentioned.</p>
","63040"
"Determine corners of a specific plane in the frustum","8583","","<p>I'm working on a game with a 2D view in a 3D world. It's a kind of shoot'em up. I've a spaceship at the center of the screen and i want that ennemies appear at the borders of my window. Now i don't know how to determine positions of the borders of the window. </p>

<p>For example, my camera is at (0,0,0) and looking forward (0,0,1). I set my spaceship at (0,0,50). I also know the near plane (1) and the far plane(1000). I think i'd have to find the 4 corners of the plane in the frustum whose z position is 50, and with these corner i can determine borders. But i don't know how to determine x and y. </p>
","<p><em>Disclaimer:</em> This solution really is simplified for your particular problem, because your camera is looking straight down the Z axis of the world's coordinate system. Also, the center point at 50 units away is already given as (0, 0, 50). If your camera's viewing direction was an arbitrary vector, there would be more multiplications involving the distance with a cross product of the viewing vector and the camera's Up vector.</p>

<p>Determining the borders of a plane at a given distance is dependent on the FOV angle in which the view is projected. Usually, the FOV angle is measured in the Y axis for rectangular viewports. </p>

<p>For any given distance Z from the camera, the shortest distance D from the center point of a plane perpendicular to the viewing vector at Z to one of its borders above or below the center (really, the intersection of the plane and frustum) is <code>D = tan(FOV / 2) * Z</code> . Add and subtract D from the center point's Y component to get the maximum and minimum Y extents.</p>

<p>To get the minimum and maximum X extents, add and subtract <code>D * aspect_ratio</code>.</p>

<p>Now getting the location of the plane's corners is simply plugging in the mix/max X and Y in its four possible combinations along with the Z distance.</p>
","19801"
"How could I constrain player movement to the surface of a 3D object using Unity?","8574","","<p>I'm trying to create an effect similar to that of Mario Galaxy or Geometry Wars 3 where as the player walks around the ""planet"" gravity seems to adjust and they don't fall off the edge of the object as they would if the gravity was fixed in a single direction.</p>

<p><a href=""http://images.gameskinny.com/gameskinny/a8079d12afbcf6957b0cb51857990004.jpg"" rel=""nofollow noreferrer"">http://images.gameskinny.com/gameskinny/a8079d12afbcf6957b0cb51857990004.jpg</a></p>

<p><img src=""https://cdn1.tnwcdn.com/wp-content/blogs.dir/1/files/2014/11/geowars2.gif"" alt=""Geometry Wars 3""></p>

<p>I managed to implement something close to what I'm looking for using an approach where the object that should have the gravity attracts other rigid bodies towards it, but by using the built in physics engine for Unity, applying movement with AddForce and the likes, I just couldn't get the movement to feel right. I couldn't get the player to move fast enough without the player starting to fly off the surface of the object and I couldn't find a good balance of applied force and gravity to accommodate for this. My current implementation is an adaptation of what was found <a href=""http://forum.unity3d.com/threads/faux-gravity-making-my-brain-spin-help.8873/"" rel=""nofollow noreferrer"">here</a></p>

<p>I feel like the solution would probably still use physics to get the player grounded onto the object if they were to leave the surface, but once the player has been grounded there would be a way to snap the player to the surface and turn off physics and control the player through other means but I'm really not sure.</p>

<p>What kind of approach should I take to snap the player to the surface of objects? Note that the solution should work in 3D space (as opposed to 2D) and should be able to be implemented using the free version of Unity.</p>
","<p>I managed to accomplish what I needed, primarily with the assistance of <a href=""http://www.asteroidbase.com/devlog/7-learning-how-to-walk/"">this blog post</a> for the surface snapping piece of the puzzle and came up with my own ideas for player movement and camera.</p>

<h2>Snapping Player to the Surface of an Object</h2>

<p>The basic setup consists of a large sphere (the world) and a smaller sphere (the player) both with sphere colliders attached to them. </p>

<p>The bulk of the work being done was in the following two methods:</p>

<pre><code>private void UpdatePlayerTransform(Vector3 movementDirection)
{                
    RaycastHit hitInfo;

    if (GetRaycastDownAtNewPosition(movementDirection, out hitInfo))
    {
        Quaternion targetRotation = Quaternion.FromToRotation(Vector3.up, hitInfo.normal);
        Quaternion finalRotation = Quaternion.RotateTowards(transform.rotation, targetRotation, float.PositiveInfinity);

        transform.rotation = finalRotation;
        transform.position = hitInfo.point + hitInfo.normal * .5f;
    }
}

private bool GetRaycastDownAtNewPosition(Vector3 movementDirection, out RaycastHit hitInfo)
{
    Vector3 newPosition = transform.position;
    Ray ray = new Ray(transform.position + movementDirection * Speed, -transform.up);        

    if (Physics.Raycast(ray, out hitInfo, float.PositiveInfinity, WorldLayerMask))
    {
        return true;
    }

    return false;
}
</code></pre>

<p>The <code>Vector3 movementDirection</code> parameter is just as it sounds, the direction we are going to be moving our player in this frame, and calculating that vector, while ended up relatively simple in this example, was a bit tricky for me to figure out at first. More on that later, but just keep in mind that it's a normalized vector in the direction the player is moving this frame.</p>

<p>Stepping through, the first thing we do is check if a ray, originating at the hypothetical future position directed towards the players down vector (-transform.up) hits the world using WorldLayerMask which is a public LayerMask property of the script. If you want more complex collisions or multiple layers you will have to build your own layer mask. If the raycast successfully hits something the hitInfo is used to retrieve the normal and hit point to calculate the new position and rotation of the player which should be right on the object. Offsetting the player's position may be required depending on size and origin of the player object in question.</p>

<p>Finally, this has really only been tested and likely only works well on simple objects such as spheres. As the blog post I based my solution off of suggests, you will likely want to perform multiple raycasts and average them for your position and rotation to get a much nicer transition when moving over more complex terrain. There may also be other pitfalls I've not thought of at this point.</p>

<h2>Camera and Movement</h2>

<p>Once the player was sticking to the surface of the object the next task to tackle was movement. I had originally started out with movement relative to the player but I started running into issues at the poles of the sphere where directions suddenly changed making my player rapidly change direction over and over not letting me ever pass the poles. What I wound up doing was making my players movement relative to the camera.</p>

<p>What worked well for my needs was to have a camera that strictly followed the player based solely on the players position. As a result, even though the camera was technically rotating, pressing up always moved the player towards the top of the screen, down towards the bottom, and so on with left and right.</p>

<p>To do this, the following was executed on the camera where the target object was the player:</p>

<pre><code>private void FixedUpdate()
{
    // Calculate and set camera position
    Vector3 desiredPosition = this.target.TransformPoint(0, this.height, -this.distance);
    this.transform.position = Vector3.Lerp(this.transform.position, desiredPosition, Time.deltaTime * this.damping);

    // Calculate and set camera rotation
    Quaternion desiredRotation = Quaternion.LookRotation(this.target.position - this.transform.position, this.target.up);
    this.transform.rotation = Quaternion.Slerp(this.transform.rotation, desiredRotation, Time.deltaTime * this.rotationDamping);
}
</code></pre>

<p>Finally, to move the player, we leveraged the transform of the main camera so that with our controls up moves up, down moves down, etc. And it is here we call UpdatePlayerTransform which will get our position snapped to the world object.</p>

<pre><code>void Update () 
{        
    Vector3 movementDirection = Vector3.zero;
    if (Input.GetAxisRaw(""Vertical"") &gt; 0)
    {
        movementDirection += cameraTransform.up;
    }
    else if (Input.GetAxisRaw(""Vertical"") &lt; 0)
    {
        movementDirection += -cameraTransform.up;
    }

    if (Input.GetAxisRaw(""Horizontal"") &gt; 0)
    {
        movementDirection += cameraTransform.right;
    }
    else if (Input.GetAxisRaw(""Horizontal"") &lt; 0)
    {
        movementDirection += -cameraTransform.right;
    }

    movementDirection.Normalize();

    UpdatePlayerTransform(movementDirection);
}
</code></pre>

<p>To implement a more interesting camera but the controls to be about the same as what we have here you could easily implement a camera that isn't rendered or just another dummy object to base movement off of and then use the more interesting camera to render what you want the game to look like. This will allow nice camera transitions as you go around objects without breaking the controls.</p>
","90163"
"Unity 5 disabling a script","8568","","<p>I'm using Unity 5 and want to disable a script called Unit based on whether the instance is a client or a server. I have tried using:</p>

<pre><code>GetComponent(""Unit"").enabled = false;
</code></pre>

<p>However I get hit with this error: </p>

<blockquote>
  <p><code>Assets/Scripts/DisablingUnitScriptIfPlayer.cs(14,46): error CS1061: Type UnityEngine.Component' does not contain a definition for 'enabled' and no extension method 'enabled' of type 'UnityEngine.Component' could be found (are you missing a using directive or an assembly reference?)</code></p>
</blockquote>

<p>Looking at some tutorials, this worked in previous versions, but I can't find how to make this work for Unity 5. What do I need to change?</p>
","<p>Please check solution described <a href=""http://answers.unity3d.com/questions/923325/disabling-unknown-script-components-in-unity-5.html"" rel=""nofollow"">here</a></p>

<p>For your case it would be :</p>

<pre><code>(GetComponent(""Unit"") as MonoBehaviour).enabled = false;
</code></pre>

<p>Warning this will crash if the ""Unit"" component is not deriving from MonoBehavior (if this is a script you wrote, it should ...)</p>

<h1>EDIT:</h1>

<p>The solution proposed by Lohoris in comments is much cleaner and faster, and actuall the official way to do it fom the <a href=""http://docs.unity3d.com/ScriptReference/GameObject.GetComponent.html"" rel=""nofollow"">doc</a>: </p>

<p><em>It is better to use GetComponent with a Type instead of a string for performance reasons. Sometimes you might not be able to get to the type however, for example when trying to access a C# script from Javascript. In that case you can simply access the component by name instead of type.</em></p>

<p>So the good code is :</p>

<pre><code>GetComponent&lt;Unit&gt;().enabled = false;
</code></pre>

<p>Which will still of course crash if your object has no Unit component.</p>
","105785"
"How can I generate signed distance fields (2D) in real time, fast?","8562","","<p>In a <a href=""https://gamedev.stackexchange.com/questions/26786/fast-pixelshader-2d-raytracing/26787#26787"">previous question</a>, it was suggested that signed distance fields can be precomputed, loaded at runtime and then used from there.</p>

<p>For reasons I will explain at the end of this question (for people interested), I need to create the distance fields in real time.</p>

<p>There are some papers out there for different methods which are supposed to be viable in real-time environments, such as methods for Chamfer distance transforms and Voronoi diagram-approximation based transforms (as suggested in <a href=""http://fumufumu.q-games.com/gdc2010/shooterGDC.pdf"" rel=""nofollow noreferrer"">this presentation by the Pixeljunk Shooter dev guy</a>), but I (and thus can be assumed a lot of other people) have a very hard time actually putting them to use, since they're usually long, largely bloated with math and not very algorithmic in their explanation.</p>

<p>What algorithm would you suggest for creating the distance fields in real-time (favourably on the GPU) especially considering the resulting quality of the distance fields? </p>

<p>Since I'm looking for an actual explanation/tutorial as opposed to a link to just another paper or slide, this question will receive a bounty once it's eligible for one :-).</p>

<p>Here's why I need to do it in real time:</p>

<blockquote>
  <p>If you have to precompute these SDFs for large 2D environments (think of a large Terraria-like map), this would mean that you're accepting a rather large overhead in storage space (and map-generation time) in favour of implementing a more complicated algorithm that is fast enough for real time SDF generation.</p>
  
  <p>For example, a relatively small map with 1000*256 (width*height) with a tile size of 10*10 pixels and thus total dimensions of 10000*2560 pixels would already cost you around 2 megabytes of size, if you choose a relatively small SDF resolution of 128x128, assuming that you're storing only the distance values from 0 to 255.</p>
  
  <p>Obviously, this can quickly become too much and is an overhead that I don't want to have.</p>
</blockquote>

<p>There's something else:</p>

<blockquote>
  <p>SDFs can be used for many things (like collision detection), and some useful applications are potentially not even discovered yet. I think a lot of people are going to look for these things in the future, and if we get a comprehensive answer in here, I think we're going to help a lot of people.</p>
</blockquote>
","<p>Catalin Zima explains how to achieve dynamic 2D shadows in <a href=""http://www.catalinzima.com/2010/07/my-technique-for-the-shader-based-dynamic-2d-shadows/"" rel=""nofollow"">his article</a> - and he does use a signed distance field (from what I can tell that is just a fancy name for a shadow buffer in this context). His method does need a GPU, and his implementation as-is isn't the best (his dropped below 60Hz at about 20 lights on my machine, mine got about 500 lights); which is to be expected as he has favoured clarity of code over speed.</p>

<p><strong>Implementation</strong></p>

<p>Exactly as implemented by him:</p>

<ol>
<li>Render all shadow casters into a texture.</li>
<li>Calculate the distance to the centre of the light for each pixel, and assign that value to the RGB of opaque pixels.</li>
<li>Distort the image so that it represents how a 3D camera would have seen those pixels.</li>
<li>Squash the image into a 2xN sized image using the unusual resize described in his article (a plain resize won't work).</li>
<li>The 2xN image is now your signed distance field for all four quadrants of the light (remember that one quadrant is basically a single camera frustum at 90 degrees).</li>
<li>Render the lightmap.</li>
<li>Blur the lightmap (based on the distance from the light) so that you get soft shadows.</li>
</ol>

<p>My final implementation was (each step being a single shader):</p>

<ol>
<li>Do (1).</li>
<li>Do <a href=""https://gist.github.com/2384073"" rel=""nofollow"">(2) and (3)</a>.</li>
<li>Do (4). His implementation is really slow: if you can try and use GPGPU for this. I couldn't use GPGPU (XNA) so what I did was:
<ul>
<li>Set up a mesh where the first N/2 columns were represents by N/2 quads with the EXACT same position (covering the first column of the final buffer) but differing texture co-ordinates (same thing for the second N/2 columns)</li>
<li>Turn off depth-testing on the GPU.</li>
<li>Use the MIN pixel blending function.</li>
</ul></li>
<li>Do (6) and (7).</li>
</ol>

<p>It's quite ingenious: it's basically a direct translation of how shadows are handled in 3D into 2D.</p>

<p><strong>Pitfalls</strong></p>

<p>The main pitfall is that some objects shouldn't be shadowed: in my example I was writing a Liero (real-time worms) clone and hence didn't want, for example, the players' worms to be shadowed (at least the one on each player's screen). All I did for these 'special' objects was redraw them as a last step. The irony was that most objects were not shadowed (worms, landscape foreground) so there is an overdraw issue here.</p>
","27254"
"2D Platformer AABB collision problems","8560","","<p><img src=""https://i.stack.imgur.com/OZZp1.gif"" alt=""http://dl.dropbox.com/u/3724424/Programming/Gifs/game6.gif""></p>

<p>I have a problem with AABB collision resolution.</p>

<hr>

<p>I resolve AABB intersection by resolving the X axis first, then the Y axis. 
This is done to prevent this bug: <a href=""https://i.stack.imgur.com/NLg4j.png"" rel=""nofollow noreferrer"">http://i.stack.imgur.com/NLg4j.png</a></p>

<hr>

<p>The current method works fine when an object moves into the player and the player has to be pushed horizontally. As you can see in the .gif, the horizontal spikes push the player correctly.</p>

<hr>

<p>When the vertical spikes move into the player, however, the X axis is still resolved first. This makes ""using the spikes as a lift"" impossible. </p>

<p>When the player moves into the vertical spikes (affected by gravity, falls into them), he's pushed on the Y axis, because there was no overlap on the X axis to begin with.</p>

<hr>

<p>Something I tried was the method described in the first answer of this link: <a href=""https://gamedev.stackexchange.com/questions/13774/2d-rectangular-object-collision-detect-direction"">2D rectangular object collision detection</a></p>

<p>However the spikes and moving objects move by having their position changed, not velocity, and I don't calculate their next predicted position until their Update() method is called. 
Needless to say this solution didn't work either. :(</p>

<hr>

<p>I need to solve AABB collision in a way that both of the cases described above work as intended.</p>

<p>This is my current collision source code: <a href=""http://pastebin.com/MiCi3nA1"" rel=""nofollow noreferrer"">http://pastebin.com/MiCi3nA1</a></p>

<p>I'd be really grateful if someone could look into this, since this bug has been present in the engine all the way back from the beginning, and I've been struggling to find a good solution, without any success. This is seriously making me spend nights looking at the collision code and preventing me from getting to the ""fun part"" and coding the game logic :(</p>

<hr>

<p>I tried implementing the same collision system as in the XNA AppHub platformer demo (by copy-pasting most of the stuff). However the ""jumping"" bug occurs in my game, while it doesn't occur in the AppHub demo. 
[ jumping bug: <a href=""https://i.stack.imgur.com/NLg4j.png"" rel=""nofollow noreferrer"">http://i.stack.imgur.com/NLg4j.png</a> ]</p>

<p>To jump I check if the player is ""onGround"", then add -5 to Velocity.Y.</p>

<p>Since the player's Velocity.X is higher than Velocity.Y (refer to the fourth panel in the diagram), onGround is set to true when it shouldn't be, and thus lets the player jump in mid-air.</p>

<p>I believe this doesn't happen in the AppHub demo because the player's Velocity.X will never be higher than Velocity.Y, but I may be mistaken.</p>

<p>I solved this before by resolving on the X axis first, then on the Y axis. But that screws up the collision with the spikes as I stated above.</p>
","<p>OK, I figured out why the <a href=""http://create.msdn.com/en-US/education/catalog/sample/platformer"" rel=""nofollow noreferrer"">XNA AppHub platformer demo</a> doesn't have the ""jumping"" bug: <strong>the demo tests the collision tiles from <em>top to bottom</em></strong>. When up against a ""wall"" the player may be overlapping multiple tiles. The resolution order is important because resolving one collision may also resolve other collisions (but in a different direction). The <code>onGround</code> property is only set when the collision is resolved by pushing the player up on the y-axis. This resolution will not occur if the previous resolutions pushed the player down and/or horizontally.
<br><br></p>

<p>I was able to reproduce the ""jumping"" bug in the XNA demo by changing this line:</p>

<pre><code>for (int y = topTile; y &lt;= bottomTile; ++y)
</code></pre>

<p>to this:</p>

<pre><code>for (int y = bottomTile; y &gt;= topTile; --y)
</code></pre>

<p>(I also tweaked some of the physics-related constants, but this should not matter.)
<br><br></p>

<p><strong>Perhaps sorting <code>bodiesToCheck</code> on the y-axis before resolving the the collisions in your game will fix the ""jumping"" bug.</strong> I suggest resolving the collision on the ""shallow"" axis of penetration, as the XNA demo does and <a href=""https://gamedev.stackexchange.com/questions/14486/2d-platformer-aabb-collision-problems/14491#14491"">Trevor suggests</a>. Also note the XNA demo player is twice as tall as the collide-able tiles, making the multiple collision case more likely. </p>
","14671"
"How To Smoothly Animate From One Camera Position To Another","8556","","<p>The Question is basically self explanatory. I have a scene with many cameras and I'd like to smoothly switch from one to another. I am not looking for a cross fade effect but more to a camera moving and rotating the view in order to reach the next camera point of view and so on. To this end I have tried the following code:</p>

<pre><code>    firstCamera.transform.position.x = Mathf.Lerp(firstCamera.transform.position.x, nextCamer.transform.position.x,Time.deltaTime*smooth);
    firstCamera.transform.position.y = Mathf.Lerp(firstCamera.transform.position.y, nextCamera.transform.position.y,Time.deltaTime*smooth);
    firstCamera.transform.position.z = Mathf.Lerp(firstCamera.transform.position.z, nextCamera.transform.position.z,Time.deltaTime*smooth);

    firstCamera.transform.rotation.x = Mathf.Lerp(firstCamera.transform.rotation.x, nextCamera.transform.rotation.x,Time.deltaTime*smooth);
    firstCamera.transform.rotation.z = Mathf.Lerp(firstCamera.transform.rotation.z, nextCamera.transform.rotation.z,Time.deltaTime*smooth);
    firstCamera.transform.rotation.y = Mathf.Lerp(firstCamera.transform.rotation.y, nextCamera.transform.rotation.y,Time.deltaTime*smooth);
</code></pre>

<p>But the result is actually not that good. </p>

<p>Thank you all, I fixed it this way</p>

<pre><code> var pos:Vector3 = firstCamera.transform.position;
    var rot:Quaternion = firstCamera.transform.rotation;
    firstCamera.transform.position = Vector3.Lerp(pos, nextCamera.transform.position,Time.deltaTime*smooth);
    firstCamera.transform.rotation = Quaternion.Lerp(rot, nextCamera.transform.rotation,Time.deltaTime*smooth);
</code></pre>
","<p>Consider using Quaternion.Lerp or <a href=""http://unity3d.com/support/documentation/ScriptReference/Quaternion.Slerp.html"">Quaternion.Slerp</a> instead of lerping the euler angles directly.</p>
","30685"
"How do I prevent flickering when drawing to a JPanel?","8542","","<p>So I have a JFrame holding a JPanel, to which I'm drawing at about 60 FPS. I've been told that ""Swing is double buffered by default"", but, nevertheless I'm getting massive flickering. At first, I tried modifying the Graphics object from <code>JPanel.getGraphics()</code>, but was not surprised when it flickered (to black, the background colour of the game so far), as I assumed that it was redrawing when I blanked the screen. However, then I overrode <code>paintComponent()</code>, passing the Graphics to all objects to draw with, and made it call the super version, which I assumed would solve it, but no difference.</p>

<p>I'm still getting the Graphics object from the same place, i.e. <code>JPanel.getGraphics()</code>, because <code>paintComponent()</code> needs a Graphics argument. Should I be getting it from some other place? If not, what else could be causing the problem?</p>
","<p>Whoops. Looks like I should have been calling <code>repaint()</code>, not calling <code>paintComponent(Graphics)</code> directly. <code>repaint()</code> calls that as part of the double buffering process, so it shouldn't be called by hand if you want to avoid flickering.</p>
","18703"
"How can I convert screen coordinatess to world coordinates in OpenTK?","8537","","<p>I'm making a windows forms application with opengl view. I need to get the mouse coords converted to the opengl world coords. Well, my Y coord gets converted wrong. It's hard to explain, so here is the video:
<a href=""http://tinypic.com/r/23sal8k/6"" rel=""nofollow"">http://tinypic.com/r/23sal8k/6</a>. I'm constantly pressing left mouse button and the red dot should be where the mouse is(but it isn't). Here is the code:</p>

<pre><code>    private void glview_MouseDown(object sender, System.Windows.Forms.MouseEventArgs e)
    {
        if (e.Button == MouseButtons.Left)
        {
            Point worldCoords = convertScreenToWorldCoords(e.X, e.Y);
            shitx = worldCoords.X;
            shity = worldCoords.Y;
        }
    }


    // functions:
    public static Point convertScreenToWorldCoords(int x, int y)
    {
        int[] viewport = new int[4];
        Matrix4 modelViewMatrix, projectionMatrix;
        GL.GetFloat(GetPName.ModelviewMatrix, out modelViewMatrix);
        GL.GetFloat(GetPName.ProjectionMatrix, out projectionMatrix);
        GL.GetInteger(GetPName.Viewport, viewport);
        Vector2 mouse;
        mouse.X = x;
        mouse.Y = viewport[3] - y;
        Vector4 vector = UnProject(ref projectionMatrix, modelViewMatrix, new Size(viewport[2], viewport[3]), mouse);
        Point coords = new Point((int)vector.X, (int)vector.Y);
        return coords;
    }
    public static Vector4 UnProject(ref Matrix4 projection, Matrix4 view, Size viewport, Vector2 mouse)
    {
        Vector4 vec;

        vec.X = 2.0f * mouse.X / (float)viewport.Width - 1;
        vec.Y = -(2.0f * mouse.Y / (float)viewport.Height - 1);
        vec.Z = 0;
        vec.W = 1.0f;

        Matrix4 viewInv = Matrix4.Invert(view);
        Matrix4 projInv = Matrix4.Invert(projection);

        Vector4.Transform(ref vec, ref projInv, out vec);
        Vector4.Transform(ref vec, ref viewInv, out vec);

        if (vec.W &gt; float.Epsilon || vec.W &lt; float.Epsilon)
        {
            vec.X /= vec.W;
            vec.Y /= vec.W;
            vec.Z /= vec.W;
        }

        return vec;
    }
</code></pre>
","<p>Finally, I got this fixed. I just changed</p>

<pre><code>mouse.Y = viewport[3] - y;
</code></pre>

<p>to</p>

<pre><code>mouse.Y = y + (ClientRectangle.Height - glview.Size.Height);
</code></pre>

<p>still not very accurate but not very bad.</p>
","52975"
"Rotate sphere in Javascript / three.js while moving along x/z plane","8534","","<p>I have a sphere/ball in three.js which I want to ""roll"" around on the x/z plane. For the z axis I could simply do this no matter what the current x and y rotation is:</p>

<pre><code>sphere.roll_z = function(distance) {
      sphere.position.z += distance;
      sphere.rotation.x += distance &gt; 0 ? 0.05 : -0.05;
    }
</code></pre>

<p>But how can I roll it along the x axis? And how could I <em>properly</em> do the roll_z? I've found a lot about quaternion and matrices, but I can't figure out how to use them properly to achieve my (rather simple) goal.</p>

<p>I'm aware that I have to update multiple rotations and that I have to calculate how far to rotate the sphere to match the distance, but the ""how"" is the question. It's probably just lack of mathematical skills which I should train, but a working example/short explanation would help a lot to start with.</p>

<p>Here is an example of how the rotation goes wrong (WASD movement): <a href=""http://js.blockheaven.net/simple.html"" rel=""nofollow"">http://js.blockheaven.net/simple.html</a></p>
","<p>After searching arround for hours, digging through three.js code and commits I found out which code snippets do what I was intending to do and how to make them run with the current three.js version (documentation and all stackexchange answers are outdated).</p>

<pre><code>// Rotate an object around an arbitrary axis in world space
var rotWorldMatrix;
function rotateAroundWorldAxis(object, axis, radians) {
  rotWorldMatrix = new THREE.Matrix4();
  rotWorldMatrix.makeRotationAxis(axis.normalize(), radians);
  rotWorldMatrix.multiplySelf(object.matrix);
  object.matrix = rotWorldMatrix;
  object.rotation.setEulerFromRotationMatrix(object.matrix);
}
</code></pre>

<p>Original by Cory Gross found at: <a href=""https://stackoverflow.com/questions/11060734/how-to-rotate-a-3d-object-on-axis-three-js?rq=1"">https://stackoverflow.com/questions/11060734/how-to-rotate-a-3d-object-on-axis-three-js?rq=1</a> (but getRotationFromMatrix is outdated).</p>

<p>This method rotates the object based on world axes aka rolling a ball on the floor while the camera is fixed. To use this, it needs to know which axe (x, y, z) of the object it should rotate:</p>

<pre><code>var xAxis = new THREE.Vector3(1, 0, 0);
var yAxis = new THREE.Vector3(0, 1, 0);
var zAxis = new THREE.Vector3(0, 0, 1);
</code></pre>

<p>Now, because I want to move it by a certain distance of pixels, to calculate the angle to rotate it:</p>

<pre><code>var angle = distance / (2 * Math.PI * object.boundRadius) * Math.PI;
</code></pre>

<p>And there is my roll_z function:</p>

<pre><code>sphere.roll_z = function(distance) {
  this.position.z += distance;

  var xAxis = new THREE.Vector3(1, 0, 0);
  var angle = distance / (2 * Math.PI * this.boundRadius) * Math.PI;
  rotateAroundWorldAxis(this, xAxis, angle);
}
</code></pre>

<p>Hope this might help others trying to achieve the same thing from going crazy like I was.</p>
","37410"
"What is the difference between an orthographic and oblique projection?","8531","","<p>They both seem to be a parallel projection. I know that the angles of axes of viewing differ based on the type of orthographic projection (eg, an isometric projection has equal angles for all the axes).</p>

<p>But what sets the oblique projection apart from the orthographical projection?</p>

<p><a href=""http://upload.wikimedia.org/wikipedia/commons/4/41/Graphical_projection_comparison.png"" rel=""nofollow"">I found this image on Wikipedia</a> and I don't see what sets the two oblique examples apart from the dimetric example.</p>
","<p>They're both similar, in that they are both parallel projections (lines that are parallel in the source are parallel in the projection). In a parallel projection of <code>(x, y, z)</code> onto the <code>xy</code> plane becomes <code>(x + az, y + bz, 0)</code>. When <code>a</code> and <code>b</code> are equal, the projection is orthographic; otherwise the projection is oblique.</p>

<p>Another way to look at it is that in an orthographic projection, the projector lines intersect the plane being projected on to at a perpendicular angle (thus, they are <em>orthogonal</em>, thus the name of the projection), whereas in an oblique projection those lines form oblique angles (non-right angles) with the projection plane.</p>
","95615"
"what is the simplest 3d software for unity?","8527","","<p>Ive heard a lot about Daz studio, Poser, Maya, K-3d, Anim8or, Blender, and all the rest.</p>

<p>My question is which one is the best choice in terms of simplicity and quality. price is not an issue really. I'm programming games in java for android mobile devices at the moment but i will eventually move onto larger platforms. I would like to utilize unity3d for the game programming itself and utilize a 3d modeling software just to create the game objects. </p>

<p>I just need to know the best one to get started with from scratch or should i use a combination of multiple ones? Any insight for this would be great, thanks!</p>
","<h1>TL;DR</h1>

<p>In short.. <a href=""http://www.blender.org/"">Get Blender!</a> Since you're a beginner it's not worth pouring k's into a software you have no idea how to fully utilize.</p>

<h1>Simplicity explained</h1>

<p>Well, simplicity is a relative term. For one Blender will be simple, for the other guy Maya. But in the end it depends on how much you use the tool. For example, if you start with Blender, as time passes you'll get better with it, developing it into a habit, and therefore, widening the margin to transition into Maya freely.</p>

<h1>It's the format that matters</h1>

<p>Almost any 3D software will do, the only difference is in how you export your model and whether Unity3D supports it.</p>

<p>For sure, the de-facto standard for some time has been <a href=""http://en.wikipedia.org/wiki/FBX"">Autodesk's FBX</a>, hence most developers use Autodesk software. And, yes, Unity supports it, plus it's recommended to use FBX.</p>

<p>Then there is <a href=""http://en.wikipedia.org/wiki/COLLADA"">COLLADA</a>. <a href=""http://answers.unity3d.com/questions/13553/does-unity-26-support-collada.html"">Rumors say</a> that Unity3D doesn't have a full support for <a href=""http://en.wikipedia.org/wiki/COLLADA"">COLLADA</a>.</p>

<p>But, yes, Unity has wide support for importing not so universal formats- *.3ds, *.max to name a few.</p>

<p>Haven't been working with Unity lately and haven't used other software than 3DS Max, therefore I cannot precisely say what formats Unity supports. But I've tried *.3ds and *.max- more or less, but they work.</p>

<h3>Urgent:</h3>

<blockquote>
  <p>Formats like COLLADA and FBX are meant to be used by default.
  Developers have put a lot of effort in these formats, meaning, that
  they will not only export/import with mesh, but with animations, that
  you can bake in and all the other stuff the actual model will posses.</p>
  
  <p>Plus, they are software independent. You can work with Blender, your
  friend with 3DS Max and an outsourced modeler with Maya or XSI and FBX
  will provide almost 100% support for every tool.</p>
  
  <p>It's strongly encouraged to use these universal formats.</p>
</blockquote>

<p>As for the software itself, everything will be OK as long as they support FBX and/or COLLADA.</p>

<p>I'd recommend one of these:</p>

<ul>
<li><a href=""http://www.blender.org/"">Blender</a></li>
<li><a href=""http://usa.autodesk.com/3ds-max/"">3DS Max</a></li>
<li><a href=""http://usa.autodesk.com/maya/"">Maya</a> (from what I've heard, Maya is more complete than Max, but then again, it's more complex than Max)</li>
</ul>

<p>Since Blender is Open-Source it's free for everybody, everything and forever. It has huge community, lots of plugins and so on and so forth. In short, a free, packed 3D software for almost everything you can imagine.</p>

<p>Autodesk products on the other hand are better developed, they're commercial products, therefore higher quality product, plus, relatively better community- resulting in more plugins and 3rd party tools.<br>
Autodesk software is not cheap tho', but provides educational license for every single tool they have there for an exchange of stripped down license.<br>
One more bonus for Autodesk would be the infinte amount of quality and really helpful plugins/3rd party software. But the plugins tend to not be cheap either.</p>

<h3>Details</h3>

<p>As rojcyk mentioned, there are tools such as ZBrush (Sculptris is the stripped down, free version of ZBrush). These are mostly meant to be used for details, like, when you need to add that quality 6 pack to your Rambo guy.</p>

<p>There is a bonus for this, you only have to make a reference model, and ZBrush will allow you to add that extra detail much faster and more precise than the plain ol' modelling tool, hence they fell into the category of ""Sculpting tools"".</p>

<h1>It's not the tools it's the carpenter</h1>

<p>The information above should be enough, but yes, modelling as for everything else in this world, doesn't just ""happen"". Takes a lot of time and a lot of knowledge to end up in something really usable.</p>

<h3>Good luck and have fun!</h3>
","20904"
"Can I write plugin/extension to Unity editor?","8525","","<p>Is there possiblity to write my own plugin/extension to Unity editor ? I want to write plugin to generate map for me from xml file.</p>
","<p>""Plugins"" in Unity nomenclature mean native code (read: written in C/C++/Objective-C) DLLs.  For what you want to do you more than likely don't need (or want, really) to use plugins.</p>

<p>For extensions, the Unity editor is very scriptable.</p>

<p>Are you asking if you can </p>

<ol>
<li>Populate a unity scene at editor time from an XML file</li>
<li>Replace unity's default scene format entirely with an xml file.</li>
</ol>

<p>Either way, what you're asking is more than possible.  Here's an example of somebody completely replacing Unity's binary scene file format with a text representation: <a href=""https://github.com/terravision/UnityTextScene"">https://github.com/terravision/UnityTextScene</a></p>

<p>What you probably want to do is more likely just take advantage of their editor scripting tools.  For example, look at <a href=""http://unity3d.com/support/documentation/ScriptReference/ScriptableWizard.html"">ScriptableWizard</a>.  You can take that base code and then do something like load an XML file and spawn a bunch of prefabs, or whatever.  </p>

<p>Pretty much the vast majority of things you see in the editor is scriptable.  You can attach components, move/rotate/scale things, spawn prefabs, edit materials, all sorts of things.</p>
","8519"
"Best way to learn iphone game development?","8519","","<p>I know php and some python, but not much c. Where should I start to learn iphone game development? Is there some recommended books/tutorials for beginners? I'm looking at using cocos2d but I'm open to anything that isn't too limited.</p>
","<p>I also just recently started developing for iOS. I found the <a href=""http://www.cocos2d-iphone.org/wiki/doku.php/"" rel=""nofollow"">documentation</a> over at <a href=""http://www.cocos2d-iphone.org/"" rel=""nofollow"">cocos2d-iphone.org</a> quite helpful, but sadly it isn't very in-depth. That's why I also bought the ""<a href=""http://www.learn-cocos2d.com/"" rel=""nofollow"">Learn iPhone and iPad Cocos2D Game Development Book</a>"" (written by Steffen Itterheim who is also an active community member here on gamedev SE).</p>

<p>Objective-C was also new to me, but thankfully the documentation over at <a href=""http://developer.apple.com"" rel=""nofollow"">developer.apple.com</a> is really good. Be sure to also read the <a href=""https://developer.apple.com/library/ios/#documentation/Cocoa/Conceptual/ObjectiveC/Introduction/introObjectiveC.html"" rel=""nofollow"">introduction to Objective-C</a>.</p>

<p>I've got some C++ experience, so the whole memory-management stuff wasn't totally new to me (well, actually everybody should know about that stuff, even if you don't have to manage things yourself). Since Objective-C doesn't come with a garbage-collector (at least not when you develop for iOS), you should also read the <a href=""https://developer.apple.com/library/ios/#documentation/Cocoa/Conceptual/MemoryMgmt/MemoryMgmt.html"" rel=""nofollow"">memory-management guide</a>. XCode also comes with a handy tool called ""<a href=""http://developer.apple.com/library/mac/#documentation/Performance/Conceptual/ManagingMemory/Articles/FindingLeaks.html"" rel=""nofollow"">Leaks</a>"" which allows you to profile memory-usage and detect leaks. This makes spotting memory-leaks much easier and you should definitely run your app through it (make sure to always run on the device, since the simulator apparently produces leaks where there aren't any).</p>

<p>Umm, I went a bit off-topic in the last paragraph I guess, but it's always good to know about this stuff beforehand :-)</p>

<p><strong>Update:</strong> Since you're open to other options, you might also consider <a href=""http://unity3d.com/"" rel=""nofollow"">Unity3D</a>, <a href=""http://www.udk.com/"" rel=""nofollow"">UDK</a> or even <a href=""http://www.ogre3d.org/"" rel=""nofollow"">Ogre3D</a> (although it's not a game-engine but ""just"" a graphics-engine).</p>
","7628"
"Server-side Architecture for Online Game","8510","","<p>basically I have a game client that has communicate with a server for almost every action it takes, the game is in Java (using LWJGL) and right now I will start making the server.</p>

<p>The base of the game is normally one client communicating with the server alone, but I will require later on for several clients to work together for some functionalities.</p>

<p>I've already read how authentication server should be sepparated and I intend on doing it.
The problem is I am completely inexperienced in this kind of server-side programming, all I've ever programmed were JSF web applications.</p>

<p>I imagine I'll do socket connections for pretty much every game communication since HTML is very slow, but I still don't really know where to start on my server.</p>

<p>I would appreciate reading material or guidelines on where to start, what architecture should the game server have and maybe some suggestions on frameworks that could help me getting the client-server communication.</p>

<p>I've looked into <a href=""http://kenai.com/projects/jnag/pages/OverviewOfJnag"" rel=""nofollow"">JNAG</a> but I have no experience with this kind of thing, so I can't really tell if it is a solid and good messaging layer.</p>

<p>Any help is appreciated...
Thanks !</p>

<p>EDIT:</p>

<p>Just a little more information about the game. It is intended to be a very complex game with several functionalities, making some functionalities a ""program"" inside the program.
It is not an usual game, like FPS or RPG but I intend on having a lot of users using these many different ""programs"" inside the game.</p>

<p>If I wasn't clear enough, I'd really appreciate people that have already developed games with java client/server architecture, how they communicated, any frameworks, apis, messaging systems, etc.</p>

<p>It is not a question of lack of knowledge of language, more a question for advice, so I don't end up creating something that works, but in the later stages will have to be rewriten for any kind of limiting reason.
PS: sorry if my english is not perfect...</p>
","<p>Unfortunately, I'm not aware of any (good) online resources or books on this topic. And I don't know Java. However, seeing that there are no answers yet, I'll share a few tips from personal experience.</p>

<p>First off, you need a <em>fast and reliable</em> RPC, or at least message queue, mechanism. This is what shall be used for both client-server and server-server communication. I don't know if there are any ready-made solutions for Java. With .NET we'd always made our own custom one, as this mechanism is really important. Most commonly a lightweight binary message protocol over TCP is used, but other options may be better depending on the type of game. A turn-based strategy might be better with XML or SOAP, and a fast-paced shooter may warrant UDP.</p>

<p>The absolute minimum for messaging system is the ability to reliably invoke remote actions, <em>while guaranteeing their order</em>. A really helpful addition is support for request-answer pattern, where a remote action may return some kind of result to its initiator. This is not required, but can make your life much easier.</p>

<p>Once you have your messaging, think about partitioning your server. Most probably, a single server machine will not be enough to host the game for all players. You need to carefully consider what tasks can be independent of each other, and thus can be delegated to different servers. Authentication and login is the most obvious candidate for this partitioning. Among others are statistic and rating calculations, database communication (a server to act a specialized DB cache). The problem with MMO games, as opposed to web apps, is that they tend to be highly stateful, with lots of data needed for each player. And most operations require access to all, or almost all, of this data.</p>

<p>Even if you use a single server, you pretty much have to take advantage of multiple processors. Any MMO server is a highly concurrent program (our current server has about 30 concurrent threads). To have any hope of solving synchronization problems, you have to <em>isolate</em> different threads. Like different servers, they'll have their own data, and will communicate using some kind of message-passing interface. Possibly even the same RPC that you network uses, if it's fast enough.</p>

<p>Then you have your database. MMO players usually do a lot of things and generate a lot of chages to the game world, that have to be saved in the database. All the servers I worked with did not save these immediately - instead, changes were accumulated in memory and then saved in bulk every 5 minutes or so. This allows the game to progress more smoothly, at the cost of possible delay when writing takes place. This delay is the main reason to have a separate machine for database communication.</p>

<p>Usually MMO games use relational databases as their data backend, but I believe that NoSQL databases might be better. Usually, you have a bunch of data in your DB for each character, load it all when said character logs in, and very rarely, if ever, do any complex queries. This mode of operation seems to be the forte of NoSQL. That said, I've yet to use a NoSQL DB with an actual MMO server, so I might be wrong here.</p>

<p>Another database-related thing I want to warn you about is this. Many developers, especially early in production cycle, are tempted to store ""game-design"" data in a DB. I'm talking about things like items' and NPCs' parameters, abilities, and other stuff like that. Don't do that. These things are actually static data that does not change unless there's a server update; and this data is always needed by the server. Normally, you won't be doing any queries against it except a <code>SELECT * ...</code> at server startup. Thus, you don't actually need a database, and having these things in a DB has a lot of drawbacks. For one, you can't put a database under source control.</p>

<p>These are three main components for a MMO server architecture: network communication, logic partitioning and database access. All logic using these three is probably very game-dependent. I might have some more advice if you ask more specific questions and tell us more about the game.</p>
","9696"
"How would you implement chromatic aberration?","8502","","<p>How would you implement the effect of <a href=""http://en.wikipedia.org/wiki/Chromatic_aberration"">chromatic aberration</a> with shaders?</p>

<p>Would rendering of the world with different focus distances for each color solve the problem (maybe with the usage of only one depth rendering pass)?</p>
","<p>Chromatic aberration is caused when a lens can't focus every color to the same focal point. A simple way to fake this effect, and render it as a quick full-screen post-process, is to apply an offset to each color channel in a fragment shader.</p>

<p>By using a different offset for each channel, you can achieve a reasonable facsimile of the desired effect. An example of this technique can be found <a href=""http://blog.jahfer.com/2012/04/02/experimenting-shaders-openframeworks/"">here</a>; the fragment shader would look something like this:</p>

<pre><code>void main () {
    // Previously, you'd have rendered your complete scene into a texture
    // bound to ""fullScreenTexture.""
    vec4 rValue = texture2D(fullscreenTexture, gl_TexCoords[0] - rOffset);  
    vec4 gValue = texture2D(fullscreenTexture, gl_TexCoords[0] - gOffset);
    vec4 bValue = texture2D(fullscreenTexture, gl_TexCoords[0] - bOffset);  

    // Combine the offset colors.
    gl_FragColor = vec4(rValue.r, gValue.g, bValue.b, 1.0);
}
</code></pre>

<p>This simple hack doesn't really take into account the fact that chromatic aberration is a lens effect, though: to get a better simulation, you'd actually want to render something to act as the lens. This is similar to how you render objects that are reflective or refractive. Consequently, a typical reflection/refraction shader can be the basis for implementing chromatic aberration. </p>

<p>Normally, you'd compute a single refraction vector based on a view vector and some defined <a href=""http://en.wikipedia.org/wiki/Refractive_index"">index of refraction</a>, using GLSL's <a href=""http://www.opengl.org/sdk/docs/manglsl/xhtml/refract.xml"">refract</a> function in a vertex shader:</p>

<pre><code>void main () {
    // ...

    // RefractionVector is a varying vec3.
    // 'ratio' is the ratio of the two indices of refraction.
    RefractionVector = refract(incidentVector, normalVector, ratio);

    // ...
}
</code></pre>

<p>Then you'd use that vector in a fragment shader to perform an cube texture lookup (into an environment map). Typically this is done alongside a reflection effect as well, and combined used a computed <a href=""http://www.hash.com/am2004/Rendering/Fresnel%20Term/Fresnel%20Term.htm"">Fresnel term</a>.</p>

<p>To simulate chromatic aberration, then, you can perform <em>three different</em> refraction vector computations, each one slightly offset via differing indices of refraction, in the vertex shader:</p>

<pre><code>void main () {
    // ...

    // RefractionVector is a varying vec3, as above.
    // 'ratioR,' et cetera, is the ratio of indices of refraction for
    // the red, green and blue components respectively.
    RedRefractionVector = refract(incidentVector, normalVector, ratioR);
    GreenRefractionVector = refract(incidentVector, normalVector, ratioG);
    BlueRefractionVector = refract(incidentVector, normalVector, ratioB);

    // ...
}
</code></pre>

<p>Those three different vectors can be used to perform three different cube map lookups, which can be mixed together similar to how the colors were mixed in the simple example:</p>

<pre><code>void main () {
    vec3 color;
    color.r = vec3(textureCube(EnvironmentMap, RedRefractionVector)).r;
    color.g = vec3(textureCube(EnvironmentMap, GreenRefractionVector)).g;
    color.b = vec3(textureCube(EnvironmentMap, BlueRefractionVector)).b;

    gl_FragColor = vec4(color, 1.0);
}
</code></pre>

<p>For more details, the <a href=""http://rads.stackoverflow.com/amzn/click/0321637631"">OpenGL Orange Book</a> is available and contains an example of the basic reflection and refraction effects, as well as an example of the chromatic aberration effect.</p>
","58412"
"LibGDX - Check if currently on Android/Desktop","8485","","<p>I'm using LibGDX and flixel-android to build a Desktop/Android game. It feels like there should be a way of checking to see if you're currently being run on an Android device, the Desktop, and so on, but I can't find it anywhere. Am I supposed to just pass it down from the individual launchers? Surely LibGDX can just tell me?</p>
","<p>I think you're after <a href=""http://code.google.com/p/libgdx/wiki/ApplicationQuerying"">Application querying</a></p>

<pre><code>switch(Gdx.app.getType()) {
   case ApplicationType.Android:
       // android specific code
   case ApplicationType.Desktop:
       // desktop specific code
   case ApplicationType.WebGl:
       /// HTML5 specific code
}
</code></pre>
","36000"
"OpenGL ES 2.0: Vertex and Fragment Shader for 2D with Transparency","8484","","<p>Could I knindly ask for correct examples of <strong>OpenGL ES 2.0 Vertex and Fragment shader</strong> for displaying 2D textured sprites <strong>with transparency</strong>?</p>

<p>I have fairly simple shaders that display textured polygon pairs but transparency is not applied despite:</p>

<ul>
<li>texture map contains transparency information</li>
<li>Blending is enabled: glEnable(GL_BLEND); glEnable(GL_DEPTH_TEST); glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA);</li>
</ul>

<p><em>My Vertex Shader:</em></p>

<pre><code>uniform mat4 uOrthoProjection;
uniform vec3 Translation;

attribute vec4 Position;
attribute vec2 TextureCoord;

varying vec2 TextureCoordOut;

void main()
{
    gl_Position = uOrthoProjection * (Position + vec4(Translation, 0));
    TextureCoordOut = TextureCoord;
}
</code></pre>

<p><em>My Fragment Shader:</em></p>

<pre><code>varying mediump vec2 TextureCoordOut;
uniform sampler2D Sampler;

void main()
{
    gl_FragColor = texture2D(Sampler, TextureCoordOut);
}
</code></pre>
","<p>Bunkai (I expect that Bunkai is your first name),</p>

<p>turn off the depthBufer. Do you use depth (different Z)? If not why depthBuffer? It is for 3D or layered 2D. </p>

<p>Transparent objects are rendered <strong>always</strong> after opaque objects. Do you use this order?</p>

<p>It must be one of this, i'm sure.</p>
","9031"
"How to avoid gimbal lock","8482","","<p>I am trying to write code with rotates an object.</p>

<p>I implemented it as:</p>

<p>Rotation about X-axis is given by the amount of change in y coordinates of a mouse and 
Rotation about Y-axis is given by the amount of change in x coordinates of a mouse.</p>

<p>This method is simple and work fine until on the the axis coincides with Z-axis, in short a gimble lock occurs.</p>

<p>How can I utilize the rotation arount Z-axis to avoid gimbal lock.</p>
","<p>The simple solution is not to store the orientation of the object as angles around axes (X-, Y-, Z-axis), as for instance in euler angles.</p>

<p>Store the orientation of the object as a matrix or a quaternion.</p>

<p>This can cause gimbal lock, using euler angles:</p>

<pre><code>class Object
{
    float m_angleAxisX;
    float m_angleAxisY;
    float m_angleAxisZ;
};
</code></pre>

<p>No gimbal lock:</p>

<pre><code>class Object
{
    matrix m_orientation;   
};
</code></pre>

<p>No gimbal lock either:</p>

<pre><code>class Object
{
    quaternion m_orientation;   
};
</code></pre>

<p>Now whenever the mouse is changed, multiply m_orientation with the orientation change coming from the mouse movement each frame.</p>
","51418"
"sprite animation in openGL","8477","","<p>I am facing problems on implementing sprite animation in openGL ES.
I've googled it and the only thing i am getting is the Tutorial implementing via Canvas.</p>

<p>I know the way but I am having problems in implementing it.</p>

<p>What I need : A sprite animation on collision detection.</p>

<p>What I did : Collision Detection function working properly.</p>

<p>PS : Everything is working fine but i want to implement the animation in OPENGL ONLY. Canvas won't work in my case.</p>

<p>------------------------ EDIT-----------------------</p>

<p>I now have a sprite sheet, say the one below having some certain co-ordinates, but from where will be the (u,v) co-ordinates start?
Should I consider my u,v co-ordinates from (0,0) or from (0,5) and in which pattern should i store them in my list..?
----> From Left to right
         OR
----> from top to bottom</p>

<p>Do i need to have a 2D array in my sprites class?
here is the image for a better understanding.</p>

<p><img src=""https://i.stack.imgur.com/P9ufT.png"" alt=""Sprite sheet"">
I am assuming that I have a NxN sprite sheet, where N = 3,4,5,6,....and so on.</p>

<p>.</p>

<p>.</p>

<pre><code>class FragileSquare{

FloatBuffer fVertexBuffer, mTextureBuffer;

ByteBuffer mColorBuff;

ByteBuffer mIndexBuff;

int[] textures = new int[1];

public boolean beingHitFromBall = false;

int numberSprites = 49;

int columnInt = 7;      //number of columns as int

float columnFloat = 7.0f; //number of columns as float

float rowFloat = 7.0f;


public FragileSquare() {
    // TODO Auto-generated constructor stub

    float vertices [] = {-1.0f,1.0f,            //byte index 0
                         1.0f, 1.0f,            //byte index 1
                                    //byte index 2
                         -1.0f, -1.0f,
                         1.0f,-1.0f};           //byte index 3


    float textureCoord[] = {
                            0.0f,0.0f,
                            0.142f,0.0f,
                            0.0f,0.142f,
                            0.142f,0.142f           


    };


    byte indices[] = {0, 1, 2,
            1, 2, 3 };

    ByteBuffer byteBuffer = ByteBuffer.allocateDirect(4*2 * 4); // 4 vertices, 2 co-ordinates(x,y) 4 for converting in float
    byteBuffer.order(ByteOrder.nativeOrder());
    fVertexBuffer = byteBuffer.asFloatBuffer();
    fVertexBuffer.put(vertices);
    fVertexBuffer.position(0);

    ByteBuffer byteBuffer2 = ByteBuffer.allocateDirect(textureCoord.length * 4);
    byteBuffer2.order(ByteOrder.nativeOrder());
    mTextureBuffer =  byteBuffer2.asFloatBuffer();
    mTextureBuffer.put(textureCoord);
    mTextureBuffer.position(0);

}



public void draw(GL10 gl){


    gl.glFrontFace(GL11.GL_CW);

    gl.glEnableClientState(GL10.GL_VERTEX_ARRAY);
    gl.glVertexPointer(1,GL10.GL_FLOAT, 0, fVertexBuffer);
    gl.glEnable(GL10.GL_TEXTURE_2D);
    int idx = (int) ((System.currentTimeMillis()%(200*4))/200);
    gl.glMatrixMode(GL10.GL_TEXTURE); 
    gl.glTranslatef((idx%columnInt)/columnFloat, (idx/columnInt)/rowFloat, 0);
    gl.glMatrixMode(GL10.GL_MODELVIEW); 
    gl.glEnable(GL10.GL_BLEND);
    gl.glBlendFunc(GL10.GL_SRC_ALPHA, GL10.GL_ONE_MINUS_SRC_ALPHA);

    gl.glBindTexture(GL10.GL_TEXTURE_2D, textures[0]); //4
    gl.glTexCoordPointer(2, GL10.GL_FLOAT,0, mTextureBuffer); //5
    gl.glEnableClientState(GL10.GL_TEXTURE_COORD_ARRAY);
    gl.glDrawArrays(GL10.GL_TRIANGLE_STRIP, 0, 4); //7
    gl.glFrontFace(GL11.GL_CCW);
    gl.glDisableClientState(GL10.GL_VERTEX_ARRAY);
    gl.glDisableClientState(GL10.GL_TEXTURE_COORD_ARRAY);
    gl.glMatrixMode(GL10.GL_TEXTURE);
    gl.glLoadIdentity();
    gl.glMatrixMode(GL10.GL_MODELVIEW);
}

public void loadFragileTexture(GL10 gl, Context context, int resource)
{
    Bitmap bitmap = BitmapFactory.decodeResource(context.getResources(), resource);
    gl.glGenTextures(1, textures, 0);
    gl.glBindTexture(GL10.GL_TEXTURE_2D, textures[0]);
    gl.glTexParameterf(GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_MIN_FILTER, GL10.GL_LINEAR);
    gl.glTexParameterf(GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_MAG_FILTER, GL10.GL_LINEAR);
    gl.glTexParameterf(GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_WRAP_S, GL10.GL_REPEAT);
    gl.glTexParameterf(GL10.GL_TEXTURE_2D, GL10.GL_TEXTURE_WRAP_T, GL10.GL_REPEAT);
    GLUtils.texImage2D(GL10.GL_TEXTURE_2D, 0, bitmap, 0);
    bitmap.recycle();
}
</code></pre>

<p>}</p>
","<p>This is a code snippet I'm using in my Android application.</p>

<pre><code>gl.glEnable(GL10.GL_TEXTURE_2D);
gl.glMatrixMode(GL10.GL_TEXTURE);    //edit the texture matrix
gl.glTranslatef(u, v, 0);            //translate the uv space (you can also rotate, scale, ...)
gl.glMatrixMode(GL10.GL_MODELVIEW);  //go back to the modelview matrix
gl.glBindTexture(GL10.GL_TEXTURE_2D, getTexture());
gl.glEnableClientState(GL10.GL_TEXTURE_COORD_ARRAY);           //map the texture on the triangles
gl.glTexCoordPointer(2, GL10.GL_FLOAT, 0, getTextureBuffer()); //load texture coordinates
</code></pre>

<p>The trick here is to use glMatrixMode followed by glTranslatef.
That will allow you to translate the uv space.</p>

<p>uv coordinates range from (0,0) to (1,1)</p>

<p>Let's suppose you have a squared texture with 4 frames and you want to texturize a quad.
I will use the following coordinates to define frames in uv space (the choice is up to you)</p>

<p>1st (0, 0) (0.5, 0.5)</p>

<p>2nd (0.5, 0) (1, 0.5)</p>

<p>3rd (0, 0.5) (0.5, 1)</p>

<p>4th (0.5, 0.5) (1, 1)</p>

<p>With glTexCoordPointer you should map the 1st frame on your quad then when you want to show the 2nd frame you call glTranslatef(0.5, 0, 0), glTranslatef(0, 0.5, 0) for the 3rd and glTranslatef(0.5, 0.5, 0) for the 4th.</p>

<p>The code above is tested and work very well, I hope the example is clear enough.</p>

<hr>

<p>EDIT:</p>

<p>at the end of your draw function you should reset your texture matrix whit this code.</p>

<pre><code>gl.glDisableClientState(GL10.GL_TEXTURE_COORD_ARRAY);
gl.glMatrixMode(GL10.GL_TEXTURE);
gl.glLoadIdentity();
gl.glMatrixMode(GL10.GL_MODELVIEW);
</code></pre>

<hr>

<p>ok, let's take 5 rows and 4 columns as an example.
There are max 20 sprites in your spriteset so use
    int idx = (int)((System.currentTimeMillis()%200*number_of_sprites)))/200);</p>

<p>idx now go from 0 to number_of_sprites-1 (can be &lt; 20 if you have for example 5 rows, 4 columns but only 18 sprite) changing it's value every 200ms.
Assuming you have your sprite from left to right and from top to bottom than you can find your frame coordinate in uv space doing this.</p>

<pre><code>int c = 4;      //number of columns as int
float cf = 4.f; //number of columns as float
float rf = 5.f; //number of rows as float
gl.glTranslatef((idx%c)/cf, (idx/c)/rf, 0);
</code></pre>

<p>when you do idx%c you find your column index, the results is always between 0 and c-1 </p>

<p>idx%c is an integer, you need to scale it to a value between 0.0 and 1.0 so you divide by cf, cf is a float so there is an implicit cast here</p>

<p>idx/c is the same thing but for rows, idx and c are both integer so the result is still integer, and it's the row index, dividing by rf you get a value between 0.0 and 1.0</p>
","37570"
"How can I remove inventory items in a Bukkit plugin?","8469","","<p>I am making a Bukkit plugin that takes the player to a ""FunZone"" and allows them to do just about anything. I don't want data transferred between the two worlds. So far I have got most everything stopped. Here's the problem code:</p>

<pre><code>            Integer normInvSize = player.getInventory().getSize();
            Integer i = 0;
            for (i=0; i&lt;normInvSize; i++) {
                ItemStack item = player.getInventory().getItem(i);
                pConfig.set(player.getWorld().getName()+""Inv.""+i.toString()+"".amount"", item.getAmount());
                Short durab = item.getDurability();
                pConfig.set(player.getWorld().getName()+""Inv.""+i.toString()+"".durabillity"", durab.intValue());
                pConfig.set(player.getWorld().getName()+""Inv.""+i.toString()+"".type"", item.getTypeId());
                player.getInventory().removeItem(new ItemStack(item.getType(), item.getAmount()));
            }
</code></pre>

<p>I have everything set up how I want it but I get stray items following me between the worlds. The line</p>

<pre><code>player.getInventory().removeItem(new ItemStack(item.getType(), item.getAmount()));
</code></pre>

<p>does not remove all of the inventory. I want some code that will remove all inventory items (I've handled armor already). I already have a way to restore the inventory later, but my code currently won't remove everything. For example I can end up transfering some stone tools from the ""FunZone"" to the normal world, which I don't want.</p>
","<p>You can't clear a list while you're iterating over it, at least not in this way. Let me show you this, we'll assume a list with 5 items:</p>

<ol>
<li>List: 5, Index: 0</li>
<li>List: 4, Index: 1</li>
<li>List: 3, Index: 2</li>
<li>Break condition already met. 2 Items remaining.</li>
</ol>

<p>What you want to do is clear the whole inventory <em>after</em> you've iterated over it.</p>

<pre><code>// Cache the inventory instead of a number you'll only use once.
PlayerInventory inventory = player.getInventory();

// Cache the world name
String worldName = player.getWorld().getName();

// Use a foreach instead. Looks better.
for (ItemStack stack : inventory.getContents()) {
    // More cache, String concetanations are expensive!
    String start = worldName + ""Inv."" + Integer.toString(i);

    pConfig.set(start + "".amount"", stack.getAmount());
    pConfig.set(start + "".durability"", stack.getDurability().intValue()); // Please be aware that I fixed a typo in durability
    pConfig.set(start + "".type"", stack.getTypeId());
}

// And now clear the inventory
inventory.clear();
</code></pre>

<p>Also, I don't know what <code>pConfig</code> is, but the structure smells broken if you need save stuff like this. You use an Object-Oriented language, so if you need to split strings to get <em>something</em>, you're doing something wrong. You might want to rewrite that...thing.</p>

<p>For further infos please go to Stack Overflow, f.e.: <a href=""https://stackoverflow.com/questions/223918/java-efficient-equivalent-to-removing-while-iterating-a-collection"">Efficient Equivalent to Removing while Iterating a Collection</a></p>
","22608"
"What are the advantages and limitations of using Qt for game development?","8462","","<p>I know there is already a thread asking for example 3d games written using Qt. What I'd like to have a discussion about is whether or not Qt is a good framework for game development.</p>

<p>In my experience Qt is a joy to work with and thanks to QML and QML/3d it's looking like it could be a viable framework for game development. The thought of using signals and slots for gamedev is exciting.</p>

<p>I'd like to hear some opinions on Qt in general as a game development platform. What are it's limitations? What are it's advantages?</p>

<p>Edit: I found an <a href=""http://developer.qt.nokia.com/forums/viewforum/17"" rel=""nofollow"">official Qt game development forum</a>.</p>
","<p>If used properly, Qt can be great for games.  It has good OpenGL support if you want hardware acceleration, and if you're dealing with 2D elements or custom widgets, the QPainter class and its friends have decent performance (just stay away from QPainter::SetOpacity, that'll kill your performance).</p>

<p>The other great thing about Qt for games is Qt Style Sheets.  You can create a custom look-and-feel for your GUI using a CSS-like syntax, so your game's GUI won't look like a boring gray platform-specific interface.</p>
","15837"
"XNA, SpriteBatch: Slow when rendering lots of sprites?","8461","","<p>I've just now tested rendering a lot of sprites using XNA's SpriteBatch class. What I basically do is this:</p>

<p>Somewhere in the code, I have a list which contains all sprites that have to be rendered. I prefilled this list with <strong>2500</strong> Sprites, all of which have the same rotational angle, texture, position etc. </p>

<p>I then draw them like this:</p>

<pre><code>    spriteBatch.Begin();
    foreach (Sprite spr in sprites)
        spriteBatch.Draw(spr.Texture, spr.Position+spr.Center, spr.SourceRect, spr.Color,MathHelper.ToRadians( spr.Rotation ), spr.Center, spr.Scale, SpriteEffects.None, spr.Depth);

    spriteBatch.End();
</code></pre>

<p>and I'm getting really poor performance. I only average about 15FPS with my Radeon HD 6850 graphics card and i5 2500k CPU. </p>

<p>This is <strong>very</strong> surprising to me, since I average about 70 FPS doing exactly the same thing with my own custom OpenGL engine, which uses old OpenGL rendering (meaning one draw call for every single sprite). I actually expected XNAs rendering to be a ton faster, since it draws everything in one draw call. </p>

<p>Am I rendering this the wrong way? Playing around with SpriteSortMode settings has made almost no difference, some of them just make it a tiny bit slower (depth sorting etc.).</p>
","<p>I am not sure, but I think you have each sprite with an instance of its own texture. Meaning instead of doing 1 sprite batch, you are doing 2500 sprite batches. Try replacing spr.Texture with a single local Texture instance.</p>

<p>Also you do arithmetic and call functions from inside the spritebatch function call, which could slow it down more. Try to have all your calculations done somewhere else, and try to store the rotations in the correct format instead of what you are doing.</p>
","13868"
"What makes MMOs with real-money economies legal?","8460","","<p>I beieve most MMOs with an in-game currency tied to a real-world currency (e.g. <a href=""https://wiki.guildwars2.com/wiki/Gem""><em>Guild Wars 2</em>'s gems</a> or <em>Eve</em>'s PLEX) do <em>not</em> allow in-game items to be traded back into real cash for a bunch of reasons—partly because they may be subject to changes to the game's ""normal"" economy but generally because this would open up a bunch of legal issues with money laundering, gaming/gambling laws and so on.</p>

<p>However, <a href=""http://www.entropiauniverse.com/entropia-universe/""><em>Entropia Universe</em></a> (<a href=""https://en.wikipedia.org/wiki/Entropia_Universe"">wikipedia link</a>) has an in-game economy which is tied directly to US dollars, allowing players to ""cash out"" of the game and back into real money. They have even gone so far as to produce bank cards which withdraw from the game and have now formed an actual bank to regulate trades.</p>

<p>Why are there not more games which take this approach of a game economy tied directly to real money?</p>

<p>I understand that the economy needs to be carefully designed and balanced to avoid in-game over-inflation or other exploits leading to in-game currency being ""created"" from nothing, but the bigger concern seems to me to be the legal issues this would create. Given the amount of random chance involved in the game, is this not effectively gambling? If so, how does <em>Entropia Universe</em> allow worldwide users without kicking up a storm of trouble from different regional authorities and governments? Surely this is exactly the kind of thing which is banned in certain US states or other countries. Is it because the game is based in Sweden and their more permissive laws allow it?</p>
","<p>In my experience, the reason you don't see this very often (at least in the US) is ""it's very complicated, we as game developers lack the expertise, and there isn't much profit in it.""</p>

<p>Online gambling laws are <em>really</em> complicated. I'm not even going to pretend my limited comprehension of legalese is up to the task of parsing them. It's not necessarily <a href=""https://en.wikipedia.org/wiki/Virtual_economy#Gambling_regulation"">very clear how MMO games fit into that law</a>:</p>

<blockquote>
  <p>During an interview with Virtual World News, Alex Chapman of the
  British law firm Campbell Hooper stated: ""Now we’ve spoken with the
  gambling commission, and they’ve said that MMOGs aren’t the reason for
  the [Gambling Act 2005], but they won’t say outright, and we’ve asked
  directly, that they won’t be covered. You can see how these would be
  ignored at first, but very soon they could be in trouble. It’s a risk,
  but a very easy risk to avoid.""</p>
</blockquote>

<p>But I know of no cases where a game operating in the US (at least) has tried to go up against this law and get it sorted it out in the courts. Consequently, everybody seems to feel like the safer thing to do is simply avoid the possibility by preventing cash-outs and prohibiting secondary markets, rather than deal with having every aspect of the game scrutinized constantly and possibly repeatedly by <a href=""https://en.wikipedia.org/wiki/Gaming_law"">gambling lawyers</a>.</p>

<p>But the legal specifics are just one aspect of the problem. Another major part of the issue is that when you start allowing cash-outs, you're building more than just a game. You're building a game with a pseudo-bank attached to it.</p>

<p>The logistical implications are many. Primarily though, this means you need to be able to keep sufficient liquidity of assets in order to serve all your potential cash-outs. Game studios aren't really banks (and even then, banks are only required to keep <a href=""http://www.federalreserve.gov/monetarypolicy/reservereq.htm"">10% of their outstanding liability</a> in the US at least), so they're not FDIC-insured. If everybody tried to withdraw what they're owed from the game at once, the studio would probably fold unless they kept all of that money readily on-hand. And since nothing like the FDIC backs game studios, most of those players would get nothing.</p>

<p>Even <em>having</em> that money is a problem. If a game allowed you to generate real money from in-game currency or items that did not at one point originate from putting real money into the system, you'd have to produce that money from <em>somewhere</em> (your profits or savings from elsewhere).</p>

<p>Even if you do restrict the system so at any given point, only cash that has been put in (by somebody) can be taken out (possibly by somebody else), backing 100% of cash-out severely curtails your ability to make any profit off that money... and micro-transactions are an appealing and reliably form of generating profit for a studio. This means the studio can't funnel that profit back to shareholders or employees (in the case of a profit sharing plan).</p>

<p>The studio could invest the funds, certainly, but you wouldn't want it invested into anything high-risk because of the chance of dropping below the balance required to back 100% cash-out. The potential earnings on a very stable investment are much less attractive because of the typical lifetime of a game studio (short), to the point where that investment capital (that money players are putting in to your game) seems like a far better place to take profit from than a piddling amount of interest on said capital.</p>

<p>So games just stay away from it. It's less stressful.</p>

<hr>

<p>As for Entropia Universe in particular, you're right that being based out of Sweden is probably the key factor in allowing it to operate the way it does. Swedish law regarding online gambling appears to be far more amenable to the scenario than US or UK law. </p>
","112777"
"Game logic on the server! Good or bad?","8454","","<p>I'm currently planning a simple online multiplayer game. And here is the question. Does it make sense to make the whole game logic on the server and just send the input from the client to the server? Which are the pros and the cons or are there any reasons why I shouldn't do that?</p>
","<p>You don't want to send player input to the server.  What you probably want to do is send an abstracted representation of what the player wants to do to the server, and then run the logic on there.</p>

<p>Likewise you don't necessarily want to send back everything the client needs to do.  For example, you can send some kind of message saying ""NPC X died"", and the client determines what animation/sounds to play.  Stuff like that.</p>

<p>The trick is to find the line where bandwidth and processing power (on the server) is trumped by preventing people from cheating.  Usually you make any kind of game-changing authoritative decision on the server only, and leave all the ancillary visual stuff to the client.  </p>

<p>There are a lot of more specific questions on this topic all over the site.  For example:</p>

<p><a href=""https://gamedev.stackexchange.com/questions/3884/should-collision-detection-be-done-server-side-or-cooperatively-between-client-s"">Should collision detection be done server-side or cooperatively between client/server?</a></p>

<p><a href=""https://gamedev.stackexchange.com/questions/15996/who-does-the-ai-calculations-in-an-mmo"">Who does the AI calculations in an MMO?</a></p>

<p><a href=""https://gamedev.stackexchange.com/questions/12799/should-the-game-host-be-the-authority-or-another-dumb-client"">Should the game host be the authority, or another dumb client?</a></p>
","20427"
"Inverting matrix in HLSL","8443","","<p>I've got an object in HLSL and I'm using hardware instancing to render multiple copies. But I've come a bit of a cropper when it comes to the vertex normals. Currently I am not using normal mapping (although planning to implement it soon), I'm just putting the normals inside the vertex structure. I can put the world matrix and get it out in HLSL just fine, but I need the inverse transpose if I want the world position of the vertex normal from object space. How can I invert a matrix in HLSL? Or am I going to have to send the matrix and it's inverse in the instance buffer?</p>

<p>Or is this somehing that normal mapping doesn't require?</p>
","<blockquote>
  <p>Or is this somehing that normal
  mapping doesn't require?</p>
</blockquote>

<p>That's right, normal mapping doesn't require this.</p>

<p>In most cases the best way to do normal mapping is to store the normal map normals in tangent space. That is, a normal in the normal map pointing in the same direction as the surface normal is &lt;0,0,1>. (This is why many normal maps are mostly blue, since they are stored in tangent space.)</p>

<p>Instead of transforming every normal in the normal map into world space (as you're about to do), you can just transform the lights and camera into tangent space on the CPU before the draw call. Then no transformation of the normal map normals is needed.</p>

<p>This means that you will do perhaps 2-10 matrix multiplications on the CPU, saving thousands or millions of transformations on the GPU.</p>

<p>See this article for a more in depth explanation of normal mapping and tangent space:
<a href=""http://www.gamasutra.com/view/feature/1515/messing_with_tangent_space.php"">http://www.gamasutra.com/view/feature/1515/messing_with_tangent_space.php</a></p>
","11700"
"Debugging Shader Code?","8441","","<p>I'm writing a game engine, and when I use a perspective camera I get a black screen. I am not going to ask exactly why this is because there would be a lot of code to share and, frankly, I think that's a bit petty a question even to bother you all with.</p>

<p>The trouble is that I don't know how to debug it. All that changes is my projection matrix, and if my projection matrix looks fine, I don't know why it doesn't work. Ideally I'd print out the values of various things as the shader did its calculations, but GLSL inconveniently doesn't have a printf() function.</p>

<p>So my question is: how do I debug my problem? The only thing I can think of is checking as many values as I can client-side and then programming by permutation, but I've done that and gotten nowhere. Is there a way I can see what's happening in the video card? Is there a completely different technique I could be using?</p>

<p>I'm using GLSL version 420 (and features specific to that version), so I don't think that glslDevil is an option, considering that it was last updated in 2010.</p>

<p><strong>EDIT</strong></p>

<p>I managed to solve my problem through some completely unrelated debugging. </p>
","<p>You can also use a program like glIntercept, which is like PIX but then for OpenGL. Next to intercepting and logging all calls it also let's you display shader usage and edit the shaders at run time. This last option (editing the shaders at runtime) could be extremely helpful when debugging because you can keep editing in parts until something goes wrong and you can quickly debug a value by outputting a color.</p>

<p><a href=""http://code.google.com/p/glintercept/"" rel=""nofollow"">http://code.google.com/p/glintercept/</a></p>
","34395"
"Why do engines need to be optimized for new processors of the same architecture?","8439","","<p>When a new processor generation is released, most websites report that game engines and programs need to be optimized for the new hardware. I do not quite understand why. A processor usually has an architecture that defines what kind of instruction set it uses. The one we all use nowadays is amd_x86_64 . Why would any program or compiler need to be updated if all processors use this same architecture? Surely there are features WITHIN the pipeline of the new processor that optimizes the execution of machine code, but why would the machine code itself need to be changed if the architecture did not?</p>
","<p><strong>Because different <em>generations</em> of the same architecture can have different instruction sets</strong>.</p>

<p>For example, <a href=""https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions"" rel=""noreferrer"">Streaming SIMD Extensions</a> are probably the best-known x86 instruction set, but yet, and despite there just being one x86 architecture, there exists SSE, SSE2, SSE3, and SSE4.</p>

<p>Each of these generations can include new instructions that provide faster ways of performing certain operations.  An example that would be relevant to games might be dot product instructions.</p>

<p>So if a game engine is compiled for a previous generation of an architecture, it will not have support for these newer instructions.  Similarly, it may be necessary to optimize the engine for newer instructions; <a href=""https://en.wikipedia.org/wiki/SSE4"" rel=""noreferrer"">SSE4</a>, for example, has support for dot product instructions that work on array-of-structs data.  An optimization that could take advantage of these newer instructions would be to change your data layout to array-of-structs.</p>
","152283"
"Is it possible to use nav-mesh in 2d game in Unity?","8428","","<p>I'm working on game that needs navigation and obstacle avoidance. I've used nav-mesh on 3d project before but now I'm trying to use it in 2d sprite game but it seems like it doesn't work. </p>

<p>I want to know if really it doesn't work and, if it doesn't, what would be a good replacement for a 2d project for the navigation of entities. </p>

<p>I'm looking for free tools.</p>
","<p>You cannot use the Unity Navmesh in 2D, you would have to write your own.  As far as I know, there are no free nav mesh tools available.</p>

<p>Alternatively, you could use a Nodal Pathfinding approach, as detailed here:</p>

<p><a href=""http://www.jgallant.com/nodal-pathfinding-in-unity-2d-with-a-in-non-grid-based-games/"" rel=""nofollow"">http://www.jgallant.com/nodal-pathfinding-in-unity-2d-with-a-in-non-grid-based-games/</a></p>
","117599"
"Rotate canvas along its center based on user touch - Android","8426","","<p>I want to rotate the canvas circularly on its center axis based on user touch.</p>

<p>i want to rotate based on center but its rotating based on top left corner .</p>

<p>so i am able to see only 1/4 for rotation of image.</p>

<p>any idea.. </p>

<p>Like a old phone dialer .</p>

<p>I have tried like as follows</p>

<pre><code>onDraw(Canvas canvas){
  canvas.save();
  // do my rotation
  canvas.rotate(rotation,0,0);
  canvas.drawBitmap( ((BitmapDrawable)d).getBitmap(),0,0,p );
  canvas.restore();
}

@Override
        public boolean onTouchEvent(MotionEvent e) {
                  float x = e.getX();
              float y = e.getY();
              updateRotation(x,y);
              mPreviousX = x;
              mPreviousY = y;
            invalidate();
        }

  private void updateRotation(float x, float y) {

          double r = Math.atan2(x - centerX, centerY - y);
            rotation = (int) Math.toDegrees(r);
        }
</code></pre>
","<p>The core problem in your code is probably that you pass in <code>0, 0</code> as the pivot point to rotate about in your rotate call.</p>

<p>For a more robust way of expressing your transformation, in linear algebra the way to rotate about an <em>arbitrary point</em> is to <em>translate</em> the world in such a way that the point is at the origin, <em>rotate</em>, and then <em>translate back</em>.</p>

<p>That is, <code>translate(-px, -py) * rotate(theta) * translate(px, py)</code>, where p is the point.</p>
","15947"
"GLSL if-else statement unexpected behaviour","8412","","<p>This question is related to this <a href=""https://gamedev.stackexchange.com/questions/31941/opengl-behaviour-depending-on-the-graphics-card""><strong>other one</strong></a> I asked a few days ago. Because I have finally get to the bottom of the issue, I have rather preferred to open a new question with a more detailed information of what is going on. </p>

<p>I basically have a GLSL fragment shader that is giving me unexpected results, depending on whether it is executed using a NVIDIA Quadro, in which works as expected, or a NVIDIA GeForce, in which does something weird. After a detailed evaluation of what is going on, I have realised that the issue is around the <code>discard</code> operation when using the NVIDIA GeForce 560 Ti. </p>

<p>Can someone explain me why these the two codes behave different in a NVIDIA GeForce 560 Ti, but exactly the sume in a NVIDIA Quadro?</p>

<hr>

<p><strong>EDIT #1</strong>: After some deeper evaluation I can conclude that the <code>discard</code> statement it is not the problem. The problem occurs when running the <code>sumw if-else</code> statement at the end of the shader, once <code>colour</code> has been computed. For whatever reason, if I run the <code>sumw if-else</code> at the end the shader, the final render is not the expected one. On the other hand, if the <code>sumw if-else</code> statement is in the middle of the shader, right before running the code that computes the final value of <code>colour</code>, the shaders works as expected. </p>

<hr>

<p><strong>VERSION #1</strong> (works <em>wrong</em> in GeForce 560, basically doesn't discard the pixel)</p>

<pre><code>i = 0;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[0],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 1;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[1],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 2;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[2],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 3;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[3],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 4;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[4],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 5;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[5],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 6;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[6],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 7;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[7],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }       

if (sumw&lt;=0.0)           // Evaluating this here makes that the shader behave wrong
{
    discard;
} 
else 
{                                               
    gl_FragColor = vec4(colour, 1);
}       
</code></pre>

<p><strong>VERSION #2</strong> (works the same in both graphics card)</p>

<pre><code>if(sumw&lt;=0.0)            // Evaluating this here makes that the shader perform as expected
{
    discard;
}
else
{
i = 0;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[0],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 1;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[1],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 2;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[2],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 3;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[3],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 4;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[4],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 5;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[5],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 6;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[6],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }                                                                       
i = 7;                                                                          
    if (i&lt;numCameras &amp;&amp; sumw&gt;0.0)                                           
    {                                                                       
        vec4 texCoord = gl_TextureMatrix[i] * p;                            
        vec4 texColour = texture2DProj(texSampler[7],texCoord);             
        float w = camw[i] / sumw;                                           
        if (w&gt;1.0) w = 1.0;                                                 
        colour += texColour.rgb*w;                                          
    }       
}                                                       
gl_FragColor = vec4(colour, 1);
</code></pre>

<p>If I am not mistaken, the only difference between the two codes is that the first version  does not discard the pixel until the rest of operation have been compleated, whereas the second version discards the pixel if necessary, otherwise carries on with the rest of the computation.</p>

<p>However, they should behave the same, because the computation of <code>colour</code> <strong>dos not affect the condition</strong> to discard or not, because <code>sumw</code> doesn't change its value.</p>

<p>Any explanation to this?</p>
","<p>You are inducing undefined behavior.</p>

<p>The behavior of the texture functions that <a href=""https://www.opengl.org/wiki/Sampler_%28GLSL%29#Texture_lookup_in_shader_stages"" rel=""nofollow"">need implicit derivatives</a> is <em>undefined</em> if the texture coordinate provided to it is not <a href=""https://www.opengl.org/wiki/Sampler_%28GLSL%29#Non-uniform_flow_control"" rel=""nofollow"">within uniform flow (ie: in a conditional branch or uses the results of such a conditional branch)</a>.</p>

<p>The texture coordinates you use, not to mention the samplers, are all based on the results of conditional branching logic. Therefore, the results of accessing the texture with them are undefined.</p>

<p>To resolve this, you must either do all of your texture accesses <em>before</em> deciding which results to use, or you must get gradients for all of your texture coordinates and then <a href=""http://www.opengl.org/wiki/GLSL_Sampler#Gradient_texture_access"" rel=""nofollow"">use the texture ""Grad"" function(s)</a>. Or you can use a texture ""Lod"" function for a specific Lod of the image (but you won't get mipmaping, for obvious reasons).</p>
","32561"
"How do I enable higher FPS in XNA 4.0?","8393","","<p>I created a <a href=""http://files.scharley.me/private/FpsCounter.cs"" rel=""nofollow""><code>FpsCounter</code> <code>DrawableGameComponent</code> (linked to code, it's longish)</a>. It works great: It displays 60.0 fps normally. If I artificially slow down the game loop, it drops.</p>

<p>My 'game' at the moment is a single keyboard-controlled sprite, so it should be possible to render more frequently than 60 frames a second.</p>

<p>I figured turning off vertical synchronization would increase the FPS cap:</p>

<pre><code>public Game1()
{
    _graphics = new GraphicsDeviceManager(this)
                    {
                        PreferredBackBufferWidth = WindowWidth,
                        PreferredBackBufferHeight = WindowHeight,
                        SynchronizeWithVerticalRetrace = false,
                    };
    _graphics.ApplyChanges();
    Content.RootDirectory = ""Content"";
}
</code></pre>

<p>However, even though the above code seems like it should turn off vsync, it doesn't seem to be. Is there something wrong with my constructor, or perhaps my FPS calculations? Or is there something else that may be limiting the frame count?</p>
","<p>if Game.IsFixedTimeStep is true the update method will be called every 1/60 seconds</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/microsoft.xna.framework.game.isfixedtimestep.aspx"">http://msdn.microsoft.com/en-us/library/microsoft.xna.framework.game.isfixedtimestep.aspx</a></p>

<p>""The default value for IsFixedTimeStep is true.""</p>
","16074"
"2D Spatial partitioning alternatives to spatial hashes and quadtrees","8387","","<p>I've been trying to implement a spatial partitioning algorithm in my game, but both spatial hashes and quadtrees aren't what I'm looking for.</p>

<p>My level size is not supposed to have a limit (only Int32 limits). I need a spatial partitioning algorithm that doesn't need a ""Level Width"" and a ""Level Height"".</p>

<p>I have many moving physical objects. I need the algorithm to be fast enough to support 500+ objects.</p>

<p>Any alternative?</p>
","<p>I've decided to go with fixed 2D grids.</p>

<p>I've made two videos which explain in-depth how I implemented them, and the current implementation is available on my GitHub page: <a href=""https://github.com/SuperV1234/SSVSCollision"" rel=""nofollow"">https://github.com/SuperV1234/SSVSCollision</a></p>

<p><a href=""http://www.youtube.com/watch?v=7HY_SqqaoL4"" rel=""nofollow"">http://www.youtube.com/watch?v=7HY_SqqaoL4</a></p>

<p><a href=""http://www.youtube.com/watch?v=vYB37BDtHuQ"" rel=""nofollow"">http://www.youtube.com/watch?v=vYB37BDtHuQ</a></p>
","57221"
"Best technique to create oldschool (fake 3D) racing game?","8376","","<p>What would be a good approach to develop the render system for an oldschool type racing game that uses a pseudo 3D scenery, like for example <strong>Outrun</strong> or <strong>Lotus Esprit Turbo Challenge</strong>? There's an endless scrolling road and scenery graphics are placed like billboard items, etc. I think you get the idea.</p>

<p><img src=""https://i.stack.imgur.com/Dw2oE.png"" alt=""Screenshot from Lotus: The Ultimate Challenge""></p>

<p>Are these developed in a similar way like <a href=""http://en.wikipedia.org/wiki/Mode_7"" rel=""noreferrer"">Mode7</a> or is there a different technique behind it? Does the technique has a specific name I could search for on the web? I need to develop something like that in Flash.</p>
","<p>There's an <a href=""http://www.extentofthejam.com/pseudo/"">excellent article</a> out there that explains the 3D rendering of these games in detail. And you'll also find a complete <a href=""http://codeincomplete.com/posts/2012/6/23/javascript_racer_v1_straight/"">implementation in JavaScript here</a>. </p>

<p>The basic idea is as follows: You divide your screen into a number of strips and use perspective-projection to calculate the texture-coordinates (scaling and y position inside the road-texture) for each strip. Then you draw the portion of the texture into the strip, resulting in a road that vanishes in the distance. </p>
","49641"
"How do OpenGL's texelFetch and texture differ?","8374","","<p>I understand the main differences between <code>texelFetch</code> and <code>texture</code>, but have some questions about the details:</p>

<ul>
<li>Does <code>texelFetch</code> involve a performance penalty? Such as not using a cache or such?</li>
<li>Are <code>texelFetch</code> and <code>texture</code> interchangeable when using <code>GL_NEAREST</code>?</li>
</ul>
","<p><code>texelFetch</code> is quite different from <code>texture</code>.</p>

<p><code>texture</code> is your usual texture access function which handles filtering and normalized (<code>[0,1]</code>) texture coordinates.  <code>texelFetch</code> directly accesses a texel in the texture (no filtering) using unnormalized coordinates (e.g. <code>(64,64)</code> in the middle-ish texel in a 128x128 texture vs <code>(.5,.5)</code> in normalized coordinates).</p>
","66475"
"Why is Y up in many Games?","8359","","<p>I learned at school that the z-axis is up. It is the same in modeling software like Blender. However in many games the y-axis is up.</p>

<p>What is reason?</p>
","<p>I think the direction of the coordinate axes are holdovers from different domains where the crucial plane was different, and X/Y were aligned with that crucial plane. In some applications the ground plane was the most important, thus X/Y were the ground and Z ended up perpendicular to that. For games however the crucial plane is usually the screen (especially of course back when they were 2D and just starting to transition to 3D) thus X/Y were the screen and then when games went 3D Z ended up perpendicular to that.</p>

<p>You can see that kind of distinction between the two biggest 3D art tools: 3ds max and Maya. The Z axis is up in 3ds max because that grew out of architectural tools, while the Y axis is up in Maya because that grew out of movie-making tools.</p>

<p>The important thing to realize when comparing any specific tool to what you learned in school is that it's all arbitrary. It really doesn't matter which way the axes are pointed as long as you keep everything consistent and translate correctly between different coordinate systems.</p>
","46226"
"Accessing Canvas and Button components in a scene","8348","","<p>I have a scene with the following hierarchy:</p>

<p><img src=""https://i.stack.imgur.com/4A7pS.png"" alt=""enter image description here""></p>

<p>This is game scene and the game manager is a singleton with the following variable fields:</p>

<pre><code>// canvas
public Canvas PauseCanvas;
public Canvas MainMenuCanvas;
</code></pre>

<p>Before implementing singleton, I assigned them from the inspector. Now that the game manager is singleton, I need to assign them through script on level load. I can see one solution to this situation:</p>

<ul>
<li>Getting all canvas components through <code>GetComponents&lt;Canvas&gt;()</code> and then iterating and checking their <code>name</code> fields to assign them accordingly or maybe using LINQ. </li>
</ul>

<p><strong>What I want to ask is</strong>: Is there a name-based search method just like finding game objects with name <code>GameObject.Find(""Name"")</code> that is applicable for Components?</p>
","<p>There is no such method but you can use this to find your elements : <code>yourCanvas = GameObject.Find(""CanvasName"").GetComponent&lt;Canvas&gt;();</code></p>
","92233"
"What are the dangers of self-teaching game development?","8332","","<p>I am about to embark upon a journey into game development.  Following answers to my last question, I will be using C# and XNA.</p>

<p>However, I don't personally know any other game developers and I don't work in the industry so, as such, will be self-taught.  The exception to this is obviously the asking of questions and reading of online/printed information but I would still class this as being self-taught.</p>

<p>With that, I want to be prepared for issues that I may encounter through not having someone to ""keep me under their wing"".</p>

<p>As an analogy, when self-teaching myself to play guitar, I played the A major chord in such a manner that it made moving to a chord I learned later more difficult.</p>

<p>If you could share your lessons learned and advice on what might go wrong in my learning of game development I'd be grateful.</p>

<p>I am well aware that making mistakes is the biggest part of learning but, if there're mistakes I can be prepared for then I'd be happier with that.</p>
","<h3>Game development is like structural engineering</h3>

<p>There are minimum requirements for functionality. The minimum requirements are not exceptionally challenging and many people can learn how to fulfill them. That's the <strong>function</strong> part. It's the small part. This is where the decisions of what language to use, platform to develop on, or what libraries to utilize come in.</p>

<p>The next part is the big part. The <strong>form</strong> part. Form is what really distinguishes the good games from the great games. This is the part that's the <em>art</em> of game development. I'm not talking about just the sensory assets (graphics, sound, etc?). I'm talking about  crafting an experience. This is the hard part.</p>

<p>The function part comes from tutorials, libraries and a bit of time. Anyone can do it.</p>

<p>The form part comes from you. It's the passion that got you to want to make games in the first place. It's like telling a story, a made up story (or a true story you embellish, a lot). <strong>The more you tell the story, the better it gets</strong>. In software development we call it iterating. Your story is your code. The first time you tell it, it won't be very good. Things will be out of place, you'll realize that this bit should go there and that one here. You'll find that things will probably flow better if you arranged things this way or expanded on this bit. So, just like a good story, you'll tell it, gauge how good it is, and then modify it. This takes dedication and this takes time. Don't fret if the first thing you produce isn't gold. I have worked long and hard on many parts of my game only to rip them out later because I thought of a <em>much</em> better way of doing it. Don't worry about this, it's all part of the learning process. You always learn from your mistakes, and often making those mistakes is what leads you to the better way of doing things.</p>

<p>So what you should take away from this is this:</p>

<ul>
<li>Play test often.</li>
<li>Don't get caught up on the function right now. Don't worry to much about optimization, or which library will be the best in the long run. Just get the minimum functionality, <em>then</em> iterate.</li>
<li>Once the function is done, congratulate yourself, you're a small fraction of the way done.</li>
<li>Wear sun screen</li>
<li>This is a skill that takes time to develop, you know that from learning a musical instrument, this is no different, you will get better.</li>
<li>Remember what you're in this for, the joy of creating! If things get boring, then switch to something else (try out some game jams to break-up your development time). But don't quit just because it's hard.</li>
<li>The game development community here on SE is great. You'll find everything you need here. You can post a question or hop into chat and discuss your ideas.</li>
</ul>

<p>The internet is full of feathers of information in blog posts, tutorials and communities like this one. Collectively, I'd say that's a pretty good wing to be under. Basically the dangers are not severe. You might do things the ""wrong"" or hard way for a while, but you'll learn eventually. You appear to have plenty of programming experience, so I think you'll pick up on the function part quickly. The mistakes made in game development and ""regular"" development overlap a lot. Your experience will help you avoid many of the common issues the befall new game developers. I think you'll do just fine. Good luck.</p>
","28505"
"TRON: Game A.I algorithm?","8323","","<p>Lightcycles or whatever it was called like.</p>

<hr>

<p>Given a 2d array representing the game map, where each element can be either 0 or 1 (0 representing blank space and 1 representing filled space), what is the algorithm used for TRON enemy A.I?</p>
","<p>I haven't had the chance to dig through their code, but Armagetron Advanced is an open-source relatively mature lightcycle battling game.</p>

<p>You can find the source (and executables) here: <a href=""http://armagetronad.net/downloads.php"">http://armagetronad.net/downloads.php</a></p>
","8082"
"How can I check for Shader Model 3 support?","8315","","<p>Currently I am working on a 3D visualization app. A requirement of my app is that host's graphics card supports Shader Model 3. How can I check for Shader Model 3 support?</p>

<p>I know that these versions are supposed to support these models:</p>

<ul>
<li>DirectX 8.0 - Shader Model 1.0 &amp; 1.1</li>
<li>DirectX 8.0a - Shader Model 1.3</li>
<li>DirectX 8.1 - Shader Model 1.4</li>
<li>DirectX 9.0 - Shader Model 2.0</li>
<li>DirectX 9.0a - Shader Model 2.0a</li>
<li>DirectX 9.0b - Shader Model 2.0b</li>
<li>DirectX 9.0c - Shader Model 3.0</li>
<li>DirectX 10.0* - Shader Model 4.0</li>
<li>DirectX 10.1* - Shader Model 4.1</li>
<li>DirectX 11.0* - Shader Model 5.0</li>
</ul>

<p>But some graphic hardware doesn't support Shader Model 3.0 even with the proper DirectX version. So I want to <em>determine it by checking the hardware</em> not just the DirectX version.</p>
","<p>You'll need to check the GPU capabilities through D3DCAPS (check the DirectX SDK docs if you don't know it). More than just determining the shader model, you can check for specific capabilities supported.</p>

<p>For a one-off check (not gonna help you at runtime) you can use GPU-Z.</p>
","22706"
"Game state and input handling in component-based entity systems","8309","","<p>My question is:</p>

<p><strong>How can I handle game states in my entity system, without resorting to keeping a stack of game state objects around?</strong></p>

<p>So the design of my entity system means that when an entity needs to register for input events for instance, the input component calls the input system and says ""register this entity for this input"". This is all fine and well, however if you add into this the concept of game states (say a pause screen), it becomes a problem to work out if an entity is in the current state and should receive the input.</p>

<p>I could augment the input component/system so that it says, ""register this entity for this input while in these game states"", but this requires that every entity know which states it's going to be used in, and that may not be obvious. Also, keeping a list of game states around per registered input (and other systems that use callbacks) doesn't sound too efficient.</p>

<p>Another idea I had is since there will be an entity that represents the game state, mark that as being disabled, then when generating the input event check that the entity is not a descendant of a disabled game state entity. Seems expensive to work out the parent for every callback.</p>

<p>Another idea is to have all the systems store their data keyed against the current state, that way when generating the input, the target entity won't even be a candidate. However this really hurts the ability to allow communication between entities in different states (not so much a problem for pause screens, but think lock picking in Oblivion/Skyrim).</p>

<p>The only other idea I've had is to have all components handle a state change events and communicate with their relevant system to disable anything they have registered, and re-enable it when switching back to this state.</p>

<p>The second (mark an object as disabled) and forth (have each component deal with state changes) seem like the best of my ideas, but none of them jump out at me as being particularly great.</p>

<p>Does anyone else have any other ideas on how to do this?</p>

<p><em>edit</em> While I talk about input specifically in this question, it can mean any system capable of sending messages/events to entities, such as collisions, timer events, etc...</p>
","<p>What is often used is an intermediate <code>Intent System</code> which abstracts the input and keeps track of the context and relevant gamestates.</p>

<p>The Intent system will stop transmitting inputs when the simulation is paused for example.
It also handles the mapping between controller events and intents (move in direction, run, shoot, reload...).</p>

<p>This way your other conponents are not dependent on specific gamepads/inputs (BUTTON_A, BUTTON_B vs BUTTON_X, BUTTON_O...) but they all react to the same intents (IntentRun, IntentReload...).</p>

<p>Another advantage is that the intent system can be aware of available controllers being added/removed, as it can send intents to any subscriber even outside the simulation you can handle intents like <code>AddPlayer(controllerID)</code>.</p>

<p>How much information about the game state you provide to the system either through events/message or directly is up to you. But the time invested in the Intent system is usually worth it.</p>

<p>You can manage Intent Contexts which will generate intents when they are attached to the system.</p>

<p>The context can be prioritized, i.e.:</p>

<ul>
<li>SimulationAvailableContext sends intents to the simulation while it is available (but not running) for example move the camera, zoom in zoom out, add/remove player...</li>
<li>SimulationRunningContext sends intents to the simulation while it is not paused move player, send unit to position, shoot...</li>
</ul>

<p>This way you can add and remove the contexts which are currently relevant.</p>

<p>And one thing about the whole intent systems is that it should run while the simulation is paused.</p>

<p>One way which is often used to play/pause the game simulation without breaking non simulation related updates is to use a different sets of times. i.e. <code>GenericSystem::onTime(Long time, Long deltaTime, Long simTime, Long simDeltaTime)</code>.</p>

<p>With this approach your engine can simply block the increments on the games's simTime which in turn will block updates on the relevant animation &amp; physics engines which use <code>simTime and simDeltaTime</code> while allowing continuous updates of your camera spring effect if it has to move even during pause, the animation of the loading effect on a virtual in-game billboard while data is being downloaded...</p>
","48399"
"Computing pixel's screen position in a vertex shader: right or wrong?","8302","","<p>I am building a deferred rendering engine and I have a question. The article I took the sample code from suggested computing screen position of the pixel as follows:</p>

<pre><code>VertexShaderFunction()
{
    ...
    output.Position = mul(worldViewProj, input.Position);
    output.ScreenPosition = output.Position;
}

PixelShaderFunction()
{
    input.ScreenPosition.xy /= input.ScreenPosition.w;
    float2 TexCoord = 0.5f * (float2(input.ScreenPosition.x,-input.ScreenPosition.y) + 1);
    ...
}
</code></pre>

<p>The question is what if I compute the position in the vertex shader (which should optimize the performance as VSF is launched significantly less number of times than PSF) would I get the per-vertex lighting insted. Here is how I want to do this:</p>

<pre><code>VertexShaderFunction()
{
    ...
    output.Position = mul(worldViewProj, input.Position);
    output.ScreenPosition.xy = output.Position / output.Position.w;
}

PixelShaderFunction()
{
    float2 TexCoord = 0.5f * (float2(input.ScreenPosition.x,-input.ScreenPosition.y) + 1);
    ...
}
</code></pre>

<p>What exactly happens with the data I pass from VS to PS? How exactly is it interpolated? Will it give me the right per-pixel result in this case? I tried launching the game both ways and saw no visual difference. Is my assumption right?</p>

<p>Thanks.</p>

<p>P.S. I am optimizing the point light shader, so I actually pass a sphere geometry into the VS.</p>

<p>Solution:</p>

<pre><code>struct PSInput
{
    float2 vPos : VPOS;
};

PixelShaderFunction(PSInput input)
{
    float2 ScrPos = input.vPos*halfPixel*2;

        //The correct Screen Space Texture Coordinates.
    float2 TexCoord = ScrPos + halfPixel;

    //Bonus: getting the world position.
    ScrPos = ScrPos*2 - 1;
    ScrPos = float2(ScrPos.x, -ScrPos.y);

    float4 position;
    position.xy = ScrPos;
    position.z = depthVal; // Read from the depth map.
    position.w = 1.0f;

    position = mul(position, InvertViewProjection);
    position /= position.w;
}
</code></pre>
","<p>As you are using hlsl I presume you use DirectX. You can use the input semantic VPOS (DX9) or SV_Position (DX>=10):
<a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/bb509647%28v=vs.85%29.aspx#VPOS"" rel=""nofollow"">MSDN - VPOS &amp; SV_POSITION semantics</a></p>

<p>When you pass the render target resolution reciprocal one mad is sufficient to construct the screen space uv for every type of geometry.</p>

<hr>

<p>You can not simply do what you proposed as the interpolation does a perspective correction. In SM4 you can deactivate this for a single fragment shader input by setting the interpolation modifier to <code>noperspective</code>:
<a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/bb509668%28v=vs.85%29.aspx"" rel=""nofollow"">MSDN - InterpolationModifier</a></p>

<p>I did not use this method but it should work. Using the semantic is the easier and probably equally performant way.</p>

<hr>

<p>A simple optimization for your code is replacing</p>

<pre><code>float2 TexCoord = 0.5f * (float2(input.ScreenPosition.x,-input.ScreenPosition.y) + 1);
</code></pre>

<p>by</p>

<pre><code>float2 TexCoord = 0.5f * float2(input.ScreenPosition.x,-input.ScreenPosition.y) + 0.5f;
</code></pre>

<p>this should ensure that a mad instruction is used instead of two seperate instructions.</p>
","63873"
"What is the point of update independent rendering in a game loop?","8301","","<p>There are dozens of articles, books and discussions out there on game loops. However, I pretty often come across something like this:</p>

<pre><code>while(running)
{
    processInput();
    while(isTimeForUpdate)
    {
        update();
    }
    render();
}
</code></pre>

<p>What basically is bothering me about this approach is the ""update-independent"" rendering e.g. render a frame when there is no change at all. So my question is why this approach is often taught?</p>
","<p>There's a long history of how we arrived at this common convention, with lots of fascinating challenges along the way, so I'll try to motivate it in stages:</p>

<h2>1. Problem: Devices run at different speeds</h2>

<p>Ever try to play an old DOS game on a modern PC, and it runs unplayably fast - just a blur?</p>

<p>A lot of old games had a very naive update loop - they'd collect input, update game state, and render as fast as the hardware would allow, without accounting for how much time had elapsed. Which means as soon as the hardware changes, the gameplay changes.</p>

<p>We generally want our players to have a consistent experience and game feel on a range of devices, (as long as they meet some minimum spec) whether they're using last year's phone or the newest model, a top-end gaming desktop or a mid-tier laptop.</p>

<p>In particular, for games that are competitive (either multiplayer or via leaderboards) we don't want players running on a particular device to have an advantage over others because they can run faster or have more time to react.</p>

<p>The surefire solution here is to lock the rate at which we do gameplay state updates. That way we can guarantee the results will always be the same.</p>

<h2>2. So, why not just lock the framerate (eg. using VSync) and still run the gameplay state updates &amp; rendering in lockstep?</h2>

<p>This can work, but is not always palatable to the audience. There was a long time when running at a solid 30 fps was considered the gold standard for games. Now, players routinely expect 60 fps as the minimum bar, especially in multiplayer action games, and some older titles now look noticeably choppy as our expectations have changed. There's also a vocal group of PC players in particular who object to framerate locks at all. They paid a lot for their bleeding-edge hardware, and want to be able to use that computing muscle for the smoothest, highest-fidelity rendering it's capable of.</p>

<p>In VR in particular, framerate is king, and the standard keeps creeping up. Early in the recent resurgence of VR, games often ran around 60 fps. Now 90 is more standard, and harware like the PSVR is beginning to support 120. This may continue to rise yet. So, if a VR game limits its framerate to what's doable &amp; accepted today, it's liable to be left behind as hardware and expectations develop further.</p>

<p>(As a rule, be wary when told ""players can't perceive anything faster than XXX"" as it's usually based on a particular type of ""perception,"" like recognizing a frame in sequence. Perception of continuity of motion is generally far far more sensitive. )</p>

<p>The last issue here is that a game using a locked framerate also needs to be conservative - if you ever hit a moment in the game where you're updating &amp; displaying an unusually high number of objects, you don't want to miss your frame deadline and cause a noticeable stutter or hitch. So you either need to set your content budgets low enough to leave headroom, or invest in more complicated dynamic quality adjustment features to avoid pegging the whole play experience to the worst-case performance on min-spec hardware.</p>

<p>This can be especially problematic if the performance problems show up late in development, when all your existing systems are built &amp; tuned assuming a lockstep rendering framerate that now you can't always hit. Decoupling update &amp; rendering rates gives more flexibility for dealing with performance variability.</p>

<h2>3. Doesn't updating at a fixed timestep have the same problems as (2)?</h2>

<p>I think this is the meat of the original question: if we decouple our updates and sometimes render two frames with no game state updates in between, then isn't it the same as lockstep rendering at a lower framerate, since there's no visible change on the screen?</p>

<p>There's actually several different ways games use the decoupling of these updates to good effect:</p>

<p><strong>a) The update rate can be <em>faster</em> than the rendered framerate</strong></p>

<p>As tyjkenn notes in another answer, physics in particular is often stepped at a higher frequency than the rendering, which helps minimize integration errors and give more accurate collisions. So, rather than having 0 or 1 updates between rendered frames you might have 5 or 10 or 50. </p>

<p>Now the player rendering at 120 fps can get 2 updates per frame, while the player on lower spec hardware rendering at 30 fps gets 8 updates per frame, and both their games run at the same gameplay-ticks-per-realtime-second speed. The better hardware makes it look smoother, but doesn't radically alter how the gameplay works.</p>

<p>There's a risk here that, <a href=""https://gamedev.stackexchange.com/a/105113/39518"">if the update rate is mismatched to the framerate, you can get a ""beat frequency"" between the two</a>. Eg. most frames we have enough time for 4 game state updates and a little leftover, then every so often we have enough saved up to do 5 updates in a frame, making a little jump or stutter in the movement. This can be addressed by...</p>

<p><strong>b) Interpolating (or extrapolating) the game state between updates</strong></p>

<p>Here we'll often let the game state live one fixed timestep in the future, and store enough information from the 2 most recent states that we can render an arbitrary point between them. Then when we're ready to show a new frame on-screen, we blend to the appropriate moment for display purposes only (ie. we don't modify the underlying gameplay state here)</p>

<p>When done right this makes the movement feel buttery smooth, and even helps to mask some fluctuation in framerate, as long as we don't drop <em>too</em> low.</p>

<p><strong>c) Adding smoothness to non-gameplay-state changes</strong></p>

<p>Even without interpolating gameplay state, we can still get some smoothness wins.</p>

<p>Purely visual changes like character animation, particle systems or VFX, and user interface elements like HUD, often update separately from the gameplay state's fixed timestep. This means if we're ticking our gameplay state multiple times per frame, we're not paying their cost with every tick - only on the final render pass. Instead, we scale the playback speed of these effects to match the length of the frame, so they play as smoothly as the rendering framerate allows, without impacting game speed or fairness as discussed in (1).</p>

<p>Camera movement can do this too - <a href=""https://xinreality.com/wiki/Timewarp"" rel=""noreferrer"">especially in VR, we'll sometimes show the same frame more than once but reproject it to take into account the player's head movement in between</a>, so we can improve the perceived latency and comfort, even if we can't natively render everything that fast. Some game streaming systems (where the game is running on a server and the player runs only a thin client) use a version of this too.</p>

<h2>4. Why not just use that (c) style for everything? If it works for animation and UI, can't we simply scale our gameplay state updates to match the current framerate?</h2>

<p>Yes* this is possible, but no it's not simple.</p>

<p>This answer is already a bit long so I won't go into all the gory details, just a quick summary:</p>

<ul>
<li><p>Multiplying by <code>deltaTime</code> works to adjust to variable-length updates for  <em>linear</em> change (eg. movement with constant velocity, countdown of a timer, or progress along an animation timeline)</p></li>
<li><p>Unfortunately, many aspects of games are <em>non-linear</em>. Even something as simple as gravity demands more sophisticated integration techniques or higher-resolution substeps to avoid diverging results under varying framerates. Player input and control is itself a huge source of non-linearity.</p></li>
<li><p>In particular, the results of discrete collision detection and resolution depend on update rate, leading to tunneling and jittering errors if frames get too long. So a variable framerate forces us to use more complex/expensive continuous collision detection methods on more of our content, or tolerate variability in our physics. Even continuous collision detection runs into challenges when objects move in arcs, requiring shorter timesteps...</p></li>
</ul>

<p>So, in the general case for a game of medium complexity, maintaining consistent behaviour &amp; fairness entirely through <code>deltaTime</code> scaling is somewhere between very difficult &amp; maintenance intensive to outright infeasible.</p>

<p><strong>Standardizing an update rate</strong> lets us guarantee more <strong>consistent behaviour across a range of conditions</strong>, often with simpler code.</p>

<p>Keeping that update rate <strong>decoupled from rendering</strong> gives us <strong>flexibility</strong> to control the smoothness and performance of the experience <strong>without altering the gameplay logic</strong>.</p>

<p>Even then <a href=""https://www.youtube.com/watch?v=fdAOPHgW7qM"" rel=""noreferrer"">we never get truly ""perfect"" framerate independence</a> but like so many approaches in games it gives us a controllable method to dial in toward ""good enough"" for the needs of a given game. That's why it's commonly taught as a useful starting point.</p>
","132835"
"Implementing Scrolling Background in LibGDX game","8299","","<p>I am making a game in LibGDX. After working for whole a day..I could not come out with a solution on  Scrolling background. </p>

<p>My Screen width n height is 960 x 540. I have a png image of 1024 x 540. I want to scroll the background in such a way that it contuosly goes back with camera</p>

<p>x-- as per camera </p>

<p>I tried many alternatives... drawing the image twice ..did a lot of calculations and many others....
but finally end up with this dirty code</p>

<pre><code>if(bg_x2 &gt;= - Assets.bg.getRegionWidth())   {   
//calculated it to position bg .. camera was initially at 15
                bg_x2 = (16 -4*camera.position.x);
                bg_x1=bg_x2+Assets.bg.getRegionWidth();
            }
            else{
                bg_x1 = (16 -4*camera.position.x)%224;  // this 16 is not proper
//I think there can be other ways
                bg_x2=bg_x1+Assets.bg.getRegionWidth();
            }

//drawing twice     
       batch.draw(Assets.bg, bg_x2, bg_y);
        batch.draw(Assets.bg, bg_x1, bg_y);
</code></pre>

<p>The Simple idea is SCROLLING BACKGROUND WITH SIZE SOMEWHAT MORE THAN SCREEN SIZE SO THAT IT LOOK SMOOTH. Even after a lot of search, i didn't find an online solution. Please help.</p>
","<p>You can use parrallaxBackgroung and ParrallaxLayer classes</p>

<p>They will manage all u need in an optimized manner and also its very easy to implement</p>

<p><a href=""http://www.badlogicgames.com/forum/viewtopic.php?f=17&amp;t=1795"" rel=""nofollow"">http://www.badlogicgames.com/forum/viewtopic.php?f=17&amp;t=1795</a></p>
","58622"
"Most efficient 3d depth sorting for isometric 3d in AS3?","8297","","<p>I am not using the built in 3d MovieClips, and I am storing the 3d location my way.</p>

<p>I have read a few different articles on sorting depths, but most of them seem in efficient.</p>

<p>I had a really efficient way to do it in AS2, but it was really hacky, and I am guessing there are more efficient ways that do not rely on possibly unreliable hacks.</p>

<p><strong>What is the most efficient way to sort display depths using AS3 with Z depths I already have?</strong></p>
","<p>If you're talking a tile-based isometric game, you have a fixed number of different depths that are bounded between some known nearest and farthest depth. In that case, it's a perfect candidate for a <a href=""http://en.wikipedia.org/wiki/Pigeonhole_sort"">pigeonhole sort</a>, which has the best possible algorithmic complexity.</p>

<p>Just make an array where each index corresponds to a depth, and each element is a collection of entities at that depth. Sorting is just (in pseudo-code):</p>

<pre><code>sort(entities)
    buckets = new Array(MaxDistance)

    for index in buckets
        buckets[index] = new Array
    end

    // distribute to buckets
    for entity in entities
        distance = calculateDistance(entity)
        buckets[distance].add(entity)
    end

    // flatten
    result = new Array
    for bucket in buckets
        for entity in bucket
            result.add(entity)
        end
    end
end
</code></pre>

<p>And that's from a completely unsorted collection. An even better option is to simply persist the buckets and keep the entity's bucket location updated when its depth changes.</p>
","3532"
"When mapping the surface of a sphere with tiles, how might you deal with polar distortion?","8293","","<p>It's easy to deal with the way locations interact on a clean Cartesian grid.  It's just vanilla math.  And you can kind of ignore the geometry of the sphere's surface for a bunch of it if you want to just truncate the poles or something.  But I keep coming up with ideas for games where the polar space matters.  Geo-coded ARGs and global roguelikes and stuff.</p>

<p>I want square(ish?) locations -- reasonably representable by square tiles of the same size across the globe, anyway.</p>

<p>This has to be a solved problem, right?</p>

<p>What are the solutions?  </p>

<p>ETA:</p>

<p>At the equator -- and assuming that your square locations are reasonably small, it's close enough to true that you can get away with having one square in the rows north and south of the most equatorial row.  And you could probably get away with that by just hand-waving the difference up to like 45-degrees or so.  But eventually, you need to have fewer squares in a pole-ward circumferential row.  If I reduce the length of the row by one and offset the squares by 1/2 then they're just like hexes  and it's relatively easy to do the coding to keep track of the connections.  But as you get pole-ward, it gets more and more extreme.</p>

<p>Projecting the surface of the world onto the surface of a cube is tempting.  But I figured there must be more elegant solutions already in use.  </p>

<p>If I did the cube thing (not dissecting it further through geodesy) Are there any pros and cons related to placing the pole at the center of a face or at the vertex of three sides?</p>
","<p>I think you are looking for a <a href=""http://en.wikipedia.org/wiki/geodesic_grid"" rel=""nofollow noreferrer"">geodesic grid</a>.
Lots of people approximate the earth with a cube:</p>

<p><img src=""https://i.stack.imgur.com/opJ2v.jpg"" alt=""Most cartographic problems would disappear on a polyhedral Earth""></p>

<p><a href=""http://www.progonos.com/furuti/MapProj/Normal/ProjPoly/projPoly2.html"" rel=""nofollow noreferrer"">Carlos A. Furuti has lots of maps of earth that fold up into a cube</a></p>

<p>You may also be interested in the
The <a href=""http://en.wikipedia.org/wiki/Peirce_quincuncial_projection"" rel=""nofollow noreferrer"">Peirce quincuncial projection</a> which maps the whole Earth to one or two squares.</p>

<p>The icosahedron (Dymaxion map ; <a href=""http://space.mit.edu/home/tegmark/icosahedron.html"" rel=""nofollow noreferrer"">""What is the best way to pixelize a sphere?""</a> ) gives slightly less distortion, but is more complicated.</p>
","9486"
"Algorithm for procedureral 2D map with connected paths","8277","","<p><strong>Problem to solve:</strong> Generate a random 2D dungeon map for a tile-based game where all rooms are connected.</p>

<p>I am looking for better solutions than what I currently have.</p>

<p>My current solution is that I run two algorithms. The first generates the dungeon with its rooms. The second make sure that all rooms are connected. I am curious what other soltions may exist. Faster and / or easier etc. Speed is not really a concern, but if speed can be gained at no real cost, well, that is a good thing. More important is that I, and others that read, may learn different ways to approach and solve the problem.</p>

<p>Below are my current implementation. Rooms currently have no exits or exits in any 2, 3 or 4 directions.</p>

<p><strong>Generating the dungeon rooms</strong></p>

<p>Setup: Set the current room to the top left room.</p>

<ol>
<li>Get a valid room type for the room (where valid room type is a type with no exits out of the dungeon and that have exits that matches the exits of the room above and the room to the left. Only need to check above and to the left due to step 2 below).</li>
<li>Put down the room and advance the x-coordinate one step. If the x-coordinate exceeds the dungeon width, set the x-coordinate to 0 and advance the y-coordinate one step. If the y-coordinate exceeds the dungeon height, we are done.</li>
<li>Repeat from #1.</li>
</ol>

<p>I then check to see if all rooms are connected If they are not all connected I run a second algorithm that, in a non-sexy but definately good enough way in terms of dungeon layout, goes through the rooms and change them so that all end up being connected.</p>

<p><strong>Checking to see if all rooms are connected</strong></p>

<p>Setup: Create a 2D map of integers representing paths and initialize the entries to a ""unprocessed"" (not yet traversed) value, -1. Set a start path index integer that keeps track of the current path to 1. Set the current room to the top left room by adding it to a stack of rooms to check. </p>

<ol>
<li>If the stack contains rooms to check, pop it set the path index of the room to the current path index. If the stack does not contain any rooms, increase the path index and try to get a room by advancing column by column, row by row, until we get a room that has not been processed yet. If no room can be found, we are done.</li>
<li>Check to see if the room has an exit to the left. If it has add the left room to the stack if it is not already on there.</li>
<li>Repeat step 2 for down, right and top directions (since we are using a stack that means the rooms are traversed in clockwise order, starting with the top direction).</li>
<li>Repeat from step 1.</li>
<li>If the path indices count is greater than one, there are disconnected rooms.</li>
</ol>

<p>If there are disconnected rooms I then group the rooms by their path index, get the index of the biggest path and connect all other rooms to those rooms. This is a work in progress, but my (current, ""brutish"") plan is to go through each room in a room group (except the first) check to see if there is a horizontal or vertical path to the biggeset room group, and if so, create a horizontal / vertical path there by injecting / updating the rooms inbetween. Rinse and repeat. Ugly, yes, but it is something that will not be noticable in terms of visual pattern so it works in that sense.</p>
","<p>One of the best, and most used, algorithms I've seen out there is generating dungeons using Binary Space Partitioning.</p>

<p>The best general explanation I've read is the one found in <a href=""http://doryen.eptalys.net/articles/bsp-dungeon-generation/"" rel=""noreferrer"">The Chronicles of Doryen</a> (attached at the end for backup purposes) because explains the procedure without getting into the code, thus leaving the implementation to the reader.</p>

<p>Two other tutorials on the same subject, with code, can be found at</p>

<ul>
<li><a href=""http://gamedevelopment.tutsplus.com/tutorials/how-to-use-bsp-trees-to-generate-game-maps--gamedev-12268"" rel=""noreferrer"">How to Use BSP Trees to Generate Game Maps</a></li>
<li><a href=""http://eskerda.com/bsp-dungeon-generation/"" rel=""noreferrer"">Dungeon generation using BSP trees</a></li>
</ul>

<hr>

<blockquote>
  <h2>Building the BSP tree</h2>
  
  <p>We start with a rectangular dungeon filled with wall cells. We are
  going to split this dungeon recursively until each sub-dungeon has
  approximately the size of a room. The dungeon splitting uses this
  operation :</p>
  
  <ul>
  <li>Choose a random direction : horizontal or vertical splitting</li>
  <li>Choose a random position (x for vertical, y for horizontal)</li>
  <li>Split the dungeon into two sub-dungeons</li>
  </ul>
  
  <p><img src=""https://i.stack.imgur.com/Kdgah.jpg"" alt=""enter image description here""></p>
  
  <p>Now we have two sub-dungeons A and B. We can apply the same operation
  to both of them.</p>
  
  <p><img src=""https://i.stack.imgur.com/mDGjA.jpg"" alt=""enter image description here""></p>
  
  <p>When choosing the splitting position, we have to take care not to be
  too close to the dungeon border. We must be able to place a room
  inside each generated sub-dungeon. We repeat until the lowest
  sub-dungeons have approximately the size of the rooms we want to
  generate.</p>
  
  <p><img src=""https://i.stack.imgur.com/3aep7.jpg"" alt=""enter image description here""></p>
  
  <h2>Building the dungeon</h2>
  
  <p>Now we create a room with random size in each leaf of the tree. Of
  course, the room must be contained inside the corresponding
  sub-dungeon. Thanks to the BSP tree, we can’t have two overlapping
  rooms.</p>
  
  <p><img src=""https://i.stack.imgur.com/lWwMO.jpg"" alt=""enter image description here""></p>
  
  <p>To build corridors, we loop through all the leafs of the tree,
  connecting each leaf to its sister. If the two rooms have face-to-face
  walls, we can use a straight corridor. Else we have to use a Z shaped
  corridor.</p>
  
  <p><img src=""https://i.stack.imgur.com/yPNfW.jpg"" alt=""enter image description here""></p>
  
  <p>Now we get up one level in the tree and repeat the process for the
  father sub-regions. Now, we can connect two sub-regions with a link
  either between two rooms, or a corridor and a room or two corridors.</p>
  
  <p><img src=""https://i.stack.imgur.com/3EAHN.jpg"" alt=""enter image description here""></p>
  
  <p>We repeat the process until we have connected the first two
  sub-dungeons A and B</p>
  
  <p><img src=""https://i.stack.imgur.com/mbpmj.jpg"" alt=""enter image description here""></p>
</blockquote>
","82066"
"OpenGL - Calculating camera view matrix","8275","","<p><strong>Problem</strong></p>

<p>I am calculating the model, view and projection matrices independently to be used in my shader as follows:</p>

<pre><code>gl_Position = projection * view * model * vec4(in_Position, 1.0);
</code></pre>

<p>When I try to calculate my camera's view matrix the Z axis is flipped and my camera seems like it is looking backwards.</p>

<p>My program is written in C# using the OpenTK library.</p>

<p><strong>Translation (Working)</strong></p>

<p>I've created a test scene as follows:</p>

<p><img src=""https://i.stack.imgur.com/D5Lhb.png"" alt=""enter image description here""> <img src=""https://i.stack.imgur.com/JJwZP.png"" alt=""enter image description here""></p>

<p>From my understanding of the OpenGL coordinate system they are positioned correctly.</p>

<p>The <strong>model</strong> matrix is created using:</p>

<pre><code>Matrix4 translation = Matrix4.CreateTranslation(modelPosition);
Matrix4 model = translation;
</code></pre>

<p>The <strong>view</strong> matrix is created using: </p>

<pre><code>Matrix4 translation = Matrix4.CreateTranslation(-cameraPosition);
Matrix4 view = translation;
</code></pre>

<p><strong>Rotation (Not-Working)</strong></p>

<p>I now want to create the camera's rotation matrix.  To do this I use the camera's right, up and forward vectors:</p>

<pre><code>// Hard coded example orientation:
// Normally calculated from up and forward
// Similar to look-at camera.
Vector3 r = Vector.UnitX;
Vector3 u = Vector3.UnitY;
Vector3 f = -Vector3.UnitZ;

Matrix4 rot = new Matrix4(
    r.X, r.Y, r.Z, 0,
    u.X, u.Y, u.Z, 0,
    f.X, f.Y, f.Z, 0,
    0.0f, 0.0f, 0.0f, 1.0f);
</code></pre>

<p>This results in the following matrix being created:</p>

<p><img src=""https://i.stack.imgur.com/e400S.gif"" alt=""enter image description here""></p>

<p>I know that multiplying by the identity matrix would produce no rotation.  This is clearly not the identity matrix and therefore will apply some rotation.</p>

<p>I thought that because this is aligned with the OpenGL coordinate system is should produce no rotation.  Is this the wrong way to calculate the rotation matrix?</p>

<p>I then create my view matrix as:</p>

<pre><code>// OpenTK is row-major so the order of operations is reversed:
Matrix4 view = translation * rot;
</code></pre>

<p>Rotation almost works now but the -Z/+Z axis has been flipped, with the green cube now appearing closer to the camera.  <strong>It seems like the camera is looking backwards</strong>, especially if I move it around.</p>

<p>My goal is to store the position and orientation of all objects (including the camera) as:</p>

<pre><code>Vector3 position;
Vector3 up;
Vector3 forward;
</code></pre>

<p>Apologies for writing such a long question and thank you in advance.  I've tried following tutorials/guides from many sites but I keep ending up with something wrong.</p>

<p><strong>Edit: Projection Matrix Set-up</strong></p>

<pre><code>Matrix4 projection = Matrix4.CreatePerspectiveFieldOfView(
    (float)(0.5 * Math.PI),
    (float)display.Width / display.Height,
    0.1f,
    1000.0f);
</code></pre>
","<p>The problem is that constructing the matrix out of the right, up, and forward vectors inherently sets up coordinates in which X points right, Y points up, and Z points forward.  The Z axis in this coordinate system points the opposite of the direction it's ""supposed"" to point (for right-handed view space, as seen in your first diagram).</p>

<p>To fix the problem, you just need to build the view matrix using the camera's right, up, and <em>backward</em> (negative forward) vectors instead.</p>
","75685"
"Moving from XNA to Android","8260","","<p>I've been using XNA to learn game programming for some time, and I'm interested in moving to Android.  Having said that; the learning curve to get started seems to have ramped up exponentially.  I have a working knowledge of Java (started with it before learning C#).  Is there an intermediate step I should take in order to prepare myself for working with Android game programming?  And are there any resources that are geared toward moving from XNA to Android?  </p>
","<p>You could try using <a href=""https://github.com/mono/MonoGame"" rel=""nofollow"">MonoGame</a> or wait for <a href=""http://andrewrussell.net/exen/"" rel=""nofollow"">ExEn</a> they are both ports of XNA to alternate platforms.</p>
","14404"
"Beat detection and FFT","8260","","<p>I am working on a platformer game which includes music with beat detection. I am currently detecting beats by checking for when the current amplitude exceeds a historical sample. This doesn't work well with genres of music, like rock, which have a pretty steady amplitude.</p>

<p>So I looked further and found algorithms splitting the sound into multiple bands using FFT...  then I found the <a href=""http://en.literateprograms.org/Cooley-Tukey_FFT_algorithm_%28C%29"">Cooley-Tukey FFt algorithm</a></p>

<p>The only problem I'm having is that I am quite new to audio and I have no idea how to use that to split the signal up into multiple signals.</p>

<p>So my question is : </p>

<p>How do you use a FFT to split a signal into multiple bands ?</p>

<p>Also for the guys interested, this is my algorithm in c# :</p>

<pre><code>// C = threshold, N = size of history buffer / 1024
    public void PlaceBeatMarkers(float C, int N)
    {
        List&lt;float&gt; instantEnergyList = new List&lt;float&gt;();
        short[] samples = soundData.Samples;

        float timePerSample = 1 / (float)soundData.SampleRate;
        int sampleIndex = 0;
        int nextSamples = 1024;

        // Calculate instant energy for every 1024 samples.
        while (sampleIndex + nextSamples &lt; samples.Length)
        {

            float instantEnergy = 0;

            for (int i = 0; i &lt; nextSamples; i++)
            {
                instantEnergy += Math.Abs((float)samples[sampleIndex + i]);
            }

            instantEnergy /= nextSamples;
            instantEnergyList.Add(instantEnergy);

            if(sampleIndex + nextSamples &gt;= samples.Length)
                nextSamples = samples.Length - sampleIndex - 1;

            sampleIndex += nextSamples;
        }


        int index = N;
        int numInBuffer = index;
        float historyBuffer = 0;

        //Fill the history buffer with n * instant energy
        for (int i = 0; i &lt; index; i++)
        {
            historyBuffer += instantEnergyList[i];
        }

        // If instantEnergy / samples in buffer &lt; instantEnergy for the next sample then add beatmarker.
        while (index + 1 &lt; instantEnergyList.Count)
        {
            if(instantEnergyList[index + 1] &gt; (historyBuffer / numInBuffer) * C)
                beatMarkers.Add((index + 1) * 1024 * timePerSample); 
            historyBuffer -= instantEnergyList[index - numInBuffer];
            historyBuffer += instantEnergyList[index + 1];
            index++;
        }
    }
</code></pre>
","<p>Well, if your input signal is real (as in, each sample is a real number), the spectrum will be symmetric and complex.  Exploiting the symmetry, usually FFT algorithms pack the result by giving you back only the positive half of the spectrum.  The real part of each band is in the even samples and the imaginary part in the odd samples.  Or sometimes the real parts are packed together in the first half of the response and the imaginary parts in the second half.</p>

<p>In formulas, if X[k] = FFT( x[n] ), you give it a vector i[n] = x[n] , and get an output o[m], then</p>

<pre><code>X[k] = o[2k] + j·o[2k+1]
</code></pre>

<p>(although sometimes you get X[k] = o[k] + j·o[k+K/2], where K is the length of your window, 1024 in your example).  By the way, j is the imaginary unit, sqrt(-1).</p>

<p>The magnitude of a band is computed as the root of the product of this band with its complex conjugate:</p>

<pre><code>|X[k]| = sqrt( X[k] · X[k]* )
</code></pre>

<p>And the energy is defined as the square of the magnitude.</p>

<p>If we call a = o[2k] and b = o[2k+1], we get</p>

<pre><code>X[k] = a + j·b
</code></pre>

<p>therefore</p>

<pre><code>E[k] = |X[k]|^2 = (a+j·b)·(a-j·b) = a·a + b·b
</code></pre>

<p>Unrolling the whole thing, if you got o[m] as output from the FFT algorithm, the energy in the band k is:</p>

<pre><code>E[k] = o[2k] · o[2k] + o[2k+1] · o[2k+1]
</code></pre>

<p>(Note: I used the symbol · to indicate multiplication instead of the usual * in order to avoid confusion with the conjugation operator)</p>

<p>The frequency of the band k, assuming a sampling frequency of 44.1Khz and a window of 1024 samples, is</p>

<pre><code>freq(k) = k / 1024 * 44100 [Hz]
</code></pre>

<p>So, for example, your first band k=0 represents 0 Hz, k=1 is 43 Hz, and the last one k=511 is 22KHz (the Nyquist frequency).</p>

<p>I hope this answers your question about how do you get the energy of the signal per band using the FFT.</p>

<p><strong>Addendum</strong>: Answering your question in the comment, and assuming you are using the code from the link you posted in the question (The Cooley-Tukey algorithm in C):
Let's say you have your input data as a vector of short ints:</p>

<pre><code>// len is 1024 in this example.  It MUST be a power of 2
// centerFreq is given in Hz, for example 43.0
double EnergyForBand( short *input, int len, double centerFreq)
{
  int i;
  int band;
  complex *xin;
  complex *xout;
  double magnitude;
  double samplingFreq = 44100.0; 

  // 1. Get the input as a vector of complex samples
  xin = (complex *)malloc(sizeof(struct complex_t) * len);

  for (i=0;i&lt;len;i++) {
    xin[i].re = (double)input[i];
    xin[i].im = 0;
  }

  // 2. Transform the signal
  xout = FFT_simple(xin, len);

  // 3. Find the band ( Note: floor(x+0.5) = round(x) )
  band = (int) floor(centerFreq * len / samplingFreq + 0.5); 

  // 4. Get the magnitude
  magnitude = complex_magnitude( xout[band] );

  // 5. Don't leak memory
  free( xin );
  free( xout );

  // 6. Return energy
  return magnitude * magnitude;
}
</code></pre>

<p>My C is a bit rusty (I am mostly coding in C++ nowadays), but I hope I didn´t make any big mistake with this code.  Of course if you were interested in the energy of other bands it makes no sense to transform the whole window for each of them, that would be a waste of CPU time.  In that case do the transformation once and get all the values you need from xout.</p>
","9791"
"RPG movement holding down button","8256","","<p>I've been writing a simple top down mini RPG in python.</p>

<p>My problem is that when I move the player I have to repeatedly tap the arrow key. Each time I tap the key the player moves 5 PX in the direction of the key I press, but if I hold down the key he doesn't keep moving, he just moves the first 5 PX.</p>

<p>My moving code looks like this:</p>

<pre><code># event loop
    for event in pygame.event.get():
        if event.type == pygame.QUIT: 
            sys.exit()        
        elif event.type == pygame.KEYDOWN:          # check for key presses          
            if event.key == pygame.K_LEFT:        # left arrow turns left
                x = x + -x_speed
            elif event.key == pygame.K_RIGHT:     # right arrow turns right
                x = x + x_speed
            elif event.key == pygame.K_UP:        # up arrow goes up
                y = y + -y_speed
            elif event.key == pygame.K_DOWN:     # down arrow goes down
                y = y + y_speed    
</code></pre>

<p>And farther up I define the x_speed ect.</p>

<p>How do I make it keep moving when I hold down the key?</p>
","<p>Your problem is the fact that you're only looking at <code>KEYDOWN</code> events.</p>

<p>What you need to do is toggle a boolean value when a key is pressed or released.</p>

<p>Something like this would work:</p>

<pre><code># event loop
for event in pygame.event.get():
    if event.type == pygame.QUIT: 
        sys.exit()        
    elif event.type == pygame.KEYDOWN:          # check for key presses          
        if event.key == pygame.K_LEFT:        # left arrow turns left
            pressed_left = True
        elif event.key == pygame.K_RIGHT:     # right arrow turns right
            pressed_right = True
        elif event.key == pygame.K_UP:        # up arrow goes up
            pressed_up = True
        elif event.key == pygame.K_DOWN:     # down arrow goes down
            pressed_down = True
    elif event.type == pygame.KEYUP:            # check for key releases
        if event.key == pygame.K_LEFT:        # left arrow turns left
            pressed_left = False
        elif event.key == pygame.K_RIGHT:     # right arrow turns right
            pressed_right = False
        elif event.key == pygame.K_UP:        # up arrow goes up
            pressed_up = False
        elif event.key == pygame.K_DOWN:     # down arrow goes down
            pressed_down = False

# In your game loop, check for key states:
if pressed_left:
    x -= x_speed
if pressed_right:
    x += x_speed
if pressed_up:
    y -= y_speed
if pressed_down:
    y += y_speed
</code></pre>

<p>This way, you're actually looking at <em>both</em> presses and releases, and moving while the key is pressed.</p>
","54864"
"Generated 3d tree meshes","8254","","<p>I did not find a question on these lines yet, correct me if I'm wrong.</p>

<p>Trees (and fauna in general) are common in games. Due to their nature, they are a good candidate for procedural generation.</p>

<p>There's <a href=""http://www.speedtree.com/"" rel=""nofollow"">SpeedTree</a>, of course, if you can afford it; as far as I can tell, it doesn't provide the possibility of generating your tree meshes at runtime. Then there's <a href=""https://developer.mozilla.org/media/uploads/demos/s/u/supereggbert/8da64348bcea91221c37f6521923487d/snappytree_1340441920_demo_package/index.html"" rel=""nofollow"">SnappyTree</a>, an online webgl based tree generator based on the <a href=""https://github.com/supereggbert/proctree.js/"" rel=""nofollow"">proctree.js</a> which is some ~500 lines of javascript.</p>

<p>One could use either of above (or some other tree generator I haven't stumbled upon) to create a few dozen tree meshes beforehand - or model them from scratch in a 3d modeller - and then randomly mirror/scale them for a few more variants.. </p>

<p>But I'd rather have a free, linkable tree mesh generator.</p>

<p>Possible solutions:</p>

<ul>
<li>Port proctree.js to c++ and deal with the open source license (doesn't seem to be gpl, so could be doable; the author may also be willing to co-operate to make the license even more free).</li>
<li>Roll my own based on L-systems.</li>
<li>Don't bother, just use offline generated trees.</li>
<li>Use some other method I haven't found yet.</li>
</ul>

<p><strong>Update 2015</strong>: ended up porting proctree.js to c++ <a href=""https://github.com/jarikomppa/proctree"" rel=""nofollow"">https://github.com/jarikomppa/proctree</a></p>
","<p>I've done a fair bit of work in this area, although most of my demos are older:</p>

<p>(flash 2010)<br>
  <a href=""http://genesisbbs.com/appstem.html"">http://genesisbbs.com/appstem.html</a> (click and drag mouse)<br>
  <a href=""http://genesisbbs.com/appstem2.html"">http://genesisbbs.com/appstem2.html</a><br>
  (directX 2006)<br>
  <a href=""http://vimeo.com/5206795"">http://vimeo.com/5206795</a>  </p>

<p>I highly encourage you to roll your own, if you are doing this for fun.  You will almost certainly need to work with <a href=""http://en.wikipedia.org/wiki/Quaternion"">Quaternions</a>.  Understanding them is very hard, but you don't need to go too deep to use them.  Think of a quaternion as a vector with an extra component: rotation.  If you want your plants to twist and turn as they grow, they will need quaternions.</p>

<p>Other things to learn:<br>
  <a href=""http://en.wikipedia.org/wiki/Lichtenberg_figure"">Lichtenberg Figures</a><br>
  <a href=""https://www.google.com/search?hl=en&amp;safe=off&amp;q=laplacian%20growth&amp;bav=on.2,or.r_gc.r_pw.r_cp.r_qf.&amp;bpcl=40096503&amp;biw=2094&amp;bih=1192&amp;um=1&amp;ie=UTF-8&amp;tbm=isch&amp;source=og&amp;sa=N&amp;tab=wi&amp;ei=Il3UUP3PA-KE2wXjpoC4AQ"">Laplacian Growth</a><br>
  <a href=""http://en.wikipedia.org/wiki/Voronoi_diagram"">Voronoi Diagrams</a><br>
  Nearest Neighbor algorithms (google them)  </p>

<p>I (personally) would discourage the use of L-Systems, other than to perhaps dictate a grammar for what grows where, i.e. [seed -> [root] / [trunk->branch->[flower/leaf]].  L systems are not good for responding to environmental stimuli like sunlight direction, gravity, obstacles, etc.</p>

<p>As for speed concerns, a single tree can be generated in realtime.  For memory purposes and performance though, you will likely only want to generate a small set of trees and instance them a bit if you are dealing with forests.</p>

<p>Most existing tree generators are not that great (IMHO), besides the high-end ones used for Maya and such.</p>

<p>I also highly, highly recommend using voxels to generate the tree (then skin with a mesh if needed).  The advantage of voxels is that you can easily simulate growth algorithms using things like Laplacian growth and various automata (not Conway's game of life, but other rules produce interesting results).</p>
","45996"
"Procedural world  generation oriented on gameplay features","8244","","<p>In large procedural landscape games, the land seems dull, but that's probably because the real world is largely dull, with only limited places where the scenery is dramatic or tactical.</p>

<p>Looking at world generation from this point of view, a landscape generator for a game (that is, not for the sake of scenery, but for the sake of gameplay) needs to <strong>not</strong> follow the rules of landscaping, but instead some rules married to the expectations of the gamer. For example, there could be a choke point / route generator that creates hills ravines, rivers and mountains between cities, rather than the natural way cities arise, scattered on the land based on resources or conditions generated by the mountains and rainfall patterns.</p>

<p>Is there any existing work being done like this? Start with cities or population centres and then add in terrain afterwards?</p>

<p>The reason I'm asking is that I'd previously pondered taking existing maps from fantasy fiction (my own and others), putting the information into the system as a base point, and then generating a good world to play in from it. This seems covered by existing technology, that is, where the designer puts in all the necessary information such as the city populations, resources, biomes, road networks and rivers, then allows the PCG fill in the gaps.</p>

<p>But now I'm wondering if it may be possible to have a content generator generate also the overall design. Generate the cities and population centres, balancing them so that there is a natural seeming need of commerce, then generate the positions and connectivity, then from the type of city produce the list of necessary resources that must be nearby, and only then, maybe given some rules on how to make the journey between cities both believable and interesting, generate the final content including the roads, the choke points, the bridges and tunnels, ferries and the terrain including the biomes and coastline necessary.</p>

<p>If this has been done before, I'd like to know, and would like to know what went wrong, and what went right.</p>
","<p>Here's a great example of procedural terrain generation, using parameters like moisture, height etc... 
<a href=""http://www-cs-students.stanford.edu/~amitp/game-programming/polygon-map-generation/"">http://www-cs-students.stanford.edu/~amitp/game-programming/polygon-map-generation/</a></p>
","14054"
"Drawing a one pixel wide line in 3D space","8241","","<p>I'd like to draw a line in 3D space that is always exactly one pixel wide on screen, no matter how far away from the camera it is. (And the same for single points too).</p>

<p>Any hints on how I could do that?</p>
","<p><strong>Rendering Lines - Method 1 (Primitives)</strong></p>

<p>For simple lines in 3D space you can draw them using a <code>LineList</code> or <code>LineStrip</code> primitive. Here's the minimal amount of code you have to add to an empty XNA project to have it draw a line from (0,0,0) to (0,0,-50). The line should appear to have roughly the same width no matter where the camera is located.</p>

<pre class=""lang-cs prettyprint-override""><code>// Inside your Game class
private BasicEffect basicEffect;
private Vector3 startPoint = new Vector3(0, 0, 0);
private Vector3 endPoint = new Vector3(0, 0, -50);

// Inside your Game.LoadContent method
basicEffect = new BasicEffect(GraphicsDevice);
basicEffect.View = Matrix.CreateLookAt(new Vector3(50, 50, 50), new Vector3(0, 0, 0), Vector3.Up);
basicEffect.Projection = Matrix.CreatePerspectiveFieldOfView(MathHelper.ToRadians(45f), GraphicsDevice.Viewport.AspectRatio, 1f, 1000f);

// Inside your Game.Draw method
basicEffect.CurrentTechnique.Passes[0].Apply();
var vertices = new[] { new VertexPositionColor(startPoint, Color.White),  new VertexPositionColor(endPoint, Color.White) };
GraphicsDevice.DrawUserPrimitives(PrimitiveType.LineList, vertices, 0, 1);
</code></pre>

<p>I basically created a simple <code>BasicEffect</code> to hold my view and projection transformations, and passed two vertices (storing position and color) to the <code>GraphicsDevice.DrawUserPrimitives</code> method to be rendered as a<code>LineList</code>.</p>

<p>Of course there are many ways to optimize it, most of which involve the creation of a <code>VertexBuffer</code> to store all of the vertices, and batching as many lines as possible into a single Draw call but that's irrelevant to the question.</p>

<hr>

<p><strong>Rendering Points - Method 1 (SpriteBatch)</strong></p>

<p>As for drawing points, this used to be easy using point sprites but <a href=""http://blogs.msdn.com/b/shawnhar/archive/2010/03/22/point-sprites-in-xna-game-studio-4-0.aspx"" rel=""noreferrer"">they were removed from XNA 4.0</a>. There's a few alternatives though. The easiest way is to create a 1x1 white <code>Texture2D</code> object, and render it using <code>SpriteBatch</code> in the correct screen location, which you can easily find using the <a href=""http://msdn.microsoft.com/en-us/library/microsoft.xna.framework.graphics.viewport.project.aspx"" rel=""noreferrer"">Viewport.Project method</a>.</p>

<p>You can create the required <code>Texture2D</code> object like this:</p>

<pre><code>Texture2D pixel = new Texture2D(GraphicsDevice, 1, 1);
pixel.SetData(new [] { Color.White });
</code></pre>

<p>And render it at location (x,y,z) like this:</p>

<pre><code>// Find screen equivalent of 3D location in world
Vector3 worldLocation = new Vector3(0, 0, 50);
Vector3 screenLocation = GraphicsDevice.Viewport.Project(worldLocation, projectionMatrix, viewMatrix, Matrix.Identity);

// Draw our pixel texture there
spriteBatch.Begin();
spriteBatch.Draw(pixel, new Vector2(screenLocation.X, screenLocation.Y), Color.White);
spriteBatch.End();
</code></pre>

<hr>

<p><strong>Rendering Lines - Method 2 (SpriteBatch)</strong></p>

<p>Alternatively, you can also draw lines using a <code>SpriteBatch</code> using the <a href=""http://www.david-amador.com/2010/01/drawing-lines-in-xna/"" rel=""noreferrer"">technique described here</a>. In this case you'd simply need to find the screen space coordinate for both ends of the 3D line (once again using <code>Viewport.Project</code>) and then draw a regular line between them.</p>

<hr>

<p><strong>Rendering Points - Method 2 (Small Line with Primitives)</strong></p>

<p>In the comments, eBusiness raised the following question:</p>

<blockquote>
  <p>What about a line with the same start and end point, wouldn't that produce a point? Or would it simply be invisible?</p>
</blockquote>

<p>I gave it a try and rendering a <code>LineList</code> using the <em>same</em> start and end points resulted in <em>nothing</em> being drawn. I found a way around it though so I'll describe it here for completeness.</p>

<p>The trick is not to use the same start and end points, but instead to draw a line so small, that it only <em>appears as one pixel</em> when drawn. So, in order to choose the correct end point, I first projected the world space point into screen space, moved it right one pixel <em>in screen space</em>, and finally projected it back into world space. That's the end point of your line in order to make it look like a dot. Something like this:</p>

<pre><code>Vector3 GetEndPointForDot(Vector3 start)
{
    // Convert start point to screen space
    Vector3 screenPoint = GraphicsDevice.Viewport.Project(start, projection, view, Matrix.Identity);

    // Screen space is defined in pixels so adding (1,0,0) moves it right one pixel
    screenPoint += Vector3.Right;

    // Finally unproject it back into world space
    return GraphicsDevice.Viewport.Unproject(screenPoint, projection, view, Matrix.Identity);
}
</code></pre>

<p>Followed by rendering it as a normal line primitive.</p>

<hr>

<p><strong>Demonstration</strong></p>

<p>Here's what I got drawing a white line in 3D space using a line list primitive, and red dots at both ends of the line using a 1x1 texture and SpriteBatch. The code used is pretty much what I wrote above. I've also zoomed in so you can confirm that they're exactly one pixel wide:</p>

<p><img src=""https://i.stack.imgur.com/9IpUQ.png"" alt=""enter image description here""></p>
","23142"
"Efficient billboarding sprites in Unity 5","8241","","<p>What's the most efficient way to do billboarding sprites in Unity 5?</p>

<p>I want to make a forest of sprite trees in 3d space. Those sprites need to face the camera at all times. I am working on VERY performance restricted hardware - I need the game to run on mobile at 60+ FPS - the scripts have their overhead and moving/turnign trees cannot be static, so I cant use static batching for them.</p>

<p>The naive method of adding a script to each tree that makes it LookAt the camera each update is not good enough in terms of FPS.</p>

<p>I know the grass/details for terrain uses billboards, but it uses the sprite only as a silhouette for the grass and paints it with a flat colour.</p>
","<p>Instead of using LookAt, you can have the shader force the object to be rendered facing the camera. Thus, no script needs to be added to the tree, and the extra work the shader does is very little. Here's an example:
<a href=""http://en.wikibooks.org/wiki/Cg_Programming/Unity/Billboards"" rel=""noreferrer"">Billboard Shader</a></p>

<p>Also, since they don't actually move or rotate (as far as the CPU is concerned) and share the same material, you can turn on <a href=""http://docs.unity3d.com/Manual/DrawCallBatching.html"" rel=""noreferrer"">static batching</a>.</p>

<p>I hope this helps!</p>
","98515"
"Enabling and Disabling children in Unity","8239","","<p>I'm trying to create an enable/ disable game objects in Unity.  I used <a href=""http://docs.unity3d.com/Documentation/ScriptReference/GameObject.SetActiveRecursively.html"" rel=""nofollow"">GameObject.SetActiveRecursively</a> but it only works one-way.  </p>

<p>I used a collider in which when an object enters the collider.  The game objects become enabled.  When they leave or get to a certain point, they disable.</p>

<p>How would I make this a two way system, making it able to be enabled while inside the collider and disabled when outside the collider?</p>

<p>-- The collider is in the game object who is being disabled and enabled.</p>

<p>According to <a href=""http://answers.unity3d.com/questions/14014/activate-children.html"" rel=""nofollow"">this</a> information from Unity Answers, the object becomes disabled.  So how would I make the object enabled?</p>

<pre><code>function OnTriggerEnter(other : Collider){
    if(other.tag == ""Player""){
        gameObject.SetActiveRecursively(true);

    }
}

function OnTriggerExit(other : Collider){
    if(other.tag == ""Player""){
        gameObject.SetActiveRecursively(false);
    }
}
</code></pre>
","<p>Let's say you have the following hierarchy:</p>

<ul>
<li>ColliderAndScript
<ul>
<li>SetOfMeshes</li>
<li>AnotherSetOfMeshes</li>
</ul></li>
</ul>

<p>Attach your script and collider to ColliderAndScript. Add your things you want enabled/disabled as children. Then make your script like this:</p>

<pre><code>function OnTriggerEnter (other : Collider) {
    if(other.tag == ""Player""){
        for (var child : Transform in transform) {
            child.gameObject.SetActiveRecursively(false);
        }
    }
}

function OnTriggerExit(other : Collider){
    if(other.tag == ""Player""){
        for (var child : Transform in transform) {
            child.gameObject.SetActiveRecursively(true);
        }
    }
}
</code></pre>

<p>This should enable all children when you enter the collider, and disable them when you exit.</p>
","32163"
"Get collision details from Rectangle.Intersects()","8236","","<p>I have a Breakout game in which, at some point, I detect the collision between the ball and the paddle with something like this:</p>

<pre><code>// Ball class
rectangle.Intersects(paddle.Rectangle);
</code></pre>

<p>Is there any way I can get the exact coordinates of the collision, or any details about it, with the current <code>XNA API</code>?</p>

<p>I thought of doing some basic calculations, such as comparing the exact coordinates of each object on the moment of the collision. It would look something like this:</p>

<pre><code>// Ball class
if((rectangle.X - paddle.Rectangle.X) &lt; (paddle.Rectangle.Width / 2))
    // Collision happened on the left side
else
    // Collision happened on the right side
</code></pre>

<p>But I'm not sure this is the correct way to do it.</p>

<p>Do you guys have any tips on maybe an engine I might have to use to achieve that? Or even good coding practices using this method?</p>
","<p>XNA's rectangles are pretty limited. The <code>Rectangle.Intersects()</code> method only returns a boolean result, so you'll need to do more tests yourself if you want details. You can, however, use the <code>Rectangle.Intersect(Rectangle, Rectangle)</code> method to get the rectangle where the two overlap. That will give you some information on depth and location, at least.</p>
","45840"
"Simulating ""line of sight"" with obstacles on 2d grid?","8227","","<p>Ran into an interesting problem. I need to figure out how to simulate line of sight - simple enough, just on a 2d grid with obstacles. Either a grid cell is visible, or it's not.</p>

<p>I can get something really rudimentary going - like spreading n spaces from player, or blocking horizontal propagation when an adjacent obstacle is detected, but I can't let myself live with it. Plenty of other apps are using more sophisticated methods that slope the line of sight around corners etc, and I want to be up to par.</p>

<p>So far DCSS has been my source of inspiration when I'm stumped, I'm hoping to get something close to what they have: <a href=""http://crawl.s-z.org/"">http://crawl.s-z.org/</a>.</p>

<p>Any insight would be appreciated - thanks for the help!</p>

<p>(Forgive if this is embarassingly noobish - only started game dev a few weeks ago, trying hard to catch up.)</p>
","<p><a href=""http://en.wikipedia.org/wiki/Ray_casting"" rel=""noreferrer"">Ray casting</a> is a very fast and efficient way to determine line-of-sight. It basically involves sending a ray (think of it like an infinite laser that can't be redirected) from a certain position in a certain direction. Using this ray, you can determine things like which point(s) it intersects and how far away from the origin it was when it crossed a certain point.</p>

<p>So for example, in a player/enemy scenario, the ray could originate from the enemy with the direction being the location of the player. If the ray collides with a solid tile, the enemy can't see the player. If it doesn't, the enemy can see the player.</p>

<p><a href=""http://www.codeproject.com/Articles/15604/Ray-casting-in-a-2D-tile-based-environment"" rel=""noreferrer"">Here</a> is an excellent tutorial that will should help.</p>

<p>You can also consider <a href=""http://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm"" rel=""noreferrer"">Bresenham's line algorithm</a> (summed up, it creates lines) for something that might be more easily scaled to tiles.</p>
","47546"
"How can I implement hexagonal tilemap picking in XNA?","8224","","<p>I have a hexagon tiled map in which i need to check when a hexagon is clicked. The hexagons aren't actually touching, rather they have a slight gap in between each of them.</p>

<p>Does anyone know how I could go about checking whether a hexagon is clicked without over complicating the whole thing?</p>
","<p>Take a look to this picture</p>

<p><img src=""https://i.stack.imgur.com/sWxoL.png"" alt=""hexagonal decomposition""></p>

<p>As you can see there is a relatively intuitive way to map x,y rectangular coordinate system to the hexagonal one.</p>

<p>We may talk about ""rect"" irregular hexagons ie hexagons inscribed in ellipses or hexagons obtained from regular hexagons scaled in both directions disproportionately (no rotations-shearings).</p>

<p>A rect hexagon can be defined by the height and width of the circumscribing rectangle plus the width of the inscribing one. (W,w,h)</p>

<p><img src=""https://i.stack.imgur.com/LMALP.png"" alt=""inscribing/circumscribing rectangles""></p>

<p>The easiest way to find out the hexagonal index is to partitionate the space as follow:</p>

<p><img src=""https://i.stack.imgur.com/TQMwd.png"" alt=""space partition""></p>

<p>The rectangle width is w + (W - w)/2 = (w + W)/2, its height is h/2; the width of the green rectangle is (W-w)/2. Is easy to find out where in which rectangle the point falls:</p>

<p><img src=""https://i.stack.imgur.com/QrhsX.gif"" alt=""enter image description here""></p>

<p>u and v are the reminder coordinates that indicates where the point is whithin the i,j rectangle: Using w we can say if we are in the green area (u &lt; (W-w)/2) or not.</p>

<p>if it is the case we are in the green area we need to know if we are in the upper or lower half of the hexagon: we are in the upper half if i and j are both even or both odd;  we are in the lower half otherwise.</p>

<p>In both cases it is usefull to trasform u and v so they vary between 0 and 1:</p>

<p><img src=""https://i.stack.imgur.com/Cwr6y.gif"" alt=""enter image description here""></p>

<p>if we are in the lower half <strong>and</strong> v &lt; u  </p>

<p>or </p>

<p>if we are in the upper half <strong>and</strong> (1-v) > u </p>

<p>then we decrement i by one</p>

<p>Now we simply have to decrement j by one if i is odd to see that i is the horizontal hexagon index (column) and the integer part of j/2 is the vertical hexagon index (row)</p>

<p><img src=""https://i.stack.imgur.com/6Qc5v.png"" alt=""enter image description here""></p>
","20762"
"How to use particle editor for libgdx?","8221","","<p>In the libgdx wiki, <a href=""http://code.google.com/p/libgdx/wiki/ParticleEditor"" rel=""nofollow"">this particle editor</a> is recommended. And <a href=""http://www.badlogicgames.com/wordpress/?p=1255"" rel=""nofollow"">this blog was helpful</a>. But the problem is that I am not sure yet how to use it for my game. Let's say I want to have a fire-effect in my game. How can I get help for this particle editor?</p>
","<p>Found <a href=""https://github.com/libgdx/libgdx/blob/master/tests/gdx-tests/src/com/badlogic/gdx/tests/ParticleEmitterTest.java"" rel=""nofollow noreferrer"">the answer in here</a>. You can directly use the output of the editor in the API. It's really cool.</p>

<p><img src=""https://i.stack.imgur.com/T2tag.jpg"" alt=""enter image description here""><img src=""https://i.stack.imgur.com/IIOva.jpg"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/jyKF7.jpg"" alt=""enter image description here""> </p>
","22015"
"Registering InputListener in libGDX","8220","","<p>I'm just getting started with libGDX and have run into a snag registering an InputListener for a button. I've gone through many examples and this code appears correct to me but the associated callback never triggers (""touched"" is not printed to console). I'm just posting the code with the abstract game screen and the implementing screen. The application starts successfully with a label of ""Exit"" in the bottom left hand corner, but clicking the button/label does nothing.</p>

<p>I'm guessing the fix is something simple. What am I overlooking?</p>

<pre><code>public abstract class GameScreen&lt;T&gt; implements Screen
{
    protected final T game;
    protected final SpriteBatch batch;
    protected final Stage stage;

    public GameScreen(T game) 
    {
        this.game = game;
        this.batch = new SpriteBatch();
        this.stage = new Stage(0, 0, true);
    }

    @Override
    public final void render(float delta) 
    {
        update(delta);

        // Clear the screen with the given RGB color (black)
        Gdx.gl.glClearColor(0f, 0f, 0f, 1f);
        Gdx.gl.glClear(GL20.GL_COLOR_BUFFER_BIT);

        stage.act(delta);
        stage.draw();
    }

    public abstract void update(float delta);

    @Override
    public void resize(int width, int height) 
    {
        stage.setViewport(width, height, true);
    }

    @Override
    public void show() 
    {
        Gdx.input.setInputProcessor(stage);
    }

    // hide, pause, resume, dipose
}

public class ExampleScreen extends GameScreen&lt;MyGame&gt;
{
    private TextButton exitButton;

    public ExampleScreen(MyGame game)
    {
        super(game);
    }

    @Override
    public void show()
    {
        super.show();

        TextButton.TextButtonStyle buttonStyle = new TextButton.TextButtonStyle();          
        buttonStyle.font = Font.getFont(""Origicide"", 32);
        buttonStyle.fontColor = Color.WHITE;

        exitButton = new TextButton(""Exit"", buttonStyle);
        exitButton.addListener(new InputListener() {
            @Override
            public void touchUp (InputEvent event, float x, float y, int pointer, int button) {
                System.out.println(""touched"");
            }
        });
        stage.addActor(exitButton);
    }

    @Override
    public void update(float delta) 
    {    
    }
}
</code></pre>
","<p>The solution to this was answered by a kind user in the libGDX chatroom. </p>

<p>In order for touchUp to be triggered, touchDown must also be implemented.</p>

<pre><code>exitButton.addListener(new InputListener() 
{
    @Override
    public bool touchDown (InputEvent event, float x, float y, int pointer, int button) 
    {
        System.out.println(""touchdown"");
        return true;
    }
    @Override
    public void touchUp (InputEvent event, float x, float y, int pointer, int button) 
    {
        System.out.println(""touchup"");
    }
});
</code></pre>
","60130"
"Shadows in deferred rendering","8212","","<p>I've read some material about deferred rendering, and I think I get the gist of it. But what I don't understand is how it accomplishes shadows. The G-buffer, as far as I'm aware, does not involve creating a shadowmap for each light, so I'm confused as to how the lighting pass is aware of whether or not each pixel is occluded. After all, a given pixel which is visible from the camera's perspective may not actually be visible from the perspective of any given light- and that occluding geometry may not be visible from the camera's perspective and therefore have nothing written about it into the G-buffer.</p>

<p>If you start rendering shadowmaps, then it seems pretty much the same as forward rendering- you render all the geometry in the scene for every light to render the shadowmaps.</p>

<p>So how does deferred rendering accomplish shadows equivalent to forward rendering?</p>
","<p>Deferred shading doesn't do anything special for shadows.  You still need to render the shadow maps normally and then render each light with the appropriate shadow map bound as a texture.</p>

<p>It's still better than forward rendering because you don't need to redraw the scene in the main view to apply the lighting.  Drawing the shadow map is often much cheaper than drawing more passes in the main view because you don't need to do any pixel shading, and shadow maps often contain less of the scene (you can cull out a lot more stuff).</p>

<p>People do sometimes do ""deferred shadows"" for one light, typically the main directional light. The primary reason to do this is to use cascaded shadow maps or another approach that uses multiple shadow maps for the same light.  You can reserve one channel in the G-buffer for a shadow mask (white where lit, dark where shadowed) and apply all cascaded shadow maps into this G-buffer channel; then the shader for the light just reads the shadow mask and multiplies it into the light color.  This is nice since it decouples shadows from shading, but you're still drawing all the same shadow maps.</p>
","25437"
"What revenue models exist for online games?","8205","","<p>What revenue models exist for online games?</p>
","<ol>
<li>Subscription. The easiest model, where you simply require a sum of money from your players each month. Monthly payments are most common, but variants exist. Most famous example - WoW.</li>
<li>Freemium subscription. Essentially the same as subscription, but players CAN play for free with some limitations. For example, non-paying players can't visit all locations, or reach maximum level, or somesuch. Dungeon runners used this model, and Dofus IIRC.</li>
<li>Box sales. You simply sell boxed version of your game for some fixed amount, and let players who bought it play forever after. Guild Wars does it; also this model is common among team shooters like TF2 and COD:MW2.</li>
<li>In-game advertising. Show some ads to players and hope they bring enough money. I'm not aware of games that use advertising as a single, or biggest, source of income.</li>
<li>Microtransactions. You sell some virtual items to your players for trivial (or sometimes not) amounts of cash. Some games only sell ""cosmetic"" items that do not affect gameplay; some sell ""helpers"" that make the game a little easier; still others sell all kind of game-breaking uber-weapons and such. Almost all Asian games use this model extensively. </li>
<li>Virtual currency. A very special case of microtransactions, this is where in-game virtual currency has a fixed rate of exchange with real-world currency, and can be exchanged both ways. The only game that does it, as far as I know, is Entropia Universe.</li>
<li>Server leasing. You sell virtual space in your game, allowing players to have their own place in the game. Second Life uses this model.</li>
<li>Merchandise. The game itself is free, and you make money by selling game-related merchandise like posters and t-shirts and the like. Kingdom of Loathing is a game that uses this model.</li>
<li>Offer walls. A kind of microtransactions, but instead of selling items for cash, you show your players a ""wall"" of offers from your partners. Something like ""Participate in this online survey, and receive some in-game currency"". D&amp;D Online had it at one time, and a lot of social games use this model in addition to simple microtransactions.  </li>
<li>Offer flash games for free to other portal sites. A very very BIG component for a lot of sites. Used to drive traffic to their main sits. It's essentially exchanging content for a link back to your site. (Added by eLouai)  </li>
</ol>

<p>That's all I can think of at the moment, but I'm sure I missed several more.</p>
","4986"
"How do I load a texture in OpenGL where the origin of the texture(0, 0) isn't in the bottom left?","8185","","<p>When loading a texture in OpenGL, how do I specify the origin of the data I am loading?</p>

<p>For example, how would I load a Targa that has it's origin at the top left instead of the bottom left of the image?</p>
","<p>You can't, at least not directly. The origin of textures in OpenGL is the lower-left corner. You need to vertically flip your image if it doesn't match this coordinate system. So it's really an image processing problem, not an OpenGL problem.</p>

<p>(Alternatively, you can flip all your texture coordinates that refer to the image.)</p>
","26177"
"Ignoring collisions without using physics layers","8185","","<p>Trying to ignore collisions between certain prefabs, but in this case I don't want to use layers since these are specific object pairs that I want to not collide, and creating a layer for each prefab would complicate the layer matrix more than I want to.</p>

<p>What I tried so far:</p>

<pre><code>public void OnCollisionEnter(Collision collision) {
    if (collision.gameObject.tag == ""Bullet"") {
        Physics.IgnoreCollision(collision.collider, collider);
    }
}
</code></pre>

<p>So I tried ignoring the collision in the <code>OnCollisionEnter</code>, but this only worked partially. The objects did go one through the other, but they both slowed down. My guess is that the first frame of the collision, the one that generated the call to OnCollisionEnter, was calculated regardless of the ignore command.</p>

<p>Any ideas how I can make all bullets not collide to one another, without putting them in a separate layer?</p>
","<p>Ok, so I haven't seen anyone answering with a solution for ignoring collusion between certain prefabs without assigning them their own layers (which are limited to 32).</p>

<p>So it's clear that in current unity versions, you must call <code>IgnoreCollision()</code> for each pair of instantiated objects.</p>

<p>So the solution I found, is an old one (before the layers were introduced), but it seems like it can work. It's called a ""collision manager"", and it's basically a class that stores  references to all the objects that are instantiated, and calls <code>IgnoreCollision()</code> for every pair of objects of types that should not collide. To make it work each object has to register itself with the collision manager and it's type in the <code>Start()</code> method. This way the collision manager can make sure that every pair of objects of types that shouldn't collide will not collide, assuming all objects register themselves.</p>

<p>Here's the link to the article I found, although it's very lacking in explanation:</p>

<p><a href=""http://wiki.unity3d.com/index.php?title=CollisionIgnoreManager"" rel=""nofollow"">http://wiki.unity3d.com/index.php?title=CollisionIgnoreManager</a></p>
","55740"
"How is software rendering done?","8183","","<p>I would like to explore realtime software based rasterization. I know everything is going towards the GPU these days but there are a few games where it still makes sense to use a software renderer. </p>

<p>For example: <a href=""http://www.lexaloffle.com/bbs/?tid=201"">Voxeltron</a></p>

<blockquote>
  <p>Voxatron is an arena shooter that takes place in a world made of
  voxels (little cubes, kind of). Everything in the game is displayed in
  a virtual 128x128x64 voxel display, including the menus and player
  inventory. If you look closely, you can sometimes see the inventory
  (score/life/ammo) casting a shadow on some of the objects on the
  ground.</p>
  
  <p>I've been working on voxel rendering and modeling tools for a long
  time now, with the ultimate goal of making a large explorey adventure
  game. About half a year ago it fused with work I was doing on arena
  shooters for Conflux, and this is the result.</p>
  
  <p>It's quite a simple game at heart -- mostly just Robotron set in a 3d
  destructible world with goofy creatures. I'm unsure how major the
  implications of destructibility will be for gameplay, but it sure is
  fun to blast away pieces of wall. I've also added an experimental
  wall-building pickup you can use to construct barriers to hide from
  scary monsters.</p>
  
  <p>The game takes place in a small set of arenas. Some of them feature
  rooms with set action pieces, somewhere between Knightlore and Smash
  TV. This is some of the original adventure based design sneaking back
  in, and an excuse to create thematic environments.</p>
  
  <p>Features:</p>
  
  <ul>
  <li><strong>Custom software rendering with soft shadows.</strong> </li>
  <li>Built-in sound and music    synthesizer (also used to make the
  trailer music). </li>
  <li>Playback &amp; post game recording.</li>
  </ul>
</blockquote>
","<p>I am going to assume you already know some basic linear algebra, the kind involved in: 3d projections, camera setup, transforming vertices into world position, etc... If you don't, there are plenty of great places to learn from. Here are two that I like: </p>

<p><a href=""http://rads.stackoverflow.com/amzn/click/1568814135"" rel=""noreferrer"">Game Engine Architecture</a></p>

<ul>
<li>Brief coverage of basic linear algebra but does cover everything you need to know. The book is worth having for many other reasons too. </li>
</ul>

<p><a href=""http://rads.stackoverflow.com/amzn/click/1568814240"" rel=""noreferrer"">Real-time Rendering</a> </p>

<ul>
<li>A little bit more detailed coverage but again sticks to only what you might need to know. Again, I recommend this one for the topics covered in the rest of the chapters.</li>
</ul>

<hr>

<p>Once you know about how to represent and handle 3d objects you are ready to look at how to draw them to the screen. Typically this is done with a scan line triangle rasterization technique. It is actually a pretty simple concept. You draw one row of one triangle at a time while interpolating color and uv texture coordinates. This process is continued for all triangles on the screen. You could even implement a depth buffer to handle out of order rendering.</p>

<p><img src=""https://i.stack.imgur.com/b7yN0.png"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/rQYEb.png"" alt=""enter image description here"">
<img src=""https://i.stack.imgur.com/MCFZP.png"" alt=""enter image description here""></p>

<p>This is covered in more detail in these articles:</p>

<p><a href=""http://joshbeam.com/articles/triangle_rasterization/"" rel=""noreferrer"">Tutorial - Introduction to Software-based Rendering: Triangle Rasterization</a></p>

<p><a href=""http://www.devmaster.net/articles/software-rendering/part1.php"" rel=""noreferrer"">Software Rendering School: Part I</a></p>

<hr>

<p>And just for fun, check out the following article:</p>

<p><a href=""http://fabiensanglard.net/quake2/quake2_software_renderer.php"" rel=""noreferrer"">Quake 2 Source Code Review 3/4 (Software Renderer)</a></p>
","17576"
"Essentials for building a RTS","8170","","<p>I was wondering if anyone had any links to good reads or books in regards to things to think about when developing a RTS game, I would have been reading things like <a href=""http://content.gpwiki.org/index.php/RTS_Design_Guide"">http://content.gpwiki.org/index.php/RTS_Design_Guide</a> and <a href=""http://www.oxeyegames.com/category/rts-design/"">http://www.oxeyegames.com/category/rts-design/</a> but would like to read more into it. </p>

<p>Also I have development experience and soon would like to start building the skeleton myself but if anyone has any additional articles about the process (not in programming, but more on planning) that would be great help.</p>
","<p>You could read some Gamasutra features. That's usually a good source of information, from people that actually ship games:</p>

<ul>
<li><a href=""http://www.gamasutra.com/view/feature/132562/the_design_of_starcraft_ii.php"">The Design of <em>StarCraft II</em></a></li>
<li><a href=""http://www.gamasutra.com/view/feature/134199/starcraft_ii_building_on_the_beta.php""><em>StarCraft II</em>: Building On The Beta</a></li>
<li><a href=""http://www.gamasutra.com/view/feature/3094/1500_archers_on_a_288_network_.php"">1500 Archers on a 28.8: Network Programming in Age of Empires and Beyond</a></li>
<li><a href=""http://www.gamasutra.com/view/feature/134311/successful_playtesting_in_swords__.php"">Successful Playtesting In <em>Swords &amp; Soldiers</em></a></li>
<li><a href=""http://www.gamasutra.com/view/feature/132618/postmortem_ronimo_games_swords__.php"">Postmortem: Ronimo Games' <em>Swords &amp; Soldiers</em></a></li>
<li><a href=""http://www.gamasutra.com/view/feature/132691/the_end_of_rts_a_command__.php"">The End of RTS? A <em>Command &amp; Conquer 4</em> Interview</a></li>
<li>etc.</li>
</ul>
","27557"
"How do I get beautiful small text in XNA without using external libraries?","8167","","<p>In XNA, the spritefont technology is horrible. Nuclex does the job so much better, but I don't want to have any external references, and I'm nearly done with my game.</p>

<p>When using fonts like Sansation or Quicksand, it looks terrible in smaller sizes of the fonts. It's so bad!</p>

<p>Is there a known workaround for this? I tried setting the fontsizes to extremely high, and then scaling them down in the spritebatch with no luck.</p>
","<p>XNA <a href=""http://blogs.msdn.com/b/shawnhar/archive/2007/04/26/bitmap-fonts-in-xna.aspx"">lets you import a texture as a spritefont</a>. You can probably get better hinting and anti-aliasing in your font if you lay each character out manually in a good image editing program, rather than relying on the sprite sheet that XNA generates.</p>
","15473"
"SDL 2.0 setup on code::blocks using gcc(MinGW) on win7","8159","","<p>I have recently installed code::blocks on my system running windows 7 home premium 64-bit, and wanted to start learning SDL. The code::blocks executable is the one installed by the ""<em>codeblocks-12.11mingw-setup.exe</em>""- setup wizard, which also installs gcc and MinGW as implied by the name. I proceeded to download the precompiled version of SDL 2.0 development files ""<em>SDL2-devel-2.0.0-mingw.tar.gz</em>"" from the SDL site, created a new empty project, pointed the compiler to the /include directory and the linker to the /lib directory of the 32-bit version of SDL 2.0 using the project specific search directories and set the IDE to treat the project as a GUI application instead of a console application.
However, trying to build the project always results to a build error of the form:</p>

<pre><code>`SDL_main':
undefined reference to `SDL_Init'
undefined reference to `SDL_Quit'
undefined reference to `WinMain@16'
=== Build finished: 3 errors, 0 warnings (0 minutes, 0 seconds) ===
</code></pre>

<p>Which is understandable since I have not specified any linker flags, but adding the flags <code>-lmingw32 -lSDLmain -lSDL</code> to ""other linker options"" in the IDE results in the error:</p>

<pre><code>ld.exe  cannot find -lSDLmain
ld.exe  cannot find -lSDL
=== Build finished: 2 errors, 0 warnings (0 minutes, 0 seconds) ===
</code></pre>

<p>Implying it did indeed recognize the flag <code>-lmingw32</code>.
I tried to copy the appropriate SDL dev files directly to MinGW/include and MinGW/lib, and placed the runtime DLL in the project directory to no avail. Do I have the wrong linker options for SDL 2.0, are they in the wrong order, or am I missing something else?</p>

<p>EDIT: checking all the involved files revealed that libSDLmain.a has been replaced by libSDL2main.a etc. in SDL 2.0. After replacing the linker options with <code>-lmingw32 -lSDL2main -lSDL2</code> the linker stopped complaining about not finding missing statically linked libraries. However it now again fails to find the definition of the various SDL routines called in the program, giving the same output as stated in the first case (undefined reference to X).</p>

<p>EDIT2: Just found out i'm not alone with this problem, there is an old, unanswered question about the exact same problem on stackoverflow: <a href=""https://stackoverflow.com/questions/17011028/i-can-compile-with-sdl1-2-but-not-with-sdl2-cb"">https://stackoverflow.com/questions/17011028/i-can-compile-with-sdl1-2-but-not-with-sdl2-cb</a></p>

<hr>

<p>Source code:</p>

<pre><code>#include &lt;SDL2/SDL.h&gt;

int main(int argc, char* argv[])
{
  SDL_Init(SDL_INIT_EVERYTHING);
  SDL_Quit();
  return 0;
}
</code></pre>

<p>Build log from building the project after adding the aforementioned linker options and SDL files directly in MinGW's /include and /lib directiories and removing the search directories from the project's options:</p>

<pre><code>-------------- Build: Debug in newProject(compiler: GNU GCC Compiler)---------------

mingw32-g++.exe  -o bin\Debug\newProject.exe obj\Debug\newProject\newProject\main.o   -lmingw32 -lSDLmain -lSDL   -mwindows
c:/program files (x86)/codeblocks/mingw/bin/../lib/gcc/mingw32/4.7.1/../../../../mingw32/bin/ld.exe: cannot find -lSDLmain
c:/program files (x86)/codeblocks/mingw/bin/../lib/gcc/mingw32/4.7.1/../../../../mingw32/bin/ld.exe: cannot find -lSDL
collect2.exe: error: ld returned 1 exit status
Process terminated with status 1 (0 minutes, 0 seconds)
2 errors, 0 warnings (0 minutes, 0 seconds)
</code></pre>
","<p>After exhaustively troubleshooting everything, I finally noticed that I had accidentally linked the program to the 64-bit version of SDL while compiling for 32-bit, and now the project compiles and links effortlessly.</p>
","58971"
"Calculate random points (pixel) within a circle (image)","8159","","<p>I have an image that contains a circles at a specific location, and of a specific diameter. What I need to do is to be able to calculate random points within the circle, and then manipulate the pixels said points correlate to. I have the following code already:</p>

<pre><code>private Point CalculatePoint()
{
    var angle = _random.NextDouble() * ( Math.PI * 2 );
    var x = _originX + ( _radius * Math.Cos( angle ) );
    var y = _originY + ( _radius * Math.Sin( angle ) );
    return new Point( ( int )x, ( int )y );
}
</code></pre>

<p>And that works fine for finding all the points at the circumference of the circle, but I need all points from anywhere in the circle. If this doesn't make sense let me know and I will do my best to clarify.</p>
","<p>If you want a simple solution just randomize the radius too:</p>

<pre><code>private Point CalculatePoint()
{
    var angle = _random.NextDouble() * Math.PI * 2;
    var radius = _random.NextDouble() * _radius;
    var x = _originX + radius * Math.Cos(angle);
    var y = _originY + radius * Math.Sin(angle);
    return new Point((int)x,(int)y);
}
</code></pre>

<p>That however results in your points being more concentrated towards the center of the circle:</p>

<p><img src=""https://i.stack.imgur.com/FEFgd.png"" alt=""enter image description here""></p>

<p>In order to get an uniform distribution make the following change to the algorithm:</p>

<pre><code>var radius = Math.Sqrt(_random.NextDouble()) * _radius;
</code></pre>

<p>Which will give the following result:</p>

<p><img src=""https://i.stack.imgur.com/ni59s.png"" alt=""enter image description here""></p>

<p>For more information check the following link: <a href=""http://mathworld.wolfram.com/DiskPointPicking.html"" rel=""nofollow noreferrer"">MathWorld - Disk Point Picking</a>.</p>

<p>And finally here's a simple <a href=""http://jsfiddle.net/d9VRu/"" rel=""nofollow noreferrer"">JsFiddle demonstration</a> comparing both version of the algorithm.</p>
","26714"
"First time shadow mapping problems","8158","","<p>I have implemented basic shadow mapping for the first time in OpenGL using shaders and I'm facing some problems. Below you can see an example of my rendered scene:</p>

<p><img src=""https://i.stack.imgur.com/VxvNS.jpg"" alt=""enter image description here""></p>

<p>The process of the shadow mapping I'm following is that I render the scene to the framebuffer using a View Matrix from the light point of view and the projection and model matrices used for normal rendering.</p>

<p>In the second pass, I send the above MVP matrix from the light point of view to the vertex shader which transforms the position to light space. The fragment shader does the perspective divide and changes the position to texture coordinates.</p>

<p>Here is my vertex shader,</p>

<pre><code>
#version 150 core

uniform mat4 ModelViewMatrix;
uniform mat3 NormalMatrix;
uniform mat4 MVPMatrix;
uniform mat4 lightMVP;

uniform float scale;

in vec3 in_Position;
in vec3 in_Normal;
in vec2 in_TexCoord;

smooth out vec3 pass_Normal;
smooth out vec3 pass_Position;
smooth out vec2 TexCoord;
smooth out vec4 lightspace_Position;

void main(void){
    pass_Normal = NormalMatrix * in_Normal; 
    pass_Position = (ModelViewMatrix * vec4(scale * in_Position, 1.0)).xyz;
    lightspace_Position = lightMVP * vec4(scale * in_Position, 1.0);
    TexCoord = in_TexCoord;

    gl_Position = MVPMatrix * vec4(scale * in_Position, 1.0);
}
</code></pre>

<p>And my fragment shader,</p>

<pre><code>
#version 150 core

struct Light{
    vec3 direction;
};

uniform Light light;
uniform sampler2D inSampler;
uniform sampler2D inShadowMap;

smooth in vec3 pass_Normal;
smooth in vec3 pass_Position;
smooth in vec2 TexCoord;
smooth in vec4 lightspace_Position;

out vec4 out_Color;


float CalcShadowFactor(vec4 lightspace_Position){

    vec3 ProjectionCoords = lightspace_Position.xyz / lightspace_Position.w;

    vec2 UVCoords;
    UVCoords.x = 0.5 * ProjectionCoords.x + 0.5;
    UVCoords.y = 0.5 * ProjectionCoords.y + 0.5;

    float Depth = texture(inShadowMap, UVCoords).x;
    if(Depth &lt (ProjectionCoords.z + 0.001)) return 0.5;
    else return 1.0;
}

void main(void){

    vec3 Normal = normalize(pass_Normal);
    vec3 light_Direction = -normalize(light.direction);
    vec3 camera_Direction = normalize(-pass_Position);
    vec3 half_vector = normalize(camera_Direction + light_Direction);

    float diffuse = max(0.2, dot(Normal, light_Direction));
    vec3 temp_Color = diffuse * vec3(1.0);

    float specular = max( 0.0, dot( Normal, half_vector) );

    float shadowFactor = CalcShadowFactor(lightspace_Position);

    if(diffuse != 0 && shadowFactor &gt 0.5){
        float fspecular = pow(specular, 128.0);
        temp_Color += fspecular;
    }

    out_Color = vec4(shadowFactor * texture(inSampler, TexCoord).xyz * temp_Color, 1.0);
}
</code></pre>

<p>One of the problems is self shadowing as you can see in the picture, the crate has its own shadow cast on itself. What I have tried is enabling polygon offset (i.e. glEnable(POLYGON_OFFSET_FILL), glPolygonOffset(GLfloat, GLfloat) ) but it didn't change much. As you see in the fragment shader, I have put a static offset value of 0.001 but I have to change the value depending on the distance of the light to get more desirable effects , which not very handy. I also tried using front face culling when I render to the framebuffer, that didn't change much too.</p>

<p>The other problem is that pixels outside the Light's view frustum get shaded. The only object that is supposed to be able to cast shadows is the crate. I guess I should pick more appropriate projection and view matrices, but I'm not sure how to do that. What are some common practices, should I pick an orthographic projection?</p>

<p>From googling around a bit, I understand that these issues are not that trivial. Does anyone have any easy to implement solutions to these problems. Could you give me some additional tips?</p>

<p>Please ask me if you need more information on my code.</p>

<p><a href=""https://i.imgur.com/ATOQh.jpg"" rel=""nofollow noreferrer"">Here</a> is a comparison with and without shadow mapping of a close-up of the crate. The self-shadowing is more visible.</p>
","<p>You should not shadow the polygons that are back faced from the light.</p>

<p>I changed your fragment shader to below code.</p>

<pre><code>float CalcShadowFactor(vec4 lightspace_Position)
{

    vec3 ProjectionCoords = lightspace_Position.xyz / lightspace_Position.w;

    vec2 UVCoords;
    UVCoords.x = 0.5 * ProjectionCoords.x + 0.5;
    UVCoords.y = 0.5 * ProjectionCoords.y + 0.5;

    float Depth = texture(inShadowMap, UVCoords).x;
    if(Depth &lt; (ProjectionCoords.z + 0.001)) return 0.5;
    else return 1.0;
}

void main(void)
{

    vec3 Normal = normalize(pass_Normal);
    vec3 light_Direction = -normalize(light.direction);
    vec3 camera_Direction = normalize(-pass_Position);
    vec3 half_vector = normalize(camera_Direction + light_Direction);

    float fndotl = dot(Normal, light_Direction);
    float shadowFactor = CalcShadowFactor(lightspace_Position);
    float diffuse = max(0.0, fndotl) * shadowFactor + 0.2;
    vec3 temp_Color = vec3(diffuse);

    float specular = max( 0.0, dot( Normal, half_vector) );

    if(shadowFactor &gt; 0.9){
        float fspecular = pow(specular, 128.0);
        temp_Color += fspecular;
    }

    out_Color = vec4(shadowFactor * texture(inSampler, TexCoord).xyz * temp_Color, 1.0);
}
</code></pre>
","30085"
"How can I save my game state so it can be resumed when my application resumes?","8127","","<p>I've found that after resuming my game the whole engine is reloaded and application is reinitialized. I want to save engine state and in ""onResume,"" resume the game process from where it left off.</p>

<p>I've tried to save the engine (mEngine) and then after resume the game in ""onLoadEngine"" return saved engine. I think it is a bad solution and it doesn't work anyway.</p>

<p>What is the best solution for resuming my game (after the power key was pressed, for example) in AndEngine ?</p>
","<p>Since the game state is going to be specific to your game, there isn't built in functionality for this in the engine. One solution would be to write the state information you want to keep to an XML file. Likely you'd want to load this saved state in your <code>onStart()</code> function. But really that's up to you and how you want your game to behave.</p>

<p>There's a blog post about the flow between states, and when to save and load states: <a href=""http://www.andengine.org/forums/post25660.html#p25660"" rel=""nofollow"">http://www.andengine.org/forums/post25660.html#p25660</a></p>

<p>And information on how to read/write a file:
<a href=""http://www.anddev.org/write_to_and_read_from_a_file-t3173.html"" rel=""nofollow"">http://www.anddev.org/write_to_and_read_from_a_file-t3173.html</a></p>
","22969"
"OpenGL Insanely Slow","8124","","<p>I'm learning C++, and I'm writing my first OpenGL program. Unfortunately, it seems to be defaulting to Software Rendering (CPU uses bounces, GPU uses stays at 1%). I'm using SDL as the Windowing system. I've got no idea why, but when there is significant scaling, the program grinds to a halt. My PC should be able to handle it - I'm using an 8800GTX. My texture is 1024x1024, 32 bit RGBA and loaded with DevIL,  and glGetString(GL_VENDOR) is returning ""NVidia Corporation"". Any ideas?</p>

<p>I'm sorry to be dumping all the code, but I've got absolutely no idea at all what is doing it. I'm very new to OpenGL.</p>

<pre><code>#pragma once
#include ""SDL.h""
#include ""SDL_opengl.h""7
#include ""IL/il.h""
#include ""IL/ilut.h""
#include &lt;math.h&gt;    

const int SCREEN_WIDTH = 1024;
const int SCREEN_HEIGHT = 768;
const int SCREEN_BPP = 32;
const int FPS = 60;
const int XSIZE = 1024; 
const int YSIZE = 768;

int main( int argc, char *argv[] )
{
    bool quit = false;

    SDL_Init(SDL_INIT_EVERYTHING);
    SDL_GL_SetAttribute(SDL_GL_DOUBLEBUFFER, 1);
    SDL_GL_SetAttribute(SDL_GL_RED_SIZE, 8);
    SDL_GL_SetAttribute(SDL_GL_GREEN_SIZE, 8);
    SDL_GL_SetAttribute(SDL_GL_BLUE_SIZE, 8);
    SDL_GL_SetAttribute(SDL_GL_ALPHA_SIZE, 8);

    SDL_SetVideoMode(SCREEN_WIDTH, SCREEN_HEIGHT, SCREEN_BPP, SDL_HWSURFACE |  SDL_OPENGL);     

    glEnable(GL_TEXTURE_2D);

    const GLubyte * Vendor = glGetString(GL_VENDOR);

    glClearColor(0.0f, 0.0f, 0.0f, 1.0f); // Clear the background of our window to red      
    glMatrixMode (GL_PROJECTION);
    glLoadIdentity ();
    glOrtho(0, XSIZE, YSIZE, 0, 0, 1);
    glMatrixMode (GL_MODELVIEW);

    glDisable(GL_DEPTH_TEST);

    GLuint image;

    ilInit();
    ilutRenderer(ILUT_OPENGL);  

    ILuint texid;
    ILboolean success;
    ilGenImages(1, &amp;texid);
    ilBindImage(texid);

    success = ilLoadImage(""Textures.png"");
    if (success)
    {
        success = ilConvertImage(IL_RGBA, IL_UNSIGNED_BYTE);
        if (!success)
        {
            SDL_Quit();
            return -1;
        }
        glGenTextures(1, &amp;image);
        glBindTexture(GL_TEXTURE_2D, image);
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER,
        GL_NEAREST);
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER,
        GL_NEAREST);
        glTexImage2D(GL_TEXTURE_2D, 0, ilGetInteger(IL_IMAGE_BPP), ilGetInteger(IL_IMAGE_WIDTH),
          ilGetInteger(IL_IMAGE_HEIGHT), 0, ilGetInteger(IL_IMAGE_FORMAT), GL_UNSIGNED_BYTE,
          ilGetData());
        ilDeleteImages(1, &amp;texid);
    }
    else
    {
        SDL_Quit();
        return -2;
    }


    SDL_Event event;

    float x = 0.0f;

    while (!quit) 
    {
        while ( SDL_PollEvent(&amp;event) )
        {
            switch (event.type)
            {
                case SDL_QUIT:
                    quit = true;
                    break;
            }
        }

        glClear(GL_COLOR_BUFFER_BIT);

        glLoadIdentity();
        glTranslatef(200.0f, 200.0f, 0.0f);
        glRotatef(x,0.0f,0.0f, 1.0f);       
        glScalef(1.0f+x, 1.0f+x, 1.0f+x);
        glBegin(GL_QUADS);      
        glTexCoord2f(0.0f, 0.0f);
        glVertex2f(-100, -100); 
        glTexCoord2f(0.0f, 0.119140f);      
        glVertex2f(-100, 100); 
        glTexCoord2f(0.091797f, 0.119140f);
        glVertex2f(100, 100); 
        glTexCoord2f(0.091797f, 0.0f);
        glVertex2f(100, -100);
        glEnd();

        x += 0.1f;

        SDL_GL_SwapBuffers();
        glFlush;        
    }

    return 0;
}
</code></pre>

<p>Edit : (24/04/2011 9.22 PM AEST)
When run on an ancient card, on an ancient computer, it maintains ~60FPS.</p>
","<p>I've got no idea why, but it seems to have repaired itself. I even put a NPOT texture to test and I'm still getting very, very reasonable FPS rates. I don't think I've changed anything, and I've really got not idea at all why it is fixed. I'm sorry that this doesn't seem to be really answering the question. If anybody else can decipher why - you're doing better then me.</p>

<p>My final source is below:</p>

<pre><code>#pragma once
#include ""SDL.h""
#include ""SDL_opengl.h""
#include ""IL/il.h""
#include ""IL/ilut.h""
#include &lt;math.h&gt;    
#include &lt;fstream&gt;

const int SCREEN_WIDTH = 1024;
const int SCREEN_HEIGHT = 768;
const int SCREEN_BPP = 32;
const int FPS = 60;
const int XSIZE = 1024; 
const int YSIZE = 768;

using namespace std;

int main( int argc, char *argv[] )
{
bool quit = false;

SDL_Init(SDL_INIT_EVERYTHING);
SDL_GL_SetAttribute(SDL_GL_DOUBLEBUFFER, 1);
SDL_GL_SetAttribute(SDL_GL_RED_SIZE, 8);
SDL_GL_SetAttribute(SDL_GL_GREEN_SIZE, 8);
SDL_GL_SetAttribute(SDL_GL_BLUE_SIZE, 8);
SDL_GL_SetAttribute(SDL_GL_ALPHA_SIZE, 8);

SDL_SetVideoMode(SCREEN_WIDTH, SCREEN_HEIGHT, SCREEN_BPP, SDL_HWSURFACE |  SDL_OPENGL);     

glEnable(GL_TEXTURE_2D);

const GLubyte * Vendor = glGetString(GL_VENDOR);

glClearColor(0.0f, 0.0f, 0.0f, 1.0f); // Clear the background of our window to red      
glMatrixMode (GL_PROJECTION);
glLoadIdentity ();
glOrtho(0, XSIZE, YSIZE, 0, 0, 1);
glMatrixMode (GL_MODELVIEW);

glDisable(GL_DEPTH_TEST);

GLuint image;

ilInit();
ilutRenderer(ILUT_OPENGL);  

ILuint texid;
ILboolean success;
ilGenImages(1, &amp;texid);
ilBindImage(texid);

success = ilLoadImage(""Textures.png"");

    Uint32 startclock = 0;
Uint32 deltaclock = 0;
Uint32 currentFPS = 0;      
startclock = SDL_GetTicks();
deltaclock = SDL_GetTicks();

fstream Log;
Log.open(""log.txt"", ios::out | ios::trunc);
Log.clear();    

if (success)
{
    success = ilConvertImage(IL_RGBA, IL_UNSIGNED_BYTE);
    if (!success)
    {
        SDL_Quit();
        return -1;
    }
    glGenTextures(1, &amp;image);
    glBindTexture(GL_TEXTURE_2D, image);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER,
    GL_NEAREST);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER,
    GL_NEAREST);
    glTexImage2D(GL_TEXTURE_2D, 0, ilGetInteger(IL_IMAGE_BPP), ilGetInteger(IL_IMAGE_WIDTH),
      ilGetInteger(IL_IMAGE_HEIGHT), 0, ilGetInteger(IL_IMAGE_FORMAT), GL_UNSIGNED_BYTE,
      ilGetData());
    ilDeleteImages(1, &amp;texid);
}
else
{
    SDL_Quit();
    return -2;
}


SDL_Event event;

float x = 0.0f;

while (!quit) 
{
    while ( SDL_PollEvent(&amp;event) )
    {
        switch (event.type)
        {
            case SDL_QUIT:
                quit = true;
                break;
        }
    }

    glClear(GL_COLOR_BUFFER_BIT);

    glLoadIdentity();
    glTranslatef(200.0f, 200.0f, 0.0f);
    glRotatef(x,0.0f,0.0f, 1.0f);       
    glScalef(1.0f+x, 1.0f+x, 1.0f+x);
    glBegin(GL_QUADS);      
    glTexCoord2f(0.0f, 0.0f);
    glVertex2f(-100, -100); 
    glTexCoord2f(0.0f, 0.119140f);      
    glVertex2f(-100, 100); 
    glTexCoord2f(0.091797f, 0.119140f);
    glVertex2f(100, 100); 
    glTexCoord2f(0.091797f, 0.0f);
    glVertex2f(100, -100);
    glEnd();

    x += 0.1f;

    SDL_GL_SwapBuffers();

    deltaclock = SDL_GetTicks() - startclock;
    startclock = SDL_GetTicks();
    if ( deltaclock != 0 )  currentFPS = 1000 / deltaclock; 
    static char buffer[20] = {0}; 
    sprintf( buffer, ""%d "", currentFPS ); 
    SDL_WM_SetCaption( buffer,0 ); 

    if (currentFPS &lt; 4) { quit = true ;}

    Log &lt;&lt; buffer;

}
Log.close();
return 0;
}
</code></pre>
","11555"
"How to deal with differences between 2D screen coordinates and Cartesian coordinates","8110","","<ul>
<li>Most 2D screen/bitmap coordinate systems have the positive Y axis pointing <em>down</em> (with the the origin in the upper left corner).</li>
<li>This is counter to how most people think geometrically with the positive Y axis pointing <em>up</em> (with the origin in the center).</li>
</ul>

<p><strong>How do most games manage the two different 2D coordinate systems?</strong> There are two main types of coordinates (screen vs. Cartesian), but there could be many different coordinate spaces: sprite space, world space, view space, screen space, etc... </p>

<p><strong>Background:</strong></p>

<p>I originally made the world coordinates in my game match the 2D screen coordinate convention. This made it very natural to use the graphics drawing routines, but subtle issues arose when using trigonometric functions like atan2(). The results of feeding atan2() 2D screen coordinates are very confusing because atan2() assumes the positive y axis points up.</p>

<p>So I changed my world coordinates to follow the classic Cartesian coordinate system (with the origin at the bottom left of the screen). Reasoning with atan2() is much more straight-forward, but now it is harder to do other types of reasoning:</p>

<ul>
<li>If I click the screen here, what sprite is underneath?</li>
<li>Where did I click on that sprite?</li>
<li>If a sprite is drawn in the wrong location, what was calculated incorrectly? The screen coordinates or the world coordinates?</li>
</ul>

<p>I realize conversion from screen to Cartesian coordinates involves simply scaling the y value by -1 with an optional translation of both (x,y) values. I'm more interested in best practices for game design:</p>

<ul>
<li>Do most games just stick with the screen coordinate convention and change their thinking about how things like atan2() should work?</li>
<li>When/how are coordinate system conversions done? (Using matrices, OOP abstraction, etc)</li>
<li>Are sprite locations stored as the center of the sprite or one of the corners? The sprite's height/width going in the ""wrong"" direction seems to be a common problem when I draw them.</li>
</ul>

<p>Although my question is mainly about 2D games, it seems OpenGL uses a coordinate system where the Y axis points up. OpenGL must eventually project those 3D coordinates onto a 2D screen coordinate system. Perhaps some guidance could be found in OpenGL's method...</p>
","<p>Having tried every conceivable way of doing it, I have found if it's purely a 2D game, just use the screen drawing system, it will make your life much easier. Sin, Cos, and atan2 need to be used slightly differently, but this inconvenience is easily made up for by the simplicity of knowing which way up, down, clockwise and anti-clockwise are. I would also recommend working in pixels rather than meters for 2D games - it's much easier to think about on-screen distances, and the chances of you wanting to change the whole scale of your game are close to zero.</p>

<p>""How do most games manage the two different 2D coordinate systems?""</p>

<ul>
<li>most 2D games I've seen the source for use the screen system, but each entity should know its world space, let your drawing manager convert this to a screen position. At this point you'll do whatever matrix transformation you need.</li>
</ul>

<p>""Are sprite locations stored as the center of the sprite or one of the corners?""</p>

<ul>
<li>If you work from the centre it makes rotation more straight forward, although you'll want to know the corners as well.</li>
</ul>

<p>""Perhaps some guidance could be found in OpenGL's method...""</p>

<ul>
<li>3D engines are a completely different case. As they have true cameras, the screen position can be wildly different from the world position. For a top-down game you'd be working in the X and Z axes, rather than the X and Y for one thing.</li>
</ul>
","2484"
"How do I create a simple clickable button?","8094","","<p>I've tried to attach this function to the play button.</p>

<pre><code>public void Play () {
    Application.LoadLevel(""Scene1"");
}
</code></pre>

<p>I've created an empty <strong>Game Object</strong> and attached my script to it. But when I go to the <code>OnClick()</code> method in the Play button and try to select my <code>Play()</code> method can't find it, there is only a bunch of useless functions that do nothing to help me load the level.</p>

<p>And apparently most tutorials and forum posts suggest doing it this way, but it doesn't work for me.</p>

<p>Other posts say that you can assign the <code>OnClick()</code>-method in your script and show how to assign the function, but no one remembered to mention how to get the button object to which I could assign the function.</p>

<p>I'm new to unity and this problem is getting very frustrating. I'm using the free version of Unity for now.</p>
","<p><strong>I am assumming you are trying to make a GameObject that, when clicked, will load another level. If so, continue on with this answer. If not, explain what you want in the comments below or in your question.</strong>
<br><br>
<strong>Note: In this case, I am going to use the OnMouseButton() method, since it would suit your needs perfectly</strong></p>

<hr>

<h1>Steps</h1>

<h3>Step One: Preparation</h3>

<p>I would make a Game Object that would act as the button<br>
<em>This includes:</em></p>

<ul>
<li>A 3D Model with a Collider (Cube)</li>
<li>A 2D Sprite with a 2D Collider (Sprite)</li>
<li><em>An OnGUI Element:</em> <strong>Note, OnGUI is redundant and most would recomend the next option</strong></li>
<li>Unity 4.6 GUI Object</li>
</ul>

<p><strong>In this case, I will make an empty cube</strong><br>
<img src=""https://i.stack.imgur.com/6Ciol.png"" alt=""enter image description here"">
<br><h3>Step Two: Coding</h3>Now, create a new script or use an existing script for controlling the play button. In this case, I will make a script called PlayButton, but the following code will work on an existing script</p>

<pre><code>using UnityEngine;
using System.Collections;

public class PlayButton : MonoBehaviour {
    void Start() {

    }

    void Update() {

    }
}
</code></pre>

<p>Now, what we are going to use is the method <strong>OnMouseDown()</strong>, which will run when the cursor clicks the game object. Also, we do not need the <strong>Start()</strong> and <strong>Update()</strong> methods, so we will remove them from the script.</p>

<pre><code>using UnityEngine;
using System.Collections;

public class PlayButton : MonoBehaviour {
    void OnMouseDown() {
    }
}
</code></pre>

<p>From here we can do one of two things. We can directly load the next level inside this block of code, or we could call another block of code that would load the next level. I will do both for example sake. In the first example, we will add the code <strong>Application.LoadLevel(""Scene1"")</strong>, which will simply load the level <strong>Scene1</strong></p>

<pre><code>using UnityEngine;
using System.Collections;

public class PlayButton : MonoBehaviour {
    void OnMouseDown() {
        Application.LoadLevel(""Scene1"");
    }
}
</code></pre>

<p>And that's it! Skip to the next step if that is all you want. If you would rather call a separate method that loads the next level, look down a bit further before moving to the next step.</p>

<p>Now, I am going to make a method, called <strong>Play()</strong>, that will load the next level. This code will be activated when I click on the Game Object that holds this code. The <strong>OnMouseDown()</strong> method will simply trigger the <strong>Play()</strong> method, rather than actually loading the level itself.</p>

<pre><code>using UnityEngine;
using System.Collections;

public class PlayButton : MonoBehaviour {
    void OnMouseDown() {
        Play();
    }
    void Play() {
        Application.LoadLevel(""Scene1"");
    }
}
</code></pre>

<h3>Step Three: End</h3>

<p>All you need to do now is to attach the script onto a Game Object that you would like to be the play button, in this case it will be Red Cube. Then Click the Play Button to activate the game and see if it works out.
<img src=""https://i.stack.imgur.com/hdbfy.png"" alt=""enter image description here""><img src=""https://i.stack.imgur.com/3es6K.png"" alt=""enter image description here"">
<h1>REMEMBER:</h1>Make sure that you added the scene to the Build Settings, or else it will not work out properly. Search on Google to find out how to do that if you are not familiar with it.<br><hr><h1>References/More Info</h1>
<a href=""http://docs.unity3d.com/ScriptReference/MonoBehaviour.OnMouseDown.html"" rel=""nofollow noreferrer"">Unity Script Reference: OnMouseDown()</a><img src=""https://i.stack.imgur.com/PCKMu.png"" alt=""enter image description here""></p>
","90747"
"How to determine counter-clockwise vertex winding","8092","","<p>I've been causing myself some confusion lately with regards to vertex winding in a mesh class that i'm writing.</p>

<p>Currently, the mesh contains the appropriate structures for:</p>

<ul>
<li>vertices (vector3)</li>
<li>indices (vector3 - actually a custom struct of 3 ints)</li>
<li>normals (vector3)</li>
<li>colors (vector4)</li>
</ul>

<p>Starting out simple, i'm trying to model a cuboid with 24 vertices and 12 indices. What is causing me confusion at the moment is how vertex winding is determined for each face. OpenGL-ES seems to be set to counter clockwise winding by default (which can be changed) but i'm really not sure how CCW is determined in 3 dimensions?</p>

<p>It was my understanding that the ""front"" and ""back"" of an object would be defined by the direction of the vector for each vertices normal, rather than the ordering of each vertex that defines a ""face"". It would seem however that this isn't true. Either that, or (more likely) my code isn't entirely correct. </p>

<p>If this isn't the case, how is CCW defined in 3 dimensions? How does this translate for the 6 faces of a cuboid? If I use the same logic for the back face of the cuboid as the front face, surely one of the faces would point inwards? </p>

<p>I'm really struggling to get my head around this when manually defining vertices for my mesh. The confusion really kicks in when I try to work out how vertex data is stored in a model/mesh file created by MAYA or Blender etc. Are all faces oriented outwards when an object is exported?</p>

<p>Or perhaps my original assumption was correct whereby the normals define what is to be determined as the front of each face, but then why does OpenGL have a flag for specifying the vertex winding order?</p>

<p>Also, considering the three vectors A, B and C; surely the same winding (regardless of orientation) could be achieved in three different ways, i.e: A->B->C or B->C->A or C->A->B?</p>

<p>Is there a simple way for determining such things or have I completely missed the mark somewhere?</p>
","<p>OpenGL actually has two sets of normals for every face: one you supply with the <code>GL_NORMAL</code> vertex attribute and one it determines with the winding. This second normal is used to discard faces in backface culling and is determined through the following formula:</p>

<pre><code>// http://glm.g-truc.net - OpenGL Mathematics library

glm::vec3 a, b, c;
glm::vec3 ab = b - a;
glm::vec3 ac = c - a;
glm::vec3 normal = glm::normalize(glm::cross(ab, ac));
</code></pre>

<p>If you are confused about the winding of your vertices, try calculating this normal yourself and rendering it on your faces. You can then easily spot where you made a logical error.</p>

<p><strong>EDIT:</strong></p>

<p>Suppose you have a set of vertices and you absolutely have to make sure what the winding is. </p>

<p>Given the face <code>P</code> with vertices <code>a</code>, <code>b</code> and <code>c</code>.</p>

<pre><code>// calculate three axes

glm::vec3 axis_x = glm::normalize(b - a);
glm::vec3 axis_y = glm::normalize(c - a);
glm::vec3 axis_z = glm::cross(axis_x, axis_y);

// construct a transform matrix from our axes

glm::mat3x3 object_transform;
object_transform[0] = axis_x;
object_transform[1] = axis_y;
object_transform[2] = axis_z;

// invert the matrix

glm::mat3x3 object_to_world_transform = glm::inverse(object_transform);

// transform the outward normal using the matrix

glm::vec3 normal = object_to_world_transform * axis_z;

// check winding

if (normal.z &gt; 0.f)
{
    // Counter-clockwise winding
}
else
{
    // Clockwise winding
}
</code></pre>

<p>Note: I didn't have time to check this! I might have reversed the check for winding at the end. I'll edit when I get home.</p>
","30539"
"What happened to .fx files in D3D11?","8090","","<p>It seems they <em>completely</em> ruined .fx file loading / parsing in D3D11.</p>

<p>In D3D9, loading an <em>entire</em> effect file was D3DXCreateEffectFromFile( .. ), and you got a <a href=""http://msdn.microsoft.com/en-us/library/bb205788%28VS.85%29.aspx""><code>ID3DXEffect9</code></a>, which had great methods like <code>SetTechnique</code> and <code>BeginPass</code>, making it easy to load and execute a shader with multiple techniques.</p>

<p>Is this completely manual now in D3D11?  The highest level functionality I can find is loading a SINGLE shader from an FX file using <a href=""http://msdn.microsoft.com/en-us/library/ff476261%28VS.85%29.aspx""><code>D3DX11CompileFromFile</code></a>.</p>

<p>Does anyone know if there's an easier way to load FX files and choose a technique?  With the level of functionality provided in D3D11 now, it seems like you're better off just writing .hlsl files and forgetting about the whole idea of Techniques.</p>
","<p>The effect functionality was refactored. It's fundamentally the same set of operations, you just have more control over them -- similar to how the D3D10+ interface redesign does mostly the same stuff as the 9 API, but affords you a more direct model of the hardware or driver to work with. The cost of this change to you is more verbosity in your code; more steps you have to take (often with more parameters) to reach a similar result.</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ff728664%28v=vs.85%29.aspx"">D3D11 no longer ships binaries for the Effect API; it was moved to separate library which is provided as source (in the SDK sample directory)</a> and you must compile it yourself. This was done to help divorce the versioning of the effect API from the versioning of the D3D API itself, which is tied to the Windows SDK). It also lets interested parties optimize and customize the API for their needs, as appropriate.</p>

<p>The HLSL compiler is still part of the core API (d3dcompiler_XX.dll) and can be used to <a href=""http://msdn.microsoft.com/en-us/library/dd607324%28v=VS.85%29.aspx"">turn .fx or HLSL source into compiled bytecode</a>. That in-memory bytecode can, in turn, be used to <a href=""http://msdn.microsoft.com/en-us/library/dd607324%28v=VS.85%29.aspx"">produce an effect from the Effects11 API</a>.</p>
","17606"
"Rendering performance for Flash games","8082","","<p>I was reading on SO about <a href=""https://stackoverflow.com/questions/1018074/flash-performance-for-game-dev-native-render-vs-bitmapdata-framebuffer"">native flash rendering vs building a custom <code>BitmapData</code> frame buffer</a> and some of the answers were a bit conflicting, so I was wondering:</p>

<ol>
<li>Is it generally best practice to go the custom Bitmap buffer route or is it best to leave rendering to the flash engine?</li>
<li>If you're using vector animations (<code>MovieClip</code>s) as opposed to sprites, does that change the answer to the above?</li>
<li>If so is it best practice to use sprite based animations?</li>
</ol>

<p>(I'm targeting Flash 10 if that makes any difference)</p>
","<p><strong>1. There is no general best practice.</strong> </p>

<p>If you got a lot of (complex shaped) elements, particles etc. in your game, the bitmap buffer approach is going to be <em>much</em> faster. The bitmap buffer will also scale better with increasing complexity of your sprites. The vector renderer <em>will</em> become slower with more complex shapes or tween (shape tween) animations, it has some other benefits though: </p>

<ul>
<li>You can freely scale your assets or even zoom into the scene without loss of quality.</li>
<li>Rotation or other transformations like skewing will be much easier to perform on vector graphics</li>
</ul>

<p>So in conclusion, it boils down to what kind of game you're building.</p>

<p><strong>2. Using MovieClips instead of bitmap sprite-sheets</strong></p>

<p>I guess you meant ""bitmap sprite-sheets"" and not the AS3 <em>Sprite</em> class?</p>

<p>This doesn't make a difference, really. You can always turn your MovieClip based animations into animated bitmaps. Either manually, <a href=""https://gamedev.stackexchange.com/questions/335/what-is-a-good-tool-for-producing-animated-sprites/385#385"">by exporting the movie to frames and turn them into a sprite-sheet</a>, or dynamically, by rendering a sprite sheet from your MovieClip at runtime. Here's how I would do this:</p>

<ol>
<li>Create an instance of the MovieClip and <code>stop()</code> it.</li>
<li>Create a <code>new BitmapData</code> object with the same width and height as the Movieclip.</li>
<li>Use the <a href=""http://help.adobe.com/en_US/FlashPlatform/reference/actionscript/3/flash/display/BitmapData.html?allClasses=1#draw%28%29"" rel=""nofollow noreferrer"">draw()</a> method, to render the MovieClip to the BitmapData.</li>
<li>Store the BitmapData object in an Array or Vector.</li>
<li>Go to the next frame of your MovieClip and repeat Steps 2 - 4, do this until you reached the last frame of your MovieClip. It's also a good idea to update two variables with the <em>max width</em> and <em>max height</em> of your MovieClip frames (since these can change from frame to frame).</li>
<li>Now you can combine all the stored BitmapData Objects into a Sprite-Sheet (use <a href=""http://help.adobe.com/en_US/FlashPlatform/reference/actionscript/3/flash/display/BitmapData.html?allClasses=1#copyPixels%28%29"" rel=""nofollow noreferrer"">BitmapData.copyPixels()</a>)</li>
</ol>

<p><strong>3. Sprite-based animations</strong></p>

<p>As mentioned in the answer to your first question, there's no definite answer to that. If you need to perform a lot of transformations with your objects, eg. <em>scaling</em> and <em>rotating</em> you're probably better off by using the flash native renderer. If you got pre-defined animations that can be baked to sprite-sheets (manually or dynamically), <strong>and</strong> if you need to display hundreds of sprites at the same time, then go for a bitmap-rendering engine.</p>
","1142"
"What Java class should I use to represent a Vector?","8082","","<p>Does Java have a built-in Vector class suitable for handling collision detection / response? It should have methods like <code>subtract(Vector v)</code>, <code>normalize()</code>, <code>dotProduct(Vector v)</code>, ...</p>

<p>It seems logical to use <code>java.awt.Rectangle</code> and <code>java.awt.Polygon</code> to calculate collisions. Would I be right to use these classes for this purpose?</p>

<p>I understand collision detection; I'm only wondering what approach to it is idiomatic in Java. I'm new to the language and to application development in general.</p>
","<p>There is no built in math Vector class. You'll have to implement your own or use a library like <a href=""http://jscience.org/"" rel=""nofollow"">JScience</a> - its project page is <a href=""http://java.net/projects/jscience"" rel=""nofollow"">here</a>.</p>

<p>EDIT: As comment below suggested, JScience isn't really designed for gaming application is missing some optimizations. A more game oriented vector math API can be found in <a href=""http://libgdx.badlogicgames.com/nightlies/docs/api/com/badlogic/gdx/math/Vector2.html"" rel=""nofollow"" title=""libgdx vector class"">libgdx</a>. I imagine it should not be too difficult to extract just the <a href=""https://github.com/libgdx/libgdx/tree/master/gdx/src/com/badlogic/gdx/math"" rel=""nofollow"">math classes from libgdx</a>.</p>
","26431"
"Simple game engines / development tools made with artists in mind?","8069","","<p>I've been working in the 2d art side of games for a while now, and my full time job keeps me very busy on the art side of things, but I'm becoming more and more interested in learning to prototype my own games.</p>

<p>I know very very little programming, though I did take some in college (in TorqueScript, of all things), and while I could probably take the time to learn it, the learning curve is a bit too steep for me as it's completely separated from my current job.</p>

<p>I'm wondering if there are any game engines out there with an interface designed with artists in mind, where the learning curve might be easier for me, and where my current skill set will be more easily applied. I bought an indy license for Torque Game Builder but it still requires a lot of scripting and finding good, basic, entry-level tutorials is proving difficult.</p>

<p>Basically I'm looking for a tool where I can focus on the art and game design, and where the programming is minimal, or is easy to learn and has really excellent documentation. No idea if anything like that exists, but it's worth a shot. :]</p>

<p>Any ideas?</p>
","<p>My recommendation would be to check out <a href=""http://unity3d.com/"">Unity</a>, as it is one of the simplest, yet deceptively powerful, engines I have run across. The engine is <a href=""http://unity3d.com/support/documentation/"">well documented</a>, <a href=""http://unity3d.com/support/community"">the community</a> is very active and friendly, and there are a number of <a href=""http://unity3d.com/support/resources/tutorials/"">tutorials</a> available to help you get up to speed.</p>

<p><strong>Update:</strong> Although Unity has a bit of a learning curve, I chose to recommend it over other engines for a couple of reasons:</p>

<ul>
<li><strong>Workflow</strong> - Unlike simpler engines out there, Unity uses a workflow that is similar in many aspects to what is used in the game industry, meaning that your time spent learning is an investment toward your career, not just learning a tool.</li>
<li><strong>Support</strong> - Unity has a very active and friendly community, which is something a lot of smaller engines don't have.</li>
<li><strong>Power</strong> -  Unity comes with a lot of features and supports a number of platforms.</li>
</ul>
","4692"
"Game ideas for a platformer","8065","","<p>I have created a platformer which currently has the features listed below. I would greatly appreciate any further ideas which I could implement! (I don't play a lot of games which is why I require help)</p>

<ul>
<li>Walking/jumping/movement</li>
<li>player can shoot lasers</li>
<li>enemies also walk, fly, and shoot lasers</li>
<li>water (you can swim in this)</li>
<li>mud (slows you down on contact, and stops you from jumping)</li>
<li>ladders</li>
<li>damage when falling from a large height, unless falling into water</li>
<li>moving platforms</li>
<li>springboards (jumping on them shoot you into the air)</li>
<li>growing platforms (allow you to reach new places)</li>
<li>key and door system</li>
<li>gem and coin collection system</li>
<li>teleporting</li>
<li>turrets</li>
</ul>
","<p>Interesting and strategic AI behavior.</p>

<p>At all costs avoid the syndrome of enemies that run in a line toward the player weapon fire.  Games where the player walking backward and firing is the winning strategy undermine any other cool things you might have put in.</p>

<p>Enemies should show some sense of self-preservation by means of: taking cover, keeping distance, holding back until sufficient numbers of team mates are available for an assault, coordinated use of different weapons systems, character support roles to heal the injured.</p>

<p>Some degree of AI unpredictability is also helpful to keep things interesting.</p>
","9482"
"FBO Depth Buffer not working","8055","","<p>I'm trying to get the depth buffer for my 2D game working by offsetting the z value of the rectangles. For some reason, <em>my depth buffer is coming back empty</em>. The value is always 0. I'm assuiming there is something wrong with how I attach the depth buffer to the FBO? But I've looked over that code many times and don't see anything wrong with it. Let me know if you need more information.</p>

<ul>
<li>I have depth testing enabled with GL_LEQUAL. </li>
<li>I have znear and zfar set to 1.f, -10.f and I have 9 quads setup at three different depths.</li>
<li>I have set glClearDepth(1.0) and I clear bot the COLOR_BUFFER_BIT and DEPTH_BUFFER_BIT before I draw to the FBO, however the value is still 0. </li>
</ul>

<p>FBO setup:</p>

<pre><code>RenderTarget::RenderTarget(int width, int height) {

    mWidth = width;
    mHeight = height;
    mVbo = 0;

    // Create the color buffer
    glGenTextures(1, &amp;mTextureId);
    glBindTexture(GL_TEXTURE_2D, mTextureId);
    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, mWidth, mHeight, 0, GL_RGBA, GL_UNSIGNED_BYTE, NULL);


    // Create the depth buffer
    glGenTextures(1, &amp;mDepth);
    glBindTexture(GL_TEXTURE_2D, mDepth);
    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
    glTexImage2D(GL_TEXTURE_2D, 0, GL_DEPTH_COMPONENT32, mWidth, mHeight, 0, GL_RED, GL_BYTE, NULL);

    /*glGenRenderbuffers(1, &amp;mDepth);
    glBindRenderbuffer(GL_RENDERBUFFER, mDepth);
    glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT32, mWidth, mHeight);*/

    // Create the frame buffer
    glGenFramebuffers(1, &amp;mFbo);
    glBindFramebuffer(GL_FRAMEBUFFER, mFbo);

    glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, mTextureId, 0);
    glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_TEXTURE_2D, mDepth, 0);



    GLenum err = glCheckFramebufferStatus(GL_FRAMEBUFFER);
    assert(err == GL_FRAMEBUFFER_COMPLETE);

    glBindFramebuffer(GL_FRAMEBUFFER, 0);

    createVbo();
}
</code></pre>

<p>Fragment shader</p>

<pre><code>#version 120

uniform sampler2D diffuseMap;
uniform sampler2D lightmap;
uniform sampler2D depthMap;

varying vec4 texCoord[2];

void main()
{
    vec4 color = texture2D(diffuseMap, gl_TexCoord[0].st);
    vec4 light = texture2D(lightmap, gl_TexCoord[0].st);
    vec4 depth = texture2D(depthMap, gl_TexCoord[0].st);

    vec4 final = color * vec4(0.1);
    final += color * light;
    gl_FragColor= vec4(depth.r, depth.r, depth.r, 1.0);
}
</code></pre>

<p>Method to draw sprites to the screen/framebuffer</p>

<pre><code>void GraphicsDevice::drawSprite(ISprite *sprite, float x, float y, float z, Material::TextureType type, Color c) {

    glActiveTexture(GL_TEXTURE0);
    glEnableClientState(GL_VERTEX_ARRAY);
    glEnableClientState(GL_TEXTURE_COORD_ARRAY);


    glBindBuffer(GL_ARRAY_BUFFER, sprite-&gt;getVbo());

    glBindTexture(GL_TEXTURE_2D, sprite-&gt;getMaterial()-&gt;getTexture(type)-&gt;getId());

    glPushMatrix();
    glTranslatef(x, y, z);
    glColor4f(c.r, c.g, c.b, c.a);

    glVertexPointer(3, GL_FLOAT, sizeof(Vertex), (void*)offsetof(Vertex, x));
    glTexCoordPointer(2, GL_FLOAT, sizeof(Vertex), (void*)offsetof(Vertex, tx));

    glDrawArrays(GL_TRIANGLE_STRIP, 0, 4);

    glPopMatrix();

    glBindBuffer(GL_ARRAY_BUFFER, 0);
    glDisableClientState(GL_TEXTURE_COORD_ARRAY);
    glDisableClientState(GL_VERTEX_ARRAY);

}
</code></pre>
","<p>The problem was I was creating and binding the depth buffer texture to GL_DEPTH_ATTACHMENT. I found some random code that attached the depth buffer to GL_DEPTH_STENCIL_ATTACHMENT, so I tried that out and it works exactly as I expect it to. So the new FBO code looks like this</p>

<pre><code>glTexImage2D(GL_TEXTURE_2D, 0, GL_DEPTH24_STENCIL8, mWidth, mHeight, 0, GL_DEPTH_STENCIL, GL_UNSIGNED_INT_24_8, NULL);
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_TEXTURE_2D, mDepth, 0);
</code></pre>

<p>I would really appreciate it if someone could explain why this works and my previous one doesn't.</p>
","24259"
"Looking at the mouse position in a top down Unity game?","8052","","<p>I'm trying to make a simple top down game where the player looks at wherever the mouse is pointed.  The player is only going to rotate on the Y axis.</p>

<p>Here's what I have so far but I can't seem to get it working. </p>

<pre><code>private void RotateToMouse()
{   
    //Veriables
    Vector3 ScreenMouse;
    Vector3 ShipPos;

    //Get Mouse Point ON screen
    ScreenMouse.x  = Input.mousePosition.x;
    ScreenMouse.y  = Input.mousePosition.y;
    ScreenMouse.z  = 1;

    //Get Mouse Point In World
    WorldMouse = Camera.main.ScreenToWorldPoint(ScreenMouse);
    //Get Ship Position
    ShipPos = transform.position;

    //Get Angle Of Mouse From Ship Position
    Angle = Mathf.Atan2(ShipPos.z - WorldMouse.z,ShipPos.x - WorldMouse.x) * 180 / Mathf.PI;

    transform.localEulerAngles = new Vector3(0,Angle,0);        
}
</code></pre>
","<p>Instead of using Atan2, I would suggest using the built in function <a href=""http://unity3d.com/support/documentation/ScriptReference/Transform.LookAt.html"" rel=""nofollow""><code>Transform.LookAt</code></a></p>

<p>So, after you get <code>WorldMouse</code>, just do <code>transform.LookAt( WorldMouse );</code>.</p>

<p>You <em>might</em> have to set <code>WorldMouse.y</code> equal to <code>transform.position.y</code>, but it shouldn't matter.</p>
","24268"
"how does HDR work?","8042","","<p>I'm trying to understand what HDR is and how it works.</p>

<p>I understand the basic concepts and have an slight idea of how it is implemented with D3D/hlsl.</p>

<p>However it's still pretty foggy.</p>

<p>Say I'm rendering a sphere with a texture of the earth and a small point list of vertices to act as stars, how would I render this in HDR ?</p>

<p>Here are a few things I'm confused about:</p>

<ul>
<li><p>I'm guessing, I can't use just any basic image format for the texture as the values would be limited to [0, 255] and clamped to [0, 1] in a shader. Same goes for the back buffer, I take it the format needs to be a float point format ?</p></li>
<li><p>What are the other steps involved ? Surely there has to be more than just using floating point formats to render to a render target and then apply some bloom as a post process ? (considering the output will be 8bpp anyway)</p></li>
</ul>

<p>Basically, what are the steps for HDR ? How does it work ? I can't seem to find any good papers / articles that describe the process, other than <a href=""http://www.xnainfo.com/content.php?content=28"">this one</a>, but it seems to skim over the basics a little, so it's confusing.</p>
","<p>HDR techniques allows you to simulate a greater range of detail than you can view on screen than with traditional lighting/textures. You can  compare it to how the eye behaves when exposed to different amounts of light - when there's too much light the eye lets less light in so things are still in your visible range. When there is not enough light, the iris opens more so more details can be seen.</p>

<p><img src=""https://i.stack.imgur.com/TM3yV.jpg"" alt=""bit-tech.net HDR comparison""></p>

<p>The right hand side of this image is using HDR. It makes more use of the range of colors, the darks are darker and the bright areas are brighter. In comparison the left hand side of the image looks a little flat.</p>

<p>The basic steps are:</p>

<ol>
<li><p>Render your scene to floating point texture (with a format such as A16B16G16R16F) using
other floating point textures on your models, and/or lights
that may have a brightness greater than
1.0f.</p></li>
<li><p>To display this texture the range of
visible colors needs to be converted
to something displayable on your
screen - this process is called
<a href=""http://en.wikipedia.org/wiki/Tone_mapping"" rel=""noreferrer"">tone mapping</a>, and a variety of
different tone mapping equations can
be used to get different effects.
This is a must since monitors can't
display the full range of colors or luminescence that we
can store in floating point
textures (it would be cool if it was
possible, but it would also be a
blinding hazard...).</p></li>
<li><p>Bloom and other after effects are
added to further exaggerate the
difference in luminescence of the
things rendered. The bloom is calculated from the floating point buffer and combined with the tone mapped image.</p></li>
</ol>

<p><em>Hope that helps</em></p>
","12531"
"Should actors in a game be responsible for drawing themselves?","8041","","<p>I am very new to game development, but not to programming.</p>

<p>I am (again) playing around with a Pong type game using JavaScript's <code>canvas</code> element.</p>

<p>I have created a <code>Paddle</code> object which has the following properties...</p>

<ul>
<li><code>width</code></li>
<li><code>height</code></li>
<li><code>x</code></li>
<li><code>y</code></li>
<li><code>colour</code></li>
</ul>

<p>I also have a <code>Pong</code> object which has properties such as...</p>

<ul>
<li><code>width</code></li>
<li><code>height</code></li>
<li><code>backgroundColour</code></li>
<li><code>draw()</code>.</li>
</ul>

<p>The <code>draw()</code> method currently is resetting the <code>canvas</code> and that is where a question came up.</p>

<p>Should the <code>Paddle</code> object have a <code>draw()</code> method responsible for its drawing, or should the <code>draw()</code> of the <code>Pong</code> object be responsible for drawing its actors (I assume that is the correct term, please correct me if I'm incorrect).</p>

<p>I figured that it would be advantagous for the <code>Paddle</code> to draw itself, as I instantiate two objects, <code>Player</code> and <code>Enemy</code>. If it were not in the <code>Pong</code>'s <code>draw()</code>, I'd need to write similar code twice.</p>

<p>What is the best practice here?</p>

<p>Thanks.</p>
","<p>Having actors draw themselves is not a good design, for two main reasons:</p>

<p>1) it violates the <a href=""http://en.wikipedia.org/wiki/Single_responsibility_principle"">single responsibility principle</a>, as those actors presumably had another job to do before you shoved render code into them.</p>

<p>2) it makes extension difficult; if every actor type implements its own drawing, and you need to change the way you draw <em>in general</em>, you may have to modify a lot of code. Avoiding overuse of inheritance can alleviate this to some extent, but not completely.</p>

<p>It's better for your renderer to be handling the drawing. After all, that's what it means to be a renderer. The renderer's draw method should take a ""render description"" object, which contains everything you need to render a thing. References to (probably shared) geometry data, instance-specific transformations or material properties such as color, et cetera. It then draws that, and doesn't care what that render description is supposed to ""be.""</p>

<p>Your actors can then hold on to a render description they create themselves. Since actors are typically logic processing types, they can push state changes to the render description as needed -- for example, when an actor takes damage it could set the color of its render description to red to indicate this.</p>

<p>Then you can simply iterate every visible actor, enqeue their render descriptions into the renderer, and let it do its thing (basically; you could generalize this even further).</p>
","14138"
"Unable to connect to UDP server using ip as hostname","8033","","<p>i have a little promblem. When i connect to my UDP server using localhost as a hostname, everything goes fine, but when i use my ip as a hostname, the client cant connect to the server. What could couse such issue? As i know the server and the client are fine, because i had the same problem with other servers. But if i'm not right, i give you the code...
Server:</p>

<pre><code>import java.io.*;
import java.net.*;
import java.util.*;

public class UDPServer extends Thread {
    public final static int PORT = 7331;
    private final static int BUFFER = 1024;

    private DatagramSocket socket;
    private ArrayList&lt;InetAddress&gt; clientAddresses;
    private ArrayList&lt;Integer&gt; clientPorts;
    private HashSet&lt;String&gt; existingClients;
    public UDPServer() throws IOException {
        socket = new DatagramSocket(PORT);
        clientAddresses = new ArrayList();
        clientPorts = new ArrayList();
        existingClients = new HashSet();
    }

    public void run() {
        byte[] buf = new byte[BUFFER];
        while (true) {
            try {
                Arrays.fill(buf, (byte)0);
                DatagramPacket packet = new DatagramPacket(buf, buf.length);
                socket.receive(packet);

                String content = new String(buf, buf.length);

                InetAddress clientAddress = packet.getAddress();
                int clientPort = packet.getPort();

                String id = clientAddress.toString() + "","" + clientPort;
                if (!existingClients.contains(id)) {
                    existingClients.add( id );
                    clientPorts.add( clientPort );
                    clientAddresses.add(clientAddress);
                }

                System.out.println(id + "" : "" + content);
                byte[] data = (id + "" : "" +  content).getBytes();
                for (int i=0; i &lt; clientAddresses.size(); i++) {
                    InetAddress cl = clientAddresses.get(i);
                    int cp = clientPorts.get(i);
                    packet = new DatagramPacket(data, data.length, cl, cp);
                    socket.send(packet);
                }
            } catch(Exception e) {
                System.err.println(e);
            }
        }
    }

    public static void main(String args[]) throws Exception {
        UDPServer s = new UDPServer();
        s.start();
    }
}
</code></pre>

<p>Client:</p>

<pre><code>import java.io.*;
import java.net.*;
import java.util.*;


class MessageSender implements Runnable {
    public final static int PORT = 7331;
    private DatagramSocket sock;
    private String hostname;
    MessageSender(DatagramSocket s, String h) {
        sock = s;
        hostname = h;
    }
    private void sendMessage(String s) throws Exception {
        byte buf[] = s.getBytes();
        InetAddress address = InetAddress.getByName(hostname);
        DatagramPacket packet = new DatagramPacket(buf, buf.length, address, PORT);
        sock.send(packet);
    }
    public void run() {
        boolean connected = false;
        do {
            try {
                sendMessage(""GREETINGS"");
                connected = true;
            } catch (Exception e) {

            }
        } while (!connected);
        BufferedReader in = new BufferedReader(new InputStreamReader(System.in));
        while (true) {
            try {
                while (!in.ready()) {
                    Thread.sleep(100);
                }
                sendMessage(in.readLine());
            } catch(Exception e) {
                System.err.println(e);
            }
        }
    }
}
class MessageReceiver implements Runnable {
    DatagramSocket sock;
    byte buf[];
    MessageReceiver(DatagramSocket s) {
        sock = s;
        buf = new byte[1024];
    }
    public void run() {
        while (true) {
            try {
                DatagramPacket packet = new DatagramPacket(buf, buf.length);
                sock.receive(packet);
                String received = new String(packet.getData(), 0, packet.getLength());
                System.out.println(received);
            } catch(Exception e) {
                System.err.println(e);
            }
        }
    }
}
public class UDPClient {

    public static void main(String args[]) throws Exception {
        String host = null;
        if (args.length &lt; 1) {
            System.out.println(""Usage: java ChatClient &lt;server_hostname&gt;"");
            System.exit(0);
        } else {
            host = args[0];
        }
        DatagramSocket socket = new DatagramSocket();
        MessageReceiver r = new MessageReceiver(socket);
        MessageSender s = new MessageSender(socket, host);
        Thread rt = new Thread(r);
        Thread st = new Thread(s);
        rt.start(); st.start();
    }
}
</code></pre>
","<p>As the above commenters were mentioning, you are probably in a subnet behind a router using a NAT configuration. This gives your network one single external IP. You need to figure out and use your local IP in the network. Use ipconfig/ifconfig (depends on your OS) to figure this out. For Windows, open a command prompt. (Click start then run and enter ""cmd"") And then enter ""ipconfig"", you can then find your IPv4 address under the relevant device/connection.</p>

<p>Ok, so going to elaborate a little more. In this case your phone is the router. If it's configured to use NAT, it can only have one external IP for all the devices in it's subnet. You can connect to the ""outside"" but they can't explicitly connect to you. In order to remedy this you're going to have to adjust your phone settings or connect using an alternative.</p>

<p>For a better and more specific explanation check out <a href=""http://www.howstuffworks.com/nat.htm"" rel=""nofollow"">this</a> page I grabbed from the top of a google search.</p>
","23720"
"Are there game engines like Unity but for 2D?","8030","","<p>I really like the convenience of unity3d.  The ability to edit the level and see my results in real time are great.  My problem is the idea I want to implement is 2d and uses 2d sprites.  Scaling sprites appears to be a problem for me and all advice I receive says to purchase 150 dollars addons for unity. I love the physics components and the rapid prototyping but I figured that maybe unity is not the tool for the job for this 2d game.    </p>

<p>Is there any 2d game engine like unity but for 2d games that would work on the PC and Android?  Or is this something most people code themselves and make?  To me the most important features of Unity3d were its ease to see what was edited and then have it apply instantly. </p>

<p>Thank you. Most searches seemed to give me frameworks and not a large engine suite.  </p>
","<p><a href=""http://flashpunk.net/"">Flashpunk</a> is a free library for Flex which provides a lot of functionality for 2D games. It doesn't have real time level editing, but there are tile based editors you can use to easily produce levels such as the <a href=""http://ogmoeditor.com/"">Ogmo Editor</a>.</p>
","24868"
"How can I use Rectangle.Intersect() to resolve collisions in XNA?","8029","","<p>I have a 2D game written in XNA, and I've been trying to fine-tune my collision resolution. All of my game objects are squares, which means detecting a collision is easy - use the position and the size of each entity (which is already known) to craft a corresponding <code>Rectangle</code>, then compare the two with <code>Rectangle.Intersect()</code>.</p>

<p>This works fine for the most part, but has been running into weird corner cases where the collision resolution doubles an entity's jump height, or gets caught between tiles when moving horizontally across a flat surface.</p>

<p>I have recently expanded my code to include a velocity for each game entity, and I thought it would be possible to avoid some of these problems by preventing the need for these resolutions in the first place.</p>

<p>The idea would be to use an entity's position + velocity to predict a collision, then reduce the velocity to prevent a collision from occurring in the first place.</p>

<p>I can still use <code>Rectangle.Intersect()</code> to determine if the entity is in a collision, but I'm horribly confused on how to go from the <code>Rectangle</code> returned by <code>Rectangle.Intersect()</code> to an appropriate velocity counter-vector to avoid the collision.</p>

<p>Is there a straightforward way to go from the intersection <code>Rectangle</code> to an appropriate counter-velocity?</p>
","<p>I've actually implemented this just the other day. I started from the XNA Platformer Sample but noticed it had a few problems on corner cases. This was especially noticeable when using it for Zelda-like movement, because the character would get stuck between tiles when hugging the walls in <em>a certain direction</em>. I tried several changes to the algorithm, but there would always be one direction where the problem would appear.</p>

<p>I looked around a bit, and although I was skeptic, ended up trying a simple solution that I read in one forum - and it worked! So, instead of moving the player all at once and then resolving each collision along the smallest axis of intersection depth, the trick was to update and resolve on the X and Y axes separately. The process is still very similar to before, except for that difference. In other words:</p>

<ol>
<li>Apply horizontal velocity to your position.</li>
<li>Round position.X to prevent jittering on some edge cases.</li>
<li>Iterate through each obstacle that the player is intersecting, calculating the horizontal intersection depth and subtracting it from the player's position so that he no longer intersects that obstacle.</li>
<li>Repeat 1-3 but for the vertical axis.</li>
</ol>

<p>And so far it seems to be working, even when trying different player sizes and movement speeds, and ""hugging"" every wall in every direction. I've also noticed that as long as I cap the maximum instantaneous speed to the smallest value between the player's size and the tile's size, then he won't ever funnel through the walls. And that's still moving pretty fast!</p>

<p>I intended to clean it up a little, maybe make it completely generic, and release on my blog one of these days. But meanwhile I'll just drop every relevant bit of the code in a pastie, albeit unorganized, so you can read through it:</p>

<p><a href=""http://pastie.org/3152377"">http://pastie.org/3152377</a></p>

<p>And <a href=""http://www.youtube.com/watch?v=5-D0PGdoDDY"">here's a little video</a> of that code in action, where I'm forcibly trying to push against every wall. I used normal a player size slightly smaller than the tile, and a normal movement speed, but I've also tested with many different values.</p>

<p><strong>Edit</strong> </p>

<p>By the way, I'm using a custom method to get the intersection depth (basically the one from the Platformer sample modified to work on 1 dimension at a time) instead of <code>Rectangle.Intersect</code>. That's mostly because while <code>Rectangle.Intersect</code> gives you the depth, it does not give you the direction of the intersection, so you'd need to do some extra checks to find that out.</p>
","22119"
"What's the state of the art in Space Partitioning for games?","8020","","<p>I know about BSP trees, Octrees and Portal that where used for a long time. But modern games still use this systems or they are using new things?</p>

<p>If it's possible with pros and cons, considering rendering and collision detection.</p>
","<p>Yes, the Unreal engine 3 for instance still uses a BSP -- mainly because it's used during the CSG process. Doom3/id tech 4 uses portals, and I think I've read something that id Tech 5 is back to BSP trees. There are some games which use octrees, too. In game, my understanding is that UE3 moved to a more dynamic approach with occlusion queries, but I would be surprised if they don't use the BSP to at least determine which static meshes are in sight. Other games might just use view-frustum culling (Civilization for instance.) It really depends on what type of game you look.</p>

<p>The reason that BSPs and stuff is still around is because you can't do much better. If you have static geometry, a BSP is great if you construct it right. It requires you to write a BSP builder though, which is tricky (but it might happen for free if your CSG solution uses one!) Octrees and more dynamic solutions (like relying on occlusion queries for everything) are simpler to implement, have higher runtime cost but don't require (expensive) pre-processing of the levels. That's a trade-off that some games are willing to do (Crytek for instance wants everything to run in real-time, so they don't spend processing time to build a static acceleration structure.) Other runtime approaches are for instance software rasterization on the CPU and performing occlusion queries on the CPU (this is used by the Frostbite engine.)</p>

<p>For a really modern approach, look at <a href=""http://www.umbrasoftware.com/"">Umbra</a>, which is a middleware for visibility queries. If you search the web a bit, you should find some of the master thesis which describe the early beginnings of Umbra. </p>

<p>Bottom line: Whether you want to use a BSP/Octree/no AS will highly depend on the type of game you want to create. If your levels are mostly static, you should take advantage of that and build some static acceleration structure. If everything is dynamic, you need of course another approach.</p>

<p>For collision detection, I would take a look at Bullet and PhysX and their collision detection algorithms. But my feeling is that the physics solutions are less tied to the visibility than they used to be -- a physics solution might want to use a GPU based BVH, in that case, there's not much sense to try to use that for visibility queries.</p>
","5503"
"Dungeons in a 3d space game","8015","","<p>I'm in the process of creating a prototype for a 3d space game (3rd person). My question is this:</p>

<p><strong>How can a 3d space game have Zelda-like (or similar) dungeons in open space?</strong></p>

<p><strong><em>Problems:</em></strong></p>

<ol>
<li><p>Space has no walls (obviously) - how to restrict movement?</p></li>
<li><p>No movement restrictions - no doors.</p></li>
<li><p>No doors, no interesting mechanics of opening them.</p></li>
<li><p>No backtracing (for example after acquiring new power at the end that enables access to a place at the beginning of the dungeon).</p></li>
</ol>

<p><strong><em>More info:</em></strong> <a href=""https://www.youtube.com/watch?v=fqKGl6exyyY"">The Legend of Zelda: Oracle of Ages and Seasons' dungeon design</a> - to see how some Zelda games do it.</p>

<p>The dungeon should be in 1 star system.</p>

<p>The EVE Online example is a good one, in the sense that it has been done before and it works, but for me it always somehow felt like cheating because in EVE you can travel anywhere... but not to a pocket of space right behind the dungeon gate. Even if you had a bookmark there.</p>

<p>And since my game will most likely feature even more free-form travel then EVE (think Elite: Dangerous) then what I'm saying is I'm looking for something that could improve that can be found in EVE.</p>
","<p>Level designers I've spoken with often lament how difficult it is to create interesting challenges &amp; spaces in open areas, so you've definitely set a hard problem for yourself.</p>

<p>That said, the core structure of something like a Zelda dungeon is often about finding a number of <a href=""http://tvtropes.org/pmwiki/pmwiki.php/Main/MacGuffin"" rel=""noreferrer"">MacGuffins</a> (items required to progress) or switches (locations where you modify some dungeon state) in a particular sequence. And so even without walls, you can still <strong>introduce structure via the <a href=""https://en.wikipedia.org/wiki/Dependency_graph"" rel=""noreferrer"">dependency graph</a> of these actions</strong>.</p>

<p>Let's run through an arbitrary example (which may not directly align to your gameplay or fiction):</p>

<ul>
<li><p>The player wants to get to a warp gate to go to the next space sector (something to act as an end goal, you can replace this with whatever...)</p>

<ul>
<li>Because there's no walls, they can just fly up to it, so we have it begin in a powered-off state to put some challenge in their way.</li>
</ul></li>
<li><p>To activate it they'll need to turn on three power-beaming stations around the map.</p></li>
<li><p>One station is missing an energy crystal, so they need to go to a nearby asteroid field to collect one.</p></li>
<li><p>Another station has a turret that keeps you from getting close. The player needs to go back to the asteroid field and tow an asteroid they can use as a shield.</p></li>
<li><p>The final station is damaged, but the spare parts to fix it are in locked chests at the other two stations. The player collects a maintenance key at this station that lets them access the chests.</p></li>
<li><p>spare parts collected, they can return to the third station, repair it, then head to the warp gate to escape (and maybe fight the space monster boss lured to it by all the activity)</p></li>
</ul>

<p>This lets us construct a reasonably interesting dependency graph without a hard wall that blocks the player anywhere, and gives them cause to re-visit a few previously explored areas in a new context.</p>

<p><a href=""https://i.stack.imgur.com/M2m2E.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/M2m2E.jpg"" alt=""Diagram illustrating dependency relationships in the scenario above.""></a></p>

<p>Here the variety of interactions has to take up some of the slack left by variety of spatial layouts &amp; approach, since we have fewer tools in open space to control the latter. (Though that doesn't preclude you from introducing constrained spaces at key sites along the graph, like big space stations or wrecks the player needs to navigate into through a controlled number of doors - I avoided such cases above just to show you can get interesting dependency relationships without always going to interior spaces)</p>

<p>The other side of this challenge is <strong>landmarking.</strong> It's extremely easy to get lost and disoriented in space. If the player is to feel like they're purposefully solving challenges, rather than just chasing a waypoint, you'll need to give them tools to understand where they are and let them plan.</p>

<p>In the example above, we led the player to the asteroid field landmark to find the energy crystal, which ensured they knew it was there when they later needed an asteroid (or vice versa). Coming back to a recognizably familiar landmark like that, with a new purpose in mind, can really help a scenario feel like a space the player is exploring and mastering, rather than a sequence of arbitrary roadblocks.</p>

<p>Consider using things like gassy nebulae, debris fields, space stations, planets, etc. to give players these kinds of landmarks they can recognize.</p>
","130871"
"Unity custom shaders and z-fighting","8007","","<p>I've just readed a chapter of <strong>Unity iOS Essential</strong> by Robert Wiebe.</p>

<p>It shows a solution for handling <code>z-figthing</code> problem occuring while rendering a street on a plane with the same y offset.</p>

<p>Basically it modified Normal-Diffuse shader provided by Unity, specifing the (texture?) offset in -1, -1.</p>

<p>Here's basically what the shader looks like:</p>

<pre><code>Shader ""Custom/ModifiedNormalDiffuse"" {
    Properties {
        _Color (""Main Color"", Color) = (1,1,1,1)
        _MainTex (""Base (RGB)"", 2D) = ""white"" {}
    }
    SubShader {
        Offset -1,-1   //THIS IS THE ADDED LINE
        Tags { ""RenderType""=""Opaque"" }
        LOD 200

        CGPROGRAM
        #pragma surface surf Lambert

        sampler2D _MainTex;
        fixed4 _Color;

        struct Input {
            float2 uv_MainTex;
        };

        void surf (Input IN, inout SurfaceOutput o) {
            half4 c = tex2D (_MainTex, IN.uv_MainTex) *_Color;
            o.Albedo = c.rgb;
            o.Alpha = c.a;
        }
        ENDCG
    } 
    FallBack ""Diffuse""
}
</code></pre>

<p>Ok. That's simple and it works.
The author says about it:</p>

<blockquote>
  <p>...we could use a copy of the shader that draw the road at an Offset
  of -1, -1 so that whenever the two textures are drawn, the road is
  always drawn last.</p>
</blockquote>

<p>I don't know <code>CG</code> nor <code>GLSL</code>, but I've a little bit of experience with <code>HLSL</code>. Anyway I can't figure out what exactly is going on.</p>

<p>Could anyone explain me what exactly <code>Offset</code> directly does, and how is solves z-fighting problems?</p>
","<p>It appears to be a slightly misleading book. Offset does not change drawing order or even the 3D position of pixels. It simply adds some numbers to the Z value (the one that's going to the Z tests and Z-buffer) of a pixel (hence the term ""offset""), making it appear above or below other triangles. This is generally used to prioritize visibility of triangles with (nearly) coincident surface planes.</p>

<p>To find out, what exactly is it that the parameters change, refer to the <a href=""http://docs.unity3d.com/Documentation/Components/SL-CullAndDepth.html"">Unity ShaderLab documentation</a>.</p>

<p>As for Z-fighting... in this case, offset would shift the odds of having more visible pixels towards your road plane.</p>
","35850"
"How object-oriented are videogames?","8006","","<p>I've always wondered to what extent object orientation is used by videogames, especially huge 3D projects.
I reckon it would be cool that both <code>troll</code> and <code>werewolf</code> inherited its attributes from <code>enemy</code> and overwrote some of them. But maybe classes are too heavy to be practical, I don't know...</p>
","<p>To come to your example I will explain my thoughts about Entites in videogames. I won't discuss the general advantage and disadvantage of objects and classes, neither their whole role in Videogames.</p>

<p>Entities in small videogames are mostly defined by separate classes, in big games they are often defined in files. There are two general approaches to follow:</p>

<p><strong>Extension</strong>:
In your example <code>Troll</code> and <code>Werewolf</code> will extend <code>Enemy</code>, which extends <code>Entity</code>. <code>Entity</code> takes care about the basic things like movement, health etc., while <code>Enemy</code> would state the subclasses as enemies and do other things (Minecraft follows this approach).</p>

<p><strong>Component based</strong>: The second approach (and my favorite) is one <code>Entity</code> class, which has components. A component could be <code>Moveable</code> or <code>Enemy</code>. These components take care of <strong>one</strong> thing like movement or physics. This method breaks long Extension chains and minimizes the risk of running into a conflict. For example: <em>How can you make non-moveable Enemies, if they inherit from a moveable Character?</em>. </p>

<p>In big videogames like World of Warcraft or Starcraft 2, Entities aren't classes, but sets of data, which specify the whole Entity. Scripting is also important, because you define what the Entity does not in a Class, but in a Script (if it is unique, not things like moving). </p>

<p>I am currently programming a RTS and I take the component based approach with Descriptor and Script files for Entites, Skills, Items and everything else dynamic in the game.</p>
","14164"
"Giving a Bomberman AI intelligent bomb placement","7984","","<p>I'm trying to implement an AI algorithm for Bomberman. Currently I have a working but not very smart rudimentary implementation (the current AI is overzealous in placing bombs).</p>

<p>This is the first AI I've ever tried implementing and I'm a bit stuck. The more sophisticated algorithms I have in mind (the ones that I expect to make better decisions) are too convoluted to be good solutions.</p>

<p>What general tips do you have for implementing a Bomberman AI? Are there radically different approaches for making the bot either more defensive or offensive?</p>

<hr>

<p><strong>Edit:</strong> <em>Current algorithm</em></p>

<p>My current algorithm goes something like this (pseudo-code):</p>

<p>1) Try to place a bomb and then find a cell that is safe from all the bombs, including the one that you just placed. To find that cell, iterate over the four directions; if you can find any safe divergent cell and reach it in time (eg. if the direction is up or down, look for a cell that is found to the left or right of this path), then it's safe to place a bomb and move in that direction.</p>

<p>2) If you can't find and safe divergent cells, try NOT placing a bomb and look again. This time you'll only need to look for a safe cell in only one direction (you don't have to diverge from it).</p>

<p>3) If you still can't find a safe cell, don't do anything.  </p>

<pre><code>for $(direction) in (up, down, left, right):
    place bomb at current location
    if (can find and reach divergent safe cell in current $(direction)):
        bomb = true
        move = $(direction)
        return

for $(direction) in (up, down, left, right):
    do not place bomb at current location
    if (any safe cell in the current $(direction)):
        bomb = false
        move = $(direction)
        return

else:
    bomb = false
    move = stay_put
</code></pre>

<p>This algorithm makes the bot very trigger-happy (it'll place bombs very frequently). It doesn't kill itself, but it does have a habit of making itself vulnerable by going into dead ends where it can be blocked and killed by the other players.</p>

<p>Do you have any suggestions on how I might improve this algorithm? Or maybe I should try something completely different?</p>

<p><strong>One of the problems</strong> with this algorithm is that it tends to leave the bot with very few (frequently just one) safe cells on which it can stand. This is because the bot leaves a trail of bombs behind it, as long as it doesn't kill itself.</p>

<p>However, leaving a trail of bombs behind leaves few places where you can hide. If one of the other players or bots decide to place a bomb somewhere near you, it often happens that you have no place to hide and you die.</p>

<p>I need a better way to decide when to place bombs. </p>
","<p>The problem you're facing is that your AI never stops to make an intelligent decision about where it should place its next bomb, which leaves it just dropping bombs whenever it can and then working out ""shit, shit, what do I do now!?""</p>

<h3>Pausing to think</h3>

<p>Right now, your AI just wanders to nowhere in particular. Sometimes, however, it should actually <em>be moving to</em> a target. For instance, if it sees a powerup and thinks it can reach it before the player, perhaps it ought to find a safe path to that tile and move there, keeping an eye out for bombs and avoiding them along the way.</p>

<p>The same moving-to-target behaviour can be used when it <em>thinks about where to place its next bomb</em>.</p>

<p>When your AI can place a bomb, instead of just doing so immediately, it should briefly use a <a href=""http://en.wikipedia.org/wiki/Artificial_intelligence#Search_and_optimization"" rel=""nofollow"">search algorithm</a> to choose from the available bomb placement spots based on criteria such as:</p>

<ul>
<li>Is it nearby? (so that it doesn't walk to the diagonal opposite corner of the map each time it wants to place a bomb)</li>
<li>Is there a place I can hide from the explosion - and can I reach there before the bomb explodes?</li>
<li>Will the explosion blow up tiles and give me powerups?</li>
<li>Will it potentially attack the player? (an easier AI might avoid this in the early game, an aggressive AI will pursue this - whilst not forgetting about powerups)</li>
</ul>

<p>When this decision has been made, the AI has chosen a bomb placement spot, and a place to hide from its explosion. It can now walk to the spot, place its bomb, then walk to its hiding place. Once it reaches its hiding place, it might want to keep walking and finding bomb locations (if it has multiple bombs), provided it keeps in mind to keep out of the way of the bomb it walked here to avoid.</p>

<h3>On walking, and finding a safe path</h3>

<p>You can develop for your AI a single walk-to-point method and use this each time you want it to walk someplace. This method could use the <a href=""https://en.wikipedia.org/wiki/A%2a_search_algorithm"" rel=""nofollow"">A* search algorithm</a> to find its path.</p>

<p>In order to keep the AI safe, you may want to make it recheck its path each time a new bomb is placed. To avoid explosions, it could check the time til the bomb explodes, and consider a potential explosion tile safe to walk over if the bomb won't explode whilst it's walking through that tile - and if it's not safe, treat it as an impassable tile.</p>

<p>To give your AI faults (so it can actually be blown up sometimes) it should make calculation errors: forgetting about a bomb absent-mindedly, underestimating the explosion size or the time til the bomb explodes, etc.</p>

<p><strong>Side note:</strong> You can also make its random walking seem more purposeful by randomly picking spots to walk to, or always having a new bomb placement spot in mind to walk to, instead of just randomly picking an adjacent tile to wander to. That way it won't go wandering back and forth on the same spot as if it can't make up its mind.</p>
","25784"
"How can I fix ""the referenced script on this Behaviour is missing"" warnings?","7978","","<p>One of my game objects used to have a script that I have now deleted on purpose. Now it keeps saying this message as a warning:</p>

<blockquote>
  <p>The referenced script on this Behaviour is missing!</p>
</blockquote>

<p>How can I rid of that?</p>
","<p>Remove the missing reference from your GameObject. You attached your script to something, remove the now missing component, and done.</p>
","73845"
"View matrix in opengl","7976","","<p>Sorry for my clumsy question.
But I don't know where I am wrong at creating view matrix.</p>

<p>I have the following code:</p>

<pre><code> createMatrix(vec4f(xAxis.x, xAxis.y, xAxis.z, dot(xAxis,eye)), 
 vec4f(  yAxis.x_, yAxis.y_, yAxis.z_, dot(yAxis,eye)), 
 vec4f(-zAxis.x_, -zAxis.y_, -zAxis.z_, -dot(zAxis,eye)), 
 vec4f(0, 0, 0, 1)); //column1, column2,...
</code></pre>

<p>I have tried to transpose it, but with no success.
I have also tried to use gluLookAt(...) with success.
At the reference page, I watched the remarks about the to-be-created matrix, and it seems the same as mine. Where I am wrong?</p>
","<p>In openGl matrices are transposed in memory. So transpose the matrix is OK. But your code doesn't look correct.</p>

<p>So you are in OpenGl. OpenGl uses right handed coordinate system. And for RH is lookat function defined like this:</p>

<pre><code>zaxis = normal(cameraPosition - cameraTarget)
xaxis = normal(cross(cameraUpVector, zaxis))
yaxis = cross(zaxis, xaxis)

 xaxis.x           yaxis.x           zaxis.x          0
 xaxis.y           yaxis.y           zaxis.y          0
 xaxis.z           yaxis.z           zaxis.z          0
-dot(xaxis, cameraPosition)  -dot(yaxis, cameraPosition)  -dot(zaxis, cameraPosition)  1
</code></pre>

<p>Especialy take care about <code>zaxis = normal(cameraPosition - cameraTarget)</code> because it is the only difference between RH and LH system. </p>

<p><strong>Save it transposed and that's it</strong></p>
","8845"
"Switching renderer off/on for an object in unity using C#","7968","","<p>I have a GameObject called 'Stone' that is rendered on Game Play. I have attached a C# script called RenderOff to to make 'Stone' invisible on Game Play.</p>

<p><strong>RenderOff.cs</strong></p>

<pre><code>using UnityEngine;
using System.Collections;

public class RenderOff : MonoBehaviour {


    void Start () {

        this.gameobject.renderer.enabled = false;

    }

}
</code></pre>

<p>It has errors - <strong>Type 'RenderOff' does not contain a definition for <code>gameobject' and no extension method</code>gameobject' of type `RenderOff' could be found</strong>.</p>

<p>What does that mean ?</p>
","<p><code>gameObject</code> is case-sensitive.</p>

<p>If you're using Unity 4.x, you should be able to disable a renderer like so:</p>

<pre><code>this.gameObject.renderer.enabled = false;
</code></pre>

<p>If you're using Unity 5.x, the shortcut to <code>.renderer</code> has been removed. Instead, you'll need to call:</p>

<pre><code>this.gameObject.GetComponent&lt;Renderer&gt;().enabled = false;
</code></pre>

<p>Note too that you can also get away with not using <code>this.gameObject</code>, and just use <code>gameObject</code> instead:</p>

<pre><code>gameObject.GetComponent&lt;Renderer&gt;().enabled = false;
</code></pre>
","98399"
"Rendering SVG art directly in XNA","7964","","<p>Suppose I have a bunch of 2D art in some vectorized format such as SVG. Is there an easy-ish way to render that directly without having to implement a full SVG renderer myself?</p>

<p>Of course I could rasterize it off-line (e.g. in the content pipeline) for different resolutions/zoom levels, but I would like to maintain the crisp visuals at continuous zoom levels that vector graphics offer.</p>
","<p>A good question. I was experimenting with this at one point - I couldn't find a easy, pre-built solution. But let me point you to some of the resources I found when attempting to implement it myself:</p>

<hr>

<p>First of all there's an article from GPU Gems 3: <a href=""http://http.developer.nvidia.com/GPUGems3/gpugems3_ch25.html"">Rendering Vector Art on the GPU</a> (and the associated <a href=""http://research.microsoft.com/~cloop/LoopBlinn05.pdf"">Loop-Blinn paper</a>).</p>

<p>The hardest part is that, while drawing quadratic curves are easy, cubic curves (like those found in your typical SVG) are considerably harder. The article goes into detail on this, but you'll need to bring your maths hat.</p>

<p>The alternative to rendering cubic curves is to convert the cubic curves to quadratic ones. Also a non-trivial problem.</p>

<p>Once you can render vector curves on the GPU, it's a simple matter of parsing the SVG in your content pipeline and turning it into a mesh that you can render. <strong>Parsing SVG is easy</strong>, by the way.</p>

<p>Another, potentially easier alternative is to forego curves all together and simply triangulate a linear approximation of your SVG.</p>

<p>Both these solutions require triangulation - <a href=""http://triangulator.codeplex.com/"">here's a reasonable triangulator suited to XNA</a>.</p>

<hr>

<p>As a completely different alternative, you can use a ""distance field"" to render sprites with nearly-vector-like sharp edges.</p>

<p>Here is a paper from Valve from SIGGRAPH 2007 on how to do this: <a href=""http://www.valvesoftware.com/publications/2007/SIGGRAPH2007_AlphaTestedMagnification.pdf"">Improved Alpha-Tested Magniﬁcation for Vector Textures and Special Effects</a> (PDF)</p>

<p>The basic method here is very easy to implement. The difficulty comes when trying to make it support sharp corners (something only touched on in the paper). This method also has some pretty severe limitations for anything but drawing simple shapes. It's best suited to UI text and decals (like Valve is using it for).</p>

<hr>

<p>Now that I've said all that -  I have to say that, in my experience, all the effort here is not worth it!</p>

<p>Unless your <em>gameplay</em> is going to be based primarily around <strong><em>extreme</em></strong> vector zooming effects like the very cool <a href=""http://pouet.net/prod.php?which=50131"">Masagin</a> demo, you can get away with pre-rendering your SVG and simply using bitmap techniques (easier, better supported, etc).</p>

<p>(One of the first techniques that comes to mind is <a href=""http://blogs.msdn.com/b/shawnhar/archive/2009/09/14/texture-filtering-mipmaps.aspx"">mipmapping</a> (<a href=""http://en.wikipedia.org/wiki/Mipmap"">wiki</a>) high-resolution versions of your sprites, to give you resolution independence up until your maximum sprite size.)</p>

<p><a href=""http://wam-games.com/2010/04/svg-in-xna/"">This blog post</a> is probably a good place to get started adding SVG rendering support to your XNA content pipeline.</p>
","2228"
"How do I Sync data from client to server?","7963","","<p>I'm trying to Sync data from the client to the server using the new Unity Networking, and I'm failing for some reason.</p>

<p>I've set up a prefab with a <code>NetworkIdentity</code> component with the attribute <code>Local Player Authority</code> set.</p>

<p>I (manually) spawn that on the server, and it is correctly propagated to the clients.</p>

<p>I have a couple of vars on this class, which the client sets and the server should read:</p>

<pre><code>public class PlayerController : NetworkBehaviour
{
    [SyncVar] public bool engineOn;
    [SyncVar] public Quaternion lookAt;
</code></pre>

<p>The client correctly sets them, however the server never receives them, they always stay at the default value.</p>

<p>What might be happening?</p>
","<p><code>[SyncVar]</code> only sends messages from the server to the client.
You need <code>[Command]</code>.</p>
","103619"
"Couldn't all games avoid post-start loading?","7946","","<p>Just like giant open world games load massive maps dynamically, couldn't we load separate maps, menus, and virtually any interface or 3D setting via that same dynamic loading method? Without changing the environment, it seem like interfaces and various locations within the game could all be loaded dynamically the same way massive open world maps are loaded as you walk through them. </p>

<p>Why isnt this done? I see so many modern games where you have to wait a minute or more while the match / map / level is loading. I know there's a latency involved with connecting peers but that doesnt take more than a few moments in my experience. What issues exists with this concept to stop it from being used to eliminate loading time involved with loading map / level / interface data?</p>
","<p>The answer is yes, this could be done, in most cases, at least to some extent. </p>

<p>The reasons it isn't done are many:</p>

<ul>
<li>It requires time and money to do it right. </li>
<li>The amount of bugs that pass testing will be higher</li>
<li>Load times are accepted by the users.</li>
<li>There can be other reasons for load times, such as balancing server load.</li>
<li>Generic solutions that can be bought off the shelf are more compatible with ""load all at once"".</li>
</ul>
","120581"